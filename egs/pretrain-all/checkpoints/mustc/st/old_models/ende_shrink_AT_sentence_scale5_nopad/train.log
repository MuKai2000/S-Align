2023-07-13 13:01:29 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:10096
2023-07-13 13:01:29 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:10096
2023-07-13 13:01:29 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-13 13:01:29 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:10096
2023-07-13 13:01:29 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-13 13:01:29 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:10096
2023-07-13 13:01:29 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-13 13:01:29 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:10096
2023-07-13 13:01:29 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-13 13:01:29 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:10096
2023-07-13 13:01:29 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-13 13:01:29 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:10096
2023-07-13 13:01:29 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-13 13:01:29 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:10096
2023-07-13 13:01:29 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-13 13:01:29 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-13 13:01:29 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:01:29 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:01:29 | INFO | fairseq.distributed.utils | initialized host test1 as rank 0
2023-07-13 13:01:29 | INFO | fairseq.distributed.utils | initialized host test1 as rank 4
2023-07-13 13:01:29 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:01:29 | INFO | fairseq.distributed.utils | initialized host test1 as rank 2
2023-07-13 13:01:29 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:01:29 | INFO | fairseq.distributed.utils | initialized host test1 as rank 6
2023-07-13 13:01:29 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:01:29 | INFO | fairseq.distributed.utils | initialized host test1 as rank 7
2023-07-13 13:01:29 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:01:29 | INFO | fairseq.distributed.utils | initialized host test1 as rank 1
2023-07-13 13:01:29 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:01:29 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:01:29 | INFO | fairseq.distributed.utils | initialized host test1 as rank 5
2023-07-13 13:01:29 | INFO | fairseq.distributed.utils | initialized host test1 as rank 3
2023-07-13 13:01:31 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:10096', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-13 13:01:31 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-13 13:01:31 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-13 13:01:31 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-13 13:01:31 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-13 13:01:31 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-13 13:01:36 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-13 13:01:36 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-13 13:01:36 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-13 13:01:39 | INFO | root | load pretrained hubert
2023-07-13 13:01:39 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-13 13:01:41 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-13 13:01:42 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-13 13:01:42 | INFO | root | share the sematic adapter and textual encoder
2023-07-13 13:01:42 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-13 13:01:42 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-13 13:01:42 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-13 13:01:42 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-13 13:01:42 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-13 13:01:42 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-13 13:01:42 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-13 13:01:42 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:01:42 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:01:42 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 13:01:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-13 13:01:53 | INFO | torch.distributed.distributed_c10d | Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:2 (world_size=8, worker_count=4, timeout=0:30:00)
2023-07-13 13:01:54 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-13 13:01:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-13 13:01:54 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-13 13:01:54 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:01:54 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:01:54 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:01:54 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:01:54 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:01:54 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:01:54 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:01:54 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:01:54 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-13 13:01:54 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-13 13:01:54 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-13 13:01:54 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt
2023-07-13 13:01:54 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt
2023-07-13 13:01:54 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-13 13:01:54 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-13 13:01:54 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:01:54 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:01:56 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 13:01:58 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 13:02:00 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
Traceback (most recent call last):
  File "/workspace/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/workspace/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/workspace/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 240, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 198, in start_processes
    while not context.join():
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 1 terminated with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/workspace/fairseq-AT/fairseq/distributed/utils.py", line 328, in distributed_main
    main(cfg, **kwargs)
  File "/workspace/fairseq-AT/fairseq_cli/train.py", line 164, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/workspace/fairseq-AT/fairseq/checkpoint_utils.py", line 272, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/workspace/fairseq-AT/fairseq/trainer.py", line 725, in get_train_iterator
    self.reset_dummy_batch(batch_iterator.first_batch)
  File "/workspace/fairseq-AT/fairseq/data/iterators.py", line 372, in first_batch
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/workspace/fairseq-AT/fairseq/data/iterators.py", line 372, in <listcomp>
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/workspace/fairseq-AT/fairseq/data/round_robin_zip_datasets.py", line 56, in __getitem__
    [
  File "/workspace/fairseq-AT/fairseq/data/round_robin_zip_datasets.py", line 57, in <listcomp>
    (key, dataset[self._map_index(key, index)])
  File "/workspace/fairseq-AT/fairseq/data/concat_dataset.py", line 39, in __getitem__
    return self.datasets[dataset_idx][sample_idx]
  File "/workspace/fairseq-AT/fairseq/data/audio/triple_dataset.py", line 180, in __getitem__
    source= get_features_or_waveform(
  File "/workspace/fairseq-AT/fairseq/data/audio/audio_utils.py", line 188, in get_features_or_waveform
    return get_waveform(
  File "/workspace/fairseq-AT/fairseq/data/audio/audio_utils.py", line 109, in get_waveform
    waveform, sample_rate = convert_waveform(
  File "/workspace/fairseq-AT/fairseq/data/audio/audio_utils.py", line 46, in convert_waveform
    import torchaudio.sox_effects as ta_sox
  File "/usr/local/lib/python3.8/dist-packages/torchaudio-2.0.2-py3.8-linux-x86_64.egg/torchaudio/__init__.py", line 1, in <module>
    from torchaudio import (  # noqa: F401
  File "/usr/local/lib/python3.8/dist-packages/torchaudio-2.0.2-py3.8-linux-x86_64.egg/torchaudio/_extension/__init__.py", line 43, in <module>
    _load_lib("libtorchaudio")
  File "/usr/local/lib/python3.8/dist-packages/torchaudio-2.0.2-py3.8-linux-x86_64.egg/torchaudio/_extension/utils.py", line 61, in _load_lib
    torch.ops.load_library(path)
  File "/usr/local/lib/python3.8/dist-packages/torch/_ops.py", line 641, in load_library
    ctypes.CDLL(path)
  File "/usr/lib/python3.8/ctypes/__init__.py", line 373, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: /usr/local/lib/python3.8/dist-packages/torchaudio-2.0.2-py3.8-linux-x86_64.egg/torchaudio/lib/libtorchaudio.so: undefined symbol: _ZNK5torch8autograd4Node4nameEv

2023-07-13 13:04:22 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:12661
2023-07-13 13:04:22 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:12661
2023-07-13 13:04:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-13 13:04:22 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:12661
2023-07-13 13:04:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-13 13:04:22 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:12661
2023-07-13 13:04:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-13 13:04:22 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:12661
2023-07-13 13:04:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-13 13:04:22 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:12661
2023-07-13 13:04:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-13 13:04:22 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:12661
2023-07-13 13:04:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-13 13:04:22 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:12661
2023-07-13 13:04:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-13 13:04:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-13 13:04:22 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:04:22 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:04:22 | INFO | fairseq.distributed.utils | initialized host test1 as rank 2
2023-07-13 13:04:22 | INFO | fairseq.distributed.utils | initialized host test1 as rank 0
2023-07-13 13:04:22 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:04:22 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:04:22 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:04:22 | INFO | fairseq.distributed.utils | initialized host test1 as rank 4
2023-07-13 13:04:22 | INFO | fairseq.distributed.utils | initialized host test1 as rank 7
2023-07-13 13:04:22 | INFO | fairseq.distributed.utils | initialized host test1 as rank 1
2023-07-13 13:04:22 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:04:22 | INFO | fairseq.distributed.utils | initialized host test1 as rank 3
2023-07-13 13:04:22 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:04:22 | INFO | fairseq.distributed.utils | initialized host test1 as rank 5
2023-07-13 13:04:22 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:04:22 | INFO | fairseq.distributed.utils | initialized host test1 as rank 6
2023-07-13 13:04:24 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12661', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-13 13:04:24 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-13 13:04:24 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-13 13:04:24 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-13 13:04:24 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-13 13:04:24 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-13 13:04:29 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-13 13:04:29 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-13 13:04:29 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-13 13:04:32 | INFO | root | load pretrained hubert
2023-07-13 13:04:35 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-13 13:04:35 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-13 13:04:36 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-13 13:04:36 | INFO | root | share the sematic adapter and textual encoder
2023-07-13 13:04:36 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-13 13:04:36 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-13 13:04:36 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-13 13:04:36 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-13 13:04:36 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-13 13:04:36 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-13 13:04:36 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-13 13:04:36 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:04:36 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:04:36 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 13:04:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-13 13:04:43 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-13 13:04:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-13 13:04:43 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-13 13:04:43 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:04:43 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:04:43 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:04:43 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:04:43 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:04:43 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:04:43 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:04:43 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:04:43 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-13 13:04:43 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-13 13:04:43 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-13 13:04:43 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt
2023-07-13 13:04:43 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt
2023-07-13 13:04:43 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-13 13:04:43 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-13 13:04:43 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:04:43 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:04:45 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 13:04:47 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 13:04:48 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
Traceback (most recent call last):
  File "/workspace/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/workspace/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/workspace/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 240, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 198, in start_processes
    while not context.join():
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 4 terminated with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/workspace/fairseq-AT/fairseq/distributed/utils.py", line 328, in distributed_main
    main(cfg, **kwargs)
  File "/workspace/fairseq-AT/fairseq_cli/train.py", line 164, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/workspace/fairseq-AT/fairseq/checkpoint_utils.py", line 272, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/workspace/fairseq-AT/fairseq/trainer.py", line 725, in get_train_iterator
    self.reset_dummy_batch(batch_iterator.first_batch)
  File "/workspace/fairseq-AT/fairseq/data/iterators.py", line 372, in first_batch
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/workspace/fairseq-AT/fairseq/data/iterators.py", line 372, in <listcomp>
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/workspace/fairseq-AT/fairseq/data/round_robin_zip_datasets.py", line 56, in __getitem__
    [
  File "/workspace/fairseq-AT/fairseq/data/round_robin_zip_datasets.py", line 57, in <listcomp>
    (key, dataset[self._map_index(key, index)])
  File "/workspace/fairseq-AT/fairseq/data/concat_dataset.py", line 39, in __getitem__
    return self.datasets[dataset_idx][sample_idx]
  File "/workspace/fairseq-AT/fairseq/data/audio/triple_dataset.py", line 180, in __getitem__
    source= get_features_or_waveform(
  File "/workspace/fairseq-AT/fairseq/data/audio/audio_utils.py", line 188, in get_features_or_waveform
    return get_waveform(
  File "/workspace/fairseq-AT/fairseq/data/audio/audio_utils.py", line 109, in get_waveform
    waveform, sample_rate = convert_waveform(
  File "/workspace/fairseq-AT/fairseq/data/audio/audio_utils.py", line 46, in convert_waveform
    import torchaudio.sox_effects as ta_sox
  File "/usr/local/lib/python3.8/dist-packages/torchaudio-2.0.2-py3.8-linux-x86_64.egg/torchaudio/__init__.py", line 1, in <module>
    from torchaudio import (  # noqa: F401
  File "/usr/local/lib/python3.8/dist-packages/torchaudio-2.0.2-py3.8-linux-x86_64.egg/torchaudio/_extension/__init__.py", line 43, in <module>
    _load_lib("libtorchaudio")
  File "/usr/local/lib/python3.8/dist-packages/torchaudio-2.0.2-py3.8-linux-x86_64.egg/torchaudio/_extension/utils.py", line 61, in _load_lib
    torch.ops.load_library(path)
  File "/usr/local/lib/python3.8/dist-packages/torch/_ops.py", line 641, in load_library
    ctypes.CDLL(path)
  File "/usr/lib/python3.8/ctypes/__init__.py", line 373, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: /usr/local/lib/python3.8/dist-packages/torchaudio-2.0.2-py3.8-linux-x86_64.egg/torchaudio/lib/libtorchaudio.so: undefined symbol: _ZNK5torch8autograd4Node4nameEv

2023-07-13 13:13:41 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:15097
2023-07-13 13:13:41 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:15097
2023-07-13 13:13:41 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:15097
2023-07-13 13:13:41 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:15097
2023-07-13 13:13:41 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:15097
2023-07-13 13:13:41 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:15097
2023-07-13 13:13:41 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:15097
2023-07-13 13:13:41 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:15097
2023-07-13 13:13:41 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-13 13:13:41 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-13 13:13:41 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-13 13:13:41 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-13 13:13:41 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-13 13:13:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-13 13:13:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-13 13:13:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-13 13:13:42 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:13:42 | INFO | fairseq.distributed.utils | initialized host test1 as rank 5
2023-07-13 13:13:42 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:13:42 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:13:42 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:13:42 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:13:42 | INFO | fairseq.distributed.utils | initialized host test1 as rank 2
2023-07-13 13:13:42 | INFO | fairseq.distributed.utils | initialized host test1 as rank 6
2023-07-13 13:13:42 | INFO | fairseq.distributed.utils | initialized host test1 as rank 4
2023-07-13 13:13:42 | INFO | fairseq.distributed.utils | initialized host test1 as rank 3
2023-07-13 13:13:42 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:13:42 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:13:42 | INFO | fairseq.distributed.utils | initialized host test1 as rank 1
2023-07-13 13:13:42 | INFO | fairseq.distributed.utils | initialized host test1 as rank 7
2023-07-13 13:13:42 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:13:42 | INFO | fairseq.distributed.utils | initialized host test1 as rank 0
2023-07-13 13:13:44 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15097', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-13 13:13:44 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-13 13:13:44 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-13 13:13:44 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-13 13:13:44 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-13 13:13:44 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-13 13:13:49 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-13 13:13:49 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-13 13:13:49 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-13 13:13:51 | INFO | root | load pretrained hubert
2023-07-13 13:13:55 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-13 13:13:57 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-13 13:14:00 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-13 13:14:00 | INFO | root | share the sematic adapter and textual encoder
2023-07-13 13:14:00 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-13 13:14:00 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-13 13:14:00 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-13 13:14:00 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-13 13:14:00 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-13 13:14:00 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-13 13:14:00 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-13 13:14:00 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:14:00 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:14:00 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 13:14:06 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-13 13:14:06 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-13 13:14:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-13 13:14:06 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-13 13:14:06 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:14:06 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:14:06 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:14:06 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:14:06 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:14:06 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:14:06 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:14:06 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:14:06 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-13 13:14:06 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-13 13:14:06 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-13 13:14:06 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt
2023-07-13 13:14:06 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt
2023-07-13 13:14:06 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-13 13:14:06 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-13 13:14:06 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:14:06 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:14:08 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 13:14:09 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 13:14:11 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 13:15:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 13:15:16 | INFO | fairseq.trainer | begin training epoch 1
2023-07-13 13:15:16 | INFO | fairseq_cli.train | Start iterating over samples
tensor([[False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False,  True,
          True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False,  True,
          True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False,  True,  True,  True,  True,
          True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False,  True,  True,  True,  True,  True,
          True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False,  True,  True,  True,  True,  True,
          True,  True]], device='cuda:0')
tensor([[False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False,  True,  True,  True,
          True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False,  True,  True,  True,  True,  True,  True,  True,  True,
          True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False,  True,  True,  True,  True,  True,  True,  True,  True,
          True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True]], device='cuda:3')
tensor([[False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False,  True,  True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
          True,  True,  True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False,  True,
          True,  True,  True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False,  True,  True,
          True,  True,  True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True]], device='cuda:7')
tensor([[False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False,  True,
          True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False,  True,  True,
          True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False,  True,  True,  True,
          True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False,  True,  True,  True,
          True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False,  True,  True,  True,
          True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False,  True,  True,  True,
          True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False,  True,  True,  True,
          True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False,  True,  True,  True,  True,
          True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False,  True,  True,  True,  True,  True,
          True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True]], device='cuda:4')
tensor([[False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
          True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
          True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False,  True,
          True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False,  True,  True,  True,  True,
          True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False,  True,  True,  True,  True,
          True,  True,  True]], device='cuda:2')
tensor([[False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False,  True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False,  True,  True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False,  True,  True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False,  True,  True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
          True,  True,  True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
          True,  True,  True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False,  True,
          True,  True,  True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False,  True,
          True,  True,  True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False,  True,
          True,  True,  True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False,  True,
          True,  True,  True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False,  True,  True,
          True,  True,  True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False,  True,  True,
          True,  True,  True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False,  True,  True,
          True,  True,  True,  True,  True,  True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False,  True,  True,  True,
          True,  True,  True,  True,  True,  True]], device='cuda:6')
tensor([[False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
          True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False,  True,  True,
          True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False,  True,  True,  True,  True,  True,
          True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False,  True,  True,  True,  True,  True,  True,  True,
          True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False,  True,  True,  True,  True,  True,  True,  True,  True,
          True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False,  True,  True,  True,  True,  True,  True,  True,  True,
          True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True]], device='cuda:1')
Traceback (most recent call last):
  File "/workspace/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/workspace/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/workspace/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/workspace/fairseq-AT/fairseq/distributed/utils.py", line 328, in distributed_main
    main(cfg, **kwargs)
  File "/workspace/fairseq-AT/fairseq_cli/train.py", line 190, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/usr/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/workspace/fairseq-AT/fairseq_cli/train.py", line 316, in train
    log_output = trainer.train_step(samples)
  File "/usr/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/workspace/fairseq-AT/fairseq/trainer.py", line 863, in train_step
    raise e
  File "/workspace/fairseq-AT/fairseq/trainer.py", line 830, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/workspace/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py", line 528, in train_step
    loss, sample_size, logging_output, norm_list = self._per_task_train_loss(
  File "/workspace/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py", line 423, in _per_task_train_loss
    loss, sample_size, logging_output = criterion(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/fairseq-AT/fairseq/criterions/label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT.py", line 346, in forward
    weight = torch.cat(
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument tensors in method wrapper_CUDA_cat)

/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 30 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-07-13 13:18:15 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:19732
2023-07-13 13:18:15 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:19732
2023-07-13 13:18:15 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:19732
2023-07-13 13:18:15 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:19732
2023-07-13 13:18:15 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:19732
2023-07-13 13:18:15 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:19732
2023-07-13 13:18:15 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:19732
2023-07-13 13:18:15 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:19732
2023-07-13 13:18:15 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-13 13:18:15 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-13 13:18:16 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-13 13:18:16 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-13 13:18:16 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-13 13:18:16 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-13 13:18:16 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-13 13:18:16 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-13 13:18:16 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:18:16 | INFO | fairseq.distributed.utils | initialized host test1 as rank 3
2023-07-13 13:18:16 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:18:16 | INFO | fairseq.distributed.utils | initialized host test1 as rank 6
2023-07-13 13:18:16 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:18:16 | INFO | fairseq.distributed.utils | initialized host test1 as rank 4
2023-07-13 13:18:16 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:18:16 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:18:16 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:18:16 | INFO | fairseq.distributed.utils | initialized host test1 as rank 1
2023-07-13 13:18:16 | INFO | fairseq.distributed.utils | initialized host test1 as rank 5
2023-07-13 13:18:16 | INFO | fairseq.distributed.utils | initialized host test1 as rank 0
2023-07-13 13:18:16 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:18:16 | INFO | fairseq.distributed.utils | initialized host test1 as rank 2
2023-07-13 13:18:16 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:18:16 | INFO | fairseq.distributed.utils | initialized host test1 as rank 7
2023-07-13 13:18:19 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19732', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-13 13:18:19 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-13 13:18:19 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-13 13:18:19 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-13 13:18:19 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-13 13:18:19 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-13 13:18:23 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-13 13:18:23 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-13 13:18:23 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-13 13:18:25 | INFO | root | load pretrained hubert
2023-07-13 13:18:27 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-13 13:18:29 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-13 13:18:32 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-13 13:18:32 | INFO | root | share the sematic adapter and textual encoder
2023-07-13 13:18:32 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-13 13:18:32 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-13 13:18:32 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-13 13:18:32 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-13 13:18:32 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-13 13:18:32 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-13 13:18:32 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-13 13:18:32 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:18:32 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:18:32 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 13:18:39 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-13 13:18:40 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-13 13:18:40 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-13 13:18:41 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-13 13:18:41 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:18:41 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:18:41 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:18:41 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:18:41 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:18:41 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:18:41 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:18:41 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:18:41 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-13 13:18:41 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-13 13:18:41 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-13 13:18:41 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt
2023-07-13 13:18:41 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt
2023-07-13 13:18:41 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-13 13:18:41 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-13 13:18:41 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:18:41 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:18:43 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 13:18:44 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 13:18:46 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 13:19:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 13:19:50 | INFO | fairseq.trainer | begin training epoch 1
2023-07-13 13:19:50 | INFO | fairseq_cli.train | Start iterating over samples
torch.Size([158, 8, 512]) torch.Size([52, 8, 512]) torch.Size([8, 1]) torch.Size([8, 1]) tensor(437.1131, device='cuda:0', grad_fn=<MulBackward0>) 16
2023-07-13 13:19:59 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/crash.pt
torch.Size([280, 6, 512]) torch.Size([91, 6, 512]) torch.Size([6, 1]) torch.Size([6, 1]) tensor(775.3854, device='cuda:3', grad_fn=<MulBackward0>) 12
2023-07-13 13:20:00 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/crash.pt
torch.Size([132, 8, 512]) torch.Size([43, 8, 512]) torch.Size([8, 1]) torch.Size([8, 1]) tensor(362.9227, device='cuda:2', grad_fn=<MulBackward0>) 16
torch.Size([59, 24, 512]) torch.Size([26, 24, 512]) torch.Size([24, 1]) torch.Size([24, 1]) tensor(165.0102, device='cuda:6', grad_fn=<MulBackward0>) 48
torch.Size([200, 8, 512]) torch.Size([66, 8, 512]) torch.Size([8, 1]) torch.Size([8, 1]) tensor(555.1472, device='cuda:5', grad_fn=<MulBackward0>) 16
torch.Size([81, 16, 512]) torch.Size([34, 16, 512]) torch.Size([16, 1]) torch.Size([16, 1]) tensor(220.2085, device='cuda:4', grad_fn=<MulBackward0>) 32
torch.Size([121, 8, 512]) torch.Size([46, 8, 512]) torch.Size([8, 1]) torch.Size([8, 1]) tensor(337.0172, device='cuda:7', grad_fn=<MulBackward0>) 16
Traceback (most recent call last):
  File "/workspace/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/workspace/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/workspace/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 3 terminated with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/workspace/fairseq-AT/fairseq/distributed/utils.py", line 328, in distributed_main
    main(cfg, **kwargs)
  File "/workspace/fairseq-AT/fairseq_cli/train.py", line 190, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/usr/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/workspace/fairseq-AT/fairseq_cli/train.py", line 316, in train
    log_output = trainer.train_step(samples)
  File "/usr/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/workspace/fairseq-AT/fairseq/trainer.py", line 830, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/workspace/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py", line 528, in train_step
    loss, sample_size, logging_output, norm_list = self._per_task_train_loss(
  File "/workspace/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py", line 423, in _per_task_train_loss
    loss, sample_size, logging_output = criterion(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/fairseq-AT/fairseq/criterions/label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT.py", line 391, in forward
    assert False
AssertionError

/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 30 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-07-13 13:21:10 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:15141
2023-07-13 13:21:10 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:15141
2023-07-13 13:21:10 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:15141
2023-07-13 13:21:10 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:15141
2023-07-13 13:21:10 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-13 13:21:10 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:15141
2023-07-13 13:21:10 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:15141
2023-07-13 13:21:11 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:15141
2023-07-13 13:21:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-13 13:21:11 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:15141
2023-07-13 13:21:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-13 13:21:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-13 13:21:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-13 13:21:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-13 13:21:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-13 13:21:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-13 13:21:11 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:21:11 | INFO | fairseq.distributed.utils | initialized host test1 as rank 1
2023-07-13 13:21:11 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:21:11 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:21:11 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:21:11 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:21:11 | INFO | fairseq.distributed.utils | initialized host test1 as rank 7
2023-07-13 13:21:11 | INFO | fairseq.distributed.utils | initialized host test1 as rank 4
2023-07-13 13:21:11 | INFO | fairseq.distributed.utils | initialized host test1 as rank 2
2023-07-13 13:21:11 | INFO | fairseq.distributed.utils | initialized host test1 as rank 5
2023-07-13 13:21:11 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:21:11 | INFO | fairseq.distributed.utils | initialized host test1 as rank 0
2023-07-13 13:21:11 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:21:11 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:21:11 | INFO | fairseq.distributed.utils | initialized host test1 as rank 3
2023-07-13 13:21:11 | INFO | fairseq.distributed.utils | initialized host test1 as rank 6
2023-07-13 13:21:14 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15141', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-13 13:21:14 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-13 13:21:14 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-13 13:21:14 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-13 13:21:14 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-13 13:21:14 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-13 13:21:18 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-13 13:21:18 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-13 13:21:19 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-13 13:21:20 | INFO | root | load pretrained hubert
2023-07-13 13:21:24 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-13 13:21:25 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-13 13:21:28 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-13 13:21:28 | INFO | root | share the sematic adapter and textual encoder
2023-07-13 13:21:28 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-13 13:21:28 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-13 13:21:28 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-13 13:21:28 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-13 13:21:28 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-13 13:21:28 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-13 13:21:28 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-13 13:21:28 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:21:28 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:21:28 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 13:21:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-13 13:21:37 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-13 13:21:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-13 13:21:38 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-13 13:21:38 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:21:38 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:21:38 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:21:38 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:21:38 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:21:38 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:21:38 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:21:38 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:21:38 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-13 13:21:38 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-13 13:21:38 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-13 13:21:38 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt
2023-07-13 13:21:38 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt
2023-07-13 13:21:38 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-13 13:21:38 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-13 13:21:38 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:21:38 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:21:39 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 13:21:41 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 13:21:43 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 13:22:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 13:22:47 | INFO | fairseq.trainer | begin training epoch 1
2023-07-13 13:22:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 13:23:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-13 13:24:00 | INFO | train_inner | epoch 001:    101 / 1474 loss=20.77, trans_loss=5.641, nll_loss=4.216, w2v_ctc_loss=22.495, task_loss=8.636, contrastive_loss=3.311, total=4200.41, n_correct=212.56, ppl=18.59, accuracy=5.06, wps=20092.8, ups=1.6, wpb=12542.9, bsz=467.5, num_updates=100, lr=4.098e-06, gnorm=1.009, clip=0, loss_scale=64, train_wall=65, gb_free=19, wall=142
2023-07-13 13:25:01 | INFO | train_inner | epoch 001:    201 / 1474 loss=18.53, trans_loss=5.416, nll_loss=3.997, w2v_ctc_loss=19.349, task_loss=9.329, contrastive_loss=3.291, total=4127.38, n_correct=259.87, ppl=15.97, accuracy=6.296, wps=20136.4, ups=1.63, wpb=12327, bsz=463.1, num_updates=200, lr=8.096e-06, gnorm=3.648, clip=0, loss_scale=64, train_wall=61, gb_free=19.2, wall=204
2023-07-13 13:26:02 | INFO | train_inner | epoch 001:    301 / 1474 loss=11.615, trans_loss=5.384, nll_loss=4.02, w2v_ctc_loss=8.801, task_loss=11.249, contrastive_loss=3.217, total=4079.62, n_correct=261.39, ppl=16.22, accuracy=6.407, wps=20082.4, ups=1.65, wpb=12195.4, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=4.666, clip=0, loss_scale=64, train_wall=60, gb_free=19.9, wall=264
2023-07-13 13:27:03 | INFO | train_inner | epoch 001:    401 / 1474 loss=10.432, trans_loss=5.486, nll_loss=4.181, w2v_ctc_loss=6.831, task_loss=10.627, contrastive_loss=3.268, total=4174.14, n_correct=210.68, ppl=18.14, accuracy=5.047, wps=20365.3, ups=1.63, wpb=12461.1, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=3.025, clip=0, loss_scale=64, train_wall=61, gb_free=18.9, wall=325
2023-07-13 13:28:06 | INFO | train_inner | epoch 001:    501 / 1474 loss=10.13, trans_loss=5.654, nll_loss=4.448, w2v_ctc_loss=6.166, task_loss=9.567, contrastive_loss=3.305, total=4176.18, n_correct=158.11, ppl=21.83, accuracy=3.786, wps=20072.4, ups=1.6, wpb=12513, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=1.55, clip=0, loss_scale=64, train_wall=62, gb_free=19.2, wall=388
2023-07-13 13:29:07 | INFO | train_inner | epoch 001:    601 / 1474 loss=9.826, trans_loss=5.573, nll_loss=4.36, w2v_ctc_loss=5.803, task_loss=8.09, contrastive_loss=3.382, total=4147.79, n_correct=299.01, ppl=20.54, accuracy=7.209, wps=20009.2, ups=1.62, wpb=12368.1, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.898, clip=0, loss_scale=64, train_wall=61, gb_free=18.9, wall=450
2023-07-13 13:30:08 | INFO | train_inner | epoch 001:    701 / 1474 loss=9.613, trans_loss=5.522, nll_loss=4.296, w2v_ctc_loss=5.682, task_loss=7.248, contrastive_loss=3.109, total=4152.1, n_correct=310.59, ppl=19.64, accuracy=7.48, wps=20263.6, ups=1.64, wpb=12373.8, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=0.562, clip=0, loss_scale=64, train_wall=61, gb_free=19.5, wall=511
2023-07-13 13:31:09 | INFO | train_inner | epoch 001:    801 / 1474 loss=9.298, trans_loss=5.414, nll_loss=4.137, w2v_ctc_loss=5.434, task_loss=7.008, contrastive_loss=3.033, total=4123.83, n_correct=317.63, ppl=17.59, accuracy=7.702, wps=20287.1, ups=1.65, wpb=12311.9, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=0.797, clip=0, loss_scale=64, train_wall=60, gb_free=19.1, wall=571
2023-07-13 13:32:10 | INFO | train_inner | epoch 001:    901 / 1474 loss=9.021, trans_loss=5.36, nll_loss=4.062, w2v_ctc_loss=5.251, task_loss=7.055, contrastive_loss=2.791, total=4163.61, n_correct=307.39, ppl=16.71, accuracy=7.383, wps=20554.9, ups=1.66, wpb=12409.7, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=1.172, clip=0, loss_scale=64, train_wall=60, gb_free=18.8, wall=632
2023-07-13 13:33:11 | INFO | train_inner | epoch 001:   1001 / 1474 loss=8.777, trans_loss=5.374, nll_loss=4.081, w2v_ctc_loss=5.022, task_loss=7.356, contrastive_loss=2.641, total=4135.34, n_correct=287.09, ppl=16.93, accuracy=6.942, wps=20076.9, ups=1.62, wpb=12363.9, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=1.579, clip=0, loss_scale=64, train_wall=61, gb_free=19, wall=693
2023-07-13 13:34:12 | INFO | train_inner | epoch 001:   1101 / 1474 loss=8.634, trans_loss=5.442, nll_loss=4.167, w2v_ctc_loss=4.838, task_loss=8.402, contrastive_loss=2.503, total=4147.38, n_correct=268.29, ppl=17.97, accuracy=6.469, wps=20380.4, ups=1.65, wpb=12356.9, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=1.442, clip=0, loss_scale=64, train_wall=60, gb_free=18.8, wall=754
2023-07-13 13:35:12 | INFO | train_inner | epoch 001:   1201 / 1474 loss=8.33, trans_loss=5.396, nll_loss=4.106, w2v_ctc_loss=4.645, task_loss=7.606, contrastive_loss=2.229, total=4139.9, n_correct=296.89, ppl=17.22, accuracy=7.171, wps=20435.3, ups=1.65, wpb=12386.7, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=1.821, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=815
2023-07-13 13:36:13 | INFO | train_inner | epoch 001:   1301 / 1474 loss=8.092, trans_loss=5.38, nll_loss=4.085, w2v_ctc_loss=4.463, task_loss=7.326, contrastive_loss=2.023, total=4046.58, n_correct=300.38, ppl=16.97, accuracy=7.423, wps=19933.5, ups=1.65, wpb=12092.5, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=1.877, clip=0, loss_scale=64, train_wall=60, gb_free=19.7, wall=875
2023-07-13 13:37:14 | INFO | train_inner | epoch 001:   1401 / 1474 loss=7.909, trans_loss=5.36, nll_loss=4.072, w2v_ctc_loss=4.299, task_loss=7.214, contrastive_loss=2.098, total=4133.18, n_correct=320.32, ppl=16.82, accuracy=7.75, wps=20129.3, ups=1.64, wpb=12300.7, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=2.003, clip=0, loss_scale=64, train_wall=61, gb_free=19.9, wall=936
2023-07-13 13:37:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
Traceback (most recent call last):
  File "/workspace/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/workspace/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/workspace/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 2 terminated with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/workspace/fairseq-AT/fairseq/distributed/utils.py", line 328, in distributed_main
    main(cfg, **kwargs)
  File "/workspace/fairseq-AT/fairseq_cli/train.py", line 190, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/usr/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/workspace/fairseq-AT/fairseq_cli/train.py", line 330, in train
    valid_losses, should_stop = validate_and_save(
  File "/workspace/fairseq-AT/fairseq_cli/train.py", line 421, in validate_and_save
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "/workspace/fairseq-AT/fairseq_cli/train.py", line 505, in validate
    trainer.valid_step(sample)
  File "/usr/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/workspace/fairseq-AT/fairseq/trainer.py", line 1127, in valid_step
    _loss, sample_size, logging_output = self.task.valid_step(
  File "/workspace/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py", line 715, in valid_step
    loss, sample_size, logging_output = self._per_task_pair_valid_loss(per_task, model, criterion, sample)
  File "/workspace/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py", line 597, in _per_task_pair_valid_loss
    bleu = self._inference_with_bleu(self.sequence_generator, sample[per_task], model)
  File "/workspace/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py", line 680, in _inference_with_bleu
    gen_out = self.inference_step(generator, [model], sample, prefix_tokens=None)
  File "/workspace/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py", line 751, in inference_step
    if save_top:
NameError: name 'save_top' is not defined

/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 32 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-07-13 13:43:50 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:12054
2023-07-13 13:43:50 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:12054
2023-07-13 13:43:50 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:12054
2023-07-13 13:43:50 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:12054
2023-07-13 13:43:50 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:12054
2023-07-13 13:43:50 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:12054
2023-07-13 13:43:50 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:12054
2023-07-13 13:43:50 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:12054
2023-07-13 13:43:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-13 13:43:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-13 13:43:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-13 13:43:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-13 13:43:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-13 13:43:51 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-13 13:43:51 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-13 13:43:51 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-13 13:43:51 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:43:51 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:43:51 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:43:51 | INFO | fairseq.distributed.utils | initialized host test1 as rank 4
2023-07-13 13:43:51 | INFO | fairseq.distributed.utils | initialized host test1 as rank 1
2023-07-13 13:43:51 | INFO | fairseq.distributed.utils | initialized host test1 as rank 0
2023-07-13 13:43:51 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:43:51 | INFO | fairseq.distributed.utils | initialized host test1 as rank 2
2023-07-13 13:43:51 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:43:51 | INFO | fairseq.distributed.utils | initialized host test1 as rank 6
2023-07-13 13:43:51 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:43:51 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:43:51 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 13:43:51 | INFO | fairseq.distributed.utils | initialized host test1 as rank 5
2023-07-13 13:43:51 | INFO | fairseq.distributed.utils | initialized host test1 as rank 7
2023-07-13 13:43:51 | INFO | fairseq.distributed.utils | initialized host test1 as rank 3
2023-07-13 13:43:54 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12054', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-13 13:43:54 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-13 13:43:54 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-13 13:43:54 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-13 13:43:54 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-13 13:43:54 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-13 13:43:59 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-13 13:43:59 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-13 13:43:59 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-13 13:44:00 | INFO | root | load pretrained hubert
2023-07-13 13:44:04 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-13 13:44:06 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-13 13:44:09 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-13 13:44:09 | INFO | root | share the sematic adapter and textual encoder
2023-07-13 13:44:09 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-13 13:44:09 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-13 13:44:09 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-13 13:44:09 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-13 13:44:09 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-13 13:44:09 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-13 13:44:09 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-13 13:44:09 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:44:09 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:44:10 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 13:44:15 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-13 13:44:15 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-13 13:44:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-13 13:44:15 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-13 13:44:15 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:44:15 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:44:15 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:44:15 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:44:15 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:44:15 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:44:15 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:44:15 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 13:44:15 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-13 13:44:15 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-13 13:44:15 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-13 13:44:15 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt
2023-07-13 13:44:15 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt
2023-07-13 13:44:15 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-13 13:44:15 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-13 13:44:15 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:44:15 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 13:44:17 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 13:44:18 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 13:44:20 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 13:45:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 13:45:26 | INFO | fairseq.trainer | begin training epoch 1
2023-07-13 13:45:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 13:45:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-13 13:46:37 | INFO | train_inner | epoch 001:    101 / 1474 loss=20.77, trans_loss=5.641, nll_loss=4.216, w2v_ctc_loss=22.495, task_loss=8.636, contrastive_loss=3.311, total=4200.41, n_correct=212.67, ppl=18.59, accuracy=5.063, wps=20098.6, ups=1.6, wpb=12542.9, bsz=467.5, num_updates=100, lr=4.098e-06, gnorm=1.009, clip=0, loss_scale=64, train_wall=64, gb_free=19, wall=142
2023-07-13 13:47:38 | INFO | train_inner | epoch 001:    201 / 1474 loss=18.53, trans_loss=5.416, nll_loss=3.997, w2v_ctc_loss=19.349, task_loss=9.329, contrastive_loss=3.291, total=4127.38, n_correct=259.63, ppl=15.97, accuracy=6.29, wps=20202.4, ups=1.64, wpb=12327, bsz=463.1, num_updates=200, lr=8.096e-06, gnorm=3.648, clip=0, loss_scale=64, train_wall=61, gb_free=19.2, wall=203
2023-07-13 13:48:43 | INFO | train_inner | epoch 001:    301 / 1474 loss=11.613, trans_loss=5.382, nll_loss=4.017, w2v_ctc_loss=8.801, task_loss=11.248, contrastive_loss=3.217, total=4079.62, n_correct=261.64, ppl=16.19, accuracy=6.413, wps=18786.5, ups=1.54, wpb=12195.4, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=4.666, clip=0, loss_scale=64, train_wall=64, gb_free=19.9, wall=268
2023-07-13 13:49:56 | INFO | train_inner | epoch 001:    401 / 1474 loss=10.432, trans_loss=5.486, nll_loss=4.182, w2v_ctc_loss=6.831, task_loss=10.627, contrastive_loss=3.268, total=4174.14, n_correct=210.36, ppl=18.15, accuracy=5.04, wps=17087.7, ups=1.37, wpb=12461.1, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=3.025, clip=0, loss_scale=64, train_wall=72, gb_free=18.9, wall=341
2023-07-13 13:50:58 | INFO | train_inner | epoch 001:    501 / 1474 loss=10.13, trans_loss=5.654, nll_loss=4.448, w2v_ctc_loss=6.166, task_loss=9.567, contrastive_loss=3.305, total=4176.18, n_correct=157.93, ppl=21.82, accuracy=3.782, wps=20374.9, ups=1.63, wpb=12513, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=1.55, clip=0, loss_scale=64, train_wall=61, gb_free=19.2, wall=402
2023-07-13 13:51:58 | INFO | train_inner | epoch 001:    601 / 1474 loss=9.826, trans_loss=5.572, nll_loss=4.36, w2v_ctc_loss=5.803, task_loss=8.091, contrastive_loss=3.382, total=4147.79, n_correct=298.69, ppl=20.53, accuracy=7.201, wps=20290.9, ups=1.64, wpb=12368.1, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.898, clip=0, loss_scale=64, train_wall=61, gb_free=18.9, wall=463
2023-07-13 13:52:59 | INFO | train_inner | epoch 001:    701 / 1474 loss=9.613, trans_loss=5.522, nll_loss=4.295, w2v_ctc_loss=5.682, task_loss=7.248, contrastive_loss=3.109, total=4152.1, n_correct=311.18, ppl=19.63, accuracy=7.495, wps=20361.5, ups=1.65, wpb=12373.8, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=0.562, clip=0, loss_scale=64, train_wall=60, gb_free=19.5, wall=524
2023-07-13 13:54:11 | INFO | train_inner | epoch 001:    801 / 1474 loss=9.297, trans_loss=5.414, nll_loss=4.136, w2v_ctc_loss=5.434, task_loss=7.008, contrastive_loss=3.033, total=4123.83, n_correct=317.99, ppl=17.58, accuracy=7.711, wps=17197.9, ups=1.4, wpb=12311.9, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=0.799, clip=0, loss_scale=64, train_wall=71, gb_free=19.1, wall=596
2023-07-13 13:56:39 | INFO | train_inner | epoch 001:    901 / 1474 loss=9.02, trans_loss=5.36, nll_loss=4.062, w2v_ctc_loss=5.251, task_loss=7.055, contrastive_loss=2.79, total=4163.61, n_correct=307.14, ppl=16.71, accuracy=7.377, wps=8391.6, ups=0.68, wpb=12409.7, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=1.169, clip=0, loss_scale=64, train_wall=147, gb_free=18.8, wall=744
2023-07-13 14:04:44 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:14154
2023-07-13 14:04:44 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:14154
2023-07-13 14:04:44 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:14154
2023-07-13 14:04:44 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:14154
2023-07-13 14:04:44 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:14154
2023-07-13 14:04:44 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:14154
2023-07-13 14:04:44 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:14154
2023-07-13 14:04:44 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:14154
2023-07-13 14:04:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-13 14:04:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-13 14:04:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-13 14:04:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-13 14:04:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-13 14:04:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-13 14:04:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-13 14:04:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-13 14:04:44 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 14:04:44 | INFO | fairseq.distributed.utils | initialized host test1 as rank 5
2023-07-13 14:04:44 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 14:04:44 | INFO | fairseq.distributed.utils | initialized host test1 as rank 0
2023-07-13 14:04:44 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 14:04:44 | INFO | fairseq.distributed.utils | initialized host test1 as rank 3
2023-07-13 14:04:44 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 14:04:44 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 14:04:44 | INFO | fairseq.distributed.utils | initialized host test1 as rank 1
2023-07-13 14:04:44 | INFO | fairseq.distributed.utils | initialized host test1 as rank 2
2023-07-13 14:04:44 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 14:04:44 | INFO | fairseq.distributed.utils | initialized host test1 as rank 6
2023-07-13 14:04:44 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 14:04:44 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 14:04:44 | INFO | fairseq.distributed.utils | initialized host test1 as rank 7
2023-07-13 14:04:44 | INFO | fairseq.distributed.utils | initialized host test1 as rank 4
2023-07-13 14:04:46 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:14154', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-13 14:04:46 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-13 14:04:46 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-13 14:04:46 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-13 14:04:46 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-13 14:04:46 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-13 14:04:51 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-13 14:04:51 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-13 14:04:51 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-13 14:04:53 | INFO | root | load pretrained hubert
2023-07-13 14:04:57 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-13 14:04:59 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-13 14:05:03 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-13 14:05:03 | INFO | root | share the sematic adapter and textual encoder
2023-07-13 14:05:03 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-13 14:05:03 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-13 14:05:03 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-13 14:05:03 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-13 14:05:03 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-13 14:05:03 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-13 14:05:03 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-13 14:05:03 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 14:05:03 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 14:05:03 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 14:05:09 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-13 14:05:12 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-13 14:05:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-13 14:05:12 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-13 14:05:12 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 14:05:12 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 14:05:12 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 14:05:12 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 14:05:12 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 14:05:12 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 14:05:12 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 14:05:12 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 14:05:12 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-13 14:05:12 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-13 14:05:12 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-13 14:05:12 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt
2023-07-13 14:05:12 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt
2023-07-13 14:05:12 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-13 14:05:12 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-13 14:05:12 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 14:05:12 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 14:05:14 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 14:05:15 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 14:05:17 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 15:41:13 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:18016
2023-07-13 15:41:13 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:18016
2023-07-13 15:41:13 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:18016
2023-07-13 15:41:13 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-13 15:41:13 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:18016
2023-07-13 15:41:13 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:18016
2023-07-13 15:41:13 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:18016
2023-07-13 15:41:13 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:18016
2023-07-13 15:41:13 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:18016
2023-07-13 15:41:13 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-13 15:41:13 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-13 15:41:13 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-13 15:41:13 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-13 15:41:13 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-13 15:41:13 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-13 15:41:13 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-13 15:41:13 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 15:41:13 | INFO | fairseq.distributed.utils | initialized host test1 as rank 6
2023-07-13 15:41:13 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 15:41:13 | INFO | fairseq.distributed.utils | initialized host test1 as rank 7
2023-07-13 15:41:13 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 15:41:13 | INFO | fairseq.distributed.utils | initialized host test1 as rank 0
2023-07-13 15:41:13 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 15:41:13 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 15:41:13 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 15:41:13 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 15:41:13 | INFO | fairseq.distributed.utils | initialized host test1 as rank 4
2023-07-13 15:41:13 | INFO | fairseq.distributed.utils | initialized host test1 as rank 5
2023-07-13 15:41:13 | INFO | fairseq.distributed.utils | initialized host test1 as rank 3
2023-07-13 15:41:13 | INFO | fairseq.distributed.utils | initialized host test1 as rank 2
2023-07-13 15:41:13 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-13 15:41:13 | INFO | fairseq.distributed.utils | initialized host test1 as rank 1
2023-07-13 15:41:16 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18016', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-13 15:41:16 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-13 15:41:16 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-13 15:41:16 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-13 15:41:16 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-13 15:41:16 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-13 15:41:20 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-13 15:41:20 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-13 15:41:20 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-13 15:41:22 | INFO | root | load pretrained hubert
2023-07-13 15:41:26 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-13 15:41:26 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-13 15:41:29 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-13 15:41:30 | INFO | root | share the sematic adapter and textual encoder
2023-07-13 15:41:30 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-13 15:41:30 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-13 15:41:30 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-13 15:41:30 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-13 15:41:30 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-13 15:41:30 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-13 15:41:30 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-13 15:41:30 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 15:41:30 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 15:41:30 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 15:41:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-13 15:41:36 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-13 15:41:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-13 15:41:37 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-13 15:41:37 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 15:41:37 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 15:41:37 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 15:41:37 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 15:41:37 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 15:41:37 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 15:41:37 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 15:41:37 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-13 15:41:37 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-13 15:41:37 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-13 15:41:37 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-13 15:41:37 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt
2023-07-13 15:41:37 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt
2023-07-13 15:41:37 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-13 15:41:37 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-13 15:41:37 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 15:41:37 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-13 15:41:38 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 15:41:40 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 15:41:42 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-13 15:42:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 15:42:46 | INFO | fairseq.trainer | begin training epoch 1
2023-07-13 15:42:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 15:43:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-13 15:43:58 | INFO | train_inner | epoch 001:    101 / 1474 loss=20.77, trans_loss=5.641, nll_loss=4.216, w2v_ctc_loss=22.495, task_loss=8.636, contrastive_loss=3.311, total=4200.41, n_correct=212.52, ppl=18.59, accuracy=5.06, wps=20269.1, ups=1.61, wpb=12542.9, bsz=467.5, num_updates=100, lr=4.098e-06, gnorm=1.009, clip=0, loss_scale=64, train_wall=64, gb_free=19, wall=141
2023-07-13 15:44:58 | INFO | train_inner | epoch 001:    201 / 1474 loss=18.53, trans_loss=5.417, nll_loss=3.997, w2v_ctc_loss=19.349, task_loss=9.329, contrastive_loss=3.291, total=4127.38, n_correct=259.93, ppl=15.97, accuracy=6.298, wps=20341.9, ups=1.65, wpb=12327, bsz=463.1, num_updates=200, lr=8.096e-06, gnorm=3.648, clip=0, loss_scale=64, train_wall=60, gb_free=19.2, wall=202
2023-07-13 15:45:59 | INFO | train_inner | epoch 001:    301 / 1474 loss=11.614, trans_loss=5.383, nll_loss=4.018, w2v_ctc_loss=8.801, task_loss=11.248, contrastive_loss=3.217, total=4079.62, n_correct=261.63, ppl=16.2, accuracy=6.413, wps=20206.6, ups=1.66, wpb=12195.4, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=4.666, clip=0, loss_scale=64, train_wall=60, gb_free=19.9, wall=262
2023-07-13 15:46:59 | INFO | train_inner | epoch 001:    401 / 1474 loss=10.432, trans_loss=5.486, nll_loss=4.182, w2v_ctc_loss=6.831, task_loss=10.627, contrastive_loss=3.268, total=4174.14, n_correct=210.73, ppl=18.15, accuracy=5.048, wps=20614.2, ups=1.65, wpb=12461.1, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=3.025, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=322
2023-07-13 15:48:00 | INFO | train_inner | epoch 001:    501 / 1474 loss=10.13, trans_loss=5.654, nll_loss=4.448, w2v_ctc_loss=6.166, task_loss=9.567, contrastive_loss=3.305, total=4176.18, n_correct=158.02, ppl=21.82, accuracy=3.784, wps=20448.1, ups=1.63, wpb=12513, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=1.55, clip=0, loss_scale=64, train_wall=61, gb_free=19.2, wall=384
2023-07-13 15:49:01 | INFO | train_inner | epoch 001:    601 / 1474 loss=9.826, trans_loss=5.573, nll_loss=4.36, w2v_ctc_loss=5.803, task_loss=8.091, contrastive_loss=3.382, total=4147.79, n_correct=298.83, ppl=20.54, accuracy=7.205, wps=20415.5, ups=1.65, wpb=12368.1, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.898, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=444
2023-07-13 15:50:01 | INFO | train_inner | epoch 001:    701 / 1474 loss=9.613, trans_loss=5.522, nll_loss=4.295, w2v_ctc_loss=5.682, task_loss=7.247, contrastive_loss=3.109, total=4152.1, n_correct=311.08, ppl=19.63, accuracy=7.492, wps=20479.3, ups=1.66, wpb=12373.8, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=0.562, clip=0, loss_scale=64, train_wall=60, gb_free=19.5, wall=505
2023-07-13 15:51:02 | INFO | train_inner | epoch 001:    801 / 1474 loss=9.298, trans_loss=5.415, nll_loss=4.137, w2v_ctc_loss=5.434, task_loss=7.008, contrastive_loss=3.033, total=4123.83, n_correct=317.41, ppl=17.59, accuracy=7.697, wps=20380.9, ups=1.66, wpb=12311.9, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=0.798, clip=0, loss_scale=64, train_wall=60, gb_free=19.1, wall=565
2023-07-13 15:52:02 | INFO | train_inner | epoch 001:    901 / 1474 loss=9.021, trans_loss=5.36, nll_loss=4.063, w2v_ctc_loss=5.251, task_loss=7.055, contrastive_loss=2.791, total=4163.61, n_correct=306.66, ppl=16.71, accuracy=7.365, wps=20599.6, ups=1.66, wpb=12409.7, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=1.172, clip=0, loss_scale=64, train_wall=60, gb_free=18.8, wall=625
2023-07-13 15:53:03 | INFO | train_inner | epoch 001:   1001 / 1474 loss=8.778, trans_loss=5.375, nll_loss=4.082, w2v_ctc_loss=5.022, task_loss=7.353, contrastive_loss=2.641, total=4135.34, n_correct=286.58, ppl=16.94, accuracy=6.93, wps=20299.9, ups=1.64, wpb=12363.9, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=1.577, clip=0, loss_scale=64, train_wall=60, gb_free=19, wall=686
2023-07-13 15:54:03 | INFO | train_inner | epoch 001:   1101 / 1474 loss=8.621, trans_loss=5.435, nll_loss=4.158, w2v_ctc_loss=4.838, task_loss=8.209, contrastive_loss=2.49, total=4147.38, n_correct=272.85, ppl=17.86, accuracy=6.579, wps=20441.7, ups=1.65, wpb=12356.9, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=1.467, clip=0, loss_scale=64, train_wall=60, gb_free=18.8, wall=747
2023-07-13 15:55:04 | INFO | train_inner | epoch 001:   1201 / 1474 loss=8.324, trans_loss=5.393, nll_loss=4.101, w2v_ctc_loss=4.647, task_loss=7.606, contrastive_loss=2.222, total=4139.9, n_correct=300.35, ppl=17.16, accuracy=7.255, wps=20409.8, ups=1.65, wpb=12386.7, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=1.809, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=807
2023-07-13 15:56:04 | INFO | train_inner | epoch 001:   1301 / 1474 loss=8.089, trans_loss=5.378, nll_loss=4.082, w2v_ctc_loss=4.465, task_loss=7.326, contrastive_loss=2.019, total=4046.58, n_correct=304.2, ppl=16.94, accuracy=7.517, wps=20067.5, ups=1.66, wpb=12092.5, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=1.885, clip=0, loss_scale=64, train_wall=60, gb_free=19.7, wall=868
2023-07-13 15:57:05 | INFO | train_inner | epoch 001:   1401 / 1474 loss=7.908, trans_loss=5.359, nll_loss=4.071, w2v_ctc_loss=4.3, task_loss=7.214, contrastive_loss=2.096, total=4133.18, n_correct=320.93, ppl=16.81, accuracy=7.765, wps=20221, ups=1.64, wpb=12300.7, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=2.01, clip=0, loss_scale=64, train_wall=60, gb_free=19.9, wall=928
2023-07-13 15:57:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-07-13 15:58:24 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.662 | trans_loss 11.033 | nll_loss 10.053 | w2v_ctc_loss 5.572 | task_loss 37.741 | contrastive_loss 2.472 | total 4003.4 | n_correct 352 | ppl 1062.03 | accuracy 8.793 | uer 71.247 | wer 69.289 | raw_wer 69.289 | bleu 0.02 | wps 1430.2 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-07-13 15:58:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-07-13 15:58:24 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 15:58:26 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 15:58:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.02) (writing took 5.02747884998098 seconds)
2023-07-13 15:58:29 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-07-13 15:58:29 | INFO | train | epoch 001 | loss 10.644 | trans_loss 5.452 | nll_loss 4.153 | w2v_ctc_loss 7.627 | task_loss 8.259 | contrastive_loss 2.829 | total 4138.32 | n_correct 276.07 | ppl 17.79 | accuracy 6.671 | wps 19507 | ups 1.58 | wpb 12354.6 | bsz 458.3 | num_updates 1473 | lr 5.89905e-05 | gnorm 1.857 | clip 0 | loss_scale 64 | train_wall 890 | gb_free 19.2 | wall 1012
2023-07-13 15:58:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 15:58:29 | INFO | fairseq.trainer | begin training epoch 2
2023-07-13 15:58:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 15:58:52 | INFO | train_inner | epoch 002:     27 / 1474 loss=7.704, trans_loss=5.352, nll_loss=4.053, w2v_ctc_loss=4.106, task_loss=6.883, contrastive_loss=1.922, total=4162.95, n_correct=338.23, ppl=16.6, accuracy=8.125, wps=11557, ups=0.93, wpb=12414, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=1.737, clip=0, loss_scale=64, train_wall=60, gb_free=19.6, wall=1036
2023-07-13 15:59:53 | INFO | train_inner | epoch 002:    127 / 1474 loss=7.543, trans_loss=5.348, nll_loss=4.05, w2v_ctc_loss=3.993, task_loss=7.329, contrastive_loss=1.716, total=4155.98, n_correct=335.77, ppl=16.56, accuracy=8.079, wps=20362.3, ups=1.64, wpb=12390, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=1.699, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=1097
2023-07-13 16:00:54 | INFO | train_inner | epoch 002:    227 / 1474 loss=7.355, trans_loss=5.297, nll_loss=3.993, w2v_ctc_loss=3.8, task_loss=6.051, contrastive_loss=1.741, total=4179.21, n_correct=345.84, ppl=15.92, accuracy=8.275, wps=20549.5, ups=1.65, wpb=12488.1, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=1.676, clip=0, loss_scale=64, train_wall=60, gb_free=19, wall=1157
2023-07-13 16:01:55 | INFO | train_inner | epoch 002:    327 / 1474 loss=7.197, trans_loss=5.299, nll_loss=3.989, w2v_ctc_loss=3.71, task_loss=6.871, contrastive_loss=1.44, total=4146.1, n_correct=338.2, ppl=15.88, accuracy=8.157, wps=20428.6, ups=1.65, wpb=12381, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=1.553, clip=0, loss_scale=64, train_wall=60, gb_free=18.8, wall=1218
2023-07-13 16:02:55 | INFO | train_inner | epoch 002:    427 / 1474 loss=7.046, trans_loss=5.283, nll_loss=3.97, w2v_ctc_loss=3.619, task_loss=7.108, contrastive_loss=1.243, total=4037.99, n_correct=340.43, ppl=15.68, accuracy=8.431, wps=20053.9, ups=1.66, wpb=12079.4, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=1.529, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=1278
2023-07-13 16:03:55 | INFO | train_inner | epoch 002:    527 / 1474 loss=6.942, trans_loss=5.28, nll_loss=3.962, w2v_ctc_loss=3.463, task_loss=6.085, contrastive_loss=1.338, total=4176.97, n_correct=363.37, ppl=15.58, accuracy=8.699, wps=20618.2, ups=1.65, wpb=12475.1, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=1.416, clip=0, loss_scale=64, train_wall=60, gb_free=19.6, wall=1339
2023-07-13 16:03:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 16:04:29 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 9.001 | trans_loss 10.812 | nll_loss 9.762 | w2v_ctc_loss 4.53 | task_loss 37.75 | contrastive_loss 1.676 | total 4003.4 | n_correct 378.2 | ppl 868.28 | accuracy 9.447 | uer 61.694 | wer 59.532 | raw_wer 59.532 | bleu 0.04 | wps 1447.6 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.04
2023-07-13 16:04:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-07-13 16:04:29 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_2_2000.pt
2023-07-13 16:04:32 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_2_2000.pt
2023-07-13 16:04:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.04) (writing took 9.15344736201223 seconds)
2023-07-13 16:05:39 | INFO | train_inner | epoch 002:    627 / 1474 loss=6.807, trans_loss=5.27, nll_loss=3.953, w2v_ctc_loss=3.364, task_loss=6.273, contrastive_loss=1.125, total=4126.49, n_correct=361.84, ppl=15.49, accuracy=8.769, wps=11879.4, ups=0.97, wpb=12299.1, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=1.236, clip=0, loss_scale=128, train_wall=60, gb_free=19.2, wall=1442
2023-07-13 16:06:39 | INFO | train_inner | epoch 002:    727 / 1474 loss=6.725, trans_loss=5.244, nll_loss=3.924, w2v_ctc_loss=3.275, task_loss=6.137, contrastive_loss=1.231, total=4149.06, n_correct=378.34, ppl=15.18, accuracy=9.119, wps=20530.4, ups=1.66, wpb=12372.9, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=1.186, clip=0, loss_scale=128, train_wall=60, gb_free=19.2, wall=1503
2023-07-13 16:07:40 | INFO | train_inner | epoch 002:    827 / 1474 loss=6.639, trans_loss=5.233, nll_loss=3.908, w2v_ctc_loss=3.205, task_loss=6.308, contrastive_loss=1.172, total=4175.4, n_correct=384.32, ppl=15.01, accuracy=9.204, wps=20550.7, ups=1.65, wpb=12477.6, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=1.077, clip=0, loss_scale=128, train_wall=60, gb_free=19.8, wall=1563
2023-07-13 16:08:40 | INFO | train_inner | epoch 002:    927 / 1474 loss=6.541, trans_loss=5.224, nll_loss=3.898, w2v_ctc_loss=3.109, task_loss=6.431, contrastive_loss=1.15, total=4104.2, n_correct=380.03, ppl=14.91, accuracy=9.26, wps=20275.8, ups=1.66, wpb=12243.8, bsz=445.9, num_updates=2400, lr=9.6052e-05, gnorm=1.043, clip=0, loss_scale=128, train_wall=60, gb_free=19, wall=1624
2023-07-13 16:09:41 | INFO | train_inner | epoch 002:   1027 / 1474 loss=6.454, trans_loss=5.215, nll_loss=3.884, w2v_ctc_loss=3.03, task_loss=6.251, contrastive_loss=1.005, total=4102.5, n_correct=384.02, ppl=14.76, accuracy=9.361, wps=20340.5, ups=1.66, wpb=12270.3, bsz=456.3, num_updates=2500, lr=0.00010005, gnorm=0.924, clip=0, loss_scale=128, train_wall=60, gb_free=19.2, wall=1684
2023-07-13 16:10:42 | INFO | train_inner | epoch 002:   1127 / 1474 loss=6.412, trans_loss=5.207, nll_loss=3.877, w2v_ctc_loss=2.95, task_loss=5.673, contrastive_loss=1.213, total=4187.61, n_correct=401.1, ppl=14.69, accuracy=9.578, wps=20391, ups=1.63, wpb=12484.3, bsz=487.1, num_updates=2600, lr=0.000104048, gnorm=0.852, clip=0, loss_scale=128, train_wall=61, gb_free=19.5, wall=1745
2023-07-13 16:11:43 | INFO | train_inner | epoch 002:   1227 / 1474 loss=6.352, trans_loss=5.193, nll_loss=3.858, w2v_ctc_loss=2.904, task_loss=5.72, contrastive_loss=1.134, total=4221.06, n_correct=417.07, ppl=14.5, accuracy=9.881, wps=20651.1, ups=1.64, wpb=12590.1, bsz=492.8, num_updates=2700, lr=0.000108046, gnorm=0.826, clip=0, loss_scale=128, train_wall=61, gb_free=19.4, wall=1806
2023-07-13 16:12:43 | INFO | train_inner | epoch 002:   1327 / 1474 loss=6.254, trans_loss=5.176, nll_loss=3.841, w2v_ctc_loss=2.865, task_loss=6.026, contrastive_loss=0.847, total=4157.86, n_correct=413.42, ppl=14.33, accuracy=9.943, wps=20710.2, ups=1.67, wpb=12422.5, bsz=460.7, num_updates=2800, lr=0.000112044, gnorm=0.807, clip=0, loss_scale=128, train_wall=60, gb_free=19.5, wall=1866
2023-07-13 16:13:44 | INFO | train_inner | epoch 002:   1427 / 1474 loss=6.218, trans_loss=5.177, nll_loss=3.839, w2v_ctc_loss=2.819, task_loss=6.776, contrastive_loss=0.931, total=4054.34, n_correct=408.37, ppl=14.31, accuracy=10.072, wps=19949.9, ups=1.64, wpb=12128.6, bsz=438.8, num_updates=2900, lr=0.000116042, gnorm=0.766, clip=0, loss_scale=128, train_wall=60, gb_free=19.4, wall=1927
2023-07-13 16:14:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 16:14:46 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.157 | trans_loss 10.207 | nll_loss 8.997 | w2v_ctc_loss 3.604 | task_loss 37.726 | contrastive_loss 0.995 | total 4003.4 | n_correct 497.8 | ppl 511.1 | accuracy 12.434 | uer 51.496 | wer 50.472 | raw_wer 50.472 | bleu 0.11 | wps 1450.1 | wpb 4003.4 | bsz 141.8 | num_updates 2947 | best_bleu 0.11
2023-07-13 16:14:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2947 updates
2023-07-13 16:14:46 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 16:14:51 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 16:14:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt (epoch 2 @ 2947 updates, score 0.11) (writing took 8.242286690045148 seconds)
2023-07-13 16:14:55 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-07-13 16:14:55 | INFO | train | epoch 002 | loss 6.748 | trans_loss 5.246 | nll_loss 3.924 | w2v_ctc_loss 3.292 | task_loss 6.351 | contrastive_loss 1.237 | total 4138.65 | n_correct 375.732 | ppl 15.18 | accuracy 9.079 | wps 18468.2 | ups 1.49 | wpb 12355.8 | bsz 458.5 | num_updates 2947 | lr 0.000117921 | gnorm 1.18 | clip 0 | loss_scale 128 | train_wall 887 | gb_free 19.3 | wall 1998
2023-07-13 16:14:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 16:14:55 | INFO | fairseq.trainer | begin training epoch 3
2023-07-13 16:14:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 16:15:35 | INFO | train_inner | epoch 003:     53 / 1474 loss=6.142, trans_loss=5.159, nll_loss=3.817, w2v_ctc_loss=2.766, task_loss=6.334, contrastive_loss=0.827, total=4071.2, n_correct=421.61, ppl=14.09, accuracy=10.356, wps=10915.5, ups=0.9, wpb=12148.3, bsz=442.6, num_updates=3000, lr=0.00012004, gnorm=0.731, clip=0, loss_scale=128, train_wall=61, gb_free=19.1, wall=2038
2023-07-13 16:15:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-13 16:15:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-13 16:15:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-13 16:15:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-13 16:15:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-07-13 16:17:05 | INFO | train_inner | epoch 003:    158 / 1474 loss=5.392, trans_loss=4.475, nll_loss=2.923, w2v_ctc_loss=2.412, task_loss=4.236, contrastive_loss=0.69, total=4144.18, n_correct=1056.6, ppl=7.58, accuracy=25.496, wps=13684.3, ups=1.11, wpb=12381.7, bsz=458.6, num_updates=3100, lr=0.000124038, gnorm=1.68, clip=1, loss_scale=4, train_wall=90, gb_free=16.7, wall=2129
2023-07-13 16:18:33 | INFO | train_inner | epoch 003:    258 / 1474 loss=4.958, trans_loss=4.191, nll_loss=2.548, w2v_ctc_loss=2.142, task_loss=4.297, contrastive_loss=0.603, total=4161.13, n_correct=1374.42, ppl=5.85, accuracy=33.03, wps=14128.7, ups=1.14, wpb=12444.3, bsz=467, num_updates=3200, lr=0.000128036, gnorm=1.143, clip=0, loss_scale=4, train_wall=88, gb_free=17.3, wall=2217
2023-07-13 16:20:01 | INFO | train_inner | epoch 003:    358 / 1474 loss=4.817, trans_loss=4.098, nll_loss=2.426, w2v_ctc_loss=2.042, task_loss=4.328, contrastive_loss=0.632, total=4150.02, n_correct=1501.43, ppl=5.37, accuracy=36.179, wps=14163, ups=1.15, wpb=12369, bsz=461.6, num_updates=3300, lr=0.000132034, gnorm=1.145, clip=0, loss_scale=4, train_wall=87, gb_free=17.3, wall=2304
2023-07-13 16:21:28 | INFO | train_inner | epoch 003:    458 / 1474 loss=4.669, trans_loss=4.02, nll_loss=2.325, w2v_ctc_loss=1.951, task_loss=4.189, contrastive_loss=0.487, total=4209.57, n_correct=1635.95, ppl=5.01, accuracy=38.863, wps=14332.9, ups=1.14, wpb=12537.6, bsz=476.8, num_updates=3400, lr=0.000136032, gnorm=1.038, clip=0, loss_scale=4, train_wall=87, gb_free=16.2, wall=2392
2023-07-13 16:22:55 | INFO | train_inner | epoch 003:    558 / 1474 loss=4.564, trans_loss=3.978, nll_loss=2.265, w2v_ctc_loss=1.858, task_loss=4.617, contrastive_loss=0.457, total=4088.48, n_correct=1655.43, ppl=4.81, accuracy=40.49, wps=14093.7, ups=1.15, wpb=12237.1, bsz=439.7, num_updates=3500, lr=0.00014003, gnorm=0.999, clip=0, loss_scale=4, train_wall=86, gb_free=17.8, wall=2479
2023-07-13 16:24:24 | INFO | train_inner | epoch 003:    658 / 1474 loss=4.499, trans_loss=3.933, nll_loss=2.208, w2v_ctc_loss=1.798, task_loss=4.133, contrastive_loss=0.56, total=4221.58, n_correct=1790.5, ppl=4.62, accuracy=42.413, wps=14200, ups=1.13, wpb=12558.6, bsz=481.9, num_updates=3600, lr=0.000144028, gnorm=0.946, clip=0, loss_scale=4, train_wall=88, gb_free=16.5, wall=2567
2023-07-13 16:25:50 | INFO | train_inner | epoch 003:    758 / 1474 loss=4.419, trans_loss=3.9, nll_loss=2.165, w2v_ctc_loss=1.76, task_loss=4.122, contrastive_loss=0.33, total=4167.41, n_correct=1809.65, ppl=4.48, accuracy=43.424, wps=14415, ups=1.16, wpb=12462.8, bsz=472.6, num_updates=3700, lr=0.000148026, gnorm=0.952, clip=0, loss_scale=4, train_wall=86, gb_free=16.5, wall=2653
2023-07-13 16:27:17 | INFO | train_inner | epoch 003:    858 / 1474 loss=4.369, trans_loss=3.883, nll_loss=2.141, w2v_ctc_loss=1.718, task_loss=4.372, contrastive_loss=0.295, total=4165.53, n_correct=1836.31, ppl=4.41, accuracy=44.083, wps=14345.7, ups=1.15, wpb=12445.3, bsz=456.1, num_updates=3800, lr=0.000152024, gnorm=0.922, clip=0, loss_scale=4, train_wall=86, gb_free=17.2, wall=2740
2023-07-13 16:28:44 | INFO | train_inner | epoch 003:    958 / 1474 loss=4.337, trans_loss=3.854, nll_loss=2.103, w2v_ctc_loss=1.697, task_loss=4.197, contrastive_loss=0.329, total=4162.3, n_correct=1886.53, ppl=4.3, accuracy=45.324, wps=14288.6, ups=1.15, wpb=12408.5, bsz=469.2, num_updates=3900, lr=0.000156022, gnorm=0.925, clip=0, loss_scale=4, train_wall=86, gb_free=16.9, wall=2827
2023-07-13 16:30:10 | INFO | train_inner | epoch 003:   1058 / 1474 loss=4.312, trans_loss=3.845, nll_loss=2.091, w2v_ctc_loss=1.682, task_loss=4.605, contrastive_loss=0.286, total=4069.95, n_correct=1865.46, ppl=4.26, accuracy=45.835, wps=14067.8, ups=1.16, wpb=12168.2, bsz=443.6, num_updates=4000, lr=0.00016002, gnorm=0.923, clip=0, loss_scale=4, train_wall=86, gb_free=16.5, wall=2914
2023-07-13 16:30:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 16:30:43 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 4.979 | trans_loss 6.413 | nll_loss 3.955 | w2v_ctc_loss 1.953 | task_loss 21.834 | contrastive_loss 0.385 | total 4003.4 | n_correct 1960.1 | ppl 15.51 | accuracy 48.961 | uer 28.978 | wer 30.092 | raw_wer 30.092 | bleu 7.58 | wps 1543.9 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 7.58
2023-07-13 16:30:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-07-13 16:30:43 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_3_4000.pt
2023-07-13 16:30:45 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_3_4000.pt
2023-07-13 16:30:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 7.58) (writing took 9.234030175954103 seconds)
2023-07-13 16:32:19 | INFO | train_inner | epoch 003:   1158 / 1474 loss=4.275, trans_loss=3.836, nll_loss=2.079, w2v_ctc_loss=1.643, task_loss=4.704, contrastive_loss=0.264, total=4038.49, n_correct=1866.6, ppl=4.23, accuracy=46.22, wps=9380.9, ups=0.78, wpb=12064, bsz=432.5, num_updates=4100, lr=0.000164018, gnorm=0.899, clip=0, loss_scale=4, train_wall=86, gb_free=16.6, wall=3042
2023-07-13 16:33:46 | INFO | train_inner | epoch 003:   1258 / 1474 loss=4.239, trans_loss=3.819, nll_loss=2.058, w2v_ctc_loss=1.609, task_loss=4.595, contrastive_loss=0.25, total=4064.31, n_correct=1913.52, ppl=4.17, accuracy=47.081, wps=13975.6, ups=1.15, wpb=12147.9, bsz=433.9, num_updates=4200, lr=0.000168016, gnorm=0.877, clip=0, loss_scale=4, train_wall=87, gb_free=17.5, wall=3129
2023-07-13 16:35:13 | INFO | train_inner | epoch 003:   1358 / 1474 loss=4.224, trans_loss=3.797, nll_loss=2.032, w2v_ctc_loss=1.591, task_loss=4.383, contrastive_loss=0.361, total=4134.58, n_correct=1966.56, ppl=4.09, accuracy=47.564, wps=14038.1, ups=1.14, wpb=12326.9, bsz=460.7, num_updates=4300, lr=0.000172014, gnorm=0.895, clip=0, loss_scale=4, train_wall=87, gb_free=17.9, wall=3217
2023-07-13 16:36:41 | INFO | train_inner | epoch 003:   1458 / 1474 loss=4.191, trans_loss=3.784, nll_loss=2.015, w2v_ctc_loss=1.56, task_loss=4.128, contrastive_loss=0.343, total=4209.94, n_correct=2033.88, ppl=4.04, accuracy=48.311, wps=14340.7, ups=1.14, wpb=12573.7, bsz=477.4, num_updates=4400, lr=0.000176012, gnorm=0.87, clip=0, loss_scale=4, train_wall=87, gb_free=17.2, wall=3305
2023-07-13 16:36:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 16:37:26 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 4.838 | trans_loss 6.288 | nll_loss 3.787 | w2v_ctc_loss 1.783 | task_loss 21.329 | contrastive_loss 0.359 | total 4003.4 | n_correct 2051.6 | ppl 13.8 | accuracy 51.246 | uer 27.725 | wer 28.381 | raw_wer 28.381 | bleu 8.69 | wps 1585.6 | wpb 4003.4 | bsz 141.8 | num_updates 4416 | best_bleu 8.69
2023-07-13 16:37:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4416 updates
2023-07-13 16:37:26 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 16:37:30 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 16:37:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt (epoch 3 @ 4416 updates, score 8.69) (writing took 9.611225450993516 seconds)
2023-07-13 16:37:36 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-07-13 16:37:36 | INFO | train | epoch 003 | loss 4.574 | trans_loss 4 | nll_loss 2.296 | w2v_ctc_loss 1.85 | task_loss 4.414 | contrastive_loss 0.438 | total 4140.05 | n_correct 1683.27 | ppl 4.91 | accuracy 40.658 | wps 13337.9 | ups 1.08 | wpb 12360.2 | bsz 459 | num_updates 4416 | lr 0.000176652 | gnorm 1.004 | clip 0.1 | loss_scale 4 | train_wall 1264 | gb_free 16.8 | wall 3359
2023-07-13 16:37:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 16:37:36 | INFO | fairseq.trainer | begin training epoch 4
2023-07-13 16:37:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 16:38:56 | INFO | train_inner | epoch 004:     84 / 1474 loss=4.111, trans_loss=3.755, nll_loss=1.977, w2v_ctc_loss=1.518, task_loss=4.492, contrastive_loss=0.197, total=4099.41, n_correct=2010.79, ppl=3.94, accuracy=49.051, wps=9030.8, ups=0.74, wpb=12215.8, bsz=439.5, num_updates=4500, lr=0.00018001, gnorm=0.845, clip=0, loss_scale=4, train_wall=86, gb_free=16.6, wall=3440
2023-07-13 16:40:23 | INFO | train_inner | epoch 004:    184 / 1474 loss=4.093, trans_loss=3.739, nll_loss=1.955, w2v_ctc_loss=1.497, task_loss=4.118, contrastive_loss=0.222, total=4175.15, n_correct=2076.99, ppl=3.88, accuracy=49.746, wps=14365.2, ups=1.15, wpb=12466.1, bsz=468.3, num_updates=4600, lr=0.000184008, gnorm=0.854, clip=0, loss_scale=4, train_wall=86, gb_free=16.8, wall=3527
2023-07-13 16:41:50 | INFO | train_inner | epoch 004:    284 / 1474 loss=4.112, trans_loss=3.741, nll_loss=1.96, w2v_ctc_loss=1.495, task_loss=4.351, contrastive_loss=0.351, total=4145.23, n_correct=2059.69, ppl=3.89, accuracy=49.688, wps=14190.5, ups=1.15, wpb=12387.3, bsz=463, num_updates=4700, lr=0.000188006, gnorm=0.854, clip=0, loss_scale=4, train_wall=87, gb_free=16.1, wall=3614
2023-07-13 16:43:17 | INFO | train_inner | epoch 004:    384 / 1474 loss=4.078, trans_loss=3.74, nll_loss=1.956, w2v_ctc_loss=1.48, task_loss=4.534, contrastive_loss=0.193, total=4127.66, n_correct=2060.27, ppl=3.88, accuracy=49.914, wps=14191.1, ups=1.15, wpb=12298.8, bsz=443.5, num_updates=4800, lr=0.000192004, gnorm=0.834, clip=0, loss_scale=4, train_wall=86, gb_free=17.6, wall=3701
2023-07-13 16:44:45 | INFO | train_inner | epoch 004:    484 / 1474 loss=4.095, trans_loss=3.72, nll_loss=1.934, w2v_ctc_loss=1.442, task_loss=3.936, contrastive_loss=0.593, total=4218.78, n_correct=2134.57, ppl=3.82, accuracy=50.597, wps=14309.6, ups=1.14, wpb=12578.2, bsz=497.8, num_updates=4900, lr=0.000196002, gnorm=0.829, clip=0, loss_scale=4, train_wall=87, gb_free=16.7, wall=3789
2023-07-13 16:46:13 | INFO | train_inner | epoch 004:    584 / 1474 loss=4.067, trans_loss=3.718, nll_loss=1.93, w2v_ctc_loss=1.472, task_loss=4.092, contrastive_loss=0.268, total=4217.52, n_correct=2139.49, ppl=3.81, accuracy=50.729, wps=14381.7, ups=1.14, wpb=12583.6, bsz=485.9, num_updates=5000, lr=0.0002, gnorm=0.843, clip=0, loss_scale=4, train_wall=87, gb_free=16.3, wall=3876
asr_weight tensor(0.8505, device='cuda:0')
mt_weight tensor(0.8085, device='cuda:0')
2023-07-13 16:47:41 | INFO | train_inner | epoch 004:    684 / 1474 loss=4.048, trans_loss=3.72, nll_loss=1.929, w2v_ctc_loss=1.437, task_loss=4.475, contrastive_loss=0.314, total=4176.39, n_correct=2127.87, ppl=3.81, accuracy=50.95, wps=14061.5, ups=1.13, wpb=12440.1, bsz=455.8, num_updates=5100, lr=0.00019803, gnorm=0.705, clip=0, loss_scale=8, train_wall=88, gb_free=17.2, wall=3964
2023-07-13 16:49:08 | INFO | train_inner | epoch 004:    784 / 1474 loss=4.036, trans_loss=3.715, nll_loss=1.923, w2v_ctc_loss=1.446, task_loss=4.804, contrastive_loss=0.187, total=4026.63, n_correct=2058.66, ppl=3.79, accuracy=51.126, wps=13860.6, ups=1.15, wpb=12049.9, bsz=420.6, num_updates=5200, lr=0.000196116, gnorm=0.715, clip=0, loss_scale=8, train_wall=87, gb_free=13.5, wall=4051
2023-07-13 16:50:36 | INFO | train_inner | epoch 004:    884 / 1474 loss=4.04, trans_loss=3.701, nll_loss=1.91, w2v_ctc_loss=1.431, task_loss=4.351, contrastive_loss=0.37, total=4186.04, n_correct=2156.2, ppl=3.76, accuracy=51.509, wps=14177.6, ups=1.13, wpb=12493.4, bsz=466.3, num_updates=5300, lr=0.000194257, gnorm=0.701, clip=0, loss_scale=8, train_wall=88, gb_free=17.8, wall=4140
2023-07-13 16:52:04 | INFO | train_inner | epoch 004:    984 / 1474 loss=3.995, trans_loss=3.692, nll_loss=1.898, w2v_ctc_loss=1.407, task_loss=4.425, contrastive_loss=0.227, total=4125.02, n_correct=2139.91, ppl=3.73, accuracy=51.876, wps=14090.6, ups=1.14, wpb=12319.9, bsz=457.1, num_updates=5400, lr=0.00019245, gnorm=0.694, clip=0, loss_scale=8, train_wall=87, gb_free=13.1, wall=4227
2023-07-13 16:53:31 | INFO | train_inner | epoch 004:   1084 / 1474 loss=4.004, trans_loss=3.698, nll_loss=1.904, w2v_ctc_loss=1.415, task_loss=4.708, contrastive_loss=0.204, total=4075.6, n_correct=2112.37, ppl=3.74, accuracy=51.83, wps=13957.3, ups=1.15, wpb=12166.1, bsz=435.7, num_updates=5500, lr=0.000190693, gnorm=0.699, clip=0, loss_scale=8, train_wall=87, gb_free=16.2, wall=4314
2023-07-13 16:54:58 | INFO | train_inner | epoch 004:   1184 / 1474 loss=4.004, trans_loss=3.689, nll_loss=1.894, w2v_ctc_loss=1.399, task_loss=4.085, contrastive_loss=0.311, total=4161.18, n_correct=2179.37, ppl=3.72, accuracy=52.374, wps=14346.3, ups=1.15, wpb=12451.8, bsz=483.4, num_updates=5600, lr=0.000188982, gnorm=0.698, clip=0, loss_scale=8, train_wall=86, gb_free=16.9, wall=4401
2023-07-13 16:56:24 | INFO | train_inner | epoch 004:   1284 / 1474 loss=3.987, trans_loss=3.685, nll_loss=1.887, w2v_ctc_loss=1.385, task_loss=4.165, contrastive_loss=0.276, total=4156.53, n_correct=2186.47, ppl=3.7, accuracy=52.603, wps=14339.5, ups=1.15, wpb=12424.6, bsz=472.7, num_updates=5700, lr=0.000187317, gnorm=0.687, clip=0, loss_scale=8, train_wall=86, gb_free=16.2, wall=4488
2023-07-13 16:57:49 | INFO | train_inner | epoch 004:   1384 / 1474 loss=3.962, trans_loss=3.678, nll_loss=1.879, w2v_ctc_loss=1.386, task_loss=4.48, contrastive_loss=0.157, total=4101.23, n_correct=2164.4, ppl=3.68, accuracy=52.774, wps=14366.5, ups=1.17, wpb=12255, bsz=437.6, num_updates=5800, lr=0.000185695, gnorm=0.673, clip=0, loss_scale=8, train_wall=85, gb_free=15.8, wall=4573
2023-07-13 16:59:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
asr_weight tensor(0.8505, device='cuda:5')
mt_weight tensor(0.8085, device='cuda:5')
asr_weight tensor(0.8505, device='cuda:7')
mt_weight tensor(0.8085, device='cuda:7')
asr_weight tensor(0.8505, device='cuda:4')
mt_weight tensor(0.8085, device='cuda:4')
asr_weight tensor(0.8505, device='cuda:3')
mt_weight tensor(0.8085, device='cuda:3')
asr_weight tensor(0.8505, device='cuda:6')
mt_weight tensor(0.8085, device='cuda:6')
asr_weight tensor(0.8505, device='cuda:2')
mt_weight tensor(0.8085, device='cuda:2')
asr_weight tensor(0.8505, device='cuda:1')
mt_weight tensor(0.8085, device='cuda:1')
2023-07-13 16:59:36 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.515 | trans_loss 5.934 | nll_loss 3.318 | w2v_ctc_loss 1.537 | task_loss 22.394 | contrastive_loss 0.302 | total 4003.4 | n_correct 2254 | ppl 9.97 | accuracy 56.302 | uer 22.581 | wer 24.201 | raw_wer 24.201 | bleu 15.07 | wps 1844.4 | wpb 4003.4 | bsz 141.8 | num_updates 5890 | best_bleu 15.07
2023-07-13 16:59:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5890 updates
2023-07-13 16:59:36 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 16:59:40 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 16:59:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt (epoch 4 @ 5890 updates, score 15.07) (writing took 8.329224204062484 seconds)
2023-07-13 16:59:45 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-07-13 16:59:45 | INFO | train | epoch 004 | loss 4.038 | trans_loss 3.711 | nll_loss 1.92 | w2v_ctc_loss 1.438 | task_loss 4.356 | contrastive_loss 0.275 | total 4138.65 | n_correct 2118.61 | ppl 3.78 | accuracy 51.191 | wps 13709.3 | ups 1.11 | wpb 12355.8 | bsz 458.5 | num_updates 5890 | lr 0.000184271 | gnorm 0.753 | clip 0 | loss_scale 8 | train_wall 1278 | gb_free 15 | wall 4688
2023-07-13 16:59:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 16:59:45 | INFO | fairseq.trainer | begin training epoch 5
2023-07-13 16:59:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 17:00:02 | INFO | train_inner | epoch 005:     10 / 1474 loss=3.943, trans_loss=3.673, nll_loss=1.873, w2v_ctc_loss=1.36, task_loss=4.531, contrastive_loss=0.175, total=4037.7, n_correct=2138.29, ppl=3.66, accuracy=52.958, wps=9135.2, ups=0.76, wpb=12062.8, bsz=439.3, num_updates=5900, lr=0.000184115, gnorm=0.678, clip=0, loss_scale=8, train_wall=86, gb_free=17, wall=4705
2023-07-13 17:01:29 | INFO | train_inner | epoch 005:    110 / 1474 loss=3.848, trans_loss=3.621, nll_loss=1.806, w2v_ctc_loss=1.28, task_loss=3.946, contrastive_loss=0.183, total=4247.37, n_correct=2315.87, ppl=3.5, accuracy=54.525, wps=14533, ups=1.15, wpb=12683.8, bsz=495.1, num_updates=6000, lr=0.000182574, gnorm=0.65, clip=0, loss_scale=8, train_wall=87, gb_free=16.9, wall=4792
2023-07-13 17:01:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 17:01:58 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.508 | trans_loss 5.933 | nll_loss 3.317 | w2v_ctc_loss 1.517 | task_loss 22.44 | contrastive_loss 0.299 | total 4003.4 | n_correct 2243.2 | ppl 9.97 | accuracy 56.032 | uer 22.671 | wer 24.283 | raw_wer 24.283 | bleu 14.22 | wps 1794.9 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 15.07
2023-07-13 17:01:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-07-13 17:01:58 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_5_6000.pt
2023-07-13 17:02:00 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_5_6000.pt
2023-07-13 17:02:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 14.22) (writing took 6.384816866950132 seconds)
2023-07-13 17:03:30 | INFO | train_inner | epoch 005:    210 / 1474 loss=3.892, trans_loss=3.63, nll_loss=1.816, w2v_ctc_loss=1.295, task_loss=4.036, contrastive_loss=0.405, total=4189.85, n_correct=2274.69, ppl=3.52, accuracy=54.29, wps=10302, ups=0.82, wpb=12492.8, bsz=488.2, num_updates=6100, lr=0.000181071, gnorm=0.651, clip=0, loss_scale=8, train_wall=85, gb_free=17.9, wall=4914
2023-07-13 17:04:56 | INFO | train_inner | epoch 005:    310 / 1474 loss=3.889, trans_loss=3.63, nll_loss=1.819, w2v_ctc_loss=1.316, task_loss=4.496, contrastive_loss=0.255, total=4090.1, n_correct=2209.45, ppl=3.53, accuracy=54.019, wps=14194.8, ups=1.16, wpb=12240, bsz=443.9, num_updates=6200, lr=0.000179605, gnorm=0.67, clip=0, loss_scale=8, train_wall=86, gb_free=16.4, wall=5000
2023-07-13 17:06:24 | INFO | train_inner | epoch 005:    410 / 1474 loss=3.869, trans_loss=3.621, nll_loss=1.811, w2v_ctc_loss=1.278, task_loss=4.206, contrastive_loss=0.342, total=4147.17, n_correct=2260.53, ppl=3.51, accuracy=54.508, wps=14192.4, ups=1.15, wpb=12381.8, bsz=472.5, num_updates=6300, lr=0.000178174, gnorm=0.671, clip=0, loss_scale=8, train_wall=87, gb_free=15.1, wall=5087
2023-07-13 17:07:50 | INFO | train_inner | epoch 005:    510 / 1474 loss=3.86, trans_loss=3.634, nll_loss=1.821, w2v_ctc_loss=1.291, task_loss=4.925, contrastive_loss=0.13, total=4026.81, n_correct=2185.71, ppl=3.53, accuracy=54.279, wps=13896.5, ups=1.15, wpb=12047.2, bsz=416.6, num_updates=6400, lr=0.000176777, gnorm=0.658, clip=0, loss_scale=8, train_wall=86, gb_free=17.5, wall=5174
2023-07-13 17:09:18 | INFO | train_inner | epoch 005:    610 / 1474 loss=3.862, trans_loss=3.627, nll_loss=1.813, w2v_ctc_loss=1.275, task_loss=4.491, contrastive_loss=0.299, total=4107.75, n_correct=2236.32, ppl=3.51, accuracy=54.441, wps=13996.4, ups=1.14, wpb=12245.3, bsz=451.2, num_updates=6500, lr=0.000175412, gnorm=0.665, clip=0, loss_scale=8, train_wall=87, gb_free=16.3, wall=5261
2023-07-13 17:10:45 | INFO | train_inner | epoch 005:    710 / 1474 loss=3.869, trans_loss=3.624, nll_loss=1.811, w2v_ctc_loss=1.286, task_loss=4.146, contrastive_loss=0.281, total=4178.85, n_correct=2279.33, ppl=3.51, accuracy=54.544, wps=14308.2, ups=1.15, wpb=12462.3, bsz=480.9, num_updates=6600, lr=0.000174078, gnorm=0.658, clip=0, loss_scale=8, train_wall=87, gb_free=17.8, wall=5348
2023-07-13 17:12:13 | INFO | train_inner | epoch 005:    810 / 1474 loss=3.854, trans_loss=3.626, nll_loss=1.811, w2v_ctc_loss=1.275, task_loss=4.506, contrastive_loss=0.204, total=4127.73, n_correct=2258.07, ppl=3.51, accuracy=54.705, wps=14025.8, ups=1.14, wpb=12320.4, bsz=449.2, num_updates=6700, lr=0.000172774, gnorm=0.652, clip=0, loss_scale=8, train_wall=87, gb_free=15.4, wall=5436
2023-07-13 17:13:39 | INFO | train_inner | epoch 005:    910 / 1474 loss=3.835, trans_loss=3.622, nll_loss=1.808, w2v_ctc_loss=1.264, task_loss=4.535, contrastive_loss=0.166, total=4095.48, n_correct=2245.66, ppl=3.5, accuracy=54.833, wps=14118.2, ups=1.15, wpb=12237.9, bsz=445.3, num_updates=6800, lr=0.000171499, gnorm=0.658, clip=0, loss_scale=8, train_wall=86, gb_free=15.8, wall=5523
2023-07-13 17:15:06 | INFO | train_inner | epoch 005:   1010 / 1474 loss=3.852, trans_loss=3.623, nll_loss=1.81, w2v_ctc_loss=1.273, task_loss=4.304, contrastive_loss=0.248, total=4165.12, n_correct=2288.18, ppl=3.51, accuracy=54.937, wps=14318.6, ups=1.15, wpb=12426.3, bsz=463.5, num_updates=6900, lr=0.000170251, gnorm=0.649, clip=0, loss_scale=8, train_wall=86, gb_free=15.9, wall=5610
2023-07-13 17:16:34 | INFO | train_inner | epoch 005:   1110 / 1474 loss=3.857, trans_loss=3.623, nll_loss=1.807, w2v_ctc_loss=1.27, task_loss=4.324, contrastive_loss=0.248, total=4176.72, n_correct=2298.13, ppl=3.5, accuracy=55.022, wps=14132.6, ups=1.13, wpb=12467.3, bsz=466.1, num_updates=7000, lr=0.000169031, gnorm=0.645, clip=0, loss_scale=8, train_wall=88, gb_free=16.9, wall=5698
2023-07-13 17:18:02 | INFO | train_inner | epoch 005:   1210 / 1474 loss=3.826, trans_loss=3.621, nll_loss=1.805, w2v_ctc_loss=1.255, task_loss=4.46, contrastive_loss=0.153, total=4164.13, n_correct=2301.4, ppl=3.5, accuracy=55.267, wps=14102, ups=1.14, wpb=12416.1, bsz=453.8, num_updates=7100, lr=0.000167836, gnorm=0.648, clip=0, loss_scale=16, train_wall=88, gb_free=17.1, wall=5786
2023-07-13 17:19:30 | INFO | train_inner | epoch 005:   1310 / 1474 loss=3.813, trans_loss=3.616, nll_loss=1.799, w2v_ctc_loss=1.242, task_loss=4.447, contrastive_loss=0.123, total=4134.91, n_correct=2288.15, ppl=3.48, accuracy=55.337, wps=14152.2, ups=1.15, wpb=12356.4, bsz=445.6, num_updates=7200, lr=0.000166667, gnorm=0.639, clip=0, loss_scale=16, train_wall=87, gb_free=16.6, wall=5873
2023-07-13 17:20:56 | INFO | train_inner | epoch 005:   1410 / 1474 loss=3.814, trans_loss=3.61, nll_loss=1.797, w2v_ctc_loss=1.242, task_loss=4.403, contrastive_loss=0.186, total=4134.37, n_correct=2280.42, ppl=3.47, accuracy=55.158, wps=14223.8, ups=1.15, wpb=12339.9, bsz=458.5, num_updates=7300, lr=0.000165521, gnorm=0.642, clip=0, loss_scale=16, train_wall=86, gb_free=17.9, wall=5960
2023-07-13 17:21:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 17:22:23 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.44 | trans_loss 5.874 | nll_loss 3.239 | w2v_ctc_loss 1.426 | task_loss 22.447 | contrastive_loss 0.3 | total 4003.4 | n_correct 2288.3 | ppl 9.44 | accuracy 57.159 | uer 21.626 | wer 23.385 | raw_wer 23.385 | bleu 14.89 | wps 1667 | wpb 4003.4 | bsz 141.8 | num_updates 7364 | best_bleu 15.07
2023-07-13 17:22:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7364 updates
2023-07-13 17:22:23 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_14.8900.pt
2023-07-13 17:22:25 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_14.8900.pt
2023-07-13 17:22:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_14.8900.pt (epoch 5 @ 7364 updates, score 14.89) (writing took 5.411385298008099 seconds)
2023-07-13 17:22:28 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-07-13 17:22:28 | INFO | train | epoch 005 | loss 3.852 | trans_loss 3.623 | nll_loss 1.809 | w2v_ctc_loss 1.274 | task_loss 4.369 | contrastive_loss 0.231 | total 4138.65 | n_correct 2265.49 | ppl 3.5 | accuracy 54.74 | wps 13355.5 | ups 1.08 | wpb 12355.8 | bsz 458.5 | num_updates 7364 | lr 0.0001648 | gnorm 0.655 | clip 0 | loss_scale 16 | train_wall 1277 | gb_free 16.4 | wall 6052
2023-07-13 17:22:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 17:22:28 | INFO | fairseq.trainer | begin training epoch 6
2023-07-13 17:22:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 17:23:08 | INFO | train_inner | epoch 006:     36 / 1474 loss=3.793, trans_loss=3.593, nll_loss=1.771, w2v_ctc_loss=1.225, task_loss=4.479, contrastive_loss=0.183, total=4115.45, n_correct=2305.02, ppl=3.41, accuracy=56.009, wps=9356.7, ups=0.76, wpb=12279.2, bsz=447.9, num_updates=7400, lr=0.000164399, gnorm=0.658, clip=0, loss_scale=16, train_wall=87, gb_free=16.6, wall=6091
2023-07-13 17:24:35 | INFO | train_inner | epoch 006:    136 / 1474 loss=3.74, trans_loss=3.568, nll_loss=1.739, w2v_ctc_loss=1.172, task_loss=4.359, contrastive_loss=0.227, total=4154.25, n_correct=2348.3, ppl=3.34, accuracy=56.528, wps=14225, ups=1.15, wpb=12409.6, bsz=456.1, num_updates=7500, lr=0.000163299, gnorm=0.635, clip=0, loss_scale=16, train_wall=87, gb_free=15.7, wall=6178
2023-07-13 17:26:02 | INFO | train_inner | epoch 006:    236 / 1474 loss=3.758, trans_loss=3.577, nll_loss=1.752, w2v_ctc_loss=1.213, task_loss=4.69, contrastive_loss=0.135, total=4112.66, n_correct=2308.57, ppl=3.37, accuracy=56.133, wps=14097.2, ups=1.15, wpb=12281.7, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.64, clip=0, loss_scale=16, train_wall=87, gb_free=16.3, wall=6266
2023-07-13 17:27:31 | INFO | train_inner | epoch 006:    336 / 1474 loss=3.766, trans_loss=3.566, nll_loss=1.738, w2v_ctc_loss=1.168, task_loss=4.05, contrastive_loss=0.44, total=4177.51, n_correct=2367.55, ppl=3.34, accuracy=56.674, wps=14020.2, ups=1.12, wpb=12463.7, bsz=491.3, num_updates=7700, lr=0.000161165, gnorm=0.639, clip=0, loss_scale=16, train_wall=88, gb_free=16.3, wall=6354
2023-07-13 17:28:58 | INFO | train_inner | epoch 006:    436 / 1474 loss=3.729, trans_loss=3.569, nll_loss=1.741, w2v_ctc_loss=1.172, task_loss=4.209, contrastive_loss=0.149, total=4154.57, n_correct=2357.72, ppl=3.34, accuracy=56.75, wps=14296.6, ups=1.15, wpb=12407.2, bsz=470.2, num_updates=7800, lr=0.000160128, gnorm=0.632, clip=0, loss_scale=16, train_wall=86, gb_free=16.3, wall=6441
2023-07-13 17:30:25 | INFO | train_inner | epoch 006:    536 / 1474 loss=3.739, trans_loss=3.572, nll_loss=1.746, w2v_ctc_loss=1.187, task_loss=4.391, contrastive_loss=0.136, total=4167.79, n_correct=2363.33, ppl=3.35, accuracy=56.705, wps=14240.6, ups=1.15, wpb=12419.2, bsz=455.2, num_updates=7900, lr=0.000159111, gnorm=0.638, clip=0, loss_scale=16, train_wall=87, gb_free=15.9, wall=6528
2023-07-13 17:31:51 | INFO | train_inner | epoch 006:    636 / 1474 loss=3.736, trans_loss=3.574, nll_loss=1.745, w2v_ctc_loss=1.166, task_loss=4.144, contrastive_loss=0.192, total=4146.17, n_correct=2350.38, ppl=3.35, accuracy=56.688, wps=14345.4, ups=1.16, wpb=12395.5, bsz=471.6, num_updates=8000, lr=0.000158114, gnorm=0.634, clip=0, loss_scale=16, train_wall=86, gb_free=16.7, wall=6615
2023-07-13 17:31:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 17:32:20 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.386 | trans_loss 5.813 | nll_loss 3.158 | w2v_ctc_loss 1.396 | task_loss 22.63 | contrastive_loss 0.277 | total 4003.4 | n_correct 2317.1 | ppl 8.93 | accuracy 57.878 | uer 20.617 | wer 22.371 | raw_wer 22.371 | bleu 17.12 | wps 1891.1 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 17.12
2023-07-13 17:32:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-07-13 17:32:20 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_6_8000.pt
2023-07-13 17:32:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_6_8000.pt
2023-07-13 17:32:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 17.12) (writing took 9.438556071952917 seconds)
2023-07-13 17:33:57 | INFO | train_inner | epoch 006:    736 / 1474 loss=3.745, trans_loss=3.575, nll_loss=1.751, w2v_ctc_loss=1.19, task_loss=4.47, contrastive_loss=0.147, total=4148.65, n_correct=2349.14, ppl=3.37, accuracy=56.624, wps=9886.5, ups=0.8, wpb=12378.4, bsz=453.7, num_updates=8100, lr=0.000157135, gnorm=0.633, clip=0, loss_scale=16, train_wall=87, gb_free=15.8, wall=6740
2023-07-13 17:35:25 | INFO | train_inner | epoch 006:    836 / 1474 loss=3.739, trans_loss=3.58, nll_loss=1.754, w2v_ctc_loss=1.176, task_loss=4.598, contrastive_loss=0.128, total=4114.34, n_correct=2323, ppl=3.37, accuracy=56.461, wps=13871.6, ups=1.13, wpb=12292.5, bsz=441.6, num_updates=8200, lr=0.000156174, gnorm=0.642, clip=0, loss_scale=16, train_wall=88, gb_free=15.3, wall=6829
2023-07-13 17:36:52 | INFO | train_inner | epoch 006:    936 / 1474 loss=3.755, trans_loss=3.578, nll_loss=1.754, w2v_ctc_loss=1.186, task_loss=4.561, contrastive_loss=0.224, total=4081.53, n_correct=2304.5, ppl=3.37, accuracy=56.462, wps=13995.9, ups=1.15, wpb=12166.1, bsz=444.5, num_updates=8300, lr=0.00015523, gnorm=0.644, clip=0, loss_scale=16, train_wall=87, gb_free=17.9, wall=6916
2023-07-13 17:38:19 | INFO | train_inner | epoch 006:   1036 / 1474 loss=3.751, trans_loss=3.571, nll_loss=1.745, w2v_ctc_loss=1.167, task_loss=4.16, contrastive_loss=0.301, total=4165.84, n_correct=2368.82, ppl=3.35, accuracy=56.863, wps=14334.5, ups=1.15, wpb=12437.3, bsz=477.2, num_updates=8400, lr=0.000154303, gnorm=0.64, clip=0, loss_scale=16, train_wall=86, gb_free=17, wall=7002
2023-07-13 17:39:45 | INFO | train_inner | epoch 006:   1136 / 1474 loss=3.738, trans_loss=3.578, nll_loss=1.752, w2v_ctc_loss=1.174, task_loss=4.845, contrastive_loss=0.131, total=4072.29, n_correct=2306.38, ppl=3.37, accuracy=56.636, wps=14056.6, ups=1.16, wpb=12165.1, bsz=428, num_updates=8500, lr=0.000153393, gnorm=0.634, clip=0, loss_scale=16, train_wall=86, gb_free=17.1, wall=7089
2023-07-13 17:41:13 | INFO | train_inner | epoch 006:   1236 / 1474 loss=3.76, trans_loss=3.569, nll_loss=1.742, w2v_ctc_loss=1.154, task_loss=4.245, contrastive_loss=0.45, total=4141.55, n_correct=2360.91, ppl=3.35, accuracy=57.005, wps=14187.4, ups=1.15, wpb=12385.8, bsz=474.8, num_updates=8600, lr=0.000152499, gnorm=0.631, clip=0, loss_scale=16, train_wall=87, gb_free=13.5, wall=7176
2023-07-13 17:42:39 | INFO | train_inner | epoch 006:   1336 / 1474 loss=3.72, trans_loss=3.576, nll_loss=1.747, w2v_ctc_loss=1.155, task_loss=4.361, contrastive_loss=0.117, total=4125.31, n_correct=2355.28, ppl=3.36, accuracy=57.093, wps=14275.1, ups=1.16, wpb=12316, bsz=452.6, num_updates=8700, lr=0.00015162, gnorm=0.628, clip=0, loss_scale=16, train_wall=86, gb_free=17.8, wall=7263
2023-07-13 17:44:07 | INFO | train_inner | epoch 006:   1436 / 1474 loss=3.718, trans_loss=3.565, nll_loss=1.738, w2v_ctc_loss=1.164, task_loss=4.37, contrastive_loss=0.124, total=4196.2, n_correct=2401.32, ppl=3.34, accuracy=57.226, wps=14233.2, ups=1.14, wpb=12515.5, bsz=461.5, num_updates=8800, lr=0.000150756, gnorm=0.621, clip=0, loss_scale=16, train_wall=88, gb_free=11.8, wall=7350
2023-07-13 17:44:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 17:45:09 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.342 | trans_loss 5.771 | nll_loss 3.097 | w2v_ctc_loss 1.346 | task_loss 22.856 | contrastive_loss 0.277 | total 4003.4 | n_correct 2349.3 | ppl 8.55 | accuracy 58.683 | uer 19.515 | wer 21.181 | raw_wer 21.181 | bleu 17.07 | wps 1770.9 | wpb 4003.4 | bsz 141.8 | num_updates 8838 | best_bleu 17.12
2023-07-13 17:45:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8838 updates
2023-07-13 17:45:09 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_17.0701.pt
2023-07-13 17:45:11 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_17.0701.pt
2023-07-13 17:45:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_17.0701.pt (epoch 6 @ 8838 updates, score 17.07) (writing took 5.405383102945052 seconds)
2023-07-13 17:45:14 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-07-13 17:45:14 | INFO | train | epoch 006 | loss 3.741 | trans_loss 3.572 | nll_loss 1.745 | w2v_ctc_loss 1.174 | task_loss 4.374 | contrastive_loss 0.207 | total 4138.65 | n_correct 2347.54 | ppl 3.35 | accuracy 56.722 | wps 13329.8 | ups 1.08 | wpb 12355.8 | bsz 458.5 | num_updates 8838 | lr 0.000150431 | gnorm 0.635 | clip 0 | loss_scale 16 | train_wall 1279 | gb_free 15.3 | wall 7418
2023-07-13 17:45:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 17:45:15 | INFO | fairseq.trainer | begin training epoch 7
2023-07-13 17:45:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 17:46:17 | INFO | train_inner | epoch 007:     62 / 1474 loss=3.672, trans_loss=3.542, nll_loss=1.707, w2v_ctc_loss=1.121, task_loss=4.271, contrastive_loss=0.139, total=4108.19, n_correct=2374.62, ppl=3.26, accuracy=57.802, wps=9429.7, ups=0.77, wpb=12269.7, bsz=461.9, num_updates=8900, lr=0.000149906, gnorm=0.622, clip=0, loss_scale=16, train_wall=87, gb_free=17.2, wall=7481
2023-07-13 17:47:44 | INFO | train_inner | epoch 007:    162 / 1474 loss=3.662, trans_loss=3.533, nll_loss=1.696, w2v_ctc_loss=1.105, task_loss=4.438, contrastive_loss=0.214, total=4106.05, n_correct=2378.06, ppl=3.24, accuracy=57.916, wps=14149.3, ups=1.15, wpb=12254.3, bsz=455.4, num_updates=9000, lr=0.000149071, gnorm=0.628, clip=0, loss_scale=16, train_wall=86, gb_free=16.9, wall=7567
2023-07-13 17:49:10 | INFO | train_inner | epoch 007:    262 / 1474 loss=3.655, trans_loss=3.533, nll_loss=1.693, w2v_ctc_loss=1.111, task_loss=4.433, contrastive_loss=0.12, total=4129.3, n_correct=2396.71, ppl=3.23, accuracy=58.042, wps=14226.3, ups=1.15, wpb=12322.9, bsz=451.8, num_updates=9100, lr=0.00014825, gnorm=0.623, clip=0, loss_scale=16, train_wall=86, gb_free=17.4, wall=7654
2023-07-13 17:50:38 | INFO | train_inner | epoch 007:    362 / 1474 loss=3.681, trans_loss=3.537, nll_loss=1.701, w2v_ctc_loss=1.1, task_loss=4.218, contrastive_loss=0.378, total=4201.67, n_correct=2430.05, ppl=3.25, accuracy=57.835, wps=14303.3, ups=1.14, wpb=12533.1, bsz=479.7, num_updates=9200, lr=0.000147442, gnorm=0.62, clip=0, loss_scale=32, train_wall=87, gb_free=15.6, wall=7741
2023-07-13 17:52:04 | INFO | train_inner | epoch 007:    462 / 1474 loss=3.676, trans_loss=3.536, nll_loss=1.702, w2v_ctc_loss=1.106, task_loss=4.308, contrastive_loss=0.3, total=4155.31, n_correct=2401.19, ppl=3.25, accuracy=57.786, wps=14341.1, ups=1.16, wpb=12394.6, bsz=465.5, num_updates=9300, lr=0.000146647, gnorm=0.624, clip=0, loss_scale=32, train_wall=86, gb_free=16.9, wall=7828
2023-07-13 17:53:31 | INFO | train_inner | epoch 007:    562 / 1474 loss=3.657, trans_loss=3.537, nll_loss=1.7, w2v_ctc_loss=1.11, task_loss=4.284, contrastive_loss=0.128, total=4165.88, n_correct=2420.73, ppl=3.25, accuracy=58.108, wps=14241.8, ups=1.15, wpb=12401.8, bsz=459, num_updates=9400, lr=0.000145865, gnorm=0.621, clip=0, loss_scale=32, train_wall=87, gb_free=17.3, wall=7915
2023-07-13 17:55:00 | INFO | train_inner | epoch 007:    662 / 1474 loss=3.65, trans_loss=3.541, nll_loss=1.703, w2v_ctc_loss=1.094, task_loss=4.385, contrastive_loss=0.113, total=4149.29, n_correct=2412.72, ppl=3.26, accuracy=58.148, wps=14023.3, ups=1.13, wpb=12393.1, bsz=451.6, num_updates=9500, lr=0.000145095, gnorm=0.614, clip=0, loss_scale=32, train_wall=88, gb_free=17.2, wall=8003
2023-07-13 17:56:27 | INFO | train_inner | epoch 007:    762 / 1474 loss=3.66, trans_loss=3.538, nll_loss=1.701, w2v_ctc_loss=1.108, task_loss=4.539, contrastive_loss=0.115, total=4134.54, n_correct=2402.62, ppl=3.25, accuracy=58.111, wps=14125.4, ups=1.14, wpb=12358.8, bsz=449.8, num_updates=9600, lr=0.000144338, gnorm=0.624, clip=0, loss_scale=32, train_wall=87, gb_free=14.1, wall=8091
2023-07-13 17:57:55 | INFO | train_inner | epoch 007:    862 / 1474 loss=3.657, trans_loss=3.538, nll_loss=1.701, w2v_ctc_loss=1.1, task_loss=4.398, contrastive_loss=0.135, total=4151.77, n_correct=2413.92, ppl=3.25, accuracy=58.142, wps=14224.4, ups=1.15, wpb=12405.1, bsz=461.9, num_updates=9700, lr=0.000143592, gnorm=0.624, clip=0, loss_scale=32, train_wall=87, gb_free=15.1, wall=8178
2023-07-13 17:59:22 | INFO | train_inner | epoch 007:    962 / 1474 loss=3.665, trans_loss=3.537, nll_loss=1.702, w2v_ctc_loss=1.095, task_loss=4.2, contrastive_loss=0.229, total=4124.8, n_correct=2402.28, ppl=3.25, accuracy=58.24, wps=14122.8, ups=1.15, wpb=12316.5, bsz=471.2, num_updates=9800, lr=0.000142857, gnorm=0.633, clip=0, loss_scale=32, train_wall=87, gb_free=16.8, wall=8265
2023-07-13 18:00:49 | INFO | train_inner | epoch 007:   1062 / 1474 loss=3.66, trans_loss=3.546, nll_loss=1.711, w2v_ctc_loss=1.105, task_loss=4.592, contrastive_loss=0.097, total=4113.08, n_correct=2386.36, ppl=3.27, accuracy=58.019, wps=14148.2, ups=1.15, wpb=12291.6, bsz=439.4, num_updates=9900, lr=0.000142134, gnorm=0.62, clip=0, loss_scale=32, train_wall=86, gb_free=15, wall=8352
2023-07-13 18:01:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-13 18:02:17 | INFO | train_inner | epoch 007:   1163 / 1474 loss=3.662, trans_loss=3.534, nll_loss=1.702, w2v_ctc_loss=1.102, task_loss=4.36, contrastive_loss=0.206, total=4113.08, n_correct=2390.3, ppl=3.25, accuracy=58.115, wps=13871.4, ups=1.13, wpb=12284.5, bsz=459.5, num_updates=10000, lr=0.000141421, gnorm=0.627, clip=0, loss_scale=16, train_wall=88, gb_free=16.2, wall=8441
2023-07-13 18:02:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 18:02:44 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.311 | trans_loss 5.733 | nll_loss 3.052 | w2v_ctc_loss 1.33 | task_loss 22.923 | contrastive_loss 0.272 | total 4003.4 | n_correct 2373.7 | ppl 8.3 | accuracy 59.292 | uer 19.122 | wer 21.017 | raw_wer 21.017 | bleu 17.43 | wps 2021.3 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 17.43
2023-07-13 18:02:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-07-13 18:02:44 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_7_10000.pt
2023-07-13 18:02:47 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_7_10000.pt
2023-07-13 18:02:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 17.43) (writing took 13.801767309079878 seconds)
asr_weight tensor(0.6121, device='cuda:0')
mt_weight tensor(0.5129, device='cuda:0')
2023-07-13 18:04:25 | INFO | train_inner | epoch 007:   1263 / 1474 loss=3.642, trans_loss=3.532, nll_loss=1.697, w2v_ctc_loss=1.088, task_loss=4.433, contrastive_loss=0.124, total=4129.52, n_correct=2404.79, ppl=3.24, accuracy=58.234, wps=9678.3, ups=0.78, wpb=12329.2, bsz=450.2, num_updates=10100, lr=0.00014072, gnorm=0.481, clip=0, loss_scale=16, train_wall=86, gb_free=17, wall=8568
2023-07-13 18:05:51 | INFO | train_inner | epoch 007:   1363 / 1474 loss=3.651, trans_loss=3.528, nll_loss=1.692, w2v_ctc_loss=1.099, task_loss=4.109, contrastive_loss=0.162, total=4172.87, n_correct=2445.7, ppl=3.23, accuracy=58.61, wps=14368.8, ups=1.15, wpb=12453.5, bsz=476.2, num_updates=10200, lr=0.000140028, gnorm=0.485, clip=0, loss_scale=16, train_wall=86, gb_free=17.3, wall=8655
2023-07-13 18:07:20 | INFO | train_inner | epoch 007:   1463 / 1474 loss=3.67, trans_loss=3.54, nll_loss=1.708, w2v_ctc_loss=1.1, task_loss=4.734, contrastive_loss=0.226, total=4109.42, n_correct=2387.41, ppl=3.27, accuracy=58.096, wps=13841.9, ups=1.13, wpb=12285.7, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.494, clip=0, loss_scale=16, train_wall=88, gb_free=16.6, wall=8744
2023-07-13 18:07:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
asr_weight tensor(0.6121, device='cuda:2')
mt_weight tensor(0.5129, device='cuda:2')
asr_weight tensor(0.6121, device='cuda:6')
mt_weight tensor(0.5129, device='cuda:6')
asr_weight tensor(0.6121, device='cuda:4')
mt_weight tensor(0.5129, device='cuda:4')
asr_weight tensor(0.6121, device='cuda:5')
mt_weight tensor(0.5129, device='cuda:5')
asr_weight tensor(0.6121, device='cuda:3')
mt_weight tensor(0.5129, device='cuda:3')
asr_weight tensor(0.6121, device='cuda:7')
mt_weight tensor(0.5129, device='cuda:7')
asr_weight tensor(0.6121, device='cuda:1')
mt_weight tensor(0.5129, device='cuda:1')
2023-07-13 18:07:57 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.309 | trans_loss 5.722 | nll_loss 3.037 | w2v_ctc_loss 1.35 | task_loss 22.983 | contrastive_loss 0.269 | total 4003.4 | n_correct 2373.5 | ppl 8.21 | accuracy 59.287 | uer 18.953 | wer 20.771 | raw_wer 20.771 | bleu 17.45 | wps 1893.4 | wpb 4003.4 | bsz 141.8 | num_updates 10311 | best_bleu 17.45
2023-07-13 18:07:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10311 updates
2023-07-13 18:07:57 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 18:08:01 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 18:08:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt (epoch 7 @ 10311 updates, score 17.45) (writing took 8.227286907029338 seconds)
2023-07-13 18:08:06 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-07-13 18:08:06 | INFO | train | epoch 007 | loss 3.66 | trans_loss 3.536 | nll_loss 1.7 | w2v_ctc_loss 1.102 | task_loss 4.388 | contrastive_loss 0.181 | total 4137.25 | n_correct 2403.7 | ppl 3.25 | accuracy 58.099 | wps 13268.8 | ups 1.07 | wpb 12352.3 | bsz 457.8 | num_updates 10311 | lr 0.000139272 | gnorm 0.595 | clip 0 | loss_scale 16 | train_wall 1279 | gb_free 13.5 | wall 8789
2023-07-13 18:08:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 18:08:06 | INFO | fairseq.trainer | begin training epoch 8
2023-07-13 18:08:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 18:09:32 | INFO | train_inner | epoch 008:     89 / 1474 loss=3.599, trans_loss=3.511, nll_loss=1.664, w2v_ctc_loss=1.054, task_loss=4.631, contrastive_loss=0.12, total=4116.25, n_correct=2426.88, ppl=3.17, accuracy=58.959, wps=9322.7, ups=0.76, wpb=12265.9, bsz=443.3, num_updates=10400, lr=0.000138675, gnorm=0.483, clip=0, loss_scale=16, train_wall=86, gb_free=17.1, wall=8875
2023-07-13 18:10:58 | INFO | train_inner | epoch 008:    189 / 1474 loss=3.61, trans_loss=3.514, nll_loss=1.67, w2v_ctc_loss=1.058, task_loss=4.759, contrastive_loss=0.141, total=4037.23, n_correct=2379.46, ppl=3.18, accuracy=58.938, wps=13857.4, ups=1.15, wpb=12033.3, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.49, clip=0, loss_scale=16, train_wall=86, gb_free=13.1, wall=8962
2023-07-13 18:12:25 | INFO | train_inner | epoch 008:    289 / 1474 loss=3.584, trans_loss=3.502, nll_loss=1.654, w2v_ctc_loss=1.038, task_loss=4.12, contrastive_loss=0.137, total=4207.78, n_correct=2498.28, ppl=3.15, accuracy=59.373, wps=14481.7, ups=1.15, wpb=12570.1, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.477, clip=0, loss_scale=16, train_wall=86, gb_free=13.3, wall=9049
2023-07-13 18:13:53 | INFO | train_inner | epoch 008:    389 / 1474 loss=3.616, trans_loss=3.511, nll_loss=1.666, w2v_ctc_loss=1.066, task_loss=4.676, contrastive_loss=0.16, total=4127.24, n_correct=2432.18, ppl=3.17, accuracy=58.93, wps=13984.8, ups=1.14, wpb=12318.5, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=0.48, clip=0, loss_scale=16, train_wall=88, gb_free=12.1, wall=9137
2023-07-13 18:15:21 | INFO | train_inner | epoch 008:    489 / 1474 loss=3.643, trans_loss=3.511, nll_loss=1.668, w2v_ctc_loss=1.048, task_loss=3.93, contrastive_loss=0.425, total=4203.76, n_correct=2481.06, ppl=3.18, accuracy=59.02, wps=14330.3, ups=1.14, wpb=12567.7, bsz=504.5, num_updates=10800, lr=0.000136083, gnorm=0.498, clip=0, loss_scale=16, train_wall=87, gb_free=14.7, wall=9225
2023-07-13 18:16:48 | INFO | train_inner | epoch 008:    589 / 1474 loss=3.603, trans_loss=3.51, nll_loss=1.667, w2v_ctc_loss=1.06, task_loss=4.783, contrastive_loss=0.095, total=4062.5, n_correct=2393.13, ppl=3.18, accuracy=58.908, wps=14018.6, ups=1.15, wpb=12171.9, bsz=427.9, num_updates=10900, lr=0.000135457, gnorm=0.481, clip=0, loss_scale=16, train_wall=86, gb_free=11.7, wall=9311
2023-07-13 18:18:15 | INFO | train_inner | epoch 008:    689 / 1474 loss=3.602, trans_loss=3.507, nll_loss=1.664, w2v_ctc_loss=1.066, task_loss=4.515, contrastive_loss=0.106, total=4142.78, n_correct=2456.57, ppl=3.17, accuracy=59.298, wps=14184.8, ups=1.15, wpb=12347.9, bsz=448.6, num_updates=11000, lr=0.00013484, gnorm=0.481, clip=0, loss_scale=16, train_wall=87, gb_free=16, wall=9398
2023-07-13 18:19:42 | INFO | train_inner | epoch 008:    789 / 1474 loss=3.605, trans_loss=3.504, nll_loss=1.661, w2v_ctc_loss=1.051, task_loss=4.493, contrastive_loss=0.193, total=4118.9, n_correct=2439.63, ppl=3.16, accuracy=59.23, wps=14188.2, ups=1.15, wpb=12327.8, bsz=447.8, num_updates=11100, lr=0.000134231, gnorm=0.484, clip=0, loss_scale=16, train_wall=86, gb_free=15.3, wall=9485
2023-07-13 18:21:09 | INFO | train_inner | epoch 008:    889 / 1474 loss=3.601, trans_loss=3.506, nll_loss=1.664, w2v_ctc_loss=1.042, task_loss=4.204, contrastive_loss=0.202, total=4169.01, n_correct=2472.64, ppl=3.17, accuracy=59.31, wps=14306.5, ups=1.15, wpb=12455.3, bsz=473.7, num_updates=11200, lr=0.000133631, gnorm=0.483, clip=0, loss_scale=16, train_wall=87, gb_free=16.3, wall=9572
2023-07-13 18:22:35 | INFO | train_inner | epoch 008:    989 / 1474 loss=3.577, trans_loss=3.501, nll_loss=1.657, w2v_ctc_loss=1.035, task_loss=4.191, contrastive_loss=0.103, total=4154.69, n_correct=2469.79, ppl=3.15, accuracy=59.446, wps=14404.9, ups=1.16, wpb=12398.4, bsz=464.9, num_updates=11300, lr=0.000133038, gnorm=0.478, clip=0, loss_scale=16, train_wall=86, gb_free=17.8, wall=9658
2023-07-13 18:24:03 | INFO | train_inner | epoch 008:   1089 / 1474 loss=3.616, trans_loss=3.509, nll_loss=1.667, w2v_ctc_loss=1.045, task_loss=4.367, contrastive_loss=0.327, total=4199.1, n_correct=2478.57, ppl=3.18, accuracy=59.026, wps=14259.9, ups=1.14, wpb=12520.7, bsz=465.3, num_updates=11400, lr=0.000132453, gnorm=0.479, clip=0, loss_scale=16, train_wall=87, gb_free=13, wall=9746
2023-07-13 18:25:30 | INFO | train_inner | epoch 008:   1189 / 1474 loss=3.592, trans_loss=3.507, nll_loss=1.666, w2v_ctc_loss=1.046, task_loss=4.135, contrastive_loss=0.113, total=4177.31, n_correct=2480.47, ppl=3.17, accuracy=59.38, wps=14372.7, ups=1.15, wpb=12476.4, bsz=472.6, num_updates=11500, lr=0.000131876, gnorm=0.479, clip=0, loss_scale=16, train_wall=86, gb_free=15.1, wall=9833
2023-07-13 18:26:56 | INFO | train_inner | epoch 008:   1289 / 1474 loss=3.604, trans_loss=3.509, nll_loss=1.669, w2v_ctc_loss=1.057, task_loss=4.58, contrastive_loss=0.134, total=4063.85, n_correct=2398.95, ppl=3.18, accuracy=59.031, wps=14033.5, ups=1.16, wpb=12141.2, bsz=438.4, num_updates=11600, lr=0.000131306, gnorm=0.487, clip=0, loss_scale=16, train_wall=86, gb_free=16.9, wall=9920
2023-07-13 18:28:23 | INFO | train_inner | epoch 008:   1389 / 1474 loss=3.608, trans_loss=3.509, nll_loss=1.671, w2v_ctc_loss=1.051, task_loss=4.327, contrastive_loss=0.188, total=4141.5, n_correct=2452.53, ppl=3.18, accuracy=59.218, wps=14292.3, ups=1.16, wpb=12351.9, bsz=461.5, num_updates=11700, lr=0.000130744, gnorm=0.483, clip=0, loss_scale=16, train_wall=86, gb_free=16.7, wall=10006
2023-07-13 18:29:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 18:30:05 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.286 | trans_loss 5.688 | nll_loss 2.99 | w2v_ctc_loss 1.349 | task_loss 22.958 | contrastive_loss 0.267 | total 4003.4 | n_correct 2400.3 | ppl 7.94 | accuracy 59.957 | uer 18.432 | wer 20.107 | raw_wer 20.107 | bleu 18.27 | wps 1837.8 | wpb 4003.4 | bsz 141.8 | num_updates 11785 | best_bleu 18.27
2023-07-13 18:30:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11785 updates
2023-07-13 18:30:05 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 18:30:09 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 18:30:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt (epoch 8 @ 11785 updates, score 18.27) (writing took 8.24972390907351 seconds)
2023-07-13 18:30:13 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-07-13 18:30:13 | INFO | train | epoch 008 | loss 3.604 | trans_loss 3.508 | nll_loss 1.665 | w2v_ctc_loss 1.05 | task_loss 4.386 | contrastive_loss 0.182 | total 4138.65 | n_correct 2448.74 | ppl 3.17 | accuracy 59.168 | wps 13718.7 | ups 1.11 | wpb 12355.8 | bsz 458.5 | num_updates 11785 | lr 0.000130272 | gnorm 0.483 | clip 0 | loss_scale 16 | train_wall 1276 | gb_free 17.1 | wall 10117
2023-07-13 18:30:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 18:30:14 | INFO | fairseq.trainer | begin training epoch 9
2023-07-13 18:30:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 18:30:35 | INFO | train_inner | epoch 009:     15 / 1474 loss=3.601, trans_loss=3.504, nll_loss=1.662, w2v_ctc_loss=1.029, task_loss=4.225, contrastive_loss=0.316, total=4139.35, n_correct=2464.23, ppl=3.16, accuracy=59.532, wps=9314.1, ups=0.76, wpb=12332.8, bsz=472.9, num_updates=11800, lr=0.000130189, gnorm=0.483, clip=0, loss_scale=16, train_wall=87, gb_free=16.4, wall=10138
2023-07-13 18:32:02 | INFO | train_inner | epoch 009:    115 / 1474 loss=3.533, trans_loss=3.475, nll_loss=1.622, w2v_ctc_loss=0.993, task_loss=4.152, contrastive_loss=0.13, total=4181.9, n_correct=2523.08, ppl=3.08, accuracy=60.333, wps=14337.2, ups=1.15, wpb=12493.2, bsz=475.9, num_updates=11900, lr=0.000129641, gnorm=0.471, clip=0, loss_scale=16, train_wall=87, gb_free=16.4, wall=10226
2023-07-13 18:33:29 | INFO | train_inner | epoch 009:    215 / 1474 loss=3.543, trans_loss=3.485, nll_loss=1.635, w2v_ctc_loss=1.004, task_loss=4.734, contrastive_loss=0.091, total=4062.07, n_correct=2440.42, ppl=3.11, accuracy=60.078, wps=13908.8, ups=1.15, wpb=12136.5, bsz=431.6, num_updates=12000, lr=0.000129099, gnorm=0.478, clip=0, loss_scale=16, train_wall=87, gb_free=15.8, wall=10313
2023-07-13 18:33:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 18:33:57 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.273 | trans_loss 5.697 | nll_loss 3.003 | w2v_ctc_loss 1.287 | task_loss 22.796 | contrastive_loss 0.273 | total 4003.4 | n_correct 2395.2 | ppl 8.01 | accuracy 59.829 | uer 18.48 | wer 20.316 | raw_wer 20.316 | bleu 17.94 | wps 1963.7 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 18.27
2023-07-13 18:33:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-07-13 18:33:57 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_9_12000.pt
2023-07-13 18:33:59 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_9_12000.pt
2023-07-13 18:34:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 17.94) (writing took 6.147062115021981 seconds)
2023-07-13 18:35:30 | INFO | train_inner | epoch 009:    315 / 1474 loss=3.53, trans_loss=3.472, nll_loss=1.62, w2v_ctc_loss=0.987, task_loss=4.092, contrastive_loss=0.138, total=4152.1, n_correct=2513.14, ppl=3.07, accuracy=60.527, wps=10316.2, ups=0.83, wpb=12422.8, bsz=476.6, num_updates=12100, lr=0.000128565, gnorm=0.472, clip=0, loss_scale=32, train_wall=86, gb_free=16.5, wall=10433
2023-07-13 18:36:58 | INFO | train_inner | epoch 009:    415 / 1474 loss=3.541, trans_loss=3.481, nll_loss=1.632, w2v_ctc_loss=1.002, task_loss=4.29, contrastive_loss=0.108, total=4203.78, n_correct=2524.48, ppl=3.1, accuracy=60.053, wps=14230.7, ups=1.13, wpb=12545.5, bsz=469.8, num_updates=12200, lr=0.000128037, gnorm=0.474, clip=0, loss_scale=32, train_wall=88, gb_free=17.2, wall=10521
2023-07-13 18:38:25 | INFO | train_inner | epoch 009:    515 / 1474 loss=3.574, trans_loss=3.491, nll_loss=1.644, w2v_ctc_loss=1.028, task_loss=4.603, contrastive_loss=0.158, total=4112.78, n_correct=2459.14, ppl=3.13, accuracy=59.793, wps=14111.5, ups=1.15, wpb=12260.1, bsz=437.7, num_updates=12300, lr=0.000127515, gnorm=0.485, clip=0, loss_scale=32, train_wall=86, gb_free=16.3, wall=10608
2023-07-13 18:39:53 | INFO | train_inner | epoch 009:    615 / 1474 loss=3.543, trans_loss=3.481, nll_loss=1.633, w2v_ctc_loss=1, task_loss=4.466, contrastive_loss=0.118, total=4131.32, n_correct=2484.3, ppl=3.1, accuracy=60.133, wps=14032.2, ups=1.14, wpb=12355.3, bsz=455, num_updates=12400, lr=0.000127, gnorm=0.478, clip=0, loss_scale=32, train_wall=88, gb_free=17.9, wall=10696
2023-07-13 18:41:20 | INFO | train_inner | epoch 009:    715 / 1474 loss=3.572, trans_loss=3.489, nll_loss=1.642, w2v_ctc_loss=1.019, task_loss=4.492, contrastive_loss=0.2, total=4082.11, n_correct=2443.61, ppl=3.12, accuracy=59.861, wps=14043.5, ups=1.15, wpb=12206.9, bsz=449.7, num_updates=12500, lr=0.000126491, gnorm=0.483, clip=0, loss_scale=32, train_wall=86, gb_free=17.1, wall=10783
2023-07-13 18:42:48 | INFO | train_inner | epoch 009:    815 / 1474 loss=3.58, trans_loss=3.476, nll_loss=1.63, w2v_ctc_loss=1.013, task_loss=3.949, contrastive_loss=0.341, total=4221.08, n_correct=2533.69, ppl=3.1, accuracy=60.025, wps=14333.6, ups=1.14, wpb=12600.2, bsz=501.6, num_updates=12600, lr=0.000125988, gnorm=0.481, clip=0, loss_scale=32, train_wall=87, gb_free=17.7, wall=10871
2023-07-13 18:44:16 | INFO | train_inner | epoch 009:    915 / 1474 loss=3.576, trans_loss=3.489, nll_loss=1.642, w2v_ctc_loss=1.009, task_loss=4.548, contrastive_loss=0.324, total=4142.34, n_correct=2484.76, ppl=3.12, accuracy=59.984, wps=14007.8, ups=1.13, wpb=12345.3, bsz=448.9, num_updates=12700, lr=0.000125491, gnorm=0.476, clip=0, loss_scale=32, train_wall=88, gb_free=17.4, wall=10959
2023-07-13 18:45:43 | INFO | train_inner | epoch 009:   1015 / 1474 loss=3.564, trans_loss=3.497, nll_loss=1.65, w2v_ctc_loss=1.016, task_loss=4.925, contrastive_loss=0.104, total=4097.15, n_correct=2445.61, ppl=3.14, accuracy=59.691, wps=14039.4, ups=1.15, wpb=12230.8, bsz=422.6, num_updates=12800, lr=0.000125, gnorm=0.478, clip=0, loss_scale=32, train_wall=87, gb_free=16.9, wall=11046
2023-07-13 18:47:10 | INFO | train_inner | epoch 009:   1115 / 1474 loss=3.551, trans_loss=3.485, nll_loss=1.635, w2v_ctc_loss=1.009, task_loss=4.09, contrastive_loss=0.128, total=4182.29, n_correct=2519.56, ppl=3.11, accuracy=60.244, wps=14260.8, ups=1.15, wpb=12446.8, bsz=477.6, num_updates=12900, lr=0.000124515, gnorm=0.477, clip=0, loss_scale=32, train_wall=87, gb_free=17.3, wall=11134
2023-07-13 18:48:38 | INFO | train_inner | epoch 009:   1215 / 1474 loss=3.566, trans_loss=3.495, nll_loss=1.645, w2v_ctc_loss=1.017, task_loss=4.657, contrastive_loss=0.111, total=4141.43, n_correct=2480, ppl=3.13, accuracy=59.883, wps=14066.1, ups=1.13, wpb=12406.5, bsz=446.6, num_updates=13000, lr=0.000124035, gnorm=0.481, clip=0, loss_scale=32, train_wall=88, gb_free=17.6, wall=11222
2023-07-13 18:50:05 | INFO | train_inner | epoch 009:   1315 / 1474 loss=3.561, trans_loss=3.482, nll_loss=1.634, w2v_ctc_loss=0.991, task_loss=3.993, contrastive_loss=0.308, total=4203.91, n_correct=2536.75, ppl=3.1, accuracy=60.343, wps=14424.6, ups=1.15, wpb=12540.7, bsz=492.3, num_updates=13100, lr=0.00012356, gnorm=0.481, clip=0, loss_scale=32, train_wall=87, gb_free=17.4, wall=11309
2023-07-13 18:51:32 | INFO | train_inner | epoch 009:   1415 / 1474 loss=3.563, trans_loss=3.497, nll_loss=1.651, w2v_ctc_loss=1.019, task_loss=4.749, contrastive_loss=0.089, total=4077.08, n_correct=2437.62, ppl=3.14, accuracy=59.788, wps=14049.4, ups=1.15, wpb=12171.4, bsz=429.1, num_updates=13200, lr=0.000123091, gnorm=0.484, clip=0, loss_scale=32, train_wall=86, gb_free=17.4, wall=11396
2023-07-13 18:52:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 18:52:49 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.256 | trans_loss 5.669 | nll_loss 2.969 | w2v_ctc_loss 1.298 | task_loss 22.951 | contrastive_loss 0.265 | total 4003.4 | n_correct 2411.9 | ppl 7.83 | accuracy 60.246 | uer 17.973 | wer 19.727 | raw_wer 19.727 | bleu 18.3 | wps 2030.8 | wpb 4003.4 | bsz 141.8 | num_updates 13259 | best_bleu 18.3
2023-07-13 18:52:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13259 updates
2023-07-13 18:52:49 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 18:52:53 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 18:52:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt (epoch 9 @ 13259 updates, score 18.3) (writing took 8.188101820996962 seconds)
2023-07-13 18:52:58 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-07-13 18:52:58 | INFO | train | epoch 009 | loss 3.557 | trans_loss 3.485 | nll_loss 1.637 | w2v_ctc_loss 1.008 | task_loss 4.387 | contrastive_loss 0.174 | total 4138.65 | n_correct 2485.96 | ppl 3.11 | accuracy 60.067 | wps 13346.1 | ups 1.08 | wpb 12355.8 | bsz 458.5 | num_updates 13259 | lr 0.000122817 | gnorm 0.479 | clip 0 | loss_scale 32 | train_wall 1281 | gb_free 12 | wall 11481
2023-07-13 18:52:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 18:52:58 | INFO | fairseq.trainer | begin training epoch 10
2023-07-13 18:52:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 18:53:42 | INFO | train_inner | epoch 010:     41 / 1474 loss=3.539, trans_loss=3.477, nll_loss=1.625, w2v_ctc_loss=0.989, task_loss=4.182, contrastive_loss=0.186, total=4100.86, n_correct=2484.43, ppl=3.09, accuracy=60.583, wps=9440.3, ups=0.77, wpb=12244.8, bsz=470.2, num_updates=13300, lr=0.000122628, gnorm=0.48, clip=0, loss_scale=32, train_wall=86, gb_free=16.7, wall=11525
2023-07-13 18:55:09 | INFO | train_inner | epoch 010:    141 / 1474 loss=3.495, trans_loss=3.46, nll_loss=1.6, w2v_ctc_loss=0.956, task_loss=4.136, contrastive_loss=0.107, total=4240.18, n_correct=2590.85, ppl=3.03, accuracy=61.102, wps=14629.4, ups=1.15, wpb=12698.4, bsz=479.1, num_updates=13400, lr=0.000122169, gnorm=0.463, clip=0, loss_scale=32, train_wall=86, gb_free=15.1, wall=11612
2023-07-13 18:56:35 | INFO | train_inner | epoch 010:    241 / 1474 loss=3.512, trans_loss=3.456, nll_loss=1.599, w2v_ctc_loss=0.968, task_loss=4.338, contrastive_loss=0.231, total=4126.3, n_correct=2522.55, ppl=3.03, accuracy=61.133, wps=14187.3, ups=1.15, wpb=12290.2, bsz=460.9, num_updates=13500, lr=0.000121716, gnorm=0.48, clip=0, loss_scale=32, train_wall=86, gb_free=15.7, wall=11699
2023-07-13 18:58:03 | INFO | train_inner | epoch 010:    341 / 1474 loss=3.503, trans_loss=3.456, nll_loss=1.602, w2v_ctc_loss=0.965, task_loss=4.465, contrastive_loss=0.142, total=4132.25, n_correct=2517.4, ppl=3.03, accuracy=60.921, wps=14099.7, ups=1.14, wpb=12358.2, bsz=452.8, num_updates=13600, lr=0.000121268, gnorm=0.47, clip=0, loss_scale=32, train_wall=87, gb_free=14.9, wall=11786
2023-07-13 18:59:32 | INFO | train_inner | epoch 010:    441 / 1474 loss=3.513, trans_loss=3.46, nll_loss=1.605, w2v_ctc_loss=0.951, task_loss=4.207, contrastive_loss=0.316, total=4203.14, n_correct=2558.27, ppl=3.04, accuracy=60.866, wps=14137.7, ups=1.13, wpb=12542, bsz=481.7, num_updates=13700, lr=0.000120824, gnorm=0.468, clip=0, loss_scale=32, train_wall=88, gb_free=16.5, wall=11875
2023-07-13 19:00:59 | INFO | train_inner | epoch 010:    541 / 1474 loss=3.525, trans_loss=3.471, nll_loss=1.616, w2v_ctc_loss=0.99, task_loss=4.685, contrastive_loss=0.098, total=4106.5, n_correct=2494.41, ppl=3.06, accuracy=60.743, wps=14056.3, ups=1.15, wpb=12236.6, bsz=440, num_updates=13800, lr=0.000120386, gnorm=0.481, clip=0, loss_scale=32, train_wall=87, gb_free=16.6, wall=11962
2023-07-13 19:02:26 | INFO | train_inner | epoch 010:    641 / 1474 loss=3.532, trans_loss=3.468, nll_loss=1.615, w2v_ctc_loss=0.98, task_loss=4.181, contrastive_loss=0.213, total=4170.61, n_correct=2535.66, ppl=3.06, accuracy=60.798, wps=14246.6, ups=1.14, wpb=12452.8, bsz=476.1, num_updates=13900, lr=0.000119952, gnorm=0.476, clip=0, loss_scale=32, train_wall=87, gb_free=11.3, wall=12049
2023-07-13 19:03:53 | INFO | train_inner | epoch 010:    741 / 1474 loss=3.524, trans_loss=3.47, nll_loss=1.617, w2v_ctc_loss=0.993, task_loss=4.417, contrastive_loss=0.097, total=4123.31, n_correct=2501.75, ppl=3.07, accuracy=60.673, wps=14227.7, ups=1.16, wpb=12306.3, bsz=453, num_updates=14000, lr=0.000119523, gnorm=0.487, clip=0, loss_scale=32, train_wall=86, gb_free=17.2, wall=12136
2023-07-13 19:03:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 19:04:20 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.269 | trans_loss 5.667 | nll_loss 2.961 | w2v_ctc_loss 1.345 | task_loss 23.036 | contrastive_loss 0.268 | total 4003.4 | n_correct 2416.6 | ppl 7.79 | accuracy 60.364 | uer 18.093 | wer 19.846 | raw_wer 19.846 | bleu 18.93 | wps 1979.3 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 18.93
2023-07-13 19:04:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-07-13 19:04:20 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_10_14000.pt
2023-07-13 19:04:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_10_14000.pt
2023-07-13 19:04:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 18.93) (writing took 9.209749825997278 seconds)
2023-07-13 19:05:57 | INFO | train_inner | epoch 010:    841 / 1474 loss=3.508, trans_loss=3.467, nll_loss=1.613, w2v_ctc_loss=0.968, task_loss=4.331, contrastive_loss=0.098, total=4125.69, n_correct=2509.47, ppl=3.06, accuracy=60.825, wps=9925.8, ups=0.8, wpb=12339.2, bsz=456.1, num_updates=14100, lr=0.000119098, gnorm=0.476, clip=0, loss_scale=64, train_wall=87, gb_free=15.9, wall=12260
2023-07-13 19:06:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-13 19:07:25 | INFO | train_inner | epoch 010:    942 / 1474 loss=3.513, trans_loss=3.464, nll_loss=1.611, w2v_ctc_loss=0.983, task_loss=4.256, contrastive_loss=0.105, total=4154.5, n_correct=2531.09, ppl=3.05, accuracy=60.924, wps=14024.6, ups=1.13, wpb=12362.4, bsz=463.5, num_updates=14200, lr=0.000118678, gnorm=0.478, clip=0, loss_scale=32, train_wall=88, gb_free=15.6, wall=12348
2023-07-13 19:08:53 | INFO | train_inner | epoch 010:   1042 / 1474 loss=3.52, trans_loss=3.47, nll_loss=1.619, w2v_ctc_loss=0.983, task_loss=4.761, contrastive_loss=0.111, total=4067.53, n_correct=2463.41, ppl=3.07, accuracy=60.563, wps=13872.8, ups=1.14, wpb=12142, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.483, clip=0, loss_scale=32, train_wall=87, gb_free=17, wall=12436
2023-07-13 19:10:19 | INFO | train_inner | epoch 010:   1142 / 1474 loss=3.522, trans_loss=3.473, nll_loss=1.621, w2v_ctc_loss=0.987, task_loss=4.89, contrastive_loss=0.091, total=4044.03, n_correct=2449.08, ppl=3.08, accuracy=60.56, wps=13968.1, ups=1.16, wpb=12072.9, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.482, clip=0, loss_scale=32, train_wall=86, gb_free=17.4, wall=12522
2023-07-13 19:11:46 | INFO | train_inner | epoch 010:   1242 / 1474 loss=3.513, trans_loss=3.466, nll_loss=1.616, w2v_ctc_loss=0.983, task_loss=4.489, contrastive_loss=0.086, total=4110.41, n_correct=2494.63, ppl=3.07, accuracy=60.691, wps=14175.7, ups=1.15, wpb=12302.3, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.48, clip=0, loss_scale=32, train_wall=86, gb_free=16.6, wall=12609
2023-07-13 19:13:13 | INFO | train_inner | epoch 010:   1342 / 1474 loss=3.511, trans_loss=3.466, nll_loss=1.613, w2v_ctc_loss=0.976, task_loss=4.49, contrastive_loss=0.099, total=4121.38, n_correct=2506.89, ppl=3.06, accuracy=60.826, wps=14072.4, ups=1.14, wpb=12315.5, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.48, clip=0, loss_scale=32, train_wall=87, gb_free=14.3, wall=12697
2023-07-13 19:14:42 | INFO | train_inner | epoch 010:   1442 / 1474 loss=3.544, trans_loss=3.471, nll_loss=1.622, w2v_ctc_loss=0.962, task_loss=4.144, contrastive_loss=0.352, total=4192.39, n_correct=2543.92, ppl=3.08, accuracy=60.679, wps=14139.3, ups=1.13, wpb=12477.9, bsz=482, num_updates=14700, lr=0.000116642, gnorm=0.479, clip=0, loss_scale=32, train_wall=88, gb_free=17.2, wall=12785
2023-07-13 19:15:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 19:15:36 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.245 | trans_loss 5.65 | nll_loss 2.942 | w2v_ctc_loss 1.305 | task_loss 22.987 | contrastive_loss 0.262 | total 4003.4 | n_correct 2425.9 | ppl 7.69 | accuracy 60.596 | uer 17.745 | wer 19.72 | raw_wer 19.72 | bleu 19.2 | wps 2020.3 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 19.2
2023-07-13 19:15:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-07-13 19:15:36 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 19:15:40 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 19:15:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt (epoch 10 @ 14732 updates, score 19.2) (writing took 8.471524841967039 seconds)
2023-07-13 19:15:44 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-07-13 19:15:44 | INFO | train | epoch 010 | loss 3.517 | trans_loss 3.466 | nll_loss 1.612 | w2v_ctc_loss 0.974 | task_loss 4.394 | contrastive_loss 0.164 | total 4137.84 | n_correct 2516.52 | ppl 3.06 | accuracy 60.817 | wps 13316.4 | ups 1.08 | wpb 12353.7 | bsz 458.1 | num_updates 14732 | lr 0.000116516 | gnorm 0.477 | clip 0 | loss_scale 32 | train_wall 1280 | gb_free 17.4 | wall 12848
2023-07-13 19:15:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 19:15:45 | INFO | fairseq.trainer | begin training epoch 11
2023-07-13 19:15:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 19:16:51 | INFO | train_inner | epoch 011:     68 / 1474 loss=3.48, trans_loss=3.447, nll_loss=1.588, w2v_ctc_loss=0.942, task_loss=4.063, contrastive_loss=0.174, total=4175.24, n_correct=2574.24, ppl=3.01, accuracy=61.655, wps=9628.8, ups=0.77, wpb=12460.8, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.468, clip=0, loss_scale=32, train_wall=86, gb_free=16.9, wall=12914
2023-07-13 19:18:19 | INFO | train_inner | epoch 011:    168 / 1474 loss=3.47, trans_loss=3.446, nll_loss=1.588, w2v_ctc_loss=0.943, task_loss=4.538, contrastive_loss=0.094, total=4087.78, n_correct=2512.46, ppl=3.01, accuracy=61.463, wps=13953.6, ups=1.14, wpb=12225.8, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.476, clip=0, loss_scale=32, train_wall=87, gb_free=16.7, wall=13002
2023-07-13 19:19:46 | INFO | train_inner | epoch 011:    268 / 1474 loss=3.467, trans_loss=3.445, nll_loss=1.588, w2v_ctc_loss=0.94, task_loss=4.516, contrastive_loss=0.091, total=4118.77, n_correct=2529.63, ppl=3.01, accuracy=61.417, wps=14123.7, ups=1.15, wpb=12285.5, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.478, clip=0, loss_scale=32, train_wall=87, gb_free=12.7, wall=13089
asr_weight tensor(0.2620, device='cuda:0')
mt_weight tensor(0.1595, device='cuda:0')
2023-07-13 19:21:12 | INFO | train_inner | epoch 011:    368 / 1474 loss=3.463, trans_loss=3.443, nll_loss=1.582, w2v_ctc_loss=0.934, task_loss=4.503, contrastive_loss=0.094, total=4097.83, n_correct=2527.19, ppl=2.99, accuracy=61.671, wps=14180.3, ups=1.16, wpb=12202.1, bsz=444.2, num_updates=15100, lr=0.000115087, gnorm=0.36, clip=0, loss_scale=32, train_wall=86, gb_free=16.4, wall=13175
2023-07-13 19:22:39 | INFO | train_inner | epoch 011:    468 / 1474 loss=3.504, trans_loss=3.458, nll_loss=1.599, w2v_ctc_loss=0.942, task_loss=4.606, contrastive_loss=0.253, total=4110.64, n_correct=2518.19, ppl=3.03, accuracy=61.26, wps=13963.8, ups=1.14, wpb=12265.6, bsz=450.5, num_updates=15200, lr=0.000114708, gnorm=0.357, clip=0, loss_scale=32, train_wall=87, gb_free=16.5, wall=13263
2023-07-13 19:24:07 | INFO | train_inner | epoch 011:    568 / 1474 loss=3.509, trans_loss=3.454, nll_loss=1.6, w2v_ctc_loss=0.956, task_loss=4.711, contrastive_loss=0.25, total=4071.69, n_correct=2495.48, ppl=3.03, accuracy=61.289, wps=13839, ups=1.14, wpb=12176.5, bsz=440.6, num_updates=15300, lr=0.000114332, gnorm=0.361, clip=0, loss_scale=32, train_wall=88, gb_free=16.5, wall=13351
2023-07-13 19:25:35 | INFO | train_inner | epoch 011:    668 / 1474 loss=3.509, trans_loss=3.451, nll_loss=1.592, w2v_ctc_loss=0.946, task_loss=4.313, contrastive_loss=0.329, total=4157.2, n_correct=2549.95, ppl=3.02, accuracy=61.338, wps=14220.7, ups=1.15, wpb=12400.2, bsz=464.4, num_updates=15400, lr=0.000113961, gnorm=0.362, clip=0, loss_scale=32, train_wall=87, gb_free=16.9, wall=13438
2023-07-13 19:27:03 | INFO | train_inner | epoch 011:    768 / 1474 loss=3.49, trans_loss=3.455, nll_loss=1.597, w2v_ctc_loss=0.957, task_loss=4.414, contrastive_loss=0.095, total=4174.91, n_correct=2562.88, ppl=3.02, accuracy=61.388, wps=14185.9, ups=1.14, wpb=12472.8, bsz=460.4, num_updates=15500, lr=0.000113592, gnorm=0.362, clip=0, loss_scale=32, train_wall=87, gb_free=17.1, wall=13526
2023-07-13 19:28:30 | INFO | train_inner | epoch 011:    868 / 1474 loss=3.483, trans_loss=3.453, nll_loss=1.598, w2v_ctc_loss=0.955, task_loss=4.587, contrastive_loss=0.08, total=4118.44, n_correct=2518.98, ppl=3.03, accuracy=61.163, wps=14120.6, ups=1.15, wpb=12290.5, bsz=440.6, num_updates=15600, lr=0.000113228, gnorm=0.361, clip=0, loss_scale=32, train_wall=87, gb_free=11.2, wall=13613
2023-07-13 19:29:57 | INFO | train_inner | epoch 011:    968 / 1474 loss=3.486, trans_loss=3.453, nll_loss=1.596, w2v_ctc_loss=0.954, task_loss=4.492, contrastive_loss=0.096, total=4140.92, n_correct=2540.01, ppl=3.02, accuracy=61.339, wps=14143.6, ups=1.14, wpb=12353.7, bsz=452.9, num_updates=15700, lr=0.000112867, gnorm=0.359, clip=0, loss_scale=32, train_wall=87, gb_free=15.8, wall=13700
2023-07-13 19:31:24 | INFO | train_inner | epoch 011:   1068 / 1474 loss=3.491, trans_loss=3.451, nll_loss=1.595, w2v_ctc_loss=0.956, task_loss=4.307, contrastive_loss=0.12, total=4136.99, n_correct=2543.08, ppl=3.02, accuracy=61.472, wps=14239.9, ups=1.15, wpb=12367, bsz=463.2, num_updates=15800, lr=0.000112509, gnorm=0.357, clip=0, loss_scale=32, train_wall=86, gb_free=17.7, wall=13787
2023-07-13 19:32:51 | INFO | train_inner | epoch 011:   1168 / 1474 loss=3.49, trans_loss=3.454, nll_loss=1.603, w2v_ctc_loss=0.961, task_loss=4.36, contrastive_loss=0.104, total=4185.65, n_correct=2561.01, ppl=3.04, accuracy=61.185, wps=14271.6, ups=1.14, wpb=12477.8, bsz=464.7, num_updates=15900, lr=0.000112154, gnorm=0.359, clip=0, loss_scale=32, train_wall=87, gb_free=14.3, wall=13875
2023-07-13 19:34:19 | INFO | train_inner | epoch 011:   1268 / 1474 loss=3.514, trans_loss=3.455, nll_loss=1.6, w2v_ctc_loss=0.968, task_loss=4.222, contrastive_loss=0.195, total=4171.89, n_correct=2558.69, ppl=3.03, accuracy=61.332, wps=14187.6, ups=1.14, wpb=12466.6, bsz=471.1, num_updates=16000, lr=0.000111803, gnorm=0.361, clip=0, loss_scale=32, train_wall=87, gb_free=16.1, wall=13963
2023-07-13 19:34:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
asr_weight tensor(0.2620, device='cuda:7')
mt_weight tensor(0.1595, device='cuda:7')
asr_weight tensor(0.2620, device='cuda:6')
mt_weight tensor(0.1595, device='cuda:6')
asr_weight tensor(0.2620, device='cuda:4')
mt_weight tensor(0.1595, device='cuda:4')
asr_weight tensor(0.2620, device='cuda:5')
mt_weight tensor(0.1595, device='cuda:5')
asr_weight tensor(0.2620, device='cuda:3')
mt_weight tensor(0.1595, device='cuda:3')
asr_weight tensor(0.2620, device='cuda:2')
mt_weight tensor(0.1595, device='cuda:2')
asr_weight tensor(0.2620, device='cuda:1')
mt_weight tensor(0.1595, device='cuda:1')
2023-07-13 19:34:46 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.256 | trans_loss 5.637 | nll_loss 2.925 | w2v_ctc_loss 1.371 | task_loss 23.177 | contrastive_loss 0.259 | total 4003.4 | n_correct 2432.9 | ppl 7.59 | accuracy 60.771 | uer 17.559 | wer 19.268 | raw_wer 19.268 | bleu 18.99 | wps 2021.6 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.2
2023-07-13 19:34:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-07-13 19:34:46 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_11_16000.pt
2023-07-13 19:34:48 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_11_16000.pt
2023-07-13 19:34:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 18.99) (writing took 6.423107202979736 seconds)
2023-07-13 19:36:21 | INFO | train_inner | epoch 011:   1368 / 1474 loss=3.52, trans_loss=3.452, nll_loss=1.596, w2v_ctc_loss=0.944, task_loss=4.06, contrastive_loss=0.41, total=4190.34, n_correct=2568.68, ppl=3.02, accuracy=61.3, wps=10251.1, ups=0.82, wpb=12512.8, bsz=491.8, num_updates=16100, lr=0.000111456, gnorm=0.358, clip=0, loss_scale=32, train_wall=88, gb_free=17.1, wall=14085
2023-07-13 19:37:49 | INFO | train_inner | epoch 011:   1468 / 1474 loss=3.481, trans_loss=3.453, nll_loss=1.598, w2v_ctc_loss=0.946, task_loss=4.241, contrastive_loss=0.106, total=4158.39, n_correct=2551.32, ppl=3.03, accuracy=61.354, wps=14193.9, ups=1.14, wpb=12421.8, bsz=468, num_updates=16200, lr=0.000111111, gnorm=0.357, clip=0, loss_scale=64, train_wall=87, gb_free=17.1, wall=14172
2023-07-13 19:37:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 19:38:21 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.23 | trans_loss 5.626 | nll_loss 2.915 | w2v_ctc_loss 1.308 | task_loss 23.022 | contrastive_loss 0.262 | total 4003.4 | n_correct 2433.9 | ppl 7.54 | accuracy 60.796 | uer 17.564 | wer 19.433 | raw_wer 19.433 | bleu 19.23 | wps 1962.9 | wpb 4003.4 | bsz 141.8 | num_updates 16206 | best_bleu 19.23
2023-07-13 19:38:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16206 updates
2023-07-13 19:38:21 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 19:38:26 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 19:38:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt (epoch 11 @ 16206 updates, score 19.23) (writing took 8.318062595906667 seconds)
2023-07-13 19:38:30 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-07-13 19:38:30 | INFO | train | epoch 011 | loss 3.49 | trans_loss 3.451 | nll_loss 1.594 | w2v_ctc_loss 0.95 | task_loss 4.392 | contrastive_loss 0.163 | total 4138.65 | n_correct 2540.44 | ppl 3.02 | accuracy 61.383 | wps 13340.1 | ups 1.08 | wpb 12355.8 | bsz 458.5 | num_updates 16206 | lr 0.000111091 | gnorm 0.38 | clip 0 | loss_scale 64 | train_wall 1281 | gb_free 17.3 | wall 14213
2023-07-13 19:38:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 19:38:30 | INFO | fairseq.trainer | begin training epoch 12
2023-07-13 19:38:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 19:39:59 | INFO | train_inner | epoch 012:     94 / 1474 loss=3.454, trans_loss=3.428, nll_loss=1.562, w2v_ctc_loss=0.927, task_loss=4.196, contrastive_loss=0.147, total=4146.82, n_correct=2584.54, ppl=2.95, accuracy=62.326, wps=9471.6, ups=0.77, wpb=12379.4, bsz=470.8, num_updates=16300, lr=0.00011077, gnorm=0.357, clip=0, loss_scale=64, train_wall=86, gb_free=15.9, wall=14303
2023-07-13 19:41:26 | INFO | train_inner | epoch 012:    194 / 1474 loss=3.45, trans_loss=3.429, nll_loss=1.565, w2v_ctc_loss=0.927, task_loss=4.541, contrastive_loss=0.083, total=4120.68, n_correct=2562.76, ppl=2.96, accuracy=62.193, wps=14188.3, ups=1.15, wpb=12345.4, bsz=442.1, num_updates=16400, lr=0.000110432, gnorm=0.357, clip=0, loss_scale=64, train_wall=87, gb_free=15.8, wall=14390
2023-07-13 19:42:54 | INFO | train_inner | epoch 012:    294 / 1474 loss=3.447, trans_loss=3.43, nll_loss=1.568, w2v_ctc_loss=0.914, task_loss=4.128, contrastive_loss=0.126, total=4199.46, n_correct=2615.62, ppl=2.97, accuracy=62.285, wps=14302.1, ups=1.14, wpb=12539.6, bsz=480.4, num_updates=16500, lr=0.000110096, gnorm=0.353, clip=0, loss_scale=64, train_wall=87, gb_free=16.7, wall=14478
2023-07-13 19:44:22 | INFO | train_inner | epoch 012:    394 / 1474 loss=3.45, trans_loss=3.433, nll_loss=1.572, w2v_ctc_loss=0.924, task_loss=4.296, contrastive_loss=0.102, total=4151.14, n_correct=2579.04, ppl=2.97, accuracy=62.128, wps=14125.1, ups=1.14, wpb=12410, bsz=461.6, num_updates=16600, lr=0.000109764, gnorm=0.354, clip=0, loss_scale=64, train_wall=87, gb_free=17.2, wall=14565
2023-07-13 19:45:49 | INFO | train_inner | epoch 012:    494 / 1474 loss=3.479, trans_loss=3.446, nll_loss=1.585, w2v_ctc_loss=0.949, task_loss=4.397, contrastive_loss=0.113, total=4110.49, n_correct=2540.98, ppl=3, accuracy=61.817, wps=14037.8, ups=1.15, wpb=12226.9, bsz=453.3, num_updates=16700, lr=0.000109435, gnorm=0.362, clip=0, loss_scale=64, train_wall=87, gb_free=14.1, wall=14653
2023-07-13 19:47:17 | INFO | train_inner | epoch 012:    594 / 1474 loss=3.473, trans_loss=3.434, nll_loss=1.575, w2v_ctc_loss=0.934, task_loss=4.212, contrastive_loss=0.199, total=4189.92, n_correct=2596.5, ppl=2.98, accuracy=61.97, wps=14278.4, ups=1.14, wpb=12531.1, bsz=472.7, num_updates=16800, lr=0.000109109, gnorm=0.359, clip=0, loss_scale=64, train_wall=87, gb_free=15.1, wall=14740
2023-07-13 19:48:43 | INFO | train_inner | epoch 012:    694 / 1474 loss=3.465, trans_loss=3.43, nll_loss=1.57, w2v_ctc_loss=0.913, task_loss=4.011, contrastive_loss=0.317, total=4206.3, n_correct=2618.79, ppl=2.97, accuracy=62.259, wps=14439.2, ups=1.15, wpb=12501.9, bsz=488.5, num_updates=16900, lr=0.000108786, gnorm=0.354, clip=0, loss_scale=64, train_wall=86, gb_free=16.4, wall=14827
2023-07-13 19:50:10 | INFO | train_inner | epoch 012:    794 / 1474 loss=3.468, trans_loss=3.438, nll_loss=1.576, w2v_ctc_loss=0.939, task_loss=4.489, contrastive_loss=0.1, total=4085.96, n_correct=2536.98, ppl=2.98, accuracy=62.09, wps=14054.7, ups=1.15, wpb=12212.6, bsz=445.7, num_updates=17000, lr=0.000108465, gnorm=0.363, clip=0, loss_scale=64, train_wall=86, gb_free=16.6, wall=14914
2023-07-13 19:51:38 | INFO | train_inner | epoch 012:    894 / 1474 loss=3.463, trans_loss=3.434, nll_loss=1.575, w2v_ctc_loss=0.923, task_loss=4.482, contrastive_loss=0.162, total=4169.74, n_correct=2591.9, ppl=2.98, accuracy=62.16, wps=14168.1, ups=1.14, wpb=12453, bsz=459.6, num_updates=17100, lr=0.000108148, gnorm=0.357, clip=0, loss_scale=64, train_wall=87, gb_free=16.2, wall=15002
2023-07-13 19:53:05 | INFO | train_inner | epoch 012:    994 / 1474 loss=3.477, trans_loss=3.441, nll_loss=1.582, w2v_ctc_loss=0.94, task_loss=4.495, contrastive_loss=0.179, total=4117.67, n_correct=2548.52, ppl=2.99, accuracy=61.892, wps=14109.5, ups=1.15, wpb=12288, bsz=452.1, num_updates=17200, lr=0.000107833, gnorm=0.359, clip=0, loss_scale=64, train_wall=87, gb_free=17.7, wall=15089
2023-07-13 19:54:32 | INFO | train_inner | epoch 012:   1094 / 1474 loss=3.496, trans_loss=3.446, nll_loss=1.588, w2v_ctc_loss=0.946, task_loss=4.595, contrastive_loss=0.237, total=4047.61, n_correct=2498.84, ppl=3.01, accuracy=61.736, wps=13954.7, ups=1.15, wpb=12086.1, bsz=435.6, num_updates=17300, lr=0.000107521, gnorm=0.365, clip=0, loss_scale=64, train_wall=86, gb_free=16.9, wall=15175
2023-07-13 19:55:59 | INFO | train_inner | epoch 012:   1194 / 1474 loss=3.494, trans_loss=3.445, nll_loss=1.59, w2v_ctc_loss=0.958, task_loss=4.351, contrastive_loss=0.178, total=4184.55, n_correct=2574.12, ppl=3.01, accuracy=61.515, wps=14343.4, ups=1.15, wpb=12497.1, bsz=471.4, num_updates=17400, lr=0.000107211, gnorm=0.358, clip=0, loss_scale=64, train_wall=87, gb_free=16.9, wall=15263
2023-07-13 19:57:27 | INFO | train_inner | epoch 012:   1294 / 1474 loss=3.482, trans_loss=3.447, nll_loss=1.592, w2v_ctc_loss=0.952, task_loss=4.794, contrastive_loss=0.104, total=4086.33, n_correct=2522.36, ppl=3.01, accuracy=61.727, wps=13964.5, ups=1.14, wpb=12210.8, bsz=437.2, num_updates=17500, lr=0.000106904, gnorm=0.365, clip=0, loss_scale=64, train_wall=87, gb_free=17, wall=15350
2023-07-13 19:58:54 | INFO | train_inner | epoch 012:   1394 / 1474 loss=3.472, trans_loss=3.441, nll_loss=1.583, w2v_ctc_loss=0.924, task_loss=4.462, contrastive_loss=0.219, total=4134.89, n_correct=2560.71, ppl=3, accuracy=61.929, wps=14104.8, ups=1.14, wpb=12323.9, bsz=456.6, num_updates=17600, lr=0.0001066, gnorm=0.359, clip=0, loss_scale=64, train_wall=87, gb_free=17.4, wall=15437
2023-07-13 20:00:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 20:00:30 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.224 | trans_loss 5.623 | nll_loss 2.91 | w2v_ctc_loss 1.299 | task_loss 22.944 | contrastive_loss 0.257 | total 4003.4 | n_correct 2441.6 | ppl 7.51 | accuracy 60.988 | uer 17.522 | wer 19.216 | raw_wer 19.216 | bleu 19.48 | wps 1924.1 | wpb 4003.4 | bsz 141.8 | num_updates 17680 | best_bleu 19.48
2023-07-13 20:00:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17680 updates
2023-07-13 20:00:30 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 20:00:35 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 20:00:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt (epoch 12 @ 17680 updates, score 19.48) (writing took 8.384592917049304 seconds)
2023-07-13 20:00:39 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-07-13 20:00:39 | INFO | train | epoch 012 | loss 3.469 | trans_loss 3.438 | nll_loss 1.578 | w2v_ctc_loss 0.934 | task_loss 4.391 | contrastive_loss 0.159 | total 4138.65 | n_correct 2565.8 | ppl 2.99 | accuracy 61.996 | wps 13700.8 | ups 1.11 | wpb 12355.8 | bsz 458.5 | num_updates 17680 | lr 0.000106359 | gnorm 0.359 | clip 0 | loss_scale 64 | train_wall 1279 | gb_free 13.2 | wall 15542
2023-07-13 20:00:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 20:00:39 | INFO | fairseq.trainer | begin training epoch 13
2023-07-13 20:00:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 20:01:05 | INFO | train_inner | epoch 013:     20 / 1474 loss=3.472, trans_loss=3.44, nll_loss=1.583, w2v_ctc_loss=0.946, task_loss=4.54, contrastive_loss=0.092, total=4104.86, n_correct=2538.56, ppl=3, accuracy=61.843, wps=9361.3, ups=0.76, wpb=12264.8, bsz=445.3, num_updates=17700, lr=0.000106299, gnorm=0.362, clip=0, loss_scale=64, train_wall=87, gb_free=15, wall=15568
2023-07-13 20:02:33 | INFO | train_inner | epoch 013:    120 / 1474 loss=3.426, trans_loss=3.416, nll_loss=1.55, w2v_ctc_loss=0.904, task_loss=4.387, contrastive_loss=0.107, total=4161.2, n_correct=2612.92, ppl=2.93, accuracy=62.792, wps=14172.4, ups=1.14, wpb=12419, bsz=454.4, num_updates=17800, lr=0.000106, gnorm=0.356, clip=0, loss_scale=64, train_wall=87, gb_free=16.3, wall=15656
2023-07-13 20:04:01 | INFO | train_inner | epoch 013:    220 / 1474 loss=3.47, trans_loss=3.42, nll_loss=1.559, w2v_ctc_loss=0.91, task_loss=4.062, contrastive_loss=0.394, total=4202.62, n_correct=2629.81, ppl=2.95, accuracy=62.575, wps=14141.2, ups=1.13, wpb=12504.4, bsz=492.4, num_updates=17900, lr=0.000105703, gnorm=0.357, clip=0, loss_scale=64, train_wall=88, gb_free=17.3, wall=15744
2023-07-13 20:05:28 | INFO | train_inner | epoch 013:    320 / 1474 loss=3.429, trans_loss=3.42, nll_loss=1.554, w2v_ctc_loss=0.906, task_loss=4.533, contrastive_loss=0.088, total=4112.8, n_correct=2587.06, ppl=2.94, accuracy=62.903, wps=14170.4, ups=1.16, wpb=12262.5, bsz=444, num_updates=18000, lr=0.000105409, gnorm=0.361, clip=0, loss_scale=64, train_wall=86, gb_free=17.9, wall=15831
2023-07-13 20:05:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 20:05:56 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.231 | trans_loss 5.623 | nll_loss 2.904 | w2v_ctc_loss 1.321 | task_loss 23.039 | contrastive_loss 0.256 | total 4003.4 | n_correct 2442.2 | ppl 7.48 | accuracy 61.003 | uer 17.357 | wer 18.978 | raw_wer 18.978 | bleu 19.3 | wps 1890.2 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.48
2023-07-13 20:05:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-07-13 20:05:56 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_13_18000.pt
2023-07-13 20:05:58 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_13_18000.pt
2023-07-13 20:06:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.3) (writing took 6.331242298008874 seconds)
2023-07-13 20:07:29 | INFO | train_inner | epoch 013:    420 / 1474 loss=3.448, trans_loss=3.426, nll_loss=1.562, w2v_ctc_loss=0.913, task_loss=4.131, contrastive_loss=0.149, total=4176.06, n_correct=2621.33, ppl=2.95, accuracy=62.77, wps=10236.6, ups=0.82, wpb=12453.9, bsz=476.2, num_updates=18100, lr=0.000105118, gnorm=0.355, clip=0, loss_scale=64, train_wall=86, gb_free=16.6, wall=15953
2023-07-13 20:08:57 | INFO | train_inner | epoch 013:    520 / 1474 loss=3.454, trans_loss=3.427, nll_loss=1.564, w2v_ctc_loss=0.918, task_loss=4.27, contrastive_loss=0.2, total=4197.57, n_correct=2620.54, ppl=2.96, accuracy=62.43, wps=14257.9, ups=1.14, wpb=12523.8, bsz=477.2, num_updates=18200, lr=0.000104828, gnorm=0.358, clip=0, loss_scale=64, train_wall=87, gb_free=15.5, wall=16040
2023-07-13 20:10:24 | INFO | train_inner | epoch 013:    620 / 1474 loss=3.43, trans_loss=3.419, nll_loss=1.555, w2v_ctc_loss=0.91, task_loss=4.248, contrastive_loss=0.083, total=4160.12, n_correct=2613.47, ppl=2.94, accuracy=62.822, wps=14263.9, ups=1.15, wpb=12433.1, bsz=463, num_updates=18300, lr=0.000104542, gnorm=0.355, clip=0, loss_scale=128, train_wall=87, gb_free=16.5, wall=16128
2023-07-13 20:10:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-13 20:11:52 | INFO | train_inner | epoch 013:    721 / 1474 loss=3.45, trans_loss=3.426, nll_loss=1.563, w2v_ctc_loss=0.932, task_loss=4.857, contrastive_loss=0.082, total=4097.44, n_correct=2557.52, ppl=2.95, accuracy=62.418, wps=13931.1, ups=1.14, wpb=12231.1, bsz=427.9, num_updates=18400, lr=0.000104257, gnorm=0.358, clip=0, loss_scale=64, train_wall=87, gb_free=16.8, wall=16215
2023-07-13 20:13:20 | INFO | train_inner | epoch 013:    821 / 1474 loss=3.446, trans_loss=3.426, nll_loss=1.564, w2v_ctc_loss=0.916, task_loss=4.455, contrastive_loss=0.143, total=4121.73, n_correct=2570.87, ppl=2.96, accuracy=62.374, wps=13969.7, ups=1.13, wpb=12319.8, bsz=460, num_updates=18500, lr=0.000103975, gnorm=0.364, clip=0, loss_scale=64, train_wall=88, gb_free=15, wall=16304
2023-07-13 20:14:47 | INFO | train_inner | epoch 013:    921 / 1474 loss=3.44, trans_loss=3.426, nll_loss=1.565, w2v_ctc_loss=0.915, task_loss=4.487, contrastive_loss=0.094, total=4107.01, n_correct=2567.26, ppl=2.96, accuracy=62.509, wps=14154.4, ups=1.15, wpb=12264.1, bsz=444.7, num_updates=18600, lr=0.000103695, gnorm=0.359, clip=0, loss_scale=64, train_wall=86, gb_free=16.1, wall=16390
2023-07-13 20:16:13 | INFO | train_inner | epoch 013:   1021 / 1474 loss=3.457, trans_loss=3.424, nll_loss=1.565, w2v_ctc_loss=0.926, task_loss=4.64, contrastive_loss=0.161, total=4081.02, n_correct=2541.54, ppl=2.96, accuracy=62.277, wps=14124.1, ups=1.16, wpb=12208.8, bsz=440.1, num_updates=18700, lr=0.000103418, gnorm=0.361, clip=0, loss_scale=64, train_wall=86, gb_free=16.4, wall=16477
2023-07-13 20:17:40 | INFO | train_inner | epoch 013:   1121 / 1474 loss=3.444, trans_loss=3.424, nll_loss=1.561, w2v_ctc_loss=0.911, task_loss=4.338, contrastive_loss=0.138, total=4105.62, n_correct=2572.61, ppl=2.95, accuracy=62.661, wps=14206.7, ups=1.16, wpb=12265.4, bsz=458.9, num_updates=18800, lr=0.000103142, gnorm=0.359, clip=0, loss_scale=64, train_wall=86, gb_free=16.9, wall=16563
2023-07-13 20:19:07 | INFO | train_inner | epoch 013:   1221 / 1474 loss=3.459, trans_loss=3.435, nll_loss=1.573, w2v_ctc_loss=0.931, task_loss=4.681, contrastive_loss=0.085, total=4110.35, n_correct=2564.73, ppl=2.98, accuracy=62.397, wps=14035, ups=1.14, wpb=12287.7, bsz=442.6, num_updates=18900, lr=0.000102869, gnorm=0.367, clip=0, loss_scale=64, train_wall=87, gb_free=15.1, wall=16651
2023-07-13 20:20:35 | INFO | train_inner | epoch 013:   1321 / 1474 loss=3.45, trans_loss=3.424, nll_loss=1.564, w2v_ctc_loss=0.912, task_loss=4.323, contrastive_loss=0.213, total=4112.2, n_correct=2575.1, ppl=2.96, accuracy=62.621, wps=14032.6, ups=1.14, wpb=12280.4, bsz=462.3, num_updates=19000, lr=0.000102598, gnorm=0.36, clip=0, loss_scale=64, train_wall=87, gb_free=17.7, wall=16738
2023-07-13 20:22:02 | INFO | train_inner | epoch 013:   1421 / 1474 loss=3.464, trans_loss=3.433, nll_loss=1.572, w2v_ctc_loss=0.912, task_loss=4.315, contrastive_loss=0.229, total=4180.88, n_correct=2606.72, ppl=2.97, accuracy=62.349, wps=14323.2, ups=1.15, wpb=12470.5, bsz=468.3, num_updates=19100, lr=0.000102329, gnorm=0.355, clip=0, loss_scale=64, train_wall=87, gb_free=15.5, wall=16825
2023-07-13 20:22:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 20:23:15 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.215 | trans_loss 5.606 | nll_loss 2.89 | w2v_ctc_loss 1.308 | task_loss 23.17 | contrastive_loss 0.254 | total 4003.4 | n_correct 2451.1 | ppl 7.41 | accuracy 61.225 | uer 17.421 | wer 19.246 | raw_wer 19.246 | bleu 19.19 | wps 2019.2 | wpb 4003.4 | bsz 141.8 | num_updates 19153 | best_bleu 19.48
2023-07-13 20:23:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19153 updates
2023-07-13 20:23:15 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_19.1907.pt
2023-07-13 20:23:17 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_19.1907.pt
2023-07-13 20:23:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_19.1907.pt (epoch 13 @ 19153 updates, score 19.19) (writing took 5.302062585949898 seconds)
2023-07-13 20:23:20 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-07-13 20:23:20 | INFO | train | epoch 013 | loss 3.447 | trans_loss 3.425 | nll_loss 1.562 | w2v_ctc_loss 0.916 | task_loss 4.39 | contrastive_loss 0.155 | total 4138.62 | n_correct 2589.34 | ppl 2.95 | accuracy 62.565 | wps 13370.2 | ups 1.08 | wpb 12355.9 | bsz 458.6 | num_updates 19153 | lr 0.000102187 | gnorm 0.359 | clip 0 | loss_scale 64 | train_wall 1279 | gb_free 17.7 | wall 16904
2023-07-13 20:23:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 20:23:21 | INFO | fairseq.trainer | begin training epoch 14
2023-07-13 20:23:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 20:24:09 | INFO | train_inner | epoch 014:     47 / 1474 loss=3.411, trans_loss=3.405, nll_loss=1.539, w2v_ctc_loss=0.896, task_loss=4.006, contrastive_loss=0.102, total=4176.2, n_correct=2641.18, ppl=2.91, accuracy=63.244, wps=9791.8, ups=0.78, wpb=12486.4, bsz=483.4, num_updates=19200, lr=0.000102062, gnorm=0.354, clip=0, loss_scale=64, train_wall=86, gb_free=11.2, wall=16953
2023-07-13 20:25:36 | INFO | train_inner | epoch 014:    147 / 1474 loss=3.407, trans_loss=3.404, nll_loss=1.532, w2v_ctc_loss=0.892, task_loss=4.44, contrastive_loss=0.078, total=4080.86, n_correct=2594.82, ppl=2.89, accuracy=63.585, wps=14024, ups=1.15, wpb=12203.2, bsz=449.3, num_updates=19300, lr=0.000101797, gnorm=0.356, clip=0, loss_scale=64, train_wall=87, gb_free=17, wall=17040
2023-07-13 20:27:03 | INFO | train_inner | epoch 014:    247 / 1474 loss=3.431, trans_loss=3.416, nll_loss=1.549, w2v_ctc_loss=0.89, task_loss=4.631, contrastive_loss=0.213, total=4106.97, n_correct=2594.08, ppl=2.93, accuracy=63.163, wps=14041.2, ups=1.15, wpb=12224.4, bsz=440, num_updates=19400, lr=0.000101535, gnorm=0.359, clip=0, loss_scale=64, train_wall=87, gb_free=12.7, wall=17127
2023-07-13 20:28:30 | INFO | train_inner | epoch 014:    347 / 1474 loss=3.398, trans_loss=3.398, nll_loss=1.535, w2v_ctc_loss=0.888, task_loss=4.021, contrastive_loss=0.123, total=4179.8, n_correct=2646.29, ppl=2.9, accuracy=63.311, wps=14317.7, ups=1.15, wpb=12454.9, bsz=483.8, num_updates=19500, lr=0.000101274, gnorm=0.355, clip=0, loss_scale=64, train_wall=87, gb_free=17.4, wall=17214
2023-07-13 20:29:57 | INFO | train_inner | epoch 014:    447 / 1474 loss=3.413, trans_loss=3.413, nll_loss=1.547, w2v_ctc_loss=0.895, task_loss=4.528, contrastive_loss=0.075, total=4120.38, n_correct=2597.26, ppl=2.92, accuracy=63.034, wps=14121.1, ups=1.15, wpb=12283.1, bsz=444.5, num_updates=19600, lr=0.000101015, gnorm=0.356, clip=0, loss_scale=64, train_wall=87, gb_free=17.3, wall=17301
2023-07-13 20:31:25 | INFO | train_inner | epoch 014:    547 / 1474 loss=3.441, trans_loss=3.421, nll_loss=1.556, w2v_ctc_loss=0.913, task_loss=4.661, contrastive_loss=0.117, total=4089.86, n_correct=2568.88, ppl=2.94, accuracy=62.811, wps=13974.3, ups=1.14, wpb=12262.9, bsz=443.3, num_updates=19700, lr=0.000100759, gnorm=0.362, clip=0, loss_scale=64, train_wall=87, gb_free=12.4, wall=17389
2023-07-13 20:32:52 | INFO | train_inner | epoch 014:    647 / 1474 loss=3.43, trans_loss=3.416, nll_loss=1.551, w2v_ctc_loss=0.895, task_loss=4.4, contrastive_loss=0.178, total=4158.94, n_correct=2619.92, ppl=2.93, accuracy=62.995, wps=14274.3, ups=1.15, wpb=12415.4, bsz=460, num_updates=19800, lr=0.000100504, gnorm=0.361, clip=0, loss_scale=64, train_wall=87, gb_free=16.4, wall=17476
2023-07-13 20:34:19 | INFO | train_inner | epoch 014:    747 / 1474 loss=3.413, trans_loss=3.409, nll_loss=1.543, w2v_ctc_loss=0.893, task_loss=4.26, contrastive_loss=0.087, total=4150.03, n_correct=2626.99, ppl=2.91, accuracy=63.301, wps=14276.5, ups=1.15, wpb=12407.3, bsz=465.5, num_updates=19900, lr=0.000100251, gnorm=0.354, clip=0, loss_scale=64, train_wall=86, gb_free=15.7, wall=17562
2023-07-13 20:35:46 | INFO | train_inner | epoch 014:    847 / 1474 loss=3.424, trans_loss=3.405, nll_loss=1.541, w2v_ctc_loss=0.887, task_loss=4.2, contrastive_loss=0.233, total=4162.8, n_correct=2630.33, ppl=2.91, accuracy=63.187, wps=14230.8, ups=1.15, wpb=12422.9, bsz=475.8, num_updates=20000, lr=0.0001, gnorm=0.356, clip=0, loss_scale=64, train_wall=87, gb_free=17.2, wall=17650
2023-07-13 20:35:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 20:36:11 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.209 | trans_loss 5.598 | nll_loss 2.877 | w2v_ctc_loss 1.305 | task_loss 23.05 | contrastive_loss 0.255 | total 4003.4 | n_correct 2456.5 | ppl 7.35 | accuracy 61.36 | uer 17.105 | wer 18.948 | raw_wer 18.948 | bleu 19.69 | wps 2257.3 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.69
2023-07-13 20:36:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-07-13 20:36:11 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_14_20000.pt
2023-07-13 20:36:13 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_14_20000.pt
2023-07-13 20:36:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.69) (writing took 9.41426428896375 seconds)
asr_weight tensor(0.0260, device='cuda:0')
mt_weight tensor(0.0016, device='cuda:0')
2023-07-13 20:37:22 | INFO | train_inner | epoch 014:    947 / 1474 loss=3.94, trans_loss=5.364, nll_loss=2.71, w2v_ctc_loss=1.3, task_loss=12.983, contrastive_loss=0.135, total=4159.46, n_correct=2603.45, ppl=6.54, accuracy=62.591, wps=4430.1, ups=1.04, wpb=4251.9, bsz=158.1, num_updates=20100, lr=9.97509e-05, gnorm=0.958, clip=0, loss_scale=64, train_wall=61, gb_free=15.6, wall=17746
2023-07-13 20:38:24 | INFO | train_inner | epoch 014:   1047 / 1474 loss=3.96, trans_loss=5.429, nll_loss=2.75, w2v_ctc_loss=1.294, task_loss=13.16, contrastive_loss=0.271, total=4155.93, n_correct=2604.94, ppl=6.73, accuracy=62.68, wps=6753.2, ups=1.62, wpb=4155.9, bsz=153, num_updates=20200, lr=9.95037e-05, gnorm=0.959, clip=0, loss_scale=64, train_wall=61, gb_free=16.7, wall=17807
2023-07-13 20:39:25 | INFO | train_inner | epoch 014:   1147 / 1474 loss=3.986, trans_loss=5.438, nll_loss=2.761, w2v_ctc_loss=1.314, task_loss=12.385, contrastive_loss=0.716, total=4228.09, n_correct=2642.93, ppl=6.78, accuracy=62.509, wps=6874.8, ups=1.63, wpb=4228.1, bsz=163.2, num_updates=20300, lr=9.92583e-05, gnorm=0.952, clip=0, loss_scale=64, train_wall=61, gb_free=17.7, wall=17869
2023-07-13 20:40:26 | INFO | train_inner | epoch 014:   1247 / 1474 loss=3.991, trans_loss=5.447, nll_loss=2.771, w2v_ctc_loss=1.34, task_loss=15.377, contrastive_loss=0.104, total=4027.71, n_correct=2511.79, ppl=6.83, accuracy=62.363, wps=6681.8, ups=1.66, wpb=4027.7, bsz=136.8, num_updates=20400, lr=9.90148e-05, gnorm=0.993, clip=0, loss_scale=128, train_wall=60, gb_free=17, wall=17929
2023-07-13 20:41:26 | INFO | train_inner | epoch 014:   1347 / 1474 loss=3.938, trans_loss=5.42, nll_loss=2.738, w2v_ctc_loss=1.287, task_loss=12.614, contrastive_loss=0.135, total=4198.71, n_correct=2639.16, ppl=6.67, accuracy=62.856, wps=6899, ups=1.64, wpb=4198.7, bsz=157.7, num_updates=20500, lr=9.8773e-05, gnorm=0.961, clip=0, loss_scale=128, train_wall=60, gb_free=16.9, wall=17990
2023-07-13 20:42:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-13 20:42:27 | INFO | train_inner | epoch 014:   1448 / 1474 loss=3.958, trans_loss=5.432, nll_loss=2.753, w2v_ctc_loss=1.299, task_loss=13.229, contrastive_loss=0.192, total=4128.2, n_correct=2589.09, ppl=6.74, accuracy=62.717, wps=6809.6, ups=1.65, wpb=4128.2, bsz=151.3, num_updates=20600, lr=9.85329e-05, gnorm=0.956, clip=0, loss_scale=64, train_wall=60, gb_free=15.5, wall=18051
2023-07-13 20:42:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
asr_weight tensor(0.0260, device='cuda:7')
mt_weight tensor(0.0016, device='cuda:7')
asr_weight tensor(0.0260, device='cuda:5')
mt_weight tensor(0.0016, device='cuda:5')
asr_weight tensor(0.0260, device='cuda:1')
mt_weight tensor(0.0016, device='cuda:1')
asr_weight tensor(0.0260, device='cuda:4')
mt_weight tensor(0.0016, device='cuda:4')
asr_weight tensor(0.0260, device='cuda:3')
mt_weight tensor(0.0016, device='cuda:3')
asr_weight tensor(0.0260, device='cuda:2')
mt_weight tensor(0.0016, device='cuda:2')
asr_weight tensor(0.0260, device='cuda:6')
mt_weight tensor(0.0016, device='cuda:6')
2023-07-13 20:43:10 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.212 | trans_loss 5.6 | nll_loss 2.882 | w2v_ctc_loss 1.308 | task_loss 23.029 | contrastive_loss 0.259 | total 4003.4 | n_correct 2458.6 | ppl 7.37 | accuracy 61.413 | uer 17.195 | wer 19.075 | raw_wer 19.075 | bleu 19.88 | wps 1957.4 | wpb 4003.4 | bsz 141.8 | num_updates 20626 | best_bleu 19.88
2023-07-13 20:43:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20626 updates
2023-07-13 20:43:10 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 20:43:14 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 20:43:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt (epoch 14 @ 20626 updates, score 19.88) (writing took 8.396767221041955 seconds)
2023-07-13 20:43:19 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-07-13 20:43:19 | INFO | train | epoch 014 | loss 3.53 | trans_loss 3.81 | nll_loss 1.783 | w2v_ctc_loss 0.979 | task_loss 6.122 | contrastive_loss 0.16 | total 4137.79 | n_correct 2604.78 | ppl 3.44 | accuracy 62.951 | wps 10896.4 | ups 1.23 | wpb 8864.8 | bsz 329.2 | num_updates 20626 | lr 9.84708e-05 | gnorm 0.615 | clip 0 | loss_scale 64 | train_wall 1113 | gb_free 16.6 | wall 18102
2023-07-13 20:43:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 20:43:19 | INFO | fairseq.trainer | begin training epoch 15
2023-07-13 20:43:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 20:44:11 | INFO | train_inner | epoch 015:     74 / 1474 loss=3.929, trans_loss=5.395, nll_loss=2.704, w2v_ctc_loss=1.267, task_loss=13.233, contrastive_loss=0.309, total=4083.88, n_correct=2583.77, ppl=6.52, accuracy=63.268, wps=3928.7, ups=0.96, wpb=4083.9, bsz=150.1, num_updates=20700, lr=9.82946e-05, gnorm=0.955, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=18154
2023-07-13 20:45:12 | INFO | train_inner | epoch 015:    174 / 1474 loss=3.925, trans_loss=5.387, nll_loss=2.693, w2v_ctc_loss=1.291, task_loss=13.74, contrastive_loss=0.126, total=4115.73, n_correct=2607.87, ppl=6.47, accuracy=63.363, wps=6798, ups=1.65, wpb=4115.7, bsz=148.9, num_updates=20800, lr=9.80581e-05, gnorm=0.952, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=18215
2023-07-13 20:46:12 | INFO | train_inner | epoch 015:    274 / 1474 loss=3.908, trans_loss=5.382, nll_loss=2.687, w2v_ctc_loss=1.272, task_loss=12.672, contrastive_loss=0.112, total=4193.15, n_correct=2664.43, ppl=6.44, accuracy=63.542, wps=6945.1, ups=1.66, wpb=4193.1, bsz=156.3, num_updates=20900, lr=9.78232e-05, gnorm=0.94, clip=0, loss_scale=64, train_wall=60, gb_free=13.1, wall=18275
2023-07-13 20:47:12 | INFO | train_inner | epoch 015:    374 / 1474 loss=3.908, trans_loss=5.375, nll_loss=2.678, w2v_ctc_loss=1.264, task_loss=13.344, contrastive_loss=0.16, total=4167.66, n_correct=2649.09, ppl=6.4, accuracy=63.563, wps=6925, ups=1.66, wpb=4167.7, bsz=153, num_updates=21000, lr=9.759e-05, gnorm=0.952, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=18336
2023-07-13 20:48:13 | INFO | train_inner | epoch 015:    474 / 1474 loss=3.943, trans_loss=5.4, nll_loss=2.71, w2v_ctc_loss=1.28, task_loss=13.783, contrastive_loss=0.337, total=4074.53, n_correct=2571.58, ppl=6.54, accuracy=63.114, wps=6713.5, ups=1.65, wpb=4074.5, bsz=147.1, num_updates=21100, lr=9.73585e-05, gnorm=0.966, clip=0, loss_scale=64, train_wall=60, gb_free=16, wall=18396
2023-07-13 20:49:13 | INFO | train_inner | epoch 015:    574 / 1474 loss=3.938, trans_loss=5.398, nll_loss=2.708, w2v_ctc_loss=1.311, task_loss=13.636, contrastive_loss=0.125, total=4140.59, n_correct=2614.19, ppl=6.54, accuracy=63.136, wps=6884.8, ups=1.66, wpb=4140.6, bsz=149.4, num_updates=21200, lr=9.71286e-05, gnorm=0.961, clip=0, loss_scale=64, train_wall=60, gb_free=12.6, wall=18456
2023-07-13 20:50:14 | INFO | train_inner | epoch 015:    674 / 1474 loss=3.933, trans_loss=5.392, nll_loss=2.7, w2v_ctc_loss=1.288, task_loss=13.337, contrastive_loss=0.291, total=4134.99, n_correct=2618.02, ppl=6.5, accuracy=63.314, wps=6755.5, ups=1.63, wpb=4135, bsz=153.5, num_updates=21300, lr=9.69003e-05, gnorm=0.965, clip=0, loss_scale=64, train_wall=61, gb_free=11.1, wall=18518
2023-07-13 20:51:15 | INFO | train_inner | epoch 015:    774 / 1474 loss=3.935, trans_loss=5.402, nll_loss=2.715, w2v_ctc_loss=1.3, task_loss=13.327, contrastive_loss=0.133, total=4173.66, n_correct=2631.4, ppl=6.57, accuracy=63.048, wps=6861, ups=1.64, wpb=4173.7, bsz=152.5, num_updates=21400, lr=9.66736e-05, gnorm=0.967, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=18578
2023-07-13 20:52:15 | INFO | train_inner | epoch 015:    874 / 1474 loss=3.942, trans_loss=5.404, nll_loss=2.717, w2v_ctc_loss=1.298, task_loss=14.24, contrastive_loss=0.124, total=4059.35, n_correct=2562.21, ppl=6.58, accuracy=63.119, wps=6761.9, ups=1.67, wpb=4059.3, bsz=144.1, num_updates=21500, lr=9.64486e-05, gnorm=0.971, clip=0, loss_scale=64, train_wall=60, gb_free=15.8, wall=18639
2023-07-13 20:53:15 | INFO | train_inner | epoch 015:    974 / 1474 loss=3.933, trans_loss=5.395, nll_loss=2.706, w2v_ctc_loss=1.281, task_loss=13.278, contrastive_loss=0.291, total=4122.87, n_correct=2607.6, ppl=6.52, accuracy=63.247, wps=6863, ups=1.66, wpb=4122.9, bsz=150.8, num_updates=21600, lr=9.6225e-05, gnorm=0.952, clip=0, loss_scale=64, train_wall=60, gb_free=17.7, wall=18699
2023-07-13 20:53:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-13 20:54:18 | INFO | train_inner | epoch 015:   1075 / 1474 loss=3.936, trans_loss=5.401, nll_loss=2.714, w2v_ctc_loss=1.294, task_loss=12.803, contrastive_loss=0.29, total=4165.38, n_correct=2631.31, ppl=6.56, accuracy=63.171, wps=6653.9, ups=1.6, wpb=4165.4, bsz=157.2, num_updates=21700, lr=9.60031e-05, gnorm=0.954, clip=0, loss_scale=32, train_wall=62, gb_free=16.9, wall=18761
2023-07-13 20:55:18 | INFO | train_inner | epoch 015:   1175 / 1474 loss=3.898, trans_loss=5.383, nll_loss=2.694, w2v_ctc_loss=1.255, task_loss=11.757, contrastive_loss=0.215, total=4187.68, n_correct=2658.99, ppl=6.47, accuracy=63.496, wps=6929.6, ups=1.65, wpb=4187.7, bsz=164.9, num_updates=21800, lr=9.57826e-05, gnorm=0.939, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=18822
2023-07-13 20:56:19 | INFO | train_inner | epoch 015:   1275 / 1474 loss=3.941, trans_loss=5.403, nll_loss=2.717, w2v_ctc_loss=1.315, task_loss=13.624, contrastive_loss=0.126, total=4141.6, n_correct=2612.4, ppl=6.57, accuracy=63.077, wps=6830.6, ups=1.65, wpb=4141.6, bsz=150.5, num_updates=21900, lr=9.55637e-05, gnorm=0.97, clip=0, loss_scale=32, train_wall=60, gb_free=13.8, wall=18882
2023-07-13 20:57:20 | INFO | train_inner | epoch 015:   1375 / 1474 loss=3.931, trans_loss=5.394, nll_loss=2.704, w2v_ctc_loss=1.296, task_loss=13.663, contrastive_loss=0.101, total=4099.6, n_correct=2592.46, ppl=6.52, accuracy=63.237, wps=6751.9, ups=1.65, wpb=4099.6, bsz=146.6, num_updates=22000, lr=9.53463e-05, gnorm=0.965, clip=0, loss_scale=32, train_wall=60, gb_free=14.7, wall=18943
2023-07-13 20:57:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 20:57:47 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.208 | trans_loss 5.594 | nll_loss 2.868 | w2v_ctc_loss 1.315 | task_loss 23.082 | contrastive_loss 0.254 | total 4003.4 | n_correct 2463.6 | ppl 7.3 | accuracy 61.538 | uer 17.225 | wer 19.011 | raw_wer 19.011 | bleu 19.64 | wps 1945.1 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 19.88
2023-07-13 20:57:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-07-13 20:57:47 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_15_22000.pt
2023-07-13 20:57:49 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_15_22000.pt
2023-07-13 20:57:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.64) (writing took 6.176449813996442 seconds)
2023-07-13 20:58:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 20:59:21 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.231 | trans_loss 5.596 | nll_loss 2.882 | w2v_ctc_loss 1.382 | task_loss 23.156 | contrastive_loss 0.259 | total 4003.4 | n_correct 2464 | ppl 7.37 | accuracy 61.548 | uer 17.57 | wer 19.261 | raw_wer 19.261 | bleu 19.81 | wps 2010.9 | wpb 4003.4 | bsz 141.8 | num_updates 22099 | best_bleu 19.88
2023-07-13 20:59:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22099 updates
2023-07-13 20:59:21 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_19.8106.pt
2023-07-13 20:59:24 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_19.8106.pt
2023-07-13 20:59:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_19.8106.pt (epoch 15 @ 22099 updates, score 19.81) (writing took 5.248738458030857 seconds)
2023-07-13 20:59:27 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-07-13 20:59:27 | INFO | train | epoch 015 | loss 3.928 | trans_loss 5.393 | nll_loss 2.703 | w2v_ctc_loss 1.286 | task_loss 13.234 | contrastive_loss 0.203 | total 4136.69 | n_correct 2617.23 | ppl 6.51 | accuracy 63.269 | wps 6293.8 | ups 1.52 | wpb 4136.7 | bsz 152.4 | num_updates 22099 | lr 9.51325e-05 | gnorm 0.958 | clip 0 | loss_scale 32 | train_wall 888 | gb_free 17.2 | wall 19070
2023-07-13 20:59:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 20:59:27 | INFO | fairseq.trainer | begin training epoch 16
2023-07-13 20:59:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 20:59:36 | INFO | train_inner | epoch 016:      1 / 1474 loss=3.935, trans_loss=5.405, nll_loss=2.722, w2v_ctc_loss=1.288, task_loss=12.637, contrastive_loss=0.278, total=4149.9, n_correct=2618.78, ppl=6.6, accuracy=63.105, wps=3048.9, ups=0.73, wpb=4149.9, bsz=158.2, num_updates=22100, lr=9.51303e-05, gnorm=0.963, clip=0, loss_scale=32, train_wall=61, gb_free=17.6, wall=19079
2023-07-13 21:00:36 | INFO | train_inner | epoch 016:    101 / 1474 loss=3.878, trans_loss=5.346, nll_loss=2.642, w2v_ctc_loss=1.261, task_loss=12.657, contrastive_loss=0.158, total=4118.73, n_correct=2638.13, ppl=6.24, accuracy=64.052, wps=6859, ups=1.67, wpb=4118.7, bsz=157, num_updates=22200, lr=9.49158e-05, gnorm=0.956, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=19139
2023-07-13 21:01:36 | INFO | train_inner | epoch 016:    201 / 1474 loss=3.877, trans_loss=5.343, nll_loss=2.637, w2v_ctc_loss=1.238, task_loss=13.559, contrastive_loss=0.112, total=4106.45, n_correct=2633.46, ppl=6.22, accuracy=64.13, wps=6771.4, ups=1.65, wpb=4106.4, bsz=148.7, num_updates=22300, lr=9.47027e-05, gnorm=0.946, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=19200
2023-07-13 21:02:37 | INFO | train_inner | epoch 016:    301 / 1474 loss=3.913, trans_loss=5.37, nll_loss=2.674, w2v_ctc_loss=1.285, task_loss=13.018, contrastive_loss=0.255, total=4169.65, n_correct=2653.25, ppl=6.38, accuracy=63.632, wps=6820.8, ups=1.64, wpb=4169.6, bsz=154.9, num_updates=22400, lr=9.44911e-05, gnorm=0.968, clip=0, loss_scale=32, train_wall=61, gb_free=11.2, wall=19261
2023-07-13 21:03:38 | INFO | train_inner | epoch 016:    401 / 1474 loss=3.925, trans_loss=5.37, nll_loss=2.672, w2v_ctc_loss=1.285, task_loss=14.127, contrastive_loss=0.284, total=4063.79, n_correct=2584.7, ppl=6.38, accuracy=63.603, wps=6754.3, ups=1.66, wpb=4063.8, bsz=143.2, num_updates=22500, lr=9.42809e-05, gnorm=0.96, clip=0, loss_scale=32, train_wall=60, gb_free=13.1, wall=19321
2023-07-13 21:04:39 | INFO | train_inner | epoch 016:    501 / 1474 loss=3.892, trans_loss=5.363, nll_loss=2.666, w2v_ctc_loss=1.268, task_loss=12.625, contrastive_loss=0.175, total=4179.53, n_correct=2670.94, ppl=6.34, accuracy=63.905, wps=6814.1, ups=1.63, wpb=4179.5, bsz=159.8, num_updates=22600, lr=9.40721e-05, gnorm=0.953, clip=0, loss_scale=32, train_wall=61, gb_free=17.9, wall=19382
2023-07-13 21:05:39 | INFO | train_inner | epoch 016:    601 / 1474 loss=3.895, trans_loss=5.358, nll_loss=2.658, w2v_ctc_loss=1.262, task_loss=13.331, contrastive_loss=0.1, total=4121.37, n_correct=2632.49, ppl=6.31, accuracy=63.874, wps=6891.3, ups=1.67, wpb=4121.4, bsz=148.7, num_updates=22700, lr=9.38647e-05, gnorm=0.952, clip=0, loss_scale=32, train_wall=59, gb_free=18, wall=19442
2023-07-13 21:06:39 | INFO | train_inner | epoch 016:    701 / 1474 loss=3.909, trans_loss=5.372, nll_loss=2.676, w2v_ctc_loss=1.281, task_loss=13.522, contrastive_loss=0.108, total=4099.17, n_correct=2606.44, ppl=6.39, accuracy=63.585, wps=6805.6, ups=1.66, wpb=4099.2, bsz=148.7, num_updates=22800, lr=9.36586e-05, gnorm=0.957, clip=0, loss_scale=32, train_wall=60, gb_free=17, wall=19502
2023-07-13 21:07:40 | INFO | train_inner | epoch 016:    801 / 1474 loss=3.899, trans_loss=5.367, nll_loss=2.671, w2v_ctc_loss=1.254, task_loss=12.587, contrastive_loss=0.227, total=4184.53, n_correct=2663.16, ppl=6.37, accuracy=63.643, wps=6889.6, ups=1.65, wpb=4184.5, bsz=156.5, num_updates=22900, lr=9.34539e-05, gnorm=0.951, clip=0, loss_scale=32, train_wall=60, gb_free=13.7, wall=19563
2023-07-13 21:08:40 | INFO | train_inner | epoch 016:    901 / 1474 loss=3.899, trans_loss=5.363, nll_loss=2.667, w2v_ctc_loss=1.258, task_loss=12.95, contrastive_loss=0.21, total=4151.84, n_correct=2649.53, ppl=6.35, accuracy=63.816, wps=6847.6, ups=1.65, wpb=4151.8, bsz=153.5, num_updates=23000, lr=9.32505e-05, gnorm=0.948, clip=0, loss_scale=32, train_wall=60, gb_free=17, wall=19624
2023-07-13 21:09:41 | INFO | train_inner | epoch 016:   1001 / 1474 loss=3.925, trans_loss=5.382, nll_loss=2.689, w2v_ctc_loss=1.293, task_loss=13.696, contrastive_loss=0.207, total=4112.79, n_correct=2605.25, ppl=6.45, accuracy=63.345, wps=6749.8, ups=1.64, wpb=4112.8, bsz=149.8, num_updates=23100, lr=9.30484e-05, gnorm=0.957, clip=0, loss_scale=32, train_wall=61, gb_free=15.2, wall=19685
2023-07-13 21:10:43 | INFO | train_inner | epoch 016:   1101 / 1474 loss=3.931, trans_loss=5.388, nll_loss=2.698, w2v_ctc_loss=1.301, task_loss=14.071, contrastive_loss=0.159, total=4111.6, n_correct=2603, ppl=6.49, accuracy=63.309, wps=6705.3, ups=1.63, wpb=4111.6, bsz=147.8, num_updates=23200, lr=9.28477e-05, gnorm=0.974, clip=0, loss_scale=32, train_wall=61, gb_free=14.9, wall=19746
2023-07-13 21:11:44 | INFO | train_inner | epoch 016:   1201 / 1474 loss=3.924, trans_loss=5.383, nll_loss=2.693, w2v_ctc_loss=1.265, task_loss=13.432, contrastive_loss=0.348, total=4157.51, n_correct=2630.7, ppl=6.46, accuracy=63.276, wps=6804.5, ups=1.64, wpb=4157.5, bsz=153.3, num_updates=23300, lr=9.26482e-05, gnorm=0.965, clip=0, loss_scale=32, train_wall=61, gb_free=15.1, wall=19807
2023-07-13 21:12:45 | INFO | train_inner | epoch 016:   1301 / 1474 loss=3.922, trans_loss=5.384, nll_loss=2.694, w2v_ctc_loss=1.288, task_loss=12.79, contrastive_loss=0.313, total=4151.03, n_correct=2636.08, ppl=6.47, accuracy=63.504, wps=6775.7, ups=1.63, wpb=4151, bsz=157.2, num_updates=23400, lr=9.245e-05, gnorm=0.958, clip=0, loss_scale=32, train_wall=61, gb_free=16.8, wall=19868
2023-07-13 21:13:46 | INFO | train_inner | epoch 016:   1401 / 1474 loss=3.903, trans_loss=5.376, nll_loss=2.684, w2v_ctc_loss=1.276, task_loss=12.637, contrastive_loss=0.161, total=4201.47, n_correct=2668.57, ppl=6.43, accuracy=63.515, wps=6877.5, ups=1.64, wpb=4201.5, bsz=160.4, num_updates=23500, lr=9.22531e-05, gnorm=0.951, clip=0, loss_scale=32, train_wall=61, gb_free=16.2, wall=19930
2023-07-13 21:14:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 21:14:58 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.181 | trans_loss 5.578 | nll_loss 2.857 | w2v_ctc_loss 1.263 | task_loss 23.261 | contrastive_loss 0.246 | total 4003.4 | n_correct 2468.7 | ppl 7.24 | accuracy 61.665 | uer 16.842 | wer 18.594 | raw_wer 18.594 | bleu 20.11 | wps 1876.5 | wpb 4003.4 | bsz 141.8 | num_updates 23573 | best_bleu 20.11
2023-07-13 21:14:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23573 updates
2023-07-13 21:14:58 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 21:15:02 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 21:15:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt (epoch 16 @ 23573 updates, score 20.11) (writing took 8.312366215977818 seconds)
2023-07-13 21:15:06 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-07-13 21:15:06 | INFO | train | epoch 016 | loss 3.908 | trans_loss 5.37 | nll_loss 2.674 | w2v_ctc_loss 1.273 | task_loss 13.194 | contrastive_loss 0.219 | total 4138.65 | n_correct 2634.17 | ppl 6.38 | accuracy 63.648 | wps 6493.3 | ups 1.57 | wpb 4138.6 | bsz 152.8 | num_updates 23573 | lr 9.21102e-05 | gnorm 0.958 | clip 0 | loss_scale 32 | train_wall 889 | gb_free 15.6 | wall 20010
2023-07-13 21:15:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 21:15:07 | INFO | fairseq.trainer | begin training epoch 17
2023-07-13 21:15:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 21:15:31 | INFO | train_inner | epoch 017:     27 / 1474 loss=3.914, trans_loss=5.361, nll_loss=2.664, w2v_ctc_loss=1.266, task_loss=13.45, contrastive_loss=0.444, total=4145.04, n_correct=2645.16, ppl=6.34, accuracy=63.815, wps=3948.5, ups=0.95, wpb=4145, bsz=151.2, num_updates=23600, lr=9.20575e-05, gnorm=0.963, clip=0, loss_scale=32, train_wall=61, gb_free=15.8, wall=20035
2023-07-13 21:16:32 | INFO | train_inner | epoch 017:    127 / 1474 loss=3.88, trans_loss=5.333, nll_loss=2.626, w2v_ctc_loss=1.265, task_loss=13.569, contrastive_loss=0.11, total=4117.27, n_correct=2640.82, ppl=6.17, accuracy=64.14, wps=6790.2, ups=1.65, wpb=4117.3, bsz=148.1, num_updates=23700, lr=9.1863e-05, gnorm=0.95, clip=0, loss_scale=64, train_wall=60, gb_free=17.9, wall=20095
2023-07-13 21:16:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-13 21:17:33 | INFO | train_inner | epoch 017:    228 / 1474 loss=3.884, trans_loss=5.34, nll_loss=2.636, w2v_ctc_loss=1.252, task_loss=21.774, contrastive_loss=0.245, total=4133.06, n_correct=2653.6, ppl=6.22, accuracy=64.204, wps=6767.7, ups=1.64, wpb=4133.1, bsz=155.4, num_updates=23800, lr=9.16698e-05, gnorm=1.033, clip=0, loss_scale=32, train_wall=61, gb_free=16.2, wall=20156
2023-07-13 21:18:33 | INFO | train_inner | epoch 017:    328 / 1474 loss=3.903, trans_loss=5.34, nll_loss=2.635, w2v_ctc_loss=1.251, task_loss=25.646, contrastive_loss=0.486, total=4157.94, n_correct=2667.45, ppl=6.21, accuracy=64.153, wps=6897.6, ups=1.66, wpb=4157.9, bsz=152.5, num_updates=23900, lr=9.14779e-05, gnorm=0.963, clip=0, loss_scale=32, train_wall=60, gb_free=14.8, wall=20217
2023-07-13 21:19:34 | INFO | train_inner | epoch 017:    428 / 1474 loss=3.93, trans_loss=5.369, nll_loss=2.674, w2v_ctc_loss=1.266, task_loss=25.365, contrastive_loss=0.226, total=4141.8, n_correct=2643.99, ppl=6.38, accuracy=63.837, wps=6773, ups=1.64, wpb=4141.8, bsz=153.3, num_updates=24000, lr=9.12871e-05, gnorm=1.031, clip=0, loss_scale=32, train_wall=61, gb_free=17.5, wall=20278
2023-07-13 21:19:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 21:19:59 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.308 | trans_loss 5.634 | nll_loss 2.93 | w2v_ctc_loss 1.343 | task_loss 42.312 | contrastive_loss 0.459 | total 4003.4 | n_correct 2437.7 | ppl 7.62 | accuracy 60.891 | uer 17.057 | wer 18.862 | raw_wer 18.862 | bleu 18.89 | wps 2297.6 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 20.11
2023-07-13 21:19:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-07-13 21:19:59 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_17_24000.pt
2023-07-13 21:20:01 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_17_24000.pt
2023-07-13 21:20:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 18.89) (writing took 5.145391852012835 seconds)
2023-07-13 21:21:06 | INFO | train_inner | epoch 017:    528 / 1474 loss=4.144, trans_loss=5.533, nll_loss=2.884, w2v_ctc_loss=1.311, task_loss=20.998, contrastive_loss=0.603, total=4180.09, n_correct=2548.32, ppl=7.38, accuracy=60.963, wps=4560.1, ups=1.09, wpb=4180.1, bsz=153.8, num_updates=24100, lr=9.10975e-05, gnorm=1.577, clip=0, loss_scale=32, train_wall=61, gb_free=17.3, wall=20369
2023-07-13 21:22:07 | INFO | train_inner | epoch 017:    628 / 1474 loss=3.918, trans_loss=5.378, nll_loss=2.684, w2v_ctc_loss=1.265, task_loss=16.153, contrastive_loss=0.144, total=4166.6, n_correct=2644.97, ppl=6.42, accuracy=63.48, wps=6835.5, ups=1.64, wpb=4166.6, bsz=151.1, num_updates=24200, lr=9.09091e-05, gnorm=0.972, clip=0, loss_scale=32, train_wall=61, gb_free=15.9, wall=20430
2023-07-13 21:23:08 | INFO | train_inner | epoch 017:    728 / 1474 loss=3.917, trans_loss=5.37, nll_loss=2.674, w2v_ctc_loss=1.285, task_loss=15.811, contrastive_loss=0.223, total=4168.97, n_correct=2652.35, ppl=6.38, accuracy=63.621, wps=6871.3, ups=1.65, wpb=4169, bsz=154.2, num_updates=24300, lr=9.07218e-05, gnorm=0.973, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=20491
2023-07-13 21:24:08 | INFO | train_inner | epoch 017:    828 / 1474 loss=3.905, trans_loss=5.361, nll_loss=2.662, w2v_ctc_loss=1.277, task_loss=16.135, contrastive_loss=0.146, total=4097.38, n_correct=2615.17, ppl=6.33, accuracy=63.825, wps=6786.1, ups=1.66, wpb=4097.4, bsz=148.7, num_updates=24400, lr=9.05357e-05, gnorm=0.956, clip=0, loss_scale=32, train_wall=60, gb_free=11, wall=20551
2023-07-13 21:25:08 | INFO | train_inner | epoch 017:    928 / 1474 loss=3.88, trans_loss=5.345, nll_loss=2.642, w2v_ctc_loss=1.246, task_loss=15.813, contrastive_loss=0.138, total=4105.01, n_correct=2629.02, ppl=6.24, accuracy=64.044, wps=6889.1, ups=1.68, wpb=4105, bsz=152.1, num_updates=24500, lr=9.03508e-05, gnorm=0.962, clip=0, loss_scale=32, train_wall=59, gb_free=16.8, wall=20611
2023-07-13 21:26:08 | INFO | train_inner | epoch 017:   1028 / 1474 loss=3.892, trans_loss=5.351, nll_loss=2.651, w2v_ctc_loss=1.27, task_loss=15.997, contrastive_loss=0.144, total=4105.88, n_correct=2625.47, ppl=6.28, accuracy=63.944, wps=6797.9, ups=1.66, wpb=4105.9, bsz=151.7, num_updates=24600, lr=9.0167e-05, gnorm=0.962, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=20671
2023-07-13 21:27:08 | INFO | train_inner | epoch 017:   1128 / 1474 loss=3.885, trans_loss=5.347, nll_loss=2.646, w2v_ctc_loss=1.251, task_loss=16.367, contrastive_loss=0.126, total=4095.58, n_correct=2619.42, ppl=6.26, accuracy=63.957, wps=6816.6, ups=1.66, wpb=4095.6, bsz=149.3, num_updates=24700, lr=8.99843e-05, gnorm=0.965, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=20731
2023-07-13 21:28:09 | INFO | train_inner | epoch 017:   1228 / 1474 loss=3.926, trans_loss=5.376, nll_loss=2.685, w2v_ctc_loss=1.262, task_loss=15.768, contrastive_loss=0.604, total=4162.14, n_correct=2644.2, ppl=6.43, accuracy=63.53, wps=6785.6, ups=1.63, wpb=4162.1, bsz=160.1, num_updates=24800, lr=8.98027e-05, gnorm=0.968, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=20793
2023-07-13 21:29:10 | INFO | train_inner | epoch 017:   1328 / 1474 loss=3.9, trans_loss=5.358, nll_loss=2.661, w2v_ctc_loss=1.251, task_loss=15.938, contrastive_loss=0.284, total=4149.03, n_correct=2647.42, ppl=6.32, accuracy=63.808, wps=6810.6, ups=1.64, wpb=4149, bsz=153.4, num_updates=24900, lr=8.96221e-05, gnorm=0.96, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=20854
2023-07-13 21:30:11 | INFO | train_inner | epoch 017:   1428 / 1474 loss=3.886, trans_loss=5.352, nll_loss=2.653, w2v_ctc_loss=1.252, task_loss=16.201, contrastive_loss=0.123, total=4117.13, n_correct=2630.81, ppl=6.29, accuracy=63.899, wps=6757, ups=1.64, wpb=4117.1, bsz=151.9, num_updates=25000, lr=8.94427e-05, gnorm=0.95, clip=0, loss_scale=32, train_wall=61, gb_free=17.6, wall=20915
asr_weight tensor(0.0260, device='cuda:0')
mt_weight tensor(0.0016, device='cuda:0')
2023-07-13 21:30:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
asr_weight tensor(0.0260, device='cuda:4')
mt_weight tensor(0.0016, device='cuda:4')
asr_weight tensor(0.0260, device='cuda:6')
mt_weight tensor(0.0016, device='cuda:6')
asr_weight tensor(0.0260, device='cuda:7')
mt_weight tensor(0.0016, device='cuda:7')
asr_weight tensor(0.0260, device='cuda:5')
mt_weight tensor(0.0016, device='cuda:5')
asr_weight tensor(0.0260, device='cuda:2')
mt_weight tensor(0.0016, device='cuda:2')
asr_weight tensor(0.0260, device='cuda:3')
mt_weight tensor(0.0016, device='cuda:3')
asr_weight tensor(0.0260, device='cuda:1')
mt_weight tensor(0.0016, device='cuda:1')
2023-07-13 21:31:08 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.204 | trans_loss 5.579 | nll_loss 2.86 | w2v_ctc_loss 1.328 | task_loss 23.085 | contrastive_loss 0.262 | total 4003.4 | n_correct 2464.3 | ppl 7.26 | accuracy 61.555 | uer 17.211 | wer 18.963 | raw_wer 18.963 | bleu 19.68 | wps 1881.2 | wpb 4003.4 | bsz 141.8 | num_updates 25046 | best_bleu 20.11
2023-07-13 21:31:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25046 updates
2023-07-13 21:31:08 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_19.6800.pt
2023-07-13 21:31:10 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_19.6800.pt
2023-07-13 21:31:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_19.6800.pt (epoch 17 @ 25046 updates, score 19.68) (writing took 5.413773325970396 seconds)
2023-07-13 21:31:14 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-07-13 21:31:14 | INFO | train | epoch 017 | loss 3.916 | trans_loss 5.367 | nll_loss 2.671 | w2v_ctc_loss 1.265 | task_loss 17.846 | contrastive_loss 0.253 | total 4136.62 | n_correct 2634.78 | ppl 6.37 | accuracy 63.694 | wps 6299.4 | ups 1.52 | wpb 4136.6 | bsz 152.5 | num_updates 25046 | lr 8.93605e-05 | gnorm 1.013 | clip 0 | loss_scale 32 | train_wall 889 | gb_free 16.6 | wall 20977
2023-07-13 21:31:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 21:31:14 | INFO | fairseq.trainer | begin training epoch 18
2023-07-13 21:31:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 21:31:55 | INFO | train_inner | epoch 018:     54 / 1474 loss=3.882, trans_loss=5.336, nll_loss=2.632, w2v_ctc_loss=1.26, task_loss=16.355, contrastive_loss=0.144, total=4138.21, n_correct=2656.12, ppl=6.2, accuracy=64.185, wps=3972.7, ups=0.96, wpb=4138.2, bsz=151.6, num_updates=25100, lr=8.92644e-05, gnorm=0.962, clip=0, loss_scale=32, train_wall=61, gb_free=17.8, wall=21019
2023-07-13 21:32:56 | INFO | train_inner | epoch 018:    154 / 1474 loss=3.861, trans_loss=5.311, nll_loss=2.599, w2v_ctc_loss=1.211, task_loss=15.203, contrastive_loss=0.392, total=4158.88, n_correct=2686.05, ppl=6.06, accuracy=64.586, wps=6888.4, ups=1.66, wpb=4158.9, bsz=157, num_updates=25200, lr=8.90871e-05, gnorm=0.947, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=21079
2023-07-13 21:33:57 | INFO | train_inner | epoch 018:    254 / 1474 loss=3.848, trans_loss=5.308, nll_loss=2.595, w2v_ctc_loss=1.235, task_loss=15.572, contrastive_loss=0.125, total=4164.11, n_correct=2693.15, ppl=6.04, accuracy=64.675, wps=6815.5, ups=1.64, wpb=4164.1, bsz=156.2, num_updates=25300, lr=8.89108e-05, gnorm=0.951, clip=0, loss_scale=32, train_wall=61, gb_free=15.2, wall=21140
2023-07-13 21:34:58 | INFO | train_inner | epoch 018:    354 / 1474 loss=3.867, trans_loss=5.319, nll_loss=2.609, w2v_ctc_loss=1.238, task_loss=16.327, contrastive_loss=0.154, total=4163.13, n_correct=2681.68, ppl=6.1, accuracy=64.415, wps=6847.3, ups=1.64, wpb=4163.1, bsz=150.7, num_updates=25400, lr=8.87357e-05, gnorm=0.958, clip=0, loss_scale=32, train_wall=60, gb_free=17.7, wall=21201
2023-07-13 21:35:59 | INFO | train_inner | epoch 018:    454 / 1474 loss=3.895, trans_loss=5.338, nll_loss=2.634, w2v_ctc_loss=1.256, task_loss=17.159, contrastive_loss=0.338, total=4087.83, n_correct=2624.26, ppl=6.21, accuracy=64.197, wps=6652.6, ups=1.63, wpb=4087.8, bsz=147.7, num_updates=25500, lr=8.85615e-05, gnorm=0.962, clip=0, loss_scale=32, train_wall=61, gb_free=16.5, wall=21263
2023-07-13 21:37:00 | INFO | train_inner | epoch 018:    554 / 1474 loss=3.837, trans_loss=5.305, nll_loss=2.593, w2v_ctc_loss=1.228, task_loss=14.444, contrastive_loss=0.149, total=4204.41, n_correct=2719.18, ppl=6.03, accuracy=64.674, wps=6921.8, ups=1.65, wpb=4204.4, bsz=164, num_updates=25600, lr=8.83883e-05, gnorm=0.94, clip=0, loss_scale=32, train_wall=60, gb_free=17.5, wall=21323
2023-07-13 21:38:00 | INFO | train_inner | epoch 018:    654 / 1474 loss=3.892, trans_loss=5.343, nll_loss=2.641, w2v_ctc_loss=1.254, task_loss=16.551, contrastive_loss=0.289, total=4096.81, n_correct=2625.12, ppl=6.24, accuracy=64.077, wps=6832.9, ups=1.67, wpb=4096.8, bsz=149.4, num_updates=25700, lr=8.82162e-05, gnorm=0.96, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=21383
2023-07-13 21:39:00 | INFO | train_inner | epoch 018:    754 / 1474 loss=3.89, trans_loss=5.337, nll_loss=2.633, w2v_ctc_loss=1.263, task_loss=15.28, contrastive_loss=0.472, total=4208.29, n_correct=2700.61, ppl=6.21, accuracy=64.174, wps=6937.3, ups=1.65, wpb=4208.3, bsz=161.4, num_updates=25800, lr=8.80451e-05, gnorm=0.939, clip=0, loss_scale=64, train_wall=60, gb_free=17.9, wall=21444
2023-07-13 21:40:01 | INFO | train_inner | epoch 018:    854 / 1474 loss=3.873, trans_loss=5.33, nll_loss=2.625, w2v_ctc_loss=1.247, task_loss=16.257, contrastive_loss=0.107, total=4166.81, n_correct=2680.63, ppl=6.17, accuracy=64.333, wps=6854.5, ups=1.65, wpb=4166.8, bsz=151, num_updates=25900, lr=8.7875e-05, gnorm=0.95, clip=0, loss_scale=64, train_wall=60, gb_free=13, wall=21505
2023-07-13 21:41:01 | INFO | train_inner | epoch 018:    954 / 1474 loss=3.855, trans_loss=5.323, nll_loss=2.616, w2v_ctc_loss=1.23, task_loss=14.871, contrastive_loss=0.153, total=4142.65, n_correct=2668.75, ppl=6.13, accuracy=64.421, wps=6950.2, ups=1.68, wpb=4142.6, bsz=158, num_updates=26000, lr=8.77058e-05, gnorm=0.957, clip=0, loss_scale=64, train_wall=59, gb_free=15.1, wall=21564
2023-07-13 21:41:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 21:41:29 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.2 | trans_loss 5.572 | nll_loss 2.848 | w2v_ctc_loss 1.333 | task_loss 23.061 | contrastive_loss 0.256 | total 4003.4 | n_correct 2471.9 | ppl 7.2 | accuracy 61.745 | uer 17.057 | wer 18.892 | raw_wer 18.892 | bleu 19.75 | wps 1915.1 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 20.11
2023-07-13 21:41:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-07-13 21:41:29 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_18_26000.pt
2023-07-13 21:41:31 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_18_26000.pt
2023-07-13 21:41:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 19.75) (writing took 6.258131183101796 seconds)
2023-07-13 21:42:37 | INFO | train_inner | epoch 018:   1054 / 1474 loss=3.871, trans_loss=5.331, nll_loss=2.626, w2v_ctc_loss=1.236, task_loss=16.736, contrastive_loss=0.129, total=4137.77, n_correct=2658.35, ppl=6.17, accuracy=64.246, wps=4310.3, ups=1.04, wpb=4137.8, bsz=150.2, num_updates=26100, lr=8.75376e-05, gnorm=0.947, clip=0, loss_scale=64, train_wall=61, gb_free=17.5, wall=21660
2023-07-13 21:43:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-13 21:43:38 | INFO | train_inner | epoch 018:   1155 / 1474 loss=3.876, trans_loss=5.324, nll_loss=2.618, w2v_ctc_loss=1.248, task_loss=15.224, contrastive_loss=0.342, total=4153.75, n_correct=2674.9, ppl=6.14, accuracy=64.397, wps=6791.8, ups=1.64, wpb=4153.8, bsz=157.1, num_updates=26200, lr=8.73704e-05, gnorm=0.951, clip=0, loss_scale=32, train_wall=61, gb_free=15.2, wall=21722
2023-07-13 21:44:38 | INFO | train_inner | epoch 018:   1255 / 1474 loss=3.891, trans_loss=5.342, nll_loss=2.64, w2v_ctc_loss=1.258, task_loss=17.191, contrastive_loss=0.119, total=4089.17, n_correct=2618.94, ppl=6.23, accuracy=64.046, wps=6778.8, ups=1.66, wpb=4089.2, bsz=143.8, num_updates=26300, lr=8.72041e-05, gnorm=0.96, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=21782
2023-07-13 21:45:39 | INFO | train_inner | epoch 018:   1355 / 1474 loss=3.91, trans_loss=5.356, nll_loss=2.66, w2v_ctc_loss=1.289, task_loss=17.157, contrastive_loss=0.171, total=4068.84, n_correct=2599.63, ppl=6.32, accuracy=63.891, wps=6765.4, ups=1.66, wpb=4068.8, bsz=145.7, num_updates=26400, lr=8.70388e-05, gnorm=0.969, clip=0, loss_scale=32, train_wall=60, gb_free=15.6, wall=21842
2023-07-13 21:46:39 | INFO | train_inner | epoch 018:   1455 / 1474 loss=3.888, trans_loss=5.342, nll_loss=2.64, w2v_ctc_loss=1.264, task_loss=17.017, contrastive_loss=0.139, total=4113.23, n_correct=2633.22, ppl=6.24, accuracy=64.018, wps=6760.7, ups=1.64, wpb=4113.2, bsz=148.6, num_updates=26500, lr=8.68744e-05, gnorm=0.963, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=21903
2023-07-13 21:46:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 21:47:18 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.206 | trans_loss 5.57 | nll_loss 2.847 | w2v_ctc_loss 1.357 | task_loss 23.106 | contrastive_loss 0.256 | total 4003.4 | n_correct 2468.7 | ppl 7.2 | accuracy 61.665 | uer 17.124 | wer 19.004 | raw_wer 19.004 | bleu 19.73 | wps 1951 | wpb 4003.4 | bsz 141.8 | num_updates 26519 | best_bleu 20.11
2023-07-13 21:47:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26519 updates
2023-07-13 21:47:18 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_19.7305.pt
2023-07-13 21:47:20 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_19.7305.pt
2023-07-13 21:47:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_19.7305.pt (epoch 18 @ 26519 updates, score 19.73) (writing took 5.279373056953773 seconds)
2023-07-13 21:47:23 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-07-13 21:47:23 | INFO | train | epoch 018 | loss 3.875 | trans_loss 5.329 | nll_loss 2.623 | w2v_ctc_loss 1.246 | task_loss 16.037 | contrastive_loss 0.226 | total 4138.76 | n_correct 2661.2 | ppl 6.16 | accuracy 64.299 | wps 6288.8 | ups 1.52 | wpb 4138.8 | bsz 152.8 | num_updates 26519 | lr 8.68433e-05 | gnorm 0.954 | clip 0 | loss_scale 32 | train_wall 888 | gb_free 16.1 | wall 21946
2023-07-13 21:47:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 21:47:23 | INFO | fairseq.trainer | begin training epoch 19
2023-07-13 21:47:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 21:48:20 | INFO | train_inner | epoch 019:     81 / 1474 loss=3.858, trans_loss=5.303, nll_loss=2.59, w2v_ctc_loss=1.228, task_loss=15.95, contrastive_loss=0.239, total=4107.26, n_correct=2654.67, ppl=6.02, accuracy=64.634, wps=4085, ups=0.99, wpb=4107.3, bsz=148.8, num_updates=26600, lr=8.6711e-05, gnorm=0.962, clip=0, loss_scale=32, train_wall=60, gb_free=13.1, wall=22003
2023-07-13 21:49:22 | INFO | train_inner | epoch 019:    181 / 1474 loss=3.846, trans_loss=5.297, nll_loss=2.582, w2v_ctc_loss=1.242, task_loss=14.978, contrastive_loss=0.221, total=4222.18, n_correct=2737.96, ppl=5.99, accuracy=64.847, wps=6852.7, ups=1.62, wpb=4222.2, bsz=162.2, num_updates=26700, lr=8.65485e-05, gnorm=0.944, clip=0, loss_scale=32, train_wall=61, gb_free=12.1, wall=22065
2023-07-13 21:50:22 | INFO | train_inner | epoch 019:    281 / 1474 loss=3.832, trans_loss=5.284, nll_loss=2.565, w2v_ctc_loss=1.219, task_loss=15.777, contrastive_loss=0.11, total=4187.37, n_correct=2724.46, ppl=5.92, accuracy=65.064, wps=6913.9, ups=1.65, wpb=4187.4, bsz=153.5, num_updates=26800, lr=8.63868e-05, gnorm=0.939, clip=0, loss_scale=32, train_wall=60, gb_free=17.6, wall=22126
2023-07-13 21:51:22 | INFO | train_inner | epoch 019:    381 / 1474 loss=3.85, trans_loss=5.296, nll_loss=2.581, w2v_ctc_loss=1.216, task_loss=15.827, contrastive_loss=0.325, total=4170.67, n_correct=2701.68, ppl=5.99, accuracy=64.778, wps=6910.4, ups=1.66, wpb=4170.7, bsz=155.3, num_updates=26900, lr=8.62261e-05, gnorm=0.954, clip=0, loss_scale=32, train_wall=60, gb_free=17.3, wall=22186
2023-07-13 21:52:23 | INFO | train_inner | epoch 019:    481 / 1474 loss=3.855, trans_loss=5.307, nll_loss=2.595, w2v_ctc_loss=1.24, task_loss=16.413, contrastive_loss=0.14, total=4115.22, n_correct=2661.35, ppl=6.04, accuracy=64.671, wps=6822.8, ups=1.66, wpb=4115.2, bsz=150.9, num_updates=27000, lr=8.60663e-05, gnorm=0.957, clip=0, loss_scale=32, train_wall=60, gb_free=15.4, wall=22246
2023-07-13 21:53:23 | INFO | train_inner | epoch 019:    581 / 1474 loss=3.849, trans_loss=5.299, nll_loss=2.585, w2v_ctc_loss=1.223, task_loss=15.694, contrastive_loss=0.268, total=4129.22, n_correct=2676.47, ppl=6, accuracy=64.818, wps=6824.5, ups=1.65, wpb=4129.2, bsz=153, num_updates=27100, lr=8.59074e-05, gnorm=0.96, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=22307
2023-07-13 21:54:24 | INFO | train_inner | epoch 019:    681 / 1474 loss=3.832, trans_loss=5.301, nll_loss=2.588, w2v_ctc_loss=1.211, task_loss=14.603, contrastive_loss=0.124, total=4197.2, n_correct=2719.36, ppl=6.01, accuracy=64.79, wps=6919.1, ups=1.65, wpb=4197.2, bsz=160.4, num_updates=27200, lr=8.57493e-05, gnorm=0.942, clip=0, loss_scale=32, train_wall=60, gb_free=14.9, wall=22367
2023-07-13 21:55:25 | INFO | train_inner | epoch 019:    781 / 1474 loss=3.854, trans_loss=5.306, nll_loss=2.593, w2v_ctc_loss=1.243, task_loss=16.185, contrastive_loss=0.145, total=4142.6, n_correct=2677.22, ppl=6.03, accuracy=64.627, wps=6761.1, ups=1.63, wpb=4142.6, bsz=152.5, num_updates=27300, lr=8.55921e-05, gnorm=0.95, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=22429
2023-07-13 21:56:26 | INFO | train_inner | epoch 019:    881 / 1474 loss=3.865, trans_loss=5.32, nll_loss=2.612, w2v_ctc_loss=1.248, task_loss=16.414, contrastive_loss=0.115, total=4153.47, n_correct=2674.77, ppl=6.11, accuracy=64.398, wps=6869.2, ups=1.65, wpb=4153.5, bsz=151.5, num_updates=27400, lr=8.54358e-05, gnorm=0.951, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=22489
2023-07-13 21:57:27 | INFO | train_inner | epoch 019:    981 / 1474 loss=3.888, trans_loss=5.332, nll_loss=2.629, w2v_ctc_loss=1.234, task_loss=16.026, contrastive_loss=0.584, total=4101.29, n_correct=2634.74, ppl=6.18, accuracy=64.242, wps=6690, ups=1.63, wpb=4101.3, bsz=155, num_updates=27500, lr=8.52803e-05, gnorm=0.969, clip=0, loss_scale=32, train_wall=61, gb_free=16.8, wall=22550
2023-07-13 21:58:28 | INFO | train_inner | epoch 019:   1081 / 1474 loss=3.884, trans_loss=5.335, nll_loss=2.632, w2v_ctc_loss=1.249, task_loss=17.177, contrastive_loss=0.203, total=4036.97, n_correct=2593.58, ppl=6.2, accuracy=64.246, wps=6601.3, ups=1.64, wpb=4037, bsz=145.5, num_updates=27600, lr=8.51257e-05, gnorm=0.982, clip=0, loss_scale=32, train_wall=61, gb_free=14.9, wall=22612
2023-07-13 21:59:29 | INFO | train_inner | epoch 019:   1181 / 1474 loss=3.885, trans_loss=5.329, nll_loss=2.624, w2v_ctc_loss=1.25, task_loss=16.24, contrastive_loss=0.368, total=4137.49, n_correct=2655.26, ppl=6.16, accuracy=64.176, wps=6753, ups=1.63, wpb=4137.5, bsz=153.8, num_updates=27700, lr=8.49719e-05, gnorm=0.969, clip=0, loss_scale=32, train_wall=61, gb_free=15.1, wall=22673
2023-07-13 22:00:30 | INFO | train_inner | epoch 019:   1281 / 1474 loss=3.874, trans_loss=5.33, nll_loss=2.626, w2v_ctc_loss=1.237, task_loss=16.244, contrastive_loss=0.163, total=4141.89, n_correct=2660.57, ppl=6.17, accuracy=64.236, wps=6863.9, ups=1.66, wpb=4141.9, bsz=150.1, num_updates=27800, lr=8.48189e-05, gnorm=0.951, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=22733
2023-07-13 22:01:31 | INFO | train_inner | epoch 019:   1381 / 1474 loss=3.86, trans_loss=5.314, nll_loss=2.606, w2v_ctc_loss=1.238, task_loss=16.418, contrastive_loss=0.133, total=4133.26, n_correct=2665.74, ppl=6.09, accuracy=64.495, wps=6774.5, ups=1.64, wpb=4133.3, bsz=150.5, num_updates=27900, lr=8.46668e-05, gnorm=0.954, clip=0, loss_scale=32, train_wall=61, gb_free=16.4, wall=22794
2023-07-13 22:02:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 22:02:54 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.215 | trans_loss 5.575 | nll_loss 2.853 | w2v_ctc_loss 1.376 | task_loss 23.124 | contrastive_loss 0.259 | total 4003.4 | n_correct 2472.4 | ppl 7.22 | accuracy 61.758 | uer 17.36 | wer 19.082 | raw_wer 19.082 | bleu 19.71 | wps 1919 | wpb 4003.4 | bsz 141.8 | num_updates 27993 | best_bleu 20.11
2023-07-13 22:02:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27993 updates
2023-07-13 22:02:54 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_19.7107.pt
2023-07-13 22:02:56 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_19.7107.pt
2023-07-13 22:02:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_19.7107.pt (epoch 19 @ 27993 updates, score 19.71) (writing took 5.227147971978411 seconds)
2023-07-13 22:03:00 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-07-13 22:03:00 | INFO | train | epoch 019 | loss 3.859 | trans_loss 5.311 | nll_loss 2.6 | w2v_ctc_loss 1.235 | task_loss 16.039 | contrastive_loss 0.223 | total 4138.65 | n_correct 2672.65 | ppl 6.06 | accuracy 64.578 | wps 6512.7 | ups 1.57 | wpb 4138.6 | bsz 152.8 | num_updates 27993 | lr 8.4526e-05 | gnorm 0.957 | clip 0 | loss_scale 32 | train_wall 890 | gb_free 17.5 | wall 22883
2023-07-13 22:03:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 22:03:00 | INFO | fairseq.trainer | begin training epoch 20
2023-07-13 22:03:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 22:03:12 | INFO | train_inner | epoch 020:      7 / 1474 loss=3.862, trans_loss=5.311, nll_loss=2.602, w2v_ctc_loss=1.23, task_loss=16.236, contrastive_loss=0.301, total=4119.08, n_correct=2658.41, ppl=6.07, accuracy=64.539, wps=4056.4, ups=0.98, wpb=4119.1, bsz=152.1, num_updates=28000, lr=8.45154e-05, gnorm=0.966, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=22896
2023-07-13 22:03:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 22:03:41 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.199 | trans_loss 5.575 | nll_loss 2.85 | w2v_ctc_loss 1.325 | task_loss 23.047 | contrastive_loss 0.257 | total 4003.4 | n_correct 2476.6 | ppl 7.21 | accuracy 61.862 | uer 17.06 | wer 18.802 | raw_wer 18.802 | bleu 19.71 | wps 1799 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.11
2023-07-13 22:03:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-07-13 22:03:41 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_20_28000.pt
2023-07-13 22:03:43 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_20_28000.pt
2023-07-13 22:03:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 19.71) (writing took 6.3821282589342445 seconds)
2023-07-13 22:04:48 | INFO | train_inner | epoch 020:    107 / 1474 loss=3.816, trans_loss=5.269, nll_loss=2.546, w2v_ctc_loss=1.207, task_loss=15.446, contrastive_loss=0.145, total=4195.03, n_correct=2736.44, ppl=5.84, accuracy=65.231, wps=4380, ups=1.04, wpb=4195, bsz=156.8, num_updates=28100, lr=8.43649e-05, gnorm=0.946, clip=0, loss_scale=32, train_wall=60, gb_free=15.3, wall=22992
2023-07-13 22:05:49 | INFO | train_inner | epoch 020:    207 / 1474 loss=3.835, trans_loss=5.278, nll_loss=2.557, w2v_ctc_loss=1.212, task_loss=16.656, contrastive_loss=0.249, total=4154.14, n_correct=2704.87, ppl=5.88, accuracy=65.113, wps=6828.5, ups=1.64, wpb=4154.1, bsz=150.5, num_updates=28200, lr=8.42152e-05, gnorm=0.953, clip=0, loss_scale=32, train_wall=60, gb_free=17.4, wall=23052
2023-07-13 22:06:50 | INFO | train_inner | epoch 020:    307 / 1474 loss=3.808, trans_loss=5.27, nll_loss=2.548, w2v_ctc_loss=1.21, task_loss=14.477, contrastive_loss=0.129, total=4188.05, n_correct=2733.47, ppl=5.85, accuracy=65.268, wps=6894.1, ups=1.65, wpb=4188.1, bsz=163.1, num_updates=28300, lr=8.40663e-05, gnorm=0.952, clip=0, loss_scale=64, train_wall=60, gb_free=15.7, wall=23113
2023-07-13 22:07:50 | INFO | train_inner | epoch 020:    407 / 1474 loss=3.827, trans_loss=5.277, nll_loss=2.556, w2v_ctc_loss=1.206, task_loss=16.288, contrastive_loss=0.124, total=4115.16, n_correct=2679.5, ppl=5.88, accuracy=65.113, wps=6787.5, ups=1.65, wpb=4115.2, bsz=148.5, num_updates=28400, lr=8.39181e-05, gnorm=0.953, clip=0, loss_scale=64, train_wall=60, gb_free=15.7, wall=23174
2023-07-13 22:08:52 | INFO | train_inner | epoch 020:    507 / 1474 loss=3.851, trans_loss=5.298, nll_loss=2.584, w2v_ctc_loss=1.216, task_loss=16.398, contrastive_loss=0.3, total=4108.46, n_correct=2663.79, ppl=6, accuracy=64.837, wps=6718.7, ups=1.64, wpb=4108.5, bsz=150.2, num_updates=28500, lr=8.37708e-05, gnorm=0.954, clip=0, loss_scale=64, train_wall=61, gb_free=16.6, wall=23235
2023-07-13 22:09:52 | INFO | train_inner | epoch 020:    607 / 1474 loss=3.858, trans_loss=5.299, nll_loss=2.585, w2v_ctc_loss=1.222, task_loss=16.848, contrastive_loss=0.303, total=4094.9, n_correct=2649.52, ppl=6, accuracy=64.703, wps=6815.4, ups=1.66, wpb=4094.9, bsz=148, num_updates=28600, lr=8.36242e-05, gnorm=0.961, clip=0, loss_scale=64, train_wall=60, gb_free=12.4, wall=23295
2023-07-13 22:10:52 | INFO | train_inner | epoch 020:    707 / 1474 loss=3.845, trans_loss=5.296, nll_loss=2.581, w2v_ctc_loss=1.23, task_loss=15.985, contrastive_loss=0.113, total=4140.23, n_correct=2683.81, ppl=5.99, accuracy=64.823, wps=6847.7, ups=1.65, wpb=4140.2, bsz=150.3, num_updates=28700, lr=8.34784e-05, gnorm=0.956, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=23355
2023-07-13 22:11:52 | INFO | train_inner | epoch 020:    807 / 1474 loss=3.835, trans_loss=5.289, nll_loss=2.573, w2v_ctc_loss=1.223, task_loss=15.889, contrastive_loss=0.117, total=4140.66, n_correct=2691.92, ppl=5.95, accuracy=65.012, wps=6893.3, ups=1.66, wpb=4140.7, bsz=152.8, num_updates=28800, lr=8.33333e-05, gnorm=0.949, clip=0, loss_scale=64, train_wall=60, gb_free=17.6, wall=23416
2023-07-13 22:12:54 | INFO | train_inner | epoch 020:    907 / 1474 loss=3.872, trans_loss=5.311, nll_loss=2.602, w2v_ctc_loss=1.214, task_loss=15.326, contrastive_loss=0.698, total=4157.15, n_correct=2688.01, ppl=6.07, accuracy=64.66, wps=6748.9, ups=1.62, wpb=4157.1, bsz=161.3, num_updates=28900, lr=8.3189e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=61, gb_free=17.8, wall=23477
2023-07-13 22:13:55 | INFO | train_inner | epoch 020:   1007 / 1474 loss=3.835, trans_loss=5.293, nll_loss=2.578, w2v_ctc_loss=1.213, task_loss=15.894, contrastive_loss=0.128, total=4171.86, n_correct=2707.63, ppl=5.97, accuracy=64.902, wps=6789.9, ups=1.63, wpb=4171.9, bsz=154.3, num_updates=29000, lr=8.30455e-05, gnorm=0.951, clip=0, loss_scale=64, train_wall=61, gb_free=16.2, wall=23539
2023-07-13 22:14:56 | INFO | train_inner | epoch 020:   1107 / 1474 loss=3.858, trans_loss=5.305, nll_loss=2.595, w2v_ctc_loss=1.216, task_loss=15.435, contrastive_loss=0.402, total=4162.96, n_correct=2694.11, ppl=6.04, accuracy=64.716, wps=6831.8, ups=1.64, wpb=4163, bsz=157.5, num_updates=29100, lr=8.29027e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=61, gb_free=17.2, wall=23600
2023-07-13 22:15:56 | INFO | train_inner | epoch 020:   1207 / 1474 loss=3.858, trans_loss=5.299, nll_loss=2.585, w2v_ctc_loss=1.249, task_loss=17.585, contrastive_loss=0.108, total=4033.74, n_correct=2610.16, ppl=6, accuracy=64.708, wps=6687, ups=1.66, wpb=4033.7, bsz=142.6, num_updates=29200, lr=8.27606e-05, gnorm=0.976, clip=0, loss_scale=64, train_wall=60, gb_free=17.4, wall=23660
2023-07-13 22:16:57 | INFO | train_inner | epoch 020:   1307 / 1474 loss=3.853, trans_loss=5.305, nll_loss=2.595, w2v_ctc_loss=1.229, task_loss=16.989, contrastive_loss=0.118, total=4124.42, n_correct=2667, ppl=6.04, accuracy=64.664, wps=6787.7, ups=1.65, wpb=4124.4, bsz=148.5, num_updates=29300, lr=8.26192e-05, gnorm=0.972, clip=0, loss_scale=64, train_wall=60, gb_free=16.2, wall=23721
2023-07-13 22:17:58 | INFO | train_inner | epoch 020:   1407 / 1474 loss=3.856, trans_loss=5.306, nll_loss=2.595, w2v_ctc_loss=1.234, task_loss=17.047, contrastive_loss=0.114, total=4114.1, n_correct=2656.99, ppl=6.04, accuracy=64.583, wps=6797.3, ups=1.65, wpb=4114.1, bsz=146.8, num_updates=29400, lr=8.24786e-05, gnorm=0.97, clip=0, loss_scale=64, train_wall=60, gb_free=14.7, wall=23781
2023-07-13 22:18:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 22:19:07 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.169 | trans_loss 5.563 | nll_loss 2.841 | w2v_ctc_loss 1.253 | task_loss 23.156 | contrastive_loss 0.252 | total 4003.4 | n_correct 2473.2 | ppl 7.17 | accuracy 61.777 | uer 16.771 | wer 18.575 | raw_wer 18.575 | bleu 20.06 | wps 1768.6 | wpb 4003.4 | bsz 141.8 | num_updates 29467 | best_bleu 20.11
2023-07-13 22:19:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29467 updates
2023-07-13 22:19:07 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.0603.pt
2023-07-13 22:19:09 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.0603.pt
2023-07-13 22:19:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.0603.pt (epoch 20 @ 29467 updates, score 20.06) (writing took 5.4537122109904885 seconds)
2023-07-13 22:19:13 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-07-13 22:19:13 | INFO | train | epoch 020 | loss 3.843 | trans_loss 5.293 | nll_loss 2.578 | w2v_ctc_loss 1.22 | task_loss 16.032 | contrastive_loss 0.219 | total 4138.65 | n_correct 2684.78 | ppl 5.97 | accuracy 64.871 | wps 6270.6 | ups 1.52 | wpb 4138.6 | bsz 152.8 | num_updates 29467 | lr 8.23848e-05 | gnorm 0.959 | clip 0 | loss_scale 64 | train_wall 888 | gb_free 16.8 | wall 23856
2023-07-13 22:19:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 22:19:13 | INFO | fairseq.trainer | begin training epoch 21
2023-07-13 22:19:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 22:19:41 | INFO | train_inner | epoch 021:     33 / 1474 loss=3.852, trans_loss=5.302, nll_loss=2.592, w2v_ctc_loss=1.223, task_loss=15.122, contrastive_loss=0.355, total=4155.01, n_correct=2689.54, ppl=6.03, accuracy=64.73, wps=4013, ups=0.97, wpb=4155, bsz=158.8, num_updates=29500, lr=8.23387e-05, gnorm=0.971, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=23885
2023-07-13 22:20:42 | INFO | train_inner | epoch 021:    133 / 1474 loss=3.811, trans_loss=5.254, nll_loss=2.527, w2v_ctc_loss=1.187, task_loss=15.164, contrastive_loss=0.339, total=4186.67, n_correct=2740.05, ppl=5.76, accuracy=65.447, wps=6855.2, ups=1.64, wpb=4186.7, bsz=158.7, num_updates=29600, lr=8.21995e-05, gnorm=0.94, clip=0, loss_scale=64, train_wall=61, gb_free=13.4, wall=23946
2023-07-13 22:21:43 | INFO | train_inner | epoch 021:    233 / 1474 loss=3.803, trans_loss=5.259, nll_loss=2.534, w2v_ctc_loss=1.18, task_loss=15.064, contrastive_loss=0.247, total=4166.37, n_correct=2725.68, ppl=5.79, accuracy=65.421, wps=6904, ups=1.66, wpb=4166.4, bsz=157.6, num_updates=29700, lr=8.2061e-05, gnorm=0.956, clip=0, loss_scale=64, train_wall=60, gb_free=14.3, wall=24006
2023-07-13 22:22:44 | INFO | train_inner | epoch 021:    333 / 1474 loss=3.825, trans_loss=5.267, nll_loss=2.544, w2v_ctc_loss=1.212, task_loss=16.3, contrastive_loss=0.246, total=4132.25, n_correct=2696.11, ppl=5.83, accuracy=65.246, wps=6787.7, ups=1.64, wpb=4132.2, bsz=152.5, num_updates=29800, lr=8.19232e-05, gnorm=0.95, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=24067
2023-07-13 22:23:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-13 22:23:44 | INFO | train_inner | epoch 021:    434 / 1474 loss=3.805, trans_loss=5.262, nll_loss=2.538, w2v_ctc_loss=1.189, task_loss=15.28, contrastive_loss=0.11, total=4191.69, n_correct=2742.64, ppl=5.81, accuracy=65.43, wps=6898.3, ups=1.65, wpb=4191.7, bsz=155.5, num_updates=29900, lr=8.17861e-05, gnorm=0.942, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=24128
2023-07-13 22:24:45 | INFO | train_inner | epoch 021:    534 / 1474 loss=3.822, trans_loss=5.266, nll_loss=2.543, w2v_ctc_loss=1.218, task_loss=16.706, contrastive_loss=0.102, total=4083.98, n_correct=2665.23, ppl=5.83, accuracy=65.261, wps=6750.4, ups=1.65, wpb=4084, bsz=147.5, num_updates=30000, lr=8.16497e-05, gnorm=0.965, clip=0, loss_scale=32, train_wall=60, gb_free=13.4, wall=24188
2023-07-13 22:24:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 22:25:11 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.194 | trans_loss 5.564 | nll_loss 2.839 | w2v_ctc_loss 1.334 | task_loss 23.128 | contrastive_loss 0.251 | total 4003.4 | n_correct 2479.4 | ppl 7.15 | accuracy 61.932 | uer 16.71 | wer 18.43 | raw_wer 18.43 | bleu 19.96 | wps 2059.7 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.11
2023-07-13 22:25:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-07-13 22:25:11 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_21_30000.pt
2023-07-13 22:25:13 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_21_30000.pt
2023-07-13 22:25:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 19.96) (writing took 6.353650013916194 seconds)
asr_weight tensor(0.0260, device='cuda:0')
mt_weight tensor(0.0016, device='cuda:0')
2023-07-13 22:26:19 | INFO | train_inner | epoch 021:    634 / 1474 loss=3.827, trans_loss=5.269, nll_loss=2.547, w2v_ctc_loss=1.19, task_loss=15.865, contrastive_loss=0.444, total=4215.41, n_correct=2752.98, ppl=5.85, accuracy=65.308, wps=4488.2, ups=1.06, wpb=4215.4, bsz=157.7, num_updates=30100, lr=8.15139e-05, gnorm=0.939, clip=0, loss_scale=32, train_wall=61, gb_free=11.8, wall=24282
2023-07-13 22:27:20 | INFO | train_inner | epoch 021:    734 / 1474 loss=3.823, trans_loss=5.278, nll_loss=2.559, w2v_ctc_loss=1.2, task_loss=15.973, contrastive_loss=0.167, total=4152.97, n_correct=2704.62, ppl=5.89, accuracy=65.125, wps=6782.6, ups=1.63, wpb=4153, bsz=154.7, num_updates=30200, lr=8.13788e-05, gnorm=0.953, clip=0, loss_scale=32, train_wall=61, gb_free=16.5, wall=24343
2023-07-13 22:28:21 | INFO | train_inner | epoch 021:    834 / 1474 loss=3.842, trans_loss=5.289, nll_loss=2.573, w2v_ctc_loss=1.214, task_loss=16.982, contrastive_loss=0.193, total=4066.93, n_correct=2641.07, ppl=5.95, accuracy=64.94, wps=6642.5, ups=1.63, wpb=4066.9, bsz=147.2, num_updates=30300, lr=8.12444e-05, gnorm=0.972, clip=0, loss_scale=32, train_wall=61, gb_free=17.1, wall=24405
2023-07-13 22:29:21 | INFO | train_inner | epoch 021:    934 / 1474 loss=3.828, trans_loss=5.277, nll_loss=2.558, w2v_ctc_loss=1.214, task_loss=16.036, contrastive_loss=0.141, total=4103.34, n_correct=2668.09, ppl=5.89, accuracy=65.022, wps=6830.7, ups=1.66, wpb=4103.3, bsz=150.5, num_updates=30400, lr=8.11107e-05, gnorm=0.96, clip=0, loss_scale=32, train_wall=60, gb_free=14.3, wall=24465
2023-07-13 22:30:21 | INFO | train_inner | epoch 021:   1034 / 1474 loss=3.846, trans_loss=5.299, nll_loss=2.587, w2v_ctc_loss=1.226, task_loss=16.349, contrastive_loss=0.136, total=4099.86, n_correct=2654.7, ppl=6.01, accuracy=64.751, wps=6831.5, ups=1.67, wpb=4099.9, bsz=149.4, num_updates=30500, lr=8.09776e-05, gnorm=0.969, clip=0, loss_scale=32, train_wall=60, gb_free=11.8, wall=24525
2023-07-13 22:31:22 | INFO | train_inner | epoch 021:   1134 / 1474 loss=3.846, trans_loss=5.288, nll_loss=2.571, w2v_ctc_loss=1.228, task_loss=17.301, contrastive_loss=0.145, total=4120.75, n_correct=2675.43, ppl=5.94, accuracy=64.926, wps=6800.3, ups=1.65, wpb=4120.8, bsz=146.7, num_updates=30600, lr=8.08452e-05, gnorm=0.972, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=24585
2023-07-13 22:32:22 | INFO | train_inner | epoch 021:   1234 / 1474 loss=3.828, trans_loss=5.278, nll_loss=2.56, w2v_ctc_loss=1.205, task_loss=15.234, contrastive_loss=0.245, total=4154.73, n_correct=2702.97, ppl=5.9, accuracy=65.058, wps=6883.9, ups=1.66, wpb=4154.7, bsz=155.8, num_updates=30700, lr=8.07134e-05, gnorm=0.949, clip=0, loss_scale=32, train_wall=60, gb_free=13, wall=24646
2023-07-13 22:33:23 | INFO | train_inner | epoch 021:   1334 / 1474 loss=3.817, trans_loss=5.274, nll_loss=2.556, w2v_ctc_loss=1.197, task_loss=15.531, contrastive_loss=0.166, total=4147.17, n_correct=2707.85, ppl=5.88, accuracy=65.294, wps=6842.8, ups=1.65, wpb=4147.2, bsz=155.9, num_updates=30800, lr=8.05823e-05, gnorm=0.969, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=24706
2023-07-13 22:34:24 | INFO | train_inner | epoch 021:   1434 / 1474 loss=3.856, trans_loss=5.298, nll_loss=2.585, w2v_ctc_loss=1.237, task_loss=16.834, contrastive_loss=0.26, total=4133.93, n_correct=2678.18, ppl=6, accuracy=64.785, wps=6731.8, ups=1.63, wpb=4133.9, bsz=152.2, num_updates=30900, lr=8.04518e-05, gnorm=0.967, clip=0, loss_scale=32, train_wall=61, gb_free=15.7, wall=24768
2023-07-13 22:34:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
asr_weight tensor(0.0260, device='cuda:5')
mt_weight tensor(0.0016, device='cuda:5')
asr_weight tensor(0.0260, device='cuda:7')
mt_weight tensor(0.0016, device='cuda:7')
asr_weight tensor(0.0260, device='cuda:2')
mt_weight tensor(0.0016, device='cuda:2')
asr_weight tensor(0.0260, device='cuda:4')
mt_weight tensor(0.0016, device='cuda:4')
asr_weight tensor(0.0260, device='cuda:1')
mt_weight tensor(0.0016, device='cuda:1')
asr_weight tensor(0.0260, device='cuda:6')
mt_weight tensor(0.0016, device='cuda:6')
asr_weight tensor(0.0260, device='cuda:3')
mt_weight tensor(0.0016, device='cuda:3')
2023-07-13 22:35:15 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.193 | trans_loss 5.569 | nll_loss 2.846 | w2v_ctc_loss 1.318 | task_loss 23.166 | contrastive_loss 0.254 | total 4003.4 | n_correct 2474.8 | ppl 7.19 | accuracy 61.817 | uer 16.999 | wer 18.84 | raw_wer 18.84 | bleu 19.79 | wps 1926.1 | wpb 4003.4 | bsz 141.8 | num_updates 30940 | best_bleu 20.11
2023-07-13 22:35:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30940 updates
2023-07-13 22:35:15 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_19.7902.pt
2023-07-13 22:35:18 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_19.7902.pt
2023-07-13 22:35:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_19.7902.pt (epoch 21 @ 30940 updates, score 19.79) (writing took 5.297867264947854 seconds)
2023-07-13 22:35:21 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-07-13 22:35:21 | INFO | train | epoch 021 | loss 3.828 | trans_loss 5.276 | nll_loss 2.556 | w2v_ctc_loss 1.206 | task_loss 16.051 | contrastive_loss 0.219 | total 4138.46 | n_correct 2695.68 | ppl 5.88 | accuracy 65.137 | wps 6296.2 | ups 1.52 | wpb 4138.5 | bsz 152.8 | num_updates 30940 | lr 8.03998e-05 | gnorm 0.958 | clip 0 | loss_scale 32 | train_wall 888 | gb_free 15.6 | wall 24824
2023-07-13 22:35:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 22:35:21 | INFO | fairseq.trainer | begin training epoch 22
2023-07-13 22:35:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 22:36:05 | INFO | train_inner | epoch 022:     60 / 1474 loss=3.814, trans_loss=5.258, nll_loss=2.534, w2v_ctc_loss=1.206, task_loss=16.266, contrastive_loss=0.104, total=4128.84, n_correct=2699.61, ppl=5.79, accuracy=65.384, wps=4104.8, ups=0.99, wpb=4128.8, bsz=148.8, num_updates=31000, lr=8.03219e-05, gnorm=0.966, clip=0, loss_scale=32, train_wall=60, gb_free=14.5, wall=24868
2023-07-13 22:37:06 | INFO | train_inner | epoch 022:    160 / 1474 loss=3.805, trans_loss=5.247, nll_loss=2.519, w2v_ctc_loss=1.194, task_loss=16.15, contrastive_loss=0.268, total=4123.35, n_correct=2706.94, ppl=5.73, accuracy=65.649, wps=6781.9, ups=1.64, wpb=4123.4, bsz=155.1, num_updates=31100, lr=8.01927e-05, gnorm=0.953, clip=0, loss_scale=32, train_wall=60, gb_free=14.9, wall=24929
2023-07-13 22:38:07 | INFO | train_inner | epoch 022:    260 / 1474 loss=3.774, trans_loss=5.235, nll_loss=2.504, w2v_ctc_loss=1.165, task_loss=14.13, contrastive_loss=0.151, total=4267.16, n_correct=2810.11, ppl=5.67, accuracy=65.854, wps=6997.5, ups=1.64, wpb=4267.2, bsz=165, num_updates=31200, lr=8.00641e-05, gnorm=0.927, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=24990
2023-07-13 22:39:09 | INFO | train_inner | epoch 022:    360 / 1474 loss=3.825, trans_loss=5.257, nll_loss=2.532, w2v_ctc_loss=1.185, task_loss=16.301, contrastive_loss=0.461, total=4180.09, n_correct=2738.09, ppl=5.78, accuracy=65.503, wps=6727, ups=1.61, wpb=4180.1, bsz=155, num_updates=31300, lr=7.99361e-05, gnorm=0.955, clip=0, loss_scale=32, train_wall=62, gb_free=17.7, wall=25052
2023-07-13 22:40:10 | INFO | train_inner | epoch 022:    460 / 1474 loss=3.831, trans_loss=5.27, nll_loss=2.547, w2v_ctc_loss=1.206, task_loss=16.948, contrastive_loss=0.229, total=4132.62, n_correct=2698.34, ppl=5.84, accuracy=65.294, wps=6802, ups=1.65, wpb=4132.6, bsz=148.6, num_updates=31400, lr=7.98087e-05, gnorm=0.96, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=25113
2023-07-13 22:41:11 | INFO | train_inner | epoch 022:    560 / 1474 loss=3.808, trans_loss=5.258, nll_loss=2.533, w2v_ctc_loss=1.199, task_loss=16.165, contrastive_loss=0.126, total=4155.5, n_correct=2717.4, ppl=5.79, accuracy=65.393, wps=6764.3, ups=1.63, wpb=4155.5, bsz=153.7, num_updates=31500, lr=7.96819e-05, gnorm=0.961, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=25174
2023-07-13 22:42:10 | INFO | train_inner | epoch 022:    660 / 1474 loss=3.791, trans_loss=5.243, nll_loss=2.515, w2v_ctc_loss=1.162, task_loss=15.116, contrastive_loss=0.291, total=4147.84, n_correct=2722.98, ppl=5.71, accuracy=65.648, wps=6979.6, ups=1.68, wpb=4147.8, bsz=156.6, num_updates=31600, lr=7.95557e-05, gnorm=0.947, clip=0, loss_scale=32, train_wall=59, gb_free=13.4, wall=25234
2023-07-13 22:43:11 | INFO | train_inner | epoch 022:    760 / 1474 loss=3.811, trans_loss=5.256, nll_loss=2.53, w2v_ctc_loss=1.202, task_loss=16.428, contrastive_loss=0.133, total=4166.89, n_correct=2730.42, ppl=5.78, accuracy=65.527, wps=6848.4, ups=1.64, wpb=4166.9, bsz=152.2, num_updates=31700, lr=7.94301e-05, gnorm=0.957, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=25295
2023-07-13 22:44:13 | INFO | train_inner | epoch 022:    860 / 1474 loss=3.825, trans_loss=5.269, nll_loss=2.548, w2v_ctc_loss=1.206, task_loss=17.513, contrastive_loss=0.103, total=4074.75, n_correct=2653.75, ppl=5.85, accuracy=65.127, wps=6611.1, ups=1.62, wpb=4074.8, bsz=144.2, num_updates=31800, lr=7.93052e-05, gnorm=0.969, clip=0, loss_scale=32, train_wall=61, gb_free=17.6, wall=25356
2023-07-13 22:45:14 | INFO | train_inner | epoch 022:    960 / 1474 loss=3.804, trans_loss=5.256, nll_loss=2.532, w2v_ctc_loss=1.19, task_loss=16.104, contrastive_loss=0.108, total=4136.34, n_correct=2706.42, ppl=5.78, accuracy=65.43, wps=6814, ups=1.65, wpb=4136.3, bsz=151.8, num_updates=31900, lr=7.91808e-05, gnorm=0.961, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=25417
2023-07-13 22:46:15 | INFO | train_inner | epoch 022:   1060 / 1474 loss=3.813, trans_loss=5.258, nll_loss=2.534, w2v_ctc_loss=1.178, task_loss=15.281, contrastive_loss=0.443, total=4157.21, n_correct=2724.28, ppl=5.79, accuracy=65.531, wps=6822, ups=1.64, wpb=4157.2, bsz=157.7, num_updates=32000, lr=7.90569e-05, gnorm=0.958, clip=0, loss_scale=64, train_wall=61, gb_free=12.5, wall=25478
2023-07-13 22:46:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 22:46:42 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.198 | trans_loss 5.569 | nll_loss 2.845 | w2v_ctc_loss 1.335 | task_loss 23.11 | contrastive_loss 0.257 | total 4003.4 | n_correct 2477.3 | ppl 7.18 | accuracy 61.88 | uer 16.829 | wer 18.78 | raw_wer 18.78 | bleu 20.01 | wps 1899.2 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.11
2023-07-13 22:46:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-07-13 22:46:42 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_22_32000.pt
2023-07-13 22:46:44 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_22_32000.pt
2023-07-13 22:46:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 20.01) (writing took 6.284074480063282 seconds)
2023-07-13 22:47:49 | INFO | train_inner | epoch 022:   1160 / 1474 loss=3.84, trans_loss=5.285, nll_loss=2.569, w2v_ctc_loss=1.21, task_loss=16.697, contrastive_loss=0.204, total=4092.91, n_correct=2660.3, ppl=5.93, accuracy=64.998, wps=4340.2, ups=1.06, wpb=4092.9, bsz=147.2, num_updates=32100, lr=7.89337e-05, gnorm=0.962, clip=0, loss_scale=64, train_wall=60, gb_free=16.2, wall=25572
2023-07-13 22:48:50 | INFO | train_inner | epoch 022:   1260 / 1474 loss=3.812, trans_loss=5.273, nll_loss=2.554, w2v_ctc_loss=1.195, task_loss=14.884, contrastive_loss=0.2, total=4182.65, n_correct=2728.48, ppl=5.87, accuracy=65.233, wps=6887.7, ups=1.65, wpb=4182.6, bsz=161.8, num_updates=32200, lr=7.8811e-05, gnorm=0.951, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=25633
2023-07-13 22:49:50 | INFO | train_inner | epoch 022:   1360 / 1474 loss=3.811, trans_loss=5.262, nll_loss=2.54, w2v_ctc_loss=1.181, task_loss=15.946, contrastive_loss=0.244, total=4071.58, n_correct=2661.63, ppl=5.82, accuracy=65.371, wps=6790.5, ups=1.67, wpb=4071.6, bsz=150.3, num_updates=32300, lr=7.86889e-05, gnorm=0.962, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=25693
2023-07-13 22:50:50 | INFO | train_inner | epoch 022:   1460 / 1474 loss=3.841, trans_loss=5.283, nll_loss=2.566, w2v_ctc_loss=1.218, task_loss=17.182, contrastive_loss=0.134, total=4077.83, n_correct=2648.6, ppl=5.92, accuracy=64.951, wps=6750.5, ups=1.66, wpb=4077.8, bsz=144, num_updates=32400, lr=7.85674e-05, gnorm=0.964, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=25753
2023-07-13 22:50:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 22:51:27 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.193 | trans_loss 5.569 | nll_loss 2.844 | w2v_ctc_loss 1.316 | task_loss 23.018 | contrastive_loss 0.258 | total 4003.4 | n_correct 2481.8 | ppl 7.18 | accuracy 61.992 | uer 16.986 | wer 18.922 | raw_wer 18.922 | bleu 20.35 | wps 1881.2 | wpb 4003.4 | bsz 141.8 | num_updates 32414 | best_bleu 20.35
2023-07-13 22:51:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32414 updates
2023-07-13 22:51:27 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 22:51:31 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 22:51:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt (epoch 22 @ 32414 updates, score 20.35) (writing took 8.22543944104109 seconds)
2023-07-13 22:51:36 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-07-13 22:51:36 | INFO | train | epoch 022 | loss 3.813 | trans_loss 5.26 | nll_loss 2.536 | w2v_ctc_loss 1.193 | task_loss 16.053 | contrastive_loss 0.217 | total 4138.65 | n_correct 2706.92 | ppl 5.8 | accuracy 65.406 | wps 6255.9 | ups 1.51 | wpb 4138.6 | bsz 152.8 | num_updates 32414 | lr 7.85505e-05 | gnorm 0.956 | clip 0 | loss_scale 64 | train_wall 889 | gb_free 12.2 | wall 25799
2023-07-13 22:51:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 22:51:36 | INFO | fairseq.trainer | begin training epoch 23
2023-07-13 22:51:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 22:52:37 | INFO | train_inner | epoch 023:     86 / 1474 loss=3.792, trans_loss=5.235, nll_loss=2.503, w2v_ctc_loss=1.192, task_loss=16.621, contrastive_loss=0.12, total=4089.8, n_correct=2694.04, ppl=5.67, accuracy=65.872, wps=3831.1, ups=0.94, wpb=4089.8, bsz=149.7, num_updates=32500, lr=7.84465e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=61, gb_free=16.8, wall=25860
2023-07-13 22:53:37 | INFO | train_inner | epoch 023:    186 / 1474 loss=3.791, trans_loss=5.233, nll_loss=2.5, w2v_ctc_loss=1.181, task_loss=16.922, contrastive_loss=0.115, total=4117.76, n_correct=2711.26, ppl=5.66, accuracy=65.843, wps=6784.4, ups=1.65, wpb=4117.8, bsz=148, num_updates=32600, lr=7.8326e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=60, gb_free=15.7, wall=25921
2023-07-13 22:54:39 | INFO | train_inner | epoch 023:    286 / 1474 loss=3.8, trans_loss=5.242, nll_loss=2.513, w2v_ctc_loss=1.171, task_loss=16.333, contrastive_loss=0.274, total=4144.73, n_correct=2721.77, ppl=5.71, accuracy=65.668, wps=6774.2, ups=1.63, wpb=4144.7, bsz=152, num_updates=32700, lr=7.82062e-05, gnorm=0.962, clip=0, loss_scale=64, train_wall=61, gb_free=17.6, wall=25982
2023-07-13 22:55:39 | INFO | train_inner | epoch 023:    386 / 1474 loss=3.79, trans_loss=5.235, nll_loss=2.503, w2v_ctc_loss=1.175, task_loss=16.483, contrastive_loss=0.101, total=4126.79, n_correct=2719.25, ppl=5.67, accuracy=65.893, wps=6843.7, ups=1.66, wpb=4126.8, bsz=148.2, num_updates=32800, lr=7.80869e-05, gnorm=0.954, clip=0, loss_scale=64, train_wall=60, gb_free=17.3, wall=26042
2023-07-13 22:56:39 | INFO | train_inner | epoch 023:    486 / 1474 loss=3.792, trans_loss=5.242, nll_loss=2.513, w2v_ctc_loss=1.174, task_loss=15.65, contrastive_loss=0.214, total=4150.15, n_correct=2725.09, ppl=5.71, accuracy=65.662, wps=6886, ups=1.66, wpb=4150.1, bsz=156, num_updates=32900, lr=7.79681e-05, gnorm=0.955, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=26103
2023-07-13 22:57:40 | INFO | train_inner | epoch 023:    586 / 1474 loss=3.772, trans_loss=5.229, nll_loss=2.496, w2v_ctc_loss=1.166, task_loss=15.132, contrastive_loss=0.111, total=4174.6, n_correct=2749.91, ppl=5.64, accuracy=65.872, wps=6885.4, ups=1.65, wpb=4174.6, bsz=158.2, num_updates=33000, lr=7.78499e-05, gnorm=0.943, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=26163
2023-07-13 22:58:40 | INFO | train_inner | epoch 023:    686 / 1474 loss=3.796, trans_loss=5.238, nll_loss=2.507, w2v_ctc_loss=1.179, task_loss=16.16, contrastive_loss=0.189, total=4136.6, n_correct=2717.57, ppl=5.69, accuracy=65.696, wps=6843.3, ups=1.65, wpb=4136.6, bsz=150.6, num_updates=33100, lr=7.77322e-05, gnorm=0.949, clip=0, loss_scale=64, train_wall=60, gb_free=17.8, wall=26224
2023-07-13 22:59:41 | INFO | train_inner | epoch 023:    786 / 1474 loss=3.811, trans_loss=5.256, nll_loss=2.532, w2v_ctc_loss=1.202, task_loss=16.169, contrastive_loss=0.149, total=4147.22, n_correct=2716.8, ppl=5.78, accuracy=65.509, wps=6881.4, ups=1.66, wpb=4147.2, bsz=152.6, num_updates=33200, lr=7.76151e-05, gnorm=0.97, clip=0, loss_scale=64, train_wall=60, gb_free=17.4, wall=26284
2023-07-13 23:00:41 | INFO | train_inner | epoch 023:    886 / 1474 loss=3.787, trans_loss=5.24, nll_loss=2.512, w2v_ctc_loss=1.172, task_loss=14.533, contrastive_loss=0.303, total=4193.16, n_correct=2758.44, ppl=5.7, accuracy=65.784, wps=6971.9, ups=1.66, wpb=4193.2, bsz=163.6, num_updates=33300, lr=7.74984e-05, gnorm=0.954, clip=0, loss_scale=64, train_wall=60, gb_free=16.2, wall=26344
2023-07-13 23:01:41 | INFO | train_inner | epoch 023:    986 / 1474 loss=3.829, trans_loss=5.257, nll_loss=2.533, w2v_ctc_loss=1.184, task_loss=16.025, contrastive_loss=0.621, total=4164.33, n_correct=2721.01, ppl=5.79, accuracy=65.341, wps=6856.1, ups=1.65, wpb=4164.3, bsz=155.1, num_updates=33400, lr=7.73823e-05, gnorm=0.964, clip=0, loss_scale=64, train_wall=60, gb_free=17.8, wall=26405
2023-07-13 23:02:42 | INFO | train_inner | epoch 023:   1086 / 1474 loss=3.82, trans_loss=5.256, nll_loss=2.532, w2v_ctc_loss=1.211, task_loss=17.258, contrastive_loss=0.127, total=4088.37, n_correct=2674.47, ppl=5.78, accuracy=65.417, wps=6719.5, ups=1.64, wpb=4088.4, bsz=144.8, num_updates=33500, lr=7.72667e-05, gnorm=0.973, clip=0, loss_scale=64, train_wall=60, gb_free=15.8, wall=26466
2023-07-13 23:03:44 | INFO | train_inner | epoch 023:   1186 / 1474 loss=3.795, trans_loss=5.246, nll_loss=2.519, w2v_ctc_loss=1.188, task_loss=15.971, contrastive_loss=0.112, total=4162.3, n_correct=2729.11, ppl=5.73, accuracy=65.567, wps=6789.7, ups=1.63, wpb=4162.3, bsz=154.5, num_updates=33600, lr=7.71517e-05, gnorm=0.957, clip=0, loss_scale=64, train_wall=61, gb_free=15.8, wall=26527
2023-07-13 23:04:45 | INFO | train_inner | epoch 023:   1286 / 1474 loss=3.79, trans_loss=5.247, nll_loss=2.521, w2v_ctc_loss=1.17, task_loss=15.624, contrastive_loss=0.131, total=4131.74, n_correct=2710.51, ppl=5.74, accuracy=65.602, wps=6781.8, ups=1.64, wpb=4131.7, bsz=154.4, num_updates=33700, lr=7.70371e-05, gnorm=0.953, clip=0, loss_scale=64, train_wall=61, gb_free=17.2, wall=26588
2023-07-13 23:05:45 | INFO | train_inner | epoch 023:   1386 / 1474 loss=3.831, trans_loss=5.278, nll_loss=2.561, w2v_ctc_loss=1.201, task_loss=16.181, contrastive_loss=0.245, total=4141.25, n_correct=2696.4, ppl=5.9, accuracy=65.111, wps=6821.2, ups=1.65, wpb=4141.2, bsz=152.4, num_updates=33800, lr=7.69231e-05, gnorm=0.966, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=26649
2023-07-13 23:06:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 23:07:04 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.21 | trans_loss 5.561 | nll_loss 2.836 | w2v_ctc_loss 1.391 | task_loss 23.11 | contrastive_loss 0.258 | total 4003.4 | n_correct 2479.8 | ppl 7.14 | accuracy 61.942 | uer 16.988 | wer 18.832 | raw_wer 18.832 | bleu 19.93 | wps 2050 | wpb 4003.4 | bsz 141.8 | num_updates 33888 | best_bleu 20.35
2023-07-13 23:07:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33888 updates
2023-07-13 23:07:04 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_19.9306.pt
2023-07-13 23:07:07 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_19.9306.pt
2023-07-13 23:07:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_19.9306.pt (epoch 23 @ 33888 updates, score 19.93) (writing took 5.341509267920628 seconds)
2023-07-13 23:07:10 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-07-13 23:07:10 | INFO | train | epoch 023 | loss 3.802 | trans_loss 5.247 | nll_loss 2.52 | w2v_ctc_loss 1.183 | task_loss 16.057 | contrastive_loss 0.217 | total 4138.65 | n_correct 2715.26 | ppl 5.73 | accuracy 65.607 | wps 6532.6 | ups 1.58 | wpb 4138.6 | bsz 152.8 | num_updates 33888 | lr 7.68231e-05 | gnorm 0.959 | clip 0 | loss_scale 64 | train_wall 888 | gb_free 14.1 | wall 26733
2023-07-13 23:07:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 23:07:10 | INFO | fairseq.trainer | begin training epoch 24
2023-07-13 23:07:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 23:07:25 | INFO | train_inner | epoch 024:     12 / 1474 loss=3.824, trans_loss=5.269, nll_loss=2.55, w2v_ctc_loss=1.173, task_loss=16.013, contrastive_loss=0.398, total=4095.53, n_correct=2672.68, ppl=5.86, accuracy=65.258, wps=4091.9, ups=1, wpb=4095.5, bsz=153.1, num_updates=33900, lr=7.68095e-05, gnorm=0.966, clip=0, loss_scale=64, train_wall=60, gb_free=17.5, wall=26749
2023-07-13 23:08:26 | INFO | train_inner | epoch 024:    112 / 1474 loss=3.782, trans_loss=5.22, nll_loss=2.485, w2v_ctc_loss=1.162, task_loss=14.917, contrastive_loss=0.441, total=4167.42, n_correct=2750.77, ppl=5.6, accuracy=66.007, wps=6881.6, ups=1.65, wpb=4167.4, bsz=161.5, num_updates=34000, lr=7.66965e-05, gnorm=0.94, clip=0, loss_scale=128, train_wall=60, gb_free=17.8, wall=26809
2023-07-13 23:08:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 23:08:54 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.19 | trans_loss 5.558 | nll_loss 2.827 | w2v_ctc_loss 1.332 | task_loss 23.057 | contrastive_loss 0.253 | total 4003.4 | n_correct 2483.5 | ppl 7.1 | accuracy 62.035 | uer 16.606 | wer 18.486 | raw_wer 18.486 | bleu 20 | wps 1933.5 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.35
2023-07-13 23:08:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-07-13 23:08:54 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_24_34000.pt
2023-07-13 23:08:56 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_24_34000.pt
2023-07-13 23:09:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 20.0) (writing took 6.282772770966403 seconds)
2023-07-13 23:10:02 | INFO | train_inner | epoch 024:    212 / 1474 loss=3.773, trans_loss=5.221, nll_loss=2.487, w2v_ctc_loss=1.134, task_loss=14.072, contrastive_loss=0.541, total=4247.08, n_correct=2804.36, ppl=5.61, accuracy=66.03, wps=4419.8, ups=1.04, wpb=4247.1, bsz=169.8, num_updates=34100, lr=7.6584e-05, gnorm=0.939, clip=0, loss_scale=128, train_wall=61, gb_free=16.9, wall=26905
2023-07-13 23:11:03 | INFO | train_inner | epoch 024:    312 / 1474 loss=3.763, trans_loss=5.212, nll_loss=2.474, w2v_ctc_loss=1.16, task_loss=15.495, contrastive_loss=0.106, total=4139.31, n_correct=2741.61, ppl=5.56, accuracy=66.234, wps=6834.1, ups=1.65, wpb=4139.3, bsz=154.2, num_updates=34200, lr=7.64719e-05, gnorm=0.958, clip=0, loss_scale=128, train_wall=60, gb_free=16.6, wall=26966
2023-07-13 23:11:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-13 23:12:05 | INFO | train_inner | epoch 024:    413 / 1474 loss=3.806, trans_loss=5.235, nll_loss=2.504, w2v_ctc_loss=1.196, task_loss=17.415, contrastive_loss=0.163, total=4127.95, n_correct=2716.81, ppl=5.67, accuracy=65.815, wps=6667.2, ups=1.62, wpb=4127.9, bsz=145.2, num_updates=34300, lr=7.63604e-05, gnorm=0.979, clip=0, loss_scale=64, train_wall=61, gb_free=16.8, wall=27028
2023-07-13 23:13:05 | INFO | train_inner | epoch 024:    513 / 1474 loss=3.793, trans_loss=5.232, nll_loss=2.5, w2v_ctc_loss=1.177, task_loss=16.276, contrastive_loss=0.241, total=4144.91, n_correct=2730.88, ppl=5.66, accuracy=65.885, wps=6809.8, ups=1.64, wpb=4144.9, bsz=151.6, num_updates=34400, lr=7.62493e-05, gnorm=0.965, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=27089
2023-07-13 23:14:06 | INFO | train_inner | epoch 024:    613 / 1474 loss=3.776, trans_loss=5.223, nll_loss=2.489, w2v_ctc_loss=1.157, task_loss=16.147, contrastive_loss=0.166, total=4165.3, n_correct=2746.9, ppl=5.61, accuracy=65.947, wps=6866.1, ups=1.65, wpb=4165.3, bsz=153.8, num_updates=34500, lr=7.61387e-05, gnorm=0.946, clip=0, loss_scale=64, train_wall=60, gb_free=16, wall=27149
2023-07-13 23:15:07 | INFO | train_inner | epoch 024:    713 / 1474 loss=3.803, trans_loss=5.24, nll_loss=2.51, w2v_ctc_loss=1.187, task_loss=16.554, contrastive_loss=0.191, total=4102.21, n_correct=2698.59, ppl=5.7, accuracy=65.784, wps=6764.5, ups=1.65, wpb=4102.2, bsz=147.5, num_updates=34600, lr=7.60286e-05, gnorm=0.957, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=27210
2023-07-13 23:16:08 | INFO | train_inner | epoch 024:    813 / 1474 loss=3.782, trans_loss=5.234, nll_loss=2.504, w2v_ctc_loss=1.165, task_loss=16.225, contrastive_loss=0.146, total=4110.6, n_correct=2704.46, ppl=5.67, accuracy=65.792, wps=6750.9, ups=1.64, wpb=4110.6, bsz=152.7, num_updates=34700, lr=7.5919e-05, gnorm=0.964, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=27271
2023-07-13 23:17:08 | INFO | train_inner | epoch 024:    913 / 1474 loss=3.811, trans_loss=5.247, nll_loss=2.519, w2v_ctc_loss=1.195, task_loss=17.779, contrastive_loss=0.097, total=4043.03, n_correct=2646.4, ppl=5.73, accuracy=65.456, wps=6708.9, ups=1.66, wpb=4043, bsz=140.5, num_updates=34800, lr=7.58098e-05, gnorm=0.979, clip=0, loss_scale=64, train_wall=60, gb_free=11.7, wall=27331
2023-07-13 23:18:09 | INFO | train_inner | epoch 024:   1013 / 1474 loss=3.791, trans_loss=5.242, nll_loss=2.514, w2v_ctc_loss=1.166, task_loss=16.57, contrastive_loss=0.104, total=4136.81, n_correct=2716.82, ppl=5.71, accuracy=65.674, wps=6799, ups=1.64, wpb=4136.8, bsz=149.2, num_updates=34900, lr=7.57011e-05, gnorm=0.967, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=27392
2023-07-13 23:19:09 | INFO | train_inner | epoch 024:   1113 / 1474 loss=3.78, trans_loss=5.225, nll_loss=2.492, w2v_ctc_loss=1.171, task_loss=15.532, contrastive_loss=0.19, total=4135.73, n_correct=2727.33, ppl=5.63, accuracy=65.946, wps=6822.8, ups=1.65, wpb=4135.7, bsz=154.4, num_updates=35000, lr=7.55929e-05, gnorm=0.962, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=27453
asr_weight tensor(0.0260, device='cuda:0')
mt_weight tensor(0.0016, device='cuda:0')
2023-07-13 23:20:10 | INFO | train_inner | epoch 024:   1213 / 1474 loss=3.791, trans_loss=5.246, nll_loss=2.52, w2v_ctc_loss=1.169, task_loss=15.918, contrastive_loss=0.169, total=4148.3, n_correct=2721.95, ppl=5.73, accuracy=65.616, wps=6815.2, ups=1.64, wpb=4148.3, bsz=155.4, num_updates=35100, lr=7.54851e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=27514
2023-07-13 23:21:11 | INFO | train_inner | epoch 024:   1313 / 1474 loss=3.808, trans_loss=5.251, nll_loss=2.526, w2v_ctc_loss=1.192, task_loss=17.104, contrastive_loss=0.115, total=4110.05, n_correct=2692.75, ppl=5.76, accuracy=65.516, wps=6760.6, ups=1.64, wpb=4110.1, bsz=147.1, num_updates=35200, lr=7.53778e-05, gnorm=0.972, clip=0, loss_scale=64, train_wall=60, gb_free=17.4, wall=27574
2023-07-13 23:22:11 | INFO | train_inner | epoch 024:   1413 / 1474 loss=3.81, trans_loss=5.249, nll_loss=2.524, w2v_ctc_loss=1.203, task_loss=16.752, contrastive_loss=0.11, total=4090.91, n_correct=2682.14, ppl=5.75, accuracy=65.563, wps=6825.2, ups=1.67, wpb=4090.9, bsz=146.4, num_updates=35300, lr=7.5271e-05, gnorm=0.966, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=27634
2023-07-13 23:22:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
asr_weight tensor(0.0260, device='cuda:7')
mt_weight tensor(0.0016, device='cuda:7')
asr_weight tensor(0.0260, device='cuda:6')
mt_weight tensor(0.0016, device='cuda:6')
asr_weight tensor(0.0260, device='cuda:3')
mt_weight tensor(0.0016, device='cuda:3')
asr_weight tensor(0.0260, device='cuda:4')
mt_weight tensor(0.0016, device='cuda:4')
asr_weight tensor(0.0260, device='cuda:2')
mt_weight tensor(0.0016, device='cuda:2')
asr_weight tensor(0.0260, device='cuda:5')
mt_weight tensor(0.0016, device='cuda:5')
asr_weight tensor(0.0260, device='cuda:1')
mt_weight tensor(0.0016, device='cuda:1')
2023-07-13 23:23:14 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.205 | trans_loss 5.567 | nll_loss 2.84 | w2v_ctc_loss 1.362 | task_loss 23.149 | contrastive_loss 0.251 | total 4003.4 | n_correct 2484.3 | ppl 7.16 | accuracy 62.055 | uer 16.914 | wer 18.795 | raw_wer 18.795 | bleu 20 | wps 1958.7 | wpb 4003.4 | bsz 141.8 | num_updates 35361 | best_bleu 20.35
2023-07-13 23:23:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35361 updates
2023-07-13 23:23:14 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.0007.pt
2023-07-13 23:23:17 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.0007.pt
2023-07-13 23:23:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.0007.pt (epoch 24 @ 35361 updates, score 20.0) (writing took 5.541950052022003 seconds)
2023-07-13 23:23:20 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-07-13 23:23:20 | INFO | train | epoch 024 | loss 3.789 | trans_loss 5.234 | nll_loss 2.503 | w2v_ctc_loss 1.172 | task_loss 16.078 | contrastive_loss 0.2 | total 4137.03 | n_correct 2722.61 | ppl 5.67 | accuracy 65.811 | wps 6280.7 | ups 1.52 | wpb 4137 | bsz 152.6 | num_updates 35361 | lr 7.5206e-05 | gnorm 0.96 | clip 0 | loss_scale 64 | train_wall 889 | gb_free 16.3 | wall 27703
2023-07-13 23:23:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 23:23:20 | INFO | fairseq.trainer | begin training epoch 25
2023-07-13 23:23:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 23:23:51 | INFO | train_inner | epoch 025:     39 / 1474 loss=3.766, trans_loss=5.216, nll_loss=2.48, w2v_ctc_loss=1.159, task_loss=15.337, contrastive_loss=0.127, total=4166.95, n_correct=2754.05, ppl=5.58, accuracy=66.093, wps=4145.8, ups=0.99, wpb=4166.9, bsz=156, num_updates=35400, lr=7.51646e-05, gnorm=0.942, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=27735
2023-07-13 23:24:52 | INFO | train_inner | epoch 025:    139 / 1474 loss=3.758, trans_loss=5.205, nll_loss=2.465, w2v_ctc_loss=1.154, task_loss=15.735, contrastive_loss=0.125, total=4133.64, n_correct=2741.51, ppl=5.52, accuracy=66.322, wps=6815.8, ups=1.65, wpb=4133.6, bsz=153.9, num_updates=35500, lr=7.50587e-05, gnorm=0.955, clip=0, loss_scale=64, train_wall=60, gb_free=15.9, wall=27796
2023-07-13 23:25:53 | INFO | train_inner | epoch 025:    239 / 1474 loss=3.765, trans_loss=5.206, nll_loss=2.466, w2v_ctc_loss=1.164, task_loss=16.51, contrastive_loss=0.132, total=4114.53, n_correct=2724.49, ppl=5.52, accuracy=66.216, wps=6703.6, ups=1.63, wpb=4114.5, bsz=151.4, num_updates=35600, lr=7.49532e-05, gnorm=0.956, clip=0, loss_scale=64, train_wall=61, gb_free=17.2, wall=27857
2023-07-13 23:26:55 | INFO | train_inner | epoch 025:    339 / 1474 loss=3.778, trans_loss=5.212, nll_loss=2.473, w2v_ctc_loss=1.16, task_loss=17.081, contrastive_loss=0.189, total=4148.7, n_correct=2740.97, ppl=5.55, accuracy=66.068, wps=6783.3, ups=1.64, wpb=4148.7, bsz=147.6, num_updates=35700, lr=7.48481e-05, gnorm=0.961, clip=0, loss_scale=64, train_wall=61, gb_free=16.8, wall=27918
2023-07-13 23:27:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-13 23:27:56 | INFO | train_inner | epoch 025:    440 / 1474 loss=3.79, trans_loss=5.218, nll_loss=2.481, w2v_ctc_loss=1.191, task_loss=17.252, contrastive_loss=0.106, total=4142.33, n_correct=2737.09, ppl=5.58, accuracy=66.076, wps=6722.6, ups=1.62, wpb=4142.3, bsz=144.7, num_updates=35800, lr=7.47435e-05, gnorm=0.966, clip=0, loss_scale=32, train_wall=61, gb_free=16, wall=27980
2023-07-13 23:28:57 | INFO | train_inner | epoch 025:    540 / 1474 loss=3.778, trans_loss=5.228, nll_loss=2.497, w2v_ctc_loss=1.176, task_loss=15.672, contrastive_loss=0.129, total=4160.61, n_correct=2745.36, ppl=5.64, accuracy=65.985, wps=6873.9, ups=1.65, wpb=4160.6, bsz=157, num_updates=35900, lr=7.46393e-05, gnorm=0.957, clip=0, loss_scale=32, train_wall=60, gb_free=17.7, wall=28040
2023-07-13 23:29:57 | INFO | train_inner | epoch 025:    640 / 1474 loss=3.775, trans_loss=5.216, nll_loss=2.481, w2v_ctc_loss=1.161, task_loss=15.897, contrastive_loss=0.264, total=4153.68, n_correct=2748.44, ppl=5.58, accuracy=66.169, wps=6900.7, ups=1.66, wpb=4153.7, bsz=154.8, num_updates=36000, lr=7.45356e-05, gnorm=0.957, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=28100
2023-07-13 23:29:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 23:30:23 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.21 | trans_loss 5.567 | nll_loss 2.84 | w2v_ctc_loss 1.378 | task_loss 23.043 | contrastive_loss 0.255 | total 4003.4 | n_correct 2480.8 | ppl 7.16 | accuracy 61.967 | uer 17.017 | wer 18.855 | raw_wer 18.855 | bleu 20.12 | wps 2020.5 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.35
2023-07-13 23:30:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-07-13 23:30:23 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_25_36000.pt
2023-07-13 23:30:25 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_25_36000.pt
2023-07-13 23:30:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 20.12) (writing took 6.445711091044359 seconds)
2023-07-13 23:31:31 | INFO | train_inner | epoch 025:    740 / 1474 loss=3.786, trans_loss=5.22, nll_loss=2.485, w2v_ctc_loss=1.169, task_loss=16.274, contrastive_loss=0.258, total=4128.34, n_correct=2727.2, ppl=5.6, accuracy=66.06, wps=4400.3, ups=1.07, wpb=4128.3, bsz=150.6, num_updates=36100, lr=7.44323e-05, gnorm=0.966, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=28194
2023-07-13 23:32:31 | INFO | train_inner | epoch 025:    840 / 1474 loss=3.757, trans_loss=5.219, nll_loss=2.484, w2v_ctc_loss=1.15, task_loss=14.792, contrastive_loss=0.15, total=4182.4, n_correct=2766.43, ppl=5.59, accuracy=66.145, wps=6922.2, ups=1.66, wpb=4182.4, bsz=163, num_updates=36200, lr=7.43294e-05, gnorm=0.968, clip=0, loss_scale=32, train_wall=60, gb_free=17.8, wall=28255
2023-07-13 23:33:32 | INFO | train_inner | epoch 025:    940 / 1474 loss=3.775, trans_loss=5.222, nll_loss=2.488, w2v_ctc_loss=1.161, task_loss=15.217, contrastive_loss=0.263, total=4155.21, n_correct=2741.65, ppl=5.61, accuracy=65.981, wps=6822.6, ups=1.64, wpb=4155.2, bsz=158.5, num_updates=36300, lr=7.4227e-05, gnorm=0.953, clip=0, loss_scale=32, train_wall=60, gb_free=14.4, wall=28316
2023-07-13 23:34:33 | INFO | train_inner | epoch 025:   1040 / 1474 loss=3.797, trans_loss=5.235, nll_loss=2.504, w2v_ctc_loss=1.148, task_loss=15.955, contrastive_loss=0.481, total=4177.7, n_correct=2748.1, ppl=5.67, accuracy=65.78, wps=6872.9, ups=1.65, wpb=4177.7, bsz=154.9, num_updates=36400, lr=7.41249e-05, gnorm=0.956, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=28376
2023-07-13 23:35:34 | INFO | train_inner | epoch 025:   1140 / 1474 loss=3.785, trans_loss=5.227, nll_loss=2.494, w2v_ctc_loss=1.163, task_loss=17.308, contrastive_loss=0.098, total=4039.24, n_correct=2662.24, ppl=5.63, accuracy=65.909, wps=6601.2, ups=1.63, wpb=4039.2, bsz=142.6, num_updates=36500, lr=7.40233e-05, gnorm=0.977, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=28438
2023-07-13 23:36:34 | INFO | train_inner | epoch 025:   1240 / 1474 loss=3.782, trans_loss=5.228, nll_loss=2.496, w2v_ctc_loss=1.164, task_loss=16.249, contrastive_loss=0.118, total=4090.59, n_correct=2693.28, ppl=5.64, accuracy=65.841, wps=6852.5, ups=1.68, wpb=4090.6, bsz=147.8, num_updates=36600, lr=7.39221e-05, gnorm=0.974, clip=0, loss_scale=32, train_wall=59, gb_free=17.4, wall=28497
2023-07-13 23:37:35 | INFO | train_inner | epoch 025:   1340 / 1474 loss=3.779, trans_loss=5.221, nll_loss=2.487, w2v_ctc_loss=1.154, task_loss=15.613, contrastive_loss=0.303, total=4164.34, n_correct=2751.22, ppl=5.61, accuracy=66.066, wps=6862.9, ups=1.65, wpb=4164.3, bsz=155.1, num_updates=36700, lr=7.38213e-05, gnorm=0.951, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=28558
2023-07-13 23:38:36 | INFO | train_inner | epoch 025:   1440 / 1474 loss=3.805, trans_loss=5.249, nll_loss=2.523, w2v_ctc_loss=1.182, task_loss=16.738, contrastive_loss=0.204, total=4099.11, n_correct=2686.2, ppl=5.75, accuracy=65.531, wps=6655.3, ups=1.62, wpb=4099.1, bsz=149.7, num_updates=36800, lr=7.3721e-05, gnorm=0.971, clip=0, loss_scale=32, train_wall=61, gb_free=12.6, wall=28620
2023-07-13 23:38:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 23:39:22 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.178 | trans_loss 5.552 | nll_loss 2.825 | w2v_ctc_loss 1.305 | task_loss 23.085 | contrastive_loss 0.253 | total 4003.4 | n_correct 2491.1 | ppl 7.09 | accuracy 62.225 | uer 16.545 | wer 18.594 | raw_wer 18.594 | bleu 20.59 | wps 2129.3 | wpb 4003.4 | bsz 141.8 | num_updates 36834 | best_bleu 20.59
2023-07-13 23:39:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36834 updates
2023-07-13 23:39:22 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 23:39:26 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt
2023-07-13 23:39:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_best.pt (epoch 25 @ 36834 updates, score 20.59) (writing took 8.55778040701989 seconds)
2023-07-13 23:39:31 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-07-13 23:39:31 | INFO | train | epoch 025 | loss 3.779 | trans_loss 5.222 | nll_loss 2.487 | w2v_ctc_loss 1.164 | task_loss 16.075 | contrastive_loss 0.201 | total 4137.25 | n_correct 2731.08 | ppl 5.61 | accuracy 66.012 | wps 6277.6 | ups 1.52 | wpb 4137.2 | bsz 152.6 | num_updates 36834 | lr 7.36869e-05 | gnorm 0.962 | clip 0 | loss_scale 32 | train_wall 890 | gb_free 14.6 | wall 28674
2023-07-13 23:39:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 23:39:31 | INFO | fairseq.trainer | begin training epoch 26
2023-07-13 23:39:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 23:40:19 | INFO | train_inner | epoch 026:     66 / 1474 loss=3.745, trans_loss=5.197, nll_loss=2.456, w2v_ctc_loss=1.132, task_loss=15.075, contrastive_loss=0.174, total=4180.21, n_correct=2775.44, ppl=5.49, accuracy=66.395, wps=4071.6, ups=0.97, wpb=4180.2, bsz=159.2, num_updates=36900, lr=7.3621e-05, gnorm=0.951, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=28722
2023-07-13 23:41:20 | INFO | train_inner | epoch 026:    166 / 1474 loss=3.744, trans_loss=5.188, nll_loss=2.445, w2v_ctc_loss=1.104, task_loss=14.103, contrastive_loss=0.545, total=4270.78, n_correct=2847.3, ppl=5.44, accuracy=66.669, wps=6954, ups=1.63, wpb=4270.8, bsz=170.2, num_updates=37000, lr=7.35215e-05, gnorm=0.933, clip=0, loss_scale=32, train_wall=61, gb_free=15.5, wall=28784
2023-07-13 23:42:21 | INFO | train_inner | epoch 026:    266 / 1474 loss=3.773, trans_loss=5.207, nll_loss=2.468, w2v_ctc_loss=1.162, task_loss=15.942, contrastive_loss=0.295, total=4125.04, n_correct=2736.09, ppl=5.53, accuracy=66.329, wps=6741.7, ups=1.63, wpb=4125, bsz=153.6, num_updates=37100, lr=7.34223e-05, gnorm=0.971, clip=0, loss_scale=32, train_wall=61, gb_free=15.4, wall=28845
2023-07-13 23:43:22 | INFO | train_inner | epoch 026:    366 / 1474 loss=3.753, trans_loss=5.198, nll_loss=2.458, w2v_ctc_loss=1.14, task_loss=15.368, contrastive_loss=0.21, total=4165.74, n_correct=2766.6, ppl=5.49, accuracy=66.413, wps=6888.6, ups=1.65, wpb=4165.7, bsz=157.3, num_updates=37200, lr=7.33236e-05, gnorm=0.961, clip=0, loss_scale=32, train_wall=60, gb_free=17, wall=28905
2023-07-13 23:44:22 | INFO | train_inner | epoch 026:    466 / 1474 loss=3.751, trans_loss=5.19, nll_loss=2.447, w2v_ctc_loss=1.14, task_loss=15.245, contrastive_loss=0.3, total=4170.23, n_correct=2778.11, ppl=5.45, accuracy=66.618, wps=6876.8, ups=1.65, wpb=4170.2, bsz=157.7, num_updates=37300, lr=7.32252e-05, gnorm=0.945, clip=0, loss_scale=32, train_wall=60, gb_free=17.9, wall=28966
2023-07-13 23:45:23 | INFO | train_inner | epoch 026:    566 / 1474 loss=3.773, trans_loss=5.21, nll_loss=2.472, w2v_ctc_loss=1.176, task_loss=16.192, contrastive_loss=0.14, total=4155.02, n_correct=2750.87, ppl=5.55, accuracy=66.206, wps=6837.3, ups=1.65, wpb=4155, bsz=151.9, num_updates=37400, lr=7.31272e-05, gnorm=0.96, clip=0, loss_scale=32, train_wall=60, gb_free=17.9, wall=29027
2023-07-13 23:46:24 | INFO | train_inner | epoch 026:    666 / 1474 loss=3.755, trans_loss=5.201, nll_loss=2.461, w2v_ctc_loss=1.134, task_loss=16.393, contrastive_loss=0.112, total=4136.96, n_correct=2743.92, ppl=5.51, accuracy=66.327, wps=6844.1, ups=1.65, wpb=4137, bsz=149.6, num_updates=37500, lr=7.30297e-05, gnorm=0.948, clip=0, loss_scale=32, train_wall=60, gb_free=15.5, wall=29087
2023-07-13 23:47:24 | INFO | train_inner | epoch 026:    766 / 1474 loss=3.784, trans_loss=5.218, nll_loss=2.482, w2v_ctc_loss=1.15, task_loss=16.326, contrastive_loss=0.339, total=4086.28, n_correct=2700.39, ppl=5.59, accuracy=66.084, wps=6761, ups=1.65, wpb=4086.3, bsz=149.2, num_updates=37600, lr=7.29325e-05, gnorm=0.975, clip=0, loss_scale=32, train_wall=60, gb_free=15.3, wall=29148
2023-07-13 23:48:25 | INFO | train_inner | epoch 026:    866 / 1474 loss=3.765, trans_loss=5.21, nll_loss=2.472, w2v_ctc_loss=1.154, task_loss=15.886, contrastive_loss=0.141, total=4183.26, n_correct=2768.41, ppl=5.55, accuracy=66.178, wps=6900.9, ups=1.65, wpb=4183.3, bsz=154.1, num_updates=37700, lr=7.28357e-05, gnorm=0.968, clip=0, loss_scale=32, train_wall=60, gb_free=17.5, wall=29208
2023-07-13 23:49:25 | INFO | train_inner | epoch 026:    966 / 1474 loss=3.779, trans_loss=5.22, nll_loss=2.485, w2v_ctc_loss=1.145, task_loss=16.615, contrastive_loss=0.248, total=4137.96, n_correct=2733.02, ppl=5.6, accuracy=66.048, wps=6831.6, ups=1.65, wpb=4138, bsz=149.5, num_updates=37800, lr=7.27393e-05, gnorm=0.957, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=29269
2023-07-13 23:50:27 | INFO | train_inner | epoch 026:   1066 / 1474 loss=3.778, trans_loss=5.217, nll_loss=2.483, w2v_ctc_loss=1.165, task_loss=16.919, contrastive_loss=0.114, total=4120.53, n_correct=2724.82, ppl=5.59, accuracy=66.128, wps=6706.5, ups=1.63, wpb=4120.5, bsz=147.1, num_updates=37900, lr=7.26433e-05, gnorm=0.973, clip=0, loss_scale=64, train_wall=61, gb_free=16.8, wall=29330
2023-07-13 23:51:28 | INFO | train_inner | epoch 026:   1166 / 1474 loss=3.786, trans_loss=5.227, nll_loss=2.494, w2v_ctc_loss=1.166, task_loss=16.815, contrastive_loss=0.192, total=4113.86, n_correct=2711.78, ppl=5.63, accuracy=65.918, wps=6758.1, ups=1.64, wpb=4113.9, bsz=149.2, num_updates=38000, lr=7.25476e-05, gnorm=0.968, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=29391
2023-07-13 23:51:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 23:51:55 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.197 | trans_loss 5.557 | nll_loss 2.829 | w2v_ctc_loss 1.358 | task_loss 23.152 | contrastive_loss 0.252 | total 4003.4 | n_correct 2480 | ppl 7.11 | accuracy 61.947 | uer 16.548 | wer 18.445 | raw_wer 18.445 | bleu 20.04 | wps 1907.3 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.59
2023-07-13 23:51:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-07-13 23:51:55 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_26_38000.pt
2023-07-13 23:51:57 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_26_38000.pt
2023-07-13 23:52:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 20.04) (writing took 6.445032465970144 seconds)
2023-07-13 23:53:03 | INFO | train_inner | epoch 026:   1266 / 1474 loss=3.805, trans_loss=5.241, nll_loss=2.512, w2v_ctc_loss=1.189, task_loss=17.947, contrastive_loss=0.116, total=3996.19, n_correct=2623.37, ppl=5.7, accuracy=65.647, wps=4208.6, ups=1.05, wpb=3996.2, bsz=139.6, num_updates=38100, lr=7.24524e-05, gnorm=0.989, clip=0, loss_scale=64, train_wall=60, gb_free=17.8, wall=29486
2023-07-13 23:54:04 | INFO | train_inner | epoch 026:   1366 / 1474 loss=3.773, trans_loss=5.227, nll_loss=2.496, w2v_ctc_loss=1.153, task_loss=16.049, contrastive_loss=0.145, total=4159.74, n_correct=2745.93, ppl=5.64, accuracy=66.012, wps=6765.2, ups=1.63, wpb=4159.7, bsz=155.7, num_updates=38200, lr=7.23575e-05, gnorm=0.962, clip=0, loss_scale=64, train_wall=61, gb_free=17.4, wall=29548
2023-07-13 23:55:05 | INFO | train_inner | epoch 026:   1466 / 1474 loss=3.757, trans_loss=5.216, nll_loss=2.482, w2v_ctc_loss=1.138, task_loss=15.212, contrastive_loss=0.134, total=4165.66, n_correct=2755.4, ppl=5.59, accuracy=66.146, wps=6890.3, ups=1.65, wpb=4165.7, bsz=158.7, num_updates=38300, lr=7.22629e-05, gnorm=0.952, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=29608
2023-07-13 23:55:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-13 23:55:36 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.188 | trans_loss 5.552 | nll_loss 2.824 | w2v_ctc_loss 1.341 | task_loss 23.099 | contrastive_loss 0.25 | total 4003.4 | n_correct 2487.6 | ppl 7.08 | accuracy 62.137 | uer 16.68 | wer 18.586 | raw_wer 18.586 | bleu 20.05 | wps 1919.1 | wpb 4003.4 | bsz 141.8 | num_updates 38308 | best_bleu 20.59
2023-07-13 23:55:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38308 updates
2023-07-13 23:55:36 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.0507.pt
2023-07-13 23:55:39 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.0507.pt
2023-07-13 23:55:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.0507.pt (epoch 26 @ 38308 updates, score 20.05) (writing took 5.307618219987489 seconds)
2023-07-13 23:55:42 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-07-13 23:55:42 | INFO | train | epoch 026 | loss 3.768 | trans_loss 5.21 | nll_loss 2.473 | w2v_ctc_loss 1.15 | task_loss 16.061 | contrastive_loss 0.216 | total 4138.65 | n_correct 2740.7 | ppl 5.55 | accuracy 66.222 | wps 6281.5 | ups 1.52 | wpb 4138.6 | bsz 152.8 | num_updates 38308 | lr 7.22554e-05 | gnorm 0.961 | clip 0 | loss_scale 64 | train_wall 890 | gb_free 16.3 | wall 29645
2023-07-13 23:55:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-13 23:55:42 | INFO | fairseq.trainer | begin training epoch 27
2023-07-13 23:55:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-13 23:56:45 | INFO | train_inner | epoch 027:     92 / 1474 loss=3.739, trans_loss=5.169, nll_loss=2.418, w2v_ctc_loss=1.129, task_loss=17.296, contrastive_loss=0.092, total=4054.57, n_correct=2710.65, ppl=5.35, accuracy=66.854, wps=4036.1, ups=1, wpb=4054.6, bsz=141.2, num_updates=38400, lr=7.21688e-05, gnorm=0.97, clip=0, loss_scale=64, train_wall=59, gb_free=16.5, wall=29708
2023-07-13 23:57:46 | INFO | train_inner | epoch 027:    192 / 1474 loss=3.722, trans_loss=5.17, nll_loss=2.42, w2v_ctc_loss=1.129, task_loss=15.228, contrastive_loss=0.149, total=4195.2, n_correct=2801.29, ppl=5.35, accuracy=66.774, wps=6835.6, ups=1.63, wpb=4195.2, bsz=161.6, num_updates=38500, lr=7.2075e-05, gnorm=0.949, clip=0, loss_scale=64, train_wall=61, gb_free=17.3, wall=29770
2023-07-13 23:58:48 | INFO | train_inner | epoch 027:    292 / 1474 loss=3.744, trans_loss=5.186, nll_loss=2.441, w2v_ctc_loss=1.138, task_loss=16.113, contrastive_loss=0.115, total=4162.23, n_correct=2773.05, ppl=5.43, accuracy=66.624, wps=6807.3, ups=1.64, wpb=4162.2, bsz=152.7, num_updates=38600, lr=7.19816e-05, gnorm=0.957, clip=0, loss_scale=64, train_wall=61, gb_free=17.3, wall=29831
2023-07-13 23:58:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-14 00:05:20 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:11755
2023-07-14 00:05:20 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11755
2023-07-14 00:05:20 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11755
2023-07-14 00:05:20 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11755
2023-07-14 00:05:20 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:11755
2023-07-14 00:05:20 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:11755
2023-07-14 00:05:20 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:11755
2023-07-14 00:05:20 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11755
2023-07-14 00:05:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-14 00:05:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-14 00:05:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-14 00:05:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-14 00:05:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-14 00:05:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-14 00:05:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-14 00:05:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-14 00:05:21 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-14 00:05:21 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-14 00:05:21 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-14 00:05:21 | INFO | fairseq.distributed.utils | initialized host test1 as rank 3
2023-07-14 00:05:21 | INFO | fairseq.distributed.utils | initialized host test1 as rank 1
2023-07-14 00:05:21 | INFO | fairseq.distributed.utils | initialized host test1 as rank 7
2023-07-14 00:05:21 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-14 00:05:21 | INFO | fairseq.distributed.utils | initialized host test1 as rank 0
2023-07-14 00:05:21 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-14 00:05:21 | INFO | fairseq.distributed.utils | initialized host test1 as rank 4
2023-07-14 00:05:21 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-14 00:05:21 | INFO | fairseq.distributed.utils | initialized host test1 as rank 6
2023-07-14 00:05:21 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-14 00:05:21 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-14 00:05:21 | INFO | fairseq.distributed.utils | initialized host test1 as rank 5
2023-07-14 00:05:21 | INFO | fairseq.distributed.utils | initialized host test1 as rank 2
2023-07-14 00:05:23 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11755', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-14 00:05:23 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-14 00:05:23 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-14 00:05:23 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-14 00:05:23 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-14 00:05:23 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-14 00:05:28 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-14 00:05:28 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-14 00:05:28 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-14 00:05:30 | INFO | root | load pretrained hubert
2023-07-14 00:05:33 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-14 00:05:34 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-14 00:05:36 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-14 00:05:36 | INFO | root | share the sematic adapter and textual encoder
2023-07-14 00:05:36 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-14 00:05:36 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-14 00:05:36 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-14 00:05:36 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-14 00:05:36 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-14 00:05:36 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-14 00:05:36 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-14 00:05:36 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-14 00:05:36 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-14 00:05:36 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-14 00:05:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-14 00:05:46 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-14 00:05:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-14 00:05:47 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-14 00:05:47 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-14 00:05:47 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-14 00:05:47 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-14 00:05:47 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-14 00:05:47 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-14 00:05:47 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-14 00:05:47 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-14 00:05:47 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-14 00:05:47 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-14 00:05:47 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-14 00:05:47 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-14 00:05:47 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt
2023-07-14 00:05:49 | INFO | fairseq.trainer | load the task parameters
asr_weight tensor(0.0016, device='cuda:0')
mt_weight tensor(0.0260, device='cuda:0')
2023-07-14 00:05:49 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt (epoch 27 @ 38308 updates)
2023-07-14 00:05:49 | INFO | fairseq.trainer | loading train data for epoch 27
2023-07-14 00:05:49 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-14 00:05:49 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-14 00:05:49 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-14 00:05:53 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-14 00:05:57 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-14 00:06:00 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-14 00:07:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-14 00:07:04 | INFO | fairseq.trainer | begin training epoch 27
2023-07-14 00:07:04 | INFO | fairseq_cli.train | Start iterating over samples
asr_weight tensor(0.0016, device='cuda:3')
mt_weight tensor(0.0260, device='cuda:3')
asr_weight tensor(0.0016, device='cuda:5')
mt_weight tensor(0.0260, device='cuda:5')
asr_weight tensor(0.0016, device='cuda:2')
mt_weight tensor(0.0260, device='cuda:2')
asr_weight tensor(0.0016, device='cuda:4')
mt_weight tensor(0.0260, device='cuda:4')
asr_weight tensor(0.0016, device='cuda:6')
mt_weight tensor(0.0260, device='cuda:6')
asr_weight tensor(0.0016, device='cuda:1')
mt_weight tensor(0.0260, device='cuda:1')
asr_weight tensor(0.0016, device='cuda:7')
mt_weight tensor(0.0260, device='cuda:7')
2023-07-14 00:08:13 | INFO | train_inner | epoch 027:     92 / 1474 loss=3.734, trans_loss=5.167, nll_loss=2.415, w2v_ctc_loss=1.125, task_loss=16.899, contrastive_loss=0.093, total=4095.52, n_correct=2742.38, ppl=5.33, accuracy=66.96, wps=6764.8, ups=1.65, wpb=4095.5, bsz=144.3, num_updates=38400, lr=7.21688e-05, gnorm=0.972, clip=0, loss_scale=64, train_wall=61, gb_free=16.5, wall=146
2023-07-14 00:09:15 | INFO | train_inner | epoch 027:    192 / 1474 loss=3.725, trans_loss=5.175, nll_loss=2.427, w2v_ctc_loss=1.128, task_loss=15.202, contrastive_loss=0.149, total=4195.2, n_correct=2801, ppl=5.38, accuracy=66.767, wps=6778.8, ups=1.62, wpb=4195.2, bsz=161.6, num_updates=38500, lr=7.2075e-05, gnorm=0.947, clip=0, loss_scale=64, train_wall=61, gb_free=17.3, wall=208
2023-07-14 00:10:16 | INFO | train_inner | epoch 027:    292 / 1474 loss=3.753, trans_loss=5.193, nll_loss=2.45, w2v_ctc_loss=1.152, task_loss=16.094, contrastive_loss=0.117, total=4162.23, n_correct=2770.52, ppl=5.46, accuracy=66.563, wps=6754, ups=1.62, wpb=4162.2, bsz=152.7, num_updates=38600, lr=7.19816e-05, gnorm=0.959, clip=0, loss_scale=64, train_wall=61, gb_free=17.3, wall=270
2023-07-14 00:11:18 | INFO | train_inner | epoch 027:    392 / 1474 loss=3.779, trans_loss=5.202, nll_loss=2.462, w2v_ctc_loss=1.141, task_loss=16.826, contrastive_loss=0.481, total=4079.05, n_correct=2705.34, ppl=5.51, accuracy=66.323, wps=6575.2, ups=1.61, wpb=4079.1, bsz=148.6, num_updates=38700, lr=7.18885e-05, gnorm=0.971, clip=0, loss_scale=64, train_wall=62, gb_free=17.1, wall=332
2023-07-14 00:12:20 | INFO | train_inner | epoch 027:    492 / 1474 loss=3.758, trans_loss=5.205, nll_loss=2.467, w2v_ctc_loss=1.137, task_loss=14.695, contrastive_loss=0.353, total=4243.25, n_correct=2812.8, ppl=5.53, accuracy=66.289, wps=6881.5, ups=1.62, wpb=4243.2, bsz=165.5, num_updates=38800, lr=7.17958e-05, gnorm=0.952, clip=0, loss_scale=64, train_wall=61, gb_free=15.9, wall=393
2023-07-14 00:13:21 | INFO | train_inner | epoch 027:    592 / 1474 loss=3.748, trans_loss=5.191, nll_loss=2.448, w2v_ctc_loss=1.135, task_loss=15.641, contrastive_loss=0.232, total=4137.92, n_correct=2752.44, ppl=5.46, accuracy=66.517, wps=6794.1, ups=1.64, wpb=4137.9, bsz=156.7, num_updates=38900, lr=7.17035e-05, gnorm=0.962, clip=0, loss_scale=64, train_wall=60, gb_free=16.1, wall=454
2023-07-14 00:14:22 | INFO | train_inner | epoch 027:    692 / 1474 loss=3.764, trans_loss=5.203, nll_loss=2.463, w2v_ctc_loss=1.148, task_loss=16.137, contrastive_loss=0.19, total=4158.48, n_correct=2758.21, ppl=5.51, accuracy=66.327, wps=6793.6, ups=1.63, wpb=4158.5, bsz=152, num_updates=39000, lr=7.16115e-05, gnorm=0.971, clip=0, loss_scale=64, train_wall=61, gb_free=15.9, wall=515
2023-07-14 00:15:23 | INFO | train_inner | epoch 027:    792 / 1474 loss=3.761, trans_loss=5.2, nll_loss=2.459, w2v_ctc_loss=1.146, task_loss=17.002, contrastive_loss=0.113, total=4100.88, n_correct=2722.09, ppl=5.5, accuracy=66.378, wps=6704.2, ups=1.63, wpb=4100.9, bsz=146.1, num_updates=39100, lr=7.15199e-05, gnorm=0.968, clip=0, loss_scale=64, train_wall=61, gb_free=15.9, wall=577
2023-07-14 00:16:24 | INFO | train_inner | epoch 027:    892 / 1474 loss=3.752, trans_loss=5.201, nll_loss=2.46, w2v_ctc_loss=1.123, task_loss=16.522, contrastive_loss=0.102, total=4111.94, n_correct=2729.04, ppl=5.5, accuracy=66.369, wps=6757.1, ups=1.64, wpb=4111.9, bsz=147.4, num_updates=39200, lr=7.14286e-05, gnorm=0.958, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=637
2023-07-14 00:17:26 | INFO | train_inner | epoch 027:    992 / 1474 loss=3.771, trans_loss=5.204, nll_loss=2.466, w2v_ctc_loss=1.136, task_loss=15.616, contrastive_loss=0.474, total=4189.27, n_correct=2775.69, ppl=5.53, accuracy=66.257, wps=6801.5, ups=1.62, wpb=4189.3, bsz=157.5, num_updates=39300, lr=7.13376e-05, gnorm=0.949, clip=0, loss_scale=64, train_wall=61, gb_free=14.6, wall=699
2023-07-14 00:18:27 | INFO | train_inner | epoch 027:   1092 / 1474 loss=3.746, trans_loss=5.192, nll_loss=2.451, w2v_ctc_loss=1.131, task_loss=15.958, contrastive_loss=0.138, total=4160.42, n_correct=2763.22, ppl=5.47, accuracy=66.417, wps=6813.9, ups=1.64, wpb=4160.4, bsz=153.7, num_updates=39400, lr=7.1247e-05, gnorm=0.958, clip=0, loss_scale=64, train_wall=61, gb_free=17.2, wall=760
2023-07-14 00:19:28 | INFO | train_inner | epoch 027:   1192 / 1474 loss=3.777, trans_loss=5.215, nll_loss=2.48, w2v_ctc_loss=1.167, task_loss=16.812, contrastive_loss=0.145, total=4103.72, n_correct=2715.12, ppl=5.58, accuracy=66.162, wps=6708.8, ups=1.63, wpb=4103.7, bsz=148.6, num_updates=39500, lr=7.11568e-05, gnorm=0.98, clip=0, loss_scale=64, train_wall=61, gb_free=17.8, wall=821
2023-07-14 00:20:29 | INFO | train_inner | epoch 027:   1292 / 1474 loss=3.78, trans_loss=5.218, nll_loss=2.483, w2v_ctc_loss=1.148, task_loss=17.197, contrastive_loss=0.249, total=4065.94, n_correct=2687.03, ppl=5.59, accuracy=66.086, wps=6671.7, ups=1.64, wpb=4065.9, bsz=146.2, num_updates=39600, lr=7.10669e-05, gnorm=0.975, clip=0, loss_scale=64, train_wall=61, gb_free=16.3, wall=882
2023-07-14 00:21:30 | INFO | train_inner | epoch 027:   1392 / 1474 loss=3.759, trans_loss=5.206, nll_loss=2.469, w2v_ctc_loss=1.14, task_loss=15.121, contrastive_loss=0.214, total=4149.21, n_correct=2747.73, ppl=5.54, accuracy=66.223, wps=6820.4, ups=1.64, wpb=4149.2, bsz=156.3, num_updates=39700, lr=7.09773e-05, gnorm=0.958, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=943
2023-07-14 00:22:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-07-14 00:22:46 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.188 | trans_loss 5.552 | nll_loss 2.821 | w2v_ctc_loss 1.341 | task_loss 23.089 | contrastive_loss 0.25 | total 4003.4 | n_correct 2494.4 | ppl 7.06 | accuracy 62.307 | uer 16.54 | wer 18.4 | raw_wer 18.4 | bleu 20.15 | wps 1980.1 | wpb 4003.4 | bsz 141.8 | num_updates 39782 | best_bleu 20.59
2023-07-14 00:22:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39782 updates
2023-07-14 00:22:46 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.1505.pt
2023-07-14 00:22:48 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.1505.pt
2023-07-14 00:22:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.1505.pt (epoch 27 @ 39782 updates, score 20.15) (writing took 5.390043628984131 seconds)
2023-07-14 00:22:51 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-07-14 00:22:51 | INFO | train | epoch 027 | loss 3.757 | trans_loss 5.198 | nll_loss 2.457 | w2v_ctc_loss 1.14 | task_loss 16.045 | contrastive_loss 0.215 | total 4138.65 | n_correct 2747.99 | ppl 5.49 | accuracy 66.398 | wps 6530.9 | ups 1.58 | wpb 4138.6 | bsz 152.8 | num_updates 39782 | lr 7.09042e-05 | gnorm 0.963 | clip 0 | loss_scale 64 | train_wall 902 | gb_free 17.9 | wall 1024
2023-07-14 00:22:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-14 00:22:51 | INFO | fairseq.trainer | begin training epoch 28
2023-07-14 00:22:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-14 00:23:10 | INFO | train_inner | epoch 028:     18 / 1474 loss=3.743, trans_loss=5.192, nll_loss=2.451, w2v_ctc_loss=1.128, task_loss=15.531, contrastive_loss=0.119, total=4106.72, n_correct=2729.98, ppl=5.47, accuracy=66.476, wps=4119.6, ups=1, wpb=4106.7, bsz=152.5, num_updates=39800, lr=7.08881e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=1043
2023-07-14 00:24:10 | INFO | train_inner | epoch 028:    118 / 1474 loss=3.731, trans_loss=5.164, nll_loss=2.412, w2v_ctc_loss=1.123, task_loss=16.87, contrastive_loss=0.111, total=4103.42, n_correct=2747.46, ppl=5.32, accuracy=66.955, wps=6739.7, ups=1.64, wpb=4103.4, bsz=146, num_updates=39900, lr=7.07992e-05, gnorm=0.962, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=1104
2023-07-14 00:25:11 | INFO | train_inner | epoch 028:    218 / 1474 loss=3.72, trans_loss=5.17, nll_loss=2.421, w2v_ctc_loss=1.114, task_loss=15.001, contrastive_loss=0.126, total=4200.12, n_correct=2810.01, ppl=5.35, accuracy=66.903, wps=6900.5, ups=1.64, wpb=4200.1, bsz=158.9, num_updates=40000, lr=7.07107e-05, gnorm=0.958, clip=0, loss_scale=64, train_wall=60, gb_free=11.5, wall=1164
2023-07-14 00:25:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-14 00:25:36 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.184 | trans_loss 5.557 | nll_loss 2.831 | w2v_ctc_loss 1.314 | task_loss 23.152 | contrastive_loss 0.249 | total 4003.4 | n_correct 2491.8 | ppl 7.12 | accuracy 62.242 | uer 16.622 | wer 18.579 | raw_wer 18.579 | bleu 20.27 | wps 2157.8 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.59
2023-07-14 00:25:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-07-14 00:25:36 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_28_40000.pt
2023-07-14 00:25:38 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_28_40000.pt
2023-07-14 00:25:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 20.27) (writing took 6.425927915028296 seconds)
asr_weight tensor(0.0260, device='cuda:0')
mt_weight tensor(0.0016, device='cuda:0')
2023-07-14 00:26:44 | INFO | train_inner | epoch 028:    318 / 1474 loss=3.774, trans_loss=5.192, nll_loss=2.45, w2v_ctc_loss=1.115, task_loss=16.041, contrastive_loss=0.786, total=4147.36, n_correct=2760.56, ppl=5.46, accuracy=66.562, wps=4464.2, ups=1.08, wpb=4147.4, bsz=157.7, num_updates=40100, lr=7.06225e-05, gnorm=0.96, clip=0, loss_scale=64, train_wall=61, gb_free=16.8, wall=1257
2023-07-14 00:27:46 | INFO | train_inner | epoch 028:    418 / 1474 loss=3.747, trans_loss=5.185, nll_loss=2.44, w2v_ctc_loss=1.141, task_loss=16.601, contrastive_loss=0.101, total=4087.34, n_correct=2725.78, ppl=5.43, accuracy=66.688, wps=6653.2, ups=1.63, wpb=4087.3, bsz=147.6, num_updates=40200, lr=7.05346e-05, gnorm=0.959, clip=0, loss_scale=64, train_wall=61, gb_free=17, wall=1319
2023-07-14 00:28:47 | INFO | train_inner | epoch 028:    518 / 1474 loss=3.743, trans_loss=5.181, nll_loss=2.435, w2v_ctc_loss=1.133, task_loss=16.609, contrastive_loss=0.123, total=4099.71, n_correct=2733.68, ppl=5.41, accuracy=66.68, wps=6673.2, ups=1.63, wpb=4099.7, bsz=148.1, num_updates=40300, lr=7.0447e-05, gnorm=0.964, clip=0, loss_scale=64, train_wall=61, gb_free=15.5, wall=1380
2023-07-14 00:29:48 | INFO | train_inner | epoch 028:    618 / 1474 loss=3.748, trans_loss=5.19, nll_loss=2.447, w2v_ctc_loss=1.136, task_loss=16.263, contrastive_loss=0.127, total=4177.06, n_correct=2778.35, ppl=5.45, accuracy=66.514, wps=6848.3, ups=1.64, wpb=4177.1, bsz=152, num_updates=40400, lr=7.03598e-05, gnorm=0.96, clip=0, loss_scale=128, train_wall=61, gb_free=17.4, wall=1441
2023-07-14 00:30:49 | INFO | train_inner | epoch 028:    718 / 1474 loss=3.744, trans_loss=5.191, nll_loss=2.45, w2v_ctc_loss=1.125, task_loss=14.411, contrastive_loss=0.348, total=4190.74, n_correct=2791.88, ppl=5.46, accuracy=66.62, wps=6871.3, ups=1.64, wpb=4190.7, bsz=164.2, num_updates=40500, lr=7.02728e-05, gnorm=0.96, clip=0, loss_scale=128, train_wall=61, gb_free=15.7, wall=1502
2023-07-14 00:31:50 | INFO | train_inner | epoch 028:    818 / 1474 loss=3.733, trans_loss=5.182, nll_loss=2.437, w2v_ctc_loss=1.125, task_loss=15.872, contrastive_loss=0.112, total=4091.75, n_correct=2728.85, ppl=5.42, accuracy=66.692, wps=6721.3, ups=1.64, wpb=4091.8, bsz=153, num_updates=40600, lr=7.01862e-05, gnorm=0.972, clip=0, loss_scale=128, train_wall=60, gb_free=16.7, wall=1563
2023-07-14 00:32:52 | INFO | train_inner | epoch 028:    918 / 1474 loss=3.752, trans_loss=5.19, nll_loss=2.446, w2v_ctc_loss=1.126, task_loss=16.546, contrastive_loss=0.232, total=4123.89, n_correct=2744.97, ppl=5.45, accuracy=66.563, wps=6675.2, ups=1.62, wpb=4123.9, bsz=150.5, num_updates=40700, lr=7.01e-05, gnorm=0.96, clip=0, loss_scale=128, train_wall=61, gb_free=17.3, wall=1625
2023-07-14 00:33:53 | INFO | train_inner | epoch 028:   1018 / 1474 loss=3.77, trans_loss=5.203, nll_loss=2.464, w2v_ctc_loss=1.147, task_loss=15.602, contrastive_loss=0.337, total=4176.06, n_correct=2768.9, ppl=5.52, accuracy=66.304, wps=6795.4, ups=1.63, wpb=4176.1, bsz=155.7, num_updates=40800, lr=7.0014e-05, gnorm=0.977, clip=0, loss_scale=128, train_wall=61, gb_free=17, wall=1686
2023-07-14 00:34:55 | INFO | train_inner | epoch 028:   1118 / 1474 loss=3.739, trans_loss=5.185, nll_loss=2.441, w2v_ctc_loss=1.134, task_loss=15.599, contrastive_loss=0.152, total=4206.08, n_correct=2801.46, ppl=5.43, accuracy=66.605, wps=6783.7, ups=1.61, wpb=4206.1, bsz=158.7, num_updates=40900, lr=6.99284e-05, gnorm=0.946, clip=0, loss_scale=128, train_wall=62, gb_free=17.3, wall=1748
2023-07-14 00:35:56 | INFO | train_inner | epoch 028:   1218 / 1474 loss=3.736, trans_loss=5.188, nll_loss=2.446, w2v_ctc_loss=1.118, task_loss=15.747, contrastive_loss=0.127, total=4109.72, n_correct=2737.98, ppl=5.45, accuracy=66.622, wps=6789.6, ups=1.65, wpb=4109.7, bsz=153.5, num_updates=41000, lr=6.9843e-05, gnorm=0.949, clip=0, loss_scale=128, train_wall=60, gb_free=16.3, wall=1809
2023-07-14 00:36:57 | INFO | train_inner | epoch 028:   1318 / 1474 loss=3.769, trans_loss=5.2, nll_loss=2.46, w2v_ctc_loss=1.149, task_loss=17.497, contrastive_loss=0.153, total=4085.44, n_correct=2709.41, ppl=5.5, accuracy=66.319, wps=6666.9, ups=1.63, wpb=4085.4, bsz=142.8, num_updates=41100, lr=6.9758e-05, gnorm=0.977, clip=0, loss_scale=128, train_wall=61, gb_free=16.5, wall=1870
2023-07-14 00:37:58 | INFO | train_inner | epoch 028:   1418 / 1474 loss=3.767, trans_loss=5.204, nll_loss=2.464, w2v_ctc_loss=1.139, task_loss=17.087, contrastive_loss=0.196, total=4137.47, n_correct=2741.4, ppl=5.52, accuracy=66.258, wps=6765.2, ups=1.64, wpb=4137.5, bsz=147.4, num_updates=41200, lr=6.96733e-05, gnorm=0.972, clip=0, loss_scale=128, train_wall=61, gb_free=17, wall=1931
2023-07-14 00:38:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
asr_weight tensor(0.0260, device='cuda:7')
mt_weight tensor(0.0016, device='cuda:7')
asr_weight tensor(0.0260, device='cuda:5')
mt_weight tensor(0.0016, device='cuda:5')
asr_weight tensor(0.0260, device='cuda:6')
mt_weight tensor(0.0016, device='cuda:6')
asr_weight tensor(0.0260, device='cuda:2')
mt_weight tensor(0.0016, device='cuda:2')
asr_weight tensor(0.0260, device='cuda:4')
mt_weight tensor(0.0016, device='cuda:4')
asr_weight tensor(0.0260, device='cuda:1')
mt_weight tensor(0.0016, device='cuda:1')
asr_weight tensor(0.0260, device='cuda:3')
mt_weight tensor(0.0016, device='cuda:3')
2023-07-14 00:38:59 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.188 | trans_loss 5.553 | nll_loss 2.825 | w2v_ctc_loss 1.336 | task_loss 23.17 | contrastive_loss 0.253 | total 4003.4 | n_correct 2494.3 | ppl 7.09 | accuracy 62.305 | uer 16.744 | wer 18.724 | raw_wer 18.724 | bleu 20.34 | wps 1867.8 | wpb 4003.4 | bsz 141.8 | num_updates 41256 | best_bleu 20.59
2023-07-14 00:38:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41256 updates
2023-07-14 00:38:59 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.3404.pt
2023-07-14 00:39:01 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.3404.pt
2023-07-14 00:39:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.3404.pt (epoch 28 @ 41256 updates, score 20.34) (writing took 5.326692951028235 seconds)
2023-07-14 00:39:05 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-07-14 00:39:05 | INFO | train | epoch 028 | loss 3.747 | trans_loss 5.187 | nll_loss 2.443 | w2v_ctc_loss 1.13 | task_loss 16.039 | contrastive_loss 0.215 | total 4138.65 | n_correct 2756.57 | ppl 5.44 | accuracy 66.605 | wps 6267.2 | ups 1.51 | wpb 4138.6 | bsz 152.8 | num_updates 41256 | lr 6.9626e-05 | gnorm 0.962 | clip 0 | loss_scale 128 | train_wall 895 | gb_free 16.7 | wall 1998
2023-07-14 00:39:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-14 00:39:05 | INFO | fairseq.trainer | begin training epoch 29
2023-07-14 00:39:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-14 00:39:39 | INFO | train_inner | epoch 029:     44 / 1474 loss=3.721, trans_loss=5.165, nll_loss=2.416, w2v_ctc_loss=1.122, task_loss=15.393, contrastive_loss=0.138, total=4168.25, n_correct=2793.19, ppl=5.34, accuracy=67.011, wps=4117.5, ups=0.99, wpb=4168.2, bsz=157.9, num_updates=41300, lr=6.95889e-05, gnorm=0.952, clip=0, loss_scale=128, train_wall=60, gb_free=17.8, wall=2033
2023-07-14 00:39:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-14 00:40:42 | INFO | train_inner | epoch 029:    145 / 1474 loss=3.717, trans_loss=5.161, nll_loss=2.409, w2v_ctc_loss=1.101, task_loss=15.851, contrastive_loss=0.158, total=4110.31, n_correct=2755.63, ppl=5.31, accuracy=67.042, wps=6561.6, ups=1.6, wpb=4110.3, bsz=152.8, num_updates=41400, lr=6.95048e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=62, gb_free=14.4, wall=2095
2023-07-14 00:41:44 | INFO | train_inner | epoch 029:    245 / 1474 loss=3.715, trans_loss=5.159, nll_loss=2.406, w2v_ctc_loss=1.097, task_loss=14.705, contrastive_loss=0.354, total=4197.24, n_correct=2816.6, ppl=5.3, accuracy=67.106, wps=6733.5, ups=1.6, wpb=4197.2, bsz=165, num_updates=41500, lr=6.9421e-05, gnorm=0.954, clip=0, loss_scale=64, train_wall=62, gb_free=17.3, wall=2158
2023-07-14 00:42:45 | INFO | train_inner | epoch 029:    345 / 1474 loss=3.751, trans_loss=5.183, nll_loss=2.437, w2v_ctc_loss=1.144, task_loss=17.258, contrastive_loss=0.117, total=4092.21, n_correct=2731.82, ppl=5.42, accuracy=66.757, wps=6713.7, ups=1.64, wpb=4092.2, bsz=145.3, num_updates=41600, lr=6.93375e-05, gnorm=0.974, clip=0, loss_scale=64, train_wall=61, gb_free=15.9, wall=2219
2023-07-14 00:43:46 | INFO | train_inner | epoch 029:    445 / 1474 loss=3.716, trans_loss=5.156, nll_loss=2.403, w2v_ctc_loss=1.119, task_loss=15.459, contrastive_loss=0.104, total=4161.27, n_correct=2794.99, ppl=5.29, accuracy=67.167, wps=6857.2, ups=1.65, wpb=4161.3, bsz=153.9, num_updates=41700, lr=6.92543e-05, gnorm=0.968, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=2279
2023-07-14 00:44:48 | INFO | train_inner | epoch 029:    545 / 1474 loss=3.763, trans_loss=5.188, nll_loss=2.443, w2v_ctc_loss=1.134, task_loss=16.913, contrastive_loss=0.296, total=4159.68, n_correct=2772.29, ppl=5.44, accuracy=66.647, wps=6767.2, ups=1.63, wpb=4159.7, bsz=148.2, num_updates=41800, lr=6.91714e-05, gnorm=0.968, clip=0, loss_scale=64, train_wall=61, gb_free=16.7, wall=2341
2023-07-14 00:45:48 | INFO | train_inner | epoch 029:    645 / 1474 loss=3.74, trans_loss=5.177, nll_loss=2.431, w2v_ctc_loss=1.12, task_loss=15.157, contrastive_loss=0.432, total=4143.76, n_correct=2767.34, ppl=5.39, accuracy=66.783, wps=6828.3, ups=1.65, wpb=4143.8, bsz=159.4, num_updates=41900, lr=6.90889e-05, gnorm=0.975, clip=0, loss_scale=64, train_wall=60, gb_free=17.4, wall=2401
2023-07-14 00:46:50 | INFO | train_inner | epoch 029:    745 / 1474 loss=3.727, trans_loss=5.172, nll_loss=2.424, w2v_ctc_loss=1.115, task_loss=14.867, contrastive_loss=0.27, total=4234.8, n_correct=2832.48, ppl=5.37, accuracy=66.886, wps=6873.6, ups=1.62, wpb=4234.8, bsz=164.1, num_updates=42000, lr=6.90066e-05, gnorm=0.96, clip=0, loss_scale=64, train_wall=61, gb_free=17, wall=2463
2023-07-14 00:46:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-14 00:47:16 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.209 | trans_loss 5.56 | nll_loss 2.833 | w2v_ctc_loss 1.387 | task_loss 23.219 | contrastive_loss 0.259 | total 4003.4 | n_correct 2482.9 | ppl 7.13 | accuracy 62.02 | uer 16.909 | wer 18.735 | raw_wer 18.735 | bleu 20.23 | wps 1923.4 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.59
2023-07-14 00:47:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-07-14 00:47:16 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_29_42000.pt
2023-07-14 00:47:18 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_29_42000.pt
2023-07-14 00:47:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 20.23) (writing took 6.230553357047029 seconds)
2023-07-14 00:48:24 | INFO | train_inner | epoch 029:    845 / 1474 loss=3.751, trans_loss=5.19, nll_loss=2.446, w2v_ctc_loss=1.122, task_loss=17.739, contrastive_loss=0.105, total=4033.21, n_correct=2678.92, ppl=5.45, accuracy=66.422, wps=4291.4, ups=1.06, wpb=4033.2, bsz=140.8, num_updates=42100, lr=6.89246e-05, gnorm=0.98, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=2557
2023-07-14 00:49:24 | INFO | train_inner | epoch 029:    945 / 1474 loss=3.744, trans_loss=5.186, nll_loss=2.442, w2v_ctc_loss=1.127, task_loss=16.359, contrastive_loss=0.123, total=4085.97, n_correct=2723.89, ppl=5.43, accuracy=66.664, wps=6771.9, ups=1.66, wpb=4086, bsz=148.4, num_updates=42200, lr=6.88428e-05, gnorm=0.979, clip=0, loss_scale=64, train_wall=60, gb_free=17.3, wall=2617
2023-07-14 00:50:25 | INFO | train_inner | epoch 029:   1045 / 1474 loss=3.736, trans_loss=5.174, nll_loss=2.427, w2v_ctc_loss=1.114, task_loss=16.057, contrastive_loss=0.271, total=4140.84, n_correct=2764.91, ppl=5.38, accuracy=66.772, wps=6847.2, ups=1.65, wpb=4140.8, bsz=153.4, num_updates=42300, lr=6.87614e-05, gnorm=0.975, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=2678
2023-07-14 00:51:25 | INFO | train_inner | epoch 029:   1145 / 1474 loss=3.758, trans_loss=5.189, nll_loss=2.446, w2v_ctc_loss=1.147, task_loss=17.479, contrastive_loss=0.096, total=4068.4, n_correct=2704.49, ppl=5.45, accuracy=66.476, wps=6728.4, ups=1.65, wpb=4068.4, bsz=142.1, num_updates=42400, lr=6.86803e-05, gnorm=0.98, clip=0, loss_scale=64, train_wall=60, gb_free=17.6, wall=2738
2023-07-14 00:52:26 | INFO | train_inner | epoch 029:   1245 / 1474 loss=3.75, trans_loss=5.191, nll_loss=2.449, w2v_ctc_loss=1.135, task_loss=16.467, contrastive_loss=0.109, total=4154.79, n_correct=2763.2, ppl=5.46, accuracy=66.506, wps=6820.6, ups=1.64, wpb=4154.8, bsz=149.8, num_updates=42500, lr=6.85994e-05, gnorm=0.96, clip=0, loss_scale=64, train_wall=61, gb_free=17, wall=2799
2023-07-14 00:53:27 | INFO | train_inner | epoch 029:   1345 / 1474 loss=3.735, trans_loss=5.176, nll_loss=2.43, w2v_ctc_loss=1.112, task_loss=15.71, contrastive_loss=0.24, total=4166.4, n_correct=2780.8, ppl=5.39, accuracy=66.743, wps=6804.8, ups=1.63, wpb=4166.4, bsz=155.8, num_updates=42600, lr=6.85189e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=61, gb_free=16.7, wall=2860
2023-07-14 00:54:29 | INFO | train_inner | epoch 029:   1445 / 1474 loss=3.744, trans_loss=5.184, nll_loss=2.441, w2v_ctc_loss=1.122, task_loss=15.753, contrastive_loss=0.299, total=4169.4, n_correct=2778.56, ppl=5.43, accuracy=66.642, wps=6784.8, ups=1.63, wpb=4169.4, bsz=156, num_updates=42700, lr=6.84386e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=61, gb_free=16.1, wall=2922
2023-07-14 00:54:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-14 00:55:12 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.187 | trans_loss 5.555 | nll_loss 2.824 | w2v_ctc_loss 1.329 | task_loss 23.188 | contrastive_loss 0.259 | total 4003.4 | n_correct 2483.8 | ppl 7.08 | accuracy 62.042 | uer 16.423 | wer 18.348 | raw_wer 18.348 | bleu 20.26 | wps 2022.5 | wpb 4003.4 | bsz 141.8 | num_updates 42729 | best_bleu 20.59
2023-07-14 00:55:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42729 updates
2023-07-14 00:55:12 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.2606.pt
2023-07-14 00:55:14 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.2606.pt
2023-07-14 00:55:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.2606.pt (epoch 29 @ 42729 updates, score 20.26) (writing took 5.478429567068815 seconds)
2023-07-14 00:55:18 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-07-14 00:55:18 | INFO | train | epoch 029 | loss 3.737 | trans_loss 5.176 | nll_loss 2.429 | w2v_ctc_loss 1.121 | task_loss 16.052 | contrastive_loss 0.212 | total 4138.09 | n_correct 2763.4 | ppl 5.39 | accuracy 66.779 | wps 6263.5 | ups 1.51 | wpb 4138.1 | bsz 152.7 | num_updates 42729 | lr 6.84154e-05 | gnorm 0.968 | clip 0 | loss_scale 64 | train_wall 894 | gb_free 16.4 | wall 2971
2023-07-14 00:55:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-14 00:55:18 | INFO | fairseq.trainer | begin training epoch 30
2023-07-14 00:55:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-14 00:56:09 | INFO | train_inner | epoch 030:     71 / 1474 loss=3.715, trans_loss=5.157, nll_loss=2.404, w2v_ctc_loss=1.09, task_loss=15.244, contrastive_loss=0.328, total=4176.73, n_correct=2802.08, ppl=5.29, accuracy=67.088, wps=4156.5, ups=1, wpb=4176.7, bsz=159.5, num_updates=42800, lr=6.83586e-05, gnorm=0.956, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=3022
2023-07-14 00:57:10 | INFO | train_inner | epoch 030:    171 / 1474 loss=3.702, trans_loss=5.139, nll_loss=2.381, w2v_ctc_loss=1.102, task_loss=14.959, contrastive_loss=0.196, total=4202.84, n_correct=2834.1, ppl=5.21, accuracy=67.433, wps=6936.6, ups=1.65, wpb=4202.8, bsz=159.3, num_updates=42900, lr=6.82789e-05, gnorm=0.966, clip=0, loss_scale=64, train_wall=60, gb_free=13.1, wall=3083
2023-07-14 00:58:10 | INFO | train_inner | epoch 030:    271 / 1474 loss=3.724, trans_loss=5.155, nll_loss=2.401, w2v_ctc_loss=1.124, task_loss=16.514, contrastive_loss=0.105, total=4120.08, n_correct=2763.57, ppl=5.28, accuracy=67.076, wps=6792.7, ups=1.65, wpb=4120.1, bsz=148.2, num_updates=43000, lr=6.81994e-05, gnorm=0.975, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=3144
2023-07-14 00:59:12 | INFO | train_inner | epoch 030:    371 / 1474 loss=3.708, trans_loss=5.148, nll_loss=2.392, w2v_ctc_loss=1.099, task_loss=16.093, contrastive_loss=0.111, total=4175.82, n_correct=2807.93, ppl=5.25, accuracy=67.243, wps=6822.4, ups=1.63, wpb=4175.8, bsz=153.1, num_updates=43100, lr=6.81203e-05, gnorm=0.958, clip=0, loss_scale=64, train_wall=61, gb_free=15.8, wall=3205
2023-07-14 01:00:12 | INFO | train_inner | epoch 030:    471 / 1474 loss=3.721, trans_loss=5.16, nll_loss=2.409, w2v_ctc_loss=1.113, task_loss=15.386, contrastive_loss=0.238, total=4128.9, n_correct=2766.98, ppl=5.31, accuracy=67.015, wps=6791.1, ups=1.64, wpb=4128.9, bsz=156.2, num_updates=43200, lr=6.80414e-05, gnorm=0.966, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=3266
2023-07-14 01:01:13 | INFO | train_inner | epoch 030:    571 / 1474 loss=3.718, trans_loss=5.162, nll_loss=2.41, w2v_ctc_loss=1.103, task_loss=15.688, contrastive_loss=0.164, total=4162.83, n_correct=2792.96, ppl=5.32, accuracy=67.093, wps=6823.5, ups=1.64, wpb=4162.8, bsz=155.7, num_updates=43300, lr=6.79628e-05, gnorm=0.957, clip=0, loss_scale=64, train_wall=61, gb_free=15.3, wall=3327
2023-07-14 01:02:14 | INFO | train_inner | epoch 030:    671 / 1474 loss=3.717, trans_loss=5.159, nll_loss=2.407, w2v_ctc_loss=1.109, task_loss=15.629, contrastive_loss=0.188, total=4197.56, n_correct=2811, ppl=5.3, accuracy=66.967, wps=6909.1, ups=1.65, wpb=4197.6, bsz=158.8, num_updates=43400, lr=6.78844e-05, gnorm=0.962, clip=0, loss_scale=128, train_wall=60, gb_free=16.7, wall=3387
2023-07-14 01:02:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-14 01:03:16 | INFO | train_inner | epoch 030:    772 / 1474 loss=3.745, trans_loss=5.179, nll_loss=2.433, w2v_ctc_loss=1.14, task_loss=16.942, contrastive_loss=0.125, total=4082.57, n_correct=2727.04, ppl=5.4, accuracy=66.797, wps=6658.3, ups=1.63, wpb=4082.6, bsz=146.9, num_updates=43500, lr=6.78064e-05, gnorm=0.977, clip=0, loss_scale=64, train_wall=61, gb_free=12.3, wall=3449
2023-07-14 01:04:16 | INFO | train_inner | epoch 030:    872 / 1474 loss=3.734, trans_loss=5.172, nll_loss=2.424, w2v_ctc_loss=1.113, task_loss=16.823, contrastive_loss=0.116, total=4089.18, n_correct=2734.47, ppl=5.37, accuracy=66.871, wps=6793.1, ups=1.66, wpb=4089.2, bsz=145.7, num_updates=43600, lr=6.77285e-05, gnorm=0.981, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=3509
2023-07-14 01:05:17 | INFO | train_inner | epoch 030:    972 / 1474 loss=3.736, trans_loss=5.176, nll_loss=2.429, w2v_ctc_loss=1.125, task_loss=16.253, contrastive_loss=0.155, total=4140.03, n_correct=2766.91, ppl=5.38, accuracy=66.833, wps=6799.7, ups=1.64, wpb=4140, bsz=152, num_updates=43700, lr=6.7651e-05, gnorm=0.983, clip=0, loss_scale=64, train_wall=60, gb_free=14.2, wall=3570
2023-07-14 01:06:18 | INFO | train_inner | epoch 030:   1072 / 1474 loss=3.761, trans_loss=5.185, nll_loss=2.439, w2v_ctc_loss=1.12, task_loss=17.966, contrastive_loss=0.29, total=4101.12, n_correct=2730.88, ppl=5.42, accuracy=66.589, wps=6638.3, ups=1.62, wpb=4101.1, bsz=141.4, num_updates=43800, lr=6.75737e-05, gnorm=0.974, clip=0, loss_scale=64, train_wall=61, gb_free=17, wall=3632
2023-07-14 01:07:20 | INFO | train_inner | epoch 030:   1172 / 1474 loss=3.73, trans_loss=5.172, nll_loss=2.425, w2v_ctc_loss=1.111, task_loss=15.406, contrastive_loss=0.257, total=4168.22, n_correct=2786.21, ppl=5.37, accuracy=66.844, wps=6794.3, ups=1.63, wpb=4168.2, bsz=157.3, num_updates=43900, lr=6.74967e-05, gnorm=0.978, clip=0, loss_scale=64, train_wall=61, gb_free=16.9, wall=3693
2023-07-14 01:08:21 | INFO | train_inner | epoch 030:   1272 / 1474 loss=3.757, trans_loss=5.186, nll_loss=2.442, w2v_ctc_loss=1.145, task_loss=18.024, contrastive_loss=0.119, total=4032.74, n_correct=2684.83, ppl=5.43, accuracy=66.576, wps=6634.9, ups=1.65, wpb=4032.7, bsz=140.9, num_updates=44000, lr=6.742e-05, gnorm=1, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=3754
2023-07-14 01:08:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-14 01:08:47 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.193 | trans_loss 5.555 | nll_loss 2.825 | w2v_ctc_loss 1.345 | task_loss 23.184 | contrastive_loss 0.262 | total 4003.4 | n_correct 2497.5 | ppl 7.09 | accuracy 62.384 | uer 16.63 | wer 18.508 | raw_wer 18.508 | bleu 20.57 | wps 1962.5 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.59
2023-07-14 01:08:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-07-14 01:08:47 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_30_44000.pt
2023-07-14 01:08:49 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_30_44000.pt
2023-07-14 01:08:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 20.57) (writing took 6.440419576945715 seconds)
2023-07-14 01:09:54 | INFO | train_inner | epoch 030:   1372 / 1474 loss=3.708, trans_loss=5.162, nll_loss=2.414, w2v_ctc_loss=1.1, task_loss=15.092, contrastive_loss=0.143, total=4166.96, n_correct=2792.75, ppl=5.33, accuracy=67.021, wps=4452.7, ups=1.07, wpb=4167, bsz=161.1, num_updates=44100, lr=6.73435e-05, gnorm=0.958, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=3847
2023-07-14 01:10:54 | INFO | train_inner | epoch 030:   1472 / 1474 loss=3.742, trans_loss=5.179, nll_loss=2.435, w2v_ctc_loss=1.106, task_loss=15.363, contrastive_loss=0.43, total=4125.17, n_correct=2754.22, ppl=5.41, accuracy=66.766, wps=6886.3, ups=1.67, wpb=4125.2, bsz=155, num_updates=44200, lr=6.72673e-05, gnorm=0.976, clip=0, loss_scale=64, train_wall=59, gb_free=17.2, wall=3907
2023-07-14 01:10:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-14 01:11:21 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.193 | trans_loss 5.55 | nll_loss 2.821 | w2v_ctc_loss 1.358 | task_loss 23.209 | contrastive_loss 0.253 | total 4003.4 | n_correct 2496.8 | ppl 7.07 | accuracy 62.367 | uer 16.638 | wer 18.392 | raw_wer 18.392 | bleu 20.49 | wps 1977.6 | wpb 4003.4 | bsz 141.8 | num_updates 44202 | best_bleu 20.59
2023-07-14 01:11:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44202 updates
2023-07-14 01:11:21 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.4906.pt
2023-07-14 01:11:24 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.4906.pt
2023-07-14 01:11:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.4906.pt (epoch 30 @ 44202 updates, score 20.49) (writing took 5.4796172849601135 seconds)
2023-07-14 01:11:27 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-07-14 01:11:27 | INFO | train | epoch 030 | loss 3.728 | trans_loss 5.166 | nll_loss 2.416 | w2v_ctc_loss 1.114 | task_loss 16.079 | contrastive_loss 0.2 | total 4137.39 | n_correct 2769.91 | ppl 5.34 | accuracy 66.948 | wps 6287 | ups 1.52 | wpb 4137.4 | bsz 152.6 | num_updates 44202 | lr 6.72658e-05 | gnorm 0.972 | clip 0 | loss_scale 64 | train_wall 890 | gb_free 17.2 | wall 3940
2023-07-14 01:11:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-14 01:11:27 | INFO | fairseq.trainer | begin training epoch 31
2023-07-14 01:11:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-14 01:12:35 | INFO | train_inner | epoch 031:     98 / 1474 loss=3.712, trans_loss=5.143, nll_loss=2.386, w2v_ctc_loss=1.11, task_loss=16.646, contrastive_loss=0.115, total=4081.34, n_correct=2750.56, ppl=5.23, accuracy=67.394, wps=4035.1, ups=0.99, wpb=4081.3, bsz=147.3, num_updates=44300, lr=6.71913e-05, gnorm=0.97, clip=0, loss_scale=64, train_wall=61, gb_free=16.6, wall=4008
2023-07-14 01:12:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-14 01:13:37 | INFO | train_inner | epoch 031:    199 / 1474 loss=3.716, trans_loss=5.149, nll_loss=2.393, w2v_ctc_loss=1.108, task_loss=16.733, contrastive_loss=0.124, total=4129.26, n_correct=2776.82, ppl=5.25, accuracy=67.247, wps=6667.9, ups=1.61, wpb=4129.3, bsz=148.7, num_updates=44400, lr=6.71156e-05, gnorm=0.965, clip=0, loss_scale=32, train_wall=61, gb_free=16.9, wall=4070
2023-07-14 01:14:39 | INFO | train_inner | epoch 031:    299 / 1474 loss=3.721, trans_loss=5.151, nll_loss=2.395, w2v_ctc_loss=1.105, task_loss=16.426, contrastive_loss=0.242, total=4149.21, n_correct=2790.66, ppl=5.26, accuracy=67.258, wps=6736.3, ups=1.62, wpb=4149.2, bsz=150.8, num_updates=44500, lr=6.70402e-05, gnorm=0.969, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=4132
2023-07-14 01:15:39 | INFO | train_inner | epoch 031:    399 / 1474 loss=3.724, trans_loss=5.155, nll_loss=2.401, w2v_ctc_loss=1.103, task_loss=17.538, contrastive_loss=0.118, total=4092.62, n_correct=2745.56, ppl=5.28, accuracy=67.086, wps=6777, ups=1.66, wpb=4092.6, bsz=142.8, num_updates=44600, lr=6.6965e-05, gnorm=0.974, clip=0, loss_scale=32, train_wall=60, gb_free=17.3, wall=4192
2023-07-14 01:16:40 | INFO | train_inner | epoch 031:    499 / 1474 loss=3.72, trans_loss=5.153, nll_loss=2.398, w2v_ctc_loss=1.122, task_loss=16.78, contrastive_loss=0.135, total=4111.85, n_correct=2759.34, ppl=5.27, accuracy=67.107, wps=6774.2, ups=1.65, wpb=4111.9, bsz=150.1, num_updates=44700, lr=6.689e-05, gnorm=0.971, clip=0, loss_scale=32, train_wall=60, gb_free=11.5, wall=4253
2023-07-14 01:17:40 | INFO | train_inner | epoch 031:    599 / 1474 loss=3.721, trans_loss=5.157, nll_loss=2.404, w2v_ctc_loss=1.111, task_loss=16.779, contrastive_loss=0.115, total=4083.44, n_correct=2741.48, ppl=5.29, accuracy=67.137, wps=6753.4, ups=1.65, wpb=4083.4, bsz=147.3, num_updates=44800, lr=6.68153e-05, gnorm=0.982, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=4313
2023-07-14 01:18:41 | INFO | train_inner | epoch 031:    699 / 1474 loss=3.696, trans_loss=5.143, nll_loss=2.387, w2v_ctc_loss=1.085, task_loss=15.264, contrastive_loss=0.117, total=4213.98, n_correct=2836.62, ppl=5.23, accuracy=67.315, wps=6951, ups=1.65, wpb=4214, bsz=157.8, num_updates=44900, lr=6.67409e-05, gnorm=0.957, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=4374
2023-07-14 01:19:42 | INFO | train_inner | epoch 031:    799 / 1474 loss=3.73, trans_loss=5.161, nll_loss=2.409, w2v_ctc_loss=1.101, task_loss=16.846, contrastive_loss=0.252, total=4097.37, n_correct=2744.82, ppl=5.31, accuracy=66.99, wps=6727.4, ups=1.64, wpb=4097.4, bsz=147.9, num_updates=45000, lr=6.66667e-05, gnorm=0.968, clip=0, loss_scale=32, train_wall=60, gb_free=13.3, wall=4435
asr_weight tensor(0.0260, device='cuda:0')
mt_weight tensor(0.0016, device='cuda:0')
2023-07-14 01:20:42 | INFO | train_inner | epoch 031:    899 / 1474 loss=3.72, trans_loss=5.155, nll_loss=2.401, w2v_ctc_loss=1.108, task_loss=16.742, contrastive_loss=0.145, total=4096.72, n_correct=2747.61, ppl=5.28, accuracy=67.069, wps=6768.3, ups=1.65, wpb=4096.7, bsz=148, num_updates=45100, lr=6.65927e-05, gnorm=0.981, clip=0, loss_scale=32, train_wall=60, gb_free=17.4, wall=4496
2023-07-14 01:21:42 | INFO | train_inner | epoch 031:    999 / 1474 loss=3.726, trans_loss=5.168, nll_loss=2.42, w2v_ctc_loss=1.103, task_loss=15.12, contrastive_loss=0.312, total=4187.84, n_correct=2803.04, ppl=5.35, accuracy=66.933, wps=6969.9, ups=1.66, wpb=4187.8, bsz=159.7, num_updates=45200, lr=6.6519e-05, gnorm=0.952, clip=0, loss_scale=32, train_wall=60, gb_free=17.4, wall=4556
2023-07-14 01:22:43 | INFO | train_inner | epoch 031:   1099 / 1474 loss=3.716, trans_loss=5.161, nll_loss=2.411, w2v_ctc_loss=1.101, task_loss=15.731, contrastive_loss=0.209, total=4149.44, n_correct=2780.97, ppl=5.32, accuracy=67.02, wps=6889, ups=1.66, wpb=4149.4, bsz=157.5, num_updates=45300, lr=6.64455e-05, gnorm=0.96, clip=0, loss_scale=32, train_wall=60, gb_free=17.7, wall=4616
2023-07-14 01:23:43 | INFO | train_inner | epoch 031:   1199 / 1474 loss=3.726, trans_loss=5.164, nll_loss=2.416, w2v_ctc_loss=1.094, task_loss=14.979, contrastive_loss=0.439, total=4189.76, n_correct=2806.71, ppl=5.34, accuracy=66.99, wps=7006.4, ups=1.67, wpb=4189.8, bsz=160.6, num_updates=45400, lr=6.63723e-05, gnorm=0.959, clip=0, loss_scale=32, train_wall=59, gb_free=13.6, wall=4676
2023-07-14 01:24:43 | INFO | train_inner | epoch 031:   1299 / 1474 loss=3.707, trans_loss=5.16, nll_loss=2.41, w2v_ctc_loss=1.1, task_loss=14.375, contrastive_loss=0.132, total=4227.44, n_correct=2836.4, ppl=5.32, accuracy=67.095, wps=6953.9, ups=1.64, wpb=4227.4, bsz=163.2, num_updates=45500, lr=6.62994e-05, gnorm=0.952, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=4736
2023-07-14 01:25:45 | INFO | train_inner | epoch 031:   1399 / 1474 loss=3.741, trans_loss=5.173, nll_loss=2.427, w2v_ctc_loss=1.103, task_loss=14.707, contrastive_loss=0.55, total=4186.05, n_correct=2801.44, ppl=5.38, accuracy=66.923, wps=6793.6, ups=1.62, wpb=4186.1, bsz=163.3, num_updates=45600, lr=6.62266e-05, gnorm=0.984, clip=0, loss_scale=32, train_wall=61, gb_free=17.6, wall=4798
2023-07-14 01:26:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
asr_weight tensor(0.0260, device='cuda:7')
mt_weight tensor(0.0016, device='cuda:7')
asr_weight tensor(0.0260, device='cuda:1')
mt_weight tensor(0.0016, device='cuda:1')
asr_weight tensor(0.0260, device='cuda:5')
mt_weight tensor(0.0016, device='cuda:5')
asr_weight tensor(0.0260, device='cuda:2')
mt_weight tensor(0.0016, device='cuda:2')
asr_weight tensor(0.0260, device='cuda:4')
mt_weight tensor(0.0016, device='cuda:4')
asr_weight tensor(0.0260, device='cuda:6')
mt_weight tensor(0.0016, device='cuda:6')
asr_weight tensor(0.0260, device='cuda:3')
mt_weight tensor(0.0016, device='cuda:3')
2023-07-14 01:26:57 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.186 | trans_loss 5.551 | nll_loss 2.821 | w2v_ctc_loss 1.331 | task_loss 23.212 | contrastive_loss 0.257 | total 4003.4 | n_correct 2497.3 | ppl 7.07 | accuracy 62.379 | uer 16.418 | wer 18.329 | raw_wer 18.329 | bleu 20.39 | wps 1949.2 | wpb 4003.4 | bsz 141.8 | num_updates 45675 | best_bleu 20.59
2023-07-14 01:26:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45675 updates
2023-07-14 01:26:57 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.3903.pt
2023-07-14 01:26:59 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.3903.pt
2023-07-14 01:27:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.3903.pt (epoch 31 @ 45675 updates, score 20.39) (writing took 5.4433621619828045 seconds)
2023-07-14 01:27:02 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-07-14 01:27:02 | INFO | train | epoch 031 | loss 3.72 | trans_loss 5.157 | nll_loss 2.405 | w2v_ctc_loss 1.105 | task_loss 16.061 | contrastive_loss 0.213 | total 4137.95 | n_correct 2776.57 | ppl 5.3 | accuracy 67.1 | wps 6518.1 | ups 1.58 | wpb 4137.9 | bsz 152.7 | num_updates 45675 | lr 6.61722e-05 | gnorm 0.968 | clip 0 | loss_scale 32 | train_wall 888 | gb_free 12.5 | wall 4875
2023-07-14 01:27:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-14 01:27:03 | INFO | fairseq.trainer | begin training epoch 32
2023-07-14 01:27:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-14 01:27:25 | INFO | train_inner | epoch 032:     25 / 1474 loss=3.721, trans_loss=5.155, nll_loss=2.402, w2v_ctc_loss=1.111, task_loss=16.912, contrastive_loss=0.108, total=4042.6, n_correct=2714.23, ppl=5.28, accuracy=67.141, wps=4028.7, ups=1, wpb=4042.6, bsz=144.4, num_updates=45700, lr=6.61541e-05, gnorm=0.985, clip=0, loss_scale=32, train_wall=59, gb_free=16.5, wall=4898
2023-07-14 01:28:26 | INFO | train_inner | epoch 032:    125 / 1474 loss=3.667, trans_loss=5.112, nll_loss=2.347, w2v_ctc_loss=1.066, task_loss=14.814, contrastive_loss=0.132, total=4227.68, n_correct=2868.41, ppl=5.09, accuracy=67.848, wps=6989.9, ups=1.65, wpb=4227.7, bsz=161.6, num_updates=45800, lr=6.60819e-05, gnorm=0.95, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=4959
2023-07-14 01:29:27 | INFO | train_inner | epoch 032:    225 / 1474 loss=3.691, trans_loss=5.139, nll_loss=2.381, w2v_ctc_loss=1.089, task_loss=15.291, contrastive_loss=0.151, total=4157.32, n_correct=2800.09, ppl=5.21, accuracy=67.353, wps=6838, ups=1.64, wpb=4157.3, bsz=160.3, num_updates=45900, lr=6.60098e-05, gnorm=0.958, clip=0, loss_scale=32, train_wall=60, gb_free=17.3, wall=5020
2023-07-14 01:30:26 | INFO | train_inner | epoch 032:    325 / 1474 loss=3.677, trans_loss=5.119, nll_loss=2.356, w2v_ctc_loss=1.069, task_loss=15.127, contrastive_loss=0.138, total=4183.45, n_correct=2836.24, ppl=5.12, accuracy=67.797, wps=6984.7, ups=1.67, wpb=4183.4, bsz=157.2, num_updates=46000, lr=6.5938e-05, gnorm=0.959, clip=0, loss_scale=32, train_wall=59, gb_free=17.7, wall=5080
2023-07-14 01:30:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-14 01:30:52 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.21 | trans_loss 5.564 | nll_loss 2.836 | w2v_ctc_loss 1.38 | task_loss 23.018 | contrastive_loss 0.266 | total 4003.4 | n_correct 2489.1 | ppl 7.14 | accuracy 62.175 | uer 16.763 | wer 18.564 | raw_wer 18.564 | bleu 20.13 | wps 2085.2 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.59
2023-07-14 01:30:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-07-14 01:30:52 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_32_46000.pt
2023-07-14 01:30:54 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_32_46000.pt
2023-07-14 01:30:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 20.13) (writing took 5.182514115003869 seconds)
2023-07-14 01:31:58 | INFO | train_inner | epoch 032:    425 / 1474 loss=3.697, trans_loss=5.134, nll_loss=2.375, w2v_ctc_loss=1.09, task_loss=15.96, contrastive_loss=0.13, total=4157.28, n_correct=2806.96, ppl=5.19, accuracy=67.519, wps=4528.5, ups=1.09, wpb=4157.3, bsz=152.9, num_updates=46100, lr=6.58665e-05, gnorm=0.964, clip=0, loss_scale=32, train_wall=61, gb_free=15.1, wall=5171
2023-07-14 01:33:00 | INFO | train_inner | epoch 032:    525 / 1474 loss=3.72, trans_loss=5.152, nll_loss=2.398, w2v_ctc_loss=1.111, task_loss=15.502, contrastive_loss=0.299, total=4198.93, n_correct=2824.68, ppl=5.27, accuracy=67.271, wps=6808.1, ups=1.62, wpb=4198.9, bsz=158.8, num_updates=46200, lr=6.57952e-05, gnorm=0.963, clip=0, loss_scale=32, train_wall=61, gb_free=17.4, wall=5233
2023-07-14 01:34:01 | INFO | train_inner | epoch 032:    625 / 1474 loss=3.721, trans_loss=5.156, nll_loss=2.403, w2v_ctc_loss=1.11, task_loss=16.555, contrastive_loss=0.148, total=4142.69, n_correct=2780.02, ppl=5.29, accuracy=67.107, wps=6797.7, ups=1.64, wpb=4142.7, bsz=150.8, num_updates=46300, lr=6.57241e-05, gnorm=0.97, clip=0, loss_scale=32, train_wall=61, gb_free=17.5, wall=5294
2023-07-14 01:35:02 | INFO | train_inner | epoch 032:    725 / 1474 loss=3.722, trans_loss=5.155, nll_loss=2.402, w2v_ctc_loss=1.121, task_loss=16.378, contrastive_loss=0.116, total=4154.59, n_correct=2788.69, ppl=5.28, accuracy=67.123, wps=6820.1, ups=1.64, wpb=4154.6, bsz=150.9, num_updates=46400, lr=6.56532e-05, gnorm=0.972, clip=0, loss_scale=64, train_wall=61, gb_free=16.2, wall=5355
2023-07-14 01:36:02 | INFO | train_inner | epoch 032:    825 / 1474 loss=3.707, trans_loss=5.145, nll_loss=2.388, w2v_ctc_loss=1.087, task_loss=16.536, contrastive_loss=0.108, total=4114.54, n_correct=2769.24, ppl=5.24, accuracy=67.304, wps=6862.3, ups=1.67, wpb=4114.5, bsz=147.4, num_updates=46500, lr=6.55826e-05, gnorm=0.965, clip=0, loss_scale=64, train_wall=60, gb_free=17.3, wall=5415
2023-07-14 01:37:02 | INFO | train_inner | epoch 032:    925 / 1474 loss=3.718, trans_loss=5.156, nll_loss=2.404, w2v_ctc_loss=1.104, task_loss=16.638, contrastive_loss=0.107, total=4139.67, n_correct=2777.9, ppl=5.29, accuracy=67.104, wps=6827.6, ups=1.65, wpb=4139.7, bsz=149.2, num_updates=46600, lr=6.55122e-05, gnorm=0.977, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=5476
2023-07-14 01:38:03 | INFO | train_inner | epoch 032:   1025 / 1474 loss=3.717, trans_loss=5.154, nll_loss=2.401, w2v_ctc_loss=1.088, task_loss=15.936, contrastive_loss=0.296, total=4119.15, n_correct=2765.5, ppl=5.28, accuracy=67.138, wps=6841.4, ups=1.66, wpb=4119.1, bsz=152.2, num_updates=46700, lr=6.5442e-05, gnorm=0.957, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=5536
2023-07-14 01:39:04 | INFO | train_inner | epoch 032:   1125 / 1474 loss=3.754, trans_loss=5.173, nll_loss=2.424, w2v_ctc_loss=1.125, task_loss=18.928, contrastive_loss=0.181, total=4019.61, n_correct=2685.36, ppl=5.37, accuracy=66.806, wps=6540.2, ups=1.63, wpb=4019.6, bsz=135.7, num_updates=46800, lr=6.5372e-05, gnorm=0.997, clip=0, loss_scale=64, train_wall=61, gb_free=17.8, wall=5597
2023-07-14 01:40:05 | INFO | train_inner | epoch 032:   1225 / 1474 loss=3.743, trans_loss=5.174, nll_loss=2.428, w2v_ctc_loss=1.104, task_loss=15.832, contrastive_loss=0.395, total=4149.28, n_correct=2771.55, ppl=5.38, accuracy=66.796, wps=6812.7, ups=1.64, wpb=4149.3, bsz=155.2, num_updates=46900, lr=6.53023e-05, gnorm=0.978, clip=0, loss_scale=64, train_wall=60, gb_free=16.1, wall=5658
2023-07-14 01:41:05 | INFO | train_inner | epoch 032:   1325 / 1474 loss=3.712, trans_loss=5.153, nll_loss=2.399, w2v_ctc_loss=1.094, task_loss=16.418, contrastive_loss=0.11, total=4079.22, n_correct=2740.18, ppl=5.28, accuracy=67.174, wps=6805.5, ups=1.67, wpb=4079.2, bsz=148.1, num_updates=47000, lr=6.52328e-05, gnorm=0.981, clip=0, loss_scale=64, train_wall=60, gb_free=15.4, wall=5718
2023-07-14 01:42:05 | INFO | train_inner | epoch 032:   1425 / 1474 loss=3.745, trans_loss=5.167, nll_loss=2.418, w2v_ctc_loss=1.107, task_loss=16.124, contrastive_loss=0.574, total=4111.41, n_correct=2751.76, ppl=5.34, accuracy=66.93, wps=6855.3, ups=1.67, wpb=4111.4, bsz=153.1, num_updates=47100, lr=6.51635e-05, gnorm=0.98, clip=0, loss_scale=64, train_wall=60, gb_free=16.2, wall=5778
2023-07-14 01:42:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-14 01:43:01 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.195 | trans_loss 5.55 | nll_loss 2.822 | w2v_ctc_loss 1.361 | task_loss 23.226 | contrastive_loss 0.264 | total 4003.4 | n_correct 2495.9 | ppl 7.07 | accuracy 62.345 | uer 16.54 | wer 18.415 | raw_wer 18.415 | bleu 20.23 | wps 1927.4 | wpb 4003.4 | bsz 141.8 | num_updates 47149 | best_bleu 20.59
2023-07-14 01:43:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47149 updates
2023-07-14 01:43:01 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.2305.pt
2023-07-14 01:43:03 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.2305.pt
2023-07-14 01:43:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.2305.pt (epoch 32 @ 47149 updates, score 20.23) (writing took 5.351705164066516 seconds)
2023-07-14 01:43:06 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-07-14 01:43:06 | INFO | train | epoch 032 | loss 3.713 | trans_loss 5.149 | nll_loss 2.395 | w2v_ctc_loss 1.096 | task_loss 16.036 | contrastive_loss 0.216 | total 4138.65 | n_correct 2782.89 | ppl 5.26 | accuracy 67.242 | wps 6330.1 | ups 1.53 | wpb 4138.6 | bsz 152.8 | num_updates 47149 | lr 6.51297e-05 | gnorm 0.97 | clip 0 | loss_scale 64 | train_wall 887 | gb_free 16.8 | wall 5839
2023-07-14 01:43:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-14 01:43:06 | INFO | fairseq.trainer | begin training epoch 33
2023-07-14 01:43:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-16 22:05:37 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:16003
2023-07-16 22:05:37 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:16003
2023-07-16 22:05:37 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:16003
2023-07-16 22:05:37 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:16003
2023-07-16 22:05:37 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:16003
2023-07-16 22:05:37 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:16003
2023-07-16 22:05:37 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:16003
2023-07-16 22:05:37 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:16003
2023-07-16 22:05:38 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-16 22:05:38 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-16 22:05:38 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-16 22:05:38 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-16 22:05:38 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-16 22:05:38 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-16 22:05:38 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-16 22:05:38 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-16 22:05:38 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-16 22:05:38 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-16 22:05:38 | INFO | fairseq.distributed.utils | initialized host test1 as rank 7
2023-07-16 22:05:38 | INFO | fairseq.distributed.utils | initialized host test1 as rank 4
2023-07-16 22:05:38 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-16 22:05:38 | INFO | fairseq.distributed.utils | initialized host test1 as rank 0
2023-07-16 22:05:38 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-16 22:05:38 | INFO | fairseq.distributed.utils | initialized host test1 as rank 2
2023-07-16 22:05:38 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-16 22:05:38 | INFO | fairseq.distributed.utils | initialized host test1 as rank 3
2023-07-16 22:05:38 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-16 22:05:38 | INFO | fairseq.distributed.utils | initialized host test1 as rank 5
2023-07-16 22:05:38 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-16 22:05:38 | INFO | fairseq.distributed.utils | initialized host test1 as rank 6
2023-07-16 22:05:38 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-16 22:05:38 | INFO | fairseq.distributed.utils | initialized host test1 as rank 1
2023-07-16 22:05:40 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16003', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=True, at_scale=5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-16 22:05:41 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-16 22:05:41 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-16 22:05:41 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-16 22:05:41 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-16 22:05:41 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-16 22:05:46 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-16 22:05:46 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-16 22:05:46 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-16 22:05:47 | INFO | root | load pretrained hubert
2023-07-16 22:05:51 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-16 22:05:52 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-16 22:05:56 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-16 22:05:56 | INFO | root | share the sematic adapter and textual encoder
2023-07-16 22:05:56 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-16 22:05:56 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-16 22:05:56 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-16 22:05:56 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-16 22:05:56 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-16 22:05:56 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-16 22:05:56 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-16 22:05:56 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-16 22:05:56 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-16 22:05:56 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-16 22:06:04 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-16 22:06:04 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-16 22:06:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-16 22:06:05 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-16 22:06:05 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-16 22:06:05 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-16 22:06:05 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-16 22:06:05 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-16 22:06:05 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-16 22:06:05 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-16 22:06:05 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-16 22:06:05 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-16 22:06:05 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-16 22:06:05 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-16 22:06:05 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-16 22:06:05 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt
2023-07-16 22:06:09 | INFO | fairseq.trainer | load the task parameters
asr_weight tensor(0.0016, device='cuda:0')
mt_weight tensor(0.0260, device='cuda:0')
2023-07-16 22:06:09 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt (epoch 33 @ 47149 updates)
2023-07-16 22:06:09 | INFO | fairseq.trainer | loading train data for epoch 33
2023-07-16 22:06:09 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-16 22:06:09 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-16 22:06:09 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-16 22:06:14 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-16 22:06:16 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-16 22:06:18 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
asr_weight tensor(0.0016, device='cuda:6')
mt_weight tensor(0.0260, device='cuda:6')
2023-07-16 22:07:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-16 22:07:23 | INFO | fairseq.trainer | begin training epoch 33
2023-07-16 22:07:23 | INFO | fairseq_cli.train | Start iterating over samples
asr_weight tensor(0.0016, device='cuda:7')
mt_weight tensor(0.0260, device='cuda:7')
asr_weight tensor(0.0016, device='cuda:1')
mt_weight tensor(0.0260, device='cuda:1')
asr_weight tensor(0.0016, device='cuda:4')
mt_weight tensor(0.0260, device='cuda:4')
asr_weight tensor(0.0016, device='cuda:3')
mt_weight tensor(0.0260, device='cuda:3')
asr_weight tensor(0.0016, device='cuda:2')
mt_weight tensor(0.0260, device='cuda:2')
asr_weight tensor(0.0016, device='cuda:5')
mt_weight tensor(0.0260, device='cuda:5')
2023-07-16 22:08:09 | INFO | train_inner | epoch 033:     51 / 1474 loss=3.693, trans_loss=5.128, nll_loss=2.365, w2v_ctc_loss=1.089, task_loss=16.45, contrastive_loss=0.116, total=4147.18, n_correct=2808.84, ppl=5.15, accuracy=67.729, wps=6626.7, ups=1.6, wpb=4147.2, bsz=151.6, num_updates=47200, lr=6.50945e-05, gnorm=0.959, clip=0, loss_scale=64, train_wall=38, gb_free=16.8, wall=125
2023-07-16 22:09:11 | INFO | train_inner | epoch 033:    151 / 1474 loss=3.689, trans_loss=5.119, nll_loss=2.354, w2v_ctc_loss=1.069, task_loss=17.333, contrastive_loss=0.091, total=4071.44, n_correct=2758.75, ppl=5.11, accuracy=67.759, wps=6590, ups=1.62, wpb=4071.4, bsz=142.1, num_updates=47300, lr=6.50256e-05, gnorm=0.975, clip=0, loss_scale=64, train_wall=61, gb_free=16.4, wall=186
2023-07-16 22:10:14 | INFO | train_inner | epoch 033:    251 / 1474 loss=3.691, trans_loss=5.127, nll_loss=2.367, w2v_ctc_loss=1.074, task_loss=13.664, contrastive_loss=0.449, total=4281.28, n_correct=2897.8, ppl=5.16, accuracy=67.685, wps=6785.7, ups=1.58, wpb=4281.3, bsz=173.2, num_updates=47400, lr=6.4957e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=63, gb_free=16.7, wall=249
2023-07-16 22:11:16 | INFO | train_inner | epoch 033:    351 / 1474 loss=3.702, trans_loss=5.136, nll_loss=2.377, w2v_ctc_loss=1.091, task_loss=16.492, contrastive_loss=0.146, total=4111.69, n_correct=2774.37, ppl=5.19, accuracy=67.475, wps=6640.8, ups=1.62, wpb=4111.7, bsz=149.2, num_updates=47500, lr=6.48886e-05, gnorm=0.989, clip=0, loss_scale=64, train_wall=62, gb_free=17.1, wall=311
2023-07-16 22:12:17 | INFO | train_inner | epoch 033:    451 / 1474 loss=3.665, trans_loss=5.111, nll_loss=2.344, w2v_ctc_loss=1.058, task_loss=15.034, contrastive_loss=0.111, total=4147.28, n_correct=2815.27, ppl=5.08, accuracy=67.882, wps=6796.3, ups=1.64, wpb=4147.3, bsz=156.7, num_updates=47600, lr=6.48204e-05, gnorm=0.96, clip=0, loss_scale=64, train_wall=61, gb_free=16.8, wall=372
2023-07-16 22:13:19 | INFO | train_inner | epoch 033:    551 / 1474 loss=3.714, trans_loss=5.141, nll_loss=2.383, w2v_ctc_loss=1.1, task_loss=16.782, contrastive_loss=0.148, total=4127.68, n_correct=2780.32, ppl=5.21, accuracy=67.358, wps=6725.7, ups=1.63, wpb=4127.7, bsz=146.3, num_updates=47700, lr=6.47524e-05, gnorm=0.975, clip=0, loss_scale=64, train_wall=61, gb_free=15.8, wall=434
2023-07-16 22:13:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-16 22:14:21 | INFO | train_inner | epoch 033:    652 / 1474 loss=3.714, trans_loss=5.148, nll_loss=2.392, w2v_ctc_loss=1.09, task_loss=16.302, contrastive_loss=0.217, total=4162.35, n_correct=2797.31, ppl=5.25, accuracy=67.205, wps=6653.9, ups=1.6, wpb=4162.4, bsz=151.7, num_updates=47800, lr=6.46846e-05, gnorm=0.982, clip=0, loss_scale=32, train_wall=62, gb_free=17.9, wall=496
2023-07-16 22:15:23 | INFO | train_inner | epoch 033:    752 / 1474 loss=3.723, trans_loss=5.15, nll_loss=2.396, w2v_ctc_loss=1.117, task_loss=17.399, contrastive_loss=0.109, total=4070.75, n_correct=2734.7, ppl=5.26, accuracy=67.179, wps=6632.8, ups=1.63, wpb=4070.8, bsz=143.6, num_updates=47900, lr=6.46171e-05, gnorm=0.983, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=558
2023-07-16 22:16:24 | INFO | train_inner | epoch 033:    852 / 1474 loss=3.69, trans_loss=5.135, nll_loss=2.378, w2v_ctc_loss=1.073, task_loss=15.279, contrastive_loss=0.246, total=4130.24, n_correct=2788.52, ppl=5.2, accuracy=67.515, wps=6680.3, ups=1.62, wpb=4130.2, bsz=158.2, num_updates=48000, lr=6.45497e-05, gnorm=0.967, clip=0, loss_scale=32, train_wall=61, gb_free=16.9, wall=620
2023-07-16 22:16:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-07-16 22:16:51 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.2 | trans_loss 5.555 | nll_loss 2.827 | w2v_ctc_loss 1.362 | task_loss 23.152 | contrastive_loss 0.27 | total 4003.4 | n_correct 2495.2 | ppl 7.1 | accuracy 62.327 | uer 16.505 | wer 18.355 | raw_wer 18.355 | bleu 20.35 | wps 1875.5 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.59
2023-07-16 22:16:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-07-16 22:16:51 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_33_48000.pt
2023-07-16 22:16:53 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_33_48000.pt
2023-07-16 22:16:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 20.35) (writing took 8.014644339913502 seconds)
2023-07-16 22:18:01 | INFO | train_inner | epoch 033:    952 / 1474 loss=3.704, trans_loss=5.141, nll_loss=2.385, w2v_ctc_loss=1.102, task_loss=15.986, contrastive_loss=0.136, total=4151.18, n_correct=2798.55, ppl=5.22, accuracy=67.416, wps=4318.4, ups=1.04, wpb=4151.2, bsz=154.1, num_updates=48100, lr=6.44826e-05, gnorm=0.973, clip=0, loss_scale=32, train_wall=61, gb_free=11.6, wall=716
2023-07-16 22:19:03 | INFO | train_inner | epoch 033:   1052 / 1474 loss=3.728, trans_loss=5.152, nll_loss=2.398, w2v_ctc_loss=1.11, task_loss=16.082, contrastive_loss=0.346, total=4140.1, n_correct=2777.82, ppl=5.27, accuracy=67.095, wps=6668.6, ups=1.61, wpb=4140.1, bsz=153.8, num_updates=48200, lr=6.44157e-05, gnorm=0.988, clip=0, loss_scale=32, train_wall=62, gb_free=12.1, wall=778
2023-07-16 22:20:04 | INFO | train_inner | epoch 033:   1152 / 1474 loss=3.722, trans_loss=5.157, nll_loss=2.406, w2v_ctc_loss=1.089, task_loss=16.001, contrastive_loss=0.321, total=4182.67, n_correct=2807.64, ppl=5.3, accuracy=67.126, wps=6761.2, ups=1.62, wpb=4182.7, bsz=154.7, num_updates=48300, lr=6.43489e-05, gnorm=0.973, clip=0, loss_scale=32, train_wall=61, gb_free=17.7, wall=840
2023-07-16 22:21:06 | INFO | train_inner | epoch 033:   1252 / 1474 loss=3.715, trans_loss=5.147, nll_loss=2.391, w2v_ctc_loss=1.105, task_loss=16.905, contrastive_loss=0.121, total=4110.02, n_correct=2767.91, ppl=5.25, accuracy=67.345, wps=6660.3, ups=1.62, wpb=4110, bsz=147.2, num_updates=48400, lr=6.42824e-05, gnorm=0.986, clip=0, loss_scale=32, train_wall=61, gb_free=17.1, wall=901
2023-07-16 22:22:29 | INFO | train_inner | epoch 033:   1352 / 1474 loss=3.703, trans_loss=5.145, nll_loss=2.391, w2v_ctc_loss=1.098, task_loss=15.748, contrastive_loss=0.159, total=4128.82, n_correct=2776.12, ppl=5.25, accuracy=67.238, wps=4963.6, ups=1.2, wpb=4128.8, bsz=156.2, num_updates=48500, lr=6.42161e-05, gnorm=0.968, clip=0, loss_scale=32, train_wall=83, gb_free=16.3, wall=985
2023-07-16 22:23:32 | INFO | train_inner | epoch 033:   1452 / 1474 loss=3.712, trans_loss=5.143, nll_loss=2.389, w2v_ctc_loss=1.073, task_loss=15.906, contrastive_loss=0.449, total=4123.47, n_correct=2777.72, ppl=5.24, accuracy=67.364, wps=6626.2, ups=1.61, wpb=4123.5, bsz=154.4, num_updates=48600, lr=6.415e-05, gnorm=0.96, clip=0, loss_scale=32, train_wall=62, gb_free=16.7, wall=1047
2023-07-16 22:23:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-16 22:24:11 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.205 | trans_loss 5.552 | nll_loss 2.824 | w2v_ctc_loss 1.387 | task_loss 23.163 | contrastive_loss 0.263 | total 4003.4 | n_correct 2491.9 | ppl 7.08 | accuracy 62.245 | uer 16.566 | wer 18.314 | raw_wer 18.314 | bleu 20.28 | wps 1976.7 | wpb 4003.4 | bsz 141.8 | num_updates 48622 | best_bleu 20.59
2023-07-16 22:24:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48622 updates
2023-07-16 22:24:11 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.2803.pt
2023-07-16 22:24:13 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.2803.pt
2023-07-16 22:24:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.2803.pt (epoch 33 @ 48622 updates, score 20.28) (writing took 5.304175777011551 seconds)
2023-07-16 22:24:16 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-07-16 22:24:16 | INFO | train | epoch 033 | loss 3.704 | trans_loss 5.139 | nll_loss 2.382 | w2v_ctc_loss 1.089 | task_loss 16.018 | contrastive_loss 0.216 | total 4138.68 | n_correct 2790.07 | ppl 5.21 | accuracy 67.414 | wps 6104.8 | ups 1.48 | wpb 4138.7 | bsz 152.9 | num_updates 48622 | lr 6.41355e-05 | gnorm 0.974 | clip 0 | loss_scale 32 | train_wall 933 | gb_free 18 | wall 1091
2023-07-16 22:24:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-16 22:24:16 | INFO | fairseq.trainer | begin training epoch 34
2023-07-16 22:24:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-16 22:25:12 | INFO | train_inner | epoch 034:     78 / 1474 loss=3.68, trans_loss=5.114, nll_loss=2.349, w2v_ctc_loss=1.072, task_loss=15.818, contrastive_loss=0.124, total=4128.94, n_correct=2799.13, ppl=5.09, accuracy=67.793, wps=4120.2, ups=1, wpb=4128.9, bsz=151.1, num_updates=48700, lr=6.40841e-05, gnorm=0.978, clip=0, loss_scale=32, train_wall=61, gb_free=15.4, wall=1147
2023-07-16 22:26:13 | INFO | train_inner | epoch 034:    178 / 1474 loss=3.683, trans_loss=5.113, nll_loss=2.347, w2v_ctc_loss=1.079, task_loss=16.729, contrastive_loss=0.126, total=4071.22, n_correct=2761.62, ppl=5.09, accuracy=67.833, wps=6630.9, ups=1.63, wpb=4071.2, bsz=147.6, num_updates=48800, lr=6.40184e-05, gnorm=0.975, clip=0, loss_scale=32, train_wall=61, gb_free=15.8, wall=1208
2023-07-16 22:27:15 | INFO | train_inner | epoch 034:    278 / 1474 loss=3.709, trans_loss=5.135, nll_loss=2.376, w2v_ctc_loss=1.071, task_loss=15.098, contrastive_loss=0.545, total=4237.89, n_correct=2858.06, ppl=5.19, accuracy=67.441, wps=6881, ups=1.62, wpb=4237.9, bsz=163.5, num_updates=48900, lr=6.39529e-05, gnorm=0.971, clip=0, loss_scale=32, train_wall=61, gb_free=10.9, wall=1270
2023-07-16 22:28:16 | INFO | train_inner | epoch 034:    378 / 1474 loss=3.676, trans_loss=5.112, nll_loss=2.346, w2v_ctc_loss=1.057, task_loss=15.122, contrastive_loss=0.317, total=4167, n_correct=2832.42, ppl=5.08, accuracy=67.973, wps=6798, ups=1.63, wpb=4167, bsz=159.5, num_updates=49000, lr=6.38877e-05, gnorm=0.962, clip=0, loss_scale=32, train_wall=61, gb_free=17.5, wall=1331
2023-07-16 22:29:18 | INFO | train_inner | epoch 034:    478 / 1474 loss=3.708, trans_loss=5.133, nll_loss=2.372, w2v_ctc_loss=1.098, task_loss=17.573, contrastive_loss=0.114, total=4071.65, n_correct=2749.36, ppl=5.18, accuracy=67.524, wps=6550.1, ups=1.61, wpb=4071.7, bsz=142.4, num_updates=49100, lr=6.38226e-05, gnorm=0.994, clip=0, loss_scale=32, train_wall=62, gb_free=12, wall=1393
2023-07-16 22:30:19 | INFO | train_inner | epoch 034:    578 / 1474 loss=3.684, trans_loss=5.119, nll_loss=2.355, w2v_ctc_loss=1.075, task_loss=16.31, contrastive_loss=0.118, total=4110.13, n_correct=2784.7, ppl=5.12, accuracy=67.752, wps=6735.3, ups=1.64, wpb=4110.1, bsz=149.5, num_updates=49200, lr=6.37577e-05, gnorm=0.967, clip=0, loss_scale=32, train_wall=61, gb_free=16.9, wall=1454
2023-07-16 22:31:20 | INFO | train_inner | epoch 034:    678 / 1474 loss=3.679, trans_loss=5.118, nll_loss=2.355, w2v_ctc_loss=1.063, task_loss=16.239, contrastive_loss=0.109, total=4128.65, n_correct=2796.17, ppl=5.11, accuracy=67.726, wps=6760.9, ups=1.64, wpb=4128.6, bsz=150.4, num_updates=49300, lr=6.3693e-05, gnorm=0.969, clip=0, loss_scale=32, train_wall=61, gb_free=17.9, wall=1516
2023-07-16 22:32:21 | INFO | train_inner | epoch 034:    778 / 1474 loss=3.71, trans_loss=5.146, nll_loss=2.39, w2v_ctc_loss=1.072, task_loss=16.81, contrastive_loss=0.247, total=4075.69, n_correct=2742.87, ppl=5.24, accuracy=67.298, wps=6693.5, ups=1.64, wpb=4075.7, bsz=147.3, num_updates=49400, lr=6.36285e-05, gnorm=0.986, clip=0, loss_scale=32, train_wall=60, gb_free=17.4, wall=1576
2023-07-16 22:33:23 | INFO | train_inner | epoch 034:    878 / 1474 loss=3.708, trans_loss=5.139, nll_loss=2.382, w2v_ctc_loss=1.09, task_loss=16.94, contrastive_loss=0.166, total=4104.97, n_correct=2768.09, ppl=5.21, accuracy=67.433, wps=6679.7, ups=1.63, wpb=4105, bsz=148.2, num_updates=49500, lr=6.35642e-05, gnorm=0.994, clip=0, loss_scale=32, train_wall=61, gb_free=17.9, wall=1638
2023-07-16 22:34:24 | INFO | train_inner | epoch 034:    978 / 1474 loss=3.698, trans_loss=5.137, nll_loss=2.381, w2v_ctc_loss=1.09, task_loss=15.674, contrastive_loss=0.159, total=4168.94, n_correct=2813.23, ppl=5.21, accuracy=67.481, wps=6808.3, ups=1.63, wpb=4168.9, bsz=156.4, num_updates=49600, lr=6.35001e-05, gnorm=0.968, clip=0, loss_scale=32, train_wall=61, gb_free=15.2, wall=1699
2023-07-16 22:35:25 | INFO | train_inner | epoch 034:   1078 / 1474 loss=3.701, trans_loss=5.139, nll_loss=2.382, w2v_ctc_loss=1.1, task_loss=15.451, contrastive_loss=0.122, total=4155.12, n_correct=2800.01, ppl=5.21, accuracy=67.387, wps=6793, ups=1.63, wpb=4155.1, bsz=154.6, num_updates=49700, lr=6.34361e-05, gnorm=0.978, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=1760
2023-07-16 22:36:27 | INFO | train_inner | epoch 034:   1178 / 1474 loss=3.701, trans_loss=5.136, nll_loss=2.378, w2v_ctc_loss=1.083, task_loss=16.584, contrastive_loss=0.144, total=4096.48, n_correct=2763.43, ppl=5.2, accuracy=67.459, wps=6661.7, ups=1.63, wpb=4096.5, bsz=148.6, num_updates=49800, lr=6.33724e-05, gnorm=0.971, clip=0, loss_scale=64, train_wall=61, gb_free=16.9, wall=1822
2023-07-16 22:37:27 | INFO | train_inner | epoch 034:   1278 / 1474 loss=3.698, trans_loss=5.134, nll_loss=2.375, w2v_ctc_loss=1.085, task_loss=16.247, contrastive_loss=0.111, total=4149.03, n_correct=2798.57, ppl=5.19, accuracy=67.451, wps=6845.1, ups=1.65, wpb=4149, bsz=149.9, num_updates=49900, lr=6.33089e-05, gnorm=0.975, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=1882
2023-07-16 22:38:29 | INFO | train_inner | epoch 034:   1378 / 1474 loss=3.699, trans_loss=5.14, nll_loss=2.384, w2v_ctc_loss=1.085, task_loss=15.328, contrastive_loss=0.243, total=4200.34, n_correct=2828.61, ppl=5.22, accuracy=67.342, wps=6810.4, ups=1.62, wpb=4200.3, bsz=161, num_updates=50000, lr=6.32456e-05, gnorm=0.975, clip=0, loss_scale=64, train_wall=61, gb_free=15.3, wall=1944
2023-07-16 22:38:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-16 22:38:54 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.21 | trans_loss 5.561 | nll_loss 2.832 | w2v_ctc_loss 1.386 | task_loss 23.223 | contrastive_loss 0.265 | total 4003.4 | n_correct 2489.1 | ppl 7.12 | accuracy 62.175 | uer 16.473 | wer 18.288 | raw_wer 18.288 | bleu 20.21 | wps 2162.4 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.59
2023-07-16 22:38:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-07-16 22:38:54 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_34_50000.pt
2023-07-16 22:38:56 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_34_50000.pt
2023-07-16 22:38:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 20.21) (writing took 5.161628072964959 seconds)
mt_weight tensor(0.0260, device='cuda:0')
asr_weight tensor(0.0016, device='cuda:0')
2023-07-16 22:39:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.0260, device='cuda:4')
asr_weight tensor(0.0016, device='cuda:4')
mt_weight tensor(0.0260, device='cuda:1')
asr_weight tensor(0.0016, device='cuda:1')
mt_weight tensor(0.0260, device='cuda:7')
asr_weight tensor(0.0016, device='cuda:7')
mt_weight tensor(0.0260, device='cuda:2')
asr_weight tensor(0.0016, device='cuda:2')
mt_weight tensor(0.0260, device='cuda:6')
asr_weight tensor(0.0016, device='cuda:6')
mt_weight tensor(0.0260, device='cuda:5')
asr_weight tensor(0.0016, device='cuda:5')
mt_weight tensor(0.0260, device='cuda:3')
asr_weight tensor(0.0016, device='cuda:3')
2023-07-16 22:40:23 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.198 | trans_loss 5.554 | nll_loss 2.827 | w2v_ctc_loss 1.364 | task_loss 23.152 | contrastive_loss 0.261 | total 4003.4 | n_correct 2493.4 | ppl 7.09 | accuracy 62.282 | uer 16.537 | wer 18.392 | raw_wer 18.392 | bleu 20.47 | wps 2032.6 | wpb 4003.4 | bsz 141.8 | num_updates 50096 | best_bleu 20.59
2023-07-16 22:40:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50096 updates
2023-07-16 22:40:23 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.4701.pt
2023-07-16 22:40:26 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.4701.pt
2023-07-16 22:40:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.4701.pt (epoch 34 @ 50096 updates, score 20.47) (writing took 5.664108954952098 seconds)
2023-07-16 22:40:29 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-07-16 22:40:29 | INFO | train | epoch 034 | loss 3.696 | trans_loss 5.13 | nll_loss 2.37 | w2v_ctc_loss 1.079 | task_loss 16.033 | contrastive_loss 0.217 | total 4138.65 | n_correct 2795.8 | ppl 5.17 | accuracy 67.553 | wps 6270.1 | ups 1.52 | wpb 4138.6 | bsz 152.8 | num_updates 50096 | lr 6.31849e-05 | gnorm 0.975 | clip 0 | loss_scale 64 | train_wall 898 | gb_free 17.5 | wall 2064
2023-07-16 22:40:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-16 22:40:29 | INFO | fairseq.trainer | begin training epoch 35
2023-07-16 22:40:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-16 22:40:39 | INFO | train_inner | epoch 035:      4 / 1474 loss=3.706, trans_loss=5.139, nll_loss=2.383, w2v_ctc_loss=1.068, task_loss=14.648, contrastive_loss=0.52, total=4211.77, n_correct=2838.89, ppl=5.22, accuracy=67.404, wps=3228.6, ups=0.77, wpb=4211.8, bsz=163.5, num_updates=50100, lr=6.31824e-05, gnorm=0.973, clip=0, loss_scale=64, train_wall=61, gb_free=16.8, wall=2075
2023-07-16 22:41:41 | INFO | train_inner | epoch 035:    104 / 1474 loss=3.68, trans_loss=5.107, nll_loss=2.34, w2v_ctc_loss=1.052, task_loss=15.501, contrastive_loss=0.395, total=4165.08, n_correct=2830.03, ppl=5.06, accuracy=67.947, wps=6764.8, ups=1.62, wpb=4165.1, bsz=156.3, num_updates=50200, lr=6.31194e-05, gnorm=0.965, clip=0, loss_scale=64, train_wall=61, gb_free=15.3, wall=2136
2023-07-16 22:42:43 | INFO | train_inner | epoch 035:    204 / 1474 loss=3.661, trans_loss=5.103, nll_loss=2.335, w2v_ctc_loss=1.061, task_loss=15.077, contrastive_loss=0.114, total=4176.66, n_correct=2842.91, ppl=5.05, accuracy=68.067, wps=6761.9, ups=1.62, wpb=4176.7, bsz=158.5, num_updates=50300, lr=6.30567e-05, gnorm=0.968, clip=0, loss_scale=64, train_wall=61, gb_free=15.3, wall=2198
2023-07-16 22:43:44 | INFO | train_inner | epoch 035:    304 / 1474 loss=3.702, trans_loss=5.118, nll_loss=2.354, w2v_ctc_loss=1.077, task_loss=16.805, contrastive_loss=0.449, total=4108.8, n_correct=2785.48, ppl=5.11, accuracy=67.793, wps=6721.1, ups=1.64, wpb=4108.8, bsz=150, num_updates=50400, lr=6.29941e-05, gnorm=0.983, clip=0, loss_scale=64, train_wall=61, gb_free=17, wall=2259
2023-07-16 22:44:45 | INFO | train_inner | epoch 035:    404 / 1474 loss=3.705, trans_loss=5.125, nll_loss=2.362, w2v_ctc_loss=1.098, task_loss=17.817, contrastive_loss=0.119, total=4069.25, n_correct=2751.92, ppl=5.14, accuracy=67.627, wps=6703.2, ups=1.65, wpb=4069.2, bsz=141.5, num_updates=50500, lr=6.29317e-05, gnorm=0.978, clip=0, loss_scale=64, train_wall=60, gb_free=17.4, wall=2320
2023-07-16 22:45:46 | INFO | train_inner | epoch 035:    504 / 1474 loss=3.696, trans_loss=5.126, nll_loss=2.364, w2v_ctc_loss=1.073, task_loss=16.216, contrastive_loss=0.263, total=4152.56, n_correct=2810.23, ppl=5.15, accuracy=67.675, wps=6800.9, ups=1.64, wpb=4152.6, bsz=152.5, num_updates=50600, lr=6.28695e-05, gnorm=0.977, clip=0, loss_scale=64, train_wall=61, gb_free=16.2, wall=2381
2023-07-16 22:46:46 | INFO | train_inner | epoch 035:    604 / 1474 loss=3.676, trans_loss=5.11, nll_loss=2.344, w2v_ctc_loss=1.047, task_loss=16.042, contrastive_loss=0.283, total=4166.96, n_correct=2832.23, ppl=5.08, accuracy=67.969, wps=6872.9, ups=1.65, wpb=4167, bsz=153.9, num_updates=50700, lr=6.28074e-05, gnorm=0.957, clip=0, loss_scale=64, train_wall=60, gb_free=15.6, wall=2441
2023-07-16 22:47:47 | INFO | train_inner | epoch 035:    704 / 1474 loss=3.703, trans_loss=5.13, nll_loss=2.369, w2v_ctc_loss=1.101, task_loss=16.894, contrastive_loss=0.136, total=4076.62, n_correct=2754.33, ppl=5.16, accuracy=67.564, wps=6710.1, ups=1.65, wpb=4076.6, bsz=146.7, num_updates=50800, lr=6.27456e-05, gnorm=0.993, clip=0, loss_scale=64, train_wall=60, gb_free=15.2, wall=2502
2023-07-16 22:48:49 | INFO | train_inner | epoch 035:    804 / 1474 loss=3.686, trans_loss=5.122, nll_loss=2.36, w2v_ctc_loss=1.087, task_loss=15.734, contrastive_loss=0.156, total=4160.7, n_correct=2813.88, ppl=5.13, accuracy=67.63, wps=6711.3, ups=1.61, wpb=4160.7, bsz=156.3, num_updates=50900, lr=6.26839e-05, gnorm=0.96, clip=0, loss_scale=64, train_wall=62, gb_free=16.7, wall=2564
2023-07-16 22:49:51 | INFO | train_inner | epoch 035:    904 / 1474 loss=3.704, trans_loss=5.131, nll_loss=2.371, w2v_ctc_loss=1.104, task_loss=16.852, contrastive_loss=0.114, total=4094.05, n_correct=2762.46, ppl=5.17, accuracy=67.475, wps=6633, ups=1.62, wpb=4094.1, bsz=146.9, num_updates=51000, lr=6.26224e-05, gnorm=0.991, clip=0, loss_scale=64, train_wall=61, gb_free=17.6, wall=2626
2023-07-16 22:50:52 | INFO | train_inner | epoch 035:   1004 / 1474 loss=3.707, trans_loss=5.134, nll_loss=2.376, w2v_ctc_loss=1.074, task_loss=16.155, contrastive_loss=0.364, total=4142.62, n_correct=2796.87, ppl=5.19, accuracy=67.515, wps=6784.5, ups=1.64, wpb=4142.6, bsz=153.5, num_updates=51100, lr=6.25611e-05, gnorm=0.979, clip=0, loss_scale=64, train_wall=61, gb_free=13.4, wall=2687
2023-07-16 22:51:52 | INFO | train_inner | epoch 035:   1104 / 1474 loss=3.689, trans_loss=5.128, nll_loss=2.368, w2v_ctc_loss=1.081, task_loss=15.295, contrastive_loss=0.133, total=4189.04, n_correct=2835.26, ppl=5.16, accuracy=67.683, wps=6919, ups=1.65, wpb=4189, bsz=155.9, num_updates=51200, lr=6.25e-05, gnorm=0.974, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=2748
2023-07-16 22:52:53 | INFO | train_inner | epoch 035:   1204 / 1474 loss=3.684, trans_loss=5.124, nll_loss=2.364, w2v_ctc_loss=1.064, task_loss=14.892, contrastive_loss=0.239, total=4212.4, n_correct=2848.75, ppl=5.15, accuracy=67.628, wps=6929.1, ups=1.64, wpb=4212.4, bsz=160.2, num_updates=51300, lr=6.24391e-05, gnorm=0.977, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=2808
2023-07-16 22:53:54 | INFO | train_inner | epoch 035:   1304 / 1474 loss=3.685, trans_loss=5.128, nll_loss=2.37, w2v_ctc_loss=1.078, task_loss=15.442, contrastive_loss=0.14, total=4133.45, n_correct=2793.49, ppl=5.17, accuracy=67.583, wps=6799.5, ups=1.65, wpb=4133.4, bsz=156.1, num_updates=51400, lr=6.23783e-05, gnorm=0.98, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=2869
2023-07-16 22:54:56 | INFO | train_inner | epoch 035:   1404 / 1474 loss=3.704, trans_loss=5.137, nll_loss=2.378, w2v_ctc_loss=1.082, task_loss=17.343, contrastive_loss=0.113, total=4063.25, n_correct=2739.2, ppl=5.2, accuracy=67.414, wps=6600.3, ups=1.62, wpb=4063.2, bsz=143.7, num_updates=51500, lr=6.23177e-05, gnorm=0.975, clip=0, loss_scale=64, train_wall=61, gb_free=16.2, wall=2931
2023-07-16 22:55:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-16 22:56:04 | INFO | dev_st | epoch 035 | valid on 'dev_st' subset | loss 4.198 | trans_loss 5.557 | nll_loss 2.823 | w2v_ctc_loss 1.356 | task_loss 23.262 | contrastive_loss 0.26 | total 4003.4 | n_correct 2496 | ppl 7.08 | accuracy 62.347 | uer 16.564 | wer 18.344 | raw_wer 18.344 | bleu 20.19 | wps 2101.5 | wpb 4003.4 | bsz 141.8 | num_updates 51570 | best_bleu 20.59
2023-07-16 22:56:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 51570 updates
2023-07-16 22:56:04 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt
2023-07-16 22:56:09 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt
2023-07-16 22:56:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt (epoch 35 @ 51570 updates, score 20.19) (writing took 4.810774214915 seconds)
2023-07-16 22:56:09 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-07-16 22:56:09 | INFO | train | epoch 035 | loss 3.69 | trans_loss 5.123 | nll_loss 2.361 | w2v_ctc_loss 1.075 | task_loss 16.041 | contrastive_loss 0.217 | total 4138.65 | n_correct 2801.45 | ppl 5.14 | accuracy 67.69 | wps 6492 | ups 1.57 | wpb 4138.6 | bsz 152.8 | num_updates 51570 | lr 6.22754e-05 | gnorm 0.976 | clip 0 | loss_scale 64 | train_wall 895 | gb_free 17.4 | wall 3004
2023-07-16 22:56:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-16 22:56:09 | INFO | fairseq.trainer | begin training epoch 36
2023-07-16 22:56:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-16 22:56:35 | INFO | train_inner | epoch 036:     30 / 1474 loss=3.672, trans_loss=5.109, nll_loss=2.343, w2v_ctc_loss=1.052, task_loss=15.764, contrastive_loss=0.197, total=4117.12, n_correct=2795.62, ppl=5.07, accuracy=67.902, wps=4160.3, ups=1.01, wpb=4117.1, bsz=153.4, num_updates=51600, lr=6.22573e-05, gnorm=0.984, clip=0, loss_scale=64, train_wall=60, gb_free=15.7, wall=3030
2023-07-16 22:57:36 | INFO | train_inner | epoch 036:    130 / 1474 loss=3.672, trans_loss=5.102, nll_loss=2.333, w2v_ctc_loss=1.068, task_loss=16.705, contrastive_loss=0.129, total=4103.41, n_correct=2792.65, ppl=5.04, accuracy=68.057, wps=6716.8, ups=1.64, wpb=4103.4, bsz=149.1, num_updates=51700, lr=6.2197e-05, gnorm=0.98, clip=0, loss_scale=64, train_wall=61, gb_free=15.8, wall=3091
2023-07-16 22:58:37 | INFO | train_inner | epoch 036:    230 / 1474 loss=3.68, trans_loss=5.11, nll_loss=2.344, w2v_ctc_loss=1.074, task_loss=16.289, contrastive_loss=0.165, total=4154.16, n_correct=2823.32, ppl=5.08, accuracy=67.964, wps=6803.1, ups=1.64, wpb=4154.2, bsz=152.4, num_updates=51800, lr=6.2137e-05, gnorm=0.981, clip=0, loss_scale=64, train_wall=61, gb_free=16.2, wall=3152
2023-07-16 22:59:37 | INFO | train_inner | epoch 036:    330 / 1474 loss=3.65, trans_loss=5.093, nll_loss=2.322, w2v_ctc_loss=1.036, task_loss=15.11, contrastive_loss=0.111, total=4166.89, n_correct=2842.98, ppl=5, accuracy=68.228, wps=6957.9, ups=1.67, wpb=4166.9, bsz=155.5, num_updates=51900, lr=6.20771e-05, gnorm=0.961, clip=0, loss_scale=128, train_wall=59, gb_free=15.5, wall=3212
2023-07-16 22:59:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-16 23:00:38 | INFO | train_inner | epoch 036:    431 / 1474 loss=3.67, trans_loss=5.106, nll_loss=2.34, w2v_ctc_loss=1.048, task_loss=14.382, contrastive_loss=0.333, total=4210.15, n_correct=2863.2, ppl=5.06, accuracy=68.007, wps=6858.5, ups=1.63, wpb=4210.1, bsz=163.1, num_updates=52000, lr=6.20174e-05, gnorm=0.966, clip=0, loss_scale=64, train_wall=61, gb_free=17.1, wall=3273
2023-07-16 23:00:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-16 23:01:04 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 4.208 | trans_loss 5.556 | nll_loss 2.824 | w2v_ctc_loss 1.39 | task_loss 23.145 | contrastive_loss 0.264 | total 4003.4 | n_correct 2503.2 | ppl 7.08 | accuracy 62.527 | uer 16.529 | wer 18.463 | raw_wer 18.463 | bleu 20.29 | wps 1995.2 | wpb 4003.4 | bsz 141.8 | num_updates 52000 | best_bleu 20.59
2023-07-16 23:01:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 52000 updates
2023-07-16 23:01:04 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_36_52000.pt
2023-07-16 23:01:06 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_36_52000.pt
2023-07-16 23:01:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_36_52000.pt (epoch 36 @ 52000 updates, score 20.29) (writing took 6.244601249927655 seconds)
2023-07-16 23:02:13 | INFO | train_inner | epoch 036:    531 / 1474 loss=3.704, trans_loss=5.125, nll_loss=2.365, w2v_ctc_loss=1.05, task_loss=16.139, contrastive_loss=0.626, total=4145.92, n_correct=2804.2, ppl=5.15, accuracy=67.638, wps=4349, ups=1.05, wpb=4145.9, bsz=155.5, num_updates=52100, lr=6.19578e-05, gnorm=0.984, clip=0, loss_scale=64, train_wall=62, gb_free=16.6, wall=3368
2023-07-16 23:03:14 | INFO | train_inner | epoch 036:    631 / 1474 loss=3.665, trans_loss=5.099, nll_loss=2.33, w2v_ctc_loss=1.052, task_loss=15.444, contrastive_loss=0.271, total=4180.58, n_correct=2845.22, ppl=5.03, accuracy=68.058, wps=6861.4, ups=1.64, wpb=4180.6, bsz=158.3, num_updates=52200, lr=6.18984e-05, gnorm=0.965, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=3429
2023-07-16 23:04:15 | INFO | train_inner | epoch 036:    731 / 1474 loss=3.683, trans_loss=5.124, nll_loss=2.363, w2v_ctc_loss=1.081, task_loss=15.37, contrastive_loss=0.141, total=4185.09, n_correct=2834.49, ppl=5.14, accuracy=67.728, wps=6861.7, ups=1.64, wpb=4185.1, bsz=158.6, num_updates=52300, lr=6.18392e-05, gnorm=0.976, clip=0, loss_scale=64, train_wall=61, gb_free=17.3, wall=3490
2023-07-16 23:04:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-16 23:05:17 | INFO | train_inner | epoch 036:    832 / 1474 loss=3.708, trans_loss=5.136, nll_loss=2.379, w2v_ctc_loss=1.07, task_loss=15.39, contrastive_loss=0.437, total=4158.97, n_correct=2804.7, ppl=5.2, accuracy=67.437, wps=6757.7, ups=1.62, wpb=4159, bsz=158.1, num_updates=52400, lr=6.17802e-05, gnorm=0.984, clip=0, loss_scale=32, train_wall=61, gb_free=16.5, wall=3552
2023-07-16 23:06:18 | INFO | train_inner | epoch 036:    932 / 1474 loss=3.668, trans_loss=5.103, nll_loss=2.336, w2v_ctc_loss=1.055, task_loss=16.243, contrastive_loss=0.12, total=4175.34, n_correct=2836.95, ppl=5.05, accuracy=67.945, wps=6818.8, ups=1.63, wpb=4175.3, bsz=152.7, num_updates=52500, lr=6.17213e-05, gnorm=0.975, clip=0, loss_scale=32, train_wall=61, gb_free=17.7, wall=3613
2023-07-16 23:07:19 | INFO | train_inner | epoch 036:   1032 / 1474 loss=3.688, trans_loss=5.12, nll_loss=2.358, w2v_ctc_loss=1.078, task_loss=16.54, contrastive_loss=0.11, total=4176.5, n_correct=2829.6, ppl=5.13, accuracy=67.751, wps=6855.6, ups=1.64, wpb=4176.5, bsz=150.8, num_updates=52600, lr=6.16626e-05, gnorm=0.968, clip=0, loss_scale=32, train_wall=61, gb_free=16.5, wall=3674
2023-07-16 23:08:20 | INFO | train_inner | epoch 036:   1132 / 1474 loss=3.684, trans_loss=5.118, nll_loss=2.355, w2v_ctc_loss=1.083, task_loss=15.993, contrastive_loss=0.142, total=4130.46, n_correct=2796.64, ppl=5.12, accuracy=67.708, wps=6726.3, ups=1.63, wpb=4130.5, bsz=153.3, num_updates=52700, lr=6.16041e-05, gnorm=0.983, clip=0, loss_scale=32, train_wall=61, gb_free=17.9, wall=3735
2023-07-16 23:09:21 | INFO | train_inner | epoch 036:   1232 / 1474 loss=3.702, trans_loss=5.122, nll_loss=2.359, w2v_ctc_loss=1.092, task_loss=17.934, contrastive_loss=0.1, total=4051.75, n_correct=2742.24, ppl=5.13, accuracy=67.68, wps=6644.7, ups=1.64, wpb=4051.8, bsz=140, num_updates=52800, lr=6.15457e-05, gnorm=0.986, clip=0, loss_scale=32, train_wall=61, gb_free=17.2, wall=3796
2023-07-16 23:10:21 | INFO | train_inner | epoch 036:   1332 / 1474 loss=3.678, trans_loss=5.119, nll_loss=2.356, w2v_ctc_loss=1.065, task_loss=16.034, contrastive_loss=0.122, total=4108.74, n_correct=2781.59, ppl=5.12, accuracy=67.699, wps=6830.7, ups=1.66, wpb=4108.7, bsz=152.6, num_updates=52900, lr=6.14875e-05, gnorm=0.975, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=3857
2023-07-16 23:11:22 | INFO | train_inner | epoch 036:   1432 / 1474 loss=3.729, trans_loss=5.144, nll_loss=2.388, w2v_ctc_loss=1.106, task_loss=18.078, contrastive_loss=0.227, total=4048.28, n_correct=2724.9, ppl=5.23, accuracy=67.31, wps=6642.4, ups=1.64, wpb=4048.3, bsz=139.4, num_updates=53000, lr=6.14295e-05, gnorm=1.003, clip=0, loss_scale=32, train_wall=61, gb_free=11.3, wall=3918
2023-07-16 23:11:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-16 23:12:14 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 4.198 | trans_loss 5.554 | nll_loss 2.825 | w2v_ctc_loss 1.357 | task_loss 23.064 | contrastive_loss 0.27 | total 4003.4 | n_correct 2497.8 | ppl 7.09 | accuracy 62.392 | uer 16.322 | wer 18.09 | raw_wer 18.09 | bleu 20.54 | wps 1914 | wpb 4003.4 | bsz 141.8 | num_updates 53042 | best_bleu 20.59
2023-07-16 23:12:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 53042 updates
2023-07-16 23:12:14 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.5406.pt
2023-07-16 23:12:16 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.5406.pt
2023-07-16 23:12:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.5406.pt (epoch 36 @ 53042 updates, score 20.54) (writing took 5.321059744106606 seconds)
2023-07-16 23:12:20 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-07-16 23:12:20 | INFO | train | epoch 036 | loss 3.684 | trans_loss 5.115 | nll_loss 2.351 | w2v_ctc_loss 1.068 | task_loss 16.083 | contrastive_loss 0.214 | total 4136.2 | n_correct 2804.75 | ppl 5.1 | accuracy 67.81 | wps 6271.5 | ups 1.52 | wpb 4136.2 | bsz 152.4 | num_updates 53042 | lr 6.14052e-05 | gnorm 0.978 | clip 0 | loss_scale 32 | train_wall 891 | gb_free 17 | wall 3975
2023-07-16 23:12:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-16 23:12:20 | INFO | fairseq.trainer | begin training epoch 37
2023-07-16 23:12:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-16 23:13:03 | INFO | train_inner | epoch 037:     58 / 1474 loss=3.664, trans_loss=5.097, nll_loss=2.326, w2v_ctc_loss=1.055, task_loss=16.01, contrastive_loss=0.134, total=4092.98, n_correct=2785.82, ppl=5.02, accuracy=68.063, wps=4060.5, ups=0.99, wpb=4093, bsz=150, num_updates=53100, lr=6.13716e-05, gnorm=0.987, clip=0, loss_scale=32, train_wall=60, gb_free=15.5, wall=4018
2023-07-16 23:14:05 | INFO | train_inner | epoch 037:    158 / 1474 loss=3.668, trans_loss=5.097, nll_loss=2.327, w2v_ctc_loss=1.054, task_loss=16.371, contrastive_loss=0.242, total=4124.56, n_correct=2809.07, ppl=5.02, accuracy=68.106, wps=6725.9, ups=1.63, wpb=4124.6, bsz=153.4, num_updates=53200, lr=6.13139e-05, gnorm=0.976, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=4080
2023-07-16 23:15:06 | INFO | train_inner | epoch 037:    258 / 1474 loss=3.641, trans_loss=5.084, nll_loss=2.31, w2v_ctc_loss=1.035, task_loss=14.977, contrastive_loss=0.126, total=4188.93, n_correct=2861.86, ppl=4.96, accuracy=68.32, wps=6868.7, ups=1.64, wpb=4188.9, bsz=159.7, num_updates=53300, lr=6.12564e-05, gnorm=0.972, clip=0, loss_scale=32, train_wall=61, gb_free=15.2, wall=4141
2023-07-16 23:16:07 | INFO | train_inner | epoch 037:    358 / 1474 loss=3.671, trans_loss=5.098, nll_loss=2.328, w2v_ctc_loss=1.074, task_loss=16.196, contrastive_loss=0.142, total=4171.05, n_correct=2840.2, ppl=5.02, accuracy=68.093, wps=6812.8, ups=1.63, wpb=4171.1, bsz=152.9, num_updates=53400, lr=6.1199e-05, gnorm=0.97, clip=0, loss_scale=32, train_wall=61, gb_free=16.1, wall=4202
2023-07-16 23:17:08 | INFO | train_inner | epoch 037:    458 / 1474 loss=3.701, trans_loss=5.122, nll_loss=2.36, w2v_ctc_loss=1.051, task_loss=15.359, contrastive_loss=0.56, total=4184.96, n_correct=2833.55, ppl=5.14, accuracy=67.708, wps=6826.6, ups=1.63, wpb=4185, bsz=159.5, num_updates=53500, lr=6.11418e-05, gnorm=0.984, clip=0, loss_scale=32, train_wall=61, gb_free=13.6, wall=4263
2023-07-16 23:18:09 | INFO | train_inner | epoch 037:    558 / 1474 loss=3.664, trans_loss=5.097, nll_loss=2.327, w2v_ctc_loss=1.058, task_loss=16.646, contrastive_loss=0.116, total=4091.86, n_correct=2786.65, ppl=5.02, accuracy=68.102, wps=6721.3, ups=1.64, wpb=4091.9, bsz=149.9, num_updates=53600, lr=6.10847e-05, gnorm=0.975, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=4324
2023-07-16 23:19:10 | INFO | train_inner | epoch 037:    658 / 1474 loss=3.69, trans_loss=5.111, nll_loss=2.345, w2v_ctc_loss=1.085, task_loss=17.032, contrastive_loss=0.134, total=4096.37, n_correct=2775.6, ppl=5.08, accuracy=67.758, wps=6719.7, ups=1.64, wpb=4096.4, bsz=145.2, num_updates=53700, lr=6.10278e-05, gnorm=0.988, clip=0, loss_scale=32, train_wall=61, gb_free=15.2, wall=4385
2023-07-16 23:20:11 | INFO | train_inner | epoch 037:    758 / 1474 loss=3.668, trans_loss=5.102, nll_loss=2.334, w2v_ctc_loss=1.047, task_loss=15.922, contrastive_loss=0.251, total=4124.05, n_correct=2805.33, ppl=5.04, accuracy=68.024, wps=6798.3, ups=1.65, wpb=4124.1, bsz=152.7, num_updates=53800, lr=6.09711e-05, gnorm=0.966, clip=0, loss_scale=32, train_wall=60, gb_free=13.8, wall=4446
2023-07-16 23:21:11 | INFO | train_inner | epoch 037:    858 / 1474 loss=3.656, trans_loss=5.101, nll_loss=2.333, w2v_ctc_loss=1.045, task_loss=15.108, contrastive_loss=0.121, total=4161.41, n_correct=2829.37, ppl=5.04, accuracy=67.991, wps=6872.7, ups=1.65, wpb=4161.4, bsz=157.5, num_updates=53900, lr=6.09145e-05, gnorm=0.959, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=4506
2023-07-16 23:22:12 | INFO | train_inner | epoch 037:    958 / 1474 loss=3.696, trans_loss=5.121, nll_loss=2.358, w2v_ctc_loss=1.093, task_loss=16.931, contrastive_loss=0.133, total=4108.96, n_correct=2786.83, ppl=5.13, accuracy=67.823, wps=6755.5, ups=1.64, wpb=4109, bsz=147.4, num_updates=54000, lr=6.08581e-05, gnorm=1, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=4567
2023-07-16 23:22:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-16 23:22:39 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 4.206 | trans_loss 5.559 | nll_loss 2.831 | w2v_ctc_loss 1.375 | task_loss 23.075 | contrastive_loss 0.265 | total 4003.4 | n_correct 2498.2 | ppl 7.12 | accuracy 62.402 | uer 16.55 | wer 18.437 | raw_wer 18.437 | bleu 20.49 | wps 1748.9 | wpb 4003.4 | bsz 141.8 | num_updates 54000 | best_bleu 20.59
2023-07-16 23:22:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54000 updates
2023-07-16 23:22:39 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_37_54000.pt
2023-07-16 23:22:42 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_37_54000.pt
2023-07-16 23:22:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_37_54000.pt (epoch 37 @ 54000 updates, score 20.49) (writing took 6.503022815915756 seconds)
2023-07-16 23:23:47 | INFO | train_inner | epoch 037:   1058 / 1474 loss=3.671, trans_loss=5.102, nll_loss=2.334, w2v_ctc_loss=1.04, task_loss=15.319, contrastive_loss=0.383, total=4140.79, n_correct=2818.65, ppl=5.04, accuracy=68.07, wps=4347.5, ups=1.05, wpb=4140.8, bsz=157.3, num_updates=54100, lr=6.08018e-05, gnorm=0.979, clip=0, loss_scale=32, train_wall=61, gb_free=15.3, wall=4662
2023-07-16 23:24:48 | INFO | train_inner | epoch 037:   1158 / 1474 loss=3.692, trans_loss=5.122, nll_loss=2.361, w2v_ctc_loss=1.056, task_loss=15.232, contrastive_loss=0.446, total=4188.76, n_correct=2835.71, ppl=5.14, accuracy=67.698, wps=6858.2, ups=1.64, wpb=4188.8, bsz=158.6, num_updates=54200, lr=6.07457e-05, gnorm=0.971, clip=0, loss_scale=32, train_wall=61, gb_free=15.4, wall=4723
2023-07-16 23:25:49 | INFO | train_inner | epoch 037:   1258 / 1474 loss=3.669, trans_loss=5.112, nll_loss=2.347, w2v_ctc_loss=1.051, task_loss=15.555, contrastive_loss=0.139, total=4170.22, n_correct=2831.72, ppl=5.09, accuracy=67.903, wps=6852.7, ups=1.64, wpb=4170.2, bsz=155.8, num_updates=54300, lr=6.06897e-05, gnorm=0.974, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=4784
2023-07-16 23:26:50 | INFO | train_inner | epoch 037:   1358 / 1474 loss=3.703, trans_loss=5.121, nll_loss=2.358, w2v_ctc_loss=1.105, task_loss=17.688, contrastive_loss=0.116, total=4071.07, n_correct=2756.28, ppl=5.13, accuracy=67.704, wps=6649.5, ups=1.63, wpb=4071.1, bsz=142.7, num_updates=54400, lr=6.06339e-05, gnorm=0.995, clip=0, loss_scale=64, train_wall=61, gb_free=10.4, wall=4845
2023-07-16 23:27:51 | INFO | train_inner | epoch 037:   1458 / 1474 loss=3.671, trans_loss=5.107, nll_loss=2.341, w2v_ctc_loss=1.045, task_loss=15.832, contrastive_loss=0.182, total=4160.94, n_correct=2826.08, ppl=5.07, accuracy=67.919, wps=6812.5, ups=1.64, wpb=4160.9, bsz=153.1, num_updates=54500, lr=6.05783e-05, gnorm=0.967, clip=0, loss_scale=64, train_wall=61, gb_free=16, wall=4907
2023-07-16 23:28:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-16 23:28:31 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 4.213 | trans_loss 5.561 | nll_loss 2.831 | w2v_ctc_loss 1.39 | task_loss 23.166 | contrastive_loss 0.275 | total 4003.4 | n_correct 2495.1 | ppl 7.12 | accuracy 62.325 | uer 16.457 | wer 18.34 | raw_wer 18.34 | bleu 19.96 | wps 1687.3 | wpb 4003.4 | bsz 141.8 | num_updates 54516 | best_bleu 20.59
2023-07-16 23:28:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54516 updates
2023-07-16 23:28:31 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt
2023-07-16 23:28:35 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt
2023-07-16 23:28:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_last.pt (epoch 37 @ 54516 updates, score 19.96) (writing took 4.2701774219749495 seconds)
2023-07-16 23:28:35 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-07-16 23:28:35 | INFO | train | epoch 037 | loss 3.676 | trans_loss 5.106 | nll_loss 2.34 | w2v_ctc_loss 1.06 | task_loss 16.042 | contrastive_loss 0.219 | total 4138.65 | n_correct 2812.05 | ppl 5.06 | accuracy 67.946 | wps 6254.9 | ups 1.51 | wpb 4138.6 | bsz 152.8 | num_updates 54516 | lr 6.05694e-05 | gnorm 0.978 | clip 0 | loss_scale 64 | train_wall 893 | gb_free 13.3 | wall 4950
2023-07-16 23:28:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-16 23:28:35 | INFO | fairseq.trainer | begin training epoch 38
2023-07-16 23:28:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-16 23:29:34 | INFO | train_inner | epoch 038:     84 / 1474 loss=3.661, trans_loss=5.09, nll_loss=2.318, w2v_ctc_loss=1.052, task_loss=16.785, contrastive_loss=0.111, total=4084.91, n_correct=2787.9, ppl=4.98, accuracy=68.249, wps=3973.4, ups=0.97, wpb=4084.9, bsz=146.6, num_updates=54600, lr=6.05228e-05, gnorm=0.984, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=5009
2023-07-16 23:30:35 | INFO | train_inner | epoch 038:    184 / 1474 loss=3.655, trans_loss=5.082, nll_loss=2.306, w2v_ctc_loss=1.043, task_loss=16.891, contrastive_loss=0.117, total=4081.45, n_correct=2791.34, ppl=4.94, accuracy=68.391, wps=6716, ups=1.65, wpb=4081.5, bsz=146, num_updates=54700, lr=6.04674e-05, gnorm=0.984, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=5070
2023-07-16 23:31:36 | INFO | train_inner | epoch 038:    284 / 1474 loss=3.663, trans_loss=5.093, nll_loss=2.322, w2v_ctc_loss=1.043, task_loss=16.909, contrastive_loss=0.153, total=4059.24, n_correct=2769.03, ppl=5, accuracy=68.215, wps=6714.1, ups=1.65, wpb=4059.2, bsz=146.6, num_updates=54800, lr=6.04122e-05, gnorm=0.979, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=5131
2023-07-16 23:32:37 | INFO | train_inner | epoch 038:    384 / 1474 loss=3.665, trans_loss=5.095, nll_loss=2.324, w2v_ctc_loss=1.062, task_loss=15.802, contrastive_loss=0.157, total=4176.56, n_correct=2849.01, ppl=5.01, accuracy=68.214, wps=6839.1, ups=1.64, wpb=4176.6, bsz=154.6, num_updates=54900, lr=6.03572e-05, gnorm=0.984, clip=0, loss_scale=64, train_wall=61, gb_free=16.3, wall=5192
2023-07-16 23:33:37 | INFO | train_inner | epoch 038:    484 / 1474 loss=3.644, trans_loss=5.083, nll_loss=2.308, w2v_ctc_loss=1.028, task_loss=15.425, contrastive_loss=0.15, total=4191.63, n_correct=2864.21, ppl=4.95, accuracy=68.332, wps=6955.6, ups=1.66, wpb=4191.6, bsz=156.4, num_updates=55000, lr=6.03023e-05, gnorm=0.965, clip=0, loss_scale=64, train_wall=60, gb_free=15.9, wall=5252
mt_weight tensor(0.0260, device='cuda:0')
asr_weight tensor(0.0016, device='cuda:0')
2023-07-16 23:34:39 | INFO | train_inner | epoch 038:    584 / 1474 loss=3.693, trans_loss=5.112, nll_loss=2.347, w2v_ctc_loss=1.045, task_loss=15.942, contrastive_loss=0.485, total=4179.76, n_correct=2832.52, ppl=5.09, accuracy=67.768, wps=6702.9, ups=1.6, wpb=4179.8, bsz=154.8, num_updates=55100, lr=6.02475e-05, gnorm=0.982, clip=0, loss_scale=64, train_wall=62, gb_free=16.1, wall=5314
2023-07-16 23:35:41 | INFO | train_inner | epoch 038:    684 / 1474 loss=3.666, trans_loss=5.093, nll_loss=2.324, w2v_ctc_loss=1.041, task_loss=15.261, contrastive_loss=0.451, total=4173.72, n_correct=2844.39, ppl=5.01, accuracy=68.15, wps=6794, ups=1.63, wpb=4173.7, bsz=160.6, num_updates=55200, lr=6.01929e-05, gnorm=0.966, clip=0, loss_scale=64, train_wall=61, gb_free=16.5, wall=5376
2023-07-16 23:36:41 | INFO | train_inner | epoch 038:    784 / 1474 loss=3.643, trans_loss=5.083, nll_loss=2.31, w2v_ctc_loss=1.025, task_loss=14.712, contrastive_loss=0.302, total=4183.15, n_correct=2861.17, ppl=4.96, accuracy=68.397, wps=6894.4, ups=1.65, wpb=4183.1, bsz=163.3, num_updates=55300, lr=6.01385e-05, gnorm=0.974, clip=0, loss_scale=64, train_wall=60, gb_free=17.8, wall=5436
2023-07-16 23:37:41 | INFO | train_inner | epoch 038:    884 / 1474 loss=3.646, trans_loss=5.085, nll_loss=2.313, w2v_ctc_loss=1.043, task_loss=15.291, contrastive_loss=0.122, total=4121.14, n_correct=2815.22, ppl=4.97, accuracy=68.312, wps=6876.7, ups=1.67, wpb=4121.1, bsz=155.6, num_updates=55400, lr=6.00842e-05, gnorm=0.982, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=5496
2023-07-16 23:38:42 | INFO | train_inner | epoch 038:    984 / 1474 loss=3.683, trans_loss=5.114, nll_loss=2.349, w2v_ctc_loss=1.066, task_loss=16.062, contrastive_loss=0.189, total=4118.13, n_correct=2797.22, ppl=5.1, accuracy=67.925, wps=6812.2, ups=1.65, wpb=4118.1, bsz=151, num_updates=55500, lr=6.003e-05, gnorm=0.994, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=5557
2023-07-16 23:39:43 | INFO | train_inner | epoch 038:   1084 / 1474 loss=3.664, trans_loss=5.101, nll_loss=2.334, w2v_ctc_loss=1.053, task_loss=14.545, contrastive_loss=0.253, total=4251.69, n_correct=2892.22, ppl=5.04, accuracy=68.025, wps=6964.4, ups=1.64, wpb=4251.7, bsz=164.7, num_updates=55600, lr=5.9976e-05, gnorm=0.97, clip=0, loss_scale=64, train_wall=61, gb_free=12.1, wall=5618
2023-07-16 23:40:45 | INFO | train_inner | epoch 038:   1184 / 1474 loss=3.69, trans_loss=5.112, nll_loss=2.347, w2v_ctc_loss=1.075, task_loss=17.687, contrastive_loss=0.131, total=4075.24, n_correct=2761.88, ppl=5.09, accuracy=67.772, wps=6533.9, ups=1.6, wpb=4075.2, bsz=143.2, num_updates=55700, lr=5.99222e-05, gnorm=0.989, clip=0, loss_scale=64, train_wall=62, gb_free=17.4, wall=5680
2023-07-16 23:41:46 | INFO | train_inner | epoch 038:   1284 / 1474 loss=3.684, trans_loss=5.118, nll_loss=2.354, w2v_ctc_loss=1.06, task_loss=16.944, contrastive_loss=0.126, total=4146.63, n_correct=2809.67, ppl=5.11, accuracy=67.758, wps=6765.6, ups=1.63, wpb=4146.6, bsz=148.5, num_updates=55800, lr=5.98684e-05, gnorm=0.979, clip=0, loss_scale=64, train_wall=61, gb_free=17.7, wall=5742
2023-07-16 23:42:47 | INFO | train_inner | epoch 038:   1384 / 1474 loss=3.685, trans_loss=5.118, nll_loss=2.356, w2v_ctc_loss=1.064, task_loss=15.844, contrastive_loss=0.233, total=4151.37, n_correct=2810.83, ppl=5.12, accuracy=67.708, wps=6835.6, ups=1.65, wpb=4151.4, bsz=155, num_updates=55900, lr=5.98149e-05, gnorm=0.99, clip=0, loss_scale=64, train_wall=60, gb_free=15, wall=5802
2023-07-16 23:43:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.0260, device='cuda:7')
asr_weight tensor(0.0016, device='cuda:7')
mt_weight tensor(0.0260, device='cuda:5')
asr_weight tensor(0.0016, device='cuda:5')
mt_weight tensor(0.0260, device='cuda:6')
asr_weight tensor(0.0016, device='cuda:6')
mt_weight tensor(0.0260, device='cuda:3')
asr_weight tensor(0.0016, device='cuda:3')
mt_weight tensor(0.0260, device='cuda:4')
asr_weight tensor(0.0016, device='cuda:4')
mt_weight tensor(0.0260, device='cuda:2')
asr_weight tensor(0.0016, device='cuda:2')
mt_weight tensor(0.0260, device='cuda:1')
asr_weight tensor(0.0016, device='cuda:1')
2023-07-16 23:44:09 | INFO | dev_st | epoch 038 | valid on 'dev_st' subset | loss 4.187 | trans_loss 5.554 | nll_loss 2.824 | w2v_ctc_loss 1.32 | task_loss 23.138 | contrastive_loss 0.268 | total 4003.4 | n_correct 2499.8 | ppl 7.08 | accuracy 62.442 | uer 16.149 | wer 17.978 | raw_wer 17.978 | bleu 20.54 | wps 1855 | wpb 4003.4 | bsz 141.8 | num_updates 55990 | best_bleu 20.59
2023-07-16 23:44:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 55990 updates
2023-07-16 23:44:09 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.5403.pt
2023-07-16 23:44:11 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.5403.pt
2023-07-16 23:44:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.5403.pt (epoch 38 @ 55990 updates, score 20.54) (writing took 5.4151993279810995 seconds)
2023-07-16 23:44:15 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-07-16 23:44:15 | INFO | train | epoch 038 | loss 3.668 | trans_loss 5.099 | nll_loss 2.33 | w2v_ctc_loss 1.05 | task_loss 16.037 | contrastive_loss 0.219 | total 4138.65 | n_correct 2817.74 | ppl 5.03 | accuracy 68.084 | wps 6489.5 | ups 1.57 | wpb 4138.6 | bsz 152.8 | num_updates 55990 | lr 5.97668e-05 | gnorm 0.981 | clip 0 | loss_scale 64 | train_wall 892 | gb_free 16.8 | wall 5890
2023-07-16 23:44:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-16 23:44:15 | INFO | fairseq.trainer | begin training epoch 39
2023-07-16 23:44:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-16 23:44:29 | INFO | train_inner | epoch 039:     10 / 1474 loss=3.69, trans_loss=5.111, nll_loss=2.345, w2v_ctc_loss=1.064, task_loss=17.337, contrastive_loss=0.249, total=4036.48, n_correct=2740.89, ppl=5.08, accuracy=67.903, wps=3980.4, ups=0.99, wpb=4036.5, bsz=142.5, num_updates=56000, lr=5.97614e-05, gnorm=0.991, clip=0, loss_scale=64, train_wall=60, gb_free=14.4, wall=5904
2023-07-16 23:44:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-16 23:44:55 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 4.206 | trans_loss 5.555 | nll_loss 2.824 | w2v_ctc_loss 1.381 | task_loss 23.145 | contrastive_loss 0.271 | total 4003.4 | n_correct 2497.2 | ppl 7.08 | accuracy 62.377 | uer 16.253 | wer 17.945 | raw_wer 17.945 | bleu 20.16 | wps 1973.9 | wpb 4003.4 | bsz 141.8 | num_updates 56000 | best_bleu 20.59
2023-07-16 23:44:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 56000 updates
2023-07-16 23:44:55 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_39_56000.pt
2023-07-16 23:44:57 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_39_56000.pt
2023-07-16 23:45:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_39_56000.pt (epoch 39 @ 56000 updates, score 20.16) (writing took 5.1414485649438575 seconds)
2023-07-16 23:46:00 | INFO | train_inner | epoch 039:    110 / 1474 loss=3.653, trans_loss=5.072, nll_loss=2.293, w2v_ctc_loss=1.049, task_loss=17.035, contrastive_loss=0.116, total=4055.79, n_correct=2781.27, ppl=4.9, accuracy=68.575, wps=4433.3, ups=1.09, wpb=4055.8, bsz=143.5, num_updates=56100, lr=5.97081e-05, gnorm=0.986, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=5995
2023-07-16 23:47:21 | INFO | train_inner | epoch 039:    210 / 1474 loss=3.652, trans_loss=5.077, nll_loss=2.3, w2v_ctc_loss=1.051, task_loss=16.397, contrastive_loss=0.116, total=4135.11, n_correct=2828.68, ppl=4.92, accuracy=68.406, wps=5099.9, ups=1.23, wpb=4135.1, bsz=149.8, num_updates=56200, lr=5.9655e-05, gnorm=0.977, clip=0, loss_scale=64, train_wall=81, gb_free=15.8, wall=6076
2023-07-16 23:48:22 | INFO | train_inner | epoch 039:    310 / 1474 loss=3.639, trans_loss=5.066, nll_loss=2.286, w2v_ctc_loss=1.033, task_loss=16.248, contrastive_loss=0.125, total=4138.26, n_correct=2840.53, ppl=4.88, accuracy=68.641, wps=6766.9, ups=1.64, wpb=4138.3, bsz=150.5, num_updates=56300, lr=5.9602e-05, gnorm=0.967, clip=0, loss_scale=64, train_wall=61, gb_free=17.6, wall=6137
2023-07-16 23:49:23 | INFO | train_inner | epoch 039:    410 / 1474 loss=3.669, trans_loss=5.091, nll_loss=2.32, w2v_ctc_loss=1.044, task_loss=15.843, contrastive_loss=0.421, total=4133.25, n_correct=2821.21, ppl=4.99, accuracy=68.256, wps=6760.6, ups=1.64, wpb=4133.2, bsz=156.4, num_updates=56400, lr=5.95491e-05, gnorm=0.984, clip=0, loss_scale=64, train_wall=61, gb_free=16.9, wall=6199
2023-07-16 23:50:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-16 23:50:26 | INFO | train_inner | epoch 039:    511 / 1474 loss=3.67, trans_loss=5.092, nll_loss=2.321, w2v_ctc_loss=1.041, task_loss=16.003, contrastive_loss=0.44, total=4134.74, n_correct=2819.7, ppl=5, accuracy=68.195, wps=6653.7, ups=1.61, wpb=4134.7, bsz=154.5, num_updates=56500, lr=5.94964e-05, gnorm=0.969, clip=0, loss_scale=64, train_wall=62, gb_free=17, wall=6261
2023-07-16 23:51:26 | INFO | train_inner | epoch 039:    611 / 1474 loss=3.668, trans_loss=5.097, nll_loss=2.327, w2v_ctc_loss=1.043, task_loss=16.274, contrastive_loss=0.231, total=4131.41, n_correct=2816.33, ppl=5.02, accuracy=68.169, wps=6797.2, ups=1.65, wpb=4131.4, bsz=151.4, num_updates=56600, lr=5.94438e-05, gnorm=0.982, clip=0, loss_scale=64, train_wall=60, gb_free=16, wall=6321
2023-07-16 23:52:26 | INFO | train_inner | epoch 039:    711 / 1474 loss=3.66, trans_loss=5.093, nll_loss=2.322, w2v_ctc_loss=1.033, task_loss=15.572, contrastive_loss=0.217, total=4133.78, n_correct=2819.06, ppl=5, accuracy=68.196, wps=6895.4, ups=1.67, wpb=4133.8, bsz=152.9, num_updates=56700, lr=5.93914e-05, gnorm=0.97, clip=0, loss_scale=64, train_wall=60, gb_free=16.2, wall=6381
2023-07-16 23:53:28 | INFO | train_inner | epoch 039:    811 / 1474 loss=3.655, trans_loss=5.087, nll_loss=2.315, w2v_ctc_loss=1.047, task_loss=16.101, contrastive_loss=0.143, total=4178.43, n_correct=2851.27, ppl=4.98, accuracy=68.238, wps=6780.2, ups=1.62, wpb=4178.4, bsz=154.9, num_updates=56800, lr=5.93391e-05, gnorm=0.976, clip=0, loss_scale=64, train_wall=61, gb_free=17.1, wall=6443
2023-07-16 23:54:29 | INFO | train_inner | epoch 039:    911 / 1474 loss=3.659, trans_loss=5.09, nll_loss=2.318, w2v_ctc_loss=1.04, task_loss=16.541, contrastive_loss=0.147, total=4125.39, n_correct=2815.56, ppl=4.98, accuracy=68.25, wps=6708, ups=1.63, wpb=4125.4, bsz=149.5, num_updates=56900, lr=5.92869e-05, gnorm=0.977, clip=0, loss_scale=64, train_wall=61, gb_free=17, wall=6505
2023-07-16 23:55:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-16 23:55:32 | INFO | train_inner | epoch 039:   1012 / 1474 loss=3.666, trans_loss=5.102, nll_loss=2.335, w2v_ctc_loss=1.051, task_loss=16.132, contrastive_loss=0.156, total=4176.11, n_correct=2841.59, ppl=5.04, accuracy=68.044, wps=6725.5, ups=1.61, wpb=4176.1, bsz=155.5, num_updates=57000, lr=5.92349e-05, gnorm=0.978, clip=0, loss_scale=32, train_wall=62, gb_free=16.8, wall=6567
2023-07-16 23:56:32 | INFO | train_inner | epoch 039:   1112 / 1474 loss=3.655, trans_loss=5.088, nll_loss=2.317, w2v_ctc_loss=1.034, task_loss=14.992, contrastive_loss=0.313, total=4192.7, n_correct=2861.72, ppl=4.98, accuracy=68.255, wps=6924.6, ups=1.65, wpb=4192.7, bsz=160.9, num_updates=57100, lr=5.9183e-05, gnorm=0.96, clip=0, loss_scale=32, train_wall=60, gb_free=12.5, wall=6627
2023-07-16 23:57:33 | INFO | train_inner | epoch 039:   1212 / 1474 loss=3.672, trans_loss=5.106, nll_loss=2.341, w2v_ctc_loss=1.055, task_loss=15.958, contrastive_loss=0.207, total=4126.68, n_correct=2802.92, ppl=5.07, accuracy=67.922, wps=6817.2, ups=1.65, wpb=4126.7, bsz=154.6, num_updates=57200, lr=5.91312e-05, gnorm=0.983, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=6688
2023-07-16 23:58:34 | INFO | train_inner | epoch 039:   1312 / 1474 loss=3.659, trans_loss=5.098, nll_loss=2.33, w2v_ctc_loss=1.044, task_loss=15.329, contrastive_loss=0.174, total=4176.04, n_correct=2844.87, ppl=5.03, accuracy=68.124, wps=6821.8, ups=1.63, wpb=4176, bsz=157.7, num_updates=57300, lr=5.90796e-05, gnorm=0.978, clip=0, loss_scale=32, train_wall=61, gb_free=17.4, wall=6749
2023-07-16 23:59:34 | INFO | train_inner | epoch 039:   1412 / 1474 loss=3.679, trans_loss=5.102, nll_loss=2.332, w2v_ctc_loss=1.051, task_loss=17.606, contrastive_loss=0.102, total=4055.22, n_correct=2757.3, ppl=5.04, accuracy=67.994, wps=6746, ups=1.66, wpb=4055.2, bsz=139.2, num_updates=57400, lr=5.90281e-05, gnorm=0.993, clip=0, loss_scale=32, train_wall=60, gb_free=15.1, wall=6809
2023-07-17 00:00:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 00:00:39 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 4.197 | trans_loss 5.555 | nll_loss 2.826 | w2v_ctc_loss 1.35 | task_loss 23.064 | contrastive_loss 0.269 | total 4003.4 | n_correct 2499.8 | ppl 7.09 | accuracy 62.442 | uer 16.11 | wer 17.852 | raw_wer 17.852 | bleu 20.42 | wps 1996.9 | wpb 4003.4 | bsz 141.8 | num_updates 57462 | best_bleu 20.59
2023-07-17 00:00:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 57462 updates
2023-07-17 00:00:39 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.4205.pt
2023-07-17 00:00:41 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.4205.pt
2023-07-17 00:00:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.4205.pt (epoch 39 @ 57462 updates, score 20.42) (writing took 5.358384352992289 seconds)
2023-07-17 00:00:44 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-07-17 00:00:44 | INFO | train | epoch 039 | loss 3.661 | trans_loss 5.091 | nll_loss 2.319 | w2v_ctc_loss 1.044 | task_loss 16.071 | contrastive_loss 0.207 | total 4136.86 | n_correct 2822.27 | ppl 4.99 | accuracy 68.222 | wps 6156 | ups 1.49 | wpb 4136.9 | bsz 152.5 | num_updates 57462 | lr 5.89963e-05 | gnorm 0.977 | clip 0 | loss_scale 32 | train_wall 912 | gb_free 15.7 | wall 6879
2023-07-17 00:00:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 00:00:45 | INFO | fairseq.trainer | begin training epoch 40
2023-07-17 00:00:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 00:01:15 | INFO | train_inner | epoch 040:     38 / 1474 loss=3.652, trans_loss=5.094, nll_loss=2.324, w2v_ctc_loss=1.03, task_loss=15.454, contrastive_loss=0.149, total=4169.65, n_correct=2842.67, ppl=5.01, accuracy=68.175, wps=4114.5, ups=0.99, wpb=4169.6, bsz=156, num_updates=57500, lr=5.89768e-05, gnorm=0.987, clip=0, loss_scale=32, train_wall=61, gb_free=16.1, wall=6910
2023-07-17 00:02:16 | INFO | train_inner | epoch 040:    138 / 1474 loss=3.64, trans_loss=5.066, nll_loss=2.286, w2v_ctc_loss=1.043, task_loss=15.946, contrastive_loss=0.132, total=4150.02, n_correct=2849.08, ppl=4.88, accuracy=68.652, wps=6836.6, ups=1.65, wpb=4150, bsz=152.6, num_updates=57600, lr=5.89256e-05, gnorm=0.977, clip=0, loss_scale=32, train_wall=60, gb_free=17.9, wall=6971
2023-07-17 00:03:16 | INFO | train_inner | epoch 040:    238 / 1474 loss=3.643, trans_loss=5.069, nll_loss=2.29, w2v_ctc_loss=1.04, task_loss=16.399, contrastive_loss=0.133, total=4101.15, n_correct=2812.67, ppl=4.89, accuracy=68.582, wps=6818.6, ups=1.66, wpb=4101.1, bsz=149.9, num_updates=57700, lr=5.88745e-05, gnorm=0.983, clip=0, loss_scale=32, train_wall=60, gb_free=10.8, wall=7031
2023-07-17 00:04:16 | INFO | train_inner | epoch 040:    338 / 1474 loss=3.63, trans_loss=5.072, nll_loss=2.295, w2v_ctc_loss=1.023, task_loss=14.79, contrastive_loss=0.155, total=4161.74, n_correct=2853.18, ppl=4.91, accuracy=68.557, wps=6920.9, ups=1.66, wpb=4161.7, bsz=160.6, num_updates=57800, lr=5.88235e-05, gnorm=0.98, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=7091
2023-07-17 00:05:17 | INFO | train_inner | epoch 040:    438 / 1474 loss=3.654, trans_loss=5.082, nll_loss=2.308, w2v_ctc_loss=1.034, task_loss=16.004, contrastive_loss=0.306, total=4141.51, n_correct=2829.53, ppl=4.95, accuracy=68.321, wps=6773, ups=1.64, wpb=4141.5, bsz=155.3, num_updates=57900, lr=5.87727e-05, gnorm=0.982, clip=0, loss_scale=32, train_wall=61, gb_free=16.7, wall=7153
2023-07-17 00:06:19 | INFO | train_inner | epoch 040:    538 / 1474 loss=3.648, trans_loss=5.075, nll_loss=2.299, w2v_ctc_loss=1.021, task_loss=15.554, contrastive_loss=0.352, total=4167.53, n_correct=2857.06, ppl=4.92, accuracy=68.555, wps=6800.7, ups=1.63, wpb=4167.5, bsz=157.8, num_updates=58000, lr=5.8722e-05, gnorm=0.964, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=7214
2023-07-17 00:06:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 00:06:44 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 4.206 | trans_loss 5.558 | nll_loss 2.831 | w2v_ctc_loss 1.373 | task_loss 23.103 | contrastive_loss 0.27 | total 4003.4 | n_correct 2498.7 | ppl 7.12 | accuracy 62.414 | uer 16.311 | wer 18.116 | raw_wer 18.116 | bleu 20.28 | wps 2096.5 | wpb 4003.4 | bsz 141.8 | num_updates 58000 | best_bleu 20.59
2023-07-17 00:06:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58000 updates
2023-07-17 00:06:44 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_40_58000.pt
2023-07-17 00:06:46 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_40_58000.pt
2023-07-17 00:06:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_40_58000.pt (epoch 40 @ 58000 updates, score 20.28) (writing took 5.244334434974007 seconds)
2023-07-17 00:07:51 | INFO | train_inner | epoch 040:    638 / 1474 loss=3.67, trans_loss=5.093, nll_loss=2.322, w2v_ctc_loss=1.063, task_loss=16.661, contrastive_loss=0.158, total=4118.6, n_correct=2805.17, ppl=5, accuracy=68.11, wps=4487.2, ups=1.09, wpb=4118.6, bsz=149.2, num_updates=58100, lr=5.86715e-05, gnorm=0.987, clip=0, loss_scale=32, train_wall=61, gb_free=12.7, wall=7306
2023-07-17 00:08:51 | INFO | train_inner | epoch 040:    738 / 1474 loss=3.638, trans_loss=5.077, nll_loss=2.301, w2v_ctc_loss=1.023, task_loss=15.448, contrastive_loss=0.118, total=4137.91, n_correct=2833.79, ppl=4.93, accuracy=68.484, wps=6846, ups=1.65, wpb=4137.9, bsz=154.2, num_updates=58200, lr=5.8621e-05, gnorm=0.974, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=7366
2023-07-17 00:09:52 | INFO | train_inner | epoch 040:    838 / 1474 loss=3.667, trans_loss=5.094, nll_loss=2.325, w2v_ctc_loss=1.031, task_loss=14.499, contrastive_loss=0.54, total=4214.92, n_correct=2872.5, ppl=5.01, accuracy=68.151, wps=6879.6, ups=1.63, wpb=4214.9, bsz=164.6, num_updates=58300, lr=5.85707e-05, gnorm=0.975, clip=0, loss_scale=32, train_wall=61, gb_free=16.8, wall=7427
2023-07-17 00:10:53 | INFO | train_inner | epoch 040:    938 / 1474 loss=3.671, trans_loss=5.095, nll_loss=2.325, w2v_ctc_loss=1.054, task_loss=16.881, contrastive_loss=0.171, total=4092.24, n_correct=2786.08, ppl=5.01, accuracy=68.082, wps=6721.7, ups=1.64, wpb=4092.2, bsz=146.8, num_updates=58400, lr=5.85206e-05, gnorm=1.005, clip=0, loss_scale=32, train_wall=60, gb_free=15.2, wall=7488
2023-07-17 00:11:54 | INFO | train_inner | epoch 040:   1038 / 1474 loss=3.691, trans_loss=5.108, nll_loss=2.342, w2v_ctc_loss=1.061, task_loss=17.344, contrastive_loss=0.212, total=4119.93, n_correct=2799.04, ppl=5.07, accuracy=67.939, wps=6763.6, ups=1.64, wpb=4119.9, bsz=143.8, num_updates=58500, lr=5.84705e-05, gnorm=1.004, clip=0, loss_scale=32, train_wall=61, gb_free=16, wall=7549
2023-07-17 00:12:55 | INFO | train_inner | epoch 040:   1138 / 1474 loss=3.669, trans_loss=5.098, nll_loss=2.329, w2v_ctc_loss=1.055, task_loss=16.729, contrastive_loss=0.141, total=4124.74, n_correct=2803.35, ppl=5.02, accuracy=67.964, wps=6743.3, ups=1.63, wpb=4124.7, bsz=149.2, num_updates=58600, lr=5.84206e-05, gnorm=0.995, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=7610
2023-07-17 00:13:57 | INFO | train_inner | epoch 040:   1238 / 1474 loss=3.657, trans_loss=5.083, nll_loss=2.309, w2v_ctc_loss=1.038, task_loss=15.735, contrastive_loss=0.262, total=4198.52, n_correct=2871.02, ppl=4.96, accuracy=68.382, wps=6815.1, ups=1.62, wpb=4198.5, bsz=155.4, num_updates=58700, lr=5.83708e-05, gnorm=0.975, clip=0, loss_scale=32, train_wall=61, gb_free=17.2, wall=7672
2023-07-17 00:14:57 | INFO | train_inner | epoch 040:   1338 / 1474 loss=3.662, trans_loss=5.094, nll_loss=2.325, w2v_ctc_loss=1.031, task_loss=16.137, contrastive_loss=0.273, total=4124.38, n_correct=2812.69, ppl=5.01, accuracy=68.197, wps=6809, ups=1.65, wpb=4124.4, bsz=153, num_updates=58800, lr=5.83212e-05, gnorm=0.99, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=7733
2023-07-17 00:15:58 | INFO | train_inner | epoch 040:   1438 / 1474 loss=3.664, trans_loss=5.094, nll_loss=2.323, w2v_ctc_loss=1.048, task_loss=16.093, contrastive_loss=0.203, total=4121.8, n_correct=2809.61, ppl=5.01, accuracy=68.165, wps=6789.9, ups=1.65, wpb=4121.8, bsz=152.2, num_updates=58900, lr=5.82717e-05, gnorm=0.98, clip=0, loss_scale=32, train_wall=60, gb_free=15.8, wall=7793
2023-07-17 00:16:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 00:16:45 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 4.208 | trans_loss 5.555 | nll_loss 2.823 | w2v_ctc_loss 1.385 | task_loss 23.114 | contrastive_loss 0.279 | total 4003.4 | n_correct 2501.1 | ppl 7.08 | accuracy 62.474 | uer 16.351 | wer 18.042 | raw_wer 18.042 | bleu 20.43 | wps 2075.7 | wpb 4003.4 | bsz 141.8 | num_updates 58936 | best_bleu 20.59
2023-07-17 00:16:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58936 updates
2023-07-17 00:16:45 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.4302.pt
2023-07-17 00:16:48 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.4302.pt
2023-07-17 00:16:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint.best_bleu_20.4302.pt (epoch 40 @ 58936 updates, score 20.43) (writing took 5.2406812000554055 seconds)
2023-07-17 00:16:51 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-07-17 00:16:51 | INFO | train | epoch 040 | loss 3.657 | trans_loss 5.085 | nll_loss 2.312 | w2v_ctc_loss 1.039 | task_loss 16.016 | contrastive_loss 0.223 | total 4138.65 | n_correct 2826.7 | ppl 4.97 | accuracy 68.3 | wps 6310.4 | ups 1.52 | wpb 4138.6 | bsz 152.8 | num_updates 58936 | lr 5.82539e-05 | gnorm 0.984 | clip 0 | loss_scale 32 | train_wall 891 | gb_free 16 | wall 7846
2023-07-17 00:16:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 00:16:51 | INFO | fairseq.trainer | begin training epoch 41
2023-07-17 00:16:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 00:17:38 | INFO | train_inner | epoch 041:     64 / 1474 loss=3.649, trans_loss=5.076, nll_loss=2.3, w2v_ctc_loss=1.037, task_loss=16.645, contrastive_loss=0.142, total=4088.95, n_correct=2800.03, ppl=4.92, accuracy=68.478, wps=4109, ups=1, wpb=4089, bsz=147.8, num_updates=59000, lr=5.82223e-05, gnorm=0.99, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=7893
2023-07-17 00:18:39 | INFO | train_inner | epoch 041:    164 / 1474 loss=3.623, trans_loss=5.05, nll_loss=2.266, w2v_ctc_loss=1.012, task_loss=15.516, contrastive_loss=0.253, total=4141.51, n_correct=2856.71, ppl=4.81, accuracy=68.977, wps=6797.2, ups=1.64, wpb=4141.5, bsz=155.7, num_updates=59100, lr=5.8173e-05, gnorm=0.983, clip=0, loss_scale=64, train_wall=61, gb_free=16, wall=7954
2023-07-17 00:19:39 | INFO | train_inner | epoch 041:    264 / 1474 loss=3.632, trans_loss=5.068, nll_loss=2.29, w2v_ctc_loss=1.012, task_loss=14.912, contrastive_loss=0.237, total=4181.72, n_correct=2871.15, ppl=4.89, accuracy=68.66, wps=6883.1, ups=1.65, wpb=4181.7, bsz=159.6, num_updates=59200, lr=5.81238e-05, gnorm=0.972, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=8014
2023-07-17 00:20:40 | INFO | train_inner | epoch 041:    364 / 1474 loss=3.645, trans_loss=5.068, nll_loss=2.291, w2v_ctc_loss=1.045, task_loss=16.023, contrastive_loss=0.156, total=4147.02, n_correct=2848.65, ppl=4.89, accuracy=68.691, wps=6836.5, ups=1.65, wpb=4147, bsz=152.5, num_updates=59300, lr=5.80748e-05, gnorm=0.988, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=8075
2023-07-17 00:21:41 | INFO | train_inner | epoch 041:    464 / 1474 loss=3.633, trans_loss=5.063, nll_loss=2.282, w2v_ctc_loss=1.022, task_loss=16.117, contrastive_loss=0.121, total=4144.36, n_correct=2848.79, ppl=4.86, accuracy=68.739, wps=6814.9, ups=1.64, wpb=4144.4, bsz=151.4, num_updates=59400, lr=5.80259e-05, gnorm=0.971, clip=0, loss_scale=64, train_wall=60, gb_free=16.1, wall=8136
2023-07-17 00:22:41 | INFO | train_inner | epoch 041:    564 / 1474 loss=3.641, trans_loss=5.071, nll_loss=2.293, w2v_ctc_loss=1.03, task_loss=16.054, contrastive_loss=0.156, total=4145.19, n_correct=2843.59, ppl=4.9, accuracy=68.6, wps=6866.2, ups=1.66, wpb=4145.2, bsz=153.6, num_updates=59500, lr=5.79771e-05, gnorm=0.972, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=8196
2023-07-17 00:23:42 | INFO | train_inner | epoch 041:    664 / 1474 loss=3.627, trans_loss=5.064, nll_loss=2.285, w2v_ctc_loss=1.023, task_loss=15.06, contrastive_loss=0.13, total=4189.74, n_correct=2879.03, ppl=4.87, accuracy=68.716, wps=6937.9, ups=1.66, wpb=4189.7, bsz=159, num_updates=59600, lr=5.79284e-05, gnorm=0.978, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=8257
2023-07-17 00:24:42 | INFO | train_inner | epoch 041:    764 / 1474 loss=3.644, trans_loss=5.073, nll_loss=2.297, w2v_ctc_loss=1.03, task_loss=16.185, contrastive_loss=0.121, total=4150.75, n_correct=2841.53, ppl=4.91, accuracy=68.458, wps=6827.2, ups=1.64, wpb=4150.8, bsz=150.4, num_updates=59700, lr=5.78799e-05, gnorm=0.981, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=8317
2023-07-17 00:25:43 | INFO | train_inner | epoch 041:    864 / 1474 loss=3.649, trans_loss=5.078, nll_loss=2.302, w2v_ctc_loss=1.031, task_loss=16.603, contrastive_loss=0.126, total=4108.1, n_correct=2810.85, ppl=4.93, accuracy=68.422, wps=6734.1, ups=1.64, wpb=4108.1, bsz=147.9, num_updates=59800, lr=5.78315e-05, gnorm=0.989, clip=0, loss_scale=64, train_wall=61, gb_free=16.9, wall=8379
2023-07-17 00:26:45 | INFO | train_inner | epoch 041:    964 / 1474 loss=3.673, trans_loss=5.092, nll_loss=2.321, w2v_ctc_loss=1.05, task_loss=16.688, contrastive_loss=0.305, total=4122.2, n_correct=2810.17, ppl=5, accuracy=68.172, wps=6732.8, ups=1.63, wpb=4122.2, bsz=149.6, num_updates=59900, lr=5.77832e-05, gnorm=0.993, clip=0, loss_scale=64, train_wall=61, gb_free=15.2, wall=8440
2023-07-17 00:27:45 | INFO | train_inner | epoch 041:   1064 / 1474 loss=3.653, trans_loss=5.086, nll_loss=2.314, w2v_ctc_loss=1.038, task_loss=15.938, contrastive_loss=0.134, total=4133.83, n_correct=2823.08, ppl=4.97, accuracy=68.292, wps=6831.6, ups=1.65, wpb=4133.8, bsz=152, num_updates=60000, lr=5.7735e-05, gnorm=0.983, clip=0, loss_scale=64, train_wall=60, gb_free=12.8, wall=8500
2023-07-17 00:27:45 | INFO | fairseq_cli.train | Stopping training due to num_updates: 60000 >= max_update: 60000
2023-07-17 00:27:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 00:28:10 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 4.216 | trans_loss 5.56 | nll_loss 2.83 | w2v_ctc_loss 1.399 | task_loss 23.032 | contrastive_loss 0.278 | total 4003.4 | n_correct 2497 | ppl 7.11 | accuracy 62.372 | uer 16.431 | wer 18.284 | raw_wer 18.284 | bleu 20.15 | wps 2133.9 | wpb 4003.4 | bsz 141.8 | num_updates 60000 | best_bleu 20.59
2023-07-17 00:28:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 60000 updates
2023-07-17 00:28:10 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_41_60000.pt
2023-07-17 00:28:12 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_41_60000.pt
2023-07-17 00:28:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_sentence_scale5_nopad/checkpoint_41_60000.pt (epoch 41 @ 60000 updates, score 20.15) (writing took 5.2470887179952115 seconds)
2023-07-17 00:28:16 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-07-17 00:28:16 | INFO | train | epoch 041 | loss 3.642 | trans_loss 5.071 | nll_loss 2.294 | w2v_ctc_loss 1.03 | task_loss 15.94 | contrastive_loss 0.173 | total 4144.26 | n_correct 2842.06 | ppl 4.9 | accuracy 68.578 | wps 6437.5 | ups 1.55 | wpb 4144.3 | bsz 153 | num_updates 60000 | lr 5.7735e-05 | gnorm 0.982 | clip 0 | loss_scale 64 | train_wall 641 | gb_free 12.8 | wall 8531
2023-07-17 00:28:16 | INFO | fairseq_cli.train | done training in 8452.3 seconds
/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 384 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
