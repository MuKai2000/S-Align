2023-08-02 18:03:33 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:11246
2023-08-02 18:03:33 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:11246
2023-08-02 18:03:33 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:11246
2023-08-02 18:03:33 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11246
2023-08-02 18:03:33 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11246
2023-08-02 18:03:33 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11246
2023-08-02 18:03:33 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:11246
2023-08-02 18:03:33 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11246
2023-08-02 18:03:33 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-02 18:03:33 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-02 18:03:34 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-02 18:03:34 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-02 18:03:34 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-02 18:03:34 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-02 18:03:34 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-02 18:03:34 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-02 18:03:34 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-02 18:03:34 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-08-02 18:03:34 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-02 18:03:34 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-02 18:03:34 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-02 18:03:34 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-08-02 18:03:34 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-08-02 18:03:34 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-02 18:03:34 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-08-02 18:03:34 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-08-02 18:03:34 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-02 18:03:34 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-02 18:03:34 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-08-02 18:03:34 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-08-02 18:03:34 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-02 18:03:34 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-08-02 18:03:38 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11246', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=True, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=True, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=True, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-02 18:03:39 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-02 18:03:39 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-02 18:03:39 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-02 18:03:39 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 1.0
2023-08-02 18:03:39 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-02 18:03:43 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-02 18:03:43 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-02 18:03:43 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-02 18:03:45 | INFO | root | load pretrained hubert
2023-08-02 18:03:46 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-02 18:03:47 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-02 18:03:51 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-02 18:03:51 | INFO | root | share the sematic adapter and textual encoder
2023-08-02 18:03:51 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-02 18:03:51 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-02 18:03:51 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-02 18:03:51 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-02 18:03:51 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-08-02 18:03:51 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-02 18:03:51 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-02 18:03:51 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-02 18:03:51 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-02 18:03:51 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-02 18:03:56 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-02 18:03:56 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-02 18:03:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-02 18:03:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-02 18:03:57 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-02 18:03:57 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-02 18:03:57 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-02 18:03:57 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-02 18:03:57 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-02 18:03:57 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-02 18:03:57 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-02 18:03:57 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-02 18:03:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-02 18:03:57 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-02 18:03:57 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-02 18:03:57 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_last.pt
2023-08-02 18:03:57 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_last.pt
2023-08-02 18:03:57 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-02 18:03:57 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-02 18:03:57 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-02 18:03:57 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-02 18:03:58 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-02 18:04:00 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-02 18:04:47 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-02 18:04:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-02 18:04:47 | INFO | fairseq.trainer | begin training epoch 1
2023-08-02 18:04:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-02 18:06:03 | INFO | train_inner | epoch 001:    100 / 1474 loss=19.616, trans_loss=5.599, nll_loss=4.164, w2v_ctc_loss=23.048, task_loss=0, contrastive_loss=3.325, total=4207.04, n_correct=209.38, ppl=17.93, accuracy=4.977, wps=20181.3, ups=1.61, wpb=12551.1, bsz=471.4, num_updates=100, lr=4.098e-06, gnorm=0.913, clip=0, loss_scale=128, train_wall=68, gb_free=19.5, wall=126
2023-08-02 18:06:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-02 18:07:06 | INFO | train_inner | epoch 001:    201 / 1474 loss=17.415, trans_loss=5.473, nll_loss=4.06, w2v_ctc_loss=19.847, task_loss=0, contrastive_loss=3.283, total=4121.36, n_correct=224.35, ppl=16.68, accuracy=5.444, wps=19614.8, ups=1.59, wpb=12305.5, bsz=461.4, num_updates=200, lr=8.096e-06, gnorm=3.718, clip=0, loss_scale=64, train_wall=62, gb_free=19.2, wall=189
2023-08-02 18:08:07 | INFO | train_inner | epoch 001:    301 / 1474 loss=10.343, trans_loss=5.501, nll_loss=4.148, w2v_ctc_loss=8.993, task_loss=0, contrastive_loss=3.204, total=4079.62, n_correct=201.5, ppl=17.73, accuracy=4.939, wps=19955.3, ups=1.64, wpb=12186.7, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=4.711, clip=0, loss_scale=64, train_wall=60, gb_free=19.9, wall=250
2023-08-02 18:09:08 | INFO | train_inner | epoch 001:    401 / 1474 loss=9.071, trans_loss=5.525, nll_loss=4.201, w2v_ctc_loss=6.983, task_loss=0, contrastive_loss=3.236, total=4174.14, n_correct=191.29, ppl=18.39, accuracy=4.583, wps=20458.4, ups=1.64, wpb=12463.5, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=3.015, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=311
2023-08-02 18:10:09 | INFO | train_inner | epoch 001:    501 / 1474 loss=8.63, trans_loss=5.497, nll_loss=4.181, w2v_ctc_loss=6.334, task_loss=0, contrastive_loss=3.231, total=4176.18, n_correct=185.2, ppl=18.13, accuracy=4.435, wps=20394.5, ups=1.63, wpb=12479.7, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=1.448, clip=0, loss_scale=64, train_wall=61, gb_free=19.2, wall=372
2023-08-02 18:11:12 | INFO | train_inner | epoch 001:    601 / 1474 loss=8.377, trans_loss=5.525, nll_loss=4.216, w2v_ctc_loss=5.959, task_loss=0, contrastive_loss=3.287, total=4147.79, n_correct=182.13, ppl=18.58, accuracy=4.391, wps=19744.1, ups=1.6, wpb=12371.6, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.752, clip=0, loss_scale=64, train_wall=62, gb_free=19, wall=435
2023-08-02 18:12:13 | INFO | train_inner | epoch 001:    701 / 1474 loss=8.202, trans_loss=5.52, nll_loss=4.216, w2v_ctc_loss=5.831, task_loss=0, contrastive_loss=3.038, total=4152.1, n_correct=196.17, ppl=18.58, accuracy=4.725, wps=20326, ups=1.64, wpb=12395.5, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=0.563, clip=0, loss_scale=64, train_wall=60, gb_free=19.5, wall=496
2023-08-02 18:13:13 | INFO | train_inner | epoch 001:    801 / 1474 loss=7.926, trans_loss=5.462, nll_loss=4.154, w2v_ctc_loss=5.602, task_loss=0, contrastive_loss=2.945, total=4123.83, n_correct=239.04, ppl=17.8, accuracy=5.797, wps=20201.5, ups=1.64, wpb=12306.1, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=0.816, clip=0, loss_scale=64, train_wall=60, gb_free=19.2, wall=557
2023-08-02 18:14:14 | INFO | train_inner | epoch 001:    901 / 1474 loss=7.65, trans_loss=5.424, nll_loss=4.119, w2v_ctc_loss=5.407, task_loss=0, contrastive_loss=2.704, total=4163.61, n_correct=264.1, ppl=17.38, accuracy=6.343, wps=20504.8, ups=1.65, wpb=12433.9, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=1.33, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=618
2023-08-02 18:15:16 | INFO | train_inner | epoch 001:   1001 / 1474 loss=7.384, trans_loss=5.405, nll_loss=4.105, w2v_ctc_loss=5.19, task_loss=0, contrastive_loss=2.55, total=4135.34, n_correct=286.05, ppl=17.21, accuracy=6.917, wps=19939.8, ups=1.61, wpb=12353.2, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=1.461, clip=0, loss_scale=64, train_wall=61, gb_free=19, wall=680
2023-08-02 18:16:17 | INFO | train_inner | epoch 001:   1101 / 1474 loss=7.108, trans_loss=5.395, nll_loss=4.096, w2v_ctc_loss=4.986, task_loss=0, contrastive_loss=2.328, total=4147.38, n_correct=309.77, ppl=17.1, accuracy=7.469, wps=20203.3, ups=1.63, wpb=12367, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=1.701, clip=0, loss_scale=64, train_wall=61, gb_free=18.9, wall=741
2023-08-02 18:17:18 | INFO | train_inner | epoch 001:   1201 / 1474 loss=6.87, trans_loss=5.371, nll_loss=4.073, w2v_ctc_loss=4.812, task_loss=0, contrastive_loss=2.117, total=4139.9, n_correct=317.16, ppl=16.83, accuracy=7.661, wps=20279.7, ups=1.64, wpb=12366.5, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=1.744, clip=0, loss_scale=64, train_wall=60, gb_free=19, wall=802
2023-08-02 18:18:19 | INFO | train_inner | epoch 001:   1301 / 1474 loss=6.655, trans_loss=5.371, nll_loss=4.075, w2v_ctc_loss=4.614, task_loss=0, contrastive_loss=1.939, total=4046.58, n_correct=321.25, ppl=16.85, accuracy=7.939, wps=19925, ups=1.65, wpb=12081.6, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=1.845, clip=0, loss_scale=64, train_wall=60, gb_free=19.7, wall=862
2023-08-02 18:19:20 | INFO | train_inner | epoch 001:   1401 / 1474 loss=6.453, trans_loss=5.364, nll_loss=4.07, w2v_ctc_loss=4.413, task_loss=0, contrastive_loss=2.009, total=4133.18, n_correct=330.09, ppl=16.8, accuracy=7.986, wps=20330.4, ups=1.65, wpb=12350, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=1.751, clip=0, loss_scale=64, train_wall=60, gb_free=19.9, wall=923
2023-08-02 18:20:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 18:20:44 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.957 | trans_loss 11 | nll_loss 10.002 | w2v_ctc_loss 5.796 | task_loss 0 | contrastive_loss 2.354 | total 4003.4 | n_correct 358.9 | ppl 1025.11 | accuracy 8.965 | uer 71.744 | wer 69.673 | raw_wer 69.673 | bleu 0.02 | wps 1178.1 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-08-02 18:20:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-08-02 18:20:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 18:20:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 18:20:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.02) (writing took 7.527310436591506 seconds)
2023-08-02 18:20:52 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-02 18:20:52 | INFO | train | epoch 001 | loss 9.264 | trans_loss 5.455 | nll_loss 4.13 | w2v_ctc_loss 7.831 | task_loss 0 | contrastive_loss 2.759 | total 4138.36 | n_correct 251.289 | ppl 17.51 | accuracy 6.072 | wps 19139.8 | ups 1.55 | wpb 12355 | bsz 458.4 | num_updates 1473 | lr 5.89905e-05 | gnorm 1.834 | clip 0 | loss_scale 64 | train_wall 902 | gb_free 19.2 | wall 1015
2023-08-02 18:20:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-02 18:20:52 | INFO | fairseq.trainer | begin training epoch 2
2023-08-02 18:20:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-02 18:21:17 | INFO | train_inner | epoch 002:     27 / 1474 loss=6.266, trans_loss=5.355, nll_loss=4.054, w2v_ctc_loss=4.221, task_loss=0, contrastive_loss=1.857, total=4162.95, n_correct=336.14, ppl=16.61, accuracy=8.075, wps=10589.3, ups=0.85, wpb=12416.8, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=1.7, clip=0, loss_scale=64, train_wall=61, gb_free=19.7, wall=1040
2023-08-02 18:22:18 | INFO | train_inner | epoch 002:    127 / 1474 loss=6.089, trans_loss=5.348, nll_loss=4.045, w2v_ctc_loss=4.098, task_loss=0, contrastive_loss=1.649, total=4155.98, n_correct=337.76, ppl=16.51, accuracy=8.127, wps=20375.5, ups=1.64, wpb=12394.8, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=1.672, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=1101
2023-08-02 18:23:18 | INFO | train_inner | epoch 002:    227 / 1474 loss=5.93, trans_loss=5.327, nll_loss=4.023, w2v_ctc_loss=3.902, task_loss=0, contrastive_loss=1.679, total=4179.21, n_correct=347.18, ppl=16.25, accuracy=8.307, wps=20663.9, ups=1.66, wpb=12484.6, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=1.486, clip=0, loss_scale=64, train_wall=60, gb_free=19, wall=1162
2023-08-02 18:24:19 | INFO | train_inner | epoch 002:    327 / 1474 loss=5.757, trans_loss=5.329, nll_loss=4.022, w2v_ctc_loss=3.8, task_loss=0, contrastive_loss=1.391, total=4146.1, n_correct=349.33, ppl=16.24, accuracy=8.426, wps=20374.4, ups=1.65, wpb=12374.1, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=1.466, clip=0, loss_scale=64, train_wall=60, gb_free=18.8, wall=1222
2023-08-02 18:25:20 | INFO | train_inner | epoch 002:    427 / 1474 loss=5.606, trans_loss=5.32, nll_loss=4.016, w2v_ctc_loss=3.698, task_loss=0, contrastive_loss=1.208, total=4037.99, n_correct=342.32, ppl=16.18, accuracy=8.477, wps=19694.7, ups=1.63, wpb=12069.2, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=1.434, clip=0, loss_scale=64, train_wall=61, gb_free=19, wall=1284
2023-08-02 18:26:21 | INFO | train_inner | epoch 002:    527 / 1474 loss=5.504, trans_loss=5.306, nll_loss=3.994, w2v_ctc_loss=3.54, task_loss=0, contrastive_loss=1.309, total=4176.97, n_correct=364.79, ppl=15.93, accuracy=8.733, wps=20345.1, ups=1.63, wpb=12463.5, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=1.354, clip=0, loss_scale=64, train_wall=61, gb_free=19.6, wall=1345
2023-08-02 18:26:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 18:27:01 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 9.296 | trans_loss 10.791 | nll_loss 9.732 | w2v_ctc_loss 4.674 | task_loss 0 | contrastive_loss 1.654 | total 4003.4 | n_correct 404.4 | ppl 850.59 | accuracy 10.101 | uer 61.33 | wer 59.211 | raw_wer 59.211 | bleu 0.05 | wps 1199.6 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.05
2023-08-02 18:27:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-02 18:27:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_2_2000.pt
2023-08-02 18:27:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_2_2000.pt
2023-08-02 18:27:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.05) (writing took 24.966102002188563 seconds)
2023-08-02 18:28:27 | INFO | train_inner | epoch 002:    627 / 1474 loss=5.363, trans_loss=5.294, nll_loss=3.978, w2v_ctc_loss=3.431, task_loss=0, contrastive_loss=1.111, total=4126.49, n_correct=368.67, ppl=15.75, accuracy=8.934, wps=9838.5, ups=0.8, wpb=12314.9, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=1.201, clip=0, loss_scale=64, train_wall=60, gb_free=19.2, wall=1470
2023-08-02 18:29:27 | INFO | train_inner | epoch 002:    727 / 1474 loss=5.295, trans_loss=5.282, nll_loss=3.967, w2v_ctc_loss=3.347, task_loss=0, contrastive_loss=1.21, total=4149.06, n_correct=373.8, ppl=15.64, accuracy=9.009, wps=20449.6, ups=1.65, wpb=12386.4, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=1.143, clip=0, loss_scale=64, train_wall=60, gb_free=19.2, wall=1531
2023-08-02 18:30:28 | INFO | train_inner | epoch 002:    827 / 1474 loss=5.206, trans_loss=5.271, nll_loss=3.955, w2v_ctc_loss=3.275, task_loss=0, contrastive_loss=1.159, total=4175.4, n_correct=383.8, ppl=15.51, accuracy=9.192, wps=20458, ups=1.64, wpb=12471.9, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=1.066, clip=0, loss_scale=128, train_wall=60, gb_free=19.8, wall=1592
2023-08-02 18:31:30 | INFO | train_inner | epoch 002:    927 / 1474 loss=5.106, trans_loss=5.255, nll_loss=3.933, w2v_ctc_loss=3.178, task_loss=0, contrastive_loss=1.142, total=4104.2, n_correct=382.24, ppl=15.27, accuracy=9.313, wps=19882.1, ups=1.62, wpb=12253.1, bsz=445.9, num_updates=2400, lr=9.6052e-05, gnorm=1.06, clip=0, loss_scale=128, train_wall=61, gb_free=19, wall=1653
2023-08-02 18:32:30 | INFO | train_inner | epoch 002:   1027 / 1474 loss=5.022, trans_loss=5.248, nll_loss=3.928, w2v_ctc_loss=3.106, task_loss=0, contrastive_loss=0.995, total=4102.5, n_correct=386.41, ppl=15.22, accuracy=9.419, wps=20287.4, ups=1.66, wpb=12251.2, bsz=456.3, num_updates=2500, lr=0.00010005, gnorm=0.917, clip=0, loss_scale=128, train_wall=60, gb_free=19.3, wall=1714
2023-08-02 18:33:31 | INFO | train_inner | epoch 002:   1127 / 1474 loss=4.985, trans_loss=5.242, nll_loss=3.918, w2v_ctc_loss=3.019, task_loss=0, contrastive_loss=1.208, total=4187.61, n_correct=400.22, ppl=15.12, accuracy=9.557, wps=20608.3, ups=1.65, wpb=12495.7, bsz=487.1, num_updates=2600, lr=0.000104048, gnorm=0.93, clip=0, loss_scale=128, train_wall=60, gb_free=19.5, wall=1774
2023-08-02 18:34:32 | INFO | train_inner | epoch 002:   1227 / 1474 loss=4.921, trans_loss=5.226, nll_loss=3.899, w2v_ctc_loss=2.973, task_loss=0, contrastive_loss=1.128, total=4221.06, n_correct=416.75, ppl=14.92, accuracy=9.873, wps=20540.8, ups=1.63, wpb=12596.1, bsz=492.8, num_updates=2700, lr=0.000108046, gnorm=0.838, clip=0, loss_scale=128, train_wall=61, gb_free=19.5, wall=1836
2023-08-02 18:35:33 | INFO | train_inner | epoch 002:   1327 / 1474 loss=4.82, trans_loss=5.216, nll_loss=3.891, w2v_ctc_loss=2.934, task_loss=0, contrastive_loss=0.839, total=4157.86, n_correct=412.06, ppl=14.84, accuracy=9.91, wps=20374.9, ups=1.64, wpb=12425.5, bsz=460.7, num_updates=2800, lr=0.000112044, gnorm=0.797, clip=0, loss_scale=128, train_wall=60, gb_free=19.5, wall=1897
2023-08-02 18:36:34 | INFO | train_inner | epoch 002:   1427 / 1474 loss=4.781, trans_loss=5.223, nll_loss=3.899, w2v_ctc_loss=2.891, task_loss=0, contrastive_loss=0.925, total=4054.34, n_correct=401.55, ppl=14.92, accuracy=9.904, wps=19878, ups=1.64, wpb=12107, bsz=438.8, num_updates=2900, lr=0.000116042, gnorm=0.76, clip=0, loss_scale=128, train_wall=60, gb_free=19.4, wall=1958
2023-08-02 18:37:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 18:37:41 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.527 | trans_loss 10.313 | nll_loss 9.143 | w2v_ctc_loss 3.742 | task_loss 0 | contrastive_loss 1.002 | total 4003.4 | n_correct 492.8 | ppl 565.3 | accuracy 12.31 | uer 52.066 | wer 50.673 | raw_wer 50.673 | bleu 0.13 | wps 1217.8 | wpb 4003.4 | bsz 141.8 | num_updates 2947 | best_bleu 0.13
2023-08-02 18:37:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2947 updates
2023-08-02 18:37:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 18:37:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 18:38:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt (epoch 2 @ 2947 updates, score 0.13) (writing took 23.43514788709581 seconds)
2023-08-02 18:38:04 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-02 18:38:04 | INFO | train | epoch 002 | loss 5.312 | trans_loss 5.277 | nll_loss 3.961 | w2v_ctc_loss 3.369 | task_loss 0 | contrastive_loss 1.213 | total 4138.65 | n_correct 376.539 | ppl 15.57 | accuracy 9.098 | wps 17639 | ups 1.43 | wpb 12355.8 | bsz 458.5 | num_updates 2947 | lr 0.000117921 | gnorm 1.149 | clip 0 | loss_scale 128 | train_wall 889 | gb_free 19.3 | wall 2048
2023-08-02 18:38:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-02 18:38:04 | INFO | fairseq.trainer | begin training epoch 3
2023-08-02 18:38:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-02 18:38:45 | INFO | train_inner | epoch 003:     53 / 1474 loss=4.705, trans_loss=5.195, nll_loss=3.864, w2v_ctc_loss=2.827, task_loss=0, contrastive_loss=0.828, total=4071.2, n_correct=420.22, ppl=14.56, accuracy=10.322, wps=9276.8, ups=0.76, wpb=12154.1, bsz=442.6, num_updates=3000, lr=0.00012004, gnorm=0.749, clip=0, loss_scale=128, train_wall=60, gb_free=19.1, wall=2089
2023-08-02 18:38:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-02 18:38:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-02 18:38:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-02 18:38:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-02 18:38:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-02 18:40:08 | INFO | train_inner | epoch 003:    158 / 1474 loss=3.926, trans_loss=4.405, nll_loss=2.831, w2v_ctc_loss=2.507, task_loss=0, contrastive_loss=0.767, total=4144.18, n_correct=1126.62, ppl=7.11, accuracy=27.186, wps=15018.8, ups=1.21, wpb=12374.6, bsz=458.6, num_updates=3100, lr=0.000124038, gnorm=2.201, clip=1, loss_scale=4, train_wall=82, gb_free=16.8, wall=2171
2023-08-02 18:41:27 | INFO | train_inner | epoch 003:    258 / 1474 loss=3.515, trans_loss=4.147, nll_loss=2.495, w2v_ctc_loss=2.278, task_loss=0, contrastive_loss=0.658, total=4161.13, n_correct=1417.86, ppl=5.64, accuracy=34.074, wps=15545.6, ups=1.25, wpb=12431.5, bsz=467, num_updates=3200, lr=0.000128036, gnorm=1.698, clip=0, loss_scale=4, train_wall=79, gb_free=17.3, wall=2251
2023-08-02 18:42:47 | INFO | train_inner | epoch 003:    358 / 1474 loss=3.391, trans_loss=4.093, nll_loss=2.42, w2v_ctc_loss=2.184, task_loss=0, contrastive_loss=0.683, total=4150.02, n_correct=1497.94, ppl=5.35, accuracy=36.095, wps=15561.4, ups=1.26, wpb=12384.9, bsz=461.6, num_updates=3300, lr=0.000132034, gnorm=1.582, clip=0, loss_scale=4, train_wall=79, gb_free=17.3, wall=2331
2023-08-02 18:44:07 | INFO | train_inner | epoch 003:    458 / 1474 loss=3.269, trans_loss=4.043, nll_loss=2.355, w2v_ctc_loss=2.099, task_loss=0, contrastive_loss=0.535, total=4209.57, n_correct=1596.5, ppl=5.12, accuracy=37.925, wps=15784.4, ups=1.26, wpb=12566, bsz=476.8, num_updates=3400, lr=0.000136032, gnorm=1.427, clip=0, loss_scale=4, train_wall=79, gb_free=16.3, wall=2410
2023-08-02 18:45:26 | INFO | train_inner | epoch 003:    558 / 1474 loss=3.166, trans_loss=4.014, nll_loss=2.318, w2v_ctc_loss=2.023, task_loss=0, contrastive_loss=0.494, total=4088.48, n_correct=1594.97, ppl=4.99, accuracy=39.011, wps=15429.3, ups=1.26, wpb=12212.5, bsz=439.7, num_updates=3500, lr=0.00014003, gnorm=1.325, clip=0, loss_scale=4, train_wall=79, gb_free=17.8, wall=2489
2023-08-02 18:46:46 | INFO | train_inner | epoch 003:    658 / 1474 loss=3.103, trans_loss=3.979, nll_loss=2.267, w2v_ctc_loss=1.942, task_loss=0, contrastive_loss=0.604, total=4221.58, n_correct=1706.43, ppl=4.81, accuracy=40.422, wps=15724.2, ups=1.25, wpb=12587.8, bsz=481.9, num_updates=3600, lr=0.000144028, gnorm=1.23, clip=0, loss_scale=4, train_wall=79, gb_free=16.6, wall=2569
2023-08-02 18:48:05 | INFO | train_inner | epoch 003:    758 / 1474 loss=3.018, trans_loss=3.946, nll_loss=2.229, w2v_ctc_loss=1.908, task_loss=0, contrastive_loss=0.372, total=4167.41, n_correct=1732.86, ppl=4.69, accuracy=41.581, wps=15679.2, ups=1.26, wpb=12447.6, bsz=472.6, num_updates=3700, lr=0.000148026, gnorm=1.133, clip=0, loss_scale=4, train_wall=79, gb_free=16.6, wall=2649
2023-08-02 18:49:24 | INFO | train_inner | epoch 003:    858 / 1474 loss=2.953, trans_loss=3.932, nll_loss=2.208, w2v_ctc_loss=1.851, task_loss=0, contrastive_loss=0.33, total=4165.53, n_correct=1762.3, ppl=4.62, accuracy=42.307, wps=15734.3, ups=1.27, wpb=12437.8, bsz=456.1, num_updates=3800, lr=0.000152024, gnorm=1.062, clip=0, loss_scale=4, train_wall=78, gb_free=17.3, wall=2728
2023-08-02 18:50:44 | INFO | train_inner | epoch 003:    958 / 1474 loss=2.917, trans_loss=3.91, nll_loss=2.179, w2v_ctc_loss=1.818, task_loss=0, contrastive_loss=0.357, total=4162.3, n_correct=1808.1, ppl=4.53, accuracy=43.44, wps=15595.3, ups=1.26, wpb=12417, bsz=469.2, num_updates=3900, lr=0.000156022, gnorm=1.074, clip=0, loss_scale=4, train_wall=79, gb_free=17, wall=2807
2023-08-02 18:52:03 | INFO | train_inner | epoch 003:   1058 / 1474 loss=2.884, trans_loss=3.891, nll_loss=2.155, w2v_ctc_loss=1.804, task_loss=0, contrastive_loss=0.314, total=4069.95, n_correct=1784.11, ppl=4.45, accuracy=43.836, wps=15361.9, ups=1.26, wpb=12153.7, bsz=443.6, num_updates=4000, lr=0.00016002, gnorm=1.067, clip=0, loss_scale=4, train_wall=79, gb_free=16.5, wall=2887
2023-08-02 18:52:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 18:52:30 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.206 | trans_loss 6.417 | nll_loss 3.966 | w2v_ctc_loss 2.154 | task_loss 0 | contrastive_loss 0.421 | total 4003.4 | n_correct 1966.8 | ppl 15.62 | accuracy 49.128 | uer 30.292 | wer 31.144 | raw_wer 31.144 | bleu 11.18 | wps 1758.4 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 11.18
2023-08-02 18:52:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-02 18:52:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_3_4000.pt
2023-08-02 18:52:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_3_4000.pt
2023-08-02 18:52:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 11.18) (writing took 24.73424954339862 seconds)
2023-08-02 18:54:13 | INFO | train_inner | epoch 003:   1158 / 1474 loss=2.844, trans_loss=3.886, nll_loss=2.147, w2v_ctc_loss=1.764, task_loss=0, contrastive_loss=0.298, total=4038.49, n_correct=1786.8, ppl=4.43, accuracy=44.244, wps=9263.2, ups=0.77, wpb=12054.8, bsz=432.5, num_updates=4100, lr=0.000164018, gnorm=1.096, clip=0, loss_scale=4, train_wall=78, gb_free=16.6, wall=3017
2023-08-02 18:55:31 | INFO | train_inner | epoch 003:   1258 / 1474 loss=2.794, trans_loss=3.863, nll_loss=2.119, w2v_ctc_loss=1.726, task_loss=0, contrastive_loss=0.274, total=4064.31, n_correct=1832.09, ppl=4.34, accuracy=45.078, wps=15614.8, ups=1.29, wpb=12136.8, bsz=433.9, num_updates=4200, lr=0.000168016, gnorm=1.03, clip=0, loss_scale=4, train_wall=77, gb_free=17.5, wall=3094
2023-08-02 18:56:51 | INFO | train_inner | epoch 003:   1358 / 1474 loss=2.777, trans_loss=3.845, nll_loss=2.096, w2v_ctc_loss=1.688, task_loss=0, contrastive_loss=0.385, total=4134.58, n_correct=1895.33, ppl=4.27, accuracy=45.841, wps=15513.5, ups=1.26, wpb=12343.8, bsz=460.7, num_updates=4300, lr=0.000172014, gnorm=0.996, clip=0, loss_scale=4, train_wall=79, gb_free=17.9, wall=3174
2023-08-02 18:58:10 | INFO | train_inner | epoch 003:   1458 / 1474 loss=2.746, trans_loss=3.832, nll_loss=2.08, w2v_ctc_loss=1.664, task_loss=0, contrastive_loss=0.364, total=4209.94, n_correct=1956.16, ppl=4.23, accuracy=46.465, wps=15801.1, ups=1.26, wpb=12573.5, bsz=477.4, num_updates=4400, lr=0.000176012, gnorm=0.948, clip=0, loss_scale=4, train_wall=79, gb_free=17.2, wall=3254
2023-08-02 18:58:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 18:58:51 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.068 | trans_loss 6.295 | nll_loss 3.803 | w2v_ctc_loss 1.989 | task_loss 0 | contrastive_loss 0.409 | total 4003.4 | n_correct 2045.5 | ppl 13.96 | accuracy 51.094 | uer 29.507 | wer 29.921 | raw_wer 29.921 | bleu 13.11 | wps 1663 | wpb 4003.4 | bsz 141.8 | num_updates 4416 | best_bleu 13.11
2023-08-02 18:58:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4416 updates
2023-08-02 18:58:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 18:59:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 18:59:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt (epoch 3 @ 4416 updates, score 13.11) (writing took 23.45840498059988 seconds)
2023-08-02 18:59:14 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-02 18:59:14 | INFO | train | epoch 003 | loss 3.148 | trans_loss 4.027 | nll_loss 2.334 | w2v_ctc_loss 1.975 | task_loss 0 | contrastive_loss 0.476 | total 4140.05 | n_correct 1635.22 | ppl 5.04 | accuracy 39.498 | wps 14293.8 | ups 1.16 | wpb 12360.1 | bsz 459 | num_updates 4416 | lr 0.000176652 | gnorm 1.253 | clip 0.1 | loss_scale 4 | train_wall 1150 | gb_free 16.6 | wall 3318
2023-08-02 18:59:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-02 18:59:15 | INFO | fairseq.trainer | begin training epoch 4
2023-08-02 18:59:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-02 19:00:28 | INFO | train_inner | epoch 004:     84 / 1474 loss=2.662, trans_loss=3.799, nll_loss=2.034, w2v_ctc_loss=1.612, task_loss=0, contrastive_loss=0.216, total=4099.41, n_correct=1937.74, ppl=4.09, accuracy=47.269, wps=8863.6, ups=0.72, wpb=12237, bsz=439.5, num_updates=4500, lr=0.00018001, gnorm=0.917, clip=0, loss_scale=4, train_wall=78, gb_free=16.5, wall=3392
2023-08-02 19:01:46 | INFO | train_inner | epoch 004:    184 / 1474 loss=2.643, trans_loss=3.779, nll_loss=2.007, w2v_ctc_loss=1.592, task_loss=0, contrastive_loss=0.245, total=4175.15, n_correct=2007.91, ppl=4.02, accuracy=48.092, wps=15959.4, ups=1.28, wpb=12464.9, bsz=468.3, num_updates=4600, lr=0.000184008, gnorm=0.901, clip=0, loss_scale=4, train_wall=78, gb_free=16.9, wall=3470
2023-08-02 19:03:06 | INFO | train_inner | epoch 004:    284 / 1474 loss=2.657, trans_loss=3.783, nll_loss=2.015, w2v_ctc_loss=1.588, task_loss=0, contrastive_loss=0.368, total=4145.23, n_correct=1988.78, ppl=4.04, accuracy=47.978, wps=15604.5, ups=1.26, wpb=12382.4, bsz=463, num_updates=4700, lr=0.000188006, gnorm=0.905, clip=0, loss_scale=4, train_wall=79, gb_free=16.2, wall=3549
2023-08-02 19:04:25 | INFO | train_inner | epoch 004:    384 / 1474 loss=2.615, trans_loss=3.783, nll_loss=2.011, w2v_ctc_loss=1.57, task_loss=0, contrastive_loss=0.212, total=4127.66, n_correct=1993.82, ppl=4.03, accuracy=48.304, wps=15594, ups=1.27, wpb=12314.6, bsz=443.5, num_updates=4800, lr=0.000192004, gnorm=0.907, clip=0, loss_scale=4, train_wall=78, gb_free=17.6, wall=3628
2023-08-02 19:05:44 | INFO | train_inner | epoch 004:    484 / 1474 loss=2.657, trans_loss=3.766, nll_loss=1.993, w2v_ctc_loss=1.542, task_loss=0, contrastive_loss=0.618, total=4218.78, n_correct=2060.93, ppl=3.98, accuracy=48.851, wps=15869.7, ups=1.26, wpb=12592.4, bsz=497.8, num_updates=4900, lr=0.000196002, gnorm=0.987, clip=0, loss_scale=4, train_wall=79, gb_free=16.7, wall=3707
2023-08-02 19:07:03 | INFO | train_inner | epoch 004:    584 / 1474 loss=2.609, trans_loss=3.759, nll_loss=1.984, w2v_ctc_loss=1.556, task_loss=0, contrastive_loss=0.289, total=4217.52, n_correct=2076.9, ppl=3.96, accuracy=49.245, wps=15891.6, ups=1.26, wpb=12591.1, bsz=485.9, num_updates=5000, lr=0.0002, gnorm=0.914, clip=0, loss_scale=4, train_wall=79, gb_free=16.3, wall=3787
mt_weight tensor(1.)
asr_weight tensor(0.4739, device='cuda:0')
2023-08-02 19:08:24 | INFO | train_inner | epoch 004:    684 / 1474 loss=2.573, trans_loss=3.762, nll_loss=1.983, w2v_ctc_loss=1.515, task_loss=0, contrastive_loss=0.33, total=4176.39, n_correct=2067.25, ppl=3.95, accuracy=49.498, wps=15452.9, ups=1.24, wpb=12448.9, bsz=455.8, num_updates=5100, lr=0.00019803, gnorm=0.594, clip=0, loss_scale=8, train_wall=80, gb_free=17.3, wall=3867
2023-08-02 19:09:44 | INFO | train_inner | epoch 004:    784 / 1474 loss=2.553, trans_loss=3.751, nll_loss=1.975, w2v_ctc_loss=1.527, task_loss=0, contrastive_loss=0.2, total=4026.63, n_correct=2001.96, ppl=3.93, accuracy=49.718, wps=15036, ups=1.25, wpb=12025, bsz=420.6, num_updates=5200, lr=0.000196116, gnorm=0.592, clip=0, loss_scale=8, train_wall=79, gb_free=13.6, wall=3947
2023-08-02 19:11:03 | INFO | train_inner | epoch 004:    884 / 1474 loss=2.578, trans_loss=3.739, nll_loss=1.96, w2v_ctc_loss=1.522, task_loss=0, contrastive_loss=0.381, total=4186.04, n_correct=2093.46, ppl=3.89, accuracy=50.011, wps=15783.4, ups=1.26, wpb=12501.4, bsz=466.3, num_updates=5300, lr=0.000194257, gnorm=0.597, clip=0, loss_scale=8, train_wall=78, gb_free=17.8, wall=4026
2023-08-02 19:12:22 | INFO | train_inner | epoch 004:    984 / 1474 loss=2.539, trans_loss=3.73, nll_loss=1.949, w2v_ctc_loss=1.505, task_loss=0, contrastive_loss=0.252, total=4125.02, n_correct=2083.72, ppl=3.86, accuracy=50.514, wps=15539.4, ups=1.26, wpb=12321, bsz=457.1, num_updates=5400, lr=0.00019245, gnorm=0.598, clip=0, loss_scale=8, train_wall=79, gb_free=13.1, wall=4106
2023-08-02 19:13:42 | INFO | train_inner | epoch 004:   1084 / 1474 loss=2.533, trans_loss=3.737, nll_loss=1.956, w2v_ctc_loss=1.506, task_loss=0, contrastive_loss=0.223, total=4075.6, n_correct=2057.94, ppl=3.88, accuracy=50.494, wps=15295.8, ups=1.26, wpb=12163.4, bsz=435.7, num_updates=5500, lr=0.000190693, gnorm=0.583, clip=0, loss_scale=8, train_wall=79, gb_free=16.3, wall=4185
2023-08-02 19:15:01 | INFO | train_inner | epoch 004:   1184 / 1474 loss=2.543, trans_loss=3.725, nll_loss=1.944, w2v_ctc_loss=1.498, task_loss=0, contrastive_loss=0.339, total=4161.18, n_correct=2115.15, ppl=3.85, accuracy=50.831, wps=15610, ups=1.26, wpb=12431.8, bsz=483.4, num_updates=5600, lr=0.000188982, gnorm=0.586, clip=0, loss_scale=8, train_wall=79, gb_free=17, wall=4265
2023-08-02 19:16:20 | INFO | train_inner | epoch 004:   1284 / 1474 loss=2.51, trans_loss=3.713, nll_loss=1.928, w2v_ctc_loss=1.473, task_loss=0, contrastive_loss=0.297, total=4156.53, n_correct=2138.51, ppl=3.81, accuracy=51.449, wps=15838.8, ups=1.28, wpb=12411.4, bsz=472.7, num_updates=5700, lr=0.000187317, gnorm=0.563, clip=0, loss_scale=8, train_wall=78, gb_free=16.1, wall=4343
2023-08-02 19:17:38 | INFO | train_inner | epoch 004:   1384 / 1474 loss=2.478, trans_loss=3.713, nll_loss=1.927, w2v_ctc_loss=1.466, task_loss=0, contrastive_loss=0.175, total=4101.23, n_correct=2109.84, ppl=3.8, accuracy=51.444, wps=15740.6, ups=1.29, wpb=12249, bsz=437.6, num_updates=5800, lr=0.000185695, gnorm=0.548, clip=0, loss_scale=8, train_wall=77, gb_free=15.9, wall=4421
2023-08-02 19:18:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.4739, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.4739, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.4739, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.4739, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.4739, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.4739, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.4739, device='cuda:3')
2023-08-02 19:19:14 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.708 | trans_loss 5.948 | nll_loss 3.338 | w2v_ctc_loss 1.657 | task_loss 0 | contrastive_loss 0.318 | total 4003.4 | n_correct 2242.3 | ppl 10.11 | accuracy 56.01 | uer 24.145 | wer 25.529 | raw_wer 25.529 | bleu 16.12 | wps 1929.6 | wpb 4003.4 | bsz 141.8 | num_updates 5890 | best_bleu 16.12
2023-08-02 19:19:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5890 updates
2023-08-02 19:19:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 19:19:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 19:19:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt (epoch 4 @ 5890 updates, score 16.12) (writing took 24.919609082862735 seconds)
2023-08-02 19:19:39 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-02 19:19:39 | INFO | train | epoch 004 | loss 2.574 | trans_loss 3.749 | nll_loss 1.972 | w2v_ctc_loss 1.527 | task_loss 0 | contrastive_loss 0.295 | total 4138.65 | n_correct 2057.09 | ppl 3.92 | accuracy 49.704 | wps 14876.5 | ups 1.2 | wpb 12355.8 | bsz 458.5 | num_updates 5890 | lr 0.000184271 | gnorm 0.716 | clip 0 | loss_scale 8 | train_wall 1156 | gb_free 15.1 | wall 4542
2023-08-02 19:19:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-02 19:19:39 | INFO | fairseq.trainer | begin training epoch 5
2023-08-02 19:19:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-02 19:19:54 | INFO | train_inner | epoch 005:     10 / 1474 loss=2.461, trans_loss=3.704, nll_loss=1.916, w2v_ctc_loss=1.44, task_loss=0, contrastive_loss=0.197, total=4037.7, n_correct=2090.18, ppl=3.77, accuracy=51.767, wps=8811.5, ups=0.73, wpb=12055.9, bsz=439.3, num_updates=5900, lr=0.000184115, gnorm=0.557, clip=0, loss_scale=8, train_wall=78, gb_free=17, wall=4558
2023-08-02 19:21:14 | INFO | train_inner | epoch 005:    110 / 1474 loss=2.393, trans_loss=3.645, nll_loss=1.839, w2v_ctc_loss=1.369, task_loss=0, contrastive_loss=0.206, total=4247.37, n_correct=2271.3, ppl=3.58, accuracy=53.475, wps=15960.8, ups=1.26, wpb=12683.4, bsz=495.1, num_updates=6000, lr=0.000182574, gnorm=0.547, clip=0, loss_scale=8, train_wall=79, gb_free=16.9, wall=4637
2023-08-02 19:21:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 19:21:38 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.698 | trans_loss 5.94 | nll_loss 3.323 | w2v_ctc_loss 1.64 | task_loss 0 | contrastive_loss 0.327 | total 4003.4 | n_correct 2247.7 | ppl 10.01 | accuracy 56.145 | uer 23.662 | wer 25.197 | raw_wer 25.197 | bleu 16.15 | wps 2084.5 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 16.15
2023-08-02 19:21:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-08-02 19:21:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_5_6000.pt
2023-08-02 19:21:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_5_6000.pt
2023-08-02 19:22:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 16.15) (writing took 25.49102173373103 seconds)
2023-08-02 19:23:21 | INFO | train_inner | epoch 005:    210 / 1474 loss=2.438, trans_loss=3.66, nll_loss=1.855, w2v_ctc_loss=1.389, task_loss=0, contrastive_loss=0.43, total=4189.85, n_correct=2225.93, ppl=3.62, accuracy=53.127, wps=9806.2, ups=0.78, wpb=12500.5, bsz=488.2, num_updates=6100, lr=0.000181071, gnorm=0.565, clip=0, loss_scale=8, train_wall=78, gb_free=17.9, wall=4765
2023-08-02 19:24:39 | INFO | train_inner | epoch 005:    310 / 1474 loss=2.412, trans_loss=3.653, nll_loss=1.851, w2v_ctc_loss=1.395, task_loss=0, contrastive_loss=0.265, total=4090.1, n_correct=2165.51, ppl=3.61, accuracy=52.945, wps=15732.8, ups=1.29, wpb=12228.1, bsz=443.9, num_updates=6200, lr=0.000179605, gnorm=0.542, clip=0, loss_scale=8, train_wall=77, gb_free=16.4, wall=4843
2023-08-02 19:25:58 | INFO | train_inner | epoch 005:    410 / 1474 loss=2.403, trans_loss=3.644, nll_loss=1.841, w2v_ctc_loss=1.36, task_loss=0, contrastive_loss=0.357, total=4147.17, n_correct=2222.54, ppl=3.58, accuracy=53.592, wps=15629.4, ups=1.26, wpb=12395.1, bsz=472.5, num_updates=6300, lr=0.000178174, gnorm=0.537, clip=0, loss_scale=8, train_wall=79, gb_free=15.1, wall=4922
2023-08-02 19:27:18 | INFO | train_inner | epoch 005:    510 / 1474 loss=2.372, trans_loss=3.654, nll_loss=1.85, w2v_ctc_loss=1.369, task_loss=0, contrastive_loss=0.149, total=4026.81, n_correct=2146.26, ppl=3.61, accuracy=53.299, wps=15185.8, ups=1.26, wpb=12029.7, bsz=416.6, num_updates=6400, lr=0.000176777, gnorm=0.531, clip=0, loss_scale=8, train_wall=79, gb_free=17.5, wall=5001
2023-08-02 19:28:37 | INFO | train_inner | epoch 005:    610 / 1474 loss=2.393, trans_loss=3.658, nll_loss=1.854, w2v_ctc_loss=1.357, task_loss=0, contrastive_loss=0.321, total=4107.75, n_correct=2191.73, ppl=3.62, accuracy=53.356, wps=15506.6, ups=1.27, wpb=12253.8, bsz=451.2, num_updates=6500, lr=0.000175412, gnorm=0.542, clip=0, loss_scale=8, train_wall=78, gb_free=16.4, wall=5080
2023-08-02 19:29:56 | INFO | train_inner | epoch 005:    710 / 1474 loss=2.395, trans_loss=3.653, nll_loss=1.849, w2v_ctc_loss=1.36, task_loss=0, contrastive_loss=0.301, total=4178.85, n_correct=2243.49, ppl=3.6, accuracy=53.687, wps=15736.8, ups=1.26, wpb=12473.1, bsz=480.9, num_updates=6600, lr=0.000174078, gnorm=0.542, clip=0, loss_scale=8, train_wall=79, gb_free=17.8, wall=5159
2023-08-02 19:31:15 | INFO | train_inner | epoch 005:    810 / 1474 loss=2.376, trans_loss=3.652, nll_loss=1.848, w2v_ctc_loss=1.354, task_loss=0, contrastive_loss=0.225, total=4127.73, n_correct=2215.79, ppl=3.6, accuracy=53.681, wps=15525, ups=1.26, wpb=12320.4, bsz=449.2, num_updates=6700, lr=0.000172774, gnorm=0.539, clip=0, loss_scale=8, train_wall=79, gb_free=15.4, wall=5239
2023-08-02 19:32:35 | INFO | train_inner | epoch 005:    910 / 1474 loss=2.348, trans_loss=3.641, nll_loss=1.835, w2v_ctc_loss=1.339, task_loss=0, contrastive_loss=0.185, total=4095.48, n_correct=2215.29, ppl=3.57, accuracy=54.091, wps=15400.5, ups=1.26, wpb=12229.5, bsz=445.3, num_updates=6800, lr=0.000171499, gnorm=0.523, clip=0, loss_scale=8, train_wall=79, gb_free=15.8, wall=5318
2023-08-02 19:33:53 | INFO | train_inner | epoch 005:   1010 / 1474 loss=2.359, trans_loss=3.644, nll_loss=1.838, w2v_ctc_loss=1.339, task_loss=0, contrastive_loss=0.267, total=4165.12, n_correct=2249.49, ppl=3.58, accuracy=54.008, wps=15791.5, ups=1.27, wpb=12433.6, bsz=463.5, num_updates=6900, lr=0.000170251, gnorm=0.523, clip=0, loss_scale=8, train_wall=78, gb_free=15.9, wall=5397
2023-08-02 19:35:13 | INFO | train_inner | epoch 005:   1110 / 1474 loss=2.374, trans_loss=3.644, nll_loss=1.838, w2v_ctc_loss=1.348, task_loss=0, contrastive_loss=0.271, total=4176.72, n_correct=2261.37, ppl=3.57, accuracy=54.142, wps=15628.6, ups=1.25, wpb=12459.2, bsz=466.1, num_updates=7000, lr=0.000169031, gnorm=0.52, clip=0, loss_scale=8, train_wall=79, gb_free=16.9, wall=5477
2023-08-02 19:36:32 | INFO | train_inner | epoch 005:   1210 / 1474 loss=2.332, trans_loss=3.64, nll_loss=1.832, w2v_ctc_loss=1.321, task_loss=0, contrastive_loss=0.173, total=4164.13, n_correct=2264.24, ppl=3.56, accuracy=54.375, wps=15683.2, ups=1.26, wpb=12420.9, bsz=453.8, num_updates=7100, lr=0.000167836, gnorm=0.521, clip=0, loss_scale=16, train_wall=79, gb_free=17.2, wall=5556
2023-08-02 19:37:52 | INFO | train_inner | epoch 005:   1310 / 1474 loss=2.319, trans_loss=3.64, nll_loss=1.833, w2v_ctc_loss=1.311, task_loss=0, contrastive_loss=0.14, total=4134.91, n_correct=2246.12, ppl=3.56, accuracy=54.321, wps=15531.5, ups=1.26, wpb=12341.4, bsz=445.6, num_updates=7200, lr=0.000166667, gnorm=0.513, clip=0, loss_scale=16, train_wall=79, gb_free=16.5, wall=5635
2023-08-02 19:39:11 | INFO | train_inner | epoch 005:   1410 / 1474 loss=2.328, trans_loss=3.638, nll_loss=1.833, w2v_ctc_loss=1.308, task_loss=0, contrastive_loss=0.206, total=4134.37, n_correct=2253.65, ppl=3.56, accuracy=54.51, wps=15622.1, ups=1.27, wpb=12347.5, bsz=458.5, num_updates=7300, lr=0.000165521, gnorm=0.519, clip=0, loss_scale=16, train_wall=78, gb_free=17.9, wall=5714
2023-08-02 19:40:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 19:40:24 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.593 | trans_loss 5.855 | nll_loss 3.219 | w2v_ctc_loss 1.483 | task_loss 0 | contrastive_loss 0.329 | total 4003.4 | n_correct 2293.7 | ppl 9.31 | accuracy 57.294 | uer 22.252 | wer 23.989 | raw_wer 23.989 | bleu 16.99 | wps 2108 | wpb 4003.4 | bsz 141.8 | num_updates 7364 | best_bleu 16.99
2023-08-02 19:40:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7364 updates
2023-08-02 19:40:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 19:40:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 19:40:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt (epoch 5 @ 7364 updates, score 16.99) (writing took 24.474140338599682 seconds)
2023-08-02 19:40:49 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-02 19:40:49 | INFO | train | epoch 005 | loss 2.373 | trans_loss 3.647 | nll_loss 1.842 | w2v_ctc_loss 1.351 | task_loss 0 | contrastive_loss 0.25 | total 4138.65 | n_correct 2225.9 | ppl 3.58 | accuracy 53.783 | wps 14341.1 | ups 1.16 | wpb 12355.8 | bsz 458.5 | num_updates 7364 | lr 0.0001648 | gnorm 0.534 | clip 0 | loss_scale 16 | train_wall 1156 | gb_free 16.5 | wall 5812
2023-08-02 19:40:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-02 19:40:49 | INFO | fairseq.trainer | begin training epoch 6
2023-08-02 19:40:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-02 19:41:25 | INFO | train_inner | epoch 006:     36 / 1474 loss=2.312, trans_loss=3.615, nll_loss=1.801, w2v_ctc_loss=1.302, task_loss=0, contrastive_loss=0.203, total=4115.45, n_correct=2263.97, ppl=3.48, accuracy=55.011, wps=9146.8, ups=0.74, wpb=12281.2, bsz=447.9, num_updates=7400, lr=0.000164399, gnorm=0.528, clip=0, loss_scale=16, train_wall=79, gb_free=16.6, wall=5849
2023-08-02 19:42:44 | INFO | train_inner | epoch 006:    136 / 1474 loss=2.269, trans_loss=3.581, nll_loss=1.758, w2v_ctc_loss=1.254, task_loss=0, contrastive_loss=0.246, total=4154.25, n_correct=2313.58, ppl=3.38, accuracy=55.692, wps=15725.6, ups=1.27, wpb=12407.4, bsz=456.1, num_updates=7500, lr=0.000163299, gnorm=0.512, clip=0, loss_scale=16, train_wall=78, gb_free=15.8, wall=5928
2023-08-02 19:44:03 | INFO | train_inner | epoch 006:    236 / 1474 loss=2.276, trans_loss=3.591, nll_loss=1.772, w2v_ctc_loss=1.282, task_loss=0, contrastive_loss=0.152, total=4112.66, n_correct=2279.98, ppl=3.42, accuracy=55.438, wps=15585.9, ups=1.27, wpb=12287.2, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.51, clip=0, loss_scale=16, train_wall=78, gb_free=16.4, wall=6006
2023-08-02 19:45:23 | INFO | train_inner | epoch 006:    336 / 1474 loss=2.29, trans_loss=3.578, nll_loss=1.755, w2v_ctc_loss=1.232, task_loss=0, contrastive_loss=0.46, total=4177.51, n_correct=2343.19, ppl=3.38, accuracy=56.091, wps=15526.2, ups=1.24, wpb=12473.8, bsz=491.3, num_updates=7700, lr=0.000161165, gnorm=0.515, clip=0, loss_scale=16, train_wall=80, gb_free=16.3, wall=6087
2023-08-02 19:46:42 | INFO | train_inner | epoch 006:    436 / 1474 loss=2.25, trans_loss=3.583, nll_loss=1.762, w2v_ctc_loss=1.242, task_loss=0, contrastive_loss=0.169, total=4154.57, n_correct=2327.48, ppl=3.39, accuracy=56.022, wps=15829.1, ups=1.28, wpb=12405.5, bsz=470.2, num_updates=7800, lr=0.000160128, gnorm=0.511, clip=0, loss_scale=16, train_wall=78, gb_free=16.3, wall=6165
2023-08-02 19:48:00 | INFO | train_inner | epoch 006:    536 / 1474 loss=2.256, trans_loss=3.591, nll_loss=1.771, w2v_ctc_loss=1.256, task_loss=0, contrastive_loss=0.155, total=4167.79, n_correct=2332.89, ppl=3.41, accuracy=55.974, wps=15826.7, ups=1.27, wpb=12438.5, bsz=455.2, num_updates=7900, lr=0.000159111, gnorm=0.513, clip=0, loss_scale=16, train_wall=78, gb_free=16, wall=6244
2023-08-02 19:49:19 | INFO | train_inner | epoch 006:    636 / 1474 loss=2.255, trans_loss=3.592, nll_loss=1.772, w2v_ctc_loss=1.236, task_loss=0, contrastive_loss=0.212, total=4146.17, n_correct=2319.07, ppl=3.42, accuracy=55.933, wps=15633.6, ups=1.26, wpb=12376.6, bsz=471.6, num_updates=8000, lr=0.000158114, gnorm=0.51, clip=0, loss_scale=16, train_wall=78, gb_free=16.5, wall=6323
2023-08-02 19:49:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 19:49:42 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.562 | trans_loss 5.805 | nll_loss 3.146 | w2v_ctc_loss 1.517 | task_loss 0 | contrastive_loss 0.305 | total 4003.4 | n_correct 2323 | ppl 8.85 | accuracy 58.026 | uer 21.275 | wer 23.038 | raw_wer 23.038 | bleu 17.62 | wps 2365.5 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 17.62
2023-08-02 19:49:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-08-02 19:49:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_6_8000.pt
2023-08-02 19:49:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_6_8000.pt
2023-08-02 19:50:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 17.62) (writing took 24.13105946406722 seconds)
2023-08-02 19:51:25 | INFO | train_inner | epoch 006:    736 / 1474 loss=2.258, trans_loss=3.595, nll_loss=1.777, w2v_ctc_loss=1.254, task_loss=0, contrastive_loss=0.169, total=4148.65, n_correct=2317.12, ppl=3.43, accuracy=55.852, wps=9866.2, ups=0.8, wpb=12388, bsz=453.7, num_updates=8100, lr=0.000157135, gnorm=0.509, clip=0, loss_scale=16, train_wall=79, gb_free=15.8, wall=6448
2023-08-02 19:52:44 | INFO | train_inner | epoch 006:    836 / 1474 loss=2.25, trans_loss=3.601, nll_loss=1.784, w2v_ctc_loss=1.245, task_loss=0, contrastive_loss=0.148, total=4114.34, n_correct=2294.72, ppl=3.44, accuracy=55.774, wps=15614.7, ups=1.27, wpb=12282.2, bsz=441.6, num_updates=8200, lr=0.000156174, gnorm=0.51, clip=0, loss_scale=16, train_wall=78, gb_free=15.3, wall=6527
2023-08-02 19:54:03 | INFO | train_inner | epoch 006:    936 / 1474 loss=2.267, trans_loss=3.601, nll_loss=1.784, w2v_ctc_loss=1.246, task_loss=0, contrastive_loss=0.245, total=4081.53, n_correct=2276.45, ppl=3.44, accuracy=55.774, wps=15424.5, ups=1.27, wpb=12181.3, bsz=444.5, num_updates=8300, lr=0.00015523, gnorm=0.511, clip=0, loss_scale=16, train_wall=78, gb_free=17.9, wall=6606
2023-08-02 19:55:22 | INFO | train_inner | epoch 006:   1036 / 1474 loss=2.257, trans_loss=3.586, nll_loss=1.767, w2v_ctc_loss=1.226, task_loss=0, contrastive_loss=0.321, total=4165.84, n_correct=2342.66, ppl=3.4, accuracy=56.235, wps=15693.4, ups=1.26, wpb=12435.7, bsz=477.2, num_updates=8400, lr=0.000154303, gnorm=0.511, clip=0, loss_scale=16, train_wall=79, gb_free=17, wall=6685
2023-08-02 19:56:40 | INFO | train_inner | epoch 006:   1136 / 1474 loss=2.245, trans_loss=3.593, nll_loss=1.775, w2v_ctc_loss=1.243, task_loss=0, contrastive_loss=0.15, total=4072.29, n_correct=2277.55, ppl=3.42, accuracy=55.928, wps=15462.9, ups=1.27, wpb=12157.6, bsz=428, num_updates=8500, lr=0.000153393, gnorm=0.515, clip=0, loss_scale=16, train_wall=78, gb_free=17.2, wall=6764
2023-08-02 19:57:59 | INFO | train_inner | epoch 006:   1236 / 1474 loss=2.275, trans_loss=3.582, nll_loss=1.764, w2v_ctc_loss=1.224, task_loss=0, contrastive_loss=0.466, total=4141.55, n_correct=2330.27, ppl=3.4, accuracy=56.266, wps=15667.6, ups=1.27, wpb=12370.9, bsz=474.8, num_updates=8600, lr=0.000152499, gnorm=0.511, clip=0, loss_scale=16, train_wall=78, gb_free=13.6, wall=6843
2023-08-02 19:59:18 | INFO | train_inner | epoch 006:   1336 / 1474 loss=2.222, trans_loss=3.59, nll_loss=1.769, w2v_ctc_loss=1.221, task_loss=0, contrastive_loss=0.135, total=4125.31, n_correct=2325.7, ppl=3.41, accuracy=56.376, wps=15706.9, ups=1.28, wpb=12305, bsz=452.6, num_updates=8700, lr=0.00015162, gnorm=0.502, clip=0, loss_scale=16, train_wall=78, gb_free=17.9, wall=6921
2023-08-02 20:00:37 | INFO | train_inner | epoch 006:   1436 / 1474 loss=2.224, trans_loss=3.583, nll_loss=1.763, w2v_ctc_loss=1.223, task_loss=0, contrastive_loss=0.143, total=4196.2, n_correct=2369.77, ppl=3.39, accuracy=56.474, wps=15770.5, ups=1.26, wpb=12525.2, bsz=461.5, num_updates=8800, lr=0.000150756, gnorm=0.496, clip=0, loss_scale=16, train_wall=79, gb_free=11.9, wall=7001
2023-08-02 20:01:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 20:01:29 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.511 | trans_loss 5.763 | nll_loss 3.101 | w2v_ctc_loss 1.451 | task_loss 0 | contrastive_loss 0.291 | total 4003.4 | n_correct 2350.7 | ppl 8.58 | accuracy 58.718 | uer 20.187 | wer 21.886 | raw_wer 21.886 | bleu 18.02 | wps 2316.2 | wpb 4003.4 | bsz 141.8 | num_updates 8838 | best_bleu 18.02
2023-08-02 20:01:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8838 updates
2023-08-02 20:01:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 20:01:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 20:01:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt (epoch 6 @ 8838 updates, score 18.02) (writing took 23.443669179454446 seconds)
2023-08-02 20:01:52 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-02 20:01:52 | INFO | train | epoch 006 | loss 2.255 | trans_loss 3.589 | nll_loss 1.769 | w2v_ctc_loss 1.241 | task_loss 0 | contrastive_loss 0.226 | total 4138.65 | n_correct 2317.89 | ppl 3.41 | accuracy 56.006 | wps 14412.5 | ups 1.17 | wpb 12355.8 | bsz 458.5 | num_updates 8838 | lr 0.000150431 | gnorm 0.509 | clip 0 | loss_scale 16 | train_wall 1154 | gb_free 15.4 | wall 7076
2023-08-02 20:01:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-02 20:01:53 | INFO | fairseq.trainer | begin training epoch 7
2023-08-02 20:01:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-02 20:02:50 | INFO | train_inner | epoch 007:     62 / 1474 loss=2.191, trans_loss=3.557, nll_loss=1.73, w2v_ctc_loss=1.191, task_loss=0, contrastive_loss=0.159, total=4108.19, n_correct=2346.53, ppl=3.32, accuracy=57.118, wps=9256.8, ups=0.75, wpb=12266.6, bsz=461.9, num_updates=8900, lr=0.000149906, gnorm=0.504, clip=0, loss_scale=16, train_wall=78, gb_free=17.3, wall=7133
2023-08-02 20:04:08 | INFO | train_inner | epoch 007:    162 / 1474 loss=2.188, trans_loss=3.547, nll_loss=1.716, w2v_ctc_loss=1.175, task_loss=0, contrastive_loss=0.232, total=4106.05, n_correct=2355.55, ppl=3.28, accuracy=57.368, wps=15654.8, ups=1.28, wpb=12258.7, bsz=455.4, num_updates=9000, lr=0.000149071, gnorm=0.508, clip=0, loss_scale=16, train_wall=78, gb_free=16.9, wall=7211
2023-08-02 20:05:27 | INFO | train_inner | epoch 007:    262 / 1474 loss=2.173, trans_loss=3.543, nll_loss=1.708, w2v_ctc_loss=1.18, task_loss=0, contrastive_loss=0.136, total=4129.3, n_correct=2379.36, ppl=3.27, accuracy=57.621, wps=15619.3, ups=1.27, wpb=12322.8, bsz=451.8, num_updates=9100, lr=0.00014825, gnorm=0.503, clip=0, loss_scale=16, train_wall=78, gb_free=17.4, wall=7290
2023-08-02 20:06:46 | INFO | train_inner | epoch 007:    362 / 1474 loss=2.21, trans_loss=3.551, nll_loss=1.72, w2v_ctc_loss=1.17, task_loss=0, contrastive_loss=0.401, total=4201.67, n_correct=2407.33, ppl=3.3, accuracy=57.295, wps=15821.2, ups=1.26, wpb=12539.8, bsz=479.7, num_updates=9200, lr=0.000147442, gnorm=0.5, clip=0, loss_scale=32, train_wall=79, gb_free=15.6, wall=7370
2023-08-02 20:08:05 | INFO | train_inner | epoch 007:    462 / 1474 loss=2.197, trans_loss=3.551, nll_loss=1.723, w2v_ctc_loss=1.167, task_loss=0, contrastive_loss=0.324, total=4155.31, n_correct=2377.74, ppl=3.3, accuracy=57.222, wps=15730.7, ups=1.27, wpb=12410.9, bsz=465.5, num_updates=9300, lr=0.000146647, gnorm=0.504, clip=0, loss_scale=32, train_wall=78, gb_free=16.9, wall=7449
2023-08-02 20:09:23 | INFO | train_inner | epoch 007:    562 / 1474 loss=2.174, trans_loss=3.553, nll_loss=1.721, w2v_ctc_loss=1.171, task_loss=0, contrastive_loss=0.149, total=4165.88, n_correct=2390.64, ppl=3.3, accuracy=57.386, wps=15979.8, ups=1.29, wpb=12426.4, bsz=459, num_updates=9400, lr=0.000145865, gnorm=0.502, clip=0, loss_scale=32, train_wall=77, gb_free=17.4, wall=7526
2023-08-02 20:10:42 | INFO | train_inner | epoch 007:    662 / 1474 loss=2.162, trans_loss=3.551, nll_loss=1.72, w2v_ctc_loss=1.164, task_loss=0, contrastive_loss=0.131, total=4149.29, n_correct=2389.42, ppl=3.29, accuracy=57.586, wps=15663, ups=1.27, wpb=12381.3, bsz=451.6, num_updates=9500, lr=0.000145095, gnorm=0.501, clip=0, loss_scale=32, train_wall=78, gb_free=17.3, wall=7605
2023-08-02 20:12:01 | INFO | train_inner | epoch 007:    762 / 1474 loss=2.164, trans_loss=3.545, nll_loss=1.714, w2v_ctc_loss=1.167, task_loss=0, contrastive_loss=0.132, total=4134.54, n_correct=2381.85, ppl=3.28, accuracy=57.609, wps=15554.4, ups=1.26, wpb=12345.4, bsz=449.8, num_updates=9600, lr=0.000144338, gnorm=0.499, clip=0, loss_scale=32, train_wall=79, gb_free=14.1, wall=7685
2023-08-02 20:13:20 | INFO | train_inner | epoch 007:    862 / 1474 loss=2.168, trans_loss=3.555, nll_loss=1.726, w2v_ctc_loss=1.166, task_loss=0, contrastive_loss=0.153, total=4151.77, n_correct=2384.81, ppl=3.31, accuracy=57.441, wps=15677.9, ups=1.27, wpb=12391.6, bsz=461.9, num_updates=9700, lr=0.000143592, gnorm=0.504, clip=0, loss_scale=32, train_wall=78, gb_free=15.1, wall=7764
2023-08-02 20:14:39 | INFO | train_inner | epoch 007:    962 / 1474 loss=2.176, trans_loss=3.55, nll_loss=1.721, w2v_ctc_loss=1.155, task_loss=0, contrastive_loss=0.247, total=4124.8, n_correct=2375.6, ppl=3.3, accuracy=57.593, wps=15594.9, ups=1.27, wpb=12313.3, bsz=471.2, num_updates=9800, lr=0.000142857, gnorm=0.503, clip=0, loss_scale=32, train_wall=78, gb_free=16.8, wall=7843
2023-08-02 20:15:58 | INFO | train_inner | epoch 007:   1062 / 1474 loss=2.162, trans_loss=3.56, nll_loss=1.734, w2v_ctc_loss=1.166, task_loss=0, contrastive_loss=0.115, total=4113.08, n_correct=2359.12, ppl=3.33, accuracy=57.357, wps=15512.1, ups=1.26, wpb=12279.6, bsz=439.4, num_updates=9900, lr=0.000142134, gnorm=0.501, clip=0, loss_scale=32, train_wall=79, gb_free=15, wall=7922
2023-08-02 20:17:18 | INFO | train_inner | epoch 007:   1162 / 1474 loss=2.198, trans_loss=3.546, nll_loss=1.72, w2v_ctc_loss=1.155, task_loss=0, contrastive_loss=0.379, total=4134.15, n_correct=2382.87, ppl=3.29, accuracy=57.639, wps=15574.6, ups=1.26, wpb=12353.7, bsz=470.3, num_updates=10000, lr=0.000141421, gnorm=0.504, clip=0, loss_scale=32, train_wall=79, gb_free=16.3, wall=8001
2023-08-02 20:17:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 20:17:39 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.471 | trans_loss 5.72 | nll_loss 3.045 | w2v_ctc_loss 1.421 | task_loss 0 | contrastive_loss 0.288 | total 4003.4 | n_correct 2370 | ppl 8.25 | accuracy 59.2 | uer 19.197 | wer 20.842 | raw_wer 20.842 | bleu 18.47 | wps 2462.8 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 18.47
2023-08-02 20:17:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-08-02 20:17:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_7_10000.pt
2023-08-02 20:17:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_7_10000.pt
2023-08-02 20:18:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 18.47) (writing took 24.27530441991985 seconds)
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:0')
2023-08-02 20:19:23 | INFO | train_inner | epoch 007:   1262 / 1474 loss=2.152, trans_loss=3.552, nll_loss=1.726, w2v_ctc_loss=1.15, task_loss=0, contrastive_loss=0.143, total=4133.98, n_correct=2379.43, ppl=3.31, accuracy=57.558, wps=9873, ups=0.8, wpb=12343.8, bsz=450.9, num_updates=10100, lr=0.00014072, gnorm=0.415, clip=0, loss_scale=32, train_wall=78, gb_free=16.9, wall=8126
2023-08-02 20:20:41 | INFO | train_inner | epoch 007:   1362 / 1474 loss=2.17, trans_loss=3.547, nll_loss=1.718, w2v_ctc_loss=1.165, task_loss=0, contrastive_loss=0.18, total=4171.46, n_correct=2413.1, ppl=3.29, accuracy=57.848, wps=15993.9, ups=1.28, wpb=12453.1, bsz=475.5, num_updates=10200, lr=0.000140028, gnorm=0.419, clip=0, loss_scale=32, train_wall=77, gb_free=17.8, wall=8204
2023-08-02 20:22:01 | INFO | train_inner | epoch 007:   1462 / 1474 loss=2.174, trans_loss=3.552, nll_loss=1.727, w2v_ctc_loss=1.159, task_loss=0, contrastive_loss=0.243, total=4106.94, n_correct=2361.09, ppl=3.31, accuracy=57.49, wps=15230, ups=1.24, wpb=12271.2, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.423, clip=0, loss_scale=32, train_wall=80, gb_free=15.9, wall=8285
2023-08-02 20:22:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:1')
2023-08-02 20:22:34 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.473 | trans_loss 5.721 | nll_loss 3.047 | w2v_ctc_loss 1.426 | task_loss 0 | contrastive_loss 0.283 | total 4003.4 | n_correct 2374.7 | ppl 8.26 | accuracy 59.317 | uer 20.054 | wer 21.703 | raw_wer 21.703 | bleu 18.53 | wps 2091 | wpb 4003.4 | bsz 141.8 | num_updates 10312 | best_bleu 18.53
2023-08-02 20:22:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10312 updates
2023-08-02 20:22:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 20:22:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 20:22:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt (epoch 7 @ 10312 updates, score 18.53) (writing took 24.219363164156675 seconds)
2023-08-02 20:22:59 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-02 20:22:59 | INFO | train | epoch 007 | loss 2.176 | trans_loss 3.55 | nll_loss 1.72 | w2v_ctc_loss 1.166 | task_loss 0 | contrastive_loss 0.21 | total 4138.65 | n_correct 2379.78 | ppl 3.3 | accuracy 57.501 | wps 14375.6 | ups 1.16 | wpb 12355.8 | bsz 458.5 | num_updates 10312 | lr 0.000139266 | gnorm 0.485 | clip 0 | loss_scale 32 | train_wall 1155 | gb_free 13.5 | wall 8343
2023-08-02 20:23:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-02 20:23:00 | INFO | fairseq.trainer | begin training epoch 8
2023-08-02 20:23:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-02 20:24:16 | INFO | train_inner | epoch 008:     88 / 1474 loss=2.121, trans_loss=3.526, nll_loss=1.686, w2v_ctc_loss=1.123, task_loss=0, contrastive_loss=0.139, total=4120.74, n_correct=2407.83, ppl=3.22, accuracy=58.432, wps=9096, ups=0.74, wpb=12287.4, bsz=444.5, num_updates=10400, lr=0.000138675, gnorm=0.417, clip=0, loss_scale=32, train_wall=78, gb_free=17.4, wall=8420
2023-08-02 20:25:34 | INFO | train_inner | epoch 008:    188 / 1474 loss=2.119, trans_loss=3.519, nll_loss=1.676, w2v_ctc_loss=1.117, task_loss=0, contrastive_loss=0.158, total=4028.45, n_correct=2356.03, ppl=3.2, accuracy=58.485, wps=15420.5, ups=1.28, wpb=12015, bsz=426.7, num_updates=10500, lr=0.000138013, gnorm=0.423, clip=0, loss_scale=32, train_wall=77, gb_free=16.6, wall=8498
2023-08-02 20:26:53 | INFO | train_inner | epoch 008:    288 / 1474 loss=2.12, trans_loss=3.513, nll_loss=1.673, w2v_ctc_loss=1.118, task_loss=0, contrastive_loss=0.16, total=4212.3, n_correct=2474.38, ppl=3.19, accuracy=58.742, wps=16033.5, ups=1.28, wpb=12569, bsz=489.5, num_updates=10600, lr=0.000137361, gnorm=0.418, clip=0, loss_scale=32, train_wall=78, gb_free=17, wall=8576
2023-08-02 20:28:13 | INFO | train_inner | epoch 008:    388 / 1474 loss=2.132, trans_loss=3.522, nll_loss=1.684, w2v_ctc_loss=1.133, task_loss=0, contrastive_loss=0.176, total=4124.65, n_correct=2410.04, ppl=3.21, accuracy=58.43, wps=15378.2, ups=1.25, wpb=12310, bsz=439.9, num_updates=10700, lr=0.000136717, gnorm=0.42, clip=0, loss_scale=32, train_wall=80, gb_free=16.6, wall=8656
2023-08-02 20:29:32 | INFO | train_inner | epoch 008:    488 / 1474 loss=2.167, trans_loss=3.518, nll_loss=1.68, w2v_ctc_loss=1.112, task_loss=0, contrastive_loss=0.444, total=4205.7, n_correct=2463.02, ppl=3.2, accuracy=58.564, wps=15783.6, ups=1.26, wpb=12552.8, bsz=505.9, num_updates=10800, lr=0.000136083, gnorm=0.419, clip=0, loss_scale=32, train_wall=79, gb_free=16.5, wall=8736
2023-08-02 20:30:51 | INFO | train_inner | epoch 008:    588 / 1474 loss=2.121, trans_loss=3.521, nll_loss=1.687, w2v_ctc_loss=1.132, task_loss=0, contrastive_loss=0.113, total=4063.27, n_correct=2372.78, ppl=3.22, accuracy=58.396, wps=15508.4, ups=1.28, wpb=12148.1, bsz=428.8, num_updates=10900, lr=0.000135457, gnorm=0.42, clip=0, loss_scale=32, train_wall=78, gb_free=16.6, wall=8814
2023-08-02 20:32:10 | INFO | train_inner | epoch 008:    688 / 1474 loss=2.116, trans_loss=3.516, nll_loss=1.677, w2v_ctc_loss=1.128, task_loss=0, contrastive_loss=0.124, total=4140.15, n_correct=2432.14, ppl=3.2, accuracy=58.745, wps=15653.8, ups=1.27, wpb=12356.4, bsz=447.4, num_updates=11000, lr=0.00013484, gnorm=0.41, clip=0, loss_scale=32, train_wall=78, gb_free=17, wall=8893
2023-08-02 20:33:29 | INFO | train_inner | epoch 008:    788 / 1474 loss=2.124, trans_loss=3.517, nll_loss=1.683, w2v_ctc_loss=1.119, task_loss=0, contrastive_loss=0.21, total=4121.11, n_correct=2412.61, ppl=3.21, accuracy=58.543, wps=15493.4, ups=1.26, wpb=12317.3, bsz=446.8, num_updates=11100, lr=0.000134231, gnorm=0.418, clip=0, loss_scale=32, train_wall=79, gb_free=17.6, wall=8972
2023-08-02 20:34:48 | INFO | train_inner | epoch 008:    888 / 1474 loss=2.125, trans_loss=3.519, nll_loss=1.684, w2v_ctc_loss=1.111, task_loss=0, contrastive_loss=0.225, total=4158.35, n_correct=2439.52, ppl=3.21, accuracy=58.666, wps=15782.3, ups=1.27, wpb=12419.9, bsz=470.3, num_updates=11200, lr=0.000133631, gnorm=0.419, clip=0, loss_scale=64, train_wall=78, gb_free=16.9, wall=9051
2023-08-02 20:36:06 | INFO | train_inner | epoch 008:    988 / 1474 loss=2.101, trans_loss=3.518, nll_loss=1.682, w2v_ctc_loss=1.105, task_loss=0, contrastive_loss=0.124, total=4170.95, n_correct=2453.24, ppl=3.21, accuracy=58.817, wps=15967.4, ups=1.28, wpb=12452.8, bsz=470.7, num_updates=11300, lr=0.000133038, gnorm=0.413, clip=0, loss_scale=64, train_wall=77, gb_free=16.1, wall=9129
2023-08-02 20:37:25 | INFO | train_inner | epoch 008:   1088 / 1474 loss=2.14, trans_loss=3.527, nll_loss=1.693, w2v_ctc_loss=1.112, task_loss=0, contrastive_loss=0.348, total=4194.19, n_correct=2446.35, ppl=3.23, accuracy=58.327, wps=15752.3, ups=1.26, wpb=12518.3, bsz=464.3, num_updates=11400, lr=0.000132453, gnorm=0.418, clip=0, loss_scale=64, train_wall=79, gb_free=17.4, wall=9209
2023-08-02 20:38:44 | INFO | train_inner | epoch 008:   1188 / 1474 loss=2.108, trans_loss=3.52, nll_loss=1.686, w2v_ctc_loss=1.112, task_loss=0, contrastive_loss=0.12, total=4165.68, n_correct=2447.82, ppl=3.22, accuracy=58.762, wps=15807.1, ups=1.27, wpb=12442.9, bsz=467.9, num_updates=11500, lr=0.000131876, gnorm=0.414, clip=0, loss_scale=64, train_wall=78, gb_free=17.6, wall=9287
2023-08-02 20:40:02 | INFO | train_inner | epoch 008:   1288 / 1474 loss=2.121, trans_loss=3.523, nll_loss=1.69, w2v_ctc_loss=1.123, task_loss=0, contrastive_loss=0.166, total=4079.12, n_correct=2383.21, ppl=3.23, accuracy=58.425, wps=15663.5, ups=1.29, wpb=12185.1, bsz=444, num_updates=11600, lr=0.000131306, gnorm=0.421, clip=0, loss_scale=64, train_wall=77, gb_free=15.9, wall=9365
2023-08-02 20:41:20 | INFO | train_inner | epoch 008:   1388 / 1474 loss=2.128, trans_loss=3.527, nll_loss=1.695, w2v_ctc_loss=1.118, task_loss=0, contrastive_loss=0.205, total=4136.76, n_correct=2420.24, ppl=3.24, accuracy=58.506, wps=15811.3, ups=1.28, wpb=12354.4, bsz=459.3, num_updates=11700, lr=0.000130744, gnorm=0.416, clip=0, loss_scale=64, train_wall=77, gb_free=16.2, wall=9443
2023-08-02 20:42:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 20:42:50 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.455 | trans_loss 5.68 | nll_loss 2.987 | w2v_ctc_loss 1.464 | task_loss 0 | contrastive_loss 0.277 | total 4003.4 | n_correct 2398.4 | ppl 7.93 | accuracy 59.909 | uer 19.231 | wer 20.931 | raw_wer 20.931 | bleu 18.87 | wps 2169.4 | wpb 4003.4 | bsz 141.8 | num_updates 11786 | best_bleu 18.87
2023-08-02 20:42:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11786 updates
2023-08-02 20:42:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 20:43:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 20:43:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt (epoch 8 @ 11786 updates, score 18.87) (writing took 23.654751926660538 seconds)
2023-08-02 20:43:14 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-02 20:43:15 | INFO | train | epoch 008 | loss 2.124 | trans_loss 3.521 | nll_loss 1.684 | w2v_ctc_loss 1.118 | task_loss 0 | contrastive_loss 0.201 | total 4138.65 | n_correct 2424.31 | ppl 3.21 | accuracy 58.577 | wps 14987.3 | ups 1.21 | wpb 12355.8 | bsz 458.5 | num_updates 11786 | lr 0.000130266 | gnorm 0.418 | clip 0 | loss_scale 64 | train_wall 1151 | gb_free 17.1 | wall 9558
2023-08-02 20:43:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-02 20:43:15 | INFO | fairseq.trainer | begin training epoch 9
2023-08-02 20:43:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-02 20:43:33 | INFO | train_inner | epoch 009:     14 / 1474 loss=2.125, trans_loss=3.52, nll_loss=1.683, w2v_ctc_loss=1.099, task_loss=0, contrastive_loss=0.326, total=4126.64, n_correct=2426.29, ppl=3.21, accuracy=58.796, wps=9222.4, ups=0.75, wpb=12312.4, bsz=468.3, num_updates=11800, lr=0.000130189, gnorm=0.424, clip=0, loss_scale=64, train_wall=78, gb_free=17.5, wall=9577
2023-08-02 20:44:52 | INFO | train_inner | epoch 009:    114 / 1474 loss=2.068, trans_loss=3.481, nll_loss=1.633, w2v_ctc_loss=1.068, task_loss=0, contrastive_loss=0.16, total=4190.32, n_correct=2504.56, ppl=3.1, accuracy=59.77, wps=15871, ups=1.27, wpb=12513.4, bsz=478.7, num_updates=11900, lr=0.000129641, gnorm=0.412, clip=0, loss_scale=64, train_wall=78, gb_free=16.7, wall=9656
2023-08-02 20:46:11 | INFO | train_inner | epoch 009:    214 / 1474 loss=2.062, trans_loss=3.486, nll_loss=1.639, w2v_ctc_loss=1.073, task_loss=0, contrastive_loss=0.109, total=4071.85, n_correct=2426.72, ppl=3.11, accuracy=59.597, wps=15416.5, ups=1.27, wpb=12158.6, bsz=435.4, num_updates=12000, lr=0.000129099, gnorm=0.419, clip=0, loss_scale=64, train_wall=78, gb_free=16.8, wall=9735
2023-08-02 20:46:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 20:46:32 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.422 | trans_loss 5.687 | nll_loss 2.997 | w2v_ctc_loss 1.342 | task_loss 0 | contrastive_loss 0.275 | total 4003.4 | n_correct 2395.3 | ppl 7.98 | accuracy 59.832 | uer 18.822 | wer 20.551 | raw_wer 20.551 | bleu 18.67 | wps 2447.8 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 18.87
2023-08-02 20:46:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-08-02 20:46:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_9_12000.pt
2023-08-02 20:46:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_9_12000.pt
2023-08-02 20:46:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.67) (writing took 21.6993717122823 seconds)
2023-08-02 20:48:13 | INFO | train_inner | epoch 009:    314 / 1474 loss=2.06, trans_loss=3.475, nll_loss=1.628, w2v_ctc_loss=1.061, task_loss=0, contrastive_loss=0.158, total=4145.76, n_correct=2485.49, ppl=3.09, accuracy=59.953, wps=10181.5, ups=0.82, wpb=12388.7, bsz=475.4, num_updates=12100, lr=0.000128565, gnorm=0.417, clip=0, loss_scale=64, train_wall=78, gb_free=16.7, wall=9856
2023-08-02 20:49:33 | INFO | train_inner | epoch 009:    414 / 1474 loss=2.066, trans_loss=3.492, nll_loss=1.648, w2v_ctc_loss=1.071, task_loss=0, contrastive_loss=0.127, total=4204.03, n_correct=2500.01, ppl=3.13, accuracy=59.467, wps=15722.7, ups=1.25, wpb=12552.3, bsz=469.6, num_updates=12200, lr=0.000128037, gnorm=0.411, clip=0, loss_scale=64, train_wall=79, gb_free=16.4, wall=9936
2023-08-02 20:50:52 | INFO | train_inner | epoch 009:    514 / 1474 loss=2.091, trans_loss=3.499, nll_loss=1.656, w2v_ctc_loss=1.091, task_loss=0, contrastive_loss=0.175, total=4116.9, n_correct=2443.14, ppl=3.15, accuracy=59.344, wps=15565.2, ups=1.27, wpb=12286.7, bsz=438.4, num_updates=12300, lr=0.000127515, gnorm=0.421, clip=0, loss_scale=64, train_wall=78, gb_free=15.6, wall=10015
2023-08-02 20:52:10 | INFO | train_inner | epoch 009:    614 / 1474 loss=2.063, trans_loss=3.489, nll_loss=1.646, w2v_ctc_loss=1.068, task_loss=0, contrastive_loss=0.139, total=4124.71, n_correct=2454.24, ppl=3.13, accuracy=59.501, wps=15709.8, ups=1.27, wpb=12328.1, bsz=452.6, num_updates=12400, lr=0.000127, gnorm=0.416, clip=0, loss_scale=64, train_wall=78, gb_free=17.5, wall=10093
2023-08-02 20:53:28 | INFO | train_inner | epoch 009:    714 / 1474 loss=2.096, trans_loss=3.501, nll_loss=1.661, w2v_ctc_loss=1.09, task_loss=0, contrastive_loss=0.221, total=4077.28, n_correct=2415.26, ppl=3.16, accuracy=59.237, wps=15591.1, ups=1.28, wpb=12181.2, bsz=448.7, num_updates=12500, lr=0.000126491, gnorm=0.424, clip=0, loss_scale=64, train_wall=78, gb_free=17.2, wall=10172
2023-08-02 20:54:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-02 20:54:48 | INFO | train_inner | epoch 009:    815 / 1474 loss=2.094, trans_loss=3.492, nll_loss=1.652, w2v_ctc_loss=1.085, task_loss=0, contrastive_loss=0.221, total=4206.67, n_correct=2504.15, ppl=3.14, accuracy=59.528, wps=15699, ups=1.25, wpb=12571.6, bsz=492.4, num_updates=12600, lr=0.000125988, gnorm=0.418, clip=0, loss_scale=32, train_wall=79, gb_free=17.7, wall=10252
2023-08-02 20:56:09 | INFO | train_inner | epoch 009:    915 / 1474 loss=2.098, trans_loss=3.499, nll_loss=1.656, w2v_ctc_loss=1.078, task_loss=0, contrastive_loss=0.341, total=4142.34, n_correct=2459.73, ppl=3.15, accuracy=59.38, wps=15369.8, ups=1.24, wpb=12359.9, bsz=448.9, num_updates=12700, lr=0.000125491, gnorm=0.419, clip=0, loss_scale=32, train_wall=80, gb_free=17.4, wall=10332
2023-08-02 20:57:27 | INFO | train_inner | epoch 009:   1015 / 1474 loss=2.078, trans_loss=3.508, nll_loss=1.667, w2v_ctc_loss=1.085, task_loss=0, contrastive_loss=0.123, total=4097.15, n_correct=2419.49, ppl=3.17, accuracy=59.053, wps=15554, ups=1.27, wpb=12228.7, bsz=422.6, num_updates=12800, lr=0.000125, gnorm=0.421, clip=0, loss_scale=32, train_wall=78, gb_free=16.9, wall=10411
2023-08-02 20:58:45 | INFO | train_inner | epoch 009:   1115 / 1474 loss=2.076, trans_loss=3.502, nll_loss=1.659, w2v_ctc_loss=1.075, task_loss=0, contrastive_loss=0.15, total=4182.29, n_correct=2489.2, ppl=3.16, accuracy=59.518, wps=15949, ups=1.28, wpb=12467.1, bsz=477.6, num_updates=12900, lr=0.000124515, gnorm=0.416, clip=0, loss_scale=32, train_wall=78, gb_free=17.4, wall=10489
2023-08-02 21:00:05 | INFO | train_inner | epoch 009:   1215 / 1474 loss=2.083, trans_loss=3.503, nll_loss=1.664, w2v_ctc_loss=1.091, task_loss=0, contrastive_loss=0.131, total=4141.43, n_correct=2454.53, ppl=3.17, accuracy=59.268, wps=15570.1, ups=1.26, wpb=12364.7, bsz=446.6, num_updates=13000, lr=0.000124035, gnorm=0.417, clip=0, loss_scale=32, train_wall=79, gb_free=17.6, wall=10568
2023-08-02 21:01:24 | INFO | train_inner | epoch 009:   1315 / 1474 loss=2.097, trans_loss=3.498, nll_loss=1.656, w2v_ctc_loss=1.07, task_loss=0, contrastive_loss=0.323, total=4203.91, n_correct=2507.9, ppl=3.15, accuracy=59.656, wps=15855.8, ups=1.26, wpb=12545.2, bsz=492.3, num_updates=13100, lr=0.00012356, gnorm=0.416, clip=0, loss_scale=32, train_wall=79, gb_free=17.4, wall=10647
2023-08-02 21:02:42 | INFO | train_inner | epoch 009:   1415 / 1474 loss=2.072, trans_loss=3.509, nll_loss=1.67, w2v_ctc_loss=1.082, task_loss=0, contrastive_loss=0.105, total=4077.08, n_correct=2416, ppl=3.18, accuracy=59.258, wps=15533.2, ups=1.28, wpb=12165, bsz=429.1, num_updates=13200, lr=0.000123091, gnorm=0.416, clip=0, loss_scale=32, train_wall=78, gb_free=17.5, wall=10726
2023-08-02 21:03:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 21:03:51 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.414 | trans_loss 5.653 | nll_loss 2.956 | w2v_ctc_loss 1.398 | task_loss 0 | contrastive_loss 0.268 | total 4003.4 | n_correct 2419.4 | ppl 7.76 | accuracy 60.434 | uer 18.39 | wer 19.988 | raw_wer 19.988 | bleu 18.8 | wps 2261.5 | wpb 4003.4 | bsz 141.8 | num_updates 13259 | best_bleu 18.87
2023-08-02 21:03:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13259 updates
2023-08-02 21:03:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_18.8000.pt
2023-08-02 21:03:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_18.8000.pt
2023-08-02 21:04:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_18.8000.pt (epoch 9 @ 13259 updates, score 18.8) (writing took 18.307827016338706 seconds)
2023-08-02 21:04:09 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-02 21:04:10 | INFO | train | epoch 009 | loss 2.08 | trans_loss 3.496 | nll_loss 1.653 | w2v_ctc_loss 1.078 | task_loss 0 | contrastive_loss 0.182 | total 4137.17 | n_correct 2460.24 | ppl 3.14 | accuracy 59.467 | wps 14497.4 | ups 1.17 | wpb 12351.5 | bsz 457.7 | num_updates 13259 | lr 0.000122817 | gnorm 0.418 | clip 0 | loss_scale 32 | train_wall 1154 | gb_free 12 | wall 10813
2023-08-02 21:04:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-02 21:04:10 | INFO | fairseq.trainer | begin training epoch 10
2023-08-02 21:04:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-02 21:04:50 | INFO | train_inner | epoch 010:     41 / 1474 loss=2.069, trans_loss=3.487, nll_loss=1.643, w2v_ctc_loss=1.06, task_loss=0, contrastive_loss=0.207, total=4100.86, n_correct=2458.16, ppl=3.12, accuracy=59.943, wps=9604.8, ups=0.78, wpb=12239.9, bsz=470.2, num_updates=13300, lr=0.000122628, gnorm=0.42, clip=0, loss_scale=32, train_wall=77, gb_free=16.6, wall=10853
2023-08-02 21:06:09 | INFO | train_inner | epoch 010:    141 / 1474 loss=2.021, trans_loss=3.461, nll_loss=1.609, w2v_ctc_loss=1.027, task_loss=0, contrastive_loss=0.13, total=4240.18, n_correct=2568.29, ppl=3.05, accuracy=60.57, wps=15938.9, ups=1.26, wpb=12664, bsz=479.1, num_updates=13400, lr=0.000122169, gnorm=0.41, clip=0, loss_scale=32, train_wall=79, gb_free=15.2, wall=10933
2023-08-02 21:07:28 | INFO | train_inner | epoch 010:    241 / 1474 loss=2.049, trans_loss=3.465, nll_loss=1.611, w2v_ctc_loss=1.041, task_loss=0, contrastive_loss=0.253, total=4126.3, n_correct=2498.44, ppl=3.05, accuracy=60.549, wps=15632.2, ups=1.27, wpb=12312.3, bsz=460.9, num_updates=13500, lr=0.000121716, gnorm=0.415, clip=0, loss_scale=32, train_wall=78, gb_free=15.8, wall=11011
2023-08-02 21:08:47 | INFO | train_inner | epoch 010:    341 / 1474 loss=2.028, trans_loss=3.462, nll_loss=1.614, w2v_ctc_loss=1.033, task_loss=0, contrastive_loss=0.16, total=4132.25, n_correct=2496.82, ppl=3.06, accuracy=60.423, wps=15691, ups=1.27, wpb=12352, bsz=452.8, num_updates=13600, lr=0.000121268, gnorm=0.413, clip=0, loss_scale=32, train_wall=78, gb_free=14.9, wall=11090
2023-08-02 21:10:06 | INFO | train_inner | epoch 010:    441 / 1474 loss=2.05, trans_loss=3.468, nll_loss=1.618, w2v_ctc_loss=1.024, task_loss=0, contrastive_loss=0.339, total=4203.14, n_correct=2539.35, ppl=3.07, accuracy=60.416, wps=15801.4, ups=1.26, wpb=12548.6, bsz=481.7, num_updates=13700, lr=0.000120824, gnorm=0.416, clip=0, loss_scale=32, train_wall=79, gb_free=16.5, wall=11170
2023-08-02 21:11:26 | INFO | train_inner | epoch 010:    541 / 1474 loss=2.047, trans_loss=3.483, nll_loss=1.633, w2v_ctc_loss=1.057, task_loss=0, contrastive_loss=0.116, total=4106.5, n_correct=2463.75, ppl=3.1, accuracy=59.996, wps=15367.6, ups=1.26, wpb=12244.6, bsz=440, num_updates=13800, lr=0.000120386, gnorm=0.416, clip=0, loss_scale=32, train_wall=79, gb_free=16.6, wall=11249
2023-08-02 21:12:45 | INFO | train_inner | epoch 010:    641 / 1474 loss=2.061, trans_loss=3.478, nll_loss=1.63, w2v_ctc_loss=1.05, task_loss=0, contrastive_loss=0.237, total=4170.61, n_correct=2512.27, ppl=3.1, accuracy=60.237, wps=15656.2, ups=1.26, wpb=12448.2, bsz=476.1, num_updates=13900, lr=0.000119952, gnorm=0.421, clip=0, loss_scale=32, train_wall=79, gb_free=11.3, wall=11329
2023-08-02 21:14:03 | INFO | train_inner | epoch 010:    741 / 1474 loss=2.05, trans_loss=3.48, nll_loss=1.633, w2v_ctc_loss=1.063, task_loss=0, contrastive_loss=0.116, total=4123.31, n_correct=2477.74, ppl=3.1, accuracy=60.091, wps=15833.2, ups=1.29, wpb=12306.7, bsz=453, num_updates=14000, lr=0.000119523, gnorm=0.421, clip=0, loss_scale=32, train_wall=77, gb_free=17.2, wall=11407
2023-08-02 21:14:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 21:14:25 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.414 | trans_loss 5.653 | nll_loss 2.95 | w2v_ctc_loss 1.395 | task_loss 0 | contrastive_loss 0.277 | total 4003.4 | n_correct 2416.1 | ppl 7.73 | accuracy 60.351 | uer 18.645 | wer 20.428 | raw_wer 20.428 | bleu 19.18 | wps 2140.8 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 19.18
2023-08-02 21:14:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-08-02 21:14:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_10_14000.pt
2023-08-02 21:14:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_10_14000.pt
2023-08-02 21:15:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 19.18) (writing took 42.4953930079937 seconds)
2023-08-02 21:16:27 | INFO | train_inner | epoch 010:    841 / 1474 loss=2.027, trans_loss=3.474, nll_loss=1.626, w2v_ctc_loss=1.035, task_loss=0, contrastive_loss=0.117, total=4125.69, n_correct=2488.18, ppl=3.09, accuracy=60.309, wps=8529.3, ups=0.69, wpb=12321, bsz=456.1, num_updates=14100, lr=0.000119098, gnorm=0.415, clip=0, loss_scale=32, train_wall=78, gb_free=15.9, wall=11551
2023-08-02 21:17:46 | INFO | train_inner | epoch 010:    941 / 1474 loss=2.048, trans_loss=3.477, nll_loss=1.628, w2v_ctc_loss=1.047, task_loss=0, contrastive_loss=0.16, total=4170.41, n_correct=2514.37, ppl=3.09, accuracy=60.291, wps=15765, ups=1.27, wpb=12437.5, bsz=470.8, num_updates=14200, lr=0.000118678, gnorm=0.418, clip=0, loss_scale=32, train_wall=78, gb_free=16.3, wall=11630
2023-08-02 21:19:05 | INFO | train_inner | epoch 010:   1041 / 1474 loss=2.042, trans_loss=3.48, nll_loss=1.635, w2v_ctc_loss=1.049, task_loss=0, contrastive_loss=0.129, total=4072.57, n_correct=2443.92, ppl=3.11, accuracy=60.009, wps=15401.3, ups=1.27, wpb=12161.8, bsz=434.8, num_updates=14300, lr=0.000118262, gnorm=0.419, clip=0, loss_scale=32, train_wall=78, gb_free=17.1, wall=11709
2023-08-02 21:20:24 | INFO | train_inner | epoch 010:   1141 / 1474 loss=2.049, trans_loss=3.489, nll_loss=1.645, w2v_ctc_loss=1.06, task_loss=0, contrastive_loss=0.111, total=4041.97, n_correct=2413.85, ppl=3.13, accuracy=59.72, wps=15443, ups=1.28, wpb=12067, bsz=421.9, num_updates=14400, lr=0.000117851, gnorm=0.422, clip=0, loss_scale=32, train_wall=77, gb_free=16.7, wall=11787
2023-08-02 21:21:42 | INFO | train_inner | epoch 010:   1241 / 1474 loss=2.042, trans_loss=3.476, nll_loss=1.633, w2v_ctc_loss=1.057, task_loss=0, contrastive_loss=0.107, total=4103.65, n_correct=2468.49, ppl=3.1, accuracy=60.154, wps=15635.3, ups=1.27, wpb=12271.8, bsz=443.9, num_updates=14500, lr=0.000117444, gnorm=0.422, clip=0, loss_scale=32, train_wall=78, gb_free=15.8, wall=11865
2023-08-02 21:23:02 | INFO | train_inner | epoch 010:   1341 / 1474 loss=2.041, trans_loss=3.482, nll_loss=1.639, w2v_ctc_loss=1.052, task_loss=0, contrastive_loss=0.121, total=4121.93, n_correct=2476.8, ppl=3.11, accuracy=60.088, wps=15483.2, ups=1.26, wpb=12309.4, bsz=451.2, num_updates=14600, lr=0.000117041, gnorm=0.423, clip=0, loss_scale=64, train_wall=79, gb_free=16.9, wall=11945
2023-08-02 21:23:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-02 21:24:22 | INFO | train_inner | epoch 010:   1442 / 1474 loss=2.069, trans_loss=3.488, nll_loss=1.644, w2v_ctc_loss=1.034, task_loss=0, contrastive_loss=0.325, total=4181.55, n_correct=2512.43, ppl=3.12, accuracy=60.084, wps=15555.2, ups=1.25, wpb=12473.5, bsz=475, num_updates=14700, lr=0.000116642, gnorm=0.422, clip=0, loss_scale=32, train_wall=80, gb_free=17.2, wall=12025
2023-08-02 21:24:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 21:25:09 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.417 | trans_loss 5.642 | nll_loss 2.936 | w2v_ctc_loss 1.432 | task_loss 0 | contrastive_loss 0.273 | total 4003.4 | n_correct 2427.7 | ppl 7.65 | accuracy 60.641 | uer 18.05 | wer 19.846 | raw_wer 19.846 | bleu 19.34 | wps 2400.4 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 19.34
2023-08-02 21:25:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-08-02 21:25:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 21:25:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 21:25:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt (epoch 10 @ 14732 updates, score 19.34) (writing took 22.980865571647882 seconds)
2023-08-02 21:25:32 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-02 21:25:32 | INFO | train | epoch 010 | loss 2.045 | trans_loss 3.476 | nll_loss 1.628 | w2v_ctc_loss 1.043 | task_loss 0 | contrastive_loss 0.184 | total 4137.97 | n_correct 2492.08 | ppl 3.09 | accuracy 60.225 | wps 14186.7 | ups 1.15 | wpb 12353.8 | bsz 458.1 | num_updates 14732 | lr 0.000116516 | gnorm 0.418 | clip 0 | loss_scale 32 | train_wall 1154 | gb_free 17.4 | wall 12096
2023-08-02 21:25:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-02 21:25:32 | INFO | fairseq.trainer | begin training epoch 11
2023-08-02 21:25:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-02 21:26:32 | INFO | train_inner | epoch 011:     68 / 1474 loss=2.015, trans_loss=3.45, nll_loss=1.594, w2v_ctc_loss=1.014, task_loss=0, contrastive_loss=0.196, total=4175.24, n_correct=2549.29, ppl=3.02, accuracy=61.057, wps=9574.2, ups=0.77, wpb=12463.5, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.41, clip=0, loss_scale=32, train_wall=77, gb_free=17, wall=12155
2023-08-02 21:27:51 | INFO | train_inner | epoch 011:    168 / 1474 loss=2.006, trans_loss=3.451, nll_loss=1.598, w2v_ctc_loss=1.02, task_loss=0, contrastive_loss=0.115, total=4087.78, n_correct=2492.63, ppl=3.03, accuracy=60.978, wps=15521.6, ups=1.27, wpb=12214.2, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.421, clip=0, loss_scale=32, train_wall=78, gb_free=16.6, wall=12234
2023-08-02 21:29:09 | INFO | train_inner | epoch 011:    268 / 1474 loss=1.995, trans_loss=3.45, nll_loss=1.596, w2v_ctc_loss=1.009, task_loss=0, contrastive_loss=0.11, total=4118.77, n_correct=2513.06, ppl=3.02, accuracy=61.015, wps=15605.1, ups=1.27, wpb=12299.1, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.414, clip=0, loss_scale=32, train_wall=78, gb_free=12.7, wall=12313
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:0')
2023-08-02 21:30:05 | INFO | train_inner | epoch 011:    368 / 1474 loss=2.183, trans_loss=5.129, nll_loss=2.376, w2v_ctc_loss=0.765, task_loss=0, contrastive_loss=0.088, total=4097.83, n_correct=2495.1, ppl=5.19, accuracy=60.888, wps=14803.9, ups=1.8, wpb=8240.8, bsz=298, num_updates=15100, lr=0.000115087, gnorm=0.57, clip=0, loss_scale=32, train_wall=55, gb_free=15.8, wall=12369
2023-08-02 21:31:01 | INFO | train_inner | epoch 011:    468 / 1474 loss=2.2, trans_loss=5.167, nll_loss=2.403, w2v_ctc_loss=0.762, task_loss=0, contrastive_loss=0.208, total=4110.64, n_correct=2492.44, ppl=5.29, accuracy=60.634, wps=14649.8, ups=1.78, wpb=8221.3, bsz=300.4, num_updates=15200, lr=0.000114708, gnorm=0.568, clip=0, loss_scale=32, train_wall=55, gb_free=16.6, wall=12425
2023-08-02 21:31:58 | INFO | train_inner | epoch 011:    568 / 1474 loss=2.203, trans_loss=5.167, nll_loss=2.403, w2v_ctc_loss=0.775, task_loss=0, contrastive_loss=0.207, total=4071.69, n_correct=2468.88, ppl=5.29, accuracy=60.635, wps=14403.3, ups=1.77, wpb=8143.4, bsz=293.7, num_updates=15300, lr=0.000114332, gnorm=0.572, clip=0, loss_scale=32, train_wall=56, gb_free=16.2, wall=12481
2023-08-02 21:32:54 | INFO | train_inner | epoch 011:    668 / 1474 loss=2.209, trans_loss=5.169, nll_loss=2.406, w2v_ctc_loss=0.772, task_loss=0, contrastive_loss=0.262, total=4157.2, n_correct=2512.13, ppl=5.3, accuracy=60.428, wps=14709, ups=1.77, wpb=8314.4, bsz=309.6, num_updates=15400, lr=0.000113961, gnorm=0.57, clip=0, loss_scale=32, train_wall=56, gb_free=17, wall=12538
2023-08-02 21:33:51 | INFO | train_inner | epoch 011:    768 / 1474 loss=2.201, trans_loss=5.177, nll_loss=2.417, w2v_ctc_loss=0.783, task_loss=0, contrastive_loss=0.088, total=4174.91, n_correct=2532.51, ppl=5.34, accuracy=60.66, wps=14832.3, ups=1.78, wpb=8349.8, bsz=306.9, num_updates=15500, lr=0.000113592, gnorm=0.57, clip=0, loss_scale=32, train_wall=56, gb_free=17.3, wall=12594
2023-08-02 21:34:46 | INFO | train_inner | epoch 011:    868 / 1474 loss=2.197, trans_loss=5.179, nll_loss=2.418, w2v_ctc_loss=0.775, task_loss=0, contrastive_loss=0.075, total=4118.44, n_correct=2490.76, ppl=5.34, accuracy=60.478, wps=14871.9, ups=1.81, wpb=8236.9, bsz=293.7, num_updates=15600, lr=0.000113228, gnorm=0.562, clip=0, loss_scale=32, train_wall=55, gb_free=11.4, wall=12649
2023-08-02 21:35:42 | INFO | train_inner | epoch 011:    968 / 1474 loss=2.199, trans_loss=5.177, nll_loss=2.417, w2v_ctc_loss=0.783, task_loss=0, contrastive_loss=0.089, total=4140.92, n_correct=2506.81, ppl=5.34, accuracy=60.538, wps=14890, ups=1.8, wpb=8281.8, bsz=301.9, num_updates=15700, lr=0.000112867, gnorm=0.571, clip=0, loss_scale=32, train_wall=55, gb_free=15.9, wall=12705
2023-08-02 21:36:38 | INFO | train_inner | epoch 011:   1068 / 1474 loss=2.196, trans_loss=5.17, nll_loss=2.409, w2v_ctc_loss=0.778, task_loss=0, contrastive_loss=0.108, total=4136.99, n_correct=2511.77, ppl=5.31, accuracy=60.715, wps=14693, ups=1.78, wpb=8274, bsz=308.8, num_updates=15800, lr=0.000112509, gnorm=0.571, clip=0, loss_scale=32, train_wall=56, gb_free=17.9, wall=12761
2023-08-02 21:37:34 | INFO | train_inner | epoch 011:   1168 / 1474 loss=2.199, trans_loss=5.178, nll_loss=2.42, w2v_ctc_loss=0.779, task_loss=0, contrastive_loss=0.095, total=4185.65, n_correct=2533.78, ppl=5.35, accuracy=60.535, wps=14902.5, ups=1.78, wpb=8371.3, bsz=309.8, num_updates=15900, lr=0.000112154, gnorm=0.567, clip=0, loss_scale=32, train_wall=56, gb_free=14.4, wall=12818
2023-08-02 21:38:30 | INFO | train_inner | epoch 011:   1268 / 1474 loss=2.204, trans_loss=5.173, nll_loss=2.414, w2v_ctc_loss=0.782, task_loss=0, contrastive_loss=0.164, total=4171.89, n_correct=2528.65, ppl=5.33, accuracy=60.612, wps=14916.5, ups=1.79, wpb=8343.8, bsz=314.1, num_updates=16000, lr=0.000111803, gnorm=0.57, clip=0, loss_scale=32, train_wall=55, gb_free=16.2, wall=12874
2023-08-02 21:38:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:2')
2023-08-02 21:38:52 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.418 | trans_loss 5.638 | nll_loss 2.938 | w2v_ctc_loss 1.444 | task_loss 0 | contrastive_loss 0.273 | total 4003.4 | n_correct 2432.9 | ppl 7.66 | accuracy 60.771 | uer 18.042 | wer 19.749 | raw_wer 19.749 | bleu 18.98 | wps 2420.8 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.34
2023-08-02 21:38:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-08-02 21:38:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_11_16000.pt
2023-08-02 21:38:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_11_16000.pt
2023-08-02 21:39:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 18.98) (writing took 36.37541903182864 seconds)
2023-08-02 21:40:28 | INFO | train_inner | epoch 011:   1368 / 1474 loss=2.213, trans_loss=5.174, nll_loss=2.416, w2v_ctc_loss=0.769, task_loss=0, contrastive_loss=0.327, total=4190.34, n_correct=2538.56, ppl=5.34, accuracy=60.581, wps=7116.2, ups=0.85, wpb=8380.7, bsz=327.9, num_updates=16100, lr=0.000111456, gnorm=0.567, clip=0, loss_scale=32, train_wall=56, gb_free=17.3, wall=12991
2023-08-02 21:41:25 | INFO | train_inner | epoch 011:   1468 / 1474 loss=2.196, trans_loss=5.177, nll_loss=2.419, w2v_ctc_loss=0.775, task_loss=0, contrastive_loss=0.098, total=4158.39, n_correct=2516.27, ppl=5.35, accuracy=60.511, wps=14650.2, ups=1.76, wpb=8316.8, bsz=312, num_updates=16200, lr=0.000111111, gnorm=0.563, clip=0, loss_scale=32, train_wall=56, gb_free=17.1, wall=13048
2023-08-02 21:41:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 21:41:49 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.384 | trans_loss 5.628 | nll_loss 2.927 | w2v_ctc_loss 1.355 | task_loss 0 | contrastive_loss 0.267 | total 4003.4 | n_correct 2435.7 | ppl 7.6 | accuracy 60.841 | uer 18.228 | wer 19.794 | raw_wer 19.794 | bleu 19.5 | wps 2432.4 | wpb 4003.4 | bsz 141.8 | num_updates 16206 | best_bleu 19.5
2023-08-02 21:41:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16206 updates
2023-08-02 21:41:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 21:42:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 21:42:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt (epoch 11 @ 16206 updates, score 19.5) (writing took 22.657902233302593 seconds)
2023-08-02 21:42:13 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-02 21:42:13 | INFO | train | epoch 011 | loss 2.151 | trans_loss 4.742 | nll_loss 2.207 | w2v_ctc_loss 0.835 | task_loss 0 | contrastive_loss 0.142 | total 4138.65 | n_correct 2511.55 | ppl 4.62 | accuracy 60.685 | wps 13292.4 | ups 1.47 | wpb 9021 | bsz 333.4 | num_updates 16206 | lr 0.000111091 | gnorm 0.541 | clip 0 | loss_scale 32 | train_wall 879 | gb_free 17.5 | wall 13096
2023-08-02 21:42:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-02 21:42:13 | INFO | fairseq.trainer | begin training epoch 12
2023-08-02 21:42:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-02 21:43:13 | INFO | train_inner | epoch 012:     94 / 1474 loss=2.171, trans_loss=5.118, nll_loss=2.341, w2v_ctc_loss=0.758, task_loss=0, contrastive_loss=0.13, total=4146.82, n_correct=2555.77, ppl=5.06, accuracy=61.632, wps=7684.7, ups=0.93, wpb=8293.6, bsz=313.9, num_updates=16300, lr=0.00011077, gnorm=0.569, clip=0, loss_scale=32, train_wall=55, gb_free=16, wall=13156
2023-08-02 21:44:08 | INFO | train_inner | epoch 012:    194 / 1474 loss=2.174, trans_loss=5.13, nll_loss=2.355, w2v_ctc_loss=0.765, task_loss=0, contrastive_loss=0.08, total=4120.68, n_correct=2527.58, ppl=5.12, accuracy=61.339, wps=14838.8, ups=1.8, wpb=8241.4, bsz=294.7, num_updates=16400, lr=0.000110432, gnorm=0.569, clip=0, loss_scale=32, train_wall=55, gb_free=15.9, wall=13212
2023-08-02 21:45:04 | INFO | train_inner | epoch 012:    294 / 1474 loss=2.173, trans_loss=5.129, nll_loss=2.355, w2v_ctc_loss=0.755, task_loss=0, contrastive_loss=0.113, total=4199.46, n_correct=2577.83, ppl=5.12, accuracy=61.385, wps=14936, ups=1.78, wpb=8398.9, bsz=320.3, num_updates=16500, lr=0.000110096, gnorm=0.564, clip=0, loss_scale=32, train_wall=56, gb_free=16.8, wall=13268
2023-08-02 21:46:01 | INFO | train_inner | epoch 012:    394 / 1474 loss=2.176, trans_loss=5.136, nll_loss=2.364, w2v_ctc_loss=0.763, task_loss=0, contrastive_loss=0.096, total=4151.14, n_correct=2543.28, ppl=5.15, accuracy=61.267, wps=14767.9, ups=1.78, wpb=8302.3, bsz=307.8, num_updates=16600, lr=0.000109764, gnorm=0.57, clip=0, loss_scale=32, train_wall=56, gb_free=17.4, wall=13324
2023-08-02 21:46:56 | INFO | train_inner | epoch 012:    494 / 1474 loss=2.186, trans_loss=5.151, nll_loss=2.385, w2v_ctc_loss=0.771, task_loss=0, contrastive_loss=0.103, total=4110.49, n_correct=2512, ppl=5.22, accuracy=61.112, wps=14729.8, ups=1.79, wpb=8221, bsz=302.2, num_updates=16700, lr=0.000109435, gnorm=0.572, clip=0, loss_scale=64, train_wall=55, gb_free=14.3, wall=13380
2023-08-02 21:47:53 | INFO | train_inner | epoch 012:    594 / 1474 loss=2.183, trans_loss=5.14, nll_loss=2.37, w2v_ctc_loss=0.766, task_loss=0, contrastive_loss=0.169, total=4189.92, n_correct=2565.91, ppl=5.17, accuracy=61.24, wps=14912.1, ups=1.78, wpb=8379.8, bsz=315.1, num_updates=16800, lr=0.000109109, gnorm=0.569, clip=0, loss_scale=64, train_wall=56, gb_free=15.2, wall=13436
2023-08-02 21:48:49 | INFO | train_inner | epoch 012:    694 / 1474 loss=2.18, trans_loss=5.138, nll_loss=2.369, w2v_ctc_loss=0.745, task_loss=0, contrastive_loss=0.257, total=4206.3, n_correct=2586.17, ppl=5.17, accuracy=61.483, wps=14895.7, ups=1.77, wpb=8412.6, bsz=325.7, num_updates=16900, lr=0.000108786, gnorm=0.56, clip=0, loss_scale=64, train_wall=56, gb_free=16.5, wall=13492
2023-08-02 21:49:45 | INFO | train_inner | epoch 012:    794 / 1474 loss=2.176, trans_loss=5.138, nll_loss=2.368, w2v_ctc_loss=0.766, task_loss=0, contrastive_loss=0.09, total=4085.96, n_correct=2506.69, ppl=5.16, accuracy=61.349, wps=14539.3, ups=1.78, wpb=8171.9, bsz=297.1, num_updates=17000, lr=0.000108465, gnorm=0.573, clip=0, loss_scale=64, train_wall=56, gb_free=16.3, wall=13549
2023-08-02 21:50:41 | INFO | train_inner | epoch 012:    894 / 1474 loss=2.184, trans_loss=5.146, nll_loss=2.378, w2v_ctc_loss=0.763, task_loss=0, contrastive_loss=0.147, total=4169.74, n_correct=2552.32, ppl=5.2, accuracy=61.211, wps=14948.9, ups=1.79, wpb=8339.5, bsz=306.4, num_updates=17100, lr=0.000108148, gnorm=0.565, clip=0, loss_scale=64, train_wall=55, gb_free=16.3, wall=13604
2023-08-02 21:51:37 | INFO | train_inner | epoch 012:    994 / 1474 loss=2.188, trans_loss=5.157, nll_loss=2.393, w2v_ctc_loss=0.768, task_loss=0, contrastive_loss=0.153, total=4117.67, n_correct=2512.88, ppl=5.25, accuracy=61.027, wps=14756.3, ups=1.79, wpb=8235.3, bsz=301.4, num_updates=17200, lr=0.000107833, gnorm=0.57, clip=0, loss_scale=64, train_wall=55, gb_free=18, wall=13660
2023-08-02 21:52:33 | INFO | train_inner | epoch 012:   1094 / 1474 loss=2.196, trans_loss=5.163, nll_loss=2.4, w2v_ctc_loss=0.771, task_loss=0, contrastive_loss=0.196, total=4047.61, n_correct=2463.62, ppl=5.28, accuracy=60.866, wps=14483, ups=1.79, wpb=8095.2, bsz=290.4, num_updates=17300, lr=0.000107521, gnorm=0.581, clip=0, loss_scale=64, train_wall=55, gb_free=16.8, wall=13716
2023-08-02 21:53:29 | INFO | train_inner | epoch 012:   1194 / 1474 loss=2.199, trans_loss=5.169, nll_loss=2.409, w2v_ctc_loss=0.781, task_loss=0, contrastive_loss=0.154, total=4184.55, n_correct=2542.95, ppl=5.31, accuracy=60.77, wps=14910.6, ups=1.78, wpb=8369.1, bsz=314.3, num_updates=17400, lr=0.000107211, gnorm=0.569, clip=0, loss_scale=64, train_wall=56, gb_free=16.9, wall=13772
2023-08-02 21:54:24 | INFO | train_inner | epoch 012:   1294 / 1474 loss=2.194, trans_loss=5.162, nll_loss=2.399, w2v_ctc_loss=0.787, task_loss=0, contrastive_loss=0.098, total=4086.33, n_correct=2484.02, ppl=5.28, accuracy=60.789, wps=14695.2, ups=1.8, wpb=8172.7, bsz=291.4, num_updates=17500, lr=0.000106904, gnorm=0.581, clip=0, loss_scale=64, train_wall=55, gb_free=16.9, wall=13828
2023-08-02 21:54:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-02 21:55:21 | INFO | train_inner | epoch 012:   1395 / 1474 loss=2.182, trans_loss=5.162, nll_loss=2.4, w2v_ctc_loss=0.76, task_loss=0, contrastive_loss=0.087, total=4126.63, n_correct=2516.49, ppl=5.28, accuracy=60.982, wps=14661.5, ups=1.78, wpb=8253.3, bsz=298.8, num_updates=17600, lr=0.0001066, gnorm=0.574, clip=0, loss_scale=32, train_wall=56, gb_free=17.3, wall=13884
2023-08-02 21:56:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 21:56:27 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.398 | trans_loss 5.617 | nll_loss 2.908 | w2v_ctc_loss 1.431 | task_loss 0 | contrastive_loss 0.265 | total 4003.4 | n_correct 2442.1 | ppl 7.51 | accuracy 61.001 | uer 18.058 | wer 19.563 | raw_wer 19.563 | bleu 19.65 | wps 2371.8 | wpb 4003.4 | bsz 141.8 | num_updates 17679 | best_bleu 19.65
2023-08-02 21:56:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17679 updates
2023-08-02 21:56:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 21:56:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 21:56:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt (epoch 12 @ 17679 updates, score 19.65) (writing took 24.729766255244613 seconds)
2023-08-02 21:56:52 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-02 21:56:52 | INFO | train | epoch 012 | loss 2.183 | trans_loss 5.146 | nll_loss 2.379 | w2v_ctc_loss 0.766 | task_loss 0 | contrastive_loss 0.132 | total 4137.82 | n_correct 2531.09 | ppl 5.2 | accuracy 61.17 | wps 13854.4 | ups 1.67 | wpb 8275.6 | bsz 305.3 | num_updates 17679 | lr 0.000106362 | gnorm 0.57 | clip 0 | loss_scale 32 | train_wall 817 | gb_free 13.3 | wall 13976
2023-08-02 21:56:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-02 21:56:53 | INFO | fairseq.trainer | begin training epoch 13
2023-08-02 21:56:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-02 21:57:12 | INFO | train_inner | epoch 013:     21 / 1474 loss=2.186, trans_loss=5.159, nll_loss=2.395, w2v_ctc_loss=0.774, task_loss=0, contrastive_loss=0.088, total=4096.49, n_correct=2500.11, ppl=5.26, accuracy=61.031, wps=7387.7, ups=0.9, wpb=8193, bsz=295.4, num_updates=17700, lr=0.000106299, gnorm=0.574, clip=0, loss_scale=32, train_wall=56, gb_free=15, wall=13995
2023-08-02 21:58:08 | INFO | train_inner | epoch 013:    121 / 1474 loss=2.159, trans_loss=5.107, nll_loss=2.326, w2v_ctc_loss=0.751, task_loss=0, contrastive_loss=0.099, total=4160.97, n_correct=2576.82, ppl=5.02, accuracy=61.928, wps=14837.4, ups=1.78, wpb=8321.9, bsz=302.9, num_updates=17800, lr=0.000106, gnorm=0.563, clip=0, loss_scale=32, train_wall=56, gb_free=16.6, wall=14051
2023-08-02 21:59:04 | INFO | train_inner | epoch 013:    221 / 1474 loss=2.18, trans_loss=5.12, nll_loss=2.345, w2v_ctc_loss=0.748, task_loss=0, contrastive_loss=0.319, total=4212.08, n_correct=2596, ppl=5.08, accuracy=61.632, wps=15084, ups=1.79, wpb=8424.2, bsz=329.7, num_updates=17900, lr=0.000105703, gnorm=0.578, clip=0, loss_scale=32, train_wall=55, gb_free=15, wall=14107
2023-08-02 21:59:59 | INFO | train_inner | epoch 013:    321 / 1474 loss=2.156, trans_loss=5.11, nll_loss=2.33, w2v_ctc_loss=0.745, task_loss=0, contrastive_loss=0.082, total=4102.3, n_correct=2540.72, ppl=5.03, accuracy=61.934, wps=14716.1, ups=1.79, wpb=8204.6, bsz=294.1, num_updates=18000, lr=0.000105409, gnorm=0.574, clip=0, loss_scale=32, train_wall=55, gb_free=17.5, wall=14163
2023-08-02 21:59:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 22:00:21 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.41 | trans_loss 5.631 | nll_loss 2.92 | w2v_ctc_loss 1.434 | task_loss 0 | contrastive_loss 0.272 | total 4003.4 | n_correct 2437.3 | ppl 7.57 | accuracy 60.881 | uer 18.366 | wer 20.145 | raw_wer 20.145 | bleu 19.42 | wps 2180 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.65
2023-08-02 22:00:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-08-02 22:00:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_13_18000.pt
2023-08-02 22:00:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_13_18000.pt
2023-08-02 22:00:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.42) (writing took 31.421999206766486 seconds)
2023-08-02 22:01:49 | INFO | train_inner | epoch 013:    421 / 1474 loss=2.167, trans_loss=5.118, nll_loss=2.342, w2v_ctc_loss=0.755, task_loss=0, contrastive_loss=0.134, total=4177.29, n_correct=2585.71, ppl=5.07, accuracy=61.899, wps=7590.1, ups=0.91, wpb=8354.6, bsz=318.4, num_updates=18100, lr=0.000105118, gnorm=0.566, clip=0, loss_scale=32, train_wall=56, gb_free=17.8, wall=14273
2023-08-02 22:02:46 | INFO | train_inner | epoch 013:    521 / 1474 loss=2.172, trans_loss=5.125, nll_loss=2.351, w2v_ctc_loss=0.753, task_loss=0, contrastive_loss=0.172, total=4201.22, n_correct=2587.02, ppl=5.1, accuracy=61.578, wps=14944.2, ups=1.78, wpb=8402.4, bsz=319, num_updates=18200, lr=0.000104828, gnorm=0.571, clip=0, loss_scale=32, train_wall=56, gb_free=13.4, wall=14329
2023-08-02 22:03:41 | INFO | train_inner | epoch 013:    621 / 1474 loss=2.16, trans_loss=5.121, nll_loss=2.346, w2v_ctc_loss=0.749, task_loss=0, contrastive_loss=0.08, total=4161.98, n_correct=2572.17, ppl=5.08, accuracy=61.802, wps=15039.9, ups=1.81, wpb=8324, bsz=308.3, num_updates=18300, lr=0.000104542, gnorm=0.566, clip=0, loss_scale=32, train_wall=55, gb_free=16.2, wall=14385
2023-08-02 22:04:37 | INFO | train_inner | epoch 013:    721 / 1474 loss=2.176, trans_loss=5.135, nll_loss=2.363, w2v_ctc_loss=0.777, task_loss=0, contrastive_loss=0.078, total=4096.76, n_correct=2513.13, ppl=5.14, accuracy=61.344, wps=14657.4, ups=1.79, wpb=8193.5, bsz=284.6, num_updates=18400, lr=0.000104257, gnorm=0.579, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=14440
2023-08-02 22:05:34 | INFO | train_inner | epoch 013:    821 / 1474 loss=2.173, trans_loss=5.133, nll_loss=2.361, w2v_ctc_loss=0.755, task_loss=0, contrastive_loss=0.132, total=4121.73, n_correct=2533.83, ppl=5.14, accuracy=61.475, wps=14558.8, ups=1.77, wpb=8243.5, bsz=306.7, num_updates=18500, lr=0.000103975, gnorm=0.578, clip=0, loss_scale=32, train_wall=56, gb_free=15.2, wall=14497
2023-08-02 22:06:30 | INFO | train_inner | epoch 013:    921 / 1474 loss=2.169, trans_loss=5.134, nll_loss=2.363, w2v_ctc_loss=0.759, task_loss=0, contrastive_loss=0.089, total=4107.01, n_correct=2527.82, ppl=5.15, accuracy=61.549, wps=14642.3, ups=1.78, wpb=8214, bsz=296.5, num_updates=18600, lr=0.000103695, gnorm=0.579, clip=0, loss_scale=32, train_wall=56, gb_free=16.3, wall=14553
2023-08-02 22:07:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-02 22:07:26 | INFO | train_inner | epoch 013:   1022 / 1474 loss=2.172, trans_loss=5.137, nll_loss=2.367, w2v_ctc_loss=0.765, task_loss=0, contrastive_loss=0.073, total=4059.24, n_correct=2494.12, ppl=5.16, accuracy=61.443, wps=14500.4, ups=1.79, wpb=8118.5, bsz=285.1, num_updates=18700, lr=0.000103418, gnorm=0.576, clip=0, loss_scale=16, train_wall=55, gb_free=16.9, wall=14609
2023-08-02 22:08:22 | INFO | train_inner | epoch 013:   1122 / 1474 loss=2.166, trans_loss=5.127, nll_loss=2.354, w2v_ctc_loss=0.753, task_loss=0, contrastive_loss=0.124, total=4098.77, n_correct=2530.75, ppl=5.11, accuracy=61.744, wps=14672.3, ups=1.79, wpb=8197.5, bsz=304.8, num_updates=18800, lr=0.000103142, gnorm=0.575, clip=0, loss_scale=16, train_wall=55, gb_free=14.1, wall=14665
2023-08-02 22:09:18 | INFO | train_inner | epoch 013:   1222 / 1474 loss=2.173, trans_loss=5.141, nll_loss=2.373, w2v_ctc_loss=0.763, task_loss=0, contrastive_loss=0.08, total=4115.57, n_correct=2529.24, ppl=5.18, accuracy=61.455, wps=14534, ups=1.77, wpb=8231.1, bsz=295.9, num_updates=18900, lr=0.000102869, gnorm=0.569, clip=0, loss_scale=16, train_wall=56, gb_free=15.4, wall=14722
2023-08-02 22:10:14 | INFO | train_inner | epoch 013:   1322 / 1474 loss=2.171, trans_loss=5.127, nll_loss=2.355, w2v_ctc_loss=0.755, task_loss=0, contrastive_loss=0.178, total=4111.02, n_correct=2537.05, ppl=5.12, accuracy=61.713, wps=14633.4, ups=1.78, wpb=8222, bsz=307.8, num_updates=19000, lr=0.000102598, gnorm=0.568, clip=0, loss_scale=16, train_wall=56, gb_free=18.1, wall=14778
2023-08-02 22:11:10 | INFO | train_inner | epoch 013:   1422 / 1474 loss=2.178, trans_loss=5.141, nll_loss=2.373, w2v_ctc_loss=0.753, task_loss=0, contrastive_loss=0.191, total=4179.06, n_correct=2566.1, ppl=5.18, accuracy=61.404, wps=14973.5, ups=1.79, wpb=8358.1, bsz=311.9, num_updates=19100, lr=0.000102329, gnorm=0.57, clip=0, loss_scale=16, train_wall=55, gb_free=16.4, wall=14834
2023-08-02 22:11:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 22:12:02 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.394 | trans_loss 5.616 | nll_loss 2.904 | w2v_ctc_loss 1.417 | task_loss 0 | contrastive_loss 0.273 | total 4003.4 | n_correct 2445.8 | ppl 7.49 | accuracy 61.093 | uer 18.055 | wer 19.787 | raw_wer 19.787 | bleu 19.52 | wps 2292.7 | wpb 4003.4 | bsz 141.8 | num_updates 19152 | best_bleu 19.65
2023-08-02 22:12:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19152 updates
2023-08-02 22:12:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_19.5206.pt
2023-08-02 22:12:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_19.5206.pt
2023-08-02 22:12:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_19.5206.pt (epoch 13 @ 19152 updates, score 19.52) (writing took 13.575462771579623 seconds)
2023-08-02 22:12:16 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-02 22:12:16 | INFO | train | epoch 013 | loss 2.169 | trans_loss 5.126 | nll_loss 2.353 | w2v_ctc_loss 0.756 | task_loss 0 | contrastive_loss 0.132 | total 4137.08 | n_correct 2550.34 | ppl 5.11 | accuracy 61.646 | wps 13200.8 | ups 1.6 | wpb 8274.2 | bsz 305.1 | num_updates 19152 | lr 0.00010219 | gnorm 0.572 | clip 0 | loss_scale 16 | train_wall 817 | gb_free 17.9 | wall 14899
2023-08-02 22:12:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-02 22:12:16 | INFO | fairseq.trainer | begin training epoch 14
2023-08-02 22:12:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-02 22:12:51 | INFO | train_inner | epoch 014:     48 / 1474 loss=2.149, trans_loss=5.096, nll_loss=2.316, w2v_ctc_loss=0.743, task_loss=0, contrastive_loss=0.097, total=4179.66, n_correct=2606.73, ppl=4.98, accuracy=62.367, wps=8299.4, ups=0.99, wpb=8359.3, bsz=322, num_updates=19200, lr=0.000102062, gnorm=0.571, clip=0, loss_scale=16, train_wall=55, gb_free=11.2, wall=14934
2023-08-02 22:13:47 | INFO | train_inner | epoch 014:    148 / 1474 loss=2.143, trans_loss=5.083, nll_loss=2.297, w2v_ctc_loss=0.745, task_loss=0, contrastive_loss=0.078, total=4081.01, n_correct=2552.97, ppl=4.91, accuracy=62.557, wps=14525.9, ups=1.78, wpb=8162, bsz=300.6, num_updates=19300, lr=0.000101797, gnorm=0.568, clip=0, loss_scale=16, train_wall=56, gb_free=16.3, wall=14991
2023-08-02 22:14:43 | INFO | train_inner | epoch 014:    248 / 1474 loss=2.158, trans_loss=5.103, nll_loss=2.322, w2v_ctc_loss=0.746, task_loss=0, contrastive_loss=0.179, total=4109.83, n_correct=2555.63, ppl=5, accuracy=62.183, wps=14800.9, ups=1.8, wpb=8219.7, bsz=295.2, num_updates=19400, lr=0.000101535, gnorm=0.574, clip=0, loss_scale=16, train_wall=55, gb_free=15.9, wall=15046
2023-08-02 22:15:39 | INFO | train_inner | epoch 014:    348 / 1474 loss=2.149, trans_loss=5.095, nll_loss=2.313, w2v_ctc_loss=0.74, task_loss=0, contrastive_loss=0.116, total=4171.83, n_correct=2598.1, ppl=4.97, accuracy=62.277, wps=14908.9, ups=1.79, wpb=8343.7, bsz=319.7, num_updates=19500, lr=0.000101274, gnorm=0.568, clip=0, loss_scale=16, train_wall=55, gb_free=17, wall=15102
2023-08-02 22:16:35 | INFO | train_inner | epoch 014:    448 / 1474 loss=2.151, trans_loss=5.107, nll_loss=2.329, w2v_ctc_loss=0.74, task_loss=0, contrastive_loss=0.087, total=4142.75, n_correct=2571.19, ppl=5.02, accuracy=62.065, wps=14674.7, ups=1.77, wpb=8285.5, bsz=302.2, num_updates=19600, lr=0.000101015, gnorm=0.581, clip=0, loss_scale=16, train_wall=56, gb_free=17, wall=15159
2023-08-02 22:17:32 | INFO | train_inner | epoch 014:    548 / 1474 loss=2.163, trans_loss=5.112, nll_loss=2.334, w2v_ctc_loss=0.763, task_loss=0, contrastive_loss=0.096, total=4073.76, n_correct=2520.19, ppl=5.04, accuracy=61.864, wps=14417.1, ups=1.77, wpb=8147.5, bsz=290.9, num_updates=19700, lr=0.000100759, gnorm=0.585, clip=0, loss_scale=16, train_wall=56, gb_free=15.8, wall=15215
2023-08-02 22:18:28 | INFO | train_inner | epoch 014:    648 / 1474 loss=2.16, trans_loss=5.111, nll_loss=2.334, w2v_ctc_loss=0.745, task_loss=0, contrastive_loss=0.154, total=4158.79, n_correct=2575.83, ppl=5.04, accuracy=61.937, wps=14830.9, ups=1.78, wpb=8317.6, bsz=306.8, num_updates=19800, lr=0.000100504, gnorm=0.567, clip=0, loss_scale=16, train_wall=55, gb_free=17.5, wall=15271
2023-08-02 22:19:24 | INFO | train_inner | epoch 014:    748 / 1474 loss=2.146, trans_loss=5.098, nll_loss=2.317, w2v_ctc_loss=0.74, task_loss=0, contrastive_loss=0.085, total=4145.47, n_correct=2584.25, ppl=4.98, accuracy=62.339, wps=14846.6, ups=1.79, wpb=8290.9, bsz=309.6, num_updates=19900, lr=0.000100251, gnorm=0.57, clip=0, loss_scale=16, train_wall=55, gb_free=16.5, wall=15327
2023-08-02 22:20:20 | INFO | train_inner | epoch 014:    848 / 1474 loss=2.161, trans_loss=5.103, nll_loss=2.325, w2v_ctc_loss=0.744, task_loss=0, contrastive_loss=0.196, total=4171.1, n_correct=2593.23, ppl=5.01, accuracy=62.171, wps=14798, ups=1.77, wpb=8342.2, bsz=319.7, num_updates=20000, lr=0.0001, gnorm=0.572, clip=0, loss_scale=16, train_wall=56, gb_free=16.9, wall=15383
2023-08-02 22:20:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 22:20:43 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.384 | trans_loss 5.603 | nll_loss 2.89 | w2v_ctc_loss 1.415 | task_loss 0 | contrastive_loss 0.264 | total 4003.4 | n_correct 2448.4 | ppl 7.41 | accuracy 61.158 | uer 17.986 | wer 19.802 | raw_wer 19.802 | bleu 19.3 | wps 2206.3 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.65
2023-08-02 22:20:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-08-02 22:20:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_14_20000.pt
2023-08-02 22:20:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_14_20000.pt
2023-08-02 22:21:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.3) (writing took 31.21314131654799 seconds)
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:0')
2023-08-02 22:22:12 | INFO | train_inner | epoch 014:    948 / 1474 loss=2.157, trans_loss=5.112, nll_loss=2.336, w2v_ctc_loss=0.745, task_loss=0, contrastive_loss=0.129, total=4167.75, n_correct=2583.17, ppl=5.05, accuracy=61.98, wps=7451.7, ups=0.89, wpb=8335.5, bsz=310.1, num_updates=20100, lr=9.97509e-05, gnorm=0.572, clip=0, loss_scale=16, train_wall=56, gb_free=16.5, wall=15495
2023-08-02 22:23:08 | INFO | train_inner | epoch 014:   1048 / 1474 loss=2.156, trans_loss=5.117, nll_loss=2.342, w2v_ctc_loss=0.741, task_loss=0, contrastive_loss=0.107, total=4143.92, n_correct=2565.36, ppl=5.07, accuracy=61.907, wps=14761, ups=1.78, wpb=8287.8, bsz=300.7, num_updates=20200, lr=9.95037e-05, gnorm=0.572, clip=0, loss_scale=16, train_wall=56, gb_free=16.3, wall=15551
2023-08-02 22:24:04 | INFO | train_inner | epoch 014:   1148 / 1474 loss=2.182, trans_loss=5.115, nll_loss=2.341, w2v_ctc_loss=0.754, task_loss=0, contrastive_loss=0.383, total=4228.69, n_correct=2617.43, ppl=5.07, accuracy=61.897, wps=15098.4, ups=1.79, wpb=8457.4, bsz=327.2, num_updates=20300, lr=9.92583e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=55, gb_free=16, wall=15607
2023-08-02 22:25:00 | INFO | train_inner | epoch 014:   1248 / 1474 loss=2.165, trans_loss=5.134, nll_loss=2.363, w2v_ctc_loss=0.761, task_loss=0, contrastive_loss=0.064, total=4021.19, n_correct=2476.29, ppl=5.15, accuracy=61.581, wps=14355.9, ups=1.79, wpb=8042.4, bsz=271.7, num_updates=20400, lr=9.90148e-05, gnorm=0.583, clip=0, loss_scale=16, train_wall=55, gb_free=16.6, wall=15663
2023-08-02 22:25:56 | INFO | train_inner | epoch 014:   1348 / 1474 loss=2.156, trans_loss=5.121, nll_loss=2.349, w2v_ctc_loss=0.742, task_loss=0, contrastive_loss=0.086, total=4213.9, n_correct=2609.1, ppl=5.1, accuracy=61.917, wps=14963.2, ups=1.78, wpb=8427.8, bsz=319.4, num_updates=20500, lr=9.8773e-05, gnorm=0.566, clip=0, loss_scale=16, train_wall=56, gb_free=16.4, wall=15720
2023-08-02 22:26:53 | INFO | train_inner | epoch 014:   1448 / 1474 loss=2.163, trans_loss=5.129, nll_loss=2.359, w2v_ctc_loss=0.747, task_loss=0, contrastive_loss=0.124, total=4130.28, n_correct=2552.67, ppl=5.13, accuracy=61.804, wps=14701.2, ups=1.78, wpb=8260.6, bsz=304.1, num_updates=20600, lr=9.85329e-05, gnorm=0.579, clip=0, loss_scale=16, train_wall=56, gb_free=15.6, wall=15776
2023-08-02 22:27:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:2')
2023-08-02 22:27:29 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.395 | trans_loss 5.609 | nll_loss 2.9 | w2v_ctc_loss 1.438 | task_loss 0 | contrastive_loss 0.27 | total 4003.4 | n_correct 2454.1 | ppl 7.46 | accuracy 61.3 | uer 18.066 | wer 19.794 | raw_wer 19.794 | bleu 19.41 | wps 2375.9 | wpb 4003.4 | bsz 141.8 | num_updates 20626 | best_bleu 19.65
2023-08-02 22:27:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20626 updates
2023-08-02 22:27:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_19.4102.pt
2023-08-02 22:27:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_19.4102.pt
2023-08-02 22:27:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_19.4102.pt (epoch 14 @ 20626 updates, score 19.41) (writing took 19.01280316710472 seconds)
2023-08-02 22:27:49 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-02 22:27:49 | INFO | train | epoch 014 | loss 2.158 | trans_loss 5.11 | nll_loss 2.332 | w2v_ctc_loss 0.747 | task_loss 0 | contrastive_loss 0.134 | total 4138.65 | n_correct 2567.66 | ppl 5.04 | accuracy 62.041 | wps 13076.6 | ups 1.58 | wpb 8277.3 | bsz 305.7 | num_updates 20626 | lr 9.84708e-05 | gnorm 0.574 | clip 0 | loss_scale 16 | train_wall 819 | gb_free 16.6 | wall 15832
2023-08-02 22:27:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-02 22:27:49 | INFO | fairseq.trainer | begin training epoch 15
2023-08-02 22:27:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-02 22:28:38 | INFO | train_inner | epoch 015:     74 / 1474 loss=2.151, trans_loss=5.095, nll_loss=2.314, w2v_ctc_loss=0.739, task_loss=0, contrastive_loss=0.173, total=4083.88, n_correct=2546.1, ppl=4.97, accuracy=62.345, wps=7755.3, ups=0.95, wpb=8167.8, bsz=300.2, num_updates=20700, lr=9.82946e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=55, gb_free=16.1, wall=15881
2023-08-02 22:29:34 | INFO | train_inner | epoch 015:    174 / 1474 loss=2.142, trans_loss=5.084, nll_loss=2.298, w2v_ctc_loss=0.745, task_loss=0, contrastive_loss=0.082, total=4115.73, n_correct=2574.64, ppl=4.92, accuracy=62.556, wps=14658.9, ups=1.78, wpb=8231.5, bsz=297.8, num_updates=20800, lr=9.80581e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=56, gb_free=17.1, wall=15937
2023-08-02 22:30:30 | INFO | train_inner | epoch 015:    274 / 1474 loss=2.134, trans_loss=5.083, nll_loss=2.297, w2v_ctc_loss=0.73, task_loss=0, contrastive_loss=0.072, total=4193.15, n_correct=2629.13, ppl=4.92, accuracy=62.701, wps=14975, ups=1.79, wpb=8386.3, bsz=312.6, num_updates=20900, lr=9.78232e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=55, gb_free=13.3, wall=15993
2023-08-02 22:31:26 | INFO | train_inner | epoch 015:    374 / 1474 loss=2.139, trans_loss=5.078, nll_loss=2.291, w2v_ctc_loss=0.735, task_loss=0, contrastive_loss=0.101, total=4167.66, n_correct=2607.23, ppl=4.89, accuracy=62.559, wps=14950.6, ups=1.79, wpb=8335.3, bsz=306, num_updates=21000, lr=9.759e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=55, gb_free=16.4, wall=16049
2023-08-02 22:32:21 | INFO | train_inner | epoch 015:    474 / 1474 loss=2.144, trans_loss=5.089, nll_loss=2.305, w2v_ctc_loss=0.723, task_loss=0, contrastive_loss=0.186, total=4074.53, n_correct=2540.09, ppl=4.94, accuracy=62.341, wps=14622.7, ups=1.79, wpb=8149.1, bsz=294.2, num_updates=21100, lr=9.73585e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=55, gb_free=16.1, wall=16105
2023-08-02 22:33:18 | INFO | train_inner | epoch 015:    574 / 1474 loss=2.139, trans_loss=5.087, nll_loss=2.303, w2v_ctc_loss=0.738, task_loss=0, contrastive_loss=0.08, total=4140.59, n_correct=2586.85, ppl=4.93, accuracy=62.475, wps=14741.2, ups=1.78, wpb=8281.2, bsz=298.8, num_updates=21200, lr=9.71286e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=56, gb_free=12.7, wall=16161
2023-08-02 22:34:14 | INFO | train_inner | epoch 015:    674 / 1474 loss=2.152, trans_loss=5.09, nll_loss=2.307, w2v_ctc_loss=0.743, task_loss=0, contrastive_loss=0.168, total=4134.99, n_correct=2583.6, ppl=4.95, accuracy=62.481, wps=14607.2, ups=1.77, wpb=8270, bsz=307.1, num_updates=21300, lr=9.69003e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=56, gb_free=11.3, wall=16218
2023-08-02 22:35:10 | INFO | train_inner | epoch 015:    774 / 1474 loss=2.146, trans_loss=5.098, nll_loss=2.317, w2v_ctc_loss=0.743, task_loss=0, contrastive_loss=0.083, total=4173.66, n_correct=2599.79, ppl=4.98, accuracy=62.29, wps=14886.3, ups=1.78, wpb=8347.3, bsz=305, num_updates=21400, lr=9.66736e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=55, gb_free=17, wall=16274
2023-08-02 22:36:06 | INFO | train_inner | epoch 015:    874 / 1474 loss=2.149, trans_loss=5.104, nll_loss=2.325, w2v_ctc_loss=0.746, task_loss=0, contrastive_loss=0.079, total=4059.35, n_correct=2525.22, ppl=5.01, accuracy=62.207, wps=14603.7, ups=1.8, wpb=8118.7, bsz=288.3, num_updates=21500, lr=9.64486e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=55, gb_free=15.8, wall=16329
2023-08-02 22:37:02 | INFO | train_inner | epoch 015:    974 / 1474 loss=2.148, trans_loss=5.098, nll_loss=2.317, w2v_ctc_loss=0.735, task_loss=0, contrastive_loss=0.162, total=4122.87, n_correct=2570.18, ppl=4.98, accuracy=62.34, wps=14798.5, ups=1.79, wpb=8245.7, bsz=301.7, num_updates=21600, lr=9.6225e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=55, gb_free=17.9, wall=16385
2023-08-02 22:37:59 | INFO | train_inner | epoch 015:   1074 / 1474 loss=2.167, trans_loss=5.105, nll_loss=2.328, w2v_ctc_loss=0.742, task_loss=0, contrastive_loss=0.323, total=4192.24, n_correct=2608.03, ppl=5.02, accuracy=62.211, wps=14730, ups=1.76, wpb=8384.5, bsz=325.2, num_updates=21700, lr=9.60031e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=56, gb_free=17.5, wall=16442
2023-08-02 22:38:55 | INFO | train_inner | epoch 015:   1174 / 1474 loss=2.137, trans_loss=5.09, nll_loss=2.31, w2v_ctc_loss=0.721, task_loss=0, contrastive_loss=0.127, total=4185, n_correct=2624.85, ppl=4.96, accuracy=62.72, wps=14942.2, ups=1.79, wpb=8370, bsz=329.3, num_updates=21800, lr=9.57826e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=55, gb_free=16.6, wall=16498
2023-08-02 22:39:50 | INFO | train_inner | epoch 015:   1274 / 1474 loss=2.149, trans_loss=5.1, nll_loss=2.322, w2v_ctc_loss=0.747, task_loss=0, contrastive_loss=0.083, total=4152.04, n_correct=2585.78, ppl=5, accuracy=62.277, wps=14959.8, ups=1.8, wpb=8304.1, bsz=303.7, num_updates=21900, lr=9.55637e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=55, gb_free=16.7, wall=16554
2023-08-02 22:40:47 | INFO | train_inner | epoch 015:   1374 / 1474 loss=2.14, trans_loss=5.101, nll_loss=2.322, w2v_ctc_loss=0.733, task_loss=0, contrastive_loss=0.066, total=4100.21, n_correct=2559.79, ppl=5, accuracy=62.431, wps=14552, ups=1.77, wpb=8200.4, bsz=293.6, num_updates=22000, lr=9.53463e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=56, gb_free=17.8, wall=16610
2023-08-02 22:40:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 22:41:08 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.365 | trans_loss 5.605 | nll_loss 2.891 | w2v_ctc_loss 1.347 | task_loss 0 | contrastive_loss 0.268 | total 4003.4 | n_correct 2456.4 | ppl 7.42 | accuracy 61.358 | uer 17.747 | wer 19.544 | raw_wer 19.544 | bleu 19.62 | wps 2392.8 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 19.65
2023-08-02 22:41:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-08-02 22:41:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_15_22000.pt
2023-08-02 22:41:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_15_22000.pt
2023-08-02 22:41:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.62) (writing took 22.817086098715663 seconds)
2023-08-02 22:42:29 | INFO | train_inner | epoch 015:   1474 / 1474 loss=2.156, trans_loss=5.107, nll_loss=2.333, w2v_ctc_loss=0.741, task_loss=0, contrastive_loss=0.162, total=4141.17, n_correct=2577.07, ppl=5.04, accuracy=62.23, wps=8090.9, ups=0.98, wpb=8282.3, bsz=314.3, num_updates=22100, lr=9.51303e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=57, gb_free=17.1, wall=16712
2023-08-02 22:42:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 22:42:52 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.382 | trans_loss 5.602 | nll_loss 2.888 | w2v_ctc_loss 1.413 | task_loss 0 | contrastive_loss 0.271 | total 4003.4 | n_correct 2454 | ppl 7.4 | accuracy 61.298 | uer 17.795 | wer 19.503 | raw_wer 19.503 | bleu 19.68 | wps 2188.2 | wpb 4003.4 | bsz 141.8 | num_updates 22100 | best_bleu 19.68
2023-08-02 22:42:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22100 updates
2023-08-02 22:42:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 22:43:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 22:43:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt (epoch 15 @ 22100 updates, score 19.68) (writing took 23.619072446599603 seconds)
2023-08-02 22:43:16 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-02 22:43:16 | INFO | train | epoch 015 | loss 2.146 | trans_loss 5.093 | nll_loss 2.311 | w2v_ctc_loss 0.737 | task_loss 0 | contrastive_loss 0.132 | total 4138.65 | n_correct 2583.94 | ppl 4.96 | accuracy 62.434 | wps 13157.9 | ups 1.59 | wpb 8277.3 | bsz 305.7 | num_updates 22100 | lr 9.51303e-05 | gnorm 0.573 | clip 0 | loss_scale 32 | train_wall 818 | gb_free 17.1 | wall 16760
2023-08-02 22:43:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-02 22:43:16 | INFO | fairseq.trainer | begin training epoch 16
2023-08-02 22:43:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-02 22:44:20 | INFO | train_inner | epoch 016:    100 / 1474 loss=2.127, trans_loss=5.062, nll_loss=2.271, w2v_ctc_loss=0.726, task_loss=0, contrastive_loss=0.102, total=4126.22, n_correct=2601.17, ppl=4.83, accuracy=63.04, wps=7435.9, ups=0.9, wpb=8252.4, bsz=315.6, num_updates=22200, lr=9.49158e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=55, gb_free=16.4, wall=16823
2023-08-02 22:45:16 | INFO | train_inner | epoch 016:    200 / 1474 loss=2.121, trans_loss=5.061, nll_loss=2.268, w2v_ctc_loss=0.718, task_loss=0, contrastive_loss=0.074, total=4100.6, n_correct=2588.34, ppl=4.82, accuracy=63.121, wps=14581.9, ups=1.78, wpb=8201.2, bsz=296.8, num_updates=22300, lr=9.47027e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=56, gb_free=13.2, wall=16880
2023-08-02 22:46:12 | INFO | train_inner | epoch 016:    300 / 1474 loss=2.137, trans_loss=5.071, nll_loss=2.283, w2v_ctc_loss=0.733, task_loss=0, contrastive_loss=0.149, total=4166.94, n_correct=2617.2, ppl=4.87, accuracy=62.809, wps=14880.8, ups=1.79, wpb=8333.9, bsz=308.9, num_updates=22400, lr=9.44911e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=55, gb_free=17.4, wall=16936
2023-08-02 22:47:08 | INFO | train_inner | epoch 016:    400 / 1474 loss=2.139, trans_loss=5.073, nll_loss=2.284, w2v_ctc_loss=0.736, task_loss=0, contrastive_loss=0.162, total=4073.3, n_correct=2555.75, ppl=4.87, accuracy=62.744, wps=14570.2, ups=1.79, wpb=8146.6, bsz=288.1, num_updates=22500, lr=9.42809e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=55, gb_free=17.3, wall=16992
2023-08-02 22:48:04 | INFO | train_inner | epoch 016:    500 / 1474 loss=2.131, trans_loss=5.071, nll_loss=2.284, w2v_ctc_loss=0.727, task_loss=0, contrastive_loss=0.109, total=4174.67, n_correct=2626.6, ppl=4.87, accuracy=62.918, wps=14892.3, ups=1.78, wpb=8349.3, bsz=319.1, num_updates=22600, lr=9.40721e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=55, gb_free=16.3, wall=17048
2023-08-02 22:49:00 | INFO | train_inner | epoch 016:    600 / 1474 loss=2.128, trans_loss=5.075, nll_loss=2.288, w2v_ctc_loss=0.725, task_loss=0, contrastive_loss=0.069, total=4124.65, n_correct=2591.29, ppl=4.88, accuracy=62.824, wps=14850.4, ups=1.8, wpb=8249.3, bsz=297.6, num_updates=22700, lr=9.38647e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=55, gb_free=16.6, wall=17103
2023-08-02 22:49:55 | INFO | train_inner | epoch 016:    700 / 1474 loss=2.131, trans_loss=5.08, nll_loss=2.294, w2v_ctc_loss=0.729, task_loss=0, contrastive_loss=0.071, total=4095.49, n_correct=2569.86, ppl=4.9, accuracy=62.749, wps=14726.6, ups=1.8, wpb=8191, bsz=296.3, num_updates=22800, lr=9.36586e-05, gnorm=0.576, clip=0, loss_scale=64, train_wall=55, gb_free=16.4, wall=17159
2023-08-02 22:50:52 | INFO | train_inner | epoch 016:    800 / 1474 loss=2.133, trans_loss=5.079, nll_loss=2.294, w2v_ctc_loss=0.719, task_loss=0, contrastive_loss=0.134, total=4174.94, n_correct=2617.24, ppl=4.9, accuracy=62.689, wps=14842.9, ups=1.78, wpb=8349.9, bsz=310.9, num_updates=22900, lr=9.34539e-05, gnorm=0.574, clip=0, loss_scale=64, train_wall=56, gb_free=16.7, wall=17215
2023-08-02 22:51:48 | INFO | train_inner | epoch 016:    900 / 1474 loss=2.133, trans_loss=5.077, nll_loss=2.293, w2v_ctc_loss=0.724, task_loss=0, contrastive_loss=0.127, total=4163.19, n_correct=2619.65, ppl=4.9, accuracy=62.924, wps=14852.5, ups=1.78, wpb=8326.4, bsz=310.6, num_updates=23000, lr=9.32505e-05, gnorm=0.57, clip=0, loss_scale=64, train_wall=56, gb_free=17, wall=17271
2023-08-02 22:52:44 | INFO | train_inner | epoch 016:   1000 / 1474 loss=2.146, trans_loss=5.093, nll_loss=2.311, w2v_ctc_loss=0.742, task_loss=0, contrastive_loss=0.125, total=4103.45, n_correct=2560.96, ppl=4.96, accuracy=62.41, wps=14624.2, ups=1.78, wpb=8206.9, bsz=298.1, num_updates=23100, lr=9.30484e-05, gnorm=0.58, clip=0, loss_scale=64, train_wall=56, gb_free=15.3, wall=17327
2023-08-02 22:53:40 | INFO | train_inner | epoch 016:   1100 / 1474 loss=2.146, trans_loss=5.096, nll_loss=2.316, w2v_ctc_loss=0.743, task_loss=0, contrastive_loss=0.101, total=4119.27, n_correct=2571.1, ppl=4.98, accuracy=62.416, wps=14613.1, ups=1.77, wpb=8238.5, bsz=295.3, num_updates=23200, lr=9.28477e-05, gnorm=0.579, clip=0, loss_scale=64, train_wall=56, gb_free=18.1, wall=17384
2023-08-02 22:54:37 | INFO | train_inner | epoch 016:   1200 / 1474 loss=2.139, trans_loss=5.087, nll_loss=2.305, w2v_ctc_loss=0.718, task_loss=0, contrastive_loss=0.195, total=4165.11, n_correct=2607.45, ppl=4.94, accuracy=62.602, wps=14746.9, ups=1.77, wpb=8330.2, bsz=308.7, num_updates=23300, lr=9.26482e-05, gnorm=0.571, clip=0, loss_scale=64, train_wall=56, gb_free=16.9, wall=17440
2023-08-02 22:55:32 | INFO | train_inner | epoch 016:   1300 / 1474 loss=2.145, trans_loss=5.09, nll_loss=2.309, w2v_ctc_loss=0.734, task_loss=0, contrastive_loss=0.172, total=4134.61, n_correct=2587.42, ppl=4.96, accuracy=62.58, wps=14803.5, ups=1.79, wpb=8269.2, bsz=310.8, num_updates=23400, lr=9.245e-05, gnorm=0.573, clip=0, loss_scale=64, train_wall=55, gb_free=17, wall=17496
2023-08-02 22:56:29 | INFO | train_inner | epoch 016:   1400 / 1474 loss=2.141, trans_loss=5.092, nll_loss=2.312, w2v_ctc_loss=0.737, task_loss=0, contrastive_loss=0.108, total=4206.33, n_correct=2631.69, ppl=4.97, accuracy=62.565, wps=14836.4, ups=1.76, wpb=8412.7, bsz=322.2, num_updates=23500, lr=9.22531e-05, gnorm=0.578, clip=0, loss_scale=64, train_wall=56, gb_free=15.9, wall=17553
2023-08-02 22:57:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 22:57:34 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.364 | trans_loss 5.593 | nll_loss 2.879 | w2v_ctc_loss 1.374 | task_loss 0 | contrastive_loss 0.263 | total 4003.4 | n_correct 2462.7 | ppl 7.35 | accuracy 61.515 | uer 17.501 | wer 19.104 | raw_wer 19.104 | bleu 19.69 | wps 2204.5 | wpb 4003.4 | bsz 141.8 | num_updates 23574 | best_bleu 19.69
2023-08-02 22:57:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23574 updates
2023-08-02 22:57:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 22:57:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 22:57:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt (epoch 16 @ 23574 updates, score 19.69) (writing took 25.226243015378714 seconds)
2023-08-02 22:57:59 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-02 22:57:59 | INFO | train | epoch 016 | loss 2.136 | trans_loss 5.08 | nll_loss 2.294 | w2v_ctc_loss 0.729 | task_loss 0 | contrastive_loss 0.13 | total 4138.65 | n_correct 2596.26 | ppl 4.91 | accuracy 62.732 | wps 13812.2 | ups 1.67 | wpb 8277.3 | bsz 305.7 | num_updates 23574 | lr 9.21082e-05 | gnorm 0.577 | clip 0 | loss_scale 64 | train_wall 818 | gb_free 15.8 | wall 17643
2023-08-02 22:58:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-02 22:58:00 | INFO | fairseq.trainer | begin training epoch 17
2023-08-02 22:58:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-02 22:58:22 | INFO | train_inner | epoch 017:     26 / 1474 loss=2.137, trans_loss=5.074, nll_loss=2.288, w2v_ctc_loss=0.721, task_loss=0, contrastive_loss=0.236, total=4152.31, n_correct=2607.05, ppl=4.88, accuracy=62.786, wps=7383.9, ups=0.89, wpb=8304.6, bsz=304.6, num_updates=23600, lr=9.20575e-05, gnorm=0.58, clip=0, loss_scale=64, train_wall=56, gb_free=14.2, wall=17665
2023-08-02 22:59:18 | INFO | train_inner | epoch 017:    126 / 1474 loss=2.119, trans_loss=5.051, nll_loss=2.256, w2v_ctc_loss=0.725, task_loss=0, contrastive_loss=0.075, total=4118.91, n_correct=2605.6, ppl=4.78, accuracy=63.259, wps=14666.6, ups=1.78, wpb=8237.8, bsz=295.8, num_updates=23700, lr=9.1863e-05, gnorm=0.575, clip=0, loss_scale=64, train_wall=56, gb_free=16.7, wall=17721
2023-08-02 22:59:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-02 23:00:14 | INFO | train_inner | epoch 017:    227 / 1474 loss=2.121, trans_loss=5.047, nll_loss=2.252, w2v_ctc_loss=0.708, task_loss=0, contrastive_loss=0.2, total=4141.88, n_correct=2625.58, ppl=4.76, accuracy=63.391, wps=14751.2, ups=1.78, wpb=8283.8, bsz=312.3, num_updates=23800, lr=9.16698e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=56, gb_free=17.1, wall=17777
2023-08-02 23:01:10 | INFO | train_inner | epoch 017:    327 / 1474 loss=2.129, trans_loss=5.058, nll_loss=2.267, w2v_ctc_loss=0.715, task_loss=0, contrastive_loss=0.244, total=4156.91, n_correct=2623.4, ppl=4.81, accuracy=63.109, wps=14762.6, ups=1.78, wpb=8313.8, bsz=305.7, num_updates=23900, lr=9.14779e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=56, gb_free=17.8, wall=17834
2023-08-02 23:02:07 | INFO | train_inner | epoch 017:    427 / 1474 loss=2.116, trans_loss=5.056, nll_loss=2.264, w2v_ctc_loss=0.715, task_loss=0, contrastive_loss=0.074, total=4146.43, n_correct=2628.2, ppl=4.8, accuracy=63.385, wps=14610.2, ups=1.76, wpb=8292.9, bsz=308, num_updates=24000, lr=9.12871e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=56, gb_free=16.5, wall=17891
2023-08-02 23:02:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 23:02:29 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.371 | trans_loss 5.599 | nll_loss 2.884 | w2v_ctc_loss 1.386 | task_loss 0 | contrastive_loss 0.26 | total 4003.4 | n_correct 2455.1 | ppl 7.38 | accuracy 61.325 | uer 17.58 | wer 19.261 | raw_wer 19.261 | bleu 19.29 | wps 2365.5 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 19.69
2023-08-02 23:02:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-08-02 23:02:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_17_24000.pt
2023-08-02 23:02:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_17_24000.pt
2023-08-02 23:02:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.29) (writing took 12.812071980908513 seconds)
2023-08-02 23:03:39 | INFO | train_inner | epoch 017:    527 / 1474 loss=2.126, trans_loss=5.061, nll_loss=2.27, w2v_ctc_loss=0.724, task_loss=0, contrastive_loss=0.121, total=4182.1, n_correct=2637.44, ppl=4.82, accuracy=63.065, wps=9066.1, ups=1.08, wpb=8364.2, bsz=307.9, num_updates=24100, lr=9.10975e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=56, gb_free=17, wall=17983
2023-08-02 23:04:35 | INFO | train_inner | epoch 017:    627 / 1474 loss=2.118, trans_loss=5.065, nll_loss=2.275, w2v_ctc_loss=0.717, task_loss=0, contrastive_loss=0.066, total=4167.27, n_correct=2631.18, ppl=4.84, accuracy=63.139, wps=14893.1, ups=1.79, wpb=8334.5, bsz=302.2, num_updates=24200, lr=9.09091e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=55, gb_free=11.4, wall=18039
2023-08-02 23:05:32 | INFO | train_inner | epoch 017:    727 / 1474 loss=2.133, trans_loss=5.071, nll_loss=2.284, w2v_ctc_loss=0.733, task_loss=0, contrastive_loss=0.119, total=4166.12, n_correct=2623.41, ppl=4.87, accuracy=62.97, wps=14774.5, ups=1.77, wpb=8332.2, bsz=308.1, num_updates=24300, lr=9.07218e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=56, gb_free=16.6, wall=18095
2023-08-02 23:06:28 | INFO | train_inner | epoch 017:    827 / 1474 loss=2.123, trans_loss=5.069, nll_loss=2.281, w2v_ctc_loss=0.721, task_loss=0, contrastive_loss=0.081, total=4091.64, n_correct=2578.46, ppl=4.86, accuracy=63.018, wps=14578.8, ups=1.78, wpb=8183.3, bsz=295.3, num_updates=24400, lr=9.05357e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=56, gb_free=17.6, wall=18151
2023-08-02 23:07:23 | INFO | train_inner | epoch 017:    927 / 1474 loss=2.121, trans_loss=5.069, nll_loss=2.282, w2v_ctc_loss=0.716, task_loss=0, contrastive_loss=0.078, total=4106.83, n_correct=2586.21, ppl=4.86, accuracy=62.973, wps=14778, ups=1.8, wpb=8213.7, bsz=304.6, num_updates=24500, lr=9.03508e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=55, gb_free=16.1, wall=18207
2023-08-02 23:08:19 | INFO | train_inner | epoch 017:   1027 / 1474 loss=2.123, trans_loss=5.069, nll_loss=2.281, w2v_ctc_loss=0.721, task_loss=0, contrastive_loss=0.084, total=4115.49, n_correct=2596.11, ppl=4.86, accuracy=63.081, wps=14777.6, ups=1.8, wpb=8231, bsz=305.8, num_updates=24600, lr=9.0167e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=18263
2023-08-02 23:09:15 | INFO | train_inner | epoch 017:   1127 / 1474 loss=2.12, trans_loss=5.07, nll_loss=2.282, w2v_ctc_loss=0.716, task_loss=0, contrastive_loss=0.069, total=4078.39, n_correct=2569.06, ppl=4.86, accuracy=62.992, wps=14524, ups=1.78, wpb=8156.8, bsz=293.7, num_updates=24700, lr=8.99843e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=55, gb_free=15.9, wall=18319
2023-08-02 23:10:12 | INFO | train_inner | epoch 017:   1227 / 1474 loss=2.146, trans_loss=5.079, nll_loss=2.297, w2v_ctc_loss=0.715, task_loss=0, contrastive_loss=0.32, total=4173.49, n_correct=2613.34, ppl=4.91, accuracy=62.618, wps=14685.1, ups=1.76, wpb=8347, bsz=323.7, num_updates=24800, lr=8.98027e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=56, gb_free=16.4, wall=18376
2023-08-02 23:11:08 | INFO | train_inner | epoch 017:   1327 / 1474 loss=2.125, trans_loss=5.073, nll_loss=2.288, w2v_ctc_loss=0.707, task_loss=0, contrastive_loss=0.154, total=4156.28, n_correct=2617.5, ppl=4.88, accuracy=62.977, wps=14836.7, ups=1.78, wpb=8312.6, bsz=308, num_updates=24900, lr=8.96221e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=55, gb_free=18.1, wall=18432
2023-08-02 23:12:04 | INFO | train_inner | epoch 017:   1427 / 1474 loss=2.124, trans_loss=5.078, nll_loss=2.293, w2v_ctc_loss=0.718, task_loss=0, contrastive_loss=0.074, total=4112.95, n_correct=2586.6, ppl=4.9, accuracy=62.889, wps=14662.4, ups=1.78, wpb=8225.9, bsz=303.2, num_updates=25000, lr=8.94427e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=56, gb_free=17.1, wall=18488
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:0')
2023-08-02 23:12:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:2')
2023-08-02 23:12:53 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.365 | trans_loss 5.581 | nll_loss 2.863 | w2v_ctc_loss 1.409 | task_loss 0 | contrastive_loss 0.263 | total 4003.4 | n_correct 2461.2 | ppl 7.27 | accuracy 61.478 | uer 17.546 | wer 19.213 | raw_wer 19.213 | bleu 20.04 | wps 2416.9 | wpb 4003.4 | bsz 141.8 | num_updates 25047 | best_bleu 20.04
2023-08-02 23:12:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25047 updates
2023-08-02 23:12:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 23:13:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-02 23:13:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt (epoch 17 @ 25047 updates, score 20.04) (writing took 24.348750922828913 seconds)
2023-08-02 23:13:17 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-02 23:13:17 | INFO | train | epoch 017 | loss 2.125 | trans_loss 5.065 | nll_loss 2.277 | w2v_ctc_loss 0.719 | task_loss 0 | contrastive_loss 0.124 | total 4137.84 | n_correct 2609.42 | ppl 4.85 | accuracy 63.062 | wps 13279.1 | ups 1.6 | wpb 8275.7 | bsz 305.4 | num_updates 25047 | lr 8.93588e-05 | gnorm 0.574 | clip 0 | loss_scale 32 | train_wall 820 | gb_free 16.6 | wall 18561
2023-08-02 23:13:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-02 23:13:18 | INFO | fairseq.trainer | begin training epoch 18
2023-08-02 23:13:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-02 23:13:56 | INFO | train_inner | epoch 018:     53 / 1474 loss=2.122, trans_loss=5.061, nll_loss=2.27, w2v_ctc_loss=0.724, task_loss=0, contrastive_loss=0.083, total=4139.04, n_correct=2613.58, ppl=4.82, accuracy=63.145, wps=7430.8, ups=0.9, wpb=8278.1, bsz=303.3, num_updates=25100, lr=8.92644e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=56, gb_free=17.3, wall=18599
2023-08-02 23:14:52 | INFO | train_inner | epoch 018:    153 / 1474 loss=2.11, trans_loss=5.033, nll_loss=2.233, w2v_ctc_loss=0.693, task_loss=0, contrastive_loss=0.209, total=4154.85, n_correct=2644.58, ppl=4.7, accuracy=63.65, wps=14877.5, ups=1.79, wpb=8309.7, bsz=312.7, num_updates=25200, lr=8.90871e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=55, gb_free=17, wall=18655
2023-08-02 23:15:47 | INFO | train_inner | epoch 018:    253 / 1474 loss=2.103, trans_loss=5.035, nll_loss=2.237, w2v_ctc_loss=0.704, task_loss=0, contrastive_loss=0.075, total=4162.72, n_correct=2655.96, ppl=4.71, accuracy=63.803, wps=14888.2, ups=1.79, wpb=8325.4, bsz=312.9, num_updates=25300, lr=8.89108e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=55, gb_free=16.4, wall=18711
2023-08-02 23:16:43 | INFO | train_inner | epoch 018:    353 / 1474 loss=2.111, trans_loss=5.046, nll_loss=2.25, w2v_ctc_loss=0.711, task_loss=0, contrastive_loss=0.09, total=4161.22, n_correct=2642.9, ppl=4.76, accuracy=63.513, wps=14899.4, ups=1.79, wpb=8322.4, bsz=301.5, num_updates=25400, lr=8.87357e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=55, gb_free=14.8, wall=18767
2023-08-02 23:17:39 | INFO | train_inner | epoch 018:    453 / 1474 loss=2.117, trans_loss=5.049, nll_loss=2.254, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.179, total=4092.36, n_correct=2592.76, ppl=4.77, accuracy=63.356, wps=14571.1, ups=1.78, wpb=8184.7, bsz=295.3, num_updates=25500, lr=8.85615e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=56, gb_free=16.8, wall=18823
2023-08-02 23:18:35 | INFO | train_inner | epoch 018:    553 / 1474 loss=2.103, trans_loss=5.036, nll_loss=2.239, w2v_ctc_loss=0.701, task_loss=0, contrastive_loss=0.091, total=4206.45, n_correct=2683.93, ppl=4.72, accuracy=63.805, wps=15030.2, ups=1.79, wpb=8412.9, bsz=328.9, num_updates=25600, lr=8.83883e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=55, gb_free=18.1, wall=18879
2023-08-02 23:19:31 | INFO | train_inner | epoch 018:    653 / 1474 loss=2.122, trans_loss=5.059, nll_loss=2.268, w2v_ctc_loss=0.713, task_loss=0, contrastive_loss=0.159, total=4097.96, n_correct=2593.68, ppl=4.82, accuracy=63.292, wps=14775.8, ups=1.8, wpb=8195.9, bsz=298.6, num_updates=25700, lr=8.82162e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=55, gb_free=12.6, wall=18934
2023-08-02 23:20:27 | INFO | train_inner | epoch 018:    753 / 1474 loss=2.131, trans_loss=5.058, nll_loss=2.269, w2v_ctc_loss=0.72, task_loss=0, contrastive_loss=0.25, total=4208.5, n_correct=2658.43, ppl=4.82, accuracy=63.168, wps=14890, ups=1.77, wpb=8417, bsz=322.6, num_updates=25800, lr=8.80451e-05, gnorm=0.574, clip=0, loss_scale=64, train_wall=56, gb_free=16.5, wall=18991
2023-08-02 23:21:23 | INFO | train_inner | epoch 018:    853 / 1474 loss=2.112, trans_loss=5.057, nll_loss=2.266, w2v_ctc_loss=0.71, task_loss=0, contrastive_loss=0.064, total=4166.07, n_correct=2636.84, ppl=4.81, accuracy=63.293, wps=14966.6, ups=1.8, wpb=8332.1, bsz=302.4, num_updates=25900, lr=8.7875e-05, gnorm=0.58, clip=0, loss_scale=64, train_wall=55, gb_free=16.1, wall=19047
2023-08-02 23:22:19 | INFO | train_inner | epoch 018:    953 / 1474 loss=2.106, trans_loss=5.047, nll_loss=2.254, w2v_ctc_loss=0.699, task_loss=0, contrastive_loss=0.089, total=4141.27, n_correct=2635.64, ppl=4.77, accuracy=63.643, wps=14944.2, ups=1.8, wpb=8282.5, bsz=316, num_updates=26000, lr=8.77058e-05, gnorm=0.575, clip=0, loss_scale=64, train_wall=55, gb_free=16.3, wall=19102
2023-08-02 23:22:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 23:22:41 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.371 | trans_loss 5.59 | nll_loss 2.868 | w2v_ctc_loss 1.405 | task_loss 0 | contrastive_loss 0.264 | total 4003.4 | n_correct 2463.8 | ppl 7.3 | accuracy 61.543 | uer 17.485 | wer 19.25 | raw_wer 19.25 | bleu 19.9 | wps 2044.3 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 20.04
2023-08-02 23:22:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-08-02 23:22:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_18_26000.pt
2023-08-02 23:22:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_18_26000.pt
2023-08-02 23:23:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 19.9) (writing took 26.410345710814 seconds)
2023-08-02 23:24:05 | INFO | train_inner | epoch 018:   1053 / 1474 loss=2.111, trans_loss=5.057, nll_loss=2.266, w2v_ctc_loss=0.702, task_loss=0, contrastive_loss=0.077, total=4134.55, n_correct=2617.92, ppl=4.81, accuracy=63.318, wps=7794.9, ups=0.94, wpb=8269.1, bsz=300.8, num_updates=26100, lr=8.75376e-05, gnorm=0.581, clip=0, loss_scale=64, train_wall=56, gb_free=16.1, wall=19208
2023-08-02 23:25:01 | INFO | train_inner | epoch 018:   1153 / 1474 loss=2.118, trans_loss=5.047, nll_loss=2.255, w2v_ctc_loss=0.707, task_loss=0, contrastive_loss=0.185, total=4157.63, n_correct=2638.71, ppl=4.77, accuracy=63.467, wps=14793.3, ups=1.78, wpb=8315.3, bsz=314, num_updates=26200, lr=8.73704e-05, gnorm=0.573, clip=0, loss_scale=64, train_wall=56, gb_free=17.4, wall=19264
2023-08-02 23:25:57 | INFO | train_inner | epoch 018:   1253 / 1474 loss=2.116, trans_loss=5.069, nll_loss=2.282, w2v_ctc_loss=0.711, task_loss=0, contrastive_loss=0.069, total=4085.66, n_correct=2581.32, ppl=4.86, accuracy=63.18, wps=14632.2, ups=1.79, wpb=8171.3, bsz=286.6, num_updates=26300, lr=8.72041e-05, gnorm=0.579, clip=0, loss_scale=64, train_wall=55, gb_free=17.7, wall=19320
2023-08-02 23:26:53 | INFO | train_inner | epoch 018:   1353 / 1474 loss=2.129, trans_loss=5.075, nll_loss=2.29, w2v_ctc_loss=0.726, task_loss=0, contrastive_loss=0.096, total=4065.6, n_correct=2558.19, ppl=4.89, accuracy=62.923, wps=14512.8, ups=1.78, wpb=8131.2, bsz=291.1, num_updates=26400, lr=8.70388e-05, gnorm=0.584, clip=0, loss_scale=64, train_wall=55, gb_free=13.6, wall=19376
2023-08-02 23:27:49 | INFO | train_inner | epoch 018:   1453 / 1474 loss=2.12, trans_loss=5.068, nll_loss=2.282, w2v_ctc_loss=0.716, task_loss=0, contrastive_loss=0.081, total=4122.48, n_correct=2601.26, ppl=4.86, accuracy=63.099, wps=14728.6, ups=1.79, wpb=8245, bsz=299.5, num_updates=26500, lr=8.68744e-05, gnorm=0.577, clip=0, loss_scale=64, train_wall=55, gb_free=17.4, wall=19432
2023-08-02 23:28:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 23:28:22 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.377 | trans_loss 5.588 | nll_loss 2.869 | w2v_ctc_loss 1.431 | task_loss 0 | contrastive_loss 0.264 | total 4003.4 | n_correct 2468 | ppl 7.31 | accuracy 61.648 | uer 17.405 | wer 19.164 | raw_wer 19.164 | bleu 20 | wps 2455.7 | wpb 4003.4 | bsz 141.8 | num_updates 26521 | best_bleu 20.04
2023-08-02 23:28:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26521 updates
2023-08-02 23:28:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.0006.pt
2023-08-02 23:28:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.0006.pt
2023-08-02 23:28:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.0006.pt (epoch 18 @ 26521 updates, score 20.0) (writing took 17.06939997896552 seconds)
2023-08-02 23:28:40 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-02 23:28:40 | INFO | train | epoch 018 | loss 2.115 | trans_loss 5.052 | nll_loss 2.26 | w2v_ctc_loss 0.709 | task_loss 0 | contrastive_loss 0.126 | total 4138.65 | n_correct 2623.55 | ppl 4.79 | accuracy 63.391 | wps 13230.4 | ups 1.6 | wpb 8277.3 | bsz 305.7 | num_updates 26521 | lr 8.684e-05 | gnorm 0.576 | clip 0 | loss_scale 64 | train_wall 815 | gb_free 16.2 | wall 19483
2023-08-02 23:28:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-02 23:28:40 | INFO | fairseq.trainer | begin training epoch 19
2023-08-02 23:28:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-02 23:29:32 | INFO | train_inner | epoch 019:     79 / 1474 loss=2.101, trans_loss=5.027, nll_loss=2.226, w2v_ctc_loss=0.698, task_loss=0, contrastive_loss=0.129, total=4101.48, n_correct=2618.65, ppl=4.68, accuracy=63.846, wps=7914.1, ups=0.96, wpb=8203, bsz=296.9, num_updates=26600, lr=8.6711e-05, gnorm=0.581, clip=0, loss_scale=64, train_wall=55, gb_free=17.4, wall=19536
2023-08-02 23:30:30 | INFO | train_inner | epoch 019:    179 / 1474 loss=2.107, trans_loss=5.024, nll_loss=2.224, w2v_ctc_loss=0.711, task_loss=0, contrastive_loss=0.128, total=4227.39, n_correct=2699.25, ppl=4.67, accuracy=63.851, wps=14792.4, ups=1.75, wpb=8454.8, bsz=324.7, num_updates=26700, lr=8.65485e-05, gnorm=0.577, clip=0, loss_scale=64, train_wall=57, gb_free=15.8, wall=19593
2023-08-02 23:31:26 | INFO | train_inner | epoch 019:    279 / 1474 loss=2.093, trans_loss=5.021, nll_loss=2.218, w2v_ctc_loss=0.7, task_loss=0, contrastive_loss=0.065, total=4186.65, n_correct=2682.44, ppl=4.65, accuracy=64.071, wps=14939.1, ups=1.78, wpb=8373.3, bsz=306.4, num_updates=26800, lr=8.63868e-05, gnorm=0.571, clip=0, loss_scale=64, train_wall=55, gb_free=14.2, wall=19649
2023-08-02 23:32:22 | INFO | train_inner | epoch 019:    379 / 1474 loss=2.106, trans_loss=5.03, nll_loss=2.232, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.175, total=4165.84, n_correct=2660.22, ppl=4.7, accuracy=63.858, wps=14787.4, ups=1.77, wpb=8331.7, bsz=310, num_updates=26900, lr=8.62261e-05, gnorm=0.572, clip=0, loss_scale=64, train_wall=56, gb_free=16.2, wall=19705
2023-08-02 23:33:18 | INFO | train_inner | epoch 019:    479 / 1474 loss=2.104, trans_loss=5.036, nll_loss=2.238, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.084, total=4122.98, n_correct=2629.03, ppl=4.72, accuracy=63.765, wps=14744.2, ups=1.79, wpb=8246, bsz=302.7, num_updates=27000, lr=8.60663e-05, gnorm=0.575, clip=0, loss_scale=64, train_wall=55, gb_free=17.4, wall=19761
2023-08-02 23:34:14 | INFO | train_inner | epoch 019:    579 / 1474 loss=2.104, trans_loss=5.034, nll_loss=2.236, w2v_ctc_loss=0.7, task_loss=0, contrastive_loss=0.147, total=4121.66, n_correct=2631.04, ppl=4.71, accuracy=63.834, wps=14689.9, ups=1.78, wpb=8243.3, bsz=304.4, num_updates=27100, lr=8.59074e-05, gnorm=0.583, clip=0, loss_scale=64, train_wall=55, gb_free=17.1, wall=19817
2023-08-02 23:35:10 | INFO | train_inner | epoch 019:    679 / 1474 loss=2.092, trans_loss=5.034, nll_loss=2.236, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.074, total=4205.65, n_correct=2688.31, ppl=4.71, accuracy=63.921, wps=15099.9, ups=1.8, wpb=8411.3, bsz=322.9, num_updates=27200, lr=8.57493e-05, gnorm=0.569, clip=0, loss_scale=64, train_wall=55, gb_free=16.5, wall=19873
2023-08-02 23:36:06 | INFO | train_inner | epoch 019:    779 / 1474 loss=2.104, trans_loss=5.038, nll_loss=2.242, w2v_ctc_loss=0.707, task_loss=0, contrastive_loss=0.079, total=4120.36, n_correct=2620.26, ppl=4.73, accuracy=63.593, wps=14692, ups=1.78, wpb=8240.7, bsz=298.5, num_updates=27300, lr=8.55921e-05, gnorm=0.573, clip=0, loss_scale=64, train_wall=56, gb_free=14.3, wall=19929
2023-08-02 23:37:01 | INFO | train_inner | epoch 019:    879 / 1474 loss=2.109, trans_loss=5.048, nll_loss=2.255, w2v_ctc_loss=0.709, task_loss=0, contrastive_loss=0.077, total=4176.52, n_correct=2652.21, ppl=4.77, accuracy=63.503, wps=15004.8, ups=1.8, wpb=8353, bsz=309.8, num_updates=27400, lr=8.54358e-05, gnorm=0.583, clip=0, loss_scale=64, train_wall=55, gb_free=17.2, wall=19985
2023-08-02 23:37:58 | INFO | train_inner | epoch 019:    979 / 1474 loss=2.127, trans_loss=5.057, nll_loss=2.268, w2v_ctc_loss=0.705, task_loss=0, contrastive_loss=0.307, total=4079.93, n_correct=2583.73, ppl=4.82, accuracy=63.328, wps=14407.8, ups=1.77, wpb=8159.9, bsz=305, num_updates=27500, lr=8.52803e-05, gnorm=0.592, clip=0, loss_scale=64, train_wall=56, gb_free=16.7, wall=20042
2023-08-02 23:38:54 | INFO | train_inner | epoch 019:   1079 / 1474 loss=2.113, trans_loss=5.059, nll_loss=2.269, w2v_ctc_loss=0.702, task_loss=0, contrastive_loss=0.115, total=4041.08, n_correct=2558.29, ppl=4.82, accuracy=63.307, wps=14517.8, ups=1.8, wpb=8082.2, bsz=292.3, num_updates=27600, lr=8.51257e-05, gnorm=0.582, clip=0, loss_scale=64, train_wall=55, gb_free=16.3, wall=20097
2023-08-02 23:39:50 | INFO | train_inner | epoch 019:   1179 / 1474 loss=2.123, trans_loss=5.057, nll_loss=2.267, w2v_ctc_loss=0.709, task_loss=0, contrastive_loss=0.195, total=4146.59, n_correct=2626.06, ppl=4.81, accuracy=63.331, wps=14740.9, ups=1.78, wpb=8293.2, bsz=310.1, num_updates=27700, lr=8.49719e-05, gnorm=0.584, clip=0, loss_scale=64, train_wall=56, gb_free=12.8, wall=20154
2023-08-02 23:40:45 | INFO | train_inner | epoch 019:   1279 / 1474 loss=2.108, trans_loss=5.057, nll_loss=2.267, w2v_ctc_loss=0.695, task_loss=0, contrastive_loss=0.094, total=4142.96, n_correct=2625.78, ppl=4.81, accuracy=63.379, wps=14970.7, ups=1.81, wpb=8285.9, bsz=300.3, num_updates=27800, lr=8.48189e-05, gnorm=0.577, clip=0, loss_scale=64, train_wall=55, gb_free=16.4, wall=20209
2023-08-02 23:41:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-02 23:41:42 | INFO | train_inner | epoch 019:   1380 / 1474 loss=2.109, trans_loss=5.054, nll_loss=2.264, w2v_ctc_loss=0.707, task_loss=0, contrastive_loss=0.08, total=4133.53, n_correct=2623.32, ppl=4.8, accuracy=63.464, wps=14674, ups=1.77, wpb=8267.1, bsz=299.9, num_updates=27900, lr=8.46668e-05, gnorm=0.583, clip=0, loss_scale=64, train_wall=56, gb_free=16.8, wall=20265
2023-08-02 23:42:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 23:42:56 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.371 | trans_loss 5.586 | nll_loss 2.868 | w2v_ctc_loss 1.418 | task_loss 0 | contrastive_loss 0.268 | total 4003.4 | n_correct 2468.2 | ppl 7.3 | accuracy 61.653 | uer 17.214 | wer 19.015 | raw_wer 19.015 | bleu 20.01 | wps 2286 | wpb 4003.4 | bsz 141.8 | num_updates 27994 | best_bleu 20.04
2023-08-02 23:42:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27994 updates
2023-08-02 23:42:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.0109.pt
2023-08-02 23:43:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.0109.pt
2023-08-02 23:43:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.0109.pt (epoch 19 @ 27994 updates, score 20.01) (writing took 13.130565280094743 seconds)
2023-08-02 23:43:10 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-02 23:43:10 | INFO | train | epoch 019 | loss 2.107 | trans_loss 5.041 | nll_loss 2.246 | w2v_ctc_loss 0.702 | task_loss 0 | contrastive_loss 0.124 | total 4138.78 | n_correct 2634.31 | ppl 4.74 | accuracy 63.649 | wps 14007.3 | ups 1.69 | wpb 8277.6 | bsz 305.6 | num_updates 27994 | lr 8.45245e-05 | gnorm 0.579 | clip 0 | loss_scale 64 | train_wall 817 | gb_free 17.7 | wall 20354
2023-08-02 23:43:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-02 23:43:10 | INFO | fairseq.trainer | begin training epoch 20
2023-08-02 23:43:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-02 23:43:21 | INFO | train_inner | epoch 020:      6 / 1474 loss=2.108, trans_loss=5.047, nll_loss=2.254, w2v_ctc_loss=0.696, task_loss=0, contrastive_loss=0.163, total=4117.61, n_correct=2619.21, ppl=4.77, accuracy=63.61, wps=8336.7, ups=1.01, wpb=8235.2, bsz=303, num_updates=28000, lr=8.45154e-05, gnorm=0.586, clip=0, loss_scale=64, train_wall=56, gb_free=16.7, wall=20364
2023-08-02 23:43:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 23:43:43 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.366 | trans_loss 5.583 | nll_loss 2.86 | w2v_ctc_loss 1.404 | task_loss 0 | contrastive_loss 0.267 | total 4003.4 | n_correct 2476.8 | ppl 7.26 | accuracy 61.867 | uer 17.105 | wer 18.892 | raw_wer 18.892 | bleu 20.25 | wps 2310 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.25
2023-08-02 23:43:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-08-02 23:43:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_20_28000.pt
2023-08-02 23:43:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_20_28000.pt
2023-08-02 23:44:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 20.25) (writing took 25.36018848977983 seconds)
2023-08-02 23:45:06 | INFO | train_inner | epoch 020:    106 / 1474 loss=2.085, trans_loss=5.007, nll_loss=2.201, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.086, total=4192.82, n_correct=2695.58, ppl=4.6, accuracy=64.29, wps=7989.1, ups=0.95, wpb=8385.6, bsz=312.8, num_updates=28100, lr=8.43649e-05, gnorm=0.571, clip=0, loss_scale=64, train_wall=56, gb_free=16.5, wall=20469
2023-08-02 23:46:01 | INFO | train_inner | epoch 020:    206 / 1474 loss=2.092, trans_loss=5.015, nll_loss=2.211, w2v_ctc_loss=0.691, task_loss=0, contrastive_loss=0.138, total=4155.9, n_correct=2666.07, ppl=4.63, accuracy=64.151, wps=14853.7, ups=1.79, wpb=8311.8, bsz=302.3, num_updates=28200, lr=8.42152e-05, gnorm=0.574, clip=0, loss_scale=64, train_wall=55, gb_free=12.3, wall=20525
2023-08-02 23:46:57 | INFO | train_inner | epoch 020:    306 / 1474 loss=2.088, trans_loss=5.011, nll_loss=2.207, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.078, total=4192.69, n_correct=2700.59, ppl=4.62, accuracy=64.412, wps=15060.3, ups=1.8, wpb=8385.4, bsz=327.6, num_updates=28300, lr=8.40663e-05, gnorm=0.576, clip=0, loss_scale=64, train_wall=55, gb_free=17.3, wall=20581
2023-08-02 23:47:53 | INFO | train_inner | epoch 020:    406 / 1474 loss=2.087, trans_loss=5.016, nll_loss=2.213, w2v_ctc_loss=0.686, task_loss=0, contrastive_loss=0.074, total=4116.96, n_correct=2641.92, ppl=4.64, accuracy=64.172, wps=14763.3, ups=1.79, wpb=8233.9, bsz=296.8, num_updates=28400, lr=8.39181e-05, gnorm=0.578, clip=0, loss_scale=64, train_wall=55, gb_free=13.2, wall=20636
2023-08-02 23:48:49 | INFO | train_inner | epoch 020:    506 / 1474 loss=2.102, trans_loss=5.034, nll_loss=2.236, w2v_ctc_loss=0.692, task_loss=0, contrastive_loss=0.162, total=4100.73, n_correct=2615.28, ppl=4.71, accuracy=63.776, wps=14552.1, ups=1.77, wpb=8201.5, bsz=298.4, num_updates=28500, lr=8.37708e-05, gnorm=0.588, clip=0, loss_scale=64, train_wall=56, gb_free=16.5, wall=20693
2023-08-02 23:49:45 | INFO | train_inner | epoch 020:    606 / 1474 loss=2.105, trans_loss=5.031, nll_loss=2.232, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.165, total=4101.99, n_correct=2617.52, ppl=4.7, accuracy=63.811, wps=14750.1, ups=1.8, wpb=8204, bsz=298.3, num_updates=28600, lr=8.36242e-05, gnorm=0.583, clip=0, loss_scale=64, train_wall=55, gb_free=14, wall=20748
2023-08-02 23:50:41 | INFO | train_inner | epoch 020:    706 / 1474 loss=2.098, trans_loss=5.034, nll_loss=2.236, w2v_ctc_loss=0.7, task_loss=0, contrastive_loss=0.065, total=4124.25, n_correct=2632.05, ppl=4.71, accuracy=63.819, wps=14839.2, ups=1.8, wpb=8248.5, bsz=297.2, num_updates=28700, lr=8.34784e-05, gnorm=0.58, clip=0, loss_scale=64, train_wall=55, gb_free=17, wall=20804
2023-08-02 23:51:36 | INFO | train_inner | epoch 020:    806 / 1474 loss=2.097, trans_loss=5.03, nll_loss=2.232, w2v_ctc_loss=0.701, task_loss=0, contrastive_loss=0.072, total=4153.23, n_correct=2654.74, ppl=4.7, accuracy=63.92, wps=14875, ups=1.79, wpb=8306.5, bsz=308.5, num_updates=28800, lr=8.33333e-05, gnorm=0.579, clip=0, loss_scale=64, train_wall=55, gb_free=17.9, wall=20860
2023-08-02 23:52:33 | INFO | train_inner | epoch 020:    906 / 1474 loss=2.126, trans_loss=5.042, nll_loss=2.249, w2v_ctc_loss=0.699, task_loss=0, contrastive_loss=0.367, total=4153.72, n_correct=2640.67, ppl=4.75, accuracy=63.574, wps=14633.8, ups=1.76, wpb=8307.4, bsz=320.7, num_updates=28900, lr=8.3189e-05, gnorm=0.582, clip=0, loss_scale=64, train_wall=56, gb_free=16.3, wall=20917
2023-08-02 23:53:29 | INFO | train_inner | epoch 020:   1006 / 1474 loss=2.095, trans_loss=5.035, nll_loss=2.238, w2v_ctc_loss=0.689, task_loss=0, contrastive_loss=0.077, total=4156.05, n_correct=2653.86, ppl=4.72, accuracy=63.855, wps=14863, ups=1.79, wpb=8312.1, bsz=305.3, num_updates=29000, lr=8.30455e-05, gnorm=0.573, clip=0, loss_scale=64, train_wall=55, gb_free=15.5, wall=20973
2023-08-02 23:54:25 | INFO | train_inner | epoch 020:   1106 / 1474 loss=2.11, trans_loss=5.037, nll_loss=2.242, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.215, total=4181.53, n_correct=2667.32, ppl=4.73, accuracy=63.788, wps=14961.9, ups=1.79, wpb=8363.1, bsz=320.2, num_updates=29100, lr=8.29027e-05, gnorm=0.575, clip=0, loss_scale=64, train_wall=55, gb_free=17.4, wall=21028
2023-08-02 23:55:21 | INFO | train_inner | epoch 020:   1206 / 1474 loss=2.101, trans_loss=5.037, nll_loss=2.24, w2v_ctc_loss=0.708, task_loss=0, contrastive_loss=0.06, total=4029.26, n_correct=2566.53, ppl=4.72, accuracy=63.697, wps=14493.5, ups=1.8, wpb=8058.5, bsz=282.4, num_updates=29200, lr=8.27606e-05, gnorm=0.59, clip=0, loss_scale=64, train_wall=55, gb_free=16.9, wall=21084
2023-08-02 23:56:17 | INFO | train_inner | epoch 020:   1306 / 1474 loss=2.097, trans_loss=5.041, nll_loss=2.246, w2v_ctc_loss=0.693, task_loss=0, contrastive_loss=0.073, total=4127.21, n_correct=2632.58, ppl=4.75, accuracy=63.786, wps=14588.8, ups=1.77, wpb=8254.4, bsz=299.9, num_updates=29300, lr=8.26192e-05, gnorm=0.581, clip=0, loss_scale=64, train_wall=56, gb_free=15.1, wall=21141
2023-08-02 23:57:13 | INFO | train_inner | epoch 020:   1406 / 1474 loss=2.098, trans_loss=5.043, nll_loss=2.248, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.067, total=4110.89, n_correct=2617.74, ppl=4.75, accuracy=63.678, wps=14780.7, ups=1.8, wpb=8221.8, bsz=291.6, num_updates=29400, lr=8.24786e-05, gnorm=0.582, clip=0, loss_scale=64, train_wall=55, gb_free=13.8, wall=21196
2023-08-02 23:57:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-02 23:58:12 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.34 | trans_loss 5.573 | nll_loss 2.849 | w2v_ctc_loss 1.345 | task_loss 0 | contrastive_loss 0.264 | total 4003.4 | n_correct 2474.3 | ppl 7.21 | accuracy 61.805 | uer 17.094 | wer 18.858 | raw_wer 18.858 | bleu 20.01 | wps 2314 | wpb 4003.4 | bsz 141.8 | num_updates 29468 | best_bleu 20.25
2023-08-02 23:58:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29468 updates
2023-08-02 23:58:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.0102.pt
2023-08-02 23:58:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.0102.pt
2023-08-02 23:58:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.0102.pt (epoch 20 @ 29468 updates, score 20.01) (writing took 34.27087816596031 seconds)
2023-08-02 23:58:47 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-02 23:58:47 | INFO | train | epoch 020 | loss 2.099 | trans_loss 5.03 | nll_loss 2.232 | w2v_ctc_loss 0.694 | task_loss 0 | contrastive_loss 0.122 | total 4138.65 | n_correct 2644.86 | ppl 4.7 | accuracy 63.906 | wps 13023.5 | ups 1.57 | wpb 8277.3 | bsz 305.7 | num_updates 29468 | lr 8.23834e-05 | gnorm 0.58 | clip 0 | loss_scale 64 | train_wall 816 | gb_free 16.4 | wall 21290
2023-08-02 23:58:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-02 23:58:47 | INFO | fairseq.trainer | begin training epoch 21
2023-08-02 23:58:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-02 23:59:13 | INFO | train_inner | epoch 021:     32 / 1474 loss=2.105, trans_loss=5.036, nll_loss=2.241, w2v_ctc_loss=0.69, task_loss=0, contrastive_loss=0.191, total=4166.35, n_correct=2659.98, ppl=4.73, accuracy=63.844, wps=6924.4, ups=0.83, wpb=8332.7, bsz=319.4, num_updates=29500, lr=8.23387e-05, gnorm=0.583, clip=0, loss_scale=64, train_wall=56, gb_free=11.8, wall=21317
2023-08-02 23:59:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-03 00:00:10 | INFO | train_inner | epoch 021:    133 / 1474 loss=2.078, trans_loss=4.998, nll_loss=2.189, w2v_ctc_loss=0.686, task_loss=0, contrastive_loss=0.07, total=4154.79, n_correct=2679.29, ppl=4.56, accuracy=64.487, wps=14699.6, ups=1.77, wpb=8309.6, bsz=307.8, num_updates=29600, lr=8.21995e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=56, gb_free=13.5, wall=21373
2023-08-03 00:01:06 | INFO | train_inner | epoch 021:    233 / 1474 loss=2.079, trans_loss=5.005, nll_loss=2.198, w2v_ctc_loss=0.67, task_loss=0, contrastive_loss=0.135, total=4166.37, n_correct=2686.4, ppl=4.59, accuracy=64.478, wps=14889.8, ups=1.79, wpb=8332.7, bsz=315.2, num_updates=29700, lr=8.2061e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=55, gb_free=14.5, wall=21429
2023-08-03 00:02:02 | INFO | train_inner | epoch 021:    333 / 1474 loss=2.088, trans_loss=5.008, nll_loss=2.202, w2v_ctc_loss=0.689, task_loss=0, contrastive_loss=0.137, total=4132.25, n_correct=2656.97, ppl=4.6, accuracy=64.298, wps=14775.9, ups=1.79, wpb=8264.5, bsz=305, num_updates=29800, lr=8.19232e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=55, gb_free=17, wall=21485
2023-08-03 00:02:57 | INFO | train_inner | epoch 021:    433 / 1474 loss=2.077, trans_loss=5.007, nll_loss=2.202, w2v_ctc_loss=0.675, task_loss=0, contrastive_loss=0.067, total=4195.53, n_correct=2700.65, ppl=4.6, accuracy=64.37, wps=15038.5, ups=1.79, wpb=8391.1, bsz=311.6, num_updates=29900, lr=8.17861e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=55, gb_free=16.7, wall=21541
2023-08-03 00:03:53 | INFO | train_inner | epoch 021:    533 / 1474 loss=2.081, trans_loss=5.007, nll_loss=2.202, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.061, total=4085.05, n_correct=2631.6, ppl=4.6, accuracy=64.42, wps=14601.6, ups=1.79, wpb=8170.1, bsz=296.1, num_updates=30000, lr=8.16497e-05, gnorm=0.596, clip=0, loss_scale=32, train_wall=55, gb_free=16.5, wall=21597
2023-08-03 00:03:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 00:04:15 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.354 | trans_loss 5.591 | nll_loss 2.871 | w2v_ctc_loss 1.353 | task_loss 0 | contrastive_loss 0.254 | total 4003.4 | n_correct 2466.2 | ppl 7.32 | accuracy 61.603 | uer 17.129 | wer 18.963 | raw_wer 18.963 | bleu 19.81 | wps 2430.9 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.25
2023-08-03 00:04:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-08-03 00:04:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_21_30000.pt
2023-08-03 00:04:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_21_30000.pt
2023-08-03 00:04:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 19.81) (writing took 20.037315333262086 seconds)
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:0')
2023-08-03 00:05:32 | INFO | train_inner | epoch 021:    633 / 1474 loss=2.094, trans_loss=5.016, nll_loss=2.214, w2v_ctc_loss=0.679, task_loss=0, contrastive_loss=0.235, total=4220.3, n_correct=2709.32, ppl=4.64, accuracy=64.197, wps=8561.6, ups=1.01, wpb=8440.6, bsz=315.8, num_updates=30100, lr=8.15139e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=56, gb_free=16, wall=21695
2023-08-03 00:06:28 | INFO | train_inner | epoch 021:    733 / 1474 loss=2.091, trans_loss=5.025, nll_loss=2.225, w2v_ctc_loss=0.686, task_loss=0, contrastive_loss=0.097, total=4148.18, n_correct=2657.14, ppl=4.68, accuracy=64.056, wps=14804.9, ups=1.78, wpb=8296.4, bsz=308.3, num_updates=30200, lr=8.13788e-05, gnorm=0.587, clip=0, loss_scale=32, train_wall=55, gb_free=12.4, wall=21751
2023-08-03 00:07:25 | INFO | train_inner | epoch 021:    833 / 1474 loss=2.093, trans_loss=5.028, nll_loss=2.228, w2v_ctc_loss=0.686, task_loss=0, contrastive_loss=0.108, total=4062.56, n_correct=2599.48, ppl=4.68, accuracy=63.986, wps=14361.4, ups=1.77, wpb=8125.1, bsz=293, num_updates=30300, lr=8.12444e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=56, gb_free=16.5, wall=21808
2023-08-03 00:08:20 | INFO | train_inner | epoch 021:    933 / 1474 loss=2.089, trans_loss=5.02, nll_loss=2.22, w2v_ctc_loss=0.689, task_loss=0, contrastive_loss=0.082, total=4103.66, n_correct=2629.64, ppl=4.66, accuracy=64.08, wps=14708.1, ups=1.79, wpb=8207.3, bsz=301.5, num_updates=30400, lr=8.11107e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=55, gb_free=17.4, wall=21864
2023-08-03 00:09:16 | INFO | train_inner | epoch 021:   1033 / 1474 loss=2.094, trans_loss=5.036, nll_loss=2.239, w2v_ctc_loss=0.689, task_loss=0, contrastive_loss=0.079, total=4100.54, n_correct=2619.03, ppl=4.72, accuracy=63.87, wps=14720.8, ups=1.79, wpb=8201.1, bsz=298.2, num_updates=30500, lr=8.09776e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=55, gb_free=18.1, wall=21920
2023-08-03 00:10:12 | INFO | train_inner | epoch 021:   1133 / 1474 loss=2.091, trans_loss=5.027, nll_loss=2.227, w2v_ctc_loss=0.689, task_loss=0, contrastive_loss=0.081, total=4119.98, n_correct=2636.94, ppl=4.68, accuracy=64.004, wps=14788.3, ups=1.79, wpb=8240, bsz=294, num_updates=30600, lr=8.08452e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=55, gb_free=18.1, wall=21975
2023-08-03 00:11:08 | INFO | train_inner | epoch 021:   1233 / 1474 loss=2.093, trans_loss=5.025, nll_loss=2.227, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.134, total=4161.49, n_correct=2668.44, ppl=4.68, accuracy=64.122, wps=14841.3, ups=1.78, wpb=8323, bsz=313, num_updates=30700, lr=8.07134e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=55, gb_free=17, wall=22031
2023-08-03 00:12:04 | INFO | train_inner | epoch 021:   1333 / 1474 loss=2.093, trans_loss=5.027, nll_loss=2.23, w2v_ctc_loss=0.69, task_loss=0, contrastive_loss=0.096, total=4141.76, n_correct=2656.12, ppl=4.69, accuracy=64.13, wps=14836.3, ups=1.79, wpb=8283.5, bsz=311.7, num_updates=30800, lr=8.05823e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=55, gb_free=17.6, wall=22087
2023-08-03 00:13:00 | INFO | train_inner | epoch 021:   1433 / 1474 loss=2.108, trans_loss=5.038, nll_loss=2.243, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.146, total=4127.02, n_correct=2626.07, ppl=4.73, accuracy=63.631, wps=14673.8, ups=1.78, wpb=8254, bsz=302.1, num_updates=30900, lr=8.04518e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=56, gb_free=16.7, wall=22143
2023-08-03 00:13:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:1')
2023-08-03 00:13:48 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.364 | trans_loss 5.581 | nll_loss 2.86 | w2v_ctc_loss 1.406 | task_loss 0 | contrastive_loss 0.262 | total 4003.4 | n_correct 2475.3 | ppl 7.26 | accuracy 61.83 | uer 17.264 | wer 19.041 | raw_wer 19.041 | bleu 20.06 | wps 1992 | wpb 4003.4 | bsz 141.8 | num_updates 30941 | best_bleu 20.25
2023-08-03 00:13:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30941 updates
2023-08-03 00:13:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.0602.pt
2023-08-03 00:13:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.0602.pt
2023-08-03 00:14:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.0602.pt (epoch 21 @ 30941 updates, score 20.06) (writing took 13.40360751748085 seconds)
2023-08-03 00:14:02 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-03 00:14:02 | INFO | train | epoch 021 | loss 2.09 | trans_loss 5.019 | nll_loss 2.218 | w2v_ctc_loss 0.686 | task_loss 0 | contrastive_loss 0.114 | total 4137.02 | n_correct 2653.8 | ppl 4.65 | accuracy 64.148 | wps 13324.7 | ups 1.61 | wpb 8274 | bsz 305.1 | num_updates 30941 | lr 8.03985e-05 | gnorm 0.582 | clip 0 | loss_scale 32 | train_wall 817 | gb_free 15.7 | wall 22205
2023-08-03 00:14:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 00:14:02 | INFO | fairseq.trainer | begin training epoch 22
2023-08-03 00:14:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 00:14:42 | INFO | train_inner | epoch 022:     59 / 1474 loss=2.08, trans_loss=5.007, nll_loss=2.201, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.061, total=4140.16, n_correct=2667.22, ppl=4.6, accuracy=64.423, wps=8145.9, ups=0.98, wpb=8280.3, bsz=300.1, num_updates=31000, lr=8.03219e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=55, gb_free=18, wall=22245
2023-08-03 00:15:38 | INFO | train_inner | epoch 022:    159 / 1474 loss=2.08, trans_loss=4.994, nll_loss=2.184, w2v_ctc_loss=0.678, task_loss=0, contrastive_loss=0.146, total=4115.86, n_correct=2658.19, ppl=4.55, accuracy=64.584, wps=14630.5, ups=1.78, wpb=8231.7, bsz=309.4, num_updates=31100, lr=8.01927e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=56, gb_free=17.6, wall=22301
2023-08-03 00:16:34 | INFO | train_inner | epoch 022:    259 / 1474 loss=2.067, trans_loss=4.99, nll_loss=2.18, w2v_ctc_loss=0.667, task_loss=0, contrastive_loss=0.076, total=4247.73, n_correct=2755.09, ppl=4.53, accuracy=64.86, wps=15254.8, ups=1.8, wpb=8495.5, bsz=323.2, num_updates=31200, lr=8.00641e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=55, gb_free=14.3, wall=22357
2023-08-03 00:17:30 | INFO | train_inner | epoch 022:    359 / 1474 loss=2.094, trans_loss=5.004, nll_loss=2.198, w2v_ctc_loss=0.68, task_loss=0, contrastive_loss=0.25, total=4212.22, n_correct=2716.52, ppl=4.59, accuracy=64.491, wps=14854.7, ups=1.76, wpb=8424.4, bsz=317.9, num_updates=31300, lr=7.99361e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=56, gb_free=15.8, wall=22414
2023-08-03 00:18:26 | INFO | train_inner | epoch 022:    459 / 1474 loss=2.086, trans_loss=5.01, nll_loss=2.204, w2v_ctc_loss=0.683, task_loss=0, contrastive_loss=0.127, total=4131.12, n_correct=2657.01, ppl=4.61, accuracy=64.317, wps=14828.5, ups=1.79, wpb=8262.2, bsz=297.3, num_updates=31400, lr=7.98087e-05, gnorm=0.587, clip=0, loss_scale=32, train_wall=55, gb_free=16.8, wall=22470
2023-08-03 00:19:22 | INFO | train_inner | epoch 022:    559 / 1474 loss=2.079, trans_loss=5.004, nll_loss=2.198, w2v_ctc_loss=0.682, task_loss=0, contrastive_loss=0.075, total=4153.54, n_correct=2679.43, ppl=4.59, accuracy=64.51, wps=14727.4, ups=1.77, wpb=8307.1, bsz=307.1, num_updates=31500, lr=7.96819e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=56, gb_free=15.3, wall=22526
2023-08-03 00:20:18 | INFO | train_inner | epoch 022:    659 / 1474 loss=2.075, trans_loss=4.997, nll_loss=2.19, w2v_ctc_loss=0.665, task_loss=0, contrastive_loss=0.155, total=4143.91, n_correct=2679.51, ppl=4.56, accuracy=64.661, wps=14943.1, ups=1.8, wpb=8287.8, bsz=313.1, num_updates=31600, lr=7.95557e-05, gnorm=0.572, clip=0, loss_scale=64, train_wall=55, gb_free=16.2, wall=22581
2023-08-03 00:21:14 | INFO | train_inner | epoch 022:    759 / 1474 loss=2.08, trans_loss=5.006, nll_loss=2.201, w2v_ctc_loss=0.683, task_loss=0, contrastive_loss=0.076, total=4168.91, n_correct=2683.11, ppl=4.6, accuracy=64.36, wps=14818, ups=1.78, wpb=8337.8, bsz=303.5, num_updates=31700, lr=7.94301e-05, gnorm=0.587, clip=0, loss_scale=64, train_wall=56, gb_free=17.8, wall=22638
2023-08-03 00:22:10 | INFO | train_inner | epoch 022:    859 / 1474 loss=2.086, trans_loss=5.02, nll_loss=2.218, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.061, total=4079.59, n_correct=2615.56, ppl=4.65, accuracy=64.113, wps=14519.2, ups=1.78, wpb=8159.2, bsz=288.7, num_updates=31800, lr=7.93052e-05, gnorm=0.59, clip=0, loss_scale=64, train_wall=56, gb_free=17.5, wall=22694
2023-08-03 00:23:06 | INFO | train_inner | epoch 022:    959 / 1474 loss=2.075, trans_loss=5.008, nll_loss=2.204, w2v_ctc_loss=0.671, task_loss=0, contrastive_loss=0.062, total=4129.75, n_correct=2661.45, ppl=4.61, accuracy=64.446, wps=14782.7, ups=1.79, wpb=8259.5, bsz=303.9, num_updates=31900, lr=7.91808e-05, gnorm=0.582, clip=0, loss_scale=64, train_wall=55, gb_free=18, wall=22750
2023-08-03 00:23:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-03 00:24:02 | INFO | train_inner | epoch 022:   1060 / 1474 loss=2.089, trans_loss=5.011, nll_loss=2.209, w2v_ctc_loss=0.674, task_loss=0, contrastive_loss=0.234, total=4153.15, n_correct=2675.31, ppl=4.62, accuracy=64.416, wps=14829.2, ups=1.79, wpb=8306.3, bsz=314, num_updates=32000, lr=7.90569e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=55, gb_free=12.6, wall=22806
2023-08-03 00:24:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 00:24:26 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.346 | trans_loss 5.587 | nll_loss 2.869 | w2v_ctc_loss 1.338 | task_loss 0 | contrastive_loss 0.253 | total 4003.4 | n_correct 2473 | ppl 7.31 | accuracy 61.772 | uer 17.248 | wer 19.175 | raw_wer 19.175 | bleu 19.61 | wps 2083.4 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.25
2023-08-03 00:24:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-08-03 00:24:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_22_32000.pt
2023-08-03 00:24:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_22_32000.pt
2023-08-03 00:24:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 19.61) (writing took 16.044826935976744 seconds)
2023-08-03 00:25:38 | INFO | train_inner | epoch 022:   1160 / 1474 loss=2.097, trans_loss=5.032, nll_loss=2.236, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.115, total=4092.91, n_correct=2614.85, ppl=4.71, accuracy=63.887, wps=8560.8, ups=1.05, wpb=8185.8, bsz=294.3, num_updates=32100, lr=7.89337e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=55, gb_free=16.3, wall=22901
2023-08-03 00:26:34 | INFO | train_inner | epoch 022:   1260 / 1474 loss=2.09, trans_loss=5.023, nll_loss=2.224, w2v_ctc_loss=0.683, task_loss=0, contrastive_loss=0.112, total=4182.65, n_correct=2681.5, ppl=4.67, accuracy=64.11, wps=14976.6, ups=1.79, wpb=8365.3, bsz=323.6, num_updates=32200, lr=7.8811e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=55, gb_free=16.5, wall=22957
2023-08-03 00:27:29 | INFO | train_inner | epoch 022:   1360 / 1474 loss=2.081, trans_loss=5.014, nll_loss=2.213, w2v_ctc_loss=0.671, task_loss=0, contrastive_loss=0.131, total=4071.58, n_correct=2621.47, ppl=4.64, accuracy=64.385, wps=14616.4, ups=1.79, wpb=8143.2, bsz=300.6, num_updates=32300, lr=7.86889e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=23013
2023-08-03 00:28:25 | INFO | train_inner | epoch 022:   1460 / 1474 loss=2.092, trans_loss=5.032, nll_loss=2.234, w2v_ctc_loss=0.693, task_loss=0, contrastive_loss=0.078, total=4077.83, n_correct=2611.46, ppl=4.7, accuracy=64.04, wps=14672.7, ups=1.8, wpb=8155.7, bsz=288, num_updates=32400, lr=7.85674e-05, gnorm=0.595, clip=0, loss_scale=32, train_wall=55, gb_free=16.4, wall=23069
2023-08-03 00:28:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 00:28:56 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.355 | trans_loss 5.583 | nll_loss 2.86 | w2v_ctc_loss 1.371 | task_loss 0 | contrastive_loss 0.265 | total 4003.4 | n_correct 2470.8 | ppl 7.26 | accuracy 61.718 | uer 17.448 | wer 19.276 | raw_wer 19.276 | bleu 20.4 | wps 2257.8 | wpb 4003.4 | bsz 141.8 | num_updates 32414 | best_bleu 20.4
2023-08-03 00:28:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32414 updates
2023-08-03 00:28:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-03 00:29:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt
2023-08-03 00:29:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_best.pt (epoch 22 @ 32414 updates, score 20.4) (writing took 23.02355113066733 seconds)
2023-08-03 00:29:19 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-03 00:29:19 | INFO | train | epoch 022 | loss 2.083 | trans_loss 5.009 | nll_loss 2.205 | w2v_ctc_loss 0.68 | task_loss 0 | contrastive_loss 0.12 | total 4138.51 | n_correct 2664.55 | ppl 4.61 | accuracy 64.384 | wps 13289.6 | ups 1.61 | wpb 8277 | bsz 305.6 | num_updates 32414 | lr 7.85505e-05 | gnorm 0.583 | clip 0 | loss_scale 32 | train_wall 816 | gb_free 12.3 | wall 23123
2023-08-03 00:29:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 00:29:19 | INFO | fairseq.trainer | begin training epoch 23
2023-08-03 00:29:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 00:30:15 | INFO | train_inner | epoch 023:     86 / 1474 loss=2.071, trans_loss=4.988, nll_loss=2.177, w2v_ctc_loss=0.68, task_loss=0, contrastive_loss=0.07, total=4089.8, n_correct=2650.64, ppl=4.52, accuracy=64.811, wps=7461.2, ups=0.91, wpb=8179.6, bsz=299.5, num_updates=32500, lr=7.84465e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=23178
2023-08-03 00:31:11 | INFO | train_inner | epoch 023:    186 / 1474 loss=2.062, trans_loss=4.98, nll_loss=2.166, w2v_ctc_loss=0.664, task_loss=0, contrastive_loss=0.066, total=4117.76, n_correct=2674.6, ppl=4.49, accuracy=64.953, wps=14673.2, ups=1.78, wpb=8235.5, bsz=296, num_updates=32600, lr=7.8326e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=56, gb_free=15.8, wall=23234
2023-08-03 00:32:07 | INFO | train_inner | epoch 023:    286 / 1474 loss=2.071, trans_loss=4.992, nll_loss=2.182, w2v_ctc_loss=0.661, task_loss=0, contrastive_loss=0.146, total=4144.73, n_correct=2682.18, ppl=4.54, accuracy=64.713, wps=14796.8, ups=1.79, wpb=8289.5, bsz=304, num_updates=32700, lr=7.82062e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=56, gb_free=17.8, wall=23290
2023-08-03 00:33:03 | INFO | train_inner | epoch 023:    386 / 1474 loss=2.065, trans_loss=4.99, nll_loss=2.179, w2v_ctc_loss=0.666, task_loss=0, contrastive_loss=0.057, total=4126.79, n_correct=2678.74, ppl=4.53, accuracy=64.911, wps=14738.4, ups=1.79, wpb=8253.6, bsz=296.4, num_updates=32800, lr=7.80869e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=55, gb_free=17.3, wall=23346
2023-08-03 00:33:58 | INFO | train_inner | epoch 023:    486 / 1474 loss=2.079, trans_loss=4.998, nll_loss=2.191, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.12, total=4150.15, n_correct=2681.79, ppl=4.56, accuracy=64.619, wps=14965, ups=1.8, wpb=8300.3, bsz=312.1, num_updates=32900, lr=7.79681e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=55, gb_free=16.5, wall=23402
2023-08-03 00:34:54 | INFO | train_inner | epoch 023:    586 / 1474 loss=2.06, trans_loss=4.982, nll_loss=2.17, w2v_ctc_loss=0.663, task_loss=0, contrastive_loss=0.064, total=4174.6, n_correct=2717.4, ppl=4.5, accuracy=65.094, wps=14914.2, ups=1.79, wpb=8349.2, bsz=316.3, num_updates=33000, lr=7.78499e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=55, gb_free=16.7, wall=23458
2023-08-03 00:35:50 | INFO | train_inner | epoch 023:    686 / 1474 loss=2.071, trans_loss=4.992, nll_loss=2.183, w2v_ctc_loss=0.669, task_loss=0, contrastive_loss=0.103, total=4136.6, n_correct=2676.73, ppl=4.54, accuracy=64.708, wps=14851, ups=1.8, wpb=8273.2, bsz=301.2, num_updates=33100, lr=7.77322e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=55, gb_free=18, wall=23514
2023-08-03 00:36:46 | INFO | train_inner | epoch 023:    786 / 1474 loss=2.075, trans_loss=5.002, nll_loss=2.195, w2v_ctc_loss=0.675, task_loss=0, contrastive_loss=0.086, total=4147.22, n_correct=2677.91, ppl=4.58, accuracy=64.571, wps=14826.1, ups=1.79, wpb=8294.4, bsz=305.1, num_updates=33200, lr=7.76151e-05, gnorm=0.589, clip=0, loss_scale=32, train_wall=55, gb_free=17.6, wall=23569
2023-08-03 00:37:42 | INFO | train_inner | epoch 023:    886 / 1474 loss=2.079, trans_loss=4.997, nll_loss=2.19, w2v_ctc_loss=0.672, task_loss=0, contrastive_loss=0.167, total=4193.16, n_correct=2713.25, ppl=4.56, accuracy=64.707, wps=15100.6, ups=1.8, wpb=8386.3, bsz=327.3, num_updates=33300, lr=7.74984e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=55, gb_free=16.2, wall=23625
2023-08-03 00:38:38 | INFO | train_inner | epoch 023:    986 / 1474 loss=2.085, trans_loss=5.002, nll_loss=2.197, w2v_ctc_loss=0.661, task_loss=0, contrastive_loss=0.317, total=4164.33, n_correct=2688.59, ppl=4.58, accuracy=64.562, wps=14782.3, ups=1.77, wpb=8328.7, bsz=310.1, num_updates=33400, lr=7.73823e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=56, gb_free=17.9, wall=23681
2023-08-03 00:39:34 | INFO | train_inner | epoch 023:   1086 / 1474 loss=2.082, trans_loss=5.01, nll_loss=2.207, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.071, total=4088.37, n_correct=2630.84, ppl=4.62, accuracy=64.349, wps=14566.8, ups=1.78, wpb=8176.7, bsz=289.6, num_updates=33500, lr=7.72667e-05, gnorm=0.593, clip=0, loss_scale=32, train_wall=55, gb_free=15.8, wall=23737
2023-08-03 00:40:30 | INFO | train_inner | epoch 023:   1186 / 1474 loss=2.074, trans_loss=5.007, nll_loss=2.203, w2v_ctc_loss=0.675, task_loss=0, contrastive_loss=0.063, total=4162.3, n_correct=2685.33, ppl=4.61, accuracy=64.516, wps=14849.3, ups=1.78, wpb=8324.6, bsz=309, num_updates=33600, lr=7.71517e-05, gnorm=0.589, clip=0, loss_scale=32, train_wall=55, gb_free=16, wall=23794
2023-08-03 00:41:26 | INFO | train_inner | epoch 023:   1286 / 1474 loss=2.071, trans_loss=5.006, nll_loss=2.202, w2v_ctc_loss=0.664, task_loss=0, contrastive_loss=0.077, total=4131.74, n_correct=2670.76, ppl=4.6, accuracy=64.64, wps=14843.2, ups=1.8, wpb=8263.5, bsz=308.7, num_updates=33700, lr=7.70371e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=55, gb_free=17.4, wall=23849
2023-08-03 00:42:22 | INFO | train_inner | epoch 023:   1386 / 1474 loss=2.089, trans_loss=5.026, nll_loss=2.228, w2v_ctc_loss=0.678, task_loss=0, contrastive_loss=0.134, total=4141.25, n_correct=2659.29, ppl=4.69, accuracy=64.215, wps=14700.7, ups=1.77, wpb=8282.5, bsz=304.7, num_updates=33800, lr=7.69231e-05, gnorm=0.599, clip=0, loss_scale=32, train_wall=56, gb_free=17, wall=23906
2023-08-03 00:43:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 00:43:33 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.364 | trans_loss 5.578 | nll_loss 2.857 | w2v_ctc_loss 1.415 | task_loss 0 | contrastive_loss 0.261 | total 4003.4 | n_correct 2483.3 | ppl 7.25 | accuracy 62.03 | uer 17.235 | wer 19.075 | raw_wer 19.075 | bleu 20.03 | wps 2381.4 | wpb 4003.4 | bsz 141.8 | num_updates 33888 | best_bleu 20.4
2023-08-03 00:43:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33888 updates
2023-08-03 00:43:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.0305.pt
2023-08-03 00:43:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.0305.pt
2023-08-03 00:43:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.0305.pt (epoch 23 @ 33888 updates, score 20.03) (writing took 13.760881453752518 seconds)
2023-08-03 00:43:48 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-03 00:43:48 | INFO | train | epoch 023 | loss 2.075 | trans_loss 4.999 | nll_loss 2.193 | w2v_ctc_loss 0.671 | task_loss 0 | contrastive_loss 0.118 | total 4138.65 | n_correct 2675.21 | ppl 4.57 | accuracy 64.64 | wps 14048.2 | ups 1.7 | wpb 8277.3 | bsz 305.7 | num_updates 33888 | lr 7.68231e-05 | gnorm 0.585 | clip 0 | loss_scale 32 | train_wall 816 | gb_free 14.1 | wall 23991
2023-08-03 00:43:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 00:43:48 | INFO | fairseq.trainer | begin training epoch 24
2023-08-03 00:43:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 00:44:02 | INFO | train_inner | epoch 024:     12 / 1474 loss=2.092, trans_loss=5.018, nll_loss=2.218, w2v_ctc_loss=0.673, task_loss=0, contrastive_loss=0.212, total=4095.53, n_correct=2630.8, ppl=4.65, accuracy=64.236, wps=8217.2, ups=1, wpb=8191.1, bsz=306.3, num_updates=33900, lr=7.68095e-05, gnorm=0.598, clip=0, loss_scale=32, train_wall=56, gb_free=17.6, wall=24005
2023-08-03 00:44:58 | INFO | train_inner | epoch 024:    112 / 1474 loss=2.07, trans_loss=4.97, nll_loss=2.154, w2v_ctc_loss=0.661, task_loss=0, contrastive_loss=0.232, total=4167.42, n_correct=2715.26, ppl=4.45, accuracy=65.154, wps=14878.8, ups=1.79, wpb=8334.8, bsz=323, num_updates=34000, lr=7.66965e-05, gnorm=0.581, clip=0, loss_scale=64, train_wall=55, gb_free=18, wall=24061
2023-08-03 00:44:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 00:45:21 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.354 | trans_loss 5.581 | nll_loss 2.858 | w2v_ctc_loss 1.376 | task_loss 0 | contrastive_loss 0.258 | total 4003.4 | n_correct 2477.5 | ppl 7.25 | accuracy 61.885 | uer 17.126 | wer 18.817 | raw_wer 18.817 | bleu 20.05 | wps 2253.1 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.4
2023-08-03 00:45:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-08-03 00:45:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_24_34000.pt
2023-08-03 00:45:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_24_34000.pt
2023-08-03 00:45:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 20.05) (writing took 21.940557351335883 seconds)
2023-08-03 00:46:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-03 00:46:40 | INFO | train_inner | epoch 024:    213 / 1474 loss=2.063, trans_loss=4.976, nll_loss=2.163, w2v_ctc_loss=0.656, task_loss=0, contrastive_loss=0.136, total=4217.55, n_correct=2749.83, ppl=4.48, accuracy=65.2, wps=8239.7, ups=0.98, wpb=8435.1, bsz=328.6, num_updates=34100, lr=7.6584e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=56, gb_free=17, wall=24164
2023-08-03 00:47:37 | INFO | train_inner | epoch 024:    313 / 1474 loss=2.058, trans_loss=4.979, nll_loss=2.165, w2v_ctc_loss=0.663, task_loss=0, contrastive_loss=0.061, total=4128.18, n_correct=2688.3, ppl=4.49, accuracy=65.121, wps=14653.2, ups=1.77, wpb=8256.4, bsz=305.5, num_updates=34200, lr=7.64719e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=56, gb_free=16.5, wall=24220
2023-08-03 00:48:33 | INFO | train_inner | epoch 024:    413 / 1474 loss=2.081, trans_loss=4.987, nll_loss=2.175, w2v_ctc_loss=0.673, task_loss=0, contrastive_loss=0.207, total=4158.92, n_correct=2689.51, ppl=4.52, accuracy=64.668, wps=14797.3, ups=1.78, wpb=8317.8, bsz=299.7, num_updates=34300, lr=7.63604e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=56, gb_free=16.8, wall=24276
2023-08-03 00:49:29 | INFO | train_inner | epoch 024:    513 / 1474 loss=2.067, trans_loss=4.983, nll_loss=2.17, w2v_ctc_loss=0.666, task_loss=0, contrastive_loss=0.13, total=4144.91, n_correct=2693.1, ppl=4.5, accuracy=64.974, wps=14809.2, ups=1.79, wpb=8289.8, bsz=303.3, num_updates=34400, lr=7.62493e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=55, gb_free=17.2, wall=24332
2023-08-03 00:50:25 | INFO | train_inner | epoch 024:    613 / 1474 loss=2.061, trans_loss=4.983, nll_loss=2.171, w2v_ctc_loss=0.656, task_loss=0, contrastive_loss=0.095, total=4165.3, n_correct=2704.87, ppl=4.5, accuracy=64.938, wps=14878.7, ups=1.79, wpb=8330.6, bsz=307.7, num_updates=34500, lr=7.61387e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=55, gb_free=15.9, wall=24388
2023-08-03 00:51:21 | INFO | train_inner | epoch 024:    713 / 1474 loss=2.07, trans_loss=4.996, nll_loss=2.188, w2v_ctc_loss=0.667, task_loss=0, contrastive_loss=0.104, total=4102.21, n_correct=2655.45, ppl=4.56, accuracy=64.732, wps=14562.9, ups=1.78, wpb=8204.4, bsz=295.1, num_updates=34600, lr=7.60286e-05, gnorm=0.589, clip=0, loss_scale=32, train_wall=56, gb_free=17.1, wall=24445
2023-08-03 00:52:17 | INFO | train_inner | epoch 024:    813 / 1474 loss=2.068, trans_loss=4.997, nll_loss=2.19, w2v_ctc_loss=0.664, task_loss=0, contrastive_loss=0.084, total=4110.6, n_correct=2660.3, ppl=4.56, accuracy=64.718, wps=14678.3, ups=1.79, wpb=8221.2, bsz=305.3, num_updates=34700, lr=7.5919e-05, gnorm=0.587, clip=0, loss_scale=32, train_wall=55, gb_free=16.7, wall=24501
2023-08-03 00:53:13 | INFO | train_inner | epoch 024:    913 / 1474 loss=2.074, trans_loss=5.007, nll_loss=2.201, w2v_ctc_loss=0.674, task_loss=0, contrastive_loss=0.055, total=4043.03, n_correct=2604.52, ppl=4.6, accuracy=64.42, wps=14531.5, ups=1.8, wpb=8086.1, bsz=281, num_updates=34800, lr=7.58098e-05, gnorm=0.596, clip=0, loss_scale=32, train_wall=55, gb_free=11.8, wall=24556
2023-08-03 00:54:09 | INFO | train_inner | epoch 024:   1013 / 1474 loss=2.067, trans_loss=5, nll_loss=2.194, w2v_ctc_loss=0.664, task_loss=0, contrastive_loss=0.06, total=4136.81, n_correct=2677.31, ppl=4.58, accuracy=64.719, wps=14816, ups=1.79, wpb=8273.6, bsz=298.4, num_updates=34900, lr=7.57011e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=55, gb_free=17.1, wall=24612
2023-08-03 00:55:05 | INFO | train_inner | epoch 024:   1113 / 1474 loss=2.068, trans_loss=4.988, nll_loss=2.179, w2v_ctc_loss=0.669, task_loss=0, contrastive_loss=0.105, total=4135.73, n_correct=2683.16, ppl=4.53, accuracy=64.878, wps=14711.6, ups=1.78, wpb=8271.5, bsz=308.9, num_updates=35000, lr=7.55929e-05, gnorm=0.591, clip=0, loss_scale=32, train_wall=56, gb_free=17.3, wall=24668
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:0')
2023-08-03 00:56:01 | INFO | train_inner | epoch 024:   1213 / 1474 loss=2.069, trans_loss=4.996, nll_loss=2.19, w2v_ctc_loss=0.663, task_loss=0, contrastive_loss=0.095, total=4148.3, n_correct=2686.31, ppl=4.56, accuracy=64.757, wps=14852.7, ups=1.79, wpb=8296.6, bsz=310.8, num_updates=35100, lr=7.54851e-05, gnorm=0.585, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=24724
2023-08-03 00:56:56 | INFO | train_inner | epoch 024:   1313 / 1474 loss=2.077, trans_loss=5.009, nll_loss=2.205, w2v_ctc_loss=0.68, task_loss=0, contrastive_loss=0.065, total=4110.05, n_correct=2650.26, ppl=4.61, accuracy=64.482, wps=14768.7, ups=1.8, wpb=8220.1, bsz=294.3, num_updates=35200, lr=7.53778e-05, gnorm=0.593, clip=0, loss_scale=32, train_wall=55, gb_free=17.5, wall=24780
2023-08-03 00:57:52 | INFO | train_inner | epoch 024:   1413 / 1474 loss=2.077, trans_loss=5.007, nll_loss=2.203, w2v_ctc_loss=0.682, task_loss=0, contrastive_loss=0.065, total=4090.91, n_correct=2638.96, ppl=4.61, accuracy=64.508, wps=14730.6, ups=1.8, wpb=8181.8, bsz=292.7, num_updates=35300, lr=7.5271e-05, gnorm=0.591, clip=0, loss_scale=32, train_wall=55, gb_free=16.2, wall=24835
2023-08-03 00:58:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:3')
2023-08-03 00:58:48 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.355 | trans_loss 5.58 | nll_loss 2.856 | w2v_ctc_loss 1.377 | task_loss 0 | contrastive_loss 0.264 | total 4003.4 | n_correct 2476.3 | ppl 7.24 | accuracy 61.855 | uer 16.954 | wer 18.84 | raw_wer 18.84 | bleu 19.9 | wps 2358.4 | wpb 4003.4 | bsz 141.8 | num_updates 35361 | best_bleu 20.4
2023-08-03 00:58:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35361 updates
2023-08-03 00:58:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_last.pt
2023-08-03 00:59:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_last.pt
2023-08-03 00:59:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_last.pt (epoch 24 @ 35361 updates, score 19.9) (writing took 12.104451104998589 seconds)
2023-08-03 00:59:00 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-03 00:59:00 | INFO | train | epoch 024 | loss 2.069 | trans_loss 4.991 | nll_loss 2.182 | w2v_ctc_loss 0.667 | task_loss 0 | contrastive_loss 0.106 | total 4136.37 | n_correct 2680.92 | ppl 4.54 | accuracy 64.813 | wps 13349.3 | ups 1.61 | wpb 8272.7 | bsz 304.8 | num_updates 35361 | lr 7.5206e-05 | gnorm 0.585 | clip 0 | loss_scale 32 | train_wall 818 | gb_free 16.4 | wall 24904
2023-08-03 00:59:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 00:59:01 | INFO | fairseq.trainer | begin training epoch 25
2023-08-03 00:59:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 00:59:29 | INFO | train_inner | epoch 025:     39 / 1474 loss=2.058, trans_loss=4.981, nll_loss=2.169, w2v_ctc_loss=0.658, task_loss=0, contrastive_loss=0.071, total=4166.95, n_correct=2714.42, ppl=4.5, accuracy=65.142, wps=8539.6, ups=1.02, wpb=8333.9, bsz=312, num_updates=35400, lr=7.51646e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=56, gb_free=16.8, wall=24933
2023-08-03 01:00:26 | INFO | train_inner | epoch 025:    139 / 1474 loss=2.05, trans_loss=4.963, nll_loss=2.145, w2v_ctc_loss=0.653, task_loss=0, contrastive_loss=0.07, total=4133.64, n_correct=2703.94, ppl=4.42, accuracy=65.413, wps=14694.6, ups=1.78, wpb=8267.3, bsz=307.7, num_updates=35500, lr=7.50587e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=56, gb_free=16.1, wall=24989
2023-08-03 01:01:22 | INFO | train_inner | epoch 025:    239 / 1474 loss=2.054, trans_loss=4.968, nll_loss=2.152, w2v_ctc_loss=0.658, task_loss=0, contrastive_loss=0.074, total=4114.53, n_correct=2686.78, ppl=4.45, accuracy=65.3, wps=14661.8, ups=1.78, wpb=8229.1, bsz=302.7, num_updates=35600, lr=7.49532e-05, gnorm=0.585, clip=0, loss_scale=32, train_wall=55, gb_free=17.3, wall=25045
2023-08-03 01:02:18 | INFO | train_inner | epoch 025:    339 / 1474 loss=2.06, trans_loss=4.974, nll_loss=2.158, w2v_ctc_loss=0.659, task_loss=0, contrastive_loss=0.102, total=4148.7, n_correct=2695.51, ppl=4.46, accuracy=64.972, wps=14671.9, ups=1.77, wpb=8297.4, bsz=295.1, num_updates=35700, lr=7.48481e-05, gnorm=0.591, clip=0, loss_scale=32, train_wall=56, gb_free=16.5, wall=25102
2023-08-03 01:03:15 | INFO | train_inner | epoch 025:    439 / 1474 loss=2.074, trans_loss=4.98, nll_loss=2.166, w2v_ctc_loss=0.673, task_loss=0, contrastive_loss=0.181, total=4167.03, n_correct=2706.09, ppl=4.49, accuracy=64.94, wps=14720.9, ups=1.77, wpb=8334.1, bsz=298.3, num_updates=35800, lr=7.47435e-05, gnorm=0.593, clip=0, loss_scale=32, train_wall=56, gb_free=12.8, wall=25159
2023-08-03 01:04:11 | INFO | train_inner | epoch 025:    539 / 1474 loss=2.063, trans_loss=4.984, nll_loss=2.173, w2v_ctc_loss=0.663, task_loss=0, contrastive_loss=0.074, total=4156.93, n_correct=2701.57, ppl=4.51, accuracy=64.99, wps=14786.5, ups=1.78, wpb=8313.9, bsz=312.8, num_updates=35900, lr=7.46393e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=56, gb_free=17.2, wall=25215
2023-08-03 01:05:07 | INFO | train_inner | epoch 025:    639 / 1474 loss=2.066, trans_loss=4.977, nll_loss=2.164, w2v_ctc_loss=0.666, task_loss=0, contrastive_loss=0.141, total=4153.23, n_correct=2700.06, ppl=4.48, accuracy=65.011, wps=14952.6, ups=1.8, wpb=8306.5, bsz=309.6, num_updates=36000, lr=7.45356e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=55, gb_free=15.2, wall=25270
2023-08-03 01:05:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 01:05:30 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.349 | trans_loss 5.577 | nll_loss 2.853 | w2v_ctc_loss 1.37 | task_loss 0 | contrastive_loss 0.256 | total 4003.4 | n_correct 2482 | ppl 7.23 | accuracy 61.997 | uer 17.002 | wer 18.903 | raw_wer 18.903 | bleu 19.9 | wps 2283.7 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.4
2023-08-03 01:05:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-08-03 01:05:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_25_36000.pt
2023-08-03 01:05:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_25_36000.pt
2023-08-03 01:05:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 19.9) (writing took 13.219395032152534 seconds)
2023-08-03 01:06:39 | INFO | train_inner | epoch 025:    739 / 1474 loss=2.067, trans_loss=4.982, nll_loss=2.17, w2v_ctc_loss=0.663, task_loss=0, contrastive_loss=0.136, total=4123.21, n_correct=2678.67, ppl=4.5, accuracy=64.966, wps=8966.4, ups=1.09, wpb=8246.4, bsz=300.7, num_updates=36100, lr=7.44323e-05, gnorm=0.594, clip=0, loss_scale=64, train_wall=55, gb_free=15.1, wall=25362
2023-08-03 01:07:35 | INFO | train_inner | epoch 025:    839 / 1474 loss=2.06, trans_loss=4.982, nll_loss=2.172, w2v_ctc_loss=0.657, task_loss=0, contrastive_loss=0.084, total=4197.27, n_correct=2731.12, ppl=4.51, accuracy=65.069, wps=14975.3, ups=1.78, wpb=8394.5, bsz=328.2, num_updates=36200, lr=7.43294e-05, gnorm=0.585, clip=0, loss_scale=64, train_wall=56, gb_free=16.4, wall=25418
2023-08-03 01:08:31 | INFO | train_inner | epoch 025:    939 / 1474 loss=2.067, trans_loss=4.987, nll_loss=2.179, w2v_ctc_loss=0.663, task_loss=0, contrastive_loss=0.14, total=4137.23, n_correct=2685.43, ppl=4.53, accuracy=64.909, wps=14780.5, ups=1.79, wpb=8274.5, bsz=313.3, num_updates=36300, lr=7.4227e-05, gnorm=0.59, clip=0, loss_scale=64, train_wall=55, gb_free=16.8, wall=25474
2023-08-03 01:09:27 | INFO | train_inner | epoch 025:   1039 / 1474 loss=2.074, trans_loss=4.994, nll_loss=2.187, w2v_ctc_loss=0.654, task_loss=0, contrastive_loss=0.252, total=4183.45, n_correct=2710.09, ppl=4.55, accuracy=64.781, wps=14893.7, ups=1.78, wpb=8366.9, bsz=311, num_updates=36400, lr=7.41249e-05, gnorm=0.584, clip=0, loss_scale=64, train_wall=56, gb_free=16.9, wall=25530
2023-08-03 01:10:22 | INFO | train_inner | epoch 025:   1139 / 1474 loss=2.057, trans_loss=4.988, nll_loss=2.177, w2v_ctc_loss=0.653, task_loss=0, contrastive_loss=0.054, total=4045.24, n_correct=2625.99, ppl=4.52, accuracy=64.916, wps=14605.9, ups=1.81, wpb=8090.5, bsz=287, num_updates=36500, lr=7.40233e-05, gnorm=0.593, clip=0, loss_scale=64, train_wall=55, gb_free=16.7, wall=25586
2023-08-03 01:11:18 | INFO | train_inner | epoch 025:   1239 / 1474 loss=2.061, trans_loss=4.994, nll_loss=2.186, w2v_ctc_loss=0.659, task_loss=0, contrastive_loss=0.057, total=4079.17, n_correct=2644.5, ppl=4.55, accuracy=64.829, wps=14641.8, ups=1.79, wpb=8158.3, bsz=292.3, num_updates=36600, lr=7.39221e-05, gnorm=0.597, clip=0, loss_scale=64, train_wall=55, gb_free=17.2, wall=25642
2023-08-03 01:12:14 | INFO | train_inner | epoch 025:   1339 / 1474 loss=2.072, trans_loss=4.992, nll_loss=2.184, w2v_ctc_loss=0.665, task_loss=0, contrastive_loss=0.163, total=4173.55, n_correct=2706.39, ppl=4.54, accuracy=64.846, wps=15001.8, ups=1.8, wpb=8347.1, bsz=312.7, num_updates=36700, lr=7.38213e-05, gnorm=0.596, clip=0, loss_scale=64, train_wall=55, gb_free=17, wall=25697
2023-08-03 01:13:10 | INFO | train_inner | epoch 025:   1439 / 1474 loss=2.075, trans_loss=5.007, nll_loss=2.203, w2v_ctc_loss=0.666, task_loss=0, contrastive_loss=0.11, total=4102.27, n_correct=2648, ppl=4.6, accuracy=64.55, wps=14559.4, ups=1.77, wpb=8204.5, bsz=299.9, num_updates=36800, lr=7.3721e-05, gnorm=0.593, clip=0, loss_scale=64, train_wall=56, gb_free=16.1, wall=25754
2023-08-03 01:13:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 01:13:52 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.349 | trans_loss 5.574 | nll_loss 2.851 | w2v_ctc_loss 1.371 | task_loss 0 | contrastive_loss 0.264 | total 4003.4 | n_correct 2480.8 | ppl 7.21 | accuracy 61.967 | uer 16.882 | wer 18.791 | raw_wer 18.791 | bleu 20.34 | wps 2259.1 | wpb 4003.4 | bsz 141.8 | num_updates 36835 | best_bleu 20.4
2023-08-03 01:13:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36835 updates
2023-08-03 01:13:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.3401.pt
2023-08-03 01:13:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.3401.pt
2023-08-03 01:14:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.3401.pt (epoch 25 @ 36835 updates, score 20.34) (writing took 16.900110507383943 seconds)
2023-08-03 01:14:10 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-03 01:14:10 | INFO | train | epoch 025 | loss 2.064 | trans_loss 4.984 | nll_loss 2.172 | w2v_ctc_loss 0.661 | task_loss 0 | contrastive_loss 0.116 | total 4138.65 | n_correct 2689.11 | ppl 4.51 | accuracy 64.976 | wps 13417.3 | ups 1.62 | wpb 8277.3 | bsz 305.7 | num_updates 36835 | lr 7.36859e-05 | gnorm 0.589 | clip 0 | loss_scale 64 | train_wall 818 | gb_free 14.7 | wall 25813
2023-08-03 01:14:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 01:14:10 | INFO | fairseq.trainer | begin training epoch 26
2023-08-03 01:14:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 01:14:54 | INFO | train_inner | epoch 026:     65 / 1474 loss=2.051, trans_loss=4.963, nll_loss=2.146, w2v_ctc_loss=0.649, task_loss=0, contrastive_loss=0.096, total=4178.19, n_correct=2734.65, ppl=4.43, accuracy=65.451, wps=8045.8, ups=0.96, wpb=8356.4, bsz=317.5, num_updates=36900, lr=7.3621e-05, gnorm=0.583, clip=0, loss_scale=64, train_wall=55, gb_free=14.7, wall=25857
2023-08-03 01:15:50 | INFO | train_inner | epoch 026:    165 / 1474 loss=2.059, trans_loss=4.958, nll_loss=2.14, w2v_ctc_loss=0.64, task_loss=0, contrastive_loss=0.279, total=4269.55, n_correct=2799.48, ppl=4.41, accuracy=65.569, wps=15151.7, ups=1.77, wpb=8539.1, bsz=341.4, num_updates=37000, lr=7.35215e-05, gnorm=0.577, clip=0, loss_scale=64, train_wall=56, gb_free=15.7, wall=25914
2023-08-03 01:16:47 | INFO | train_inner | epoch 026:    265 / 1474 loss=2.059, trans_loss=4.962, nll_loss=2.145, w2v_ctc_loss=0.66, task_loss=0, contrastive_loss=0.155, total=4128.39, n_correct=2697.51, ppl=4.42, accuracy=65.34, wps=14661.4, ups=1.78, wpb=8256.8, bsz=306.8, num_updates=37100, lr=7.34223e-05, gnorm=0.594, clip=0, loss_scale=64, train_wall=56, gb_free=10.7, wall=25970
2023-08-03 01:17:42 | INFO | train_inner | epoch 026:    365 / 1474 loss=2.056, trans_loss=4.966, nll_loss=2.15, w2v_ctc_loss=0.658, task_loss=0, contrastive_loss=0.114, total=4166.22, n_correct=2722.19, ppl=4.44, accuracy=65.34, wps=14949.7, ups=1.79, wpb=8332.4, bsz=315, num_updates=37200, lr=7.33236e-05, gnorm=0.59, clip=0, loss_scale=64, train_wall=55, gb_free=16.9, wall=26026
2023-08-03 01:18:38 | INFO | train_inner | epoch 026:    465 / 1474 loss=2.054, trans_loss=4.959, nll_loss=2.141, w2v_ctc_loss=0.651, task_loss=0, contrastive_loss=0.157, total=4171.18, n_correct=2733.71, ppl=4.41, accuracy=65.538, wps=14927.7, ups=1.79, wpb=8342.4, bsz=315.5, num_updates=37300, lr=7.32252e-05, gnorm=0.582, clip=0, loss_scale=64, train_wall=55, gb_free=16.7, wall=26082
2023-08-03 01:19:34 | INFO | train_inner | epoch 026:    565 / 1474 loss=2.06, trans_loss=4.976, nll_loss=2.162, w2v_ctc_loss=0.668, task_loss=0, contrastive_loss=0.075, total=4139.82, n_correct=2696.87, ppl=4.48, accuracy=65.145, wps=14750.7, ups=1.78, wpb=8279.6, bsz=300, num_updates=37400, lr=7.31272e-05, gnorm=0.594, clip=0, loss_scale=64, train_wall=55, gb_free=15.5, wall=26138
2023-08-03 01:20:31 | INFO | train_inner | epoch 026:    665 / 1474 loss=2.05, trans_loss=4.971, nll_loss=2.155, w2v_ctc_loss=0.651, task_loss=0, contrastive_loss=0.064, total=4146.72, n_correct=2706.22, ppl=4.46, accuracy=65.262, wps=14758.8, ups=1.78, wpb=8293.4, bsz=302.7, num_updates=37500, lr=7.30297e-05, gnorm=0.592, clip=0, loss_scale=64, train_wall=56, gb_free=17.1, wall=26194
2023-08-03 01:21:27 | INFO | train_inner | epoch 026:    765 / 1474 loss=2.064, trans_loss=4.98, nll_loss=2.168, w2v_ctc_loss=0.654, task_loss=0, contrastive_loss=0.175, total=4084.89, n_correct=2657.3, ppl=4.49, accuracy=65.052, wps=14617.3, ups=1.79, wpb=8169.8, bsz=297.2, num_updates=37600, lr=7.29325e-05, gnorm=0.595, clip=0, loss_scale=64, train_wall=55, gb_free=17.5, wall=26250
2023-08-03 01:22:23 | INFO | train_inner | epoch 026:    865 / 1474 loss=2.057, trans_loss=4.973, nll_loss=2.159, w2v_ctc_loss=0.659, task_loss=0, contrastive_loss=0.078, total=4180.78, n_correct=2724.73, ppl=4.46, accuracy=65.173, wps=14920.8, ups=1.78, wpb=8361.6, bsz=309.6, num_updates=37700, lr=7.28357e-05, gnorm=0.58, clip=0, loss_scale=64, train_wall=55, gb_free=16.2, wall=26306
2023-08-03 01:23:19 | INFO | train_inner | epoch 026:    965 / 1474 loss=2.061, trans_loss=4.987, nll_loss=2.177, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.129, total=4147.79, n_correct=2694.22, ppl=4.52, accuracy=64.956, wps=14782.2, ups=1.78, wpb=8295.6, bsz=299.5, num_updates=37800, lr=7.27393e-05, gnorm=0.583, clip=0, loss_scale=64, train_wall=55, gb_free=13, wall=26362
2023-08-03 01:24:15 | INFO | train_inner | epoch 026:   1065 / 1474 loss=2.054, trans_loss=4.98, nll_loss=2.168, w2v_ctc_loss=0.656, task_loss=0, contrastive_loss=0.06, total=4118.07, n_correct=2686.56, ppl=4.49, accuracy=65.238, wps=14709.5, ups=1.79, wpb=8236.1, bsz=293.6, num_updates=37900, lr=7.26433e-05, gnorm=0.586, clip=0, loss_scale=64, train_wall=55, gb_free=16.1, wall=26418
2023-08-03 01:25:11 | INFO | train_inner | epoch 026:   1165 / 1474 loss=2.063, trans_loss=4.99, nll_loss=2.181, w2v_ctc_loss=0.658, task_loss=0, contrastive_loss=0.1, total=4108.48, n_correct=2668.72, ppl=4.53, accuracy=64.956, wps=14492.6, ups=1.76, wpb=8217, bsz=297.9, num_updates=38000, lr=7.25476e-05, gnorm=0.593, clip=0, loss_scale=64, train_wall=56, gb_free=16.5, wall=26475
2023-08-03 01:25:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 01:25:36 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.371 | trans_loss 5.582 | nll_loss 2.859 | w2v_ctc_loss 1.427 | task_loss 0 | contrastive_loss 0.263 | total 4003.4 | n_correct 2478.4 | ppl 7.26 | accuracy 61.907 | uer 17.007 | wer 18.922 | raw_wer 18.922 | bleu 19.98 | wps 2018.3 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.4
2023-08-03 01:25:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-08-03 01:25:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_26_38000.pt
2023-08-03 01:25:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_26_38000.pt
2023-08-03 01:25:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 19.98) (writing took 16.535175643861294 seconds)
2023-08-03 01:26:49 | INFO | train_inner | epoch 026:   1265 / 1474 loss=2.069, trans_loss=5.001, nll_loss=2.195, w2v_ctc_loss=0.672, task_loss=0, contrastive_loss=0.063, total=4005.94, n_correct=2585.67, ppl=4.58, accuracy=64.546, wps=8193.1, ups=1.02, wpb=8011.9, bsz=280.6, num_updates=38100, lr=7.24524e-05, gnorm=0.601, clip=0, loss_scale=64, train_wall=55, gb_free=16.7, wall=26573
2023-08-03 01:27:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-03 01:27:46 | INFO | train_inner | epoch 026:   1366 / 1474 loss=2.057, trans_loss=4.987, nll_loss=2.177, w2v_ctc_loss=0.65, task_loss=0, contrastive_loss=0.079, total=4148.47, n_correct=2699.56, ppl=4.52, accuracy=65.074, wps=14518.7, ups=1.75, wpb=8296.9, bsz=309.3, num_updates=38200, lr=7.23575e-05, gnorm=0.592, clip=0, loss_scale=64, train_wall=56, gb_free=17.5, wall=26630
2023-08-03 01:28:42 | INFO | train_inner | epoch 026:   1466 / 1474 loss=2.053, trans_loss=4.983, nll_loss=2.174, w2v_ctc_loss=0.646, task_loss=0, contrastive_loss=0.072, total=4165.66, n_correct=2717.66, ppl=4.51, accuracy=65.24, wps=14872.6, ups=1.79, wpb=8331.3, bsz=317.5, num_updates=38300, lr=7.22629e-05, gnorm=0.591, clip=0, loss_scale=64, train_wall=55, gb_free=16.5, wall=26686
2023-08-03 01:28:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 01:29:09 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.355 | trans_loss 5.581 | nll_loss 2.857 | w2v_ctc_loss 1.378 | task_loss 0 | contrastive_loss 0.258 | total 4003.4 | n_correct 2479.4 | ppl 7.25 | accuracy 61.932 | uer 16.856 | wer 18.545 | raw_wer 18.545 | bleu 19.63 | wps 2394.3 | wpb 4003.4 | bsz 141.8 | num_updates 38308 | best_bleu 20.4
2023-08-03 01:29:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38308 updates
2023-08-03 01:29:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_last.pt
2023-08-03 01:29:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_last.pt
2023-08-03 01:29:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_last.pt (epoch 26 @ 38308 updates, score 19.63) (writing took 12.764002343639731 seconds)
2023-08-03 01:29:21 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-03 01:29:21 | INFO | train | epoch 026 | loss 2.058 | trans_loss 4.975 | nll_loss 2.162 | w2v_ctc_loss 0.655 | task_loss 0 | contrastive_loss 0.114 | total 4138.45 | n_correct 2698.33 | ppl 4.47 | accuracy 65.201 | wps 13374.7 | ups 1.62 | wpb 8276.9 | bsz 305.6 | num_updates 38308 | lr 7.22554e-05 | gnorm 0.589 | clip 0 | loss_scale 64 | train_wall 818 | gb_free 16.2 | wall 26725
2023-08-03 01:29:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 01:29:22 | INFO | fairseq.trainer | begin training epoch 27
2023-08-03 01:29:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 01:30:20 | INFO | train_inner | epoch 027:     92 / 1474 loss=2.032, trans_loss=4.94, nll_loss=2.114, w2v_ctc_loss=0.638, task_loss=0, contrastive_loss=0.05, total=4054.57, n_correct=2669.93, ppl=4.33, accuracy=65.85, wps=8344.9, ups=1.03, wpb=8109.1, bsz=282.4, num_updates=38400, lr=7.21688e-05, gnorm=0.598, clip=0, loss_scale=64, train_wall=55, gb_free=16.5, wall=26783
2023-08-03 01:31:16 | INFO | train_inner | epoch 027:    192 / 1474 loss=2.041, trans_loss=4.945, nll_loss=2.123, w2v_ctc_loss=0.649, task_loss=0, contrastive_loss=0.083, total=4195.2, n_correct=2761.89, ppl=4.35, accuracy=65.835, wps=14994.4, ups=1.79, wpb=8390.4, bsz=323.2, num_updates=38500, lr=7.2075e-05, gnorm=0.582, clip=0, loss_scale=64, train_wall=55, gb_free=17.4, wall=26839
2023-08-03 01:32:12 | INFO | train_inner | epoch 027:    292 / 1474 loss=2.042, trans_loss=4.953, nll_loss=2.132, w2v_ctc_loss=0.648, task_loss=0, contrastive_loss=0.063, total=4162.23, n_correct=2735.63, ppl=4.38, accuracy=65.725, wps=14755.1, ups=1.77, wpb=8324.5, bsz=305.5, num_updates=38600, lr=7.19816e-05, gnorm=0.583, clip=0, loss_scale=64, train_wall=56, gb_free=17.4, wall=26895
2023-08-03 01:33:09 | INFO | train_inner | epoch 027:    392 / 1474 loss=2.058, trans_loss=4.963, nll_loss=2.145, w2v_ctc_loss=0.644, task_loss=0, contrastive_loss=0.247, total=4079.05, n_correct=2668.64, ppl=4.42, accuracy=65.423, wps=14344.1, ups=1.76, wpb=8158.1, bsz=297.1, num_updates=38700, lr=7.18885e-05, gnorm=0.595, clip=0, loss_scale=64, train_wall=56, gb_free=17.1, wall=26952
2023-08-03 01:34:05 | INFO | train_inner | epoch 027:    492 / 1474 loss=2.059, trans_loss=4.969, nll_loss=2.154, w2v_ctc_loss=0.648, task_loss=0, contrastive_loss=0.187, total=4243.25, n_correct=2773.76, ppl=4.45, accuracy=65.369, wps=14993.4, ups=1.77, wpb=8486.5, bsz=331, num_updates=38800, lr=7.17958e-05, gnorm=0.581, clip=0, loss_scale=64, train_wall=56, gb_free=16.1, wall=27009
2023-08-03 01:35:01 | INFO | train_inner | epoch 027:    592 / 1474 loss=2.054, trans_loss=4.963, nll_loss=2.147, w2v_ctc_loss=0.653, task_loss=0, contrastive_loss=0.124, total=4137.92, n_correct=2706.44, ppl=4.43, accuracy=65.406, wps=14825.1, ups=1.79, wpb=8275.8, bsz=313.5, num_updates=38900, lr=7.17035e-05, gnorm=0.591, clip=0, loss_scale=64, train_wall=55, gb_free=16.2, wall=27065
2023-08-03 01:35:58 | INFO | train_inner | epoch 027:    692 / 1474 loss=2.055, trans_loss=4.971, nll_loss=2.156, w2v_ctc_loss=0.654, task_loss=0, contrastive_loss=0.102, total=4158.48, n_correct=2715.61, ppl=4.46, accuracy=65.303, wps=14749, ups=1.77, wpb=8317, bsz=304.1, num_updates=39000, lr=7.16115e-05, gnorm=0.588, clip=0, loss_scale=64, train_wall=56, gb_free=15.9, wall=27121
2023-08-03 01:36:53 | INFO | train_inner | epoch 027:    792 / 1474 loss=2.052, trans_loss=4.971, nll_loss=2.156, w2v_ctc_loss=0.655, task_loss=0, contrastive_loss=0.063, total=4100.88, n_correct=2674.47, ppl=4.46, accuracy=65.217, wps=14746.1, ups=1.8, wpb=8201.8, bsz=292.2, num_updates=39100, lr=7.15199e-05, gnorm=0.597, clip=0, loss_scale=64, train_wall=55, gb_free=16.1, wall=27177
2023-08-03 01:37:49 | INFO | train_inner | epoch 027:    892 / 1474 loss=2.047, trans_loss=4.975, nll_loss=2.161, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.055, total=4111.94, n_correct=2687.64, ppl=4.47, accuracy=65.362, wps=14786.2, ups=1.8, wpb=8223.9, bsz=294.9, num_updates=39200, lr=7.14286e-05, gnorm=0.595, clip=0, loss_scale=64, train_wall=55, gb_free=16.3, wall=27232
2023-08-03 01:38:45 | INFO | train_inner | epoch 027:    992 / 1474 loss=2.06, trans_loss=4.971, nll_loss=2.157, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.244, total=4189.27, n_correct=2736.27, ppl=4.46, accuracy=65.316, wps=14940.6, ups=1.78, wpb=8378.5, bsz=314.9, num_updates=39300, lr=7.13376e-05, gnorm=0.581, clip=0, loss_scale=64, train_wall=55, gb_free=14.7, wall=27288
2023-08-03 01:39:41 | INFO | train_inner | epoch 027:   1092 / 1474 loss=2.044, trans_loss=4.967, nll_loss=2.151, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.075, total=4160.42, n_correct=2722.94, ppl=4.44, accuracy=65.449, wps=14925.9, ups=1.79, wpb=8320.8, bsz=307.3, num_updates=39400, lr=7.1247e-05, gnorm=0.586, clip=0, loss_scale=64, train_wall=55, gb_free=17.2, wall=27344
2023-08-03 01:40:37 | INFO | train_inner | epoch 027:   1192 / 1474 loss=2.058, trans_loss=4.978, nll_loss=2.167, w2v_ctc_loss=0.661, task_loss=0, contrastive_loss=0.079, total=4103.72, n_correct=2673.43, ppl=4.49, accuracy=65.147, wps=14667, ups=1.79, wpb=8207.4, bsz=297.1, num_updates=39500, lr=7.11568e-05, gnorm=0.596, clip=0, loss_scale=64, train_wall=55, gb_free=17.9, wall=27400
2023-08-03 01:41:32 | INFO | train_inner | epoch 027:   1292 / 1474 loss=2.063, trans_loss=4.985, nll_loss=2.174, w2v_ctc_loss=0.655, task_loss=0, contrastive_loss=0.128, total=4065.94, n_correct=2643.88, ppl=4.51, accuracy=65.025, wps=14599.6, ups=1.8, wpb=8131.9, bsz=292.4, num_updates=39600, lr=7.10669e-05, gnorm=0.603, clip=0, loss_scale=64, train_wall=55, gb_free=16.4, wall=27456
2023-08-03 01:42:28 | INFO | train_inner | epoch 027:   1392 / 1474 loss=2.051, trans_loss=4.976, nll_loss=2.164, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.112, total=4149.21, n_correct=2709.34, ppl=4.48, accuracy=65.298, wps=14931, ups=1.8, wpb=8298.4, bsz=312.6, num_updates=39700, lr=7.09773e-05, gnorm=0.592, clip=0, loss_scale=64, train_wall=55, gb_free=17.1, wall=27511
2023-08-03 01:43:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 01:43:36 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.362 | trans_loss 5.573 | nll_loss 2.849 | w2v_ctc_loss 1.422 | task_loss 0 | contrastive_loss 0.257 | total 4003.4 | n_correct 2477.3 | ppl 7.2 | accuracy 61.88 | uer 16.864 | wer 18.765 | raw_wer 18.765 | bleu 19.98 | wps 2343.8 | wpb 4003.4 | bsz 141.8 | num_updates 39782 | best_bleu 20.4
2023-08-03 01:43:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39782 updates
2023-08-03 01:43:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_last.pt
2023-08-03 01:43:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_last.pt
2023-08-03 01:43:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_last.pt (epoch 27 @ 39782 updates, score 19.98) (writing took 12.626345723867416 seconds)
2023-08-03 01:43:49 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-03 01:43:49 | INFO | train | epoch 027 | loss 2.051 | trans_loss 4.966 | nll_loss 2.15 | w2v_ctc_loss 0.648 | task_loss 0 | contrastive_loss 0.114 | total 4138.65 | n_correct 2707.31 | ppl 4.44 | accuracy 65.415 | wps 14064.8 | ups 1.7 | wpb 8277.3 | bsz 305.7 | num_updates 39782 | lr 7.09042e-05 | gnorm 0.591 | clip 0 | loss_scale 64 | train_wall 817 | gb_free 18.1 | wall 27592
2023-08-03 01:43:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 01:43:49 | INFO | fairseq.trainer | begin training epoch 28
2023-08-03 01:43:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 01:44:06 | INFO | train_inner | epoch 028:     18 / 1474 loss=2.043, trans_loss=4.966, nll_loss=2.15, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.064, total=4106.72, n_correct=2691.51, ppl=4.44, accuracy=65.539, wps=8388.6, ups=1.02, wpb=8213.4, bsz=305, num_updates=39800, lr=7.08881e-05, gnorm=0.599, clip=0, loss_scale=64, train_wall=56, gb_free=16.3, wall=27609
2023-08-03 01:45:01 | INFO | train_inner | epoch 028:    118 / 1474 loss=2.032, trans_loss=4.937, nll_loss=2.111, w2v_ctc_loss=0.638, task_loss=0, contrastive_loss=0.059, total=4103.42, n_correct=2706.6, ppl=4.32, accuracy=65.96, wps=14768.2, ups=1.8, wpb=8206.8, bsz=292, num_updates=39900, lr=7.07992e-05, gnorm=0.593, clip=0, loss_scale=64, train_wall=55, gb_free=16.4, wall=27665
2023-08-03 01:45:57 | INFO | train_inner | epoch 028:    218 / 1474 loss=2.032, trans_loss=4.941, nll_loss=2.117, w2v_ctc_loss=0.634, task_loss=0, contrastive_loss=0.067, total=4200.12, n_correct=2769.6, ppl=4.34, accuracy=65.941, wps=15088, ups=1.8, wpb=8400.2, bsz=317.8, num_updates=40000, lr=7.07107e-05, gnorm=0.58, clip=0, loss_scale=64, train_wall=55, gb_free=11.6, wall=27721
2023-08-03 01:45:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 01:46:19 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.364 | trans_loss 5.586 | nll_loss 2.865 | w2v_ctc_loss 1.394 | task_loss 0 | contrastive_loss 0.264 | total 4003.4 | n_correct 2476.7 | ppl 7.28 | accuracy 61.865 | uer 16.914 | wer 18.784 | raw_wer 18.784 | bleu 20.06 | wps 2414.8 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.4
2023-08-03 01:46:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-08-03 01:46:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_28_40000.pt
2023-08-03 01:46:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_28_40000.pt
2023-08-03 01:46:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 20.06) (writing took 39.96300202049315 seconds)
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:0')
2023-08-03 01:48:00 | INFO | train_inner | epoch 028:    318 / 1474 loss=2.064, trans_loss=4.955, nll_loss=2.136, w2v_ctc_loss=0.634, task_loss=0, contrastive_loss=0.401, total=4147.36, n_correct=2712.83, ppl=4.39, accuracy=65.411, wps=6758.1, ups=0.81, wpb=8294.7, bsz=315.4, num_updates=40100, lr=7.06225e-05, gnorm=0.595, clip=0, loss_scale=64, train_wall=56, gb_free=17, wall=27843
2023-08-03 01:48:56 | INFO | train_inner | epoch 028:    418 / 1474 loss=2.039, trans_loss=4.952, nll_loss=2.131, w2v_ctc_loss=0.644, task_loss=0, contrastive_loss=0.054, total=4087.34, n_correct=2686.98, ppl=4.38, accuracy=65.739, wps=14575.1, ups=1.78, wpb=8174.7, bsz=295.1, num_updates=40200, lr=7.05346e-05, gnorm=0.592, clip=0, loss_scale=128, train_wall=56, gb_free=17.1, wall=27899
2023-08-03 01:49:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-03 01:49:52 | INFO | train_inner | epoch 028:    519 / 1474 loss=2.041, trans_loss=4.956, nll_loss=2.137, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.068, total=4100.53, n_correct=2689.53, ppl=4.4, accuracy=65.59, wps=14647.1, ups=1.79, wpb=8201.1, bsz=296.1, num_updates=40300, lr=7.0447e-05, gnorm=0.595, clip=0, loss_scale=64, train_wall=55, gb_free=16.3, wall=27955
2023-08-03 01:50:48 | INFO | train_inner | epoch 028:    619 / 1474 loss=2.045, trans_loss=4.965, nll_loss=2.148, w2v_ctc_loss=0.644, task_loss=0, contrastive_loss=0.068, total=4178.12, n_correct=2736.24, ppl=4.43, accuracy=65.49, wps=14968.4, ups=1.79, wpb=8356.2, bsz=305.3, num_updates=40400, lr=7.03598e-05, gnorm=0.585, clip=0, loss_scale=64, train_wall=55, gb_free=16, wall=28011
2023-08-03 01:51:44 | INFO | train_inner | epoch 028:    719 / 1474 loss=2.051, trans_loss=4.961, nll_loss=2.145, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.181, total=4185.82, n_correct=2747.64, ppl=4.42, accuracy=65.642, wps=14893.5, ups=1.78, wpb=8371.6, bsz=326.4, num_updates=40500, lr=7.02728e-05, gnorm=0.588, clip=0, loss_scale=64, train_wall=56, gb_free=16.3, wall=28067
2023-08-03 01:52:40 | INFO | train_inner | epoch 028:    819 / 1474 loss=2.039, trans_loss=4.958, nll_loss=2.14, w2v_ctc_loss=0.64, task_loss=0, contrastive_loss=0.059, total=4096.2, n_correct=2691.41, ppl=4.41, accuracy=65.705, wps=14669.7, ups=1.79, wpb=8192.4, bsz=307, num_updates=40600, lr=7.01862e-05, gnorm=0.595, clip=0, loss_scale=64, train_wall=55, gb_free=16.1, wall=28123
2023-08-03 01:53:36 | INFO | train_inner | epoch 028:    919 / 1474 loss=2.054, trans_loss=4.971, nll_loss=2.156, w2v_ctc_loss=0.65, task_loss=0, contrastive_loss=0.123, total=4120.27, n_correct=2689.81, ppl=4.46, accuracy=65.282, wps=14686.2, ups=1.78, wpb=8240.5, bsz=300.8, num_updates=40700, lr=7.01e-05, gnorm=0.599, clip=0, loss_scale=64, train_wall=55, gb_free=17.7, wall=28179
2023-08-03 01:54:32 | INFO | train_inner | epoch 028:   1019 / 1474 loss=2.058, trans_loss=4.968, nll_loss=2.154, w2v_ctc_loss=0.651, task_loss=0, contrastive_loss=0.176, total=4177.86, n_correct=2728.85, ppl=4.45, accuracy=65.317, wps=14964.2, ups=1.79, wpb=8355.7, bsz=311.1, num_updates=40800, lr=7.0014e-05, gnorm=0.596, clip=0, loss_scale=64, train_wall=55, gb_free=16.7, wall=28235
2023-08-03 01:55:28 | INFO | train_inner | epoch 028:   1119 / 1474 loss=2.042, trans_loss=4.958, nll_loss=2.141, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.081, total=4210.86, n_correct=2761.59, ppl=4.41, accuracy=65.583, wps=14935.3, ups=1.77, wpb=8421.7, bsz=318.9, num_updates=40900, lr=6.99284e-05, gnorm=0.586, clip=0, loss_scale=64, train_wall=56, gb_free=17.8, wall=28292
2023-08-03 01:56:24 | INFO | train_inner | epoch 028:   1219 / 1474 loss=2.044, trans_loss=4.967, nll_loss=2.153, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.068, total=4104.61, n_correct=2688.8, ppl=4.45, accuracy=65.507, wps=14691.2, ups=1.79, wpb=8209.2, bsz=305.6, num_updates=41000, lr=6.9843e-05, gnorm=0.596, clip=0, loss_scale=64, train_wall=55, gb_free=16.8, wall=28348
2023-08-03 01:57:20 | INFO | train_inner | epoch 028:   1319 / 1474 loss=2.055, trans_loss=4.976, nll_loss=2.162, w2v_ctc_loss=0.658, task_loss=0, contrastive_loss=0.082, total=4087.78, n_correct=2667.78, ppl=4.47, accuracy=65.262, wps=14589.2, ups=1.78, wpb=8175.6, bsz=285.1, num_updates=41100, lr=6.9758e-05, gnorm=0.601, clip=0, loss_scale=64, train_wall=55, gb_free=15.4, wall=28404
2023-08-03 01:58:16 | INFO | train_inner | epoch 028:   1419 / 1474 loss=2.05, trans_loss=4.972, nll_loss=2.158, w2v_ctc_loss=0.644, task_loss=0, contrastive_loss=0.101, total=4145.03, n_correct=2709.07, ppl=4.46, accuracy=65.357, wps=14802.6, ups=1.79, wpb=8290.1, bsz=297.6, num_updates=41200, lr=6.96733e-05, gnorm=0.585, clip=0, loss_scale=64, train_wall=55, gb_free=17.9, wall=28460
2023-08-03 01:58:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:2')
2023-08-03 01:59:10 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.367 | trans_loss 5.583 | nll_loss 2.861 | w2v_ctc_loss 1.411 | task_loss 0 | contrastive_loss 0.26 | total 4003.4 | n_correct 2479.8 | ppl 7.27 | accuracy 61.942 | uer 16.956 | wer 18.635 | raw_wer 18.635 | bleu 19.87 | wps 2186.5 | wpb 4003.4 | bsz 141.8 | num_updates 41255 | best_bleu 20.4
2023-08-03 01:59:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41255 updates
2023-08-03 01:59:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_last.pt
2023-08-03 01:59:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_last.pt
2023-08-03 01:59:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_last.pt (epoch 28 @ 41255 updates, score 19.87) (writing took 12.583026422187686 seconds)
2023-08-03 01:59:23 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-03 01:59:23 | INFO | train | epoch 028 | loss 2.046 | trans_loss 4.96 | nll_loss 2.142 | w2v_ctc_loss 0.643 | task_loss 0 | contrastive_loss 0.113 | total 4138.77 | n_correct 2713.57 | ppl 4.41 | accuracy 65.565 | wps 13058.3 | ups 1.58 | wpb 8277.5 | bsz 305.7 | num_updates 41255 | lr 6.96268e-05 | gnorm 0.592 | clip 0 | loss_scale 64 | train_wall 817 | gb_free 16.7 | wall 28526
2023-08-03 01:59:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 01:59:23 | INFO | fairseq.trainer | begin training epoch 29
2023-08-03 01:59:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 01:59:55 | INFO | train_inner | epoch 029:     45 / 1474 loss=2.038, trans_loss=4.945, nll_loss=2.124, w2v_ctc_loss=0.644, task_loss=0, contrastive_loss=0.073, total=4163.06, n_correct=2743.64, ppl=4.36, accuracy=65.904, wps=8388.3, ups=1.01, wpb=8326.1, bsz=314, num_updates=41300, lr=6.95889e-05, gnorm=0.591, clip=0, loss_scale=64, train_wall=56, gb_free=16.4, wall=28559
2023-08-03 02:00:51 | INFO | train_inner | epoch 029:    145 / 1474 loss=2.037, trans_loss=4.94, nll_loss=2.115, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.105, total=4116.29, n_correct=2714.64, ppl=4.33, accuracy=65.949, wps=14784.3, ups=1.8, wpb=8232.6, bsz=308.5, num_updates=41400, lr=6.95048e-05, gnorm=0.593, clip=0, loss_scale=64, train_wall=55, gb_free=14.5, wall=28615
2023-08-03 02:01:47 | INFO | train_inner | epoch 029:    245 / 1474 loss=2.038, trans_loss=4.936, nll_loss=2.112, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.183, total=4197.24, n_correct=2769.09, ppl=4.32, accuracy=65.974, wps=14995.5, ups=1.79, wpb=8394.5, bsz=329.9, num_updates=41500, lr=6.9421e-05, gnorm=0.594, clip=0, loss_scale=64, train_wall=55, gb_free=17.3, wall=28671
2023-08-03 02:02:43 | INFO | train_inner | epoch 029:    345 / 1474 loss=2.04, trans_loss=4.953, nll_loss=2.133, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.062, total=4092.21, n_correct=2687.98, ppl=4.39, accuracy=65.685, wps=14621.6, ups=1.79, wpb=8184.4, bsz=290.6, num_updates=41600, lr=6.93375e-05, gnorm=0.6, clip=0, loss_scale=64, train_wall=55, gb_free=15.9, wall=28727
2023-08-03 02:03:39 | INFO | train_inner | epoch 029:    445 / 1474 loss=2.025, trans_loss=4.932, nll_loss=2.105, w2v_ctc_loss=0.631, task_loss=0, contrastive_loss=0.055, total=4161.27, n_correct=2751.75, ppl=4.3, accuracy=66.128, wps=14753.6, ups=1.77, wpb=8322.5, bsz=307.8, num_updates=41700, lr=6.92543e-05, gnorm=0.595, clip=0, loss_scale=64, train_wall=56, gb_free=16.2, wall=28783
2023-08-03 02:04:35 | INFO | train_inner | epoch 029:    545 / 1474 loss=2.046, trans_loss=4.955, nll_loss=2.136, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.152, total=4159.68, n_correct=2726.34, ppl=4.39, accuracy=65.542, wps=14911.9, ups=1.79, wpb=8319.4, bsz=296.5, num_updates=41800, lr=6.91714e-05, gnorm=0.591, clip=0, loss_scale=64, train_wall=55, gb_free=16.4, wall=28839
2023-08-03 02:05:31 | INFO | train_inner | epoch 029:    645 / 1474 loss=2.043, trans_loss=4.945, nll_loss=2.124, w2v_ctc_loss=0.633, task_loss=0, contrastive_loss=0.224, total=4143.76, n_correct=2729.7, ppl=4.36, accuracy=65.875, wps=14840.6, ups=1.79, wpb=8287.5, bsz=318.8, num_updates=41900, lr=6.90889e-05, gnorm=0.597, clip=0, loss_scale=64, train_wall=55, gb_free=17.6, wall=28895
2023-08-03 02:06:28 | INFO | train_inner | epoch 029:    745 / 1474 loss=2.038, trans_loss=4.945, nll_loss=2.123, w2v_ctc_loss=0.631, task_loss=0, contrastive_loss=0.142, total=4234.8, n_correct=2788.14, ppl=4.36, accuracy=65.839, wps=14960.7, ups=1.77, wpb=8469.6, bsz=328.1, num_updates=42000, lr=6.90066e-05, gnorm=0.587, clip=0, loss_scale=64, train_wall=56, gb_free=17.1, wall=28951
2023-08-03 02:06:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 02:06:52 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.361 | trans_loss 5.579 | nll_loss 2.855 | w2v_ctc_loss 1.4 | task_loss 0 | contrastive_loss 0.267 | total 4003.4 | n_correct 2487.1 | ppl 7.23 | accuracy 62.125 | uer 16.802 | wer 18.56 | raw_wer 18.56 | bleu 20.18 | wps 2044.2 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.4
2023-08-03 02:06:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-08-03 02:06:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_29_42000.pt
2023-08-03 02:06:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_29_42000.pt
2023-08-03 02:07:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 20.18) (writing took 18.620150353759527 seconds)
2023-08-03 02:08:07 | INFO | train_inner | epoch 029:    845 / 1474 loss=2.044, trans_loss=4.968, nll_loss=2.152, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.054, total=4033.21, n_correct=2636.65, ppl=4.44, accuracy=65.373, wps=8104.5, ups=1, wpb=8066.4, bsz=281.6, num_updates=42100, lr=6.89246e-05, gnorm=0.597, clip=0, loss_scale=64, train_wall=55, gb_free=16.8, wall=29051
2023-08-03 02:09:03 | INFO | train_inner | epoch 029:    945 / 1474 loss=2.042, trans_loss=4.964, nll_loss=2.148, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.066, total=4085.97, n_correct=2678.63, ppl=4.43, accuracy=65.557, wps=14712.2, ups=1.8, wpb=8171.9, bsz=296.8, num_updates=42200, lr=6.88428e-05, gnorm=0.594, clip=0, loss_scale=64, train_wall=55, gb_free=17.5, wall=29106
2023-08-03 02:09:59 | INFO | train_inner | epoch 029:   1045 / 1474 loss=2.041, trans_loss=4.954, nll_loss=2.135, w2v_ctc_loss=0.635, task_loss=0, contrastive_loss=0.142, total=4140.84, n_correct=2721.48, ppl=4.39, accuracy=65.723, wps=14856, ups=1.79, wpb=8281.7, bsz=306.7, num_updates=42300, lr=6.87614e-05, gnorm=0.594, clip=0, loss_scale=128, train_wall=55, gb_free=17, wall=29162
2023-08-03 02:10:54 | INFO | train_inner | epoch 029:   1145 / 1474 loss=2.042, trans_loss=4.967, nll_loss=2.151, w2v_ctc_loss=0.646, task_loss=0, contrastive_loss=0.049, total=4068.4, n_correct=2664.63, ppl=4.44, accuracy=65.496, wps=14736.7, ups=1.81, wpb=8136.8, bsz=284.2, num_updates=42400, lr=6.86803e-05, gnorm=0.592, clip=0, loss_scale=128, train_wall=55, gb_free=17.8, wall=29217
2023-08-03 02:11:50 | INFO | train_inner | epoch 029:   1245 / 1474 loss=2.042, trans_loss=4.967, nll_loss=2.152, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.058, total=4154.79, n_correct=2723.89, ppl=4.45, accuracy=65.56, wps=14764, ups=1.78, wpb=8309.6, bsz=299.6, num_updates=42500, lr=6.85994e-05, gnorm=0.588, clip=0, loss_scale=128, train_wall=56, gb_free=17.1, wall=29274
2023-08-03 02:12:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-03 02:12:47 | INFO | train_inner | epoch 029:   1346 / 1474 loss=2.041, trans_loss=4.958, nll_loss=2.141, w2v_ctc_loss=0.634, task_loss=0, contrastive_loss=0.111, total=4154.8, n_correct=2725.37, ppl=4.41, accuracy=65.596, wps=14720.4, ups=1.77, wpb=8309.6, bsz=307.2, num_updates=42600, lr=6.85189e-05, gnorm=0.592, clip=0, loss_scale=64, train_wall=56, gb_free=18.1, wall=29330
2023-08-03 02:13:42 | INFO | train_inner | epoch 029:   1446 / 1474 loss=2.048, trans_loss=4.96, nll_loss=2.144, w2v_ctc_loss=0.643, task_loss=0, contrastive_loss=0.152, total=4162.2, n_correct=2728.79, ppl=4.42, accuracy=65.561, wps=14944.1, ups=1.8, wpb=8324.4, bsz=311.5, num_updates=42700, lr=6.84386e-05, gnorm=0.588, clip=0, loss_scale=64, train_wall=55, gb_free=17.6, wall=29386
2023-08-03 02:13:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 02:14:20 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.367 | trans_loss 5.574 | nll_loss 2.85 | w2v_ctc_loss 1.432 | task_loss 0 | contrastive_loss 0.262 | total 4003.4 | n_correct 2487.1 | ppl 7.21 | accuracy 62.125 | uer 16.85 | wer 18.65 | raw_wer 18.65 | bleu 19.83 | wps 2321.7 | wpb 4003.4 | bsz 141.8 | num_updates 42728 | best_bleu 20.4
2023-08-03 02:14:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42728 updates
2023-08-03 02:14:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_last.pt
2023-08-03 02:14:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_last.pt
2023-08-03 02:14:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_last.pt (epoch 29 @ 42728 updates, score 19.83) (writing took 11.997094947844744 seconds)
2023-08-03 02:14:32 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-03 02:14:32 | INFO | train | epoch 029 | loss 2.04 | trans_loss 4.952 | nll_loss 2.132 | w2v_ctc_loss 0.637 | task_loss 0 | contrastive_loss 0.111 | total 4137.67 | n_correct 2719.27 | ppl 4.38 | accuracy 65.72 | wps 13398.6 | ups 1.62 | wpb 8275.3 | bsz 305.4 | num_updates 42728 | lr 6.84162e-05 | gnorm 0.593 | clip 0 | loss_scale 64 | train_wall 816 | gb_free 16.3 | wall 29436
2023-08-03 02:14:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 02:14:32 | INFO | fairseq.trainer | begin training epoch 30
2023-08-03 02:14:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 02:15:21 | INFO | train_inner | epoch 030:     72 / 1474 loss=2.034, trans_loss=4.937, nll_loss=2.112, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.169, total=4182.65, n_correct=2762.59, ppl=4.32, accuracy=66.049, wps=8506.8, ups=1.02, wpb=8365.3, bsz=320.5, num_updates=42800, lr=6.83586e-05, gnorm=0.591, clip=0, loss_scale=64, train_wall=55, gb_free=13.9, wall=29484
2023-08-03 02:16:17 | INFO | train_inner | epoch 030:    172 / 1474 loss=2.024, trans_loss=4.918, nll_loss=2.088, w2v_ctc_loss=0.631, task_loss=0, contrastive_loss=0.102, total=4203.05, n_correct=2792.69, ppl=4.25, accuracy=66.444, wps=14954.4, ups=1.78, wpb=8406.1, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.585, clip=0, loss_scale=64, train_wall=56, gb_free=17.7, wall=29540
2023-08-03 02:17:13 | INFO | train_inner | epoch 030:    272 / 1474 loss=2.031, trans_loss=4.937, nll_loss=2.111, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.053, total=4116.93, n_correct=2717.13, ppl=4.32, accuracy=65.999, wps=14778.8, ups=1.79, wpb=8233.9, bsz=295.1, num_updates=43000, lr=6.81994e-05, gnorm=0.587, clip=0, loss_scale=64, train_wall=55, gb_free=17.2, wall=29596
2023-08-03 02:18:09 | INFO | train_inner | epoch 030:    372 / 1474 loss=2.023, trans_loss=4.93, nll_loss=2.103, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.057, total=4173.13, n_correct=2764.02, ppl=4.3, accuracy=66.234, wps=14889.6, ups=1.78, wpb=8346.3, bsz=305.6, num_updates=43100, lr=6.81203e-05, gnorm=0.584, clip=0, loss_scale=64, train_wall=55, gb_free=12.4, wall=29652
2023-08-03 02:19:04 | INFO | train_inner | epoch 030:    472 / 1474 loss=2.029, trans_loss=4.934, nll_loss=2.109, w2v_ctc_loss=0.623, task_loss=0, contrastive_loss=0.122, total=4135.2, n_correct=2731.82, ppl=4.31, accuracy=66.063, wps=14877.4, ups=1.8, wpb=8270.4, bsz=314.8, num_updates=43200, lr=6.80414e-05, gnorm=0.592, clip=0, loss_scale=64, train_wall=55, gb_free=17.2, wall=29708
2023-08-03 02:20:00 | INFO | train_inner | epoch 030:    572 / 1474 loss=2.032, trans_loss=4.944, nll_loss=2.121, w2v_ctc_loss=0.631, task_loss=0, contrastive_loss=0.085, total=4168.65, n_correct=2750.9, ppl=4.35, accuracy=65.99, wps=14935.5, ups=1.79, wpb=8337.3, bsz=312.1, num_updates=43300, lr=6.79628e-05, gnorm=0.59, clip=0, loss_scale=64, train_wall=55, gb_free=16.2, wall=29763
2023-08-03 02:20:56 | INFO | train_inner | epoch 030:    672 / 1474 loss=2.039, trans_loss=4.945, nll_loss=2.123, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.102, total=4183.65, n_correct=2755.8, ppl=4.36, accuracy=65.871, wps=14916.4, ups=1.78, wpb=8367.3, bsz=314.5, num_updates=43400, lr=6.78844e-05, gnorm=0.598, clip=0, loss_scale=64, train_wall=56, gb_free=17.1, wall=29820
2023-08-03 02:21:52 | INFO | train_inner | epoch 030:    772 / 1474 loss=2.053, trans_loss=4.959, nll_loss=2.141, w2v_ctc_loss=0.649, task_loss=0, contrastive_loss=0.178, total=4106.9, n_correct=2690.91, ppl=4.41, accuracy=65.522, wps=14654.5, ups=1.78, wpb=8213.8, bsz=302.9, num_updates=43500, lr=6.78064e-05, gnorm=0.6, clip=0, loss_scale=64, train_wall=55, gb_free=12.5, wall=29876
2023-08-03 02:22:48 | INFO | train_inner | epoch 030:    872 / 1474 loss=2.033, trans_loss=4.95, nll_loss=2.129, w2v_ctc_loss=0.633, task_loss=0, contrastive_loss=0.06, total=4089.18, n_correct=2691.54, ppl=4.37, accuracy=65.821, wps=14562.5, ups=1.78, wpb=8178.4, bsz=291.4, num_updates=43600, lr=6.77285e-05, gnorm=0.594, clip=0, loss_scale=64, train_wall=56, gb_free=16.7, wall=29932
2023-08-03 02:23:44 | INFO | train_inner | epoch 030:    972 / 1474 loss=2.039, trans_loss=4.954, nll_loss=2.134, w2v_ctc_loss=0.638, task_loss=0, contrastive_loss=0.081, total=4140.03, n_correct=2720, ppl=4.39, accuracy=65.7, wps=14850.4, ups=1.79, wpb=8280.1, bsz=303.9, num_updates=43700, lr=6.7651e-05, gnorm=0.594, clip=0, loss_scale=64, train_wall=55, gb_free=14.3, wall=29988
2023-08-03 02:24:41 | INFO | train_inner | epoch 030:   1072 / 1474 loss=2.047, trans_loss=4.964, nll_loss=2.147, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.144, total=4101.12, n_correct=2682.89, ppl=4.43, accuracy=65.418, wps=14523.3, ups=1.77, wpb=8202.2, bsz=282.8, num_updates=43800, lr=6.75737e-05, gnorm=0.597, clip=0, loss_scale=64, train_wall=56, gb_free=16.8, wall=30044
2023-08-03 02:25:36 | INFO | train_inner | epoch 030:   1172 / 1474 loss=2.035, trans_loss=4.951, nll_loss=2.133, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.128, total=4168.22, n_correct=2743.17, ppl=4.38, accuracy=65.812, wps=14931.7, ups=1.79, wpb=8336.4, bsz=314.5, num_updates=43900, lr=6.74967e-05, gnorm=0.593, clip=0, loss_scale=64, train_wall=55, gb_free=17, wall=30100
2023-08-03 02:26:32 | INFO | train_inner | epoch 030:   1272 / 1474 loss=2.042, trans_loss=4.961, nll_loss=2.144, w2v_ctc_loss=0.643, task_loss=0, contrastive_loss=0.063, total=4032.74, n_correct=2644.98, ppl=4.42, accuracy=65.588, wps=14382.2, ups=1.78, wpb=8065.5, bsz=281.8, num_updates=44000, lr=6.742e-05, gnorm=0.606, clip=0, loss_scale=64, train_wall=55, gb_free=17.1, wall=30156
2023-08-03 02:26:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 02:26:59 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.356 | trans_loss 5.578 | nll_loss 2.853 | w2v_ctc_loss 1.391 | task_loss 0 | contrastive_loss 0.256 | total 4003.4 | n_correct 2484.7 | ppl 7.22 | accuracy 62.065 | uer 16.712 | wer 18.545 | raw_wer 18.545 | bleu 19.84 | wps 1883.9 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.4
2023-08-03 02:26:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-08-03 02:26:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_30_44000.pt
2023-08-03 02:27:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_30_44000.pt
2023-08-03 02:27:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 19.84) (writing took 12.920098710805178 seconds)
2023-08-03 02:28:08 | INFO | train_inner | epoch 030:   1372 / 1474 loss=2.035, trans_loss=4.951, nll_loss=2.133, w2v_ctc_loss=0.632, task_loss=0, contrastive_loss=0.077, total=4166.96, n_correct=2742.33, ppl=4.39, accuracy=65.811, wps=8717, ups=1.05, wpb=8333.9, bsz=322.3, num_updates=44100, lr=6.73435e-05, gnorm=0.594, clip=0, loss_scale=64, train_wall=55, gb_free=15.4, wall=30252
2023-08-03 02:28:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-03 02:29:04 | INFO | train_inner | epoch 030:   1473 / 1474 loss=2.042, trans_loss=4.956, nll_loss=2.139, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.218, total=4151.2, n_correct=2731.35, ppl=4.4, accuracy=65.797, wps=14802.9, ups=1.78, wpb=8302.4, bsz=316.1, num_updates=44200, lr=6.72673e-05, gnorm=0.586, clip=0, loss_scale=32, train_wall=56, gb_free=16.6, wall=30308
2023-08-03 02:29:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 02:29:28 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.372 | trans_loss 5.577 | nll_loss 2.853 | w2v_ctc_loss 1.438 | task_loss 0 | contrastive_loss 0.266 | total 4003.4 | n_correct 2486.9 | ppl 7.23 | accuracy 62.12 | uer 16.933 | wer 18.87 | raw_wer 18.87 | bleu 20.09 | wps 2153.4 | wpb 4003.4 | bsz 141.8 | num_updates 44201 | best_bleu 20.4
2023-08-03 02:29:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44201 updates
2023-08-03 02:29:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.0900.pt
2023-08-03 02:29:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.0900.pt
2023-08-03 02:29:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.0900.pt (epoch 30 @ 44201 updates, score 20.09) (writing took 21.428228810429573 seconds)
2023-08-03 02:29:50 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-03 02:29:50 | INFO | train | epoch 030 | loss 2.036 | trans_loss 4.946 | nll_loss 2.124 | w2v_ctc_loss 0.633 | task_loss 0 | contrastive_loss 0.111 | total 4139.12 | n_correct 2726.83 | ppl 4.36 | accuracy 65.879 | wps 13286.5 | ups 1.6 | wpb 8278.2 | bsz 305.7 | num_updates 44201 | lr 6.72665e-05 | gnorm 0.593 | clip 0 | loss_scale 32 | train_wall 817 | gb_free 17.4 | wall 30354
2023-08-03 02:29:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 02:29:50 | INFO | fairseq.trainer | begin training epoch 31
2023-08-03 02:29:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 02:30:54 | INFO | train_inner | epoch 031:     99 / 1474 loss=2.025, trans_loss=4.928, nll_loss=2.098, w2v_ctc_loss=0.634, task_loss=0, contrastive_loss=0.055, total=4054.44, n_correct=2685.48, ppl=4.28, accuracy=66.236, wps=7387.1, ups=0.91, wpb=8108.9, bsz=288.2, num_updates=44300, lr=6.71913e-05, gnorm=0.596, clip=0, loss_scale=32, train_wall=55, gb_free=16.7, wall=30417
2023-08-03 02:31:50 | INFO | train_inner | epoch 031:    199 / 1474 loss=2.028, trans_loss=4.931, nll_loss=2.103, w2v_ctc_loss=0.633, task_loss=0, contrastive_loss=0.087, total=4147.4, n_correct=2746.13, ppl=4.3, accuracy=66.213, wps=14707.4, ups=1.77, wpb=8294.8, bsz=302.2, num_updates=44400, lr=6.71156e-05, gnorm=0.596, clip=0, loss_scale=32, train_wall=56, gb_free=17.1, wall=30474
2023-08-03 02:32:47 | INFO | train_inner | epoch 031:    299 / 1474 loss=2.027, trans_loss=4.927, nll_loss=2.099, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.122, total=4149.21, n_correct=2749.62, ppl=4.28, accuracy=66.269, wps=14756.6, ups=1.78, wpb=8298.4, bsz=301.6, num_updates=44500, lr=6.70402e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=56, gb_free=16.5, wall=30530
2023-08-03 02:33:42 | INFO | train_inner | epoch 031:    399 / 1474 loss=2.028, trans_loss=4.941, nll_loss=2.116, w2v_ctc_loss=0.63, task_loss=0, contrastive_loss=0.059, total=4092.62, n_correct=2697.58, ppl=4.33, accuracy=65.913, wps=14698.4, ups=1.8, wpb=8185.2, bsz=285.6, num_updates=44600, lr=6.6965e-05, gnorm=0.605, clip=0, loss_scale=32, train_wall=55, gb_free=17.4, wall=30586
2023-08-03 02:34:38 | INFO | train_inner | epoch 031:    499 / 1474 loss=2.032, trans_loss=4.936, nll_loss=2.11, w2v_ctc_loss=0.643, task_loss=0, contrastive_loss=0.071, total=4111.85, n_correct=2714.09, ppl=4.32, accuracy=66.007, wps=14633.6, ups=1.78, wpb=8223.7, bsz=300.3, num_updates=44700, lr=6.689e-05, gnorm=0.605, clip=0, loss_scale=32, train_wall=56, gb_free=11.6, wall=30642
2023-08-03 02:35:35 | INFO | train_inner | epoch 031:    599 / 1474 loss=2.023, trans_loss=4.934, nll_loss=2.108, w2v_ctc_loss=0.623, task_loss=0, contrastive_loss=0.059, total=4083.44, n_correct=2699.91, ppl=4.31, accuracy=66.119, wps=14540.9, ups=1.78, wpb=8166.9, bsz=294.5, num_updates=44800, lr=6.68153e-05, gnorm=0.598, clip=0, loss_scale=32, train_wall=56, gb_free=17, wall=30698
2023-08-03 02:36:31 | INFO | train_inner | epoch 031:    699 / 1474 loss=2.02, trans_loss=4.931, nll_loss=2.105, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.06, total=4213.98, n_correct=2792.72, ppl=4.3, accuracy=66.273, wps=14988.1, ups=1.78, wpb=8428, bsz=315.7, num_updates=44900, lr=6.67409e-05, gnorm=0.585, clip=0, loss_scale=32, train_wall=56, gb_free=16.5, wall=30754
2023-08-03 02:37:27 | INFO | train_inner | epoch 031:    799 / 1474 loss=2.038, trans_loss=4.949, nll_loss=2.128, w2v_ctc_loss=0.632, task_loss=0, contrastive_loss=0.132, total=4097.37, n_correct=2693.42, ppl=4.37, accuracy=65.735, wps=14600.8, ups=1.78, wpb=8194.7, bsz=295.8, num_updates=45000, lr=6.66667e-05, gnorm=0.602, clip=0, loss_scale=32, train_wall=56, gb_free=13.4, wall=30810
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:0')
2023-08-03 02:38:23 | INFO | train_inner | epoch 031:    899 / 1474 loss=2.028, trans_loss=4.936, nll_loss=2.112, w2v_ctc_loss=0.63, task_loss=0, contrastive_loss=0.076, total=4096.72, n_correct=2706.61, ppl=4.32, accuracy=66.068, wps=14729, ups=1.8, wpb=8193.4, bsz=296.1, num_updates=45100, lr=6.65927e-05, gnorm=0.603, clip=0, loss_scale=32, train_wall=55, gb_free=17.5, wall=30866
2023-08-03 02:39:19 | INFO | train_inner | epoch 031:    999 / 1474 loss=2.037, trans_loss=4.947, nll_loss=2.127, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.16, total=4187.84, n_correct=2758.97, ppl=4.37, accuracy=65.881, wps=14808.1, ups=1.77, wpb=8375.7, bsz=319.5, num_updates=45200, lr=6.6519e-05, gnorm=0.601, clip=0, loss_scale=32, train_wall=56, gb_free=17.6, wall=30923
2023-08-03 02:40:15 | INFO | train_inner | epoch 031:   1099 / 1474 loss=2.033, trans_loss=4.942, nll_loss=2.121, w2v_ctc_loss=0.628, task_loss=0, contrastive_loss=0.11, total=4149.44, n_correct=2740.71, ppl=4.35, accuracy=66.05, wps=14864.4, ups=1.79, wpb=8298.9, bsz=315, num_updates=45300, lr=6.64455e-05, gnorm=0.595, clip=0, loss_scale=32, train_wall=55, gb_free=17.9, wall=30979
2023-08-03 02:41:11 | INFO | train_inner | epoch 031:   1199 / 1474 loss=2.04, trans_loss=4.947, nll_loss=2.128, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.222, total=4189.76, n_correct=2762.78, ppl=4.37, accuracy=65.941, wps=14992.6, ups=1.79, wpb=8379.5, bsz=321.3, num_updates=45400, lr=6.63723e-05, gnorm=0.589, clip=0, loss_scale=32, train_wall=55, gb_free=13.7, wall=31034
2023-08-03 02:42:07 | INFO | train_inner | epoch 031:   1299 / 1474 loss=2.031, trans_loss=4.948, nll_loss=2.128, w2v_ctc_loss=0.63, task_loss=0, contrastive_loss=0.067, total=4227.44, n_correct=2789.78, ppl=4.37, accuracy=65.992, wps=15111.8, ups=1.79, wpb=8454.9, bsz=326.3, num_updates=45500, lr=6.62994e-05, gnorm=0.593, clip=0, loss_scale=32, train_wall=55, gb_free=16.6, wall=31090
2023-08-03 02:43:04 | INFO | train_inner | epoch 031:   1399 / 1474 loss=2.049, trans_loss=4.948, nll_loss=2.128, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.273, total=4186.05, n_correct=2754.36, ppl=4.37, accuracy=65.799, wps=14767.9, ups=1.76, wpb=8372.1, bsz=326.6, num_updates=45600, lr=6.62266e-05, gnorm=0.596, clip=0, loss_scale=32, train_wall=56, gb_free=17.8, wall=31147
2023-08-03 02:43:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2396, device='cuda:2')
2023-08-03 02:44:07 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.365 | trans_loss 5.573 | nll_loss 2.848 | w2v_ctc_loss 1.427 | task_loss 0 | contrastive_loss 0.262 | total 4003.4 | n_correct 2490.3 | ppl 7.2 | accuracy 62.205 | uer 16.776 | wer 18.579 | raw_wer 18.579 | bleu 20.02 | wps 2438.1 | wpb 4003.4 | bsz 141.8 | num_updates 45675 | best_bleu 20.4
2023-08-03 02:44:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45675 updates
2023-08-03 02:44:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_last.pt
2023-08-03 02:44:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_last.pt
2023-08-03 02:44:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_last.pt (epoch 31 @ 45675 updates, score 20.02) (writing took 13.004043351858854 seconds)
2023-08-03 02:44:20 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-03 02:44:20 | INFO | train | epoch 031 | loss 2.031 | trans_loss 4.94 | nll_loss 2.116 | w2v_ctc_loss 0.629 | task_loss 0 | contrastive_loss 0.11 | total 4138.65 | n_correct 2732.52 | ppl 4.34 | accuracy 66.025 | wps 14024.6 | ups 1.69 | wpb 8277.3 | bsz 305.7 | num_updates 45675 | lr 6.61722e-05 | gnorm 0.597 | clip 0 | loss_scale 32 | train_wall 818 | gb_free 12.6 | wall 31224
2023-08-03 02:44:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 02:44:20 | INFO | fairseq.trainer | begin training epoch 32
2023-08-03 02:44:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 02:44:41 | INFO | train_inner | epoch 032:     25 / 1474 loss=2.026, trans_loss=4.94, nll_loss=2.117, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.055, total=4042.6, n_correct=2670.22, ppl=4.34, accuracy=66.052, wps=8274.8, ups=1.02, wpb=8085.2, bsz=288.7, num_updates=45700, lr=6.61541e-05, gnorm=0.605, clip=0, loss_scale=32, train_wall=55, gb_free=16.7, wall=31245
2023-08-03 02:45:37 | INFO | train_inner | epoch 032:    125 / 1474 loss=2.006, trans_loss=4.903, nll_loss=2.069, w2v_ctc_loss=0.608, task_loss=0, contrastive_loss=0.068, total=4227.68, n_correct=2820.9, ppl=4.2, accuracy=66.725, wps=15151.4, ups=1.79, wpb=8455.4, bsz=323.3, num_updates=45800, lr=6.60819e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=55, gb_free=16.3, wall=31301
2023-08-03 02:46:33 | INFO | train_inner | epoch 032:    225 / 1474 loss=2.018, trans_loss=4.919, nll_loss=2.089, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.079, total=4157.32, n_correct=2764, ppl=4.26, accuracy=66.485, wps=14766.6, ups=1.78, wpb=8314.6, bsz=320.6, num_updates=45900, lr=6.60098e-05, gnorm=0.602, clip=0, loss_scale=32, train_wall=56, gb_free=17.5, wall=31357
2023-08-03 02:47:30 | INFO | train_inner | epoch 032:    325 / 1474 loss=2.009, trans_loss=4.91, nll_loss=2.078, w2v_ctc_loss=0.61, task_loss=0, contrastive_loss=0.069, total=4183.45, n_correct=2789.88, ppl=4.22, accuracy=66.688, wps=14799.7, ups=1.77, wpb=8366.9, bsz=314.4, num_updates=46000, lr=6.5938e-05, gnorm=0.596, clip=0, loss_scale=32, train_wall=56, gb_free=17.8, wall=31413
2023-08-03 02:47:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 02:47:53 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.385 | trans_loss 5.592 | nll_loss 2.869 | w2v_ctc_loss 1.448 | task_loss 0 | contrastive_loss 0.269 | total 4003.4 | n_correct 2485.6 | ppl 7.31 | accuracy 62.087 | uer 17.007 | wer 18.825 | raw_wer 18.825 | bleu 19.87 | wps 2196 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.4
2023-08-03 02:47:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-08-03 02:47:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_32_46000.pt
2023-08-03 02:47:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_32_46000.pt
2023-08-03 02:48:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 19.87) (writing took 17.7514941226691 seconds)
2023-08-03 02:49:07 | INFO | train_inner | epoch 032:    425 / 1474 loss=2.017, trans_loss=4.92, nll_loss=2.091, w2v_ctc_loss=0.621, task_loss=0, contrastive_loss=0.064, total=4157.28, n_correct=2764.35, ppl=4.26, accuracy=66.494, wps=8578.4, ups=1.03, wpb=8314.6, bsz=305.9, num_updates=46100, lr=6.58665e-05, gnorm=0.591, clip=0, loss_scale=32, train_wall=55, gb_free=15.2, wall=31510
2023-08-03 02:50:03 | INFO | train_inner | epoch 032:    525 / 1474 loss=2.031, trans_loss=4.931, nll_loss=2.105, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.153, total=4198.93, n_correct=2779.32, ppl=4.3, accuracy=66.191, wps=14898.1, ups=1.77, wpb=8397.9, bsz=317.6, num_updates=46200, lr=6.57952e-05, gnorm=0.597, clip=0, loss_scale=32, train_wall=56, gb_free=17.6, wall=31567
2023-08-03 02:50:59 | INFO | train_inner | epoch 032:    625 / 1474 loss=2.025, trans_loss=4.935, nll_loss=2.109, w2v_ctc_loss=0.626, task_loss=0, contrastive_loss=0.074, total=4142.69, n_correct=2740.1, ppl=4.31, accuracy=66.143, wps=14750.1, ups=1.78, wpb=8285.4, bsz=301.6, num_updates=46300, lr=6.57241e-05, gnorm=0.596, clip=0, loss_scale=64, train_wall=56, gb_free=17.6, wall=31623
2023-08-03 02:51:56 | INFO | train_inner | epoch 032:    725 / 1474 loss=2.027, trans_loss=4.937, nll_loss=2.112, w2v_ctc_loss=0.634, task_loss=0, contrastive_loss=0.058, total=4154.59, n_correct=2750.89, ppl=4.32, accuracy=66.213, wps=14686.7, ups=1.77, wpb=8309.2, bsz=301.8, num_updates=46400, lr=6.56532e-05, gnorm=0.593, clip=0, loss_scale=64, train_wall=56, gb_free=16.1, wall=31680
2023-08-03 02:52:51 | INFO | train_inner | epoch 032:    825 / 1474 loss=2.018, trans_loss=4.932, nll_loss=2.106, w2v_ctc_loss=0.618, task_loss=0, contrastive_loss=0.053, total=4114.54, n_correct=2727.31, ppl=4.3, accuracy=66.285, wps=14870.7, ups=1.81, wpb=8229.1, bsz=294.9, num_updates=46500, lr=6.55826e-05, gnorm=0.594, clip=0, loss_scale=64, train_wall=55, gb_free=17.4, wall=31735
2023-08-03 02:53:48 | INFO | train_inner | epoch 032:    925 / 1474 loss=2.02, trans_loss=4.934, nll_loss=2.109, w2v_ctc_loss=0.618, task_loss=0, contrastive_loss=0.052, total=4139.67, n_correct=2738.63, ppl=4.31, accuracy=66.156, wps=14743.5, ups=1.78, wpb=8279.3, bsz=298.3, num_updates=46600, lr=6.55122e-05, gnorm=0.593, clip=0, loss_scale=64, train_wall=56, gb_free=17.2, wall=31791
2023-08-03 02:54:43 | INFO | train_inner | epoch 032:   1025 / 1474 loss=2.034, trans_loss=4.944, nll_loss=2.122, w2v_ctc_loss=0.628, task_loss=0, contrastive_loss=0.146, total=4119.15, n_correct=2715.93, ppl=4.35, accuracy=65.934, wps=14726.1, ups=1.79, wpb=8238.3, bsz=304.5, num_updates=46700, lr=6.5442e-05, gnorm=0.602, clip=0, loss_scale=64, train_wall=55, gb_free=16.7, wall=31847
2023-08-03 02:55:40 | INFO | train_inner | epoch 032:   1125 / 1474 loss=2.032, trans_loss=4.947, nll_loss=2.125, w2v_ctc_loss=0.63, task_loss=0, contrastive_loss=0.089, total=4019.61, n_correct=2645.13, ppl=4.36, accuracy=65.806, wps=14295.8, ups=1.78, wpb=8039.2, bsz=271.4, num_updates=46800, lr=6.5372e-05, gnorm=0.607, clip=0, loss_scale=64, train_wall=56, gb_free=17.9, wall=31903
2023-08-03 02:56:36 | INFO | train_inner | epoch 032:   1225 / 1474 loss=2.042, trans_loss=4.951, nll_loss=2.132, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.199, total=4149.28, n_correct=2731.31, ppl=4.38, accuracy=65.826, wps=14836.5, ups=1.79, wpb=8298.6, bsz=310.3, num_updates=46900, lr=6.53023e-05, gnorm=0.606, clip=0, loss_scale=64, train_wall=55, gb_free=16.2, wall=31959
2023-08-03 02:57:31 | INFO | train_inner | epoch 032:   1325 / 1474 loss=2.028, trans_loss=4.943, nll_loss=2.12, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.053, total=4079.22, n_correct=2690.54, ppl=4.35, accuracy=65.957, wps=14716.5, ups=1.8, wpb=8158.4, bsz=296.2, num_updates=47000, lr=6.52328e-05, gnorm=0.602, clip=0, loss_scale=64, train_wall=55, gb_free=15.4, wall=32015
2023-08-03 02:58:27 | INFO | train_inner | epoch 032:   1425 / 1474 loss=2.048, trans_loss=4.947, nll_loss=2.127, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.289, total=4111.41, n_correct=2706.48, ppl=4.37, accuracy=65.829, wps=14654.4, ups=1.78, wpb=8222.8, bsz=306.1, num_updates=47100, lr=6.51635e-05, gnorm=0.602, clip=0, loss_scale=64, train_wall=56, gb_free=16.3, wall=32071
2023-08-03 02:58:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 02:59:17 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.372 | trans_loss 5.576 | nll_loss 2.852 | w2v_ctc_loss 1.441 | task_loss 0 | contrastive_loss 0.273 | total 4003.4 | n_correct 2487.4 | ppl 7.22 | accuracy 62.132 | uer 16.938 | wer 18.638 | raw_wer 18.638 | bleu 20.21 | wps 2350.6 | wpb 4003.4 | bsz 141.8 | num_updates 47149 | best_bleu 20.4
2023-08-03 02:59:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47149 updates
2023-08-03 02:59:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.2102.pt
2023-08-03 02:59:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.2102.pt
2023-08-03 02:59:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.2102.pt (epoch 32 @ 47149 updates, score 20.21) (writing took 13.879163848236203 seconds)
2023-08-03 02:59:31 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-03 02:59:31 | INFO | train | epoch 032 | loss 2.025 | trans_loss 4.932 | nll_loss 2.106 | w2v_ctc_loss 0.623 | task_loss 0 | contrastive_loss 0.108 | total 4138.65 | n_correct 2739.9 | ppl 4.31 | accuracy 66.203 | wps 13389.4 | ups 1.62 | wpb 8277.3 | bsz 305.7 | num_updates 47149 | lr 6.51297e-05 | gnorm 0.598 | clip 0 | loss_scale 64 | train_wall 819 | gb_free 16.7 | wall 32135
2023-08-03 02:59:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 02:59:32 | INFO | fairseq.trainer | begin training epoch 33
2023-08-03 02:59:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 03:00:08 | INFO | train_inner | epoch 033:     51 / 1474 loss=2.028, trans_loss=4.929, nll_loss=2.104, w2v_ctc_loss=0.619, task_loss=0, contrastive_loss=0.16, total=4156.71, n_correct=2756.45, ppl=4.3, accuracy=66.313, wps=8267.9, ups=0.99, wpb=8313.4, bsz=322.5, num_updates=47200, lr=6.50945e-05, gnorm=0.598, clip=0, loss_scale=64, train_wall=56, gb_free=16.7, wall=32171
2023-08-03 03:01:03 | INFO | train_inner | epoch 033:    151 / 1474 loss=2.005, trans_loss=4.909, nll_loss=2.074, w2v_ctc_loss=0.606, task_loss=0, contrastive_loss=0.043, total=4071.44, n_correct=2713.53, ppl=4.21, accuracy=66.648, wps=14663.3, ups=1.8, wpb=8142.9, bsz=284.1, num_updates=47300, lr=6.50256e-05, gnorm=0.594, clip=0, loss_scale=64, train_wall=55, gb_free=16.5, wall=32227
2023-08-03 03:02:00 | INFO | train_inner | epoch 033:    251 / 1474 loss=2.028, trans_loss=4.911, nll_loss=2.081, w2v_ctc_loss=0.615, task_loss=0, contrastive_loss=0.228, total=4281.28, n_correct=2850.56, ppl=4.23, accuracy=66.582, wps=14988.9, ups=1.75, wpb=8562.6, bsz=346.3, num_updates=47400, lr=6.4957e-05, gnorm=0.586, clip=0, loss_scale=64, train_wall=56, gb_free=16.7, wall=32284
2023-08-03 03:02:56 | INFO | train_inner | epoch 033:    351 / 1474 loss=2.018, trans_loss=4.921, nll_loss=2.091, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.076, total=4111.69, n_correct=2729.61, ppl=4.26, accuracy=66.387, wps=14779.4, ups=1.8, wpb=8223.4, bsz=298.4, num_updates=47500, lr=6.48886e-05, gnorm=0.606, clip=0, loss_scale=64, train_wall=55, gb_free=17.1, wall=32340
2023-08-03 03:03:52 | INFO | train_inner | epoch 033:    451 / 1474 loss=2.005, trans_loss=4.907, nll_loss=2.073, w2v_ctc_loss=0.61, task_loss=0, contrastive_loss=0.054, total=4147.28, n_correct=2768.06, ppl=4.21, accuracy=66.744, wps=14812, ups=1.79, wpb=8294.6, bsz=313.5, num_updates=47600, lr=6.48204e-05, gnorm=0.595, clip=0, loss_scale=64, train_wall=55, gb_free=17, wall=32396
2023-08-03 03:04:48 | INFO | train_inner | epoch 033:    551 / 1474 loss=2.022, trans_loss=4.928, nll_loss=2.099, w2v_ctc_loss=0.626, task_loss=0, contrastive_loss=0.074, total=4127.68, n_correct=2733.81, ppl=4.28, accuracy=66.231, wps=14862.2, ups=1.8, wpb=8255.4, bsz=292.6, num_updates=47700, lr=6.47524e-05, gnorm=0.6, clip=0, loss_scale=64, train_wall=55, gb_free=15.9, wall=32451
2023-08-03 03:05:44 | INFO | train_inner | epoch 033:    651 / 1474 loss=2.024, trans_loss=4.935, nll_loss=2.109, w2v_ctc_loss=0.618, task_loss=0, contrastive_loss=0.108, total=4164.1, n_correct=2754.91, ppl=4.31, accuracy=66.159, wps=14739.2, ups=1.77, wpb=8328.2, bsz=302.4, num_updates=47800, lr=6.46846e-05, gnorm=0.596, clip=0, loss_scale=64, train_wall=56, gb_free=15.7, wall=32508
2023-08-03 03:06:40 | INFO | train_inner | epoch 033:    751 / 1474 loss=2.028, trans_loss=4.938, nll_loss=2.114, w2v_ctc_loss=0.636, task_loss=0, contrastive_loss=0.052, total=4064.29, n_correct=2682.48, ppl=4.33, accuracy=66.001, wps=14564.2, ups=1.79, wpb=8128.6, bsz=285.8, num_updates=47900, lr=6.46171e-05, gnorm=0.602, clip=0, loss_scale=64, train_wall=55, gb_free=17, wall=32563
2023-08-03 03:07:36 | INFO | train_inner | epoch 033:    851 / 1474 loss=2.012, trans_loss=4.919, nll_loss=2.091, w2v_ctc_loss=0.603, task_loss=0, contrastive_loss=0.125, total=4141.12, n_correct=2759.05, ppl=4.26, accuracy=66.626, wps=14700.6, ups=1.77, wpb=8282.2, bsz=318.5, num_updates=48000, lr=6.45497e-05, gnorm=0.588, clip=0, loss_scale=64, train_wall=56, gb_free=16.9, wall=32620
2023-08-03 03:07:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 03:07:58 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.372 | trans_loss 5.579 | nll_loss 2.854 | w2v_ctc_loss 1.44 | task_loss 0 | contrastive_loss 0.258 | total 4003.4 | n_correct 2487.2 | ppl 7.23 | accuracy 62.127 | uer 16.911 | wer 18.687 | raw_wer 18.687 | bleu 19.85 | wps 2402.8 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.4
2023-08-03 03:07:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-08-03 03:07:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_33_48000.pt
2023-08-03 03:08:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_33_48000.pt
2023-08-03 03:08:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 19.85) (writing took 13.258032390847802 seconds)
2023-08-03 03:09:08 | INFO | train_inner | epoch 033:    951 / 1474 loss=2.023, trans_loss=4.931, nll_loss=2.106, w2v_ctc_loss=0.628, task_loss=0, contrastive_loss=0.067, total=4147.76, n_correct=2749.46, ppl=4.3, accuracy=66.288, wps=9062.8, ups=1.09, wpb=8295.5, bsz=308.2, num_updates=48100, lr=6.44826e-05, gnorm=0.599, clip=0, loss_scale=64, train_wall=55, gb_free=17.9, wall=32711
2023-08-03 03:09:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-03 03:10:05 | INFO | train_inner | epoch 033:   1052 / 1474 loss=2.02, trans_loss=4.929, nll_loss=2.102, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.058, total=4116.77, n_correct=2729.79, ppl=4.29, accuracy=66.309, wps=14324, ups=1.74, wpb=8233.5, bsz=299.3, num_updates=48200, lr=6.44157e-05, gnorm=0.604, clip=0, loss_scale=32, train_wall=57, gb_free=12.3, wall=32769
2023-08-03 03:11:02 | INFO | train_inner | epoch 033:   1152 / 1474 loss=2.029, trans_loss=4.938, nll_loss=2.114, w2v_ctc_loss=0.617, task_loss=0, contrastive_loss=0.159, total=4182.67, n_correct=2761.54, ppl=4.33, accuracy=66.023, wps=14849, ups=1.78, wpb=8365.3, bsz=309.5, num_updates=48300, lr=6.43489e-05, gnorm=0.601, clip=0, loss_scale=32, train_wall=56, gb_free=17.8, wall=32825
2023-08-03 03:11:58 | INFO | train_inner | epoch 033:   1252 / 1474 loss=2.022, trans_loss=4.931, nll_loss=2.105, w2v_ctc_loss=0.626, task_loss=0, contrastive_loss=0.058, total=4110.02, n_correct=2722.84, ppl=4.3, accuracy=66.249, wps=14627.5, ups=1.78, wpb=8220, bsz=294.4, num_updates=48400, lr=6.42824e-05, gnorm=0.605, clip=0, loss_scale=32, train_wall=56, gb_free=17, wall=32881
2023-08-03 03:12:54 | INFO | train_inner | epoch 033:   1352 / 1474 loss=2.023, trans_loss=4.936, nll_loss=2.113, w2v_ctc_loss=0.622, task_loss=0, contrastive_loss=0.081, total=4128.82, n_correct=2735.94, ppl=4.33, accuracy=66.264, wps=14743.7, ups=1.79, wpb=8257.6, bsz=312.4, num_updates=48500, lr=6.42161e-05, gnorm=0.601, clip=0, loss_scale=32, train_wall=55, gb_free=16.4, wall=32937
2023-08-03 03:13:50 | INFO | train_inner | epoch 033:   1452 / 1474 loss=2.031, trans_loss=4.935, nll_loss=2.111, w2v_ctc_loss=0.618, task_loss=0, contrastive_loss=0.223, total=4123.47, n_correct=2732.16, ppl=4.32, accuracy=66.259, wps=14671.3, ups=1.78, wpb=8246.9, bsz=308.9, num_updates=48600, lr=6.415e-05, gnorm=0.603, clip=0, loss_scale=32, train_wall=56, gb_free=16.8, wall=32994
2023-08-03 03:14:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 03:14:24 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.371 | trans_loss 5.578 | nll_loss 2.849 | w2v_ctc_loss 1.438 | task_loss 0 | contrastive_loss 0.264 | total 4003.4 | n_correct 2490.1 | ppl 7.21 | accuracy 62.2 | uer 16.832 | wer 18.702 | raw_wer 18.702 | bleu 20.23 | wps 2417.4 | wpb 4003.4 | bsz 141.8 | num_updates 48622 | best_bleu 20.4
2023-08-03 03:14:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48622 updates
2023-08-03 03:14:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.2304.pt
2023-08-03 03:14:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.2304.pt
2023-08-03 03:14:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint.best_bleu_20.2304.pt (epoch 33 @ 48622 updates, score 20.23) (writing took 13.165337754413486 seconds)
2023-08-03 03:14:37 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-03 03:14:37 | INFO | train | epoch 033 | loss 2.021 | trans_loss 4.926 | nll_loss 2.099 | w2v_ctc_loss 0.619 | task_loss 0 | contrastive_loss 0.1 | total 4137.28 | n_correct 2744.97 | ppl 4.28 | accuracy 66.347 | wps 13452.7 | ups 1.63 | wpb 8274.6 | bsz 305.2 | num_updates 48622 | lr 6.41355e-05 | gnorm 0.598 | clip 0 | loss_scale 32 | train_wall 818 | gb_free 18.1 | wall 33041
2023-08-03 03:14:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-03 03:14:38 | INFO | fairseq.trainer | begin training epoch 34
2023-08-03 03:14:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-03 03:15:30 | INFO | train_inner | epoch 034:     78 / 1474 loss=2.008, trans_loss=4.908, nll_loss=2.075, w2v_ctc_loss=0.616, task_loss=0, contrastive_loss=0.06, total=4128.94, n_correct=2755.19, ppl=4.21, accuracy=66.729, wps=8254.3, ups=1, wpb=8257.9, bsz=302.1, num_updates=48700, lr=6.40841e-05, gnorm=0.599, clip=0, loss_scale=32, train_wall=56, gb_free=15.6, wall=33094
2023-08-03 03:16:26 | INFO | train_inner | epoch 034:    178 / 1474 loss=2.004, trans_loss=4.901, nll_loss=2.065, w2v_ctc_loss=0.61, task_loss=0, contrastive_loss=0.062, total=4071.22, n_correct=2718.61, ppl=4.18, accuracy=66.776, wps=14563.7, ups=1.79, wpb=8142.4, bsz=295.1, num_updates=48800, lr=6.40184e-05, gnorm=0.604, clip=0, loss_scale=32, train_wall=55, gb_free=15.9, wall=33150
2023-08-03 03:17:23 | INFO | train_inner | epoch 034:    278 / 1474 loss=2.033, trans_loss=4.922, nll_loss=2.093, w2v_ctc_loss=0.613, task_loss=0, contrastive_loss=0.274, total=4237.89, n_correct=2811.65, ppl=4.27, accuracy=66.346, wps=14999.4, ups=1.77, wpb=8475.8, bsz=326.9, num_updates=48900, lr=6.39529e-05, gnorm=0.599, clip=0, loss_scale=32, train_wall=56, gb_free=11.1, wall=33206
2023-08-03 03:18:18 | INFO | train_inner | epoch 034:    378 / 1474 loss=2.011, trans_loss=4.902, nll_loss=2.068, w2v_ctc_loss=0.606, task_loss=0, contrastive_loss=0.161, total=4167, n_correct=2784.68, ppl=4.19, accuracy=66.827, wps=14947.6, ups=1.79, wpb=8334, bsz=319, num_updates=49000, lr=6.38877e-05, gnorm=0.596, clip=0, loss_scale=32, train_wall=55, gb_free=17.6, wall=33262
2023-08-03 03:19:14 | INFO | train_inner | epoch 034:    478 / 1474 loss=2.017, trans_loss=4.922, nll_loss=2.092, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.054, total=4071.65, n_correct=2702, ppl=4.26, accuracy=66.361, wps=14553.4, ups=1.79, wpb=8143.3, bsz=284.8, num_updates=49100, lr=6.38226e-05, gnorm=0.608, clip=0, loss_scale=32, train_wall=55, gb_free=12.1, wall=33318
2023-08-03 03:20:10 | INFO | train_inner | epoch 034:    578 / 1474 loss=2.009, trans_loss=4.91, nll_loss=2.077, w2v_ctc_loss=0.615, task_loss=0, contrastive_loss=0.056, total=4110.13, n_correct=2742.06, ppl=4.22, accuracy=66.715, wps=14792.1, ups=1.8, wpb=8220.3, bsz=299, num_updates=49200, lr=6.37577e-05, gnorm=0.602, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=33373
2023-08-03 03:21:06 | INFO | train_inner | epoch 034:    678 / 1474 loss=2.009, trans_loss=4.915, nll_loss=2.085, w2v_ctc_loss=0.611, task_loss=0, contrastive_loss=0.05, total=4128.65, n_correct=2751.78, ppl=4.24, accuracy=66.651, wps=14723.7, ups=1.78, wpb=8257.3, bsz=300.7, num_updates=49300, lr=6.3693e-05, gnorm=0.597, clip=0, loss_scale=32, train_wall=55, gb_free=18.1, wall=33429
2023-08-03 03:22:02 | INFO | train_inner | epoch 034:    778 / 1474 loss=2.02, trans_loss=4.934, nll_loss=2.108, w2v_ctc_loss=0.606, task_loss=0, contrastive_loss=0.121, total=4075.69, n_correct=2700.8, ppl=4.31, accuracy=66.266, wps=14529.2, ups=1.78, wpb=8151.4, bsz=294.5, num_updates=49400, lr=6.36285e-05, gnorm=0.6, clip=0, loss_scale=32, train_wall=56, gb_free=17.6, wall=33486
2023-08-03 03:22:58 | INFO | train_inner | epoch 034:    878 / 1474 loss=2.018, trans_loss=4.926, nll_loss=2.099, w2v_ctc_loss=0.617, task_loss=0, contrastive_loss=0.082, total=4104.97, n_correct=2725.54, ppl=4.28, accuracy=66.396, wps=14686.5, ups=1.79, wpb=8209.9, bsz=296.3, num_updates=49500, lr=6.35642e-05, gnorm=0.615, clip=0, loss_scale=32, train_wall=55, gb_free=18.1, wall=33541
2023-08-03 03:23:54 | INFO | train_inner | epoch 034:    978 / 1474 loss=2.022, trans_loss=4.929, nll_loss=2.103, w2v_ctc_loss=0.623, task_loss=0, contrastive_loss=0.078, total=4168.94, n_correct=2762.24, ppl=4.3, accuracy=66.258, wps=14856.7, ups=1.78, wpb=8337.9, bsz=312.8, num_updates=49600, lr=6.35001e-05, gnorm=0.604, clip=0, loss_scale=32, train_wall=56, gb_free=15.3, wall=33598
2023-08-03 03:24:50 | INFO | train_inner | epoch 034:   1078 / 1474 loss=2.019, trans_loss=4.93, nll_loss=2.103, w2v_ctc_loss=0.623, task_loss=0, contrastive_loss=0.058, total=4155.12, n_correct=2755.77, ppl=4.3, accuracy=66.322, wps=14934.6, ups=1.8, wpb=8310.2, bsz=309.1, num_updates=49700, lr=6.34361e-05, gnorm=0.599, clip=0, loss_scale=32, train_wall=55, gb_free=17, wall=33653
2023-08-03 03:25:46 | INFO | train_inner | epoch 034:   1178 / 1474 loss=2.017, trans_loss=4.928, nll_loss=2.102, w2v_ctc_loss=0.617, task_loss=0, contrastive_loss=0.07, total=4096.48, n_correct=2718.16, ppl=4.29, accuracy=66.354, wps=14693.3, ups=1.79, wpb=8193, bsz=297.2, num_updates=49800, lr=6.33724e-05, gnorm=0.598, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=33709
2023-08-03 03:26:41 | INFO | train_inner | epoch 034:   1278 / 1474 loss=2.014, trans_loss=4.926, nll_loss=2.1, w2v_ctc_loss=0.615, task_loss=0, contrastive_loss=0.053, total=4149.03, n_correct=2751.67, ppl=4.29, accuracy=66.321, wps=14876.8, ups=1.79, wpb=8298.1, bsz=299.7, num_updates=49900, lr=6.33089e-05, gnorm=0.6, clip=0, loss_scale=32, train_wall=55, gb_free=16.8, wall=33765
2023-08-03 03:27:38 | INFO | train_inner | epoch 034:   1378 / 1474 loss=2.032, trans_loss=4.935, nll_loss=2.111, w2v_ctc_loss=0.632, task_loss=0, contrastive_loss=0.123, total=4200.34, n_correct=2776.73, ppl=4.32, accuracy=66.107, wps=14920, ups=1.78, wpb=8400.7, bsz=321.9, num_updates=50000, lr=6.32456e-05, gnorm=0.596, clip=0, loss_scale=32, train_wall=56, gb_free=15.3, wall=33821
2023-08-03 03:27:38 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-03 03:27:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-03 03:27:59 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.374 | trans_loss 5.577 | nll_loss 2.852 | w2v_ctc_loss 1.448 | task_loss 0 | contrastive_loss 0.261 | total 4003.4 | n_correct 2489.1 | ppl 7.22 | accuracy 62.175 | uer 16.964 | wer 18.661 | raw_wer 18.661 | bleu 20 | wps 2411.8 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.4
2023-08-03 03:27:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-08-03 03:27:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_34_50000.pt
2023-08-03 03:28:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_34_50000.pt
2023-08-03 03:28:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0801_two_cl/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 20.0) (writing took 17.13259644433856 seconds)
2023-08-03 03:28:17 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-03 03:28:17 | INFO | train | epoch 034 | loss 2.017 | trans_loss 4.92 | nll_loss 2.091 | w2v_ctc_loss 0.616 | task_loss 0 | contrastive_loss 0.095 | total 4133.33 | n_correct 2747.08 | ppl 4.26 | accuracy 66.462 | wps 13900.3 | ups 1.68 | wpb 8266.7 | bsz 304.3 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.601 | clip 0 | loss_scale 32 | train_wall 764 | gb_free 15.3 | wall 33860
2023-08-03 03:28:17 | INFO | fairseq_cli.train | done training in 33810.1 seconds
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
