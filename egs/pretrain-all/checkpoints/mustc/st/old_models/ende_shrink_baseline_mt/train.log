2023-07-10 03:45:46 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:18990
2023-07-10 03:45:46 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:18990
2023-07-10 03:45:46 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:18990
2023-07-10 03:45:46 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:18990
2023-07-10 03:45:46 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:18990
2023-07-10 03:45:46 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:18990
2023-07-10 03:45:46 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:18990
2023-07-10 03:45:46 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:18990
2023-07-10 03:45:46 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-10 03:45:46 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-10 03:45:46 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-10 03:45:46 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-10 03:45:46 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-10 03:45:47 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-10 03:45:47 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-10 03:45:47 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-10 03:45:47 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 03:45:47 | INFO | fairseq.distributed.utils | initialized host capios as rank 5
2023-07-10 03:45:47 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 03:45:47 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 03:45:47 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 03:45:47 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 03:45:47 | INFO | fairseq.distributed.utils | initialized host capios as rank 3
2023-07-10 03:45:47 | INFO | fairseq.distributed.utils | initialized host capios as rank 4
2023-07-10 03:45:47 | INFO | fairseq.distributed.utils | initialized host capios as rank 1
2023-07-10 03:45:47 | INFO | fairseq.distributed.utils | initialized host capios as rank 6
2023-07-10 03:45:47 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 03:45:47 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 03:45:47 | INFO | fairseq.distributed.utils | initialized host capios as rank 2
2023-07-10 03:45:47 | INFO | fairseq.distributed.utils | initialized host capios as rank 7
2023-07-10 03:45:47 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 03:45:47 | INFO | fairseq.distributed.utils | initialized host capios as rank 0
2023-07-10 03:45:49 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_baseline_mt', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18990', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_baseline_mt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_baseline_mt', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_baseline_mt', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_baseline_mt', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_baseline_mt', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_baseline_mt', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_baseline_mt', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-10 03:45:49 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-10 03:45:49 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-10 03:45:49 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-10 03:45:49 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-10 03:45:49 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-10 03:45:54 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-10 03:45:54 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-10 03:45:54 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-10 03:45:56 | INFO | root | load pretrained hubert
2023-07-10 03:45:56 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-10 03:45:58 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-10 03:45:59 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-10 03:45:59 | INFO | root | share the sematic adapter and textual encoder
2023-07-10 03:46:00 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-10 03:46:00 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-10 03:46:00 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-10 03:46:00 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJoint
2023-07-10 03:46:00 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-10 03:46:00 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-10 03:46:00 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-10 03:46:00 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-10 03:46:00 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-10 03:46:00 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-10 03:46:00 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-10 03:46:10 | INFO | torch.distributed.distributed_c10d | Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:2 (world_size=8, worker_count=2, timeout=0:30:00)
2023-07-10 03:46:11 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-10 03:46:11 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-10 03:46:11 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-10 03:46:11 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 03:46:11 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 03:46:11 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 03:46:11 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 03:46:11 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 03:46:11 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 03:46:11 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 03:46:11 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 03:46:11 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-10 03:46:11 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-10 03:46:11 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-10 03:46:11 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_last.pt
2023-07-10 03:46:11 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_last.pt
2023-07-10 03:46:11 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-10 03:46:11 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-10 03:46:11 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-10 03:46:11 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-10 03:46:13 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-10 03:46:15 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-10 03:46:16 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-10 03:47:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 03:47:21 | INFO | fairseq.trainer | begin training epoch 1
2023-07-10 03:47:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 03:47:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-10 03:47:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-10 03:48:21 | INFO | train_inner | epoch 001:    102 / 1474 loss=21.3, trans_loss=5.639, nll_loss=4.213, w2v_ctc_loss=25.92, contrastive_loss=0, total=4189.76, n_correct=211.03, ppl=18.55, accuracy=5.037, wps=24837.7, ups=1.98, wpb=12515.9, bsz=463.7, num_updates=100, lr=4.098e-06, gnorm=0.97, clip=0, loss_scale=32, train_wall=52, gb_free=19, wall=129
2023-07-10 03:49:10 | INFO | train_inner | epoch 001:    202 / 1474 loss=19.034, trans_loss=5.477, nll_loss=4.071, w2v_ctc_loss=22.625, contrastive_loss=0, total=4125.46, n_correct=242.2, ppl=16.81, accuracy=5.871, wps=25180, ups=2.04, wpb=12321.8, bsz=461.7, num_updates=200, lr=8.096e-06, gnorm=3.709, clip=0, loss_scale=32, train_wall=48, gb_free=19, wall=178
2023-07-10 03:49:58 | INFO | train_inner | epoch 001:    302 / 1474 loss=11.946, trans_loss=5.483, nll_loss=4.134, w2v_ctc_loss=11.722, contrastive_loss=0, total=4077.62, n_correct=230.75, ppl=17.56, accuracy=5.659, wps=25064.1, ups=2.06, wpb=12184.2, bsz=437.4, num_updates=300, lr=1.2094e-05, gnorm=4.762, clip=0, loss_scale=32, train_wall=48, gb_free=19.5, wall=227
2023-07-10 03:50:47 | INFO | train_inner | epoch 001:    402 / 1474 loss=10.665, trans_loss=5.499, nll_loss=4.174, w2v_ctc_loss=9.741, contrastive_loss=0, total=4177.45, n_correct=211.34, ppl=18.05, accuracy=5.059, wps=25502.2, ups=2.04, wpb=12472.6, bsz=462.8, num_updates=400, lr=1.6092e-05, gnorm=3.084, clip=0, loss_scale=32, train_wall=48, gb_free=19, wall=276
2023-07-10 03:51:37 | INFO | train_inner | epoch 001:    502 / 1474 loss=10.191, trans_loss=5.473, nll_loss=4.153, w2v_ctc_loss=9.036, contrastive_loss=0, total=4202.06, n_correct=207.43, ppl=17.79, accuracy=4.936, wps=25440.8, ups=2.02, wpb=12582.1, bsz=490.7, num_updates=500, lr=2.009e-05, gnorm=1.484, clip=0, loss_scale=32, train_wall=49, gb_free=15.6, wall=325
2023-07-10 03:52:26 | INFO | train_inner | epoch 001:    602 / 1474 loss=9.942, trans_loss=5.501, nll_loss=4.188, w2v_ctc_loss=8.626, contrastive_loss=0, total=4124.52, n_correct=196.19, ppl=18.23, accuracy=4.757, wps=25107.2, ups=2.04, wpb=12305.7, bsz=471, num_updates=600, lr=2.4088e-05, gnorm=0.768, clip=0, loss_scale=32, train_wall=49, gb_free=19.1, wall=374
2023-07-10 03:53:14 | INFO | train_inner | epoch 001:    702 / 1474 loss=9.749, trans_loss=5.478, nll_loss=4.168, w2v_ctc_loss=8.357, contrastive_loss=0, total=4147.01, n_correct=218.28, ppl=17.98, accuracy=5.264, wps=25708.9, ups=2.08, wpb=12358.1, bsz=455.2, num_updates=700, lr=2.8086e-05, gnorm=0.662, clip=0, loss_scale=32, train_wall=48, gb_free=19.4, wall=422
2023-07-10 03:54:02 | INFO | train_inner | epoch 001:    802 / 1474 loss=9.458, trans_loss=5.423, nll_loss=4.101, w2v_ctc_loss=7.965, contrastive_loss=0, total=4121.11, n_correct=248.73, ppl=17.15, accuracy=6.036, wps=25577.6, ups=2.08, wpb=12306.8, bsz=463.4, num_updates=800, lr=3.2084e-05, gnorm=0.879, clip=0, loss_scale=32, train_wall=48, gb_free=19.3, wall=471
2023-07-10 03:54:50 | INFO | train_inner | epoch 001:    902 / 1474 loss=9.205, trans_loss=5.396, nll_loss=4.078, w2v_ctc_loss=7.61, contrastive_loss=0, total=4167.98, n_correct=270.21, ppl=16.89, accuracy=6.483, wps=26034.5, ups=2.1, wpb=12422.1, bsz=457.5, num_updates=900, lr=3.6082e-05, gnorm=1.456, clip=0, loss_scale=32, train_wall=47, gb_free=19.2, wall=518
2023-07-10 03:55:38 | INFO | train_inner | epoch 001:   1002 / 1474 loss=8.929, trans_loss=5.372, nll_loss=4.05, w2v_ctc_loss=7.21, contrastive_loss=0, total=4136.38, n_correct=296.86, ppl=16.57, accuracy=7.177, wps=25613.1, ups=2.07, wpb=12363.4, bsz=458.8, num_updates=1000, lr=4.008e-05, gnorm=1.533, clip=0, loss_scale=32, train_wall=48, gb_free=19.5, wall=567
2023-07-10 03:56:26 | INFO | train_inner | epoch 001:   1102 / 1474 loss=8.65, trans_loss=5.366, nll_loss=4.046, w2v_ctc_loss=6.784, contrastive_loss=0, total=4148.31, n_correct=314.73, ppl=16.52, accuracy=7.587, wps=25871.5, ups=2.09, wpb=12363.5, bsz=453.4, num_updates=1100, lr=4.4078e-05, gnorm=1.947, clip=0, loss_scale=32, train_wall=47, gb_free=18.9, wall=614
2023-07-10 03:57:14 | INFO | train_inner | epoch 001:   1202 / 1474 loss=8.362, trans_loss=5.351, nll_loss=4.034, w2v_ctc_loss=6.35, contrastive_loss=0, total=4134.43, n_correct=326.44, ppl=16.38, accuracy=7.896, wps=25856, ups=2.09, wpb=12370.3, bsz=438.4, num_updates=1200, lr=4.8076e-05, gnorm=1.913, clip=0, loss_scale=32, train_wall=47, gb_free=19.6, wall=662
2023-07-10 03:58:01 | INFO | train_inner | epoch 001:   1302 / 1474 loss=8.102, trans_loss=5.35, nll_loss=4.038, w2v_ctc_loss=5.954, contrastive_loss=0, total=4055.44, n_correct=320.55, ppl=16.42, accuracy=7.904, wps=25380.1, ups=2.09, wpb=12117.4, bsz=442.9, num_updates=1300, lr=5.2074e-05, gnorm=1.853, clip=0, loss_scale=32, train_wall=47, gb_free=19.3, wall=710
2023-07-10 03:58:50 | INFO | train_inner | epoch 001:   1402 / 1474 loss=7.885, trans_loss=5.337, nll_loss=4.032, w2v_ctc_loss=5.638, contrastive_loss=0, total=4125.61, n_correct=340.38, ppl=16.36, accuracy=8.25, wps=25381.7, ups=2.07, wpb=12282.5, bsz=452, num_updates=1400, lr=5.6072e-05, gnorm=1.622, clip=0, loss_scale=32, train_wall=48, gb_free=18.8, wall=758
2023-07-10 03:59:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-07-10 03:59:57 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.726 | trans_loss 10.858 | nll_loss 9.811 | w2v_ctc_loss 5.983 | contrastive_loss 1.632 | total 4003.4 | n_correct 402.1 | ppl 898.54 | accuracy 10.044 | uer 73.262 | wer 71.69 | raw_wer 71.69 | bleu 0.03 | wps 1510.1 | wpb 4003.4 | bsz 141.8 | num_updates 1472
2023-07-10 03:59:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1472 updates
2023-07-10 03:59:57 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 03:59:59 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 04:00:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt (epoch 1 @ 1472 updates, score 0.03) (writing took 4.653552758012665 seconds)
2023-07-10 04:00:02 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-07-10 04:00:02 | INFO | train | epoch 001 | loss 10.81 | trans_loss 5.434 | nll_loss 4.102 | w2v_ctc_loss 10.029 | contrastive_loss 0 | total 4137.53 | n_correct 264.143 | ppl 17.17 | accuracy 6.384 | wps 24205.8 | ups 1.96 | wpb 12352.4 | bsz 458 | num_updates 1472 | lr 5.89506e-05 | gnorm 1.881 | clip 0 | loss_scale 32 | train_wall 710 | gb_free 19.2 | wall 830
2023-07-10 04:00:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 04:00:02 | INFO | fairseq.trainer | begin training epoch 2
2023-07-10 04:00:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 04:00:23 | INFO | train_inner | epoch 002:     28 / 1474 loss=7.668, trans_loss=5.332, nll_loss=4.019, w2v_ctc_loss=5.303, contrastive_loss=0, total=4164.65, n_correct=353.13, ppl=16.21, accuracy=8.479, wps=13340.3, ups=1.07, wpb=12416.9, bsz=471.6, num_updates=1500, lr=6.007e-05, gnorm=1.429, clip=0, loss_scale=32, train_wall=47, gb_free=18.9, wall=851
2023-07-10 04:01:12 | INFO | train_inner | epoch 002:    128 / 1474 loss=7.488, trans_loss=5.329, nll_loss=4.014, w2v_ctc_loss=5.029, contrastive_loss=0, total=4153.14, n_correct=363.11, ppl=16.15, accuracy=8.743, wps=25174.4, ups=2.03, wpb=12382.5, bsz=450.6, num_updates=1600, lr=6.4068e-05, gnorm=1.412, clip=0, loss_scale=32, train_wall=49, gb_free=19.8, wall=901
2023-07-10 04:02:00 | INFO | train_inner | epoch 002:    228 / 1474 loss=7.312, trans_loss=5.301, nll_loss=3.985, w2v_ctc_loss=4.789, contrastive_loss=0, total=4192.9, n_correct=373.46, ppl=15.83, accuracy=8.907, wps=26118.6, ups=2.09, wpb=12524.1, bsz=493, num_updates=1700, lr=6.8066e-05, gnorm=1.323, clip=0, loss_scale=32, train_wall=48, gb_free=19.2, wall=949
2023-07-10 04:02:48 | INFO | train_inner | epoch 002:    328 / 1474 loss=7.141, trans_loss=5.306, nll_loss=3.988, w2v_ctc_loss=4.52, contrastive_loss=0, total=4132.45, n_correct=371.69, ppl=15.86, accuracy=8.994, wps=25825.2, ups=2.09, wpb=12344.7, bsz=443.2, num_updates=1800, lr=7.2064e-05, gnorm=1.125, clip=0, loss_scale=32, train_wall=47, gb_free=19.4, wall=996
2023-07-10 04:03:35 | INFO | train_inner | epoch 002:    428 / 1474 loss=6.993, trans_loss=5.292, nll_loss=3.974, w2v_ctc_loss=4.307, contrastive_loss=0, total=4037.61, n_correct=364.88, ppl=15.71, accuracy=9.037, wps=25399, ups=2.1, wpb=12077.3, bsz=415.8, num_updates=1900, lr=7.6062e-05, gnorm=1.165, clip=0, loss_scale=32, train_wall=47, gb_free=19.9, wall=1044
2023-07-10 04:04:23 | INFO | train_inner | epoch 002:    528 / 1474 loss=6.882, trans_loss=5.273, nll_loss=3.947, w2v_ctc_loss=4.156, contrastive_loss=0, total=4183.4, n_correct=398.24, ppl=15.42, accuracy=9.52, wps=26134, ups=2.09, wpb=12489.2, bsz=470.3, num_updates=2000, lr=8.006e-05, gnorm=1.073, clip=0, loss_scale=32, train_wall=47, gb_free=19, wall=1092
2023-07-10 04:04:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 04:04:56 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 9.019 | trans_loss 10.58 | nll_loss 9.452 | w2v_ctc_loss 4.806 | contrastive_loss 0.956 | total 4003.4 | n_correct 456.7 | ppl 700.6 | accuracy 11.408 | uer 62.589 | wer 60.33 | raw_wer 60.33 | bleu 0.04 | wps 1519.4 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.04
2023-07-10 04:04:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-07-10 04:04:56 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_2_2000.pt
2023-07-10 04:04:58 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_2_2000.pt
2023-07-10 04:05:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.04) (writing took 8.705086342000868 seconds)
2023-07-10 04:05:52 | INFO | train_inner | epoch 002:    628 / 1474 loss=6.751, trans_loss=5.262, nll_loss=3.936, w2v_ctc_loss=3.966, contrastive_loss=0, total=4126.46, n_correct=401.27, ppl=15.31, accuracy=9.724, wps=13825.3, ups=1.12, wpb=12304.9, bsz=446.7, num_updates=2100, lr=8.4058e-05, gnorm=0.976, clip=0, loss_scale=64, train_wall=47, gb_free=19.3, wall=1181
2023-07-10 04:06:40 | INFO | train_inner | epoch 002:    728 / 1474 loss=6.681, trans_loss=5.252, nll_loss=3.926, w2v_ctc_loss=3.872, contrastive_loss=0, total=4148.66, n_correct=412.81, ppl=15.2, accuracy=9.95, wps=25886.9, ups=2.09, wpb=12368.2, bsz=462.9, num_updates=2200, lr=8.8056e-05, gnorm=0.949, clip=0, loss_scale=64, train_wall=47, gb_free=19.7, wall=1229
2023-07-10 04:07:28 | INFO | train_inner | epoch 002:    828 / 1474 loss=6.596, trans_loss=5.238, nll_loss=3.906, w2v_ctc_loss=3.752, contrastive_loss=0, total=4164.61, n_correct=416.07, ppl=15, accuracy=9.991, wps=26018.8, ups=2.09, wpb=12446.9, bsz=459.2, num_updates=2300, lr=9.2054e-05, gnorm=0.851, clip=0, loss_scale=64, train_wall=47, gb_free=19.5, wall=1276
2023-07-10 04:08:15 | INFO | train_inner | epoch 002:    928 / 1474 loss=6.513, trans_loss=5.228, nll_loss=3.895, w2v_ctc_loss=3.638, contrastive_loss=0, total=4109.63, n_correct=414.59, ppl=14.87, accuracy=10.088, wps=25815.9, ups=2.11, wpb=12261.8, bsz=447.9, num_updates=2400, lr=9.6052e-05, gnorm=0.839, clip=0, loss_scale=64, train_wall=47, gb_free=18.9, wall=1324
2023-07-10 04:09:03 | INFO | train_inner | epoch 002:   1028 / 1474 loss=6.412, trans_loss=5.219, nll_loss=3.882, w2v_ctc_loss=3.49, contrastive_loss=0, total=4101.19, n_correct=418.26, ppl=14.75, accuracy=10.199, wps=25725.6, ups=2.1, wpb=12262.4, bsz=454.5, num_updates=2500, lr=0.00010005, gnorm=0.731, clip=0, loss_scale=64, train_wall=47, gb_free=19, wall=1372
2023-07-10 04:09:51 | INFO | train_inner | epoch 002:   1128 / 1474 loss=6.389, trans_loss=5.21, nll_loss=3.874, w2v_ctc_loss=3.464, contrastive_loss=0, total=4192.73, n_correct=439.99, ppl=14.66, accuracy=10.494, wps=25865.8, ups=2.07, wpb=12503.4, bsz=488.9, num_updates=2600, lr=0.000104048, gnorm=0.743, clip=0, loss_scale=64, train_wall=48, gb_free=18.9, wall=1420
2023-07-10 04:10:40 | INFO | train_inner | epoch 002:   1228 / 1474 loss=6.324, trans_loss=5.197, nll_loss=3.856, w2v_ctc_loss=3.378, contrastive_loss=0, total=4219.96, n_correct=448.88, ppl=14.48, accuracy=10.637, wps=25854.1, ups=2.05, wpb=12583.5, bsz=491.8, num_updates=2700, lr=0.000108046, gnorm=0.667, clip=0, loss_scale=64, train_wall=48, gb_free=18.9, wall=1469
2023-07-10 04:11:28 | INFO | train_inner | epoch 002:   1328 / 1474 loss=6.223, trans_loss=5.186, nll_loss=3.846, w2v_ctc_loss=3.237, contrastive_loss=0, total=4163.26, n_correct=443.81, ppl=14.38, accuracy=10.66, wps=26063.3, ups=2.1, wpb=12439.7, bsz=463, num_updates=2800, lr=0.000112044, gnorm=0.65, clip=0, loss_scale=64, train_wall=47, gb_free=19, wall=1516
2023-07-10 04:12:16 | INFO | train_inner | epoch 002:   1428 / 1474 loss=6.202, trans_loss=5.185, nll_loss=3.84, w2v_ctc_loss=3.201, contrastive_loss=0, total=4049.42, n_correct=432.24, ppl=14.32, accuracy=10.674, wps=25289.3, ups=2.09, wpb=12112.8, bsz=437.6, num_updates=2900, lr=0.000116042, gnorm=0.691, clip=0, loss_scale=64, train_wall=47, gb_free=19.2, wall=1564
2023-07-10 04:12:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 04:13:10 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.366 | trans_loss 10.211 | nll_loss 8.984 | w2v_ctc_loss 3.749 | contrastive_loss 0.578 | total 4003.4 | n_correct 522.6 | ppl 506.51 | accuracy 13.054 | uer 51.631 | wer 50.55 | raw_wer 50.55 | bleu 0.05 | wps 1512.5 | wpb 4003.4 | bsz 141.8 | num_updates 2946 | best_bleu 0.05
2023-07-10 04:13:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2946 updates
2023-07-10 04:13:10 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 04:13:14 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 04:13:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt (epoch 2 @ 2946 updates, score 0.05) (writing took 8.23706054801005 seconds)
2023-07-10 04:13:19 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-07-10 04:13:19 | INFO | train | epoch 002 | loss 6.709 | trans_loss 5.248 | nll_loss 3.919 | w2v_ctc_loss 3.916 | contrastive_loss 0 | total 4138.65 | n_correct 407.092 | ppl 15.12 | accuracy 9.836 | wps 22852 | ups 1.85 | wpb 12355.8 | bsz 458.5 | num_updates 2946 | lr 0.000117881 | gnorm 0.941 | clip 0 | loss_scale 64 | train_wall 701 | gb_free 19.3 | wall 1627
2023-07-10 04:13:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 04:13:19 | INFO | fairseq.trainer | begin training epoch 3
2023-07-10 04:13:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 04:13:52 | INFO | train_inner | epoch 003:     54 / 1474 loss=6.125, trans_loss=5.173, nll_loss=3.826, w2v_ctc_loss=3.102, contrastive_loss=0, total=4067, n_correct=444.57, ppl=14.18, accuracy=10.931, wps=12534.3, ups=1.03, wpb=12138.5, bsz=441.4, num_updates=3000, lr=0.00012004, gnorm=0.616, clip=0, loss_scale=64, train_wall=48, gb_free=19.2, wall=1661
2023-07-10 04:13:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-10 04:13:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-10 04:13:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-10 04:14:59 | INFO | train_inner | epoch 003:    157 / 1474 loss=6.774, trans_loss=4.482, nll_loss=2.93, w2v_ctc_loss=4.842, contrastive_loss=0, total=4143.63, n_correct=1040.96, ppl=7.62, accuracy=25.122, wps=18687.1, ups=1.51, wpb=12373.7, bsz=457.1, num_updates=3100, lr=0.000124038, gnorm=1.893, clip=3, loss_scale=8, train_wall=66, gb_free=17, wall=1727
2023-07-10 04:16:04 | INFO | train_inner | epoch 003:    257 / 1474 loss=6.305, trans_loss=4.25, nll_loss=2.624, w2v_ctc_loss=4.367, contrastive_loss=0, total=4146.68, n_correct=1280.58, ppl=6.16, accuracy=30.882, wps=18970.9, ups=1.53, wpb=12407.9, bsz=461.7, num_updates=3200, lr=0.000128036, gnorm=1.226, clip=0, loss_scale=8, train_wall=65, gb_free=15.3, wall=1793
2023-07-10 04:17:09 | INFO | train_inner | epoch 003:    357 / 1474 loss=6.248, trans_loss=4.198, nll_loss=2.555, w2v_ctc_loss=4.336, contrastive_loss=0, total=4171.72, n_correct=1361.33, ppl=5.88, accuracy=32.632, wps=19149, ups=1.54, wpb=12430.3, bsz=468.1, num_updates=3300, lr=0.000132034, gnorm=1.303, clip=0, loss_scale=8, train_wall=65, gb_free=17.6, wall=1858
2023-07-10 04:18:14 | INFO | train_inner | epoch 003:    457 / 1474 loss=6.226, trans_loss=4.167, nll_loss=2.517, w2v_ctc_loss=4.339, contrastive_loss=0, total=4200.59, n_correct=1408.96, ppl=5.73, accuracy=33.542, wps=19187.9, ups=1.53, wpb=12508.3, bsz=475.4, num_updates=3400, lr=0.000136032, gnorm=1.38, clip=0, loss_scale=8, train_wall=65, gb_free=12.7, wall=1923
2023-07-10 04:19:19 | INFO | train_inner | epoch 003:    557 / 1474 loss=6.193, trans_loss=4.155, nll_loss=2.497, w2v_ctc_loss=4.291, contrastive_loss=0, total=4093.13, n_correct=1386.82, ppl=5.64, accuracy=33.882, wps=19006, ups=1.55, wpb=12255.6, bsz=440.1, num_updates=3500, lr=0.00014003, gnorm=1.319, clip=0, loss_scale=8, train_wall=64, gb_free=17.6, wall=1987
2023-07-10 04:20:24 | INFO | train_inner | epoch 003:    657 / 1474 loss=6.071, trans_loss=4.127, nll_loss=2.462, w2v_ctc_loss=4.145, contrastive_loss=0, total=4222.97, n_correct=1473.46, ppl=5.51, accuracy=34.892, wps=19074.2, ups=1.52, wpb=12561.4, bsz=483.6, num_updates=3600, lr=0.000144028, gnorm=1.298, clip=0, loss_scale=8, train_wall=65, gb_free=17, wall=2053
2023-07-10 04:21:29 | INFO | train_inner | epoch 003:    757 / 1474 loss=5.926, trans_loss=4.103, nll_loss=2.432, w2v_ctc_loss=3.938, contrastive_loss=0, total=4164.5, n_correct=1484.49, ppl=5.39, accuracy=35.646, wps=19252.9, ups=1.55, wpb=12455, bsz=470.6, num_updates=3700, lr=0.000148026, gnorm=1.264, clip=0, loss_scale=8, train_wall=64, gb_free=16.9, wall=2118
2023-07-10 04:22:34 | INFO | train_inner | epoch 003:    857 / 1474 loss=6.072, trans_loss=4.119, nll_loss=2.453, w2v_ctc_loss=4.144, contrastive_loss=0, total=4165.03, n_correct=1451.67, ppl=5.47, accuracy=34.854, wps=19055.4, ups=1.53, wpb=12441.6, bsz=457.7, num_updates=3800, lr=0.000152024, gnorm=1.783, clip=0, loss_scale=8, train_wall=65, gb_free=14.8, wall=2183
2023-07-10 04:23:40 | INFO | train_inner | epoch 003:    957 / 1474 loss=5.959, trans_loss=4.101, nll_loss=2.428, w2v_ctc_loss=3.992, contrastive_loss=0, total=4159.73, n_correct=1483.38, ppl=5.38, accuracy=35.66, wps=18918.7, ups=1.53, wpb=12402.6, bsz=467.1, num_updates=3900, lr=0.000156022, gnorm=1.747, clip=0, loss_scale=8, train_wall=65, gb_free=17.1, wall=2249
2023-07-10 04:24:44 | INFO | train_inner | epoch 003:   1057 / 1474 loss=5.934, trans_loss=4.099, nll_loss=2.425, w2v_ctc_loss=3.955, contrastive_loss=0, total=4059.97, n_correct=1444.12, ppl=5.37, accuracy=35.57, wps=18869.3, ups=1.55, wpb=12137.3, bsz=438.4, num_updates=4000, lr=0.00016002, gnorm=1.761, clip=0, loss_scale=8, train_wall=64, gb_free=17.4, wall=2313
2023-07-10 04:24:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 04:25:11 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.407 | trans_loss 7.466 | nll_loss 5.335 | w2v_ctc_loss 0.387 | contrastive_loss 0.393 | total 4003.4 | n_correct 1400.5 | ppl 40.36 | accuracy 34.983 | uer 72.784 | wer 73.387 | raw_wer 73.387 | bleu 3.14 | wps 1922.4 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 3.14
2023-07-10 04:25:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-07-10 04:25:11 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_3_4000.pt
2023-07-10 04:25:13 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_3_4000.pt
2023-07-10 04:25:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 3.14) (writing took 8.956033702008426 seconds)
2023-07-10 04:26:24 | INFO | train_inner | epoch 003:   1157 / 1474 loss=5.861, trans_loss=4.097, nll_loss=2.422, w2v_ctc_loss=3.844, contrastive_loss=0, total=4048.71, n_correct=1443.67, ppl=5.36, accuracy=35.658, wps=12158.7, ups=1.01, wpb=12091.3, bsz=437, num_updates=4100, lr=0.000164018, gnorm=1.812, clip=0, loss_scale=8, train_wall=64, gb_free=16.8, wall=2412
2023-07-10 04:27:28 | INFO | train_inner | epoch 003:   1257 / 1474 loss=5.721, trans_loss=4.08, nll_loss=2.401, w2v_ctc_loss=3.647, contrastive_loss=0, total=4063.12, n_correct=1481.33, ppl=5.28, accuracy=36.458, wps=18907.1, ups=1.56, wpb=12146.3, bsz=433.7, num_updates=4200, lr=0.000168016, gnorm=1.72, clip=0, loss_scale=8, train_wall=64, gb_free=13.7, wall=2477
2023-07-10 04:28:33 | INFO | train_inner | epoch 003:   1357 / 1474 loss=5.587, trans_loss=4.057, nll_loss=2.375, w2v_ctc_loss=3.472, contrastive_loss=0, total=4141.08, n_correct=1532.27, ppl=5.19, accuracy=37.002, wps=18927.1, ups=1.53, wpb=12348, bsz=463.4, num_updates=4300, lr=0.000172014, gnorm=1.779, clip=0, loss_scale=8, train_wall=65, gb_free=17.3, wall=2542
2023-07-10 04:29:38 | INFO | train_inner | epoch 003:   1457 / 1474 loss=5.467, trans_loss=4.047, nll_loss=2.36, w2v_ctc_loss=3.29, contrastive_loss=0, total=4212.48, n_correct=1573.61, ppl=5.14, accuracy=37.356, wps=19325.1, ups=1.54, wpb=12581.1, bsz=478.2, num_updates=4400, lr=0.000176012, gnorm=1.8, clip=0, loss_scale=8, train_wall=65, gb_free=16.8, wall=2607
2023-07-10 04:29:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 04:30:18 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.194 | trans_loss 7.188 | nll_loss 4.977 | w2v_ctc_loss 0.357 | contrastive_loss 0.361 | total 4003.4 | n_correct 1546.2 | ppl 31.5 | accuracy 38.622 | uer 69.795 | wer 70.78 | raw_wer 70.78 | bleu 4.63 | wps 1788.1 | wpb 4003.4 | bsz 141.8 | num_updates 4417 | best_bleu 4.63
2023-07-10 04:30:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4417 updates
2023-07-10 04:30:18 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 04:30:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 04:30:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt (epoch 3 @ 4417 updates, score 4.63) (writing took 8.203681620012503 seconds)
2023-07-10 04:30:26 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-07-10 04:30:26 | INFO | train | epoch 003 | loss 6.023 | trans_loss 4.185 | nll_loss 2.539 | w2v_ctc_loss 4.001 | contrastive_loss 0 | total 4139.61 | n_correct 1382.82 | ppl 5.81 | accuracy 33.404 | wps 17692 | ups 1.43 | wpb 12358.8 | bsz 458.8 | num_updates 4417 | lr 0.000176692 | gnorm 1.54 | clip 0.2 | loss_scale 8 | train_wall 942 | gb_free 16.8 | wall 2655
2023-07-10 04:30:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 04:30:26 | INFO | fairseq.trainer | begin training epoch 4
2023-07-10 04:30:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 04:31:27 | INFO | train_inner | epoch 004:     83 / 1474 loss=5.423, trans_loss=4.02, nll_loss=2.324, w2v_ctc_loss=3.265, contrastive_loss=0, total=4088.42, n_correct=1556.27, ppl=5.01, accuracy=38.065, wps=11187.1, ups=0.92, wpb=12184.2, bsz=437, num_updates=4500, lr=0.00018001, gnorm=1.885, clip=0, loss_scale=8, train_wall=64, gb_free=16.4, wall=2716
2023-07-10 04:32:32 | INFO | train_inner | epoch 004:    183 / 1474 loss=5.279, trans_loss=3.994, nll_loss=2.288, w2v_ctc_loss=3.068, contrastive_loss=0, total=4183.38, n_correct=1632.55, ppl=4.88, accuracy=39.025, wps=19400.9, ups=1.55, wpb=12489.2, bsz=469.7, num_updates=4600, lr=0.000184008, gnorm=1.659, clip=0, loss_scale=8, train_wall=64, gb_free=16.7, wall=2780
2023-07-10 04:33:37 | INFO | train_inner | epoch 004:    283 / 1474 loss=5.387, trans_loss=3.997, nll_loss=2.294, w2v_ctc_loss=3.232, contrastive_loss=0, total=4142.13, n_correct=1611.41, ppl=4.9, accuracy=38.903, wps=19054.1, ups=1.54, wpb=12379.5, bsz=463.3, num_updates=4700, lr=0.000188006, gnorm=1.716, clip=0, loss_scale=8, train_wall=65, gb_free=13.4, wall=2845
2023-07-10 04:34:41 | INFO | train_inner | epoch 004:    383 / 1474 loss=5.26, trans_loss=3.99, nll_loss=2.282, w2v_ctc_loss=3.042, contrastive_loss=0, total=4132.81, n_correct=1625.19, ppl=4.86, accuracy=39.324, wps=19025, ups=1.55, wpb=12313.3, bsz=443.6, num_updates=4800, lr=0.000192004, gnorm=1.723, clip=0, loss_scale=8, train_wall=64, gb_free=14.8, wall=2910
2023-07-10 04:35:47 | INFO | train_inner | epoch 004:    483 / 1474 loss=5.185, trans_loss=3.969, nll_loss=2.259, w2v_ctc_loss=2.944, contrastive_loss=0, total=4205.11, n_correct=1686.71, ppl=4.79, accuracy=40.111, wps=19063.4, ups=1.52, wpb=12541.4, bsz=493.7, num_updates=4900, lr=0.000196002, gnorm=1.676, clip=0, loss_scale=8, train_wall=65, gb_free=17.1, wall=2976
2023-07-10 04:36:53 | INFO | train_inner | epoch 004:    583 / 1474 loss=5.231, trans_loss=3.962, nll_loss=2.248, w2v_ctc_loss=3.027, contrastive_loss=0, total=4224.38, n_correct=1712.17, ppl=4.75, accuracy=40.531, wps=19180.7, ups=1.52, wpb=12597.9, bsz=488.9, num_updates=5000, lr=0.0002, gnorm=1.856, clip=0, loss_scale=8, train_wall=65, gb_free=12.5, wall=3041
1.0
tensor(0.8475, device='cuda:0')
2023-07-10 04:37:59 | INFO | train_inner | epoch 004:    683 / 1474 loss=5.179, trans_loss=3.963, nll_loss=2.246, w2v_ctc_loss=2.942, contrastive_loss=0, total=4182.18, n_correct=1698.95, ppl=4.74, accuracy=40.624, wps=18847.2, ups=1.51, wpb=12460.6, bsz=457.4, num_updates=5100, lr=0.00019803, gnorm=1.524, clip=0, loss_scale=16, train_wall=66, gb_free=12.5, wall=3108
2023-07-10 04:39:04 | INFO | train_inner | epoch 004:    783 / 1474 loss=5.114, trans_loss=3.964, nll_loss=2.247, w2v_ctc_loss=2.837, contrastive_loss=0, total=4025.8, n_correct=1630.26, ppl=4.75, accuracy=40.495, wps=18592.1, ups=1.54, wpb=12047, bsz=419.8, num_updates=5200, lr=0.000196116, gnorm=1.585, clip=0, loss_scale=16, train_wall=64, gb_free=16.8, wall=3172
2023-07-10 04:40:09 | INFO | train_inner | epoch 004:    883 / 1474 loss=5.171, trans_loss=3.938, nll_loss=2.219, w2v_ctc_loss=2.958, contrastive_loss=0, total=4179.58, n_correct=1732.58, ppl=4.66, accuracy=41.453, wps=19081.3, ups=1.53, wpb=12473.5, bsz=464.4, num_updates=5300, lr=0.000194257, gnorm=1.47, clip=0, loss_scale=16, train_wall=65, gb_free=14.6, wall=3238
2023-07-10 04:41:14 | INFO | train_inner | epoch 004:    983 / 1474 loss=5.033, trans_loss=3.924, nll_loss=2.2, w2v_ctc_loss=2.762, contrastive_loss=0, total=4131.6, n_correct=1734.39, ppl=4.59, accuracy=41.979, wps=18958.9, ups=1.54, wpb=12339, bsz=459.5, num_updates=5400, lr=0.00019245, gnorm=1.507, clip=0, loss_scale=16, train_wall=65, gb_free=15.1, wall=3303
2023-07-10 04:42:19 | INFO | train_inner | epoch 004:   1083 / 1474 loss=4.997, trans_loss=3.939, nll_loss=2.217, w2v_ctc_loss=2.675, contrastive_loss=0, total=4071.42, n_correct=1691.58, ppl=4.65, accuracy=41.548, wps=18699.5, ups=1.54, wpb=12153.3, bsz=434.6, num_updates=5500, lr=0.000190693, gnorm=1.365, clip=0, loss_scale=16, train_wall=65, gb_free=16.4, wall=3368
2023-07-10 04:43:24 | INFO | train_inner | epoch 004:   1183 / 1474 loss=4.904, trans_loss=3.915, nll_loss=2.187, w2v_ctc_loss=2.564, contrastive_loss=0, total=4161.85, n_correct=1772, ppl=4.55, accuracy=42.577, wps=19164.5, ups=1.54, wpb=12456.2, bsz=483.8, num_updates=5600, lr=0.000188982, gnorm=1.387, clip=0, loss_scale=16, train_wall=65, gb_free=12.7, wall=3433
2023-07-10 04:44:29 | INFO | train_inner | epoch 004:   1283 / 1474 loss=5.034, trans_loss=3.907, nll_loss=2.176, w2v_ctc_loss=2.766, contrastive_loss=0, total=4152.03, n_correct=1784.79, ppl=4.52, accuracy=42.986, wps=19243.4, ups=1.55, wpb=12413.9, bsz=471, num_updates=5700, lr=0.000187317, gnorm=1.598, clip=0, loss_scale=16, train_wall=64, gb_free=16.7, wall=3497
2023-07-10 04:45:33 | INFO | train_inner | epoch 004:   1383 / 1474 loss=4.955, trans_loss=3.901, nll_loss=2.169, w2v_ctc_loss=2.659, contrastive_loss=0, total=4099.25, n_correct=1764.74, ppl=4.5, accuracy=43.05, wps=19159.1, ups=1.56, wpb=12246, bsz=436.9, num_updates=5800, lr=0.000185695, gnorm=1.423, clip=0, loss_scale=16, train_wall=64, gb_free=12, wall=3561
2023-07-10 04:46:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
1.0
tensor(0.8475, device='cuda:4')
1.0
tensor(0.8475, device='cuda:6')
1.0
tensor(0.8475, device='cuda:5')
1.0
tensor(0.8475, device='cuda:1')
1.0
tensor(0.8475, device='cuda:3')
1.0
tensor(0.8475, device='cuda:7')
1.0
tensor(0.8475, device='cuda:2')
2023-07-10 04:46:59 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.868 | trans_loss 6.794 | nll_loss 4.437 | w2v_ctc_loss 0.238 | contrastive_loss 0.292 | total 4003.4 | n_correct 1743.9 | ppl 21.66 | accuracy 43.56 | uer 63.09 | wer 63.253 | raw_wer 63.253 | bleu 7.34 | wps 1882 | wpb 4003.4 | bsz 141.8 | num_updates 5891 | best_bleu 7.34
2023-07-10 04:46:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5891 updates
2023-07-10 04:46:59 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 04:47:03 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 04:47:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt (epoch 4 @ 5891 updates, score 7.34) (writing took 8.14612382199266 seconds)
2023-07-10 04:47:07 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-07-10 04:47:07 | INFO | train | epoch 004 | loss 5.139 | trans_loss 3.952 | nll_loss 2.234 | w2v_ctc_loss 2.891 | contrastive_loss 0 | total 4138.65 | n_correct 1694.59 | ppl 4.7 | accuracy 40.946 | wps 18196.7 | ups 1.47 | wpb 12355.8 | bsz 458.5 | num_updates 5891 | lr 0.000184256 | gnorm 1.593 | clip 0 | loss_scale 16 | train_wall 951 | gb_free 15 | wall 3656
2023-07-10 04:47:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 04:47:07 | INFO | fairseq.trainer | begin training epoch 5
2023-07-10 04:47:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 04:47:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-10 04:47:21 | INFO | train_inner | epoch 005:     10 / 1474 loss=4.958, trans_loss=3.897, nll_loss=2.162, w2v_ctc_loss=2.662, contrastive_loss=0, total=4042.41, n_correct=1749.07, ppl=4.48, accuracy=43.268, wps=11115.5, ups=0.92, wpb=12075, bsz=441.4, num_updates=5900, lr=0.000184115, gnorm=1.567, clip=0, loss_scale=8, train_wall=64, gb_free=17, wall=3670
2023-07-10 04:48:27 | INFO | train_inner | epoch 005:    110 / 1474 loss=4.741, trans_loss=3.841, nll_loss=2.091, w2v_ctc_loss=2.412, contrastive_loss=0, total=4247.37, n_correct=1903.25, ppl=4.26, accuracy=44.81, wps=19362.2, ups=1.53, wpb=12683.8, bsz=495.1, num_updates=6000, lr=0.000182574, gnorm=1.229, clip=0, loss_scale=8, train_wall=65, gb_free=16.9, wall=3735
2023-07-10 04:48:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 04:48:55 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.816 | trans_loss 6.759 | nll_loss 4.388 | w2v_ctc_loss 0.153 | contrastive_loss 0.275 | total 4003.4 | n_correct 1771.5 | ppl 20.94 | accuracy 44.25 | uer 61.349 | wer 62.619 | raw_wer 62.619 | bleu 7.21 | wps 1736.1 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 7.34
2023-07-10 04:48:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-07-10 04:48:55 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_5_6000.pt
2023-07-10 04:48:57 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_5_6000.pt
2023-07-10 04:49:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 7.21) (writing took 6.135274947009748 seconds)
2023-07-10 04:50:06 | INFO | train_inner | epoch 005:    210 / 1474 loss=4.83, trans_loss=3.844, nll_loss=2.094, w2v_ctc_loss=2.538, contrastive_loss=0, total=4189.85, n_correct=1875.7, ppl=4.27, accuracy=44.768, wps=12579.3, ups=1.01, wpb=12492.8, bsz=488.2, num_updates=6100, lr=0.000181071, gnorm=1.321, clip=0, loss_scale=8, train_wall=65, gb_free=17.9, wall=3835
2023-07-10 04:51:10 | INFO | train_inner | epoch 005:    310 / 1474 loss=4.775, trans_loss=3.848, nll_loss=2.101, w2v_ctc_loss=2.446, contrastive_loss=0, total=4090.1, n_correct=1823.37, ppl=4.29, accuracy=44.58, wps=19022.4, ups=1.55, wpb=12240, bsz=443.9, num_updates=6200, lr=0.000179605, gnorm=1.515, clip=0, loss_scale=8, train_wall=64, gb_free=16.4, wall=3899
2023-07-10 04:52:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-07-10 04:52:16 | INFO | train_inner | epoch 005:    411 / 1474 loss=4.922, trans_loss=3.848, nll_loss=2.103, w2v_ctc_loss=2.672, contrastive_loss=0, total=4126.36, n_correct=1843.11, ppl=4.3, accuracy=44.667, wps=18725.4, ups=1.52, wpb=12325.6, bsz=459.8, num_updates=6300, lr=0.000178174, gnorm=1.744, clip=0, loss_scale=4, train_wall=65, gb_free=16.2, wall=3965
2023-07-10 04:53:21 | INFO | train_inner | epoch 005:    511 / 1474 loss=4.871, trans_loss=3.852, nll_loss=2.103, w2v_ctc_loss=2.591, contrastive_loss=0, total=4026.21, n_correct=1793.71, ppl=4.3, accuracy=44.551, wps=18631.3, ups=1.55, wpb=12048.3, bsz=418.1, num_updates=6400, lr=0.000176777, gnorm=1.515, clip=0, loss_scale=4, train_wall=64, gb_free=17.1, wall=4030
2023-07-10 04:54:26 | INFO | train_inner | epoch 005:    611 / 1474 loss=4.778, trans_loss=3.854, nll_loss=2.106, w2v_ctc_loss=2.453, contrastive_loss=0, total=4109.94, n_correct=1832.48, ppl=4.3, accuracy=44.587, wps=18810.4, ups=1.54, wpb=12248.6, bsz=449.8, num_updates=6500, lr=0.000175412, gnorm=1.509, clip=0, loss_scale=4, train_wall=65, gb_free=15.6, wall=4095
2023-07-10 04:55:31 | INFO | train_inner | epoch 005:    711 / 1474 loss=4.706, trans_loss=3.835, nll_loss=2.084, w2v_ctc_loss=2.355, contrastive_loss=0, total=4176.83, n_correct=1891.45, ppl=4.24, accuracy=45.284, wps=19225.3, ups=1.54, wpb=12457.5, bsz=483.6, num_updates=6600, lr=0.000174078, gnorm=1.345, clip=0, loss_scale=4, train_wall=64, gb_free=17.1, wall=4160
2023-07-10 04:56:36 | INFO | train_inner | epoch 005:    811 / 1474 loss=4.86, trans_loss=3.843, nll_loss=2.092, w2v_ctc_loss=2.588, contrastive_loss=0, total=4127.9, n_correct=1864.7, ppl=4.26, accuracy=45.173, wps=18828.4, ups=1.53, wpb=12323.4, bsz=447.5, num_updates=6700, lr=0.000172774, gnorm=1.464, clip=0, loss_scale=4, train_wall=65, gb_free=15.9, wall=4225
2023-07-10 04:57:41 | INFO | train_inner | epoch 005:    911 / 1474 loss=4.748, trans_loss=3.833, nll_loss=2.079, w2v_ctc_loss=2.414, contrastive_loss=0, total=4101.19, n_correct=1867.24, ppl=4.23, accuracy=45.529, wps=18927.5, ups=1.54, wpb=12253.6, bsz=447.9, num_updates=6800, lr=0.000171499, gnorm=1.449, clip=0, loss_scale=4, train_wall=64, gb_free=17.3, wall=4290
2023-07-10 04:58:46 | INFO | train_inner | epoch 005:   1011 / 1474 loss=4.686, trans_loss=3.827, nll_loss=2.073, w2v_ctc_loss=2.333, contrastive_loss=0, total=4164.27, n_correct=1913.28, ppl=4.21, accuracy=45.945, wps=19276.6, ups=1.55, wpb=12422.1, bsz=462, num_updates=6900, lr=0.000170251, gnorm=1.199, clip=0, loss_scale=4, train_wall=64, gb_free=15.2, wall=4354
2023-07-10 04:59:51 | INFO | train_inner | epoch 005:   1111 / 1474 loss=4.707, trans_loss=3.827, nll_loss=2.07, w2v_ctc_loss=2.366, contrastive_loss=0, total=4168.94, n_correct=1921.23, ppl=4.2, accuracy=46.084, wps=18957.2, ups=1.52, wpb=12445, bsz=464.1, num_updates=7000, lr=0.000169031, gnorm=1.246, clip=0, loss_scale=4, train_wall=65, gb_free=16.8, wall=4420
2023-07-10 05:00:56 | INFO | train_inner | epoch 005:   1211 / 1474 loss=4.768, trans_loss=3.824, nll_loss=2.067, w2v_ctc_loss=2.46, contrastive_loss=0, total=4171.16, n_correct=1926.69, ppl=4.19, accuracy=46.191, wps=19121.1, ups=1.54, wpb=12438.5, bsz=456.3, num_updates=7100, lr=0.000167836, gnorm=1.521, clip=0, loss_scale=4, train_wall=65, gb_free=16, wall=4485
2023-07-10 05:02:01 | INFO | train_inner | epoch 005:   1311 / 1474 loss=4.587, trans_loss=3.823, nll_loss=2.064, w2v_ctc_loss=2.177, contrastive_loss=0, total=4126.97, n_correct=1907.31, ppl=4.18, accuracy=46.216, wps=18958.8, ups=1.54, wpb=12334.6, bsz=443.4, num_updates=7200, lr=0.000166667, gnorm=1.367, clip=0, loss_scale=4, train_wall=65, gb_free=15.7, wall=4550
2023-07-10 05:03:07 | INFO | train_inner | epoch 005:   1411 / 1474 loss=4.738, trans_loss=3.811, nll_loss=2.056, w2v_ctc_loss=2.43, contrastive_loss=0, total=4138.54, n_correct=1917.13, ppl=4.16, accuracy=46.324, wps=18895.7, ups=1.53, wpb=12347.9, bsz=459, num_updates=7300, lr=0.000165521, gnorm=1.567, clip=0, loss_scale=4, train_wall=65, gb_free=16.9, wall=4615
2023-07-10 05:03:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 05:04:18 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.694 | trans_loss 6.498 | nll_loss 4.046 | w2v_ctc_loss 0.37 | contrastive_loss 0.255 | total 4003.4 | n_correct 1912.2 | ppl 16.52 | accuracy 47.764 | uer 58.44 | wer 58.715 | raw_wer 58.715 | bleu 9.85 | wps 1641.4 | wpb 4003.4 | bsz 141.8 | num_updates 7363 | best_bleu 9.85
2023-07-10 05:04:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7363 updates
2023-07-10 05:04:18 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 05:04:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 05:04:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt (epoch 5 @ 7363 updates, score 9.85) (writing took 8.15231718699215 seconds)
2023-07-10 05:04:26 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-07-10 05:04:26 | INFO | train | epoch 005 | loss 4.764 | trans_loss 3.836 | nll_loss 2.083 | w2v_ctc_loss 2.444 | contrastive_loss 0 | total 4137.28 | n_correct 1877.21 | ppl 4.24 | accuracy 45.373 | wps 17493.4 | ups 1.42 | wpb 12352.2 | bsz 457.8 | num_updates 7363 | lr 0.000164812 | gnorm 1.437 | clip 0 | loss_scale 4 | train_wall 952 | gb_free 16.4 | wall 4695
2023-07-10 05:04:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 05:04:27 | INFO | fairseq.trainer | begin training epoch 6
2023-07-10 05:04:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 05:04:59 | INFO | train_inner | epoch 006:     37 / 1474 loss=4.665, trans_loss=3.802, nll_loss=2.04, w2v_ctc_loss=2.33, contrastive_loss=0, total=4113.87, n_correct=1920.09, ppl=4.11, accuracy=46.674, wps=10932.9, ups=0.89, wpb=12273.6, bsz=447.4, num_updates=7400, lr=0.000164399, gnorm=1.429, clip=0, loss_scale=4, train_wall=65, gb_free=17.9, wall=4728
2023-07-10 05:06:04 | INFO | train_inner | epoch 006:    137 / 1474 loss=4.544, trans_loss=3.773, nll_loss=2.002, w2v_ctc_loss=2.18, contrastive_loss=0, total=4161.2, n_correct=1969.39, ppl=4.01, accuracy=47.327, wps=19102.9, ups=1.54, wpb=12431.6, bsz=458.1, num_updates=7500, lr=0.000163299, gnorm=1.404, clip=0, loss_scale=4, train_wall=65, gb_free=17, wall=4793
2023-07-10 05:07:09 | INFO | train_inner | epoch 006:    237 / 1474 loss=4.616, trans_loss=3.789, nll_loss=2.025, w2v_ctc_loss=2.27, contrastive_loss=0, total=4110.12, n_correct=1915.88, ppl=4.07, accuracy=46.614, wps=18940.9, ups=1.54, wpb=12274.1, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=1.462, clip=0, loss_scale=4, train_wall=64, gb_free=17.2, wall=4857
2023-07-10 05:08:15 | INFO | train_inner | epoch 006:    337 / 1474 loss=4.625, trans_loss=3.761, nll_loss=1.99, w2v_ctc_loss=2.312, contrastive_loss=0, total=4170.52, n_correct=1998.81, ppl=3.97, accuracy=47.927, wps=18727.9, ups=1.5, wpb=12444.2, bsz=488.4, num_updates=7700, lr=0.000161165, gnorm=1.307, clip=0, loss_scale=4, train_wall=66, gb_free=15.8, wall=4924
2023-07-10 05:09:20 | INFO | train_inner | epoch 006:    437 / 1474 loss=4.559, trans_loss=3.77, nll_loss=1.998, w2v_ctc_loss=2.197, contrastive_loss=0, total=4154.89, n_correct=1987.17, ppl=3.99, accuracy=47.827, wps=19270.3, ups=1.55, wpb=12406.7, bsz=470.4, num_updates=7800, lr=0.000160128, gnorm=1.393, clip=0, loss_scale=4, train_wall=64, gb_free=16.6, wall=4988
2023-07-10 05:10:24 | INFO | train_inner | epoch 006:    537 / 1474 loss=4.592, trans_loss=3.769, nll_loss=1.999, w2v_ctc_loss=2.265, contrastive_loss=0, total=4174.46, n_correct=2000.03, ppl=4, accuracy=47.911, wps=19236.1, ups=1.55, wpb=12441.4, bsz=458.3, num_updates=7900, lr=0.000159111, gnorm=1.404, clip=0, loss_scale=4, train_wall=64, gb_free=17.3, wall=5053
2023-07-10 05:11:29 | INFO | train_inner | epoch 006:    637 / 1474 loss=4.487, trans_loss=3.771, nll_loss=1.997, w2v_ctc_loss=2.093, contrastive_loss=0, total=4145.19, n_correct=1987.85, ppl=3.99, accuracy=47.956, wps=19179.7, ups=1.55, wpb=12391.8, bsz=470.9, num_updates=8000, lr=0.000158114, gnorm=1.358, clip=0, loss_scale=4, train_wall=64, gb_free=16, wall=5118
2023-07-10 05:11:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 05:11:54 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.637 | trans_loss 6.485 | nll_loss 4.025 | w2v_ctc_loss 0.213 | contrastive_loss 0.248 | total 4003.4 | n_correct 1910.2 | ppl 16.28 | accuracy 47.714 | uer 57.37 | wer 58.245 | raw_wer 58.245 | bleu 9.65 | wps 1998.8 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 9.85
2023-07-10 05:11:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-07-10 05:11:54 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_6_8000.pt
2023-07-10 05:11:57 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_6_8000.pt
2023-07-10 05:12:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 9.65) (writing took 6.279494804999558 seconds)
2023-07-10 05:13:06 | INFO | train_inner | epoch 006:    737 / 1474 loss=4.661, trans_loss=3.776, nll_loss=2.007, w2v_ctc_loss=2.358, contrastive_loss=0, total=4151.01, n_correct=1976.04, ppl=4.02, accuracy=47.604, wps=12740.5, ups=1.03, wpb=12384.3, bsz=454.2, num_updates=8100, lr=0.000157135, gnorm=1.6, clip=0, loss_scale=4, train_wall=65, gb_free=13.2, wall=5215
2023-07-10 05:14:11 | INFO | train_inner | epoch 006:    837 / 1474 loss=4.634, trans_loss=3.782, nll_loss=2.014, w2v_ctc_loss=2.307, contrastive_loss=0, total=4108.83, n_correct=1949.21, ppl=4.04, accuracy=47.44, wps=18844.4, ups=1.54, wpb=12275.7, bsz=439.4, num_updates=8200, lr=0.000156174, gnorm=1.471, clip=0, loss_scale=4, train_wall=65, gb_free=17.2, wall=5280
2023-07-10 05:15:17 | INFO | train_inner | epoch 006:    937 / 1474 loss=4.66, trans_loss=3.78, nll_loss=2.013, w2v_ctc_loss=2.346, contrastive_loss=0, total=4076.46, n_correct=1939.67, ppl=4.04, accuracy=47.582, wps=18560.4, ups=1.53, wpb=12153.2, bsz=443, num_updates=8300, lr=0.00015523, gnorm=1.608, clip=0, loss_scale=4, train_wall=65, gb_free=12.9, wall=5345
2023-07-10 05:16:22 | INFO | train_inner | epoch 006:   1037 / 1474 loss=4.593, trans_loss=3.762, nll_loss=1.99, w2v_ctc_loss=2.263, contrastive_loss=0, total=4175.9, n_correct=2017.66, ppl=3.97, accuracy=48.317, wps=19220.6, ups=1.54, wpb=12465.4, bsz=480.4, num_updates=8400, lr=0.000154303, gnorm=1.383, clip=0, loss_scale=8, train_wall=64, gb_free=14.4, wall=5410
2023-07-10 05:17:27 | INFO | train_inner | epoch 006:   1137 / 1474 loss=4.646, trans_loss=3.776, nll_loss=2.007, w2v_ctc_loss=2.318, contrastive_loss=0, total=4077.2, n_correct=1948.67, ppl=4.02, accuracy=47.794, wps=18686.5, ups=1.53, wpb=12179.9, bsz=430.6, num_updates=8500, lr=0.000153393, gnorm=1.461, clip=0, loss_scale=8, train_wall=65, gb_free=16.4, wall=5475
2023-07-10 05:18:32 | INFO | train_inner | epoch 006:   1237 / 1474 loss=4.683, trans_loss=3.762, nll_loss=1.99, w2v_ctc_loss=2.404, contrastive_loss=0, total=4133.46, n_correct=1998.95, ppl=3.97, accuracy=48.36, wps=18874.4, ups=1.53, wpb=12360.6, bsz=470.3, num_updates=8600, lr=0.000152499, gnorm=1.512, clip=0, loss_scale=8, train_wall=65, gb_free=12.7, wall=5541
2023-07-10 05:19:37 | INFO | train_inner | epoch 006:   1337 / 1474 loss=4.531, trans_loss=3.764, nll_loss=1.988, w2v_ctc_loss=2.167, contrastive_loss=0, total=4127.77, n_correct=2010.75, ppl=3.97, accuracy=48.713, wps=19175.3, ups=1.56, wpb=12325.7, bsz=454.1, num_updates=8700, lr=0.00015162, gnorm=1.248, clip=0, loss_scale=8, train_wall=64, gb_free=17.1, wall=5605
2023-07-10 05:20:42 | INFO | train_inner | epoch 006:   1437 / 1474 loss=4.519, trans_loss=3.76, nll_loss=1.989, w2v_ctc_loss=2.156, contrastive_loss=0, total=4190.32, n_correct=2037.98, ppl=3.97, accuracy=48.635, wps=19098.6, ups=1.53, wpb=12495.5, bsz=460.5, num_updates=8800, lr=0.000150756, gnorm=1.283, clip=0, loss_scale=8, train_wall=65, gb_free=17, wall=5671
2023-07-10 05:21:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 05:21:33 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.582 | trans_loss 6.345 | nll_loss 3.843 | w2v_ctc_loss 0.367 | contrastive_loss 0.231 | total 4003.4 | n_correct 1988.8 | ppl 14.35 | accuracy 49.678 | uer 53.97 | wer 54.89 | raw_wer 54.89 | bleu 11.27 | wps 1840.7 | wpb 4003.4 | bsz 141.8 | num_updates 8837 | best_bleu 11.27
2023-07-10 05:21:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8837 updates
2023-07-10 05:21:33 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 05:21:37 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 05:21:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt (epoch 6 @ 8837 updates, score 11.27) (writing took 8.314475141989533 seconds)
2023-07-10 05:21:42 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-07-10 05:21:42 | INFO | train | epoch 006 | loss 4.593 | trans_loss 3.77 | nll_loss 2 | w2v_ctc_loss 2.255 | contrastive_loss 0 | total 4138.65 | n_correct 1981.61 | ppl 4 | accuracy 47.881 | wps 17593.3 | ups 1.42 | wpb 12355.8 | bsz 458.5 | num_updates 8837 | lr 0.00015044 | gnorm 1.414 | clip 0 | loss_scale 8 | train_wall 953 | gb_free 15.3 | wall 5730
2023-07-10 05:21:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 05:21:42 | INFO | fairseq.trainer | begin training epoch 7
2023-07-10 05:21:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 05:22:31 | INFO | train_inner | epoch 007:     63 / 1474 loss=4.486, trans_loss=3.726, nll_loss=1.943, w2v_ctc_loss=2.138, contrastive_loss=0, total=4110.43, n_correct=2033.13, ppl=3.84, accuracy=49.463, wps=11263.6, ups=0.92, wpb=12276.6, bsz=462.8, num_updates=8900, lr=0.000149906, gnorm=1.278, clip=0, loss_scale=8, train_wall=65, gb_free=17.4, wall=5780
2023-07-10 05:23:36 | INFO | train_inner | epoch 007:    163 / 1474 loss=4.463, trans_loss=3.727, nll_loss=1.944, w2v_ctc_loss=2.109, contrastive_loss=0, total=4109.53, n_correct=2025.84, ppl=3.85, accuracy=49.296, wps=18910.7, ups=1.54, wpb=12264.3, bsz=454.1, num_updates=9000, lr=0.000149071, gnorm=1.387, clip=0, loss_scale=8, train_wall=64, gb_free=13.8, wall=5844
2023-07-10 05:24:41 | INFO | train_inner | epoch 007:    263 / 1474 loss=4.429, trans_loss=3.721, nll_loss=1.934, w2v_ctc_loss=2.057, contrastive_loss=0, total=4133.29, n_correct=2050.88, ppl=3.82, accuracy=49.619, wps=19089.5, ups=1.55, wpb=12339.3, bsz=455.5, num_updates=9100, lr=0.00014825, gnorm=1.38, clip=0, loss_scale=8, train_wall=64, gb_free=15.5, wall=5909
2023-07-10 05:25:46 | INFO | train_inner | epoch 007:    363 / 1474 loss=4.489, trans_loss=3.728, nll_loss=1.944, w2v_ctc_loss=2.142, contrastive_loss=0, total=4194.76, n_correct=2070.2, ppl=3.85, accuracy=49.352, wps=19050.2, ups=1.52, wpb=12509.7, bsz=477.6, num_updates=9200, lr=0.000147442, gnorm=1.392, clip=0, loss_scale=8, train_wall=65, gb_free=13.3, wall=5975
2023-07-10 05:26:51 | INFO | train_inner | epoch 007:    463 / 1474 loss=4.602, trans_loss=3.73, nll_loss=1.951, w2v_ctc_loss=2.313, contrastive_loss=0, total=4153.22, n_correct=2040.3, ppl=3.87, accuracy=49.126, wps=19139.2, ups=1.55, wpb=12386.6, bsz=463, num_updates=9300, lr=0.000146647, gnorm=1.585, clip=0, loss_scale=8, train_wall=64, gb_free=17, wall=6040
2023-07-10 05:27:56 | INFO | train_inner | epoch 007:    563 / 1474 loss=4.491, trans_loss=3.725, nll_loss=1.942, w2v_ctc_loss=2.147, contrastive_loss=0, total=4168.14, n_correct=2066.99, ppl=3.84, accuracy=49.59, wps=19086, ups=1.54, wpb=12410.5, bsz=459.8, num_updates=9400, lr=0.000145865, gnorm=1.514, clip=0, loss_scale=8, train_wall=65, gb_free=17, wall=6105
2023-07-10 05:29:02 | INFO | train_inner | epoch 007:    663 / 1474 loss=4.425, trans_loss=3.734, nll_loss=1.95, w2v_ctc_loss=2.024, contrastive_loss=0, total=4157.82, n_correct=2053.27, ppl=3.86, accuracy=49.383, wps=18904.3, ups=1.52, wpb=12417.8, bsz=455.4, num_updates=9500, lr=0.000145095, gnorm=1.405, clip=0, loss_scale=8, train_wall=65, gb_free=15.8, wall=6170
2023-07-10 05:30:07 | INFO | train_inner | epoch 007:    763 / 1474 loss=4.451, trans_loss=3.733, nll_loss=1.95, w2v_ctc_loss=2.081, contrastive_loss=0, total=4122.1, n_correct=2035.34, ppl=3.86, accuracy=49.376, wps=18854.3, ups=1.53, wpb=12321.9, bsz=446.2, num_updates=9600, lr=0.000144338, gnorm=1.319, clip=0, loss_scale=8, train_wall=65, gb_free=15.8, wall=6236
2023-07-10 05:31:12 | INFO | train_inner | epoch 007:    863 / 1474 loss=4.321, trans_loss=3.725, nll_loss=1.939, w2v_ctc_loss=1.888, contrastive_loss=0, total=4147.23, n_correct=2060.65, ppl=3.84, accuracy=49.687, wps=18947.6, ups=1.53, wpb=12392, bsz=460.9, num_updates=9700, lr=0.000143592, gnorm=1.123, clip=0, loss_scale=8, train_wall=65, gb_free=17.6, wall=6301
2023-07-10 05:32:18 | INFO | train_inner | epoch 007:    963 / 1474 loss=4.427, trans_loss=3.719, nll_loss=1.934, w2v_ctc_loss=2.047, contrastive_loss=0, total=4140.14, n_correct=2072.07, ppl=3.82, accuracy=50.048, wps=18973.3, ups=1.54, wpb=12360, bsz=474.6, num_updates=9800, lr=0.000142857, gnorm=1.401, clip=0, loss_scale=8, train_wall=65, gb_free=16.1, wall=6366
2023-07-10 05:33:23 | INFO | train_inner | epoch 007:   1063 / 1474 loss=4.524, trans_loss=3.736, nll_loss=1.955, w2v_ctc_loss=2.185, contrastive_loss=0, total=4103.51, n_correct=2026.61, ppl=3.88, accuracy=49.387, wps=18873.6, ups=1.54, wpb=12263.4, bsz=437.5, num_updates=9900, lr=0.000142134, gnorm=1.531, clip=0, loss_scale=8, train_wall=65, gb_free=16.9, wall=6431
2023-07-10 05:34:28 | INFO | train_inner | epoch 007:   1163 / 1474 loss=4.552, trans_loss=3.717, nll_loss=1.937, w2v_ctc_loss=2.25, contrastive_loss=0, total=4137.04, n_correct=2064.28, ppl=3.83, accuracy=49.898, wps=18946.9, ups=1.53, wpb=12348.6, bsz=470.9, num_updates=10000, lr=0.000141421, gnorm=1.538, clip=0, loss_scale=8, train_wall=65, gb_free=16.3, wall=6496
2023-07-10 05:34:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 05:34:51 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.544 | trans_loss 6.388 | nll_loss 3.894 | w2v_ctc_loss 0.14 | contrastive_loss 0.23 | total 4003.4 | n_correct 1974.1 | ppl 14.86 | accuracy 49.311 | uer 55.671 | wer 57.47 | raw_wer 57.47 | bleu 10.7 | wps 2295.7 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 11.27
2023-07-10 05:34:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-07-10 05:34:51 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_7_10000.pt
2023-07-10 05:34:53 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_7_10000.pt
2023-07-10 05:34:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 10.7) (writing took 6.070784211013233 seconds)
1.0
tensor(0.5528, device='cuda:0')
2023-07-10 05:36:02 | INFO | train_inner | epoch 007:   1263 / 1474 loss=4.335, trans_loss=3.72, nll_loss=1.936, w2v_ctc_loss=1.914, contrastive_loss=0, total=4129.52, n_correct=2059.5, ppl=3.83, accuracy=49.873, wps=13047.4, ups=1.06, wpb=12329.2, bsz=450.2, num_updates=10100, lr=0.00014072, gnorm=0.997, clip=0, loss_scale=8, train_wall=64, gb_free=17, wall=6591
2023-07-10 05:37:07 | INFO | train_inner | epoch 007:   1363 / 1474 loss=4.37, trans_loss=3.706, nll_loss=1.919, w2v_ctc_loss=1.982, contrastive_loss=0, total=4172.87, n_correct=2110.17, ppl=3.78, accuracy=50.569, wps=19269.8, ups=1.55, wpb=12453.5, bsz=476.2, num_updates=10200, lr=0.000140028, gnorm=0.907, clip=0, loss_scale=8, train_wall=64, gb_free=17.3, wall=6655
2023-07-10 05:38:13 | INFO | train_inner | epoch 007:   1463 / 1474 loss=4.429, trans_loss=3.723, nll_loss=1.941, w2v_ctc_loss=2.049, contrastive_loss=0, total=4109.42, n_correct=2052.81, ppl=3.84, accuracy=49.954, wps=18650, ups=1.52, wpb=12285.7, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.972, clip=0, loss_scale=8, train_wall=65, gb_free=16.6, wall=6721
2023-07-10 05:38:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
1.0
tensor(0.5528, device='cuda:7')
1.0
tensor(0.5528, device='cuda:6')
1.0
tensor(0.5528, device='cuda:3')
1.0
tensor(0.5528, device='cuda:1')
1.0
tensor(0.5528, device='cuda:5')
1.0
tensor(0.5528, device='cuda:4')
1.0
tensor(0.5528, device='cuda:2')
2023-07-10 05:38:44 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.492 | trans_loss 6.299 | nll_loss 3.78 | w2v_ctc_loss 0.175 | contrastive_loss 0.226 | total 4003.4 | n_correct 2019.5 | ppl 13.73 | accuracy 50.445 | uer 53.274 | wer 54.823 | raw_wer 54.823 | bleu 11.4 | wps 2174.3 | wpb 4003.4 | bsz 141.8 | num_updates 10311 | best_bleu 11.4
2023-07-10 05:38:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10311 updates
2023-07-10 05:38:44 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 05:38:48 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 05:38:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt (epoch 7 @ 10311 updates, score 11.4) (writing took 8.090632173989434 seconds)
2023-07-10 05:38:52 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-07-10 05:38:52 | INFO | train | epoch 007 | loss 4.451 | trans_loss 3.724 | nll_loss 1.941 | w2v_ctc_loss 2.087 | contrastive_loss 0 | total 4138.65 | n_correct 2055.04 | ppl 3.84 | accuracy 49.655 | wps 17668.6 | ups 1.43 | wpb 12355.8 | bsz 458.5 | num_updates 10311 | lr 0.000139272 | gnorm 1.314 | clip 0 | loss_scale 8 | train_wall 954 | gb_free 13.5 | wall 6761
2023-07-10 05:38:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 05:38:53 | INFO | fairseq.trainer | begin training epoch 8
2023-07-10 05:38:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 05:39:59 | INFO | train_inner | epoch 008:     89 / 1474 loss=4.337, trans_loss=3.692, nll_loss=1.896, w2v_ctc_loss=1.945, contrastive_loss=0, total=4116.25, n_correct=2093.08, ppl=3.72, accuracy=50.849, wps=11581.2, ups=0.94, wpb=12265.9, bsz=443.3, num_updates=10400, lr=0.000138675, gnorm=0.877, clip=0, loss_scale=16, train_wall=65, gb_free=17.1, wall=6827
2023-07-10 05:41:04 | INFO | train_inner | epoch 008:    189 / 1474 loss=4.286, trans_loss=3.694, nll_loss=1.899, w2v_ctc_loss=1.877, contrastive_loss=0, total=4037.23, n_correct=2049.55, ppl=3.73, accuracy=50.766, wps=18521.3, ups=1.54, wpb=12033.3, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.873, clip=0, loss_scale=16, train_wall=65, gb_free=13.1, wall=6892
2023-07-10 05:42:09 | INFO | train_inner | epoch 008:    289 / 1474 loss=4.271, trans_loss=3.68, nll_loss=1.881, w2v_ctc_loss=1.864, contrastive_loss=0, total=4207.78, n_correct=2157.42, ppl=3.68, accuracy=51.272, wps=19160.3, ups=1.52, wpb=12570.1, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.919, clip=0, loss_scale=16, train_wall=65, gb_free=13.3, wall=6958
2023-07-10 05:43:15 | INFO | train_inner | epoch 008:    389 / 1474 loss=4.371, trans_loss=3.692, nll_loss=1.897, w2v_ctc_loss=2.001, contrastive_loss=0, total=4127.24, n_correct=2092.26, ppl=3.73, accuracy=50.694, wps=18613.8, ups=1.51, wpb=12318.5, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=1.05, clip=0, loss_scale=16, train_wall=66, gb_free=12.1, wall=7024
2023-07-10 05:44:21 | INFO | train_inner | epoch 008:    489 / 1474 loss=4.303, trans_loss=3.682, nll_loss=1.886, w2v_ctc_loss=1.9, contrastive_loss=0, total=4203.76, n_correct=2155.63, ppl=3.69, accuracy=51.279, wps=19114.1, ups=1.52, wpb=12567.7, bsz=504.5, num_updates=10800, lr=0.000136083, gnorm=0.889, clip=0, loss_scale=16, train_wall=65, gb_free=14.7, wall=7090
2023-07-10 05:45:27 | INFO | train_inner | epoch 008:    589 / 1474 loss=4.319, trans_loss=3.69, nll_loss=1.897, w2v_ctc_loss=1.924, contrastive_loss=0, total=4062.5, n_correct=2061.79, ppl=3.72, accuracy=50.752, wps=18594.3, ups=1.53, wpb=12171.9, bsz=427.9, num_updates=10900, lr=0.000135457, gnorm=0.966, clip=0, loss_scale=16, train_wall=65, gb_free=11.7, wall=7155
2023-07-10 05:46:31 | INFO | train_inner | epoch 008:    689 / 1474 loss=4.297, trans_loss=3.684, nll_loss=1.89, w2v_ctc_loss=1.886, contrastive_loss=0, total=4142.78, n_correct=2121.57, ppl=3.71, accuracy=51.211, wps=19039.4, ups=1.54, wpb=12347.9, bsz=448.6, num_updates=11000, lr=0.00013484, gnorm=0.908, clip=0, loss_scale=16, train_wall=64, gb_free=16, wall=7220
2023-07-10 05:47:37 | INFO | train_inner | epoch 008:    789 / 1474 loss=4.211, trans_loss=3.678, nll_loss=1.883, w2v_ctc_loss=1.774, contrastive_loss=0, total=4118.9, n_correct=2114.45, ppl=3.69, accuracy=51.335, wps=18923.1, ups=1.53, wpb=12327.8, bsz=447.8, num_updates=11100, lr=0.000134231, gnorm=0.831, clip=0, loss_scale=16, train_wall=65, gb_free=15.3, wall=7285
2023-07-10 05:48:42 | INFO | train_inner | epoch 008:    889 / 1474 loss=4.316, trans_loss=3.677, nll_loss=1.883, w2v_ctc_loss=1.934, contrastive_loss=0, total=4169.01, n_correct=2148.69, ppl=3.69, accuracy=51.54, wps=19048.6, ups=1.53, wpb=12455.3, bsz=473.7, num_updates=11200, lr=0.000133631, gnorm=0.898, clip=0, loss_scale=16, train_wall=65, gb_free=16.3, wall=7351
2023-07-10 05:49:47 | INFO | train_inner | epoch 008:    989 / 1474 loss=4.221, trans_loss=3.673, nll_loss=1.877, w2v_ctc_loss=1.789, contrastive_loss=0, total=4154.69, n_correct=2147.44, ppl=3.67, accuracy=51.687, wps=19043.7, ups=1.54, wpb=12398.4, bsz=464.9, num_updates=11300, lr=0.000133038, gnorm=0.894, clip=0, loss_scale=16, train_wall=65, gb_free=17.8, wall=7416
2023-07-10 05:50:53 | INFO | train_inner | epoch 008:   1089 / 1474 loss=4.301, trans_loss=3.681, nll_loss=1.888, w2v_ctc_loss=1.909, contrastive_loss=0, total=4199.1, n_correct=2154.72, ppl=3.7, accuracy=51.314, wps=19001.1, ups=1.52, wpb=12520.7, bsz=465.3, num_updates=11400, lr=0.000132453, gnorm=0.96, clip=0, loss_scale=16, train_wall=65, gb_free=13, wall=7482
2023-07-10 05:51:58 | INFO | train_inner | epoch 008:   1189 / 1474 loss=4.279, trans_loss=3.673, nll_loss=1.877, w2v_ctc_loss=1.882, contrastive_loss=0, total=4177.31, n_correct=2165.62, ppl=3.67, accuracy=51.842, wps=19134.9, ups=1.53, wpb=12476.4, bsz=472.6, num_updates=11500, lr=0.000131876, gnorm=0.925, clip=0, loss_scale=16, train_wall=65, gb_free=15.1, wall=7547
2023-07-10 05:53:03 | INFO | train_inner | epoch 008:   1289 / 1474 loss=4.29, trans_loss=3.679, nll_loss=1.886, w2v_ctc_loss=1.883, contrastive_loss=0, total=4063.85, n_correct=2087.83, ppl=3.7, accuracy=51.376, wps=18739.2, ups=1.54, wpb=12141.2, bsz=438.4, num_updates=11600, lr=0.000131306, gnorm=0.868, clip=0, loss_scale=16, train_wall=64, gb_free=16.9, wall=7612
2023-07-10 05:54:28 | INFO | train_inner | epoch 008:   1389 / 1474 loss=4.247, trans_loss=3.678, nll_loss=1.885, w2v_ctc_loss=1.83, contrastive_loss=0, total=4141.5, n_correct=2138.87, ppl=3.69, accuracy=51.645, wps=14505.3, ups=1.17, wpb=12351.9, bsz=461.5, num_updates=11700, lr=0.000130744, gnorm=0.905, clip=0, loss_scale=16, train_wall=85, gb_free=16.6, wall=7697
2023-07-10 05:55:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 05:55:47 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.419 | trans_loss 6.183 | nll_loss 3.625 | w2v_ctc_loss 0.209 | contrastive_loss 0.218 | total 4003.4 | n_correct 2089.4 | ppl 12.34 | accuracy 52.191 | uer 50.848 | wer 52.574 | raw_wer 52.574 | bleu 12.68 | wps 2400.9 | wpb 4003.4 | bsz 141.8 | num_updates 11785 | best_bleu 12.68
2023-07-10 05:55:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11785 updates
2023-07-10 05:55:47 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 05:55:51 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 05:55:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt (epoch 8 @ 11785 updates, score 12.68) (writing took 8.184002023015637 seconds)
2023-07-10 05:55:55 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-07-10 05:55:55 | INFO | train | epoch 008 | loss 4.285 | trans_loss 3.682 | nll_loss 1.887 | w2v_ctc_loss 1.879 | contrastive_loss 0 | total 4138.65 | n_correct 2122.9 | ppl 3.7 | accuracy 51.295 | wps 17812.2 | ups 1.44 | wpb 12355.8 | bsz 458.5 | num_updates 11785 | lr 0.000130272 | gnorm 0.909 | clip 0 | loss_scale 16 | train_wall 977 | gb_free 17.1 | wall 7784
2023-07-10 05:55:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 05:55:55 | INFO | fairseq.trainer | begin training epoch 9
2023-07-10 05:55:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 05:56:13 | INFO | train_inner | epoch 009:     15 / 1474 loss=4.246, trans_loss=3.67, nll_loss=1.874, w2v_ctc_loss=1.834, contrastive_loss=0, total=4139.35, n_correct=2149.95, ppl=3.66, accuracy=51.939, wps=11744.4, ups=0.95, wpb=12332.8, bsz=472.9, num_updates=11800, lr=0.000130189, gnorm=0.889, clip=0, loss_scale=16, train_wall=65, gb_free=16.2, wall=7802
2023-07-10 05:57:18 | INFO | train_inner | epoch 009:    115 / 1474 loss=4.151, trans_loss=3.645, nll_loss=1.84, w2v_ctc_loss=1.719, contrastive_loss=0, total=4181.9, n_correct=2193.44, ppl=3.58, accuracy=52.451, wps=19226.2, ups=1.54, wpb=12493.2, bsz=475.9, num_updates=11900, lr=0.000129641, gnorm=0.889, clip=0, loss_scale=16, train_wall=65, gb_free=16.4, wall=7867
2023-07-10 05:58:24 | INFO | train_inner | epoch 009:    215 / 1474 loss=4.196, trans_loss=3.657, nll_loss=1.853, w2v_ctc_loss=1.773, contrastive_loss=0, total=4062.07, n_correct=2119.33, ppl=3.61, accuracy=52.174, wps=18494.1, ups=1.52, wpb=12136.5, bsz=431.6, num_updates=12000, lr=0.000129099, gnorm=0.927, clip=0, loss_scale=16, train_wall=65, gb_free=15.7, wall=7932
2023-07-10 05:58:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 05:58:46 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.437 | trans_loss 6.2 | nll_loss 3.648 | w2v_ctc_loss 0.232 | contrastive_loss 0.212 | total 4003.4 | n_correct 2078.5 | ppl 12.54 | accuracy 51.918 | uer 50.625 | wer 52.306 | raw_wer 52.306 | bleu 12.57 | wps 2462.4 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 12.68
2023-07-10 05:58:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-07-10 05:58:46 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_9_12000.pt
2023-07-10 05:58:48 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_9_12000.pt
2023-07-10 05:58:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 12.57) (writing took 5.95108075600001 seconds)
2023-07-10 05:59:58 | INFO | train_inner | epoch 009:    315 / 1474 loss=4.146, trans_loss=3.641, nll_loss=1.834, w2v_ctc_loss=1.712, contrastive_loss=0, total=4152.1, n_correct=2188.82, ppl=3.57, accuracy=52.716, wps=13245, ups=1.07, wpb=12422.8, bsz=476.6, num_updates=12100, lr=0.000128565, gnorm=0.935, clip=0, loss_scale=16, train_wall=64, gb_free=16.4, wall=8026
2023-07-10 06:01:04 | INFO | train_inner | epoch 009:    415 / 1474 loss=4.16, trans_loss=3.65, nll_loss=1.847, w2v_ctc_loss=1.722, contrastive_loss=0, total=4203.78, n_correct=2197.21, ppl=3.6, accuracy=52.267, wps=18985.9, ups=1.51, wpb=12545.5, bsz=469.8, num_updates=12200, lr=0.000128037, gnorm=0.916, clip=0, loss_scale=16, train_wall=66, gb_free=17.2, wall=8092
2023-07-10 06:02:08 | INFO | train_inner | epoch 009:    515 / 1474 loss=4.194, trans_loss=3.659, nll_loss=1.859, w2v_ctc_loss=1.761, contrastive_loss=0, total=4112.78, n_correct=2145.28, ppl=3.63, accuracy=52.161, wps=18913.2, ups=1.54, wpb=12260.1, bsz=437.7, num_updates=12300, lr=0.000127515, gnorm=0.975, clip=0, loss_scale=16, train_wall=64, gb_free=16.3, wall=8157
2023-07-10 06:03:14 | INFO | train_inner | epoch 009:    615 / 1474 loss=4.169, trans_loss=3.649, nll_loss=1.847, w2v_ctc_loss=1.744, contrastive_loss=0, total=4131.32, n_correct=2164.9, ppl=3.6, accuracy=52.402, wps=18964.4, ups=1.53, wpb=12355.3, bsz=455, num_updates=12400, lr=0.000127, gnorm=0.915, clip=0, loss_scale=16, train_wall=65, gb_free=17.9, wall=8222
2023-07-10 06:03:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-10 06:04:19 | INFO | train_inner | epoch 009:    716 / 1474 loss=4.219, trans_loss=3.656, nll_loss=1.854, w2v_ctc_loss=1.797, contrastive_loss=0, total=4071.59, n_correct=2123.76, ppl=3.62, accuracy=52.16, wps=18531.3, ups=1.52, wpb=12173.8, bsz=445.9, num_updates=12500, lr=0.000126491, gnorm=0.949, clip=0, loss_scale=16, train_wall=65, gb_free=17.1, wall=8288
2023-07-10 06:05:25 | INFO | train_inner | epoch 009:    816 / 1474 loss=4.168, trans_loss=3.641, nll_loss=1.841, w2v_ctc_loss=1.748, contrastive_loss=0, total=4220.43, n_correct=2217.41, ppl=3.58, accuracy=52.54, wps=19139, ups=1.52, wpb=12596.8, bsz=501.1, num_updates=12600, lr=0.000125988, gnorm=0.955, clip=0, loss_scale=16, train_wall=65, gb_free=14.6, wall=8354
2023-07-10 06:06:31 | INFO | train_inner | epoch 009:    916 / 1474 loss=4.255, trans_loss=3.653, nll_loss=1.85, w2v_ctc_loss=1.871, contrastive_loss=0, total=4146.05, n_correct=2174.77, ppl=3.61, accuracy=52.454, wps=18673.2, ups=1.51, wpb=12355.9, bsz=450.3, num_updates=12700, lr=0.000125491, gnorm=0.951, clip=0, loss_scale=16, train_wall=66, gb_free=17.9, wall=8420
2023-07-10 06:07:37 | INFO | train_inner | epoch 009:   1016 / 1474 loss=4.186, trans_loss=3.668, nll_loss=1.868, w2v_ctc_loss=1.747, contrastive_loss=0, total=4101.48, n_correct=2128.66, ppl=3.65, accuracy=51.9, wps=18769.5, ups=1.53, wpb=12243.2, bsz=424.4, num_updates=12800, lr=0.000125, gnorm=1.004, clip=0, loss_scale=16, train_wall=65, gb_free=16.1, wall=8485
2023-07-10 06:08:42 | INFO | train_inner | epoch 009:   1116 / 1474 loss=4.141, trans_loss=3.649, nll_loss=1.844, w2v_ctc_loss=1.7, contrastive_loss=0, total=4179.09, n_correct=2205.18, ppl=3.59, accuracy=52.767, wps=19133.9, ups=1.54, wpb=12439.9, bsz=474.7, num_updates=12900, lr=0.000124515, gnorm=0.989, clip=0, loss_scale=16, train_wall=65, gb_free=15.5, wall=8550
2023-07-10 06:09:47 | INFO | train_inner | epoch 009:   1216 / 1474 loss=4.22, trans_loss=3.662, nll_loss=1.858, w2v_ctc_loss=1.787, contrastive_loss=0, total=4140.66, n_correct=2167.55, ppl=3.62, accuracy=52.348, wps=18946.7, ups=1.53, wpb=12405, bsz=448.1, num_updates=13000, lr=0.000124035, gnorm=0.975, clip=0, loss_scale=16, train_wall=65, gb_free=17.2, wall=8616
2023-07-10 06:10:52 | INFO | train_inner | epoch 009:   1316 / 1474 loss=4.181, trans_loss=3.643, nll_loss=1.838, w2v_ctc_loss=1.766, contrastive_loss=0, total=4204.43, n_correct=2229.58, ppl=3.57, accuracy=53.029, wps=19255.7, ups=1.54, wpb=12539.3, bsz=492.5, num_updates=13100, lr=0.00012356, gnorm=0.958, clip=0, loss_scale=16, train_wall=65, gb_free=17.8, wall=8681
2023-07-10 06:11:57 | INFO | train_inner | epoch 009:   1416 / 1474 loss=4.193, trans_loss=3.66, nll_loss=1.858, w2v_ctc_loss=1.757, contrastive_loss=0, total=4069.19, n_correct=2133.16, ppl=3.62, accuracy=52.422, wps=18680.5, ups=1.54, wpb=12152.5, bsz=427.7, num_updates=13200, lr=0.000123091, gnorm=0.919, clip=0, loss_scale=16, train_wall=65, gb_free=16.8, wall=8746
2023-07-10 06:12:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 06:13:00 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.394 | trans_loss 6.113 | nll_loss 3.538 | w2v_ctc_loss 0.289 | contrastive_loss 0.216 | total 4003.4 | n_correct 2133.2 | ppl 11.62 | accuracy 53.285 | uer 49.404 | wer 50.912 | raw_wer 50.912 | bleu 13.3 | wps 2064.3 | wpb 4003.4 | bsz 141.8 | num_updates 13258 | best_bleu 13.3
2023-07-10 06:13:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13258 updates
2023-07-10 06:13:00 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 06:13:04 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 06:13:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt (epoch 9 @ 13258 updates, score 13.3) (writing took 8.166144750983221 seconds)
2023-07-10 06:13:08 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-07-10 06:13:08 | INFO | train | epoch 009 | loss 4.187 | trans_loss 3.652 | nll_loss 1.849 | w2v_ctc_loss 1.762 | contrastive_loss 0 | total 4138 | n_correct 2169.86 | ppl 3.6 | accuracy 52.437 | wps 17608.7 | ups 1.43 | wpb 12353.8 | bsz 458.3 | num_updates 13258 | lr 0.000122822 | gnorm 0.948 | clip 0 | loss_scale 16 | train_wall 956 | gb_free 12 | wall 8817
2023-07-10 06:13:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 06:13:09 | INFO | fairseq.trainer | begin training epoch 10
2023-07-10 06:13:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 06:13:44 | INFO | train_inner | epoch 010:     42 / 1474 loss=4.197, trans_loss=3.634, nll_loss=1.825, w2v_ctc_loss=1.8, contrastive_loss=0, total=4100.8, n_correct=2180.59, ppl=3.54, accuracy=53.175, wps=11498.7, ups=0.94, wpb=12243.3, bsz=469.4, num_updates=13300, lr=0.000122628, gnorm=0.953, clip=0, loss_scale=16, train_wall=64, gb_free=16.4, wall=8852
2023-07-10 06:14:49 | INFO | train_inner | epoch 010:    142 / 1474 loss=4.111, trans_loss=3.622, nll_loss=1.807, w2v_ctc_loss=1.679, contrastive_loss=0, total=4247.35, n_correct=2271.49, ppl=3.5, accuracy=53.48, wps=19438, ups=1.53, wpb=12717.5, bsz=479.6, num_updates=13400, lr=0.000122169, gnorm=0.948, clip=0, loss_scale=16, train_wall=65, gb_free=12.1, wall=8918
2023-07-10 06:15:54 | INFO | train_inner | epoch 010:    242 / 1474 loss=4.121, trans_loss=3.618, nll_loss=1.807, w2v_ctc_loss=1.704, contrastive_loss=0, total=4122.82, n_correct=2201.83, ppl=3.5, accuracy=53.406, wps=19002.9, ups=1.55, wpb=12279.5, bsz=461.4, num_updates=13500, lr=0.000121716, gnorm=0.928, clip=0, loss_scale=16, train_wall=64, gb_free=16.4, wall=8982
2023-07-10 06:16:59 | INFO | train_inner | epoch 010:    342 / 1474 loss=4.117, trans_loss=3.619, nll_loss=1.808, w2v_ctc_loss=1.698, contrastive_loss=0, total=4138.27, n_correct=2210.19, ppl=3.5, accuracy=53.409, wps=18940.1, ups=1.53, wpb=12378.7, bsz=453.8, num_updates=13600, lr=0.000121268, gnorm=0.922, clip=0, loss_scale=16, train_wall=65, gb_free=16.5, wall=9048
2023-07-10 06:18:06 | INFO | train_inner | epoch 010:    442 / 1474 loss=4.091, trans_loss=3.624, nll_loss=1.813, w2v_ctc_loss=1.646, contrastive_loss=0, total=4196.37, n_correct=2237.07, ppl=3.51, accuracy=53.31, wps=18863.8, ups=1.51, wpb=12523.5, bsz=481.1, num_updates=13700, lr=0.000120824, gnorm=0.935, clip=0, loss_scale=16, train_wall=66, gb_free=16.6, wall=9114
2023-07-10 06:19:11 | INFO | train_inner | epoch 010:    542 / 1474 loss=4.211, trans_loss=3.637, nll_loss=1.827, w2v_ctc_loss=1.818, contrastive_loss=0, total=4102.8, n_correct=2176.58, ppl=3.55, accuracy=53.051, wps=18765.4, ups=1.54, wpb=12224.8, bsz=437.8, num_updates=13800, lr=0.000120386, gnorm=1.038, clip=0, loss_scale=16, train_wall=65, gb_free=17.1, wall=9179
2023-07-10 06:20:16 | INFO | train_inner | epoch 010:    642 / 1474 loss=4.14, trans_loss=3.628, nll_loss=1.818, w2v_ctc_loss=1.712, contrastive_loss=0, total=4176.56, n_correct=2231.24, ppl=3.53, accuracy=53.423, wps=19018.5, ups=1.53, wpb=12467.5, bsz=477.2, num_updates=13900, lr=0.000119952, gnorm=0.976, clip=0, loss_scale=16, train_wall=65, gb_free=16.4, wall=9245
2023-07-10 06:21:21 | INFO | train_inner | epoch 010:    742 / 1474 loss=4.166, trans_loss=3.63, nll_loss=1.821, w2v_ctc_loss=1.754, contrastive_loss=0, total=4125.87, n_correct=2200.36, ppl=3.53, accuracy=53.331, wps=19088.8, ups=1.55, wpb=12315.5, bsz=454.4, num_updates=14000, lr=0.000119523, gnorm=0.993, clip=0, loss_scale=16, train_wall=64, gb_free=14.7, wall=9309
2023-07-10 06:21:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 06:21:46 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.36 | trans_loss 6.083 | nll_loss 3.501 | w2v_ctc_loss 0.251 | contrastive_loss 0.21 | total 4003.4 | n_correct 2153.7 | ppl 11.32 | accuracy 53.797 | uer 48.257 | wer 49.808 | raw_wer 49.808 | bleu 14.13 | wps 2045.4 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 14.13
2023-07-10 06:21:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-07-10 06:21:46 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_10_14000.pt
2023-07-10 06:21:48 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_10_14000.pt
2023-07-10 06:21:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 14.13) (writing took 8.86257577300421 seconds)
2023-07-10 06:23:00 | INFO | train_inner | epoch 010:    842 / 1474 loss=4.121, trans_loss=3.626, nll_loss=1.814, w2v_ctc_loss=1.684, contrastive_loss=0, total=4128.44, n_correct=2207.64, ppl=3.52, accuracy=53.474, wps=12383.8, ups=1, wpb=12345, bsz=456.3, num_updates=14100, lr=0.000119098, gnorm=0.977, clip=0, loss_scale=16, train_wall=65, gb_free=14.9, wall=9409
2023-07-10 06:24:05 | INFO | train_inner | epoch 010:    942 / 1474 loss=4.132, trans_loss=3.625, nll_loss=1.816, w2v_ctc_loss=1.719, contrastive_loss=0, total=4160.94, n_correct=2224.71, ppl=3.52, accuracy=53.467, wps=19174.4, ups=1.55, wpb=12380.2, bsz=468.1, num_updates=14200, lr=0.000118678, gnorm=1.004, clip=0, loss_scale=16, train_wall=64, gb_free=15.6, wall=9474
2023-07-10 06:25:10 | INFO | train_inner | epoch 010:   1042 / 1474 loss=4.121, trans_loss=3.634, nll_loss=1.827, w2v_ctc_loss=1.678, contrastive_loss=0, total=4067.53, n_correct=2157.69, ppl=3.55, accuracy=53.047, wps=18554.7, ups=1.53, wpb=12142, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.982, clip=0, loss_scale=16, train_wall=65, gb_free=17, wall=9539
2023-07-10 06:26:15 | INFO | train_inner | epoch 010:   1142 / 1474 loss=4.184, trans_loss=3.64, nll_loss=1.835, w2v_ctc_loss=1.771, contrastive_loss=0, total=4044.03, n_correct=2136.63, ppl=3.57, accuracy=52.834, wps=18698.4, ups=1.55, wpb=12072.9, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=1.021, clip=0, loss_scale=16, train_wall=64, gb_free=17.4, wall=9604
2023-07-10 06:27:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-10 06:27:20 | INFO | train_inner | epoch 010:   1243 / 1474 loss=4.036, trans_loss=3.628, nll_loss=1.822, w2v_ctc_loss=1.556, contrastive_loss=0, total=4101.73, n_correct=2187.55, ppl=3.54, accuracy=53.332, wps=18796.6, ups=1.53, wpb=12280.2, bsz=444.8, num_updates=14500, lr=0.000117444, gnorm=1.011, clip=0, loss_scale=16, train_wall=65, gb_free=16.9, wall=9669
2023-07-10 06:28:25 | INFO | train_inner | epoch 010:   1343 / 1474 loss=4.147, trans_loss=3.627, nll_loss=1.819, w2v_ctc_loss=1.735, contrastive_loss=0, total=4127.69, n_correct=2206.28, ppl=3.53, accuracy=53.451, wps=18952.8, ups=1.54, wpb=12331.3, bsz=452.2, num_updates=14600, lr=0.000117041, gnorm=1.023, clip=0, loss_scale=16, train_wall=65, gb_free=16.3, wall=9734
2023-07-10 06:29:31 | INFO | train_inner | epoch 010:   1443 / 1474 loss=4.127, trans_loss=3.63, nll_loss=1.824, w2v_ctc_loss=1.692, contrastive_loss=0, total=4195.02, n_correct=2243.07, ppl=3.54, accuracy=53.47, wps=19047.6, ups=1.53, wpb=12488.3, bsz=483, num_updates=14700, lr=0.000116642, gnorm=0.909, clip=0, loss_scale=16, train_wall=65, gb_free=16.7, wall=9800
2023-07-10 06:29:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 06:30:13 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.361 | trans_loss 6.112 | nll_loss 3.532 | w2v_ctc_loss 0.188 | contrastive_loss 0.206 | total 4003.4 | n_correct 2137.9 | ppl 11.57 | accuracy 53.402 | uer 49.484 | wer 51.389 | raw_wer 51.389 | bleu 13.38 | wps 2642.8 | wpb 4003.4 | bsz 141.8 | num_updates 14731 | best_bleu 14.13
2023-07-10 06:30:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14731 updates
2023-07-10 06:30:13 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_13.3805.pt
2023-07-10 06:30:15 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_13.3805.pt
2023-07-10 06:30:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_13.3805.pt (epoch 10 @ 14731 updates, score 13.38) (writing took 5.175054196006386 seconds)
2023-07-10 06:30:18 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-07-10 06:30:18 | INFO | train | epoch 010 | loss 4.129 | trans_loss 3.628 | nll_loss 1.818 | w2v_ctc_loss 1.701 | contrastive_loss 0 | total 4138.36 | n_correct 2206.81 | ppl 3.53 | accuracy 53.326 | wps 17675.2 | ups 1.43 | wpb 12355.2 | bsz 458.5 | num_updates 14731 | lr 0.00011652 | gnorm 0.974 | clip 0 | loss_scale 16 | train_wall 954 | gb_free 17.4 | wall 9847
2023-07-10 06:30:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 06:30:18 | INFO | fairseq.trainer | begin training epoch 11
2023-07-10 06:30:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 06:31:10 | INFO | train_inner | epoch 011:     69 / 1474 loss=4.035, trans_loss=3.607, nll_loss=1.792, w2v_ctc_loss=1.584, contrastive_loss=0, total=4166, n_correct=2251.2, ppl=3.46, accuracy=54.037, wps=12496.9, ups=1.01, wpb=12433.1, bsz=475.7, num_updates=14800, lr=0.000116248, gnorm=0.925, clip=0, loss_scale=16, train_wall=64, gb_free=17.9, wall=9899
2023-07-10 06:32:16 | INFO | train_inner | epoch 011:    169 / 1474 loss=4.076, trans_loss=3.606, nll_loss=1.791, w2v_ctc_loss=1.648, contrastive_loss=0, total=4100.74, n_correct=2209.05, ppl=3.46, accuracy=53.87, wps=18823.5, ups=1.54, wpb=12262.6, bsz=450.6, num_updates=14900, lr=0.000115857, gnorm=0.97, clip=0, loss_scale=16, train_wall=65, gb_free=14.6, wall=9964
2023-07-10 06:33:20 | INFO | train_inner | epoch 011:    269 / 1474 loss=4.034, trans_loss=3.604, nll_loss=1.789, w2v_ctc_loss=1.583, contrastive_loss=0, total=4115.58, n_correct=2223.53, ppl=3.46, accuracy=54.027, wps=18942.1, ups=1.54, wpb=12275.7, bsz=444.2, num_updates=15000, lr=0.00011547, gnorm=0.978, clip=0, loss_scale=16, train_wall=64, gb_free=16.2, wall=10029
1.0
tensor(0.2838, device='cuda:0')
2023-07-10 06:34:25 | INFO | train_inner | epoch 011:    369 / 1474 loss=4.011, trans_loss=3.603, nll_loss=1.785, w2v_ctc_loss=1.546, contrastive_loss=0, total=4094.16, n_correct=2216.42, ppl=3.45, accuracy=54.136, wps=18819.9, ups=1.54, wpb=12192.1, bsz=443.4, num_updates=15100, lr=0.000115087, gnorm=0.7, clip=0, loss_scale=16, train_wall=64, gb_free=13.1, wall=10094
2023-07-10 06:35:31 | INFO | train_inner | epoch 011:    469 / 1474 loss=4.13, trans_loss=3.614, nll_loss=1.797, w2v_ctc_loss=1.722, contrastive_loss=0, total=4112.8, n_correct=2215.27, ppl=3.47, accuracy=53.863, wps=18652.6, ups=1.52, wpb=12272.4, bsz=453.2, num_updates=15200, lr=0.000114708, gnorm=0.732, clip=0, loss_scale=16, train_wall=65, gb_free=17.2, wall=10160
2023-07-10 06:36:37 | INFO | train_inner | epoch 011:    569 / 1474 loss=4.188, trans_loss=3.61, nll_loss=1.798, w2v_ctc_loss=1.813, contrastive_loss=0, total=4071.06, n_correct=2198.36, ppl=3.48, accuracy=54, wps=18528.2, ups=1.52, wpb=12174, bsz=438.9, num_updates=15300, lr=0.000114332, gnorm=0.756, clip=0, loss_scale=16, train_wall=65, gb_free=16.6, wall=10225
2023-07-10 06:37:42 | INFO | train_inner | epoch 011:    669 / 1474 loss=4.078, trans_loss=3.604, nll_loss=1.787, w2v_ctc_loss=1.643, contrastive_loss=0, total=4156.4, n_correct=2253.93, ppl=3.45, accuracy=54.228, wps=19011.7, ups=1.53, wpb=12399.3, bsz=465.3, num_updates=15400, lr=0.000113961, gnorm=0.728, clip=0, loss_scale=16, train_wall=65, gb_free=16.5, wall=10291
2023-07-10 06:38:48 | INFO | train_inner | epoch 011:    769 / 1474 loss=4.06, trans_loss=3.611, nll_loss=1.796, w2v_ctc_loss=1.608, contrastive_loss=0, total=4169.17, n_correct=2257.96, ppl=3.47, accuracy=54.159, wps=19008, ups=1.53, wpb=12460.4, bsz=457.2, num_updates=15500, lr=0.000113592, gnorm=0.762, clip=0, loss_scale=16, train_wall=65, gb_free=12.5, wall=10356
2023-07-10 06:39:52 | INFO | train_inner | epoch 011:    869 / 1474 loss=4.055, trans_loss=3.608, nll_loss=1.795, w2v_ctc_loss=1.615, contrastive_loss=0, total=4120.01, n_correct=2223.8, ppl=3.47, accuracy=53.976, wps=18965.2, ups=1.54, wpb=12288.7, bsz=440.2, num_updates=15600, lr=0.000113228, gnorm=0.724, clip=0, loss_scale=16, train_wall=64, gb_free=13.7, wall=10421
2023-07-10 06:40:57 | INFO | train_inner | epoch 011:    969 / 1474 loss=4.069, trans_loss=3.605, nll_loss=1.789, w2v_ctc_loss=1.633, contrastive_loss=0, total=4145.45, n_correct=2248.85, ppl=3.46, accuracy=54.249, wps=18978.5, ups=1.53, wpb=12369.7, bsz=455.5, num_updates=15700, lr=0.000112867, gnorm=0.726, clip=0, loss_scale=16, train_wall=65, gb_free=17.2, wall=10486
2023-07-10 06:42:02 | INFO | train_inner | epoch 011:   1069 / 1474 loss=4.064, trans_loss=3.604, nll_loss=1.789, w2v_ctc_loss=1.624, contrastive_loss=0, total=4141.18, n_correct=2250.41, ppl=3.46, accuracy=54.342, wps=19095.8, ups=1.54, wpb=12378.8, bsz=464.1, num_updates=15800, lr=0.000112509, gnorm=0.706, clip=0, loss_scale=16, train_wall=64, gb_free=16.7, wall=10551
2023-07-10 06:43:08 | INFO | train_inner | epoch 011:   1169 / 1474 loss=4.059, trans_loss=3.604, nll_loss=1.792, w2v_ctc_loss=1.622, contrastive_loss=0, total=4173.93, n_correct=2264.62, ppl=3.46, accuracy=54.256, wps=19048.9, ups=1.53, wpb=12444.5, bsz=460.9, num_updates=15900, lr=0.000112154, gnorm=0.74, clip=0, loss_scale=16, train_wall=65, gb_free=17.1, wall=10616
2023-07-10 06:44:13 | INFO | train_inner | epoch 011:   1269 / 1474 loss=4.062, trans_loss=3.603, nll_loss=1.787, w2v_ctc_loss=1.618, contrastive_loss=0, total=4174.26, n_correct=2269.03, ppl=3.45, accuracy=54.358, wps=18988, ups=1.52, wpb=12472, bsz=471.6, num_updates=16000, lr=0.000111803, gnorm=0.731, clip=0, loss_scale=16, train_wall=65, gb_free=17.5, wall=10682
2023-07-10 06:44:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
1.0
tensor(0.2838, device='cuda:4')
1.0
tensor(0.2838, device='cuda:3')
1.0
tensor(0.2838, device='cuda:7')
1.0
tensor(0.2838, device='cuda:2')
1.0
tensor(0.2838, device='cuda:6')
1.0
tensor(0.2838, device='cuda:1')
1.0
tensor(0.2838, device='cuda:5')
2023-07-10 06:44:36 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.338 | trans_loss 6.051 | nll_loss 3.451 | w2v_ctc_loss 0.252 | contrastive_loss 0.211 | total 4003.4 | n_correct 2180.1 | ppl 10.94 | accuracy 54.456 | uer 47.018 | wer 48.842 | raw_wer 48.842 | bleu 14.44 | wps 2525.5 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 14.44
2023-07-10 06:44:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-07-10 06:44:36 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_11_16000.pt
2023-07-10 06:44:38 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_11_16000.pt
2023-07-10 06:44:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 14.44) (writing took 9.242122197989374 seconds)
2023-07-10 06:45:52 | INFO | train_inner | epoch 011:   1369 / 1474 loss=4.09, trans_loss=3.601, nll_loss=1.784, w2v_ctc_loss=1.671, contrastive_loss=0, total=4191.56, n_correct=2284.5, ppl=3.44, accuracy=54.502, wps=12722.4, ups=1.02, wpb=12516.8, bsz=491.5, num_updates=16100, lr=0.000111456, gnorm=0.702, clip=0, loss_scale=16, train_wall=66, gb_free=17.6, wall=10780
2023-07-10 06:46:57 | INFO | train_inner | epoch 011:   1469 / 1474 loss=4.082, trans_loss=3.602, nll_loss=1.787, w2v_ctc_loss=1.657, contrastive_loss=0, total=4161.81, n_correct=2264.4, ppl=3.45, accuracy=54.409, wps=19043, ups=1.53, wpb=12429.3, bsz=469.8, num_updates=16200, lr=0.000111111, gnorm=0.714, clip=0, loss_scale=16, train_wall=65, gb_free=17, wall=10846
2023-07-10 06:47:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 06:47:25 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.293 | trans_loss 6.004 | nll_loss 3.392 | w2v_ctc_loss 0.212 | contrastive_loss 0.21 | total 4003.4 | n_correct 2207.3 | ppl 10.5 | accuracy 55.136 | uer 46.601 | wer 48.272 | raw_wer 48.272 | bleu 14.9 | wps 2116.3 | wpb 4003.4 | bsz 141.8 | num_updates 16205 | best_bleu 14.9
2023-07-10 06:47:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16205 updates
2023-07-10 06:47:25 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 06:47:29 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 06:47:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt (epoch 11 @ 16205 updates, score 14.9) (writing took 8.231864487024723 seconds)
2023-07-10 06:47:34 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-07-10 06:47:34 | INFO | train | epoch 011 | loss 4.075 | trans_loss 3.605 | nll_loss 1.79 | w2v_ctc_loss 1.642 | contrastive_loss 0 | total 4138.65 | n_correct 2242.34 | ppl 3.46 | accuracy 54.18 | wps 17586.1 | ups 1.42 | wpb 12355.8 | bsz 458.5 | num_updates 16205 | lr 0.000111094 | gnorm 0.77 | clip 0 | loss_scale 16 | train_wall 956 | gb_free 17.3 | wall 10882
2023-07-10 06:47:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 06:47:34 | INFO | fairseq.trainer | begin training epoch 12
2023-07-10 06:47:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 06:48:43 | INFO | train_inner | epoch 012:     95 / 1474 loss=4.023, trans_loss=3.577, nll_loss=1.751, w2v_ctc_loss=1.589, contrastive_loss=0, total=4139.2, n_correct=2282.95, ppl=3.37, accuracy=55.154, wps=11666.6, ups=0.94, wpb=12361.4, bsz=468.8, num_updates=16300, lr=0.00011077, gnorm=0.722, clip=0, loss_scale=16, train_wall=64, gb_free=16.1, wall=10952
2023-07-10 06:49:48 | INFO | train_inner | epoch 012:    195 / 1474 loss=3.973, trans_loss=3.578, nll_loss=1.755, w2v_ctc_loss=1.525, contrastive_loss=0, total=4126.87, n_correct=2266.59, ppl=3.37, accuracy=54.923, wps=19021.5, ups=1.54, wpb=12361.2, bsz=443.9, num_updates=16400, lr=0.000110432, gnorm=0.707, clip=0, loss_scale=16, train_wall=65, gb_free=16.6, wall=11017
2023-07-10 06:50:54 | INFO | train_inner | epoch 012:    295 / 1474 loss=4.035, trans_loss=3.576, nll_loss=1.754, w2v_ctc_loss=1.608, contrastive_loss=0, total=4203.54, n_correct=2317.05, ppl=3.37, accuracy=55.121, wps=19068.9, ups=1.52, wpb=12550.7, bsz=481.6, num_updates=16500, lr=0.000110096, gnorm=0.707, clip=0, loss_scale=16, train_wall=65, gb_free=14.8, wall=11082
2023-07-10 06:51:59 | INFO | train_inner | epoch 012:    395 / 1474 loss=4.03, trans_loss=3.58, nll_loss=1.759, w2v_ctc_loss=1.603, contrastive_loss=0, total=4149.28, n_correct=2285.04, ppl=3.38, accuracy=55.071, wps=18964, ups=1.53, wpb=12403.5, bsz=460.7, num_updates=16600, lr=0.000109764, gnorm=0.714, clip=0, loss_scale=32, train_wall=65, gb_free=15.3, wall=11148
2023-07-10 06:52:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-10 06:53:05 | INFO | train_inner | epoch 012:    496 / 1474 loss=3.996, trans_loss=3.593, nll_loss=1.771, w2v_ctc_loss=1.538, contrastive_loss=0, total=4102.21, n_correct=2247.51, ppl=3.41, accuracy=54.788, wps=18609.4, ups=1.53, wpb=12202.7, bsz=451.4, num_updates=16700, lr=0.000109435, gnorm=0.708, clip=0, loss_scale=16, train_wall=65, gb_free=17.7, wall=11213
2023-07-10 06:54:11 | INFO | train_inner | epoch 012:    596 / 1474 loss=4.016, trans_loss=3.578, nll_loss=1.758, w2v_ctc_loss=1.582, contrastive_loss=0, total=4204.6, n_correct=2318.05, ppl=3.38, accuracy=55.131, wps=19040.4, ups=1.51, wpb=12576, bsz=478.8, num_updates=16800, lr=0.000109109, gnorm=0.704, clip=0, loss_scale=16, train_wall=66, gb_free=16.6, wall=11279
2023-07-10 06:55:16 | INFO | train_inner | epoch 012:    696 / 1474 loss=4.055, trans_loss=3.574, nll_loss=1.751, w2v_ctc_loss=1.659, contrastive_loss=0, total=4197.19, n_correct=2325.19, ppl=3.37, accuracy=55.399, wps=19230.6, ups=1.54, wpb=12474.7, bsz=484.9, num_updates=16900, lr=0.000108786, gnorm=0.748, clip=0, loss_scale=16, train_wall=64, gb_free=16.8, wall=11344
2023-07-10 06:56:21 | INFO | train_inner | epoch 012:    796 / 1474 loss=4.073, trans_loss=3.584, nll_loss=1.761, w2v_ctc_loss=1.659, contrastive_loss=0, total=4094.06, n_correct=2254.96, ppl=3.39, accuracy=55.079, wps=18775.8, ups=1.53, wpb=12234.4, bsz=447.4, num_updates=17000, lr=0.000108465, gnorm=0.816, clip=0, loss_scale=16, train_wall=65, gb_free=15, wall=11409
2023-07-10 06:57:26 | INFO | train_inner | epoch 012:    896 / 1474 loss=4.038, trans_loss=3.583, nll_loss=1.764, w2v_ctc_loss=1.602, contrastive_loss=0, total=4163.5, n_correct=2288.6, ppl=3.4, accuracy=54.968, wps=19011.3, ups=1.53, wpb=12434.2, bsz=457.6, num_updates=17100, lr=0.000108148, gnorm=0.697, clip=0, loss_scale=16, train_wall=65, gb_free=13.1, wall=11475
2023-07-10 06:58:32 | INFO | train_inner | epoch 012:    996 / 1474 loss=4.054, trans_loss=3.585, nll_loss=1.765, w2v_ctc_loss=1.633, contrastive_loss=0, total=4124.99, n_correct=2264.01, ppl=3.4, accuracy=54.885, wps=18822.6, ups=1.53, wpb=12308.5, bsz=454, num_updates=17200, lr=0.000107833, gnorm=0.727, clip=0, loss_scale=16, train_wall=65, gb_free=11.5, wall=11540
2023-07-10 06:59:36 | INFO | train_inner | epoch 012:   1096 / 1474 loss=4.016, trans_loss=3.592, nll_loss=1.772, w2v_ctc_loss=1.572, contrastive_loss=0, total=4046.6, n_correct=2218.45, ppl=3.42, accuracy=54.823, wps=18742.8, ups=1.55, wpb=12084.3, bsz=434.7, num_updates=17300, lr=0.000107521, gnorm=0.736, clip=0, loss_scale=16, train_wall=64, gb_free=16.7, wall=11605
2023-07-10 07:00:41 | INFO | train_inner | epoch 012:   1196 / 1474 loss=4.092, trans_loss=3.59, nll_loss=1.774, w2v_ctc_loss=1.689, contrastive_loss=0, total=4196.85, n_correct=2293.25, ppl=3.42, accuracy=54.642, wps=19230.6, ups=1.53, wpb=12536.8, bsz=478.5, num_updates=17400, lr=0.000107211, gnorm=0.715, clip=0, loss_scale=16, train_wall=65, gb_free=16.7, wall=11670
2023-07-10 07:01:46 | INFO | train_inner | epoch 012:   1296 / 1474 loss=4.077, trans_loss=3.596, nll_loss=1.781, w2v_ctc_loss=1.655, contrastive_loss=0, total=4067.78, n_correct=2218.95, ppl=3.44, accuracy=54.549, wps=18682, ups=1.54, wpb=12155.3, bsz=428.2, num_updates=17500, lr=0.000106904, gnorm=0.786, clip=0, loss_scale=16, train_wall=65, gb_free=15.4, wall=11735
2023-07-10 07:02:52 | INFO | train_inner | epoch 012:   1396 / 1474 loss=4.04, trans_loss=3.587, nll_loss=1.768, w2v_ctc_loss=1.608, contrastive_loss=0, total=4142.88, n_correct=2274.39, ppl=3.41, accuracy=54.899, wps=18829.3, ups=1.53, wpb=12343.4, bsz=459.4, num_updates=17600, lr=0.0001066, gnorm=0.762, clip=0, loss_scale=16, train_wall=65, gb_free=15.7, wall=11801
2023-07-10 07:03:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 07:04:07 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.28 | trans_loss 5.978 | nll_loss 3.36 | w2v_ctc_loss 0.229 | contrastive_loss 0.211 | total 4003.4 | n_correct 2214.7 | ppl 10.27 | accuracy 55.32 | uer 45.786 | wer 47.843 | raw_wer 47.843 | bleu 14.84 | wps 2243.5 | wpb 4003.4 | bsz 141.8 | num_updates 17678 | best_bleu 14.9
2023-07-10 07:04:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17678 updates
2023-07-10 07:04:07 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_14.8406.pt
2023-07-10 07:04:09 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_14.8406.pt
2023-07-10 07:04:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_14.8406.pt (epoch 12 @ 17678 updates, score 14.84) (writing took 5.0894108719949145 seconds)
2023-07-10 07:04:12 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-07-10 07:04:12 | INFO | train | epoch 012 | loss 4.04 | trans_loss 3.584 | nll_loss 1.764 | w2v_ctc_loss 1.613 | contrastive_loss 0 | total 4139.14 | n_correct 2274.83 | ppl 3.4 | accuracy 54.959 | wps 18229.1 | ups 1.48 | wpb 12357 | bsz 458.6 | num_updates 17678 | lr 0.000106365 | gnorm 0.736 | clip 0 | loss_scale 16 | train_wall 955 | gb_free 13.2 | wall 11881
2023-07-10 07:04:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 07:04:12 | INFO | fairseq.trainer | begin training epoch 13
2023-07-10 07:04:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 07:04:35 | INFO | train_inner | epoch 013:     22 / 1474 loss=4.09, trans_loss=3.585, nll_loss=1.765, w2v_ctc_loss=1.689, contrastive_loss=0, total=4097.08, n_correct=2252.57, ppl=3.4, accuracy=54.98, wps=11871.1, ups=0.97, wpb=12242.7, bsz=444.9, num_updates=17700, lr=0.000106299, gnorm=0.786, clip=0, loss_scale=16, train_wall=65, gb_free=16.5, wall=11904
2023-07-10 07:05:40 | INFO | train_inner | epoch 013:    122 / 1474 loss=3.987, trans_loss=3.56, nll_loss=1.732, w2v_ctc_loss=1.563, contrastive_loss=0, total=4164.24, n_correct=2312.67, ppl=3.32, accuracy=55.536, wps=19089.6, ups=1.54, wpb=12428.2, bsz=452.9, num_updates=17800, lr=0.000106, gnorm=0.74, clip=0, loss_scale=16, train_wall=65, gb_free=17, wall=11969
2023-07-10 07:06:46 | INFO | train_inner | epoch 013:    222 / 1474 loss=4.05, trans_loss=3.567, nll_loss=1.745, w2v_ctc_loss=1.65, contrastive_loss=0, total=4201.52, n_correct=2322.35, ppl=3.35, accuracy=55.274, wps=18855.4, ups=1.51, wpb=12503.4, bsz=492.8, num_updates=17900, lr=0.000105703, gnorm=0.749, clip=0, loss_scale=16, train_wall=66, gb_free=13.3, wall=12035
2023-07-10 07:07:51 | INFO | train_inner | epoch 013:    322 / 1474 loss=4.016, trans_loss=3.568, nll_loss=1.74, w2v_ctc_loss=1.597, contrastive_loss=0, total=4102.53, n_correct=2281.4, ppl=3.34, accuracy=55.61, wps=18820.9, ups=1.54, wpb=12225.9, bsz=440.9, num_updates=18000, lr=0.000105409, gnorm=0.759, clip=0, loss_scale=16, train_wall=64, gb_free=16.2, wall=12100
2023-07-10 07:07:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 07:08:14 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.268 | trans_loss 5.984 | nll_loss 3.365 | w2v_ctc_loss 0.175 | contrastive_loss 0.206 | total 4003.4 | n_correct 2212 | ppl 10.3 | accuracy 55.253 | uer 46.03 | wer 48.089 | raw_wer 48.089 | bleu 14.74 | wps 2577.4 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 14.9
2023-07-10 07:08:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-07-10 07:08:14 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_13_18000.pt
2023-07-10 07:08:16 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_13_18000.pt
2023-07-10 07:08:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 14.74) (writing took 5.998633376992075 seconds)
2023-07-10 07:09:25 | INFO | train_inner | epoch 013:    422 / 1474 loss=4.01, trans_loss=3.567, nll_loss=1.74, w2v_ctc_loss=1.596, contrastive_loss=0, total=4190.45, n_correct=2336.75, ppl=3.34, accuracy=55.764, wps=13419.6, ups=1.07, wpb=12503.2, bsz=480.5, num_updates=18100, lr=0.000105118, gnorm=0.791, clip=0, loss_scale=16, train_wall=64, gb_free=16, wall=12193
2023-07-10 07:10:30 | INFO | train_inner | epoch 013:    522 / 1474 loss=3.995, trans_loss=3.567, nll_loss=1.741, w2v_ctc_loss=1.569, contrastive_loss=0, total=4194.45, n_correct=2327.96, ppl=3.34, accuracy=55.501, wps=19171.4, ups=1.53, wpb=12514.7, bsz=478.5, num_updates=18200, lr=0.000104828, gnorm=0.715, clip=0, loss_scale=16, train_wall=65, gb_free=17.4, wall=12259
2023-07-10 07:11:35 | INFO | train_inner | epoch 013:    622 / 1474 loss=3.959, trans_loss=3.562, nll_loss=1.735, w2v_ctc_loss=1.511, contrastive_loss=0, total=4158.04, n_correct=2316.74, ppl=3.33, accuracy=55.717, wps=19034.5, ups=1.53, wpb=12423.8, bsz=460, num_updates=18300, lr=0.000104542, gnorm=0.722, clip=0, loss_scale=16, train_wall=65, gb_free=13.7, wall=12324
2023-07-10 07:12:40 | INFO | train_inner | epoch 013:    722 / 1474 loss=4.027, trans_loss=3.575, nll_loss=1.752, w2v_ctc_loss=1.607, contrastive_loss=0, total=4099.91, n_correct=2258.2, ppl=3.37, accuracy=55.079, wps=18776.8, ups=1.53, wpb=12236, bsz=428.3, num_updates=18400, lr=0.000104257, gnorm=0.766, clip=0, loss_scale=16, train_wall=65, gb_free=16.9, wall=12389
2023-07-10 07:13:47 | INFO | train_inner | epoch 013:    822 / 1474 loss=4.061, trans_loss=3.569, nll_loss=1.744, w2v_ctc_loss=1.661, contrastive_loss=0, total=4122.78, n_correct=2281.68, ppl=3.35, accuracy=55.343, wps=18533.4, ups=1.5, wpb=12325.4, bsz=459, num_updates=18500, lr=0.000103975, gnorm=0.758, clip=0, loss_scale=16, train_wall=66, gb_free=15.1, wall=12455
2023-07-10 07:14:52 | INFO | train_inner | epoch 013:    922 / 1474 loss=3.992, trans_loss=3.568, nll_loss=1.744, w2v_ctc_loss=1.56, contrastive_loss=0, total=4102.59, n_correct=2280.52, ppl=3.35, accuracy=55.587, wps=18884.9, ups=1.54, wpb=12247.6, bsz=444.9, num_updates=18600, lr=0.000103695, gnorm=0.791, clip=0, loss_scale=16, train_wall=64, gb_free=17.4, wall=12520
2023-07-10 07:15:57 | INFO | train_inner | epoch 013:   1022 / 1474 loss=4.054, trans_loss=3.569, nll_loss=1.749, w2v_ctc_loss=1.656, contrastive_loss=0, total=4087.8, n_correct=2256.85, ppl=3.36, accuracy=55.209, wps=18766.8, ups=1.53, wpb=12231.8, bsz=440.6, num_updates=18700, lr=0.000103418, gnorm=0.789, clip=0, loss_scale=32, train_wall=65, gb_free=16.8, wall=12585
2023-07-10 07:16:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-10 07:17:02 | INFO | train_inner | epoch 013:   1123 / 1474 loss=3.995, trans_loss=3.568, nll_loss=1.742, w2v_ctc_loss=1.566, contrastive_loss=0, total=4093.05, n_correct=2281.4, ppl=3.35, accuracy=55.738, wps=18732.7, ups=1.53, wpb=12223.3, bsz=455, num_updates=18800, lr=0.000103142, gnorm=0.733, clip=0, loss_scale=16, train_wall=65, gb_free=17.7, wall=12651
2023-07-10 07:18:07 | INFO | train_inner | epoch 013:   1223 / 1474 loss=4.01, trans_loss=3.577, nll_loss=1.752, w2v_ctc_loss=1.571, contrastive_loss=0, total=4124.88, n_correct=2289.77, ppl=3.37, accuracy=55.511, wps=18929.1, ups=1.54, wpb=12330.1, bsz=445, num_updates=18900, lr=0.000102869, gnorm=0.753, clip=0, loss_scale=16, train_wall=65, gb_free=17.8, wall=12716
2023-07-10 07:19:13 | INFO | train_inner | epoch 013:   1323 / 1474 loss=4.027, trans_loss=3.564, nll_loss=1.741, w2v_ctc_loss=1.606, contrastive_loss=0, total=4108.18, n_correct=2288.26, ppl=3.34, accuracy=55.7, wps=18749, ups=1.53, wpb=12271.1, bsz=462.7, num_updates=19000, lr=0.000102598, gnorm=0.76, clip=0, loss_scale=16, train_wall=65, gb_free=16.7, wall=12781
2023-07-10 07:20:18 | INFO | train_inner | epoch 013:   1423 / 1474 loss=4.051, trans_loss=3.573, nll_loss=1.748, w2v_ctc_loss=1.64, contrastive_loss=0, total=4171.47, n_correct=2318.14, ppl=3.36, accuracy=55.571, wps=19168.6, ups=1.54, wpb=12443.7, bsz=465.8, num_updates=19100, lr=0.000102329, gnorm=0.745, clip=0, loss_scale=16, train_wall=64, gb_free=15.5, wall=12846
2023-07-10 07:20:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 07:21:14 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.273 | trans_loss 5.964 | nll_loss 3.338 | w2v_ctc_loss 0.243 | contrastive_loss 0.199 | total 4003.4 | n_correct 2230.7 | ppl 10.11 | accuracy 55.72 | uer 44.971 | wer 47.373 | raw_wer 47.373 | bleu 15.09 | wps 2323.4 | wpb 4003.4 | bsz 141.8 | num_updates 19151 | best_bleu 15.09
2023-07-10 07:21:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19151 updates
2023-07-10 07:21:14 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 07:21:18 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 07:21:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt (epoch 13 @ 19151 updates, score 15.09) (writing took 8.04168711497914 seconds)
2023-07-10 07:21:23 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-07-10 07:21:23 | INFO | train | epoch 013 | loss 4.016 | trans_loss 3.568 | nll_loss 1.743 | w2v_ctc_loss 1.597 | contrastive_loss 0 | total 4138.6 | n_correct 2298.47 | ppl 3.35 | accuracy 55.537 | wps 17662.9 | ups 1.43 | wpb 12355.6 | bsz 458.4 | num_updates 19151 | lr 0.000102193 | gnorm 0.753 | clip 0 | loss_scale 16 | train_wall 955 | gb_free 17.7 | wall 12911
2023-07-10 07:21:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 07:21:23 | INFO | fairseq.trainer | begin training epoch 14
2023-07-10 07:21:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 07:22:03 | INFO | train_inner | epoch 014:     49 / 1474 loss=3.965, trans_loss=3.544, nll_loss=1.713, w2v_ctc_loss=1.555, contrastive_loss=0, total=4182.69, n_correct=2358.21, ppl=3.28, accuracy=56.38, wps=11895.1, ups=0.95, wpb=12500.6, bsz=483.4, num_updates=19200, lr=0.000102062, gnorm=0.729, clip=0, loss_scale=16, train_wall=64, gb_free=16.2, wall=12951
2023-07-10 07:23:07 | INFO | train_inner | epoch 014:    149 / 1474 loss=3.963, trans_loss=3.544, nll_loss=1.71, w2v_ctc_loss=1.548, contrastive_loss=0, total=4086.4, n_correct=2305.73, ppl=3.27, accuracy=56.424, wps=18936.9, ups=1.55, wpb=12219, bsz=452.2, num_updates=19300, lr=0.000101797, gnorm=0.748, clip=0, loss_scale=16, train_wall=64, gb_free=17.1, wall=13016
2023-07-10 07:24:13 | INFO | train_inner | epoch 014:    249 / 1474 loss=3.99, trans_loss=3.558, nll_loss=1.727, w2v_ctc_loss=1.565, contrastive_loss=0, total=4103.37, n_correct=2297.59, ppl=3.31, accuracy=55.993, wps=18724.2, ups=1.53, wpb=12220.3, bsz=441.1, num_updates=19400, lr=0.000101535, gnorm=0.746, clip=0, loss_scale=16, train_wall=65, gb_free=17.3, wall=13081
2023-07-10 07:25:18 | INFO | train_inner | epoch 014:    349 / 1474 loss=3.918, trans_loss=3.536, nll_loss=1.709, w2v_ctc_loss=1.488, contrastive_loss=0, total=4168.35, n_correct=2349.13, ppl=3.27, accuracy=56.356, wps=19110.3, ups=1.54, wpb=12419.4, bsz=478.1, num_updates=19500, lr=0.000101274, gnorm=0.729, clip=0, loss_scale=16, train_wall=65, gb_free=16.5, wall=13146
2023-07-10 07:26:22 | INFO | train_inner | epoch 014:    449 / 1474 loss=3.976, trans_loss=3.55, nll_loss=1.72, w2v_ctc_loss=1.549, contrastive_loss=0, total=4155.83, n_correct=2330.56, ppl=3.29, accuracy=56.079, wps=19113.2, ups=1.54, wpb=12381.6, bsz=460, num_updates=19600, lr=0.000101015, gnorm=0.733, clip=0, loss_scale=16, train_wall=64, gb_free=16.1, wall=13211
2023-07-10 07:27:28 | INFO | train_inner | epoch 014:    549 / 1474 loss=4.001, trans_loss=3.561, nll_loss=1.733, w2v_ctc_loss=1.577, contrastive_loss=0, total=4064.87, n_correct=2266.55, ppl=3.32, accuracy=55.759, wps=18660.4, ups=1.53, wpb=12195.4, bsz=432.7, num_updates=19700, lr=0.000100759, gnorm=0.804, clip=0, loss_scale=16, train_wall=65, gb_free=17.9, wall=13276
2023-07-10 07:28:34 | INFO | train_inner | epoch 014:    649 / 1474 loss=3.987, trans_loss=3.559, nll_loss=1.731, w2v_ctc_loss=1.564, contrastive_loss=0, total=4167.34, n_correct=2327.98, ppl=3.32, accuracy=55.862, wps=18854.8, ups=1.52, wpb=12436.1, bsz=461.7, num_updates=19800, lr=0.000100504, gnorm=0.726, clip=0, loss_scale=16, train_wall=66, gb_free=17.2, wall=13342
2023-07-10 07:29:38 | INFO | train_inner | epoch 014:    749 / 1474 loss=3.97, trans_loss=3.55, nll_loss=1.72, w2v_ctc_loss=1.552, contrastive_loss=0, total=4142.94, n_correct=2326.56, ppl=3.29, accuracy=56.157, wps=19113.1, ups=1.54, wpb=12388, bsz=462.9, num_updates=19900, lr=0.000100251, gnorm=0.796, clip=0, loss_scale=16, train_wall=64, gb_free=16.5, wall=13407
2023-07-10 07:30:43 | INFO | train_inner | epoch 014:    849 / 1474 loss=3.974, trans_loss=3.545, nll_loss=1.717, w2v_ctc_loss=1.569, contrastive_loss=0, total=4173.06, n_correct=2344.57, ppl=3.29, accuracy=56.183, wps=19159.9, ups=1.54, wpb=12457, bsz=478.7, num_updates=20000, lr=0.0001, gnorm=0.771, clip=0, loss_scale=16, train_wall=65, gb_free=13.1, wall=13472
2023-07-10 07:30:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 07:31:06 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.271 | trans_loss 5.97 | nll_loss 3.345 | w2v_ctc_loss 0.219 | contrastive_loss 0.207 | total 4003.4 | n_correct 2227.4 | ppl 10.16 | accuracy 55.638 | uer 45.489 | wer 47.649 | raw_wer 47.649 | bleu 14.93 | wps 2591.4 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 15.09
2023-07-10 07:31:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-07-10 07:31:06 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_14_20000.pt
2023-07-10 07:31:08 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_14_20000.pt
2023-07-10 07:31:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 14.93) (writing took 6.13728000302217 seconds)
1.0
tensor(0.0271, device='cuda:0')
2023-07-10 07:31:55 | INFO | train_inner | epoch 014:    949 / 1474 loss=4.779, trans_loss=5.284, nll_loss=2.571, w2v_ctc_loss=1.188, contrastive_loss=0, total=4166.71, n_correct=2324.47, ppl=5.94, accuracy=55.787, wps=11803.3, ups=1.41, wpb=8387.8, bsz=312.5, num_updates=20100, lr=9.97509e-05, gnorm=0.867, clip=0, loss_scale=16, train_wall=42, gb_free=16.9, wall=13543
2023-07-10 07:32:37 | INFO | train_inner | epoch 014:   1049 / 1474 loss=4.803, trans_loss=5.307, nll_loss=2.578, w2v_ctc_loss=1.237, contrastive_loss=0, total=4145.57, n_correct=2327.17, ppl=5.97, accuracy=56.136, wps=19644.8, ups=2.37, wpb=8288.6, bsz=301.1, num_updates=20200, lr=9.95037e-05, gnorm=0.893, clip=0, loss_scale=16, train_wall=42, gb_free=17.7, wall=13585
2023-07-10 07:33:19 | INFO | train_inner | epoch 014:   1149 / 1474 loss=4.809, trans_loss=5.305, nll_loss=2.578, w2v_ctc_loss=1.269, contrastive_loss=0, total=4219.9, n_correct=2365.57, ppl=5.97, accuracy=56.057, wps=19961, ups=2.37, wpb=8423.8, bsz=325.2, num_updates=20300, lr=9.92583e-05, gnorm=0.912, clip=0, loss_scale=16, train_wall=42, gb_free=16.7, wall=13628
2023-07-10 07:34:00 | INFO | train_inner | epoch 014:   1249 / 1474 loss=4.812, trans_loss=5.323, nll_loss=2.597, w2v_ctc_loss=1.222, contrastive_loss=0, total=4032.06, n_correct=2248.99, ppl=6.05, accuracy=55.778, wps=19448.6, ups=2.41, wpb=8074.4, bsz=274.4, num_updates=20400, lr=9.90148e-05, gnorm=0.924, clip=0, loss_scale=16, train_wall=41, gb_free=17.9, wall=13669
2023-07-10 07:34:42 | INFO | train_inner | epoch 014:   1349 / 1474 loss=4.79, trans_loss=5.3, nll_loss=2.572, w2v_ctc_loss=1.207, contrastive_loss=0, total=4205.07, n_correct=2370.25, ppl=5.95, accuracy=56.366, wps=20104, ups=2.39, wpb=8410.5, bsz=317.3, num_updates=20500, lr=9.8773e-05, gnorm=0.869, clip=0, loss_scale=16, train_wall=41, gb_free=17, wall=13711
2023-07-10 07:35:24 | INFO | train_inner | epoch 014:   1449 / 1474 loss=4.797, trans_loss=5.308, nll_loss=2.581, w2v_ctc_loss=1.208, contrastive_loss=0, total=4126.44, n_correct=2322.25, ppl=5.98, accuracy=56.277, wps=19882, ups=2.41, wpb=8259.8, bsz=303.9, num_updates=20600, lr=9.85329e-05, gnorm=0.876, clip=0, loss_scale=16, train_wall=41, gb_free=16.5, wall=13752
2023-07-10 07:35:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
1.0
tensor(0.0271, device='cuda:3')
1.0
tensor(0.0271, device='cuda:5')
1.0
tensor(0.0271, device='cuda:7')
1.0
tensor(0.0271, device='cuda:6')
1.0
tensor(0.0271, device='cuda:4')
1.0
tensor(0.0271, device='cuda:1')
1.0
tensor(0.0271, device='cuda:2')
2023-07-10 07:35:58 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.253 | trans_loss 5.926 | nll_loss 3.292 | w2v_ctc_loss 0.261 | contrastive_loss 0.206 | total 4003.4 | n_correct 2255.8 | ppl 9.8 | accuracy 56.347 | uer 43.952 | wer 46.203 | raw_wer 46.203 | bleu 15.61 | wps 2362 | wpb 4003.4 | bsz 141.8 | num_updates 20625 | best_bleu 15.61
2023-07-10 07:35:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20625 updates
2023-07-10 07:35:58 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 07:36:02 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 07:36:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt (epoch 14 @ 20625 updates, score 15.61) (writing took 8.164890838001156 seconds)
2023-07-10 07:36:06 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-07-10 07:36:06 | INFO | train | epoch 014 | loss 4.245 | trans_loss 4.13 | nll_loss 2.005 | w2v_ctc_loss 1.443 | contrastive_loss 0 | total 4138.65 | n_correct 2321.33 | ppl 4.01 | accuracy 56.089 | wps 17733.9 | ups 1.67 | wpb 10629.1 | bsz 394.1 | num_updates 20625 | lr 9.84732e-05 | gnorm 0.814 | clip 0 | loss_scale 16 | train_wall 808 | gb_free 16.7 | wall 13795
2023-07-10 07:36:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 07:36:06 | INFO | fairseq.trainer | begin training epoch 15
2023-07-10 07:36:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 07:36:45 | INFO | train_inner | epoch 015:     75 / 1474 loss=4.789, trans_loss=5.285, nll_loss=2.55, w2v_ctc_loss=1.254, contrastive_loss=0, total=4090.99, n_correct=2309.02, ppl=5.86, accuracy=56.442, wps=10069.5, ups=1.23, wpb=8180.9, bsz=300.8, num_updates=20700, lr=9.82946e-05, gnorm=0.88, clip=0, loss_scale=16, train_wall=41, gb_free=17.2, wall=13834
2023-07-10 07:37:27 | INFO | train_inner | epoch 015:    175 / 1474 loss=4.771, trans_loss=5.278, nll_loss=2.54, w2v_ctc_loss=1.211, contrastive_loss=0, total=4115.56, n_correct=2325.65, ppl=5.82, accuracy=56.509, wps=19592, ups=2.38, wpb=8230.9, bsz=298.5, num_updates=20800, lr=9.80581e-05, gnorm=0.893, clip=0, loss_scale=32, train_wall=42, gb_free=17.2, wall=13876
2023-07-10 07:38:09 | INFO | train_inner | epoch 015:    275 / 1474 loss=4.755, trans_loss=5.276, nll_loss=2.538, w2v_ctc_loss=1.16, contrastive_loss=0, total=4182.19, n_correct=2370.03, ppl=5.81, accuracy=56.67, wps=20094.9, ups=2.4, wpb=8365.2, bsz=310.5, num_updates=20900, lr=9.78232e-05, gnorm=0.907, clip=0, loss_scale=32, train_wall=41, gb_free=16.8, wall=13917
2023-07-10 07:38:51 | INFO | train_inner | epoch 015:    375 / 1474 loss=4.763, trans_loss=5.276, nll_loss=2.538, w2v_ctc_loss=1.191, contrastive_loss=0, total=4172.52, n_correct=2365.12, ppl=5.81, accuracy=56.683, wps=19776.8, ups=2.38, wpb=8319, bsz=307.7, num_updates=21000, lr=9.759e-05, gnorm=0.887, clip=0, loss_scale=32, train_wall=42, gb_free=17.1, wall=13959
2023-07-10 07:39:33 | INFO | train_inner | epoch 015:    475 / 1474 loss=4.764, trans_loss=5.288, nll_loss=2.553, w2v_ctc_loss=1.16, contrastive_loss=0, total=4076.84, n_correct=2298.56, ppl=5.87, accuracy=56.381, wps=19494.5, ups=2.39, wpb=8151.7, bsz=293.4, num_updates=21100, lr=9.73585e-05, gnorm=0.928, clip=0, loss_scale=32, train_wall=41, gb_free=17.1, wall=14001
2023-07-10 07:40:15 | INFO | train_inner | epoch 015:    575 / 1474 loss=4.761, trans_loss=5.281, nll_loss=2.545, w2v_ctc_loss=1.161, contrastive_loss=0, total=4156.05, n_correct=2352.83, ppl=5.84, accuracy=56.612, wps=19855.7, ups=2.38, wpb=8325.4, bsz=302.8, num_updates=21200, lr=9.71286e-05, gnorm=0.903, clip=0, loss_scale=32, train_wall=41, gb_free=12.3, wall=14043
2023-07-10 07:40:56 | INFO | train_inner | epoch 015:    675 / 1474 loss=4.777, trans_loss=5.281, nll_loss=2.545, w2v_ctc_loss=1.218, contrastive_loss=0, total=4118.87, n_correct=2328.49, ppl=5.83, accuracy=56.532, wps=19726.7, ups=2.39, wpb=8252, bsz=303, num_updates=21300, lr=9.69003e-05, gnorm=0.902, clip=0, loss_scale=32, train_wall=41, gb_free=17.2, wall=14085
2023-07-10 07:41:38 | INFO | train_inner | epoch 015:    775 / 1474 loss=4.759, trans_loss=5.292, nll_loss=2.56, w2v_ctc_loss=1.134, contrastive_loss=0, total=4176.64, n_correct=2361.14, ppl=5.9, accuracy=56.532, wps=19855.4, ups=2.38, wpb=8329.5, bsz=305.3, num_updates=21400, lr=9.66736e-05, gnorm=0.892, clip=0, loss_scale=32, train_wall=41, gb_free=14.5, wall=14127
2023-07-10 07:42:20 | INFO | train_inner | epoch 015:    875 / 1474 loss=4.781, trans_loss=5.292, nll_loss=2.559, w2v_ctc_loss=1.193, contrastive_loss=0, total=4056.99, n_correct=2289.78, ppl=5.89, accuracy=56.44, wps=19729.6, ups=2.42, wpb=8144.7, bsz=288, num_updates=21500, lr=9.64486e-05, gnorm=0.871, clip=0, loss_scale=32, train_wall=41, gb_free=17.6, wall=14168
2023-07-10 07:43:01 | INFO | train_inner | epoch 015:    975 / 1474 loss=4.76, trans_loss=5.279, nll_loss=2.543, w2v_ctc_loss=1.181, contrastive_loss=0, total=4134.44, n_correct=2339.65, ppl=5.83, accuracy=56.589, wps=19824.8, ups=2.41, wpb=8240.8, bsz=304.8, num_updates=21600, lr=9.6225e-05, gnorm=0.861, clip=0, loss_scale=32, train_wall=41, gb_free=16.7, wall=14210
2023-07-10 07:43:44 | INFO | train_inner | epoch 015:   1075 / 1474 loss=4.785, trans_loss=5.287, nll_loss=2.555, w2v_ctc_loss=1.229, contrastive_loss=0, total=4185.02, n_correct=2371.09, ppl=5.88, accuracy=56.657, wps=19726.9, ups=2.36, wpb=8357.5, bsz=324.2, num_updates=21700, lr=9.60031e-05, gnorm=0.883, clip=0, loss_scale=32, train_wall=42, gb_free=17, wall=14252
2023-07-10 07:44:25 | INFO | train_inner | epoch 015:   1175 / 1474 loss=4.745, trans_loss=5.266, nll_loss=2.528, w2v_ctc_loss=1.149, contrastive_loss=0, total=4187.68, n_correct=2391.21, ppl=5.77, accuracy=57.101, wps=20190.8, ups=2.41, wpb=8376.5, bsz=329.7, num_updates=21800, lr=9.57826e-05, gnorm=0.848, clip=0, loss_scale=32, train_wall=41, gb_free=17, wall=14294
2023-07-10 07:45:07 | INFO | train_inner | epoch 015:   1275 / 1474 loss=4.794, trans_loss=5.288, nll_loss=2.555, w2v_ctc_loss=1.25, contrastive_loss=0, total=4141.6, n_correct=2346.49, ppl=5.88, accuracy=56.657, wps=19981.5, ups=2.41, wpb=8289.9, bsz=301.1, num_updates=21900, lr=9.55637e-05, gnorm=0.918, clip=0, loss_scale=32, train_wall=41, gb_free=14, wall=14335
2023-07-10 07:45:48 | INFO | train_inner | epoch 015:   1375 / 1474 loss=4.758, trans_loss=5.288, nll_loss=2.553, w2v_ctc_loss=1.128, contrastive_loss=0, total=4099.6, n_correct=2326.73, ppl=5.87, accuracy=56.755, wps=19608, ups=2.39, wpb=8204, bsz=293.2, num_updates=22000, lr=9.53463e-05, gnorm=0.883, clip=0, loss_scale=32, train_wall=41, gb_free=14.8, wall=14377
2023-07-10 07:45:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 07:46:11 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.224 | trans_loss 5.907 | nll_loss 3.265 | w2v_ctc_loss 0.21 | contrastive_loss 0.205 | total 4003.4 | n_correct 2268.1 | ppl 9.61 | accuracy 56.654 | uer 43.955 | wer 46.43 | raw_wer 46.43 | bleu 15.47 | wps 2476.1 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 15.61
2023-07-10 07:46:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-07-10 07:46:11 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_15_22000.pt
2023-07-10 07:46:13 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_15_22000.pt
2023-07-10 07:46:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 15.47) (writing took 6.22061848899466 seconds)
2023-07-10 07:47:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 07:47:22 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.238 | trans_loss 5.925 | nll_loss 3.287 | w2v_ctc_loss 0.215 | contrastive_loss 0.209 | total 4003.4 | n_correct 2260.3 | ppl 9.76 | accuracy 56.46 | uer 44.539 | wer 46.937 | raw_wer 46.937 | bleu 15.37 | wps 2536.3 | wpb 4003.4 | bsz 141.8 | num_updates 22099 | best_bleu 15.61
2023-07-10 07:47:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22099 updates
2023-07-10 07:47:22 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_15.3704.pt
2023-07-10 07:47:24 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_15.3704.pt
2023-07-10 07:47:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_15.3704.pt (epoch 15 @ 22099 updates, score 15.37) (writing took 5.111085990007268 seconds)
2023-07-10 07:47:27 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-07-10 07:47:27 | INFO | train | epoch 015 | loss 4.769 | trans_loss 5.282 | nll_loss 2.546 | w2v_ctc_loss 1.189 | contrastive_loss 0 | total 4138.65 | n_correct 2343.89 | ppl 5.84 | accuracy 56.634 | wps 17909.7 | ups 2.16 | wpb 8277.3 | bsz 305.7 | num_updates 22099 | lr 9.51325e-05 | gnorm 0.89 | clip 0 | loss_scale 32 | train_wall 609 | gb_free 17.4 | wall 14476
2023-07-10 07:47:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 07:47:27 | INFO | fairseq.trainer | begin training epoch 16
2023-07-10 07:47:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 07:47:36 | INFO | train_inner | epoch 016:      1 / 1474 loss=4.792, trans_loss=5.282, nll_loss=2.549, w2v_ctc_loss=1.253, contrastive_loss=0, total=4149.9, n_correct=2351.89, ppl=5.85, accuracy=56.673, wps=7761.1, ups=0.93, wpb=8323, bsz=316.3, num_updates=22100, lr=9.51303e-05, gnorm=0.904, clip=0, loss_scale=32, train_wall=42, gb_free=17.7, wall=14484
2023-07-10 07:48:17 | INFO | train_inner | epoch 016:    101 / 1474 loss=4.716, trans_loss=5.247, nll_loss=2.502, w2v_ctc_loss=1.104, contrastive_loss=0, total=4118.73, n_correct=2359.55, ppl=5.66, accuracy=57.288, wps=19969.1, ups=2.42, wpb=8246.5, bsz=314, num_updates=22200, lr=9.49158e-05, gnorm=0.865, clip=0, loss_scale=32, train_wall=41, gb_free=16.5, wall=14526
2023-07-10 07:48:59 | INFO | train_inner | epoch 016:    201 / 1474 loss=4.723, trans_loss=5.248, nll_loss=2.503, w2v_ctc_loss=1.115, contrastive_loss=0, total=4106.45, n_correct=2351.24, ppl=5.67, accuracy=57.257, wps=19710.2, ups=2.39, wpb=8241.7, bsz=297.4, num_updates=22300, lr=9.47027e-05, gnorm=0.88, clip=0, loss_scale=32, train_wall=41, gb_free=16.7, wall=14567
2023-07-10 07:49:40 | INFO | train_inner | epoch 016:    301 / 1474 loss=4.76, trans_loss=5.267, nll_loss=2.528, w2v_ctc_loss=1.21, contrastive_loss=0, total=4169.65, n_correct=2376.09, ppl=5.77, accuracy=56.985, wps=19959.2, ups=2.41, wpb=8296, bsz=309.9, num_updates=22400, lr=9.44911e-05, gnorm=0.918, clip=0, loss_scale=32, train_wall=41, gb_free=11.3, wall=14609
2023-07-10 07:49:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-10 07:50:22 | INFO | train_inner | epoch 016:    402 / 1474 loss=4.772, trans_loss=5.261, nll_loss=2.518, w2v_ctc_loss=1.251, contrastive_loss=0, total=4067.9, n_correct=2322.77, ppl=5.73, accuracy=57.1, wps=19377.8, ups=2.38, wpb=8148.4, bsz=286.5, num_updates=22500, lr=9.42809e-05, gnorm=0.907, clip=0, loss_scale=16, train_wall=42, gb_free=16.6, wall=14651
2023-07-10 07:51:04 | INFO | train_inner | epoch 016:    502 / 1474 loss=4.742, trans_loss=5.253, nll_loss=2.51, w2v_ctc_loss=1.183, contrastive_loss=0, total=4181.93, n_correct=2393.76, ppl=5.7, accuracy=57.241, wps=19843.8, ups=2.38, wpb=8351.1, bsz=320.3, num_updates=22600, lr=9.40721e-05, gnorm=0.907, clip=0, loss_scale=16, train_wall=42, gb_free=16.2, wall=14693
2023-07-10 07:51:46 | INFO | train_inner | epoch 016:    602 / 1474 loss=4.744, trans_loss=5.263, nll_loss=2.522, w2v_ctc_loss=1.155, contrastive_loss=0, total=4122.97, n_correct=2358.74, ppl=5.74, accuracy=57.21, wps=19909.4, ups=2.42, wpb=8241.9, bsz=299, num_updates=22700, lr=9.38647e-05, gnorm=0.892, clip=0, loss_scale=16, train_wall=41, gb_free=16.5, wall=14734
2023-07-10 07:52:28 | INFO | train_inner | epoch 016:    702 / 1474 loss=4.73, trans_loss=5.267, nll_loss=2.528, w2v_ctc_loss=1.094, contrastive_loss=0, total=4093.15, n_correct=2334.42, ppl=5.77, accuracy=57.032, wps=19601, ups=2.39, wpb=8186.5, bsz=296.5, num_updates=22800, lr=9.36586e-05, gnorm=0.914, clip=0, loss_scale=16, train_wall=41, gb_free=18.1, wall=14776
2023-07-10 07:53:09 | INFO | train_inner | epoch 016:    802 / 1474 loss=4.743, trans_loss=5.254, nll_loss=2.512, w2v_ctc_loss=1.17, contrastive_loss=0, total=4183.24, n_correct=2397.95, ppl=5.7, accuracy=57.323, wps=20133, ups=2.4, wpb=8375.8, bsz=312.1, num_updates=22900, lr=9.34539e-05, gnorm=0.867, clip=0, loss_scale=16, train_wall=41, gb_free=18, wall=14818
2023-07-10 07:53:51 | INFO | train_inner | epoch 016:    902 / 1474 loss=4.756, trans_loss=5.26, nll_loss=2.52, w2v_ctc_loss=1.198, contrastive_loss=0, total=4150.23, n_correct=2379.71, ppl=5.73, accuracy=57.339, wps=19985.7, ups=2.41, wpb=8297, bsz=306.5, num_updates=23000, lr=9.32505e-05, gnorm=0.885, clip=0, loss_scale=16, train_wall=41, gb_free=12.6, wall=14859
2023-07-10 07:54:32 | INFO | train_inner | epoch 016:   1002 / 1474 loss=4.765, trans_loss=5.269, nll_loss=2.53, w2v_ctc_loss=1.204, contrastive_loss=0, total=4116.59, n_correct=2338.59, ppl=5.78, accuracy=56.809, wps=19772.7, ups=2.4, wpb=8249.2, bsz=300.6, num_updates=23100, lr=9.30484e-05, gnorm=0.925, clip=0, loss_scale=16, train_wall=41, gb_free=17.1, wall=14901
2023-07-10 07:55:15 | INFO | train_inner | epoch 016:   1102 / 1474 loss=4.795, trans_loss=5.276, nll_loss=2.54, w2v_ctc_loss=1.281, contrastive_loss=0, total=4112.71, n_correct=2337.42, ppl=5.82, accuracy=56.834, wps=19324, ups=2.34, wpb=8242.5, bsz=295.7, num_updates=23200, lr=9.28477e-05, gnorm=0.928, clip=0, loss_scale=16, train_wall=42, gb_free=12.7, wall=14944
2023-07-10 07:55:57 | INFO | train_inner | epoch 016:   1202 / 1474 loss=4.763, trans_loss=5.265, nll_loss=2.527, w2v_ctc_loss=1.211, contrastive_loss=0, total=4161.11, n_correct=2373.05, ppl=5.76, accuracy=57.029, wps=19768.9, ups=2.38, wpb=8320.3, bsz=308.2, num_updates=23300, lr=9.26482e-05, gnorm=0.918, clip=0, loss_scale=16, train_wall=42, gb_free=16.5, wall=14986
2023-07-10 07:56:39 | INFO | train_inner | epoch 016:   1302 / 1474 loss=4.769, trans_loss=5.268, nll_loss=2.532, w2v_ctc_loss=1.222, contrastive_loss=0, total=4149.14, n_correct=2363.91, ppl=5.78, accuracy=56.973, wps=19831.2, ups=2.39, wpb=8300.5, bsz=311.9, num_updates=23400, lr=9.245e-05, gnorm=0.905, clip=0, loss_scale=16, train_wall=41, gb_free=12, wall=15028
2023-07-10 07:57:21 | INFO | train_inner | epoch 016:   1402 / 1474 loss=4.76, trans_loss=5.263, nll_loss=2.524, w2v_ctc_loss=1.211, contrastive_loss=0, total=4200.01, n_correct=2400.75, ppl=5.75, accuracy=57.161, wps=19909.2, ups=2.37, wpb=8383.4, bsz=322.2, num_updates=23500, lr=9.22531e-05, gnorm=0.909, clip=0, loss_scale=16, train_wall=42, gb_free=17.3, wall=15070
2023-07-10 07:57:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 07:58:14 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.226 | trans_loss 5.89 | nll_loss 3.243 | w2v_ctc_loss 0.253 | contrastive_loss 0.208 | total 4003.4 | n_correct 2282.8 | ppl 9.47 | accuracy 57.022 | uer 43.437 | wer 45.517 | raw_wer 45.517 | bleu 16.04 | wps 2516 | wpb 4003.4 | bsz 141.8 | num_updates 23572 | best_bleu 16.04
2023-07-10 07:58:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23572 updates
2023-07-10 07:58:14 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 07:58:18 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 07:58:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt (epoch 16 @ 23572 updates, score 16.04) (writing took 8.108079264988191 seconds)
2023-07-10 07:58:22 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-07-10 07:58:22 | INFO | train | epoch 016 | loss 4.754 | trans_loss 5.262 | nll_loss 2.522 | w2v_ctc_loss 1.191 | contrastive_loss 0 | total 4138.9 | n_correct 2363.68 | ppl 5.74 | accuracy 57.109 | wps 18615.1 | ups 2.25 | wpb 8277.7 | bsz 305.7 | num_updates 23572 | lr 9.21121e-05 | gnorm 0.902 | clip 0 | loss_scale 16 | train_wall 610 | gb_free 15.8 | wall 15131
2023-07-10 07:58:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 07:58:22 | INFO | fairseq.trainer | begin training epoch 17
2023-07-10 07:58:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 07:58:42 | INFO | train_inner | epoch 017:     28 / 1474 loss=4.772, trans_loss=5.259, nll_loss=2.518, w2v_ctc_loss=1.263, contrastive_loss=0, total=4141.79, n_correct=2370.13, ppl=5.73, accuracy=57.225, wps=10242, ups=1.24, wpb=8262.1, bsz=301.5, num_updates=23600, lr=9.20575e-05, gnorm=0.91, clip=0, loss_scale=16, train_wall=41, gb_free=16.4, wall=15150
2023-07-10 07:59:24 | INFO | train_inner | epoch 017:    128 / 1474 loss=4.75, trans_loss=5.236, nll_loss=2.488, w2v_ctc_loss=1.247, contrastive_loss=0, total=4110.88, n_correct=2366.78, ppl=5.61, accuracy=57.574, wps=19744.3, ups=2.4, wpb=8218.1, bsz=295.4, num_updates=23700, lr=9.1863e-05, gnorm=0.915, clip=0, loss_scale=16, train_wall=41, gb_free=16.7, wall=15192
2023-07-10 08:00:05 | INFO | train_inner | epoch 017:    228 / 1474 loss=4.736, trans_loss=5.234, nll_loss=2.486, w2v_ctc_loss=1.208, contrastive_loss=0, total=4171.95, n_correct=2404.89, ppl=5.6, accuracy=57.644, wps=19945.5, ups=2.39, wpb=8331.2, bsz=320.4, num_updates=23800, lr=9.16698e-05, gnorm=0.9, clip=0, loss_scale=16, train_wall=41, gb_free=16.4, wall=15234
2023-07-10 08:00:47 | INFO | train_inner | epoch 017:    328 / 1474 loss=4.721, trans_loss=5.237, nll_loss=2.49, w2v_ctc_loss=1.157, contrastive_loss=0, total=4157.94, n_correct=2391.3, ppl=5.62, accuracy=57.512, wps=19876.4, ups=2.4, wpb=8293.4, bsz=305, num_updates=23900, lr=9.14779e-05, gnorm=0.91, clip=0, loss_scale=16, train_wall=41, gb_free=14.9, wall=15276
2023-07-10 08:01:29 | INFO | train_inner | epoch 017:    428 / 1474 loss=4.731, trans_loss=5.245, nll_loss=2.499, w2v_ctc_loss=1.147, contrastive_loss=0, total=4141.8, n_correct=2385, ppl=5.65, accuracy=57.584, wps=19799.2, ups=2.38, wpb=8313.5, bsz=306.7, num_updates=24000, lr=9.12871e-05, gnorm=0.879, clip=0, loss_scale=16, train_wall=42, gb_free=17.6, wall=15318
2023-07-10 08:01:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 08:01:51 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.222 | trans_loss 5.896 | nll_loss 3.248 | w2v_ctc_loss 0.23 | contrastive_loss 0.204 | total 4003.4 | n_correct 2281.5 | ppl 9.5 | accuracy 56.989 | uer 43.886 | wer 46.046 | raw_wer 46.046 | bleu 15.7 | wps 2508.1 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 16.04
2023-07-10 08:01:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-07-10 08:01:51 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_17_24000.pt
2023-07-10 08:01:54 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_17_24000.pt
2023-07-10 08:01:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 15.7) (writing took 5.956033891008701 seconds)
2023-07-10 08:02:40 | INFO | train_inner | epoch 017:    528 / 1474 loss=4.76, trans_loss=5.246, nll_loss=2.501, w2v_ctc_loss=1.262, contrastive_loss=0, total=4180.09, n_correct=2396.14, ppl=5.66, accuracy=57.323, wps=11733.5, ups=1.41, wpb=8343, bsz=307.5, num_updates=24100, lr=9.10975e-05, gnorm=0.934, clip=0, loss_scale=16, train_wall=42, gb_free=17.4, wall=15389
2023-07-10 08:03:22 | INFO | train_inner | epoch 017:    628 / 1474 loss=4.732, trans_loss=5.245, nll_loss=2.499, w2v_ctc_loss=1.166, contrastive_loss=0, total=4166.6, n_correct=2399.66, ppl=5.65, accuracy=57.593, wps=20077.9, ups=2.41, wpb=8315.8, bsz=302.3, num_updates=24200, lr=9.09091e-05, gnorm=0.87, clip=0, loss_scale=16, train_wall=41, gb_free=16.1, wall=15430
2023-07-10 08:04:04 | INFO | train_inner | epoch 017:    728 / 1474 loss=4.761, trans_loss=5.253, nll_loss=2.511, w2v_ctc_loss=1.235, contrastive_loss=0, total=4168.97, n_correct=2389.33, ppl=5.7, accuracy=57.312, wps=19805.1, ups=2.38, wpb=8337.3, bsz=308.4, num_updates=24300, lr=9.07218e-05, gnorm=0.931, clip=0, loss_scale=16, train_wall=42, gb_free=17.3, wall=15472
2023-07-10 08:04:45 | INFO | train_inner | epoch 017:    828 / 1474 loss=4.734, trans_loss=5.246, nll_loss=2.5, w2v_ctc_loss=1.163, contrastive_loss=0, total=4097.38, n_correct=2357.36, ppl=5.66, accuracy=57.533, wps=19828.2, ups=2.42, wpb=8201.6, bsz=297.3, num_updates=24400, lr=9.05357e-05, gnorm=0.898, clip=0, loss_scale=16, train_wall=41, gb_free=11.2, wall=15514
2023-07-10 08:05:26 | INFO | train_inner | epoch 017:    928 / 1474 loss=4.721, trans_loss=5.249, nll_loss=2.505, w2v_ctc_loss=1.112, contrastive_loss=0, total=4105.01, n_correct=2361.88, ppl=5.68, accuracy=57.537, wps=19791.3, ups=2.41, wpb=8205.5, bsz=304.1, num_updates=24500, lr=9.03508e-05, gnorm=0.88, clip=0, loss_scale=32, train_wall=41, gb_free=17, wall=15555
2023-07-10 08:06:08 | INFO | train_inner | epoch 017:   1028 / 1474 loss=4.735, trans_loss=5.245, nll_loss=2.501, w2v_ctc_loss=1.169, contrastive_loss=0, total=4105.88, n_correct=2361.73, ppl=5.66, accuracy=57.521, wps=19806.6, ups=2.41, wpb=8211.2, bsz=303.4, num_updates=24600, lr=9.0167e-05, gnorm=0.893, clip=0, loss_scale=32, train_wall=41, gb_free=16.3, wall=15597
2023-07-10 08:06:49 | INFO | train_inner | epoch 017:   1128 / 1474 loss=4.72, trans_loss=5.244, nll_loss=2.499, w2v_ctc_loss=1.119, contrastive_loss=0, total=4095.58, n_correct=2361.44, ppl=5.65, accuracy=57.658, wps=19782.3, ups=2.41, wpb=8196.2, bsz=298.5, num_updates=24700, lr=8.99843e-05, gnorm=0.893, clip=0, loss_scale=32, train_wall=41, gb_free=16.5, wall=15638
2023-07-10 08:07:31 | INFO | train_inner | epoch 017:   1228 / 1474 loss=4.764, trans_loss=5.248, nll_loss=2.506, w2v_ctc_loss=1.26, contrastive_loss=0, total=4162.14, n_correct=2385.05, ppl=5.68, accuracy=57.303, wps=19951, ups=2.39, wpb=8334.5, bsz=320.2, num_updates=24800, lr=8.98027e-05, gnorm=0.919, clip=0, loss_scale=32, train_wall=41, gb_free=16.7, wall=15680
2023-07-10 08:08:13 | INFO | train_inner | epoch 017:   1328 / 1474 loss=4.762, trans_loss=5.25, nll_loss=2.507, w2v_ctc_loss=1.251, contrastive_loss=0, total=4149.03, n_correct=2384.12, ppl=5.68, accuracy=57.462, wps=19816.5, ups=2.39, wpb=8282, bsz=306.7, num_updates=24900, lr=8.96221e-05, gnorm=0.934, clip=0, loss_scale=32, train_wall=41, gb_free=17.1, wall=15722
2023-07-10 08:08:55 | INFO | train_inner | epoch 017:   1428 / 1474 loss=4.768, trans_loss=5.249, nll_loss=2.505, w2v_ctc_loss=1.253, contrastive_loss=0, total=4117.13, n_correct=2365.41, ppl=5.68, accuracy=57.453, wps=19728.1, ups=2.39, wpb=8271.4, bsz=303.7, num_updates=25000, lr=8.94427e-05, gnorm=0.937, clip=0, loss_scale=32, train_wall=42, gb_free=17.8, wall=15763
1.0
tensor(0.0271, device='cuda:0')
2023-07-10 08:09:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
1.0
tensor(0.0271, device='cuda:7')
1.0
tensor(0.0271, device='cuda:3')
1.0
tensor(0.0271, device='cuda:6')
1.0
tensor(0.0271, device='cuda:4')
1.0
tensor(0.0271, device='cuda:5')
1.0
tensor(0.0271, device='cuda:2')
1.0
tensor(0.0271, device='cuda:1')
2023-07-10 08:09:37 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.213 | trans_loss 5.868 | nll_loss 3.215 | w2v_ctc_loss 0.263 | contrastive_loss 0.206 | total 4003.4 | n_correct 2293.3 | ppl 9.29 | accuracy 57.284 | uer 43.506 | wer 45.554 | raw_wer 45.554 | bleu 15.78 | wps 2433.8 | wpb 4003.4 | bsz 141.8 | num_updates 25046 | best_bleu 16.04
2023-07-10 08:09:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25046 updates
2023-07-10 08:09:37 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_15.7809.pt
2023-07-10 08:09:39 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_15.7809.pt
2023-07-10 08:09:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_15.7809.pt (epoch 17 @ 25046 updates, score 15.78) (writing took 5.0768756970064715 seconds)
2023-07-10 08:09:42 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-07-10 08:09:42 | INFO | train | epoch 017 | loss 4.742 | trans_loss 5.245 | nll_loss 2.5 | w2v_ctc_loss 1.195 | contrastive_loss 0 | total 4138.65 | n_correct 2380.03 | ppl 5.66 | accuracy 57.508 | wps 17946.8 | ups 2.17 | wpb 8277.3 | bsz 305.7 | num_updates 25046 | lr 8.93605e-05 | gnorm 0.906 | clip 0 | loss_scale 32 | train_wall 609 | gb_free 16.8 | wall 15811
2023-07-10 08:09:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 08:09:42 | INFO | fairseq.trainer | begin training epoch 18
2023-07-10 08:09:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 08:10:13 | INFO | train_inner | epoch 018:     54 / 1474 loss=4.737, trans_loss=5.236, nll_loss=2.489, w2v_ctc_loss=1.205, contrastive_loss=0, total=4138.21, n_correct=2385.54, ppl=5.61, accuracy=57.647, wps=10576.2, ups=1.28, wpb=8278.5, bsz=303.2, num_updates=25100, lr=8.92644e-05, gnorm=0.906, clip=0, loss_scale=32, train_wall=42, gb_free=18, wall=15842
2023-07-10 08:10:55 | INFO | train_inner | epoch 018:    154 / 1474 loss=4.715, trans_loss=5.213, nll_loss=2.458, w2v_ctc_loss=1.195, contrastive_loss=0, total=4158.88, n_correct=2419.57, ppl=5.5, accuracy=58.178, wps=19875.9, ups=2.39, wpb=8308.1, bsz=314, num_updates=25200, lr=8.90871e-05, gnorm=0.91, clip=0, loss_scale=32, train_wall=41, gb_free=17.2, wall=15884
2023-07-10 08:11:37 | INFO | train_inner | epoch 018:    254 / 1474 loss=4.72, trans_loss=5.216, nll_loss=2.463, w2v_ctc_loss=1.203, contrastive_loss=0, total=4164.11, n_correct=2424.51, ppl=5.51, accuracy=58.224, wps=19816.5, ups=2.38, wpb=8312.6, bsz=312.5, num_updates=25300, lr=8.89108e-05, gnorm=0.891, clip=0, loss_scale=32, train_wall=42, gb_free=15.4, wall=15925
2023-07-10 08:12:19 | INFO | train_inner | epoch 018:    354 / 1474 loss=4.715, trans_loss=5.223, nll_loss=2.47, w2v_ctc_loss=1.16, contrastive_loss=0, total=4163.13, n_correct=2414.39, ppl=5.54, accuracy=57.995, wps=19783.1, ups=2.38, wpb=8323, bsz=301.5, num_updates=25400, lr=8.87357e-05, gnorm=0.917, clip=0, loss_scale=32, train_wall=42, gb_free=17.9, wall=15968
2023-07-10 08:13:01 | INFO | train_inner | epoch 018:    454 / 1474 loss=4.721, trans_loss=5.232, nll_loss=2.483, w2v_ctc_loss=1.155, contrastive_loss=0, total=4087.83, n_correct=2354.68, ppl=5.59, accuracy=57.602, wps=19497.6, ups=2.38, wpb=8196.7, bsz=295.3, num_updates=25500, lr=8.85615e-05, gnorm=0.968, clip=0, loss_scale=32, train_wall=42, gb_free=16.6, wall=16010
2023-07-10 08:13:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-10 08:13:43 | INFO | train_inner | epoch 018:    555 / 1474 loss=4.7, trans_loss=5.213, nll_loss=2.46, w2v_ctc_loss=1.133, contrastive_loss=0, total=4210.72, n_correct=2454.05, ppl=5.5, accuracy=58.281, wps=19965.4, ups=2.37, wpb=8426, bsz=328.4, num_updates=25600, lr=8.83883e-05, gnorm=0.899, clip=0, loss_scale=16, train_wall=42, gb_free=16.2, wall=16052
2023-07-10 08:14:25 | INFO | train_inner | epoch 018:    655 / 1474 loss=4.757, trans_loss=5.243, nll_loss=2.498, w2v_ctc_loss=1.247, contrastive_loss=0, total=4093.44, n_correct=2358.72, ppl=5.65, accuracy=57.622, wps=19699.1, ups=2.41, wpb=8186.5, bsz=298.5, num_updates=25700, lr=8.82162e-05, gnorm=0.909, clip=0, loss_scale=16, train_wall=41, gb_free=15.6, wall=16093
2023-07-10 08:15:07 | INFO | train_inner | epoch 018:    755 / 1474 loss=4.729, trans_loss=5.232, nll_loss=2.485, w2v_ctc_loss=1.187, contrastive_loss=0, total=4202.99, n_correct=2430.7, ppl=5.6, accuracy=57.833, wps=20110, ups=2.39, wpb=8401.5, bsz=322.5, num_updates=25800, lr=8.80451e-05, gnorm=0.9, clip=0, loss_scale=16, train_wall=41, gb_free=17.8, wall=16135
2023-07-10 08:15:48 | INFO | train_inner | epoch 018:    855 / 1474 loss=4.712, trans_loss=5.232, nll_loss=2.483, w2v_ctc_loss=1.124, contrastive_loss=0, total=4177.43, n_correct=2415.18, ppl=5.59, accuracy=57.815, wps=20022.4, ups=2.39, wpb=8362.8, bsz=304.8, num_updates=25900, lr=8.7875e-05, gnorm=0.895, clip=0, loss_scale=16, train_wall=41, gb_free=16.6, wall=16177
2023-07-10 08:16:30 | INFO | train_inner | epoch 018:    955 / 1474 loss=4.693, trans_loss=5.216, nll_loss=2.464, w2v_ctc_loss=1.108, contrastive_loss=0, total=4138.23, n_correct=2409.19, ppl=5.52, accuracy=58.218, wps=20043.1, ups=2.43, wpb=8259.8, bsz=314.5, num_updates=26000, lr=8.77058e-05, gnorm=0.892, clip=0, loss_scale=16, train_wall=41, gb_free=16.9, wall=16218
2023-07-10 08:16:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 08:16:52 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.216 | trans_loss 5.869 | nll_loss 3.217 | w2v_ctc_loss 0.271 | contrastive_loss 0.211 | total 4003.4 | n_correct 2289.2 | ppl 9.3 | accuracy 57.181 | uer 43.458 | wer 45.338 | raw_wer 45.338 | bleu 15.97 | wps 2414 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 16.04
2023-07-10 08:16:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-07-10 08:16:52 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_18_26000.pt
2023-07-10 08:16:55 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_18_26000.pt
2023-07-10 08:16:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 15.97) (writing took 6.038620595005341 seconds)
2023-07-10 08:17:41 | INFO | train_inner | epoch 018:   1055 / 1474 loss=4.722, trans_loss=5.236, nll_loss=2.489, w2v_ctc_loss=1.149, contrastive_loss=0, total=4133.59, n_correct=2381.98, ppl=5.61, accuracy=57.625, wps=11604.2, ups=1.4, wpb=8264.5, bsz=298.7, num_updates=26100, lr=8.75376e-05, gnorm=0.898, clip=0, loss_scale=16, train_wall=41, gb_free=16.2, wall=16289
2023-07-10 08:18:23 | INFO | train_inner | epoch 018:   1155 / 1474 loss=4.723, trans_loss=5.223, nll_loss=2.473, w2v_ctc_loss=1.182, contrastive_loss=0, total=4154.22, n_correct=2413.02, ppl=5.55, accuracy=58.086, wps=19812.6, ups=2.38, wpb=8314.8, bsz=315.1, num_updates=26200, lr=8.73704e-05, gnorm=0.927, clip=0, loss_scale=16, train_wall=42, gb_free=15.3, wall=16331
2023-07-10 08:19:04 | INFO | train_inner | epoch 018:   1255 / 1474 loss=4.715, trans_loss=5.24, nll_loss=2.493, w2v_ctc_loss=1.113, contrastive_loss=0, total=4089.17, n_correct=2361.01, ppl=5.63, accuracy=57.738, wps=19660.5, ups=2.4, wpb=8179.1, bsz=287.6, num_updates=26300, lr=8.72041e-05, gnorm=0.946, clip=0, loss_scale=16, train_wall=41, gb_free=17, wall=16373
2023-07-10 08:19:46 | INFO | train_inner | epoch 018:   1355 / 1474 loss=4.756, trans_loss=5.247, nll_loss=2.504, w2v_ctc_loss=1.229, contrastive_loss=0, total=4068.84, n_correct=2340.05, ppl=5.67, accuracy=57.511, wps=19734.8, ups=2.42, wpb=8145, bsz=291.4, num_updates=26400, lr=8.70388e-05, gnorm=0.942, clip=0, loss_scale=16, train_wall=41, gb_free=15.8, wall=16414
2023-07-10 08:20:27 | INFO | train_inner | epoch 018:   1455 / 1474 loss=4.745, trans_loss=5.24, nll_loss=2.495, w2v_ctc_loss=1.203, contrastive_loss=0, total=4113.23, n_correct=2372.79, ppl=5.64, accuracy=57.687, wps=19849.1, ups=2.41, wpb=8251.4, bsz=297.2, num_updates=26500, lr=8.68744e-05, gnorm=0.938, clip=0, loss_scale=16, train_wall=41, gb_free=16.9, wall=16456
2023-07-10 08:20:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 08:20:58 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.202 | trans_loss 5.869 | nll_loss 3.216 | w2v_ctc_loss 0.222 | contrastive_loss 0.212 | total 4003.4 | n_correct 2295.6 | ppl 9.29 | accuracy 57.341 | uer 43.511 | wer 45.916 | raw_wer 45.916 | bleu 16.12 | wps 2587.1 | wpb 4003.4 | bsz 141.8 | num_updates 26519 | best_bleu 16.12
2023-07-10 08:20:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26519 updates
2023-07-10 08:20:58 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 08:21:02 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 08:21:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt (epoch 18 @ 26519 updates, score 16.12) (writing took 8.566806070011808 seconds)
2023-07-10 08:21:07 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-07-10 08:21:07 | INFO | train | epoch 018 | loss 4.724 | trans_loss 5.229 | nll_loss 2.48 | w2v_ctc_loss 1.175 | contrastive_loss 0 | total 4138.77 | n_correct 2395.59 | ppl 5.58 | accuracy 57.882 | wps 17804.2 | ups 2.15 | wpb 8277.4 | bsz 305.7 | num_updates 26519 | lr 8.68433e-05 | gnorm 0.916 | clip 0 | loss_scale 16 | train_wall 609 | gb_free 16.3 | wall 16495
2023-07-10 08:21:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 08:21:07 | INFO | fairseq.trainer | begin training epoch 19
2023-07-10 08:21:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 08:21:49 | INFO | train_inner | epoch 019:     81 / 1474 loss=4.711, trans_loss=5.214, nll_loss=2.46, w2v_ctc_loss=1.182, contrastive_loss=0, total=4107.26, n_correct=2388.86, ppl=5.5, accuracy=58.162, wps=9988.5, ups=1.22, wpb=8182.9, bsz=297.5, num_updates=26600, lr=8.6711e-05, gnorm=0.897, clip=0, loss_scale=16, train_wall=42, gb_free=13.2, wall=16538
2023-07-10 08:22:31 | INFO | train_inner | epoch 019:    181 / 1474 loss=4.694, trans_loss=5.199, nll_loss=2.441, w2v_ctc_loss=1.151, contrastive_loss=0, total=4222.18, n_correct=2470.03, ppl=5.43, accuracy=58.501, wps=20329.4, ups=2.4, wpb=8462.7, bsz=324.4, num_updates=26700, lr=8.65485e-05, gnorm=0.91, clip=0, loss_scale=16, train_wall=41, gb_free=12.3, wall=16579
2023-07-10 08:23:12 | INFO | train_inner | epoch 019:    281 / 1474 loss=4.687, trans_loss=5.207, nll_loss=2.45, w2v_ctc_loss=1.11, contrastive_loss=0, total=4187.37, n_correct=2445.11, ppl=5.46, accuracy=58.392, wps=20091.6, ups=2.4, wpb=8374.8, bsz=307, num_updates=26800, lr=8.63868e-05, gnorm=0.909, clip=0, loss_scale=16, train_wall=41, gb_free=17.8, wall=16621
2023-07-10 08:23:54 | INFO | train_inner | epoch 019:    381 / 1474 loss=4.704, trans_loss=5.205, nll_loss=2.45, w2v_ctc_loss=1.172, contrastive_loss=0, total=4170.67, n_correct=2435.34, ppl=5.46, accuracy=58.392, wps=20021.2, ups=2.4, wpb=8331.8, bsz=310.5, num_updates=26900, lr=8.62261e-05, gnorm=0.959, clip=0, loss_scale=16, train_wall=41, gb_free=17.5, wall=16663
2023-07-10 08:24:35 | INFO | train_inner | epoch 019:    481 / 1474 loss=4.709, trans_loss=5.209, nll_loss=2.454, w2v_ctc_loss=1.175, contrastive_loss=0, total=4115.22, n_correct=2395.73, ppl=5.48, accuracy=58.216, wps=19989.4, ups=2.42, wpb=8243.3, bsz=301.9, num_updates=27000, lr=8.60663e-05, gnorm=0.896, clip=0, loss_scale=16, train_wall=41, gb_free=15.5, wall=16704
2023-07-10 08:25:17 | INFO | train_inner | epoch 019:    581 / 1474 loss=4.687, trans_loss=5.211, nll_loss=2.457, w2v_ctc_loss=1.101, contrastive_loss=0, total=4129.22, n_correct=2406.81, ppl=5.49, accuracy=58.287, wps=19816.2, ups=2.4, wpb=8249.7, bsz=306, num_updates=27100, lr=8.59074e-05, gnorm=0.908, clip=0, loss_scale=16, train_wall=41, gb_free=16.2, wall=16746
2023-07-10 08:25:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-10 08:25:59 | INFO | train_inner | epoch 019:    682 / 1474 loss=4.692, trans_loss=5.209, nll_loss=2.456, w2v_ctc_loss=1.118, contrastive_loss=0, total=4200.75, n_correct=2457.65, ppl=5.49, accuracy=58.505, wps=20107.7, ups=2.4, wpb=8391.9, bsz=322.2, num_updates=27200, lr=8.57493e-05, gnorm=0.872, clip=0, loss_scale=8, train_wall=41, gb_free=17.3, wall=16787
2023-07-10 08:26:41 | INFO | train_inner | epoch 019:    782 / 1474 loss=4.706, trans_loss=5.215, nll_loss=2.461, w2v_ctc_loss=1.14, contrastive_loss=0, total=4142.94, n_correct=2409.47, ppl=5.51, accuracy=58.158, wps=19835.6, ups=2.39, wpb=8313.1, bsz=305.4, num_updates=27300, lr=8.55921e-05, gnorm=0.939, clip=0, loss_scale=8, train_wall=41, gb_free=16.9, wall=16829
2023-07-10 08:27:22 | INFO | train_inner | epoch 019:    882 / 1474 loss=4.714, trans_loss=5.22, nll_loss=2.469, w2v_ctc_loss=1.167, contrastive_loss=0, total=4153.23, n_correct=2408.98, ppl=5.54, accuracy=58.003, wps=19903.8, ups=2.4, wpb=8302.8, bsz=303.4, num_updates=27400, lr=8.54358e-05, gnorm=0.933, clip=0, loss_scale=8, train_wall=41, gb_free=17.3, wall=16871
2023-07-10 08:28:04 | INFO | train_inner | epoch 019:    982 / 1474 loss=4.718, trans_loss=5.228, nll_loss=2.481, w2v_ctc_loss=1.159, contrastive_loss=0, total=4102.27, n_correct=2374.22, ppl=5.58, accuracy=57.876, wps=19461.3, ups=2.37, wpb=8196.5, bsz=308.7, num_updates=27500, lr=8.52803e-05, gnorm=0.905, clip=0, loss_scale=8, train_wall=42, gb_free=16.3, wall=16913
2023-07-10 08:28:46 | INFO | train_inner | epoch 019:   1082 / 1474 loss=4.717, trans_loss=5.22, nll_loss=2.468, w2v_ctc_loss=1.163, contrastive_loss=0, total=4036.79, n_correct=2341.46, ppl=5.53, accuracy=58.003, wps=19630.7, ups=2.42, wpb=8107.7, bsz=291.6, num_updates=27600, lr=8.51257e-05, gnorm=0.962, clip=0, loss_scale=8, train_wall=41, gb_free=16.2, wall=16954
2023-07-10 08:29:28 | INFO | train_inner | epoch 019:   1182 / 1474 loss=4.728, trans_loss=5.228, nll_loss=2.479, w2v_ctc_loss=1.195, contrastive_loss=0, total=4129.82, n_correct=2388.38, ppl=5.58, accuracy=57.833, wps=19631.5, ups=2.38, wpb=8244, bsz=305.9, num_updates=27700, lr=8.49719e-05, gnorm=0.937, clip=0, loss_scale=8, train_wall=42, gb_free=18, wall=16996
2023-07-10 08:30:09 | INFO | train_inner | epoch 019:   1282 / 1474 loss=4.708, trans_loss=5.222, nll_loss=2.472, w2v_ctc_loss=1.143, contrastive_loss=0, total=4147.96, n_correct=2408.51, ppl=5.55, accuracy=58.065, wps=19847.6, ups=2.4, wpb=8277.6, bsz=301.4, num_updates=27800, lr=8.48189e-05, gnorm=0.875, clip=0, loss_scale=8, train_wall=41, gb_free=16.2, wall=17038
2023-07-10 08:30:51 | INFO | train_inner | epoch 019:   1382 / 1474 loss=4.725, trans_loss=5.217, nll_loss=2.466, w2v_ctc_loss=1.206, contrastive_loss=0, total=4125.32, n_correct=2399.39, ppl=5.52, accuracy=58.163, wps=19982.6, ups=2.42, wpb=8249.8, bsz=300.4, num_updates=27900, lr=8.46668e-05, gnorm=0.928, clip=0, loss_scale=8, train_wall=41, gb_free=16.8, wall=17079
2023-07-10 08:31:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 08:31:52 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.195 | trans_loss 5.852 | nll_loss 3.192 | w2v_ctc_loss 0.241 | contrastive_loss 0.206 | total 4003.4 | n_correct 2302 | ppl 9.14 | accuracy 57.501 | uer 43.28 | wer 45.535 | raw_wer 45.535 | bleu 16.38 | wps 2464.6 | wpb 4003.4 | bsz 141.8 | num_updates 27992 | best_bleu 16.38
2023-07-10 08:31:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27992 updates
2023-07-10 08:31:52 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 08:31:56 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 08:32:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt (epoch 19 @ 27992 updates, score 16.38) (writing took 8.253063707990805 seconds)
2023-07-10 08:32:00 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-07-10 08:32:00 | INFO | train | epoch 019 | loss 4.707 | trans_loss 5.215 | nll_loss 2.462 | w2v_ctc_loss 1.156 | contrastive_loss 0 | total 4138.76 | n_correct 2408.37 | ppl 5.51 | accuracy 58.191 | wps 18658.4 | ups 2.25 | wpb 8277.5 | bsz 305.8 | num_updates 27992 | lr 8.45275e-05 | gnorm 0.92 | clip 0 | loss_scale 8 | train_wall 608 | gb_free 17.6 | wall 17149
2023-07-10 08:32:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 08:32:01 | INFO | fairseq.trainer | begin training epoch 20
2023-07-10 08:32:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 08:32:12 | INFO | train_inner | epoch 020:      8 / 1474 loss=4.71, trans_loss=5.217, nll_loss=2.467, w2v_ctc_loss=1.152, contrastive_loss=0, total=4124.63, n_correct=2403.6, ppl=5.53, accuracy=58.274, wps=10188.1, ups=1.23, wpb=8255.1, bsz=304.8, num_updates=28000, lr=8.45154e-05, gnorm=0.957, clip=0, loss_scale=8, train_wall=41, gb_free=17.6, wall=17160
2023-07-10 08:32:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 08:32:35 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.202 | trans_loss 5.852 | nll_loss 3.195 | w2v_ctc_loss 0.267 | contrastive_loss 0.205 | total 4003.4 | n_correct 2302.4 | ppl 9.16 | accuracy 57.511 | uer 42.471 | wer 44.674 | raw_wer 44.674 | bleu 16.68 | wps 2366 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 16.68
2023-07-10 08:32:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-07-10 08:32:35 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_20_28000.pt
2023-07-10 08:32:37 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_20_28000.pt
2023-07-10 08:32:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 16.68) (writing took 8.906956774997525 seconds)
2023-07-10 08:33:26 | INFO | train_inner | epoch 020:    108 / 1474 loss=4.658, trans_loss=5.187, nll_loss=2.426, w2v_ctc_loss=1.069, contrastive_loss=0, total=4199.19, n_correct=2465.58, ppl=5.37, accuracy=58.716, wps=11320.9, ups=1.35, wpb=8392, bsz=314, num_updates=28100, lr=8.43649e-05, gnorm=0.912, clip=0, loss_scale=8, train_wall=41, gb_free=15.2, wall=17234
2023-07-10 08:34:08 | INFO | train_inner | epoch 020:    208 / 1474 loss=4.659, trans_loss=5.196, nll_loss=2.437, w2v_ctc_loss=1.047, contrastive_loss=0, total=4148.29, n_correct=2427.06, ppl=5.42, accuracy=58.507, wps=19849.6, ups=2.39, wpb=8295.2, bsz=300.5, num_updates=28200, lr=8.42152e-05, gnorm=0.894, clip=0, loss_scale=8, train_wall=41, gb_free=15.9, wall=17276
2023-07-10 08:34:49 | INFO | train_inner | epoch 020:    308 / 1474 loss=4.646, trans_loss=5.187, nll_loss=2.426, w2v_ctc_loss=1.029, contrastive_loss=0, total=4191.34, n_correct=2467.06, ppl=5.38, accuracy=58.861, wps=20164.8, ups=2.41, wpb=8365, bsz=326.2, num_updates=28300, lr=8.40663e-05, gnorm=0.914, clip=0, loss_scale=8, train_wall=41, gb_free=16.1, wall=17318
2023-07-10 08:35:31 | INFO | train_inner | epoch 020:    408 / 1474 loss=4.672, trans_loss=5.192, nll_loss=2.432, w2v_ctc_loss=1.095, contrastive_loss=0, total=4114.19, n_correct=2413.31, ppl=5.4, accuracy=58.658, wps=19904.4, ups=2.41, wpb=8249.3, bsz=297.5, num_updates=28400, lr=8.39181e-05, gnorm=0.932, clip=0, loss_scale=8, train_wall=41, gb_free=15.7, wall=17359
2023-07-10 08:36:13 | INFO | train_inner | epoch 020:    508 / 1474 loss=4.697, trans_loss=5.201, nll_loss=2.444, w2v_ctc_loss=1.162, contrastive_loss=0, total=4108.2, n_correct=2400.63, ppl=5.44, accuracy=58.435, wps=19392.7, ups=2.36, wpb=8205.3, bsz=299.5, num_updates=28500, lr=8.37708e-05, gnorm=0.909, clip=0, loss_scale=8, train_wall=42, gb_free=16, wall=17402
2023-07-10 08:36:54 | INFO | train_inner | epoch 020:    608 / 1474 loss=4.696, trans_loss=5.207, nll_loss=2.452, w2v_ctc_loss=1.136, contrastive_loss=0, total=4092.44, n_correct=2381.98, ppl=5.47, accuracy=58.204, wps=19744.7, ups=2.41, wpb=8194.6, bsz=295.9, num_updates=28600, lr=8.36242e-05, gnorm=0.942, clip=0, loss_scale=8, train_wall=41, gb_free=17.8, wall=17443
2023-07-10 08:37:36 | INFO | train_inner | epoch 020:    708 / 1474 loss=4.7, trans_loss=5.205, nll_loss=2.449, w2v_ctc_loss=1.162, contrastive_loss=0, total=4137.06, n_correct=2421.26, ppl=5.46, accuracy=58.526, wps=19882.7, ups=2.41, wpb=8245.3, bsz=300.5, num_updates=28700, lr=8.34784e-05, gnorm=0.931, clip=0, loss_scale=8, train_wall=41, gb_free=16.8, wall=17484
2023-07-10 08:38:18 | INFO | train_inner | epoch 020:    808 / 1474 loss=4.688, trans_loss=5.201, nll_loss=2.445, w2v_ctc_loss=1.117, contrastive_loss=0, total=4146.78, n_correct=2427.62, ppl=5.45, accuracy=58.542, wps=19917.2, ups=2.4, wpb=8311.5, bsz=307.3, num_updates=28800, lr=8.33333e-05, gnorm=0.895, clip=0, loss_scale=8, train_wall=41, gb_free=15.6, wall=17526
2023-07-10 08:39:00 | INFO | train_inner | epoch 020:    908 / 1474 loss=4.706, trans_loss=5.208, nll_loss=2.456, w2v_ctc_loss=1.18, contrastive_loss=0, total=4161, n_correct=2430.81, ppl=5.49, accuracy=58.419, wps=19515.3, ups=2.36, wpb=8282.1, bsz=323.2, num_updates=28900, lr=8.3189e-05, gnorm=0.9, clip=0, loss_scale=8, train_wall=42, gb_free=17.7, wall=17569
2023-07-10 08:39:42 | INFO | train_inner | epoch 020:   1008 / 1474 loss=4.687, trans_loss=5.2, nll_loss=2.443, w2v_ctc_loss=1.128, contrastive_loss=0, total=4168.14, n_correct=2442.9, ppl=5.44, accuracy=58.609, wps=19862, ups=2.38, wpb=8328.5, bsz=307.3, num_updates=29000, lr=8.30455e-05, gnorm=0.944, clip=0, loss_scale=8, train_wall=42, gb_free=16.8, wall=17611
2023-07-10 08:40:24 | INFO | train_inner | epoch 020:   1108 / 1474 loss=4.704, trans_loss=5.206, nll_loss=2.452, w2v_ctc_loss=1.171, contrastive_loss=0, total=4166.49, n_correct=2435.41, ppl=5.47, accuracy=58.452, wps=19945.1, ups=2.4, wpb=8315.7, bsz=315.4, num_updates=29100, lr=8.29027e-05, gnorm=0.938, clip=0, loss_scale=8, train_wall=41, gb_free=15.2, wall=17652
2023-07-10 08:41:05 | INFO | train_inner | epoch 020:   1208 / 1474 loss=4.72, trans_loss=5.208, nll_loss=2.452, w2v_ctc_loss=1.203, contrastive_loss=0, total=4029.18, n_correct=2352.43, ppl=5.47, accuracy=58.385, wps=19428.6, ups=2.4, wpb=8087.4, bsz=284, num_updates=29200, lr=8.27606e-05, gnorm=0.948, clip=0, loss_scale=8, train_wall=41, gb_free=12.4, wall=17694
2023-07-10 08:41:47 | INFO | train_inner | epoch 020:   1308 / 1474 loss=4.704, trans_loss=5.208, nll_loss=2.454, w2v_ctc_loss=1.149, contrastive_loss=0, total=4123.21, n_correct=2405.9, ppl=5.48, accuracy=58.35, wps=19876, ups=2.4, wpb=8278.2, bsz=297.1, num_updates=29300, lr=8.26192e-05, gnorm=0.934, clip=0, loss_scale=16, train_wall=41, gb_free=17.7, wall=17736
2023-07-10 08:42:28 | INFO | train_inner | epoch 020:   1408 / 1474 loss=4.715, trans_loss=5.216, nll_loss=2.464, w2v_ctc_loss=1.167, contrastive_loss=0, total=4116.28, n_correct=2399.74, ppl=5.52, accuracy=58.299, wps=19880.2, ups=2.41, wpb=8247.7, bsz=295, num_updates=29400, lr=8.24786e-05, gnorm=0.912, clip=0, loss_scale=16, train_wall=41, gb_free=17.8, wall=17777
2023-07-10 08:42:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 08:43:17 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.197 | trans_loss 5.862 | nll_loss 3.206 | w2v_ctc_loss 0.226 | contrastive_loss 0.206 | total 4003.4 | n_correct 2296.2 | ppl 9.23 | accuracy 57.356 | uer 42.558 | wer 45.114 | raw_wer 45.114 | bleu 15.96 | wps 2672.8 | wpb 4003.4 | bsz 141.8 | num_updates 29466 | best_bleu 16.68
2023-07-10 08:43:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29466 updates
2023-07-10 08:43:17 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_15.9606.pt
2023-07-10 08:43:19 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_15.9606.pt
2023-07-10 08:43:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_15.9606.pt (epoch 20 @ 29466 updates, score 15.96) (writing took 5.170168795011705 seconds)
2023-07-10 08:43:23 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-07-10 08:43:23 | INFO | train | epoch 020 | loss 4.688 | trans_loss 5.202 | nll_loss 2.445 | w2v_ctc_loss 1.126 | contrastive_loss 0 | total 4138.65 | n_correct 2420.9 | ppl 5.45 | accuracy 58.495 | wps 17884.5 | ups 2.16 | wpb 8277.3 | bsz 305.7 | num_updates 29466 | lr 8.23862e-05 | gnorm 0.919 | clip 0 | loss_scale 16 | train_wall 609 | gb_free 16.8 | wall 17831
2023-07-10 08:43:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 08:43:23 | INFO | fairseq.trainer | begin training epoch 21
2023-07-10 08:43:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 08:43:45 | INFO | train_inner | epoch 021:     34 / 1474 loss=4.676, trans_loss=5.2, nll_loss=2.445, w2v_ctc_loss=1.09, contrastive_loss=0, total=4152.26, n_correct=2425.63, ppl=5.44, accuracy=58.417, wps=10830.1, ups=1.3, wpb=8310.1, bsz=316.3, num_updates=29500, lr=8.23387e-05, gnorm=0.923, clip=0, loss_scale=16, train_wall=41, gb_free=16.8, wall=17854
2023-07-10 08:44:27 | INFO | train_inner | epoch 021:    134 / 1474 loss=4.661, trans_loss=5.173, nll_loss=2.408, w2v_ctc_loss=1.115, contrastive_loss=0, total=4195.08, n_correct=2477.11, ppl=5.31, accuracy=59.048, wps=19852.6, ups=2.37, wpb=8386.3, bsz=319.6, num_updates=29600, lr=8.21995e-05, gnorm=0.911, clip=0, loss_scale=16, train_wall=42, gb_free=17.3, wall=17896
2023-07-10 08:45:09 | INFO | train_inner | epoch 021:    234 / 1474 loss=4.657, trans_loss=5.177, nll_loss=2.413, w2v_ctc_loss=1.091, contrastive_loss=0, total=4155.31, n_correct=2451.38, ppl=5.33, accuracy=58.994, wps=20066.7, ups=2.42, wpb=8305.4, bsz=312.6, num_updates=29700, lr=8.2061e-05, gnorm=0.895, clip=0, loss_scale=16, train_wall=41, gb_free=17.1, wall=17937
2023-07-10 08:45:51 | INFO | train_inner | epoch 021:    334 / 1474 loss=4.69, trans_loss=5.179, nll_loss=2.416, w2v_ctc_loss=1.188, contrastive_loss=0, total=4151.51, n_correct=2445.39, ppl=5.34, accuracy=58.904, wps=19922.3, ups=2.4, wpb=8316, bsz=310.8, num_updates=29800, lr=8.19232e-05, gnorm=0.898, clip=0, loss_scale=16, train_wall=41, gb_free=15.9, wall=17979
2023-07-10 08:46:32 | INFO | train_inner | epoch 021:    434 / 1474 loss=4.65, trans_loss=5.175, nll_loss=2.41, w2v_ctc_loss=1.066, contrastive_loss=0, total=4180.85, n_correct=2472.89, ppl=5.32, accuracy=59.148, wps=19984.3, ups=2.39, wpb=8359.9, bsz=306.8, num_updates=29900, lr=8.17861e-05, gnorm=0.904, clip=0, loss_scale=16, train_wall=41, gb_free=16.1, wall=18021
2023-07-10 08:47:14 | INFO | train_inner | epoch 021:    534 / 1474 loss=4.677, trans_loss=5.185, nll_loss=2.423, w2v_ctc_loss=1.124, contrastive_loss=0, total=4083.98, n_correct=2405.12, ppl=5.36, accuracy=58.892, wps=19665, ups=2.4, wpb=8190.4, bsz=295.1, num_updates=30000, lr=8.16497e-05, gnorm=0.893, clip=0, loss_scale=16, train_wall=41, gb_free=13.5, wall=18063
2023-07-10 08:47:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 08:47:37 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.19 | trans_loss 5.849 | nll_loss 3.194 | w2v_ctc_loss 0.231 | contrastive_loss 0.207 | total 4003.4 | n_correct 2305.6 | ppl 9.15 | accuracy 57.591 | uer 42.951 | wer 45.345 | raw_wer 45.345 | bleu 16.21 | wps 2273 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 16.68
2023-07-10 08:47:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-07-10 08:47:37 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_21_30000.pt
2023-07-10 08:47:39 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_21_30000.pt
2023-07-10 08:47:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 16.21) (writing took 6.111942839983385 seconds)
1.0
tensor(0.0271, device='cuda:0')
2023-07-10 08:48:26 | INFO | train_inner | epoch 021:    634 / 1474 loss=4.687, trans_loss=5.188, nll_loss=2.428, w2v_ctc_loss=1.167, contrastive_loss=0, total=4215.41, n_correct=2480.14, ppl=5.38, accuracy=58.835, wps=11759.1, ups=1.4, wpb=8403.4, bsz=315.4, num_updates=30100, lr=8.15139e-05, gnorm=0.935, clip=0, loss_scale=16, train_wall=42, gb_free=12, wall=18134
2023-07-10 08:49:07 | INFO | train_inner | epoch 021:    734 / 1474 loss=4.69, trans_loss=5.194, nll_loss=2.436, w2v_ctc_loss=1.148, contrastive_loss=0, total=4152.97, n_correct=2438.52, ppl=5.41, accuracy=58.717, wps=19932.1, ups=2.4, wpb=8318.4, bsz=309.3, num_updates=30200, lr=8.13788e-05, gnorm=0.956, clip=0, loss_scale=16, train_wall=41, gb_free=16.7, wall=18176
2023-07-10 08:49:49 | INFO | train_inner | epoch 021:    834 / 1474 loss=4.697, trans_loss=5.196, nll_loss=2.438, w2v_ctc_loss=1.164, contrastive_loss=0, total=4066.93, n_correct=2380.29, ppl=5.42, accuracy=58.528, wps=19473.7, ups=2.39, wpb=8158.7, bsz=294.4, num_updates=30300, lr=8.12444e-05, gnorm=0.924, clip=0, loss_scale=16, train_wall=41, gb_free=17.3, wall=18218
2023-07-10 08:50:31 | INFO | train_inner | epoch 021:    934 / 1474 loss=4.687, trans_loss=5.186, nll_loss=2.426, w2v_ctc_loss=1.162, contrastive_loss=0, total=4103.34, n_correct=2418.55, ppl=5.38, accuracy=58.941, wps=19720.8, ups=2.41, wpb=8188.2, bsz=301, num_updates=30400, lr=8.11107e-05, gnorm=0.927, clip=0, loss_scale=16, train_wall=41, gb_free=14.5, wall=18259
2023-07-10 08:51:12 | INFO | train_inner | epoch 021:   1034 / 1474 loss=4.703, trans_loss=5.2, nll_loss=2.444, w2v_ctc_loss=1.18, contrastive_loss=0, total=4099.86, n_correct=2403.06, ppl=5.44, accuracy=58.613, wps=19845.7, ups=2.43, wpb=8182.9, bsz=298.8, num_updates=30500, lr=8.09776e-05, gnorm=0.947, clip=0, loss_scale=16, train_wall=41, gb_free=12, wall=18301
2023-07-10 08:51:53 | INFO | train_inner | epoch 021:   1134 / 1474 loss=4.71, trans_loss=5.198, nll_loss=2.441, w2v_ctc_loss=1.206, contrastive_loss=0, total=4120.75, n_correct=2414.36, ppl=5.43, accuracy=58.59, wps=19851.8, ups=2.41, wpb=8241.3, bsz=293.5, num_updates=30600, lr=8.08452e-05, gnorm=0.952, clip=0, loss_scale=16, train_wall=41, gb_free=16.2, wall=18342
2023-07-10 08:52:35 | INFO | train_inner | epoch 021:   1234 / 1474 loss=4.663, trans_loss=5.187, nll_loss=2.427, w2v_ctc_loss=1.087, contrastive_loss=0, total=4154.73, n_correct=2446.58, ppl=5.38, accuracy=58.887, wps=19979.1, ups=2.41, wpb=8292.3, bsz=311.6, num_updates=30700, lr=8.07134e-05, gnorm=0.912, clip=0, loss_scale=16, train_wall=41, gb_free=13.2, wall=18384
2023-07-10 08:53:17 | INFO | train_inner | epoch 021:   1334 / 1474 loss=4.676, trans_loss=5.19, nll_loss=2.431, w2v_ctc_loss=1.105, contrastive_loss=0, total=4147.17, n_correct=2445.46, ppl=5.39, accuracy=58.967, wps=19760.9, ups=2.38, wpb=8315.3, bsz=311.9, num_updates=30800, lr=8.05823e-05, gnorm=0.915, clip=0, loss_scale=16, train_wall=42, gb_free=16.6, wall=18426
2023-07-10 08:53:59 | INFO | train_inner | epoch 021:   1434 / 1474 loss=4.704, trans_loss=5.209, nll_loss=2.457, w2v_ctc_loss=1.158, contrastive_loss=0, total=4133.93, n_correct=2411.25, ppl=5.49, accuracy=58.328, wps=19664.9, ups=2.38, wpb=8265.5, bsz=304.5, num_updates=30900, lr=8.04518e-05, gnorm=0.93, clip=0, loss_scale=16, train_wall=42, gb_free=15.9, wall=18468
2023-07-10 08:54:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
1.0
tensor(0.0271, device='cuda:3')
1.0
tensor(0.0271, device='cuda:7')
1.0
tensor(0.0271, device='cuda:5')
1.0
tensor(0.0271, device='cuda:6')
1.0
tensor(0.0271, device='cuda:4')
1.0
tensor(0.0271, device='cuda:2')
1.0
tensor(0.0271, device='cuda:1')
2023-07-10 08:54:38 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.196 | trans_loss 5.826 | nll_loss 3.155 | w2v_ctc_loss 0.306 | contrastive_loss 0.206 | total 4003.4 | n_correct 2320.9 | ppl 8.91 | accuracy 57.973 | uer 42.365 | wer 44.611 | raw_wer 44.611 | bleu 16.68 | wps 2602.8 | wpb 4003.4 | bsz 141.8 | num_updates 30940 | best_bleu 16.68
2023-07-10 08:54:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30940 updates
2023-07-10 08:54:38 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 08:54:42 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 08:54:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt (epoch 21 @ 30940 updates, score 16.68) (writing took 8.30899725900963 seconds)
2023-07-10 08:54:46 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-07-10 08:54:46 | INFO | train | epoch 021 | loss 4.682 | trans_loss 5.189 | nll_loss 2.429 | w2v_ctc_loss 1.139 | contrastive_loss 0 | total 4138.65 | n_correct 2434.09 | ppl 5.38 | accuracy 58.814 | wps 17843.5 | ups 2.16 | wpb 8277.3 | bsz 305.7 | num_updates 30940 | lr 8.03998e-05 | gnorm 0.924 | clip 0 | loss_scale 16 | train_wall 610 | gb_free 15.8 | wall 18515
2023-07-10 08:54:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 08:54:47 | INFO | fairseq.trainer | begin training epoch 22
2023-07-10 08:54:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 08:55:19 | INFO | train_inner | epoch 022:     60 / 1474 loss=4.657, trans_loss=5.179, nll_loss=2.415, w2v_ctc_loss=1.08, contrastive_loss=0, total=4128.84, n_correct=2441.57, ppl=5.33, accuracy=59.135, wps=10278.5, ups=1.24, wpb=8260.4, bsz=297.7, num_updates=31000, lr=8.03219e-05, gnorm=0.92, clip=0, loss_scale=16, train_wall=41, gb_free=14.6, wall=18548
2023-07-10 08:56:01 | INFO | train_inner | epoch 022:    160 / 1474 loss=4.676, trans_loss=5.172, nll_loss=2.408, w2v_ctc_loss=1.163, contrastive_loss=0, total=4123.35, n_correct=2438.72, ppl=5.31, accuracy=59.144, wps=19733.5, ups=2.39, wpb=8244.6, bsz=310.3, num_updates=31100, lr=8.01927e-05, gnorm=0.956, clip=0, loss_scale=16, train_wall=41, gb_free=15.1, wall=18590
2023-07-10 08:56:43 | INFO | train_inner | epoch 022:    260 / 1474 loss=4.638, trans_loss=5.156, nll_loss=2.387, w2v_ctc_loss=1.079, contrastive_loss=0, total=4267.16, n_correct=2541.77, ppl=5.23, accuracy=59.566, wps=20557.9, ups=2.41, wpb=8531.7, bsz=329.9, num_updates=31200, lr=8.00641e-05, gnorm=0.88, clip=0, loss_scale=16, train_wall=41, gb_free=17.1, wall=18631
2023-07-10 08:57:25 | INFO | train_inner | epoch 022:    360 / 1474 loss=4.689, trans_loss=5.178, nll_loss=2.415, w2v_ctc_loss=1.193, contrastive_loss=0, total=4180.09, n_correct=2462.02, ppl=5.33, accuracy=58.899, wps=19698.5, ups=2.36, wpb=8362.3, bsz=310, num_updates=31300, lr=7.99361e-05, gnorm=0.982, clip=0, loss_scale=32, train_wall=42, gb_free=17.8, wall=18674
2023-07-10 08:58:07 | INFO | train_inner | epoch 022:    460 / 1474 loss=4.701, trans_loss=5.186, nll_loss=2.424, w2v_ctc_loss=1.221, contrastive_loss=0, total=4132.62, n_correct=2429.55, ppl=5.37, accuracy=58.79, wps=19757.2, ups=2.4, wpb=8240.5, bsz=297.2, num_updates=31400, lr=7.98087e-05, gnorm=1.001, clip=0, loss_scale=32, train_wall=41, gb_free=16.9, wall=18715
2023-07-10 08:58:49 | INFO | train_inner | epoch 022:    560 / 1474 loss=4.675, trans_loss=5.174, nll_loss=2.409, w2v_ctc_loss=1.152, contrastive_loss=0, total=4155.5, n_correct=2457.15, ppl=5.31, accuracy=59.13, wps=19850.9, ups=2.39, wpb=8319.6, bsz=307.3, num_updates=31500, lr=7.96819e-05, gnorm=0.918, clip=0, loss_scale=32, train_wall=42, gb_free=16.8, wall=18757
2023-07-10 08:59:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-10 08:59:30 | INFO | train_inner | epoch 022:    661 / 1474 loss=4.65, trans_loss=5.164, nll_loss=2.398, w2v_ctc_loss=1.097, contrastive_loss=0, total=4142.76, n_correct=2457.19, ppl=5.27, accuracy=59.313, wps=20024.7, ups=2.42, wpb=8280.2, bsz=312.3, num_updates=31600, lr=7.95557e-05, gnorm=0.903, clip=0, loss_scale=16, train_wall=41, gb_free=16.6, wall=18799
2023-07-10 09:00:12 | INFO | train_inner | epoch 022:    761 / 1474 loss=4.673, trans_loss=5.181, nll_loss=2.419, w2v_ctc_loss=1.124, contrastive_loss=0, total=4167.89, n_correct=2461.47, ppl=5.35, accuracy=59.058, wps=19936.1, ups=2.39, wpb=8336.9, bsz=303.9, num_updates=31700, lr=7.94301e-05, gnorm=0.941, clip=0, loss_scale=16, train_wall=41, gb_free=13.3, wall=18841
2023-07-10 09:00:54 | INFO | train_inner | epoch 022:    861 / 1474 loss=4.686, trans_loss=5.188, nll_loss=2.428, w2v_ctc_loss=1.137, contrastive_loss=0, total=4075.79, n_correct=2396.41, ppl=5.38, accuracy=58.796, wps=19665.7, ups=2.4, wpb=8198.8, bsz=289, num_updates=31800, lr=7.93052e-05, gnorm=0.94, clip=0, loss_scale=16, train_wall=41, gb_free=16.6, wall=18882
2023-07-10 09:01:35 | INFO | train_inner | epoch 022:    961 / 1474 loss=4.675, trans_loss=5.175, nll_loss=2.412, w2v_ctc_loss=1.149, contrastive_loss=0, total=4134.72, n_correct=2449.37, ppl=5.32, accuracy=59.239, wps=19780.3, ups=2.39, wpb=8265.9, bsz=303.2, num_updates=31900, lr=7.91808e-05, gnorm=0.957, clip=0, loss_scale=16, train_wall=41, gb_free=14.6, wall=18924
2023-07-10 09:02:17 | INFO | train_inner | epoch 022:   1061 / 1474 loss=4.673, trans_loss=5.172, nll_loss=2.409, w2v_ctc_loss=1.154, contrastive_loss=0, total=4160.57, n_correct=2469.24, ppl=5.31, accuracy=59.349, wps=19915.6, ups=2.4, wpb=8306, bsz=315.5, num_updates=32000, lr=7.90569e-05, gnorm=0.944, clip=0, loss_scale=16, train_wall=41, gb_free=17.5, wall=18966
2023-07-10 09:02:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 09:02:39 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.196 | trans_loss 5.844 | nll_loss 3.185 | w2v_ctc_loss 0.262 | contrastive_loss 0.209 | total 4003.4 | n_correct 2315.9 | ppl 9.09 | accuracy 57.848 | uer 41.916 | wer 44.13 | raw_wer 44.13 | bleu 16.45 | wps 2532.5 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 16.68
2023-07-10 09:02:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-07-10 09:02:39 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_22_32000.pt
2023-07-10 09:02:42 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_22_32000.pt
2023-07-10 09:02:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 16.45) (writing took 6.2988540919614024 seconds)
2023-07-10 09:03:28 | INFO | train_inner | epoch 022:   1161 / 1474 loss=4.666, trans_loss=5.185, nll_loss=2.424, w2v_ctc_loss=1.103, contrastive_loss=0, total=4099.59, n_correct=2410.96, ppl=5.37, accuracy=58.81, wps=11623.7, ups=1.42, wpb=8180.2, bsz=296.2, num_updates=32100, lr=7.89337e-05, gnorm=0.915, clip=0, loss_scale=16, train_wall=41, gb_free=15.4, wall=19036
2023-07-10 09:04:09 | INFO | train_inner | epoch 022:   1261 / 1474 loss=4.658, trans_loss=5.176, nll_loss=2.415, w2v_ctc_loss=1.093, contrastive_loss=0, total=4182.05, n_correct=2469.91, ppl=5.33, accuracy=59.06, wps=19996, ups=2.39, wpb=8365.4, bsz=323, num_updates=32200, lr=7.8811e-05, gnorm=0.896, clip=0, loss_scale=16, train_wall=41, gb_free=16, wall=19078
2023-07-10 09:04:50 | INFO | train_inner | epoch 022:   1361 / 1474 loss=4.663, trans_loss=5.174, nll_loss=2.411, w2v_ctc_loss=1.108, contrastive_loss=0, total=4062.31, n_correct=2403.87, ppl=5.32, accuracy=59.175, wps=19806.5, ups=2.43, wpb=8134.9, bsz=299, num_updates=32300, lr=7.86889e-05, gnorm=0.938, clip=0, loss_scale=16, train_wall=41, gb_free=15.5, wall=19119
2023-07-10 09:05:32 | INFO | train_inner | epoch 022:   1461 / 1474 loss=4.693, trans_loss=5.196, nll_loss=2.438, w2v_ctc_loss=1.153, contrastive_loss=0, total=4081.88, n_correct=2400.96, ppl=5.42, accuracy=58.82, wps=19587.9, ups=2.4, wpb=8161.1, bsz=288.9, num_updates=32400, lr=7.85674e-05, gnorm=0.993, clip=0, loss_scale=16, train_wall=41, gb_free=17.5, wall=19161
2023-07-10 09:05:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 09:06:02 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.177 | trans_loss 5.839 | nll_loss 3.179 | w2v_ctc_loss 0.209 | contrastive_loss 0.204 | total 4003.4 | n_correct 2315.9 | ppl 9.06 | accuracy 57.848 | uer 42.181 | wer 45.095 | raw_wer 45.095 | bleu 16.35 | wps 2275.2 | wpb 4003.4 | bsz 141.8 | num_updates 32413 | best_bleu 16.68
2023-07-10 09:06:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32413 updates
2023-07-10 09:06:02 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_16.3501.pt
2023-07-10 09:06:04 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_16.3501.pt
2023-07-10 09:06:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_16.3501.pt (epoch 22 @ 32413 updates, score 16.35) (writing took 5.375987850944512 seconds)
2023-07-10 09:06:07 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-07-10 09:06:07 | INFO | train | epoch 022 | loss 4.672 | trans_loss 5.177 | nll_loss 2.413 | w2v_ctc_loss 1.135 | contrastive_loss 0 | total 4138.62 | n_correct 2445.56 | ppl 5.33 | accuracy 59.091 | wps 17908 | ups 2.16 | wpb 8277.3 | bsz 305.7 | num_updates 32413 | lr 7.85517e-05 | gnorm 0.941 | clip 0 | loss_scale 16 | train_wall 608 | gb_free 12.3 | wall 19196
2023-07-10 09:06:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 09:06:07 | INFO | fairseq.trainer | begin training epoch 23
2023-07-10 09:06:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 09:06:51 | INFO | train_inner | epoch 023:     87 / 1474 loss=4.652, trans_loss=5.159, nll_loss=2.39, w2v_ctc_loss=1.114, contrastive_loss=0, total=4096.09, n_correct=2431.95, ppl=5.24, accuracy=59.372, wps=10355.4, ups=1.26, wpb=8207.5, bsz=301.2, num_updates=32500, lr=7.84465e-05, gnorm=0.927, clip=0, loss_scale=16, train_wall=41, gb_free=16.8, wall=19240
2023-07-10 09:07:33 | INFO | train_inner | epoch 023:    187 / 1474 loss=4.655, trans_loss=5.161, nll_loss=2.392, w2v_ctc_loss=1.124, contrastive_loss=0, total=4107.77, n_correct=2436.5, ppl=5.25, accuracy=59.314, wps=19702.9, ups=2.4, wpb=8214.3, bsz=293.4, num_updates=32600, lr=7.8326e-05, gnorm=0.948, clip=0, loss_scale=16, train_wall=41, gb_free=16.7, wall=19282
2023-07-10 09:08:15 | INFO | train_inner | epoch 023:    287 / 1474 loss=4.659, trans_loss=5.158, nll_loss=2.389, w2v_ctc_loss=1.15, contrastive_loss=0, total=4153.12, n_correct=2465.35, ppl=5.24, accuracy=59.361, wps=19829.7, ups=2.39, wpb=8296.2, bsz=306.4, num_updates=32700, lr=7.82062e-05, gnorm=0.957, clip=0, loss_scale=16, train_wall=41, gb_free=17.4, wall=19324
2023-07-10 09:08:57 | INFO | train_inner | epoch 023:    387 / 1474 loss=4.645, trans_loss=5.162, nll_loss=2.394, w2v_ctc_loss=1.081, contrastive_loss=0, total=4116.7, n_correct=2443.6, ppl=5.25, accuracy=59.358, wps=19671, ups=2.39, wpb=8242.9, bsz=294, num_updates=32800, lr=7.80869e-05, gnorm=0.941, clip=0, loss_scale=16, train_wall=42, gb_free=15.7, wall=19365
2023-07-10 09:09:39 | INFO | train_inner | epoch 023:    487 / 1474 loss=4.651, trans_loss=5.163, nll_loss=2.397, w2v_ctc_loss=1.103, contrastive_loss=0, total=4157.6, n_correct=2467.45, ppl=5.27, accuracy=59.348, wps=19824.2, ups=2.39, wpb=8310.1, bsz=313.5, num_updates=32900, lr=7.79681e-05, gnorm=0.904, clip=0, loss_scale=16, train_wall=42, gb_free=17.6, wall=19407
2023-07-10 09:10:20 | INFO | train_inner | epoch 023:    587 / 1474 loss=4.633, trans_loss=5.152, nll_loss=2.382, w2v_ctc_loss=1.065, contrastive_loss=0, total=4173.42, n_correct=2491, ppl=5.21, accuracy=59.687, wps=20238.2, ups=2.42, wpb=8359.3, bsz=316, num_updates=33000, lr=7.78499e-05, gnorm=0.911, clip=0, loss_scale=16, train_wall=41, gb_free=13.3, wall=19449
2023-07-10 09:11:02 | INFO | train_inner | epoch 023:    687 / 1474 loss=4.665, trans_loss=5.165, nll_loss=2.398, w2v_ctc_loss=1.137, contrastive_loss=0, total=4137.82, n_correct=2456.98, ppl=5.27, accuracy=59.379, wps=19732.8, ups=2.38, wpb=8286.5, bsz=302.5, num_updates=33100, lr=7.77322e-05, gnorm=0.923, clip=0, loss_scale=16, train_wall=42, gb_free=17.5, wall=19491
2023-07-10 09:11:44 | INFO | train_inner | epoch 023:    787 / 1474 loss=4.648, trans_loss=5.172, nll_loss=2.408, w2v_ctc_loss=1.072, contrastive_loss=0, total=4150.99, n_correct=2457.06, ppl=5.31, accuracy=59.192, wps=19999.3, ups=2.41, wpb=8289.2, bsz=305.4, num_updates=33200, lr=7.76151e-05, gnorm=0.922, clip=0, loss_scale=16, train_wall=41, gb_free=16.8, wall=19532
2023-07-10 09:12:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-10 09:12:26 | INFO | train_inner | epoch 023:    888 / 1474 loss=4.652, trans_loss=5.155, nll_loss=2.387, w2v_ctc_loss=1.129, contrastive_loss=0, total=4184.88, n_correct=2495.89, ppl=5.23, accuracy=59.641, wps=19859.7, ups=2.38, wpb=8358.7, bsz=325.3, num_updates=33300, lr=7.74984e-05, gnorm=0.891, clip=0, loss_scale=8, train_wall=42, gb_free=17.1, wall=19574
2023-07-10 09:13:07 | INFO | train_inner | epoch 023:    988 / 1474 loss=4.67, trans_loss=5.176, nll_loss=2.414, w2v_ctc_loss=1.138, contrastive_loss=0, total=4165.01, n_correct=2462.64, ppl=5.33, accuracy=59.127, wps=19890.3, ups=2.4, wpb=8300.9, bsz=309.6, num_updates=33400, lr=7.73823e-05, gnorm=0.935, clip=0, loss_scale=8, train_wall=41, gb_free=17.9, wall=19616
2023-07-10 09:13:49 | INFO | train_inner | epoch 023:   1088 / 1474 loss=4.634, trans_loss=5.174, nll_loss=2.41, w2v_ctc_loss=1.012, contrastive_loss=0, total=4092.37, n_correct=2423.47, ppl=5.32, accuracy=59.219, wps=19640.1, ups=2.4, wpb=8198.8, bsz=290.8, num_updates=33500, lr=7.72667e-05, gnorm=0.897, clip=0, loss_scale=8, train_wall=41, gb_free=17.7, wall=19658
2023-07-10 09:14:31 | INFO | train_inner | epoch 023:   1188 / 1474 loss=4.658, trans_loss=5.172, nll_loss=2.409, w2v_ctc_loss=1.092, contrastive_loss=0, total=4164.9, n_correct=2469.51, ppl=5.31, accuracy=59.293, wps=19789, ups=2.37, wpb=8343.1, bsz=309.2, num_updates=33600, lr=7.71517e-05, gnorm=0.936, clip=0, loss_scale=8, train_wall=42, gb_free=14.1, wall=19700
2023-07-10 09:15:13 | INFO | train_inner | epoch 023:   1288 / 1474 loss=4.632, trans_loss=5.161, nll_loss=2.395, w2v_ctc_loss=1.042, contrastive_loss=0, total=4136.96, n_correct=2464.76, ppl=5.26, accuracy=59.579, wps=19809.4, ups=2.4, wpb=8266.9, bsz=309.8, num_updates=33700, lr=7.70371e-05, gnorm=0.928, clip=0, loss_scale=8, train_wall=41, gb_free=17, wall=19742
2023-07-10 09:15:55 | INFO | train_inner | epoch 023:   1388 / 1474 loss=4.66, trans_loss=5.186, nll_loss=2.426, w2v_ctc_loss=1.071, contrastive_loss=0, total=4142.84, n_correct=2443.44, ppl=5.37, accuracy=58.98, wps=19815.1, ups=2.39, wpb=8284.8, bsz=304.8, num_updates=33800, lr=7.69231e-05, gnorm=0.918, clip=0, loss_scale=8, train_wall=41, gb_free=16.5, wall=19783
2023-07-10 09:16:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 09:16:54 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.169 | trans_loss 5.821 | nll_loss 3.154 | w2v_ctc_loss 0.228 | contrastive_loss 0.205 | total 4003.4 | n_correct 2325.2 | ppl 8.9 | accuracy 58.081 | uer 42.343 | wer 44.842 | raw_wer 44.842 | bleu 16.43 | wps 2427.2 | wpb 4003.4 | bsz 141.8 | num_updates 33886 | best_bleu 16.68
2023-07-10 09:16:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33886 updates
2023-07-10 09:16:54 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_16.4308.pt
2023-07-10 09:16:56 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_16.4308.pt
2023-07-10 09:16:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_16.4308.pt (epoch 23 @ 33886 updates, score 16.43) (writing took 5.167092259973288 seconds)
2023-07-10 09:16:59 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-07-10 09:16:59 | INFO | train | epoch 023 | loss 4.65 | trans_loss 5.167 | nll_loss 2.401 | w2v_ctc_loss 1.09 | contrastive_loss 0 | total 4138.99 | n_correct 2455.3 | ppl 5.28 | accuracy 59.321 | wps 18706.3 | ups 2.26 | wpb 8277.9 | bsz 305.7 | num_updates 33886 | lr 7.68254e-05 | gnorm 0.924 | clip 0 | loss_scale 8 | train_wall 609 | gb_free 14.2 | wall 19848
2023-07-10 09:16:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 09:16:59 | INFO | fairseq.trainer | begin training epoch 24
2023-07-10 09:16:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 09:17:13 | INFO | train_inner | epoch 024:     14 / 1474 loss=4.637, trans_loss=5.18, nll_loss=2.419, w2v_ctc_loss=1.011, contrastive_loss=0, total=4084.21, n_correct=2410.69, ppl=5.35, accuracy=59.025, wps=10452.1, ups=1.28, wpb=8173.3, bsz=303.7, num_updates=33900, lr=7.68095e-05, gnorm=0.93, clip=0, loss_scale=8, train_wall=41, gb_free=15.8, wall=19862
2023-07-10 09:17:55 | INFO | train_inner | epoch 024:    114 / 1474 loss=4.599, trans_loss=5.136, nll_loss=2.361, w2v_ctc_loss=1.009, contrastive_loss=0, total=4168.61, n_correct=2496.58, ppl=5.14, accuracy=59.89, wps=19948.7, ups=2.4, wpb=8322.6, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.874, clip=0, loss_scale=8, train_wall=41, gb_free=12.1, wall=19903
2023-07-10 09:17:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 09:18:17 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.175 | trans_loss 5.831 | nll_loss 3.165 | w2v_ctc_loss 0.224 | contrastive_loss 0.207 | total 4003.4 | n_correct 2316.7 | ppl 8.97 | accuracy 57.868 | uer 42.68 | wer 45.211 | raw_wer 45.211 | bleu 16.55 | wps 2632.7 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 16.68
2023-07-10 09:18:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-07-10 09:18:17 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_24_34000.pt
2023-07-10 09:18:19 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_24_34000.pt
2023-07-10 09:18:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 16.55) (writing took 6.129861013032496 seconds)
2023-07-10 09:19:05 | INFO | train_inner | epoch 024:    214 / 1474 loss=4.603, trans_loss=5.141, nll_loss=2.369, w2v_ctc_loss=1.009, contrastive_loss=0, total=4252.53, n_correct=2546.76, ppl=5.17, accuracy=59.888, wps=12052.5, ups=1.42, wpb=8487.2, bsz=341.3, num_updates=34100, lr=7.6584e-05, gnorm=0.877, clip=0, loss_scale=8, train_wall=41, gb_free=17.1, wall=19974
2023-07-10 09:19:47 | INFO | train_inner | epoch 024:    314 / 1474 loss=4.609, trans_loss=5.146, nll_loss=2.374, w2v_ctc_loss=1.004, contrastive_loss=0, total=4138.44, n_correct=2470.66, ppl=5.18, accuracy=59.7, wps=19909.4, ups=2.4, wpb=8283.7, bsz=307.1, num_updates=34200, lr=7.64719e-05, gnorm=0.881, clip=0, loss_scale=8, train_wall=41, gb_free=15.9, wall=20015
2023-07-10 09:20:29 | INFO | train_inner | epoch 024:    414 / 1474 loss=4.66, trans_loss=5.166, nll_loss=2.399, w2v_ctc_loss=1.122, contrastive_loss=0, total=4153.83, n_correct=2464.71, ppl=5.28, accuracy=59.336, wps=19761, ups=2.38, wpb=8305.8, bsz=298.4, num_updates=34300, lr=7.63604e-05, gnorm=0.958, clip=0, loss_scale=8, train_wall=42, gb_free=16.5, wall=20057
2023-07-10 09:21:11 | INFO | train_inner | epoch 024:    514 / 1474 loss=4.634, trans_loss=5.153, nll_loss=2.383, w2v_ctc_loss=1.076, contrastive_loss=0, total=4141.88, n_correct=2466.9, ppl=5.22, accuracy=59.56, wps=19520.6, ups=2.36, wpb=8275.6, bsz=302.6, num_updates=34400, lr=7.62493e-05, gnorm=0.906, clip=0, loss_scale=8, train_wall=42, gb_free=15.5, wall=20100
2023-07-10 09:21:53 | INFO | train_inner | epoch 024:    614 / 1474 loss=4.634, trans_loss=5.154, nll_loss=2.384, w2v_ctc_loss=1.071, contrastive_loss=0, total=4162.06, n_correct=2481.84, ppl=5.22, accuracy=59.63, wps=19992.7, ups=2.4, wpb=8317.8, bsz=308.1, num_updates=34500, lr=7.61387e-05, gnorm=0.918, clip=0, loss_scale=8, train_wall=41, gb_free=17.1, wall=20141
2023-07-10 09:22:34 | INFO | train_inner | epoch 024:    714 / 1474 loss=4.65, trans_loss=5.159, nll_loss=2.391, w2v_ctc_loss=1.106, contrastive_loss=0, total=4097.35, n_correct=2435.91, ppl=5.24, accuracy=59.451, wps=19777.6, ups=2.41, wpb=8199.5, bsz=293.8, num_updates=34600, lr=7.60286e-05, gnorm=0.91, clip=0, loss_scale=8, train_wall=41, gb_free=17.5, wall=20183
2023-07-10 09:23:16 | INFO | train_inner | epoch 024:    814 / 1474 loss=4.611, trans_loss=5.154, nll_loss=2.384, w2v_ctc_loss=0.996, contrastive_loss=0, total=4124.25, n_correct=2456.2, ppl=5.22, accuracy=59.555, wps=19826.9, ups=2.41, wpb=8242.9, bsz=308.2, num_updates=34700, lr=7.5919e-05, gnorm=0.901, clip=0, loss_scale=8, train_wall=41, gb_free=16.6, wall=20224
2023-07-10 09:23:57 | INFO | train_inner | epoch 024:    914 / 1474 loss=4.625, trans_loss=5.171, nll_loss=2.406, w2v_ctc_loss=0.986, contrastive_loss=0, total=4041.44, n_correct=2393.76, ppl=5.3, accuracy=59.23, wps=19467.9, ups=2.4, wpb=8096.6, bsz=280.5, num_updates=34800, lr=7.58098e-05, gnorm=0.948, clip=0, loss_scale=8, train_wall=41, gb_free=16.6, wall=20266
2023-07-10 09:24:39 | INFO | train_inner | epoch 024:   1014 / 1474 loss=4.631, trans_loss=5.164, nll_loss=2.396, w2v_ctc_loss=1.022, contrastive_loss=0, total=4128.8, n_correct=2454.99, ppl=5.26, accuracy=59.46, wps=19749.5, ups=2.38, wpb=8282.7, bsz=296.5, num_updates=34900, lr=7.57011e-05, gnorm=0.904, clip=0, loss_scale=8, train_wall=42, gb_free=15.5, wall=20308
2023-07-10 09:25:21 | INFO | train_inner | epoch 024:   1114 / 1474 loss=4.608, trans_loss=5.144, nll_loss=2.372, w2v_ctc_loss=0.999, contrastive_loss=0, total=4130.49, n_correct=2466.96, ppl=5.18, accuracy=59.726, wps=19821.1, ups=2.39, wpb=8282.3, bsz=308.9, num_updates=35000, lr=7.55929e-05, gnorm=0.886, clip=0, loss_scale=8, train_wall=41, gb_free=16.4, wall=20350
1.0
tensor(0.0271, device='cuda:0')
2023-07-10 09:26:04 | INFO | train_inner | epoch 024:   1214 / 1474 loss=4.619, trans_loss=5.16, nll_loss=2.393, w2v_ctc_loss=1.002, contrastive_loss=0, total=4157.47, n_correct=2474.3, ppl=5.25, accuracy=59.515, wps=19563.8, ups=2.35, wpb=8318.1, bsz=311.2, num_updates=35100, lr=7.54851e-05, gnorm=0.918, clip=0, loss_scale=8, train_wall=42, gb_free=13.2, wall=20392
2023-07-10 09:26:45 | INFO | train_inner | epoch 024:   1314 / 1474 loss=4.641, trans_loss=5.169, nll_loss=2.404, w2v_ctc_loss=1.063, contrastive_loss=0, total=4107.23, n_correct=2434.28, ppl=5.29, accuracy=59.268, wps=19704.6, ups=2.41, wpb=8189.4, bsz=294.3, num_updates=35200, lr=7.53778e-05, gnorm=0.99, clip=0, loss_scale=8, train_wall=41, gb_free=17.8, wall=20434
2023-07-10 09:27:27 | INFO | train_inner | epoch 024:   1414 / 1474 loss=4.663, trans_loss=5.17, nll_loss=2.406, w2v_ctc_loss=1.12, contrastive_loss=0, total=4094.39, n_correct=2434.29, ppl=5.3, accuracy=59.454, wps=19661.8, ups=2.4, wpb=8186.3, bsz=292.9, num_updates=35300, lr=7.5271e-05, gnorm=0.974, clip=0, loss_scale=8, train_wall=41, gb_free=16.6, wall=20475
2023-07-10 09:27:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
1.0
tensor(0.0271, device='cuda:4')
1.0
tensor(0.0271, device='cuda:3')
1.0
tensor(0.0271, device='cuda:7')
1.0
tensor(0.0271, device='cuda:6')
1.0
tensor(0.0271, device='cuda:5')
1.0
tensor(0.0271, device='cuda:1')
1.0
tensor(0.0271, device='cuda:2')
2023-07-10 09:28:15 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.166 | trans_loss 5.808 | nll_loss 3.135 | w2v_ctc_loss 0.248 | contrastive_loss 0.204 | total 4003.4 | n_correct 2336.3 | ppl 8.78 | accuracy 58.358 | uer 41.844 | wer 44.107 | raw_wer 44.107 | bleu 16.93 | wps 2367.5 | wpb 4003.4 | bsz 141.8 | num_updates 35360 | best_bleu 16.93
2023-07-10 09:28:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35360 updates
2023-07-10 09:28:15 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 09:28:19 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 09:28:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt (epoch 24 @ 35360 updates, score 16.93) (writing took 8.214841353008524 seconds)
2023-07-10 09:28:24 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-07-10 09:28:24 | INFO | train | epoch 024 | loss 4.628 | trans_loss 5.156 | nll_loss 2.387 | w2v_ctc_loss 1.043 | contrastive_loss 0 | total 4138.65 | n_correct 2465.3 | ppl 5.23 | accuracy 59.568 | wps 17821.1 | ups 2.15 | wpb 8277.3 | bsz 305.7 | num_updates 35360 | lr 7.52071e-05 | gnorm 0.915 | clip 0 | loss_scale 16 | train_wall 610 | gb_free 16.5 | wall 20532
2023-07-10 09:28:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 09:28:24 | INFO | fairseq.trainer | begin training epoch 25
2023-07-10 09:28:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 09:28:48 | INFO | train_inner | epoch 025:     40 / 1474 loss=4.633, trans_loss=5.146, nll_loss=2.375, w2v_ctc_loss=1.081, contrastive_loss=0, total=4165.57, n_correct=2499.11, ppl=5.19, accuracy=59.994, wps=10249.6, ups=1.23, wpb=8340.3, bsz=311.2, num_updates=35400, lr=7.51646e-05, gnorm=0.897, clip=0, loss_scale=16, train_wall=41, gb_free=13.6, wall=20557
2023-07-10 09:29:30 | INFO | train_inner | epoch 025:    140 / 1474 loss=4.619, trans_loss=5.129, nll_loss=2.352, w2v_ctc_loss=1.085, contrastive_loss=0, total=4135.43, n_correct=2486.72, ppl=5.11, accuracy=60.132, wps=20028.2, ups=2.42, wpb=8268.2, bsz=308.9, num_updates=35500, lr=7.50587e-05, gnorm=0.926, clip=0, loss_scale=16, train_wall=41, gb_free=18, wall=20598
2023-07-10 09:30:12 | INFO | train_inner | epoch 025:    240 / 1474 loss=4.626, trans_loss=5.138, nll_loss=2.364, w2v_ctc_loss=1.076, contrastive_loss=0, total=4116.13, n_correct=2465.44, ppl=5.15, accuracy=59.897, wps=19473.2, ups=2.36, wpb=8260.2, bsz=303, num_updates=35600, lr=7.49532e-05, gnorm=0.957, clip=0, loss_scale=16, train_wall=42, gb_free=17.6, wall=20641
2023-07-10 09:30:54 | INFO | train_inner | epoch 025:    340 / 1474 loss=4.63, trans_loss=5.152, nll_loss=2.381, w2v_ctc_loss=1.061, contrastive_loss=0, total=4141.49, n_correct=2466.83, ppl=5.21, accuracy=59.564, wps=19775, ups=2.39, wpb=8276.8, bsz=294.2, num_updates=35700, lr=7.48481e-05, gnorm=0.95, clip=0, loss_scale=16, train_wall=41, gb_free=15.6, wall=20682
2023-07-10 09:31:36 | INFO | train_inner | epoch 025:    440 / 1474 loss=4.627, trans_loss=5.153, nll_loss=2.382, w2v_ctc_loss=1.065, contrastive_loss=0, total=4167.4, n_correct=2485.21, ppl=5.21, accuracy=59.635, wps=19785.8, ups=2.38, wpb=8297.2, bsz=297.7, num_updates=35800, lr=7.47435e-05, gnorm=0.948, clip=0, loss_scale=16, train_wall=41, gb_free=16.2, wall=20724
2023-07-10 09:32:18 | INFO | train_inner | epoch 025:    540 / 1474 loss=4.63, trans_loss=5.144, nll_loss=2.372, w2v_ctc_loss=1.077, contrastive_loss=0, total=4160.61, n_correct=2487.88, ppl=5.18, accuracy=59.796, wps=19962.3, ups=2.39, wpb=8337.8, bsz=313.9, num_updates=35900, lr=7.46393e-05, gnorm=0.926, clip=0, loss_scale=16, train_wall=41, gb_free=17.8, wall=20766
2023-07-10 09:32:59 | INFO | train_inner | epoch 025:    640 / 1474 loss=4.616, trans_loss=5.146, nll_loss=2.374, w2v_ctc_loss=1.028, contrastive_loss=0, total=4153.68, n_correct=2482.07, ppl=5.18, accuracy=59.756, wps=20111.5, ups=2.42, wpb=8311.3, bsz=309.6, num_updates=36000, lr=7.45356e-05, gnorm=0.919, clip=0, loss_scale=16, train_wall=41, gb_free=16.7, wall=20807
2023-07-10 09:32:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 09:33:21 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.171 | trans_loss 5.829 | nll_loss 3.162 | w2v_ctc_loss 0.216 | contrastive_loss 0.202 | total 4003.4 | n_correct 2322.3 | ppl 8.95 | accuracy 58.008 | uer 42.516 | wer 44.972 | raw_wer 44.972 | bleu 16.67 | wps 2499.4 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 16.93
2023-07-10 09:33:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-07-10 09:33:21 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_25_36000.pt
2023-07-10 09:33:24 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_25_36000.pt
2023-07-10 09:33:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 16.67) (writing took 6.3903921080054715 seconds)
2023-07-10 09:34:10 | INFO | train_inner | epoch 025:    740 / 1474 loss=4.618, trans_loss=5.144, nll_loss=2.372, w2v_ctc_loss=1.042, contrastive_loss=0, total=4128.34, n_correct=2464.97, ppl=5.17, accuracy=59.709, wps=11643.3, ups=1.41, wpb=8267.2, bsz=301.3, num_updates=36100, lr=7.44323e-05, gnorm=0.935, clip=0, loss_scale=16, train_wall=41, gb_free=17.3, wall=20878
2023-07-10 09:34:52 | INFO | train_inner | epoch 025:    840 / 1474 loss=4.616, trans_loss=5.143, nll_loss=2.371, w2v_ctc_loss=1.04, contrastive_loss=0, total=4182.4, n_correct=2509.75, ppl=5.17, accuracy=60.007, wps=19939.3, ups=2.39, wpb=8352, bsz=326, num_updates=36200, lr=7.43294e-05, gnorm=0.92, clip=0, loss_scale=16, train_wall=41, gb_free=17.9, wall=20920
2023-07-10 09:35:33 | INFO | train_inner | epoch 025:    940 / 1474 loss=4.617, trans_loss=5.139, nll_loss=2.366, w2v_ctc_loss=1.055, contrastive_loss=0, total=4155.21, n_correct=2491.24, ppl=5.16, accuracy=59.955, wps=19926.1, ups=2.4, wpb=8305.8, bsz=317, num_updates=36300, lr=7.4227e-05, gnorm=0.917, clip=0, loss_scale=16, train_wall=41, gb_free=14.6, wall=20962
2023-07-10 09:36:15 | INFO | train_inner | epoch 025:   1040 / 1474 loss=4.651, trans_loss=5.155, nll_loss=2.386, w2v_ctc_loss=1.126, contrastive_loss=0, total=4177.7, n_correct=2488.72, ppl=5.23, accuracy=59.572, wps=19907.7, ups=2.38, wpb=8348.8, bsz=309.8, num_updates=36400, lr=7.41249e-05, gnorm=0.938, clip=0, loss_scale=16, train_wall=42, gb_free=16, wall=21004
2023-07-10 09:36:57 | INFO | train_inner | epoch 025:   1140 / 1474 loss=4.626, trans_loss=5.159, nll_loss=2.391, w2v_ctc_loss=1.024, contrastive_loss=0, total=4039.24, n_correct=2404, ppl=5.25, accuracy=59.516, wps=19486.5, ups=2.41, wpb=8087.6, bsz=285.2, num_updates=36500, lr=7.40233e-05, gnorm=0.971, clip=0, loss_scale=16, train_wall=41, gb_free=16.7, wall=21045
2023-07-10 09:37:38 | INFO | train_inner | epoch 025:   1240 / 1474 loss=4.62, trans_loss=5.151, nll_loss=2.38, w2v_ctc_loss=1.03, contrastive_loss=0, total=4090.59, n_correct=2441.15, ppl=5.21, accuracy=59.677, wps=19829.9, ups=2.42, wpb=8177.5, bsz=295.7, num_updates=36600, lr=7.39221e-05, gnorm=0.921, clip=0, loss_scale=16, train_wall=41, gb_free=17.6, wall=21087
2023-07-10 09:38:20 | INFO | train_inner | epoch 025:   1340 / 1474 loss=4.612, trans_loss=5.153, nll_loss=2.385, w2v_ctc_loss=1.002, contrastive_loss=0, total=4164.34, n_correct=2491.38, ppl=5.22, accuracy=59.827, wps=19820.7, ups=2.39, wpb=8299.5, bsz=310.1, num_updates=36700, lr=7.38213e-05, gnorm=0.91, clip=0, loss_scale=16, train_wall=41, gb_free=17.2, wall=21129
2023-07-10 09:39:02 | INFO | train_inner | epoch 025:   1440 / 1474 loss=4.628, trans_loss=5.163, nll_loss=2.397, w2v_ctc_loss=1.016, contrastive_loss=0, total=4099.11, n_correct=2435.31, ppl=5.27, accuracy=59.411, wps=19407.9, ups=2.36, wpb=8222, bsz=299.3, num_updates=36800, lr=7.3721e-05, gnorm=0.973, clip=0, loss_scale=16, train_wall=42, gb_free=12.8, wall=21171
2023-07-10 09:39:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 09:39:38 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.161 | trans_loss 5.805 | nll_loss 3.134 | w2v_ctc_loss 0.236 | contrastive_loss 0.215 | total 4003.4 | n_correct 2330 | ppl 8.78 | accuracy 58.201 | uer 42.333 | wer 44.64 | raw_wer 44.64 | bleu 16.91 | wps 2632.6 | wpb 4003.4 | bsz 141.8 | num_updates 36834 | best_bleu 16.93
2023-07-10 09:39:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36834 updates
2023-07-10 09:39:38 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_16.9102.pt
2023-07-10 09:39:41 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_16.9102.pt
2023-07-10 09:39:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_16.9102.pt (epoch 25 @ 36834 updates, score 16.91) (writing took 5.258733727969229 seconds)
2023-07-10 09:39:44 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-07-10 09:39:44 | INFO | train | epoch 025 | loss 4.624 | trans_loss 5.147 | nll_loss 2.376 | w2v_ctc_loss 1.052 | contrastive_loss 0 | total 4138.65 | n_correct 2473.03 | ppl 5.19 | accuracy 59.755 | wps 17936.8 | ups 2.17 | wpb 8277.3 | bsz 305.7 | num_updates 36834 | lr 7.36869e-05 | gnorm 0.935 | clip 0 | loss_scale 16 | train_wall 610 | gb_free 14.7 | wall 21212
2023-07-10 09:39:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 09:39:44 | INFO | fairseq.trainer | begin training epoch 26
2023-07-10 09:39:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 09:40:19 | INFO | train_inner | epoch 026:     66 / 1474 loss=4.618, trans_loss=5.127, nll_loss=2.35, w2v_ctc_loss=1.079, contrastive_loss=0, total=4180.21, n_correct=2513.45, ppl=5.1, accuracy=60.127, wps=10914.4, ups=1.3, wpb=8389.7, bsz=318.3, num_updates=36900, lr=7.3621e-05, gnorm=0.909, clip=0, loss_scale=16, train_wall=41, gb_free=17.3, wall=21248
2023-07-10 09:41:01 | INFO | train_inner | epoch 026:    166 / 1474 loss=4.602, trans_loss=5.123, nll_loss=2.346, w2v_ctc_loss=1.055, contrastive_loss=0, total=4270.78, n_correct=2574.44, ppl=5.09, accuracy=60.28, wps=20151.8, ups=2.37, wpb=8512.4, bsz=340.4, num_updates=37000, lr=7.35215e-05, gnorm=0.902, clip=0, loss_scale=16, train_wall=42, gb_free=15.6, wall=21290
2023-07-10 09:41:43 | INFO | train_inner | epoch 026:    266 / 1474 loss=4.607, trans_loss=5.131, nll_loss=2.355, w2v_ctc_loss=1.043, contrastive_loss=0, total=4125.04, n_correct=2482.35, ppl=5.12, accuracy=60.178, wps=19841.3, ups=2.41, wpb=8239.8, bsz=307.1, num_updates=37100, lr=7.34223e-05, gnorm=0.927, clip=0, loss_scale=16, train_wall=41, gb_free=15.6, wall=21332
2023-07-10 09:42:25 | INFO | train_inner | epoch 026:    366 / 1474 loss=4.589, trans_loss=5.133, nll_loss=2.358, w2v_ctc_loss=0.973, contrastive_loss=0, total=4165.74, n_correct=2502.84, ppl=5.13, accuracy=60.082, wps=20040.4, ups=2.41, wpb=8328.2, bsz=314.7, num_updates=37200, lr=7.33236e-05, gnorm=0.92, clip=0, loss_scale=16, train_wall=41, gb_free=17.1, wall=21373
2023-07-10 09:43:07 | INFO | train_inner | epoch 026:    466 / 1474 loss=4.605, trans_loss=5.127, nll_loss=2.351, w2v_ctc_loss=1.05, contrastive_loss=0, total=4170.23, n_correct=2513.71, ppl=5.1, accuracy=60.277, wps=19710.3, ups=2.37, wpb=8309.6, bsz=315.4, num_updates=37300, lr=7.32252e-05, gnorm=0.898, clip=0, loss_scale=16, train_wall=42, gb_free=18, wall=21415
2023-07-10 09:43:48 | INFO | train_inner | epoch 026:    566 / 1474 loss=4.618, trans_loss=5.137, nll_loss=2.362, w2v_ctc_loss=1.05, contrastive_loss=0, total=4155.02, n_correct=2491.19, ppl=5.14, accuracy=59.956, wps=20088.3, ups=2.41, wpb=8341.7, bsz=303.9, num_updates=37400, lr=7.31272e-05, gnorm=0.93, clip=0, loss_scale=32, train_wall=41, gb_free=18.1, wall=21457
2023-07-10 09:44:30 | INFO | train_inner | epoch 026:    666 / 1474 loss=4.605, trans_loss=5.137, nll_loss=2.362, w2v_ctc_loss=1.016, contrastive_loss=0, total=4136.96, n_correct=2480.46, ppl=5.14, accuracy=59.959, wps=19812, ups=2.4, wpb=8271.2, bsz=299.2, num_updates=37500, lr=7.30297e-05, gnorm=0.932, clip=0, loss_scale=32, train_wall=41, gb_free=15.7, wall=21499
2023-07-10 09:45:12 | INFO | train_inner | epoch 026:    766 / 1474 loss=4.613, trans_loss=5.137, nll_loss=2.363, w2v_ctc_loss=1.047, contrastive_loss=0, total=4086.28, n_correct=2450.14, ppl=5.14, accuracy=59.96, wps=19672.6, ups=2.41, wpb=8169.3, bsz=298.5, num_updates=37600, lr=7.29325e-05, gnorm=0.903, clip=0, loss_scale=32, train_wall=41, gb_free=15.5, wall=21540
2023-07-10 09:45:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-10 09:45:54 | INFO | train_inner | epoch 026:    867 / 1474 loss=4.618, trans_loss=5.142, nll_loss=2.369, w2v_ctc_loss=1.052, contrastive_loss=0, total=4180.87, n_correct=2505.09, ppl=5.17, accuracy=59.918, wps=19609.5, ups=2.35, wpb=8329.6, bsz=307.4, num_updates=37700, lr=7.28357e-05, gnorm=0.974, clip=0, loss_scale=16, train_wall=42, gb_free=16.6, wall=21583
2023-07-10 09:46:36 | INFO | train_inner | epoch 026:    967 / 1474 loss=4.632, trans_loss=5.147, nll_loss=2.376, w2v_ctc_loss=1.076, contrastive_loss=0, total=4141.01, n_correct=2475.5, ppl=5.19, accuracy=59.78, wps=19815.9, ups=2.39, wpb=8280.8, bsz=299.7, num_updates=37800, lr=7.27393e-05, gnorm=0.961, clip=0, loss_scale=16, train_wall=41, gb_free=15.9, wall=21624
2023-07-10 09:47:17 | INFO | train_inner | epoch 026:   1067 / 1474 loss=4.61, trans_loss=5.141, nll_loss=2.368, w2v_ctc_loss=1.016, contrastive_loss=0, total=4113.69, n_correct=2465.84, ppl=5.16, accuracy=59.942, wps=19794.7, ups=2.4, wpb=8246.1, bsz=293, num_updates=37900, lr=7.26433e-05, gnorm=0.905, clip=0, loss_scale=16, train_wall=41, gb_free=16, wall=21666
2023-07-10 09:48:00 | INFO | train_inner | epoch 026:   1167 / 1474 loss=4.625, trans_loss=5.147, nll_loss=2.375, w2v_ctc_loss=1.058, contrastive_loss=0, total=4116.78, n_correct=2466.23, ppl=5.19, accuracy=59.907, wps=19505.4, ups=2.37, wpb=8229.6, bsz=299, num_updates=38000, lr=7.25476e-05, gnorm=0.938, clip=0, loss_scale=16, train_wall=42, gb_free=16.9, wall=21708
2023-07-10 09:48:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 09:48:23 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.165 | trans_loss 5.809 | nll_loss 3.133 | w2v_ctc_loss 0.239 | contrastive_loss 0.206 | total 4003.4 | n_correct 2334.3 | ppl 8.77 | accuracy 58.308 | uer 42.065 | wer 44.614 | raw_wer 44.614 | bleu 17.21 | wps 2368.8 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 17.21
2023-07-10 09:48:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-07-10 09:48:23 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_26_38000.pt
2023-07-10 09:48:25 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_26_38000.pt
2023-07-10 09:48:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 17.21) (writing took 8.985240617999807 seconds)
2023-07-10 09:49:14 | INFO | train_inner | epoch 026:   1267 / 1474 loss=4.636, trans_loss=5.156, nll_loss=2.387, w2v_ctc_loss=1.062, contrastive_loss=0, total=4001.06, n_correct=2381.74, ppl=5.23, accuracy=59.528, wps=10811.8, ups=1.35, wpb=8027.4, bsz=280.6, num_updates=38100, lr=7.24524e-05, gnorm=0.914, clip=0, loss_scale=16, train_wall=41, gb_free=16.1, wall=21783
2023-07-10 09:49:56 | INFO | train_inner | epoch 026:   1367 / 1474 loss=4.611, trans_loss=5.145, nll_loss=2.375, w2v_ctc_loss=1.011, contrastive_loss=0, total=4157.69, n_correct=2487.4, ppl=5.19, accuracy=59.826, wps=19825.5, ups=2.38, wpb=8322.1, bsz=310.5, num_updates=38200, lr=7.23575e-05, gnorm=0.919, clip=0, loss_scale=16, train_wall=42, gb_free=16.6, wall=21825
2023-07-10 09:50:37 | INFO | train_inner | epoch 026:   1467 / 1474 loss=4.613, trans_loss=5.134, nll_loss=2.36, w2v_ctc_loss=1.044, contrastive_loss=0, total=4158.47, n_correct=2502.56, ppl=5.13, accuracy=60.18, wps=20189.7, ups=2.42, wpb=8326.1, bsz=316.5, num_updates=38300, lr=7.22629e-05, gnorm=0.952, clip=0, loss_scale=16, train_wall=41, gb_free=17.6, wall=21866
2023-07-10 09:50:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 09:51:02 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.172 | trans_loss 5.824 | nll_loss 3.158 | w2v_ctc_loss 0.231 | contrastive_loss 0.206 | total 4003.4 | n_correct 2321.9 | ppl 8.92 | accuracy 57.998 | uer 42.492 | wer 44.823 | raw_wer 44.823 | bleu 16.93 | wps 2580.5 | wpb 4003.4 | bsz 141.8 | num_updates 38307 | best_bleu 17.21
2023-07-10 09:51:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38307 updates
2023-07-10 09:51:02 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_16.9307.pt
2023-07-10 09:51:04 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_16.9307.pt
2023-07-10 09:51:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_16.9307.pt (epoch 26 @ 38307 updates, score 16.93) (writing took 5.305204972974025 seconds)
2023-07-10 09:51:08 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-07-10 09:51:08 | INFO | train | epoch 026 | loss 4.613 | trans_loss 5.137 | nll_loss 2.363 | w2v_ctc_loss 1.043 | contrastive_loss 0 | total 4138.58 | n_correct 2483.14 | ppl 5.15 | accuracy 60 | wps 17830.7 | ups 2.15 | wpb 8277.3 | bsz 305.7 | num_updates 38307 | lr 7.22563e-05 | gnorm 0.927 | clip 0 | loss_scale 16 | train_wall 609 | gb_free 16.4 | wall 21896
2023-07-10 09:51:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 09:51:08 | INFO | fairseq.trainer | begin training epoch 27
2023-07-10 09:51:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 09:51:54 | INFO | train_inner | epoch 027:     93 / 1474 loss=4.598, trans_loss=5.118, nll_loss=2.336, w2v_ctc_loss=1.046, contrastive_loss=0, total=4067.62, n_correct=2460.24, ppl=5.05, accuracy=60.484, wps=10537.6, ups=1.3, wpb=8117.2, bsz=284.4, num_updates=38400, lr=7.21688e-05, gnorm=0.945, clip=0, loss_scale=16, train_wall=41, gb_free=15.3, wall=21943
2023-07-10 09:52:36 | INFO | train_inner | epoch 027:    193 / 1474 loss=4.592, trans_loss=5.114, nll_loss=2.334, w2v_ctc_loss=1.034, contrastive_loss=0, total=4185.52, n_correct=2533.08, ppl=5.04, accuracy=60.52, wps=20179.2, ups=2.41, wpb=8373.6, bsz=321.7, num_updates=38500, lr=7.2075e-05, gnorm=0.941, clip=0, loss_scale=16, train_wall=41, gb_free=17.9, wall=21984
2023-07-10 09:53:17 | INFO | train_inner | epoch 027:    293 / 1474 loss=4.595, trans_loss=5.12, nll_loss=2.34, w2v_ctc_loss=1.025, contrastive_loss=0, total=4167.92, n_correct=2515.36, ppl=5.06, accuracy=60.35, wps=20088.1, ups=2.41, wpb=8347.1, bsz=306.8, num_updates=38600, lr=7.19816e-05, gnorm=0.923, clip=0, loss_scale=16, train_wall=41, gb_free=17.2, wall=22026
2023-07-10 09:53:59 | INFO | train_inner | epoch 027:    393 / 1474 loss=4.625, trans_loss=5.136, nll_loss=2.362, w2v_ctc_loss=1.085, contrastive_loss=0, total=4075.21, n_correct=2446.05, ppl=5.14, accuracy=60.023, wps=19463.3, ups=2.39, wpb=8152.7, bsz=296, num_updates=38700, lr=7.18885e-05, gnorm=0.967, clip=0, loss_scale=16, train_wall=41, gb_free=17.9, wall=22068
2023-07-10 09:54:41 | INFO | train_inner | epoch 027:    493 / 1474 loss=4.616, trans_loss=5.127, nll_loss=2.352, w2v_ctc_loss=1.082, contrastive_loss=0, total=4249.35, n_correct=2557.83, ppl=5.1, accuracy=60.193, wps=20290.8, ups=2.39, wpb=8491.6, bsz=331.9, num_updates=38800, lr=7.17958e-05, gnorm=0.924, clip=0, loss_scale=16, train_wall=41, gb_free=12.6, wall=22110
2023-07-10 09:55:23 | INFO | train_inner | epoch 027:    593 / 1474 loss=4.603, trans_loss=5.123, nll_loss=2.346, w2v_ctc_loss=1.042, contrastive_loss=0, total=4133.39, n_correct=2492.18, ppl=5.08, accuracy=60.294, wps=19819, ups=2.4, wpb=8274.2, bsz=312, num_updates=38900, lr=7.17035e-05, gnorm=0.953, clip=0, loss_scale=16, train_wall=41, gb_free=12.7, wall=22151
2023-07-10 09:56:05 | INFO | train_inner | epoch 027:    693 / 1474 loss=4.61, trans_loss=5.132, nll_loss=2.356, w2v_ctc_loss=1.047, contrastive_loss=0, total=4162.71, n_correct=2503.94, ppl=5.12, accuracy=60.152, wps=19829.8, ups=2.38, wpb=8324.9, bsz=305.4, num_updates=39000, lr=7.16115e-05, gnorm=0.91, clip=0, loss_scale=16, train_wall=42, gb_free=16.6, wall=22193
2023-07-10 09:56:46 | INFO | train_inner | epoch 027:    793 / 1474 loss=4.584, trans_loss=5.126, nll_loss=2.348, w2v_ctc_loss=0.978, contrastive_loss=0, total=4103.81, n_correct=2474.01, ppl=5.09, accuracy=60.286, wps=19869.6, ups=2.42, wpb=8202.8, bsz=294.2, num_updates=39100, lr=7.15199e-05, gnorm=0.912, clip=0, loss_scale=16, train_wall=41, gb_free=16.8, wall=22235
2023-07-10 09:57:28 | INFO | train_inner | epoch 027:    893 / 1474 loss=4.585, trans_loss=5.132, nll_loss=2.355, w2v_ctc_loss=0.969, contrastive_loss=0, total=4101.56, n_correct=2468.84, ppl=5.12, accuracy=60.193, wps=19702.8, ups=2.41, wpb=8183.5, bsz=292.1, num_updates=39200, lr=7.14286e-05, gnorm=0.927, clip=0, loss_scale=16, train_wall=41, gb_free=18, wall=22276
2023-07-10 09:58:10 | INFO | train_inner | epoch 027:    993 / 1474 loss=4.595, trans_loss=5.131, nll_loss=2.356, w2v_ctc_loss=0.992, contrastive_loss=0, total=4199.56, n_correct=2527.37, ppl=5.12, accuracy=60.182, wps=19984, ups=2.37, wpb=8418.5, bsz=316.8, num_updates=39300, lr=7.13376e-05, gnorm=0.921, clip=0, loss_scale=16, train_wall=42, gb_free=12.2, wall=22318
2023-07-10 09:58:51 | INFO | train_inner | epoch 027:   1093 / 1474 loss=4.592, trans_loss=5.127, nll_loss=2.351, w2v_ctc_loss=0.993, contrastive_loss=0, total=4150.97, n_correct=2500.47, ppl=5.1, accuracy=60.238, wps=19941.4, ups=2.4, wpb=8314.2, bsz=305, num_updates=39400, lr=7.1247e-05, gnorm=0.943, clip=0, loss_scale=16, train_wall=41, gb_free=12.6, wall=22360
2023-07-10 09:59:33 | INFO | train_inner | epoch 027:   1193 / 1474 loss=4.56, trans_loss=5.135, nll_loss=2.361, w2v_ctc_loss=0.868, contrastive_loss=0, total=4103.06, n_correct=2463.14, ppl=5.14, accuracy=60.032, wps=19610.6, ups=2.39, wpb=8216.4, bsz=297.7, num_updates=39500, lr=7.11568e-05, gnorm=0.9, clip=0, loss_scale=16, train_wall=41, gb_free=16.9, wall=22402
2023-07-10 10:00:15 | INFO | train_inner | epoch 027:   1293 / 1474 loss=4.601, trans_loss=5.142, nll_loss=2.369, w2v_ctc_loss=0.985, contrastive_loss=0, total=4062.52, n_correct=2430.41, ppl=5.17, accuracy=59.825, wps=19509, ups=2.4, wpb=8139.8, bsz=292.2, num_updates=39600, lr=7.10669e-05, gnorm=0.95, clip=0, loss_scale=16, train_wall=41, gb_free=16.9, wall=22444
2023-07-10 10:00:56 | INFO | train_inner | epoch 027:   1393 / 1474 loss=4.573, trans_loss=5.13, nll_loss=2.356, w2v_ctc_loss=0.928, contrastive_loss=0, total=4152, n_correct=2497.6, ppl=5.12, accuracy=60.154, wps=20161.3, ups=2.43, wpb=8291.5, bsz=312.5, num_updates=39700, lr=7.09773e-05, gnorm=0.886, clip=0, loss_scale=16, train_wall=41, gb_free=16.9, wall=22485
2023-07-10 10:01:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 10:01:52 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.149 | trans_loss 5.79 | nll_loss 3.115 | w2v_ctc_loss 0.233 | contrastive_loss 0.206 | total 4003.4 | n_correct 2346.4 | ppl 8.67 | accuracy 58.61 | uer 42.335 | wer 44.696 | raw_wer 44.696 | bleu 17.08 | wps 2482.3 | wpb 4003.4 | bsz 141.8 | num_updates 39781 | best_bleu 17.21
2023-07-10 10:01:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39781 updates
2023-07-10 10:01:52 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.0807.pt
2023-07-10 10:01:54 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.0807.pt
2023-07-10 10:01:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.0807.pt (epoch 27 @ 39781 updates, score 17.08) (writing took 5.26145839196397 seconds)
2023-07-10 10:01:57 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-07-10 10:01:57 | INFO | train | epoch 027 | loss 4.594 | trans_loss 5.128 | nll_loss 2.351 | w2v_ctc_loss 1.002 | contrastive_loss 0 | total 4138.65 | n_correct 2492.3 | ppl 5.1 | accuracy 60.22 | wps 18776.2 | ups 2.27 | wpb 8277.3 | bsz 305.7 | num_updates 39781 | lr 7.0905e-05 | gnorm 0.926 | clip 0 | loss_scale 32 | train_wall 608 | gb_free 18.1 | wall 22546
2023-07-10 10:01:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 10:01:58 | INFO | fairseq.trainer | begin training epoch 28
2023-07-10 10:01:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 10:02:13 | INFO | train_inner | epoch 028:     19 / 1474 loss=4.567, trans_loss=5.124, nll_loss=2.348, w2v_ctc_loss=0.927, contrastive_loss=0, total=4108.43, n_correct=2480.68, ppl=5.09, accuracy=60.38, wps=10613.3, ups=1.29, wpb=8198, bsz=305.1, num_updates=39800, lr=7.08881e-05, gnorm=0.891, clip=0, loss_scale=32, train_wall=41, gb_free=16.7, wall=22562
2023-07-10 10:02:55 | INFO | train_inner | epoch 028:    119 / 1474 loss=4.577, trans_loss=5.107, nll_loss=2.323, w2v_ctc_loss=1.009, contrastive_loss=0, total=4113.41, n_correct=2492.06, ppl=5, accuracy=60.584, wps=19952.7, ups=2.43, wpb=8209.1, bsz=293.9, num_updates=39900, lr=7.07992e-05, gnorm=0.927, clip=0, loss_scale=32, train_wall=41, gb_free=17.3, wall=22603
2023-07-10 10:03:36 | INFO | train_inner | epoch 028:    219 / 1474 loss=4.567, trans_loss=5.103, nll_loss=2.319, w2v_ctc_loss=0.979, contrastive_loss=0, total=4191.56, n_correct=2546.47, ppl=4.99, accuracy=60.752, wps=20116.4, ups=2.4, wpb=8380.1, bsz=315.2, num_updates=40000, lr=7.07107e-05, gnorm=0.899, clip=0, loss_scale=32, train_wall=41, gb_free=15.5, wall=22645
2023-07-10 10:03:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 10:03:58 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.157 | trans_loss 5.795 | nll_loss 3.117 | w2v_ctc_loss 0.246 | contrastive_loss 0.206 | total 4003.4 | n_correct 2346.8 | ppl 8.68 | accuracy 58.62 | uer 41.855 | wer 44.085 | raw_wer 44.085 | bleu 17 | wps 2457.2 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 17.21
2023-07-10 10:03:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-07-10 10:03:58 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_28_40000.pt
2023-07-10 10:04:01 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_28_40000.pt
2023-07-10 10:04:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 17.0) (writing took 6.422645507962443 seconds)
1.0
tensor(0.0271, device='cuda:0')
2023-07-10 10:04:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-10 10:04:48 | INFO | train_inner | epoch 028:    320 / 1474 loss=4.597, trans_loss=5.119, nll_loss=2.34, w2v_ctc_loss=1.052, contrastive_loss=0, total=4138.95, n_correct=2493.64, ppl=5.06, accuracy=60.248, wps=11546, ups=1.4, wpb=8242.7, bsz=314.2, num_updates=40100, lr=7.06225e-05, gnorm=0.913, clip=0, loss_scale=16, train_wall=42, gb_free=13.8, wall=22716
2023-07-10 10:05:29 | INFO | train_inner | epoch 028:    420 / 1474 loss=4.581, trans_loss=5.121, nll_loss=2.342, w2v_ctc_loss=0.971, contrastive_loss=0, total=4089.84, n_correct=2469.02, ppl=5.07, accuracy=60.37, wps=19771.1, ups=2.41, wpb=8189.7, bsz=295.7, num_updates=40200, lr=7.05346e-05, gnorm=0.916, clip=0, loss_scale=16, train_wall=41, gb_free=17.1, wall=22758
2023-07-10 10:06:11 | INFO | train_inner | epoch 028:    520 / 1474 loss=4.568, trans_loss=5.115, nll_loss=2.334, w2v_ctc_loss=0.95, contrastive_loss=0, total=4098.92, n_correct=2483.33, ppl=5.04, accuracy=60.585, wps=19741.4, ups=2.41, wpb=8199.3, bsz=295.7, num_updates=40300, lr=7.0447e-05, gnorm=0.919, clip=0, loss_scale=16, train_wall=41, gb_free=17.3, wall=22799
2023-07-10 10:06:52 | INFO | train_inner | epoch 028:    620 / 1474 loss=4.599, trans_loss=5.12, nll_loss=2.341, w2v_ctc_loss=1.038, contrastive_loss=0, total=4180.1, n_correct=2525.68, ppl=5.07, accuracy=60.422, wps=20037, ups=2.4, wpb=8360.1, bsz=305.3, num_updates=40400, lr=7.03598e-05, gnorm=0.893, clip=0, loss_scale=16, train_wall=41, gb_free=16.9, wall=22841
2023-07-10 10:07:34 | INFO | train_inner | epoch 028:    720 / 1474 loss=4.599, trans_loss=5.116, nll_loss=2.338, w2v_ctc_loss=1.054, contrastive_loss=0, total=4191.62, n_correct=2533.1, ppl=5.06, accuracy=60.432, wps=20108.9, ups=2.4, wpb=8372, bsz=329.2, num_updates=40500, lr=7.02728e-05, gnorm=0.931, clip=0, loss_scale=16, train_wall=41, gb_free=17.4, wall=22883
2023-07-10 10:08:15 | INFO | train_inner | epoch 028:    820 / 1474 loss=4.589, trans_loss=5.117, nll_loss=2.339, w2v_ctc_loss=1.013, contrastive_loss=0, total=4088.91, n_correct=2476.14, ppl=5.06, accuracy=60.557, wps=19752.7, ups=2.42, wpb=8171, bsz=304.3, num_updates=40600, lr=7.01862e-05, gnorm=0.908, clip=0, loss_scale=16, train_wall=41, gb_free=17.3, wall=22924
2023-07-10 10:08:58 | INFO | train_inner | epoch 028:    920 / 1474 loss=4.596, trans_loss=5.126, nll_loss=2.349, w2v_ctc_loss=1.009, contrastive_loss=0, total=4117.01, n_correct=2481.17, ppl=5.09, accuracy=60.266, wps=19543.5, ups=2.37, wpb=8260.3, bsz=299.7, num_updates=40700, lr=7.01e-05, gnorm=0.932, clip=0, loss_scale=16, train_wall=42, gb_free=15.7, wall=22966
2023-07-10 10:10:03 | INFO | train_inner | epoch 028:   1020 / 1474 loss=4.618, trans_loss=5.121, nll_loss=2.343, w2v_ctc_loss=1.1, contrastive_loss=0, total=4182.85, n_correct=2521.65, ppl=5.07, accuracy=60.285, wps=12818.8, ups=1.53, wpb=8373.6, bsz=312, num_updates=40800, lr=7.0014e-05, gnorm=0.931, clip=0, loss_scale=16, train_wall=41, gb_free=16.8, wall=23031
2023-07-10 10:10:44 | INFO | train_inner | epoch 028:   1120 / 1474 loss=4.586, trans_loss=5.118, nll_loss=2.34, w2v_ctc_loss=0.997, contrastive_loss=0, total=4220.16, n_correct=2554.07, ppl=5.06, accuracy=60.521, wps=20314.9, ups=2.41, wpb=8439.4, bsz=321, num_updates=40900, lr=6.99284e-05, gnorm=0.905, clip=0, loss_scale=16, train_wall=41, gb_free=16.6, wall=23073
2023-07-10 10:11:50 | INFO | train_inner | epoch 028:   1220 / 1474 loss=4.595, trans_loss=5.122, nll_loss=2.344, w2v_ctc_loss=1.013, contrastive_loss=0, total=4092.46, n_correct=2471.72, ppl=5.08, accuracy=60.397, wps=12568.5, ups=1.53, wpb=8198.5, bsz=303.1, num_updates=41000, lr=6.9843e-05, gnorm=0.941, clip=0, loss_scale=16, train_wall=41, gb_free=17.9, wall=23138
2023-07-10 10:12:31 | INFO | train_inner | epoch 028:   1320 / 1474 loss=4.617, trans_loss=5.133, nll_loss=2.357, w2v_ctc_loss=1.059, contrastive_loss=0, total=4084.55, n_correct=2458.09, ppl=5.12, accuracy=60.18, wps=19614.2, ups=2.4, wpb=8182.2, bsz=285.1, num_updates=41100, lr=6.9758e-05, gnorm=0.933, clip=0, loss_scale=16, train_wall=41, gb_free=16.1, wall=23180
2023-07-10 10:13:13 | INFO | train_inner | epoch 028:   1420 / 1474 loss=4.595, trans_loss=5.14, nll_loss=2.367, w2v_ctc_loss=0.967, contrastive_loss=0, total=4154.09, n_correct=2497.06, ppl=5.16, accuracy=60.111, wps=19874.8, ups=2.39, wpb=8315.9, bsz=299.3, num_updates=41200, lr=6.96733e-05, gnorm=0.898, clip=0, loss_scale=16, train_wall=41, gb_free=16.4, wall=23222
2023-07-10 10:13:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
1.0
tensor(0.0271, device='cuda:3')
1.0
tensor(0.0271, device='cuda:7')
1.0
tensor(0.0271, device='cuda:6')
1.0
tensor(0.0271, device='cuda:5')
1.0
tensor(0.0271, device='cuda:4')
1.0
tensor(0.0271, device='cuda:1')
1.0
tensor(0.0271, device='cuda:2')
2023-07-10 10:13:57 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.155 | trans_loss 5.796 | nll_loss 3.118 | w2v_ctc_loss 0.24 | contrastive_loss 0.208 | total 4003.4 | n_correct 2347.3 | ppl 8.68 | accuracy 58.633 | uer 41.725 | wer 44.197 | raw_wer 44.197 | bleu 16.83 | wps 2645.9 | wpb 4003.4 | bsz 141.8 | num_updates 41254 | best_bleu 17.21
2023-07-10 10:13:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41254 updates
2023-07-10 10:13:57 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_16.8305.pt
2023-07-10 10:14:00 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_16.8305.pt
2023-07-10 10:14:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_16.8305.pt (epoch 28 @ 41254 updates, score 16.83) (writing took 5.284412790962961 seconds)
2023-07-10 10:14:03 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-07-10 10:14:03 | INFO | train | epoch 028 | loss 4.59 | trans_loss 5.119 | nll_loss 2.341 | w2v_ctc_loss 1.012 | contrastive_loss 0 | total 4138.36 | n_correct 2500.36 | ppl 5.07 | accuracy 60.419 | wps 16804 | ups 2.03 | wpb 8276.7 | bsz 305.5 | num_updates 41254 | lr 6.96277e-05 | gnorm 0.917 | clip 0 | loss_scale 16 | train_wall 607 | gb_free 16.9 | wall 23272
2023-07-10 10:14:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 10:14:03 | INFO | fairseq.trainer | begin training epoch 29
2023-07-10 10:14:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 10:14:30 | INFO | train_inner | epoch 029:     46 / 1474 loss=4.565, trans_loss=5.1, nll_loss=2.316, w2v_ctc_loss=0.98, contrastive_loss=0, total=4169.12, n_correct=2536.23, ppl=4.98, accuracy=60.834, wps=10833.9, ups=1.3, wpb=8337, bsz=316.4, num_updates=41300, lr=6.95889e-05, gnorm=0.941, clip=0, loss_scale=16, train_wall=41, gb_free=16.7, wall=23299
2023-07-10 10:15:12 | INFO | train_inner | epoch 029:    146 / 1474 loss=4.565, trans_loss=5.103, nll_loss=2.319, w2v_ctc_loss=0.978, contrastive_loss=0, total=4105.72, n_correct=2489.25, ppl=4.99, accuracy=60.629, wps=19579.7, ups=2.39, wpb=8206.9, bsz=304.1, num_updates=41400, lr=6.95048e-05, gnorm=0.914, clip=0, loss_scale=16, train_wall=42, gb_free=16.4, wall=23341
2023-07-10 10:15:55 | INFO | train_inner | epoch 029:    246 / 1474 loss=4.588, trans_loss=5.093, nll_loss=2.308, w2v_ctc_loss=1.074, contrastive_loss=0, total=4199.67, n_correct=2559.17, ppl=4.95, accuracy=60.937, wps=19744.6, ups=2.35, wpb=8398.8, bsz=330.5, num_updates=41500, lr=6.9421e-05, gnorm=0.923, clip=0, loss_scale=16, train_wall=42, gb_free=16, wall=23383
2023-07-10 10:16:36 | INFO | train_inner | epoch 029:    346 / 1474 loss=4.588, trans_loss=5.113, nll_loss=2.332, w2v_ctc_loss=1.021, contrastive_loss=0, total=4095.17, n_correct=2477.59, ppl=5.03, accuracy=60.5, wps=19586.7, ups=2.39, wpb=8201.6, bsz=291.2, num_updates=41600, lr=6.93375e-05, gnorm=0.949, clip=0, loss_scale=16, train_wall=41, gb_free=17, wall=23425
2023-07-10 10:17:18 | INFO | train_inner | epoch 029:    446 / 1474 loss=4.548, trans_loss=5.097, nll_loss=2.311, w2v_ctc_loss=0.932, contrastive_loss=0, total=4157.44, n_correct=2534.92, ppl=4.96, accuracy=60.973, wps=19896.3, ups=2.39, wpb=8310.1, bsz=307.7, num_updates=41700, lr=6.92543e-05, gnorm=0.915, clip=0, loss_scale=16, train_wall=41, gb_free=16.9, wall=23467
2023-07-10 10:18:00 | INFO | train_inner | epoch 029:    546 / 1474 loss=4.567, trans_loss=5.128, nll_loss=2.352, w2v_ctc_loss=0.919, contrastive_loss=0, total=4150.87, n_correct=2496.95, ppl=5.1, accuracy=60.155, wps=19794, ups=2.39, wpb=8280.5, bsz=294.9, num_updates=41800, lr=6.91714e-05, gnorm=0.884, clip=0, loss_scale=16, train_wall=41, gb_free=16.1, wall=23509
2023-07-10 10:18:42 | INFO | train_inner | epoch 029:    646 / 1474 loss=4.562, trans_loss=5.104, nll_loss=2.323, w2v_ctc_loss=0.958, contrastive_loss=0, total=4143.02, n_correct=2513.44, ppl=5, accuracy=60.667, wps=19877, ups=2.4, wpb=8290.3, bsz=318.6, num_updates=41900, lr=6.90889e-05, gnorm=0.892, clip=0, loss_scale=16, train_wall=41, gb_free=17.3, wall=23550
2023-07-10 10:19:24 | INFO | train_inner | epoch 029:    746 / 1474 loss=4.583, trans_loss=5.105, nll_loss=2.323, w2v_ctc_loss=1.024, contrastive_loss=0, total=4249.79, n_correct=2581.03, ppl=5, accuracy=60.733, wps=20218.8, ups=2.38, wpb=8508.7, bsz=330, num_updates=42000, lr=6.90066e-05, gnorm=0.904, clip=0, loss_scale=16, train_wall=42, gb_free=17, wall=23593
2023-07-10 10:19:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 10:19:46 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.146 | trans_loss 5.794 | nll_loss 3.115 | w2v_ctc_loss 0.21 | contrastive_loss 0.215 | total 4003.4 | n_correct 2345.5 | ppl 8.66 | accuracy 58.588 | uer 42.165 | wer 44.741 | raw_wer 44.741 | bleu 17.09 | wps 2533.7 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 17.21
2023-07-10 10:19:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-07-10 10:19:46 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_29_42000.pt
2023-07-10 10:19:48 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_29_42000.pt
2023-07-10 10:19:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 17.09) (writing took 6.359086078999098 seconds)
2023-07-10 10:20:58 | INFO | train_inner | epoch 029:    846 / 1474 loss=4.581, trans_loss=5.127, nll_loss=2.349, w2v_ctc_loss=0.959, contrastive_loss=0, total=4027.19, n_correct=2422.33, ppl=5.09, accuracy=60.149, wps=8535.5, ups=1.06, wpb=8060.5, bsz=280.6, num_updates=42100, lr=6.89246e-05, gnorm=0.923, clip=0, loss_scale=16, train_wall=65, gb_free=17.5, wall=23687
2023-07-10 10:21:40 | INFO | train_inner | epoch 029:    946 / 1474 loss=4.58, trans_loss=5.119, nll_loss=2.34, w2v_ctc_loss=0.973, contrastive_loss=0, total=4082.14, n_correct=2473.12, ppl=5.06, accuracy=60.584, wps=19744.9, ups=2.41, wpb=8177.2, bsz=296.3, num_updates=42200, lr=6.88428e-05, gnorm=0.906, clip=0, loss_scale=32, train_wall=41, gb_free=15.7, wall=23728
2023-07-10 10:22:21 | INFO | train_inner | epoch 029:   1046 / 1474 loss=4.597, trans_loss=5.111, nll_loss=2.33, w2v_ctc_loss=1.053, contrastive_loss=0, total=4148.18, n_correct=2514.65, ppl=5.03, accuracy=60.621, wps=20003.7, ups=2.41, wpb=8303.3, bsz=308.2, num_updates=42300, lr=6.87614e-05, gnorm=0.941, clip=0, loss_scale=32, train_wall=41, gb_free=16.3, wall=23770
2023-07-10 10:23:03 | INFO | train_inner | epoch 029:   1146 / 1474 loss=4.594, trans_loss=5.118, nll_loss=2.338, w2v_ctc_loss=1.024, contrastive_loss=0, total=4063.95, n_correct=2455.25, ppl=5.05, accuracy=60.415, wps=19735.6, ups=2.42, wpb=8138.5, bsz=283, num_updates=42400, lr=6.86803e-05, gnorm=1.005, clip=0, loss_scale=32, train_wall=41, gb_free=13.8, wall=23811
2023-07-10 10:23:44 | INFO | train_inner | epoch 029:   1246 / 1474 loss=4.595, trans_loss=5.124, nll_loss=2.347, w2v_ctc_loss=1.016, contrastive_loss=0, total=4158.81, n_correct=2512.5, ppl=5.09, accuracy=60.414, wps=19875.3, ups=2.39, wpb=8313.9, bsz=301.2, num_updates=42500, lr=6.85994e-05, gnorm=0.942, clip=0, loss_scale=32, train_wall=41, gb_free=16.1, wall=23853
2023-07-10 10:24:26 | INFO | train_inner | epoch 029:   1346 / 1474 loss=4.577, trans_loss=5.111, nll_loss=2.331, w2v_ctc_loss=0.994, contrastive_loss=0, total=4166.34, n_correct=2531.45, ppl=5.03, accuracy=60.76, wps=19879.5, ups=2.39, wpb=8312.8, bsz=310.7, num_updates=42600, lr=6.85189e-05, gnorm=0.915, clip=0, loss_scale=32, train_wall=41, gb_free=18.1, wall=23895
2023-07-10 10:25:07 | INFO | train_inner | epoch 029:   1446 / 1474 loss=4.58, trans_loss=5.116, nll_loss=2.337, w2v_ctc_loss=0.989, contrastive_loss=0, total=4162.2, n_correct=2521.61, ppl=5.05, accuracy=60.584, wps=20148.7, ups=2.42, wpb=8310.9, bsz=311.5, num_updates=42700, lr=6.84386e-05, gnorm=0.896, clip=0, loss_scale=32, train_wall=41, gb_free=17.6, wall=23936
2023-07-10 10:25:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 10:25:42 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.158 | trans_loss 5.805 | nll_loss 3.131 | w2v_ctc_loss 0.23 | contrastive_loss 0.208 | total 4003.4 | n_correct 2340.3 | ppl 8.76 | accuracy 58.458 | uer 42.096 | wer 44.816 | raw_wer 44.816 | bleu 17.08 | wps 2416.9 | wpb 4003.4 | bsz 141.8 | num_updates 42728 | best_bleu 17.21
2023-07-10 10:25:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42728 updates
2023-07-10 10:25:42 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.0804.pt
2023-07-10 10:25:44 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.0804.pt
2023-07-10 10:25:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.0804.pt (epoch 29 @ 42728 updates, score 17.08) (writing took 5.21481054200558 seconds)
2023-07-10 10:25:48 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-07-10 10:25:48 | INFO | train | epoch 029 | loss 4.577 | trans_loss 5.111 | nll_loss 2.33 | w2v_ctc_loss 0.991 | contrastive_loss 0 | total 4138.65 | n_correct 2508.11 | ppl 5.03 | accuracy 60.602 | wps 17316.7 | ups 2.09 | wpb 8277.3 | bsz 305.7 | num_updates 42728 | lr 6.84162e-05 | gnorm 0.922 | clip 0 | loss_scale 32 | train_wall 633 | gb_free 16.6 | wall 23976
2023-07-10 10:25:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 10:25:48 | INFO | fairseq.trainer | begin training epoch 30
2023-07-10 10:25:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 10:26:26 | INFO | train_inner | epoch 030:     72 / 1474 loss=4.542, trans_loss=5.096, nll_loss=2.31, w2v_ctc_loss=0.918, contrastive_loss=0, total=4182.65, n_correct=2552.41, ppl=4.96, accuracy=61.024, wps=10593.6, ups=1.27, wpb=8352.5, bsz=320.5, num_updates=42800, lr=6.83586e-05, gnorm=0.884, clip=0, loss_scale=32, train_wall=42, gb_free=14, wall=24015
2023-07-10 10:27:08 | INFO | train_inner | epoch 030:    172 / 1474 loss=4.551, trans_loss=5.086, nll_loss=2.298, w2v_ctc_loss=0.971, contrastive_loss=0, total=4203.05, n_correct=2570.53, ppl=4.92, accuracy=61.159, wps=20257.5, ups=2.41, wpb=8404.3, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.939, clip=0, loss_scale=32, train_wall=41, gb_free=17.7, wall=24056
2023-07-10 10:27:49 | INFO | train_inner | epoch 030:    272 / 1474 loss=4.563, trans_loss=5.096, nll_loss=2.31, w2v_ctc_loss=0.985, contrastive_loss=0, total=4116.93, n_correct=2507.1, ppl=4.96, accuracy=60.897, wps=19725.7, ups=2.4, wpb=8232.2, bsz=295.1, num_updates=43000, lr=6.81994e-05, gnorm=0.901, clip=0, loss_scale=32, train_wall=41, gb_free=17.3, wall=24098
2023-07-10 10:28:32 | INFO | train_inner | epoch 030:    372 / 1474 loss=4.542, trans_loss=5.098, nll_loss=2.313, w2v_ctc_loss=0.908, contrastive_loss=0, total=4173.13, n_correct=2546.34, ppl=4.97, accuracy=61.018, wps=19722.8, ups=2.37, wpb=8337.6, bsz=305.6, num_updates=43100, lr=6.81203e-05, gnorm=0.904, clip=0, loss_scale=32, train_wall=42, gb_free=12.4, wall=24140
2023-07-10 10:29:13 | INFO | train_inner | epoch 030:    472 / 1474 loss=4.554, trans_loss=5.097, nll_loss=2.311, w2v_ctc_loss=0.948, contrastive_loss=0, total=4135.2, n_correct=2516.63, ppl=4.96, accuracy=60.859, wps=19869.5, ups=2.4, wpb=8277.4, bsz=314.8, num_updates=43200, lr=6.80414e-05, gnorm=0.934, clip=0, loss_scale=32, train_wall=41, gb_free=17.2, wall=24182
2023-07-10 10:29:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-10 10:29:56 | INFO | train_inner | epoch 030:    573 / 1474 loss=4.573, trans_loss=5.102, nll_loss=2.319, w2v_ctc_loss=0.995, contrastive_loss=0, total=4162.42, n_correct=2532.26, ppl=4.99, accuracy=60.836, wps=19795.2, ups=2.37, wpb=8335.9, bsz=311, num_updates=43300, lr=6.79628e-05, gnorm=0.917, clip=0, loss_scale=16, train_wall=42, gb_free=17.5, wall=24224
2023-07-10 10:30:37 | INFO | train_inner | epoch 030:    673 / 1474 loss=4.561, trans_loss=5.102, nll_loss=2.318, w2v_ctc_loss=0.962, contrastive_loss=0, total=4187.95, n_correct=2543.02, ppl=4.99, accuracy=60.722, wps=20007, ups=2.39, wpb=8377.6, bsz=315, num_updates=43400, lr=6.78844e-05, gnorm=0.916, clip=0, loss_scale=16, train_wall=41, gb_free=16.2, wall=24266
2023-07-10 10:31:20 | INFO | train_inner | epoch 030:    773 / 1474 loss=4.613, trans_loss=5.115, nll_loss=2.336, w2v_ctc_loss=1.102, contrastive_loss=0, total=4105.32, n_correct=2484.21, ppl=5.05, accuracy=60.512, wps=19451.6, ups=2.37, wpb=8197.5, bsz=302.6, num_updates=43500, lr=6.78064e-05, gnorm=0.985, clip=0, loss_scale=16, train_wall=42, gb_free=13.5, wall=24308
2023-07-10 10:32:01 | INFO | train_inner | epoch 030:    873 / 1474 loss=4.575, trans_loss=5.106, nll_loss=2.323, w2v_ctc_loss=0.995, contrastive_loss=0, total=4102.11, n_correct=2491.56, ppl=5.01, accuracy=60.738, wps=19683.2, ups=2.4, wpb=8208.4, bsz=295.6, num_updates=43600, lr=6.77285e-05, gnorm=0.914, clip=0, loss_scale=16, train_wall=41, gb_free=17.7, wall=24350
2023-07-10 10:32:43 | INFO | train_inner | epoch 030:    973 / 1474 loss=4.575, trans_loss=5.112, nll_loss=2.332, w2v_ctc_loss=0.981, contrastive_loss=0, total=4129.98, n_correct=2502.9, ppl=5.03, accuracy=60.603, wps=19800.8, ups=2.4, wpb=8257, bsz=300.4, num_updates=43700, lr=6.7651e-05, gnorm=0.946, clip=0, loss_scale=16, train_wall=41, gb_free=16.9, wall=24392
2023-07-10 10:33:25 | INFO | train_inner | epoch 030:   1073 / 1474 loss=4.566, trans_loss=5.123, nll_loss=2.344, w2v_ctc_loss=0.926, contrastive_loss=0, total=4101.17, n_correct=2472.4, ppl=5.08, accuracy=60.285, wps=19366.2, ups=2.37, wpb=8187.5, bsz=282.3, num_updates=43800, lr=6.75737e-05, gnorm=0.939, clip=0, loss_scale=16, train_wall=42, gb_free=16.1, wall=24434
2023-07-10 10:34:07 | INFO | train_inner | epoch 030:   1173 / 1474 loss=4.598, trans_loss=5.108, nll_loss=2.327, w2v_ctc_loss=1.059, contrastive_loss=0, total=4168.36, n_correct=2534.75, ppl=5.02, accuracy=60.809, wps=19831.4, ups=2.38, wpb=8348.4, bsz=314, num_updates=43900, lr=6.74967e-05, gnorm=0.928, clip=0, loss_scale=16, train_wall=42, gb_free=16.3, wall=24476
2023-07-10 10:34:50 | INFO | train_inner | epoch 030:   1273 / 1474 loss=4.582, trans_loss=5.122, nll_loss=2.343, w2v_ctc_loss=0.969, contrastive_loss=0, total=4036.17, n_correct=2437.76, ppl=5.07, accuracy=60.398, wps=19085.3, ups=2.36, wpb=8099.1, bsz=284.3, num_updates=44000, lr=6.742e-05, gnorm=0.936, clip=0, loss_scale=16, train_wall=42, gb_free=16.1, wall=24518
2023-07-10 10:34:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 10:35:13 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.157 | trans_loss 5.789 | nll_loss 3.108 | w2v_ctc_loss 0.26 | contrastive_loss 0.208 | total 4003.4 | n_correct 2348.4 | ppl 8.62 | accuracy 58.66 | uer 41.595 | wer 44.092 | raw_wer 44.092 | bleu 17.54 | wps 2390.3 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 17.54
2023-07-10 10:35:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-07-10 10:35:13 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_30_44000.pt
2023-07-10 10:35:15 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_30_44000.pt
2023-07-10 10:35:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 17.54) (writing took 9.693606692948379 seconds)
2023-07-10 10:36:05 | INFO | train_inner | epoch 030:   1373 / 1474 loss=4.562, trans_loss=5.096, nll_loss=2.312, w2v_ctc_loss=0.971, contrastive_loss=0, total=4165.07, n_correct=2540.25, ppl=4.97, accuracy=60.989, wps=11139.5, ups=1.33, wpb=8348.6, bsz=321.6, num_updates=44100, lr=6.73435e-05, gnorm=0.939, clip=0, loss_scale=16, train_wall=41, gb_free=17.1, wall=24593
2023-07-10 10:36:46 | INFO | train_inner | epoch 030:   1473 / 1474 loss=4.566, trans_loss=5.098, nll_loss=2.315, w2v_ctc_loss=0.995, contrastive_loss=0, total=4141.76, n_correct=2523.81, ppl=4.97, accuracy=60.936, wps=19861.6, ups=2.4, wpb=8264.5, bsz=314.3, num_updates=44200, lr=6.72673e-05, gnorm=0.91, clip=0, loss_scale=16, train_wall=41, gb_free=16.7, wall=24635
2023-07-10 10:36:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 10:37:09 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.146 | trans_loss 5.795 | nll_loss 3.119 | w2v_ctc_loss 0.212 | contrastive_loss 0.206 | total 4003.4 | n_correct 2347.6 | ppl 8.69 | accuracy 58.64 | uer 42.229 | wer 44.868 | raw_wer 44.868 | bleu 16.87 | wps 2632.7 | wpb 4003.4 | bsz 141.8 | num_updates 44201 | best_bleu 17.54
2023-07-10 10:37:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44201 updates
2023-07-10 10:37:09 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_16.8709.pt
2023-07-10 10:37:11 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_16.8709.pt
2023-07-10 10:37:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_16.8709.pt (epoch 30 @ 44201 updates, score 16.87) (writing took 5.160980980959721 seconds)
2023-07-10 10:37:14 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-07-10 10:37:14 | INFO | train | epoch 030 | loss 4.569 | trans_loss 5.104 | nll_loss 2.32 | w2v_ctc_loss 0.981 | contrastive_loss 0 | total 4138.55 | n_correct 2515.6 | ppl 4.99 | accuracy 60.785 | wps 17758.8 | ups 2.15 | wpb 8277.1 | bsz 305.6 | num_updates 44201 | lr 6.72665e-05 | gnorm 0.928 | clip 0 | loss_scale 16 | train_wall 612 | gb_free 17.4 | wall 24663
2023-07-10 10:37:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 10:37:14 | INFO | fairseq.trainer | begin training epoch 31
2023-07-10 10:37:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 10:38:04 | INFO | train_inner | epoch 031:     99 / 1474 loss=4.561, trans_loss=5.092, nll_loss=2.304, w2v_ctc_loss=0.984, contrastive_loss=0, total=4054.44, n_correct=2467.85, ppl=4.94, accuracy=60.868, wps=10458.7, ups=1.29, wpb=8126.4, bsz=288.2, num_updates=44300, lr=6.71913e-05, gnorm=0.936, clip=0, loss_scale=16, train_wall=42, gb_free=16.8, wall=24713
2023-07-10 10:38:46 | INFO | train_inner | epoch 031:    199 / 1474 loss=4.572, trans_loss=5.095, nll_loss=2.308, w2v_ctc_loss=1.017, contrastive_loss=0, total=4147.4, n_correct=2526.48, ppl=4.95, accuracy=60.917, wps=19752.9, ups=2.38, wpb=8295.3, bsz=302.2, num_updates=44400, lr=6.71156e-05, gnorm=0.939, clip=0, loss_scale=16, train_wall=42, gb_free=17.1, wall=24755
2023-07-10 10:39:28 | INFO | train_inner | epoch 031:    299 / 1474 loss=4.568, trans_loss=5.093, nll_loss=2.305, w2v_ctc_loss=1.012, contrastive_loss=0, total=4149.21, n_correct=2527.18, ppl=4.94, accuracy=60.907, wps=19687.5, ups=2.37, wpb=8293.1, bsz=301.6, num_updates=44500, lr=6.70402e-05, gnorm=0.896, clip=0, loss_scale=16, train_wall=42, gb_free=16.5, wall=24797
2023-07-10 10:40:10 | INFO | train_inner | epoch 031:    399 / 1474 loss=4.568, trans_loss=5.1, nll_loss=2.315, w2v_ctc_loss=0.992, contrastive_loss=0, total=4092.62, n_correct=2485.74, ppl=4.97, accuracy=60.737, wps=19335.5, ups=2.37, wpb=8170.5, bsz=285.6, num_updates=44600, lr=6.6965e-05, gnorm=0.946, clip=0, loss_scale=16, train_wall=42, gb_free=17.4, wall=24839
2023-07-10 10:40:53 | INFO | train_inner | epoch 031:    499 / 1474 loss=4.562, trans_loss=5.092, nll_loss=2.304, w2v_ctc_loss=0.989, contrastive_loss=0, total=4111.85, n_correct=2508.3, ppl=4.94, accuracy=61.002, wps=19509.5, ups=2.37, wpb=8227.7, bsz=300.3, num_updates=44700, lr=6.689e-05, gnorm=0.94, clip=0, loss_scale=16, train_wall=42, gb_free=11.7, wall=24881
2023-07-10 10:41:35 | INFO | train_inner | epoch 031:    599 / 1474 loss=4.575, trans_loss=5.1, nll_loss=2.315, w2v_ctc_loss=1.013, contrastive_loss=0, total=4083.44, n_correct=2483.08, ppl=4.98, accuracy=60.809, wps=19409.9, ups=2.38, wpb=8161.2, bsz=294.5, num_updates=44800, lr=6.68153e-05, gnorm=0.965, clip=0, loss_scale=16, train_wall=42, gb_free=17.1, wall=24923
2023-07-10 10:42:16 | INFO | train_inner | epoch 031:    699 / 1474 loss=4.573, trans_loss=5.085, nll_loss=2.297, w2v_ctc_loss=1.042, contrastive_loss=0, total=4213.98, n_correct=2580.5, ppl=4.91, accuracy=61.237, wps=20324.9, ups=2.41, wpb=8435.3, bsz=315.7, num_updates=44900, lr=6.67409e-05, gnorm=0.953, clip=0, loss_scale=16, train_wall=41, gb_free=16.7, wall=24965
2023-07-10 10:42:58 | INFO | train_inner | epoch 031:    799 / 1474 loss=4.593, trans_loss=5.097, nll_loss=2.311, w2v_ctc_loss=1.069, contrastive_loss=0, total=4097.37, n_correct=2490.6, ppl=4.96, accuracy=60.785, wps=19544, ups=2.37, wpb=8230.1, bsz=295.8, num_updates=45000, lr=6.66667e-05, gnorm=0.961, clip=0, loss_scale=16, train_wall=42, gb_free=13.5, wall=25007
1.0
tensor(0.0271, device='cuda:0')
2023-07-10 10:43:40 | INFO | train_inner | epoch 031:    899 / 1474 loss=4.578, trans_loss=5.098, nll_loss=2.313, w2v_ctc_loss=1.024, contrastive_loss=0, total=4096.72, n_correct=2497.77, ppl=4.97, accuracy=60.97, wps=19767.2, ups=2.41, wpb=8194, bsz=296.1, num_updates=45100, lr=6.65927e-05, gnorm=0.914, clip=0, loss_scale=16, train_wall=41, gb_free=17.5, wall=25048
2023-07-10 10:44:22 | INFO | train_inner | epoch 031:    999 / 1474 loss=4.576, trans_loss=5.101, nll_loss=2.318, w2v_ctc_loss=1.02, contrastive_loss=0, total=4187.84, n_correct=2553.38, ppl=4.99, accuracy=60.971, wps=19767.6, ups=2.37, wpb=8346.1, bsz=319.5, num_updates=45200, lr=6.6519e-05, gnorm=0.928, clip=0, loss_scale=16, train_wall=42, gb_free=17.5, wall=25091
2023-07-10 10:45:04 | INFO | train_inner | epoch 031:   1099 / 1474 loss=4.56, trans_loss=5.097, nll_loss=2.313, w2v_ctc_loss=0.965, contrastive_loss=0, total=4149.44, n_correct=2524.94, ppl=4.97, accuracy=60.85, wps=19751.9, ups=2.38, wpb=8309.1, bsz=315, num_updates=45300, lr=6.64455e-05, gnorm=0.913, clip=0, loss_scale=16, train_wall=42, gb_free=17.8, wall=25133
2023-07-10 10:45:45 | INFO | train_inner | epoch 031:   1199 / 1474 loss=4.581, trans_loss=5.093, nll_loss=2.308, w2v_ctc_loss=1.056, contrastive_loss=0, total=4189.76, n_correct=2557.78, ppl=4.95, accuracy=61.048, wps=20193.6, ups=2.42, wpb=8360.8, bsz=321.3, num_updates=45400, lr=6.63723e-05, gnorm=0.926, clip=0, loss_scale=32, train_wall=41, gb_free=13.7, wall=25174
2023-07-10 10:46:27 | INFO | train_inner | epoch 031:   1299 / 1474 loss=4.556, trans_loss=5.097, nll_loss=2.314, w2v_ctc_loss=0.956, contrastive_loss=0, total=4227.44, n_correct=2581.53, ppl=4.97, accuracy=61.066, wps=20175, ups=2.39, wpb=8445.9, bsz=326.3, num_updates=45500, lr=6.62994e-05, gnorm=0.911, clip=0, loss_scale=32, train_wall=41, gb_free=16.8, wall=25216
2023-07-10 10:47:09 | INFO | train_inner | epoch 031:   1399 / 1474 loss=4.566, trans_loss=5.099, nll_loss=2.316, w2v_ctc_loss=0.985, contrastive_loss=0, total=4186.05, n_correct=2551.73, ppl=4.98, accuracy=60.958, wps=19928, ups=2.38, wpb=8375.4, bsz=326.6, num_updates=45600, lr=6.62266e-05, gnorm=0.912, clip=0, loss_scale=32, train_wall=42, gb_free=17.8, wall=25258
2023-07-10 10:47:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
1.0
tensor(0.0271, device='cuda:6')
1.0
tensor(0.0271, device='cuda:5')
1.0
tensor(0.0271, device='cuda:4')
1.0
tensor(0.0271, device='cuda:2')
1.0
tensor(0.0271, device='cuda:7')
1.0
tensor(0.0271, device='cuda:1')
1.0
tensor(0.0271, device='cuda:3')
2023-07-10 10:48:02 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.172 | trans_loss 5.788 | nll_loss 3.112 | w2v_ctc_loss 0.312 | contrastive_loss 0.207 | total 4003.4 | n_correct 2353 | ppl 8.64 | accuracy 58.775 | uer 42.073 | wer 44.57 | raw_wer 44.57 | bleu 17.1 | wps 2765.1 | wpb 4003.4 | bsz 141.8 | num_updates 45675 | best_bleu 17.54
2023-07-10 10:48:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45675 updates
2023-07-10 10:48:02 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.1006.pt
2023-07-10 10:48:04 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.1006.pt
2023-07-10 10:48:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.1006.pt (epoch 31 @ 45675 updates, score 17.1) (writing took 5.197025318979286 seconds)
2023-07-10 10:48:07 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-07-10 10:48:07 | INFO | train | epoch 031 | loss 4.571 | trans_loss 5.096 | nll_loss 2.311 | w2v_ctc_loss 1.008 | contrastive_loss 0 | total 4138.65 | n_correct 2521.99 | ppl 4.96 | accuracy 60.937 | wps 18676.9 | ups 2.26 | wpb 8277.3 | bsz 305.7 | num_updates 45675 | lr 6.61722e-05 | gnorm 0.932 | clip 0 | loss_scale 32 | train_wall 612 | gb_free 12.7 | wall 25316
2023-07-10 10:48:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 10:48:08 | INFO | fairseq.trainer | begin training epoch 32
2023-07-10 10:48:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 10:48:26 | INFO | train_inner | epoch 032:     25 / 1474 loss=4.566, trans_loss=5.095, nll_loss=2.309, w2v_ctc_loss=0.991, contrastive_loss=0, total=4042.6, n_correct=2468.11, ppl=4.95, accuracy=61.053, wps=10595.2, ups=1.31, wpb=8090.4, bsz=288.7, num_updates=45700, lr=6.61541e-05, gnorm=0.945, clip=0, loss_scale=32, train_wall=41, gb_free=16.6, wall=25334
2023-07-10 10:49:07 | INFO | train_inner | epoch 032:    125 / 1474 loss=4.518, trans_loss=5.066, nll_loss=2.272, w2v_ctc_loss=0.91, contrastive_loss=0, total=4227.68, n_correct=2604.9, ppl=4.83, accuracy=61.615, wps=20358.7, ups=2.41, wpb=8459.9, bsz=323.3, num_updates=45800, lr=6.60819e-05, gnorm=0.909, clip=0, loss_scale=32, train_wall=41, gb_free=16.8, wall=25376
2023-07-10 10:49:49 | INFO | train_inner | epoch 032:    225 / 1474 loss=4.553, trans_loss=5.082, nll_loss=2.292, w2v_ctc_loss=0.975, contrastive_loss=0, total=4157.32, n_correct=2550.03, ppl=4.9, accuracy=61.338, wps=19906.7, ups=2.38, wpb=8353.7, bsz=320.6, num_updates=45900, lr=6.60098e-05, gnorm=0.929, clip=0, loss_scale=32, train_wall=42, gb_free=17.5, wall=25418
2023-07-10 10:50:31 | INFO | train_inner | epoch 032:    325 / 1474 loss=4.541, trans_loss=5.07, nll_loss=2.278, w2v_ctc_loss=0.98, contrastive_loss=0, total=4183.45, n_correct=2575.69, ppl=4.85, accuracy=61.569, wps=20079, ups=2.4, wpb=8350.9, bsz=314.4, num_updates=46000, lr=6.5938e-05, gnorm=0.912, clip=0, loss_scale=32, train_wall=41, gb_free=17.8, wall=25459
2023-07-10 10:50:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 10:50:52 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.143 | trans_loss 5.789 | nll_loss 3.109 | w2v_ctc_loss 0.217 | contrastive_loss 0.204 | total 4003.4 | n_correct 2355.3 | ppl 8.63 | accuracy 58.832 | uer 41.77 | wer 44.212 | raw_wer 44.212 | bleu 17.12 | wps 2767.7 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 17.54
2023-07-10 10:50:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-07-10 10:50:52 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_32_46000.pt
2023-07-10 10:50:54 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_32_46000.pt
2023-07-10 10:50:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 17.12) (writing took 6.176300616993103 seconds)
2023-07-10 10:50:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-10 10:50:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 10:51:21 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.143 | trans_loss 5.789 | nll_loss 3.109 | w2v_ctc_loss 0.217 | contrastive_loss 0.204 | total 4003.4 | n_correct 2355.3 | ppl 8.63 | accuracy 58.832 | uer 41.77 | wer 44.212 | raw_wer 44.212 | bleu 17.12 | wps 2726.6 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 17.54
2023-07-10 10:51:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-07-10 10:51:21 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_32_46000.pt
2023-07-10 10:51:26 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_32_46000.pt
2023-07-10 10:51:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 17.12) (writing took 11.130404800001998 seconds)
2023-07-10 10:52:13 | INFO | train_inner | epoch 032:    426 / 1474 loss=4.547, trans_loss=5.08, nll_loss=2.291, w2v_ctc_loss=0.969, contrastive_loss=0, total=4172.34, n_correct=2559.81, ppl=4.89, accuracy=61.352, wps=8141, ups=0.98, wpb=8347.9, bsz=309.9, num_updates=46100, lr=6.58665e-05, gnorm=0.919, clip=0, loss_scale=16, train_wall=42, gb_free=17.4, wall=25562
2023-07-10 10:52:56 | INFO | train_inner | epoch 032:    526 / 1474 loss=4.571, trans_loss=5.086, nll_loss=2.298, w2v_ctc_loss=1.039, contrastive_loss=0, total=4191.15, n_correct=2558.96, ppl=4.92, accuracy=61.056, wps=19604.6, ups=2.34, wpb=8378.5, bsz=315.1, num_updates=46200, lr=6.57952e-05, gnorm=0.955, clip=0, loss_scale=16, train_wall=42, gb_free=15.5, wall=25605
2023-07-10 10:53:39 | INFO | train_inner | epoch 032:    626 / 1474 loss=4.568, trans_loss=5.098, nll_loss=2.313, w2v_ctc_loss=0.99, contrastive_loss=0, total=4138.05, n_correct=2520.06, ppl=4.97, accuracy=60.9, wps=19519.6, ups=2.36, wpb=8284.7, bsz=299.5, num_updates=46300, lr=6.57241e-05, gnorm=0.923, clip=0, loss_scale=16, train_wall=42, gb_free=13.8, wall=25647
2023-07-10 10:54:21 | INFO | train_inner | epoch 032:    726 / 1474 loss=4.56, trans_loss=5.089, nll_loss=2.301, w2v_ctc_loss=1, contrastive_loss=0, total=4156.23, n_correct=2540.39, ppl=4.93, accuracy=61.122, wps=19644.6, ups=2.37, wpb=8292.8, bsz=303, num_updates=46400, lr=6.56532e-05, gnorm=0.95, clip=0, loss_scale=16, train_wall=42, gb_free=17, wall=25689
2023-07-10 10:55:02 | INFO | train_inner | epoch 032:    826 / 1474 loss=4.561, trans_loss=5.091, nll_loss=2.304, w2v_ctc_loss=0.981, contrastive_loss=0, total=4112.3, n_correct=2510.61, ppl=4.94, accuracy=61.051, wps=19837.6, ups=2.41, wpb=8239.2, bsz=293.9, num_updates=46500, lr=6.55826e-05, gnorm=0.919, clip=0, loss_scale=16, train_wall=41, gb_free=16.3, wall=25731
2023-07-10 10:55:44 | INFO | train_inner | epoch 032:    926 / 1474 loss=4.559, trans_loss=5.089, nll_loss=2.301, w2v_ctc_loss=0.99, contrastive_loss=0, total=4139.37, n_correct=2526.12, ppl=4.93, accuracy=61.027, wps=19640.9, ups=2.38, wpb=8269.1, bsz=298.6, num_updates=46600, lr=6.55122e-05, gnorm=0.945, clip=0, loss_scale=16, train_wall=42, gb_free=13.3, wall=25773
2023-07-10 10:56:26 | INFO | train_inner | epoch 032:   1026 / 1474 loss=4.546, trans_loss=5.089, nll_loss=2.302, w2v_ctc_loss=0.938, contrastive_loss=0, total=4121.85, n_correct=2516.19, ppl=4.93, accuracy=61.045, wps=19883.8, ups=2.41, wpb=8262, bsz=306.1, num_updates=46700, lr=6.5442e-05, gnorm=0.902, clip=0, loss_scale=16, train_wall=41, gb_free=17.2, wall=25815
2023-07-10 10:57:08 | INFO | train_inner | epoch 032:   1126 / 1474 loss=4.555, trans_loss=5.105, nll_loss=2.32, w2v_ctc_loss=0.934, contrastive_loss=0, total=4015.59, n_correct=2438.25, ppl=4.99, accuracy=60.72, wps=19134.3, ups=2.38, wpb=8031.7, bsz=270.1, num_updates=46800, lr=6.5372e-05, gnorm=0.938, clip=0, loss_scale=16, train_wall=42, gb_free=17.6, wall=25857
2023-07-10 10:57:50 | INFO | train_inner | epoch 032:   1226 / 1474 loss=4.56, trans_loss=5.106, nll_loss=2.324, w2v_ctc_loss=0.954, contrastive_loss=0, total=4153.44, n_correct=2520.88, ppl=5.01, accuracy=60.694, wps=19721.4, ups=2.38, wpb=8288.1, bsz=310.8, num_updates=46900, lr=6.53023e-05, gnorm=0.936, clip=0, loss_scale=16, train_wall=42, gb_free=16.7, wall=25899
2023-07-10 10:58:32 | INFO | train_inner | epoch 032:   1326 / 1474 loss=4.558, trans_loss=5.098, nll_loss=2.312, w2v_ctc_loss=0.96, contrastive_loss=0, total=4075.86, n_correct=2487.39, ppl=4.97, accuracy=61.027, wps=19594.2, ups=2.4, wpb=8148.8, bsz=295.4, num_updates=47000, lr=6.52328e-05, gnorm=0.921, clip=0, loss_scale=16, train_wall=41, gb_free=17.2, wall=25940
2023-07-10 10:59:14 | INFO | train_inner | epoch 032:   1426 / 1474 loss=4.565, trans_loss=5.1, nll_loss=2.316, w2v_ctc_loss=0.983, contrastive_loss=0, total=4116.4, n_correct=2508.97, ppl=4.98, accuracy=60.951, wps=19537.6, ups=2.38, wpb=8215.8, bsz=307.6, num_updates=47100, lr=6.51635e-05, gnorm=0.933, clip=0, loss_scale=16, train_wall=42, gb_free=17.1, wall=25982
2023-07-10 10:59:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 10:59:56 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.145 | trans_loss 5.776 | nll_loss 3.093 | w2v_ctc_loss 0.253 | contrastive_loss 0.207 | total 4003.4 | n_correct 2360.8 | ppl 8.53 | accuracy 58.97 | uer 41.56 | wer 44.186 | raw_wer 44.186 | bleu 17.47 | wps 2565 | wpb 4003.4 | bsz 141.8 | num_updates 47148 | best_bleu 17.54
2023-07-10 10:59:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47148 updates
2023-07-10 10:59:56 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.4702.pt
2023-07-10 10:59:58 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.4702.pt
2023-07-10 11:00:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.4702.pt (epoch 32 @ 47148 updates, score 17.47) (writing took 5.5738504699547775 seconds)
2023-07-10 11:00:01 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-07-10 11:00:01 | INFO | train | epoch 032 | loss 4.555 | trans_loss 5.089 | nll_loss 2.301 | w2v_ctc_loss 0.973 | contrastive_loss 0 | total 4138.93 | n_correct 2529.47 | ppl 4.93 | accuracy 61.114 | wps 17073.4 | ups 2.06 | wpb 8277.7 | bsz 305.7 | num_updates 47148 | lr 6.51303e-05 | gnorm 0.928 | clip 0 | loss_scale 16 | train_wall 611 | gb_free 16.9 | wall 26030
2023-07-10 11:00:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 11:00:02 | INFO | fairseq.trainer | begin training epoch 33
2023-07-10 11:00:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 11:00:32 | INFO | train_inner | epoch 033:     52 / 1474 loss=4.552, trans_loss=5.084, nll_loss=2.296, w2v_ctc_loss=0.985, contrastive_loss=0, total=4149.21, n_correct=2538.51, ppl=4.91, accuracy=61.181, wps=10607, ups=1.28, wpb=8287.9, bsz=320.5, num_updates=47200, lr=6.50945e-05, gnorm=0.932, clip=0, loss_scale=16, train_wall=41, gb_free=17.3, wall=26060
2023-07-10 11:01:13 | INFO | train_inner | epoch 033:    152 / 1474 loss=4.53, trans_loss=5.075, nll_loss=2.282, w2v_ctc_loss=0.923, contrastive_loss=0, total=4073.9, n_correct=2500.32, ppl=4.86, accuracy=61.374, wps=19685.2, ups=2.41, wpb=8168.9, bsz=284.8, num_updates=47300, lr=6.50256e-05, gnorm=0.98, clip=0, loss_scale=16, train_wall=41, gb_free=15.7, wall=26102
2023-07-10 11:01:56 | INFO | train_inner | epoch 033:    252 / 1474 loss=4.515, trans_loss=5.06, nll_loss=2.265, w2v_ctc_loss=0.915, contrastive_loss=0, total=4280.14, n_correct=2644.34, ppl=4.81, accuracy=61.782, wps=20216.9, ups=2.36, wpb=8576, bsz=346.5, num_updates=47400, lr=6.4957e-05, gnorm=0.897, clip=0, loss_scale=16, train_wall=42, gb_free=16.8, wall=26144
2023-07-10 11:02:38 | INFO | train_inner | epoch 033:    352 / 1474 loss=4.534, trans_loss=5.083, nll_loss=2.294, w2v_ctc_loss=0.928, contrastive_loss=0, total=4120.27, n_correct=2521.23, ppl=4.9, accuracy=61.191, wps=19590.8, ups=2.38, wpb=8214.2, bsz=300.7, num_updates=47500, lr=6.48886e-05, gnorm=0.963, clip=0, loss_scale=16, train_wall=42, gb_free=17.6, wall=26186
2023-07-10 11:03:19 | INFO | train_inner | epoch 033:    452 / 1474 loss=4.541, trans_loss=5.063, nll_loss=2.267, w2v_ctc_loss=0.996, contrastive_loss=0, total=4141.22, n_correct=2559.31, ppl=4.81, accuracy=61.801, wps=19871.3, ups=2.4, wpb=8279.3, bsz=310.8, num_updates=47600, lr=6.48204e-05, gnorm=0.927, clip=0, loss_scale=16, train_wall=41, gb_free=16.8, wall=26228
2023-07-10 11:04:01 | INFO | train_inner | epoch 033:    552 / 1474 loss=4.577, trans_loss=5.09, nll_loss=2.302, w2v_ctc_loss=1.052, contrastive_loss=0, total=4133.59, n_correct=2528.16, ppl=4.93, accuracy=61.161, wps=19655.1, ups=2.39, wpb=8237.5, bsz=294, num_updates=47700, lr=6.47524e-05, gnorm=0.959, clip=0, loss_scale=16, train_wall=41, gb_free=15.6, wall=26270
2023-07-10 11:04:43 | INFO | train_inner | epoch 033:    652 / 1474 loss=4.571, trans_loss=5.088, nll_loss=2.3, w2v_ctc_loss=1.035, contrastive_loss=0, total=4157.63, n_correct=2541.36, ppl=4.93, accuracy=61.125, wps=19778.1, ups=2.38, wpb=8308.5, bsz=301.6, num_updates=47800, lr=6.46846e-05, gnorm=0.934, clip=0, loss_scale=16, train_wall=42, gb_free=18, wall=26312
2023-07-10 11:05:25 | INFO | train_inner | epoch 033:    752 / 1474 loss=4.581, trans_loss=5.089, nll_loss=2.301, w2v_ctc_loss=1.065, contrastive_loss=0, total=4070.75, n_correct=2485.76, ppl=4.93, accuracy=61.064, wps=19474.5, ups=2.4, wpb=8130.5, bsz=287.2, num_updates=47900, lr=6.46171e-05, gnorm=0.99, clip=0, loss_scale=16, train_wall=41, gb_free=16.8, wall=26354
2023-07-10 11:06:06 | INFO | train_inner | epoch 033:    852 / 1474 loss=4.543, trans_loss=5.071, nll_loss=2.278, w2v_ctc_loss=0.97, contrastive_loss=0, total=4130.24, n_correct=2549.92, ppl=4.85, accuracy=61.738, wps=19972.6, ups=2.41, wpb=8285.5, bsz=316.3, num_updates=48000, lr=6.45497e-05, gnorm=0.922, clip=0, loss_scale=16, train_wall=41, gb_free=17, wall=26395
2023-07-10 11:06:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 11:06:29 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.144 | trans_loss 5.774 | nll_loss 3.092 | w2v_ctc_loss 0.254 | contrastive_loss 0.207 | total 4003.4 | n_correct 2360 | ppl 8.53 | accuracy 58.95 | uer 41.762 | wer 44.279 | raw_wer 44.279 | bleu 17.7 | wps 2484.4 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 17.7
2023-07-10 11:06:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-07-10 11:06:29 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_33_48000.pt
2023-07-10 11:06:31 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_33_48000.pt
2023-07-10 11:06:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 17.7) (writing took 9.154744817991741 seconds)
2023-07-10 11:07:21 | INFO | train_inner | epoch 033:    952 / 1474 loss=4.569, trans_loss=5.082, nll_loss=2.293, w2v_ctc_loss=1.032, contrastive_loss=0, total=4151.18, n_correct=2544.13, ppl=4.9, accuracy=61.287, wps=11232.6, ups=1.35, wpb=8320.4, bsz=308.3, num_updates=48100, lr=6.44826e-05, gnorm=0.947, clip=0, loss_scale=32, train_wall=42, gb_free=11.8, wall=26469
2023-07-10 11:08:03 | INFO | train_inner | epoch 033:   1052 / 1474 loss=4.556, trans_loss=5.088, nll_loss=2.301, w2v_ctc_loss=0.979, contrastive_loss=0, total=4140.1, n_correct=2530.41, ppl=4.93, accuracy=61.12, wps=19467.7, ups=2.35, wpb=8275.4, bsz=307.6, num_updates=48200, lr=6.44157e-05, gnorm=0.924, clip=0, loss_scale=32, train_wall=42, gb_free=12.3, wall=26512
2023-07-10 11:08:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-10 11:08:45 | INFO | train_inner | epoch 033:   1153 / 1474 loss=4.547, trans_loss=5.089, nll_loss=2.302, w2v_ctc_loss=0.953, contrastive_loss=0, total=4171.38, n_correct=2550.49, ppl=4.93, accuracy=61.143, wps=19730.4, ups=2.37, wpb=8329, bsz=304.1, num_updates=48300, lr=6.43489e-05, gnorm=0.934, clip=0, loss_scale=16, train_wall=42, gb_free=15.5, wall=26554
2023-07-10 11:09:27 | INFO | train_inner | epoch 033:   1253 / 1474 loss=4.556, trans_loss=5.087, nll_loss=2.299, w2v_ctc_loss=0.973, contrastive_loss=0, total=4115.76, n_correct=2520.51, ppl=4.92, accuracy=61.24, wps=19704.3, ups=2.39, wpb=8244.7, bsz=294.7, num_updates=48400, lr=6.42824e-05, gnorm=0.964, clip=0, loss_scale=16, train_wall=41, gb_free=17, wall=26596
2023-07-10 11:10:09 | INFO | train_inner | epoch 033:   1353 / 1474 loss=4.55, trans_loss=5.079, nll_loss=2.29, w2v_ctc_loss=0.97, contrastive_loss=0, total=4120.69, n_correct=2529.18, ppl=4.89, accuracy=61.378, wps=19635.9, ups=2.37, wpb=8281.8, bsz=311.9, num_updates=48500, lr=6.42161e-05, gnorm=0.938, clip=0, loss_scale=16, train_wall=42, gb_free=17.2, wall=26638
2023-07-10 11:10:52 | INFO | train_inner | epoch 033:   1453 / 1474 loss=4.558, trans_loss=5.087, nll_loss=2.301, w2v_ctc_loss=0.989, contrastive_loss=0, total=4125.28, n_correct=2522.49, ppl=4.93, accuracy=61.147, wps=19474, ups=2.36, wpb=8238, bsz=308.7, num_updates=48600, lr=6.415e-05, gnorm=0.933, clip=0, loss_scale=16, train_wall=42, gb_free=17.3, wall=26680
2023-07-10 11:11:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 11:11:22 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.145 | trans_loss 5.773 | nll_loss 3.088 | w2v_ctc_loss 0.259 | contrastive_loss 0.209 | total 4003.4 | n_correct 2366.3 | ppl 8.5 | accuracy 59.107 | uer 40.982 | wer 43.235 | raw_wer 43.235 | bleu 17.42 | wps 2570.3 | wpb 4003.4 | bsz 141.8 | num_updates 48621 | best_bleu 17.7
2023-07-10 11:11:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48621 updates
2023-07-10 11:11:22 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.4208.pt
2023-07-10 11:11:25 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.4208.pt
2023-07-10 11:11:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.4208.pt (epoch 33 @ 48621 updates, score 17.42) (writing took 5.192866500990931 seconds)
2023-07-10 11:11:28 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-07-10 11:11:28 | INFO | train | epoch 033 | loss 4.552 | trans_loss 5.081 | nll_loss 2.291 | w2v_ctc_loss 0.983 | contrastive_loss 0 | total 4137.9 | n_correct 2537.47 | ppl 4.89 | accuracy 61.323 | wps 17760.6 | ups 2.15 | wpb 8276.1 | bsz 305.3 | num_updates 48621 | lr 6.41362e-05 | gnorm 0.944 | clip 0 | loss_scale 16 | train_wall 612 | gb_free 18.1 | wall 26716
2023-07-10 11:11:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 11:11:28 | INFO | fairseq.trainer | begin training epoch 34
2023-07-10 11:11:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 11:12:09 | INFO | train_inner | epoch 034:     79 / 1474 loss=4.527, trans_loss=5.067, nll_loss=2.273, w2v_ctc_loss=0.933, contrastive_loss=0, total=4131.47, n_correct=2548.11, ppl=4.83, accuracy=61.676, wps=10712.6, ups=1.3, wpb=8265.1, bsz=301.7, num_updates=48700, lr=6.40841e-05, gnorm=0.941, clip=0, loss_scale=16, train_wall=41, gb_free=17, wall=26757
2023-07-10 11:12:51 | INFO | train_inner | epoch 034:    179 / 1474 loss=4.546, trans_loss=5.064, nll_loss=2.268, w2v_ctc_loss=1.005, contrastive_loss=0, total=4065.88, n_correct=2507.71, ppl=4.82, accuracy=61.677, wps=19453.3, ups=2.39, wpb=8147.7, bsz=295.1, num_updates=48800, lr=6.40184e-05, gnorm=0.96, clip=0, loss_scale=16, train_wall=41, gb_free=16.4, wall=26799
2023-07-10 11:13:33 | INFO | train_inner | epoch 034:    279 / 1474 loss=4.55, trans_loss=5.08, nll_loss=2.291, w2v_ctc_loss=0.995, contrastive_loss=0, total=4246.3, n_correct=2601.66, ppl=4.89, accuracy=61.269, wps=20154.5, ups=2.38, wpb=8461.3, bsz=328.7, num_updates=48900, lr=6.39529e-05, gnorm=0.921, clip=0, loss_scale=16, train_wall=42, gb_free=18, wall=26841
2023-07-10 11:13:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-10 11:14:15 | INFO | train_inner | epoch 034:    380 / 1474 loss=4.531, trans_loss=5.065, nll_loss=2.27, w2v_ctc_loss=0.955, contrastive_loss=0, total=4161.76, n_correct=2572.95, ppl=4.82, accuracy=61.824, wps=19842.4, ups=2.38, wpb=8322.8, bsz=318.2, num_updates=49000, lr=6.38877e-05, gnorm=0.897, clip=0, loss_scale=8, train_wall=42, gb_free=16.3, wall=26883
2023-07-10 11:14:56 | INFO | train_inner | epoch 034:    480 / 1474 loss=4.56, trans_loss=5.073, nll_loss=2.28, w2v_ctc_loss=1.033, contrastive_loss=0, total=4080.7, n_correct=2502.07, ppl=4.86, accuracy=61.315, wps=19734.3, ups=2.42, wpb=8167.4, bsz=286.7, num_updates=49100, lr=6.38226e-05, gnorm=0.995, clip=0, loss_scale=8, train_wall=41, gb_free=16, wall=26925
2023-07-10 11:15:38 | INFO | train_inner | epoch 034:    580 / 1474 loss=4.543, trans_loss=5.067, nll_loss=2.273, w2v_ctc_loss=0.994, contrastive_loss=0, total=4126.98, n_correct=2546.24, ppl=4.83, accuracy=61.697, wps=19756.3, ups=2.4, wpb=8243, bsz=300.1, num_updates=49200, lr=6.37577e-05, gnorm=0.977, clip=0, loss_scale=8, train_wall=41, gb_free=16.6, wall=26966
2023-07-10 11:16:19 | INFO | train_inner | epoch 034:    680 / 1474 loss=4.534, trans_loss=5.065, nll_loss=2.271, w2v_ctc_loss=0.963, contrastive_loss=0, total=4110.23, n_correct=2532.94, ppl=4.83, accuracy=61.625, wps=19768.9, ups=2.4, wpb=8222.5, bsz=297.1, num_updates=49300, lr=6.3693e-05, gnorm=0.926, clip=0, loss_scale=8, train_wall=41, gb_free=16.6, wall=27008
2023-07-10 11:17:01 | INFO | train_inner | epoch 034:    780 / 1474 loss=4.552, trans_loss=5.084, nll_loss=2.295, w2v_ctc_loss=0.978, contrastive_loss=0, total=4087.05, n_correct=2505.7, ppl=4.91, accuracy=61.308, wps=19517.3, ups=2.39, wpb=8170.8, bsz=297.4, num_updates=49400, lr=6.36285e-05, gnorm=0.937, clip=0, loss_scale=8, train_wall=41, gb_free=16.4, wall=27050
2023-07-10 11:17:43 | INFO | train_inner | epoch 034:    880 / 1474 loss=4.533, trans_loss=5.081, nll_loss=2.291, w2v_ctc_loss=0.925, contrastive_loss=0, total=4088.94, n_correct=2505.86, ppl=4.89, accuracy=61.284, wps=19584.2, ups=2.39, wpb=8179.7, bsz=294.2, num_updates=49500, lr=6.35642e-05, gnorm=0.952, clip=0, loss_scale=8, train_wall=41, gb_free=15.3, wall=27092
2023-07-10 11:18:25 | INFO | train_inner | epoch 034:    980 / 1474 loss=4.53, trans_loss=5.082, nll_loss=2.294, w2v_ctc_loss=0.905, contrastive_loss=0, total=4175.9, n_correct=2556.47, ppl=4.9, accuracy=61.22, wps=19993.1, ups=2.39, wpb=8364.5, bsz=312.7, num_updates=49600, lr=6.35001e-05, gnorm=0.906, clip=0, loss_scale=8, train_wall=41, gb_free=14.2, wall=27133
2023-07-10 11:19:07 | INFO | train_inner | epoch 034:   1080 / 1474 loss=4.543, trans_loss=5.078, nll_loss=2.288, w2v_ctc_loss=0.964, contrastive_loss=0, total=4152.17, n_correct=2549.44, ppl=4.89, accuracy=61.4, wps=19491, ups=2.35, wpb=8286.8, bsz=309, num_updates=49700, lr=6.34361e-05, gnorm=0.943, clip=0, loss_scale=8, train_wall=42, gb_free=15, wall=27176
2023-07-10 11:19:49 | INFO | train_inner | epoch 034:   1180 / 1474 loss=4.542, trans_loss=5.082, nll_loss=2.293, w2v_ctc_loss=0.946, contrastive_loss=0, total=4101.68, n_correct=2518.09, ppl=4.9, accuracy=61.392, wps=19463.5, ups=2.37, wpb=8198.6, bsz=298, num_updates=49800, lr=6.33724e-05, gnorm=0.969, clip=0, loss_scale=8, train_wall=42, gb_free=16.5, wall=27218
2023-07-10 11:20:31 | INFO | train_inner | epoch 034:   1280 / 1474 loss=4.552, trans_loss=5.077, nll_loss=2.286, w2v_ctc_loss=0.984, contrastive_loss=0, total=4146.01, n_correct=2550.52, ppl=4.88, accuracy=61.517, wps=20073.5, ups=2.41, wpb=8314, bsz=300.6, num_updates=49900, lr=6.33089e-05, gnorm=0.954, clip=0, loss_scale=8, train_wall=41, gb_free=17.5, wall=27259
2023-07-10 11:21:13 | INFO | train_inner | epoch 034:   1380 / 1474 loss=4.567, trans_loss=5.082, nll_loss=2.294, w2v_ctc_loss=1.027, contrastive_loss=0, total=4197.99, n_correct=2573.23, ppl=4.9, accuracy=61.297, wps=20003.4, ups=2.38, wpb=8408.2, bsz=321.1, num_updates=50000, lr=6.32456e-05, gnorm=0.949, clip=0, loss_scale=8, train_wall=42, gb_free=17.5, wall=27301
2023-07-10 11:21:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 11:21:36 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.142 | trans_loss 5.774 | nll_loss 3.09 | w2v_ctc_loss 0.248 | contrastive_loss 0.208 | total 4003.4 | n_correct 2361.6 | ppl 8.52 | accuracy 58.99 | uer 40.902 | wer 43.239 | raw_wer 43.239 | bleu 17.47 | wps 2419 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 17.7
2023-07-10 11:21:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-07-10 11:21:36 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_34_50000.pt
2023-07-10 11:21:38 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_34_50000.pt
2023-07-10 11:21:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 17.47) (writing took 6.029362255008891 seconds)
1.0
tensor(0.0271, device='cuda:0')
2023-07-10 11:22:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
1.0
tensor(0.0271, device='cuda:7')
1.0
tensor(0.0271, device='cuda:1')
1.0
tensor(0.0271, device='cuda:3')
1.0
tensor(0.0271, device='cuda:5')
1.0
tensor(0.0271, device='cuda:4')
1.0
tensor(0.0271, device='cuda:6')
1.0
tensor(0.0271, device='cuda:2')
2023-07-10 11:22:43 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.138 | trans_loss 5.768 | nll_loss 3.082 | w2v_ctc_loss 0.249 | contrastive_loss 0.206 | total 4003.4 | n_correct 2362 | ppl 8.47 | accuracy 59 | uer 40.955 | wer 43.197 | raw_wer 43.197 | bleu 17.53 | wps 2580.4 | wpb 4003.4 | bsz 141.8 | num_updates 50094 | best_bleu 17.7
2023-07-10 11:22:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50094 updates
2023-07-10 11:22:43 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.5306.pt
2023-07-10 11:22:45 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.5306.pt
2023-07-10 11:22:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.5306.pt (epoch 34 @ 50094 updates, score 17.53) (writing took 5.498991952044889 seconds)
2023-07-10 11:22:49 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-07-10 11:22:49 | INFO | train | epoch 034 | loss 4.544 | trans_loss 5.075 | nll_loss 2.284 | w2v_ctc_loss 0.974 | contrastive_loss 0 | total 4139.37 | n_correct 2544.03 | ppl 4.87 | accuracy 61.459 | wps 17912.6 | ups 2.16 | wpb 8278.7 | bsz 305.8 | num_updates 50094 | lr 6.31862e-05 | gnorm 0.942 | clip 0 | loss_scale 8 | train_wall 610 | gb_free 17.6 | wall 27397
2023-07-10 11:22:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 11:22:49 | INFO | fairseq.trainer | begin training epoch 35
2023-07-10 11:22:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 11:23:00 | INFO | train_inner | epoch 035:      6 / 1474 loss=4.549, trans_loss=5.076, nll_loss=2.287, w2v_ctc_loss=0.995, contrastive_loss=0, total=4206.43, n_correct=2582.55, ppl=4.88, accuracy=61.395, wps=7855, ups=0.94, wpb=8390, bsz=324.8, num_updates=50100, lr=6.31824e-05, gnorm=0.918, clip=0, loss_scale=8, train_wall=42, gb_free=18.1, wall=27408
2023-07-10 11:23:41 | INFO | train_inner | epoch 035:    106 / 1474 loss=4.524, trans_loss=5.062, nll_loss=2.267, w2v_ctc_loss=0.937, contrastive_loss=0, total=4171.34, n_correct=2574.54, ppl=4.81, accuracy=61.72, wps=20071.4, ups=2.4, wpb=8352.2, bsz=313.6, num_updates=50200, lr=6.31194e-05, gnorm=0.92, clip=0, loss_scale=8, train_wall=41, gb_free=16.1, wall=27450
2023-07-10 11:24:23 | INFO | train_inner | epoch 035:    206 / 1474 loss=4.503, trans_loss=5.048, nll_loss=2.249, w2v_ctc_loss=0.908, contrastive_loss=0, total=4167.37, n_correct=2583.48, ppl=4.75, accuracy=61.993, wps=19779.8, ups=2.37, wpb=8336.7, bsz=316, num_updates=50300, lr=6.30567e-05, gnorm=0.903, clip=0, loss_scale=8, train_wall=42, gb_free=14.1, wall=27492
2023-07-10 11:25:06 | INFO | train_inner | epoch 035:    306 / 1474 loss=4.52, trans_loss=5.063, nll_loss=2.267, w2v_ctc_loss=0.927, contrastive_loss=0, total=4114.35, n_correct=2531.2, ppl=4.81, accuracy=61.521, wps=19564.1, ups=2.37, wpb=8245.2, bsz=299.9, num_updates=50400, lr=6.29941e-05, gnorm=0.969, clip=0, loss_scale=8, train_wall=42, gb_free=13, wall=27534
2023-07-10 11:25:47 | INFO | train_inner | epoch 035:    406 / 1474 loss=4.543, trans_loss=5.075, nll_loss=2.283, w2v_ctc_loss=0.979, contrastive_loss=0, total=4069.11, n_correct=2498.61, ppl=4.87, accuracy=61.404, wps=19456.3, ups=2.4, wpb=8112.3, bsz=283.5, num_updates=50500, lr=6.29317e-05, gnorm=1.01, clip=0, loss_scale=8, train_wall=41, gb_free=17.2, wall=27576
2023-07-10 11:26:30 | INFO | train_inner | epoch 035:    506 / 1474 loss=4.553, trans_loss=5.068, nll_loss=2.274, w2v_ctc_loss=1.035, contrastive_loss=0, total=4158.81, n_correct=2558.31, ppl=4.84, accuracy=61.515, wps=19598.1, ups=2.36, wpb=8290.4, bsz=305.1, num_updates=50600, lr=6.28695e-05, gnorm=0.93, clip=0, loss_scale=8, train_wall=42, gb_free=16.7, wall=27618
2023-07-10 11:27:12 | INFO | train_inner | epoch 035:    606 / 1474 loss=4.519, trans_loss=5.059, nll_loss=2.262, w2v_ctc_loss=0.931, contrastive_loss=0, total=4167.77, n_correct=2575.04, ppl=4.8, accuracy=61.785, wps=19771.9, ups=2.37, wpb=8341, bsz=309.7, num_updates=50700, lr=6.28074e-05, gnorm=0.9, clip=0, loss_scale=8, train_wall=42, gb_free=16.5, wall=27660
2023-07-10 11:27:54 | INFO | train_inner | epoch 035:    706 / 1474 loss=4.543, trans_loss=5.077, nll_loss=2.287, w2v_ctc_loss=0.966, contrastive_loss=0, total=4084.16, n_correct=2506, ppl=4.88, accuracy=61.359, wps=19373.3, ups=2.37, wpb=8165, bsz=294.8, num_updates=50800, lr=6.27456e-05, gnorm=0.944, clip=0, loss_scale=8, train_wall=42, gb_free=17.3, wall=27703
2023-07-10 11:28:36 | INFO | train_inner | epoch 035:    806 / 1474 loss=4.531, trans_loss=5.066, nll_loss=2.273, w2v_ctc_loss=0.945, contrastive_loss=0, total=4151.07, n_correct=2559.3, ppl=4.83, accuracy=61.654, wps=19957.2, ups=2.4, wpb=8321.9, bsz=311.5, num_updates=50900, lr=6.26839e-05, gnorm=0.964, clip=0, loss_scale=8, train_wall=41, gb_free=17.3, wall=27744
2023-07-10 11:29:18 | INFO | train_inner | epoch 035:    906 / 1474 loss=4.544, trans_loss=5.077, nll_loss=2.286, w2v_ctc_loss=0.969, contrastive_loss=0, total=4097.72, n_correct=2516.19, ppl=4.88, accuracy=61.405, wps=19505.6, ups=2.38, wpb=8185.4, bsz=292.9, num_updates=51000, lr=6.26224e-05, gnorm=0.947, clip=0, loss_scale=16, train_wall=42, gb_free=16.4, wall=27786
2023-07-10 11:29:59 | INFO | train_inner | epoch 035:   1006 / 1474 loss=4.554, trans_loss=5.069, nll_loss=2.277, w2v_ctc_loss=1.026, contrastive_loss=0, total=4141.74, n_correct=2548.88, ppl=4.85, accuracy=61.541, wps=19858.3, ups=2.4, wpb=8275.4, bsz=306.2, num_updates=51100, lr=6.25611e-05, gnorm=0.981, clip=0, loss_scale=16, train_wall=41, gb_free=17.8, wall=27828
2023-07-10 11:30:41 | INFO | train_inner | epoch 035:   1106 / 1474 loss=4.53, trans_loss=5.07, nll_loss=2.278, w2v_ctc_loss=0.939, contrastive_loss=0, total=4182.91, n_correct=2582.47, ppl=4.85, accuracy=61.739, wps=20128, ups=2.41, wpb=8361.6, bsz=311.4, num_updates=51200, lr=6.25e-05, gnorm=0.928, clip=0, loss_scale=16, train_wall=41, gb_free=10.9, wall=27869
2023-07-10 11:31:22 | INFO | train_inner | epoch 035:   1206 / 1474 loss=4.521, trans_loss=5.069, nll_loss=2.277, w2v_ctc_loss=0.917, contrastive_loss=0, total=4207.87, n_correct=2597.76, ppl=4.85, accuracy=61.736, wps=20245.9, ups=2.41, wpb=8393, bsz=320.3, num_updates=51300, lr=6.24391e-05, gnorm=0.91, clip=0, loss_scale=16, train_wall=41, gb_free=15.3, wall=27911
2023-07-10 11:32:04 | INFO | train_inner | epoch 035:   1306 / 1474 loss=4.533, trans_loss=5.069, nll_loss=2.277, w2v_ctc_loss=0.94, contrastive_loss=0, total=4141.67, n_correct=2555.89, ppl=4.85, accuracy=61.712, wps=20054.5, ups=2.41, wpb=8313.8, bsz=313.9, num_updates=51400, lr=6.23783e-05, gnorm=0.942, clip=0, loss_scale=16, train_wall=41, gb_free=16.6, wall=27952
2023-07-10 11:32:45 | INFO | train_inner | epoch 035:   1406 / 1474 loss=4.56, trans_loss=5.082, nll_loss=2.292, w2v_ctc_loss=1.004, contrastive_loss=0, total=4057.93, n_correct=2490.69, ppl=4.9, accuracy=61.378, wps=19581.3, ups=2.41, wpb=8126.1, bsz=285.6, num_updates=51500, lr=6.23177e-05, gnorm=1.004, clip=0, loss_scale=16, train_wall=41, gb_free=15.8, wall=27994
2023-07-10 11:33:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 11:33:35 | INFO | dev_st | epoch 035 | valid on 'dev_st' subset | loss 4.138 | trans_loss 5.777 | nll_loss 3.094 | w2v_ctc_loss 0.227 | contrastive_loss 0.208 | total 4003.4 | n_correct 2361.6 | ppl 8.54 | accuracy 58.99 | uer 41.048 | wer 44.01 | raw_wer 44.01 | bleu 17.11 | wps 2612.6 | wpb 4003.4 | bsz 141.8 | num_updates 51568 | best_bleu 17.7
2023-07-10 11:33:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 51568 updates
2023-07-10 11:33:35 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.1100.pt
2023-07-10 11:33:38 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.1100.pt
2023-07-10 11:33:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.1100.pt (epoch 35 @ 51568 updates, score 17.11) (writing took 5.269743554992601 seconds)
2023-07-10 11:33:41 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-07-10 11:33:41 | INFO | train | epoch 035 | loss 4.535 | trans_loss 5.068 | nll_loss 2.275 | w2v_ctc_loss 0.961 | contrastive_loss 0 | total 4138.65 | n_correct 2549.99 | ppl 4.84 | accuracy 61.614 | wps 18705.8 | ups 2.26 | wpb 8277.3 | bsz 305.7 | num_updates 51568 | lr 6.22766e-05 | gnorm 0.946 | clip 0 | loss_scale 16 | train_wall 610 | gb_free 17.5 | wall 28050
2023-07-10 11:33:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 11:33:41 | INFO | fairseq.trainer | begin training epoch 36
2023-07-10 11:33:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 11:34:02 | INFO | train_inner | epoch 036:     32 / 1474 loss=4.547, trans_loss=5.067, nll_loss=2.274, w2v_ctc_loss=1.002, contrastive_loss=0, total=4128.66, n_correct=2550.11, ppl=4.84, accuracy=61.766, wps=10745.2, ups=1.3, wpb=8256, bsz=309, num_updates=51600, lr=6.22573e-05, gnorm=0.938, clip=0, loss_scale=16, train_wall=41, gb_free=16.7, wall=28071
2023-07-10 11:34:44 | INFO | train_inner | epoch 036:    132 / 1474 loss=4.527, trans_loss=5.053, nll_loss=2.254, w2v_ctc_loss=0.977, contrastive_loss=0, total=4101.15, n_correct=2538.26, ppl=4.77, accuracy=61.891, wps=19626.1, ups=2.39, wpb=8202.2, bsz=298.9, num_updates=51700, lr=6.2197e-05, gnorm=0.962, clip=0, loss_scale=16, train_wall=41, gb_free=16.8, wall=28112
2023-07-10 11:35:26 | INFO | train_inner | epoch 036:    232 / 1474 loss=4.516, trans_loss=5.06, nll_loss=2.263, w2v_ctc_loss=0.922, contrastive_loss=0, total=4153.27, n_correct=2567.44, ppl=4.8, accuracy=61.817, wps=19660.3, ups=2.37, wpb=8295.6, bsz=303.6, num_updates=51800, lr=6.2137e-05, gnorm=0.922, clip=0, loss_scale=16, train_wall=42, gb_free=17.2, wall=28155
2023-07-10 11:36:08 | INFO | train_inner | epoch 036:    332 / 1474 loss=4.484, trans_loss=5.049, nll_loss=2.25, w2v_ctc_loss=0.844, contrastive_loss=0, total=4162.11, n_correct=2587.31, ppl=4.76, accuracy=62.163, wps=19859.8, ups=2.39, wpb=8320.7, bsz=310.2, num_updates=51900, lr=6.20771e-05, gnorm=0.886, clip=0, loss_scale=16, train_wall=41, gb_free=17, wall=28197
2023-07-10 11:36:50 | INFO | train_inner | epoch 036:    432 / 1474 loss=4.511, trans_loss=5.049, nll_loss=2.252, w2v_ctc_loss=0.94, contrastive_loss=0, total=4234.05, n_correct=2626.29, ppl=4.76, accuracy=62.028, wps=20134.9, ups=2.38, wpb=8442.3, bsz=333.1, num_updates=52000, lr=6.20174e-05, gnorm=0.889, clip=0, loss_scale=16, train_wall=41, gb_free=16.5, wall=28239
2023-07-10 11:36:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 11:37:12 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 4.141 | trans_loss 5.772 | nll_loss 3.086 | w2v_ctc_loss 0.249 | contrastive_loss 0.203 | total 4003.4 | n_correct 2361.6 | ppl 8.49 | accuracy 58.99 | uer 41.056 | wer 43.529 | raw_wer 43.529 | bleu 17.59 | wps 2691.9 | wpb 4003.4 | bsz 141.8 | num_updates 52000 | best_bleu 17.7
2023-07-10 11:37:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 52000 updates
2023-07-10 11:37:12 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_36_52000.pt
2023-07-10 11:37:14 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_36_52000.pt
2023-07-10 11:37:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_36_52000.pt (epoch 36 @ 52000 updates, score 17.59) (writing took 6.207509408006445 seconds)
2023-07-10 11:38:00 | INFO | train_inner | epoch 036:    532 / 1474 loss=4.535, trans_loss=5.061, nll_loss=2.267, w2v_ctc_loss=0.983, contrastive_loss=0, total=4149.22, n_correct=2558.86, ppl=4.81, accuracy=61.671, wps=11773.8, ups=1.42, wpb=8304, bsz=312.3, num_updates=52100, lr=6.19578e-05, gnorm=0.932, clip=0, loss_scale=16, train_wall=42, gb_free=18, wall=28309
2023-07-10 11:38:42 | INFO | train_inner | epoch 036:    632 / 1474 loss=4.523, trans_loss=5.054, nll_loss=2.257, w2v_ctc_loss=0.956, contrastive_loss=0, total=4179.05, n_correct=2590.89, ppl=4.78, accuracy=61.997, wps=19963.1, ups=2.39, wpb=8359, bsz=316.9, num_updates=52200, lr=6.18984e-05, gnorm=0.926, clip=0, loss_scale=16, train_wall=41, gb_free=17.4, wall=28351
2023-07-10 11:39:24 | INFO | train_inner | epoch 036:    732 / 1474 loss=4.528, trans_loss=5.064, nll_loss=2.269, w2v_ctc_loss=0.952, contrastive_loss=0, total=4180.07, n_correct=2578.06, ppl=4.82, accuracy=61.675, wps=19993.3, ups=2.39, wpb=8361.4, bsz=315.5, num_updates=52300, lr=6.18392e-05, gnorm=0.947, clip=0, loss_scale=16, train_wall=41, gb_free=14.2, wall=28393
2023-07-10 11:40:06 | INFO | train_inner | epoch 036:    832 / 1474 loss=4.558, trans_loss=5.067, nll_loss=2.275, w2v_ctc_loss=1.053, contrastive_loss=0, total=4178.14, n_correct=2570.89, ppl=4.84, accuracy=61.532, wps=19799.5, ups=2.38, wpb=8326.4, bsz=321.7, num_updates=52400, lr=6.17802e-05, gnorm=0.973, clip=0, loss_scale=16, train_wall=42, gb_free=16.7, wall=28435
2023-07-10 11:40:48 | INFO | train_inner | epoch 036:    932 / 1474 loss=4.525, trans_loss=5.057, nll_loss=2.26, w2v_ctc_loss=0.95, contrastive_loss=0, total=4175.34, n_correct=2581.27, ppl=4.79, accuracy=61.822, wps=20062.3, ups=2.4, wpb=8368.2, bsz=305.3, num_updates=52500, lr=6.17213e-05, gnorm=0.931, clip=0, loss_scale=16, train_wall=41, gb_free=17.9, wall=28477
2023-07-10 11:41:29 | INFO | train_inner | epoch 036:   1032 / 1474 loss=4.524, trans_loss=5.069, nll_loss=2.275, w2v_ctc_loss=0.921, contrastive_loss=0, total=4176.5, n_correct=2572.43, ppl=4.84, accuracy=61.593, wps=20114.4, ups=2.41, wpb=8358.2, bsz=301.7, num_updates=52600, lr=6.16626e-05, gnorm=0.938, clip=0, loss_scale=16, train_wall=41, gb_free=16.7, wall=28518
2023-07-10 11:42:11 | INFO | train_inner | epoch 036:   1132 / 1474 loss=4.52, trans_loss=5.067, nll_loss=2.273, w2v_ctc_loss=0.906, contrastive_loss=0, total=4130.46, n_correct=2546.95, ppl=4.83, accuracy=61.663, wps=19847.4, ups=2.4, wpb=8285.1, bsz=306.7, num_updates=52700, lr=6.16041e-05, gnorm=0.93, clip=0, loss_scale=16, train_wall=41, gb_free=18.1, wall=28560
2023-07-10 11:42:53 | INFO | train_inner | epoch 036:   1232 / 1474 loss=4.54, trans_loss=5.077, nll_loss=2.285, w2v_ctc_loss=0.943, contrastive_loss=0, total=4051.75, n_correct=2492.89, ppl=4.87, accuracy=61.526, wps=19627.2, ups=2.42, wpb=8125.4, bsz=280, num_updates=52800, lr=6.15457e-05, gnorm=0.972, clip=0, loss_scale=16, train_wall=41, gb_free=17.4, wall=28601
2023-07-10 11:43:34 | INFO | train_inner | epoch 036:   1332 / 1474 loss=4.531, trans_loss=5.069, nll_loss=2.276, w2v_ctc_loss=0.947, contrastive_loss=0, total=4108.74, n_correct=2533.79, ppl=4.84, accuracy=61.668, wps=19806.1, ups=2.41, wpb=8214.5, bsz=305.1, num_updates=52900, lr=6.14875e-05, gnorm=0.937, clip=0, loss_scale=16, train_wall=41, gb_free=16.3, wall=28643
2023-07-10 11:44:16 | INFO | train_inner | epoch 036:   1432 / 1474 loss=4.53, trans_loss=5.079, nll_loss=2.288, w2v_ctc_loss=0.916, contrastive_loss=0, total=4048.28, n_correct=2483.77, ppl=4.88, accuracy=61.354, wps=19359.6, ups=2.39, wpb=8099.7, bsz=278.8, num_updates=53000, lr=6.14295e-05, gnorm=0.96, clip=0, loss_scale=16, train_wall=41, gb_free=11.5, wall=28685
2023-07-10 11:44:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 11:44:56 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 4.142 | trans_loss 5.77 | nll_loss 3.083 | w2v_ctc_loss 0.256 | contrastive_loss 0.208 | total 4003.4 | n_correct 2363.8 | ppl 8.47 | accuracy 59.045 | uer 40.536 | wer 43.104 | raw_wer 43.104 | bleu 17.44 | wps 2384.5 | wpb 4003.4 | bsz 141.8 | num_updates 53042 | best_bleu 17.7
2023-07-10 11:44:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 53042 updates
2023-07-10 11:44:56 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.4405.pt
2023-07-10 11:44:58 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.4405.pt
2023-07-10 11:45:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.4405.pt (epoch 36 @ 53042 updates, score 17.44) (writing took 5.317212680994999 seconds)
2023-07-10 11:45:01 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-07-10 11:45:01 | INFO | train | epoch 036 | loss 4.525 | trans_loss 5.062 | nll_loss 2.267 | w2v_ctc_loss 0.945 | contrastive_loss 0 | total 4138.65 | n_correct 2555.64 | ppl 4.81 | accuracy 61.751 | wps 17928.4 | ups 2.17 | wpb 8277.3 | bsz 305.7 | num_updates 53042 | lr 6.14052e-05 | gnorm 0.936 | clip 0 | loss_scale 32 | train_wall 609 | gb_free 17.2 | wall 28730
2023-07-10 11:45:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 11:45:02 | INFO | fairseq.trainer | begin training epoch 37
2023-07-10 11:45:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 11:45:34 | INFO | train_inner | epoch 037:     58 / 1474 loss=4.519, trans_loss=5.05, nll_loss=2.251, w2v_ctc_loss=0.951, contrastive_loss=0, total=4092.98, n_correct=2541.8, ppl=4.76, accuracy=62.101, wps=10460.3, ups=1.28, wpb=8186.1, bsz=299.9, num_updates=53100, lr=6.13716e-05, gnorm=0.934, clip=0, loss_scale=32, train_wall=41, gb_free=15.7, wall=28763
2023-07-10 11:46:16 | INFO | train_inner | epoch 037:    158 / 1474 loss=4.53, trans_loss=5.055, nll_loss=2.258, w2v_ctc_loss=0.985, contrastive_loss=0, total=4124.56, n_correct=2548.77, ppl=4.78, accuracy=61.795, wps=19577.5, ups=2.38, wpb=8243, bsz=306.8, num_updates=53200, lr=6.13139e-05, gnorm=1.01, clip=0, loss_scale=32, train_wall=42, gb_free=16.7, wall=28805
2023-07-10 11:46:58 | INFO | train_inner | epoch 037:    258 / 1474 loss=4.49, trans_loss=5.036, nll_loss=2.234, w2v_ctc_loss=0.894, contrastive_loss=0, total=4188.93, n_correct=2609.4, ppl=4.71, accuracy=62.293, wps=20043.3, ups=2.39, wpb=8375.7, bsz=319.3, num_updates=53300, lr=6.12564e-05, gnorm=0.923, clip=0, loss_scale=32, train_wall=41, gb_free=15.3, wall=28847
2023-07-10 11:47:40 | INFO | train_inner | epoch 037:    358 / 1474 loss=4.509, trans_loss=5.053, nll_loss=2.254, w2v_ctc_loss=0.926, contrastive_loss=0, total=4171.05, n_correct=2584.48, ppl=4.77, accuracy=61.962, wps=19894.6, ups=2.39, wpb=8313.7, bsz=305.8, num_updates=53400, lr=6.1199e-05, gnorm=0.939, clip=0, loss_scale=32, train_wall=41, gb_free=16.3, wall=28888
2023-07-10 11:48:22 | INFO | train_inner | epoch 037:    458 / 1474 loss=4.527, trans_loss=5.063, nll_loss=2.269, w2v_ctc_loss=0.96, contrastive_loss=0, total=4184.96, n_correct=2577.43, ppl=4.82, accuracy=61.588, wps=19643.9, ups=2.36, wpb=8339.8, bsz=319, num_updates=53500, lr=6.11418e-05, gnorm=0.935, clip=0, loss_scale=32, train_wall=42, gb_free=13.8, wall=28931
2023-07-10 11:49:05 | INFO | train_inner | epoch 037:    558 / 1474 loss=4.514, trans_loss=5.051, nll_loss=2.253, w2v_ctc_loss=0.928, contrastive_loss=0, total=4091.86, n_correct=2540.3, ppl=4.77, accuracy=62.082, wps=19339.3, ups=2.36, wpb=8203.2, bsz=299.8, num_updates=53600, lr=6.10847e-05, gnorm=0.971, clip=0, loss_scale=32, train_wall=42, gb_free=16.8, wall=28973
2023-07-10 11:49:47 | INFO | train_inner | epoch 037:    658 / 1474 loss=4.524, trans_loss=5.057, nll_loss=2.261, w2v_ctc_loss=0.951, contrastive_loss=0, total=4096.37, n_correct=2525.15, ppl=4.79, accuracy=61.644, wps=19487.5, ups=2.37, wpb=8213.1, bsz=290.5, num_updates=53700, lr=6.10278e-05, gnorm=0.952, clip=0, loss_scale=32, train_wall=42, gb_free=15.4, wall=29016
2023-07-10 11:50:29 | INFO | train_inner | epoch 037:    758 / 1474 loss=4.515, trans_loss=5.053, nll_loss=2.256, w2v_ctc_loss=0.927, contrastive_loss=0, total=4124.05, n_correct=2557.4, ppl=4.78, accuracy=62.012, wps=19511.5, ups=2.36, wpb=8269.3, bsz=305.3, num_updates=53800, lr=6.09711e-05, gnorm=0.92, clip=0, loss_scale=32, train_wall=42, gb_free=14, wall=29058
2023-07-10 11:51:11 | INFO | train_inner | epoch 037:    858 / 1474 loss=4.521, trans_loss=5.05, nll_loss=2.253, w2v_ctc_loss=0.965, contrastive_loss=0, total=4161.41, n_correct=2585.2, ppl=4.77, accuracy=62.123, wps=19938.4, ups=2.4, wpb=8302.6, bsz=314.9, num_updates=53900, lr=6.09145e-05, gnorm=0.917, clip=0, loss_scale=32, train_wall=41, gb_free=16.1, wall=29100
2023-07-10 11:51:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-10 11:51:53 | INFO | train_inner | epoch 037:    959 / 1474 loss=4.532, trans_loss=5.065, nll_loss=2.271, w2v_ctc_loss=0.954, contrastive_loss=0, total=4102.47, n_correct=2533.12, ppl=4.83, accuracy=61.746, wps=19502.1, ups=2.37, wpb=8216.3, bsz=295, num_updates=54000, lr=6.08581e-05, gnorm=0.976, clip=0, loss_scale=16, train_wall=42, gb_free=16.2, wall=29142
2023-07-10 11:51:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 11:52:16 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 4.14 | trans_loss 5.785 | nll_loss 3.101 | w2v_ctc_loss 0.214 | contrastive_loss 0.206 | total 4003.4 | n_correct 2360.7 | ppl 8.58 | accuracy 58.967 | uer 40.873 | wer 43.783 | raw_wer 43.783 | bleu 17.13 | wps 2446.9 | wpb 4003.4 | bsz 141.8 | num_updates 54000 | best_bleu 17.7
2023-07-10 11:52:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54000 updates
2023-07-10 11:52:16 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_37_54000.pt
2023-07-10 11:52:18 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_37_54000.pt
2023-07-10 11:52:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_37_54000.pt (epoch 37 @ 54000 updates, score 17.13) (writing took 6.249452190997545 seconds)
2023-07-10 11:53:05 | INFO | train_inner | epoch 037:   1059 / 1474 loss=4.513, trans_loss=5.049, nll_loss=2.251, w2v_ctc_loss=0.927, contrastive_loss=0, total=4162.64, n_correct=2588.35, ppl=4.76, accuracy=62.18, wps=11671.2, ups=1.4, wpb=8346.4, bsz=319.8, num_updates=54100, lr=6.08018e-05, gnorm=0.939, clip=0, loss_scale=16, train_wall=42, gb_free=16.9, wall=29213
2023-07-10 11:53:47 | INFO | train_inner | epoch 037:   1159 / 1474 loss=4.522, trans_loss=5.059, nll_loss=2.263, w2v_ctc_loss=0.943, contrastive_loss=0, total=4176.35, n_correct=2581.07, ppl=4.8, accuracy=61.802, wps=19578.4, ups=2.34, wpb=8352.9, bsz=312.1, num_updates=54200, lr=6.07457e-05, gnorm=0.925, clip=0, loss_scale=16, train_wall=42, gb_free=16.4, wall=29256
2023-07-10 11:54:30 | INFO | train_inner | epoch 037:   1259 / 1474 loss=4.539, trans_loss=5.06, nll_loss=2.264, w2v_ctc_loss=0.997, contrastive_loss=0, total=4167.2, n_correct=2579.06, ppl=4.8, accuracy=61.89, wps=19725.8, ups=2.37, wpb=8336.4, bsz=311.9, num_updates=54300, lr=6.06897e-05, gnorm=0.959, clip=0, loss_scale=16, train_wall=42, gb_free=16.4, wall=29298
2023-07-10 11:55:12 | INFO | train_inner | epoch 037:   1359 / 1474 loss=4.55, trans_loss=5.07, nll_loss=2.276, w2v_ctc_loss=1.008, contrastive_loss=0, total=4072.63, n_correct=2508.02, ppl=4.84, accuracy=61.582, wps=19251.1, ups=2.37, wpb=8132.6, bsz=286, num_updates=54400, lr=6.06339e-05, gnorm=1.015, clip=0, loss_scale=16, train_wall=42, gb_free=16.3, wall=29340
2023-07-10 11:55:54 | INFO | train_inner | epoch 037:   1459 / 1474 loss=4.522, trans_loss=5.059, nll_loss=2.264, w2v_ctc_loss=0.939, contrastive_loss=0, total=4155.97, n_correct=2568.54, ppl=4.8, accuracy=61.804, wps=19826.1, ups=2.38, wpb=8318.1, bsz=305.1, num_updates=54500, lr=6.05783e-05, gnorm=0.915, clip=0, loss_scale=16, train_wall=42, gb_free=16.4, wall=29382
2023-07-10 11:56:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 11:56:22 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 4.134 | trans_loss 5.778 | nll_loss 3.095 | w2v_ctc_loss 0.212 | contrastive_loss 0.21 | total 4003.4 | n_correct 2356 | ppl 8.55 | accuracy 58.85 | uer 41.138 | wer 43.951 | raw_wer 43.951 | bleu 17.43 | wps 2596 | wpb 4003.4 | bsz 141.8 | num_updates 54515 | best_bleu 17.7
2023-07-10 11:56:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54515 updates
2023-07-10 11:56:22 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.4301.pt
2023-07-10 11:56:24 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.4301.pt
2023-07-10 11:56:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.4301.pt (epoch 37 @ 54515 updates, score 17.43) (writing took 5.060843583021779 seconds)
2023-07-10 11:56:27 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-07-10 11:56:27 | INFO | train | epoch 037 | loss 4.522 | trans_loss 5.056 | nll_loss 2.259 | w2v_ctc_loss 0.95 | contrastive_loss 0 | total 4138.98 | n_correct 2562.01 | ppl 4.79 | accuracy 61.899 | wps 17778 | ups 2.15 | wpb 8277.9 | bsz 305.8 | num_updates 54515 | lr 6.05699e-05 | gnorm 0.95 | clip 0 | loss_scale 16 | train_wall 614 | gb_free 13.4 | wall 29416
2023-07-10 11:56:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 11:56:28 | INFO | fairseq.trainer | begin training epoch 38
2023-07-10 11:56:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 11:57:11 | INFO | train_inner | epoch 038:     85 / 1474 loss=4.517, trans_loss=5.046, nll_loss=2.245, w2v_ctc_loss=0.961, contrastive_loss=0, total=4085.19, n_correct=2534.95, ppl=4.74, accuracy=62.052, wps=10546.2, ups=1.29, wpb=8165.3, bsz=293.6, num_updates=54600, lr=6.05228e-05, gnorm=0.941, clip=0, loss_scale=16, train_wall=41, gb_free=17.3, wall=29460
2023-07-10 11:57:53 | INFO | train_inner | epoch 038:    185 / 1474 loss=4.518, trans_loss=5.041, nll_loss=2.24, w2v_ctc_loss=0.975, contrastive_loss=0, total=4081.12, n_correct=2533.31, ppl=4.72, accuracy=62.074, wps=19445.8, ups=2.38, wpb=8171.7, bsz=292.5, num_updates=54700, lr=6.04674e-05, gnorm=0.981, clip=0, loss_scale=16, train_wall=42, gb_free=17.2, wall=29502
2023-07-10 11:58:35 | INFO | train_inner | epoch 038:    285 / 1474 loss=4.512, trans_loss=5.045, nll_loss=2.244, w2v_ctc_loss=0.944, contrastive_loss=0, total=4073.75, n_correct=2527.55, ppl=4.74, accuracy=62.045, wps=19503, ups=2.39, wpb=8155.6, bsz=295.7, num_updates=54800, lr=6.04122e-05, gnorm=0.956, clip=0, loss_scale=16, train_wall=41, gb_free=17.2, wall=29544
2023-07-10 11:59:17 | INFO | train_inner | epoch 038:    385 / 1474 loss=4.494, trans_loss=5.044, nll_loss=2.243, w2v_ctc_loss=0.892, contrastive_loss=0, total=4173.43, n_correct=2588.71, ppl=4.73, accuracy=62.028, wps=20020.2, ups=2.4, wpb=8349.9, bsz=308.2, num_updates=54900, lr=6.03572e-05, gnorm=0.953, clip=0, loss_scale=16, train_wall=41, gb_free=14.2, wall=29585
2023-07-10 11:59:59 | INFO | train_inner | epoch 038:    485 / 1474 loss=4.48, trans_loss=5.047, nll_loss=2.249, w2v_ctc_loss=0.836, contrastive_loss=0, total=4192.03, n_correct=2601.26, ppl=4.75, accuracy=62.053, wps=19970.7, ups=2.38, wpb=8374.4, bsz=312, num_updates=55000, lr=6.03023e-05, gnorm=0.93, clip=0, loss_scale=16, train_wall=42, gb_free=16.5, wall=29627
1.0
tensor(0.0271, device='cuda:0')
2023-07-10 12:00:41 | INFO | train_inner | epoch 038:    585 / 1474 loss=4.533, trans_loss=5.059, nll_loss=2.264, w2v_ctc_loss=0.987, contrastive_loss=0, total=4172.44, n_correct=2569.25, ppl=4.8, accuracy=61.577, wps=19484.5, ups=2.34, wpb=8332.4, bsz=308.8, num_updates=55100, lr=6.02475e-05, gnorm=0.929, clip=0, loss_scale=16, train_wall=42, gb_free=16.4, wall=29670
2023-07-10 12:01:24 | INFO | train_inner | epoch 038:    685 / 1474 loss=4.519, trans_loss=5.034, nll_loss=2.232, w2v_ctc_loss=0.998, contrastive_loss=0, total=4179.22, n_correct=2605.57, ppl=4.7, accuracy=62.346, wps=19653.8, ups=2.35, wpb=8367.5, bsz=322.5, num_updates=55200, lr=6.01929e-05, gnorm=0.988, clip=0, loss_scale=16, train_wall=42, gb_free=13.5, wall=29713
2023-07-10 12:02:06 | INFO | train_inner | epoch 038:    785 / 1474 loss=4.488, trans_loss=5.042, nll_loss=2.242, w2v_ctc_loss=0.873, contrastive_loss=0, total=4180.46, n_correct=2603.79, ppl=4.73, accuracy=62.285, wps=19802.5, ups=2.37, wpb=8358.2, bsz=325.7, num_updates=55300, lr=6.01385e-05, gnorm=0.952, clip=0, loss_scale=16, train_wall=42, gb_free=16.2, wall=29755
2023-07-10 12:02:48 | INFO | train_inner | epoch 038:    885 / 1474 loss=4.511, trans_loss=5.047, nll_loss=2.248, w2v_ctc_loss=0.93, contrastive_loss=0, total=4122.77, n_correct=2561.56, ppl=4.75, accuracy=62.132, wps=19897.7, ups=2.41, wpb=8263.8, bsz=311.9, num_updates=55400, lr=6.00842e-05, gnorm=0.964, clip=0, loss_scale=16, train_wall=41, gb_free=15.8, wall=29796
2023-07-10 12:03:30 | INFO | train_inner | epoch 038:    985 / 1474 loss=4.545, trans_loss=5.056, nll_loss=2.26, w2v_ctc_loss=1.01, contrastive_loss=0, total=4116.2, n_correct=2546.21, ppl=4.79, accuracy=61.858, wps=19601.1, ups=2.37, wpb=8278.8, bsz=301.5, num_updates=55500, lr=6.003e-05, gnorm=0.964, clip=0, loss_scale=16, train_wall=42, gb_free=16.6, wall=29839
2023-07-10 12:04:12 | INFO | train_inner | epoch 038:   1085 / 1474 loss=4.501, trans_loss=5.049, nll_loss=2.251, w2v_ctc_loss=0.905, contrastive_loss=0, total=4248.59, n_correct=2640.18, ppl=4.76, accuracy=62.142, wps=20017, ups=2.36, wpb=8469.8, bsz=328.8, num_updates=55600, lr=5.9976e-05, gnorm=0.974, clip=0, loss_scale=16, train_wall=42, gb_free=16.8, wall=29881
2023-07-10 12:04:54 | INFO | train_inner | epoch 038:   1185 / 1474 loss=4.544, trans_loss=5.068, nll_loss=2.274, w2v_ctc_loss=0.984, contrastive_loss=0, total=4077.59, n_correct=2511.96, ppl=4.84, accuracy=61.604, wps=19376.1, ups=2.37, wpb=8172.2, bsz=287.4, num_updates=55700, lr=5.99222e-05, gnorm=0.971, clip=0, loss_scale=16, train_wall=42, gb_free=14.5, wall=29923
2023-07-10 12:05:37 | INFO | train_inner | epoch 038:   1285 / 1474 loss=4.526, trans_loss=5.067, nll_loss=2.273, w2v_ctc_loss=0.941, contrastive_loss=0, total=4146.3, n_correct=2558.49, ppl=4.83, accuracy=61.705, wps=19567.5, ups=2.37, wpb=8267.4, bsz=295.6, num_updates=55800, lr=5.98684e-05, gnorm=0.946, clip=0, loss_scale=16, train_wall=42, gb_free=17.9, wall=29965
2023-07-10 12:06:18 | INFO | train_inner | epoch 038:   1385 / 1474 loss=4.531, trans_loss=5.062, nll_loss=2.268, w2v_ctc_loss=0.976, contrastive_loss=0, total=4156.39, n_correct=2569.03, ppl=4.82, accuracy=61.809, wps=19942.5, ups=2.41, wpb=8282.7, bsz=310.5, num_updates=55900, lr=5.98149e-05, gnorm=0.994, clip=0, loss_scale=16, train_wall=41, gb_free=16.8, wall=30007
2023-07-10 12:06:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
1.0
tensor(0.0271, device='cuda:4')
1.0
tensor(0.0271, device='cuda:6')
1.0
tensor(0.0271, device='cuda:3')
1.0
tensor(0.0271, device='cuda:2')
1.0
tensor(0.0271, device='cuda:7')
1.0
tensor(0.0271, device='cuda:1')
1.0
tensor(0.0271, device='cuda:5')
2023-07-10 12:07:17 | INFO | dev_st | epoch 038 | valid on 'dev_st' subset | loss 4.132 | trans_loss 5.764 | nll_loss 3.077 | w2v_ctc_loss 0.241 | contrastive_loss 0.201 | total 4003.4 | n_correct 2370.5 | ppl 8.44 | accuracy 59.212 | uer 40.907 | wer 43.365 | raw_wer 43.365 | bleu 17.29 | wps 2724.9 | wpb 4003.4 | bsz 141.8 | num_updates 55989 | best_bleu 17.7
2023-07-10 12:07:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 55989 updates
2023-07-10 12:07:17 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.2902.pt
2023-07-10 12:07:19 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.2902.pt
2023-07-10 12:07:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.2902.pt (epoch 38 @ 55989 updates, score 17.29) (writing took 5.229866493027657 seconds)
2023-07-10 12:07:22 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-07-10 12:07:22 | INFO | train | epoch 038 | loss 4.517 | trans_loss 5.051 | nll_loss 2.253 | w2v_ctc_loss 0.947 | contrastive_loss 0 | total 4138.65 | n_correct 2565.2 | ppl 4.77 | accuracy 61.982 | wps 18636.1 | ups 2.25 | wpb 8277.3 | bsz 305.7 | num_updates 55989 | lr 5.97673e-05 | gnorm 0.961 | clip 0 | loss_scale 32 | train_wall 614 | gb_free 17 | wall 30071
2023-07-10 12:07:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 12:07:22 | INFO | fairseq.trainer | begin training epoch 39
2023-07-10 12:07:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 12:07:35 | INFO | train_inner | epoch 039:     11 / 1474 loss=4.535, trans_loss=5.059, nll_loss=2.262, w2v_ctc_loss=0.985, contrastive_loss=0, total=4033.2, n_correct=2498.68, ppl=4.8, accuracy=61.953, wps=10553.7, ups=1.31, wpb=8061.8, bsz=285.8, num_updates=56000, lr=5.97614e-05, gnorm=0.989, clip=0, loss_scale=32, train_wall=41, gb_free=17.6, wall=30083
2023-07-10 12:07:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 12:07:57 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 4.128 | trans_loss 5.768 | nll_loss 3.078 | w2v_ctc_loss 0.216 | contrastive_loss 0.202 | total 4003.4 | n_correct 2368.8 | ppl 8.44 | accuracy 59.17 | uer 41.226 | wer 43.608 | raw_wer 43.608 | bleu 17.57 | wps 2512.7 | wpb 4003.4 | bsz 141.8 | num_updates 56000 | best_bleu 17.7
2023-07-10 12:07:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 56000 updates
2023-07-10 12:07:57 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_39_56000.pt
2023-07-10 12:07:59 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_39_56000.pt
2023-07-10 12:08:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_39_56000.pt (epoch 39 @ 56000 updates, score 17.57) (writing took 6.197668206994422 seconds)
2023-07-10 12:08:45 | INFO | train_inner | epoch 039:    111 / 1474 loss=4.485, trans_loss=5.038, nll_loss=2.234, w2v_ctc_loss=0.873, contrastive_loss=0, total=4057.77, n_correct=2530.94, ppl=4.7, accuracy=62.373, wps=11500, ups=1.42, wpb=8111, bsz=286.4, num_updates=56100, lr=5.97081e-05, gnorm=0.922, clip=0, loss_scale=32, train_wall=41, gb_free=17.7, wall=30154
2023-07-10 12:09:27 | INFO | train_inner | epoch 039:    211 / 1474 loss=4.494, trans_loss=5.038, nll_loss=2.235, w2v_ctc_loss=0.904, contrastive_loss=0, total=4134.99, n_correct=2574.63, ppl=4.71, accuracy=62.264, wps=19863.2, ups=2.4, wpb=8260.2, bsz=300.5, num_updates=56200, lr=5.9655e-05, gnorm=0.954, clip=0, loss_scale=32, train_wall=41, gb_free=16.1, wall=30195
2023-07-10 12:10:09 | INFO | train_inner | epoch 039:    311 / 1474 loss=4.514, trans_loss=5.034, nll_loss=2.23, w2v_ctc_loss=0.972, contrastive_loss=0, total=4135.88, n_correct=2582.02, ppl=4.69, accuracy=62.43, wps=19702, ups=2.38, wpb=8288.7, bsz=299.6, num_updates=56300, lr=5.9602e-05, gnorm=0.931, clip=0, loss_scale=32, train_wall=42, gb_free=13.6, wall=30237
2023-07-10 12:10:51 | INFO | train_inner | epoch 039:    411 / 1474 loss=4.536, trans_loss=5.047, nll_loss=2.248, w2v_ctc_loss=1.015, contrastive_loss=0, total=4128.52, n_correct=2561.38, ppl=4.75, accuracy=62.041, wps=19650.7, ups=2.38, wpb=8271.5, bsz=312.2, num_updates=56400, lr=5.95491e-05, gnorm=1.008, clip=0, loss_scale=32, train_wall=42, gb_free=13.1, wall=30280
2023-07-10 12:11:33 | INFO | train_inner | epoch 039:    511 / 1474 loss=4.496, trans_loss=5.039, nll_loss=2.237, w2v_ctc_loss=0.905, contrastive_loss=0, total=4143.39, n_correct=2573.8, ppl=4.71, accuracy=62.118, wps=19820.7, ups=2.38, wpb=8311.3, bsz=311.6, num_updates=56500, lr=5.94964e-05, gnorm=0.928, clip=0, loss_scale=32, train_wall=42, gb_free=17.2, wall=30321
2023-07-10 12:12:15 | INFO | train_inner | epoch 039:    611 / 1474 loss=4.493, trans_loss=5.046, nll_loss=2.245, w2v_ctc_loss=0.882, contrastive_loss=0, total=4131.41, n_correct=2562.06, ppl=4.74, accuracy=62.014, wps=19656, ups=2.38, wpb=8255.9, bsz=302.8, num_updates=56600, lr=5.94438e-05, gnorm=0.931, clip=0, loss_scale=32, train_wall=42, gb_free=16.2, wall=30363
2023-07-10 12:12:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-10 12:12:57 | INFO | train_inner | epoch 039:    712 / 1474 loss=4.488, trans_loss=5.037, nll_loss=2.235, w2v_ctc_loss=0.896, contrastive_loss=0, total=4142.23, n_correct=2577.9, ppl=4.71, accuracy=62.235, wps=19749.6, ups=2.39, wpb=8264, bsz=306.9, num_updates=56700, lr=5.93914e-05, gnorm=0.94, clip=0, loss_scale=16, train_wall=41, gb_free=16.4, wall=30405
2023-07-10 12:13:39 | INFO | train_inner | epoch 039:    812 / 1474 loss=4.52, trans_loss=5.051, nll_loss=2.253, w2v_ctc_loss=0.957, contrastive_loss=0, total=4165.72, n_correct=2577.4, ppl=4.77, accuracy=61.872, wps=19653.7, ups=2.36, wpb=8328.4, bsz=307.4, num_updates=56800, lr=5.93391e-05, gnorm=0.958, clip=0, loss_scale=16, train_wall=42, gb_free=15.6, wall=30448
2023-07-10 12:14:21 | INFO | train_inner | epoch 039:    912 / 1474 loss=4.516, trans_loss=5.047, nll_loss=2.248, w2v_ctc_loss=0.951, contrastive_loss=0, total=4131.2, n_correct=2563.16, ppl=4.75, accuracy=62.044, wps=19886.7, ups=2.4, wpb=8269.9, bsz=300.7, num_updates=56900, lr=5.92869e-05, gnorm=0.928, clip=0, loss_scale=16, train_wall=41, gb_free=12.7, wall=30489
2023-07-10 12:15:03 | INFO | train_inner | epoch 039:   1012 / 1474 loss=4.511, trans_loss=5.055, nll_loss=2.259, w2v_ctc_loss=0.925, contrastive_loss=0, total=4199.31, n_correct=2592.56, ppl=4.79, accuracy=61.738, wps=19827.5, ups=2.36, wpb=8383.9, bsz=319.2, num_updates=57000, lr=5.92349e-05, gnorm=0.934, clip=0, loss_scale=16, train_wall=42, gb_free=16.9, wall=30532
2023-07-10 12:15:45 | INFO | train_inner | epoch 039:   1112 / 1474 loss=4.495, trans_loss=5.04, nll_loss=2.24, w2v_ctc_loss=0.907, contrastive_loss=0, total=4192.7, n_correct=2612.87, ppl=4.72, accuracy=62.32, wps=20025.3, ups=2.39, wpb=8370.1, bsz=321.8, num_updates=57100, lr=5.9183e-05, gnorm=0.907, clip=0, loss_scale=16, train_wall=41, gb_free=12.6, wall=30573
2023-07-10 12:16:27 | INFO | train_inner | epoch 039:   1212 / 1474 loss=4.496, trans_loss=5.048, nll_loss=2.25, w2v_ctc_loss=0.881, contrastive_loss=0, total=4126.68, n_correct=2558.34, ppl=4.76, accuracy=61.995, wps=19773, ups=2.39, wpb=8264.1, bsz=309.2, num_updates=57200, lr=5.91312e-05, gnorm=0.921, clip=0, loss_scale=16, train_wall=41, gb_free=16.9, wall=30615
2023-07-10 12:17:08 | INFO | train_inner | epoch 039:   1312 / 1474 loss=4.488, trans_loss=5.048, nll_loss=2.25, w2v_ctc_loss=0.859, contrastive_loss=0, total=4176.04, n_correct=2594.21, ppl=4.76, accuracy=62.121, wps=19981.6, ups=2.39, wpb=8351.4, bsz=315.4, num_updates=57300, lr=5.90796e-05, gnorm=0.906, clip=0, loss_scale=16, train_wall=41, gb_free=17.5, wall=30657
2023-07-10 12:17:50 | INFO | train_inner | epoch 039:   1412 / 1474 loss=4.503, trans_loss=5.057, nll_loss=2.259, w2v_ctc_loss=0.883, contrastive_loss=0, total=4055.22, n_correct=2513.31, ppl=4.79, accuracy=61.977, wps=19545.5, ups=2.41, wpb=8107, bsz=278.4, num_updates=57400, lr=5.90281e-05, gnorm=0.938, clip=0, loss_scale=16, train_wall=41, gb_free=15.3, wall=30698
2023-07-10 12:18:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 12:18:38 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 4.115 | trans_loss 5.749 | nll_loss 3.055 | w2v_ctc_loss 0.221 | contrastive_loss 0.196 | total 4003.4 | n_correct 2379.4 | ppl 8.31 | accuracy 59.434 | uer 39.827 | wer 42.426 | raw_wer 42.426 | bleu 17.65 | wps 2416 | wpb 4003.4 | bsz 141.8 | num_updates 57462 | best_bleu 17.7
2023-07-10 12:18:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 57462 updates
2023-07-10 12:18:38 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.6507.pt
2023-07-10 12:18:40 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.6507.pt
2023-07-10 12:18:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint.best_bleu_17.6507.pt (epoch 39 @ 57462 updates, score 17.65) (writing took 5.255569531000219 seconds)
2023-07-10 12:18:43 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-07-10 12:18:43 | INFO | train | epoch 039 | loss 4.503 | trans_loss 5.045 | nll_loss 2.245 | w2v_ctc_loss 0.916 | contrastive_loss 0 | total 4138.73 | n_correct 2570.37 | ppl 4.74 | accuracy 62.105 | wps 17891.3 | ups 2.16 | wpb 8277.4 | bsz 305.7 | num_updates 57462 | lr 5.89963e-05 | gnorm 0.935 | clip 0 | loss_scale 16 | train_wall 610 | gb_free 15.9 | wall 30752
2023-07-10 12:18:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 12:18:44 | INFO | fairseq.trainer | begin training epoch 40
2023-07-10 12:18:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 12:19:08 | INFO | train_inner | epoch 040:     38 / 1474 loss=4.516, trans_loss=5.047, nll_loss=2.249, w2v_ctc_loss=0.949, contrastive_loss=0, total=4169.65, n_correct=2588.54, ppl=4.75, accuracy=62.081, wps=10702.4, ups=1.28, wpb=8345.7, bsz=312, num_updates=57500, lr=5.89768e-05, gnorm=0.915, clip=0, loss_scale=16, train_wall=41, gb_free=16.3, wall=30776
2023-07-10 12:19:49 | INFO | train_inner | epoch 040:    138 / 1474 loss=4.477, trans_loss=5.024, nll_loss=2.218, w2v_ctc_loss=0.887, contrastive_loss=0, total=4150.02, n_correct=2596.97, ppl=4.65, accuracy=62.577, wps=19904.3, ups=2.4, wpb=8287.2, bsz=305.2, num_updates=57600, lr=5.89256e-05, gnorm=0.955, clip=0, loss_scale=16, train_wall=41, gb_free=18.1, wall=30818
2023-07-10 12:20:31 | INFO | train_inner | epoch 040:    238 / 1474 loss=4.48, trans_loss=5.029, nll_loss=2.224, w2v_ctc_loss=0.88, contrastive_loss=0, total=4101.15, n_correct=2561.8, ppl=4.67, accuracy=62.465, wps=19982.3, ups=2.43, wpb=8217.1, bsz=299.8, num_updates=57700, lr=5.88745e-05, gnorm=0.918, clip=0, loss_scale=16, train_wall=41, gb_free=10.9, wall=30859
2023-07-10 12:21:12 | INFO | train_inner | epoch 040:    338 / 1474 loss=4.471, trans_loss=5.031, nll_loss=2.228, w2v_ctc_loss=0.849, contrastive_loss=0, total=4161.74, n_correct=2602.16, ppl=4.68, accuracy=62.526, wps=20075.8, ups=2.41, wpb=8315.5, bsz=321.1, num_updates=57800, lr=5.88235e-05, gnorm=0.961, clip=0, loss_scale=16, train_wall=41, gb_free=17.4, wall=30901
2023-07-10 12:21:54 | INFO | train_inner | epoch 040:    438 / 1474 loss=4.501, trans_loss=5.031, nll_loss=2.227, w2v_ctc_loss=0.948, contrastive_loss=0, total=4141.51, n_correct=2584.13, ppl=4.68, accuracy=62.396, wps=19646.5, ups=2.37, wpb=8285.4, bsz=310.5, num_updates=57900, lr=5.87727e-05, gnorm=0.943, clip=0, loss_scale=16, train_wall=42, gb_free=16.7, wall=30943
2023-07-10 12:22:36 | INFO | train_inner | epoch 040:    538 / 1474 loss=4.477, trans_loss=5.033, nll_loss=2.229, w2v_ctc_loss=0.859, contrastive_loss=0, total=4167.53, n_correct=2599.7, ppl=4.69, accuracy=62.38, wps=19946, ups=2.39, wpb=8339.8, bsz=315.5, num_updates=58000, lr=5.8722e-05, gnorm=0.908, clip=0, loss_scale=16, train_wall=41, gb_free=16.5, wall=30985
2023-07-10 12:22:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 12:22:59 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 4.138 | trans_loss 5.783 | nll_loss 3.099 | w2v_ctc_loss 0.217 | contrastive_loss 0.199 | total 4003.4 | n_correct 2363 | ppl 8.57 | accuracy 59.025 | uer 41.226 | wer 43.652 | raw_wer 43.652 | bleu 17.63 | wps 2512.8 | wpb 4003.4 | bsz 141.8 | num_updates 58000 | best_bleu 17.7
2023-07-10 12:22:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58000 updates
2023-07-10 12:22:59 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_40_58000.pt
2023-07-10 12:23:01 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_40_58000.pt
2023-07-10 12:23:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_40_58000.pt (epoch 40 @ 58000 updates, score 17.63) (writing took 6.226527229009662 seconds)
2023-07-10 12:23:47 | INFO | train_inner | epoch 040:    638 / 1474 loss=4.492, trans_loss=5.044, nll_loss=2.243, w2v_ctc_loss=0.874, contrastive_loss=0, total=4118.6, n_correct=2560.62, ppl=4.73, accuracy=62.172, wps=11695, ups=1.42, wpb=8261.6, bsz=298.4, num_updates=58100, lr=5.86715e-05, gnorm=0.938, clip=0, loss_scale=16, train_wall=41, gb_free=12.8, wall=31055
2023-07-10 12:24:28 | INFO | train_inner | epoch 040:    738 / 1474 loss=4.478, trans_loss=5.036, nll_loss=2.234, w2v_ctc_loss=0.853, contrastive_loss=0, total=4137.91, n_correct=2581.47, ppl=4.7, accuracy=62.386, wps=19960.7, ups=2.41, wpb=8275.7, bsz=308.3, num_updates=58200, lr=5.8621e-05, gnorm=0.901, clip=0, loss_scale=16, train_wall=41, gb_free=16.5, wall=31097
2023-07-10 12:25:10 | INFO | train_inner | epoch 040:    838 / 1474 loss=4.505, trans_loss=5.038, nll_loss=2.238, w2v_ctc_loss=0.946, contrastive_loss=0, total=4214.92, n_correct=2625.1, ppl=4.72, accuracy=62.281, wps=19902.2, ups=2.36, wpb=8418.8, bsz=329.3, num_updates=58300, lr=5.85707e-05, gnorm=0.932, clip=0, loss_scale=16, train_wall=42, gb_free=16.9, wall=31139
2023-07-10 12:25:52 | INFO | train_inner | epoch 040:    938 / 1474 loss=4.499, trans_loss=5.047, nll_loss=2.247, w2v_ctc_loss=0.892, contrastive_loss=0, total=4092.24, n_correct=2539.24, ppl=4.75, accuracy=62.05, wps=19643.3, ups=2.39, wpb=8205.7, bsz=293.6, num_updates=58400, lr=5.85206e-05, gnorm=0.972, clip=0, loss_scale=16, train_wall=41, gb_free=15.4, wall=31181
2023-07-10 12:26:34 | INFO | train_inner | epoch 040:   1038 / 1474 loss=4.507, trans_loss=5.053, nll_loss=2.255, w2v_ctc_loss=0.908, contrastive_loss=0, total=4119.93, n_correct=2550.21, ppl=4.77, accuracy=61.899, wps=19863.5, ups=2.41, wpb=8234.6, bsz=287.5, num_updates=58500, lr=5.84705e-05, gnorm=0.963, clip=0, loss_scale=16, train_wall=41, gb_free=16.2, wall=31222
2023-07-10 12:27:15 | INFO | train_inner | epoch 040:   1138 / 1474 loss=4.517, trans_loss=5.048, nll_loss=2.249, w2v_ctc_loss=0.947, contrastive_loss=0, total=4124.74, n_correct=2562.26, ppl=4.75, accuracy=62.119, wps=19772.4, ups=2.39, wpb=8268.2, bsz=298.3, num_updates=58600, lr=5.84206e-05, gnorm=0.957, clip=0, loss_scale=16, train_wall=41, gb_free=17.1, wall=31264
2023-07-10 12:27:57 | INFO | train_inner | epoch 040:   1238 / 1474 loss=4.49, trans_loss=5.04, nll_loss=2.24, w2v_ctc_loss=0.887, contrastive_loss=0, total=4198.52, n_correct=2620.13, ppl=4.72, accuracy=62.406, wps=20100.3, ups=2.4, wpb=8382, bsz=310.8, num_updates=58700, lr=5.83708e-05, gnorm=0.919, clip=0, loss_scale=16, train_wall=41, gb_free=17.4, wall=31306
2023-07-10 12:28:39 | INFO | train_inner | epoch 040:   1338 / 1474 loss=4.503, trans_loss=5.046, nll_loss=2.247, w2v_ctc_loss=0.912, contrastive_loss=0, total=4124.38, n_correct=2559.42, ppl=4.75, accuracy=62.056, wps=19679.4, ups=2.39, wpb=8247.5, bsz=306, num_updates=58800, lr=5.83212e-05, gnorm=0.94, clip=0, loss_scale=32, train_wall=41, gb_free=16.6, wall=31348
2023-07-10 12:29:21 | INFO | train_inner | epoch 040:   1438 / 1474 loss=4.506, trans_loss=5.048, nll_loss=2.249, w2v_ctc_loss=0.917, contrastive_loss=0, total=4121.8, n_correct=2562.69, ppl=4.76, accuracy=62.174, wps=19780.9, ups=2.4, wpb=8233.2, bsz=304.3, num_updates=58900, lr=5.82717e-05, gnorm=0.948, clip=0, loss_scale=32, train_wall=41, gb_free=16, wall=31389
2023-07-10 12:29:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 12:29:57 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 4.141 | trans_loss 5.758 | nll_loss 3.071 | w2v_ctc_loss 0.282 | contrastive_loss 0.2 | total 4003.4 | n_correct 2381.6 | ppl 8.4 | accuracy 59.489 | uer 40.682 | wer 43.045 | raw_wer 43.045 | bleu 17.87 | wps 2656.9 | wpb 4003.4 | bsz 141.8 | num_updates 58936 | best_bleu 17.87
2023-07-10 12:29:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58936 updates
2023-07-10 12:29:57 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 12:30:01 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt
2023-07-10 12:30:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_best.pt (epoch 40 @ 58936 updates, score 17.87) (writing took 8.375219737994485 seconds)
2023-07-10 12:30:06 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-07-10 12:30:06 | INFO | train | epoch 040 | loss 4.493 | trans_loss 5.039 | nll_loss 2.238 | w2v_ctc_loss 0.898 | contrastive_loss 0 | total 4138.65 | n_correct 2577.51 | ppl 4.72 | accuracy 62.279 | wps 17882.2 | ups 2.16 | wpb 8277.3 | bsz 305.7 | num_updates 58936 | lr 5.82539e-05 | gnorm 0.94 | clip 0 | loss_scale 32 | train_wall 608 | gb_free 16.1 | wall 31434
2023-07-10 12:30:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 12:30:06 | INFO | fairseq.trainer | begin training epoch 41
2023-07-10 12:30:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 12:30:41 | INFO | train_inner | epoch 041:     64 / 1474 loss=4.487, trans_loss=5.031, nll_loss=2.226, w2v_ctc_loss=0.91, contrastive_loss=0, total=4088.95, n_correct=2552.13, ppl=4.68, accuracy=62.415, wps=10126.5, ups=1.24, wpb=8146.4, bsz=295.6, num_updates=59000, lr=5.82223e-05, gnorm=0.961, clip=0, loss_scale=32, train_wall=41, gb_free=17.2, wall=31470
2023-07-10 12:30:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-10 12:31:24 | INFO | train_inner | epoch 041:    165 / 1474 loss=4.45, trans_loss=5.013, nll_loss=2.204, w2v_ctc_loss=0.822, contrastive_loss=0, total=4143.14, n_correct=2601.44, ppl=4.61, accuracy=62.789, wps=19577.3, ups=2.36, wpb=8291.7, bsz=311.6, num_updates=59100, lr=5.8173e-05, gnorm=0.913, clip=0, loss_scale=16, train_wall=42, gb_free=11.7, wall=31512
2023-07-10 12:32:05 | INFO | train_inner | epoch 041:    265 / 1474 loss=4.458, trans_loss=5.021, nll_loss=2.215, w2v_ctc_loss=0.834, contrastive_loss=0, total=4180.79, n_correct=2618.04, ppl=4.64, accuracy=62.621, wps=20055.4, ups=2.4, wpb=8348.8, bsz=318.8, num_updates=59200, lr=5.81238e-05, gnorm=0.899, clip=0, loss_scale=16, train_wall=41, gb_free=17.2, wall=31554
2023-07-10 12:32:47 | INFO | train_inner | epoch 041:    365 / 1474 loss=4.461, trans_loss=5.03, nll_loss=2.225, w2v_ctc_loss=0.811, contrastive_loss=0, total=4152.45, n_correct=2597.87, ppl=4.68, accuracy=62.562, wps=19959, ups=2.4, wpb=8312.3, bsz=306.5, num_updates=59300, lr=5.80748e-05, gnorm=0.903, clip=0, loss_scale=16, train_wall=41, gb_free=15.2, wall=31595
2023-07-10 12:33:28 | INFO | train_inner | epoch 041:    465 / 1474 loss=4.466, trans_loss=5.029, nll_loss=2.224, w2v_ctc_loss=0.833, contrastive_loss=0, total=4144.35, n_correct=2589.74, ppl=4.67, accuracy=62.488, wps=19917, ups=2.4, wpb=8294.8, bsz=303.5, num_updates=59400, lr=5.80259e-05, gnorm=0.941, clip=0, loss_scale=16, train_wall=41, gb_free=15.5, wall=31637
2023-07-10 12:34:10 | INFO | train_inner | epoch 041:    565 / 1474 loss=4.498, trans_loss=5.028, nll_loss=2.223, w2v_ctc_loss=0.938, contrastive_loss=0, total=4145.57, n_correct=2591.88, ppl=4.67, accuracy=62.522, wps=19828.6, ups=2.39, wpb=8304, bsz=306.7, num_updates=59500, lr=5.79771e-05, gnorm=0.973, clip=0, loss_scale=16, train_wall=41, gb_free=14.7, wall=31679
2023-07-10 12:34:52 | INFO | train_inner | epoch 041:    665 / 1474 loss=4.495, trans_loss=5.026, nll_loss=2.221, w2v_ctc_loss=0.942, contrastive_loss=0, total=4187.21, n_correct=2622.85, ppl=4.66, accuracy=62.64, wps=20043.7, ups=2.4, wpb=8364, bsz=317.6, num_updates=59600, lr=5.79284e-05, gnorm=0.942, clip=0, loss_scale=16, train_wall=41, gb_free=16.9, wall=31721
2023-07-10 12:35:34 | INFO | train_inner | epoch 041:    765 / 1474 loss=4.505, trans_loss=5.035, nll_loss=2.232, w2v_ctc_loss=0.95, contrastive_loss=0, total=4144.35, n_correct=2582.07, ppl=4.7, accuracy=62.303, wps=19694.1, ups=2.38, wpb=8276.4, bsz=299.1, num_updates=59700, lr=5.78799e-05, gnorm=0.964, clip=0, loss_scale=16, train_wall=42, gb_free=17.9, wall=31763
2023-07-10 12:36:16 | INFO | train_inner | epoch 041:    865 / 1474 loss=4.483, trans_loss=5.031, nll_loss=2.227, w2v_ctc_loss=0.889, contrastive_loss=0, total=4112.51, n_correct=2562.19, ppl=4.68, accuracy=62.302, wps=19729, ups=2.4, wpb=8206.3, bsz=296.9, num_updates=59800, lr=5.78315e-05, gnorm=0.93, clip=0, loss_scale=16, train_wall=41, gb_free=16.2, wall=31804
2023-07-10 12:36:58 | INFO | train_inner | epoch 041:    965 / 1474 loss=4.504, trans_loss=5.046, nll_loss=2.246, w2v_ctc_loss=0.92, contrastive_loss=0, total=4119.19, n_correct=2554.14, ppl=4.74, accuracy=62.006, wps=19657.3, ups=2.39, wpb=8231, bsz=299, num_updates=59900, lr=5.77832e-05, gnorm=0.951, clip=0, loss_scale=16, train_wall=41, gb_free=16.6, wall=31846
2023-07-10 12:37:40 | INFO | train_inner | epoch 041:   1065 / 1474 loss=4.508, trans_loss=5.037, nll_loss=2.235, w2v_ctc_loss=0.948, contrastive_loss=0, total=4142.3, n_correct=2583.53, ppl=4.71, accuracy=62.369, wps=19580.4, ups=2.36, wpb=8293.4, bsz=305, num_updates=60000, lr=5.7735e-05, gnorm=0.957, clip=0, loss_scale=16, train_wall=42, gb_free=16.6, wall=31889
2023-07-10 12:37:40 | INFO | fairseq_cli.train | Stopping training due to num_updates: 60000 >= max_update: 60000
2023-07-10 12:37:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 12:38:03 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 4.126 | trans_loss 5.759 | nll_loss 3.069 | w2v_ctc_loss 0.229 | contrastive_loss 0.205 | total 4003.4 | n_correct 2378.1 | ppl 8.39 | accuracy 59.402 | uer 40.756 | wer 43.022 | raw_wer 43.022 | bleu 17.76 | wps 2393.3 | wpb 4003.4 | bsz 141.8 | num_updates 60000 | best_bleu 17.87
2023-07-10 12:38:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 60000 updates
2023-07-10 12:38:03 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_41_60000.pt
2023-07-10 12:38:05 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_41_60000.pt
2023-07-10 12:38:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_41_60000.pt (epoch 41 @ 60000 updates, score 17.76) (writing took 6.050393087032717 seconds)
2023-07-10 12:38:10 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-07-10 12:38:10 | INFO | train | epoch 041 | loss 4.483 | trans_loss 5.029 | nll_loss 2.225 | w2v_ctc_loss 0.89 | contrastive_loss 0 | total 4144.96 | n_correct 2589.16 | ppl 4.67 | accuracy 62.465 | wps 18225 | ups 2.2 | wpb 8286.5 | bsz 306.1 | num_updates 60000 | lr 5.7735e-05 | gnorm 0.939 | clip 0 | loss_scale 16 | train_wall 442 | gb_free 16.6 | wall 31918
2023-07-10 12:38:10 | INFO | fairseq_cli.train | done training in 31849.0 seconds
/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1792 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-07-10 12:46:18 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:13992
2023-07-10 12:46:18 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:13992
2023-07-10 12:46:18 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:13992
2023-07-10 12:46:18 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:13992
2023-07-10 12:46:18 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:13992
2023-07-10 12:46:18 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:13992
2023-07-10 12:46:18 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:13992
2023-07-10 12:46:18 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:13992
2023-07-10 12:46:18 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-10 12:46:18 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-10 12:46:18 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-10 12:46:18 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-10 12:46:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-10 12:46:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-10 12:46:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-10 12:46:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-10 12:46:19 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 12:46:19 | INFO | fairseq.distributed.utils | initialized host capios as rank 6
2023-07-10 12:46:19 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 12:46:19 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 12:46:19 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 12:46:19 | INFO | fairseq.distributed.utils | initialized host capios as rank 5
2023-07-10 12:46:19 | INFO | fairseq.distributed.utils | initialized host capios as rank 7
2023-07-10 12:46:19 | INFO | fairseq.distributed.utils | initialized host capios as rank 1
2023-07-10 12:46:19 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 12:46:19 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 12:46:19 | INFO | fairseq.distributed.utils | initialized host capios as rank 4
2023-07-10 12:46:19 | INFO | fairseq.distributed.utils | initialized host capios as rank 0
2023-07-10 12:46:19 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 12:46:19 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 12:46:19 | INFO | fairseq.distributed.utils | initialized host capios as rank 3
2023-07-10 12:46:19 | INFO | fairseq.distributed.utils | initialized host capios as rank 2
2023-07-10 12:46:21 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_baseline_mt', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13992', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_baseline_mt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_baseline_mt', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_baseline_mt', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_baseline_mt', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_baseline_mt', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_baseline_mt', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_baseline_mt', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-10 12:46:21 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-10 12:46:21 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-10 12:46:21 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-10 12:46:21 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-10 12:46:21 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-10 12:46:26 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-10 12:46:26 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-10 12:46:26 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-10 12:46:27 | INFO | root | load pretrained hubert
2023-07-10 12:46:31 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-10 12:46:33 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-10 12:46:36 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-10 12:46:36 | INFO | root | share the sematic adapter and textual encoder
2023-07-10 12:46:36 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-10 12:46:36 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-10 12:46:36 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-10 12:46:36 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJoint
2023-07-10 12:46:36 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-10 12:46:36 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-10 12:46:36 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-10 12:46:36 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-10 12:46:36 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-10 12:46:36 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-10 12:46:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-10 12:46:44 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-10 12:46:44 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-10 12:46:45 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-10 12:46:45 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 12:46:45 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 12:46:45 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 12:46:45 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 12:46:45 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 12:46:45 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 12:46:45 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 12:46:45 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 12:46:45 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-10 12:46:45 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-10 12:46:45 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-10 12:46:45 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_last.pt
2023-07-10 12:46:46 | INFO | fairseq.trainer | load the task parameters
2023-07-10 12:46:47 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/ende_shrink_baseline_mt/checkpoint_last.pt (epoch 41 @ 60000 updates)
2023-07-10 12:46:47 | INFO | fairseq.trainer | loading train data for epoch 41
2023-07-10 12:46:47 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-10 12:46:47 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-10 12:46:47 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-10 12:46:49 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-10 12:46:52 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-10 12:46:54 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
