2023-07-08 07:59:27 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:18395
2023-07-08 07:59:27 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:18395
2023-07-08 07:59:27 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:18395
2023-07-08 07:59:27 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:18395
2023-07-08 07:59:27 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:18395
2023-07-08 07:59:27 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:18395
2023-07-08 07:59:27 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:18395
2023-07-08 07:59:27 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:18395
2023-07-08 07:59:27 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-08 07:59:28 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-08 07:59:28 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-08 07:59:28 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-08 07:59:28 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-08 07:59:28 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-08 07:59:28 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-08 07:59:28 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-08 07:59:28 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-08 07:59:28 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-08 07:59:28 | INFO | fairseq.distributed.utils | initialized host capios as rank 6
2023-07-08 07:59:28 | INFO | fairseq.distributed.utils | initialized host capios as rank 1
2023-07-08 07:59:28 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-08 07:59:28 | INFO | fairseq.distributed.utils | initialized host capios as rank 3
2023-07-08 07:59:28 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-08 07:59:28 | INFO | fairseq.distributed.utils | initialized host capios as rank 7
2023-07-08 07:59:28 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-08 07:59:28 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-08 07:59:28 | INFO | fairseq.distributed.utils | initialized host capios as rank 2
2023-07-08 07:59:28 | INFO | fairseq.distributed.utils | initialized host capios as rank 0
2023-07-08 07:59:28 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-08 07:59:28 | INFO | fairseq.distributed.utils | initialized host capios as rank 4
2023-07-08 07:59:28 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-08 07:59:28 | INFO | fairseq.distributed.utils | initialized host capios as rank 5
2023-07-08 07:59:30 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_tokenl', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18395', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_tokenl', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='token', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_tokenl', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_tokenl', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='token', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_tokenl', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_tokenl', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='token', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_tokenl', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_tokenl', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-08 07:59:30 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-08 07:59:30 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-08 07:59:30 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-08 07:59:30 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-08 07:59:30 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-08 07:59:35 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-08 07:59:35 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-08 07:59:35 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-08 07:59:36 | INFO | root | load pretrained hubert
2023-07-08 07:59:40 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-08 07:59:42 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-08 07:59:45 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-08 07:59:45 | INFO | root | share the sematic adapter and textual encoder
2023-07-08 07:59:46 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-08 07:59:46 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-08 07:59:46 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-08 07:59:46 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-08 07:59:46 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-08 07:59:46 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-08 07:59:46 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-08 07:59:46 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-08 07:59:46 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-08 07:59:46 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-08 07:59:53 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-08 07:59:53 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-08 07:59:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-08 07:59:54 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-08 07:59:54 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-08 07:59:54 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-08 07:59:54 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-08 07:59:54 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-08 07:59:54 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-08 07:59:54 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-08 07:59:54 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-08 07:59:54 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-08 07:59:54 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-08 07:59:54 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-08 07:59:54 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-08 07:59:54 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-08 07:59:54 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-08 07:59:54 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-08 07:59:54 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-08 07:59:54 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-08 07:59:54 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-08 07:59:55 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-08 07:59:57 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-08 07:59:59 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-08 08:01:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 08:01:04 | INFO | fairseq.trainer | begin training epoch 1
2023-07-08 08:01:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 08:01:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-08 08:02:14 | INFO | train_inner | epoch 001:    101 / 1474 loss=8.858, trans_loss=5.64, nll_loss=4.216, w2v_ctc_loss=9.594, task_loss=2.068, contrastive_loss=3.31, total=4200.41, n_correct=212.11, ppl=18.58, accuracy=5.05, wps=20261.6, ups=1.61, wpb=12542.9, bsz=467.5, num_updates=100, lr=4.098e-06, gnorm=0.399, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=141
2023-07-08 08:03:15 | INFO | train_inner | epoch 001:    201 / 1474 loss=7.921, trans_loss=5.441, nll_loss=4.027, w2v_ctc_loss=8.265, task_loss=2.012, contrastive_loss=3.286, total=4127.38, n_correct=250.15, ppl=16.3, accuracy=6.061, wps=20303.4, ups=1.65, wpb=12327, bsz=463.1, num_updates=200, lr=8.096e-06, gnorm=1.55, clip=0, loss_scale=64, train_wall=60, gb_free=19.2, wall=201
2023-07-08 08:04:15 | INFO | train_inner | epoch 001:    301 / 1474 loss=4.942, trans_loss=5.408, nll_loss=4.045, w2v_ctc_loss=3.742, task_loss=2.049, contrastive_loss=3.202, total=4079.62, n_correct=249.66, ppl=16.5, accuracy=6.12, wps=20232.6, ups=1.66, wpb=12195.4, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=1.975, clip=0, loss_scale=64, train_wall=60, gb_free=19.9, wall=262
2023-07-08 08:05:16 | INFO | train_inner | epoch 001:    401 / 1474 loss=4.424, trans_loss=5.453, nll_loss=4.12, w2v_ctc_loss=2.909, task_loss=1.695, contrastive_loss=3.236, total=4174.14, n_correct=233.79, ppl=17.38, accuracy=5.601, wps=20607.8, ups=1.65, wpb=12461.1, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=1.28, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=322
2023-07-08 08:06:17 | INFO | train_inner | epoch 001:    501 / 1474 loss=4.238, trans_loss=5.453, nll_loss=4.128, w2v_ctc_loss=2.629, task_loss=1.493, contrastive_loss=3.23, total=4176.18, n_correct=217.44, ppl=17.49, accuracy=5.207, wps=20518.3, ups=1.64, wpb=12513, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=0.611, clip=0, loss_scale=64, train_wall=61, gb_free=19.2, wall=383
2023-07-08 08:07:17 | INFO | train_inner | epoch 001:    601 / 1474 loss=4.147, trans_loss=5.485, nll_loss=4.174, w2v_ctc_loss=2.485, task_loss=1.427, contrastive_loss=3.282, total=4147.79, n_correct=212.09, ppl=18.05, accuracy=5.113, wps=20457.5, ups=1.65, wpb=12368.1, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.314, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=443
2023-07-08 08:08:17 | INFO | train_inner | epoch 001:    701 / 1474 loss=4.063, trans_loss=5.476, nll_loss=4.169, w2v_ctc_loss=2.428, task_loss=1.517, contrastive_loss=3.031, total=4152.1, n_correct=224.18, ppl=17.99, accuracy=5.399, wps=20648.4, ups=1.67, wpb=12373.8, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=0.256, clip=0, loss_scale=64, train_wall=60, gb_free=19.5, wall=503
2023-07-08 08:09:17 | INFO | train_inner | epoch 001:    801 / 1474 loss=3.955, trans_loss=5.433, nll_loss=4.118, w2v_ctc_loss=2.333, task_loss=1.485, contrastive_loss=2.93, total=4123.83, n_correct=247.74, ppl=17.37, accuracy=6.008, wps=20406.5, ups=1.66, wpb=12311.9, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=0.354, clip=0, loss_scale=64, train_wall=60, gb_free=19.1, wall=564
2023-07-08 08:10:17 | INFO | train_inner | epoch 001:    901 / 1474 loss=3.846, trans_loss=5.41, nll_loss=4.107, w2v_ctc_loss=2.26, task_loss=1.513, contrastive_loss=2.674, total=4163.61, n_correct=273.56, ppl=17.23, accuracy=6.57, wps=20674.3, ups=1.67, wpb=12409.7, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=0.511, clip=0, loss_scale=64, train_wall=60, gb_free=18.8, wall=624
2023-07-08 08:11:18 | INFO | train_inner | epoch 001:   1001 / 1474 loss=3.724, trans_loss=5.392, nll_loss=4.088, w2v_ctc_loss=2.156, task_loss=1.525, contrastive_loss=2.533, total=4135.34, n_correct=293.88, ppl=17.01, accuracy=7.107, wps=20337.3, ups=1.64, wpb=12363.9, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=0.631, clip=0, loss_scale=64, train_wall=60, gb_free=19, wall=685
2023-07-08 08:12:18 | INFO | train_inner | epoch 001:   1101 / 1474 loss=3.619, trans_loss=5.382, nll_loss=4.079, w2v_ctc_loss=2.077, task_loss=1.539, contrastive_loss=2.313, total=4147.38, n_correct=311.72, ppl=16.9, accuracy=7.516, wps=20523.2, ups=1.66, wpb=12356.9, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=0.731, clip=0, loss_scale=64, train_wall=60, gb_free=18.8, wall=745
2023-07-08 08:13:19 | INFO | train_inner | epoch 001:   1201 / 1474 loss=3.505, trans_loss=5.36, nll_loss=4.057, w2v_ctc_loss=1.992, task_loss=1.606, contrastive_loss=2.1, total=4139.9, n_correct=325.17, ppl=16.65, accuracy=7.855, wps=20465.1, ups=1.65, wpb=12386.7, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=0.708, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=805
2023-07-08 08:14:19 | INFO | train_inner | epoch 001:   1301 / 1474 loss=3.414, trans_loss=5.362, nll_loss=4.062, w2v_ctc_loss=1.911, task_loss=1.551, contrastive_loss=1.921, total=4046.58, n_correct=318.11, ppl=16.7, accuracy=7.861, wps=20264.1, ups=1.68, wpb=12092.5, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=0.736, clip=0, loss_scale=64, train_wall=59, gb_free=19.7, wall=865
2023-07-08 08:15:19 | INFO | train_inner | epoch 001:   1401 / 1474 loss=3.358, trans_loss=5.358, nll_loss=4.069, w2v_ctc_loss=1.846, task_loss=1.525, contrastive_loss=2.006, total=4133.18, n_correct=329.12, ppl=16.78, accuracy=7.963, wps=20461.9, ups=1.66, wpb=12300.7, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=0.803, clip=0, loss_scale=64, train_wall=60, gb_free=19.9, wall=925
2023-07-08 08:16:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-07-08 08:16:36 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 2.518 | trans_loss 10.956 | nll_loss 9.942 | w2v_ctc_loss 1.47 | task_loss 7.545 | contrastive_loss 2.326 | total 4003.4 | n_correct 374 | ppl 983.92 | accuracy 9.342 | uer 71.385 | wer 69.367 | raw_wer 69.367 | bleu 0.02 | wps 1472.7 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-07-08 08:16:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-07-08 08:16:36 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 08:16:39 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 08:16:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.02) (writing took 4.7084705689921975 seconds)
2023-07-08 08:16:41 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-07-08 08:16:41 | INFO | train | epoch 001 | loss 4.513 | trans_loss 5.429 | nll_loss 4.102 | w2v_ctc_loss 3.259 | task_loss 1.634 | contrastive_loss 2.748 | total 4138.32 | n_correct 267.831 | ppl 17.17 | accuracy 6.472 | wps 19597.3 | ups 1.59 | wpb 12354.6 | bsz 458.3 | num_updates 1473 | lr 5.89905e-05 | gnorm 0.77 | clip 0 | loss_scale 64 | train_wall 886 | gb_free 19.2 | wall 1007
2023-07-08 08:16:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 08:16:41 | INFO | fairseq.trainer | begin training epoch 2
2023-07-08 08:16:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 08:17:05 | INFO | train_inner | epoch 002:     27 / 1474 loss=3.275, trans_loss=5.353, nll_loss=4.052, w2v_ctc_loss=1.76, task_loss=1.456, contrastive_loss=1.837, total=4162.95, n_correct=338.11, ppl=16.58, accuracy=8.122, wps=11725.4, ups=0.94, wpb=12414, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=0.679, clip=0, loss_scale=64, train_wall=60, gb_free=19.6, wall=1031
2023-07-08 08:18:05 | INFO | train_inner | epoch 002:    127 / 1474 loss=3.195, trans_loss=5.353, nll_loss=4.053, w2v_ctc_loss=1.703, task_loss=1.555, contrastive_loss=1.637, total=4155.98, n_correct=337.34, ppl=16.59, accuracy=8.117, wps=20519.7, ups=1.66, wpb=12390, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=0.687, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=1091
2023-07-08 08:19:05 | INFO | train_inner | epoch 002:    227 / 1474 loss=3.131, trans_loss=5.325, nll_loss=4.021, w2v_ctc_loss=1.623, task_loss=1.351, contrastive_loss=1.668, total=4179.21, n_correct=348.66, ppl=16.23, accuracy=8.343, wps=20665.7, ups=1.65, wpb=12488.1, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=0.642, clip=0, loss_scale=64, train_wall=60, gb_free=19, wall=1152
2023-07-08 08:20:06 | INFO | train_inner | epoch 002:    327 / 1474 loss=3.055, trans_loss=5.327, nll_loss=4.02, w2v_ctc_loss=1.577, task_loss=1.549, contrastive_loss=1.38, total=4146.1, n_correct=349.96, ppl=16.22, accuracy=8.441, wps=20361.3, ups=1.64, wpb=12381, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=0.603, clip=0, loss_scale=64, train_wall=60, gb_free=18.8, wall=1213
2023-07-08 08:21:06 | INFO | train_inner | epoch 002:    427 / 1474 loss=2.984, trans_loss=5.315, nll_loss=4.01, w2v_ctc_loss=1.531, task_loss=1.699, contrastive_loss=1.203, total=4037.99, n_correct=342.64, ppl=16.11, accuracy=8.485, wps=20202.8, ups=1.67, wpb=12079.4, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=0.609, clip=0, loss_scale=64, train_wall=59, gb_free=18.9, wall=1272
2023-07-08 08:22:06 | INFO | train_inner | epoch 002:    527 / 1474 loss=2.965, trans_loss=5.313, nll_loss=4.002, w2v_ctc_loss=1.475, task_loss=1.478, contrastive_loss=1.307, total=4176.97, n_correct=360.32, ppl=16.02, accuracy=8.626, wps=20845.1, ups=1.67, wpb=12475.1, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=0.588, clip=0, loss_scale=64, train_wall=59, gb_free=19.6, wall=1332
2023-07-08 08:22:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 08:22:40 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 2.367 | trans_loss 10.822 | nll_loss 9.77 | w2v_ctc_loss 1.188 | task_loss 7.545 | contrastive_loss 1.65 | total 4003.4 | n_correct 395.3 | ppl 872.84 | accuracy 9.874 | uer 61.766 | wer 59.39 | raw_wer 59.39 | bleu 0.04 | wps 1465.8 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.04
2023-07-08 08:22:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-07-08 08:22:40 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_2_2000.pt
2023-07-08 08:22:42 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_2_2000.pt
2023-07-08 08:22:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.04) (writing took 8.63080376999278 seconds)
2023-07-08 08:23:48 | INFO | train_inner | epoch 002:    627 / 1474 loss=2.893, trans_loss=5.306, nll_loss=3.997, w2v_ctc_loss=1.425, task_loss=1.532, contrastive_loss=1.094, total=4126.49, n_correct=359.63, ppl=15.97, accuracy=8.715, wps=12039.7, ups=0.98, wpb=12299.1, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=0.49, clip=0, loss_scale=128, train_wall=59, gb_free=19.2, wall=1434
2023-07-08 08:24:48 | INFO | train_inner | epoch 002:    727 / 1474 loss=2.868, trans_loss=5.288, nll_loss=3.979, w2v_ctc_loss=1.39, task_loss=1.498, contrastive_loss=1.201, total=4149.06, n_correct=370.56, ppl=15.76, accuracy=8.931, wps=20678.9, ups=1.67, wpb=12372.9, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=0.495, clip=0, loss_scale=128, train_wall=59, gb_free=19.2, wall=1494
2023-07-08 08:25:48 | INFO | train_inner | epoch 002:    827 / 1474 loss=2.837, trans_loss=5.271, nll_loss=3.956, w2v_ctc_loss=1.363, task_loss=1.536, contrastive_loss=1.147, total=4175.4, n_correct=379.72, ppl=15.52, accuracy=9.094, wps=20796.7, ups=1.67, wpb=12477.6, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=0.438, clip=0, loss_scale=128, train_wall=60, gb_free=19.8, wall=1554
2023-07-08 08:26:48 | INFO | train_inner | epoch 002:    927 / 1474 loss=2.791, trans_loss=5.259, nll_loss=3.941, w2v_ctc_loss=1.32, task_loss=1.568, contrastive_loss=1.129, total=4104.2, n_correct=376.7, ppl=15.36, accuracy=9.178, wps=20390.1, ups=1.67, wpb=12243.8, bsz=445.9, num_updates=2400, lr=9.6052e-05, gnorm=0.428, clip=0, loss_scale=128, train_wall=60, gb_free=19, wall=1614
2023-07-08 08:27:48 | INFO | train_inner | epoch 002:   1027 / 1474 loss=2.758, trans_loss=5.254, nll_loss=3.934, w2v_ctc_loss=1.288, task_loss=1.525, contrastive_loss=0.985, total=4102.5, n_correct=380.04, ppl=15.29, accuracy=9.264, wps=20477.7, ups=1.67, wpb=12270.3, bsz=456.3, num_updates=2500, lr=0.00010005, gnorm=0.392, clip=0, loss_scale=128, train_wall=60, gb_free=19.2, wall=1674
2023-07-08 08:28:48 | INFO | train_inner | epoch 002:   1127 / 1474 loss=2.755, trans_loss=5.244, nll_loss=3.923, w2v_ctc_loss=1.261, task_loss=1.386, contrastive_loss=1.197, total=4187.61, n_correct=396.68, ppl=15.16, accuracy=9.473, wps=20642.7, ups=1.65, wpb=12484.3, bsz=487.1, num_updates=2600, lr=0.000104048, gnorm=0.359, clip=0, loss_scale=128, train_wall=60, gb_free=19.5, wall=1735
2023-07-08 08:29:49 | INFO | train_inner | epoch 002:   1227 / 1474 loss=2.725, trans_loss=5.236, nll_loss=3.913, w2v_ctc_loss=1.239, task_loss=1.396, contrastive_loss=1.119, total=4221.06, n_correct=407.56, ppl=15.06, accuracy=9.655, wps=20624.1, ups=1.64, wpb=12590.1, bsz=492.8, num_updates=2700, lr=0.000108046, gnorm=0.354, clip=0, loss_scale=128, train_wall=61, gb_free=19.4, wall=1796
2023-07-08 08:30:49 | INFO | train_inner | epoch 002:   1327 / 1474 loss=2.674, trans_loss=5.223, nll_loss=3.901, w2v_ctc_loss=1.217, task_loss=1.472, contrastive_loss=0.834, total=4157.86, n_correct=407.1, ppl=14.93, accuracy=9.791, wps=20833.6, ups=1.68, wpb=12422.5, bsz=460.7, num_updates=2800, lr=0.000112044, gnorm=0.336, clip=0, loss_scale=128, train_wall=59, gb_free=19.5, wall=1855
2023-07-08 08:31:50 | INFO | train_inner | epoch 002:   1427 / 1474 loss=2.652, trans_loss=5.22, nll_loss=3.893, w2v_ctc_loss=1.195, task_loss=1.65, contrastive_loss=0.919, total=4054.34, n_correct=397.18, ppl=14.85, accuracy=9.796, wps=19766.9, ups=1.63, wpb=12128.6, bsz=438.8, num_updates=2900, lr=0.000116042, gnorm=0.316, clip=0, loss_scale=128, train_wall=61, gb_free=19.4, wall=1917
2023-07-08 08:32:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 08:32:52 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 2.155 | trans_loss 10.273 | nll_loss 9.078 | w2v_ctc_loss 0.944 | task_loss 7.545 | contrastive_loss 0.985 | total 4003.4 | n_correct 505.3 | ppl 540.42 | accuracy 12.622 | uer 51.4 | wer 50.46 | raw_wer 50.46 | bleu 0.14 | wps 1459 | wpb 4003.4 | bsz 141.8 | num_updates 2947 | best_bleu 0.14
2023-07-08 08:32:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2947 updates
2023-07-08 08:32:52 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 08:32:57 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 08:33:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 2 @ 2947 updates, score 0.14) (writing took 8.124349357996834 seconds)
2023-07-08 08:33:01 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-07-08 08:33:01 | INFO | train | epoch 002 | loss 2.877 | trans_loss 5.28 | nll_loss 3.967 | w2v_ctc_loss 1.4 | task_loss 1.509 | contrastive_loss 1.204 | total 4138.65 | n_correct 372.657 | ppl 15.63 | accuracy 9.004 | wps 18590.2 | ups 1.5 | wpb 12355.8 | bsz 458.5 | num_updates 2947 | lr 0.000117921 | gnorm 0.48 | clip 0 | loss_scale 128 | train_wall 882 | gb_free 19.3 | wall 1987
2023-07-08 08:33:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 08:33:01 | INFO | fairseq.trainer | begin training epoch 3
2023-07-08 08:33:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 08:33:41 | INFO | train_inner | epoch 003:     53 / 1474 loss=2.629, trans_loss=5.201, nll_loss=3.87, w2v_ctc_loss=1.177, task_loss=1.545, contrastive_loss=0.818, total=4071.2, n_correct=411.48, ppl=14.63, accuracy=10.107, wps=10978.9, ups=0.9, wpb=12148.3, bsz=442.6, num_updates=3000, lr=0.00012004, gnorm=0.305, clip=0, loss_scale=128, train_wall=60, gb_free=19.1, wall=2027
2023-07-08 08:33:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-08 08:33:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-08 08:33:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-08 08:33:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-08 08:33:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-07-08 08:35:11 | INFO | train_inner | epoch 003:    158 / 1474 loss=2.585, trans_loss=4.47, nll_loss=2.915, w2v_ctc_loss=1.155, task_loss=1.118, contrastive_loss=0.688, total=4144.18, n_correct=1070.21, ppl=7.54, accuracy=25.824, wps=13716.1, ups=1.11, wpb=12381.7, bsz=458.6, num_updates=3100, lr=0.000124038, gnorm=0.803, clip=0, loss_scale=4, train_wall=90, gb_free=16.7, wall=2118
2023-07-08 08:36:39 | INFO | train_inner | epoch 003:    258 / 1474 loss=2.39, trans_loss=4.185, nll_loss=2.541, w2v_ctc_loss=1.032, task_loss=1.129, contrastive_loss=0.599, total=4161.13, n_correct=1384.34, ppl=5.82, accuracy=33.268, wps=14216.5, ups=1.14, wpb=12444.3, bsz=467, num_updates=3200, lr=0.000128036, gnorm=0.545, clip=0, loss_scale=4, train_wall=87, gb_free=17.3, wall=2205
2023-07-08 08:38:06 | INFO | train_inner | epoch 003:    358 / 1474 loss=2.322, trans_loss=4.095, nll_loss=2.421, w2v_ctc_loss=0.982, task_loss=1.137, contrastive_loss=0.636, total=4150.02, n_correct=1510.11, ppl=5.35, accuracy=36.388, wps=14259.3, ups=1.15, wpb=12369, bsz=461.6, num_updates=3300, lr=0.000132034, gnorm=0.552, clip=0, loss_scale=4, train_wall=86, gb_free=17.3, wall=2292
2023-07-08 08:39:33 | INFO | train_inner | epoch 003:    458 / 1474 loss=2.256, trans_loss=4.02, nll_loss=2.325, w2v_ctc_loss=0.941, task_loss=1.1, contrastive_loss=0.489, total=4209.57, n_correct=1639.21, ppl=5.01, accuracy=38.94, wps=14321.5, ups=1.14, wpb=12537.6, bsz=476.8, num_updates=3400, lr=0.000136032, gnorm=0.503, clip=0, loss_scale=4, train_wall=87, gb_free=16.2, wall=2379
2023-07-08 08:41:00 | INFO | train_inner | epoch 003:    558 / 1474 loss=2.202, trans_loss=3.978, nll_loss=2.264, w2v_ctc_loss=0.896, task_loss=1.212, contrastive_loss=0.461, total=4088.48, n_correct=1658.71, ppl=4.8, accuracy=40.57, wps=14054.2, ups=1.15, wpb=12237.1, bsz=439.7, num_updates=3500, lr=0.00014003, gnorm=0.483, clip=0, loss_scale=4, train_wall=87, gb_free=17.8, wall=2467
2023-07-08 08:42:28 | INFO | train_inner | epoch 003:    658 / 1474 loss=2.17, trans_loss=3.933, nll_loss=2.208, w2v_ctc_loss=0.867, task_loss=1.084, contrastive_loss=0.566, total=4221.58, n_correct=1788.45, ppl=4.62, accuracy=42.364, wps=14218.3, ups=1.13, wpb=12558.6, bsz=481.9, num_updates=3600, lr=0.000144028, gnorm=0.46, clip=0, loss_scale=4, train_wall=88, gb_free=16.5, wall=2555
2023-07-08 08:43:55 | INFO | train_inner | epoch 003:    758 / 1474 loss=2.125, trans_loss=3.9, nll_loss=2.164, w2v_ctc_loss=0.846, task_loss=1.086, contrastive_loss=0.335, total=4167.41, n_correct=1814.83, ppl=4.48, accuracy=43.548, wps=14357.8, ups=1.15, wpb=12462.8, bsz=472.6, num_updates=3700, lr=0.000148026, gnorm=0.459, clip=0, loss_scale=4, train_wall=86, gb_free=16.5, wall=2642
2023-07-08 08:45:22 | INFO | train_inner | epoch 003:    858 / 1474 loss=2.102, trans_loss=3.88, nll_loss=2.138, w2v_ctc_loss=0.826, task_loss=1.15, contrastive_loss=0.299, total=4165.53, n_correct=1842.28, ppl=4.4, accuracy=44.227, wps=14341.4, ups=1.15, wpb=12445.3, bsz=456.1, num_updates=3800, lr=0.000152024, gnorm=0.446, clip=0, loss_scale=4, train_wall=86, gb_free=17.2, wall=2728
2023-07-08 08:46:49 | INFO | train_inner | epoch 003:    958 / 1474 loss=2.092, trans_loss=3.854, nll_loss=2.104, w2v_ctc_loss=0.818, task_loss=1.102, contrastive_loss=0.331, total=4162.3, n_correct=1892.02, ppl=4.3, accuracy=45.456, wps=14220.9, ups=1.15, wpb=12408.5, bsz=469.2, num_updates=3900, lr=0.000156022, gnorm=0.443, clip=0, loss_scale=4, train_wall=87, gb_free=16.9, wall=2816
2023-07-08 08:48:16 | INFO | train_inner | epoch 003:   1058 / 1474 loss=2.08, trans_loss=3.845, nll_loss=2.092, w2v_ctc_loss=0.811, task_loss=1.209, contrastive_loss=0.29, total=4069.95, n_correct=1867.39, ppl=4.26, accuracy=45.882, wps=14028.5, ups=1.15, wpb=12168.2, bsz=443.6, num_updates=4000, lr=0.00016002, gnorm=0.446, clip=0, loss_scale=4, train_wall=86, gb_free=16.5, wall=2902
2023-07-08 08:48:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 08:48:48 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 1.812 | trans_loss 6.435 | nll_loss 3.987 | w2v_ctc_loss 0.716 | task_loss 4.371 | contrastive_loss 0.404 | total 4003.4 | n_correct 1937.2 | ppl 15.86 | accuracy 48.389 | uer 29.188 | wer 30.159 | raw_wer 30.159 | bleu 6.88 | wps 1557 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 6.88
2023-07-08 08:48:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-07-08 08:48:48 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_3_4000.pt
2023-07-08 08:48:50 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_3_4000.pt
2023-07-08 08:48:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 6.88) (writing took 8.948995961996843 seconds)
2023-07-08 08:50:23 | INFO | train_inner | epoch 003:   1158 / 1474 loss=2.059, trans_loss=3.835, nll_loss=2.079, w2v_ctc_loss=0.791, task_loss=1.233, contrastive_loss=0.269, total=4038.49, n_correct=1865.21, ppl=4.22, accuracy=46.186, wps=9489.6, ups=0.79, wpb=12064, bsz=432.5, num_updates=4100, lr=0.000164018, gnorm=0.432, clip=0, loss_scale=4, train_wall=86, gb_free=16.6, wall=3030
2023-07-08 08:51:49 | INFO | train_inner | epoch 003:   1258 / 1474 loss=2.045, trans_loss=3.819, nll_loss=2.058, w2v_ctc_loss=0.776, task_loss=1.206, contrastive_loss=0.252, total=4064.31, n_correct=1917.58, ppl=4.17, accuracy=47.181, wps=14153.1, ups=1.17, wpb=12147.9, bsz=433.9, num_updates=4200, lr=0.000168016, gnorm=0.427, clip=0, loss_scale=4, train_wall=85, gb_free=17.5, wall=3115
2023-07-08 08:53:16 | INFO | train_inner | epoch 003:   1358 / 1474 loss=2.038, trans_loss=3.796, nll_loss=2.032, w2v_ctc_loss=0.767, task_loss=1.151, contrastive_loss=0.367, total=4134.58, n_correct=1974.46, ppl=4.09, accuracy=47.755, wps=14153.9, ups=1.15, wpb=12326.9, bsz=460.7, num_updates=4300, lr=0.000172014, gnorm=0.431, clip=0, loss_scale=4, train_wall=87, gb_free=17.9, wall=3203
2023-07-08 08:54:43 | INFO | train_inner | epoch 003:   1458 / 1474 loss=2.017, trans_loss=3.784, nll_loss=2.015, w2v_ctc_loss=0.75, task_loss=1.083, contrastive_loss=0.345, total=4209.94, n_correct=2032.98, ppl=4.04, accuracy=48.29, wps=14434.2, ups=1.15, wpb=12573.7, bsz=477.4, num_updates=4400, lr=0.000176012, gnorm=0.419, clip=0, loss_scale=4, train_wall=87, gb_free=17.2, wall=3290
2023-07-08 08:54:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 08:55:29 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 1.789 | trans_loss 6.32 | nll_loss 3.834 | w2v_ctc_loss 0.665 | task_loss 4.255 | contrastive_loss 0.371 | total 4003.4 | n_correct 2023.3 | ppl 14.26 | accuracy 50.54 | uer 28.063 | wer 28.686 | raw_wer 28.686 | bleu 8.01 | wps 1574.3 | wpb 4003.4 | bsz 141.8 | num_updates 4416 | best_bleu 8.01
2023-07-08 08:55:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4416 updates
2023-07-08 08:55:29 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 08:55:33 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 08:55:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 3 @ 4416 updates, score 8.01) (writing took 8.142435727990232 seconds)
2023-07-08 08:55:37 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-07-08 08:55:37 | INFO | train | epoch 003 | loss 2.194 | trans_loss 4 | nll_loss 2.296 | w2v_ctc_loss 0.887 | task_loss 1.155 | contrastive_loss 0.441 | total 4140.05 | n_correct 1687.28 | ppl 4.91 | accuracy 40.755 | wps 13388.7 | ups 1.08 | wpb 12360.2 | bsz 459 | num_updates 4416 | lr 0.000176652 | gnorm 0.482 | clip 0 | loss_scale 4 | train_wall 1261 | gb_free 16.8 | wall 3343
2023-07-08 08:55:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 08:55:37 | INFO | fairseq.trainer | begin training epoch 4
2023-07-08 08:55:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 08:56:57 | INFO | train_inner | epoch 004:     84 / 1474 loss=1.983, trans_loss=3.755, nll_loss=1.977, w2v_ctc_loss=0.731, task_loss=1.18, contrastive_loss=0.201, total=4099.41, n_correct=2010.2, ppl=3.94, accuracy=49.036, wps=9124.7, ups=0.75, wpb=12215.8, bsz=439.5, num_updates=4500, lr=0.00018001, gnorm=0.405, clip=0, loss_scale=4, train_wall=85, gb_free=16.6, wall=3424
2023-07-08 08:58:23 | INFO | train_inner | epoch 004:    184 / 1474 loss=1.97, trans_loss=3.74, nll_loss=1.956, w2v_ctc_loss=0.72, task_loss=1.085, contrastive_loss=0.225, total=4175.15, n_correct=2078.1, ppl=3.88, accuracy=49.773, wps=14485.9, ups=1.16, wpb=12466.1, bsz=468.3, num_updates=4600, lr=0.000184008, gnorm=0.416, clip=0, loss_scale=4, train_wall=86, gb_free=16.8, wall=3510
2023-07-08 08:59:51 | INFO | train_inner | epoch 004:    284 / 1474 loss=1.983, trans_loss=3.74, nll_loss=1.958, w2v_ctc_loss=0.72, task_loss=1.142, contrastive_loss=0.356, total=4145.23, n_correct=2060.01, ppl=3.89, accuracy=49.696, wps=14151.7, ups=1.14, wpb=12387.3, bsz=463, num_updates=4700, lr=0.000188006, gnorm=0.409, clip=0, loss_scale=4, train_wall=87, gb_free=16.1, wall=3597
2023-07-08 09:01:17 | INFO | train_inner | epoch 004:    384 / 1474 loss=1.965, trans_loss=3.739, nll_loss=1.955, w2v_ctc_loss=0.712, task_loss=1.188, contrastive_loss=0.198, total=4127.66, n_correct=2058.59, ppl=3.88, accuracy=49.873, wps=14253.8, ups=1.16, wpb=12298.8, bsz=443.5, num_updates=4800, lr=0.000192004, gnorm=0.403, clip=0, loss_scale=4, train_wall=86, gb_free=17.6, wall=3683
2023-07-08 09:02:44 | INFO | train_inner | epoch 004:    484 / 1474 loss=1.981, trans_loss=3.72, nll_loss=1.934, w2v_ctc_loss=0.697, task_loss=1.035, contrastive_loss=0.592, total=4218.78, n_correct=2130.71, ppl=3.82, accuracy=50.505, wps=14433.6, ups=1.15, wpb=12578.2, bsz=497.8, num_updates=4900, lr=0.000196002, gnorm=0.399, clip=0, loss_scale=4, train_wall=87, gb_free=16.7, wall=3771
2023-07-08 09:04:11 | INFO | train_inner | epoch 004:    584 / 1474 loss=1.954, trans_loss=3.717, nll_loss=1.93, w2v_ctc_loss=0.706, task_loss=1.08, contrastive_loss=0.271, total=4217.52, n_correct=2140.92, ppl=3.81, accuracy=50.763, wps=14425.4, ups=1.15, wpb=12583.6, bsz=485.9, num_updates=5000, lr=0.0002, gnorm=0.403, clip=0, loss_scale=4, train_wall=87, gb_free=16.3, wall=3858
tensor(0.8467, device='cuda:0')
tensor(0.8163, device='cuda:0')
2023-07-08 09:05:39 | INFO | train_inner | epoch 004:    684 / 1474 loss=1.952, trans_loss=3.721, nll_loss=1.929, w2v_ctc_loss=0.693, task_loss=1.175, contrastive_loss=0.32, total=4176.39, n_correct=2128.07, ppl=3.81, accuracy=50.955, wps=14130.6, ups=1.14, wpb=12440.1, bsz=455.8, num_updates=5100, lr=0.00019803, gnorm=0.344, clip=0, loss_scale=8, train_wall=88, gb_free=17.2, wall=3946
2023-07-08 09:07:06 | INFO | train_inner | epoch 004:    784 / 1474 loss=1.946, trans_loss=3.714, nll_loss=1.922, w2v_ctc_loss=0.697, task_loss=1.263, contrastive_loss=0.191, total=4026.63, n_correct=2059.73, ppl=3.79, accuracy=51.153, wps=13908.5, ups=1.15, wpb=12049.9, bsz=420.6, num_updates=5200, lr=0.000196116, gnorm=0.346, clip=0, loss_scale=8, train_wall=86, gb_free=13.5, wall=4032
2023-07-08 09:08:33 | INFO | train_inner | epoch 004:    884 / 1474 loss=1.946, trans_loss=3.701, nll_loss=1.91, w2v_ctc_loss=0.69, task_loss=1.143, contrastive_loss=0.366, total=4186.04, n_correct=2153.39, ppl=3.76, accuracy=51.442, wps=14329, ups=1.15, wpb=12493.4, bsz=466.3, num_updates=5300, lr=0.000194257, gnorm=0.339, clip=0, loss_scale=8, train_wall=87, gb_free=17.8, wall=4120
2023-07-08 09:10:00 | INFO | train_inner | epoch 004:    984 / 1474 loss=1.924, trans_loss=3.692, nll_loss=1.897, w2v_ctc_loss=0.678, task_loss=1.158, contrastive_loss=0.229, total=4125.02, n_correct=2141.64, ppl=3.73, accuracy=51.918, wps=14160.1, ups=1.15, wpb=12319.9, bsz=457.1, num_updates=5400, lr=0.00019245, gnorm=0.338, clip=0, loss_scale=8, train_wall=87, gb_free=13.1, wall=4207
2023-07-08 09:11:27 | INFO | train_inner | epoch 004:   1084 / 1474 loss=1.933, trans_loss=3.698, nll_loss=1.903, w2v_ctc_loss=0.683, task_loss=1.23, contrastive_loss=0.207, total=4075.6, n_correct=2111.15, ppl=3.74, accuracy=51.8, wps=13973.9, ups=1.15, wpb=12166.1, bsz=435.7, num_updates=5500, lr=0.000190693, gnorm=0.338, clip=0, loss_scale=8, train_wall=87, gb_free=16.2, wall=4294
2023-07-08 09:12:54 | INFO | train_inner | epoch 004:   1184 / 1474 loss=1.928, trans_loss=3.689, nll_loss=1.894, w2v_ctc_loss=0.672, task_loss=1.075, contrastive_loss=0.314, total=4161.18, n_correct=2177.68, ppl=3.72, accuracy=52.333, wps=14358.1, ups=1.15, wpb=12451.8, bsz=483.4, num_updates=5600, lr=0.000188982, gnorm=0.333, clip=0, loss_scale=8, train_wall=86, gb_free=16.9, wall=4380
2023-07-08 09:14:20 | INFO | train_inner | epoch 004:   1284 / 1474 loss=1.922, trans_loss=3.683, nll_loss=1.885, w2v_ctc_loss=0.667, task_loss=1.096, contrastive_loss=0.278, total=4156.53, n_correct=2189.18, ppl=3.69, accuracy=52.668, wps=14416.3, ups=1.16, wpb=12424.6, bsz=472.7, num_updates=5700, lr=0.000187317, gnorm=0.336, clip=0, loss_scale=8, train_wall=86, gb_free=16.2, wall=4467
2023-07-08 09:15:46 | INFO | train_inner | epoch 004:   1384 / 1474 loss=1.908, trans_loss=3.679, nll_loss=1.88, w2v_ctc_loss=0.667, task_loss=1.178, contrastive_loss=0.159, total=4101.23, n_correct=2160.51, ppl=3.68, accuracy=52.68, wps=14310.5, ups=1.17, wpb=12255, bsz=437.6, num_updates=5800, lr=0.000185695, gnorm=0.324, clip=0, loss_scale=8, train_wall=85, gb_free=15.9, wall=4552
2023-07-08 09:17:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.8467, device='cuda:3')
tensor(0.8163, device='cuda:3')
tensor(0.8467, device='cuda:1')
tensor(0.8163, device='cuda:1')
tensor(0.8467, device='cuda:6')
tensor(0.8163, device='cuda:6')
tensor(0.8467, device='cuda:7')
tensor(0.8163, device='cuda:7')
tensor(0.8467, device='cuda:4')
tensor(0.8163, device='cuda:4')
tensor(0.8467, device='cuda:5')
tensor(0.8163, device='cuda:5')
tensor(0.8467, device='cuda:2')
tensor(0.8163, device='cuda:2')
2023-07-08 09:17:31 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 1.623 | trans_loss 5.969 | nll_loss 3.366 | w2v_ctc_loss 0.549 | task_loss 4.454 | contrastive_loss 0.303 | total 4003.4 | n_correct 2235.3 | ppl 10.31 | accuracy 55.835 | uer 23.078 | wer 24.667 | raw_wer 24.667 | bleu 13.85 | wps 1884.5 | wpb 4003.4 | bsz 141.8 | num_updates 5890 | best_bleu 13.85
2023-07-08 09:17:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5890 updates
2023-07-08 09:17:31 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 09:17:35 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 09:17:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 4 @ 5890 updates, score 13.85) (writing took 8.06555491600011 seconds)
2023-07-08 09:17:39 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-07-08 09:17:39 | INFO | train | epoch 004 | loss 1.946 | trans_loss 3.71 | nll_loss 1.92 | w2v_ctc_loss 0.693 | task_loss 1.144 | contrastive_loss 0.277 | total 4138.65 | n_correct 2118.14 | ppl 3.78 | accuracy 51.179 | wps 13770.5 | ups 1.11 | wpb 12355.8 | bsz 458.5 | num_updates 5890 | lr 0.000184271 | gnorm 0.364 | clip 0 | loss_scale 8 | train_wall 1272 | gb_free 15 | wall 4666
2023-07-08 09:17:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 09:17:40 | INFO | fairseq.trainer | begin training epoch 5
2023-07-08 09:17:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 09:17:56 | INFO | train_inner | epoch 005:     10 / 1474 loss=1.903, trans_loss=3.673, nll_loss=1.873, w2v_ctc_loss=0.657, task_loss=1.189, contrastive_loss=0.176, total=4037.7, n_correct=2136.65, ppl=3.66, accuracy=52.918, wps=9290.2, ups=0.77, wpb=12062.8, bsz=439.3, num_updates=5900, lr=0.000184115, gnorm=0.329, clip=0, loss_scale=8, train_wall=85, gb_free=17, wall=4682
2023-07-08 09:19:24 | INFO | train_inner | epoch 005:    110 / 1474 loss=1.853, trans_loss=3.621, nll_loss=1.805, w2v_ctc_loss=0.615, task_loss=1.038, contrastive_loss=0.186, total=4247.37, n_correct=2314.15, ppl=3.5, accuracy=54.484, wps=14434.5, ups=1.14, wpb=12683.8, bsz=495.1, num_updates=6000, lr=0.000182574, gnorm=0.313, clip=0, loss_scale=8, train_wall=87, gb_free=16.9, wall=4770
2023-07-08 09:19:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 09:19:53 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 1.598 | trans_loss 5.938 | nll_loss 3.32 | w2v_ctc_loss 0.533 | task_loss 4.485 | contrastive_loss 0.303 | total 4003.4 | n_correct 2246.5 | ppl 9.99 | accuracy 56.115 | uer 22.411 | wer 23.985 | raw_wer 23.985 | bleu 14.35 | wps 1717 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 14.35
2023-07-08 09:19:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-07-08 09:19:54 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_5_6000.pt
2023-07-08 09:19:56 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_5_6000.pt
2023-07-08 09:20:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 14.35) (writing took 8.998839713996858 seconds)
2023-07-08 09:21:28 | INFO | train_inner | epoch 005:    210 / 1474 loss=1.878, trans_loss=3.63, nll_loss=1.817, w2v_ctc_loss=0.625, task_loss=1.059, contrastive_loss=0.408, total=4189.85, n_correct=2273.4, ppl=3.52, accuracy=54.26, wps=10019.8, ups=0.8, wpb=12492.8, bsz=488.2, num_updates=6100, lr=0.000181071, gnorm=0.321, clip=0, loss_scale=8, train_wall=85, gb_free=17.9, wall=4895
2023-07-08 09:22:54 | INFO | train_inner | epoch 005:    310 / 1474 loss=1.872, trans_loss=3.63, nll_loss=1.818, w2v_ctc_loss=0.634, task_loss=1.177, contrastive_loss=0.253, total=4090.1, n_correct=2211.67, ppl=3.53, accuracy=54.074, wps=14247, ups=1.16, wpb=12240, bsz=443.9, num_updates=6200, lr=0.000179605, gnorm=0.324, clip=0, loss_scale=8, train_wall=85, gb_free=16.4, wall=4981
2023-07-08 09:24:21 | INFO | train_inner | epoch 005:    410 / 1474 loss=1.864, trans_loss=3.622, nll_loss=1.811, w2v_ctc_loss=0.615, task_loss=1.104, contrastive_loss=0.335, total=4147.17, n_correct=2260.13, ppl=3.51, accuracy=54.498, wps=14247.4, ups=1.15, wpb=12381.8, bsz=472.5, num_updates=6300, lr=0.000178174, gnorm=0.324, clip=0, loss_scale=8, train_wall=86, gb_free=15.1, wall=5068
2023-07-08 09:25:48 | INFO | train_inner | epoch 005:    510 / 1474 loss=1.856, trans_loss=3.635, nll_loss=1.822, w2v_ctc_loss=0.62, task_loss=1.293, contrastive_loss=0.132, total=4026.81, n_correct=2181.3, ppl=3.54, accuracy=54.169, wps=13912.2, ups=1.15, wpb=12047.2, bsz=416.6, num_updates=6400, lr=0.000176777, gnorm=0.321, clip=0, loss_scale=8, train_wall=86, gb_free=17.5, wall=5154
2023-07-08 09:27:14 | INFO | train_inner | epoch 005:    610 / 1474 loss=1.868, trans_loss=3.628, nll_loss=1.814, w2v_ctc_loss=0.617, task_loss=1.175, contrastive_loss=0.3, total=4107.75, n_correct=2236.18, ppl=3.52, accuracy=54.438, wps=14145.3, ups=1.16, wpb=12245.3, bsz=451.2, num_updates=6500, lr=0.000175412, gnorm=0.323, clip=0, loss_scale=8, train_wall=86, gb_free=16.3, wall=5241
2023-07-08 09:28:41 | INFO | train_inner | epoch 005:    710 / 1474 loss=1.86, trans_loss=3.623, nll_loss=1.811, w2v_ctc_loss=0.618, task_loss=1.09, contrastive_loss=0.281, total=4178.85, n_correct=2279.4, ppl=3.51, accuracy=54.546, wps=14325.4, ups=1.15, wpb=12462.3, bsz=480.9, num_updates=6600, lr=0.000174078, gnorm=0.321, clip=0, loss_scale=8, train_wall=87, gb_free=17.8, wall=5328
2023-07-08 09:30:09 | INFO | train_inner | epoch 005:    810 / 1474 loss=1.853, trans_loss=3.625, nll_loss=1.811, w2v_ctc_loss=0.613, task_loss=1.183, contrastive_loss=0.206, total=4127.73, n_correct=2258.23, ppl=3.51, accuracy=54.709, wps=14123.3, ups=1.15, wpb=12320.4, bsz=449.2, num_updates=6700, lr=0.000172774, gnorm=0.317, clip=0, loss_scale=8, train_wall=87, gb_free=15.4, wall=5415
2023-07-08 09:31:35 | INFO | train_inner | epoch 005:    910 / 1474 loss=1.846, trans_loss=3.621, nll_loss=1.806, w2v_ctc_loss=0.609, task_loss=1.19, contrastive_loss=0.167, total=4095.48, n_correct=2248.86, ppl=3.5, accuracy=54.911, wps=14158.5, ups=1.16, wpb=12237.9, bsz=445.3, num_updates=6800, lr=0.000171499, gnorm=0.318, clip=0, loss_scale=8, train_wall=86, gb_free=15.8, wall=5501
2023-07-08 09:33:01 | INFO | train_inner | epoch 005:   1010 / 1474 loss=1.859, trans_loss=3.624, nll_loss=1.811, w2v_ctc_loss=0.613, task_loss=1.13, contrastive_loss=0.251, total=4165.12, n_correct=2288.89, ppl=3.51, accuracy=54.954, wps=14447.3, ups=1.16, wpb=12426.3, bsz=463.5, num_updates=6900, lr=0.000170251, gnorm=0.312, clip=0, loss_scale=8, train_wall=86, gb_free=15.9, wall=5587
2023-07-08 09:34:28 | INFO | train_inner | epoch 005:   1110 / 1474 loss=1.858, trans_loss=3.622, nll_loss=1.805, w2v_ctc_loss=0.611, task_loss=1.134, contrastive_loss=0.25, total=4176.72, n_correct=2303.19, ppl=3.5, accuracy=55.144, wps=14282.5, ups=1.15, wpb=12467.3, bsz=466.1, num_updates=7000, lr=0.000169031, gnorm=0.311, clip=0, loss_scale=8, train_wall=87, gb_free=16.9, wall=5675
2023-07-08 09:35:55 | INFO | train_inner | epoch 005:   1210 / 1474 loss=1.842, trans_loss=3.621, nll_loss=1.805, w2v_ctc_loss=0.603, task_loss=1.17, contrastive_loss=0.154, total=4164.13, n_correct=2300.17, ppl=3.5, accuracy=55.238, wps=14274.6, ups=1.15, wpb=12416.1, bsz=453.8, num_updates=7100, lr=0.000167836, gnorm=0.313, clip=0, loss_scale=16, train_wall=87, gb_free=17.1, wall=5762
2023-07-08 09:37:22 | INFO | train_inner | epoch 005:   1310 / 1474 loss=1.831, trans_loss=3.616, nll_loss=1.798, w2v_ctc_loss=0.595, task_loss=1.171, contrastive_loss=0.124, total=4134.91, n_correct=2286.73, ppl=3.48, accuracy=55.303, wps=14258.7, ups=1.15, wpb=12356.4, bsz=445.6, num_updates=7200, lr=0.000166667, gnorm=0.309, clip=0, loss_scale=16, train_wall=86, gb_free=16.6, wall=5848
2023-07-08 09:38:48 | INFO | train_inner | epoch 005:   1410 / 1474 loss=1.836, trans_loss=3.61, nll_loss=1.796, w2v_ctc_loss=0.598, task_loss=1.152, contrastive_loss=0.188, total=4134.37, n_correct=2282.97, ppl=3.47, accuracy=55.219, wps=14271.9, ups=1.16, wpb=12339.9, bsz=458.5, num_updates=7300, lr=0.000165521, gnorm=0.311, clip=0, loss_scale=16, train_wall=86, gb_free=17.9, wall=5935
2023-07-08 09:39:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 09:40:13 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 1.578 | trans_loss 5.876 | nll_loss 3.244 | w2v_ctc_loss 0.504 | task_loss 4.47 | contrastive_loss 0.293 | total 4003.4 | n_correct 2287.2 | ppl 9.47 | accuracy 57.131 | uer 21.721 | wer 23.418 | raw_wer 23.418 | bleu 14.52 | wps 1746.8 | wpb 4003.4 | bsz 141.8 | num_updates 7364 | best_bleu 14.52
2023-07-08 09:40:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7364 updates
2023-07-08 09:40:13 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 09:40:18 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 09:40:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 5 @ 7364 updates, score 14.52) (writing took 8.717175462006708 seconds)
2023-07-08 09:40:22 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-07-08 09:40:22 | INFO | train | epoch 005 | loss 1.855 | trans_loss 3.623 | nll_loss 1.809 | w2v_ctc_loss 0.613 | task_loss 1.147 | contrastive_loss 0.231 | total 4138.65 | n_correct 2265.47 | ppl 3.5 | accuracy 54.739 | wps 13364.8 | ups 1.08 | wpb 12355.8 | bsz 458.5 | num_updates 7364 | lr 0.0001648 | gnorm 0.317 | clip 0 | loss_scale 16 | train_wall 1271 | gb_free 16.4 | wall 6028
2023-07-08 09:40:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 09:40:22 | INFO | fairseq.trainer | begin training epoch 6
2023-07-08 09:40:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 09:41:01 | INFO | train_inner | epoch 006:     36 / 1474 loss=1.824, trans_loss=3.595, nll_loss=1.773, w2v_ctc_loss=0.589, task_loss=1.176, contrastive_loss=0.183, total=4115.45, n_correct=2301.77, ppl=3.42, accuracy=55.93, wps=9232.2, ups=0.75, wpb=12279.2, bsz=447.9, num_updates=7400, lr=0.000164399, gnorm=0.317, clip=0, loss_scale=16, train_wall=86, gb_free=16.6, wall=6068
2023-07-08 09:42:28 | INFO | train_inner | epoch 006:    136 / 1474 loss=1.797, trans_loss=3.569, nll_loss=1.739, w2v_ctc_loss=0.563, task_loss=1.147, contrastive_loss=0.228, total=4154.25, n_correct=2347.72, ppl=3.34, accuracy=56.514, wps=14319.9, ups=1.15, wpb=12409.6, bsz=456.1, num_updates=7500, lr=0.000163299, gnorm=0.308, clip=0, loss_scale=16, train_wall=86, gb_free=15.7, wall=6154
2023-07-08 09:43:55 | INFO | train_inner | epoch 006:    236 / 1474 loss=1.807, trans_loss=3.576, nll_loss=1.75, w2v_ctc_loss=0.582, task_loss=1.231, contrastive_loss=0.136, total=4112.66, n_correct=2308.8, ppl=3.36, accuracy=56.139, wps=14179.1, ups=1.15, wpb=12281.7, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.308, clip=0, loss_scale=16, train_wall=86, gb_free=16.3, wall=6241
2023-07-08 09:45:23 | INFO | train_inner | epoch 006:    336 / 1474 loss=1.819, trans_loss=3.566, nll_loss=1.739, w2v_ctc_loss=0.563, task_loss=1.061, contrastive_loss=0.437, total=4177.51, n_correct=2367.68, ppl=3.34, accuracy=56.677, wps=14109.2, ups=1.13, wpb=12463.7, bsz=491.3, num_updates=7700, lr=0.000161165, gnorm=0.311, clip=0, loss_scale=16, train_wall=88, gb_free=16.3, wall=6329
2023-07-08 09:46:49 | INFO | train_inner | epoch 006:    436 / 1474 loss=1.794, trans_loss=3.569, nll_loss=1.741, w2v_ctc_loss=0.564, task_loss=1.103, contrastive_loss=0.152, total=4154.57, n_correct=2359.34, ppl=3.34, accuracy=56.789, wps=14420.7, ups=1.16, wpb=12407.2, bsz=470.2, num_updates=7800, lr=0.000160128, gnorm=0.306, clip=0, loss_scale=16, train_wall=86, gb_free=16.3, wall=6415
2023-07-08 09:48:15 | INFO | train_inner | epoch 006:    536 / 1474 loss=1.799, trans_loss=3.572, nll_loss=1.745, w2v_ctc_loss=0.57, task_loss=1.155, contrastive_loss=0.139, total=4167.79, n_correct=2364.09, ppl=3.35, accuracy=56.723, wps=14401.4, ups=1.16, wpb=12419.2, bsz=455.2, num_updates=7900, lr=0.000159111, gnorm=0.309, clip=0, loss_scale=16, train_wall=86, gb_free=15.9, wall=6502
2023-07-08 09:49:41 | INFO | train_inner | epoch 006:    636 / 1474 loss=1.794, trans_loss=3.575, nll_loss=1.746, w2v_ctc_loss=0.56, task_loss=1.092, contrastive_loss=0.195, total=4146.17, n_correct=2348.26, ppl=3.35, accuracy=56.637, wps=14400.3, ups=1.16, wpb=12395.5, bsz=471.6, num_updates=8000, lr=0.000158114, gnorm=0.308, clip=0, loss_scale=16, train_wall=86, gb_free=16.7, wall=6588
2023-07-08 09:49:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 09:50:08 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 1.55 | trans_loss 5.797 | nll_loss 3.136 | w2v_ctc_loss 0.497 | task_loss 4.508 | contrastive_loss 0.286 | total 4003.4 | n_correct 2323.6 | ppl 8.79 | accuracy 58.041 | uer 20.32 | wer 21.99 | raw_wer 21.99 | bleu 16.85 | wps 2067.1 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 16.85
2023-07-08 09:50:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-07-08 09:50:08 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_6_8000.pt
2023-07-08 09:50:10 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_6_8000.pt
2023-07-08 09:50:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 16.85) (writing took 8.957935354002984 seconds)
2023-07-08 09:51:44 | INFO | train_inner | epoch 006:    736 / 1474 loss=1.796, trans_loss=3.576, nll_loss=1.751, w2v_ctc_loss=0.57, task_loss=1.174, contrastive_loss=0.149, total=4148.65, n_correct=2346.82, ppl=3.37, accuracy=56.568, wps=10080.4, ups=0.81, wpb=12378.4, bsz=453.7, num_updates=8100, lr=0.000157135, gnorm=0.306, clip=0, loss_scale=16, train_wall=87, gb_free=15.8, wall=6711
2023-07-08 09:53:11 | INFO | train_inner | epoch 006:    836 / 1474 loss=1.804, trans_loss=3.582, nll_loss=1.756, w2v_ctc_loss=0.567, task_loss=1.204, contrastive_loss=0.131, total=4114.34, n_correct=2318.34, ppl=3.38, accuracy=56.348, wps=14201.9, ups=1.16, wpb=12292.5, bsz=441.6, num_updates=8200, lr=0.000156174, gnorm=0.31, clip=0, loss_scale=16, train_wall=86, gb_free=15.3, wall=6797
2023-07-08 09:54:37 | INFO | train_inner | epoch 006:    936 / 1474 loss=1.808, trans_loss=3.579, nll_loss=1.755, w2v_ctc_loss=0.571, task_loss=1.196, contrastive_loss=0.225, total=4081.53, n_correct=2305.71, ppl=3.37, accuracy=56.491, wps=14081.9, ups=1.16, wpb=12166.1, bsz=444.5, num_updates=8300, lr=0.00015523, gnorm=0.312, clip=0, loss_scale=16, train_wall=86, gb_free=17.9, wall=6884
2023-07-08 09:56:04 | INFO | train_inner | epoch 006:   1036 / 1474 loss=1.808, trans_loss=3.572, nll_loss=1.746, w2v_ctc_loss=0.563, task_loss=1.089, contrastive_loss=0.304, total=4165.84, n_correct=2367.44, ppl=3.35, accuracy=56.83, wps=14378.5, ups=1.16, wpb=12437.3, bsz=477.2, num_updates=8400, lr=0.000154303, gnorm=0.314, clip=0, loss_scale=16, train_wall=86, gb_free=17, wall=6970
2023-07-08 09:57:30 | INFO | train_inner | epoch 006:   1136 / 1474 loss=1.798, trans_loss=3.578, nll_loss=1.752, w2v_ctc_loss=0.565, task_loss=1.271, contrastive_loss=0.131, total=4072.29, n_correct=2308.48, ppl=3.37, accuracy=56.688, wps=14118.1, ups=1.16, wpb=12165.1, bsz=428, num_updates=8500, lr=0.000153393, gnorm=0.306, clip=0, loss_scale=16, train_wall=86, gb_free=17.1, wall=7056
2023-07-08 09:58:57 | INFO | train_inner | epoch 006:   1236 / 1474 loss=1.814, trans_loss=3.569, nll_loss=1.743, w2v_ctc_loss=0.557, task_loss=1.113, contrastive_loss=0.45, total=4141.55, n_correct=2362.04, ppl=3.35, accuracy=57.033, wps=14233, ups=1.15, wpb=12385.8, bsz=474.8, num_updates=8600, lr=0.000152499, gnorm=0.304, clip=0, loss_scale=16, train_wall=87, gb_free=13.5, wall=7143
2023-07-08 10:00:23 | INFO | train_inner | epoch 006:   1336 / 1474 loss=1.793, trans_loss=3.577, nll_loss=1.748, w2v_ctc_loss=0.558, task_loss=1.143, contrastive_loss=0.118, total=4125.31, n_correct=2353.38, ppl=3.36, accuracy=57.047, wps=14360.9, ups=1.17, wpb=12316, bsz=452.6, num_updates=8700, lr=0.00015162, gnorm=0.306, clip=0, loss_scale=16, train_wall=85, gb_free=17.8, wall=7229
2023-07-08 10:01:49 | INFO | train_inner | epoch 006:   1436 / 1474 loss=1.786, trans_loss=3.565, nll_loss=1.739, w2v_ctc_loss=0.559, task_loss=1.147, contrastive_loss=0.126, total=4196.2, n_correct=2401.37, ppl=3.34, accuracy=57.227, wps=14431.6, ups=1.15, wpb=12515.5, bsz=461.5, num_updates=8800, lr=0.000150756, gnorm=0.301, clip=0, loss_scale=16, train_wall=86, gb_free=11.8, wall=7316
2023-07-08 10:02:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 10:02:49 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 1.527 | trans_loss 5.773 | nll_loss 3.1 | w2v_ctc_loss 0.473 | task_loss 4.566 | contrastive_loss 0.275 | total 4003.4 | n_correct 2346.3 | ppl 8.57 | accuracy 58.608 | uer 19.606 | wer 21.409 | raw_wer 21.409 | bleu 16.96 | wps 1952.5 | wpb 4003.4 | bsz 141.8 | num_updates 8838 | best_bleu 16.96
2023-07-08 10:02:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8838 updates
2023-07-08 10:02:49 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 10:02:53 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 10:02:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 6 @ 8838 updates, score 16.96) (writing took 8.131521486007841 seconds)
2023-07-08 10:02:57 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-07-08 10:02:57 | INFO | train | epoch 006 | loss 1.801 | trans_loss 3.572 | nll_loss 1.746 | w2v_ctc_loss 0.565 | task_loss 1.148 | contrastive_loss 0.208 | total 4138.65 | n_correct 2347.18 | ppl 3.35 | accuracy 56.714 | wps 13437.4 | ups 1.09 | wpb 12355.8 | bsz 458.5 | num_updates 8838 | lr 0.000150431 | gnorm 0.308 | clip 0 | loss_scale 16 | train_wall 1270 | gb_free 15.3 | wall 7384
2023-07-08 10:02:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 10:02:58 | INFO | fairseq.trainer | begin training epoch 7
2023-07-08 10:02:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 10:04:00 | INFO | train_inner | epoch 007:     62 / 1474 loss=1.766, trans_loss=3.542, nll_loss=1.707, w2v_ctc_loss=0.539, task_loss=1.12, contrastive_loss=0.139, total=4108.19, n_correct=2372, ppl=3.27, accuracy=57.738, wps=9424.4, ups=0.77, wpb=12269.7, bsz=461.9, num_updates=8900, lr=0.000149906, gnorm=0.3, clip=0, loss_scale=16, train_wall=86, gb_free=17.2, wall=7446
2023-07-08 10:05:26 | INFO | train_inner | epoch 007:    162 / 1474 loss=1.768, trans_loss=3.535, nll_loss=1.698, w2v_ctc_loss=0.533, task_loss=1.163, contrastive_loss=0.217, total=4106.05, n_correct=2377.67, ppl=3.25, accuracy=57.907, wps=14227.2, ups=1.16, wpb=12254.3, bsz=455.4, num_updates=9000, lr=0.000149071, gnorm=0.305, clip=0, loss_scale=16, train_wall=86, gb_free=16.9, wall=7532
2023-07-08 10:06:52 | INFO | train_inner | epoch 007:    262 / 1474 loss=1.754, trans_loss=3.532, nll_loss=1.693, w2v_ctc_loss=0.532, task_loss=1.164, contrastive_loss=0.121, total=4129.3, n_correct=2397.46, ppl=3.23, accuracy=58.06, wps=14290.9, ups=1.16, wpb=12322.9, bsz=451.8, num_updates=9100, lr=0.00014825, gnorm=0.299, clip=0, loss_scale=16, train_wall=86, gb_free=17.4, wall=7618
2023-07-08 10:08:19 | INFO | train_inner | epoch 007:    362 / 1474 loss=1.773, trans_loss=3.539, nll_loss=1.703, w2v_ctc_loss=0.529, task_loss=1.106, contrastive_loss=0.381, total=4201.67, n_correct=2430.21, ppl=3.25, accuracy=57.839, wps=14442.8, ups=1.15, wpb=12533.1, bsz=479.7, num_updates=9200, lr=0.000147442, gnorm=0.3, clip=0, loss_scale=32, train_wall=86, gb_free=15.6, wall=7705
2023-07-08 10:09:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-08 10:09:46 | INFO | train_inner | epoch 007:    463 / 1474 loss=1.768, trans_loss=3.538, nll_loss=1.705, w2v_ctc_loss=0.535, task_loss=1.16, contrastive_loss=0.246, total=4140.2, n_correct=2390.62, ppl=3.26, accuracy=57.742, wps=14187.3, ups=1.15, wpb=12352.1, bsz=456.1, num_updates=9300, lr=0.000146647, gnorm=0.302, clip=0, loss_scale=16, train_wall=87, gb_free=16.9, wall=7792
2023-07-08 10:11:12 | INFO | train_inner | epoch 007:    563 / 1474 loss=1.759, trans_loss=3.537, nll_loss=1.702, w2v_ctc_loss=0.533, task_loss=1.122, contrastive_loss=0.129, total=4168.14, n_correct=2417.54, ppl=3.25, accuracy=58, wps=14447.8, ups=1.16, wpb=12410.5, bsz=459.8, num_updates=9400, lr=0.000145865, gnorm=0.3, clip=0, loss_scale=16, train_wall=85, gb_free=17, wall=7878
2023-07-08 10:12:39 | INFO | train_inner | epoch 007:    663 / 1474 loss=1.758, trans_loss=3.541, nll_loss=1.702, w2v_ctc_loss=0.527, task_loss=1.139, contrastive_loss=0.117, total=4157.82, n_correct=2417.22, ppl=3.25, accuracy=58.137, wps=14268, ups=1.15, wpb=12417.8, bsz=455.4, num_updates=9500, lr=0.000145095, gnorm=0.301, clip=0, loss_scale=16, train_wall=87, gb_free=15.8, wall=7965
2023-07-08 10:14:06 | INFO | train_inner | epoch 007:    763 / 1474 loss=1.761, trans_loss=3.539, nll_loss=1.702, w2v_ctc_loss=0.532, task_loss=1.201, contrastive_loss=0.114, total=4122.1, n_correct=2393.54, ppl=3.25, accuracy=58.066, wps=14176.6, ups=1.15, wpb=12321.9, bsz=446.2, num_updates=9600, lr=0.000144338, gnorm=0.302, clip=0, loss_scale=16, train_wall=87, gb_free=15.8, wall=8052
2023-07-08 10:15:32 | INFO | train_inner | epoch 007:    863 / 1474 loss=1.762, trans_loss=3.538, nll_loss=1.7, w2v_ctc_loss=0.53, task_loss=1.158, contrastive_loss=0.134, total=4147.23, n_correct=2407.72, ppl=3.25, accuracy=58.056, wps=14292.8, ups=1.15, wpb=12392, bsz=460.9, num_updates=9700, lr=0.000143592, gnorm=0.305, clip=0, loss_scale=16, train_wall=86, gb_free=17.6, wall=8139
2023-07-08 10:16:59 | INFO | train_inner | epoch 007:    963 / 1474 loss=1.764, trans_loss=3.537, nll_loss=1.702, w2v_ctc_loss=0.527, task_loss=1.094, contrastive_loss=0.229, total=4140.14, n_correct=2408.04, ppl=3.25, accuracy=58.163, wps=14302.8, ups=1.16, wpb=12360, bsz=474.6, num_updates=9800, lr=0.000142857, gnorm=0.305, clip=0, loss_scale=16, train_wall=86, gb_free=16.1, wall=8225
2023-07-08 10:18:26 | INFO | train_inner | epoch 007:   1063 / 1474 loss=1.754, trans_loss=3.545, nll_loss=1.711, w2v_ctc_loss=0.529, task_loss=1.21, contrastive_loss=0.098, total=4103.51, n_correct=2379.01, ppl=3.27, accuracy=57.975, wps=14113, ups=1.15, wpb=12263.4, bsz=437.5, num_updates=9900, lr=0.000142134, gnorm=0.301, clip=0, loss_scale=16, train_wall=86, gb_free=16.9, wall=8312
2023-07-08 10:19:52 | INFO | train_inner | epoch 007:   1163 / 1474 loss=1.769, trans_loss=3.536, nll_loss=1.705, w2v_ctc_loss=0.527, task_loss=1.117, contrastive_loss=0.364, total=4137.04, n_correct=2399.31, ppl=3.26, accuracy=57.996, wps=14291.1, ups=1.16, wpb=12348.6, bsz=470.9, num_updates=10000, lr=0.000141421, gnorm=0.307, clip=0, loss_scale=16, train_wall=86, gb_free=16.2, wall=8398
2023-07-08 10:19:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 10:20:20 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 1.519 | trans_loss 5.731 | nll_loss 3.048 | w2v_ctc_loss 0.469 | task_loss 4.563 | contrastive_loss 0.283 | total 4003.4 | n_correct 2372.3 | ppl 8.27 | accuracy 59.257 | uer 19.019 | wer 20.752 | raw_wer 20.752 | bleu 17.38 | wps 1948 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 17.38
2023-07-08 10:20:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-07-08 10:20:20 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_7_10000.pt
2023-07-08 10:20:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_7_10000.pt
2023-07-08 10:20:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 17.38) (writing took 9.547549404000165 seconds)
tensor(0.6057, device='cuda:0')
tensor(0.5101, device='cuda:0')
2023-07-08 10:21:56 | INFO | train_inner | epoch 007:   1263 / 1474 loss=1.75, trans_loss=3.532, nll_loss=1.697, w2v_ctc_loss=0.523, task_loss=1.162, contrastive_loss=0.125, total=4129.52, n_correct=2403.78, ppl=3.24, accuracy=58.21, wps=9981.4, ups=0.81, wpb=12329.2, bsz=450.2, num_updates=10100, lr=0.00014072, gnorm=0.229, clip=0, loss_scale=16, train_wall=86, gb_free=17, wall=8522
2023-07-08 10:23:21 | INFO | train_inner | epoch 007:   1363 / 1474 loss=1.757, trans_loss=3.529, nll_loss=1.693, w2v_ctc_loss=0.528, task_loss=1.078, contrastive_loss=0.162, total=4172.87, n_correct=2441.96, ppl=3.23, accuracy=58.52, wps=14515.5, ups=1.17, wpb=12453.5, bsz=476.2, num_updates=10200, lr=0.000140028, gnorm=0.232, clip=0, loss_scale=16, train_wall=85, gb_free=17.3, wall=8608
2023-07-08 10:24:49 | INFO | train_inner | epoch 007:   1463 / 1474 loss=1.763, trans_loss=3.54, nll_loss=1.708, w2v_ctc_loss=0.528, task_loss=1.242, contrastive_loss=0.227, total=4109.42, n_correct=2388.46, ppl=3.27, accuracy=58.122, wps=13973.5, ups=1.14, wpb=12285.7, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.234, clip=0, loss_scale=16, train_wall=87, gb_free=16.6, wall=8696
2023-07-08 10:24:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.6057, device='cuda:6')
tensor(0.5101, device='cuda:6')
tensor(0.6057, device='cuda:5')
tensor(0.5101, device='cuda:5')
tensor(0.6057, device='cuda:7')
tensor(0.5101, device='cuda:7')
tensor(0.6057, device='cuda:4')
tensor(0.5101, device='cuda:4')
tensor(0.6057, device='cuda:1')
tensor(0.5101, device='cuda:1')
tensor(0.6057, device='cuda:3')
tensor(0.5101, device='cuda:3')
tensor(0.6057, device='cuda:2')
tensor(0.5101, device='cuda:2')
2023-07-08 10:25:26 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 1.509 | trans_loss 5.727 | nll_loss 3.044 | w2v_ctc_loss 0.464 | task_loss 4.594 | contrastive_loss 0.274 | total 4003.4 | n_correct 2373.6 | ppl 8.25 | accuracy 59.29 | uer 18.902 | wer 20.745 | raw_wer 20.745 | bleu 17.67 | wps 1886.4 | wpb 4003.4 | bsz 141.8 | num_updates 10311 | best_bleu 17.67
2023-07-08 10:25:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10311 updates
2023-07-08 10:25:26 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 10:25:31 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 10:25:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 7 @ 10311 updates, score 17.67) (writing took 7.93848753500788 seconds)
2023-07-08 10:25:35 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-07-08 10:25:35 | INFO | train | epoch 007 | loss 1.761 | trans_loss 3.537 | nll_loss 1.701 | w2v_ctc_loss 0.53 | task_loss 1.151 | contrastive_loss 0.189 | total 4137.82 | n_correct 2402.14 | ppl 3.25 | accuracy 58.053 | wps 13407 | ups 1.09 | wpb 12353.7 | bsz 458 | num_updates 10311 | lr 0.000139272 | gnorm 0.287 | clip 0 | loss_scale 16 | train_wall 1269 | gb_free 13.5 | wall 8741
2023-07-08 10:25:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 10:25:35 | INFO | fairseq.trainer | begin training epoch 8
2023-07-08 10:25:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 10:27:00 | INFO | train_inner | epoch 008:     89 / 1474 loss=1.732, trans_loss=3.511, nll_loss=1.665, w2v_ctc_loss=0.506, task_loss=1.213, contrastive_loss=0.12, total=4116.25, n_correct=2428.31, ppl=3.17, accuracy=58.993, wps=9385.1, ups=0.77, wpb=12265.9, bsz=443.3, num_updates=10400, lr=0.000138675, gnorm=0.231, clip=0, loss_scale=16, train_wall=86, gb_free=17.1, wall=8826
2023-07-08 10:28:26 | INFO | train_inner | epoch 008:    189 / 1474 loss=1.741, trans_loss=3.515, nll_loss=1.67, w2v_ctc_loss=0.51, task_loss=1.245, contrastive_loss=0.144, total=4037.23, n_correct=2380.67, ppl=3.18, accuracy=58.968, wps=13991.5, ups=1.16, wpb=12033.3, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.236, clip=0, loss_scale=16, train_wall=86, gb_free=13.1, wall=8912
2023-07-08 10:29:52 | INFO | train_inner | epoch 008:    289 / 1474 loss=1.722, trans_loss=3.503, nll_loss=1.654, w2v_ctc_loss=0.499, task_loss=1.082, contrastive_loss=0.138, total=4207.78, n_correct=2495.62, ppl=3.15, accuracy=59.31, wps=14587.8, ups=1.16, wpb=12570.1, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.228, clip=0, loss_scale=16, train_wall=86, gb_free=13.3, wall=8999
2023-07-08 10:31:20 | INFO | train_inner | epoch 008:    389 / 1474 loss=1.742, trans_loss=3.512, nll_loss=1.667, w2v_ctc_loss=0.515, task_loss=1.221, contrastive_loss=0.161, total=4127.24, n_correct=2432.01, ppl=3.18, accuracy=58.926, wps=13962, ups=1.13, wpb=12318.5, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=0.233, clip=0, loss_scale=16, train_wall=88, gb_free=12.1, wall=9087
2023-07-08 10:32:47 | INFO | train_inner | epoch 008:    489 / 1474 loss=1.756, trans_loss=3.51, nll_loss=1.666, w2v_ctc_loss=0.504, task_loss=1.032, contrastive_loss=0.424, total=4203.76, n_correct=2482.99, ppl=3.17, accuracy=59.066, wps=14493.2, ups=1.15, wpb=12567.7, bsz=504.5, num_updates=10800, lr=0.000136083, gnorm=0.234, clip=0, loss_scale=16, train_wall=86, gb_free=14.7, wall=9174
2023-07-08 10:34:14 | INFO | train_inner | epoch 008:    589 / 1474 loss=1.73, trans_loss=3.511, nll_loss=1.668, w2v_ctc_loss=0.508, task_loss=1.255, contrastive_loss=0.095, total=4062.5, n_correct=2390.62, ppl=3.18, accuracy=58.846, wps=13987.3, ups=1.15, wpb=12171.9, bsz=427.9, num_updates=10900, lr=0.000135457, gnorm=0.23, clip=0, loss_scale=16, train_wall=87, gb_free=11.7, wall=9261
2023-07-08 10:35:41 | INFO | train_inner | epoch 008:    689 / 1474 loss=1.728, trans_loss=3.507, nll_loss=1.664, w2v_ctc_loss=0.511, task_loss=1.185, contrastive_loss=0.107, total=4142.78, n_correct=2459.13, ppl=3.17, accuracy=59.359, wps=14141.2, ups=1.15, wpb=12347.9, bsz=448.6, num_updates=11000, lr=0.00013484, gnorm=0.23, clip=0, loss_scale=16, train_wall=87, gb_free=16, wall=9348
2023-07-08 10:37:08 | INFO | train_inner | epoch 008:    789 / 1474 loss=1.732, trans_loss=3.505, nll_loss=1.662, w2v_ctc_loss=0.505, task_loss=1.18, contrastive_loss=0.195, total=4118.9, n_correct=2438.42, ppl=3.17, accuracy=59.201, wps=14240.1, ups=1.16, wpb=12327.8, bsz=447.8, num_updates=11100, lr=0.000134231, gnorm=0.233, clip=0, loss_scale=16, train_wall=86, gb_free=15.3, wall=9434
2023-07-08 10:38:35 | INFO | train_inner | epoch 008:    889 / 1474 loss=1.733, trans_loss=3.508, nll_loss=1.666, w2v_ctc_loss=0.502, task_loss=1.102, contrastive_loss=0.208, total=4169.01, n_correct=2469.86, ppl=3.17, accuracy=59.243, wps=14356.1, ups=1.15, wpb=12455.3, bsz=473.7, num_updates=11200, lr=0.000133631, gnorm=0.234, clip=0, loss_scale=16, train_wall=86, gb_free=16.3, wall=9521
2023-07-08 10:40:01 | INFO | train_inner | epoch 008:    989 / 1474 loss=1.718, trans_loss=3.502, nll_loss=1.657, w2v_ctc_loss=0.497, task_loss=1.098, contrastive_loss=0.104, total=4154.69, n_correct=2472.93, ppl=3.15, accuracy=59.521, wps=14416.2, ups=1.16, wpb=12398.4, bsz=464.9, num_updates=11300, lr=0.000133038, gnorm=0.228, clip=0, loss_scale=16, train_wall=86, gb_free=17.8, wall=9607
2023-07-08 10:41:29 | INFO | train_inner | epoch 008:   1089 / 1474 loss=1.741, trans_loss=3.508, nll_loss=1.667, w2v_ctc_loss=0.503, task_loss=1.147, contrastive_loss=0.327, total=4199.1, n_correct=2482.71, ppl=3.18, accuracy=59.125, wps=14266.7, ups=1.14, wpb=12520.7, bsz=465.3, num_updates=11400, lr=0.000132453, gnorm=0.228, clip=0, loss_scale=32, train_wall=87, gb_free=13, wall=9695
2023-07-08 10:42:55 | INFO | train_inner | epoch 008:   1189 / 1474 loss=1.724, trans_loss=3.507, nll_loss=1.666, w2v_ctc_loss=0.502, task_loss=1.086, contrastive_loss=0.115, total=4177.31, n_correct=2479.24, ppl=3.17, accuracy=59.35, wps=14431.6, ups=1.16, wpb=12476.4, bsz=472.6, num_updates=11500, lr=0.000131876, gnorm=0.229, clip=0, loss_scale=32, train_wall=86, gb_free=15.1, wall=9781
2023-07-08 10:44:21 | INFO | train_inner | epoch 008:   1289 / 1474 loss=1.733, trans_loss=3.508, nll_loss=1.667, w2v_ctc_loss=0.508, task_loss=1.2, contrastive_loss=0.135, total=4063.85, n_correct=2403.74, ppl=3.18, accuracy=59.149, wps=14071.1, ups=1.16, wpb=12141.2, bsz=438.4, num_updates=11600, lr=0.000131306, gnorm=0.233, clip=0, loss_scale=32, train_wall=86, gb_free=16.9, wall=9868
2023-07-08 10:45:47 | INFO | train_inner | epoch 008:   1389 / 1474 loss=1.732, trans_loss=3.509, nll_loss=1.67, w2v_ctc_loss=0.504, task_loss=1.141, contrastive_loss=0.187, total=4141.5, n_correct=2455.94, ppl=3.18, accuracy=59.301, wps=14427, ups=1.17, wpb=12351.9, bsz=461.5, num_updates=11700, lr=0.000130744, gnorm=0.228, clip=0, loss_scale=32, train_wall=85, gb_free=16.7, wall=9953
2023-07-08 10:47:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 10:47:28 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 1.498 | trans_loss 5.683 | nll_loss 2.986 | w2v_ctc_loss 0.459 | task_loss 4.575 | contrastive_loss 0.269 | total 4003.4 | n_correct 2408.2 | ppl 7.93 | accuracy 60.154 | uer 18.177 | wer 20.007 | raw_wer 20.007 | bleu 18.17 | wps 1956.9 | wpb 4003.4 | bsz 141.8 | num_updates 11785 | best_bleu 18.17
2023-07-08 10:47:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11785 updates
2023-07-08 10:47:28 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 10:47:32 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 10:47:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 8 @ 11785 updates, score 18.17) (writing took 8.13324637299229 seconds)
2023-07-08 10:47:36 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-07-08 10:47:36 | INFO | train | epoch 008 | loss 1.733 | trans_loss 3.508 | nll_loss 1.665 | w2v_ctc_loss 0.505 | task_loss 1.15 | contrastive_loss 0.183 | total 4138.65 | n_correct 2449.59 | ppl 3.17 | accuracy 59.188 | wps 13784.6 | ups 1.12 | wpb 12355.8 | bsz 458.5 | num_updates 11785 | lr 0.000130272 | gnorm 0.231 | clip 0 | loss_scale 32 | train_wall 1271 | gb_free 17.1 | wall 10062
2023-07-08 10:47:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 10:47:36 | INFO | fairseq.trainer | begin training epoch 9
2023-07-08 10:47:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 10:47:57 | INFO | train_inner | epoch 009:     15 / 1474 loss=1.739, trans_loss=3.504, nll_loss=1.663, w2v_ctc_loss=0.498, task_loss=1.107, contrastive_loss=0.316, total=4139.35, n_correct=2463.32, ppl=3.17, accuracy=59.51, wps=9453.3, ups=0.77, wpb=12332.8, bsz=472.9, num_updates=11800, lr=0.000130189, gnorm=0.232, clip=0, loss_scale=32, train_wall=86, gb_free=16.4, wall=10084
2023-07-08 10:49:24 | INFO | train_inner | epoch 009:    115 / 1474 loss=1.697, trans_loss=3.476, nll_loss=1.623, w2v_ctc_loss=0.477, task_loss=1.092, contrastive_loss=0.131, total=4181.9, n_correct=2524.86, ppl=3.08, accuracy=60.376, wps=14450.9, ups=1.16, wpb=12493.2, bsz=475.9, num_updates=11900, lr=0.000129641, gnorm=0.226, clip=0, loss_scale=32, train_wall=86, gb_free=16.4, wall=10170
2023-07-08 10:50:50 | INFO | train_inner | epoch 009:    215 / 1474 loss=1.702, trans_loss=3.486, nll_loss=1.636, w2v_ctc_loss=0.481, task_loss=1.241, contrastive_loss=0.093, total=4062.07, n_correct=2439.47, ppl=3.11, accuracy=60.055, wps=14029.5, ups=1.16, wpb=12136.5, bsz=431.6, num_updates=12000, lr=0.000129099, gnorm=0.228, clip=0, loss_scale=32, train_wall=86, gb_free=15.8, wall=10257
2023-07-08 10:50:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 10:51:19 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 1.504 | trans_loss 5.703 | nll_loss 3.012 | w2v_ctc_loss 0.446 | task_loss 4.566 | contrastive_loss 0.267 | total 4003.4 | n_correct 2394.4 | ppl 8.06 | accuracy 59.809 | uer 18.286 | wer 20.074 | raw_wer 20.074 | bleu 18.05 | wps 1920.9 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 18.17
2023-07-08 10:51:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-07-08 10:51:19 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_9_12000.pt
2023-07-08 10:51:21 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_9_12000.pt
2023-07-08 10:51:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.05) (writing took 6.111558693999541 seconds)
2023-07-08 10:52:51 | INFO | train_inner | epoch 009:    315 / 1474 loss=1.7, trans_loss=3.473, nll_loss=1.621, w2v_ctc_loss=0.475, task_loss=1.075, contrastive_loss=0.139, total=4152.1, n_correct=2512.22, ppl=3.08, accuracy=60.505, wps=10292.8, ups=0.83, wpb=12422.8, bsz=476.6, num_updates=12100, lr=0.000128565, gnorm=0.228, clip=0, loss_scale=32, train_wall=86, gb_free=16.4, wall=10377
2023-07-08 10:54:19 | INFO | train_inner | epoch 009:    415 / 1474 loss=1.703, trans_loss=3.481, nll_loss=1.632, w2v_ctc_loss=0.481, task_loss=1.123, contrastive_loss=0.11, total=4203.78, n_correct=2523.32, ppl=3.1, accuracy=60.025, wps=14275.8, ups=1.14, wpb=12545.5, bsz=469.8, num_updates=12200, lr=0.000128037, gnorm=0.228, clip=0, loss_scale=32, train_wall=87, gb_free=17.2, wall=10465
2023-07-08 10:55:45 | INFO | train_inner | epoch 009:    515 / 1474 loss=1.717, trans_loss=3.491, nll_loss=1.644, w2v_ctc_loss=0.493, task_loss=1.204, contrastive_loss=0.159, total=4112.78, n_correct=2460.49, ppl=3.13, accuracy=59.825, wps=14253.4, ups=1.16, wpb=12260.1, bsz=437.7, num_updates=12300, lr=0.000127515, gnorm=0.233, clip=0, loss_scale=32, train_wall=86, gb_free=16.3, wall=10551
2023-07-08 10:57:12 | INFO | train_inner | epoch 009:    615 / 1474 loss=1.702, trans_loss=3.481, nll_loss=1.633, w2v_ctc_loss=0.48, task_loss=1.173, contrastive_loss=0.118, total=4131.32, n_correct=2485.01, ppl=3.1, accuracy=60.151, wps=14260.7, ups=1.15, wpb=12355.3, bsz=455, num_updates=12400, lr=0.000127, gnorm=0.229, clip=0, loss_scale=32, train_wall=86, gb_free=17.9, wall=10638
2023-07-08 10:58:38 | INFO | train_inner | epoch 009:    715 / 1474 loss=1.721, trans_loss=3.489, nll_loss=1.642, w2v_ctc_loss=0.491, task_loss=1.175, contrastive_loss=0.202, total=4082.11, n_correct=2443.43, ppl=3.12, accuracy=59.857, wps=14126.1, ups=1.16, wpb=12206.9, bsz=449.7, num_updates=12500, lr=0.000126491, gnorm=0.234, clip=0, loss_scale=32, train_wall=86, gb_free=17.1, wall=10724
2023-07-08 11:00:05 | INFO | train_inner | epoch 009:    815 / 1474 loss=1.73, trans_loss=3.477, nll_loss=1.631, w2v_ctc_loss=0.49, task_loss=1.034, contrastive_loss=0.344, total=4221.08, n_correct=2535.25, ppl=3.1, accuracy=60.062, wps=14422.6, ups=1.14, wpb=12600.2, bsz=501.6, num_updates=12600, lr=0.000125988, gnorm=0.232, clip=0, loss_scale=32, train_wall=87, gb_free=17.7, wall=10812
2023-07-08 11:01:33 | INFO | train_inner | epoch 009:    915 / 1474 loss=1.719, trans_loss=3.49, nll_loss=1.643, w2v_ctc_loss=0.485, task_loss=1.191, contrastive_loss=0.324, total=4142.34, n_correct=2481.69, ppl=3.12, accuracy=59.91, wps=14028.6, ups=1.14, wpb=12345.3, bsz=448.9, num_updates=12700, lr=0.000125491, gnorm=0.229, clip=0, loss_scale=32, train_wall=88, gb_free=17.4, wall=10900
2023-07-08 11:03:00 | INFO | train_inner | epoch 009:   1015 / 1474 loss=1.714, trans_loss=3.498, nll_loss=1.651, w2v_ctc_loss=0.489, task_loss=1.289, contrastive_loss=0.105, total=4097.15, n_correct=2446.8, ppl=3.14, accuracy=59.72, wps=14077.3, ups=1.15, wpb=12230.8, bsz=422.6, num_updates=12800, lr=0.000125, gnorm=0.23, clip=0, loss_scale=32, train_wall=86, gb_free=16.9, wall=10987
2023-07-08 11:04:27 | INFO | train_inner | epoch 009:   1115 / 1474 loss=1.708, trans_loss=3.486, nll_loss=1.637, w2v_ctc_loss=0.486, task_loss=1.075, contrastive_loss=0.13, total=4182.29, n_correct=2522.62, ppl=3.11, accuracy=60.317, wps=14412, ups=1.16, wpb=12446.8, bsz=477.6, num_updates=12900, lr=0.000124515, gnorm=0.232, clip=0, loss_scale=32, train_wall=86, gb_free=17.3, wall=11073
2023-07-08 11:05:54 | INFO | train_inner | epoch 009:   1215 / 1474 loss=1.712, trans_loss=3.495, nll_loss=1.645, w2v_ctc_loss=0.488, task_loss=1.222, contrastive_loss=0.112, total=4141.43, n_correct=2484.32, ppl=3.13, accuracy=59.987, wps=14194, ups=1.14, wpb=12406.5, bsz=446.6, num_updates=13000, lr=0.000124035, gnorm=0.229, clip=0, loss_scale=32, train_wall=87, gb_free=17.6, wall=11160
2023-07-08 11:07:20 | INFO | train_inner | epoch 009:   1315 / 1474 loss=1.713, trans_loss=3.482, nll_loss=1.634, w2v_ctc_loss=0.477, task_loss=1.048, contrastive_loss=0.304, total=4203.91, n_correct=2535.58, ppl=3.1, accuracy=60.315, wps=14568.4, ups=1.16, wpb=12540.7, bsz=492.3, num_updates=13100, lr=0.00012356, gnorm=0.23, clip=0, loss_scale=32, train_wall=86, gb_free=17.4, wall=11247
2023-07-08 11:08:46 | INFO | train_inner | epoch 009:   1415 / 1474 loss=1.712, trans_loss=3.497, nll_loss=1.65, w2v_ctc_loss=0.489, task_loss=1.244, contrastive_loss=0.09, total=4077.08, n_correct=2440.71, ppl=3.14, accuracy=59.864, wps=14131, ups=1.16, wpb=12171.4, bsz=429.1, num_updates=13200, lr=0.000123091, gnorm=0.23, clip=0, loss_scale=32, train_wall=86, gb_free=17.4, wall=11333
2023-07-08 11:09:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 11:10:05 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 1.495 | trans_loss 5.662 | nll_loss 2.961 | w2v_ctc_loss 0.457 | task_loss 4.58 | contrastive_loss 0.256 | total 4003.4 | n_correct 2411.6 | ppl 7.78 | accuracy 60.239 | uer 17.885 | wer 19.716 | raw_wer 19.716 | bleu 18.73 | wps 1886.1 | wpb 4003.4 | bsz 141.8 | num_updates 13259 | best_bleu 18.73
2023-07-08 11:10:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13259 updates
2023-07-08 11:10:05 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 11:10:09 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 11:10:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 9 @ 13259 updates, score 18.73) (writing took 8.232754238997586 seconds)
2023-07-08 11:10:13 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-07-08 11:10:13 | INFO | train | epoch 009 | loss 1.711 | trans_loss 3.486 | nll_loss 1.637 | w2v_ctc_loss 0.485 | task_loss 1.15 | contrastive_loss 0.175 | total 4138.65 | n_correct 2486.49 | ppl 3.11 | accuracy 60.08 | wps 13417.9 | ups 1.09 | wpb 12355.8 | bsz 458.5 | num_updates 13259 | lr 0.000122817 | gnorm 0.23 | clip 0 | loss_scale 32 | train_wall 1271 | gb_free 12 | wall 11420
2023-07-08 11:10:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 11:10:13 | INFO | fairseq.trainer | begin training epoch 10
2023-07-08 11:10:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 11:10:57 | INFO | train_inner | epoch 010:     41 / 1474 loss=1.702, trans_loss=3.478, nll_loss=1.627, w2v_ctc_loss=0.477, task_loss=1.097, contrastive_loss=0.186, total=4100.86, n_correct=2482.82, ppl=3.09, accuracy=60.544, wps=9376.6, ups=0.77, wpb=12244.8, bsz=470.2, num_updates=13300, lr=0.000122628, gnorm=0.234, clip=0, loss_scale=32, train_wall=85, gb_free=16.7, wall=11463
2023-07-08 11:12:23 | INFO | train_inner | epoch 010:    141 / 1474 loss=1.683, trans_loss=3.46, nll_loss=1.601, w2v_ctc_loss=0.461, task_loss=1.086, contrastive_loss=0.109, total=4240.18, n_correct=2591.97, ppl=3.03, accuracy=61.129, wps=14680.4, ups=1.16, wpb=12698.4, bsz=479.1, num_updates=13400, lr=0.000122169, gnorm=0.225, clip=0, loss_scale=64, train_wall=86, gb_free=15.1, wall=11550
2023-07-08 11:13:50 | INFO | train_inner | epoch 010:    241 / 1474 loss=1.689, trans_loss=3.456, nll_loss=1.6, w2v_ctc_loss=0.465, task_loss=1.141, contrastive_loss=0.234, total=4126.3, n_correct=2521.38, ppl=3.03, accuracy=61.105, wps=14256.5, ups=1.16, wpb=12290.2, bsz=460.9, num_updates=13500, lr=0.000121716, gnorm=0.229, clip=0, loss_scale=64, train_wall=86, gb_free=15.7, wall=11636
2023-07-08 11:15:17 | INFO | train_inner | epoch 010:    341 / 1474 loss=1.682, trans_loss=3.456, nll_loss=1.602, w2v_ctc_loss=0.463, task_loss=1.169, contrastive_loss=0.144, total=4132.25, n_correct=2519.72, ppl=3.03, accuracy=60.977, wps=14214.1, ups=1.15, wpb=12358.2, bsz=452.8, num_updates=13600, lr=0.000121268, gnorm=0.227, clip=0, loss_scale=64, train_wall=87, gb_free=14.9, wall=11723
2023-07-08 11:16:45 | INFO | train_inner | epoch 010:    441 / 1474 loss=1.692, trans_loss=3.459, nll_loss=1.604, w2v_ctc_loss=0.457, task_loss=1.104, contrastive_loss=0.319, total=4203.14, n_correct=2562.52, ppl=3.04, accuracy=60.967, wps=14201.8, ups=1.13, wpb=12542, bsz=481.7, num_updates=13700, lr=0.000120824, gnorm=0.227, clip=0, loss_scale=64, train_wall=88, gb_free=16.5, wall=11811
2023-07-08 11:18:11 | INFO | train_inner | epoch 010:    541 / 1474 loss=1.695, trans_loss=3.471, nll_loss=1.616, w2v_ctc_loss=0.475, task_loss=1.228, contrastive_loss=0.099, total=4106.5, n_correct=2493.51, ppl=3.06, accuracy=60.721, wps=14186.5, ups=1.16, wpb=12236.6, bsz=440, num_updates=13800, lr=0.000120386, gnorm=0.231, clip=0, loss_scale=64, train_wall=86, gb_free=16.6, wall=11898
2023-07-08 11:18:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-08 11:19:39 | INFO | train_inner | epoch 010:    642 / 1474 loss=1.696, trans_loss=3.471, nll_loss=1.617, w2v_ctc_loss=0.469, task_loss=1.121, contrastive_loss=0.201, total=4152.41, n_correct=2524.27, ppl=3.07, accuracy=60.79, wps=14154.5, ups=1.14, wpb=12400.4, bsz=468.3, num_updates=13900, lr=0.000119952, gnorm=0.23, clip=0, loss_scale=32, train_wall=87, gb_free=16.4, wall=11985
2023-07-08 11:21:05 | INFO | train_inner | epoch 010:    742 / 1474 loss=1.694, trans_loss=3.47, nll_loss=1.617, w2v_ctc_loss=0.478, task_loss=1.151, contrastive_loss=0.097, total=4125.87, n_correct=2501.63, ppl=3.07, accuracy=60.633, wps=14311.7, ups=1.16, wpb=12315.5, bsz=454.4, num_updates=14000, lr=0.000119523, gnorm=0.234, clip=0, loss_scale=32, train_wall=86, gb_free=14.7, wall=12071
2023-07-08 11:21:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 11:21:31 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 1.487 | trans_loss 5.66 | nll_loss 2.957 | w2v_ctc_loss 0.462 | task_loss 4.605 | contrastive_loss 0.26 | total 4003.4 | n_correct 2418.2 | ppl 7.77 | accuracy 60.404 | uer 17.96 | wer 19.805 | raw_wer 19.805 | bleu 18.49 | wps 2070.7 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 18.73
2023-07-08 11:21:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-07-08 11:21:31 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_10_14000.pt
2023-07-08 11:21:34 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_10_14000.pt
2023-07-08 11:21:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 18.49) (writing took 6.173833779990673 seconds)
2023-07-08 11:23:04 | INFO | train_inner | epoch 010:    842 / 1474 loss=1.683, trans_loss=3.469, nll_loss=1.615, w2v_ctc_loss=0.465, task_loss=1.142, contrastive_loss=0.099, total=4128.44, n_correct=2509.14, ppl=3.06, accuracy=60.777, wps=10321.7, ups=0.84, wpb=12345, bsz=456.3, num_updates=14100, lr=0.000119098, gnorm=0.227, clip=0, loss_scale=32, train_wall=86, gb_free=14.9, wall=12191
2023-07-08 11:24:30 | INFO | train_inner | epoch 010:    942 / 1474 loss=1.695, trans_loss=3.466, nll_loss=1.614, w2v_ctc_loss=0.474, task_loss=1.105, contrastive_loss=0.138, total=4160.94, n_correct=2530.31, ppl=3.06, accuracy=60.811, wps=14429.5, ups=1.17, wpb=12380.2, bsz=468.1, num_updates=14200, lr=0.000118678, gnorm=0.232, clip=0, loss_scale=32, train_wall=85, gb_free=15.6, wall=12277
2023-07-08 11:25:57 | INFO | train_inner | epoch 010:   1042 / 1474 loss=1.692, trans_loss=3.471, nll_loss=1.62, w2v_ctc_loss=0.473, task_loss=1.246, contrastive_loss=0.112, total=4067.53, n_correct=2464.06, ppl=3.07, accuracy=60.579, wps=14034.1, ups=1.16, wpb=12142, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.232, clip=0, loss_scale=32, train_wall=86, gb_free=17, wall=12363
2023-07-08 11:27:23 | INFO | train_inner | epoch 010:   1142 / 1474 loss=1.692, trans_loss=3.474, nll_loss=1.623, w2v_ctc_loss=0.474, task_loss=1.278, contrastive_loss=0.091, total=4044.03, n_correct=2447.32, ppl=3.08, accuracy=60.517, wps=13981.3, ups=1.16, wpb=12072.9, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.231, clip=0, loss_scale=32, train_wall=86, gb_free=17.4, wall=12449
2023-07-08 11:28:50 | INFO | train_inner | epoch 010:   1242 / 1474 loss=1.689, trans_loss=3.467, nll_loss=1.618, w2v_ctc_loss=0.473, task_loss=1.177, contrastive_loss=0.087, total=4110.41, n_correct=2495.85, ppl=3.07, accuracy=60.72, wps=14227.7, ups=1.16, wpb=12302.3, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.231, clip=0, loss_scale=32, train_wall=86, gb_free=16.6, wall=12536
2023-07-08 11:30:16 | INFO | train_inner | epoch 010:   1342 / 1474 loss=1.688, trans_loss=3.467, nll_loss=1.615, w2v_ctc_loss=0.469, task_loss=1.175, contrastive_loss=0.101, total=4121.38, n_correct=2506.6, ppl=3.06, accuracy=60.819, wps=14163.9, ups=1.15, wpb=12315.5, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.229, clip=0, loss_scale=32, train_wall=86, gb_free=14.3, wall=12623
2023-07-08 11:31:43 | INFO | train_inner | epoch 010:   1442 / 1474 loss=1.706, trans_loss=3.473, nll_loss=1.625, w2v_ctc_loss=0.463, task_loss=1.084, contrastive_loss=0.353, total=4192.39, n_correct=2543.61, ppl=3.08, accuracy=60.672, wps=14366.5, ups=1.15, wpb=12477.9, bsz=482, num_updates=14700, lr=0.000116642, gnorm=0.231, clip=0, loss_scale=32, train_wall=86, gb_free=17.2, wall=12710
2023-07-08 11:32:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 11:32:39 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 1.486 | trans_loss 5.646 | nll_loss 2.941 | w2v_ctc_loss 0.459 | task_loss 4.609 | contrastive_loss 0.262 | total 4003.4 | n_correct 2425.3 | ppl 7.68 | accuracy 60.581 | uer 17.769 | wer 19.653 | raw_wer 19.653 | bleu 18.73 | wps 1738.5 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 18.73
2023-07-08 11:32:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-07-08 11:32:39 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 11:32:44 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 11:32:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 10 @ 14732 updates, score 18.73) (writing took 8.38148766499944 seconds)
2023-07-08 11:32:48 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-07-08 11:32:48 | INFO | train | epoch 010 | loss 1.691 | trans_loss 3.467 | nll_loss 1.613 | w2v_ctc_loss 0.468 | task_loss 1.153 | contrastive_loss 0.167 | total 4137.4 | n_correct 2515.87 | ppl 3.06 | accuracy 60.808 | wps 13433.3 | ups 1.09 | wpb 12352.3 | bsz 458 | num_updates 14732 | lr 0.000116516 | gnorm 0.23 | clip 0 | loss_scale 32 | train_wall 1270 | gb_free 17.4 | wall 12774
2023-07-08 11:32:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 11:32:48 | INFO | fairseq.trainer | begin training epoch 11
2023-07-08 11:32:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 11:33:54 | INFO | train_inner | epoch 011:     68 / 1474 loss=1.672, trans_loss=3.448, nll_loss=1.59, w2v_ctc_loss=0.453, task_loss=1.068, contrastive_loss=0.175, total=4175.24, n_correct=2571.87, ppl=3.01, accuracy=61.598, wps=9546, ups=0.77, wpb=12460.8, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.225, clip=0, loss_scale=32, train_wall=85, gb_free=16.9, wall=12840
2023-07-08 11:35:21 | INFO | train_inner | epoch 011:    168 / 1474 loss=1.666, trans_loss=3.447, nll_loss=1.589, w2v_ctc_loss=0.453, task_loss=1.189, contrastive_loss=0.095, total=4087.78, n_correct=2512.95, ppl=3.01, accuracy=61.475, wps=14089.7, ups=1.15, wpb=12225.8, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.229, clip=0, loss_scale=32, train_wall=86, gb_free=16.7, wall=12927
2023-07-08 11:36:47 | INFO | train_inner | epoch 011:    268 / 1474 loss=1.666, trans_loss=3.446, nll_loss=1.589, w2v_ctc_loss=0.452, task_loss=1.185, contrastive_loss=0.091, total=4118.77, n_correct=2528.93, ppl=3.01, accuracy=61.4, wps=14258.3, ups=1.16, wpb=12285.5, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.23, clip=0, loss_scale=32, train_wall=86, gb_free=12.7, wall=13013
tensor(0.2526, device='cuda:0')
tensor(0.1323, device='cuda:0')
2023-07-08 11:38:13 | INFO | train_inner | epoch 011:    368 / 1474 loss=1.671, trans_loss=3.444, nll_loss=1.584, w2v_ctc_loss=0.451, task_loss=1.18, contrastive_loss=0.096, total=4097.83, n_correct=2524.66, ppl=3, accuracy=61.61, wps=14167.7, ups=1.16, wpb=12202.1, bsz=444.2, num_updates=15100, lr=0.000115087, gnorm=0.171, clip=0, loss_scale=32, train_wall=86, gb_free=16.4, wall=13099
2023-07-08 11:39:40 | INFO | train_inner | epoch 011:    468 / 1474 loss=1.688, trans_loss=3.459, nll_loss=1.599, w2v_ctc_loss=0.453, task_loss=1.205, contrastive_loss=0.251, total=4110.64, n_correct=2515.97, ppl=3.03, accuracy=61.206, wps=14013.6, ups=1.14, wpb=12265.6, bsz=450.5, num_updates=15200, lr=0.000114708, gnorm=0.171, clip=0, loss_scale=32, train_wall=87, gb_free=16.5, wall=13187
2023-07-08 11:41:08 | INFO | train_inner | epoch 011:    568 / 1474 loss=1.689, trans_loss=3.455, nll_loss=1.6, w2v_ctc_loss=0.461, task_loss=1.231, contrastive_loss=0.252, total=4071.69, n_correct=2494.94, ppl=3.03, accuracy=61.275, wps=13991.5, ups=1.15, wpb=12176.5, bsz=440.6, num_updates=15300, lr=0.000114332, gnorm=0.172, clip=0, loss_scale=32, train_wall=87, gb_free=16.5, wall=13274
2023-07-08 11:42:34 | INFO | train_inner | epoch 011:    668 / 1474 loss=1.691, trans_loss=3.451, nll_loss=1.593, w2v_ctc_loss=0.456, task_loss=1.133, contrastive_loss=0.333, total=4157.2, n_correct=2553.26, ppl=3.02, accuracy=61.418, wps=14310.5, ups=1.15, wpb=12400.2, bsz=464.4, num_updates=15400, lr=0.000113961, gnorm=0.172, clip=0, loss_scale=32, train_wall=86, gb_free=16.9, wall=13361
2023-07-08 11:44:02 | INFO | train_inner | epoch 011:    768 / 1474 loss=1.675, trans_loss=3.456, nll_loss=1.598, w2v_ctc_loss=0.459, task_loss=1.154, contrastive_loss=0.096, total=4174.91, n_correct=2565.42, ppl=3.03, accuracy=61.449, wps=14269.6, ups=1.14, wpb=12472.8, bsz=460.4, num_updates=15500, lr=0.000113592, gnorm=0.17, clip=0, loss_scale=32, train_wall=87, gb_free=17.1, wall=13448
2023-07-08 11:45:28 | INFO | train_inner | epoch 011:    868 / 1474 loss=1.67, trans_loss=3.454, nll_loss=1.599, w2v_ctc_loss=0.458, task_loss=1.206, contrastive_loss=0.081, total=4118.44, n_correct=2519.61, ppl=3.03, accuracy=61.179, wps=14256.1, ups=1.16, wpb=12290.5, bsz=440.6, num_updates=15600, lr=0.000113228, gnorm=0.17, clip=0, loss_scale=32, train_wall=86, gb_free=11.2, wall=13534
2023-07-08 11:46:55 | INFO | train_inner | epoch 011:    968 / 1474 loss=1.672, trans_loss=3.454, nll_loss=1.597, w2v_ctc_loss=0.458, task_loss=1.176, contrastive_loss=0.097, total=4140.92, n_correct=2540.55, ppl=3.03, accuracy=61.352, wps=14237.3, ups=1.15, wpb=12353.7, bsz=452.9, num_updates=15700, lr=0.000112867, gnorm=0.169, clip=0, loss_scale=32, train_wall=86, gb_free=15.8, wall=13621
2023-07-08 11:48:21 | INFO | train_inner | epoch 011:   1068 / 1474 loss=1.68, trans_loss=3.451, nll_loss=1.595, w2v_ctc_loss=0.461, task_loss=1.13, contrastive_loss=0.122, total=4136.99, n_correct=2542.49, ppl=3.02, accuracy=61.457, wps=14357.4, ups=1.16, wpb=12367, bsz=463.2, num_updates=15800, lr=0.000112509, gnorm=0.17, clip=0, loss_scale=32, train_wall=86, gb_free=17.7, wall=13707
2023-07-08 11:49:48 | INFO | train_inner | epoch 011:   1168 / 1474 loss=1.679, trans_loss=3.455, nll_loss=1.603, w2v_ctc_loss=0.463, task_loss=1.141, contrastive_loss=0.105, total=4185.65, n_correct=2561.07, ppl=3.04, accuracy=61.187, wps=14360.3, ups=1.15, wpb=12477.8, bsz=464.7, num_updates=15900, lr=0.000112154, gnorm=0.17, clip=0, loss_scale=64, train_wall=86, gb_free=14.3, wall=13794
2023-07-08 11:51:14 | INFO | train_inner | epoch 011:   1268 / 1474 loss=1.693, trans_loss=3.456, nll_loss=1.602, w2v_ctc_loss=0.467, task_loss=1.105, contrastive_loss=0.195, total=4171.89, n_correct=2555.14, ppl=3.04, accuracy=61.247, wps=14367.4, ups=1.15, wpb=12466.6, bsz=471.1, num_updates=16000, lr=0.000111803, gnorm=0.172, clip=0, loss_scale=64, train_wall=86, gb_free=16.1, wall=13881
2023-07-08 11:51:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.2526, device='cuda:5')
tensor(0.1323, device='cuda:5')
tensor(0.2526, device='cuda:6')
tensor(0.1323, device='cuda:6')
tensor(0.2526, device='cuda:1')
tensor(0.1323, device='cuda:1')
tensor(0.2526, device='cuda:7')
tensor(0.1323, device='cuda:7')
tensor(0.2526, device='cuda:4')
tensor(0.1323, device='cuda:4')
tensor(0.2526, device='cuda:3')
tensor(0.1323, device='cuda:3')
tensor(0.2526, device='cuda:2')
tensor(0.1323, device='cuda:2')
2023-07-08 11:51:41 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 1.478 | trans_loss 5.635 | nll_loss 2.92 | w2v_ctc_loss 0.474 | task_loss 4.648 | contrastive_loss 0.252 | total 4003.4 | n_correct 2434.6 | ppl 7.57 | accuracy 60.813 | uer 17.57 | wer 19.321 | raw_wer 19.321 | bleu 18.97 | wps 2045.6 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 18.97
2023-07-08 11:51:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-07-08 11:51:41 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_11_16000.pt
2023-07-08 11:51:43 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_11_16000.pt
2023-07-08 11:51:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 18.97) (writing took 8.995852295003715 seconds)
2023-07-08 11:53:18 | INFO | train_inner | epoch 011:   1368 / 1474 loss=1.692, trans_loss=3.453, nll_loss=1.597, w2v_ctc_loss=0.454, task_loss=1.066, contrastive_loss=0.411, total=4190.34, n_correct=2568.17, ppl=3.03, accuracy=61.288, wps=10096.3, ups=0.81, wpb=12512.8, bsz=491.8, num_updates=16100, lr=0.000111456, gnorm=0.169, clip=0, loss_scale=64, train_wall=87, gb_free=17.1, wall=14005
2023-07-08 11:54:45 | INFO | train_inner | epoch 011:   1468 / 1474 loss=1.674, trans_loss=3.453, nll_loss=1.598, w2v_ctc_loss=0.456, task_loss=1.114, contrastive_loss=0.106, total=4158.39, n_correct=2554.17, ppl=3.03, accuracy=61.422, wps=14349.1, ups=1.16, wpb=12421.8, bsz=468, num_updates=16200, lr=0.000111111, gnorm=0.168, clip=0, loss_scale=64, train_wall=86, gb_free=17.1, wall=14091
2023-07-08 11:54:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 11:55:17 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 1.478 | trans_loss 5.63 | nll_loss 2.921 | w2v_ctc_loss 0.45 | task_loss 4.602 | contrastive_loss 0.261 | total 4003.4 | n_correct 2431.9 | ppl 7.57 | accuracy 60.746 | uer 17.601 | wer 19.425 | raw_wer 19.425 | bleu 18.94 | wps 1963.3 | wpb 4003.4 | bsz 141.8 | num_updates 16206 | best_bleu 18.97
2023-07-08 11:55:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16206 updates
2023-07-08 11:55:17 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_18.9409.pt
2023-07-08 11:55:20 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_18.9409.pt
2023-07-08 11:55:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_18.9409.pt (epoch 11 @ 16206 updates, score 18.94) (writing took 5.241716873992118 seconds)
2023-07-08 11:55:23 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-07-08 11:55:23 | INFO | train | epoch 011 | loss 1.678 | trans_loss 3.452 | nll_loss 1.595 | w2v_ctc_loss 0.457 | task_loss 1.151 | contrastive_loss 0.164 | total 4138.65 | n_correct 2540.32 | ppl 3.02 | accuracy 61.38 | wps 13440 | ups 1.09 | wpb 12355.8 | bsz 458.5 | num_updates 16206 | lr 0.000111091 | gnorm 0.181 | clip 0 | loss_scale 64 | train_wall 1271 | gb_free 17.3 | wall 14129
2023-07-08 11:55:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 11:55:23 | INFO | fairseq.trainer | begin training epoch 12
2023-07-08 11:55:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 11:56:52 | INFO | train_inner | epoch 012:     94 / 1474 loss=1.66, trans_loss=3.428, nll_loss=1.563, w2v_ctc_loss=0.445, task_loss=1.104, contrastive_loss=0.149, total=4146.82, n_correct=2583.18, ppl=2.95, accuracy=62.293, wps=9737.2, ups=0.79, wpb=12379.4, bsz=470.8, num_updates=16300, lr=0.00011077, gnorm=0.168, clip=0, loss_scale=64, train_wall=86, gb_free=15.9, wall=14218
2023-07-08 11:58:19 | INFO | train_inner | epoch 012:    194 / 1474 loss=1.657, trans_loss=3.43, nll_loss=1.567, w2v_ctc_loss=0.447, task_loss=1.191, contrastive_loss=0.085, total=4120.68, n_correct=2563.86, ppl=2.96, accuracy=62.219, wps=14194.7, ups=1.15, wpb=12345.4, bsz=442.1, num_updates=16400, lr=0.000110432, gnorm=0.169, clip=0, loss_scale=64, train_wall=87, gb_free=15.8, wall=14305
2023-07-08 11:59:46 | INFO | train_inner | epoch 012:    294 / 1474 loss=1.655, trans_loss=3.43, nll_loss=1.568, w2v_ctc_loss=0.439, task_loss=1.084, contrastive_loss=0.126, total=4199.46, n_correct=2616.05, ppl=2.97, accuracy=62.295, wps=14434.7, ups=1.15, wpb=12539.6, bsz=480.4, num_updates=16500, lr=0.000110096, gnorm=0.167, clip=0, loss_scale=64, train_wall=86, gb_free=16.7, wall=14392
2023-07-08 12:01:13 | INFO | train_inner | epoch 012:    394 / 1474 loss=1.662, trans_loss=3.433, nll_loss=1.572, w2v_ctc_loss=0.446, task_loss=1.127, contrastive_loss=0.104, total=4151.14, n_correct=2581.03, ppl=2.97, accuracy=62.176, wps=14265.6, ups=1.15, wpb=12410, bsz=461.6, num_updates=16600, lr=0.000109764, gnorm=0.169, clip=0, loss_scale=64, train_wall=87, gb_free=17.3, wall=14479
2023-07-08 12:02:40 | INFO | train_inner | epoch 012:    494 / 1474 loss=1.676, trans_loss=3.447, nll_loss=1.586, w2v_ctc_loss=0.457, task_loss=1.155, contrastive_loss=0.114, total=4110.49, n_correct=2541.49, ppl=3, accuracy=61.829, wps=14113.4, ups=1.15, wpb=12226.9, bsz=453.3, num_updates=16700, lr=0.000109435, gnorm=0.171, clip=0, loss_scale=64, train_wall=86, gb_free=14.1, wall=14566
2023-07-08 12:04:07 | INFO | train_inner | epoch 012:    594 / 1474 loss=1.672, trans_loss=3.435, nll_loss=1.576, w2v_ctc_loss=0.45, task_loss=1.101, contrastive_loss=0.199, total=4189.92, n_correct=2598.58, ppl=2.98, accuracy=62.02, wps=14277.5, ups=1.14, wpb=12531.1, bsz=472.7, num_updates=16800, lr=0.000109109, gnorm=0.169, clip=0, loss_scale=64, train_wall=87, gb_free=15.1, wall=14654
2023-07-08 12:05:34 | INFO | train_inner | epoch 012:    694 / 1474 loss=1.668, trans_loss=3.432, nll_loss=1.572, w2v_ctc_loss=0.441, task_loss=1.056, contrastive_loss=0.318, total=4206.3, n_correct=2613.74, ppl=2.97, accuracy=62.139, wps=14468.3, ups=1.16, wpb=12501.9, bsz=488.5, num_updates=16900, lr=0.000108786, gnorm=0.17, clip=0, loss_scale=64, train_wall=86, gb_free=16.4, wall=14740
2023-07-08 12:07:00 | INFO | train_inner | epoch 012:    794 / 1474 loss=1.663, trans_loss=3.439, nll_loss=1.577, w2v_ctc_loss=0.451, task_loss=1.179, contrastive_loss=0.101, total=4085.96, n_correct=2535.28, ppl=2.98, accuracy=62.049, wps=14092.3, ups=1.15, wpb=12212.6, bsz=445.7, num_updates=17000, lr=0.000108465, gnorm=0.171, clip=0, loss_scale=64, train_wall=86, gb_free=16.7, wall=14827
2023-07-08 12:08:27 | INFO | train_inner | epoch 012:    894 / 1474 loss=1.67, trans_loss=3.434, nll_loss=1.575, w2v_ctc_loss=0.447, task_loss=1.173, contrastive_loss=0.166, total=4169.74, n_correct=2591.55, ppl=2.98, accuracy=62.151, wps=14340.2, ups=1.15, wpb=12453, bsz=459.6, num_updates=17100, lr=0.000108148, gnorm=0.17, clip=0, loss_scale=64, train_wall=86, gb_free=16.2, wall=14914
2023-07-08 12:09:54 | INFO | train_inner | epoch 012:    994 / 1474 loss=1.674, trans_loss=3.443, nll_loss=1.584, w2v_ctc_loss=0.454, task_loss=1.175, contrastive_loss=0.181, total=4117.67, n_correct=2548.71, ppl=3, accuracy=61.897, wps=14217.8, ups=1.16, wpb=12288, bsz=452.1, num_updates=17200, lr=0.000107833, gnorm=0.171, clip=0, loss_scale=64, train_wall=86, gb_free=17.7, wall=15000
2023-07-08 12:11:20 | INFO | train_inner | epoch 012:   1094 / 1474 loss=1.686, trans_loss=3.446, nll_loss=1.588, w2v_ctc_loss=0.456, task_loss=1.205, contrastive_loss=0.239, total=4047.61, n_correct=2499.94, ppl=3.01, accuracy=61.763, wps=13985.4, ups=1.16, wpb=12086.1, bsz=435.6, num_updates=17300, lr=0.000107521, gnorm=0.173, clip=0, loss_scale=64, train_wall=86, gb_free=16.9, wall=15086
2023-07-08 12:12:47 | INFO | train_inner | epoch 012:   1194 / 1474 loss=1.678, trans_loss=3.446, nll_loss=1.592, w2v_ctc_loss=0.461, task_loss=1.14, contrastive_loss=0.178, total=4184.55, n_correct=2574.13, ppl=3.01, accuracy=61.515, wps=14343.8, ups=1.15, wpb=12497.1, bsz=471.4, num_updates=17400, lr=0.000107211, gnorm=0.171, clip=0, loss_scale=64, train_wall=87, gb_free=16.9, wall=15174
2023-07-08 12:14:14 | INFO | train_inner | epoch 012:   1294 / 1474 loss=1.671, trans_loss=3.447, nll_loss=1.593, w2v_ctc_loss=0.457, task_loss=1.256, contrastive_loss=0.105, total=4086.33, n_correct=2522.53, ppl=3.02, accuracy=61.731, wps=14011.8, ups=1.15, wpb=12210.8, bsz=437.2, num_updates=17500, lr=0.000106904, gnorm=0.173, clip=0, loss_scale=64, train_wall=87, gb_free=17, wall=15261
2023-07-08 12:15:42 | INFO | train_inner | epoch 012:   1394 / 1474 loss=1.673, trans_loss=3.441, nll_loss=1.583, w2v_ctc_loss=0.446, task_loss=1.166, contrastive_loss=0.221, total=4134.89, n_correct=2562.78, ppl=3, accuracy=61.979, wps=14123.5, ups=1.15, wpb=12323.9, bsz=456.6, num_updates=17600, lr=0.0001066, gnorm=0.17, clip=0, loss_scale=64, train_wall=87, gb_free=17.4, wall=15348
2023-07-08 12:16:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 12:17:19 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 1.484 | trans_loss 5.627 | nll_loss 2.914 | w2v_ctc_loss 0.464 | task_loss 4.596 | contrastive_loss 0.262 | total 4003.4 | n_correct 2439.2 | ppl 7.54 | accuracy 60.928 | uer 17.795 | wer 19.388 | raw_wer 19.388 | bleu 18.84 | wps 1927.5 | wpb 4003.4 | bsz 141.8 | num_updates 17680 | best_bleu 18.97
2023-07-08 12:17:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17680 updates
2023-07-08 12:17:19 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_18.8401.pt
2023-07-08 12:17:21 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_18.8401.pt
2023-07-08 12:17:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_18.8401.pt (epoch 12 @ 17680 updates, score 18.84) (writing took 5.201842395006679 seconds)
2023-07-08 12:17:24 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-07-08 12:17:24 | INFO | train | epoch 012 | loss 1.669 | trans_loss 3.438 | nll_loss 1.579 | w2v_ctc_loss 0.45 | task_loss 1.151 | contrastive_loss 0.16 | total 4138.65 | n_correct 2565.92 | ppl 2.99 | accuracy 61.999 | wps 13783.7 | ups 1.12 | wpb 12355.8 | bsz 458.5 | num_updates 17680 | lr 0.000106359 | gnorm 0.17 | clip 0 | loss_scale 64 | train_wall 1273 | gb_free 13.2 | wall 15450
2023-07-08 12:17:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 12:17:24 | INFO | fairseq.trainer | begin training epoch 13
2023-07-08 12:17:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 12:17:49 | INFO | train_inner | epoch 013:     20 / 1474 loss=1.67, trans_loss=3.441, nll_loss=1.584, w2v_ctc_loss=0.456, task_loss=1.19, contrastive_loss=0.093, total=4104.86, n_correct=2539.1, ppl=3, accuracy=61.856, wps=9591, ups=0.78, wpb=12264.8, bsz=445.3, num_updates=17700, lr=0.000106299, gnorm=0.169, clip=0, loss_scale=64, train_wall=86, gb_free=15, wall=15476
2023-07-08 12:19:17 | INFO | train_inner | epoch 013:    120 / 1474 loss=1.649, trans_loss=3.415, nll_loss=1.55, w2v_ctc_loss=0.436, task_loss=1.153, contrastive_loss=0.109, total=4161.2, n_correct=2615.71, ppl=2.93, accuracy=62.86, wps=14257.8, ups=1.15, wpb=12419, bsz=454.4, num_updates=17800, lr=0.000106, gnorm=0.168, clip=0, loss_scale=64, train_wall=87, gb_free=16.3, wall=15563
2023-07-08 12:20:44 | INFO | train_inner | epoch 013:    220 / 1474 loss=1.671, trans_loss=3.419, nll_loss=1.558, w2v_ctc_loss=0.439, task_loss=1.066, contrastive_loss=0.395, total=4202.62, n_correct=2632.8, ppl=2.94, accuracy=62.647, wps=14231.3, ups=1.14, wpb=12504.4, bsz=492.4, num_updates=17900, lr=0.000105703, gnorm=0.168, clip=0, loss_scale=64, train_wall=87, gb_free=17.3, wall=15651
2023-07-08 12:22:11 | INFO | train_inner | epoch 013:    320 / 1474 loss=1.65, trans_loss=3.421, nll_loss=1.555, w2v_ctc_loss=0.437, task_loss=1.189, contrastive_loss=0.09, total=4112.8, n_correct=2586.4, ppl=2.94, accuracy=62.887, wps=14137.6, ups=1.15, wpb=12262.5, bsz=444, num_updates=18000, lr=0.000105409, gnorm=0.171, clip=0, loss_scale=128, train_wall=86, gb_free=17.9, wall=15738
2023-07-08 12:22:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 12:22:40 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 1.485 | trans_loss 5.633 | nll_loss 2.915 | w2v_ctc_loss 0.453 | task_loss 4.588 | contrastive_loss 0.251 | total 4003.4 | n_correct 2443.3 | ppl 7.54 | accuracy 61.031 | uer 17.546 | wer 19.116 | raw_wer 19.116 | bleu 19.14 | wps 1774.3 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.14
2023-07-08 12:22:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-07-08 12:22:40 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_13_18000.pt
2023-07-08 12:22:43 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_13_18000.pt
2023-07-08 12:22:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.14) (writing took 9.03037996000785 seconds)
2023-07-08 12:24:16 | INFO | train_inner | epoch 013:    420 / 1474 loss=1.661, trans_loss=3.427, nll_loss=1.564, w2v_ctc_loss=0.441, task_loss=1.087, contrastive_loss=0.152, total=4176.06, n_correct=2620.38, ppl=2.96, accuracy=62.748, wps=9965.7, ups=0.8, wpb=12453.9, bsz=476.2, num_updates=18100, lr=0.000105118, gnorm=0.17, clip=0, loss_scale=128, train_wall=86, gb_free=16.6, wall=15863
2023-07-08 12:25:43 | INFO | train_inner | epoch 013:    520 / 1474 loss=1.667, trans_loss=3.428, nll_loss=1.565, w2v_ctc_loss=0.444, task_loss=1.12, contrastive_loss=0.199, total=4197.57, n_correct=2621.53, ppl=2.96, accuracy=62.454, wps=14350.9, ups=1.15, wpb=12523.8, bsz=477.2, num_updates=18200, lr=0.000104828, gnorm=0.17, clip=0, loss_scale=128, train_wall=87, gb_free=15.5, wall=15950
2023-07-08 12:27:10 | INFO | train_inner | epoch 013:    620 / 1474 loss=1.646, trans_loss=3.419, nll_loss=1.555, w2v_ctc_loss=0.437, task_loss=1.116, contrastive_loss=0.084, total=4160.12, n_correct=2612.49, ppl=2.94, accuracy=62.798, wps=14336.6, ups=1.15, wpb=12433.1, bsz=463, num_updates=18300, lr=0.000104542, gnorm=0.168, clip=0, loss_scale=128, train_wall=86, gb_free=16.5, wall=16037
2023-07-08 12:28:37 | INFO | train_inner | epoch 013:    720 / 1474 loss=1.66, trans_loss=3.428, nll_loss=1.566, w2v_ctc_loss=0.451, task_loss=1.271, contrastive_loss=0.082, total=4101.54, n_correct=2557.35, ppl=2.96, accuracy=62.351, wps=14045.1, ups=1.15, wpb=12238, bsz=428.5, num_updates=18400, lr=0.000104257, gnorm=0.17, clip=0, loss_scale=128, train_wall=87, gb_free=15.9, wall=16124
2023-07-08 12:28:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-08 12:30:06 | INFO | train_inner | epoch 013:    821 / 1474 loss=1.659, trans_loss=3.427, nll_loss=1.564, w2v_ctc_loss=0.441, task_loss=1.177, contrastive_loss=0.144, total=4118.2, n_correct=2569, ppl=2.96, accuracy=62.382, wps=13889.3, ups=1.13, wpb=12312.3, bsz=457.2, num_updates=18500, lr=0.000103975, gnorm=0.173, clip=0, loss_scale=64, train_wall=88, gb_free=15, wall=16212
2023-07-08 12:31:32 | INFO | train_inner | epoch 013:    921 / 1474 loss=1.65, trans_loss=3.427, nll_loss=1.565, w2v_ctc_loss=0.44, task_loss=1.177, contrastive_loss=0.097, total=4107.01, n_correct=2566.01, ppl=2.96, accuracy=62.479, wps=14245.6, ups=1.16, wpb=12264.1, bsz=444.7, num_updates=18600, lr=0.000103695, gnorm=0.171, clip=0, loss_scale=64, train_wall=86, gb_free=16.1, wall=16298
2023-07-08 12:32:59 | INFO | train_inner | epoch 013:   1021 / 1474 loss=1.667, trans_loss=3.426, nll_loss=1.567, w2v_ctc_loss=0.449, task_loss=1.214, contrastive_loss=0.163, total=4081.02, n_correct=2537.83, ppl=2.96, accuracy=62.186, wps=14088.8, ups=1.15, wpb=12208.8, bsz=440.1, num_updates=18700, lr=0.000103418, gnorm=0.171, clip=0, loss_scale=64, train_wall=86, gb_free=16.4, wall=16385
2023-07-08 12:34:24 | INFO | train_inner | epoch 013:   1121 / 1474 loss=1.654, trans_loss=3.424, nll_loss=1.561, w2v_ctc_loss=0.439, task_loss=1.137, contrastive_loss=0.139, total=4105.62, n_correct=2571.79, ppl=2.95, accuracy=62.641, wps=14322.3, ups=1.17, wpb=12265.4, bsz=458.9, num_updates=18800, lr=0.000103142, gnorm=0.17, clip=0, loss_scale=64, train_wall=85, gb_free=16.9, wall=16471
2023-07-08 12:35:51 | INFO | train_inner | epoch 013:   1221 / 1474 loss=1.663, trans_loss=3.435, nll_loss=1.574, w2v_ctc_loss=0.449, task_loss=1.227, contrastive_loss=0.086, total=4110.35, n_correct=2561.56, ppl=2.98, accuracy=62.32, wps=14165.6, ups=1.15, wpb=12287.7, bsz=442.6, num_updates=18900, lr=0.000102869, gnorm=0.173, clip=0, loss_scale=64, train_wall=86, gb_free=15.1, wall=16557
2023-07-08 12:37:18 | INFO | train_inner | epoch 013:   1321 / 1474 loss=1.657, trans_loss=3.425, nll_loss=1.566, w2v_ctc_loss=0.44, task_loss=1.134, contrastive_loss=0.215, total=4112.2, n_correct=2573.04, ppl=2.96, accuracy=62.571, wps=14124.5, ups=1.15, wpb=12280.4, bsz=462.3, num_updates=19000, lr=0.000102598, gnorm=0.172, clip=0, loss_scale=64, train_wall=86, gb_free=17.7, wall=16644
2023-07-08 12:38:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-08 12:38:46 | INFO | train_inner | epoch 013:   1422 / 1474 loss=1.654, trans_loss=3.433, nll_loss=1.57, w2v_ctc_loss=0.441, task_loss=1.171, contrastive_loss=0.08, total=4156.59, n_correct=2594.04, ppl=2.97, accuracy=62.408, wps=14181, ups=1.14, wpb=12408.2, bsz=455, num_updates=19100, lr=0.000102329, gnorm=0.169, clip=0, loss_scale=32, train_wall=87, gb_free=16.2, wall=16732
2023-07-08 12:39:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 12:39:58 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 1.47 | trans_loss 5.604 | nll_loss 2.887 | w2v_ctc_loss 0.452 | task_loss 4.623 | contrastive_loss 0.244 | total 4003.4 | n_correct 2458.2 | ppl 7.4 | accuracy 61.403 | uer 17.357 | wer 19.082 | raw_wer 19.082 | bleu 19.28 | wps 1936.5 | wpb 4003.4 | bsz 141.8 | num_updates 19152 | best_bleu 19.28
2023-07-08 12:39:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19152 updates
2023-07-08 12:39:58 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 12:40:02 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 12:40:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 13 @ 19152 updates, score 19.28) (writing took 8.246226964998641 seconds)
2023-07-08 12:40:07 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-07-08 12:40:07 | INFO | train | epoch 013 | loss 1.658 | trans_loss 3.425 | nll_loss 1.563 | w2v_ctc_loss 0.442 | task_loss 1.154 | contrastive_loss 0.146 | total 4137.24 | n_correct 2588.15 | ppl 2.95 | accuracy 62.558 | wps 13343.2 | ups 1.08 | wpb 12352.3 | bsz 457.7 | num_updates 19152 | lr 0.00010219 | gnorm 0.17 | clip 0 | loss_scale 32 | train_wall 1273 | gb_free 17.7 | wall 16813
2023-07-08 12:40:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 12:40:07 | INFO | fairseq.trainer | begin training epoch 14
2023-07-08 12:40:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 12:40:57 | INFO | train_inner | epoch 014:     48 / 1474 loss=1.638, trans_loss=3.407, nll_loss=1.54, w2v_ctc_loss=0.432, task_loss=1.058, contrastive_loss=0.101, total=4179.66, n_correct=2643.03, ppl=2.91, accuracy=63.236, wps=9505.4, ups=0.76, wpb=12495.5, bsz=483, num_updates=19200, lr=0.000102062, gnorm=0.166, clip=0, loss_scale=32, train_wall=87, gb_free=11, wall=16863
2023-07-08 12:42:23 | INFO | train_inner | epoch 014:    148 / 1474 loss=1.635, trans_loss=3.405, nll_loss=1.534, w2v_ctc_loss=0.429, task_loss=1.159, contrastive_loss=0.079, total=4081.01, n_correct=2592.87, ppl=2.9, accuracy=63.535, wps=14162.4, ups=1.16, wpb=12201.4, bsz=450.9, num_updates=19300, lr=0.000101797, gnorm=0.167, clip=0, loss_scale=32, train_wall=86, gb_free=16.1, wall=16950
2023-07-08 12:43:49 | INFO | train_inner | epoch 014:    248 / 1474 loss=1.652, trans_loss=3.415, nll_loss=1.547, w2v_ctc_loss=0.431, task_loss=1.205, contrastive_loss=0.216, total=4109.83, n_correct=2599.36, ppl=2.92, accuracy=63.247, wps=14214.9, ups=1.16, wpb=12237.8, bsz=442.7, num_updates=19400, lr=0.000101535, gnorm=0.17, clip=0, loss_scale=32, train_wall=86, gb_free=15.9, wall=17036
2023-07-08 12:45:16 | INFO | train_inner | epoch 014:    348 / 1474 loss=1.639, trans_loss=3.401, nll_loss=1.538, w2v_ctc_loss=0.43, task_loss=1.072, contrastive_loss=0.126, total=4171.83, n_correct=2639.35, ppl=2.9, accuracy=63.266, wps=14360.7, ups=1.16, wpb=12430.7, bsz=479.5, num_updates=19500, lr=0.000101274, gnorm=0.17, clip=0, loss_scale=32, train_wall=86, gb_free=16.9, wall=17122
2023-07-08 12:46:43 | INFO | train_inner | epoch 014:    448 / 1474 loss=1.642, trans_loss=3.411, nll_loss=1.546, w2v_ctc_loss=0.432, task_loss=1.156, contrastive_loss=0.091, total=4142.75, n_correct=2609.92, ppl=2.92, accuracy=63, wps=14200.7, ups=1.15, wpb=12340.5, bsz=453.3, num_updates=19600, lr=0.000101015, gnorm=0.17, clip=0, loss_scale=32, train_wall=86, gb_free=16.8, wall=17209
2023-07-08 12:48:10 | INFO | train_inner | epoch 014:    548 / 1474 loss=1.653, trans_loss=3.421, nll_loss=1.556, w2v_ctc_loss=0.439, task_loss=1.241, contrastive_loss=0.103, total=4073.76, n_correct=2561.16, ppl=2.94, accuracy=62.87, wps=13940.6, ups=1.14, wpb=12222.1, bsz=436.3, num_updates=19700, lr=0.000100759, gnorm=0.17, clip=0, loss_scale=32, train_wall=87, gb_free=15.6, wall=17297
2023-07-08 12:49:38 | INFO | train_inner | epoch 014:    648 / 1474 loss=1.649, trans_loss=3.417, nll_loss=1.553, w2v_ctc_loss=0.431, task_loss=1.148, contrastive_loss=0.18, total=4158.79, n_correct=2615.69, ppl=2.93, accuracy=62.895, wps=14246.8, ups=1.15, wpb=12412.4, bsz=460.2, num_updates=19800, lr=0.000100504, gnorm=0.169, clip=0, loss_scale=32, train_wall=87, gb_free=17.3, wall=17384
2023-07-08 12:51:04 | INFO | train_inner | epoch 014:    748 / 1474 loss=1.64, trans_loss=3.409, nll_loss=1.544, w2v_ctc_loss=0.432, task_loss=1.125, contrastive_loss=0.09, total=4145.47, n_correct=2619.8, ppl=2.92, accuracy=63.197, wps=14342.8, ups=1.16, wpb=12397.1, bsz=464.3, num_updates=19900, lr=0.000100251, gnorm=0.168, clip=0, loss_scale=32, train_wall=86, gb_free=16.4, wall=17470
2023-07-08 12:52:31 | INFO | train_inner | epoch 014:    848 / 1474 loss=1.648, trans_loss=3.406, nll_loss=1.543, w2v_ctc_loss=0.428, task_loss=1.091, contrastive_loss=0.237, total=4171.1, n_correct=2629.77, ppl=2.91, accuracy=63.047, wps=14361.5, ups=1.15, wpb=12447.1, bsz=479.5, num_updates=20000, lr=0.0001, gnorm=0.168, clip=0, loss_scale=32, train_wall=86, gb_free=16.9, wall=17557
2023-07-08 12:52:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 12:52:57 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 1.475 | trans_loss 5.601 | nll_loss 2.882 | w2v_ctc_loss 0.462 | task_loss 4.619 | contrastive_loss 0.249 | total 4003.4 | n_correct 2449.7 | ppl 7.37 | accuracy 61.19 | uer 17.185 | wer 19.034 | raw_wer 19.034 | bleu 19.34 | wps 2058 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.34
2023-07-08 12:52:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-07-08 12:52:57 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_14_20000.pt
2023-07-08 12:53:00 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_14_20000.pt
2023-07-08 12:53:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.34) (writing took 8.971543766994728 seconds)
tensor(0.0246, device='cuda:0')
tensor(0.0006, device='cuda:0')
2023-07-08 12:54:08 | INFO | train_inner | epoch 014:    948 / 1474 loss=0.98, trans_loss=5.36, nll_loss=2.704, w2v_ctc_loss=0.32, task_loss=3.388, contrastive_loss=0.226, total=4167.75, n_correct=2613.26, ppl=6.52, accuracy=62.702, wps=4398.5, ups=1.03, wpb=4260.9, bsz=157.9, num_updates=20100, lr=9.97509e-05, gnorm=0.239, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=17654
2023-07-08 12:55:09 | INFO | train_inner | epoch 014:   1048 / 1474 loss=0.973, trans_loss=5.43, nll_loss=2.75, w2v_ctc_loss=0.323, task_loss=3.526, contrastive_loss=0.181, total=4143.92, n_correct=2597.93, ppl=6.73, accuracy=62.693, wps=6750.7, ups=1.63, wpb=4143.9, bsz=150.4, num_updates=20200, lr=9.95037e-05, gnorm=0.236, clip=0, loss_scale=32, train_wall=61, gb_free=16.2, wall=17715
2023-07-08 12:56:10 | INFO | train_inner | epoch 014:   1148 / 1474 loss=0.986, trans_loss=5.434, nll_loss=2.757, w2v_ctc_loss=0.325, task_loss=3.229, contrastive_loss=0.723, total=4228.69, n_correct=2647.7, ppl=6.76, accuracy=62.613, wps=6930.8, ups=1.64, wpb=4228.7, bsz=163.6, num_updates=20300, lr=9.92583e-05, gnorm=0.237, clip=0, loss_scale=32, train_wall=61, gb_free=16, wall=17776
2023-07-08 12:57:10 | INFO | train_inner | epoch 014:   1248 / 1474 loss=0.976, trans_loss=5.441, nll_loss=2.763, w2v_ctc_loss=0.329, task_loss=4.057, contrastive_loss=0.102, total=4021.19, n_correct=2514.91, ppl=6.79, accuracy=62.541, wps=6708, ups=1.67, wpb=4021.2, bsz=135.8, num_updates=20400, lr=9.90148e-05, gnorm=0.241, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=17836
2023-07-08 12:58:11 | INFO | train_inner | epoch 014:   1348 / 1474 loss=0.963, trans_loss=5.42, nll_loss=2.737, w2v_ctc_loss=0.314, task_loss=3.261, contrastive_loss=0.137, total=4213.9, n_correct=2648.87, ppl=6.67, accuracy=62.86, wps=6942.1, ups=1.65, wpb=4213.9, bsz=159.7, num_updates=20500, lr=9.8773e-05, gnorm=0.232, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=17897
2023-07-08 12:59:11 | INFO | train_inner | epoch 014:   1448 / 1474 loss=0.971, trans_loss=5.444, nll_loss=2.769, w2v_ctc_loss=0.321, task_loss=3.445, contrastive_loss=0.214, total=4130.28, n_correct=2583.01, ppl=6.81, accuracy=62.538, wps=6874.1, ups=1.66, wpb=4130.3, bsz=152, num_updates=20600, lr=9.85329e-05, gnorm=0.237, clip=0, loss_scale=32, train_wall=60, gb_free=15.6, wall=17957
2023-07-08 12:59:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0246, device='cuda:6')
tensor(0.0006, device='cuda:6')
tensor(0.0246, device='cuda:4')
tensor(0.0006, device='cuda:4')
tensor(0.0246, device='cuda:2')
tensor(0.0006, device='cuda:2')
tensor(0.0246, device='cuda:7')
tensor(0.0006, device='cuda:7')
tensor(0.0246, device='cuda:3')
tensor(0.0006, device='cuda:3')
tensor(0.0246, device='cuda:5')
tensor(0.0006, device='cuda:5')
tensor(0.0246, device='cuda:1')
tensor(0.0006, device='cuda:1')
2023-07-08 12:59:54 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 1.478 | trans_loss 5.605 | nll_loss 2.89 | w2v_ctc_loss 0.467 | task_loss 4.606 | contrastive_loss 0.251 | total 4003.4 | n_correct 2458.3 | ppl 7.41 | accuracy 61.405 | uer 17.466 | wer 19.41 | raw_wer 19.41 | bleu 19.43 | wps 1950.5 | wpb 4003.4 | bsz 141.8 | num_updates 20626 | best_bleu 19.43
2023-07-08 12:59:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20626 updates
2023-07-08 12:59:54 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 12:59:58 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 13:00:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 14 @ 20626 updates, score 19.43) (writing took 8.295356678005191 seconds)
2023-07-08 13:00:03 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-07-08 13:00:03 | INFO | train | epoch 014 | loss 1.418 | trans_loss 3.811 | nll_loss 1.784 | w2v_ctc_loss 0.394 | task_loss 1.603 | contrastive_loss 0.163 | total 4138.65 | n_correct 2604.72 | ppl 3.44 | accuracy 62.936 | wps 10932 | ups 1.23 | wpb 8868.8 | bsz 329.4 | num_updates 20626 | lr 9.84708e-05 | gnorm 0.198 | clip 0 | loss_scale 32 | train_wall 1108 | gb_free 16.6 | wall 18009
2023-07-08 13:00:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 13:00:03 | INFO | fairseq.trainer | begin training epoch 15
2023-07-08 13:00:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 13:00:54 | INFO | train_inner | epoch 015:     74 / 1474 loss=0.965, trans_loss=5.397, nll_loss=2.707, w2v_ctc_loss=0.313, task_loss=3.466, contrastive_loss=0.313, total=4083.88, n_correct=2579.64, ppl=6.53, accuracy=63.166, wps=3933.1, ups=0.96, wpb=4083.9, bsz=150.1, num_updates=20700, lr=9.82946e-05, gnorm=0.237, clip=0, loss_scale=32, train_wall=59, gb_free=16.4, wall=18061
2023-07-08 13:01:55 | INFO | train_inner | epoch 015:    174 / 1474 loss=0.962, trans_loss=5.385, nll_loss=2.69, w2v_ctc_loss=0.317, task_loss=3.601, contrastive_loss=0.131, total=4115.73, n_correct=2607.84, ppl=6.45, accuracy=63.363, wps=6815.2, ups=1.66, wpb=4115.7, bsz=148.9, num_updates=20800, lr=9.80581e-05, gnorm=0.235, clip=0, loss_scale=32, train_wall=60, gb_free=17, wall=18121
2023-07-08 13:02:55 | INFO | train_inner | epoch 015:    274 / 1474 loss=0.953, trans_loss=5.38, nll_loss=2.685, w2v_ctc_loss=0.311, task_loss=3.333, contrastive_loss=0.113, total=4193.15, n_correct=2664.22, ppl=6.43, accuracy=63.537, wps=6930.9, ups=1.65, wpb=4193.1, bsz=156.3, num_updates=20900, lr=9.78232e-05, gnorm=0.23, clip=0, loss_scale=32, train_wall=60, gb_free=13.1, wall=18182
2023-07-08 13:03:56 | INFO | train_inner | epoch 015:    374 / 1474 loss=0.963, trans_loss=5.38, nll_loss=2.685, w2v_ctc_loss=0.314, task_loss=3.488, contrastive_loss=0.164, total=4167.66, n_correct=2646.58, ppl=6.43, accuracy=63.503, wps=6869.1, ups=1.65, wpb=4167.7, bsz=153, num_updates=21000, lr=9.759e-05, gnorm=0.236, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=18242
2023-07-08 13:04:57 | INFO | train_inner | epoch 015:    474 / 1474 loss=0.965, trans_loss=5.393, nll_loss=2.701, w2v_ctc_loss=0.315, task_loss=3.609, contrastive_loss=0.345, total=4074.53, n_correct=2577.2, ppl=6.5, accuracy=63.251, wps=6729.4, ups=1.65, wpb=4074.5, bsz=147.1, num_updates=21100, lr=9.73585e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=18303
2023-07-08 13:05:57 | INFO | train_inner | epoch 015:    574 / 1474 loss=0.963, trans_loss=5.393, nll_loss=2.703, w2v_ctc_loss=0.32, task_loss=3.572, contrastive_loss=0.13, total=4140.59, n_correct=2616.69, ppl=6.51, accuracy=63.196, wps=6908.6, ups=1.67, wpb=4140.6, bsz=149.4, num_updates=21200, lr=9.71286e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=59, gb_free=12.6, wall=18363
2023-07-08 13:06:57 | INFO | train_inner | epoch 015:    674 / 1474 loss=0.965, trans_loss=5.392, nll_loss=2.701, w2v_ctc_loss=0.318, task_loss=3.487, contrastive_loss=0.293, total=4134.99, n_correct=2617.99, ppl=6.5, accuracy=63.313, wps=6875.7, ups=1.66, wpb=4135, bsz=153.5, num_updates=21300, lr=9.69003e-05, gnorm=0.238, clip=0, loss_scale=64, train_wall=60, gb_free=11.1, wall=18423
2023-07-08 13:07:58 | INFO | train_inner | epoch 015:    774 / 1474 loss=0.966, trans_loss=5.403, nll_loss=2.714, w2v_ctc_loss=0.32, task_loss=3.486, contrastive_loss=0.137, total=4173.66, n_correct=2631.89, ppl=6.56, accuracy=63.06, wps=6862.6, ups=1.64, wpb=4173.7, bsz=152.5, num_updates=21400, lr=9.66736e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=18484
2023-07-08 13:08:57 | INFO | train_inner | epoch 015:    874 / 1474 loss=0.964, trans_loss=5.413, nll_loss=2.729, w2v_ctc_loss=0.321, task_loss=3.726, contrastive_loss=0.128, total=4059.35, n_correct=2552.27, ppl=6.63, accuracy=62.874, wps=6790.5, ups=1.67, wpb=4059.3, bsz=144.1, num_updates=21500, lr=9.64486e-05, gnorm=0.238, clip=0, loss_scale=64, train_wall=59, gb_free=15.8, wall=18544
2023-07-08 13:09:58 | INFO | train_inner | epoch 015:    974 / 1474 loss=0.967, trans_loss=5.396, nll_loss=2.706, w2v_ctc_loss=0.314, task_loss=3.473, contrastive_loss=0.295, total=4122.87, n_correct=2605.66, ppl=6.53, accuracy=63.2, wps=6835.8, ups=1.66, wpb=4122.9, bsz=150.8, num_updates=21600, lr=9.6225e-05, gnorm=0.237, clip=0, loss_scale=64, train_wall=60, gb_free=17.7, wall=18604
2023-07-08 13:10:59 | INFO | train_inner | epoch 015:   1074 / 1474 loss=0.974, trans_loss=5.406, nll_loss=2.721, w2v_ctc_loss=0.316, task_loss=3.226, contrastive_loss=0.603, total=4192.24, n_correct=2641.8, ppl=6.6, accuracy=63.016, wps=6839.2, ups=1.63, wpb=4192.2, bsz=162.6, num_updates=21700, lr=9.60031e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=61, gb_free=17.3, wall=18665
2023-07-08 13:11:59 | INFO | train_inner | epoch 015:   1174 / 1474 loss=0.954, trans_loss=5.377, nll_loss=2.685, w2v_ctc_loss=0.308, task_loss=3.103, contrastive_loss=0.22, total=4185, n_correct=2662.94, ppl=6.43, accuracy=63.631, wps=7010.5, ups=1.68, wpb=4185, bsz=164.6, num_updates=21800, lr=9.57826e-05, gnorm=0.229, clip=0, loss_scale=64, train_wall=59, gb_free=16.4, wall=18725
2023-07-08 13:12:59 | INFO | train_inner | epoch 015:   1274 / 1474 loss=0.964, trans_loss=5.396, nll_loss=2.709, w2v_ctc_loss=0.32, task_loss=3.519, contrastive_loss=0.132, total=4152.04, n_correct=2622.42, ppl=6.54, accuracy=63.16, wps=6891.3, ups=1.66, wpb=4152, bsz=151.8, num_updates=21900, lr=9.55637e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=18785
2023-07-08 13:13:59 | INFO | train_inner | epoch 015:   1374 / 1474 loss=0.966, trans_loss=5.401, nll_loss=2.713, w2v_ctc_loss=0.319, task_loss=3.559, contrastive_loss=0.105, total=4100.21, n_correct=2590.19, ppl=6.56, accuracy=63.172, wps=6798.6, ups=1.66, wpb=4100.2, bsz=146.8, num_updates=22000, lr=9.53463e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=60, gb_free=17.6, wall=18846
2023-07-08 13:13:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 13:14:25 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 1.46 | trans_loss 5.586 | nll_loss 2.861 | w2v_ctc_loss 0.449 | task_loss 4.645 | contrastive_loss 0.259 | total 4003.4 | n_correct 2473.9 | ppl 7.26 | accuracy 61.795 | uer 17.23 | wer 19.179 | raw_wer 19.179 | bleu 19.69 | wps 2128.7 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 19.69
2023-07-08 13:14:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-07-08 13:14:25 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_15_22000.pt
2023-07-08 13:14:28 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_15_22000.pt
2023-07-08 13:14:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.69) (writing took 9.020758151993505 seconds)
2023-07-08 13:15:37 | INFO | train_inner | epoch 015:   1474 / 1474 loss=0.965, trans_loss=5.409, nll_loss=2.727, w2v_ctc_loss=0.319, task_loss=3.354, contrastive_loss=0.282, total=4141.17, n_correct=2609.21, ppl=6.62, accuracy=63.007, wps=4249.8, ups=1.03, wpb=4141.2, bsz=157.2, num_updates=22100, lr=9.51303e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=61, gb_free=17.2, wall=18943
2023-07-08 13:15:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 13:16:05 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 1.467 | trans_loss 5.592 | nll_loss 2.872 | w2v_ctc_loss 0.455 | task_loss 4.625 | contrastive_loss 0.259 | total 4003.4 | n_correct 2464.7 | ppl 7.32 | accuracy 61.565 | uer 17.299 | wer 19.168 | raw_wer 19.168 | bleu 19.6 | wps 1859.6 | wpb 4003.4 | bsz 141.8 | num_updates 22100 | best_bleu 19.69
2023-07-08 13:16:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22100 updates
2023-07-08 13:16:05 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.6003.pt
2023-07-08 13:16:07 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.6003.pt
2023-07-08 13:16:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.6003.pt (epoch 15 @ 22100 updates, score 19.6) (writing took 5.307363225001609 seconds)
2023-07-08 13:16:11 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-07-08 13:16:11 | INFO | train | epoch 015 | loss 0.963 | trans_loss 5.394 | nll_loss 2.704 | w2v_ctc_loss 0.316 | task_loss 3.456 | contrastive_loss 0.229 | total 4138.65 | n_correct 2617.69 | ppl 6.52 | accuracy 63.25 | wps 6301.9 | ups 1.52 | wpb 4138.6 | bsz 152.8 | num_updates 22100 | lr 9.51303e-05 | gnorm 0.235 | clip 0 | loss_scale 64 | train_wall 884 | gb_free 17.2 | wall 18977
2023-07-08 13:16:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 13:16:11 | INFO | fairseq.trainer | begin training epoch 16
2023-07-08 13:16:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 13:17:19 | INFO | train_inner | epoch 016:    100 / 1474 loss=0.955, trans_loss=5.346, nll_loss=2.642, w2v_ctc_loss=0.309, task_loss=3.292, contrastive_loss=0.164, total=4126.22, n_correct=2643.88, ppl=6.24, accuracy=64.075, wps=4044.5, ups=0.98, wpb=4126.2, bsz=157.8, num_updates=22200, lr=9.49158e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=59, gb_free=16.3, wall=19045
2023-07-08 13:18:19 | INFO | train_inner | epoch 016:    200 / 1474 loss=0.945, trans_loss=5.342, nll_loss=2.636, w2v_ctc_loss=0.304, task_loss=3.56, contrastive_loss=0.119, total=4100.6, n_correct=2626.01, ppl=6.22, accuracy=64.04, wps=6801.4, ups=1.66, wpb=4100.6, bsz=148.4, num_updates=22300, lr=9.47027e-05, gnorm=0.233, clip=0, loss_scale=64, train_wall=60, gb_free=13, wall=19105
2023-07-08 13:19:19 | INFO | train_inner | epoch 016:    300 / 1474 loss=0.962, trans_loss=5.364, nll_loss=2.666, w2v_ctc_loss=0.315, task_loss=3.421, contrastive_loss=0.264, total=4166.94, n_correct=2659.03, ppl=6.35, accuracy=63.813, wps=6955, ups=1.67, wpb=4166.9, bsz=154.5, num_updates=22400, lr=9.44911e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=59, gb_free=17.3, wall=19165
2023-07-08 13:20:19 | INFO | train_inner | epoch 016:    400 / 1474 loss=0.961, trans_loss=5.371, nll_loss=2.674, w2v_ctc_loss=0.315, task_loss=3.683, contrastive_loss=0.288, total=4073.3, n_correct=2593.21, ppl=6.38, accuracy=63.664, wps=6826.4, ups=1.68, wpb=4073.3, bsz=144, num_updates=22500, lr=9.42809e-05, gnorm=0.237, clip=0, loss_scale=64, train_wall=59, gb_free=17.2, wall=19225
2023-07-08 13:21:20 | INFO | train_inner | epoch 016:    500 / 1474 loss=0.956, trans_loss=5.362, nll_loss=2.664, w2v_ctc_loss=0.311, task_loss=3.32, contrastive_loss=0.18, total=4174.67, n_correct=2667.77, ppl=6.34, accuracy=63.904, wps=6828.6, ups=1.64, wpb=4174.7, bsz=159.5, num_updates=22600, lr=9.40721e-05, gnorm=0.233, clip=0, loss_scale=64, train_wall=61, gb_free=16.2, wall=19286
2023-07-08 13:22:19 | INFO | train_inner | epoch 016:    600 / 1474 loss=0.959, trans_loss=5.369, nll_loss=2.672, w2v_ctc_loss=0.312, task_loss=3.484, contrastive_loss=0.108, total=4124.65, n_correct=2625.95, ppl=6.37, accuracy=63.665, wps=6902, ups=1.67, wpb=4124.6, bsz=148.8, num_updates=22700, lr=9.38647e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=59, gb_free=16.4, wall=19346
2023-07-08 13:23:19 | INFO | train_inner | epoch 016:    700 / 1474 loss=0.959, trans_loss=5.371, nll_loss=2.675, w2v_ctc_loss=0.315, task_loss=3.545, contrastive_loss=0.114, total=4095.49, n_correct=2605.54, ppl=6.39, accuracy=63.62, wps=6840.1, ups=1.67, wpb=4095.5, bsz=148.2, num_updates=22800, lr=9.36586e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=59, gb_free=16.4, wall=19406
2023-07-08 13:24:19 | INFO | train_inner | epoch 016:    800 / 1474 loss=0.955, trans_loss=5.364, nll_loss=2.666, w2v_ctc_loss=0.306, task_loss=3.318, contrastive_loss=0.232, total=4174.94, n_correct=2659.92, ppl=6.35, accuracy=63.712, wps=6964.4, ups=1.67, wpb=4174.9, bsz=155.4, num_updates=22900, lr=9.34539e-05, gnorm=0.23, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=19466
2023-07-08 13:25:19 | INFO | train_inner | epoch 016:    900 / 1474 loss=0.957, trans_loss=5.363, nll_loss=2.666, w2v_ctc_loss=0.311, task_loss=3.343, contrastive_loss=0.219, total=4163.19, n_correct=2654.16, ppl=6.35, accuracy=63.753, wps=6949.1, ups=1.67, wpb=4163.2, bsz=155.3, num_updates=23000, lr=9.32505e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=19526
2023-07-08 13:26:20 | INFO | train_inner | epoch 016:   1000 / 1474 loss=0.963, trans_loss=5.386, nll_loss=2.694, w2v_ctc_loss=0.318, task_loss=3.6, contrastive_loss=0.213, total=4103.45, n_correct=2599.16, ppl=6.47, accuracy=63.341, wps=6756.5, ups=1.65, wpb=4103.4, bsz=149, num_updates=23100, lr=9.30484e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=60, gb_free=15.1, wall=19586
2023-07-08 13:27:20 | INFO | train_inner | epoch 016:   1100 / 1474 loss=0.965, trans_loss=5.387, nll_loss=2.698, w2v_ctc_loss=0.32, task_loss=3.677, contrastive_loss=0.166, total=4119.27, n_correct=2608.5, ppl=6.49, accuracy=63.324, wps=6800.8, ups=1.65, wpb=4119.3, bsz=147.7, num_updates=23200, lr=9.28477e-05, gnorm=0.239, clip=0, loss_scale=128, train_wall=60, gb_free=17.9, wall=19647
2023-07-08 13:27:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-08 13:28:22 | INFO | train_inner | epoch 016:   1201 / 1474 loss=0.957, trans_loss=5.379, nll_loss=2.687, w2v_ctc_loss=0.313, task_loss=3.617, contrastive_loss=0.128, total=4132.57, n_correct=2620.11, ppl=6.44, accuracy=63.401, wps=6680.5, ups=1.62, wpb=4132.6, bsz=149.4, num_updates=23300, lr=9.26482e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=61, gb_free=15.1, wall=19709
2023-07-08 13:29:23 | INFO | train_inner | epoch 016:   1301 / 1474 loss=0.962, trans_loss=5.379, nll_loss=2.688, w2v_ctc_loss=0.315, task_loss=3.351, contrastive_loss=0.316, total=4151.03, n_correct=2638.68, ppl=6.44, accuracy=63.567, wps=6833.7, ups=1.65, wpb=4151, bsz=157.2, num_updates=23400, lr=9.245e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=19770
2023-07-08 13:30:24 | INFO | train_inner | epoch 016:   1401 / 1474 loss=0.96, trans_loss=5.377, nll_loss=2.685, w2v_ctc_loss=0.314, task_loss=3.296, contrastive_loss=0.174, total=4201.47, n_correct=2667.86, ppl=6.43, accuracy=63.498, wps=6940.8, ups=1.65, wpb=4201.5, bsz=160.4, num_updates=23500, lr=9.22531e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=60, gb_free=16.2, wall=19830
2023-07-08 13:31:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 13:31:36 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 1.465 | trans_loss 5.582 | nll_loss 2.86 | w2v_ctc_loss 0.464 | task_loss 4.638 | contrastive_loss 0.252 | total 4003.4 | n_correct 2473.1 | ppl 7.26 | accuracy 61.775 | uer 17.272 | wer 19.123 | raw_wer 19.123 | bleu 19.73 | wps 1854.3 | wpb 4003.4 | bsz 141.8 | num_updates 23573 | best_bleu 19.73
2023-07-08 13:31:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23573 updates
2023-07-08 13:31:36 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 13:31:40 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 13:31:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 16 @ 23573 updates, score 19.73) (writing took 8.077423929003999 seconds)
2023-07-08 13:31:44 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-07-08 13:31:44 | INFO | train | epoch 016 | loss 0.959 | trans_loss 5.369 | nll_loss 2.673 | w2v_ctc_loss 0.313 | task_loss 3.46 | contrastive_loss 0.211 | total 4137.02 | n_correct 2633.86 | ppl 6.38 | accuracy 63.666 | wps 6527.2 | ups 1.58 | wpb 4137 | bsz 152.5 | num_updates 23573 | lr 9.21102e-05 | gnorm 0.235 | clip 0 | loss_scale 64 | train_wall 882 | gb_free 15.6 | wall 19911
2023-07-08 13:31:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 13:31:44 | INFO | fairseq.trainer | begin training epoch 17
2023-07-08 13:31:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 13:32:09 | INFO | train_inner | epoch 017:     27 / 1474 loss=0.961, trans_loss=5.356, nll_loss=2.656, w2v_ctc_loss=0.309, task_loss=3.52, contrastive_loss=0.449, total=4145.04, n_correct=2648.81, ppl=6.3, accuracy=63.903, wps=3937.1, ups=0.95, wpb=4145, bsz=151.2, num_updates=23600, lr=9.20575e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=60, gb_free=15.8, wall=19935
2023-07-08 13:33:09 | INFO | train_inner | epoch 017:    127 / 1474 loss=0.954, trans_loss=5.335, nll_loss=2.628, w2v_ctc_loss=0.312, task_loss=3.554, contrastive_loss=0.12, total=4117.27, n_correct=2641.94, ppl=6.18, accuracy=64.167, wps=6822.5, ups=1.66, wpb=4117.3, bsz=148.1, num_updates=23700, lr=9.1863e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=60, gb_free=17.9, wall=19996
2023-07-08 13:34:10 | INFO | train_inner | epoch 017:    227 / 1474 loss=0.955, trans_loss=5.335, nll_loss=2.629, w2v_ctc_loss=0.305, task_loss=3.277, contrastive_loss=0.454, total=4159.6, n_correct=2674.03, ppl=6.19, accuracy=64.286, wps=6896.9, ups=1.66, wpb=4159.6, bsz=158.8, num_updates=23800, lr=9.16698e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=20056
2023-07-08 13:35:10 | INFO | train_inner | epoch 017:    327 / 1474 loss=0.958, trans_loss=5.342, nll_loss=2.639, w2v_ctc_loss=0.308, task_loss=3.427, contrastive_loss=0.459, total=4156.91, n_correct=2660.75, ppl=6.23, accuracy=64.008, wps=6920.9, ups=1.66, wpb=4156.9, bsz=152.9, num_updates=23900, lr=9.14779e-05, gnorm=0.233, clip=0, loss_scale=64, train_wall=60, gb_free=17.6, wall=20116
2023-07-08 13:36:10 | INFO | train_inner | epoch 017:    427 / 1474 loss=0.948, trans_loss=5.337, nll_loss=2.631, w2v_ctc_loss=0.309, task_loss=3.424, contrastive_loss=0.119, total=4146.43, n_correct=2665.19, ppl=6.2, accuracy=64.277, wps=6820.4, ups=1.64, wpb=4146.4, bsz=154, num_updates=24000, lr=9.12871e-05, gnorm=0.232, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=20177
2023-07-08 13:36:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 13:36:37 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 1.466 | trans_loss 5.583 | nll_loss 2.857 | w2v_ctc_loss 0.464 | task_loss 4.638 | contrastive_loss 0.248 | total 4003.4 | n_correct 2469.2 | ppl 7.24 | accuracy 61.678 | uer 17.028 | wer 18.996 | raw_wer 18.996 | bleu 19.58 | wps 1984.4 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 19.73
2023-07-08 13:36:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-07-08 13:36:37 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_17_24000.pt
2023-07-08 13:36:39 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_17_24000.pt
2023-07-08 13:36:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.58) (writing took 6.009425230004126 seconds)
2023-07-08 13:37:44 | INFO | train_inner | epoch 017:    527 / 1474 loss=0.961, trans_loss=5.351, nll_loss=2.65, w2v_ctc_loss=0.316, task_loss=3.592, contrastive_loss=0.208, total=4182.1, n_correct=2673.35, ppl=6.28, accuracy=63.924, wps=4464.5, ups=1.07, wpb=4182.1, bsz=153.9, num_updates=24100, lr=9.10975e-05, gnorm=0.238, clip=0, loss_scale=64, train_wall=61, gb_free=17, wall=20271
2023-07-08 13:38:44 | INFO | train_inner | epoch 017:    627 / 1474 loss=0.95, trans_loss=5.343, nll_loss=2.64, w2v_ctc_loss=0.308, task_loss=3.483, contrastive_loss=0.109, total=4167.27, n_correct=2671.8, ppl=6.23, accuracy=64.114, wps=6914.7, ups=1.66, wpb=4167.3, bsz=151.1, num_updates=24200, lr=9.09091e-05, gnorm=0.23, clip=0, loss_scale=64, train_wall=60, gb_free=11.3, wall=20331
2023-07-08 13:39:45 | INFO | train_inner | epoch 017:    727 / 1474 loss=0.958, trans_loss=5.355, nll_loss=2.656, w2v_ctc_loss=0.315, task_loss=3.415, contrastive_loss=0.204, total=4166.12, n_correct=2664.71, ppl=6.3, accuracy=63.961, wps=6912.6, ups=1.66, wpb=4166.1, bsz=154.1, num_updates=24300, lr=9.07218e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=20391
2023-07-08 13:40:44 | INFO | train_inner | epoch 017:    827 / 1474 loss=0.958, trans_loss=5.353, nll_loss=2.653, w2v_ctc_loss=0.313, task_loss=3.494, contrastive_loss=0.133, total=4091.64, n_correct=2615.4, ppl=6.29, accuracy=63.921, wps=6870.8, ups=1.68, wpb=4091.6, bsz=147.7, num_updates=24400, lr=9.05357e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=59, gb_free=17.4, wall=20451
2023-07-08 13:41:43 | INFO | train_inner | epoch 017:    927 / 1474 loss=0.949, trans_loss=5.342, nll_loss=2.639, w2v_ctc_loss=0.306, task_loss=3.41, contrastive_loss=0.128, total=4106.83, n_correct=2632.04, ppl=6.23, accuracy=64.089, wps=6932.4, ups=1.69, wpb=4106.8, bsz=152.3, num_updates=24500, lr=9.03508e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=59, gb_free=16, wall=20510
2023-07-08 13:42:43 | INFO | train_inner | epoch 017:   1027 / 1474 loss=0.95, trans_loss=5.344, nll_loss=2.643, w2v_ctc_loss=0.309, task_loss=3.409, contrastive_loss=0.137, total=4115.49, n_correct=2637.08, ppl=6.25, accuracy=64.077, wps=6892.5, ups=1.67, wpb=4115.5, bsz=152.9, num_updates=24600, lr=9.0167e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=59, gb_free=16.8, wall=20570
2023-07-08 13:43:43 | INFO | train_inner | epoch 017:   1127 / 1474 loss=0.95, trans_loss=5.345, nll_loss=2.644, w2v_ctc_loss=0.305, task_loss=3.592, contrastive_loss=0.111, total=4078.39, n_correct=2613.46, ppl=6.25, accuracy=64.081, wps=6868.4, ups=1.68, wpb=4078.4, bsz=146.9, num_updates=24700, lr=8.99843e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=59, gb_free=15.8, wall=20629
2023-07-08 13:44:43 | INFO | train_inner | epoch 017:   1227 / 1474 loss=0.967, trans_loss=5.364, nll_loss=2.669, w2v_ctc_loss=0.31, task_loss=3.34, contrastive_loss=0.595, total=4173.49, n_correct=2656.91, ppl=6.36, accuracy=63.662, wps=6868.6, ups=1.65, wpb=4173.5, bsz=161.9, num_updates=24800, lr=8.98027e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=20690
2023-07-08 13:45:44 | INFO | train_inner | epoch 017:   1327 / 1474 loss=0.953, trans_loss=5.351, nll_loss=2.653, w2v_ctc_loss=0.305, task_loss=3.431, contrastive_loss=0.276, total=4156.28, n_correct=2655.4, ppl=6.29, accuracy=63.889, wps=6870.9, ups=1.65, wpb=4156.3, bsz=154, num_updates=24900, lr=8.96221e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=60, gb_free=17.9, wall=20750
2023-07-08 13:46:45 | INFO | train_inner | epoch 017:   1427 / 1474 loss=0.942, trans_loss=5.351, nll_loss=2.653, w2v_ctc_loss=0.305, task_loss=3.501, contrastive_loss=0.118, total=4112.95, n_correct=2628.54, ppl=6.29, accuracy=63.909, wps=6776.7, ups=1.65, wpb=4112.9, bsz=151.6, num_updates=25000, lr=8.94427e-05, gnorm=0.233, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=20811
tensor(0.0246, device='cuda:0')
tensor(0.0006, device='cuda:0')
2023-07-08 13:47:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0246, device='cuda:6')
tensor(0.0006, device='cuda:6')
tensor(0.0246, device='cuda:7')
tensor(0.0006, device='cuda:7')
tensor(0.0246, device='cuda:4')
tensor(0.0006, device='cuda:4')
tensor(0.0246, device='cuda:5')
tensor(0.0006, device='cuda:5')
tensor(0.0246, device='cuda:3')
tensor(0.0006, device='cuda:3')
tensor(0.0246, device='cuda:1')
tensor(0.0006, device='cuda:1')
tensor(0.0246, device='cuda:2')
tensor(0.0006, device='cuda:2')
2023-07-08 13:47:38 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 1.465 | trans_loss 5.572 | nll_loss 2.849 | w2v_ctc_loss 0.47 | task_loss 4.634 | contrastive_loss 0.254 | total 4003.4 | n_correct 2474.6 | ppl 7.21 | accuracy 61.812 | uer 17.084 | wer 18.784 | raw_wer 18.784 | bleu 19.94 | wps 2156.7 | wpb 4003.4 | bsz 141.8 | num_updates 25047 | best_bleu 19.94
2023-07-08 13:47:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25047 updates
2023-07-08 13:47:38 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 13:47:42 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 13:47:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 17 @ 25047 updates, score 19.94) (writing took 8.213686627001152 seconds)
2023-07-08 13:47:46 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-07-08 13:47:46 | INFO | train | epoch 017 | loss 0.954 | trans_loss 5.346 | nll_loss 2.644 | w2v_ctc_loss 0.309 | task_loss 3.456 | contrastive_loss 0.224 | total 4138.65 | n_correct 2650.08 | ppl 6.25 | accuracy 64.032 | wps 6341 | ups 1.53 | wpb 4138.6 | bsz 152.8 | num_updates 25047 | lr 8.93588e-05 | gnorm 0.234 | clip 0 | loss_scale 64 | train_wall 882 | gb_free 16.6 | wall 20873
2023-07-08 13:47:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 13:47:46 | INFO | fairseq.trainer | begin training epoch 18
2023-07-08 13:47:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 13:48:27 | INFO | train_inner | epoch 018:     53 / 1474 loss=0.954, trans_loss=5.343, nll_loss=2.641, w2v_ctc_loss=0.312, task_loss=3.528, contrastive_loss=0.139, total=4139.04, n_correct=2651.51, ppl=6.24, accuracy=64.061, wps=4024.6, ups=0.97, wpb=4139, bsz=151.7, num_updates=25100, lr=8.92644e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=61, gb_free=17.3, wall=20914
2023-07-08 13:49:27 | INFO | train_inner | epoch 018:    153 / 1474 loss=0.949, trans_loss=5.308, nll_loss=2.594, w2v_ctc_loss=0.298, task_loss=3.297, contrastive_loss=0.381, total=4154.85, n_correct=2684.68, ppl=6.04, accuracy=64.616, wps=6920.9, ups=1.67, wpb=4154.9, bsz=156.4, num_updates=25200, lr=8.90871e-05, gnorm=0.233, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=20974
2023-07-08 13:50:28 | INFO | train_inner | epoch 018:    253 / 1474 loss=0.943, trans_loss=5.304, nll_loss=2.59, w2v_ctc_loss=0.303, task_loss=3.356, contrastive_loss=0.12, total=4162.72, n_correct=2696.52, ppl=6.02, accuracy=64.778, wps=6870.3, ups=1.65, wpb=4162.7, bsz=156.5, num_updates=25300, lr=8.89108e-05, gnorm=0.231, clip=0, loss_scale=128, train_wall=60, gb_free=16.4, wall=21034
2023-07-08 13:51:28 | INFO | train_inner | epoch 018:    353 / 1474 loss=0.948, trans_loss=5.321, nll_loss=2.612, w2v_ctc_loss=0.305, task_loss=3.506, contrastive_loss=0.151, total=4161.22, n_correct=2679.96, ppl=6.11, accuracy=64.403, wps=6921.8, ups=1.66, wpb=4161.2, bsz=150.7, num_updates=25400, lr=8.87357e-05, gnorm=0.235, clip=0, loss_scale=128, train_wall=60, gb_free=14.7, wall=21095
2023-07-08 13:52:29 | INFO | train_inner | epoch 018:    453 / 1474 loss=0.953, trans_loss=5.333, nll_loss=2.627, w2v_ctc_loss=0.307, task_loss=3.68, contrastive_loss=0.33, total=4092.36, n_correct=2630.36, ppl=6.18, accuracy=64.275, wps=6739.3, ups=1.65, wpb=4092.4, bsz=147.7, num_updates=25500, lr=8.85615e-05, gnorm=0.237, clip=0, loss_scale=128, train_wall=60, gb_free=16.9, wall=21155
2023-07-08 13:53:30 | INFO | train_inner | epoch 018:    553 / 1474 loss=0.941, trans_loss=5.306, nll_loss=2.595, w2v_ctc_loss=0.3, task_loss=3.109, contrastive_loss=0.148, total=4206.45, n_correct=2720.89, ppl=6.04, accuracy=64.684, wps=6930.5, ups=1.65, wpb=4206.4, bsz=164.5, num_updates=25600, lr=8.83883e-05, gnorm=0.23, clip=0, loss_scale=128, train_wall=60, gb_free=17.9, wall=21216
2023-07-08 13:53:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-08 13:54:30 | INFO | train_inner | epoch 018:    654 / 1474 loss=0.956, trans_loss=5.339, nll_loss=2.635, w2v_ctc_loss=0.309, task_loss=3.655, contrastive_loss=0.257, total=4074.19, n_correct=2613.38, ppl=6.21, accuracy=64.145, wps=6717.3, ups=1.65, wpb=4074.2, bsz=146.2, num_updates=25700, lr=8.82162e-05, gnorm=0.237, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=21277
2023-07-08 13:55:31 | INFO | train_inner | epoch 018:    754 / 1474 loss=0.956, trans_loss=5.333, nll_loss=2.629, w2v_ctc_loss=0.31, task_loss=3.292, contrastive_loss=0.464, total=4208.29, n_correct=2705.59, ppl=6.18, accuracy=64.292, wps=6947.7, ups=1.65, wpb=4208.3, bsz=161.4, num_updates=25800, lr=8.80451e-05, gnorm=0.232, clip=0, loss_scale=64, train_wall=60, gb_free=17.9, wall=21337
2023-07-08 13:56:31 | INFO | train_inner | epoch 018:    854 / 1474 loss=0.944, trans_loss=5.325, nll_loss=2.617, w2v_ctc_loss=0.303, task_loss=3.503, contrastive_loss=0.104, total=4166.81, n_correct=2680.34, ppl=6.14, accuracy=64.326, wps=6926.6, ups=1.66, wpb=4166.8, bsz=151, num_updates=25900, lr=8.7875e-05, gnorm=0.231, clip=0, loss_scale=64, train_wall=60, gb_free=13, wall=21397
2023-07-08 13:57:30 | INFO | train_inner | epoch 018:    954 / 1474 loss=0.944, trans_loss=5.316, nll_loss=2.607, w2v_ctc_loss=0.3, task_loss=3.212, contrastive_loss=0.148, total=4142.65, n_correct=2673.69, ppl=6.09, accuracy=64.541, wps=6975.7, ups=1.68, wpb=4142.6, bsz=158, num_updates=26000, lr=8.77058e-05, gnorm=0.233, clip=0, loss_scale=64, train_wall=59, gb_free=15.1, wall=21457
2023-07-08 13:57:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 13:57:56 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 1.469 | trans_loss 5.574 | nll_loss 2.849 | w2v_ctc_loss 0.456 | task_loss 4.598 | contrastive_loss 0.252 | total 4003.4 | n_correct 2472.2 | ppl 7.21 | accuracy 61.753 | uer 17.14 | wer 19.022 | raw_wer 19.022 | bleu 19.92 | wps 2062.5 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 19.94
2023-07-08 13:57:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-07-08 13:57:56 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_18_26000.pt
2023-07-08 13:57:58 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_18_26000.pt
2023-07-08 13:58:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 19.92) (writing took 6.171662886001286 seconds)
2023-07-08 13:59:04 | INFO | train_inner | epoch 018:   1054 / 1474 loss=0.945, trans_loss=5.326, nll_loss=2.62, w2v_ctc_loss=0.301, task_loss=3.602, contrastive_loss=0.126, total=4137.77, n_correct=2660.12, ppl=6.15, accuracy=64.289, wps=4434.3, ups=1.07, wpb=4137.8, bsz=150.2, num_updates=26100, lr=8.75376e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=61, gb_free=17.5, wall=21550
2023-07-08 14:00:04 | INFO | train_inner | epoch 018:   1154 / 1474 loss=0.95, trans_loss=5.317, nll_loss=2.609, w2v_ctc_loss=0.305, task_loss=3.274, contrastive_loss=0.337, total=4153.69, n_correct=2675.62, ppl=6.1, accuracy=64.415, wps=6853.6, ups=1.65, wpb=4153.7, bsz=157.4, num_updates=26200, lr=8.73704e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=60, gb_free=15.4, wall=21611
2023-07-08 14:01:05 | INFO | train_inner | epoch 018:   1254 / 1474 loss=0.951, trans_loss=5.339, nll_loss=2.636, w2v_ctc_loss=0.306, task_loss=3.711, contrastive_loss=0.118, total=4087.62, n_correct=2621.17, ppl=6.21, accuracy=64.125, wps=6772.7, ups=1.66, wpb=4087.6, bsz=143.6, num_updates=26300, lr=8.72041e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=21671
2023-07-08 14:02:04 | INFO | train_inner | epoch 018:   1354 / 1474 loss=0.956, trans_loss=5.349, nll_loss=2.651, w2v_ctc_loss=0.315, task_loss=3.675, contrastive_loss=0.163, total=4070.69, n_correct=2603.1, ppl=6.28, accuracy=63.947, wps=6806.3, ups=1.67, wpb=4070.7, bsz=145.9, num_updates=26400, lr=8.70388e-05, gnorm=0.241, clip=0, loss_scale=64, train_wall=59, gb_free=17.5, wall=21731
2023-07-08 14:03:05 | INFO | train_inner | epoch 018:   1454 / 1474 loss=0.952, trans_loss=5.343, nll_loss=2.642, w2v_ctc_loss=0.31, task_loss=3.64, contrastive_loss=0.135, total=4113.2, n_correct=2632.97, ppl=6.24, accuracy=64.013, wps=6835.5, ups=1.66, wpb=4113.2, bsz=148.8, num_updates=26500, lr=8.68744e-05, gnorm=0.237, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=21791
2023-07-08 14:03:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 14:03:43 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 1.463 | trans_loss 5.568 | nll_loss 2.842 | w2v_ctc_loss 0.458 | task_loss 4.634 | contrastive_loss 0.243 | total 4003.4 | n_correct 2479 | ppl 7.17 | accuracy 61.922 | uer 16.68 | wer 18.56 | raw_wer 18.56 | bleu 19.95 | wps 2155.4 | wpb 4003.4 | bsz 141.8 | num_updates 26520 | best_bleu 19.95
2023-07-08 14:03:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26520 updates
2023-07-08 14:03:43 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 14:03:47 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 14:03:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 18 @ 26520 updates, score 19.95) (writing took 8.318768710989389 seconds)
2023-07-08 14:03:51 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-07-08 14:03:51 | INFO | train | epoch 018 | loss 0.949 | trans_loss 5.326 | nll_loss 2.619 | w2v_ctc_loss 0.305 | task_loss 3.459 | contrastive_loss 0.22 | total 4137.32 | n_correct 2661.8 | ppl 6.14 | accuracy 64.336 | wps 6316.1 | ups 1.53 | wpb 4137.3 | bsz 152.6 | num_updates 26520 | lr 8.68417e-05 | gnorm 0.234 | clip 0 | loss_scale 64 | train_wall 884 | gb_free 16.1 | wall 21838
2023-07-08 14:03:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 14:03:51 | INFO | fairseq.trainer | begin training epoch 19
2023-07-08 14:03:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 14:04:48 | INFO | train_inner | epoch 019:     80 / 1474 loss=0.948, trans_loss=5.302, nll_loss=2.588, w2v_ctc_loss=0.302, task_loss=3.465, contrastive_loss=0.24, total=4102.06, n_correct=2651.48, ppl=6.01, accuracy=64.638, wps=3979, ups=0.97, wpb=4102.1, bsz=148.5, num_updates=26600, lr=8.6711e-05, gnorm=0.237, clip=0, loss_scale=64, train_wall=60, gb_free=17.6, wall=21894
2023-07-08 14:05:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-08 14:05:49 | INFO | train_inner | epoch 019:    181 / 1474 loss=0.94, trans_loss=5.288, nll_loss=2.57, w2v_ctc_loss=0.304, task_loss=3.285, contrastive_loss=0.187, total=4210.09, n_correct=2735.66, ppl=5.94, accuracy=64.979, wps=6830.1, ups=1.62, wpb=4210.1, bsz=159.6, num_updates=26700, lr=8.65485e-05, gnorm=0.23, clip=0, loss_scale=32, train_wall=61, gb_free=12.1, wall=21956
2023-07-08 14:06:50 | INFO | train_inner | epoch 019:    281 / 1474 loss=0.938, trans_loss=5.288, nll_loss=2.569, w2v_ctc_loss=0.301, task_loss=3.398, contrastive_loss=0.106, total=4187.37, n_correct=2723.04, ppl=5.93, accuracy=65.03, wps=6946.1, ups=1.66, wpb=4187.4, bsz=153.5, num_updates=26800, lr=8.63868e-05, gnorm=0.231, clip=0, loss_scale=32, train_wall=60, gb_free=17.6, wall=22016
2023-07-08 14:07:50 | INFO | train_inner | epoch 019:    381 / 1474 loss=0.946, trans_loss=5.296, nll_loss=2.581, w2v_ctc_loss=0.3, task_loss=3.41, contrastive_loss=0.32, total=4170.67, n_correct=2700.39, ppl=5.99, accuracy=64.747, wps=6932.5, ups=1.66, wpb=4170.7, bsz=155.3, num_updates=26900, lr=8.62261e-05, gnorm=0.236, clip=0, loss_scale=32, train_wall=60, gb_free=17.3, wall=22076
2023-07-08 14:08:50 | INFO | train_inner | epoch 019:    481 / 1474 loss=0.944, trans_loss=5.306, nll_loss=2.593, w2v_ctc_loss=0.305, task_loss=3.535, contrastive_loss=0.137, total=4115.22, n_correct=2664.58, ppl=6.03, accuracy=64.749, wps=6865.8, ups=1.67, wpb=4115.2, bsz=150.9, num_updates=27000, lr=8.60663e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=60, gb_free=15.3, wall=22136
2023-07-08 14:09:49 | INFO | train_inner | epoch 019:    581 / 1474 loss=0.942, trans_loss=5.298, nll_loss=2.583, w2v_ctc_loss=0.298, task_loss=3.384, contrastive_loss=0.265, total=4129.22, n_correct=2676.4, ppl=5.99, accuracy=64.816, wps=6918.9, ups=1.68, wpb=4129.2, bsz=153, num_updates=27100, lr=8.59074e-05, gnorm=0.233, clip=0, loss_scale=32, train_wall=59, gb_free=16.1, wall=22196
2023-07-08 14:10:49 | INFO | train_inner | epoch 019:    681 / 1474 loss=0.939, trans_loss=5.297, nll_loss=2.582, w2v_ctc_loss=0.295, task_loss=3.159, contrastive_loss=0.122, total=4197.2, n_correct=2720.57, ppl=5.99, accuracy=64.819, wps=7011.9, ups=1.67, wpb=4197.2, bsz=160.4, num_updates=27200, lr=8.57493e-05, gnorm=0.233, clip=0, loss_scale=32, train_wall=59, gb_free=14.9, wall=22256
2023-07-08 14:11:50 | INFO | train_inner | epoch 019:    781 / 1474 loss=0.946, trans_loss=5.307, nll_loss=2.595, w2v_ctc_loss=0.306, task_loss=3.475, contrastive_loss=0.145, total=4142.6, n_correct=2675.94, ppl=6.04, accuracy=64.596, wps=6845, ups=1.65, wpb=4142.6, bsz=152.5, num_updates=27300, lr=8.55921e-05, gnorm=0.234, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=22316
2023-07-08 14:12:50 | INFO | train_inner | epoch 019:    881 / 1474 loss=0.945, trans_loss=5.315, nll_loss=2.606, w2v_ctc_loss=0.304, task_loss=3.532, contrastive_loss=0.114, total=4153.47, n_correct=2678.01, ppl=6.09, accuracy=64.476, wps=6893.4, ups=1.66, wpb=4153.5, bsz=151.5, num_updates=27400, lr=8.54358e-05, gnorm=0.23, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=22376
2023-07-08 14:13:51 | INFO | train_inner | epoch 019:    981 / 1474 loss=0.955, trans_loss=5.329, nll_loss=2.624, w2v_ctc_loss=0.303, task_loss=3.452, contrastive_loss=0.581, total=4101.29, n_correct=2638.21, ppl=6.17, accuracy=64.326, wps=6711.6, ups=1.64, wpb=4101.3, bsz=155, num_updates=27500, lr=8.52803e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=61, gb_free=16.8, wall=22438
2023-07-08 14:14:51 | INFO | train_inner | epoch 019:   1081 / 1474 loss=0.948, trans_loss=5.33, nll_loss=2.626, w2v_ctc_loss=0.304, task_loss=3.695, contrastive_loss=0.202, total=4036.97, n_correct=2596.83, ppl=6.17, accuracy=64.326, wps=6703.1, ups=1.66, wpb=4037, bsz=145.5, num_updates=27600, lr=8.51257e-05, gnorm=0.236, clip=0, loss_scale=32, train_wall=60, gb_free=14.9, wall=22498
2023-07-08 14:15:52 | INFO | train_inner | epoch 019:   1181 / 1474 loss=0.955, trans_loss=5.329, nll_loss=2.624, w2v_ctc_loss=0.306, task_loss=3.495, contrastive_loss=0.368, total=4137.49, n_correct=2657.38, ppl=6.17, accuracy=64.227, wps=6814.4, ups=1.65, wpb=4137.5, bsz=153.8, num_updates=27700, lr=8.49719e-05, gnorm=0.239, clip=0, loss_scale=32, train_wall=60, gb_free=15.1, wall=22559
2023-07-08 14:16:52 | INFO | train_inner | epoch 019:   1281 / 1474 loss=0.955, trans_loss=5.332, nll_loss=2.629, w2v_ctc_loss=0.305, task_loss=3.493, contrastive_loss=0.16, total=4141.89, n_correct=2659.42, ppl=6.19, accuracy=64.208, wps=6911.7, ups=1.67, wpb=4141.9, bsz=150.1, num_updates=27800, lr=8.48189e-05, gnorm=0.237, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=22618
2023-07-08 14:17:52 | INFO | train_inner | epoch 019:   1381 / 1474 loss=0.948, trans_loss=5.319, nll_loss=2.611, w2v_ctc_loss=0.307, task_loss=3.527, contrastive_loss=0.135, total=4133.26, n_correct=2661.68, ppl=6.11, accuracy=64.397, wps=6857, ups=1.66, wpb=4133.3, bsz=150.5, num_updates=27900, lr=8.46668e-05, gnorm=0.235, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=22679
2023-07-08 14:18:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 14:19:15 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 1.464 | trans_loss 5.567 | nll_loss 2.846 | w2v_ctc_loss 0.469 | task_loss 4.635 | contrastive_loss 0.253 | total 4003.4 | n_correct 2479.6 | ppl 7.19 | accuracy 61.937 | uer 16.97 | wer 18.866 | raw_wer 18.866 | bleu 20.2 | wps 1985.3 | wpb 4003.4 | bsz 141.8 | num_updates 27993 | best_bleu 20.2
2023-07-08 14:19:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27993 updates
2023-07-08 14:19:15 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 14:19:19 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 14:19:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 19 @ 27993 updates, score 20.2) (writing took 8.223986485012574 seconds)
2023-07-08 14:19:23 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-07-08 14:19:23 | INFO | train | epoch 019 | loss 0.946 | trans_loss 5.31 | nll_loss 2.599 | w2v_ctc_loss 0.303 | task_loss 3.457 | contrastive_loss 0.219 | total 4137.6 | n_correct 2673.08 | ppl 6.06 | accuracy 64.605 | wps 6539 | ups 1.58 | wpb 4137.6 | bsz 152.7 | num_updates 27993 | lr 8.4526e-05 | gnorm 0.235 | clip 0 | loss_scale 32 | train_wall 883 | gb_free 17.5 | wall 22770
2023-07-08 14:19:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 14:19:23 | INFO | fairseq.trainer | begin training epoch 20
2023-07-08 14:19:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 14:19:36 | INFO | train_inner | epoch 020:      7 / 1474 loss=0.951, trans_loss=5.313, nll_loss=2.604, w2v_ctc_loss=0.306, task_loss=3.486, contrastive_loss=0.303, total=4119.08, n_correct=2660.22, ppl=6.08, accuracy=64.583, wps=3971.1, ups=0.96, wpb=4119.1, bsz=152.1, num_updates=28000, lr=8.45154e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=22782
2023-07-08 14:19:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 14:20:03 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 1.465 | trans_loss 5.571 | nll_loss 2.848 | w2v_ctc_loss 0.464 | task_loss 4.629 | contrastive_loss 0.248 | total 4003.4 | n_correct 2477.1 | ppl 7.2 | accuracy 61.875 | uer 16.978 | wer 18.829 | raw_wer 18.829 | bleu 20.32 | wps 1985.7 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.32
2023-07-08 14:20:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-07-08 14:20:03 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_20_28000.pt
2023-07-08 14:20:05 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_20_28000.pt
2023-07-08 14:20:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 20.32) (writing took 9.098531044000993 seconds)
2023-07-08 14:21:13 | INFO | train_inner | epoch 020:    107 / 1474 loss=0.934, trans_loss=5.265, nll_loss=2.541, w2v_ctc_loss=0.295, task_loss=3.325, contrastive_loss=0.145, total=4195.03, n_correct=2742.81, ppl=5.82, accuracy=65.382, wps=4308, ups=1.03, wpb=4195, bsz=156.8, num_updates=28100, lr=8.43649e-05, gnorm=0.23, clip=0, loss_scale=32, train_wall=60, gb_free=15.3, wall=22880
2023-07-08 14:22:14 | INFO | train_inner | epoch 020:    207 / 1474 loss=0.942, trans_loss=5.278, nll_loss=2.557, w2v_ctc_loss=0.296, task_loss=3.586, contrastive_loss=0.247, total=4154.14, n_correct=2706.73, ppl=5.89, accuracy=65.157, wps=6854, ups=1.65, wpb=4154.1, bsz=150.5, num_updates=28200, lr=8.42152e-05, gnorm=0.233, clip=0, loss_scale=32, train_wall=60, gb_free=17.4, wall=22940
2023-07-08 14:23:14 | INFO | train_inner | epoch 020:    307 / 1474 loss=0.932, trans_loss=5.264, nll_loss=2.539, w2v_ctc_loss=0.294, task_loss=3.127, contrastive_loss=0.127, total=4188.05, n_correct=2736.17, ppl=5.81, accuracy=65.333, wps=6971.3, ups=1.66, wpb=4188.1, bsz=163.1, num_updates=28300, lr=8.40663e-05, gnorm=0.233, clip=0, loss_scale=32, train_wall=60, gb_free=15.7, wall=23001
2023-07-08 14:24:14 | INFO | train_inner | epoch 020:    407 / 1474 loss=0.934, trans_loss=5.275, nll_loss=2.553, w2v_ctc_loss=0.294, task_loss=3.513, contrastive_loss=0.124, total=4115.16, n_correct=2682.29, ppl=5.87, accuracy=65.181, wps=6861.7, ups=1.67, wpb=4115.2, bsz=148.5, num_updates=28400, lr=8.39181e-05, gnorm=0.236, clip=0, loss_scale=32, train_wall=60, gb_free=15.7, wall=23061
2023-07-08 14:25:14 | INFO | train_inner | epoch 020:    507 / 1474 loss=0.948, trans_loss=5.296, nll_loss=2.582, w2v_ctc_loss=0.299, task_loss=3.54, contrastive_loss=0.3, total=4108.46, n_correct=2663.03, ppl=5.99, accuracy=64.818, wps=6809.5, ups=1.66, wpb=4108.5, bsz=150.2, num_updates=28500, lr=8.37708e-05, gnorm=0.237, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=23121
2023-07-08 14:26:14 | INFO | train_inner | epoch 020:    607 / 1474 loss=0.947, trans_loss=5.297, nll_loss=2.582, w2v_ctc_loss=0.301, task_loss=3.625, contrastive_loss=0.302, total=4094.9, n_correct=2648.84, ppl=5.99, accuracy=64.686, wps=6849.3, ups=1.67, wpb=4094.9, bsz=148, num_updates=28600, lr=8.36242e-05, gnorm=0.235, clip=0, loss_scale=32, train_wall=59, gb_free=12.4, wall=23181
2023-07-08 14:27:14 | INFO | train_inner | epoch 020:    707 / 1474 loss=0.943, trans_loss=5.298, nll_loss=2.584, w2v_ctc_loss=0.304, task_loss=3.453, contrastive_loss=0.113, total=4140.23, n_correct=2681.79, ppl=5.99, accuracy=64.774, wps=6875.3, ups=1.66, wpb=4140.2, bsz=150.3, num_updates=28700, lr=8.34784e-05, gnorm=0.236, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=23241
2023-07-08 14:28:14 | INFO | train_inner | epoch 020:    807 / 1474 loss=0.935, trans_loss=5.288, nll_loss=2.571, w2v_ctc_loss=0.298, task_loss=3.437, contrastive_loss=0.118, total=4140.66, n_correct=2688.99, ppl=5.94, accuracy=64.941, wps=6933, ups=1.67, wpb=4140.7, bsz=152.8, num_updates=28800, lr=8.33333e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=59, gb_free=17.6, wall=23301
2023-07-08 14:29:16 | INFO | train_inner | epoch 020:    907 / 1474 loss=0.962, trans_loss=5.314, nll_loss=2.606, w2v_ctc_loss=0.303, task_loss=3.291, contrastive_loss=0.697, total=4157.15, n_correct=2682.92, ppl=6.09, accuracy=64.537, wps=6771.8, ups=1.63, wpb=4157.1, bsz=161.3, num_updates=28900, lr=8.3189e-05, gnorm=0.237, clip=0, loss_scale=64, train_wall=61, gb_free=17.8, wall=23362
2023-07-08 14:30:16 | INFO | train_inner | epoch 020:   1007 / 1474 loss=0.943, trans_loss=5.294, nll_loss=2.579, w2v_ctc_loss=0.298, task_loss=3.422, contrastive_loss=0.13, total=4171.86, n_correct=2703.54, ppl=5.98, accuracy=64.804, wps=6875.5, ups=1.65, wpb=4171.9, bsz=154.3, num_updates=29000, lr=8.30455e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=60, gb_free=16.2, wall=23423
2023-07-08 14:31:16 | INFO | train_inner | epoch 020:   1107 / 1474 loss=0.95, trans_loss=5.301, nll_loss=2.589, w2v_ctc_loss=0.299, task_loss=3.329, contrastive_loss=0.403, total=4162.96, n_correct=2696.55, ppl=6.02, accuracy=64.775, wps=6932.5, ups=1.67, wpb=4163, bsz=157.5, num_updates=29100, lr=8.29027e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=23483
2023-07-08 14:32:17 | INFO | train_inner | epoch 020:   1207 / 1474 loss=0.936, trans_loss=5.297, nll_loss=2.583, w2v_ctc_loss=0.302, task_loss=3.784, contrastive_loss=0.11, total=4033.74, n_correct=2611.06, ppl=5.99, accuracy=64.73, wps=6690.2, ups=1.66, wpb=4033.7, bsz=142.6, num_updates=29200, lr=8.27606e-05, gnorm=0.238, clip=0, loss_scale=64, train_wall=60, gb_free=17.4, wall=23543
2023-07-08 14:33:17 | INFO | train_inner | epoch 020:   1307 / 1474 loss=0.939, trans_loss=5.302, nll_loss=2.591, w2v_ctc_loss=0.3, task_loss=3.653, contrastive_loss=0.116, total=4124.42, n_correct=2670.21, ppl=6.03, accuracy=64.741, wps=6803.1, ups=1.65, wpb=4124.4, bsz=148.5, num_updates=29300, lr=8.26192e-05, gnorm=0.233, clip=0, loss_scale=64, train_wall=60, gb_free=16.2, wall=23604
2023-07-08 14:34:18 | INFO | train_inner | epoch 020:   1407 / 1474 loss=0.946, trans_loss=5.306, nll_loss=2.596, w2v_ctc_loss=0.303, task_loss=3.664, contrastive_loss=0.115, total=4114.1, n_correct=2657.06, ppl=6.04, accuracy=64.584, wps=6785.8, ups=1.65, wpb=4114.1, bsz=146.8, num_updates=29400, lr=8.24786e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=60, gb_free=14.7, wall=23664
2023-07-08 14:34:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 14:35:23 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 1.465 | trans_loss 5.565 | nll_loss 2.841 | w2v_ctc_loss 0.46 | task_loss 4.59 | contrastive_loss 0.249 | total 4003.4 | n_correct 2479.9 | ppl 7.17 | accuracy 61.945 | uer 16.967 | wer 18.914 | raw_wer 18.914 | bleu 19.64 | wps 2080.6 | wpb 4003.4 | bsz 141.8 | num_updates 29467 | best_bleu 20.32
2023-07-08 14:35:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29467 updates
2023-07-08 14:35:23 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.6400.pt
2023-07-08 14:35:25 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.6400.pt
2023-07-08 14:35:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.6400.pt (epoch 20 @ 29467 updates, score 19.64) (writing took 5.168631667998852 seconds)
2023-07-08 14:35:28 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-07-08 14:35:28 | INFO | train | epoch 020 | loss 0.942 | trans_loss 5.292 | nll_loss 2.576 | w2v_ctc_loss 0.299 | task_loss 3.455 | contrastive_loss 0.219 | total 4138.65 | n_correct 2685.31 | ppl 5.96 | accuracy 64.884 | wps 6321.4 | ups 1.53 | wpb 4138.6 | bsz 152.8 | num_updates 29467 | lr 8.23848e-05 | gnorm 0.235 | clip 0 | loss_scale 64 | train_wall 883 | gb_free 16.8 | wall 23735
2023-07-08 14:35:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 14:35:29 | INFO | fairseq.trainer | begin training epoch 21
2023-07-08 14:35:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 14:35:57 | INFO | train_inner | epoch 021:     33 / 1474 loss=0.945, trans_loss=5.3, nll_loss=2.588, w2v_ctc_loss=0.299, task_loss=3.272, contrastive_loss=0.353, total=4155.01, n_correct=2692.57, ppl=6.01, accuracy=64.803, wps=4204.3, ups=1.01, wpb=4155, bsz=158.8, num_updates=29500, lr=8.23387e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=59, gb_free=16.5, wall=23763
2023-07-08 14:36:57 | INFO | train_inner | epoch 021:    133 / 1474 loss=0.935, trans_loss=5.259, nll_loss=2.533, w2v_ctc_loss=0.293, task_loss=3.271, contrastive_loss=0.338, total=4186.67, n_correct=2740.55, ppl=5.79, accuracy=65.459, wps=6908.8, ups=1.65, wpb=4186.7, bsz=158.7, num_updates=29600, lr=8.21995e-05, gnorm=0.233, clip=0, loss_scale=64, train_wall=60, gb_free=13.4, wall=23824
2023-07-08 14:37:58 | INFO | train_inner | epoch 021:    233 / 1474 loss=0.933, trans_loss=5.259, nll_loss=2.535, w2v_ctc_loss=0.29, task_loss=3.26, contrastive_loss=0.247, total=4166.37, n_correct=2723.36, ppl=5.79, accuracy=65.365, wps=6901.4, ups=1.66, wpb=4166.4, bsz=157.6, num_updates=29700, lr=8.2061e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=60, gb_free=14.3, wall=23884
2023-07-08 14:38:59 | INFO | train_inner | epoch 021:    333 / 1474 loss=0.937, trans_loss=5.273, nll_loss=2.551, w2v_ctc_loss=0.299, task_loss=3.51, contrastive_loss=0.249, total=4132.25, n_correct=2692.54, ppl=5.86, accuracy=65.159, wps=6783, ups=1.64, wpb=4132.2, bsz=152.5, num_updates=29800, lr=8.19232e-05, gnorm=0.237, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=23945
2023-07-08 14:39:58 | INFO | train_inner | epoch 021:    433 / 1474 loss=0.935, trans_loss=5.265, nll_loss=2.542, w2v_ctc_loss=0.294, task_loss=3.298, contrastive_loss=0.115, total=4195.53, n_correct=2741.88, ppl=5.82, accuracy=65.352, wps=7018.4, ups=1.67, wpb=4195.5, bsz=155.8, num_updates=29900, lr=8.17861e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=59, gb_free=16.7, wall=24005
2023-07-08 14:40:59 | INFO | train_inner | epoch 021:    533 / 1474 loss=0.927, trans_loss=5.261, nll_loss=2.536, w2v_ctc_loss=0.294, task_loss=3.568, contrastive_loss=0.104, total=4085.05, n_correct=2670.08, ppl=5.8, accuracy=65.362, wps=6750.7, ups=1.65, wpb=4085.1, bsz=148, num_updates=30000, lr=8.16497e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=24065
2023-07-08 14:40:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 14:41:24 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 1.47 | trans_loss 5.574 | nll_loss 2.853 | w2v_ctc_loss 0.466 | task_loss 4.602 | contrastive_loss 0.248 | total 4003.4 | n_correct 2473.1 | ppl 7.22 | accuracy 61.775 | uer 16.856 | wer 18.609 | raw_wer 18.609 | bleu 19.4 | wps 2061.8 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.32
2023-07-08 14:41:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-07-08 14:41:24 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_21_30000.pt
2023-07-08 14:41:27 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_21_30000.pt
2023-07-08 14:41:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 19.4) (writing took 5.185574625997106 seconds)
tensor(0.0246, device='cuda:0')
tensor(0.0006, device='cuda:0')
2023-07-08 14:42:30 | INFO | train_inner | epoch 021:    633 / 1474 loss=0.945, trans_loss=5.276, nll_loss=2.557, w2v_ctc_loss=0.294, task_loss=3.406, contrastive_loss=0.445, total=4220.3, n_correct=2749.56, ppl=5.88, accuracy=65.151, wps=4614.1, ups=1.09, wpb=4220.3, bsz=157.9, num_updates=30100, lr=8.15139e-05, gnorm=0.233, clip=0, loss_scale=64, train_wall=60, gb_free=15.9, wall=24157
2023-07-08 14:43:31 | INFO | train_inner | epoch 021:    733 / 1474 loss=0.934, trans_loss=5.275, nll_loss=2.555, w2v_ctc_loss=0.292, task_loss=3.474, contrastive_loss=0.168, total=4148.18, n_correct=2703.61, ppl=5.88, accuracy=65.176, wps=6884.3, ups=1.66, wpb=4148.2, bsz=154.2, num_updates=30200, lr=8.13788e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=60, gb_free=12.3, wall=24217
2023-07-08 14:44:31 | INFO | train_inner | epoch 021:    833 / 1474 loss=0.942, trans_loss=5.292, nll_loss=2.577, w2v_ctc_loss=0.299, task_loss=3.669, contrastive_loss=0.195, total=4062.56, n_correct=2634.69, ppl=5.97, accuracy=64.853, wps=6687.8, ups=1.65, wpb=4062.6, bsz=146.5, num_updates=30300, lr=8.12444e-05, gnorm=0.238, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=24278
2023-07-08 14:45:31 | INFO | train_inner | epoch 021:    933 / 1474 loss=0.94, trans_loss=5.276, nll_loss=2.556, w2v_ctc_loss=0.299, task_loss=3.449, contrastive_loss=0.141, total=4103.66, n_correct=2670.41, ppl=5.88, accuracy=65.074, wps=6856.4, ups=1.67, wpb=4103.7, bsz=150.7, num_updates=30400, lr=8.11107e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=59, gb_free=17.3, wall=24338
2023-07-08 14:46:31 | INFO | train_inner | epoch 021:   1033 / 1474 loss=0.942, trans_loss=5.295, nll_loss=2.581, w2v_ctc_loss=0.3, task_loss=3.525, contrastive_loss=0.135, total=4100.54, n_correct=2661.24, ppl=5.98, accuracy=64.9, wps=6840.1, ups=1.67, wpb=4100.5, bsz=149.1, num_updates=30500, lr=8.09776e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=60, gb_free=18, wall=24398
2023-07-08 14:47:31 | INFO | train_inner | epoch 021:   1133 / 1474 loss=0.944, trans_loss=5.284, nll_loss=2.567, w2v_ctc_loss=0.299, task_loss=3.699, contrastive_loss=0.144, total=4119.98, n_correct=2677.49, ppl=5.92, accuracy=64.988, wps=6864.5, ups=1.67, wpb=4120, bsz=147, num_updates=30600, lr=8.08452e-05, gnorm=0.237, clip=0, loss_scale=64, train_wall=60, gb_free=18, wall=24458
2023-07-08 14:48:31 | INFO | train_inner | epoch 021:   1233 / 1474 loss=0.941, trans_loss=5.283, nll_loss=2.566, w2v_ctc_loss=0.298, task_loss=3.27, contrastive_loss=0.245, total=4161.49, n_correct=2704.07, ppl=5.92, accuracy=64.978, wps=6985.3, ups=1.68, wpb=4161.5, bsz=156.5, num_updates=30700, lr=8.07134e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=59, gb_free=17, wall=24517
2023-07-08 14:49:31 | INFO | train_inner | epoch 021:   1333 / 1474 loss=0.936, trans_loss=5.277, nll_loss=2.56, w2v_ctc_loss=0.295, task_loss=3.34, contrastive_loss=0.166, total=4141.76, n_correct=2698.02, ppl=5.9, accuracy=65.142, wps=6887, ups=1.66, wpb=4141.8, bsz=155.8, num_updates=30800, lr=8.05823e-05, gnorm=0.235, clip=0, loss_scale=128, train_wall=60, gb_free=17.5, wall=24577
2023-07-08 14:49:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-08 14:50:33 | INFO | train_inner | epoch 021:   1434 / 1474 loss=0.947, trans_loss=5.302, nll_loss=2.59, w2v_ctc_loss=0.308, task_loss=3.718, contrastive_loss=0.146, total=4116, n_correct=2665.07, ppl=6.02, accuracy=64.749, wps=6680.3, ups=1.62, wpb=4116, bsz=148.5, num_updates=30900, lr=8.04518e-05, gnorm=0.238, clip=0, loss_scale=64, train_wall=61, gb_free=15.7, wall=24639
2023-07-08 14:50:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0246, device='cuda:4')
tensor(0.0006, device='cuda:4')
tensor(0.0246, device='cuda:5')
tensor(0.0006, device='cuda:5')
tensor(0.0246, device='cuda:6')
tensor(0.0006, device='cuda:6')
tensor(0.0246, device='cuda:7')
tensor(0.0006, device='cuda:7')
tensor(0.0246, device='cuda:3')
tensor(0.0006, device='cuda:3')
tensor(0.0246, device='cuda:1')
tensor(0.0006, device='cuda:1')
tensor(0.0246, device='cuda:2')
tensor(0.0006, device='cuda:2')
2023-07-08 14:51:26 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 1.462 | trans_loss 5.572 | nll_loss 2.849 | w2v_ctc_loss 0.455 | task_loss 4.618 | contrastive_loss 0.248 | total 4003.4 | n_correct 2477.7 | ppl 7.21 | accuracy 61.89 | uer 17.079 | wer 19.142 | raw_wer 19.142 | bleu 19.75 | wps 1815 | wpb 4003.4 | bsz 141.8 | num_updates 30940 | best_bleu 20.32
2023-07-08 14:51:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30940 updates
2023-07-08 14:51:26 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.7507.pt
2023-07-08 14:51:28 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.7507.pt
2023-07-08 14:51:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.7507.pt (epoch 21 @ 30940 updates, score 19.75) (writing took 5.148386200002278 seconds)
2023-07-08 14:51:31 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-07-08 14:51:31 | INFO | train | epoch 021 | loss 0.939 | trans_loss 5.277 | nll_loss 2.558 | w2v_ctc_loss 0.297 | task_loss 3.462 | contrastive_loss 0.212 | total 4137.4 | n_correct 2694.25 | ppl 5.89 | accuracy 65.12 | wps 6328.8 | ups 1.53 | wpb 4137.4 | bsz 152.6 | num_updates 30940 | lr 8.03998e-05 | gnorm 0.235 | clip 0 | loss_scale 64 | train_wall 883 | gb_free 15.6 | wall 24698
2023-07-08 14:51:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 14:51:31 | INFO | fairseq.trainer | begin training epoch 22
2023-07-08 14:51:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 14:51:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-08 14:52:16 | INFO | train_inner | epoch 022:     61 / 1474 loss=0.931, trans_loss=5.257, nll_loss=2.532, w2v_ctc_loss=0.293, task_loss=3.475, contrastive_loss=0.107, total=4136.92, n_correct=2710.18, ppl=5.78, accuracy=65.512, wps=3992.2, ups=0.97, wpb=4136.9, bsz=150.3, num_updates=31000, lr=8.03219e-05, gnorm=0.235, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=24743
2023-07-08 14:53:17 | INFO | train_inner | epoch 022:    161 / 1474 loss=0.936, trans_loss=5.252, nll_loss=2.526, w2v_ctc_loss=0.295, task_loss=3.527, contrastive_loss=0.266, total=4116.11, n_correct=2695.79, ppl=5.76, accuracy=65.494, wps=6776.2, ups=1.65, wpb=4116.1, bsz=153.4, num_updates=31100, lr=8.01927e-05, gnorm=0.235, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=24803
2023-07-08 14:54:17 | INFO | train_inner | epoch 022:    261 / 1474 loss=0.927, trans_loss=5.237, nll_loss=2.506, w2v_ctc_loss=0.287, task_loss=3.027, contrastive_loss=0.155, total=4272.11, n_correct=2810.23, ppl=5.68, accuracy=65.781, wps=7074, ups=1.66, wpb=4272.1, bsz=165.7, num_updates=31200, lr=8.00641e-05, gnorm=0.232, clip=0, loss_scale=32, train_wall=60, gb_free=18, wall=24864
2023-07-08 14:55:19 | INFO | train_inner | epoch 022:    361 / 1474 loss=0.946, trans_loss=5.269, nll_loss=2.547, w2v_ctc_loss=0.297, task_loss=3.502, contrastive_loss=0.464, total=4178.4, n_correct=2727.7, ppl=5.84, accuracy=65.281, wps=6813.4, ups=1.63, wpb=4178.4, bsz=155, num_updates=31300, lr=7.99361e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=24925
2023-07-08 14:56:19 | INFO | train_inner | epoch 022:    461 / 1474 loss=0.943, trans_loss=5.266, nll_loss=2.542, w2v_ctc_loss=0.297, task_loss=3.624, contrastive_loss=0.227, total=4132.96, n_correct=2702.29, ppl=5.83, accuracy=65.384, wps=6814.9, ups=1.65, wpb=4133, bsz=148.8, num_updates=31400, lr=7.98087e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=24986
2023-07-08 14:57:20 | INFO | train_inner | epoch 022:    561 / 1474 loss=0.937, trans_loss=5.258, nll_loss=2.533, w2v_ctc_loss=0.297, task_loss=3.463, contrastive_loss=0.129, total=4158.17, n_correct=2720.99, ppl=5.79, accuracy=65.437, wps=6853.4, ups=1.65, wpb=4158.2, bsz=153.9, num_updates=31500, lr=7.96819e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=25046
2023-07-08 14:58:19 | INFO | train_inner | epoch 022:    661 / 1474 loss=0.931, trans_loss=5.247, nll_loss=2.52, w2v_ctc_loss=0.287, task_loss=3.299, contrastive_loss=0.292, total=4139.66, n_correct=2717.03, ppl=5.74, accuracy=65.634, wps=6960.8, ups=1.68, wpb=4139.7, bsz=155.5, num_updates=31600, lr=7.95557e-05, gnorm=0.236, clip=0, loss_scale=32, train_wall=59, gb_free=16.4, wall=25106
2023-07-08 14:59:20 | INFO | train_inner | epoch 022:    761 / 1474 loss=0.934, trans_loss=5.259, nll_loss=2.535, w2v_ctc_loss=0.296, task_loss=3.554, contrastive_loss=0.135, total=4167.89, n_correct=2727.03, ppl=5.79, accuracy=65.43, wps=6886.7, ups=1.65, wpb=4167.9, bsz=152, num_updates=31700, lr=7.94301e-05, gnorm=0.236, clip=0, loss_scale=32, train_wall=60, gb_free=13.2, wall=25166
2023-07-08 15:00:20 | INFO | train_inner | epoch 022:    861 / 1474 loss=0.931, trans_loss=5.264, nll_loss=2.541, w2v_ctc_loss=0.292, task_loss=3.747, contrastive_loss=0.106, total=4075.79, n_correct=2658.85, ppl=5.82, accuracy=65.235, wps=6744.9, ups=1.65, wpb=4075.8, bsz=144.5, num_updates=31800, lr=7.93052e-05, gnorm=0.237, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=25227
2023-07-08 15:01:21 | INFO | train_inner | epoch 022:    961 / 1474 loss=0.933, trans_loss=5.256, nll_loss=2.532, w2v_ctc_loss=0.291, task_loss=3.471, contrastive_loss=0.11, total=4134.72, n_correct=2706.47, ppl=5.78, accuracy=65.457, wps=6874.9, ups=1.66, wpb=4134.7, bsz=151.6, num_updates=31900, lr=7.91808e-05, gnorm=0.236, clip=0, loss_scale=32, train_wall=60, gb_free=14.5, wall=25287
2023-07-08 15:02:21 | INFO | train_inner | epoch 022:   1061 / 1474 loss=0.937, trans_loss=5.259, nll_loss=2.536, w2v_ctc_loss=0.29, task_loss=3.289, contrastive_loss=0.446, total=4160.57, n_correct=2725.48, ppl=5.8, accuracy=65.507, wps=6921.4, ups=1.66, wpb=4160.6, bsz=157.8, num_updates=32000, lr=7.90569e-05, gnorm=0.234, clip=0, loss_scale=32, train_wall=60, gb_free=17.4, wall=25347
2023-07-08 15:02:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 15:02:47 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 1.462 | trans_loss 5.559 | nll_loss 2.834 | w2v_ctc_loss 0.469 | task_loss 4.63 | contrastive_loss 0.244 | total 4003.4 | n_correct 2487.4 | ppl 7.13 | accuracy 62.132 | uer 17.158 | wer 19.078 | raw_wer 19.078 | bleu 20.15 | wps 2009.3 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.32
2023-07-08 15:02:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-07-08 15:02:47 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_22_32000.pt
2023-07-08 15:02:49 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_22_32000.pt
2023-07-08 15:02:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 20.15) (writing took 6.13042099600716 seconds)
2023-07-08 15:03:53 | INFO | train_inner | epoch 022:   1161 / 1474 loss=0.941, trans_loss=5.289, nll_loss=2.575, w2v_ctc_loss=0.297, task_loss=3.568, contrastive_loss=0.212, total=4099.59, n_correct=2660.5, ppl=5.96, accuracy=64.897, wps=4441, ups=1.08, wpb=4099.6, bsz=148.1, num_updates=32100, lr=7.89337e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=60, gb_free=15.2, wall=25439
2023-07-08 15:04:53 | INFO | train_inner | epoch 022:   1261 / 1474 loss=0.936, trans_loss=5.273, nll_loss=2.554, w2v_ctc_loss=0.295, task_loss=3.202, contrastive_loss=0.198, total=4182.05, n_correct=2725.21, ppl=5.87, accuracy=65.164, wps=6954.7, ups=1.66, wpb=4182.1, bsz=161.5, num_updates=32200, lr=7.8811e-05, gnorm=0.232, clip=0, loss_scale=32, train_wall=60, gb_free=15.8, wall=25500
2023-07-08 15:05:53 | INFO | train_inner | epoch 022:   1361 / 1474 loss=0.935, trans_loss=5.266, nll_loss=2.545, w2v_ctc_loss=0.292, task_loss=3.455, contrastive_loss=0.243, total=4062.31, n_correct=2654.31, ppl=5.84, accuracy=65.34, wps=6825.9, ups=1.68, wpb=4062.3, bsz=149.5, num_updates=32300, lr=7.86889e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=59, gb_free=15.3, wall=25559
2023-07-08 15:06:53 | INFO | train_inner | epoch 022:   1461 / 1474 loss=0.943, trans_loss=5.284, nll_loss=2.567, w2v_ctc_loss=0.3, task_loss=3.673, contrastive_loss=0.14, total=4081.88, n_correct=2650.08, ppl=5.93, accuracy=64.923, wps=6797.9, ups=1.67, wpb=4081.9, bsz=144.5, num_updates=32400, lr=7.85674e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=60, gb_free=17.3, wall=25619
2023-07-08 15:07:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 15:07:27 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 1.471 | trans_loss 5.559 | nll_loss 2.832 | w2v_ctc_loss 0.468 | task_loss 4.587 | contrastive_loss 0.253 | total 4003.4 | n_correct 2489.7 | ppl 7.12 | accuracy 62.19 | uer 17.055 | wer 18.948 | raw_wer 18.948 | bleu 20.04 | wps 1979.4 | wpb 4003.4 | bsz 141.8 | num_updates 32413 | best_bleu 20.32
2023-07-08 15:07:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32413 updates
2023-07-08 15:07:27 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.0409.pt
2023-07-08 15:07:29 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.0409.pt
2023-07-08 15:07:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.0409.pt (epoch 22 @ 32413 updates, score 20.04) (writing took 5.265665101993363 seconds)
2023-07-08 15:07:32 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-07-08 15:07:32 | INFO | train | epoch 022 | loss 0.936 | trans_loss 5.262 | nll_loss 2.539 | w2v_ctc_loss 0.294 | task_loss 3.453 | contrastive_loss 0.219 | total 4138.89 | n_correct 2705.94 | ppl 5.81 | accuracy 65.379 | wps 6342.9 | ups 1.53 | wpb 4138.9 | bsz 152.8 | num_updates 32413 | lr 7.85517e-05 | gnorm 0.236 | clip 0 | loss_scale 32 | train_wall 882 | gb_free 12.2 | wall 25659
2023-07-08 15:07:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 15:07:33 | INFO | fairseq.trainer | begin training epoch 23
2023-07-08 15:07:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 15:08:33 | INFO | train_inner | epoch 023:     87 / 1474 loss=0.929, trans_loss=5.234, nll_loss=2.502, w2v_ctc_loss=0.293, task_loss=3.53, contrastive_loss=0.121, total=4096.09, n_correct=2699.19, ppl=5.67, accuracy=65.897, wps=4090.6, ups=1, wpb=4096.1, bsz=150.6, num_updates=32500, lr=7.84465e-05, gnorm=0.236, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=25719
2023-07-08 15:09:34 | INFO | train_inner | epoch 023:    187 / 1474 loss=0.931, trans_loss=5.231, nll_loss=2.497, w2v_ctc_loss=0.29, task_loss=3.678, contrastive_loss=0.117, total=4107.77, n_correct=2708.33, ppl=5.64, accuracy=65.932, wps=6767.1, ups=1.65, wpb=4107.8, bsz=146.7, num_updates=32600, lr=7.8326e-05, gnorm=0.237, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=25780
2023-07-08 15:10:34 | INFO | train_inner | epoch 023:    287 / 1474 loss=0.933, trans_loss=5.241, nll_loss=2.511, w2v_ctc_loss=0.288, task_loss=3.465, contrastive_loss=0.273, total=4153.12, n_correct=2726.81, ppl=5.7, accuracy=65.657, wps=6831.6, ups=1.64, wpb=4153.1, bsz=153.2, num_updates=32700, lr=7.82062e-05, gnorm=0.233, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=25841
2023-07-08 15:11:35 | INFO | train_inner | epoch 023:    387 / 1474 loss=0.929, trans_loss=5.239, nll_loss=2.509, w2v_ctc_loss=0.288, task_loss=3.577, contrastive_loss=0.103, total=4116.7, n_correct=2708.22, ppl=5.69, accuracy=65.786, wps=6835.4, ups=1.66, wpb=4116.7, bsz=147, num_updates=32800, lr=7.80869e-05, gnorm=0.236, clip=0, loss_scale=32, train_wall=60, gb_free=15.5, wall=25901
2023-07-08 15:12:35 | INFO | train_inner | epoch 023:    487 / 1474 loss=0.932, trans_loss=5.241, nll_loss=2.511, w2v_ctc_loss=0.289, task_loss=3.353, contrastive_loss=0.216, total=4157.6, n_correct=2728.9, ppl=5.7, accuracy=65.636, wps=6874, ups=1.65, wpb=4157.6, bsz=156.8, num_updates=32900, lr=7.79681e-05, gnorm=0.24, clip=0, loss_scale=32, train_wall=60, gb_free=17.4, wall=25961
2023-07-08 15:13:34 | INFO | train_inner | epoch 023:    587 / 1474 loss=0.924, trans_loss=5.232, nll_loss=2.5, w2v_ctc_loss=0.287, task_loss=3.256, contrastive_loss=0.11, total=4173.42, n_correct=2747.53, ppl=5.66, accuracy=65.834, wps=7023.3, ups=1.68, wpb=4173.4, bsz=158, num_updates=33000, lr=7.78499e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=59, gb_free=13.1, wall=26021
2023-07-08 15:14:35 | INFO | train_inner | epoch 023:    687 / 1474 loss=0.932, trans_loss=5.241, nll_loss=2.512, w2v_ctc_loss=0.29, task_loss=3.461, contrastive_loss=0.191, total=4137.82, n_correct=2714.75, ppl=5.7, accuracy=65.608, wps=6882.5, ups=1.66, wpb=4137.8, bsz=151.2, num_updates=33100, lr=7.77322e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=60, gb_free=17.3, wall=26081
2023-07-08 15:15:35 | INFO | train_inner | epoch 023:    787 / 1474 loss=0.939, trans_loss=5.254, nll_loss=2.529, w2v_ctc_loss=0.295, task_loss=3.466, contrastive_loss=0.15, total=4150.99, n_correct=2720.05, ppl=5.77, accuracy=65.528, wps=6898, ups=1.66, wpb=4151, bsz=152.7, num_updates=33200, lr=7.76151e-05, gnorm=0.239, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=26141
2023-07-08 15:16:35 | INFO | train_inner | epoch 023:    887 / 1474 loss=0.935, trans_loss=5.243, nll_loss=2.515, w2v_ctc_loss=0.291, task_loss=3.162, contrastive_loss=0.308, total=4181.99, n_correct=2749.1, ppl=5.72, accuracy=65.737, wps=6982.5, ups=1.67, wpb=4182, bsz=162.3, num_updates=33300, lr=7.74984e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=59, gb_free=16.6, wall=26201
2023-07-08 15:17:35 | INFO | train_inner | epoch 023:    987 / 1474 loss=0.943, trans_loss=5.251, nll_loss=2.525, w2v_ctc_loss=0.29, task_loss=3.441, contrastive_loss=0.626, total=4168.73, n_correct=2731.68, ppl=5.76, accuracy=65.528, wps=6865.2, ups=1.65, wpb=4168.7, bsz=155.2, num_updates=33400, lr=7.73823e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=60, gb_free=11.4, wall=26262
2023-07-08 15:18:36 | INFO | train_inner | epoch 023:   1087 / 1474 loss=0.935, trans_loss=5.255, nll_loss=2.53, w2v_ctc_loss=0.296, task_loss=3.679, contrastive_loss=0.125, total=4088.49, n_correct=2675.26, ppl=5.78, accuracy=65.434, wps=6710.3, ups=1.64, wpb=4088.5, bsz=145, num_updates=33500, lr=7.72667e-05, gnorm=0.237, clip=0, loss_scale=64, train_wall=61, gb_free=16.1, wall=26323
2023-07-08 15:19:37 | INFO | train_inner | epoch 023:   1187 / 1474 loss=0.93, trans_loss=5.256, nll_loss=2.531, w2v_ctc_loss=0.293, task_loss=3.437, contrastive_loss=0.114, total=4162.7, n_correct=2723.21, ppl=5.78, accuracy=65.419, wps=6862.1, ups=1.65, wpb=4162.7, bsz=154.7, num_updates=33600, lr=7.71517e-05, gnorm=0.233, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=26383
2023-07-08 15:20:37 | INFO | train_inner | epoch 023:   1287 / 1474 loss=0.93, trans_loss=5.245, nll_loss=2.518, w2v_ctc_loss=0.288, task_loss=3.356, contrastive_loss=0.134, total=4135.53, n_correct=2717.31, ppl=5.73, accuracy=65.706, wps=6882.4, ups=1.66, wpb=4135.5, bsz=154.5, num_updates=33700, lr=7.70371e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=26443
2023-07-08 15:21:38 | INFO | train_inner | epoch 023:   1387 / 1474 loss=0.938, trans_loss=5.272, nll_loss=2.553, w2v_ctc_loss=0.292, task_loss=3.481, contrastive_loss=0.25, total=4143.98, n_correct=2702.62, ppl=5.87, accuracy=65.218, wps=6838.4, ups=1.65, wpb=4144, bsz=152.6, num_updates=33800, lr=7.69231e-05, gnorm=0.237, clip=0, loss_scale=64, train_wall=60, gb_free=16.2, wall=26504
2023-07-08 15:22:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 15:22:55 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 1.47 | trans_loss 5.562 | nll_loss 2.838 | w2v_ctc_loss 0.489 | task_loss 4.617 | contrastive_loss 0.257 | total 4003.4 | n_correct 2486.9 | ppl 7.15 | accuracy 62.12 | uer 16.991 | wer 18.814 | raw_wer 18.814 | bleu 19.95 | wps 2078.3 | wpb 4003.4 | bsz 141.8 | num_updates 33887 | best_bleu 20.32
2023-07-08 15:22:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33887 updates
2023-07-08 15:22:55 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.9503.pt
2023-07-08 15:22:58 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.9503.pt
2023-07-08 15:23:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.9503.pt (epoch 23 @ 33887 updates, score 19.95) (writing took 5.38537376599561 seconds)
2023-07-08 15:23:01 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-07-08 15:23:01 | INFO | train | epoch 023 | loss 0.933 | trans_loss 5.247 | nll_loss 2.52 | w2v_ctc_loss 0.291 | task_loss 3.452 | contrastive_loss 0.219 | total 4138.65 | n_correct 2715.52 | ppl 5.73 | accuracy 65.614 | wps 6569.1 | ups 1.59 | wpb 4138.6 | bsz 152.8 | num_updates 33887 | lr 7.68243e-05 | gnorm 0.236 | clip 0 | loss_scale 64 | train_wall 884 | gb_free 14.1 | wall 26587
2023-07-08 15:23:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 15:23:01 | INFO | fairseq.trainer | begin training epoch 24
2023-07-08 15:23:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 15:23:17 | INFO | train_inner | epoch 024:     13 / 1474 loss=0.937, trans_loss=5.265, nll_loss=2.545, w2v_ctc_loss=0.289, task_loss=3.483, contrastive_loss=0.399, total=4085.11, n_correct=2670.2, ppl=5.84, accuracy=65.364, wps=4109, ups=1.01, wpb=4085.1, bsz=152.1, num_updates=33900, lr=7.68095e-05, gnorm=0.239, clip=0, loss_scale=64, train_wall=60, gb_free=13, wall=26603
2023-07-08 15:24:17 | INFO | train_inner | epoch 024:    113 / 1474 loss=0.931, trans_loss=5.219, nll_loss=2.483, w2v_ctc_loss=0.284, task_loss=3.189, contrastive_loss=0.437, total=4171.44, n_correct=2757.25, ppl=5.59, accuracy=66.098, wps=6916.4, ups=1.66, wpb=4171.4, bsz=162.3, num_updates=34000, lr=7.66965e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=26664
2023-07-08 15:24:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 15:24:44 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 1.464 | trans_loss 5.563 | nll_loss 2.834 | w2v_ctc_loss 0.462 | task_loss 4.625 | contrastive_loss 0.262 | total 4003.4 | n_correct 2484.7 | ppl 7.13 | accuracy 62.065 | uer 16.816 | wer 18.799 | raw_wer 18.799 | bleu 19.97 | wps 1999 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.32
2023-07-08 15:24:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-07-08 15:24:44 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_24_34000.pt
2023-07-08 15:24:46 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_24_34000.pt
2023-07-08 15:24:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 19.97) (writing took 6.214339992002351 seconds)
2023-07-08 15:25:51 | INFO | train_inner | epoch 024:    213 / 1474 loss=0.93, trans_loss=5.219, nll_loss=2.484, w2v_ctc_loss=0.281, task_loss=3.02, contrastive_loss=0.544, total=4251.29, n_correct=2808.74, ppl=5.59, accuracy=66.068, wps=4557.1, ups=1.07, wpb=4251.3, bsz=170.4, num_updates=34100, lr=7.6584e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=26757
2023-07-08 15:26:51 | INFO | train_inner | epoch 024:    313 / 1474 loss=0.922, trans_loss=5.217, nll_loss=2.48, w2v_ctc_loss=0.285, task_loss=3.382, contrastive_loss=0.108, total=4128.18, n_correct=2730.69, ppl=5.58, accuracy=66.148, wps=6896.8, ups=1.67, wpb=4128.2, bsz=152.8, num_updates=34200, lr=7.64719e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=59, gb_free=16.3, wall=26817
2023-07-08 15:27:51 | INFO | train_inner | epoch 024:    413 / 1474 loss=0.941, trans_loss=5.245, nll_loss=2.518, w2v_ctc_loss=0.294, task_loss=3.616, contrastive_loss=0.391, total=4158.92, n_correct=2730.36, ppl=5.73, accuracy=65.651, wps=6843.9, ups=1.65, wpb=4158.9, bsz=149.9, num_updates=34300, lr=7.63604e-05, gnorm=0.239, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=26878
2023-07-08 15:28:52 | INFO | train_inner | epoch 024:    513 / 1474 loss=0.929, trans_loss=5.236, nll_loss=2.504, w2v_ctc_loss=0.29, task_loss=3.512, contrastive_loss=0.242, total=4144.91, n_correct=2729.37, ppl=5.67, accuracy=65.849, wps=6793.3, ups=1.64, wpb=4144.9, bsz=151.6, num_updates=34400, lr=7.62493e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=61, gb_free=17.1, wall=26939
2023-07-08 15:29:52 | INFO | train_inner | epoch 024:    613 / 1474 loss=0.927, trans_loss=5.226, nll_loss=2.493, w2v_ctc_loss=0.286, task_loss=3.477, contrastive_loss=0.169, total=4165.3, n_correct=2746.72, ppl=5.63, accuracy=65.943, wps=6943, ups=1.67, wpb=4165.3, bsz=153.8, num_updates=34500, lr=7.61387e-05, gnorm=0.233, clip=0, loss_scale=64, train_wall=60, gb_free=16, wall=26999
2023-07-08 15:30:53 | INFO | train_inner | epoch 024:    713 / 1474 loss=0.932, trans_loss=5.239, nll_loss=2.508, w2v_ctc_loss=0.291, task_loss=3.565, contrastive_loss=0.194, total=4102.21, n_correct=2694.92, ppl=5.69, accuracy=65.694, wps=6773.1, ups=1.65, wpb=4102.2, bsz=147.5, num_updates=34600, lr=7.60286e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=27059
2023-07-08 15:31:53 | INFO | train_inner | epoch 024:    813 / 1474 loss=0.929, trans_loss=5.232, nll_loss=2.501, w2v_ctc_loss=0.287, task_loss=3.487, contrastive_loss=0.148, total=4110.6, n_correct=2707.48, ppl=5.66, accuracy=65.866, wps=6789.5, ups=1.65, wpb=4110.6, bsz=152.7, num_updates=34700, lr=7.5919e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=27120
2023-07-08 15:32:53 | INFO | train_inner | epoch 024:    913 / 1474 loss=0.929, trans_loss=5.247, nll_loss=2.518, w2v_ctc_loss=0.291, task_loss=3.823, contrastive_loss=0.1, total=4043.03, n_correct=2648.89, ppl=5.73, accuracy=65.517, wps=6782.2, ups=1.68, wpb=4043, bsz=140.5, num_updates=34800, lr=7.58098e-05, gnorm=0.238, clip=0, loss_scale=64, train_wall=59, gb_free=11.7, wall=27179
2023-07-08 15:33:53 | INFO | train_inner | epoch 024:   1013 / 1474 loss=0.924, trans_loss=5.237, nll_loss=2.507, w2v_ctc_loss=0.283, task_loss=3.571, contrastive_loss=0.107, total=4136.81, n_correct=2720.15, ppl=5.68, accuracy=65.755, wps=6849.9, ups=1.66, wpb=4136.8, bsz=149.2, num_updates=34900, lr=7.57011e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=27240
2023-07-08 15:34:54 | INFO | train_inner | epoch 024:   1113 / 1474 loss=0.928, trans_loss=5.229, nll_loss=2.498, w2v_ctc_loss=0.289, task_loss=3.351, contrastive_loss=0.192, total=4135.73, n_correct=2724.01, ppl=5.65, accuracy=65.865, wps=6864.7, ups=1.66, wpb=4135.7, bsz=154.4, num_updates=35000, lr=7.55929e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=27300
tensor(0.0246, device='cuda:0')
tensor(0.0006, device='cuda:0')
2023-07-08 15:35:54 | INFO | train_inner | epoch 024:   1213 / 1474 loss=0.931, trans_loss=5.24, nll_loss=2.513, w2v_ctc_loss=0.286, task_loss=3.426, contrastive_loss=0.172, total=4148.3, n_correct=2727.57, ppl=5.71, accuracy=65.752, wps=6875, ups=1.66, wpb=4148.3, bsz=155.4, num_updates=35100, lr=7.54851e-05, gnorm=0.236, clip=0, loss_scale=128, train_wall=60, gb_free=16.8, wall=27360
2023-07-08 15:36:55 | INFO | train_inner | epoch 024:   1313 / 1474 loss=0.932, trans_loss=5.247, nll_loss=2.52, w2v_ctc_loss=0.291, task_loss=3.677, contrastive_loss=0.118, total=4110.05, n_correct=2698.07, ppl=5.73, accuracy=65.646, wps=6783.7, ups=1.65, wpb=4110.1, bsz=147.1, num_updates=35200, lr=7.53778e-05, gnorm=0.237, clip=0, loss_scale=128, train_wall=60, gb_free=17.4, wall=27421
2023-07-08 15:37:55 | INFO | train_inner | epoch 024:   1413 / 1474 loss=0.932, trans_loss=5.246, nll_loss=2.519, w2v_ctc_loss=0.292, task_loss=3.611, contrastive_loss=0.112, total=4090.91, n_correct=2686.56, ppl=5.73, accuracy=65.671, wps=6792.2, ups=1.66, wpb=4090.9, bsz=146.4, num_updates=35300, lr=7.5271e-05, gnorm=0.236, clip=0, loss_scale=128, train_wall=60, gb_free=16.6, wall=27481
2023-07-08 15:38:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0246, device='cuda:1')
tensor(0.0006, device='cuda:1')
tensor(0.0246, device='cuda:5')
tensor(0.0006, device='cuda:5')
tensor(0.0246, device='cuda:4')
tensor(0.0006, device='cuda:4')
tensor(0.0246, device='cuda:7')
tensor(0.0006, device='cuda:7')
tensor(0.0246, device='cuda:6')
tensor(0.0006, device='cuda:6')
tensor(0.0246, device='cuda:3')
tensor(0.0006, device='cuda:3')
tensor(0.0246, device='cuda:2')
tensor(0.0006, device='cuda:2')
2023-07-08 15:38:57 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 1.459 | trans_loss 5.556 | nll_loss 2.825 | w2v_ctc_loss 0.457 | task_loss 4.625 | contrastive_loss 0.249 | total 4003.4 | n_correct 2494.7 | ppl 7.09 | accuracy 62.315 | uer 16.545 | wer 18.463 | raw_wer 18.463 | bleu 20.34 | wps 2062 | wpb 4003.4 | bsz 141.8 | num_updates 35361 | best_bleu 20.34
2023-07-08 15:38:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35361 updates
2023-07-08 15:38:57 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 15:39:01 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 15:39:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 24 @ 35361 updates, score 20.34) (writing took 8.175622851005755 seconds)
2023-07-08 15:39:05 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-07-08 15:39:05 | INFO | train | epoch 024 | loss 0.93 | trans_loss 5.234 | nll_loss 2.503 | w2v_ctc_loss 0.288 | task_loss 3.455 | contrastive_loss 0.217 | total 4138.65 | n_correct 2724.46 | ppl 5.67 | accuracy 65.83 | wps 6325.4 | ups 1.53 | wpb 4138.6 | bsz 152.8 | num_updates 35361 | lr 7.5206e-05 | gnorm 0.235 | clip 0 | loss_scale 128 | train_wall 883 | gb_free 16.3 | wall 27552
2023-07-08 15:39:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 15:39:06 | INFO | fairseq.trainer | begin training epoch 25
2023-07-08 15:39:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 15:39:37 | INFO | train_inner | epoch 025:     39 / 1474 loss=0.922, trans_loss=5.217, nll_loss=2.482, w2v_ctc_loss=0.284, task_loss=3.299, contrastive_loss=0.131, total=4166.95, n_correct=2755.57, ppl=5.59, accuracy=66.129, wps=4082.9, ups=0.98, wpb=4166.9, bsz=156, num_updates=35400, lr=7.51646e-05, gnorm=0.231, clip=0, loss_scale=128, train_wall=59, gb_free=16.6, wall=27583
2023-07-08 15:40:37 | INFO | train_inner | epoch 025:    139 / 1474 loss=0.915, trans_loss=5.199, nll_loss=2.458, w2v_ctc_loss=0.279, task_loss=3.394, contrastive_loss=0.125, total=4133.64, n_correct=2742.82, ppl=5.49, accuracy=66.354, wps=6893.4, ups=1.67, wpb=4133.6, bsz=153.9, num_updates=35500, lr=7.50587e-05, gnorm=0.23, clip=0, loss_scale=128, train_wall=60, gb_free=16, wall=27643
2023-07-08 15:41:38 | INFO | train_inner | epoch 025:    239 / 1474 loss=0.922, trans_loss=5.208, nll_loss=2.469, w2v_ctc_loss=0.285, task_loss=3.553, contrastive_loss=0.131, total=4114.53, n_correct=2725.6, ppl=5.54, accuracy=66.243, wps=6753.7, ups=1.64, wpb=4114.5, bsz=151.4, num_updates=35600, lr=7.49532e-05, gnorm=0.233, clip=0, loss_scale=128, train_wall=61, gb_free=17.2, wall=27704
2023-07-08 15:42:39 | INFO | train_inner | epoch 025:    339 / 1474 loss=0.929, trans_loss=5.214, nll_loss=2.475, w2v_ctc_loss=0.285, task_loss=3.66, contrastive_loss=0.191, total=4148.7, n_correct=2739.42, ppl=5.56, accuracy=66.031, wps=6748.2, ups=1.63, wpb=4148.7, bsz=147.6, num_updates=35700, lr=7.48481e-05, gnorm=0.237, clip=0, loss_scale=128, train_wall=61, gb_free=16.8, wall=27766
2023-07-08 15:43:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-08 15:43:41 | INFO | train_inner | epoch 025:    440 / 1474 loss=0.931, trans_loss=5.215, nll_loss=2.477, w2v_ctc_loss=0.293, task_loss=3.708, contrastive_loss=0.109, total=4142.33, n_correct=2740.65, ppl=5.57, accuracy=66.162, wps=6734.9, ups=1.63, wpb=4142.3, bsz=144.7, num_updates=35800, lr=7.47435e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=61, gb_free=16, wall=27827
2023-07-08 15:44:41 | INFO | train_inner | epoch 025:    540 / 1474 loss=0.926, trans_loss=5.226, nll_loss=2.493, w2v_ctc_loss=0.287, task_loss=3.371, contrastive_loss=0.134, total=4160.61, n_correct=2746.15, ppl=5.63, accuracy=66.004, wps=6932.9, ups=1.67, wpb=4160.6, bsz=157, num_updates=35900, lr=7.46393e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=60, gb_free=17.7, wall=27887
2023-07-08 15:45:41 | INFO | train_inner | epoch 025:    640 / 1474 loss=0.926, trans_loss=5.21, nll_loss=2.473, w2v_ctc_loss=0.283, task_loss=3.427, contrastive_loss=0.264, total=4153.68, n_correct=2751.81, ppl=5.55, accuracy=66.25, wps=6934.4, ups=1.67, wpb=4153.7, bsz=154.8, num_updates=36000, lr=7.45356e-05, gnorm=0.233, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=27947
2023-07-08 15:45:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 15:46:10 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 1.467 | trans_loss 5.559 | nll_loss 2.833 | w2v_ctc_loss 0.459 | task_loss 4.597 | contrastive_loss 0.258 | total 4003.4 | n_correct 2488.1 | ppl 7.12 | accuracy 62.15 | uer 16.826 | wer 18.53 | raw_wer 18.53 | bleu 19.94 | wps 1829.2 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.34
2023-07-08 15:46:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-07-08 15:46:10 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_25_36000.pt
2023-07-08 15:46:12 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_25_36000.pt
2023-07-08 15:46:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 19.94) (writing took 6.204347079998115 seconds)
2023-07-08 15:47:17 | INFO | train_inner | epoch 025:    740 / 1474 loss=0.927, trans_loss=5.217, nll_loss=2.481, w2v_ctc_loss=0.285, task_loss=3.501, contrastive_loss=0.256, total=4128.34, n_correct=2730.52, ppl=5.58, accuracy=66.141, wps=4301.5, ups=1.04, wpb=4128.3, bsz=150.6, num_updates=36100, lr=7.44323e-05, gnorm=0.238, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=28043
2023-07-08 15:48:17 | INFO | train_inner | epoch 025:    840 / 1474 loss=0.925, trans_loss=5.219, nll_loss=2.484, w2v_ctc_loss=0.284, task_loss=3.175, contrastive_loss=0.153, total=4182.4, n_correct=2764.44, ppl=5.59, accuracy=66.097, wps=6951.3, ups=1.66, wpb=4182.4, bsz=163, num_updates=36200, lr=7.43294e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=60, gb_free=17.8, wall=28103
2023-07-08 15:49:18 | INFO | train_inner | epoch 025:    940 / 1474 loss=0.928, trans_loss=5.221, nll_loss=2.487, w2v_ctc_loss=0.286, task_loss=3.277, contrastive_loss=0.263, total=4155.21, n_correct=2743.5, ppl=5.61, accuracy=66.026, wps=6826.2, ups=1.64, wpb=4155.2, bsz=158.5, num_updates=36300, lr=7.4227e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=60, gb_free=14.4, wall=28164
2023-07-08 15:50:18 | INFO | train_inner | epoch 025:   1040 / 1474 loss=0.938, trans_loss=5.236, nll_loss=2.507, w2v_ctc_loss=0.285, task_loss=3.426, contrastive_loss=0.484, total=4177.7, n_correct=2746.09, ppl=5.68, accuracy=65.732, wps=6902.5, ups=1.65, wpb=4177.7, bsz=154.9, num_updates=36400, lr=7.41249e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=60, gb_free=15.9, wall=28225
2023-07-08 15:51:18 | INFO | train_inner | epoch 025:   1140 / 1474 loss=0.926, trans_loss=5.23, nll_loss=2.499, w2v_ctc_loss=0.285, task_loss=3.728, contrastive_loss=0.101, total=4039.24, n_correct=2661.44, ppl=5.65, accuracy=65.89, wps=6748.6, ups=1.67, wpb=4039.2, bsz=142.6, num_updates=36500, lr=7.40233e-05, gnorm=0.239, clip=0, loss_scale=64, train_wall=59, gb_free=16.6, wall=28285
2023-07-08 15:52:18 | INFO | train_inner | epoch 025:   1240 / 1474 loss=0.928, trans_loss=5.23, nll_loss=2.498, w2v_ctc_loss=0.286, task_loss=3.497, contrastive_loss=0.12, total=4090.59, n_correct=2692.57, ppl=5.65, accuracy=65.824, wps=6881.8, ups=1.68, wpb=4090.6, bsz=147.8, num_updates=36600, lr=7.39221e-05, gnorm=0.238, clip=0, loss_scale=64, train_wall=59, gb_free=17.4, wall=28344
2023-07-08 15:53:18 | INFO | train_inner | epoch 025:   1340 / 1474 loss=0.927, trans_loss=5.22, nll_loss=2.486, w2v_ctc_loss=0.283, task_loss=3.372, contrastive_loss=0.304, total=4164.34, n_correct=2750.4, ppl=5.6, accuracy=66.046, wps=6882.6, ups=1.65, wpb=4164.3, bsz=155.1, num_updates=36700, lr=7.38213e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=28405
2023-07-08 15:54:19 | INFO | train_inner | epoch 025:   1440 / 1474 loss=0.932, trans_loss=5.25, nll_loss=2.524, w2v_ctc_loss=0.289, task_loss=3.594, contrastive_loss=0.206, total=4099.11, n_correct=2687.35, ppl=5.75, accuracy=65.559, wps=6722.4, ups=1.64, wpb=4099.1, bsz=149.7, num_updates=36800, lr=7.3721e-05, gnorm=0.238, clip=0, loss_scale=64, train_wall=61, gb_free=12.6, wall=28465
2023-07-08 15:54:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 15:55:08 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 1.458 | trans_loss 5.551 | nll_loss 2.825 | w2v_ctc_loss 0.449 | task_loss 4.617 | contrastive_loss 0.256 | total 4003.4 | n_correct 2487.5 | ppl 7.08 | accuracy 62.135 | uer 16.643 | wer 18.646 | raw_wer 18.646 | bleu 19.99 | wps 1988.4 | wpb 4003.4 | bsz 141.8 | num_updates 36834 | best_bleu 20.34
2023-07-08 15:55:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36834 updates
2023-07-08 15:55:08 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.9904.pt
2023-07-08 15:55:10 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.9904.pt
2023-07-08 15:55:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.9904.pt (epoch 25 @ 36834 updates, score 19.99) (writing took 5.251806483007385 seconds)
2023-07-08 15:55:13 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-07-08 15:55:13 | INFO | train | epoch 025 | loss 0.927 | trans_loss 5.221 | nll_loss 2.486 | w2v_ctc_loss 0.285 | task_loss 3.459 | contrastive_loss 0.202 | total 4137.25 | n_correct 2731.8 | ppl 5.6 | accuracy 66.029 | wps 6298.3 | ups 1.52 | wpb 4137.2 | bsz 152.6 | num_updates 36834 | lr 7.36869e-05 | gnorm 0.235 | clip 0 | loss_scale 64 | train_wall 885 | gb_free 14.6 | wall 28519
2023-07-08 15:55:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 15:55:13 | INFO | fairseq.trainer | begin training epoch 26
2023-07-08 15:55:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 15:56:01 | INFO | train_inner | epoch 026:     66 / 1474 loss=0.918, trans_loss=5.196, nll_loss=2.454, w2v_ctc_loss=0.279, task_loss=3.248, contrastive_loss=0.176, total=4180.21, n_correct=2777.66, ppl=5.48, accuracy=66.448, wps=4086.3, ups=0.98, wpb=4180.2, bsz=159.2, num_updates=36900, lr=7.3621e-05, gnorm=0.232, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=28568
2023-07-08 15:57:02 | INFO | train_inner | epoch 026:    166 / 1474 loss=0.927, trans_loss=5.188, nll_loss=2.444, w2v_ctc_loss=0.275, task_loss=3.02, contrastive_loss=0.542, total=4270.78, n_correct=2850.38, ppl=5.44, accuracy=66.741, wps=7054.4, ups=1.65, wpb=4270.8, bsz=170.2, num_updates=37000, lr=7.35215e-05, gnorm=0.232, clip=0, loss_scale=64, train_wall=60, gb_free=15.5, wall=28628
2023-07-08 15:58:02 | INFO | train_inner | epoch 026:    266 / 1474 loss=0.925, trans_loss=5.203, nll_loss=2.463, w2v_ctc_loss=0.284, task_loss=3.421, contrastive_loss=0.294, total=4125.04, n_correct=2736.33, ppl=5.51, accuracy=66.335, wps=6861.2, ups=1.66, wpb=4125, bsz=153.6, num_updates=37100, lr=7.34223e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=60, gb_free=15.4, wall=28688
2023-07-08 15:59:02 | INFO | train_inner | epoch 026:    366 / 1474 loss=0.923, trans_loss=5.199, nll_loss=2.458, w2v_ctc_loss=0.281, task_loss=3.31, contrastive_loss=0.21, total=4165.74, n_correct=2762.19, ppl=5.5, accuracy=66.307, wps=6952.2, ups=1.67, wpb=4165.7, bsz=157.3, num_updates=37200, lr=7.33236e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=59, gb_free=17, wall=28748
2023-07-08 16:00:02 | INFO | train_inner | epoch 026:    466 / 1474 loss=0.926, trans_loss=5.196, nll_loss=2.455, w2v_ctc_loss=0.283, task_loss=3.278, contrastive_loss=0.3, total=4170.23, n_correct=2773.4, ppl=5.48, accuracy=66.505, wps=6945.8, ups=1.67, wpb=4170.2, bsz=157.7, num_updates=37300, lr=7.32252e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=60, gb_free=17.9, wall=28808
2023-07-08 16:01:03 | INFO | train_inner | epoch 026:    566 / 1474 loss=0.921, trans_loss=5.21, nll_loss=2.472, w2v_ctc_loss=0.287, task_loss=3.485, contrastive_loss=0.143, total=4155.02, n_correct=2747.53, ppl=5.55, accuracy=66.126, wps=6846.4, ups=1.65, wpb=4155, bsz=151.9, num_updates=37400, lr=7.31272e-05, gnorm=0.238, clip=0, loss_scale=64, train_wall=60, gb_free=17.9, wall=28869
2023-07-08 16:02:03 | INFO | train_inner | epoch 026:    666 / 1474 loss=0.922, trans_loss=5.203, nll_loss=2.463, w2v_ctc_loss=0.28, task_loss=3.521, contrastive_loss=0.114, total=4136.96, n_correct=2743.79, ppl=5.51, accuracy=66.324, wps=6859.3, ups=1.66, wpb=4137, bsz=149.6, num_updates=37500, lr=7.30297e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=60, gb_free=15.5, wall=28929
2023-07-08 16:03:03 | INFO | train_inner | epoch 026:    766 / 1474 loss=0.929, trans_loss=5.221, nll_loss=2.486, w2v_ctc_loss=0.283, task_loss=3.519, contrastive_loss=0.34, total=4086.28, n_correct=2696.94, ppl=5.6, accuracy=66, wps=6773, ups=1.66, wpb=4086.3, bsz=149.2, num_updates=37600, lr=7.29325e-05, gnorm=0.239, clip=0, loss_scale=64, train_wall=60, gb_free=15.3, wall=28990
2023-07-08 16:04:04 | INFO | train_inner | epoch 026:    866 / 1474 loss=0.923, trans_loss=5.211, nll_loss=2.473, w2v_ctc_loss=0.284, task_loss=3.42, contrastive_loss=0.146, total=4183.26, n_correct=2770.07, ppl=5.55, accuracy=66.218, wps=6938.4, ups=1.66, wpb=4183.3, bsz=154.1, num_updates=37700, lr=7.28357e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=60, gb_free=17.5, wall=29050
2023-07-08 16:05:04 | INFO | train_inner | epoch 026:    966 / 1474 loss=0.927, trans_loss=5.221, nll_loss=2.488, w2v_ctc_loss=0.282, task_loss=3.576, contrastive_loss=0.249, total=4137.96, n_correct=2730.86, ppl=5.61, accuracy=65.995, wps=6868.8, ups=1.66, wpb=4138, bsz=149.5, num_updates=37800, lr=7.27393e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=29110
2023-07-08 16:06:04 | INFO | train_inner | epoch 026:   1066 / 1474 loss=0.925, trans_loss=5.217, nll_loss=2.481, w2v_ctc_loss=0.286, task_loss=3.629, contrastive_loss=0.117, total=4120.53, n_correct=2724.47, ppl=5.58, accuracy=66.119, wps=6818.6, ups=1.65, wpb=4120.5, bsz=147.1, num_updates=37900, lr=7.26433e-05, gnorm=0.235, clip=0, loss_scale=128, train_wall=60, gb_free=16.8, wall=29171
2023-07-08 16:07:05 | INFO | train_inner | epoch 026:   1166 / 1474 loss=0.927, trans_loss=5.223, nll_loss=2.49, w2v_ctc_loss=0.286, task_loss=3.617, contrastive_loss=0.194, total=4113.86, n_correct=2714.36, ppl=5.62, accuracy=65.981, wps=6741.1, ups=1.64, wpb=4113.9, bsz=149.2, num_updates=38000, lr=7.25476e-05, gnorm=0.238, clip=0, loss_scale=128, train_wall=61, gb_free=16.8, wall=29232
2023-07-08 16:07:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 16:07:31 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 1.466 | trans_loss 5.561 | nll_loss 2.833 | w2v_ctc_loss 0.474 | task_loss 4.624 | contrastive_loss 0.258 | total 4003.4 | n_correct 2486.7 | ppl 7.12 | accuracy 62.115 | uer 16.813 | wer 18.635 | raw_wer 18.635 | bleu 20.02 | wps 2048.3 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.34
2023-07-08 16:07:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-07-08 16:07:31 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_26_38000.pt
2023-07-08 16:07:33 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_26_38000.pt
2023-07-08 16:07:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 20.02) (writing took 6.256755014008377 seconds)
2023-07-08 16:08:38 | INFO | train_inner | epoch 026:   1266 / 1474 loss=0.929, trans_loss=5.239, nll_loss=2.51, w2v_ctc_loss=0.291, task_loss=3.858, contrastive_loss=0.119, total=3996.19, n_correct=2624.69, ppl=5.7, accuracy=65.68, wps=4300.8, ups=1.08, wpb=3996.2, bsz=139.6, num_updates=38100, lr=7.24524e-05, gnorm=0.244, clip=0, loss_scale=128, train_wall=60, gb_free=17.8, wall=29325
2023-07-08 16:09:39 | INFO | train_inner | epoch 026:   1366 / 1474 loss=0.928, trans_loss=5.221, nll_loss=2.487, w2v_ctc_loss=0.281, task_loss=3.436, contrastive_loss=0.145, total=4159.74, n_correct=2749.92, ppl=5.61, accuracy=66.108, wps=6798.9, ups=1.63, wpb=4159.7, bsz=155.7, num_updates=38200, lr=7.23575e-05, gnorm=0.238, clip=0, loss_scale=128, train_wall=61, gb_free=17.4, wall=29386
2023-07-08 16:10:39 | INFO | train_inner | epoch 026:   1466 / 1474 loss=0.92, trans_loss=5.213, nll_loss=2.477, w2v_ctc_loss=0.279, task_loss=3.28, contrastive_loss=0.136, total=4165.66, n_correct=2757.86, ppl=5.57, accuracy=66.205, wps=6953.4, ups=1.67, wpb=4165.7, bsz=158.7, num_updates=38300, lr=7.22629e-05, gnorm=0.235, clip=0, loss_scale=128, train_wall=59, gb_free=16.7, wall=29446
2023-07-08 16:10:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 16:11:09 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 1.471 | trans_loss 5.555 | nll_loss 2.83 | w2v_ctc_loss 0.475 | task_loss 4.604 | contrastive_loss 0.251 | total 4003.4 | n_correct 2489.6 | ppl 7.11 | accuracy 62.187 | uer 16.866 | wer 18.653 | raw_wer 18.653 | bleu 20 | wps 2218.1 | wpb 4003.4 | bsz 141.8 | num_updates 38308 | best_bleu 20.34
2023-07-08 16:11:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38308 updates
2023-07-08 16:11:09 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.0005.pt
2023-07-08 16:11:11 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.0005.pt
2023-07-08 16:11:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.0005.pt (epoch 26 @ 38308 updates, score 20.0) (writing took 5.157110305997776 seconds)
2023-07-08 16:11:14 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-07-08 16:11:14 | INFO | train | epoch 026 | loss 0.925 | trans_loss 5.21 | nll_loss 2.472 | w2v_ctc_loss 0.283 | task_loss 3.453 | contrastive_loss 0.217 | total 4138.65 | n_correct 2740.57 | ppl 5.55 | accuracy 66.219 | wps 6346.5 | ups 1.53 | wpb 4138.6 | bsz 152.8 | num_updates 38308 | lr 7.22554e-05 | gnorm 0.236 | clip 0 | loss_scale 128 | train_wall 884 | gb_free 16.2 | wall 29481
2023-07-08 16:11:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 16:11:14 | INFO | fairseq.trainer | begin training epoch 27
2023-07-08 16:11:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 16:12:18 | INFO | train_inner | epoch 027:     92 / 1474 loss=0.917, trans_loss=5.167, nll_loss=2.416, w2v_ctc_loss=0.276, task_loss=3.72, contrastive_loss=0.094, total=4054.57, n_correct=2714.27, ppl=5.34, accuracy=66.943, wps=4107.7, ups=1.01, wpb=4054.6, bsz=141.2, num_updates=38400, lr=7.21688e-05, gnorm=0.239, clip=0, loss_scale=128, train_wall=60, gb_free=16.5, wall=29544
2023-07-08 16:13:18 | INFO | train_inner | epoch 027:    192 / 1474 loss=0.913, trans_loss=5.174, nll_loss=2.426, w2v_ctc_loss=0.279, task_loss=3.271, contrastive_loss=0.154, total=4195.2, n_correct=2803.15, ppl=5.37, accuracy=66.818, wps=6956.2, ups=1.66, wpb=4195.2, bsz=161.6, num_updates=38500, lr=7.2075e-05, gnorm=0.232, clip=0, loss_scale=128, train_wall=60, gb_free=17.3, wall=29605
2023-07-08 16:14:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-08 16:14:20 | INFO | train_inner | epoch 027:    293 / 1474 loss=0.916, trans_loss=5.185, nll_loss=2.438, w2v_ctc_loss=0.279, task_loss=3.491, contrastive_loss=0.107, total=4157.22, n_correct=2772.52, ppl=5.42, accuracy=66.692, wps=6768.8, ups=1.63, wpb=4157.2, bsz=151.9, num_updates=38600, lr=7.19816e-05, gnorm=0.232, clip=0, loss_scale=64, train_wall=61, gb_free=17, wall=29666
2023-07-08 16:15:21 | INFO | train_inner | epoch 027:    393 / 1474 loss=0.93, trans_loss=5.199, nll_loss=2.458, w2v_ctc_loss=0.281, task_loss=3.621, contrastive_loss=0.477, total=4075.21, n_correct=2711.04, ppl=5.49, accuracy=66.525, wps=6613.1, ups=1.62, wpb=4075.2, bsz=148, num_updates=38700, lr=7.18885e-05, gnorm=0.237, clip=0, loss_scale=64, train_wall=61, gb_free=17.8, wall=29728
2023-07-08 16:16:22 | INFO | train_inner | epoch 027:    493 / 1474 loss=0.926, trans_loss=5.202, nll_loss=2.464, w2v_ctc_loss=0.28, task_loss=3.154, contrastive_loss=0.347, total=4249.35, n_correct=2819.86, ppl=5.52, accuracy=66.36, wps=6977.8, ups=1.64, wpb=4249.4, bsz=166, num_updates=38800, lr=7.17958e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=60, gb_free=12.4, wall=29789
2023-07-08 16:17:22 | INFO | train_inner | epoch 027:    593 / 1474 loss=0.924, trans_loss=5.196, nll_loss=2.456, w2v_ctc_loss=0.281, task_loss=3.389, contrastive_loss=0.232, total=4133.39, n_correct=2749.34, ppl=5.49, accuracy=66.515, wps=6891.4, ups=1.67, wpb=4133.4, bsz=156, num_updates=38900, lr=7.17035e-05, gnorm=0.24, clip=0, loss_scale=64, train_wall=60, gb_free=12.5, wall=29849
2023-07-08 16:18:23 | INFO | train_inner | epoch 027:    693 / 1474 loss=0.924, trans_loss=5.206, nll_loss=2.468, w2v_ctc_loss=0.283, task_loss=3.446, contrastive_loss=0.192, total=4162.71, n_correct=2758.7, ppl=5.53, accuracy=66.272, wps=6892.5, ups=1.66, wpb=4162.7, bsz=152.7, num_updates=39000, lr=7.16115e-05, gnorm=0.237, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=29909
2023-07-08 16:19:22 | INFO | train_inner | epoch 027:    793 / 1474 loss=0.92, trans_loss=5.198, nll_loss=2.457, w2v_ctc_loss=0.281, task_loss=3.633, contrastive_loss=0.12, total=4103.81, n_correct=2724.55, ppl=5.49, accuracy=66.391, wps=6899.9, ups=1.68, wpb=4103.8, bsz=147.1, num_updates=39100, lr=7.15199e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=59, gb_free=16.7, wall=29969
2023-07-08 16:20:22 | INFO | train_inner | epoch 027:    893 / 1474 loss=0.923, trans_loss=5.201, nll_loss=2.46, w2v_ctc_loss=0.277, task_loss=3.599, contrastive_loss=0.101, total=4101.56, n_correct=2719.98, ppl=5.5, accuracy=66.316, wps=6826.8, ups=1.66, wpb=4101.6, bsz=146.1, num_updates=39200, lr=7.14286e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=60, gb_free=17.8, wall=30029
2023-07-08 16:21:24 | INFO | train_inner | epoch 027:    993 / 1474 loss=0.926, trans_loss=5.209, nll_loss=2.473, w2v_ctc_loss=0.281, task_loss=3.337, contrastive_loss=0.476, total=4199.56, n_correct=2780.9, ppl=5.55, accuracy=66.219, wps=6861, ups=1.63, wpb=4199.6, bsz=158.4, num_updates=39300, lr=7.13376e-05, gnorm=0.237, clip=0, loss_scale=64, train_wall=61, gb_free=12.1, wall=30090
2023-07-08 16:22:24 | INFO | train_inner | epoch 027:   1093 / 1474 loss=0.922, trans_loss=5.199, nll_loss=2.459, w2v_ctc_loss=0.282, task_loss=3.47, contrastive_loss=0.142, total=4150.97, n_correct=2755.7, ppl=5.5, accuracy=66.387, wps=6908.8, ups=1.66, wpb=4151, bsz=152.5, num_updates=39400, lr=7.1247e-05, gnorm=0.24, clip=0, loss_scale=64, train_wall=60, gb_free=12.4, wall=30150
2023-07-08 16:23:24 | INFO | train_inner | epoch 027:   1193 / 1474 loss=0.922, trans_loss=5.207, nll_loss=2.469, w2v_ctc_loss=0.282, task_loss=3.606, contrastive_loss=0.147, total=4103.06, n_correct=2716.88, ppl=5.54, accuracy=66.216, wps=6755.8, ups=1.65, wpb=4103.1, bsz=148.8, num_updates=39500, lr=7.11568e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=30211
2023-07-08 16:24:25 | INFO | train_inner | epoch 027:   1293 / 1474 loss=0.924, trans_loss=5.219, nll_loss=2.485, w2v_ctc_loss=0.282, task_loss=3.701, contrastive_loss=0.256, total=4062.52, n_correct=2682.17, ppl=5.6, accuracy=66.022, wps=6725.6, ups=1.66, wpb=4062.5, bsz=146.1, num_updates=39600, lr=7.10669e-05, gnorm=0.24, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=30271
2023-07-08 16:25:24 | INFO | train_inner | epoch 027:   1393 / 1474 loss=0.925, trans_loss=5.21, nll_loss=2.473, w2v_ctc_loss=0.282, task_loss=3.263, contrastive_loss=0.218, total=4152, n_correct=2748.88, ppl=5.55, accuracy=66.206, wps=6986.6, ups=1.68, wpb=4152, bsz=156.2, num_updates=39700, lr=7.09773e-05, gnorm=0.237, clip=0, loss_scale=64, train_wall=59, gb_free=16.8, wall=30331
2023-07-08 16:26:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 16:26:40 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 1.472 | trans_loss 5.563 | nll_loss 2.838 | w2v_ctc_loss 0.48 | task_loss 4.607 | contrastive_loss 0.243 | total 4003.4 | n_correct 2482.3 | ppl 7.15 | accuracy 62.005 | uer 16.986 | wer 18.914 | raw_wer 18.914 | bleu 19.97 | wps 1896.2 | wpb 4003.4 | bsz 141.8 | num_updates 39781 | best_bleu 20.34
2023-07-08 16:26:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39781 updates
2023-07-08 16:26:40 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.9700.pt
2023-07-08 16:26:42 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.9700.pt
2023-07-08 16:26:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.9700.pt (epoch 27 @ 39781 updates, score 19.97) (writing took 5.29336648399476 seconds)
2023-07-08 16:26:45 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-07-08 16:26:45 | INFO | train | epoch 027 | loss 0.922 | trans_loss 5.198 | nll_loss 2.457 | w2v_ctc_loss 0.28 | task_loss 3.455 | contrastive_loss 0.216 | total 4138.14 | n_correct 2748.83 | ppl 5.49 | accuracy 66.427 | wps 6545.9 | ups 1.58 | wpb 4138.1 | bsz 152.7 | num_updates 39781 | lr 7.0905e-05 | gnorm 0.237 | clip 0 | loss_scale 64 | train_wall 884 | gb_free 17.9 | wall 30412
2023-07-08 16:26:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 16:26:46 | INFO | fairseq.trainer | begin training epoch 28
2023-07-08 16:26:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 16:27:05 | INFO | train_inner | epoch 028:     19 / 1474 loss=0.917, trans_loss=5.19, nll_loss=2.447, w2v_ctc_loss=0.274, task_loss=3.335, contrastive_loss=0.119, total=4108.43, n_correct=2734.98, ppl=5.45, accuracy=66.57, wps=4082, ups=0.99, wpb=4108.4, bsz=152.6, num_updates=39800, lr=7.08881e-05, gnorm=0.238, clip=0, loss_scale=64, train_wall=59, gb_free=16.5, wall=30431
2023-07-08 16:28:05 | INFO | train_inner | epoch 028:    119 / 1474 loss=0.919, trans_loss=5.168, nll_loss=2.417, w2v_ctc_loss=0.279, task_loss=3.601, contrastive_loss=0.114, total=4113.41, n_correct=2753.37, ppl=5.34, accuracy=66.936, wps=6814.4, ups=1.66, wpb=4113.4, bsz=147, num_updates=39900, lr=7.07992e-05, gnorm=0.238, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=30492
2023-07-08 16:29:05 | INFO | train_inner | epoch 028:    219 / 1474 loss=0.912, trans_loss=5.17, nll_loss=2.42, w2v_ctc_loss=0.274, task_loss=3.275, contrastive_loss=0.128, total=4191.56, n_correct=2802.69, ppl=5.35, accuracy=66.865, wps=6958.2, ups=1.66, wpb=4191.6, bsz=157.6, num_updates=40000, lr=7.07107e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=60, gb_free=15.4, wall=30552
2023-07-08 16:29:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 16:29:30 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 1.467 | trans_loss 5.556 | nll_loss 2.829 | w2v_ctc_loss 0.473 | task_loss 4.627 | contrastive_loss 0.242 | total 4003.4 | n_correct 2493.4 | ppl 7.1 | accuracy 62.282 | uer 16.818 | wer 18.653 | raw_wer 18.653 | bleu 20.06 | wps 2186.4 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.34
2023-07-08 16:29:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-07-08 16:29:30 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_28_40000.pt
2023-07-08 16:29:33 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_28_40000.pt
2023-07-08 16:29:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 20.06) (writing took 6.630860467994353 seconds)
tensor(0.0246, device='cuda:0')
tensor(0.0006, device='cuda:0')
2023-07-08 16:29:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-08 16:30:38 | INFO | train_inner | epoch 028:    320 / 1474 loss=0.927, trans_loss=5.175, nll_loss=2.426, w2v_ctc_loss=0.274, task_loss=3.504, contrastive_loss=0.575, total=4127.08, n_correct=2758.69, ppl=5.38, accuracy=66.844, wps=4436.5, ups=1.07, wpb=4127.1, bsz=154.4, num_updates=40100, lr=7.06225e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=61, gb_free=13.6, wall=30645
2023-07-08 16:31:39 | INFO | train_inner | epoch 028:    420 / 1474 loss=0.915, trans_loss=5.184, nll_loss=2.438, w2v_ctc_loss=0.278, task_loss=3.563, contrastive_loss=0.106, total=4089.84, n_correct=2727.01, ppl=5.42, accuracy=66.678, wps=6809.4, ups=1.66, wpb=4089.8, bsz=147.8, num_updates=40200, lr=7.05346e-05, gnorm=0.237, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=30705
2023-07-08 16:32:38 | INFO | train_inner | epoch 028:    520 / 1474 loss=0.918, trans_loss=5.18, nll_loss=2.434, w2v_ctc_loss=0.279, task_loss=3.58, contrastive_loss=0.128, total=4098.92, n_correct=2733.34, ppl=5.4, accuracy=66.684, wps=6849.2, ups=1.67, wpb=4098.9, bsz=147.8, num_updates=40300, lr=7.0447e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=59, gb_free=17.1, wall=30765
2023-07-08 16:33:39 | INFO | train_inner | epoch 028:    620 / 1474 loss=0.916, trans_loss=5.185, nll_loss=2.44, w2v_ctc_loss=0.275, task_loss=3.482, contrastive_loss=0.129, total=4180.1, n_correct=2786.28, ppl=5.43, accuracy=66.656, wps=6880.6, ups=1.65, wpb=4180.1, bsz=152.7, num_updates=40400, lr=7.03598e-05, gnorm=0.234, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=30826
2023-07-08 16:34:39 | INFO | train_inner | epoch 028:    720 / 1474 loss=0.924, trans_loss=5.189, nll_loss=2.447, w2v_ctc_loss=0.276, task_loss=3.12, contrastive_loss=0.352, total=4191.62, n_correct=2791.7, ppl=5.45, accuracy=66.602, wps=6981.2, ups=1.67, wpb=4191.6, bsz=164.6, num_updates=40500, lr=7.02728e-05, gnorm=0.234, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=30886
2023-07-08 16:35:39 | INFO | train_inner | epoch 028:    820 / 1474 loss=0.917, trans_loss=5.183, nll_loss=2.437, w2v_ctc_loss=0.275, task_loss=3.411, contrastive_loss=0.111, total=4088.91, n_correct=2731, ppl=5.42, accuracy=66.79, wps=6797.2, ups=1.66, wpb=4088.9, bsz=152.2, num_updates=40600, lr=7.01862e-05, gnorm=0.237, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=30946
2023-07-08 16:36:40 | INFO | train_inner | epoch 028:    920 / 1474 loss=0.921, trans_loss=5.2, nll_loss=2.459, w2v_ctc_loss=0.28, task_loss=3.58, contrastive_loss=0.236, total=4117.01, n_correct=2730.93, ppl=5.5, accuracy=66.333, wps=6768.3, ups=1.64, wpb=4117, bsz=149.8, num_updates=40700, lr=7.01e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=60, gb_free=15.5, wall=31007
2023-07-08 16:37:41 | INFO | train_inner | epoch 028:   1020 / 1474 loss=0.925, trans_loss=5.2, nll_loss=2.46, w2v_ctc_loss=0.282, task_loss=3.363, contrastive_loss=0.336, total=4182.85, n_correct=2774.67, ppl=5.5, accuracy=66.334, wps=6923.9, ups=1.66, wpb=4182.9, bsz=156, num_updates=40800, lr=7.0014e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=31067
2023-07-08 16:38:41 | INFO | train_inner | epoch 028:   1120 / 1474 loss=0.917, trans_loss=5.181, nll_loss=2.438, w2v_ctc_loss=0.276, task_loss=3.311, contrastive_loss=0.154, total=4220.16, n_correct=2811.53, ppl=5.42, accuracy=66.621, wps=6996.4, ups=1.66, wpb=4220.2, bsz=160.5, num_updates=40900, lr=6.99284e-05, gnorm=0.234, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=31127
2023-07-08 16:39:41 | INFO | train_inner | epoch 028:   1220 / 1474 loss=0.916, trans_loss=5.193, nll_loss=2.452, w2v_ctc_loss=0.276, task_loss=3.438, contrastive_loss=0.126, total=4092.46, n_correct=2720.95, ppl=5.47, accuracy=66.487, wps=6822.8, ups=1.67, wpb=4092.5, bsz=151.5, num_updates=41000, lr=6.9843e-05, gnorm=0.237, clip=0, loss_scale=32, train_wall=60, gb_free=17.8, wall=31187
2023-07-08 16:40:41 | INFO | train_inner | epoch 028:   1320 / 1474 loss=0.926, trans_loss=5.206, nll_loss=2.467, w2v_ctc_loss=0.284, task_loss=3.776, contrastive_loss=0.16, total=4084.55, n_correct=2707.7, ppl=5.53, accuracy=66.291, wps=6755, ups=1.65, wpb=4084.6, bsz=142.6, num_updates=41100, lr=6.9758e-05, gnorm=0.24, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=31248
2023-07-08 16:41:42 | INFO | train_inner | epoch 028:   1420 / 1474 loss=0.924, trans_loss=5.202, nll_loss=2.462, w2v_ctc_loss=0.28, task_loss=3.602, contrastive_loss=0.203, total=4154.09, n_correct=2752.51, ppl=5.51, accuracy=66.26, wps=6862, ups=1.65, wpb=4154.1, bsz=149.7, num_updates=41200, lr=6.96733e-05, gnorm=0.233, clip=0, loss_scale=32, train_wall=60, gb_free=16.2, wall=31308
2023-07-08 16:42:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0246, device='cuda:7')
tensor(0.0006, device='cuda:7')
tensor(0.0246, device='cuda:4')
tensor(0.0006, device='cuda:4')
tensor(0.0246, device='cuda:6')
tensor(0.0006, device='cuda:6')
tensor(0.0246, device='cuda:3')
tensor(0.0006, device='cuda:3')
tensor(0.0246, device='cuda:5')
tensor(0.0006, device='cuda:5')
tensor(0.0246, device='cuda:2')
tensor(0.0006, device='cuda:2')
tensor(0.0246, device='cuda:1')
tensor(0.0006, device='cuda:1')
2023-07-08 16:42:41 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 1.465 | trans_loss 5.554 | nll_loss 2.826 | w2v_ctc_loss 0.475 | task_loss 4.626 | contrastive_loss 0.255 | total 4003.4 | n_correct 2497.9 | ppl 7.09 | accuracy 62.394 | uer 16.741 | wer 18.497 | raw_wer 18.497 | bleu 20.25 | wps 1923.3 | wpb 4003.4 | bsz 141.8 | num_updates 41254 | best_bleu 20.34
2023-07-08 16:42:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41254 updates
2023-07-08 16:42:41 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.2507.pt
2023-07-08 16:42:43 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.2507.pt
2023-07-08 16:42:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.2507.pt (epoch 28 @ 41254 updates, score 20.25) (writing took 5.366824751006789 seconds)
2023-07-08 16:42:47 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-07-08 16:42:47 | INFO | train | epoch 028 | loss 0.92 | trans_loss 5.186 | nll_loss 2.442 | w2v_ctc_loss 0.278 | task_loss 3.457 | contrastive_loss 0.202 | total 4137.55 | n_correct 2755.77 | ppl 5.43 | accuracy 66.604 | wps 6340.7 | ups 1.53 | wpb 4137.6 | bsz 152.6 | num_updates 41254 | lr 6.96277e-05 | gnorm 0.236 | clip 0 | loss_scale 32 | train_wall 883 | gb_free 16.7 | wall 31373
2023-07-08 16:42:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 16:42:47 | INFO | fairseq.trainer | begin training epoch 29
2023-07-08 16:42:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 16:43:23 | INFO | train_inner | epoch 029:     46 / 1474 loss=0.915, trans_loss=5.168, nll_loss=2.419, w2v_ctc_loss=0.277, task_loss=3.302, contrastive_loss=0.152, total=4169.12, n_correct=2788.15, ppl=5.35, accuracy=66.876, wps=4141.9, ups=0.99, wpb=4169.1, bsz=158.2, num_updates=41300, lr=6.95889e-05, gnorm=0.233, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=31409
2023-07-08 16:44:23 | INFO | train_inner | epoch 029:    146 / 1474 loss=0.919, trans_loss=5.169, nll_loss=2.419, w2v_ctc_loss=0.276, task_loss=3.437, contrastive_loss=0.186, total=4105.72, n_correct=2748, ppl=5.35, accuracy=66.931, wps=6824.3, ups=1.66, wpb=4105.7, bsz=152, num_updates=41400, lr=6.95048e-05, gnorm=0.24, clip=0, loss_scale=32, train_wall=60, gb_free=16.2, wall=31469
2023-07-08 16:45:24 | INFO | train_inner | epoch 029:    246 / 1474 loss=0.915, trans_loss=5.163, nll_loss=2.412, w2v_ctc_loss=0.271, task_loss=3.163, contrastive_loss=0.355, total=4199.67, n_correct=2816.64, ppl=5.32, accuracy=67.068, wps=6908.7, ups=1.65, wpb=4199.7, bsz=165.3, num_updates=41500, lr=6.9421e-05, gnorm=0.234, clip=0, loss_scale=32, train_wall=60, gb_free=15.8, wall=31530
2023-07-08 16:46:24 | INFO | train_inner | epoch 029:    346 / 1474 loss=0.921, trans_loss=5.183, nll_loss=2.438, w2v_ctc_loss=0.282, task_loss=3.694, contrastive_loss=0.117, total=4095.17, n_correct=2730.57, ppl=5.42, accuracy=66.678, wps=6732.2, ups=1.64, wpb=4095.2, bsz=145.6, num_updates=41600, lr=6.93375e-05, gnorm=0.241, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=31591
2023-07-08 16:47:25 | INFO | train_inner | epoch 029:    446 / 1474 loss=0.907, trans_loss=5.152, nll_loss=2.396, w2v_ctc_loss=0.271, task_loss=3.337, contrastive_loss=0.106, total=4157.44, n_correct=2792.88, ppl=5.26, accuracy=67.178, wps=6883.5, ups=1.66, wpb=4157.4, bsz=153.9, num_updates=41700, lr=6.92543e-05, gnorm=0.234, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=31651
2023-07-08 16:48:25 | INFO | train_inner | epoch 029:    546 / 1474 loss=0.925, trans_loss=5.193, nll_loss=2.45, w2v_ctc_loss=0.28, task_loss=3.671, contrastive_loss=0.3, total=4150.87, n_correct=2760.66, ppl=5.46, accuracy=66.508, wps=6848.7, ups=1.65, wpb=4150.9, bsz=147.5, num_updates=41800, lr=6.91714e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=31712
2023-07-08 16:49:25 | INFO | train_inner | epoch 029:    646 / 1474 loss=0.916, trans_loss=5.171, nll_loss=2.424, w2v_ctc_loss=0.274, task_loss=3.267, contrastive_loss=0.437, total=4143.02, n_correct=2772.8, ppl=5.37, accuracy=66.927, wps=6894, ups=1.66, wpb=4143, bsz=159.3, num_updates=41900, lr=6.90889e-05, gnorm=0.237, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=31772
2023-07-08 16:50:26 | INFO | train_inner | epoch 029:    746 / 1474 loss=0.916, trans_loss=5.171, nll_loss=2.422, w2v_ctc_loss=0.273, task_loss=3.184, contrastive_loss=0.27, total=4249.79, n_correct=2840.98, ppl=5.36, accuracy=66.85, wps=7005, ups=1.65, wpb=4249.8, bsz=165, num_updates=42000, lr=6.90066e-05, gnorm=0.234, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=31833
2023-07-08 16:50:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 16:50:51 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 1.476 | trans_loss 5.566 | nll_loss 2.84 | w2v_ctc_loss 0.494 | task_loss 4.623 | contrastive_loss 0.252 | total 4003.4 | n_correct 2488.4 | ppl 7.16 | accuracy 62.157 | uer 16.736 | wer 18.459 | raw_wer 18.459 | bleu 19.92 | wps 2112.4 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.34
2023-07-08 16:50:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-07-08 16:50:51 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_29_42000.pt
2023-07-08 16:50:53 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_29_42000.pt
2023-07-08 16:50:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 19.92) (writing took 5.166713245009305 seconds)
2023-07-08 16:51:56 | INFO | train_inner | epoch 029:    846 / 1474 loss=0.919, trans_loss=5.193, nll_loss=2.45, w2v_ctc_loss=0.277, task_loss=3.838, contrastive_loss=0.109, total=4027.19, n_correct=2675.28, ppl=5.46, accuracy=66.43, wps=4463.6, ups=1.11, wpb=4027.2, bsz=140.3, num_updates=42100, lr=6.89246e-05, gnorm=0.241, clip=0, loss_scale=64, train_wall=59, gb_free=17.4, wall=31923
2023-07-08 16:52:56 | INFO | train_inner | epoch 029:    946 / 1474 loss=0.917, trans_loss=5.185, nll_loss=2.441, w2v_ctc_loss=0.278, task_loss=3.531, contrastive_loss=0.124, total=4082.14, n_correct=2719.58, ppl=5.43, accuracy=66.621, wps=6814.7, ups=1.67, wpb=4082.1, bsz=148.2, num_updates=42200, lr=6.88428e-05, gnorm=0.237, clip=0, loss_scale=64, train_wall=59, gb_free=15.6, wall=31983
2023-07-08 16:53:57 | INFO | train_inner | epoch 029:   1046 / 1474 loss=0.92, trans_loss=5.181, nll_loss=2.436, w2v_ctc_loss=0.275, task_loss=3.447, contrastive_loss=0.274, total=4148.18, n_correct=2763.89, ppl=5.41, accuracy=66.629, wps=6886, ups=1.66, wpb=4148.2, bsz=154.1, num_updates=42300, lr=6.87614e-05, gnorm=0.238, clip=0, loss_scale=64, train_wall=60, gb_free=16.1, wall=32043
2023-07-08 16:54:56 | INFO | train_inner | epoch 029:   1146 / 1474 loss=0.915, trans_loss=5.191, nll_loss=2.448, w2v_ctc_loss=0.278, task_loss=3.787, contrastive_loss=0.101, total=4063.95, n_correct=2702.55, ppl=5.46, accuracy=66.501, wps=6782.9, ups=1.67, wpb=4064, bsz=141.5, num_updates=42400, lr=6.86803e-05, gnorm=0.239, clip=0, loss_scale=64, train_wall=60, gb_free=13.6, wall=32103
2023-07-08 16:55:57 | INFO | train_inner | epoch 029:   1246 / 1474 loss=0.918, trans_loss=5.192, nll_loss=2.45, w2v_ctc_loss=0.279, task_loss=3.512, contrastive_loss=0.114, total=4158.81, n_correct=2766.12, ppl=5.47, accuracy=66.512, wps=6856.5, ups=1.65, wpb=4158.8, bsz=150.6, num_updates=42500, lr=6.85994e-05, gnorm=0.237, clip=0, loss_scale=64, train_wall=60, gb_free=15.9, wall=32163
2023-07-08 16:56:57 | INFO | train_inner | epoch 029:   1346 / 1474 loss=0.919, trans_loss=5.179, nll_loss=2.434, w2v_ctc_loss=0.275, task_loss=3.401, contrastive_loss=0.245, total=4166.34, n_correct=2781.13, ppl=5.4, accuracy=66.752, wps=6905.5, ups=1.66, wpb=4166.3, bsz=155.3, num_updates=42600, lr=6.85189e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=60, gb_free=17.9, wall=32224
2023-07-08 16:57:57 | INFO | train_inner | epoch 029:   1446 / 1474 loss=0.923, trans_loss=5.181, nll_loss=2.438, w2v_ctc_loss=0.276, task_loss=3.39, contrastive_loss=0.306, total=4162.2, n_correct=2773.51, ppl=5.42, accuracy=66.636, wps=6973.8, ups=1.68, wpb=4162.2, bsz=155.8, num_updates=42700, lr=6.84386e-05, gnorm=0.238, clip=0, loss_scale=64, train_wall=59, gb_free=17.5, wall=32284
2023-07-08 16:58:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 16:58:41 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 1.463 | trans_loss 5.558 | nll_loss 2.829 | w2v_ctc_loss 0.47 | task_loss 4.645 | contrastive_loss 0.251 | total 4003.4 | n_correct 2496.7 | ppl 7.1 | accuracy 62.364 | uer 16.81 | wer 18.698 | raw_wer 18.698 | bleu 19.89 | wps 1862.6 | wpb 4003.4 | bsz 141.8 | num_updates 42728 | best_bleu 20.34
2023-07-08 16:58:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42728 updates
2023-07-08 16:58:41 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-08 16:58:45 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-08 16:58:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt (epoch 29 @ 42728 updates, score 19.89) (writing took 4.189966995007126 seconds)
2023-07-08 16:58:45 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-07-08 16:58:45 | INFO | train | epoch 029 | loss 0.917 | trans_loss 5.178 | nll_loss 2.431 | w2v_ctc_loss 0.276 | task_loss 3.455 | contrastive_loss 0.217 | total 4138.65 | n_correct 2762.59 | ppl 5.39 | accuracy 66.751 | wps 6363.4 | ups 1.54 | wpb 4138.6 | bsz 152.8 | num_updates 42728 | lr 6.84162e-05 | gnorm 0.237 | clip 0 | loss_scale 64 | train_wall 883 | gb_free 16.4 | wall 32332
2023-07-08 16:58:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 16:58:46 | INFO | fairseq.trainer | begin training epoch 30
2023-07-08 16:58:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 16:59:38 | INFO | train_inner | epoch 030:     72 / 1474 loss=0.912, trans_loss=5.157, nll_loss=2.404, w2v_ctc_loss=0.268, task_loss=3.271, contrastive_loss=0.333, total=4182.65, n_correct=2808.38, ppl=5.29, accuracy=67.144, wps=4154.8, ups=0.99, wpb=4182.6, bsz=160.2, num_updates=42800, lr=6.83586e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=60, gb_free=13.8, wall=32384
2023-07-08 17:00:38 | INFO | train_inner | epoch 030:    172 / 1474 loss=0.909, trans_loss=5.14, nll_loss=2.382, w2v_ctc_loss=0.272, task_loss=3.246, contrastive_loss=0.197, total=4203.05, n_correct=2834.4, ppl=5.21, accuracy=67.437, wps=6965.5, ups=1.66, wpb=4203.1, bsz=159.2, num_updates=42900, lr=6.82789e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=60, gb_free=17.5, wall=32445
2023-07-08 17:01:38 | INFO | train_inner | epoch 030:    272 / 1474 loss=0.911, trans_loss=5.155, nll_loss=2.4, w2v_ctc_loss=0.276, task_loss=3.559, contrastive_loss=0.105, total=4116.93, n_correct=2765.78, ppl=5.28, accuracy=67.181, wps=6840.7, ups=1.66, wpb=4116.9, bsz=147.6, num_updates=43000, lr=6.81994e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=32505
2023-07-08 17:02:39 | INFO | train_inner | epoch 030:    372 / 1474 loss=0.911, trans_loss=5.148, nll_loss=2.391, w2v_ctc_loss=0.271, task_loss=3.472, contrastive_loss=0.116, total=4173.13, n_correct=2808.69, ppl=5.24, accuracy=67.304, wps=6870.1, ups=1.65, wpb=4173.1, bsz=152.8, num_updates=43100, lr=6.81203e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=60, gb_free=12.2, wall=32565
2023-07-08 17:03:38 | INFO | train_inner | epoch 030:    472 / 1474 loss=0.911, trans_loss=5.158, nll_loss=2.406, w2v_ctc_loss=0.271, task_loss=3.294, contrastive_loss=0.239, total=4135.2, n_correct=2775.46, ppl=5.3, accuracy=67.118, wps=6960.2, ups=1.68, wpb=4135.2, bsz=157.4, num_updates=43200, lr=6.80414e-05, gnorm=0.236, clip=0, loss_scale=64, train_wall=59, gb_free=17, wall=32625
2023-07-08 17:04:38 | INFO | train_inner | epoch 030:    572 / 1474 loss=0.911, trans_loss=5.161, nll_loss=2.41, w2v_ctc_loss=0.27, task_loss=3.371, contrastive_loss=0.166, total=4168.65, n_correct=2798.31, ppl=5.31, accuracy=67.127, wps=6954.9, ups=1.67, wpb=4168.6, bsz=156.1, num_updates=43300, lr=6.79628e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=60, gb_free=16.1, wall=32685
2023-07-08 17:05:40 | INFO | train_inner | epoch 030:    672 / 1474 loss=0.915, trans_loss=5.162, nll_loss=2.412, w2v_ctc_loss=0.275, task_loss=3.412, contrastive_loss=0.188, total=4183.65, n_correct=2801.54, ppl=5.32, accuracy=66.964, wps=6817.7, ups=1.63, wpb=4183.6, bsz=157.3, num_updates=43400, lr=6.78844e-05, gnorm=0.238, clip=0, loss_scale=64, train_wall=61, gb_free=17, wall=32746
2023-07-08 17:06:40 | INFO | train_inner | epoch 030:    772 / 1474 loss=0.924, trans_loss=5.184, nll_loss=2.439, w2v_ctc_loss=0.279, task_loss=3.524, contrastive_loss=0.353, total=4106.9, n_correct=2739.83, ppl=5.42, accuracy=66.713, wps=6763.6, ups=1.65, wpb=4106.9, bsz=151.5, num_updates=43500, lr=6.78064e-05, gnorm=0.239, clip=0, loss_scale=64, train_wall=60, gb_free=12.3, wall=32807
2023-07-08 17:07:41 | INFO | train_inner | epoch 030:    872 / 1474 loss=0.916, trans_loss=5.177, nll_loss=2.43, w2v_ctc_loss=0.275, task_loss=3.616, contrastive_loss=0.12, total=4089.18, n_correct=2732, ppl=5.39, accuracy=66.81, wps=6775, ups=1.66, wpb=4089.2, bsz=145.7, num_updates=43600, lr=6.77285e-05, gnorm=0.241, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=32867
2023-07-08 17:08:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-08 17:08:42 | INFO | train_inner | epoch 030:    973 / 1474 loss=0.92, trans_loss=5.179, nll_loss=2.433, w2v_ctc_loss=0.28, task_loss=3.51, contrastive_loss=0.16, total=4142.17, n_correct=2763.41, ppl=5.4, accuracy=66.714, wps=6795.3, ups=1.64, wpb=4142.2, bsz=151.9, num_updates=43700, lr=6.7651e-05, gnorm=0.235, clip=0, loss_scale=32, train_wall=61, gb_free=16.8, wall=32928
2023-07-08 17:09:43 | INFO | train_inner | epoch 030:   1073 / 1474 loss=0.921, trans_loss=5.184, nll_loss=2.438, w2v_ctc_loss=0.276, task_loss=3.868, contrastive_loss=0.293, total=4101.17, n_correct=2731.84, ppl=5.42, accuracy=66.611, wps=6735.4, ups=1.64, wpb=4101.2, bsz=141.2, num_updates=43800, lr=6.75737e-05, gnorm=0.24, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=32989
2023-07-08 17:10:43 | INFO | train_inner | epoch 030:   1173 / 1474 loss=0.916, trans_loss=5.169, nll_loss=2.42, w2v_ctc_loss=0.272, task_loss=3.332, contrastive_loss=0.259, total=4168.36, n_correct=2788.67, ppl=5.35, accuracy=66.901, wps=6922.4, ups=1.66, wpb=4168.4, bsz=157, num_updates=43900, lr=6.74967e-05, gnorm=0.237, clip=0, loss_scale=32, train_wall=60, gb_free=16.2, wall=33049
2023-07-08 17:11:43 | INFO | train_inner | epoch 030:   1273 / 1474 loss=0.92, trans_loss=5.183, nll_loss=2.438, w2v_ctc_loss=0.279, task_loss=3.824, contrastive_loss=0.123, total=4036.17, n_correct=2691.49, ppl=5.42, accuracy=66.684, wps=6664.6, ups=1.65, wpb=4036.2, bsz=142.1, num_updates=44000, lr=6.742e-05, gnorm=0.244, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=33110
2023-07-08 17:11:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 17:12:09 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 1.456 | trans_loss 5.554 | nll_loss 2.823 | w2v_ctc_loss 0.467 | task_loss 4.66 | contrastive_loss 0.25 | total 4003.4 | n_correct 2493.6 | ppl 7.08 | accuracy 62.287 | uer 16.638 | wer 18.426 | raw_wer 18.426 | bleu 20.36 | wps 2057.4 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.36
2023-07-08 17:12:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-07-08 17:12:09 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_30_44000.pt
2023-07-08 17:12:11 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_30_44000.pt
2023-07-08 17:12:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 20.36) (writing took 9.192997609992744 seconds)
2023-07-08 17:13:19 | INFO | train_inner | epoch 030:   1373 / 1474 loss=0.905, trans_loss=5.165, nll_loss=2.418, w2v_ctc_loss=0.268, task_loss=3.259, contrastive_loss=0.146, total=4165.07, n_correct=2788.21, ppl=5.34, accuracy=66.943, wps=4376.2, ups=1.05, wpb=4165.1, bsz=160.8, num_updates=44100, lr=6.73435e-05, gnorm=0.235, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=33205
2023-07-08 17:14:18 | INFO | train_inner | epoch 030:   1473 / 1474 loss=0.918, trans_loss=5.173, nll_loss=2.427, w2v_ctc_loss=0.27, task_loss=3.261, contrastive_loss=0.439, total=4141.76, n_correct=2769.53, ppl=5.38, accuracy=66.868, wps=6925.7, ups=1.67, wpb=4141.8, bsz=157.2, num_updates=44200, lr=6.72673e-05, gnorm=0.235, clip=0, loss_scale=32, train_wall=59, gb_free=16.6, wall=33265
2023-07-08 17:14:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 17:14:46 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 1.458 | trans_loss 5.56 | nll_loss 2.833 | w2v_ctc_loss 0.461 | task_loss 4.648 | contrastive_loss 0.258 | total 4003.4 | n_correct 2494.4 | ppl 7.13 | accuracy 62.307 | uer 16.649 | wer 18.616 | raw_wer 18.616 | bleu 20.19 | wps 1903.3 | wpb 4003.4 | bsz 141.8 | num_updates 44201 | best_bleu 20.36
2023-07-08 17:14:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44201 updates
2023-07-08 17:14:46 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.1903.pt
2023-07-08 17:14:48 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.1903.pt
2023-07-08 17:14:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.1903.pt (epoch 30 @ 44201 updates, score 20.19) (writing took 5.174873722004122 seconds)
2023-07-08 17:14:51 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-07-08 17:14:51 | INFO | train | epoch 030 | loss 0.915 | trans_loss 5.166 | nll_loss 2.416 | w2v_ctc_loss 0.273 | task_loss 3.458 | contrastive_loss 0.218 | total 4138.74 | n_correct 2771.71 | ppl 5.34 | accuracy 66.97 | wps 6310.2 | ups 1.52 | wpb 4138.7 | bsz 152.8 | num_updates 44201 | lr 6.72665e-05 | gnorm 0.237 | clip 0 | loss_scale 32 | train_wall 884 | gb_free 17.2 | wall 33298
2023-07-08 17:14:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 17:14:52 | INFO | fairseq.trainer | begin training epoch 31
2023-07-08 17:14:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 17:15:59 | INFO | train_inner | epoch 031:     99 / 1474 loss=0.911, trans_loss=5.152, nll_loss=2.397, w2v_ctc_loss=0.275, task_loss=3.675, contrastive_loss=0.115, total=4054.44, n_correct=2724.58, ppl=5.27, accuracy=67.2, wps=4027.6, ups=0.99, wpb=4054.4, bsz=144.1, num_updates=44300, lr=6.71913e-05, gnorm=0.243, clip=0, loss_scale=32, train_wall=59, gb_free=16.6, wall=33366
2023-07-08 17:17:00 | INFO | train_inner | epoch 031:    199 / 1474 loss=0.912, trans_loss=5.151, nll_loss=2.395, w2v_ctc_loss=0.271, task_loss=3.524, contrastive_loss=0.168, total=4147.4, n_correct=2788.82, ppl=5.26, accuracy=67.243, wps=6862, ups=1.65, wpb=4147.4, bsz=151.1, num_updates=44400, lr=6.71156e-05, gnorm=0.239, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=33426
2023-07-08 17:18:01 | INFO | train_inner | epoch 031:    299 / 1474 loss=0.913, trans_loss=5.152, nll_loss=2.398, w2v_ctc_loss=0.272, task_loss=3.538, contrastive_loss=0.247, total=4149.21, n_correct=2790.44, ppl=5.27, accuracy=67.252, wps=6793.8, ups=1.64, wpb=4149.2, bsz=150.8, num_updates=44500, lr=6.70402e-05, gnorm=0.237, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=33487
2023-07-08 17:19:01 | INFO | train_inner | epoch 031:    399 / 1474 loss=0.913, trans_loss=5.157, nll_loss=2.402, w2v_ctc_loss=0.271, task_loss=3.778, contrastive_loss=0.121, total=4092.62, n_correct=2747.26, ppl=5.29, accuracy=67.127, wps=6752.5, ups=1.65, wpb=4092.6, bsz=142.8, num_updates=44600, lr=6.6965e-05, gnorm=0.237, clip=0, loss_scale=32, train_wall=60, gb_free=17.3, wall=33548
2023-07-08 17:20:02 | INFO | train_inner | epoch 031:    499 / 1474 loss=0.913, trans_loss=5.153, nll_loss=2.398, w2v_ctc_loss=0.275, task_loss=3.604, contrastive_loss=0.139, total=4111.85, n_correct=2758.63, ppl=5.27, accuracy=67.09, wps=6773.4, ups=1.65, wpb=4111.9, bsz=150.1, num_updates=44700, lr=6.689e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=60, gb_free=11.5, wall=33608
2023-07-08 17:21:02 | INFO | train_inner | epoch 031:    599 / 1474 loss=0.912, trans_loss=5.155, nll_loss=2.402, w2v_ctc_loss=0.272, task_loss=3.612, contrastive_loss=0.12, total=4083.44, n_correct=2741.51, ppl=5.29, accuracy=67.137, wps=6753.1, ups=1.65, wpb=4083.4, bsz=147.3, num_updates=44800, lr=6.68153e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=33669
2023-07-08 17:22:02 | INFO | train_inner | epoch 031:    699 / 1474 loss=0.905, trans_loss=5.145, nll_loss=2.389, w2v_ctc_loss=0.266, task_loss=3.294, contrastive_loss=0.121, total=4213.98, n_correct=2832.81, ppl=5.24, accuracy=67.224, wps=7031.6, ups=1.67, wpb=4214, bsz=157.8, num_updates=44900, lr=6.67409e-05, gnorm=0.233, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=33729
2023-07-08 17:23:03 | INFO | train_inner | epoch 031:    799 / 1474 loss=0.909, trans_loss=5.165, nll_loss=2.414, w2v_ctc_loss=0.269, task_loss=3.623, contrastive_loss=0.26, total=4097.37, n_correct=2742.27, ppl=5.33, accuracy=66.928, wps=6804.7, ups=1.66, wpb=4097.4, bsz=147.9, num_updates=45000, lr=6.66667e-05, gnorm=0.237, clip=0, loss_scale=32, train_wall=60, gb_free=13.3, wall=33789
tensor(0.0246, device='cuda:0')
tensor(0.0006, device='cuda:0')
2023-07-08 17:24:03 | INFO | train_inner | epoch 031:    899 / 1474 loss=0.912, trans_loss=5.15, nll_loss=2.394, w2v_ctc_loss=0.269, task_loss=3.605, contrastive_loss=0.149, total=4096.72, n_correct=2751.32, ppl=5.26, accuracy=67.159, wps=6793.4, ups=1.66, wpb=4096.7, bsz=148, num_updates=45100, lr=6.65927e-05, gnorm=0.24, clip=0, loss_scale=32, train_wall=60, gb_free=17.4, wall=33849
2023-07-08 17:25:04 | INFO | train_inner | epoch 031:    999 / 1474 loss=0.917, trans_loss=5.166, nll_loss=2.418, w2v_ctc_loss=0.27, task_loss=3.264, contrastive_loss=0.319, total=4187.84, n_correct=2805.06, ppl=5.35, accuracy=66.981, wps=6863.9, ups=1.64, wpb=4187.8, bsz=159.7, num_updates=45200, lr=6.6519e-05, gnorm=0.236, clip=0, loss_scale=32, train_wall=61, gb_free=17.4, wall=33910
2023-07-08 17:26:05 | INFO | train_inner | epoch 031:   1099 / 1474 loss=0.915, trans_loss=5.162, nll_loss=2.412, w2v_ctc_loss=0.269, task_loss=3.382, contrastive_loss=0.21, total=4149.44, n_correct=2783.44, ppl=5.32, accuracy=67.08, wps=6844, ups=1.65, wpb=4149.4, bsz=157.5, num_updates=45300, lr=6.64455e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=60, gb_free=17.7, wall=33971
2023-07-08 17:27:04 | INFO | train_inner | epoch 031:   1199 / 1474 loss=0.921, trans_loss=5.169, nll_loss=2.422, w2v_ctc_loss=0.275, task_loss=3.223, contrastive_loss=0.444, total=4189.76, n_correct=2805.81, ppl=5.36, accuracy=66.968, wps=7021.3, ups=1.68, wpb=4189.8, bsz=160.6, num_updates=45400, lr=6.63723e-05, gnorm=0.24, clip=0, loss_scale=32, train_wall=59, gb_free=13.6, wall=34031
2023-07-08 17:28:04 | INFO | train_inner | epoch 031:   1299 / 1474 loss=0.908, trans_loss=5.16, nll_loss=2.41, w2v_ctc_loss=0.27, task_loss=3.102, contrastive_loss=0.135, total=4227.44, n_correct=2834.43, ppl=5.31, accuracy=67.048, wps=7055.3, ups=1.67, wpb=4227.4, bsz=163.2, num_updates=45500, lr=6.62994e-05, gnorm=0.233, clip=0, loss_scale=32, train_wall=59, gb_free=16.7, wall=34091
2023-07-08 17:29:05 | INFO | train_inner | epoch 031:   1399 / 1474 loss=0.919, trans_loss=5.166, nll_loss=2.419, w2v_ctc_loss=0.271, task_loss=3.17, contrastive_loss=0.538, total=4186.05, n_correct=2803.77, ppl=5.35, accuracy=66.979, wps=6930.9, ups=1.66, wpb=4186.1, bsz=163.3, num_updates=45600, lr=6.62266e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=60, gb_free=17.6, wall=34151
2023-07-08 17:29:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0246, device='cuda:6')
tensor(0.0006, device='cuda:6')
tensor(0.0246, device='cuda:5')
tensor(0.0006, device='cuda:5')
tensor(0.0246, device='cuda:4')
tensor(0.0006, device='cuda:4')
tensor(0.0246, device='cuda:2')
tensor(0.0006, device='cuda:2')
tensor(0.0246, device='cuda:1')
tensor(0.0006, device='cuda:1')
tensor(0.0246, device='cuda:3')
tensor(0.0006, device='cuda:3')
tensor(0.0246, device='cuda:7')
tensor(0.0006, device='cuda:7')
2023-07-08 17:30:16 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 1.46 | trans_loss 5.556 | nll_loss 2.83 | w2v_ctc_loss 0.472 | task_loss 4.655 | contrastive_loss 0.263 | total 4003.4 | n_correct 2496 | ppl 7.11 | accuracy 62.347 | uer 16.773 | wer 18.609 | raw_wer 18.609 | bleu 20.07 | wps 1944.9 | wpb 4003.4 | bsz 141.8 | num_updates 45675 | best_bleu 20.36
2023-07-08 17:30:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45675 updates
2023-07-08 17:30:16 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.0705.pt
2023-07-08 17:30:19 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.0705.pt
2023-07-08 17:30:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.0705.pt (epoch 31 @ 45675 updates, score 20.07) (writing took 5.172656998998718 seconds)
2023-07-08 17:30:22 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-07-08 17:30:22 | INFO | train | epoch 031 | loss 0.913 | trans_loss 5.158 | nll_loss 2.405 | w2v_ctc_loss 0.271 | task_loss 3.455 | contrastive_loss 0.219 | total 4138.65 | n_correct 2776.81 | ppl 5.3 | accuracy 67.095 | wps 6557.5 | ups 1.58 | wpb 4138.6 | bsz 152.8 | num_updates 45675 | lr 6.61722e-05 | gnorm 0.238 | clip 0 | loss_scale 32 | train_wall 884 | gb_free 12.5 | wall 34228
2023-07-08 17:30:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 17:30:22 | INFO | fairseq.trainer | begin training epoch 32
2023-07-08 17:30:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 17:30:45 | INFO | train_inner | epoch 032:     25 / 1474 loss=0.909, trans_loss=5.15, nll_loss=2.396, w2v_ctc_loss=0.269, task_loss=3.646, contrastive_loss=0.114, total=4042.6, n_correct=2715.54, ppl=5.26, accuracy=67.173, wps=4023.2, ups=1, wpb=4042.6, bsz=144.4, num_updates=45700, lr=6.61541e-05, gnorm=0.237, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=34251
2023-07-08 17:31:46 | INFO | train_inner | epoch 032:    125 / 1474 loss=0.899, trans_loss=5.111, nll_loss=2.345, w2v_ctc_loss=0.259, task_loss=3.206, contrastive_loss=0.138, total=4227.68, n_correct=2869.16, ppl=5.08, accuracy=67.866, wps=6902.4, ups=1.63, wpb=4227.7, bsz=161.6, num_updates=45800, lr=6.60819e-05, gnorm=0.233, clip=0, loss_scale=64, train_wall=61, gb_free=16.7, wall=34313
2023-07-08 17:32:47 | INFO | train_inner | epoch 032:    225 / 1474 loss=0.906, trans_loss=5.138, nll_loss=2.38, w2v_ctc_loss=0.268, task_loss=3.287, contrastive_loss=0.154, total=4157.32, n_correct=2803.9, ppl=5.2, accuracy=67.445, wps=6820.6, ups=1.64, wpb=4157.3, bsz=160.3, num_updates=45900, lr=6.60098e-05, gnorm=0.237, clip=0, loss_scale=64, train_wall=61, gb_free=17.3, wall=34374
2023-07-08 17:33:47 | INFO | train_inner | epoch 032:    325 / 1474 loss=0.902, trans_loss=5.12, nll_loss=2.356, w2v_ctc_loss=0.263, task_loss=3.264, contrastive_loss=0.14, total=4183.45, n_correct=2831.98, ppl=5.12, accuracy=67.695, wps=6980.6, ups=1.67, wpb=4183.4, bsz=157.2, num_updates=46000, lr=6.5938e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=60, gb_free=17.7, wall=34434
2023-07-08 17:33:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 17:34:13 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 1.469 | trans_loss 5.561 | nll_loss 2.834 | w2v_ctc_loss 0.484 | task_loss 4.629 | contrastive_loss 0.261 | total 4003.4 | n_correct 2492 | ppl 7.13 | accuracy 62.247 | uer 16.649 | wer 18.545 | raw_wer 18.545 | bleu 20.15 | wps 1971.7 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.36
2023-07-08 17:34:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-07-08 17:34:13 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_32_46000.pt
2023-07-08 17:34:16 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_32_46000.pt
2023-07-08 17:34:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 20.15) (writing took 6.121762106005917 seconds)
2023-07-08 17:35:20 | INFO | train_inner | epoch 032:    425 / 1474 loss=0.907, trans_loss=5.137, nll_loss=2.378, w2v_ctc_loss=0.269, task_loss=3.433, contrastive_loss=0.132, total=4157.28, n_correct=2802.77, ppl=5.2, accuracy=67.418, wps=4458.2, ups=1.07, wpb=4157.3, bsz=152.9, num_updates=46100, lr=6.58665e-05, gnorm=0.239, clip=0, loss_scale=64, train_wall=60, gb_free=15.1, wall=34527
2023-07-08 17:36:21 | INFO | train_inner | epoch 032:    525 / 1474 loss=0.915, trans_loss=5.15, nll_loss=2.396, w2v_ctc_loss=0.272, task_loss=3.343, contrastive_loss=0.3, total=4198.93, n_correct=2824.9, ppl=5.26, accuracy=67.277, wps=6912.1, ups=1.65, wpb=4198.9, bsz=158.8, num_updates=46200, lr=6.57952e-05, gnorm=0.237, clip=0, loss_scale=64, train_wall=60, gb_free=17.4, wall=34588
2023-07-08 17:37:22 | INFO | train_inner | epoch 032:    625 / 1474 loss=0.913, trans_loss=5.153, nll_loss=2.399, w2v_ctc_loss=0.272, task_loss=3.564, contrastive_loss=0.152, total=4142.69, n_correct=2780.51, ppl=5.27, accuracy=67.118, wps=6791, ups=1.64, wpb=4142.7, bsz=150.8, num_updates=46300, lr=6.57241e-05, gnorm=0.238, clip=0, loss_scale=64, train_wall=61, gb_free=17.5, wall=34649
2023-07-08 17:38:23 | INFO | train_inner | epoch 032:    725 / 1474 loss=0.912, trans_loss=5.151, nll_loss=2.396, w2v_ctc_loss=0.274, task_loss=3.525, contrastive_loss=0.12, total=4154.59, n_correct=2793.01, ppl=5.26, accuracy=67.227, wps=6803.6, ups=1.64, wpb=4154.6, bsz=150.9, num_updates=46400, lr=6.56532e-05, gnorm=0.238, clip=0, loss_scale=64, train_wall=61, gb_free=16.2, wall=34710
2023-07-08 17:39:23 | INFO | train_inner | epoch 032:    825 / 1474 loss=0.907, trans_loss=5.144, nll_loss=2.388, w2v_ctc_loss=0.267, task_loss=3.563, contrastive_loss=0.115, total=4114.54, n_correct=2769.82, ppl=5.23, accuracy=67.318, wps=6877, ups=1.67, wpb=4114.5, bsz=147.4, num_updates=46500, lr=6.55826e-05, gnorm=0.239, clip=0, loss_scale=64, train_wall=59, gb_free=17.3, wall=34770
2023-07-08 17:40:23 | INFO | train_inner | epoch 032:    925 / 1474 loss=0.912, trans_loss=5.152, nll_loss=2.399, w2v_ctc_loss=0.27, task_loss=3.575, contrastive_loss=0.112, total=4139.67, n_correct=2780.04, ppl=5.27, accuracy=67.156, wps=6873.7, ups=1.66, wpb=4139.7, bsz=149.2, num_updates=46600, lr=6.55122e-05, gnorm=0.241, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=34830
2023-07-08 17:41:23 | INFO | train_inner | epoch 032:   1025 / 1474 loss=0.91, trans_loss=5.148, nll_loss=2.393, w2v_ctc_loss=0.265, task_loss=3.432, contrastive_loss=0.298, total=4119.15, n_correct=2773.79, ppl=5.25, accuracy=67.339, wps=6888.3, ups=1.67, wpb=4119.1, bsz=152.2, num_updates=46700, lr=6.5442e-05, gnorm=0.239, clip=0, loss_scale=64, train_wall=59, gb_free=16.7, wall=34890
2023-07-08 17:42:24 | INFO | train_inner | epoch 032:   1125 / 1474 loss=0.917, trans_loss=5.167, nll_loss=2.417, w2v_ctc_loss=0.273, task_loss=4.077, contrastive_loss=0.185, total=4019.61, n_correct=2689.4, ppl=5.34, accuracy=66.907, wps=6636.9, ups=1.65, wpb=4019.6, bsz=135.7, num_updates=46800, lr=6.5372e-05, gnorm=0.244, clip=0, loss_scale=64, train_wall=60, gb_free=17.8, wall=34950
2023-07-08 17:43:24 | INFO | train_inner | epoch 032:   1225 / 1474 loss=0.92, trans_loss=5.171, nll_loss=2.424, w2v_ctc_loss=0.272, task_loss=3.419, contrastive_loss=0.394, total=4149.28, n_correct=2772.62, ppl=5.37, accuracy=66.822, wps=6847.5, ups=1.65, wpb=4149.3, bsz=155.2, num_updates=46900, lr=6.53023e-05, gnorm=0.244, clip=0, loss_scale=64, train_wall=60, gb_free=16.1, wall=35011
2023-07-08 17:44:25 | INFO | train_inner | epoch 032:   1325 / 1474 loss=0.912, trans_loss=5.158, nll_loss=2.406, w2v_ctc_loss=0.272, task_loss=3.54, contrastive_loss=0.115, total=4079.22, n_correct=2734.45, ppl=5.3, accuracy=67.034, wps=6758.5, ups=1.66, wpb=4079.2, bsz=148.1, num_updates=47000, lr=6.52328e-05, gnorm=0.241, clip=0, loss_scale=64, train_wall=60, gb_free=15.4, wall=35071
2023-07-08 17:45:25 | INFO | train_inner | epoch 032:   1425 / 1474 loss=0.921, trans_loss=5.166, nll_loss=2.417, w2v_ctc_loss=0.272, task_loss=3.478, contrastive_loss=0.577, total=4111.41, n_correct=2752.04, ppl=5.34, accuracy=66.937, wps=6853.9, ups=1.67, wpb=4111.4, bsz=153.1, num_updates=47100, lr=6.51635e-05, gnorm=0.241, clip=0, loss_scale=64, train_wall=60, gb_free=16.2, wall=35131
2023-07-08 17:45:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 17:46:21 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 1.462 | trans_loss 5.559 | nll_loss 2.831 | w2v_ctc_loss 0.469 | task_loss 4.633 | contrastive_loss 0.264 | total 4003.4 | n_correct 2491.1 | ppl 7.12 | accuracy 62.225 | uer 16.542 | wer 18.381 | raw_wer 18.381 | bleu 19.93 | wps 1958 | wpb 4003.4 | bsz 141.8 | num_updates 47149 | best_bleu 20.36
2023-07-08 17:46:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47149 updates
2023-07-08 17:46:21 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-08 17:46:26 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-08 17:46:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt (epoch 32 @ 47149 updates, score 19.93) (writing took 4.171748820008361 seconds)
2023-07-08 17:46:26 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-07-08 17:46:26 | INFO | train | epoch 032 | loss 0.911 | trans_loss 5.148 | nll_loss 2.392 | w2v_ctc_loss 0.269 | task_loss 3.455 | contrastive_loss 0.22 | total 4138.65 | n_correct 2783.53 | ppl 5.25 | accuracy 67.257 | wps 6328.6 | ups 1.53 | wpb 4138.6 | bsz 152.8 | num_updates 47149 | lr 6.51297e-05 | gnorm 0.239 | clip 0 | loss_scale 64 | train_wall 885 | gb_free 16.8 | wall 35192
2023-07-08 17:46:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 17:46:26 | INFO | fairseq.trainer | begin training epoch 33
2023-07-08 17:46:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 17:47:05 | INFO | train_inner | epoch 033:     51 / 1474 loss=0.913, trans_loss=5.149, nll_loss=2.395, w2v_ctc_loss=0.27, task_loss=3.221, contrastive_loss=0.322, total=4156.71, n_correct=2796.16, ppl=5.26, accuracy=67.269, wps=4121.8, ups=0.99, wpb=4156.7, bsz=161.2, num_updates=47200, lr=6.50945e-05, gnorm=0.239, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=35232
2023-07-08 17:48:06 | INFO | train_inner | epoch 033:    151 / 1474 loss=0.9, trans_loss=5.121, nll_loss=2.356, w2v_ctc_loss=0.26, task_loss=3.737, contrastive_loss=0.096, total=4071.44, n_correct=2757.09, ppl=5.12, accuracy=67.718, wps=6777, ups=1.66, wpb=4071.4, bsz=142.1, num_updates=47300, lr=6.50256e-05, gnorm=0.237, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=35292
2023-07-08 17:49:06 | INFO | train_inner | epoch 033:    251 / 1474 loss=0.909, trans_loss=5.125, nll_loss=2.365, w2v_ctc_loss=0.264, task_loss=2.958, contrastive_loss=0.448, total=4281.28, n_correct=2900.56, ppl=5.15, accuracy=67.75, wps=7068.6, ups=1.65, wpb=4281.3, bsz=173.2, num_updates=47400, lr=6.4957e-05, gnorm=0.234, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=35353
2023-07-08 17:50:07 | INFO | train_inner | epoch 033:    351 / 1474 loss=0.914, trans_loss=5.137, nll_loss=2.379, w2v_ctc_loss=0.271, task_loss=3.557, contrastive_loss=0.153, total=4111.69, n_correct=2772.28, ppl=5.2, accuracy=67.424, wps=6778.2, ups=1.65, wpb=4111.7, bsz=149.2, num_updates=47500, lr=6.48886e-05, gnorm=0.24, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=35413
2023-07-08 17:51:07 | INFO | train_inner | epoch 033:    451 / 1474 loss=0.897, trans_loss=5.111, nll_loss=2.344, w2v_ctc_loss=0.259, task_loss=3.241, contrastive_loss=0.114, total=4147.28, n_correct=2816.74, ppl=5.08, accuracy=67.918, wps=6946.8, ups=1.68, wpb=4147.3, bsz=156.7, num_updates=47600, lr=6.48204e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=59, gb_free=16.8, wall=35473
2023-07-08 17:52:07 | INFO | train_inner | epoch 033:    551 / 1474 loss=0.913, trans_loss=5.144, nll_loss=2.386, w2v_ctc_loss=0.269, task_loss=3.608, contrastive_loss=0.153, total=4127.68, n_correct=2776.68, ppl=5.23, accuracy=67.27, wps=6835.1, ups=1.66, wpb=4127.7, bsz=146.3, num_updates=47700, lr=6.47524e-05, gnorm=0.24, clip=0, loss_scale=64, train_wall=60, gb_free=15.8, wall=35533
2023-07-08 17:52:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-08 17:53:08 | INFO | train_inner | epoch 033:    652 / 1474 loss=0.908, trans_loss=5.149, nll_loss=2.394, w2v_ctc_loss=0.267, task_loss=3.531, contrastive_loss=0.218, total=4160.31, n_correct=2792.91, ppl=5.25, accuracy=67.132, wps=6850.3, ups=1.65, wpb=4160.3, bsz=151.1, num_updates=47800, lr=6.46846e-05, gnorm=0.238, clip=0, loss_scale=64, train_wall=60, gb_free=17.9, wall=35594
2023-07-08 17:54:08 | INFO | train_inner | epoch 033:    752 / 1474 loss=0.912, trans_loss=5.155, nll_loss=2.402, w2v_ctc_loss=0.274, task_loss=3.745, contrastive_loss=0.116, total=4070.75, n_correct=2730.22, ppl=5.28, accuracy=67.069, wps=6735.6, ups=1.65, wpb=4070.8, bsz=143.6, num_updates=47900, lr=6.46171e-05, gnorm=0.244, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=35654
2023-07-08 17:55:08 | INFO | train_inner | epoch 033:    852 / 1474 loss=0.907, trans_loss=5.131, nll_loss=2.373, w2v_ctc_loss=0.263, task_loss=3.295, contrastive_loss=0.254, total=4130.24, n_correct=2790.7, ppl=5.18, accuracy=67.568, wps=6932.2, ups=1.68, wpb=4130.2, bsz=158.2, num_updates=48000, lr=6.45497e-05, gnorm=0.235, clip=0, loss_scale=64, train_wall=59, gb_free=16.9, wall=35714
2023-07-08 17:55:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 17:55:34 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 1.467 | trans_loss 5.56 | nll_loss 2.832 | w2v_ctc_loss 0.479 | task_loss 4.637 | contrastive_loss 0.261 | total 4003.4 | n_correct 2492 | ppl 7.12 | accuracy 62.247 | uer 16.749 | wer 18.556 | raw_wer 18.556 | bleu 20.04 | wps 1970.4 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.36
2023-07-08 17:55:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-07-08 17:55:34 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_33_48000.pt
2023-07-08 17:55:36 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_33_48000.pt
2023-07-08 17:55:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 20.04) (writing took 5.092957524000667 seconds)
2023-07-08 17:56:40 | INFO | train_inner | epoch 033:    952 / 1474 loss=0.909, trans_loss=5.141, nll_loss=2.384, w2v_ctc_loss=0.269, task_loss=3.446, contrastive_loss=0.14, total=4151.18, n_correct=2797.75, ppl=5.22, accuracy=67.396, wps=4495.2, ups=1.08, wpb=4151.2, bsz=154.1, num_updates=48100, lr=6.44826e-05, gnorm=0.237, clip=0, loss_scale=64, train_wall=60, gb_free=11.6, wall=35806
2023-07-08 17:57:41 | INFO | train_inner | epoch 033:   1052 / 1474 loss=0.917, trans_loss=5.148, nll_loss=2.394, w2v_ctc_loss=0.271, task_loss=3.46, contrastive_loss=0.343, total=4140.1, n_correct=2782.11, ppl=5.25, accuracy=67.199, wps=6789.5, ups=1.64, wpb=4140.1, bsz=153.8, num_updates=48200, lr=6.44157e-05, gnorm=0.243, clip=0, loss_scale=64, train_wall=61, gb_free=12.1, wall=35867
2023-07-08 17:58:42 | INFO | train_inner | epoch 033:   1152 / 1474 loss=0.914, trans_loss=5.149, nll_loss=2.395, w2v_ctc_loss=0.266, task_loss=3.445, contrastive_loss=0.32, total=4182.67, n_correct=2811.02, ppl=5.26, accuracy=67.206, wps=6882.3, ups=1.65, wpb=4182.7, bsz=154.7, num_updates=48300, lr=6.43489e-05, gnorm=0.24, clip=0, loss_scale=64, train_wall=60, gb_free=17.7, wall=35928
2023-07-08 17:59:42 | INFO | train_inner | epoch 033:   1252 / 1474 loss=0.91, trans_loss=5.148, nll_loss=2.392, w2v_ctc_loss=0.271, task_loss=3.64, contrastive_loss=0.126, total=4110.02, n_correct=2764.61, ppl=5.25, accuracy=67.265, wps=6820.1, ups=1.66, wpb=4110, bsz=147.2, num_updates=48400, lr=6.42824e-05, gnorm=0.241, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=35988
2023-07-08 18:00:43 | INFO | train_inner | epoch 033:   1352 / 1474 loss=0.904, trans_loss=5.146, nll_loss=2.393, w2v_ctc_loss=0.269, task_loss=3.39, contrastive_loss=0.164, total=4128.82, n_correct=2780.79, ppl=5.25, accuracy=67.351, wps=6811.6, ups=1.65, wpb=4128.8, bsz=156.2, num_updates=48500, lr=6.42161e-05, gnorm=0.239, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=36049
2023-07-08 18:01:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-08 18:01:44 | INFO | train_inner | epoch 033:   1453 / 1474 loss=0.914, trans_loss=5.149, nll_loss=2.396, w2v_ctc_loss=0.267, task_loss=3.432, contrastive_loss=0.46, total=4120.54, n_correct=2774.56, ppl=5.26, accuracy=67.335, wps=6771.3, ups=1.64, wpb=4120.5, bsz=154.5, num_updates=48600, lr=6.415e-05, gnorm=0.241, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=36110
2023-07-08 18:01:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 18:02:22 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 1.463 | trans_loss 5.554 | nll_loss 2.823 | w2v_ctc_loss 0.466 | task_loss 4.636 | contrastive_loss 0.276 | total 4003.4 | n_correct 2496.8 | ppl 7.08 | accuracy 62.367 | uer 16.471 | wer 18.329 | raw_wer 18.329 | bleu 20.16 | wps 1941.8 | wpb 4003.4 | bsz 141.8 | num_updates 48621 | best_bleu 20.36
2023-07-08 18:02:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48621 updates
2023-07-08 18:02:22 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.1609.pt
2023-07-08 18:02:25 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.1609.pt
2023-07-08 18:02:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.1609.pt (epoch 33 @ 48621 updates, score 20.16) (writing took 5.282756688000518 seconds)
2023-07-08 18:02:28 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-07-08 18:02:28 | INFO | train | epoch 033 | loss 0.909 | trans_loss 5.139 | nll_loss 2.382 | w2v_ctc_loss 0.267 | task_loss 3.453 | contrastive_loss 0.22 | total 4138.39 | n_correct 2789.5 | ppl 5.21 | accuracy 67.405 | wps 6330.1 | ups 1.53 | wpb 4138.4 | bsz 152.8 | num_updates 48621 | lr 6.41362e-05 | gnorm 0.239 | clip 0 | loss_scale 32 | train_wall 883 | gb_free 18 | wall 36154
2023-07-08 18:02:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 18:02:28 | INFO | fairseq.trainer | begin training epoch 34
2023-07-08 18:02:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 18:03:25 | INFO | train_inner | epoch 034:     79 / 1474 loss=0.902, trans_loss=5.112, nll_loss=2.347, w2v_ctc_loss=0.263, task_loss=3.411, contrastive_loss=0.13, total=4131.47, n_correct=2805.63, ppl=5.09, accuracy=67.909, wps=4072.8, ups=0.99, wpb=4131.5, bsz=150.8, num_updates=48700, lr=6.40841e-05, gnorm=0.237, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=36211
2023-07-08 18:04:25 | INFO | train_inner | epoch 034:    179 / 1474 loss=0.903, trans_loss=5.117, nll_loss=2.352, w2v_ctc_loss=0.266, task_loss=3.606, contrastive_loss=0.132, total=4065.88, n_correct=2755.64, ppl=5.11, accuracy=67.775, wps=6768.2, ups=1.66, wpb=4065.9, bsz=147.5, num_updates=48800, lr=6.40184e-05, gnorm=0.24, clip=0, loss_scale=32, train_wall=60, gb_free=16.2, wall=36271
2023-07-08 18:05:26 | INFO | train_inner | epoch 034:    279 / 1474 loss=0.919, trans_loss=5.137, nll_loss=2.379, w2v_ctc_loss=0.265, task_loss=3.223, contrastive_loss=0.55, total=4246.3, n_correct=2864.29, ppl=5.2, accuracy=67.454, wps=6987.5, ups=1.65, wpb=4246.3, bsz=164.4, num_updates=48900, lr=6.39529e-05, gnorm=0.237, clip=0, loss_scale=32, train_wall=60, gb_free=17.9, wall=36332
2023-07-08 18:06:26 | INFO | train_inner | epoch 034:    379 / 1474 loss=0.904, trans_loss=5.112, nll_loss=2.346, w2v_ctc_loss=0.262, task_loss=3.286, contrastive_loss=0.325, total=4156.17, n_correct=2822.81, ppl=5.08, accuracy=67.919, wps=6858.3, ups=1.65, wpb=4156.2, bsz=158.4, num_updates=49000, lr=6.38877e-05, gnorm=0.235, clip=0, loss_scale=32, train_wall=60, gb_free=17.9, wall=36393
2023-07-08 18:07:26 | INFO | train_inner | epoch 034:    479 / 1474 loss=0.907, trans_loss=5.13, nll_loss=2.368, w2v_ctc_loss=0.268, task_loss=3.777, contrastive_loss=0.121, total=4070.55, n_correct=2749.2, ppl=5.16, accuracy=67.539, wps=6790.8, ups=1.67, wpb=4070.6, bsz=142.3, num_updates=49100, lr=6.38226e-05, gnorm=0.242, clip=0, loss_scale=32, train_wall=60, gb_free=17.6, wall=36453
2023-07-08 18:08:26 | INFO | train_inner | epoch 034:    579 / 1474 loss=0.905, trans_loss=5.118, nll_loss=2.354, w2v_ctc_loss=0.265, task_loss=3.503, contrastive_loss=0.124, total=4119.38, n_correct=2795.3, ppl=5.11, accuracy=67.857, wps=6906.2, ups=1.68, wpb=4119.4, bsz=150.1, num_updates=49200, lr=6.37577e-05, gnorm=0.239, clip=0, loss_scale=32, train_wall=59, gb_free=13.5, wall=36512
2023-07-08 18:09:26 | INFO | train_inner | epoch 034:    679 / 1474 loss=0.906, trans_loss=5.122, nll_loss=2.36, w2v_ctc_loss=0.265, task_loss=3.49, contrastive_loss=0.113, total=4124.83, n_correct=2793.78, ppl=5.13, accuracy=67.731, wps=6827.3, ups=1.66, wpb=4124.8, bsz=150.1, num_updates=49300, lr=6.3693e-05, gnorm=0.237, clip=0, loss_scale=32, train_wall=60, gb_free=14.6, wall=36573
2023-07-08 18:10:27 | INFO | train_inner | epoch 034:    779 / 1474 loss=0.914, trans_loss=5.146, nll_loss=2.39, w2v_ctc_loss=0.264, task_loss=3.617, contrastive_loss=0.25, total=4082.07, n_correct=2745.58, ppl=5.24, accuracy=67.26, wps=6735.4, ups=1.65, wpb=4082.1, bsz=147.5, num_updates=49400, lr=6.36285e-05, gnorm=0.24, clip=0, loss_scale=32, train_wall=60, gb_free=15.8, wall=36633
2023-07-08 18:11:27 | INFO | train_inner | epoch 034:    879 / 1474 loss=0.912, trans_loss=5.141, nll_loss=2.385, w2v_ctc_loss=0.267, task_loss=3.634, contrastive_loss=0.168, total=4100.9, n_correct=2764.27, ppl=5.22, accuracy=67.406, wps=6798.4, ups=1.66, wpb=4100.9, bsz=148.3, num_updates=49500, lr=6.35642e-05, gnorm=0.243, clip=0, loss_scale=32, train_wall=60, gb_free=12.6, wall=36694
2023-07-08 18:12:28 | INFO | train_inner | epoch 034:    979 / 1474 loss=0.905, trans_loss=5.136, nll_loss=2.379, w2v_ctc_loss=0.267, task_loss=3.398, contrastive_loss=0.16, total=4168.39, n_correct=2810.47, ppl=5.2, accuracy=67.423, wps=6892.9, ups=1.65, wpb=4168.4, bsz=156, num_updates=49600, lr=6.35001e-05, gnorm=0.239, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=36754
2023-07-08 18:13:27 | INFO | train_inner | epoch 034:   1079 / 1474 loss=0.908, trans_loss=5.136, nll_loss=2.378, w2v_ctc_loss=0.269, task_loss=3.345, contrastive_loss=0.125, total=4150.57, n_correct=2801.07, ppl=5.2, accuracy=67.486, wps=6974.7, ups=1.68, wpb=4150.6, bsz=154.2, num_updates=49700, lr=6.34361e-05, gnorm=0.239, clip=0, loss_scale=32, train_wall=59, gb_free=17, wall=36814
2023-07-08 18:14:28 | INFO | train_inner | epoch 034:   1179 / 1474 loss=0.905, trans_loss=5.137, nll_loss=2.379, w2v_ctc_loss=0.265, task_loss=3.571, contrastive_loss=0.148, total=4098.77, n_correct=2756.97, ppl=5.2, accuracy=67.263, wps=6799.4, ups=1.66, wpb=4098.8, bsz=148.6, num_updates=49800, lr=6.33724e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=36874
2023-07-08 18:15:29 | INFO | train_inner | epoch 034:   1279 / 1474 loss=0.904, trans_loss=5.133, nll_loss=2.374, w2v_ctc_loss=0.265, task_loss=3.486, contrastive_loss=0.117, total=4150.54, n_correct=2799.45, ppl=5.18, accuracy=67.448, wps=6804.2, ups=1.64, wpb=4150.5, bsz=150.5, num_updates=49900, lr=6.33089e-05, gnorm=0.241, clip=0, loss_scale=32, train_wall=61, gb_free=17.3, wall=36935
2023-07-08 18:16:30 | INFO | train_inner | epoch 034:   1379 / 1474 loss=0.908, trans_loss=5.145, nll_loss=2.39, w2v_ctc_loss=0.268, task_loss=3.302, contrastive_loss=0.248, total=4196.91, n_correct=2824.14, ppl=5.24, accuracy=67.291, wps=6886, ups=1.64, wpb=4196.9, bsz=160.7, num_updates=50000, lr=6.32456e-05, gnorm=0.236, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=36996
2023-07-08 18:16:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 18:16:56 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 1.466 | trans_loss 5.556 | nll_loss 2.824 | w2v_ctc_loss 0.473 | task_loss 4.641 | contrastive_loss 0.265 | total 4003.4 | n_correct 2495.2 | ppl 7.08 | accuracy 62.327 | uer 16.495 | wer 18.284 | raw_wer 18.284 | bleu 20.44 | wps 2022.8 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.44
2023-07-08 18:16:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-07-08 18:16:56 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_34_50000.pt
2023-07-08 18:16:58 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_34_50000.pt
2023-07-08 18:17:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 20.44) (writing took 8.865137218992459 seconds)
tensor(0.0246, device='cuda:0')
tensor(0.0006, device='cuda:0')
2023-07-08 18:18:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0246, device='cuda:6')
tensor(0.0006, device='cuda:6')
tensor(0.0246, device='cuda:7')
tensor(0.0006, device='cuda:7')
tensor(0.0246, device='cuda:4')
tensor(0.0006, device='cuda:4')
tensor(0.0246, device='cuda:5')
tensor(0.0006, device='cuda:5')
tensor(0.0246, device='cuda:1')
tensor(0.0006, device='cuda:1')
tensor(0.0246, device='cuda:2')
tensor(0.0006, device='cuda:2')
tensor(0.0246, device='cuda:3')
tensor(0.0006, device='cuda:3')
2023-07-08 18:18:29 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 1.469 | trans_loss 5.561 | nll_loss 2.832 | w2v_ctc_loss 0.475 | task_loss 4.621 | contrastive_loss 0.276 | total 4003.4 | n_correct 2492.4 | ppl 7.12 | accuracy 62.257 | uer 16.495 | wer 18.307 | raw_wer 18.307 | bleu 20.36 | wps 1959.6 | wpb 4003.4 | bsz 141.8 | num_updates 50095 | best_bleu 20.44
2023-07-08 18:18:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50095 updates
2023-07-08 18:18:29 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.3601.pt
2023-07-08 18:18:31 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.3601.pt
2023-07-08 18:18:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.3601.pt (epoch 34 @ 50095 updates, score 20.36) (writing took 5.0897473489894764 seconds)
2023-07-08 18:18:34 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-07-08 18:18:34 | INFO | train | epoch 034 | loss 0.908 | trans_loss 5.131 | nll_loss 2.371 | w2v_ctc_loss 0.265 | task_loss 3.452 | contrastive_loss 0.222 | total 4138.65 | n_correct 2795.26 | ppl 5.17 | accuracy 67.54 | wps 6316 | ups 1.53 | wpb 4138.6 | bsz 152.8 | num_updates 50095 | lr 6.31856e-05 | gnorm 0.239 | clip 0 | loss_scale 32 | train_wall 884 | gb_free 17.5 | wall 37120
2023-07-08 18:18:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 18:18:34 | INFO | fairseq.trainer | begin training epoch 35
2023-07-08 18:18:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 18:18:45 | INFO | train_inner | epoch 035:      5 / 1474 loss=0.916, trans_loss=5.141, nll_loss=2.386, w2v_ctc_loss=0.265, task_loss=3.17, contrastive_loss=0.529, total=4213.19, n_correct=2838.51, ppl=5.23, accuracy=67.372, wps=3107.6, ups=0.74, wpb=4213.2, bsz=163.1, num_updates=50100, lr=6.31824e-05, gnorm=0.241, clip=0, loss_scale=32, train_wall=60, gb_free=17.5, wall=37132
2023-07-08 18:19:46 | INFO | train_inner | epoch 035:    105 / 1474 loss=0.903, trans_loss=5.113, nll_loss=2.347, w2v_ctc_loss=0.259, task_loss=3.337, contrastive_loss=0.413, total=4166.04, n_correct=2825.39, ppl=5.09, accuracy=67.82, wps=6896.2, ups=1.66, wpb=4166, bsz=156.6, num_updates=50200, lr=6.31194e-05, gnorm=0.24, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=37192
2023-07-08 18:20:46 | INFO | train_inner | epoch 035:    205 / 1474 loss=0.894, trans_loss=5.101, nll_loss=2.332, w2v_ctc_loss=0.257, task_loss=3.261, contrastive_loss=0.123, total=4171.82, n_correct=2841.24, ppl=5.04, accuracy=68.106, wps=6950, ups=1.67, wpb=4171.8, bsz=158.3, num_updates=50300, lr=6.30567e-05, gnorm=0.237, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=37252
2023-07-08 18:21:46 | INFO | train_inner | epoch 035:    305 / 1474 loss=0.907, trans_loss=5.118, nll_loss=2.352, w2v_ctc_loss=0.263, task_loss=3.601, contrastive_loss=0.45, total=4111.19, n_correct=2786.46, ppl=5.11, accuracy=67.777, wps=6776.4, ups=1.65, wpb=4111.2, bsz=150, num_updates=50400, lr=6.29941e-05, gnorm=0.24, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=37313
2023-07-08 18:22:48 | INFO | train_inner | epoch 035:    405 / 1474 loss=0.911, trans_loss=5.125, nll_loss=2.362, w2v_ctc_loss=0.27, task_loss=3.838, contrastive_loss=0.126, total=4070.26, n_correct=2749.16, ppl=5.14, accuracy=67.543, wps=6643.8, ups=1.63, wpb=4070.3, bsz=141.3, num_updates=50500, lr=6.29317e-05, gnorm=0.243, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=37374
2023-07-08 18:23:48 | INFO | train_inner | epoch 035:    505 / 1474 loss=0.906, trans_loss=5.12, nll_loss=2.355, w2v_ctc_loss=0.261, task_loss=3.508, contrastive_loss=0.27, total=4154.8, n_correct=2817.05, ppl=5.12, accuracy=67.802, wps=6856.5, ups=1.65, wpb=4154.8, bsz=152.4, num_updates=50600, lr=6.28695e-05, gnorm=0.236, clip=0, loss_scale=32, train_wall=60, gb_free=14, wall=37435
2023-07-08 18:24:48 | INFO | train_inner | epoch 035:    605 / 1474 loss=0.903, trans_loss=5.111, nll_loss=2.346, w2v_ctc_loss=0.259, task_loss=3.414, contrastive_loss=0.284, total=4170.95, n_correct=2829.27, ppl=5.08, accuracy=67.833, wps=6928.8, ups=1.66, wpb=4170.9, bsz=155, num_updates=50700, lr=6.28074e-05, gnorm=0.239, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=37495
2023-07-08 18:25:48 | INFO | train_inner | epoch 035:    705 / 1474 loss=0.909, trans_loss=5.126, nll_loss=2.364, w2v_ctc_loss=0.269, task_loss=3.609, contrastive_loss=0.144, total=4081.06, n_correct=2763.55, ppl=5.15, accuracy=67.716, wps=6788.3, ups=1.66, wpb=4081.1, bsz=147.4, num_updates=50800, lr=6.27456e-05, gnorm=0.242, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=37555
2023-07-08 18:26:49 | INFO | train_inner | epoch 035:    805 / 1474 loss=0.905, trans_loss=5.122, nll_loss=2.36, w2v_ctc_loss=0.266, task_loss=3.408, contrastive_loss=0.16, total=4151.95, n_correct=2810.42, ppl=5.13, accuracy=67.689, wps=6868.1, ups=1.65, wpb=4151.9, bsz=155.1, num_updates=50900, lr=6.26839e-05, gnorm=0.237, clip=0, loss_scale=64, train_wall=60, gb_free=15.8, wall=37615
2023-07-08 18:27:49 | INFO | train_inner | epoch 035:    905 / 1474 loss=0.908, trans_loss=5.129, nll_loss=2.368, w2v_ctc_loss=0.268, task_loss=3.62, contrastive_loss=0.119, total=4096.04, n_correct=2763.21, ppl=5.16, accuracy=67.461, wps=6763.4, ups=1.65, wpb=4096, bsz=146.9, num_updates=51000, lr=6.26224e-05, gnorm=0.242, clip=0, loss_scale=64, train_wall=60, gb_free=11.6, wall=37676
2023-07-08 18:28:51 | INFO | train_inner | epoch 035:   1005 / 1474 loss=0.915, trans_loss=5.132, nll_loss=2.374, w2v_ctc_loss=0.263, task_loss=3.476, contrastive_loss=0.369, total=4144.92, n_correct=2798.06, ppl=5.18, accuracy=67.506, wps=6743.7, ups=1.63, wpb=4144.9, bsz=153.5, num_updates=51100, lr=6.25611e-05, gnorm=0.243, clip=0, loss_scale=64, train_wall=61, gb_free=15, wall=37737
2023-07-08 18:29:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-08 18:29:52 | INFO | train_inner | epoch 035:   1106 / 1474 loss=0.904, trans_loss=5.128, nll_loss=2.368, w2v_ctc_loss=0.265, task_loss=3.307, contrastive_loss=0.137, total=4185.15, n_correct=2829.93, ppl=5.16, accuracy=67.618, wps=6903.3, ups=1.65, wpb=4185.1, bsz=155.8, num_updates=51200, lr=6.25e-05, gnorm=0.237, clip=0, loss_scale=32, train_wall=60, gb_free=10.7, wall=37798
2023-07-08 18:30:52 | INFO | train_inner | epoch 035:   1206 / 1474 loss=0.909, trans_loss=5.129, nll_loss=2.37, w2v_ctc_loss=0.264, task_loss=3.195, contrastive_loss=0.244, total=4207.87, n_correct=2843.77, ppl=5.17, accuracy=67.582, wps=6991.8, ups=1.66, wpb=4207.9, bsz=160.2, num_updates=51300, lr=6.24391e-05, gnorm=0.237, clip=0, loss_scale=32, train_wall=60, gb_free=15.1, wall=37858
2023-07-08 18:31:52 | INFO | train_inner | epoch 035:   1306 / 1474 loss=0.904, trans_loss=5.128, nll_loss=2.369, w2v_ctc_loss=0.263, task_loss=3.299, contrastive_loss=0.142, total=4141.67, n_correct=2800.39, ppl=5.17, accuracy=67.615, wps=6873.3, ups=1.66, wpb=4141.7, bsz=157, num_updates=51400, lr=6.23783e-05, gnorm=0.24, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=37918
2023-07-08 18:32:52 | INFO | train_inner | epoch 035:   1406 / 1474 loss=0.907, trans_loss=5.139, nll_loss=2.381, w2v_ctc_loss=0.266, task_loss=3.779, contrastive_loss=0.12, total=4057.93, n_correct=2733.79, ppl=5.21, accuracy=67.369, wps=6750.7, ups=1.66, wpb=4057.9, bsz=142.8, num_updates=51500, lr=6.23177e-05, gnorm=0.242, clip=0, loss_scale=32, train_wall=60, gb_free=15.6, wall=37979
2023-07-08 18:33:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 18:34:01 | INFO | dev_st | epoch 035 | valid on 'dev_st' subset | loss 1.465 | trans_loss 5.562 | nll_loss 2.831 | w2v_ctc_loss 0.47 | task_loss 4.634 | contrastive_loss 0.271 | total 4003.4 | n_correct 2497.4 | ppl 7.11 | accuracy 62.382 | uer 16.423 | wer 18.269 | raw_wer 18.269 | bleu 20.2 | wps 1954.7 | wpb 4003.4 | bsz 141.8 | num_updates 51568 | best_bleu 20.44
2023-07-08 18:34:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 51568 updates
2023-07-08 18:34:01 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.2004.pt
2023-07-08 18:34:03 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.2004.pt
2023-07-08 18:34:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.2004.pt (epoch 35 @ 51568 updates, score 20.2) (writing took 5.259503876004601 seconds)
2023-07-08 18:34:06 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-07-08 18:34:06 | INFO | train | epoch 035 | loss 0.906 | trans_loss 5.123 | nll_loss 2.361 | w2v_ctc_loss 0.264 | task_loss 3.451 | contrastive_loss 0.224 | total 4138.98 | n_correct 2801.04 | ppl 5.14 | accuracy 67.675 | wps 6539.5 | ups 1.58 | wpb 4139 | bsz 152.9 | num_updates 51568 | lr 6.22766e-05 | gnorm 0.24 | clip 0 | loss_scale 32 | train_wall 885 | gb_free 17.4 | wall 38053
2023-07-08 18:34:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 18:34:07 | INFO | fairseq.trainer | begin training epoch 36
2023-07-08 18:34:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 18:34:34 | INFO | train_inner | epoch 036:     32 / 1474 loss=0.906, trans_loss=5.115, nll_loss=2.351, w2v_ctc_loss=0.263, task_loss=3.353, contrastive_loss=0.205, total=4128.66, n_correct=2798.87, ppl=5.1, accuracy=67.791, wps=4063.5, ups=0.98, wpb=4128.7, bsz=154.5, num_updates=51600, lr=6.22573e-05, gnorm=0.241, clip=0, loss_scale=32, train_wall=59, gb_free=16.5, wall=38080
2023-07-08 18:35:35 | INFO | train_inner | epoch 036:    132 / 1474 loss=0.902, trans_loss=5.104, nll_loss=2.334, w2v_ctc_loss=0.263, task_loss=3.602, contrastive_loss=0.139, total=4101.15, n_correct=2790.61, ppl=5.04, accuracy=68.045, wps=6744.6, ups=1.64, wpb=4101.1, bsz=149.4, num_updates=51700, lr=6.2197e-05, gnorm=0.24, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=38141
2023-07-08 18:36:35 | INFO | train_inner | epoch 036:    232 / 1474 loss=0.901, trans_loss=5.1, nll_loss=2.331, w2v_ctc_loss=0.26, task_loss=3.506, contrastive_loss=0.162, total=4153.27, n_correct=2829.34, ppl=5.03, accuracy=68.123, wps=6864.7, ups=1.65, wpb=4153.3, bsz=151.8, num_updates=51800, lr=6.2137e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=60, gb_free=17, wall=38201
2023-07-08 18:37:35 | INFO | train_inner | epoch 036:    332 / 1474 loss=0.898, trans_loss=5.102, nll_loss=2.333, w2v_ctc_loss=0.256, task_loss=3.275, contrastive_loss=0.118, total=4162.11, n_correct=2831.55, ppl=5.04, accuracy=68.032, wps=6975.1, ups=1.68, wpb=4162.1, bsz=155.1, num_updates=51900, lr=6.20771e-05, gnorm=0.236, clip=0, loss_scale=32, train_wall=59, gb_free=16.9, wall=38261
2023-07-08 18:38:35 | INFO | train_inner | epoch 036:    432 / 1474 loss=0.903, trans_loss=5.102, nll_loss=2.335, w2v_ctc_loss=0.256, task_loss=3.033, contrastive_loss=0.354, total=4234.05, n_correct=2880.4, ppl=5.05, accuracy=68.029, wps=7070.7, ups=1.67, wpb=4234.1, bsz=166.6, num_updates=52000, lr=6.20174e-05, gnorm=0.237, clip=0, loss_scale=32, train_wall=59, gb_free=16.3, wall=38321
2023-07-08 18:38:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 18:39:02 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 1.478 | trans_loss 5.561 | nll_loss 2.835 | w2v_ctc_loss 0.48 | task_loss 4.601 | contrastive_loss 0.266 | total 4003.4 | n_correct 2498 | ppl 7.13 | accuracy 62.397 | uer 16.585 | wer 18.493 | raw_wer 18.493 | bleu 20.12 | wps 1974.7 | wpb 4003.4 | bsz 141.8 | num_updates 52000 | best_bleu 20.44
2023-07-08 18:39:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 52000 updates
2023-07-08 18:39:02 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_36_52000.pt
2023-07-08 18:39:04 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_36_52000.pt
2023-07-08 18:39:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_36_52000.pt (epoch 36 @ 52000 updates, score 20.12) (writing took 5.174682587006828 seconds)
2023-07-08 18:40:09 | INFO | train_inner | epoch 036:    532 / 1474 loss=0.911, trans_loss=5.122, nll_loss=2.361, w2v_ctc_loss=0.258, task_loss=3.444, contrastive_loss=0.63, total=4149.22, n_correct=2806.4, ppl=5.14, accuracy=67.637, wps=4415.4, ups=1.06, wpb=4149.2, bsz=156.2, num_updates=52100, lr=6.19578e-05, gnorm=0.241, clip=0, loss_scale=32, train_wall=61, gb_free=17.9, wall=38415
2023-07-08 18:41:10 | INFO | train_inner | epoch 036:    632 / 1474 loss=0.902, trans_loss=5.1, nll_loss=2.331, w2v_ctc_loss=0.26, task_loss=3.33, contrastive_loss=0.276, total=4179.05, n_correct=2844.74, ppl=5.03, accuracy=68.071, wps=6851.9, ups=1.64, wpb=4179.1, bsz=158.4, num_updates=52200, lr=6.18984e-05, gnorm=0.236, clip=0, loss_scale=32, train_wall=61, gb_free=17.2, wall=38476
2023-07-08 18:42:10 | INFO | train_inner | epoch 036:    732 / 1474 loss=0.909, trans_loss=5.126, nll_loss=2.365, w2v_ctc_loss=0.267, task_loss=3.335, contrastive_loss=0.146, total=4180.07, n_correct=2826.31, ppl=5.15, accuracy=67.614, wps=6884, ups=1.65, wpb=4180.1, bsz=157.8, num_updates=52300, lr=6.18392e-05, gnorm=0.24, clip=0, loss_scale=32, train_wall=60, gb_free=14, wall=38537
2023-07-08 18:43:11 | INFO | train_inner | epoch 036:    832 / 1474 loss=0.915, trans_loss=5.138, nll_loss=2.381, w2v_ctc_loss=0.264, task_loss=3.239, contrastive_loss=0.473, total=4178.14, n_correct=2816.2, ppl=5.21, accuracy=67.403, wps=6933, ups=1.66, wpb=4178.1, bsz=160.9, num_updates=52400, lr=6.17802e-05, gnorm=0.24, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=38597
2023-07-08 18:44:11 | INFO | train_inner | epoch 036:    932 / 1474 loss=0.902, trans_loss=5.112, nll_loss=2.347, w2v_ctc_loss=0.261, task_loss=3.486, contrastive_loss=0.123, total=4175.34, n_correct=2831.35, ppl=5.09, accuracy=67.811, wps=6891.5, ups=1.65, wpb=4175.3, bsz=152.7, num_updates=52500, lr=6.17213e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=60, gb_free=17.7, wall=38658
2023-07-08 18:45:11 | INFO | train_inner | epoch 036:   1032 / 1474 loss=0.906, trans_loss=5.118, nll_loss=2.354, w2v_ctc_loss=0.264, task_loss=3.552, contrastive_loss=0.116, total=4176.5, n_correct=2828.37, ppl=5.11, accuracy=67.721, wps=6941.2, ups=1.66, wpb=4176.5, bsz=150.8, num_updates=52600, lr=6.16626e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=38718
2023-07-08 18:46:11 | INFO | train_inner | epoch 036:   1132 / 1474 loss=0.902, trans_loss=5.111, nll_loss=2.346, w2v_ctc_loss=0.263, task_loss=3.448, contrastive_loss=0.147, total=4130.46, n_correct=2800.18, ppl=5.08, accuracy=67.793, wps=6888.3, ups=1.67, wpb=4130.5, bsz=153.3, num_updates=52700, lr=6.16041e-05, gnorm=0.24, clip=0, loss_scale=32, train_wall=60, gb_free=17.9, wall=38778
2023-07-08 18:47:12 | INFO | train_inner | epoch 036:   1232 / 1474 loss=0.902, trans_loss=5.121, nll_loss=2.357, w2v_ctc_loss=0.265, task_loss=3.846, contrastive_loss=0.107, total=4051.75, n_correct=2745.68, ppl=5.12, accuracy=67.765, wps=6701.7, ups=1.65, wpb=4051.8, bsz=140, num_updates=52800, lr=6.15457e-05, gnorm=0.243, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=38838
2023-07-08 18:48:12 | INFO | train_inner | epoch 036:   1332 / 1474 loss=0.901, trans_loss=5.118, nll_loss=2.355, w2v_ctc_loss=0.26, task_loss=3.455, contrastive_loss=0.128, total=4108.74, n_correct=2781.74, ppl=5.12, accuracy=67.703, wps=6799.6, ups=1.65, wpb=4108.7, bsz=152.6, num_updates=52900, lr=6.14875e-05, gnorm=0.239, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=38899
2023-07-08 18:49:12 | INFO | train_inner | epoch 036:   1432 / 1474 loss=0.911, trans_loss=5.138, nll_loss=2.38, w2v_ctc_loss=0.268, task_loss=3.887, contrastive_loss=0.232, total=4048.28, n_correct=2729.54, ppl=5.21, accuracy=67.425, wps=6720.6, ups=1.66, wpb=4048.3, bsz=139.4, num_updates=53000, lr=6.14295e-05, gnorm=0.245, clip=0, loss_scale=32, train_wall=60, gb_free=11.3, wall=38959
2023-07-08 18:49:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 18:50:05 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 1.462 | trans_loss 5.56 | nll_loss 2.833 | w2v_ctc_loss 0.476 | task_loss 4.66 | contrastive_loss 0.276 | total 4003.4 | n_correct 2496.9 | ppl 7.12 | accuracy 62.369 | uer 16.585 | wer 18.195 | raw_wer 18.195 | bleu 20.56 | wps 1911.6 | wpb 4003.4 | bsz 141.8 | num_updates 53042 | best_bleu 20.56
2023-07-08 18:50:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 53042 updates
2023-07-08 18:50:05 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 18:50:10 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-08 18:50:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 36 @ 53042 updates, score 20.56) (writing took 8.473694764994434 seconds)
2023-07-08 18:50:14 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-07-08 18:50:14 | INFO | train | epoch 036 | loss 0.904 | trans_loss 5.115 | nll_loss 2.35 | w2v_ctc_loss 0.262 | task_loss 3.452 | contrastive_loss 0.223 | total 4138.65 | n_correct 2806.26 | ppl 5.1 | accuracy 67.806 | wps 6302.3 | ups 1.52 | wpb 4138.6 | bsz 152.8 | num_updates 53042 | lr 6.14052e-05 | gnorm 0.24 | clip 0 | loss_scale 32 | train_wall 884 | gb_free 17 | wall 39021
2023-07-08 18:50:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 18:50:14 | INFO | fairseq.trainer | begin training epoch 37
2023-07-08 18:50:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 18:50:58 | INFO | train_inner | epoch 037:     58 / 1474 loss=0.897, trans_loss=5.096, nll_loss=2.326, w2v_ctc_loss=0.258, task_loss=3.457, contrastive_loss=0.14, total=4092.98, n_correct=2789.4, ppl=5.01, accuracy=68.151, wps=3885.8, ups=0.95, wpb=4093, bsz=150, num_updates=53100, lr=6.13716e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=60, gb_free=15.6, wall=39064
2023-07-08 18:51:58 | INFO | train_inner | epoch 037:    158 / 1474 loss=0.903, trans_loss=5.099, nll_loss=2.328, w2v_ctc_loss=0.258, task_loss=3.51, contrastive_loss=0.244, total=4124.56, n_correct=2810.76, ppl=5.02, accuracy=68.147, wps=6810.3, ups=1.65, wpb=4124.6, bsz=153.4, num_updates=53200, lr=6.13139e-05, gnorm=0.243, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=39125
2023-07-08 18:52:59 | INFO | train_inner | epoch 037:    258 / 1474 loss=0.892, trans_loss=5.084, nll_loss=2.31, w2v_ctc_loss=0.251, task_loss=3.234, contrastive_loss=0.131, total=4188.93, n_correct=2864.08, ppl=4.96, accuracy=68.373, wps=6948.6, ups=1.66, wpb=4188.9, bsz=159.7, num_updates=53300, lr=6.12564e-05, gnorm=0.238, clip=0, loss_scale=64, train_wall=60, gb_free=15.1, wall=39185
2023-07-08 18:53:59 | INFO | train_inner | epoch 037:    358 / 1474 loss=0.903, trans_loss=5.097, nll_loss=2.327, w2v_ctc_loss=0.261, task_loss=3.479, contrastive_loss=0.145, total=4171.05, n_correct=2843.32, ppl=5.02, accuracy=68.168, wps=6908.4, ups=1.66, wpb=4171.1, bsz=152.9, num_updates=53400, lr=6.1199e-05, gnorm=0.239, clip=0, loss_scale=64, train_wall=60, gb_free=16.1, wall=39245
2023-07-08 18:54:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-08 18:55:01 | INFO | train_inner | epoch 037:    459 / 1474 loss=0.912, trans_loss=5.118, nll_loss=2.354, w2v_ctc_loss=0.261, task_loss=3.415, contrastive_loss=0.439, total=4154.31, n_correct=2817.38, ppl=5.11, accuracy=67.818, wps=6684.3, ups=1.61, wpb=4154.3, bsz=154.7, num_updates=53500, lr=6.11418e-05, gnorm=0.244, clip=0, loss_scale=32, train_wall=62, gb_free=14.1, wall=39308
2023-07-08 18:56:01 | INFO | train_inner | epoch 037:    559 / 1474 loss=0.895, trans_loss=5.098, nll_loss=2.329, w2v_ctc_loss=0.259, task_loss=3.578, contrastive_loss=0.124, total=4092.13, n_correct=2787.33, ppl=5.03, accuracy=68.114, wps=6788.2, ups=1.66, wpb=4092.1, bsz=149.9, num_updates=53600, lr=6.10847e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=39368
2023-07-08 18:57:02 | INFO | train_inner | epoch 037:    659 / 1474 loss=0.902, trans_loss=5.114, nll_loss=2.349, w2v_ctc_loss=0.266, task_loss=3.628, contrastive_loss=0.141, total=4102.49, n_correct=2780.08, ppl=5.1, accuracy=67.766, wps=6790.3, ups=1.66, wpb=4102.5, bsz=146, num_updates=53700, lr=6.10278e-05, gnorm=0.241, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=39428
2023-07-08 18:58:02 | INFO | train_inner | epoch 037:    759 / 1474 loss=0.903, trans_loss=5.101, nll_loss=2.333, w2v_ctc_loss=0.258, task_loss=3.429, contrastive_loss=0.256, total=4123.95, n_correct=2806.13, ppl=5.04, accuracy=68.045, wps=6895.2, ups=1.67, wpb=4123.9, bsz=152.4, num_updates=53800, lr=6.09711e-05, gnorm=0.24, clip=0, loss_scale=32, train_wall=59, gb_free=16.9, wall=39488
2023-07-08 18:59:02 | INFO | train_inner | epoch 037:    859 / 1474 loss=0.895, trans_loss=5.095, nll_loss=2.326, w2v_ctc_loss=0.254, task_loss=3.254, contrastive_loss=0.126, total=4159.03, n_correct=2836.17, ppl=5.01, accuracy=68.193, wps=6952.2, ups=1.67, wpb=4159, bsz=157.9, num_updates=53900, lr=6.09145e-05, gnorm=0.239, clip=0, loss_scale=32, train_wall=59, gb_free=15.9, wall=39548
2023-07-08 19:00:02 | INFO | train_inner | epoch 037:    959 / 1474 loss=0.905, trans_loss=5.124, nll_loss=2.361, w2v_ctc_loss=0.265, task_loss=3.675, contrastive_loss=0.14, total=4097.89, n_correct=2774.35, ppl=5.14, accuracy=67.702, wps=6789.6, ups=1.66, wpb=4097.9, bsz=146.2, num_updates=54000, lr=6.08581e-05, gnorm=0.244, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=39608
2023-07-08 19:00:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 19:00:28 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 1.473 | trans_loss 5.558 | nll_loss 2.828 | w2v_ctc_loss 0.488 | task_loss 4.625 | contrastive_loss 0.269 | total 4003.4 | n_correct 2504.3 | ppl 7.1 | accuracy 62.554 | uer 16.426 | wer 18.176 | raw_wer 18.176 | bleu 20.35 | wps 1994.5 | wpb 4003.4 | bsz 141.8 | num_updates 54000 | best_bleu 20.56
2023-07-08 19:00:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54000 updates
2023-07-08 19:00:28 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_37_54000.pt
2023-07-08 19:00:30 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_37_54000.pt
2023-07-08 19:00:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_37_54000.pt (epoch 37 @ 54000 updates, score 20.35) (writing took 6.237721959987539 seconds)
2023-07-08 19:01:35 | INFO | train_inner | epoch 037:   1059 / 1474 loss=0.905, trans_loss=5.107, nll_loss=2.341, w2v_ctc_loss=0.257, task_loss=3.226, contrastive_loss=0.396, total=4162.64, n_correct=2829.75, ppl=5.07, accuracy=67.98, wps=4469.1, ups=1.07, wpb=4162.6, bsz=159.9, num_updates=54100, lr=6.08018e-05, gnorm=0.24, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=39701
2023-07-08 19:02:36 | INFO | train_inner | epoch 037:   1159 / 1474 loss=0.908, trans_loss=5.122, nll_loss=2.36, w2v_ctc_loss=0.259, task_loss=3.354, contrastive_loss=0.455, total=4176.35, n_correct=2825.77, ppl=5.13, accuracy=67.661, wps=6852.3, ups=1.64, wpb=4176.4, bsz=156.1, num_updates=54200, lr=6.07457e-05, gnorm=0.238, clip=0, loss_scale=32, train_wall=61, gb_free=16.2, wall=39762
2023-07-08 19:03:36 | INFO | train_inner | epoch 037:   1259 / 1474 loss=0.9, trans_loss=5.108, nll_loss=2.342, w2v_ctc_loss=0.258, task_loss=3.346, contrastive_loss=0.141, total=4167.2, n_correct=2830.47, ppl=5.07, accuracy=67.923, wps=6939.9, ups=1.67, wpb=4167.2, bsz=155.9, num_updates=54300, lr=6.06897e-05, gnorm=0.239, clip=0, loss_scale=32, train_wall=60, gb_free=16.2, wall=39822
2023-07-08 19:04:37 | INFO | train_inner | epoch 037:   1359 / 1474 loss=0.911, trans_loss=5.123, nll_loss=2.36, w2v_ctc_loss=0.272, task_loss=3.779, contrastive_loss=0.123, total=4072.63, n_correct=2753.11, ppl=5.13, accuracy=67.6, wps=6729.3, ups=1.65, wpb=4072.6, bsz=143, num_updates=54400, lr=6.06339e-05, gnorm=0.246, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=39883
2023-07-08 19:05:36 | INFO | train_inner | epoch 037:   1459 / 1474 loss=0.903, trans_loss=5.118, nll_loss=2.355, w2v_ctc_loss=0.261, task_loss=3.432, contrastive_loss=0.187, total=4155.97, n_correct=2817.14, ppl=5.11, accuracy=67.785, wps=6959.6, ups=1.67, wpb=4156, bsz=152.6, num_updates=54500, lr=6.05783e-05, gnorm=0.241, clip=0, loss_scale=32, train_wall=59, gb_free=16.3, wall=39943
2023-07-08 19:05:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 19:06:13 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 1.472 | trans_loss 5.558 | nll_loss 2.83 | w2v_ctc_loss 0.484 | task_loss 4.621 | contrastive_loss 0.269 | total 4003.4 | n_correct 2496.1 | ppl 7.11 | accuracy 62.35 | uer 16.712 | wer 18.486 | raw_wer 18.486 | bleu 20.26 | wps 1949.2 | wpb 4003.4 | bsz 141.8 | num_updates 54515 | best_bleu 20.56
2023-07-08 19:06:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54515 updates
2023-07-08 19:06:13 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.2608.pt
2023-07-08 19:06:15 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.2608.pt
2023-07-08 19:06:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.2608.pt (epoch 37 @ 54515 updates, score 20.26) (writing took 5.3187413639971055 seconds)
2023-07-08 19:06:18 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-07-08 19:06:18 | INFO | train | epoch 037 | loss 0.903 | trans_loss 5.107 | nll_loss 2.34 | w2v_ctc_loss 0.26 | task_loss 3.458 | contrastive_loss 0.216 | total 4136.85 | n_correct 2811.4 | ppl 5.06 | accuracy 67.96 | wps 6319.8 | ups 1.53 | wpb 4136.9 | bsz 152.5 | num_updates 54515 | lr 6.05699e-05 | gnorm 0.241 | clip 0 | loss_scale 32 | train_wall 884 | gb_free 13.3 | wall 39985
2023-07-08 19:06:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 19:06:19 | INFO | fairseq.trainer | begin training epoch 38
2023-07-08 19:06:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 19:07:18 | INFO | train_inner | epoch 038:     85 / 1474 loss=0.898, trans_loss=5.084, nll_loss=2.31, w2v_ctc_loss=0.257, task_loss=3.602, contrastive_loss=0.116, total=4085.19, n_correct=2792.42, ppl=4.96, accuracy=68.355, wps=4015.1, ups=0.98, wpb=4085.2, bsz=146.8, num_updates=54600, lr=6.05228e-05, gnorm=0.244, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=40044
2023-07-08 19:08:18 | INFO | train_inner | epoch 038:    185 / 1474 loss=0.895, trans_loss=5.089, nll_loss=2.316, w2v_ctc_loss=0.257, task_loss=3.628, contrastive_loss=0.122, total=4081.12, n_correct=2786.68, ppl=4.98, accuracy=68.282, wps=6762.5, ups=1.66, wpb=4081.1, bsz=146.3, num_updates=54700, lr=6.04674e-05, gnorm=0.237, clip=0, loss_scale=32, train_wall=60, gb_free=17, wall=40105
2023-07-08 19:09:19 | INFO | train_inner | epoch 038:    285 / 1474 loss=0.899, trans_loss=5.098, nll_loss=2.328, w2v_ctc_loss=0.26, task_loss=3.6, contrastive_loss=0.161, total=4073.75, n_correct=2775.04, ppl=5.02, accuracy=68.12, wps=6759.6, ups=1.66, wpb=4073.8, bsz=147.9, num_updates=54800, lr=6.04122e-05, gnorm=0.243, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=40165
2023-07-08 19:10:19 | INFO | train_inner | epoch 038:    385 / 1474 loss=0.898, trans_loss=5.094, nll_loss=2.323, w2v_ctc_loss=0.258, task_loss=3.412, contrastive_loss=0.161, total=4173.43, n_correct=2846.85, ppl=5, accuracy=68.214, wps=6928.4, ups=1.66, wpb=4173.4, bsz=154.1, num_updates=54900, lr=6.03572e-05, gnorm=0.245, clip=0, loss_scale=32, train_wall=60, gb_free=14.1, wall=40225
2023-07-08 19:11:19 | INFO | train_inner | epoch 038:    485 / 1474 loss=0.897, trans_loss=5.084, nll_loss=2.311, w2v_ctc_loss=0.255, task_loss=3.324, contrastive_loss=0.155, total=4192.03, n_correct=2862.17, ppl=4.96, accuracy=68.276, wps=6988.8, ups=1.67, wpb=4192, bsz=156, num_updates=55000, lr=6.03023e-05, gnorm=0.242, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=40285
tensor(0.0246, device='cuda:0')
tensor(0.0006, device='cuda:0')
2023-07-08 19:12:20 | INFO | train_inner | epoch 038:    585 / 1474 loss=0.911, trans_loss=5.114, nll_loss=2.35, w2v_ctc_loss=0.259, task_loss=3.436, contrastive_loss=0.492, total=4172.44, n_correct=2827.94, ppl=5.1, accuracy=67.777, wps=6836.6, ups=1.64, wpb=4172.4, bsz=154.4, num_updates=55100, lr=6.02475e-05, gnorm=0.245, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=40346
2023-07-08 19:13:21 | INFO | train_inner | epoch 038:    685 / 1474 loss=0.902, trans_loss=5.093, nll_loss=2.323, w2v_ctc_loss=0.256, task_loss=3.268, contrastive_loss=0.458, total=4179.22, n_correct=2848.42, ppl=5, accuracy=68.157, wps=6855.1, ups=1.64, wpb=4179.2, bsz=161.2, num_updates=55200, lr=6.01929e-05, gnorm=0.24, clip=0, loss_scale=32, train_wall=61, gb_free=13.4, wall=40407
2023-07-08 19:14:21 | INFO | train_inner | epoch 038:    785 / 1474 loss=0.901, trans_loss=5.09, nll_loss=2.318, w2v_ctc_loss=0.255, task_loss=3.172, contrastive_loss=0.303, total=4180.46, n_correct=2855.61, ppl=4.99, accuracy=68.309, wps=6903.8, ups=1.65, wpb=4180.5, bsz=162.9, num_updates=55300, lr=6.01385e-05, gnorm=0.241, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=40468
2023-07-08 19:15:21 | INFO | train_inner | epoch 038:    885 / 1474 loss=0.892, trans_loss=5.09, nll_loss=2.319, w2v_ctc_loss=0.257, task_loss=3.285, contrastive_loss=0.128, total=4122.77, n_correct=2810.57, ppl=4.99, accuracy=68.172, wps=6868.1, ups=1.67, wpb=4122.8, bsz=155.9, num_updates=55400, lr=6.00842e-05, gnorm=0.24, clip=0, loss_scale=32, train_wall=60, gb_free=15.7, wall=40528
2023-07-08 19:16:22 | INFO | train_inner | epoch 038:    985 / 1474 loss=0.899, trans_loss=5.114, nll_loss=2.349, w2v_ctc_loss=0.259, task_loss=3.471, contrastive_loss=0.194, total=4116.2, n_correct=2792, ppl=5.09, accuracy=67.83, wps=6832, ups=1.66, wpb=4116.2, bsz=150.8, num_updates=55500, lr=6.003e-05, gnorm=0.236, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=40588
2023-07-08 19:17:22 | INFO | train_inner | epoch 038:   1085 / 1474 loss=0.906, trans_loss=5.104, nll_loss=2.338, w2v_ctc_loss=0.261, task_loss=3.144, contrastive_loss=0.257, total=4248.59, n_correct=2889.47, ppl=5.06, accuracy=68.01, wps=7040.6, ups=1.66, wpb=4248.6, bsz=164.4, num_updates=55600, lr=5.9976e-05, gnorm=0.241, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=40648
2023-07-08 19:18:23 | INFO | train_inner | epoch 038:   1185 / 1474 loss=0.905, trans_loss=5.117, nll_loss=2.354, w2v_ctc_loss=0.265, task_loss=3.785, contrastive_loss=0.136, total=4077.59, n_correct=2760.07, ppl=5.11, accuracy=67.689, wps=6711.3, ups=1.65, wpb=4077.6, bsz=143.7, num_updates=55700, lr=5.99222e-05, gnorm=0.244, clip=0, loss_scale=64, train_wall=60, gb_free=14.3, wall=40709
2023-07-08 19:19:24 | INFO | train_inner | epoch 038:   1285 / 1474 loss=0.908, trans_loss=5.115, nll_loss=2.35, w2v_ctc_loss=0.26, task_loss=3.669, contrastive_loss=0.131, total=4146.3, n_correct=2814.03, ppl=5.1, accuracy=67.868, wps=6799.1, ups=1.64, wpb=4146.3, bsz=147.8, num_updates=55800, lr=5.98684e-05, gnorm=0.239, clip=0, loss_scale=64, train_wall=61, gb_free=17.7, wall=40770
2023-07-08 19:20:25 | INFO | train_inner | epoch 038:   1385 / 1474 loss=0.906, trans_loss=5.114, nll_loss=2.35, w2v_ctc_loss=0.262, task_loss=3.405, contrastive_loss=0.235, total=4156.39, n_correct=2820.56, ppl=5.1, accuracy=67.861, wps=6839.7, ups=1.65, wpb=4156.4, bsz=155.3, num_updates=55900, lr=5.98149e-05, gnorm=0.24, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=40831
2023-07-08 19:21:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0246, device='cuda:6')
tensor(0.0006, device='cuda:6')
tensor(0.0246, device='cuda:1')
tensor(0.0006, device='cuda:1')
tensor(0.0246, device='cuda:7')
tensor(0.0006, device='cuda:7')
tensor(0.0246, device='cuda:4')
tensor(0.0006, device='cuda:4')
tensor(0.0246, device='cuda:5')
tensor(0.0006, device='cuda:5')
tensor(0.0246, device='cuda:3')
tensor(0.0006, device='cuda:3')
tensor(0.0246, device='cuda:2')
tensor(0.0006, device='cuda:2')
2023-07-08 19:21:45 | INFO | dev_st | epoch 038 | valid on 'dev_st' subset | loss 1.468 | trans_loss 5.562 | nll_loss 2.837 | w2v_ctc_loss 0.482 | task_loss 4.628 | contrastive_loss 0.274 | total 4003.4 | n_correct 2501.1 | ppl 7.15 | accuracy 62.474 | uer 16.67 | wer 18.392 | raw_wer 18.392 | bleu 20.32 | wps 2071.3 | wpb 4003.4 | bsz 141.8 | num_updates 55989 | best_bleu 20.56
2023-07-08 19:21:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 55989 updates
2023-07-08 19:21:45 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.3203.pt
2023-07-08 19:21:49 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.3203.pt
2023-07-08 19:21:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.3203.pt (epoch 38 @ 55989 updates, score 20.32) (writing took 6.992949060993851 seconds)
2023-07-08 19:21:52 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-07-08 19:21:52 | INFO | train | epoch 038 | loss 0.901 | trans_loss 5.101 | nll_loss 2.332 | w2v_ctc_loss 0.259 | task_loss 3.451 | contrastive_loss 0.224 | total 4138.65 | n_correct 2816.28 | ppl 5.04 | accuracy 68.048 | wps 6532.3 | ups 1.58 | wpb 4138.6 | bsz 152.8 | num_updates 55989 | lr 5.97673e-05 | gnorm 0.241 | clip 0 | loss_scale 64 | train_wall 886 | gb_free 16.8 | wall 40919
2023-07-08 19:21:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 19:21:52 | INFO | fairseq.trainer | begin training epoch 39
2023-07-08 19:21:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 19:22:07 | INFO | train_inner | epoch 039:     11 / 1474 loss=0.906, trans_loss=5.118, nll_loss=2.354, w2v_ctc_loss=0.264, task_loss=3.712, contrastive_loss=0.254, total=4033.2, n_correct=2732.06, ppl=5.11, accuracy=67.739, wps=3943.7, ups=0.98, wpb=4033.2, bsz=142.9, num_updates=56000, lr=5.97614e-05, gnorm=0.246, clip=0, loss_scale=64, train_wall=60, gb_free=17.5, wall=40933
2023-07-08 19:22:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 19:22:34 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 1.471 | trans_loss 5.56 | nll_loss 2.831 | w2v_ctc_loss 0.479 | task_loss 4.616 | contrastive_loss 0.271 | total 4003.4 | n_correct 2500.5 | ppl 7.12 | accuracy 62.459 | uer 16.518 | wer 18.336 | raw_wer 18.336 | bleu 20.32 | wps 1920.4 | wpb 4003.4 | bsz 141.8 | num_updates 56000 | best_bleu 20.56
2023-07-08 19:22:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 56000 updates
2023-07-08 19:22:34 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_39_56000.pt
2023-07-08 19:22:36 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_39_56000.pt
2023-07-08 19:22:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_39_56000.pt (epoch 39 @ 56000 updates, score 20.32) (writing took 6.305565024988027 seconds)
2023-07-08 19:23:40 | INFO | train_inner | epoch 039:    111 / 1474 loss=0.896, trans_loss=5.074, nll_loss=2.296, w2v_ctc_loss=0.258, task_loss=3.674, contrastive_loss=0.12, total=4057.77, n_correct=2777.95, ppl=4.91, accuracy=68.46, wps=4356.3, ups=1.07, wpb=4057.8, bsz=143.2, num_updates=56100, lr=5.97081e-05, gnorm=0.241, clip=0, loss_scale=64, train_wall=59, gb_free=17.5, wall=41026
2023-07-08 19:24:40 | INFO | train_inner | epoch 039:    211 / 1474 loss=0.895, trans_loss=5.07, nll_loss=2.292, w2v_ctc_loss=0.256, task_loss=3.513, contrastive_loss=0.119, total=4134.99, n_correct=2833.04, ppl=4.9, accuracy=68.514, wps=6891.8, ups=1.67, wpb=4135, bsz=150.2, num_updates=56200, lr=5.9655e-05, gnorm=0.241, clip=0, loss_scale=64, train_wall=60, gb_free=15.9, wall=41086
2023-07-08 19:25:40 | INFO | train_inner | epoch 039:    311 / 1474 loss=0.894, trans_loss=5.075, nll_loss=2.298, w2v_ctc_loss=0.257, task_loss=3.522, contrastive_loss=0.129, total=4135.88, n_correct=2833.38, ppl=4.92, accuracy=68.507, wps=6892.5, ups=1.67, wpb=4135.9, bsz=149.8, num_updates=56300, lr=5.9602e-05, gnorm=0.241, clip=0, loss_scale=64, train_wall=60, gb_free=13.4, wall=41146
2023-07-08 19:26:41 | INFO | train_inner | epoch 039:    411 / 1474 loss=0.903, trans_loss=5.084, nll_loss=2.31, w2v_ctc_loss=0.256, task_loss=3.41, contrastive_loss=0.423, total=4128.52, n_correct=2820.35, ppl=4.96, accuracy=68.314, wps=6757.8, ups=1.64, wpb=4128.5, bsz=156.1, num_updates=56400, lr=5.95491e-05, gnorm=0.242, clip=0, loss_scale=64, train_wall=61, gb_free=13, wall=41207
2023-07-08 19:27:42 | INFO | train_inner | epoch 039:    511 / 1474 loss=0.902, trans_loss=5.093, nll_loss=2.322, w2v_ctc_loss=0.257, task_loss=3.394, contrastive_loss=0.444, total=4143.39, n_correct=2821.81, ppl=5, accuracy=68.104, wps=6801.1, ups=1.64, wpb=4143.4, bsz=155.8, num_updates=56500, lr=5.94964e-05, gnorm=0.242, clip=0, loss_scale=64, train_wall=61, gb_free=17, wall=41268
2023-07-08 19:28:42 | INFO | train_inner | epoch 039:    611 / 1474 loss=0.9, trans_loss=5.094, nll_loss=2.324, w2v_ctc_loss=0.256, task_loss=3.509, contrastive_loss=0.234, total=4131.41, n_correct=2818.15, ppl=5.01, accuracy=68.213, wps=6837.8, ups=1.66, wpb=4131.4, bsz=151.4, num_updates=56600, lr=5.94438e-05, gnorm=0.239, clip=0, loss_scale=64, train_wall=60, gb_free=16, wall=41329
2023-07-08 19:29:42 | INFO | train_inner | epoch 039:    711 / 1474 loss=0.9, trans_loss=5.1, nll_loss=2.331, w2v_ctc_loss=0.256, task_loss=3.356, contrastive_loss=0.222, total=4133.78, n_correct=2814.9, ppl=5.03, accuracy=68.095, wps=6967, ups=1.69, wpb=4133.8, bsz=152.9, num_updates=56700, lr=5.93914e-05, gnorm=0.239, clip=0, loss_scale=64, train_wall=59, gb_free=16.2, wall=41388
2023-07-08 19:30:43 | INFO | train_inner | epoch 039:    811 / 1474 loss=0.898, trans_loss=5.096, nll_loss=2.326, w2v_ctc_loss=0.259, task_loss=3.461, contrastive_loss=0.145, total=4178.43, n_correct=2841.48, ppl=5.01, accuracy=68.004, wps=6860, ups=1.64, wpb=4178.4, bsz=154.9, num_updates=56800, lr=5.93391e-05, gnorm=0.243, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=41449
2023-07-08 19:31:42 | INFO | train_inner | epoch 039:    911 / 1474 loss=0.897, trans_loss=5.093, nll_loss=2.323, w2v_ctc_loss=0.257, task_loss=3.568, contrastive_loss=0.152, total=4125.39, n_correct=2811.16, ppl=5, accuracy=68.143, wps=6910.7, ups=1.68, wpb=4125.4, bsz=149.5, num_updates=56900, lr=5.92869e-05, gnorm=0.24, clip=0, loss_scale=64, train_wall=59, gb_free=17, wall=41509
2023-07-08 19:32:44 | INFO | train_inner | epoch 039:   1011 / 1474 loss=0.906, trans_loss=5.11, nll_loss=2.344, w2v_ctc_loss=0.258, task_loss=3.377, contrastive_loss=0.372, total=4198.7, n_correct=2850.89, ppl=5.08, accuracy=67.899, wps=6854, ups=1.63, wpb=4198.7, bsz=159.7, num_updates=57000, lr=5.92349e-05, gnorm=0.241, clip=0, loss_scale=64, train_wall=61, gb_free=16.2, wall=41570
2023-07-08 19:33:44 | INFO | train_inner | epoch 039:   1111 / 1474 loss=0.9, trans_loss=5.09, nll_loss=2.319, w2v_ctc_loss=0.256, task_loss=3.243, contrastive_loss=0.319, total=4194.7, n_correct=2859.75, ppl=4.99, accuracy=68.175, wps=6953.8, ups=1.66, wpb=4194.7, bsz=160.9, num_updates=57100, lr=5.9183e-05, gnorm=0.239, clip=0, loss_scale=64, train_wall=60, gb_free=15.7, wall=41630
2023-07-08 19:34:44 | INFO | train_inner | epoch 039:   1211 / 1474 loss=0.9, trans_loss=5.104, nll_loss=2.337, w2v_ctc_loss=0.259, task_loss=3.465, contrastive_loss=0.208, total=4123.07, n_correct=2802.63, ppl=5.05, accuracy=67.974, wps=6857.6, ups=1.66, wpb=4123.1, bsz=153.6, num_updates=57200, lr=5.91312e-05, gnorm=0.24, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=41691
2023-07-08 19:35:44 | INFO | train_inner | epoch 039:   1311 / 1474 loss=0.901, trans_loss=5.099, nll_loss=2.331, w2v_ctc_loss=0.258, task_loss=3.276, contrastive_loss=0.177, total=4183.27, n_correct=2847.96, ppl=5.03, accuracy=68.08, wps=6987.7, ups=1.67, wpb=4183.3, bsz=158.8, num_updates=57300, lr=5.90796e-05, gnorm=0.239, clip=0, loss_scale=64, train_wall=59, gb_free=17.2, wall=41750
2023-07-08 19:36:44 | INFO | train_inner | epoch 039:   1411 / 1474 loss=0.899, trans_loss=5.103, nll_loss=2.335, w2v_ctc_loss=0.259, task_loss=3.8, contrastive_loss=0.109, total=4052.15, n_correct=2751.55, ppl=5.05, accuracy=67.903, wps=6752.2, ups=1.67, wpb=4052.2, bsz=139.3, num_updates=57400, lr=5.90281e-05, gnorm=0.244, clip=0, loss_scale=64, train_wall=60, gb_free=13.3, wall=41810
2023-07-08 19:37:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 19:37:48 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 1.47 | trans_loss 5.558 | nll_loss 2.829 | w2v_ctc_loss 0.48 | task_loss 4.621 | contrastive_loss 0.277 | total 4003.4 | n_correct 2497.2 | ppl 7.11 | accuracy 62.377 | uer 16.441 | wer 18.131 | raw_wer 18.131 | bleu 20.21 | wps 2017.3 | wpb 4003.4 | bsz 141.8 | num_updates 57463 | best_bleu 20.56
2023-07-08 19:37:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 57463 updates
2023-07-08 19:37:48 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-08 19:37:52 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-08 19:37:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt (epoch 39 @ 57463 updates, score 20.21) (writing took 4.256631828000536 seconds)
2023-07-08 19:37:52 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-07-08 19:37:52 | INFO | train | epoch 039 | loss 0.899 | trans_loss 5.092 | nll_loss 2.321 | w2v_ctc_loss 0.257 | task_loss 3.453 | contrastive_loss 0.226 | total 4138.65 | n_correct 2821.09 | ppl 5 | accuracy 68.165 | wps 6355.6 | ups 1.54 | wpb 4138.6 | bsz 152.8 | num_updates 57463 | lr 5.89958e-05 | gnorm 0.241 | clip 0 | loss_scale 64 | train_wall 882 | gb_free 15.7 | wall 41878
2023-07-08 19:37:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 19:37:52 | INFO | fairseq.trainer | begin training epoch 40
2023-07-08 19:37:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 19:38:23 | INFO | train_inner | epoch 040:     37 / 1474 loss=0.898, trans_loss=5.09, nll_loss=2.319, w2v_ctc_loss=0.252, task_loss=3.318, contrastive_loss=0.153, total=4171.45, n_correct=2843.95, ppl=4.99, accuracy=68.177, wps=4224.2, ups=1.01, wpb=4171.4, bsz=156.1, num_updates=57500, lr=5.89768e-05, gnorm=0.24, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=41909
2023-07-08 19:39:24 | INFO | train_inner | epoch 040:    137 / 1474 loss=0.897, trans_loss=5.058, nll_loss=2.276, w2v_ctc_loss=0.255, task_loss=3.446, contrastive_loss=0.137, total=4150.33, n_correct=2858.57, ppl=4.84, accuracy=68.876, wps=6827.9, ups=1.65, wpb=4150.3, bsz=152.4, num_updates=57600, lr=5.89256e-05, gnorm=0.238, clip=0, loss_scale=128, train_wall=60, gb_free=16.2, wall=41970
2023-07-08 19:40:23 | INFO | train_inner | epoch 040:    237 / 1474 loss=0.892, trans_loss=5.072, nll_loss=2.295, w2v_ctc_loss=0.256, task_loss=3.521, contrastive_loss=0.137, total=4101.56, n_correct=2810.26, ppl=4.91, accuracy=68.517, wps=6862.9, ups=1.67, wpb=4101.6, bsz=150.4, num_updates=57700, lr=5.88745e-05, gnorm=0.242, clip=0, loss_scale=128, train_wall=59, gb_free=12.9, wall=42030
2023-07-08 19:41:23 | INFO | train_inner | epoch 040:    337 / 1474 loss=0.889, trans_loss=5.071, nll_loss=2.294, w2v_ctc_loss=0.251, task_loss=3.232, contrastive_loss=0.158, total=4153.24, n_correct=2849.29, ppl=4.91, accuracy=68.604, wps=6939.4, ups=1.67, wpb=4153.2, bsz=159.4, num_updates=57800, lr=5.88235e-05, gnorm=0.239, clip=0, loss_scale=128, train_wall=59, gb_free=17.1, wall=42090
2023-07-08 19:42:23 | INFO | train_inner | epoch 040:    437 / 1474 loss=0.901, trans_loss=5.084, nll_loss=2.311, w2v_ctc_loss=0.256, task_loss=3.454, contrastive_loss=0.309, total=4138.54, n_correct=2829.26, ppl=4.96, accuracy=68.364, wps=6865.7, ups=1.66, wpb=4138.5, bsz=154.4, num_updates=57900, lr=5.87727e-05, gnorm=0.241, clip=0, loss_scale=128, train_wall=60, gb_free=15.9, wall=42150
2023-07-08 19:43:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-08 19:43:25 | INFO | train_inner | epoch 040:    538 / 1474 loss=0.89, trans_loss=5.068, nll_loss=2.289, w2v_ctc_loss=0.251, task_loss=3.423, contrastive_loss=0.142, total=4144.53, n_correct=2845.4, ppl=4.89, accuracy=68.654, wps=6777.3, ups=1.64, wpb=4144.5, bsz=154.7, num_updates=58000, lr=5.8722e-05, gnorm=0.239, clip=0, loss_scale=64, train_wall=61, gb_free=16.4, wall=42211
2023-07-08 19:43:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 19:43:51 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 1.473 | trans_loss 5.566 | nll_loss 2.839 | w2v_ctc_loss 0.495 | task_loss 4.626 | contrastive_loss 0.274 | total 4003.4 | n_correct 2495.6 | ppl 7.16 | accuracy 62.337 | uer 16.587 | wer 18.325 | raw_wer 18.325 | bleu 20.03 | wps 2008 | wpb 4003.4 | bsz 141.8 | num_updates 58000 | best_bleu 20.56
2023-07-08 19:43:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58000 updates
2023-07-08 19:43:51 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_40_58000.pt
2023-07-08 19:43:53 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_40_58000.pt
2023-07-08 19:43:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_40_58000.pt (epoch 40 @ 58000 updates, score 20.03) (writing took 5.093720122007653 seconds)
2023-07-08 19:44:56 | INFO | train_inner | epoch 040:    638 / 1474 loss=0.898, trans_loss=5.091, nll_loss=2.319, w2v_ctc_loss=0.26, task_loss=3.588, contrastive_loss=0.163, total=4118.6, n_correct=2806.37, ppl=4.99, accuracy=68.139, wps=4491.9, ups=1.09, wpb=4118.6, bsz=149.2, num_updates=58100, lr=5.86715e-05, gnorm=0.241, clip=0, loss_scale=64, train_wall=60, gb_free=12.7, wall=42303
2023-07-08 19:45:56 | INFO | train_inner | epoch 040:    738 / 1474 loss=0.894, trans_loss=5.08, nll_loss=2.305, w2v_ctc_loss=0.254, task_loss=3.342, contrastive_loss=0.122, total=4137.91, n_correct=2828.83, ppl=4.94, accuracy=68.364, wps=6907.8, ups=1.67, wpb=4137.9, bsz=154.2, num_updates=58200, lr=5.8621e-05, gnorm=0.239, clip=0, loss_scale=64, train_wall=59, gb_free=16.4, wall=42363
2023-07-08 19:46:57 | INFO | train_inner | epoch 040:    838 / 1474 loss=0.9, trans_loss=5.091, nll_loss=2.322, w2v_ctc_loss=0.252, task_loss=3.133, contrastive_loss=0.541, total=4214.92, n_correct=2875.9, ppl=5, accuracy=68.231, wps=6926.6, ups=1.64, wpb=4214.9, bsz=164.6, num_updates=58300, lr=5.85707e-05, gnorm=0.241, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=42423
2023-07-08 19:47:57 | INFO | train_inner | epoch 040:    938 / 1474 loss=0.898, trans_loss=5.091, nll_loss=2.318, w2v_ctc_loss=0.258, task_loss=3.633, contrastive_loss=0.172, total=4092.24, n_correct=2789.31, ppl=4.99, accuracy=68.161, wps=6788.5, ups=1.66, wpb=4092.2, bsz=146.8, num_updates=58400, lr=5.85206e-05, gnorm=0.243, clip=0, loss_scale=64, train_wall=60, gb_free=15.2, wall=42484
2023-07-08 19:48:58 | INFO | train_inner | epoch 040:   1038 / 1474 loss=0.907, trans_loss=5.106, nll_loss=2.338, w2v_ctc_loss=0.26, task_loss=3.735, contrastive_loss=0.212, total=4119.93, n_correct=2800.42, ppl=5.06, accuracy=67.973, wps=6811.1, ups=1.65, wpb=4119.9, bsz=143.8, num_updates=58500, lr=5.84705e-05, gnorm=0.246, clip=0, loss_scale=64, train_wall=60, gb_free=16, wall=42544
2023-07-08 19:49:58 | INFO | train_inner | epoch 040:   1138 / 1474 loss=0.898, trans_loss=5.099, nll_loss=2.33, w2v_ctc_loss=0.258, task_loss=3.599, contrastive_loss=0.145, total=4124.74, n_correct=2807.88, ppl=5.03, accuracy=68.074, wps=6819, ups=1.65, wpb=4124.7, bsz=149.2, num_updates=58600, lr=5.84206e-05, gnorm=0.245, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=42605
2023-07-08 19:50:59 | INFO | train_inner | epoch 040:   1238 / 1474 loss=0.9, trans_loss=5.088, nll_loss=2.316, w2v_ctc_loss=0.254, task_loss=3.394, contrastive_loss=0.267, total=4198.52, n_correct=2868.69, ppl=4.98, accuracy=68.326, wps=6915.8, ups=1.65, wpb=4198.5, bsz=155.4, num_updates=58700, lr=5.83708e-05, gnorm=0.237, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=42665
2023-07-08 19:51:59 | INFO | train_inner | epoch 040:   1338 / 1474 loss=0.9, trans_loss=5.092, nll_loss=2.321, w2v_ctc_loss=0.254, task_loss=3.473, contrastive_loss=0.277, total=4124.38, n_correct=2813.1, ppl=5, accuracy=68.207, wps=6839.4, ups=1.66, wpb=4124.4, bsz=153, num_updates=58800, lr=5.83212e-05, gnorm=0.24, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=42726
2023-07-08 19:53:00 | INFO | train_inner | epoch 040:   1438 / 1474 loss=0.903, trans_loss=5.1, nll_loss=2.332, w2v_ctc_loss=0.258, task_loss=3.458, contrastive_loss=0.208, total=4121.8, n_correct=2805.14, ppl=5.03, accuracy=68.056, wps=6822.4, ups=1.66, wpb=4121.8, bsz=152.2, num_updates=58900, lr=5.82717e-05, gnorm=0.242, clip=0, loss_scale=64, train_wall=60, gb_free=15.8, wall=42786
2023-07-08 19:53:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 19:53:47 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 1.471 | trans_loss 5.557 | nll_loss 2.827 | w2v_ctc_loss 0.498 | task_loss 4.657 | contrastive_loss 0.281 | total 4003.4 | n_correct 2499.1 | ppl 7.1 | accuracy 62.424 | uer 16.672 | wer 18.34 | raw_wer 18.34 | bleu 19.9 | wps 2077.7 | wpb 4003.4 | bsz 141.8 | num_updates 58936 | best_bleu 20.56
2023-07-08 19:53:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58936 updates
2023-07-08 19:53:47 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-08 19:53:51 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-08 19:53:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt (epoch 40 @ 58936 updates, score 19.9) (writing took 4.20778578100726 seconds)
2023-07-08 19:53:51 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-07-08 19:53:51 | INFO | train | epoch 040 | loss 0.897 | trans_loss 5.085 | nll_loss 2.311 | w2v_ctc_loss 0.255 | task_loss 3.459 | contrastive_loss 0.211 | total 4136.58 | n_correct 2826.39 | ppl 4.96 | accuracy 68.327 | wps 6353.4 | ups 1.54 | wpb 4136.6 | bsz 152.5 | num_updates 58936 | lr 5.82539e-05 | gnorm 0.241 | clip 0 | loss_scale 64 | train_wall 884 | gb_free 16 | wall 42838
2023-07-08 19:53:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-08 19:53:51 | INFO | fairseq.trainer | begin training epoch 41
2023-07-08 19:53:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-08 19:54:38 | INFO | train_inner | epoch 041:     64 / 1474 loss=0.896, trans_loss=5.077, nll_loss=2.302, w2v_ctc_loss=0.254, task_loss=3.588, contrastive_loss=0.15, total=4088.95, n_correct=2796.98, ppl=4.93, accuracy=68.403, wps=4173.3, ups=1.02, wpb=4089, bsz=147.8, num_updates=59000, lr=5.82223e-05, gnorm=0.241, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=42884
2023-07-08 19:55:38 | INFO | train_inner | epoch 041:    164 / 1474 loss=0.892, trans_loss=5.054, nll_loss=2.272, w2v_ctc_loss=0.248, task_loss=3.347, contrastive_loss=0.257, total=4141.51, n_correct=2849.17, ppl=4.83, accuracy=68.795, wps=6869.9, ups=1.66, wpb=4141.5, bsz=155.7, num_updates=59100, lr=5.8173e-05, gnorm=0.239, clip=0, loss_scale=64, train_wall=60, gb_free=16, wall=42944
2023-07-08 19:56:38 | INFO | train_inner | epoch 041:    264 / 1474 loss=0.897, trans_loss=5.065, nll_loss=2.287, w2v_ctc_loss=0.251, task_loss=3.208, contrastive_loss=0.244, total=4181.72, n_correct=2873.36, ppl=4.88, accuracy=68.712, wps=7028.3, ups=1.68, wpb=4181.7, bsz=159.6, num_updates=59200, lr=5.81238e-05, gnorm=0.24, clip=0, loss_scale=64, train_wall=59, gb_free=16.5, wall=43004
2023-07-08 19:57:38 | INFO | train_inner | epoch 041:    364 / 1474 loss=0.894, trans_loss=5.073, nll_loss=2.297, w2v_ctc_loss=0.256, task_loss=3.452, contrastive_loss=0.161, total=4147.02, n_correct=2840.94, ppl=4.91, accuracy=68.506, wps=6831.8, ups=1.65, wpb=4147, bsz=152.5, num_updates=59300, lr=5.80748e-05, gnorm=0.243, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=43065
2023-07-08 19:58:38 | INFO | train_inner | epoch 041:    464 / 1474 loss=0.889, trans_loss=5.067, nll_loss=2.287, w2v_ctc_loss=0.251, task_loss=3.48, contrastive_loss=0.129, total=4144.36, n_correct=2843.32, ppl=4.88, accuracy=68.607, wps=6879.2, ups=1.66, wpb=4144.4, bsz=151.4, num_updates=59400, lr=5.80259e-05, gnorm=0.239, clip=0, loss_scale=64, train_wall=60, gb_free=16.1, wall=43125
2023-07-08 19:59:39 | INFO | train_inner | epoch 041:    564 / 1474 loss=0.895, trans_loss=5.073, nll_loss=2.295, w2v_ctc_loss=0.254, task_loss=3.455, contrastive_loss=0.163, total=4145.19, n_correct=2842.76, ppl=4.91, accuracy=68.58, wps=6881, ups=1.66, wpb=4145.2, bsz=153.6, num_updates=59500, lr=5.79771e-05, gnorm=0.24, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=43185
2023-07-08 20:00:39 | INFO | train_inner | epoch 041:    664 / 1474 loss=0.891, trans_loss=5.062, nll_loss=2.281, w2v_ctc_loss=0.249, task_loss=3.247, contrastive_loss=0.134, total=4189.74, n_correct=2880.97, ppl=4.86, accuracy=68.763, wps=6996.1, ups=1.67, wpb=4189.7, bsz=159, num_updates=59600, lr=5.79284e-05, gnorm=0.241, clip=0, loss_scale=64, train_wall=59, gb_free=16.6, wall=43245
2023-07-08 20:01:39 | INFO | train_inner | epoch 041:    764 / 1474 loss=0.894, trans_loss=5.074, nll_loss=2.298, w2v_ctc_loss=0.252, task_loss=3.491, contrastive_loss=0.127, total=4150.75, n_correct=2839.9, ppl=4.92, accuracy=68.419, wps=6878.8, ups=1.66, wpb=4150.8, bsz=150.4, num_updates=59700, lr=5.78799e-05, gnorm=0.24, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=43305
2023-07-08 20:02:39 | INFO | train_inner | epoch 041:    864 / 1474 loss=0.893, trans_loss=5.07, nll_loss=2.291, w2v_ctc_loss=0.251, task_loss=3.58, contrastive_loss=0.129, total=4108.1, n_correct=2816.65, ppl=4.89, accuracy=68.563, wps=6858.9, ups=1.67, wpb=4108.1, bsz=147.9, num_updates=59800, lr=5.78315e-05, gnorm=0.241, clip=0, loss_scale=64, train_wall=59, gb_free=16.9, wall=43365
2023-07-08 20:03:40 | INFO | train_inner | epoch 041:    964 / 1474 loss=0.903, trans_loss=5.093, nll_loss=2.321, w2v_ctc_loss=0.261, task_loss=3.583, contrastive_loss=0.312, total=4122.2, n_correct=2807.89, ppl=5, accuracy=68.116, wps=6762.6, ups=1.64, wpb=4122.2, bsz=149.6, num_updates=59900, lr=5.77832e-05, gnorm=0.247, clip=0, loss_scale=64, train_wall=61, gb_free=15.2, wall=43426
2023-07-08 20:04:40 | INFO | train_inner | epoch 041:   1064 / 1474 loss=0.896, trans_loss=5.089, nll_loss=2.317, w2v_ctc_loss=0.253, task_loss=3.433, contrastive_loss=0.14, total=4133.83, n_correct=2821.55, ppl=4.98, accuracy=68.255, wps=6888.1, ups=1.67, wpb=4133.8, bsz=152, num_updates=60000, lr=5.7735e-05, gnorm=0.244, clip=0, loss_scale=64, train_wall=60, gb_free=12.8, wall=43486
2023-07-08 20:04:40 | INFO | fairseq_cli.train | Stopping training due to num_updates: 60000 >= max_update: 60000
2023-07-08 20:04:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-08 20:05:05 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 1.477 | trans_loss 5.559 | nll_loss 2.835 | w2v_ctc_loss 0.489 | task_loss 4.609 | contrastive_loss 0.28 | total 4003.4 | n_correct 2494.3 | ppl 7.14 | accuracy 62.305 | uer 16.59 | wer 18.277 | raw_wer 18.277 | bleu 19.92 | wps 2083.6 | wpb 4003.4 | bsz 141.8 | num_updates 60000 | best_bleu 20.56
2023-07-08 20:05:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 60000 updates
2023-07-08 20:05:05 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_41_60000.pt
2023-07-08 20:05:07 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_41_60000.pt
2023-07-08 20:05:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_41_60000.pt (epoch 41 @ 60000 updates, score 19.92) (writing took 5.0441522280016216 seconds)
2023-07-08 20:05:10 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-07-08 20:05:10 | INFO | train | epoch 041 | loss 0.895 | trans_loss 5.072 | nll_loss 2.294 | w2v_ctc_loss 0.253 | task_loss 3.433 | contrastive_loss 0.179 | total 4144.26 | n_correct 2840.16 | ppl 4.91 | accuracy 68.532 | wps 6490.7 | ups 1.57 | wpb 4144.3 | bsz 153 | num_updates 60000 | lr 5.7735e-05 | gnorm 0.241 | clip 0 | loss_scale 64 | train_wall 636 | gb_free 12.8 | wall 43517
2023-07-08 20:05:10 | INFO | fairseq_cli.train | done training in 43446.8 seconds
/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1776 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
