Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 27, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
2023-07-31 11:33:14 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:14552
2023-07-31 11:33:14 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:14552
2023-07-31 11:33:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-31 11:33:14 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:14552
2023-07-31 11:33:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-31 11:33:14 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:14552
2023-07-31 11:33:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-31 11:33:14 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:14552
2023-07-31 11:33:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-31 11:33:14 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:14552
2023-07-31 11:33:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-31 11:33:14 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:14552
2023-07-31 11:33:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-31 11:33:14 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:14552
2023-07-31 11:33:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-31 11:33:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-31 11:33:14 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-31 11:33:14 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-07-31 11:33:14 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-31 11:33:14 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-07-31 11:33:14 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-31 11:33:14 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-31 11:33:14 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-31 11:33:14 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-07-31 11:33:14 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-07-31 11:33:14 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-07-31 11:33:14 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-31 11:33:14 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-31 11:33:14 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-07-31 11:33:14 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-07-31 11:33:14 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-31 11:33:14 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-07-31 11:33:18 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:14552', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-07-31 11:33:18 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-07-31 11:33:18 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-07-31 11:33:18 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-31 11:33:18 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-07-31 11:33:18 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-31 11:33:23 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-07-31 11:33:23 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-31 11:33:23 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-31 11:33:24 | INFO | root | load pretrained hubert
2023-07-31 11:33:25 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-31 11:33:25 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-31 11:33:26 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-31 11:33:26 | INFO | root | share the sematic adapter and textual encoder
2023-07-31 11:33:26 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-31 11:33:26 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-07-31 11:33:26 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-31 11:33:26 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-07-31 11:33:26 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-31 11:33:26 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-31 11:33:26 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-31 11:33:26 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-31 11:33:26 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-31 11:33:26 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-31 11:33:32 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-31 11:33:34 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-31 11:33:34 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-31 11:33:34 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-31 11:33:34 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-31 11:33:34 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-31 11:33:34 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-31 11:33:34 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-31 11:33:34 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-31 11:33:34 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-31 11:33:34 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-31 11:33:34 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-31 11:33:34 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-31 11:33:34 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-31 11:33:34 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-31 11:33:34 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_last.pt
2023-07-31 11:33:34 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_last.pt
2023-07-31 11:33:34 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-31 11:33:34 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-31 11:33:34 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-31 11:33:34 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-31 11:33:36 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-31 11:33:37 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-31 11:34:24 | INFO | fairseq.optim.adam | using FusedAdam
2023-07-31 11:34:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 11:34:24 | INFO | fairseq.trainer | begin training epoch 1
2023-07-31 11:34:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 11:35:44 | INFO | train_inner | epoch 001:    100 / 1474 loss=19.137, trans_loss=5.598, nll_loss=4.163, w2v_ctc_loss=22.485, task_loss=2.623, contrastive_loss=3.325, total=4207.04, n_correct=209.28, ppl=17.91, accuracy=4.975, wps=19370.8, ups=1.54, wpb=12551.1, bsz=471.4, num_updates=100, lr=4.098e-06, gnorm=0.891, clip=0, loss_scale=128, train_wall=72, gb_free=19.5, wall=130
2023-07-31 11:36:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-31 11:36:49 | INFO | train_inner | epoch 001:    201 / 1474 loss=16.99, trans_loss=5.477, nll_loss=4.065, w2v_ctc_loss=19.358, task_loss=2.558, contrastive_loss=3.278, total=4124.14, n_correct=223.29, ppl=16.74, accuracy=5.414, wps=18919.7, ups=1.54, wpb=12313.4, bsz=461, num_updates=200, lr=8.096e-06, gnorm=3.625, clip=0, loss_scale=64, train_wall=65, gb_free=19.2, wall=195
2023-07-31 11:37:52 | INFO | train_inner | epoch 001:    301 / 1474 loss=10.086, trans_loss=5.48, nll_loss=4.122, w2v_ctc_loss=8.784, task_loss=2.555, contrastive_loss=3.203, total=4079.62, n_correct=207.73, ppl=17.42, accuracy=5.092, wps=19153.7, ups=1.57, wpb=12186.7, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=4.607, clip=0, loss_scale=64, train_wall=63, gb_free=19.9, wall=258
2023-07-31 11:38:56 | INFO | train_inner | epoch 001:    401 / 1474 loss=8.849, trans_loss=5.518, nll_loss=4.192, w2v_ctc_loss=6.815, task_loss=2.242, contrastive_loss=3.237, total=4174.14, n_correct=193.54, ppl=18.28, accuracy=4.637, wps=19630.7, ups=1.58, wpb=12463.5, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=2.947, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=322
2023-07-31 11:40:00 | INFO | train_inner | epoch 001:    501 / 1474 loss=8.415, trans_loss=5.495, nll_loss=4.179, w2v_ctc_loss=6.176, task_loss=2.048, contrastive_loss=3.233, total=4176.18, n_correct=189.01, ppl=18.11, accuracy=4.526, wps=19506.5, ups=1.56, wpb=12479.7, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=1.416, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=386
2023-07-31 11:41:04 | INFO | train_inner | epoch 001:    601 / 1474 loss=8.165, trans_loss=5.523, nll_loss=4.214, w2v_ctc_loss=5.809, task_loss=1.906, contrastive_loss=3.288, total=4147.79, n_correct=184.62, ppl=18.56, accuracy=4.451, wps=19189.3, ups=1.55, wpb=12371.6, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.727, clip=0, loss_scale=64, train_wall=64, gb_free=18.9, wall=450
2023-07-31 11:42:08 | INFO | train_inner | epoch 001:    701 / 1474 loss=8.008, trans_loss=5.525, nll_loss=4.22, w2v_ctc_loss=5.69, task_loss=1.984, contrastive_loss=3.039, total=4152.1, n_correct=193.18, ppl=18.64, accuracy=4.653, wps=19600, ups=1.58, wpb=12395.5, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=63, gb_free=19.5, wall=514
2023-07-31 11:43:11 | INFO | train_inner | epoch 001:    801 / 1474 loss=7.732, trans_loss=5.46, nll_loss=4.151, w2v_ctc_loss=5.465, task_loss=1.92, contrastive_loss=2.947, total=4123.83, n_correct=239.22, ppl=17.77, accuracy=5.801, wps=19379.9, ups=1.57, wpb=12306.1, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=0.825, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=577
2023-07-31 11:44:14 | INFO | train_inner | epoch 001:    901 / 1474 loss=7.471, trans_loss=5.426, nll_loss=4.12, w2v_ctc_loss=5.281, task_loss=1.952, contrastive_loss=2.706, total=4163.61, n_correct=263.78, ppl=17.39, accuracy=6.335, wps=19644.9, ups=1.58, wpb=12433.9, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=1.323, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=640
2023-07-31 11:45:20 | INFO | train_inner | epoch 001:   1001 / 1474 loss=7.211, trans_loss=5.402, nll_loss=4.099, w2v_ctc_loss=5.07, task_loss=1.965, contrastive_loss=2.556, total=4135.34, n_correct=286.1, ppl=17.14, accuracy=6.918, wps=18985, ups=1.54, wpb=12353.2, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=1.419, clip=0, loss_scale=64, train_wall=65, gb_free=19, wall=705
2023-07-31 11:46:23 | INFO | train_inner | epoch 001:   1101 / 1474 loss=6.942, trans_loss=5.389, nll_loss=4.087, w2v_ctc_loss=4.871, task_loss=1.981, contrastive_loss=2.334, total=4147.38, n_correct=309.07, ppl=17, accuracy=7.452, wps=19514.1, ups=1.58, wpb=12367, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=1.652, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=769
2023-07-31 11:47:26 | INFO | train_inner | epoch 001:   1201 / 1474 loss=6.722, trans_loss=5.37, nll_loss=4.071, w2v_ctc_loss=4.705, task_loss=2.065, contrastive_loss=2.131, total=4139.9, n_correct=316.14, ppl=16.8, accuracy=7.636, wps=19483.7, ups=1.58, wpb=12366.5, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=1.763, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=832
2023-07-31 11:48:30 | INFO | train_inner | epoch 001:   1301 / 1474 loss=6.501, trans_loss=5.367, nll_loss=4.07, w2v_ctc_loss=4.51, task_loss=1.986, contrastive_loss=1.941, total=4046.58, n_correct=318.8, ppl=16.79, accuracy=7.878, wps=19105.8, ups=1.58, wpb=12081.6, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=1.735, clip=0, loss_scale=64, train_wall=63, gb_free=19.7, wall=896
2023-07-31 11:49:34 | INFO | train_inner | epoch 001:   1401 / 1474 loss=6.295, trans_loss=5.357, nll_loss=4.061, w2v_ctc_loss=4.31, task_loss=1.962, contrastive_loss=2.009, total=4133.18, n_correct=332.38, ppl=16.69, accuracy=8.042, wps=19160.2, ups=1.55, wpb=12350, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=1.625, clip=0, loss_scale=64, train_wall=64, gb_free=19.9, wall=960
2023-07-31 11:50:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 11:51:00 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.564 | trans_loss 10.915 | nll_loss 9.898 | w2v_ctc_loss 5.605 | task_loss 11.319 | contrastive_loss 2.365 | total 4003.4 | n_correct 384.2 | ppl 953.97 | accuracy 9.597 | uer 71.916 | wer 69.845 | raw_wer 69.845 | bleu 0.03 | wps 1179 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-07-31 11:51:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-07-31 11:51:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 11:51:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 11:51:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.03) (writing took 5.755754319950938 seconds)
2023-07-31 11:51:05 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-07-31 11:51:05 | INFO | train | epoch 001 | loss 9.041 | trans_loss 5.451 | nll_loss 4.126 | w2v_ctc_loss 7.644 | task_loss 2.113 | contrastive_loss 2.761 | total 4138.55 | n_correct 252.001 | ppl 17.46 | accuracy 6.089 | wps 18451.8 | ups 1.49 | wpb 12355.5 | bsz 458.4 | num_updates 1473 | lr 5.89905e-05 | gnorm 1.788 | clip 0 | loss_scale 64 | train_wall 941 | gb_free 19.2 | wall 1051
2023-07-31 11:51:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 11:51:06 | INFO | fairseq.trainer | begin training epoch 2
2023-07-31 11:51:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 11:51:32 | INFO | train_inner | epoch 002:     27 / 1474 loss=6.106, trans_loss=5.349, nll_loss=4.047, w2v_ctc_loss=4.117, task_loss=1.869, contrastive_loss=1.855, total=4162.95, n_correct=338.97, ppl=16.53, accuracy=8.143, wps=10572.5, ups=0.85, wpb=12416.8, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=1.658, clip=0, loss_scale=64, train_wall=63, gb_free=19.6, wall=1077
2023-07-31 11:52:35 | INFO | train_inner | epoch 002:    127 / 1474 loss=5.947, trans_loss=5.346, nll_loss=4.043, w2v_ctc_loss=4.001, task_loss=1.994, contrastive_loss=1.652, total=4155.98, n_correct=339.29, ppl=16.48, accuracy=8.164, wps=19650.6, ups=1.59, wpb=12394.8, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=1.725, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=1141
2023-07-31 11:53:38 | INFO | train_inner | epoch 002:    227 / 1474 loss=5.782, trans_loss=5.325, nll_loss=4.021, w2v_ctc_loss=3.805, task_loss=1.73, contrastive_loss=1.682, total=4179.21, n_correct=348.24, ppl=16.24, accuracy=8.333, wps=19708.6, ups=1.58, wpb=12484.6, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=1.503, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=1204
2023-07-31 11:54:42 | INFO | train_inner | epoch 002:    327 / 1474 loss=5.622, trans_loss=5.324, nll_loss=4.017, w2v_ctc_loss=3.715, task_loss=1.987, contrastive_loss=1.392, total=4146.1, n_correct=352.65, ppl=16.18, accuracy=8.506, wps=19240, ups=1.55, wpb=12374.1, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=1.396, clip=0, loss_scale=64, train_wall=64, gb_free=18.8, wall=1268
2023-07-31 11:55:46 | INFO | train_inner | epoch 002:    427 / 1474 loss=5.482, trans_loss=5.315, nll_loss=4.01, w2v_ctc_loss=3.617, task_loss=2.184, contrastive_loss=1.215, total=4037.99, n_correct=343.62, ppl=16.11, accuracy=8.51, wps=19063.5, ups=1.58, wpb=12069.2, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=1.439, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=1331
2023-07-31 11:56:49 | INFO | train_inner | epoch 002:    527 / 1474 loss=5.371, trans_loss=5.304, nll_loss=3.992, w2v_ctc_loss=3.456, task_loss=1.899, contrastive_loss=1.31, total=4176.97, n_correct=360.07, ppl=15.91, accuracy=8.62, wps=19719.8, ups=1.58, wpb=12463.5, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=1.282, clip=0, loss_scale=64, train_wall=63, gb_free=19.6, wall=1395
2023-07-31 11:56:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 11:57:28 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.955 | trans_loss 10.758 | nll_loss 9.684 | w2v_ctc_loss 4.515 | task_loss 11.318 | contrastive_loss 1.645 | total 4003.4 | n_correct 413.9 | ppl 822.46 | accuracy 10.339 | uer 61.442 | wer 59.256 | raw_wer 59.256 | bleu 0.05 | wps 1170.7 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.05
2023-07-31 11:57:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-07-31 11:57:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_2_2000.pt
2023-07-31 11:57:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_2_2000.pt
2023-07-31 11:57:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.05) (writing took 21.970695722848177 seconds)
2023-07-31 11:58:54 | INFO | train_inner | epoch 002:    627 / 1474 loss=5.239, trans_loss=5.297, nll_loss=3.982, w2v_ctc_loss=3.352, task_loss=1.963, contrastive_loss=1.11, total=4126.49, n_correct=367.13, ppl=15.81, accuracy=8.897, wps=9834.8, ups=0.8, wpb=12314.9, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=1.174, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=1520
2023-07-31 11:59:58 | INFO | train_inner | epoch 002:    727 / 1474 loss=5.167, trans_loss=5.281, nll_loss=3.967, w2v_ctc_loss=3.267, task_loss=1.924, contrastive_loss=1.212, total=4149.06, n_correct=374.42, ppl=15.64, accuracy=9.024, wps=19398, ups=1.57, wpb=12386.4, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=1.139, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=1584
2023-07-31 12:01:01 | INFO | train_inner | epoch 002:    827 / 1474 loss=5.077, trans_loss=5.265, nll_loss=3.948, w2v_ctc_loss=3.197, task_loss=1.976, contrastive_loss=1.161, total=4175.4, n_correct=385.24, ppl=15.43, accuracy=9.226, wps=19729, ups=1.58, wpb=12471.9, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=1.033, clip=0, loss_scale=128, train_wall=63, gb_free=19.8, wall=1647
2023-07-31 12:02:04 | INFO | train_inner | epoch 002:    927 / 1474 loss=4.986, trans_loss=5.253, nll_loss=3.931, w2v_ctc_loss=3.104, task_loss=2.016, contrastive_loss=1.143, total=4104.2, n_correct=381.35, ppl=15.26, accuracy=9.292, wps=19358.2, ups=1.58, wpb=12253.1, bsz=445.9, num_updates=2400, lr=9.6052e-05, gnorm=1.025, clip=0, loss_scale=128, train_wall=63, gb_free=19, wall=1710
2023-07-31 12:03:08 | INFO | train_inner | epoch 002:   1027 / 1474 loss=4.901, trans_loss=5.246, nll_loss=3.926, w2v_ctc_loss=3.034, task_loss=1.957, contrastive_loss=0.995, total=4102.5, n_correct=386.7, ppl=15.2, accuracy=9.426, wps=19365.5, ups=1.58, wpb=12251.2, bsz=456.3, num_updates=2500, lr=0.00010005, gnorm=0.895, clip=0, loss_scale=128, train_wall=63, gb_free=19.2, wall=1774
2023-07-31 12:04:12 | INFO | train_inner | epoch 002:   1127 / 1474 loss=4.858, trans_loss=5.241, nll_loss=3.917, w2v_ctc_loss=2.943, task_loss=1.781, contrastive_loss=1.207, total=4187.61, n_correct=400.31, ppl=15.11, accuracy=9.559, wps=19275.2, ups=1.54, wpb=12495.7, bsz=487.1, num_updates=2600, lr=0.000104048, gnorm=0.906, clip=0, loss_scale=128, train_wall=64, gb_free=19.5, wall=1838
2023-07-31 12:05:16 | INFO | train_inner | epoch 002:   1227 / 1474 loss=4.8, trans_loss=5.228, nll_loss=3.903, w2v_ctc_loss=2.899, task_loss=1.792, contrastive_loss=1.13, total=4221.06, n_correct=416.73, ppl=14.96, accuracy=9.873, wps=19724.8, ups=1.57, wpb=12596.1, bsz=492.8, num_updates=2700, lr=0.000108046, gnorm=0.816, clip=0, loss_scale=128, train_wall=63, gb_free=19.5, wall=1902
2023-07-31 12:06:19 | INFO | train_inner | epoch 002:   1327 / 1474 loss=4.707, trans_loss=5.22, nll_loss=3.897, w2v_ctc_loss=2.864, task_loss=1.888, contrastive_loss=0.838, total=4157.86, n_correct=414.24, ppl=14.89, accuracy=9.963, wps=19721.2, ups=1.59, wpb=12425.5, bsz=460.7, num_updates=2800, lr=0.000112044, gnorm=0.778, clip=0, loss_scale=128, train_wall=63, gb_free=19.5, wall=1965
2023-07-31 12:07:23 | INFO | train_inner | epoch 002:   1427 / 1474 loss=4.671, trans_loss=5.227, nll_loss=3.905, w2v_ctc_loss=2.823, task_loss=2.12, contrastive_loss=0.926, total=4054.34, n_correct=399.8, ppl=14.98, accuracy=9.861, wps=19138.3, ups=1.58, wpb=12107, bsz=438.8, num_updates=2900, lr=0.000116042, gnorm=0.73, clip=0, loss_scale=128, train_wall=63, gb_free=19.4, wall=2029
2023-07-31 12:07:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 12:08:32 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.192 | trans_loss 10.252 | nll_loss 9.071 | w2v_ctc_loss 3.614 | task_loss 11.319 | contrastive_loss 0.99 | total 4003.4 | n_correct 499.9 | ppl 537.72 | accuracy 12.487 | uer 51.897 | wer 50.669 | raw_wer 50.669 | bleu 0.12 | wps 1168.5 | wpb 4003.4 | bsz 141.8 | num_updates 2947 | best_bleu 0.12
2023-07-31 12:08:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2947 updates
2023-07-31 12:08:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 12:08:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 12:08:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt (epoch 2 @ 2947 updates, score 0.12) (writing took 21.26607914082706 seconds)
2023-07-31 12:08:54 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-07-31 12:08:54 | INFO | train | epoch 002 | loss 5.185 | trans_loss 5.276 | nll_loss 3.96 | w2v_ctc_loss 3.29 | task_loss 1.938 | contrastive_loss 1.214 | total 4138.65 | n_correct 376.718 | ppl 15.57 | accuracy 9.102 | wps 17046.9 | ups 1.38 | wpb 12355.8 | bsz 458.5 | num_updates 2947 | lr 0.000117921 | gnorm 1.126 | clip 0 | loss_scale 128 | train_wall 931 | gb_free 19.3 | wall 2120
2023-07-31 12:08:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 12:08:54 | INFO | fairseq.trainer | begin training epoch 3
2023-07-31 12:08:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 12:09:35 | INFO | train_inner | epoch 003:     53 / 1474 loss=4.596, trans_loss=5.199, nll_loss=3.869, w2v_ctc_loss=2.762, task_loss=1.987, contrastive_loss=0.827, total=4071.2, n_correct=416.54, ppl=14.61, accuracy=10.231, wps=9174, ups=0.75, wpb=12154.1, bsz=442.6, num_updates=3000, lr=0.00012004, gnorm=0.719, clip=0, loss_scale=128, train_wall=64, gb_free=19.1, wall=2161
2023-07-31 12:09:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-31 12:09:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-31 12:09:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-31 12:09:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-31 12:09:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-07-31 12:11:10 | INFO | train_inner | epoch 003:    158 / 1474 loss=3.836, trans_loss=4.382, nll_loss=2.8, w2v_ctc_loss=2.465, task_loss=1.356, contrastive_loss=0.785, total=4144.18, n_correct=1134.86, ppl=6.96, accuracy=27.384, wps=13040.5, ups=1.05, wpb=12374.6, bsz=458.6, num_updates=3100, lr=0.000124038, gnorm=2.318, clip=1, loss_scale=4, train_wall=94, gb_free=16.5, wall=2256
2023-07-31 12:12:42 | INFO | train_inner | epoch 003:    258 / 1474 loss=3.453, trans_loss=4.154, nll_loss=2.505, w2v_ctc_loss=2.247, task_loss=1.373, contrastive_loss=0.666, total=4161.13, n_correct=1402.59, ppl=5.68, accuracy=33.707, wps=13465.8, ups=1.08, wpb=12431.5, bsz=467, num_updates=3200, lr=0.000128036, gnorm=1.725, clip=0, loss_scale=4, train_wall=92, gb_free=17.1, wall=2348
2023-07-31 12:14:14 | INFO | train_inner | epoch 003:    358 / 1474 loss=3.342, trans_loss=4.104, nll_loss=2.435, w2v_ctc_loss=2.16, task_loss=1.382, contrastive_loss=0.695, total=4150.02, n_correct=1479.69, ppl=5.41, accuracy=35.655, wps=13499.2, ups=1.09, wpb=12384.9, bsz=461.6, num_updates=3300, lr=0.000132034, gnorm=1.788, clip=1, loss_scale=4, train_wall=91, gb_free=17.1, wall=2440
2023-07-31 12:15:46 | INFO | train_inner | epoch 003:    458 / 1474 loss=3.216, trans_loss=4.052, nll_loss=2.367, w2v_ctc_loss=2.073, task_loss=1.338, contrastive_loss=0.55, total=4209.57, n_correct=1582.53, ppl=5.16, accuracy=37.594, wps=13698.6, ups=1.09, wpb=12566, bsz=476.8, num_updates=3400, lr=0.000136032, gnorm=1.456, clip=0, loss_scale=4, train_wall=91, gb_free=16.1, wall=2532
2023-07-31 12:17:17 | INFO | train_inner | epoch 003:    558 / 1474 loss=3.119, trans_loss=4.028, nll_loss=2.336, w2v_ctc_loss=1.994, task_loss=1.466, contrastive_loss=0.506, total=4088.48, n_correct=1575.63, ppl=5.05, accuracy=38.538, wps=13455.6, ups=1.1, wpb=12212.5, bsz=439.7, num_updates=3500, lr=0.00014003, gnorm=1.386, clip=0, loss_scale=4, train_wall=90, gb_free=17.7, wall=2622
2023-07-31 12:18:49 | INFO | train_inner | epoch 003:    658 / 1474 loss=3.053, trans_loss=3.992, nll_loss=2.284, w2v_ctc_loss=1.915, task_loss=1.32, contrastive_loss=0.616, total=4221.58, n_correct=1690.12, ppl=4.87, accuracy=40.035, wps=13631.3, ups=1.08, wpb=12587.8, bsz=481.9, num_updates=3600, lr=0.000144028, gnorm=1.2, clip=0, loss_scale=4, train_wall=92, gb_free=16.4, wall=2715
2023-07-31 12:20:21 | INFO | train_inner | epoch 003:    758 / 1474 loss=2.97, trans_loss=3.959, nll_loss=2.246, w2v_ctc_loss=1.88, task_loss=1.317, contrastive_loss=0.381, total=4167.41, n_correct=1712.64, ppl=4.74, accuracy=41.096, wps=13557.4, ups=1.09, wpb=12447.6, bsz=472.6, num_updates=3700, lr=0.000148026, gnorm=1.15, clip=0, loss_scale=4, train_wall=91, gb_free=16.3, wall=2807
2023-07-31 12:21:52 | INFO | train_inner | epoch 003:    858 / 1474 loss=2.916, trans_loss=3.948, nll_loss=2.23, w2v_ctc_loss=1.833, task_loss=1.396, contrastive_loss=0.341, total=4165.53, n_correct=1738.56, ppl=4.69, accuracy=41.737, wps=13619.6, ups=1.1, wpb=12437.8, bsz=456.1, num_updates=3800, lr=0.000152024, gnorm=1.172, clip=0, loss_scale=4, train_wall=91, gb_free=17.1, wall=2898
2023-07-31 12:23:23 | INFO | train_inner | epoch 003:    958 / 1474 loss=2.869, trans_loss=3.922, nll_loss=2.194, w2v_ctc_loss=1.791, task_loss=1.34, contrastive_loss=0.366, total=4162.3, n_correct=1791.09, ppl=4.58, accuracy=43.031, wps=13597.7, ups=1.1, wpb=12417, bsz=469.2, num_updates=3900, lr=0.000156022, gnorm=1.07, clip=0, loss_scale=4, train_wall=91, gb_free=16.8, wall=2989
2023-07-31 12:24:54 | INFO | train_inner | epoch 003:   1058 / 1474 loss=2.843, trans_loss=3.906, nll_loss=2.175, w2v_ctc_loss=1.783, task_loss=1.468, contrastive_loss=0.324, total=4069.95, n_correct=1761.47, ppl=4.52, accuracy=43.28, wps=13388, ups=1.1, wpb=12153.7, bsz=443.6, num_updates=4000, lr=0.00016002, gnorm=1.08, clip=0, loss_scale=4, train_wall=90, gb_free=16.3, wall=3080
2023-07-31 12:24:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 12:25:20 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.078 | trans_loss 6.458 | nll_loss 4.021 | w2v_ctc_loss 2.14 | task_loss 6.439 | contrastive_loss 0.446 | total 4003.4 | n_correct 1941.6 | ppl 16.24 | accuracy 48.499 | uer 30.961 | wer 31.576 | raw_wer 31.576 | bleu 10.66 | wps 2000.9 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 10.66
2023-07-31 12:25:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-07-31 12:25:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_3_4000.pt
2023-07-31 12:25:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_3_4000.pt
2023-07-31 12:25:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 10.66) (writing took 29.08759287931025 seconds)
2023-07-31 12:27:19 | INFO | train_inner | epoch 003:   1158 / 1474 loss=2.788, trans_loss=3.894, nll_loss=2.158, w2v_ctc_loss=1.73, task_loss=1.496, contrastive_loss=0.298, total=4038.49, n_correct=1773.57, ppl=4.46, accuracy=43.917, wps=8301.2, ups=0.69, wpb=12054.8, bsz=432.5, num_updates=4100, lr=0.000164018, gnorm=1.002, clip=0, loss_scale=4, train_wall=90, gb_free=16.4, wall=3225
2023-07-31 12:28:50 | INFO | train_inner | epoch 003:   1258 / 1474 loss=2.75, trans_loss=3.876, nll_loss=2.136, w2v_ctc_loss=1.702, task_loss=1.465, contrastive_loss=0.281, total=4064.31, n_correct=1813.37, ppl=4.39, accuracy=44.617, wps=13360.7, ups=1.1, wpb=12136.8, bsz=433.9, num_updates=4200, lr=0.000168016, gnorm=1.075, clip=0, loss_scale=4, train_wall=90, gb_free=17.3, wall=3316
2023-07-31 12:30:22 | INFO | train_inner | epoch 003:   1358 / 1474 loss=2.74, trans_loss=3.861, nll_loss=2.117, w2v_ctc_loss=1.668, task_loss=1.395, contrastive_loss=0.394, total=4134.58, n_correct=1868.95, ppl=4.34, accuracy=45.203, wps=13446.3, ups=1.09, wpb=12343.8, bsz=460.7, num_updates=4300, lr=0.000172014, gnorm=1.045, clip=0, loss_scale=4, train_wall=91, gb_free=17.8, wall=3408
2023-07-31 12:31:54 | INFO | train_inner | epoch 003:   1458 / 1474 loss=2.709, trans_loss=3.847, nll_loss=2.099, w2v_ctc_loss=1.646, task_loss=1.319, contrastive_loss=0.376, total=4209.94, n_correct=1930.68, ppl=4.28, accuracy=45.86, wps=13713.6, ups=1.09, wpb=12573.5, bsz=477.4, num_updates=4400, lr=0.000176012, gnorm=1.004, clip=0, loss_scale=4, train_wall=91, gb_free=17, wall=3500
2023-07-31 12:32:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 12:32:32 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 4.943 | trans_loss 6.338 | nll_loss 3.861 | w2v_ctc_loss 1.979 | task_loss 6.221 | contrastive_loss 0.417 | total 4003.4 | n_correct 2022.9 | ppl 14.53 | accuracy 50.53 | uer 30.154 | wer 30.357 | raw_wer 30.357 | bleu 12.15 | wps 2067 | wpb 4003.4 | bsz 141.8 | num_updates 4416 | best_bleu 12.15
2023-07-31 12:32:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4416 updates
2023-07-31 12:32:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 12:32:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 12:32:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt (epoch 3 @ 4416 updates, score 12.15) (writing took 20.785037962719798 seconds)
2023-07-31 12:32:53 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-07-31 12:32:53 | INFO | train | epoch 003 | loss 3.096 | trans_loss 4.037 | nll_loss 2.346 | w2v_ctc_loss 1.948 | task_loss 1.407 | contrastive_loss 0.486 | total 4140.05 | n_correct 1618.33 | ppl 5.09 | accuracy 39.09 | wps 12618.8 | ups 1.02 | wpb 12360.1 | bsz 459 | num_updates 4416 | lr 0.000176652 | gnorm 1.294 | clip 0.1 | loss_scale 4 | train_wall 1325 | gb_free 16.4 | wall 3558
2023-07-31 12:32:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 12:32:53 | INFO | fairseq.trainer | begin training epoch 4
2023-07-31 12:32:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 12:34:17 | INFO | train_inner | epoch 004:     84 / 1474 loss=2.626, trans_loss=3.814, nll_loss=2.053, w2v_ctc_loss=1.595, task_loss=1.433, contrastive_loss=0.224, total=4099.41, n_correct=1917.84, ppl=4.15, accuracy=46.783, wps=8565.1, ups=0.7, wpb=12237, bsz=439.5, num_updates=4500, lr=0.00018001, gnorm=0.934, clip=0, loss_scale=4, train_wall=90, gb_free=16.3, wall=3643
2023-07-31 12:35:47 | INFO | train_inner | epoch 004:    184 / 1474 loss=2.606, trans_loss=3.793, nll_loss=2.027, w2v_ctc_loss=1.574, task_loss=1.324, contrastive_loss=0.251, total=4175.15, n_correct=1986.28, ppl=4.08, accuracy=47.574, wps=13797.6, ups=1.11, wpb=12464.9, bsz=468.3, num_updates=4600, lr=0.000184008, gnorm=0.923, clip=0, loss_scale=4, train_wall=90, gb_free=16.6, wall=3733
2023-07-31 12:37:18 | INFO | train_inner | epoch 004:    284 / 1474 loss=2.618, trans_loss=3.794, nll_loss=2.03, w2v_ctc_loss=1.571, task_loss=1.387, contrastive_loss=0.379, total=4145.23, n_correct=1970.87, ppl=4.08, accuracy=47.545, wps=13553.9, ups=1.09, wpb=12382.4, bsz=463, num_updates=4700, lr=0.000188006, gnorm=0.925, clip=0, loss_scale=4, train_wall=91, gb_free=15.9, wall=3824
2023-07-31 12:38:49 | INFO | train_inner | epoch 004:    384 / 1474 loss=2.571, trans_loss=3.791, nll_loss=2.022, w2v_ctc_loss=1.547, task_loss=1.448, contrastive_loss=0.214, total=4127.66, n_correct=1979.62, ppl=4.06, accuracy=47.96, wps=13574.1, ups=1.1, wpb=12314.6, bsz=443.5, num_updates=4800, lr=0.000192004, gnorm=0.865, clip=0, loss_scale=4, train_wall=90, gb_free=17.4, wall=3915
2023-07-31 12:40:21 | INFO | train_inner | epoch 004:    484 / 1474 loss=2.604, trans_loss=3.777, nll_loss=2.007, w2v_ctc_loss=1.512, task_loss=1.258, contrastive_loss=0.621, total=4218.78, n_correct=2042.82, ppl=4.02, accuracy=48.422, wps=13637.6, ups=1.08, wpb=12592.4, bsz=497.8, num_updates=4900, lr=0.000196002, gnorm=0.932, clip=0, loss_scale=4, train_wall=92, gb_free=16.5, wall=4007
2023-07-31 12:41:53 | INFO | train_inner | epoch 004:    584 / 1474 loss=2.555, trans_loss=3.766, nll_loss=1.993, w2v_ctc_loss=1.528, task_loss=1.307, contrastive_loss=0.292, total=4217.52, n_correct=2067.27, ppl=3.98, accuracy=49.016, wps=13809.7, ups=1.1, wpb=12591.1, bsz=485.9, num_updates=5000, lr=0.0002, gnorm=0.865, clip=0, loss_scale=4, train_wall=91, gb_free=16, wall=4098
mt_weight tensor(0.5000)
asr_weight tensor(0.4592, device='cuda:0')
2023-07-31 12:43:25 | INFO | train_inner | epoch 004:    684 / 1474 loss=2.525, trans_loss=3.769, nll_loss=1.993, w2v_ctc_loss=1.488, task_loss=1.425, contrastive_loss=0.335, total=4176.39, n_correct=2054.05, ppl=3.98, accuracy=49.182, wps=13426.1, ups=1.08, wpb=12448.9, bsz=455.8, num_updates=5100, lr=0.00019803, gnorm=0.566, clip=0, loss_scale=8, train_wall=92, gb_free=17.1, wall=4191
2023-07-31 12:44:57 | INFO | train_inner | epoch 004:    784 / 1474 loss=2.518, trans_loss=3.763, nll_loss=1.989, w2v_ctc_loss=1.512, task_loss=1.533, contrastive_loss=0.204, total=4026.63, n_correct=1983.54, ppl=3.97, accuracy=49.261, wps=13174.1, ups=1.1, wpb=12025, bsz=420.6, num_updates=5200, lr=0.000196116, gnorm=0.609, clip=0, loss_scale=8, train_wall=91, gb_free=13.1, wall=4282
2023-07-31 12:46:29 | INFO | train_inner | epoch 004:    884 / 1474 loss=2.536, trans_loss=3.748, nll_loss=1.971, w2v_ctc_loss=1.501, task_loss=1.387, contrastive_loss=0.388, total=4186.04, n_correct=2076.8, ppl=3.92, accuracy=49.613, wps=13536.8, ups=1.08, wpb=12501.4, bsz=466.3, num_updates=5300, lr=0.000194257, gnorm=0.598, clip=0, loss_scale=8, train_wall=92, gb_free=17.7, wall=4375
2023-07-31 12:48:01 | INFO | train_inner | epoch 004:    984 / 1474 loss=2.485, trans_loss=3.734, nll_loss=1.955, w2v_ctc_loss=1.475, task_loss=1.412, contrastive_loss=0.253, total=4125.02, n_correct=2076.87, ppl=3.88, accuracy=50.348, wps=13448, ups=1.09, wpb=12321, bsz=457.1, num_updates=5400, lr=0.00019245, gnorm=0.556, clip=0, loss_scale=8, train_wall=91, gb_free=12.7, wall=4466
2023-07-31 12:49:32 | INFO | train_inner | epoch 004:   1084 / 1474 loss=2.488, trans_loss=3.744, nll_loss=1.965, w2v_ctc_loss=1.481, task_loss=1.504, contrastive_loss=0.23, total=4075.6, n_correct=2044.35, ppl=3.9, accuracy=50.161, wps=13279.2, ups=1.09, wpb=12163.4, bsz=435.7, num_updates=5500, lr=0.000190693, gnorm=0.563, clip=0, loss_scale=8, train_wall=91, gb_free=16, wall=4558
2023-07-31 12:51:04 | INFO | train_inner | epoch 004:   1184 / 1474 loss=2.489, trans_loss=3.729, nll_loss=1.951, w2v_ctc_loss=1.469, task_loss=1.308, contrastive_loss=0.339, total=4161.18, n_correct=2102.67, ppl=3.87, accuracy=50.531, wps=13576.3, ups=1.09, wpb=12431.8, bsz=483.4, num_updates=5600, lr=0.000188982, gnorm=0.545, clip=0, loss_scale=8, train_wall=91, gb_free=16.8, wall=4650
2023-07-31 12:52:36 | INFO | train_inner | epoch 004:   1284 / 1474 loss=2.459, trans_loss=3.718, nll_loss=1.934, w2v_ctc_loss=1.445, task_loss=1.328, contrastive_loss=0.302, total=4156.53, n_correct=2128.65, ppl=3.82, accuracy=51.212, wps=13460.4, ups=1.08, wpb=12411.4, bsz=472.7, num_updates=5700, lr=0.000187317, gnorm=0.542, clip=0, loss_scale=8, train_wall=92, gb_free=15.8, wall=4742
2023-07-31 12:54:06 | INFO | train_inner | epoch 004:   1384 / 1474 loss=2.433, trans_loss=3.717, nll_loss=1.933, w2v_ctc_loss=1.443, task_loss=1.429, contrastive_loss=0.179, total=4101.23, n_correct=2101.86, ppl=3.82, accuracy=51.25, wps=13622.3, ups=1.11, wpb=12249, bsz=437.6, num_updates=5800, lr=0.000185695, gnorm=0.53, clip=0, loss_scale=8, train_wall=89, gb_free=15.6, wall=4832
2023-07-31 12:55:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.4592, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.4592, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.4592, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.4592, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.4592, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.4592, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.4592, device='cuda:3')
2023-07-31 12:55:50 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.575 | trans_loss 5.976 | nll_loss 3.373 | w2v_ctc_loss 1.626 | task_loss 6.66 | contrastive_loss 0.324 | total 4003.4 | n_correct 2224.5 | ppl 10.36 | accuracy 55.565 | uer 24.222 | wer 25.804 | raw_wer 25.804 | bleu 15.98 | wps 2240.4 | wpb 4003.4 | bsz 141.8 | num_updates 5890 | best_bleu 15.98
2023-07-31 12:55:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5890 updates
2023-07-31 12:55:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 12:56:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 12:56:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt (epoch 4 @ 5890 updates, score 15.98) (writing took 20.452301740646362 seconds)
2023-07-31 12:56:11 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-07-31 12:56:11 | INFO | train | epoch 004 | loss 2.529 | trans_loss 3.758 | nll_loss 1.983 | w2v_ctc_loss 1.504 | task_loss 1.391 | contrastive_loss 0.3 | total 4138.65 | n_correct 2043.4 | ppl 3.95 | accuracy 49.374 | wps 13026.7 | ups 1.05 | wpb 12355.8 | bsz 458.5 | num_updates 5890 | lr 0.000184271 | gnorm 0.7 | clip 0 | loss_scale 8 | train_wall 1340 | gb_free 14.8 | wall 4957
2023-07-31 12:56:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 12:56:11 | INFO | fairseq.trainer | begin training epoch 5
2023-07-31 12:56:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 12:56:28 | INFO | train_inner | epoch 005:     10 / 1474 loss=2.416, trans_loss=3.708, nll_loss=1.92, w2v_ctc_loss=1.419, task_loss=1.447, contrastive_loss=0.2, total=4037.7, n_correct=2085.24, ppl=3.78, accuracy=51.644, wps=8478.9, ups=0.7, wpb=12055.9, bsz=439.3, num_updates=5900, lr=0.000184115, gnorm=0.558, clip=0, loss_scale=8, train_wall=90, gb_free=16.9, wall=4974
2023-07-31 12:57:59 | INFO | train_inner | epoch 005:    110 / 1474 loss=2.344, trans_loss=3.65, nll_loss=1.845, w2v_ctc_loss=1.344, task_loss=1.258, contrastive_loss=0.211, total=4247.37, n_correct=2266.18, ppl=3.59, accuracy=53.355, wps=13918, ups=1.1, wpb=12683.4, bsz=495.1, num_updates=6000, lr=0.000182574, gnorm=0.514, clip=0, loss_scale=8, train_wall=91, gb_free=16.7, wall=5065
2023-07-31 12:57:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 12:58:24 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.541 | trans_loss 5.953 | nll_loss 3.339 | w2v_ctc_loss 1.568 | task_loss 6.617 | contrastive_loss 0.32 | total 4003.4 | n_correct 2228.3 | ppl 10.12 | accuracy 55.66 | uer 23.494 | wer 25.279 | raw_wer 25.279 | bleu 15.83 | wps 2030.1 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 15.98
2023-07-31 12:58:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-07-31 12:58:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_5_6000.pt
2023-07-31 12:58:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_5_6000.pt
2023-07-31 12:58:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 15.83) (writing took 16.92696120776236 seconds)
2023-07-31 13:00:12 | INFO | train_inner | epoch 005:    210 / 1474 loss=2.38, trans_loss=3.661, nll_loss=1.857, w2v_ctc_loss=1.357, task_loss=1.288, contrastive_loss=0.432, total=4189.85, n_correct=2223.49, ppl=3.62, accuracy=53.068, wps=9379.2, ups=0.75, wpb=12500.5, bsz=488.2, num_updates=6100, lr=0.000181071, gnorm=0.524, clip=0, loss_scale=8, train_wall=91, gb_free=17.8, wall=5198
2023-07-31 13:01:43 | INFO | train_inner | epoch 005:    310 / 1474 loss=2.363, trans_loss=3.655, nll_loss=1.854, w2v_ctc_loss=1.369, task_loss=1.433, contrastive_loss=0.269, total=4090.1, n_correct=2162.96, ppl=3.62, accuracy=52.883, wps=13558.4, ups=1.11, wpb=12228.1, bsz=443.9, num_updates=6200, lr=0.000179605, gnorm=0.529, clip=0, loss_scale=8, train_wall=90, gb_free=16.2, wall=5289
2023-07-31 13:03:14 | INFO | train_inner | epoch 005:    410 / 1474 loss=2.355, trans_loss=3.647, nll_loss=1.845, w2v_ctc_loss=1.338, task_loss=1.345, contrastive_loss=0.359, total=4147.17, n_correct=2214.61, ppl=3.59, accuracy=53.401, wps=13543.4, ups=1.09, wpb=12395.1, bsz=472.5, num_updates=6300, lr=0.000178174, gnorm=0.521, clip=0, loss_scale=8, train_wall=91, gb_free=14.8, wall=5380
2023-07-31 13:04:45 | INFO | train_inner | epoch 005:    510 / 1474 loss=2.326, trans_loss=3.658, nll_loss=1.856, w2v_ctc_loss=1.346, task_loss=1.564, contrastive_loss=0.149, total=4026.81, n_correct=2142.02, ppl=3.62, accuracy=53.194, wps=13235.7, ups=1.1, wpb=12029.7, bsz=416.6, num_updates=6400, lr=0.000176777, gnorm=0.516, clip=0, loss_scale=8, train_wall=90, gb_free=17.4, wall=5471
2023-07-31 13:06:17 | INFO | train_inner | epoch 005:    610 / 1474 loss=2.346, trans_loss=3.663, nll_loss=1.86, w2v_ctc_loss=1.332, task_loss=1.43, contrastive_loss=0.331, total=4107.75, n_correct=2185.94, ppl=3.63, accuracy=53.215, wps=13377, ups=1.09, wpb=12253.8, bsz=451.2, num_updates=6500, lr=0.000175412, gnorm=0.531, clip=0, loss_scale=8, train_wall=91, gb_free=16.1, wall=5563
2023-07-31 13:07:48 | INFO | train_inner | epoch 005:    710 / 1474 loss=2.341, trans_loss=3.654, nll_loss=1.851, w2v_ctc_loss=1.332, task_loss=1.322, contrastive_loss=0.303, total=4178.85, n_correct=2239.27, ppl=3.61, accuracy=53.586, wps=13734.2, ups=1.1, wpb=12473.1, bsz=480.9, num_updates=6600, lr=0.000174078, gnorm=0.516, clip=0, loss_scale=8, train_wall=90, gb_free=17.7, wall=5653
2023-07-31 13:09:20 | INFO | train_inner | epoch 005:    810 / 1474 loss=2.32, trans_loss=3.653, nll_loss=1.849, w2v_ctc_loss=1.323, task_loss=1.436, contrastive_loss=0.226, total=4127.73, n_correct=2215.65, ppl=3.6, accuracy=53.677, wps=13391.7, ups=1.09, wpb=12320.4, bsz=449.2, num_updates=6700, lr=0.000172774, gnorm=0.503, clip=0, loss_scale=8, train_wall=91, gb_free=15.1, wall=5745
2023-07-31 13:10:50 | INFO | train_inner | epoch 005:    910 / 1474 loss=2.301, trans_loss=3.644, nll_loss=1.84, w2v_ctc_loss=1.315, task_loss=1.442, contrastive_loss=0.187, total=4095.48, n_correct=2209.76, ppl=3.58, accuracy=53.956, wps=13464.2, ups=1.1, wpb=12229.5, bsz=445.3, num_updates=6800, lr=0.000171499, gnorm=0.513, clip=0, loss_scale=8, train_wall=90, gb_free=15.6, wall=5836
2023-07-31 13:12:21 | INFO | train_inner | epoch 005:   1010 / 1474 loss=2.311, trans_loss=3.646, nll_loss=1.842, w2v_ctc_loss=1.315, task_loss=1.377, contrastive_loss=0.269, total=4165.12, n_correct=2247.01, ppl=3.58, accuracy=53.948, wps=13658.7, ups=1.1, wpb=12433.6, bsz=463.5, num_updates=6900, lr=0.000170251, gnorm=0.502, clip=0, loss_scale=8, train_wall=91, gb_free=15.6, wall=5927
2023-07-31 13:13:53 | INFO | train_inner | epoch 005:   1110 / 1474 loss=2.323, trans_loss=3.646, nll_loss=1.841, w2v_ctc_loss=1.324, task_loss=1.38, contrastive_loss=0.271, total=4176.72, n_correct=2259.71, ppl=3.58, accuracy=54.103, wps=13605.8, ups=1.09, wpb=12459.2, bsz=466.1, num_updates=7000, lr=0.000169031, gnorm=0.508, clip=0, loss_scale=8, train_wall=91, gb_free=16.7, wall=6019
2023-07-31 13:15:25 | INFO | train_inner | epoch 005:   1210 / 1474 loss=2.283, trans_loss=3.643, nll_loss=1.836, w2v_ctc_loss=1.296, task_loss=1.421, contrastive_loss=0.174, total=4164.13, n_correct=2263.3, ppl=3.57, accuracy=54.352, wps=13567.4, ups=1.09, wpb=12420.9, bsz=453.8, num_updates=7100, lr=0.000167836, gnorm=0.517, clip=0, loss_scale=16, train_wall=91, gb_free=16.9, wall=6110
2023-07-31 13:16:56 | INFO | train_inner | epoch 005:   1310 / 1474 loss=2.273, trans_loss=3.641, nll_loss=1.835, w2v_ctc_loss=1.288, task_loss=1.421, contrastive_loss=0.143, total=4134.91, n_correct=2245.17, ppl=3.57, accuracy=54.298, wps=13481.4, ups=1.09, wpb=12341.4, bsz=445.6, num_updates=7200, lr=0.000166667, gnorm=0.508, clip=0, loss_scale=16, train_wall=91, gb_free=16.3, wall=6202
2023-07-31 13:18:27 | INFO | train_inner | epoch 005:   1410 / 1474 loss=2.279, trans_loss=3.641, nll_loss=1.837, w2v_ctc_loss=1.284, task_loss=1.406, contrastive_loss=0.209, total=4134.37, n_correct=2246.05, ppl=3.57, accuracy=54.326, wps=13580.7, ups=1.1, wpb=12347.5, bsz=458.5, num_updates=7300, lr=0.000165521, gnorm=0.521, clip=0, loss_scale=16, train_wall=90, gb_free=17.8, wall=6293
2023-07-31 13:19:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 13:19:48 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.442 | trans_loss 5.856 | nll_loss 3.224 | w2v_ctc_loss 1.448 | task_loss 6.71 | contrastive_loss 0.333 | total 4003.4 | n_correct 2292.6 | ppl 9.34 | accuracy 57.266 | uer 22.31 | wer 24.06 | raw_wer 24.06 | bleu 17.09 | wps 2197.2 | wpb 4003.4 | bsz 141.8 | num_updates 7364 | best_bleu 17.09
2023-07-31 13:19:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7364 updates
2023-07-31 13:19:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 13:20:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 13:20:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt (epoch 5 @ 7364 updates, score 17.09) (writing took 23.203677589073777 seconds)
2023-07-31 13:20:11 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-07-31 13:20:12 | INFO | train | epoch 005 | loss 2.324 | trans_loss 3.65 | nll_loss 1.846 | w2v_ctc_loss 1.326 | task_loss 1.393 | contrastive_loss 0.253 | total 4138.65 | n_correct 2222.23 | ppl 3.59 | accuracy 53.694 | wps 12643.7 | ups 1.02 | wpb 12355.8 | bsz 458.5 | num_updates 7364 | lr 0.0001648 | gnorm 0.518 | clip 0 | loss_scale 16 | train_wall 1337 | gb_free 16.2 | wall 6397
2023-07-31 13:20:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 13:20:12 | INFO | fairseq.trainer | begin training epoch 6
2023-07-31 13:20:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 13:20:53 | INFO | train_inner | epoch 006:     36 / 1474 loss=2.267, trans_loss=3.617, nll_loss=1.804, w2v_ctc_loss=1.281, task_loss=1.432, contrastive_loss=0.207, total=4115.45, n_correct=2259.67, ppl=3.49, accuracy=54.907, wps=8425.5, ups=0.69, wpb=12281.2, bsz=447.9, num_updates=7400, lr=0.000164399, gnorm=0.534, clip=0, loss_scale=16, train_wall=91, gb_free=16.4, wall=6439
2023-07-31 13:22:24 | INFO | train_inner | epoch 006:    136 / 1474 loss=2.221, trans_loss=3.584, nll_loss=1.762, w2v_ctc_loss=1.229, task_loss=1.391, contrastive_loss=0.247, total=4154.25, n_correct=2311.13, ppl=3.39, accuracy=55.633, wps=13631, ups=1.1, wpb=12407.4, bsz=456.1, num_updates=7500, lr=0.000163299, gnorm=0.501, clip=0, loss_scale=16, train_wall=91, gb_free=15.5, wall=6530
2023-07-31 13:23:55 | INFO | train_inner | epoch 006:    236 / 1474 loss=2.233, trans_loss=3.595, nll_loss=1.777, w2v_ctc_loss=1.261, task_loss=1.493, contrastive_loss=0.155, total=4112.66, n_correct=2275.23, ppl=3.43, accuracy=55.323, wps=13426.1, ups=1.09, wpb=12287.2, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.502, clip=0, loss_scale=16, train_wall=91, gb_free=16.1, wall=6621
2023-07-31 13:25:28 | INFO | train_inner | epoch 006:    336 / 1474 loss=2.242, trans_loss=3.581, nll_loss=1.759, w2v_ctc_loss=1.211, task_loss=1.295, contrastive_loss=0.463, total=4177.51, n_correct=2338.31, ppl=3.39, accuracy=55.974, wps=13415.8, ups=1.08, wpb=12473.8, bsz=491.3, num_updates=7700, lr=0.000161165, gnorm=0.506, clip=0, loss_scale=16, train_wall=93, gb_free=16, wall=6714
2023-07-31 13:26:59 | INFO | train_inner | epoch 006:    436 / 1474 loss=2.201, trans_loss=3.586, nll_loss=1.766, w2v_ctc_loss=1.22, task_loss=1.34, contrastive_loss=0.169, total=4154.57, n_correct=2323.69, ppl=3.4, accuracy=55.931, wps=13751.6, ups=1.11, wpb=12405.5, bsz=470.2, num_updates=7800, lr=0.000160128, gnorm=0.494, clip=0, loss_scale=16, train_wall=90, gb_free=16.1, wall=6804
2023-07-31 13:28:30 | INFO | train_inner | epoch 006:    536 / 1474 loss=2.211, trans_loss=3.593, nll_loss=1.773, w2v_ctc_loss=1.235, task_loss=1.404, contrastive_loss=0.158, total=4167.79, n_correct=2330.56, ppl=3.42, accuracy=55.918, wps=13651.9, ups=1.1, wpb=12438.5, bsz=455.2, num_updates=7900, lr=0.000159111, gnorm=0.503, clip=0, loss_scale=16, train_wall=91, gb_free=15.7, wall=6896
2023-07-31 13:30:01 | INFO | train_inner | epoch 006:    636 / 1474 loss=2.204, trans_loss=3.593, nll_loss=1.774, w2v_ctc_loss=1.213, task_loss=1.322, contrastive_loss=0.214, total=4146.17, n_correct=2315.43, ppl=3.42, accuracy=55.845, wps=13557.5, ups=1.1, wpb=12376.6, bsz=471.6, num_updates=8000, lr=0.000158114, gnorm=0.494, clip=0, loss_scale=16, train_wall=91, gb_free=16.3, wall=6987
2023-07-31 13:30:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 13:30:26 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.4 | trans_loss 5.8 | nll_loss 3.143 | w2v_ctc_loss 1.46 | task_loss 6.79 | contrastive_loss 0.295 | total 4003.4 | n_correct 2319.5 | ppl 8.83 | accuracy 57.938 | uer 21.063 | wer 22.814 | raw_wer 22.814 | bleu 17.44 | wps 2021.4 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 17.44
2023-07-31 13:30:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-07-31 13:30:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_6_8000.pt
2023-07-31 13:30:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_6_8000.pt
2023-07-31 13:31:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 17.44) (writing took 37.2275261990726 seconds)
2023-07-31 13:32:35 | INFO | train_inner | epoch 006:    736 / 1474 loss=2.209, trans_loss=3.595, nll_loss=1.777, w2v_ctc_loss=1.231, task_loss=1.425, contrastive_loss=0.167, total=4148.65, n_correct=2315.33, ppl=3.43, accuracy=55.809, wps=8039.8, ups=0.65, wpb=12388, bsz=453.7, num_updates=8100, lr=0.000157135, gnorm=0.498, clip=0, loss_scale=16, train_wall=91, gb_free=15.5, wall=7141
2023-07-31 13:34:06 | INFO | train_inner | epoch 006:    836 / 1474 loss=2.206, trans_loss=3.604, nll_loss=1.788, w2v_ctc_loss=1.225, task_loss=1.466, contrastive_loss=0.15, total=4114.34, n_correct=2288.58, ppl=3.45, accuracy=55.624, wps=13483.2, ups=1.1, wpb=12282.2, bsz=441.6, num_updates=8200, lr=0.000156174, gnorm=0.497, clip=0, loss_scale=16, train_wall=91, gb_free=15, wall=7232
2023-07-31 13:35:37 | INFO | train_inner | epoch 006:    936 / 1474 loss=2.22, trans_loss=3.602, nll_loss=1.786, w2v_ctc_loss=1.225, task_loss=1.451, contrastive_loss=0.247, total=4081.53, n_correct=2273.25, ppl=3.45, accuracy=55.696, wps=13381.9, ups=1.1, wpb=12181.3, bsz=444.5, num_updates=8300, lr=0.00015523, gnorm=0.499, clip=0, loss_scale=16, train_wall=90, gb_free=17.8, wall=7323
2023-07-31 13:37:09 | INFO | train_inner | epoch 006:   1036 / 1474 loss=2.208, trans_loss=3.587, nll_loss=1.769, w2v_ctc_loss=1.203, task_loss=1.322, contrastive_loss=0.322, total=4165.84, n_correct=2338.47, ppl=3.41, accuracy=56.134, wps=13579.5, ups=1.09, wpb=12435.7, bsz=477.2, num_updates=8400, lr=0.000154303, gnorm=0.496, clip=0, loss_scale=16, train_wall=91, gb_free=16.8, wall=7415
2023-07-31 13:38:40 | INFO | train_inner | epoch 006:   1136 / 1474 loss=2.199, trans_loss=3.595, nll_loss=1.777, w2v_ctc_loss=1.22, task_loss=1.545, contrastive_loss=0.15, total=4072.29, n_correct=2276.01, ppl=3.43, accuracy=55.89, wps=13350, ups=1.1, wpb=12157.6, bsz=428, num_updates=8500, lr=0.000153393, gnorm=0.498, clip=0, loss_scale=16, train_wall=91, gb_free=16.9, wall=7506
2023-07-31 13:40:11 | INFO | train_inner | epoch 006:   1236 / 1474 loss=2.226, trans_loss=3.584, nll_loss=1.766, w2v_ctc_loss=1.201, task_loss=1.353, contrastive_loss=0.471, total=4141.55, n_correct=2329.53, ppl=3.4, accuracy=56.248, wps=13505.3, ups=1.09, wpb=12370.9, bsz=474.8, num_updates=8600, lr=0.000152499, gnorm=0.5, clip=0, loss_scale=16, train_wall=91, gb_free=13.1, wall=7597
2023-07-31 13:41:42 | INFO | train_inner | epoch 006:   1336 / 1474 loss=2.176, trans_loss=3.592, nll_loss=1.772, w2v_ctc_loss=1.198, task_loss=1.392, contrastive_loss=0.137, total=4125.31, n_correct=2323.73, ppl=3.42, accuracy=56.329, wps=13623.5, ups=1.11, wpb=12305, bsz=452.6, num_updates=8700, lr=0.00015162, gnorm=0.494, clip=0, loss_scale=16, train_wall=90, gb_free=17.8, wall=7688
2023-07-31 13:43:14 | INFO | train_inner | epoch 006:   1436 / 1474 loss=2.175, trans_loss=3.585, nll_loss=1.766, w2v_ctc_loss=1.199, task_loss=1.395, contrastive_loss=0.144, total=4196.2, n_correct=2367.92, ppl=3.4, accuracy=56.43, wps=13568.7, ups=1.08, wpb=12525.2, bsz=461.5, num_updates=8800, lr=0.000150756, gnorm=0.487, clip=0, loss_scale=16, train_wall=92, gb_free=11.2, wall=7780
2023-07-31 13:43:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 13:44:11 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.362 | trans_loss 5.768 | nll_loss 3.103 | w2v_ctc_loss 1.407 | task_loss 6.791 | contrastive_loss 0.297 | total 4003.4 | n_correct 2346.7 | ppl 8.59 | accuracy 58.618 | uer 20.686 | wer 22.363 | raw_wer 22.363 | bleu 17.92 | wps 2266.8 | wpb 4003.4 | bsz 141.8 | num_updates 8838 | best_bleu 17.92
2023-07-31 13:44:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8838 updates
2023-07-31 13:44:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 13:44:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 13:44:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt (epoch 6 @ 8838 updates, score 17.92) (writing took 24.163680963218212 seconds)
2023-07-31 13:44:36 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-07-31 13:44:36 | INFO | train | epoch 006 | loss 2.208 | trans_loss 3.591 | nll_loss 1.772 | w2v_ctc_loss 1.219 | task_loss 1.395 | contrastive_loss 0.228 | total 4138.65 | n_correct 2314.71 | ppl 3.41 | accuracy 55.929 | wps 12441.6 | ups 1.01 | wpb 12355.8 | bsz 458.5 | num_updates 8838 | lr 0.000150431 | gnorm 0.498 | clip 0 | loss_scale 16 | train_wall 1339 | gb_free 15.1 | wall 7861
2023-07-31 13:44:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 13:44:36 | INFO | fairseq.trainer | begin training epoch 7
2023-07-31 13:44:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 13:45:41 | INFO | train_inner | epoch 007:     62 / 1474 loss=2.145, trans_loss=3.56, nll_loss=1.733, w2v_ctc_loss=1.17, task_loss=1.362, contrastive_loss=0.161, total=4108.19, n_correct=2343.94, ppl=3.32, accuracy=57.055, wps=8352.9, ups=0.68, wpb=12266.6, bsz=461.9, num_updates=8900, lr=0.000149906, gnorm=0.489, clip=0, loss_scale=16, train_wall=90, gb_free=17.1, wall=7927
2023-07-31 13:47:12 | INFO | train_inner | epoch 007:    162 / 1474 loss=2.145, trans_loss=3.549, nll_loss=1.718, w2v_ctc_loss=1.157, task_loss=1.419, contrastive_loss=0.232, total=4106.05, n_correct=2350.98, ppl=3.29, accuracy=57.256, wps=13523.6, ups=1.1, wpb=12258.7, bsz=455.4, num_updates=9000, lr=0.000149071, gnorm=0.506, clip=0, loss_scale=16, train_wall=90, gb_free=16.7, wall=8017
2023-07-31 13:48:42 | INFO | train_inner | epoch 007:    262 / 1474 loss=2.128, trans_loss=3.544, nll_loss=1.711, w2v_ctc_loss=1.159, task_loss=1.417, contrastive_loss=0.138, total=4129.3, n_correct=2379.4, ppl=3.27, accuracy=57.622, wps=13610.6, ups=1.1, wpb=12322.8, bsz=451.8, num_updates=9100, lr=0.00014825, gnorm=0.492, clip=0, loss_scale=16, train_wall=90, gb_free=17.3, wall=8108
2023-07-31 13:50:15 | INFO | train_inner | epoch 007:    362 / 1474 loss=2.161, trans_loss=3.554, nll_loss=1.724, w2v_ctc_loss=1.148, task_loss=1.345, contrastive_loss=0.408, total=4201.67, n_correct=2402.11, ppl=3.3, accuracy=57.17, wps=13508.7, ups=1.08, wpb=12539.8, bsz=479.7, num_updates=9200, lr=0.000147442, gnorm=0.485, clip=0, loss_scale=32, train_wall=92, gb_free=15.4, wall=8201
2023-07-31 13:51:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-31 13:51:47 | INFO | train_inner | epoch 007:    463 / 1474 loss=2.136, trans_loss=3.555, nll_loss=1.728, w2v_ctc_loss=1.152, task_loss=1.406, contrastive_loss=0.199, total=4141.06, n_correct=2365.4, ppl=3.31, accuracy=57.121, wps=13471.2, ups=1.09, wpb=12367.8, bsz=454.9, num_updates=9300, lr=0.000146647, gnorm=0.507, clip=0, loss_scale=16, train_wall=91, gb_free=16.8, wall=8293
2023-07-31 13:53:17 | INFO | train_inner | epoch 007:    563 / 1474 loss=2.123, trans_loss=3.552, nll_loss=1.72, w2v_ctc_loss=1.147, task_loss=1.368, contrastive_loss=0.147, total=4168.14, n_correct=2399.67, ppl=3.29, accuracy=57.572, wps=13723.7, ups=1.1, wpb=12434.7, bsz=459.8, num_updates=9400, lr=0.000145865, gnorm=0.49, clip=0, loss_scale=16, train_wall=90, gb_free=16.8, wall=8383
2023-07-31 13:54:49 | INFO | train_inner | epoch 007:    663 / 1474 loss=2.115, trans_loss=3.551, nll_loss=1.719, w2v_ctc_loss=1.14, task_loss=1.386, contrastive_loss=0.133, total=4157.82, n_correct=2396.79, ppl=3.29, accuracy=57.645, wps=13523.6, ups=1.09, wpb=12406.4, bsz=455.4, num_updates=9500, lr=0.000145095, gnorm=0.484, clip=0, loss_scale=16, train_wall=91, gb_free=15.5, wall=8475
2023-07-31 13:56:21 | INFO | train_inner | epoch 007:    763 / 1474 loss=2.116, trans_loss=3.548, nll_loss=1.718, w2v_ctc_loss=1.143, task_loss=1.462, contrastive_loss=0.129, total=4122.1, n_correct=2365.05, ppl=3.29, accuracy=57.375, wps=13381, ups=1.09, wpb=12308.4, bsz=446.2, num_updates=9600, lr=0.000144338, gnorm=0.487, clip=0, loss_scale=16, train_wall=92, gb_free=15.6, wall=8567
2023-07-31 13:57:53 | INFO | train_inner | epoch 007:    863 / 1474 loss=2.12, trans_loss=3.556, nll_loss=1.728, w2v_ctc_loss=1.144, task_loss=1.403, contrastive_loss=0.153, total=4147.23, n_correct=2379.16, ppl=3.31, accuracy=57.367, wps=13487.8, ups=1.09, wpb=12377.6, bsz=460.9, num_updates=9700, lr=0.000143592, gnorm=0.488, clip=0, loss_scale=16, train_wall=91, gb_free=17.5, wall=8659
2023-07-31 13:59:24 | INFO | train_inner | epoch 007:    963 / 1474 loss=2.127, trans_loss=3.55, nll_loss=1.721, w2v_ctc_loss=1.133, task_loss=1.328, contrastive_loss=0.249, total=4140.14, n_correct=2381.22, ppl=3.3, accuracy=57.515, wps=13503.1, ups=1.09, wpb=12359.1, bsz=474.6, num_updates=9800, lr=0.000142857, gnorm=0.492, clip=0, loss_scale=16, train_wall=91, gb_free=15.9, wall=8750
2023-07-31 14:00:55 | INFO | train_inner | epoch 007:   1063 / 1474 loss=2.116, trans_loss=3.562, nll_loss=1.736, w2v_ctc_loss=1.146, task_loss=1.465, contrastive_loss=0.114, total=4103.51, n_correct=2349.97, ppl=3.33, accuracy=57.267, wps=13478.3, ups=1.1, wpb=12251.1, bsz=437.5, num_updates=9900, lr=0.000142134, gnorm=0.487, clip=0, loss_scale=16, train_wall=90, gb_free=16.8, wall=8841
2023-07-31 14:02:27 | INFO | train_inner | epoch 007:   1163 / 1474 loss=2.149, trans_loss=3.547, nll_loss=1.721, w2v_ctc_loss=1.134, task_loss=1.36, contrastive_loss=0.384, total=4137.04, n_correct=2382.6, ppl=3.3, accuracy=57.592, wps=13404.1, ups=1.08, wpb=12361.6, bsz=470.9, num_updates=10000, lr=0.000141421, gnorm=0.498, clip=0, loss_scale=16, train_wall=92, gb_free=15.9, wall=8933
2023-07-31 14:02:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 14:02:51 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.31 | trans_loss 5.715 | nll_loss 3.04 | w2v_ctc_loss 1.359 | task_loss 6.884 | contrastive_loss 0.284 | total 4003.4 | n_correct 2378.5 | ppl 8.22 | accuracy 59.412 | uer 19.406 | wer 21.066 | raw_wer 21.066 | bleu 18.32 | wps 2244 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 18.32
2023-07-31 14:02:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-07-31 14:02:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_7_10000.pt
2023-07-31 14:02:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_7_10000.pt
2023-07-31 14:03:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 18.32) (writing took 36.8877738583833 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:0')
2023-07-31 14:04:59 | INFO | train_inner | epoch 007:   1263 / 1474 loss=2.107, trans_loss=3.554, nll_loss=1.728, w2v_ctc_loss=1.129, task_loss=1.414, contrastive_loss=0.143, total=4129.52, n_correct=2372.13, ppl=3.31, accuracy=57.443, wps=8147.6, ups=0.66, wpb=12331.4, bsz=450.2, num_updates=10100, lr=0.00014072, gnorm=0.413, clip=0, loss_scale=16, train_wall=90, gb_free=16.7, wall=9085
2023-07-31 14:06:30 | INFO | train_inner | epoch 007:   1363 / 1474 loss=2.121, trans_loss=3.547, nll_loss=1.719, w2v_ctc_loss=1.14, task_loss=1.315, contrastive_loss=0.181, total=4172.87, n_correct=2409.3, ppl=3.29, accuracy=57.737, wps=13713.1, ups=1.1, wpb=12458.1, bsz=476.2, num_updates=10200, lr=0.000140028, gnorm=0.416, clip=0, loss_scale=16, train_wall=90, gb_free=17.2, wall=9176
2023-07-31 14:08:03 | INFO | train_inner | epoch 007:   1463 / 1474 loss=2.13, trans_loss=3.553, nll_loss=1.729, w2v_ctc_loss=1.14, task_loss=1.506, contrastive_loss=0.245, total=4109.42, n_correct=2358.25, ppl=3.31, accuracy=57.386, wps=13204.8, ups=1.08, wpb=12278.1, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.425, clip=0, loss_scale=16, train_wall=92, gb_free=16.4, wall=9269
2023-07-31 14:08:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:1')
2023-07-31 14:08:36 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.317 | trans_loss 5.715 | nll_loss 3.037 | w2v_ctc_loss 1.373 | task_loss 6.862 | contrastive_loss 0.294 | total 4003.4 | n_correct 2368.8 | ppl 8.21 | accuracy 59.17 | uer 19.775 | wer 21.502 | raw_wer 21.502 | bleu 18.38 | wps 2227.7 | wpb 4003.4 | bsz 141.8 | num_updates 10311 | best_bleu 18.38
2023-07-31 14:08:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10311 updates
2023-07-31 14:08:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 14:08:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 14:08:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt (epoch 7 @ 10311 updates, score 18.38) (writing took 20.876114638522267 seconds)
2023-07-31 14:08:57 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-07-31 14:08:57 | INFO | train | epoch 007 | loss 2.128 | trans_loss 3.551 | nll_loss 1.722 | w2v_ctc_loss 1.144 | task_loss 1.399 | contrastive_loss 0.203 | total 4137.88 | n_correct 2376.55 | ppl 3.3 | accuracy 57.434 | wps 12452.4 | ups 1.01 | wpb 12353.6 | bsz 457.9 | num_updates 10311 | lr 0.000139272 | gnorm 0.477 | clip 0 | loss_scale 16 | train_wall 1340 | gb_free 13.1 | wall 9323
2023-07-31 14:08:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 14:08:57 | INFO | fairseq.trainer | begin training epoch 8
2023-07-31 14:08:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 14:10:27 | INFO | train_inner | epoch 008:     89 / 1474 loss=2.075, trans_loss=3.528, nll_loss=1.688, w2v_ctc_loss=1.101, task_loss=1.475, contrastive_loss=0.14, total=4116.25, n_correct=2401.51, ppl=3.22, accuracy=58.342, wps=8531.4, ups=0.7, wpb=12273, bsz=443.3, num_updates=10400, lr=0.000138675, gnorm=0.411, clip=0, loss_scale=16, train_wall=91, gb_free=16.9, wall=9412
2023-07-31 14:11:57 | INFO | train_inner | epoch 008:    189 / 1474 loss=2.077, trans_loss=3.52, nll_loss=1.678, w2v_ctc_loss=1.1, task_loss=1.515, contrastive_loss=0.159, total=4037.23, n_correct=2363.99, ppl=3.2, accuracy=58.555, wps=13333.3, ups=1.11, wpb=12041.5, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.423, clip=0, loss_scale=16, train_wall=90, gb_free=12.6, wall=9503
2023-07-31 14:13:28 | INFO | train_inner | epoch 008:    289 / 1474 loss=2.073, trans_loss=3.515, nll_loss=1.676, w2v_ctc_loss=1.097, task_loss=1.311, contrastive_loss=0.161, total=4207.78, n_correct=2469.63, ppl=3.19, accuracy=58.692, wps=13842.6, ups=1.1, wpb=12556.5, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.414, clip=0, loss_scale=16, train_wall=90, gb_free=12.8, wall=9593
2023-07-31 14:15:00 | INFO | train_inner | epoch 008:    389 / 1474 loss=2.091, trans_loss=3.524, nll_loss=1.686, w2v_ctc_loss=1.115, task_loss=1.491, contrastive_loss=0.18, total=4127.24, n_correct=2409.33, ppl=3.22, accuracy=58.376, wps=13359, ups=1.08, wpb=12316.2, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=0.415, clip=0, loss_scale=16, train_wall=92, gb_free=11.6, wall=9686
2023-07-31 14:16:32 | INFO | train_inner | epoch 008:    489 / 1474 loss=2.116, trans_loss=3.518, nll_loss=1.681, w2v_ctc_loss=1.089, task_loss=1.252, contrastive_loss=0.449, total=4203.76, n_correct=2462.36, ppl=3.21, accuracy=58.575, wps=13674.7, ups=1.09, wpb=12548.2, bsz=504.5, num_updates=10800, lr=0.000136083, gnorm=0.417, clip=0, loss_scale=16, train_wall=91, gb_free=14.5, wall=9777
2023-07-31 14:18:03 | INFO | train_inner | epoch 008:    589 / 1474 loss=2.081, trans_loss=3.522, nll_loss=1.689, w2v_ctc_loss=1.116, task_loss=1.525, contrastive_loss=0.115, total=4062.5, n_correct=2361.15, ppl=3.22, accuracy=58.121, wps=13248.4, ups=1.09, wpb=12145.4, bsz=427.9, num_updates=10900, lr=0.000135457, gnorm=0.421, clip=0, loss_scale=16, train_wall=91, gb_free=11.1, wall=9869
2023-07-31 14:19:34 | INFO | train_inner | epoch 008:    689 / 1474 loss=2.071, trans_loss=3.517, nll_loss=1.679, w2v_ctc_loss=1.106, task_loss=1.438, contrastive_loss=0.127, total=4142.78, n_correct=2427.69, ppl=3.2, accuracy=58.601, wps=13573, ups=1.1, wpb=12364.4, bsz=448.6, num_updates=11000, lr=0.00013484, gnorm=0.407, clip=0, loss_scale=16, train_wall=91, gb_free=15.8, wall=9960
2023-07-31 14:21:05 | INFO | train_inner | epoch 008:    789 / 1474 loss=2.079, trans_loss=3.517, nll_loss=1.683, w2v_ctc_loss=1.1, task_loss=1.433, contrastive_loss=0.21, total=4118.9, n_correct=2408.36, ppl=3.21, accuracy=58.471, wps=13533, ups=1.1, wpb=12310.9, bsz=447.8, num_updates=11100, lr=0.000134231, gnorm=0.413, clip=0, loss_scale=16, train_wall=91, gb_free=15.1, wall=10051
2023-07-31 14:22:37 | INFO | train_inner | epoch 008:    889 / 1474 loss=2.075, trans_loss=3.518, nll_loss=1.684, w2v_ctc_loss=1.087, task_loss=1.341, contrastive_loss=0.222, total=4169.01, n_correct=2447.03, ppl=3.21, accuracy=58.696, wps=13644.4, ups=1.1, wpb=12452.5, bsz=473.7, num_updates=11200, lr=0.000133631, gnorm=0.411, clip=0, loss_scale=16, train_wall=91, gb_free=16, wall=10142
2023-07-31 14:24:07 | INFO | train_inner | epoch 008:    989 / 1474 loss=2.058, trans_loss=3.521, nll_loss=1.685, w2v_ctc_loss=1.088, task_loss=1.335, contrastive_loss=0.122, total=4154.69, n_correct=2439.39, ppl=3.22, accuracy=58.714, wps=13746, ups=1.11, wpb=12403.4, bsz=464.9, num_updates=11300, lr=0.000133038, gnorm=0.415, clip=0, loss_scale=16, train_wall=90, gb_free=17.7, wall=10233
2023-07-31 14:25:39 | INFO | train_inner | epoch 008:   1089 / 1474 loss=2.092, trans_loss=3.528, nll_loss=1.694, w2v_ctc_loss=1.091, task_loss=1.392, contrastive_loss=0.346, total=4199.1, n_correct=2449.1, ppl=3.24, accuracy=58.324, wps=13643.6, ups=1.09, wpb=12534.3, bsz=465.3, num_updates=11400, lr=0.000132453, gnorm=0.412, clip=0, loss_scale=32, train_wall=91, gb_free=12.5, wall=10325
2023-07-31 14:27:10 | INFO | train_inner | epoch 008:   1189 / 1474 loss=2.065, trans_loss=3.519, nll_loss=1.685, w2v_ctc_loss=1.093, task_loss=1.323, contrastive_loss=0.132, total=4177.31, n_correct=2450.89, ppl=3.21, accuracy=58.671, wps=13651, ups=1.09, wpb=12476.3, bsz=472.6, num_updates=11500, lr=0.000131876, gnorm=0.408, clip=0, loss_scale=32, train_wall=91, gb_free=14.8, wall=10416
2023-07-31 14:28:40 | INFO | train_inner | epoch 008:   1289 / 1474 loss=2.076, trans_loss=3.525, nll_loss=1.693, w2v_ctc_loss=1.105, task_loss=1.458, contrastive_loss=0.154, total=4063.85, n_correct=2370.1, ppl=3.23, accuracy=58.322, wps=13481.7, ups=1.11, wpb=12140.6, bsz=438.4, num_updates=11600, lr=0.000131306, gnorm=0.416, clip=0, loss_scale=32, train_wall=89, gb_free=16.7, wall=10506
2023-07-31 14:30:10 | INFO | train_inner | epoch 008:   1389 / 1474 loss=2.079, trans_loss=3.528, nll_loss=1.696, w2v_ctc_loss=1.092, task_loss=1.382, contrastive_loss=0.207, total=4141.5, n_correct=2424.03, ppl=3.24, accuracy=58.53, wps=13701.6, ups=1.11, wpb=12367.2, bsz=461.5, num_updates=11700, lr=0.000130744, gnorm=0.414, clip=0, loss_scale=32, train_wall=90, gb_free=16.3, wall=10596
2023-07-31 14:31:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 14:31:50 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.289 | trans_loss 5.68 | nll_loss 2.986 | w2v_ctc_loss 1.37 | task_loss 6.883 | contrastive_loss 0.277 | total 4003.4 | n_correct 2401.5 | ppl 7.92 | accuracy 59.987 | uer 18.838 | wer 20.45 | raw_wer 20.45 | bleu 18.71 | wps 2271.8 | wpb 4003.4 | bsz 141.8 | num_updates 11785 | best_bleu 18.71
2023-07-31 14:31:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11785 updates
2023-07-31 14:31:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 14:32:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 14:32:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt (epoch 8 @ 11785 updates, score 18.71) (writing took 19.92982730269432 seconds)
2023-07-31 14:32:10 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-07-31 14:32:10 | INFO | train | epoch 008 | loss 2.079 | trans_loss 3.522 | nll_loss 1.686 | w2v_ctc_loss 1.097 | task_loss 1.398 | contrastive_loss 0.202 | total 4138.65 | n_correct 2421.57 | ppl 3.22 | accuracy 58.511 | wps 13074.6 | ups 1.06 | wpb 12355.8 | bsz 458.5 | num_updates 11785 | lr 0.000130272 | gnorm 0.414 | clip 0 | loss_scale 32 | train_wall 1334 | gb_free 16.8 | wall 10716
2023-07-31 14:32:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 14:32:10 | INFO | fairseq.trainer | begin training epoch 9
2023-07-31 14:32:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 14:32:33 | INFO | train_inner | epoch 009:     15 / 1474 loss=2.078, trans_loss=3.519, nll_loss=1.682, w2v_ctc_loss=1.078, task_loss=1.348, contrastive_loss=0.336, total=4139.35, n_correct=2431.76, ppl=3.21, accuracy=58.747, wps=8677.3, ups=0.7, wpb=12350.9, bsz=472.9, num_updates=11800, lr=0.000130189, gnorm=0.412, clip=0, loss_scale=32, train_wall=90, gb_free=15.4, wall=10739
2023-07-31 14:34:04 | INFO | train_inner | epoch 009:    115 / 1474 loss=2.022, trans_loss=3.482, nll_loss=1.635, w2v_ctc_loss=1.051, task_loss=1.33, contrastive_loss=0.153, total=4181.9, n_correct=2498.82, ppl=3.11, accuracy=59.753, wps=13623.7, ups=1.09, wpb=12488.1, bsz=475.9, num_updates=11900, lr=0.000129641, gnorm=0.405, clip=0, loss_scale=32, train_wall=91, gb_free=16.2, wall=10830
2023-07-31 14:35:35 | INFO | train_inner | epoch 009:    215 / 1474 loss=2.02, trans_loss=3.49, nll_loss=1.644, w2v_ctc_loss=1.054, task_loss=1.507, contrastive_loss=0.109, total=4062.07, n_correct=2418.88, ppl=3.13, accuracy=59.548, wps=13317.6, ups=1.1, wpb=12129.1, bsz=431.6, num_updates=12000, lr=0.000129099, gnorm=0.414, clip=0, loss_scale=32, train_wall=91, gb_free=15.5, wall=10921
2023-07-31 14:35:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 14:35:58 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.277 | trans_loss 5.689 | nll_loss 3 | w2v_ctc_loss 1.309 | task_loss 6.825 | contrastive_loss 0.278 | total 4003.4 | n_correct 2395 | ppl 8 | accuracy 59.824 | uer 18.552 | wer 20.357 | raw_wer 20.357 | bleu 18.8 | wps 2265.3 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 18.8
2023-07-31 14:35:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-07-31 14:35:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_9_12000.pt
2023-07-31 14:36:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_9_12000.pt
2023-07-31 14:36:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.8) (writing took 22.141995523124933 seconds)
2023-07-31 14:37:52 | INFO | train_inner | epoch 009:    315 / 1474 loss=2.013, trans_loss=3.477, nll_loss=1.63, w2v_ctc_loss=1.04, task_loss=1.309, contrastive_loss=0.159, total=4152.1, n_correct=2490.35, ppl=3.1, accuracy=59.978, wps=9086.5, ups=0.73, wpb=12407.3, bsz=476.6, num_updates=12100, lr=0.000128565, gnorm=0.411, clip=0, loss_scale=32, train_wall=90, gb_free=16.2, wall=11058
2023-07-31 14:39:24 | INFO | train_inner | epoch 009:    415 / 1474 loss=2.022, trans_loss=3.494, nll_loss=1.65, w2v_ctc_loss=1.052, task_loss=1.368, contrastive_loss=0.127, total=4203.78, n_correct=2501, ppl=3.14, accuracy=59.494, wps=13621.4, ups=1.09, wpb=12551.8, bsz=469.8, num_updates=12200, lr=0.000128037, gnorm=0.41, clip=0, loss_scale=32, train_wall=92, gb_free=17.1, wall=11150
2023-07-31 14:40:55 | INFO | train_inner | epoch 009:    515 / 1474 loss=2.05, trans_loss=3.5, nll_loss=1.657, w2v_ctc_loss=1.077, task_loss=1.473, contrastive_loss=0.176, total=4112.78, n_correct=2436.42, ppl=3.15, accuracy=59.24, wps=13470.4, ups=1.1, wpb=12275.6, bsz=437.7, num_updates=12300, lr=0.000127515, gnorm=0.415, clip=0, loss_scale=32, train_wall=91, gb_free=16.1, wall=11241
2023-07-31 14:42:26 | INFO | train_inner | epoch 009:    615 / 1474 loss=2.015, trans_loss=3.49, nll_loss=1.648, w2v_ctc_loss=1.044, task_loss=1.423, contrastive_loss=0.137, total=4131.32, n_correct=2459.18, ppl=3.13, accuracy=59.525, wps=13561.7, ups=1.1, wpb=12347.4, bsz=455, num_updates=12400, lr=0.000127, gnorm=0.412, clip=0, loss_scale=32, train_wall=91, gb_free=17.8, wall=11332
2023-07-31 14:43:57 | INFO | train_inner | epoch 009:    715 / 1474 loss=2.05, trans_loss=3.502, nll_loss=1.662, w2v_ctc_loss=1.07, task_loss=1.432, contrastive_loss=0.221, total=4082.11, n_correct=2416.08, ppl=3.17, accuracy=59.187, wps=13504.3, ups=1.11, wpb=12194.8, bsz=449.7, num_updates=12500, lr=0.000126491, gnorm=0.417, clip=0, loss_scale=32, train_wall=90, gb_free=16.9, wall=11423
2023-07-31 14:45:28 | INFO | train_inner | epoch 009:    815 / 1474 loss=2.069, trans_loss=3.494, nll_loss=1.655, w2v_ctc_loss=1.06, task_loss=1.262, contrastive_loss=0.364, total=4221.08, n_correct=2507.07, ppl=3.15, accuracy=59.394, wps=13748.3, ups=1.09, wpb=12613.9, bsz=501.6, num_updates=12600, lr=0.000125988, gnorm=0.416, clip=0, loss_scale=32, train_wall=91, gb_free=17.6, wall=11514
2023-07-31 14:47:02 | INFO | train_inner | epoch 009:    915 / 1474 loss=2.055, trans_loss=3.502, nll_loss=1.659, w2v_ctc_loss=1.06, task_loss=1.446, contrastive_loss=0.344, total=4142.34, n_correct=2455.82, ppl=3.16, accuracy=59.286, wps=13239, ups=1.07, wpb=12359.9, bsz=448.9, num_updates=12700, lr=0.000125491, gnorm=0.419, clip=0, loss_scale=32, train_wall=93, gb_free=17.2, wall=11608
2023-07-31 14:48:32 | INFO | train_inner | epoch 009:   1015 / 1474 loss=2.039, trans_loss=3.508, nll_loss=1.668, w2v_ctc_loss=1.07, task_loss=1.572, contrastive_loss=0.124, total=4097.15, n_correct=2420.36, ppl=3.18, accuracy=59.074, wps=13506.2, ups=1.1, wpb=12228.7, bsz=422.6, num_updates=12800, lr=0.000125, gnorm=0.423, clip=0, loss_scale=32, train_wall=90, gb_free=16.8, wall=11698
2023-07-31 14:50:03 | INFO | train_inner | epoch 009:   1115 / 1474 loss=2.031, trans_loss=3.503, nll_loss=1.66, w2v_ctc_loss=1.056, task_loss=1.306, contrastive_loss=0.15, total=4182.29, n_correct=2488.73, ppl=3.16, accuracy=59.506, wps=13747.9, ups=1.1, wpb=12467.1, bsz=477.6, num_updates=12900, lr=0.000124515, gnorm=0.413, clip=0, loss_scale=32, train_wall=90, gb_free=17.2, wall=11789
2023-07-31 14:51:35 | INFO | train_inner | epoch 009:   1215 / 1474 loss=2.038, trans_loss=3.505, nll_loss=1.665, w2v_ctc_loss=1.072, task_loss=1.485, contrastive_loss=0.13, total=4141.43, n_correct=2453.18, ppl=3.17, accuracy=59.235, wps=13399.5, ups=1.08, wpb=12364.7, bsz=446.6, num_updates=13000, lr=0.000124035, gnorm=0.411, clip=0, loss_scale=32, train_wall=92, gb_free=17.5, wall=11881
2023-07-31 14:53:07 | INFO | train_inner | epoch 009:   1315 / 1474 loss=2.053, trans_loss=3.501, nll_loss=1.661, w2v_ctc_loss=1.052, task_loss=1.272, contrastive_loss=0.326, total=4203.91, n_correct=2502.16, ppl=3.16, accuracy=59.52, wps=13615.7, ups=1.09, wpb=12545.2, bsz=492.3, num_updates=13100, lr=0.00012356, gnorm=0.421, clip=0, loss_scale=32, train_wall=92, gb_free=17.3, wall=11973
2023-07-31 14:54:38 | INFO | train_inner | epoch 009:   1415 / 1474 loss=2.032, trans_loss=3.512, nll_loss=1.673, w2v_ctc_loss=1.066, task_loss=1.509, contrastive_loss=0.105, total=4077.08, n_correct=2412.92, ppl=3.19, accuracy=59.183, wps=13447.3, ups=1.11, wpb=12165, bsz=429.1, num_updates=13200, lr=0.000123091, gnorm=0.42, clip=0, loss_scale=32, train_wall=90, gb_free=17.3, wall=12064
2023-07-31 14:55:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 14:55:53 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.261 | trans_loss 5.66 | nll_loss 2.966 | w2v_ctc_loss 1.329 | task_loss 6.884 | contrastive_loss 0.27 | total 4003.4 | n_correct 2411.4 | ppl 7.81 | accuracy 60.234 | uer 18.615 | wer 20.611 | raw_wer 20.611 | bleu 18.74 | wps 2190.9 | wpb 4003.4 | bsz 141.8 | num_updates 13259 | best_bleu 18.8
2023-07-31 14:55:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13259 updates
2023-07-31 14:55:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_18.7406.pt
2023-07-31 14:55:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_18.7406.pt
2023-07-31 14:56:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_18.7406.pt (epoch 9 @ 13259 updates, score 18.74) (writing took 15.449450643733144 seconds)
2023-07-31 14:56:09 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-07-31 14:56:09 | INFO | train | epoch 009 | loss 2.037 | trans_loss 3.497 | nll_loss 1.655 | w2v_ctc_loss 1.059 | task_loss 1.4 | contrastive_loss 0.193 | total 4138.65 | n_correct 2459.6 | ppl 3.15 | accuracy 59.43 | wps 12658.2 | ups 1.02 | wpb 12355.8 | bsz 458.5 | num_updates 13259 | lr 0.000122817 | gnorm 0.415 | clip 0 | loss_scale 32 | train_wall 1338 | gb_free 11.4 | wall 12155
2023-07-31 14:56:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 14:56:09 | INFO | fairseq.trainer | begin training epoch 10
2023-07-31 14:56:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 14:56:54 | INFO | train_inner | epoch 010:     41 / 1474 loss=2.022, trans_loss=3.489, nll_loss=1.645, w2v_ctc_loss=1.04, task_loss=1.335, contrastive_loss=0.206, total=4100.86, n_correct=2457.38, ppl=3.13, accuracy=59.924, wps=8994.1, ups=0.73, wpb=12239.9, bsz=470.2, num_updates=13300, lr=0.000122628, gnorm=0.417, clip=0, loss_scale=32, train_wall=89, gb_free=16.4, wall=12200
2023-07-31 14:58:25 | INFO | train_inner | epoch 010:    141 / 1474 loss=1.981, trans_loss=3.463, nll_loss=1.612, w2v_ctc_loss=1.013, task_loss=1.322, contrastive_loss=0.13, total=4240.18, n_correct=2562.86, ppl=3.06, accuracy=60.442, wps=13948.2, ups=1.1, wpb=12664, bsz=479.1, num_updates=13400, lr=0.000122169, gnorm=0.413, clip=0, loss_scale=64, train_wall=90, gb_free=14.8, wall=12291
2023-07-31 14:59:57 | INFO | train_inner | epoch 010:    241 / 1474 loss=2.006, trans_loss=3.466, nll_loss=1.613, w2v_ctc_loss=1.024, task_loss=1.385, contrastive_loss=0.252, total=4126.3, n_correct=2494.21, ppl=3.06, accuracy=60.447, wps=13419.4, ups=1.09, wpb=12312.3, bsz=460.9, num_updates=13500, lr=0.000121716, gnorm=0.415, clip=0, loss_scale=64, train_wall=91, gb_free=15.4, wall=12382
2023-07-31 15:00:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-31 15:01:29 | INFO | train_inner | epoch 010:    342 / 1474 loss=1.977, trans_loss=3.464, nll_loss=1.616, w2v_ctc_loss=1.016, task_loss=1.43, contrastive_loss=0.102, total=4129.45, n_correct=2494.69, ppl=3.07, accuracy=60.412, wps=13377.8, ups=1.08, wpb=12344.1, bsz=449.2, num_updates=13600, lr=0.000121268, gnorm=0.408, clip=0, loss_scale=32, train_wall=92, gb_free=16.3, wall=12475
2023-07-31 15:03:01 | INFO | train_inner | epoch 010:    442 / 1474 loss=2.004, trans_loss=3.469, nll_loss=1.619, w2v_ctc_loss=1.004, task_loss=1.345, contrastive_loss=0.339, total=4196.37, n_correct=2532.44, ppl=3.07, accuracy=60.348, wps=13628.2, ups=1.09, wpb=12528, bsz=481.1, num_updates=13700, lr=0.000120824, gnorm=0.413, clip=0, loss_scale=32, train_wall=91, gb_free=16, wall=12567
2023-07-31 15:04:32 | INFO | train_inner | epoch 010:    542 / 1474 loss=2.004, trans_loss=3.484, nll_loss=1.634, w2v_ctc_loss=1.039, task_loss=1.503, contrastive_loss=0.117, total=4102.8, n_correct=2462.34, ppl=3.1, accuracy=60.016, wps=13397.6, ups=1.1, wpb=12234.1, bsz=437.8, num_updates=13800, lr=0.000120386, gnorm=0.412, clip=0, loss_scale=32, train_wall=91, gb_free=16.9, wall=12658
2023-07-31 15:06:05 | INFO | train_inner | epoch 010:    642 / 1474 loss=2.014, trans_loss=3.48, nll_loss=1.633, w2v_ctc_loss=1.029, task_loss=1.332, contrastive_loss=0.238, total=4176.56, n_correct=2511.36, ppl=3.1, accuracy=60.13, wps=13483.6, ups=1.08, wpb=12464, bsz=477.2, num_updates=13900, lr=0.000119952, gnorm=0.417, clip=0, loss_scale=32, train_wall=92, gb_free=16.1, wall=12750
2023-07-31 15:07:35 | INFO | train_inner | epoch 010:    742 / 1474 loss=2.01, trans_loss=3.482, nll_loss=1.635, w2v_ctc_loss=1.047, task_loss=1.402, contrastive_loss=0.116, total=4125.87, n_correct=2476.32, ppl=3.11, accuracy=60.019, wps=13646.9, ups=1.11, wpb=12315.3, bsz=454.4, num_updates=14000, lr=0.000119523, gnorm=0.42, clip=0, loss_scale=32, train_wall=90, gb_free=14.3, wall=12841
2023-07-31 15:07:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 15:07:58 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.265 | trans_loss 5.659 | nll_loss 2.96 | w2v_ctc_loss 1.34 | task_loss 6.895 | contrastive_loss 0.276 | total 4003.4 | n_correct 2417.1 | ppl 7.78 | accuracy 60.376 | uer 18.597 | wer 20.182 | raw_wer 20.182 | bleu 19.17 | wps 2194.9 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 19.17
2023-07-31 15:07:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-07-31 15:07:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_10_14000.pt
2023-07-31 15:08:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_10_14000.pt
2023-07-31 15:08:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 19.17) (writing took 23.132192259654403 seconds)
2023-07-31 15:09:52 | INFO | train_inner | epoch 010:    842 / 1474 loss=1.986, trans_loss=3.476, nll_loss=1.629, w2v_ctc_loss=1.018, task_loss=1.385, contrastive_loss=0.119, total=4128.44, n_correct=2485.29, ppl=3.09, accuracy=60.199, wps=8952.4, ups=0.73, wpb=12327.8, bsz=456.3, num_updates=14100, lr=0.000119098, gnorm=0.412, clip=0, loss_scale=32, train_wall=90, gb_free=14.7, wall=12978
2023-07-31 15:11:23 | INFO | train_inner | epoch 010:    942 / 1474 loss=2, trans_loss=3.478, nll_loss=1.629, w2v_ctc_loss=1.027, task_loss=1.342, contrastive_loss=0.158, total=4160.94, n_correct=2506.82, ppl=3.09, accuracy=60.246, wps=13784.8, ups=1.11, wpb=12411.1, bsz=468.1, num_updates=14200, lr=0.000118678, gnorm=0.411, clip=0, loss_scale=32, train_wall=90, gb_free=15.3, wall=13068
2023-07-31 15:12:55 | INFO | train_inner | epoch 010:   1042 / 1474 loss=2, trans_loss=3.481, nll_loss=1.636, w2v_ctc_loss=1.031, task_loss=1.513, contrastive_loss=0.131, total=4067.53, n_correct=2435.37, ppl=3.11, accuracy=59.873, wps=13186.8, ups=1.09, wpb=12145, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.423, clip=0, loss_scale=32, train_wall=92, gb_free=16.9, wall=13161
2023-07-31 15:14:25 | INFO | train_inner | epoch 010:   1142 / 1474 loss=2.007, trans_loss=3.489, nll_loss=1.645, w2v_ctc_loss=1.044, task_loss=1.562, contrastive_loss=0.111, total=4044.03, n_correct=2414.95, ppl=3.13, accuracy=59.716, wps=13393.5, ups=1.11, wpb=12074.4, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.419, clip=0, loss_scale=32, train_wall=90, gb_free=17.3, wall=13251
2023-07-31 15:15:56 | INFO | train_inner | epoch 010:   1242 / 1474 loss=1.999, trans_loss=3.478, nll_loss=1.636, w2v_ctc_loss=1.039, task_loss=1.432, contrastive_loss=0.107, total=4110.41, n_correct=2467.75, ppl=3.11, accuracy=60.037, wps=13517, ups=1.1, wpb=12291.6, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.432, clip=0, loss_scale=32, train_wall=90, gb_free=16.4, wall=13342
2023-07-31 15:17:27 | INFO | train_inner | epoch 010:   1342 / 1474 loss=1.997, trans_loss=3.484, nll_loss=1.641, w2v_ctc_loss=1.032, task_loss=1.431, contrastive_loss=0.12, total=4121.38, n_correct=2477.43, ppl=3.12, accuracy=60.112, wps=13504.7, ups=1.1, wpb=12308.4, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.416, clip=0, loss_scale=32, train_wall=91, gb_free=13.9, wall=13433
2023-07-31 15:18:59 | INFO | train_inner | epoch 010:   1442 / 1474 loss=2.034, trans_loss=3.489, nll_loss=1.646, w2v_ctc_loss=1.018, task_loss=1.32, contrastive_loss=0.376, total=4192.39, n_correct=2513.56, ppl=3.13, accuracy=59.955, wps=13556.3, ups=1.08, wpb=12506.1, bsz=482, num_updates=14700, lr=0.000116642, gnorm=0.422, clip=0, loss_scale=32, train_wall=92, gb_free=17, wall=13525
2023-07-31 15:19:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 15:19:51 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.259 | trans_loss 5.639 | nll_loss 2.938 | w2v_ctc_loss 1.369 | task_loss 6.943 | contrastive_loss 0.269 | total 4003.4 | n_correct 2430.8 | ppl 7.66 | accuracy 60.718 | uer 18.087 | wer 19.902 | raw_wer 19.902 | bleu 19.01 | wps 2269.6 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 19.17
2023-07-31 15:19:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-07-31 15:19:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.0101.pt
2023-07-31 15:19:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.0101.pt
2023-07-31 15:20:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.0101.pt (epoch 10 @ 14732 updates, score 19.01) (writing took 28.400696959346533 seconds)
2023-07-31 15:20:19 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-07-31 15:20:19 | INFO | train | epoch 010 | loss 2.002 | trans_loss 3.477 | nll_loss 1.63 | w2v_ctc_loss 1.026 | task_loss 1.401 | contrastive_loss 0.184 | total 4138.14 | n_correct 2489.38 | ppl 3.09 | accuracy 60.157 | wps 12546 | ups 1.02 | wpb 12354.3 | bsz 458.2 | num_updates 14732 | lr 0.000116516 | gnorm 0.416 | clip 0 | loss_scale 32 | train_wall 1337 | gb_free 17.2 | wall 13605
2023-07-31 15:20:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 15:20:20 | INFO | fairseq.trainer | begin training epoch 11
2023-07-31 15:20:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 15:21:28 | INFO | train_inner | epoch 011:     68 / 1474 loss=1.973, trans_loss=3.452, nll_loss=1.597, w2v_ctc_loss=0.999, task_loss=1.298, contrastive_loss=0.197, total=4175.24, n_correct=2547.24, ppl=3.03, accuracy=61.008, wps=8365, ups=0.67, wpb=12463.5, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.408, clip=0, loss_scale=32, train_wall=89, gb_free=16.7, wall=13674
2023-07-31 15:22:59 | INFO | train_inner | epoch 011:    168 / 1474 loss=1.964, trans_loss=3.453, nll_loss=1.6, w2v_ctc_loss=1.003, task_loss=1.443, contrastive_loss=0.113, total=4087.78, n_correct=2488.03, ppl=3.03, accuracy=60.865, wps=13467.9, ups=1.1, wpb=12214.2, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.418, clip=0, loss_scale=32, train_wall=90, gb_free=16.4, wall=13765
2023-07-31 15:24:30 | INFO | train_inner | epoch 011:    268 / 1474 loss=1.953, trans_loss=3.452, nll_loss=1.598, w2v_ctc_loss=0.991, task_loss=1.442, contrastive_loss=0.109, total=4118.77, n_correct=2510.19, ppl=3.03, accuracy=60.945, wps=13460.4, ups=1.09, wpb=12299.1, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.409, clip=0, loss_scale=32, train_wall=91, gb_free=12.2, wall=13856
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:0')
2023-07-31 15:25:38 | INFO | train_inner | epoch 011:    368 / 1474 loss=2.111, trans_loss=5.132, nll_loss=2.381, w2v_ctc_loss=0.746, task_loss=2.142, contrastive_loss=0.087, total=4097.83, n_correct=2492.53, ppl=5.21, accuracy=60.826, wps=12117.4, ups=1.47, wpb=8240.8, bsz=298, num_updates=15100, lr=0.000115087, gnorm=0.566, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=13924
2023-07-31 15:26:46 | INFO | train_inner | epoch 011:    468 / 1474 loss=2.127, trans_loss=5.172, nll_loss=2.408, w2v_ctc_loss=0.741, task_loss=2.197, contrastive_loss=0.206, total=4110.64, n_correct=2488.97, ppl=5.31, accuracy=60.549, wps=12037.4, ups=1.46, wpb=8221.3, bsz=300.4, num_updates=15200, lr=0.000114708, gnorm=0.567, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=13992
2023-07-31 15:27:55 | INFO | train_inner | epoch 011:    568 / 1474 loss=2.128, trans_loss=5.169, nll_loss=2.406, w2v_ctc_loss=0.752, task_loss=2.253, contrastive_loss=0.204, total=4071.69, n_correct=2466.1, ppl=5.3, accuracy=60.567, wps=11973.2, ups=1.47, wpb=8143.4, bsz=293.7, num_updates=15300, lr=0.000114332, gnorm=0.566, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=14060
2023-07-31 15:29:03 | INFO | train_inner | epoch 011:    668 / 1474 loss=2.131, trans_loss=5.169, nll_loss=2.407, w2v_ctc_loss=0.749, task_loss=2.06, contrastive_loss=0.262, total=4157.2, n_correct=2513.95, ppl=5.3, accuracy=60.472, wps=12164, ups=1.46, wpb=8314.4, bsz=309.6, num_updates=15400, lr=0.000113961, gnorm=0.555, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=14129
2023-07-31 15:30:11 | INFO | train_inner | epoch 011:    768 / 1474 loss=2.127, trans_loss=5.181, nll_loss=2.422, w2v_ctc_loss=0.762, task_loss=2.115, contrastive_loss=0.087, total=4174.91, n_correct=2528.71, ppl=5.36, accuracy=60.569, wps=12276, ups=1.47, wpb=8349.8, bsz=306.9, num_updates=15500, lr=0.000113592, gnorm=0.554, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=14197
2023-07-31 15:31:18 | INFO | train_inner | epoch 011:    868 / 1474 loss=2.125, trans_loss=5.18, nll_loss=2.421, w2v_ctc_loss=0.756, task_loss=2.198, contrastive_loss=0.074, total=4118.44, n_correct=2484.87, ppl=5.36, accuracy=60.335, wps=12192, ups=1.48, wpb=8236.9, bsz=293.7, num_updates=15600, lr=0.000113228, gnorm=0.551, clip=0, loss_scale=64, train_wall=67, gb_free=10.6, wall=14264
2023-07-31 15:32:26 | INFO | train_inner | epoch 011:    968 / 1474 loss=2.124, trans_loss=5.179, nll_loss=2.419, w2v_ctc_loss=0.758, task_loss=2.147, contrastive_loss=0.087, total=4140.92, n_correct=2505.75, ppl=5.35, accuracy=60.512, wps=12215.6, ups=1.47, wpb=8281.8, bsz=301.9, num_updates=15700, lr=0.000112867, gnorm=0.557, clip=0, loss_scale=64, train_wall=67, gb_free=15.6, wall=14332
2023-07-31 15:33:35 | INFO | train_inner | epoch 011:   1068 / 1474 loss=2.122, trans_loss=5.174, nll_loss=2.414, w2v_ctc_loss=0.757, task_loss=2.064, contrastive_loss=0.109, total=4136.99, n_correct=2508.03, ppl=5.33, accuracy=60.625, wps=12120.5, ups=1.46, wpb=8274, bsz=308.8, num_updates=15800, lr=0.000112509, gnorm=0.559, clip=0, loss_scale=64, train_wall=68, gb_free=17.6, wall=14400
2023-07-31 15:34:43 | INFO | train_inner | epoch 011:   1168 / 1474 loss=2.124, trans_loss=5.182, nll_loss=2.424, w2v_ctc_loss=0.757, task_loss=2.084, contrastive_loss=0.094, total=4185.65, n_correct=2532.02, ppl=5.37, accuracy=60.493, wps=12267.1, ups=1.47, wpb=8371.3, bsz=309.8, num_updates=15900, lr=0.000112154, gnorm=0.553, clip=0, loss_scale=64, train_wall=68, gb_free=13.9, wall=14469
2023-07-31 15:35:50 | INFO | train_inner | epoch 011:   1268 / 1474 loss=2.128, trans_loss=5.176, nll_loss=2.417, w2v_ctc_loss=0.759, task_loss=2.01, contrastive_loss=0.162, total=4171.89, n_correct=2524.54, ppl=5.34, accuracy=60.513, wps=12330.1, ups=1.48, wpb=8343.8, bsz=314.1, num_updates=16000, lr=0.000111803, gnorm=0.559, clip=0, loss_scale=64, train_wall=67, gb_free=15.9, wall=14536
2023-07-31 15:35:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:1')
2023-07-31 15:36:13 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.264 | trans_loss 5.639 | nll_loss 2.941 | w2v_ctc_loss 1.383 | task_loss 6.931 | contrastive_loss 0.272 | total 4003.4 | n_correct 2427.8 | ppl 7.68 | accuracy 60.643 | uer 18.175 | wer 20.003 | raw_wer 20.003 | bleu 18.83 | wps 2256.4 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.17
2023-07-31 15:36:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-07-31 15:36:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_11_16000.pt
2023-07-31 15:36:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_11_16000.pt
2023-07-31 15:36:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 18.83) (writing took 22.773645067587495 seconds)
2023-07-31 15:37:45 | INFO | train_inner | epoch 011:   1368 / 1474 loss=2.132, trans_loss=5.176, nll_loss=2.419, w2v_ctc_loss=0.745, task_loss=1.939, contrastive_loss=0.326, total=4190.34, n_correct=2534.62, ppl=5.35, accuracy=60.487, wps=7310.2, ups=0.87, wpb=8380.7, bsz=327.9, num_updates=16100, lr=0.000111456, gnorm=0.552, clip=0, loss_scale=64, train_wall=68, gb_free=17, wall=14651
2023-07-31 15:38:54 | INFO | train_inner | epoch 011:   1468 / 1474 loss=2.12, trans_loss=5.181, nll_loss=2.425, w2v_ctc_loss=0.751, task_loss=2.03, contrastive_loss=0.097, total=4158.39, n_correct=2515.2, ppl=5.37, accuracy=60.485, wps=12141.6, ups=1.46, wpb=8316.8, bsz=312, num_updates=16200, lr=0.000111111, gnorm=0.55, clip=0, loss_scale=64, train_wall=68, gb_free=16.8, wall=14719
2023-07-31 15:38:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 15:39:21 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.229 | trans_loss 5.631 | nll_loss 2.931 | w2v_ctc_loss 1.284 | task_loss 6.873 | contrastive_loss 0.27 | total 4003.4 | n_correct 2428.1 | ppl 7.63 | accuracy 60.651 | uer 17.986 | wer 19.727 | raw_wer 19.727 | bleu 19.24 | wps 2240.9 | wpb 4003.4 | bsz 141.8 | num_updates 16206 | best_bleu 19.24
2023-07-31 15:39:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16206 updates
2023-07-31 15:39:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 15:39:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 15:39:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt (epoch 11 @ 16206 updates, score 19.24) (writing took 20.395149057731032 seconds)
2023-07-31 15:39:42 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-07-31 15:39:42 | INFO | train | epoch 011 | loss 2.084 | trans_loss 4.744 | nll_loss 2.21 | w2v_ctc_loss 0.813 | task_loss 1.925 | contrastive_loss 0.14 | total 4138.65 | n_correct 2508.78 | ppl 4.63 | accuracy 60.618 | wps 11440.5 | ups 1.27 | wpb 9021 | bsz 333.4 | num_updates 16206 | lr 0.000111091 | gnorm 0.531 | clip 0 | loss_scale 64 | train_wall 1057 | gb_free 17.2 | wall 14768
2023-07-31 15:39:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 15:39:42 | INFO | fairseq.trainer | begin training epoch 12
2023-07-31 15:39:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 15:40:53 | INFO | train_inner | epoch 012:     94 / 1474 loss=2.096, trans_loss=5.122, nll_loss=2.346, w2v_ctc_loss=0.736, task_loss=2.009, contrastive_loss=0.129, total=4146.82, n_correct=2551.15, ppl=5.08, accuracy=61.521, wps=6946.2, ups=0.84, wpb=8293.6, bsz=313.9, num_updates=16300, lr=0.00011077, gnorm=0.553, clip=0, loss_scale=64, train_wall=67, gb_free=15.7, wall=14839
2023-07-31 15:42:01 | INFO | train_inner | epoch 012:    194 / 1474 loss=2.103, trans_loss=5.133, nll_loss=2.359, w2v_ctc_loss=0.745, task_loss=2.169, contrastive_loss=0.079, total=4120.68, n_correct=2522.81, ppl=5.13, accuracy=61.223, wps=12207.2, ups=1.48, wpb=8241.4, bsz=294.7, num_updates=16400, lr=0.000110432, gnorm=0.558, clip=0, loss_scale=64, train_wall=67, gb_free=15.6, wall=14906
2023-07-31 15:43:09 | INFO | train_inner | epoch 012:    294 / 1474 loss=2.095, trans_loss=5.13, nll_loss=2.357, w2v_ctc_loss=0.729, task_loss=1.975, contrastive_loss=0.113, total=4199.46, n_correct=2577.69, ppl=5.12, accuracy=61.381, wps=12263.2, ups=1.46, wpb=8398.9, bsz=320.3, num_updates=16500, lr=0.000110096, gnorm=0.551, clip=0, loss_scale=64, train_wall=68, gb_free=16.5, wall=14975
2023-07-31 15:44:18 | INFO | train_inner | epoch 012:    394 / 1474 loss=2.102, trans_loss=5.14, nll_loss=2.369, w2v_ctc_loss=0.742, task_loss=2.057, contrastive_loss=0.095, total=4151.14, n_correct=2544.6, ppl=5.17, accuracy=61.299, wps=11981.5, ups=1.44, wpb=8302.3, bsz=307.8, num_updates=16600, lr=0.000109764, gnorm=0.565, clip=0, loss_scale=64, train_wall=69, gb_free=17.1, wall=15044
2023-07-31 15:45:26 | INFO | train_inner | epoch 012:    494 / 1474 loss=2.112, trans_loss=5.155, nll_loss=2.39, w2v_ctc_loss=0.749, task_loss=2.108, contrastive_loss=0.102, total=4110.49, n_correct=2508.72, ppl=5.24, accuracy=61.032, wps=12126.4, ups=1.48, wpb=8221, bsz=302.2, num_updates=16700, lr=0.000109435, gnorm=0.559, clip=0, loss_scale=64, train_wall=67, gb_free=13.7, wall=15112
2023-07-31 15:46:35 | INFO | train_inner | epoch 012:    594 / 1474 loss=2.107, trans_loss=5.143, nll_loss=2.375, w2v_ctc_loss=0.742, task_loss=2.012, contrastive_loss=0.167, total=4189.92, n_correct=2565.54, ppl=5.19, accuracy=61.231, wps=12240.7, ups=1.46, wpb=8379.8, bsz=315.1, num_updates=16800, lr=0.000109109, gnorm=0.551, clip=0, loss_scale=64, train_wall=68, gb_free=14.8, wall=15180
2023-07-31 15:47:42 | INFO | train_inner | epoch 012:    694 / 1474 loss=2.102, trans_loss=5.141, nll_loss=2.373, w2v_ctc_loss=0.724, task_loss=1.926, contrastive_loss=0.256, total=4206.3, n_correct=2581.49, ppl=5.18, accuracy=61.372, wps=12436.7, ups=1.48, wpb=8412.6, bsz=325.7, num_updates=16900, lr=0.000108786, gnorm=0.543, clip=0, loss_scale=64, train_wall=67, gb_free=16.2, wall=15248
2023-07-31 15:48:51 | INFO | train_inner | epoch 012:    794 / 1474 loss=2.104, trans_loss=5.142, nll_loss=2.373, w2v_ctc_loss=0.744, task_loss=2.144, contrastive_loss=0.091, total=4085.96, n_correct=2500.57, ppl=5.18, accuracy=61.199, wps=11901, ups=1.46, wpb=8171.9, bsz=297.1, num_updates=17000, lr=0.000108465, gnorm=0.56, clip=0, loss_scale=64, train_wall=68, gb_free=16.1, wall=15317
2023-07-31 15:49:59 | INFO | train_inner | epoch 012:    894 / 1474 loss=2.109, trans_loss=5.148, nll_loss=2.381, w2v_ctc_loss=0.74, task_loss=2.145, contrastive_loss=0.145, total=4169.74, n_correct=2546.64, ppl=5.21, accuracy=61.074, wps=12252.6, ups=1.47, wpb=8339.5, bsz=306.4, num_updates=17100, lr=0.000108148, gnorm=0.559, clip=0, loss_scale=64, train_wall=68, gb_free=16, wall=15385
2023-07-31 15:51:07 | INFO | train_inner | epoch 012:    994 / 1474 loss=2.115, trans_loss=5.159, nll_loss=2.396, w2v_ctc_loss=0.748, task_loss=2.14, contrastive_loss=0.153, total=4117.67, n_correct=2507.7, ppl=5.26, accuracy=60.901, wps=12125.9, ups=1.47, wpb=8235.3, bsz=301.4, num_updates=17200, lr=0.000107833, gnorm=0.566, clip=0, loss_scale=64, train_wall=67, gb_free=17.6, wall=15453
2023-07-31 15:52:15 | INFO | train_inner | epoch 012:   1094 / 1474 loss=2.123, trans_loss=5.164, nll_loss=2.401, w2v_ctc_loss=0.75, task_loss=2.202, contrastive_loss=0.196, total=4047.61, n_correct=2463.19, ppl=5.28, accuracy=60.855, wps=11925.8, ups=1.47, wpb=8095.2, bsz=290.4, num_updates=17300, lr=0.000107521, gnorm=0.571, clip=0, loss_scale=64, train_wall=67, gb_free=16.5, wall=15521
2023-07-31 15:53:24 | INFO | train_inner | epoch 012:   1194 / 1474 loss=2.123, trans_loss=5.171, nll_loss=2.412, w2v_ctc_loss=0.757, task_loss=2.078, contrastive_loss=0.152, total=4184.55, n_correct=2541.85, ppl=5.32, accuracy=60.744, wps=12164, ups=1.45, wpb=8369.1, bsz=314.3, num_updates=17400, lr=0.000107211, gnorm=0.549, clip=0, loss_scale=64, train_wall=68, gb_free=16.6, wall=15589
2023-07-31 15:54:31 | INFO | train_inner | epoch 012:   1294 / 1474 loss=2.121, trans_loss=5.164, nll_loss=2.403, w2v_ctc_loss=0.762, task_loss=2.284, contrastive_loss=0.097, total=4086.33, n_correct=2481.64, ppl=5.29, accuracy=60.73, wps=12058.6, ups=1.48, wpb=8172.7, bsz=291.4, num_updates=17500, lr=0.000106904, gnorm=0.559, clip=0, loss_scale=64, train_wall=67, gb_free=16.6, wall=15657
2023-07-31 15:55:39 | INFO | train_inner | epoch 012:   1394 / 1474 loss=2.113, trans_loss=5.163, nll_loss=2.401, w2v_ctc_loss=0.738, task_loss=2.132, contrastive_loss=0.181, total=4134.89, n_correct=2519.23, ppl=5.28, accuracy=60.926, wps=12191.3, ups=1.47, wpb=8269.8, bsz=304.4, num_updates=17600, lr=0.0001066, gnorm=0.56, clip=0, loss_scale=64, train_wall=67, gb_free=17.2, wall=15725
2023-07-31 15:56:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-31 15:56:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 15:56:57 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.239 | trans_loss 5.616 | nll_loss 2.908 | w2v_ctc_loss 1.357 | task_loss 6.908 | contrastive_loss 0.266 | total 4003.4 | n_correct 2443.1 | ppl 7.51 | accuracy 61.026 | uer 17.96 | wer 19.645 | raw_wer 19.645 | bleu 19.49 | wps 2154.5 | wpb 4003.4 | bsz 141.8 | num_updates 17679 | best_bleu 19.49
2023-07-31 15:56:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17679 updates
2023-07-31 15:56:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 15:57:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 15:57:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt (epoch 12 @ 17679 updates, score 19.49) (writing took 20.648835193365812 seconds)
2023-07-31 15:57:18 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-07-31 15:57:18 | INFO | train | epoch 012 | loss 2.109 | trans_loss 5.149 | nll_loss 2.382 | w2v_ctc_loss 0.743 | task_loss 2.101 | contrastive_loss 0.137 | total 4138.25 | n_correct 2528.5 | ppl 5.21 | accuracy 61.101 | wps 11539.5 | ups 1.39 | wpb 8276.5 | bsz 305.5 | num_updates 17679 | lr 0.000106362 | gnorm 0.558 | clip 0 | loss_scale 64 | train_wall 996 | gb_free 12.7 | wall 15824
2023-07-31 15:57:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 15:57:18 | INFO | fairseq.trainer | begin training epoch 13
2023-07-31 15:57:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 15:57:41 | INFO | train_inner | epoch 013:     21 / 1474 loss=2.112, trans_loss=5.162, nll_loss=2.4, w2v_ctc_loss=0.751, task_loss=2.198, contrastive_loss=0.085, total=4094.55, n_correct=2497.05, ppl=5.28, accuracy=60.985, wps=6738.9, ups=0.82, wpb=8189.1, bsz=294.1, num_updates=17700, lr=0.000106299, gnorm=0.559, clip=0, loss_scale=64, train_wall=68, gb_free=14.5, wall=15847
2023-07-31 15:58:49 | INFO | train_inner | epoch 013:    121 / 1474 loss=2.086, trans_loss=5.11, nll_loss=2.33, w2v_ctc_loss=0.73, task_loss=2.102, contrastive_loss=0.098, total=4160.97, n_correct=2574.56, ppl=5.03, accuracy=61.874, wps=12103.6, ups=1.45, wpb=8321.9, bsz=302.9, num_updates=17800, lr=0.000106, gnorm=0.554, clip=0, loss_scale=64, train_wall=68, gb_free=16.3, wall=15915
2023-07-31 15:59:58 | INFO | train_inner | epoch 013:    221 / 1474 loss=2.1, trans_loss=5.121, nll_loss=2.347, w2v_ctc_loss=0.724, task_loss=1.935, contrastive_loss=0.318, total=4212.08, n_correct=2595.99, ppl=5.09, accuracy=61.632, wps=12346.4, ups=1.47, wpb=8424.2, bsz=329.7, num_updates=17900, lr=0.000105703, gnorm=0.555, clip=0, loss_scale=64, train_wall=68, gb_free=14.5, wall=15984
2023-07-31 16:01:05 | INFO | train_inner | epoch 013:    321 / 1474 loss=2.084, trans_loss=5.112, nll_loss=2.333, w2v_ctc_loss=0.724, task_loss=2.179, contrastive_loss=0.082, total=4102.3, n_correct=2537.76, ppl=5.04, accuracy=61.862, wps=12142, ups=1.48, wpb=8204.6, bsz=294.1, num_updates=18000, lr=0.000105409, gnorm=0.554, clip=0, loss_scale=64, train_wall=67, gb_free=17.3, wall=16051
2023-07-31 16:01:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 16:01:31 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.251 | trans_loss 5.624 | nll_loss 2.915 | w2v_ctc_loss 1.373 | task_loss 6.903 | contrastive_loss 0.277 | total 4003.4 | n_correct 2443 | ppl 7.54 | accuracy 61.023 | uer 18.058 | wer 19.742 | raw_wer 19.742 | bleu 19.55 | wps 1902.9 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.55
2023-07-31 16:01:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-07-31 16:01:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_13_18000.pt
2023-07-31 16:01:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_13_18000.pt
2023-07-31 16:01:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.55) (writing took 23.101980552077293 seconds)
2023-07-31 16:03:03 | INFO | train_inner | epoch 013:    421 / 1474 loss=2.089, trans_loss=5.12, nll_loss=2.345, w2v_ctc_loss=0.731, task_loss=1.964, contrastive_loss=0.133, total=4177.29, n_correct=2581.86, ppl=5.08, accuracy=61.807, wps=7081.5, ups=0.85, wpb=8354.6, bsz=318.4, num_updates=18100, lr=0.000105118, gnorm=0.549, clip=0, loss_scale=64, train_wall=68, gb_free=17.5, wall=16169
2023-07-31 16:04:12 | INFO | train_inner | epoch 013:    521 / 1474 loss=2.096, trans_loss=5.128, nll_loss=2.356, w2v_ctc_loss=0.733, task_loss=2.037, contrastive_loss=0.17, total=4201.22, n_correct=2581.21, ppl=5.12, accuracy=61.44, wps=12235.3, ups=1.46, wpb=8402.4, bsz=319, num_updates=18200, lr=0.000104828, gnorm=0.558, clip=0, loss_scale=64, train_wall=68, gb_free=12.8, wall=16238
2023-07-31 16:05:19 | INFO | train_inner | epoch 013:    621 / 1474 loss=2.086, trans_loss=5.123, nll_loss=2.349, w2v_ctc_loss=0.727, task_loss=2.042, contrastive_loss=0.08, total=4161.98, n_correct=2568.88, ppl=5.1, accuracy=61.723, wps=12337.7, ups=1.48, wpb=8324, bsz=308.3, num_updates=18300, lr=0.000104542, gnorm=0.554, clip=0, loss_scale=64, train_wall=67, gb_free=15.8, wall=16305
2023-07-31 16:06:27 | INFO | train_inner | epoch 013:    721 / 1474 loss=2.106, trans_loss=5.138, nll_loss=2.366, w2v_ctc_loss=0.755, task_loss=2.336, contrastive_loss=0.077, total=4096.76, n_correct=2507.98, ppl=5.16, accuracy=61.219, wps=12069.2, ups=1.47, wpb=8193.5, bsz=284.6, num_updates=18400, lr=0.000104257, gnorm=0.571, clip=0, loss_scale=64, train_wall=67, gb_free=16.6, wall=16373
2023-07-31 16:07:36 | INFO | train_inner | epoch 013:    821 / 1474 loss=2.1, trans_loss=5.135, nll_loss=2.365, w2v_ctc_loss=0.738, task_loss=2.117, contrastive_loss=0.132, total=4121.73, n_correct=2530.13, ppl=5.15, accuracy=61.385, wps=12040.5, ups=1.46, wpb=8243.5, bsz=306.7, num_updates=18500, lr=0.000103975, gnorm=0.57, clip=0, loss_scale=64, train_wall=68, gb_free=14.8, wall=16442
2023-07-31 16:08:44 | INFO | train_inner | epoch 013:    921 / 1474 loss=2.097, trans_loss=5.137, nll_loss=2.367, w2v_ctc_loss=0.737, task_loss=2.144, contrastive_loss=0.089, total=4107.01, n_correct=2523.17, ppl=5.16, accuracy=61.436, wps=12094.9, ups=1.47, wpb=8214, bsz=296.5, num_updates=18600, lr=0.000103695, gnorm=0.562, clip=0, loss_scale=64, train_wall=67, gb_free=15.9, wall=16510
2023-07-31 16:09:51 | INFO | train_inner | epoch 013:   1021 / 1474 loss=2.105, trans_loss=5.14, nll_loss=2.371, w2v_ctc_loss=0.743, task_loss=2.217, contrastive_loss=0.14, total=4081.02, n_correct=2498.96, ppl=5.17, accuracy=61.234, wps=12092.1, ups=1.48, wpb=8162, bsz=293.4, num_updates=18700, lr=0.000103418, gnorm=0.578, clip=0, loss_scale=64, train_wall=67, gb_free=16.2, wall=16577
2023-07-31 16:10:58 | INFO | train_inner | epoch 013:   1121 / 1474 loss=2.092, trans_loss=5.13, nll_loss=2.358, w2v_ctc_loss=0.731, task_loss=2.067, contrastive_loss=0.121, total=4105.62, n_correct=2530.64, ppl=5.13, accuracy=61.638, wps=12216.2, ups=1.49, wpb=8211.2, bsz=305.9, num_updates=18800, lr=0.000103142, gnorm=0.555, clip=0, loss_scale=64, train_wall=67, gb_free=16.7, wall=16644
2023-07-31 16:12:07 | INFO | train_inner | epoch 013:   1221 / 1474 loss=2.1, trans_loss=5.144, nll_loss=2.377, w2v_ctc_loss=0.742, task_loss=2.235, contrastive_loss=0.08, total=4110.35, n_correct=2523.95, ppl=5.19, accuracy=61.405, wps=11944, ups=1.45, wpb=8220.7, bsz=295.1, num_updates=18900, lr=0.000102869, gnorm=0.573, clip=0, loss_scale=64, train_wall=68, gb_free=14.8, wall=16713
2023-07-31 16:13:16 | INFO | train_inner | epoch 013:   1321 / 1474 loss=2.097, trans_loss=5.13, nll_loss=2.36, w2v_ctc_loss=0.734, task_loss=2.068, contrastive_loss=0.18, total=4112.2, n_correct=2531.97, ppl=5.14, accuracy=61.572, wps=12036.7, ups=1.46, wpb=8224.4, bsz=308.2, num_updates=19000, lr=0.000102598, gnorm=0.561, clip=0, loss_scale=64, train_wall=68, gb_free=17.6, wall=16781
2023-07-31 16:14:24 | INFO | train_inner | epoch 013:   1421 / 1474 loss=2.102, trans_loss=5.143, nll_loss=2.377, w2v_ctc_loss=0.73, task_loss=2.059, contrastive_loss=0.192, total=4180.88, n_correct=2563.87, ppl=5.2, accuracy=61.324, wps=12299.2, ups=1.47, wpb=8361.8, bsz=312.2, num_updates=19100, lr=0.000102329, gnorm=0.555, clip=0, loss_scale=64, train_wall=67, gb_free=15.2, wall=16849
2023-07-31 16:14:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 16:15:23 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.235 | trans_loss 5.618 | nll_loss 2.907 | w2v_ctc_loss 1.338 | task_loss 6.931 | contrastive_loss 0.269 | total 4003.4 | n_correct 2444.6 | ppl 7.5 | accuracy 61.063 | uer 17.657 | wer 19.466 | raw_wer 19.466 | bleu 19.4 | wps 2148.2 | wpb 4003.4 | bsz 141.8 | num_updates 19153 | best_bleu 19.55
2023-07-31 16:15:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19153 updates
2023-07-31 16:15:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.4004.pt
2023-07-31 16:15:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.4004.pt
2023-07-31 16:15:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.4004.pt (epoch 13 @ 19153 updates, score 19.4) (writing took 12.791980534791946 seconds)
2023-07-31 16:15:36 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-07-31 16:15:36 | INFO | train | epoch 013 | loss 2.096 | trans_loss 5.129 | nll_loss 2.357 | w2v_ctc_loss 0.734 | task_loss 2.099 | contrastive_loss 0.135 | total 4138.65 | n_correct 2547.45 | ppl 5.12 | accuracy 61.553 | wps 11110 | ups 1.34 | wpb 8277.3 | bsz 305.7 | num_updates 19153 | lr 0.000102187 | gnorm 0.56 | clip 0 | loss_scale 64 | train_wall 995 | gb_free 17.6 | wall 16922
2023-07-31 16:15:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 16:15:37 | INFO | fairseq.trainer | begin training epoch 14
2023-07-31 16:15:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 16:16:16 | INFO | train_inner | epoch 014:     47 / 1474 loss=2.072, trans_loss=5.098, nll_loss=2.319, w2v_ctc_loss=0.722, task_loss=1.918, contrastive_loss=0.096, total=4176.2, n_correct=2602.76, ppl=4.99, accuracy=62.324, wps=7433.6, ups=0.89, wpb=8352.4, bsz=322.3, num_updates=19200, lr=0.000102062, gnorm=0.551, clip=0, loss_scale=64, train_wall=67, gb_free=10.5, wall=16962
2023-07-31 16:17:24 | INFO | train_inner | epoch 014:    147 / 1474 loss=2.072, trans_loss=5.087, nll_loss=2.302, w2v_ctc_loss=0.725, task_loss=2.121, contrastive_loss=0.078, total=4080.86, n_correct=2548.26, ppl=4.93, accuracy=62.444, wps=11985.2, ups=1.47, wpb=8161.7, bsz=299.6, num_updates=19300, lr=0.000101797, gnorm=0.553, clip=0, loss_scale=64, train_wall=68, gb_free=16.9, wall=17030
2023-07-31 16:18:32 | INFO | train_inner | epoch 014:    247 / 1474 loss=2.088, trans_loss=5.106, nll_loss=2.326, w2v_ctc_loss=0.726, task_loss=2.209, contrastive_loss=0.179, total=4106.97, n_correct=2547.74, ppl=5.01, accuracy=62.035, wps=12129.9, ups=1.48, wpb=8213.9, bsz=293.3, num_updates=19400, lr=0.000101535, gnorm=0.562, clip=0, loss_scale=64, train_wall=67, gb_free=12.2, wall=17098
2023-07-31 16:19:39 | INFO | train_inner | epoch 014:    347 / 1474 loss=2.071, trans_loss=5.095, nll_loss=2.313, w2v_ctc_loss=0.718, task_loss=1.924, contrastive_loss=0.115, total=4179.8, n_correct=2604.63, ppl=4.97, accuracy=62.315, wps=12415.6, ups=1.49, wpb=8359.6, bsz=322.5, num_updates=19500, lr=0.000101274, gnorm=0.557, clip=0, loss_scale=64, train_wall=67, gb_free=17.3, wall=17165
2023-07-31 16:20:47 | INFO | train_inner | epoch 014:    447 / 1474 loss=2.079, trans_loss=5.112, nll_loss=2.335, w2v_ctc_loss=0.719, task_loss=2.163, contrastive_loss=0.072, total=4120.38, n_correct=2552.04, ppl=5.05, accuracy=61.937, wps=12133.8, ups=1.47, wpb=8240.8, bsz=296.3, num_updates=19600, lr=0.000101015, gnorm=0.559, clip=0, loss_scale=64, train_wall=67, gb_free=17.1, wall=17233
2023-07-31 16:21:56 | INFO | train_inner | epoch 014:    547 / 1474 loss=2.093, trans_loss=5.115, nll_loss=2.337, w2v_ctc_loss=0.743, task_loss=2.226, contrastive_loss=0.11, total=4089.86, n_correct=2527.79, ppl=5.05, accuracy=61.806, wps=11879.8, ups=1.45, wpb=8179.7, bsz=295.5, num_updates=19700, lr=0.000100759, gnorm=0.568, clip=0, loss_scale=64, train_wall=68, gb_free=11.9, wall=17302
2023-07-31 16:23:04 | INFO | train_inner | epoch 014:    647 / 1474 loss=2.085, trans_loss=5.111, nll_loss=2.333, w2v_ctc_loss=0.723, task_loss=2.101, contrastive_loss=0.153, total=4158.94, n_correct=2576.17, ppl=5.04, accuracy=61.943, wps=12257.5, ups=1.47, wpb=8317.9, bsz=306.7, num_updates=19800, lr=0.000100504, gnorm=0.557, clip=0, loss_scale=128, train_wall=67, gb_free=16.1, wall=17370
2023-07-31 16:24:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-31 16:24:12 | INFO | train_inner | epoch 014:    748 / 1474 loss=2.072, trans_loss=5.102, nll_loss=2.323, w2v_ctc_loss=0.717, task_loss=2.034, contrastive_loss=0.084, total=4142.69, n_correct=2576.31, ppl=5, accuracy=62.189, wps=12084.7, ups=1.46, wpb=8285.4, bsz=310.2, num_updates=19900, lr=0.000100251, gnorm=0.556, clip=0, loss_scale=64, train_wall=68, gb_free=16.2, wall=17438
2023-07-31 16:24:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-31 16:25:21 | INFO | train_inner | epoch 014:    849 / 1474 loss=2.076, trans_loss=5.105, nll_loss=2.327, w2v_ctc_loss=0.725, task_loss=2.046, contrastive_loss=0.084, total=4153.2, n_correct=2579.93, ppl=5.02, accuracy=62.119, wps=12067.2, ups=1.45, wpb=8306.4, bsz=312, num_updates=20000, lr=0.0001, gnorm=0.559, clip=0, loss_scale=32, train_wall=68, gb_free=12.6, wall=17507
2023-07-31 16:25:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 16:25:45 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.228 | trans_loss 5.606 | nll_loss 2.895 | w2v_ctc_loss 1.341 | task_loss 6.891 | contrastive_loss 0.269 | total 4003.4 | n_correct 2450.7 | ppl 7.44 | accuracy 61.215 | uer 17.809 | wer 19.694 | raw_wer 19.694 | bleu 19.36 | wps 2033.7 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.55
2023-07-31 16:25:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-07-31 16:25:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_14_20000.pt
2023-07-31 16:25:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_14_20000.pt
2023-07-31 16:26:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.36) (writing took 22.261444421485066 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:0')
2023-07-31 16:27:17 | INFO | train_inner | epoch 014:    949 / 1474 loss=2.083, trans_loss=5.116, nll_loss=2.341, w2v_ctc_loss=0.722, task_loss=2.091, contrastive_loss=0.128, total=4166.71, n_correct=2578.79, ppl=5.07, accuracy=61.89, wps=7196.7, ups=0.86, wpb=8333.4, bsz=310.6, num_updates=20100, lr=9.97509e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=17623
2023-07-31 16:28:26 | INFO | train_inner | epoch 014:   1049 / 1474 loss=2.083, trans_loss=5.119, nll_loss=2.345, w2v_ctc_loss=0.721, task_loss=2.127, contrastive_loss=0.106, total=4145.57, n_correct=2566.1, ppl=5.08, accuracy=61.9, wps=12081.8, ups=1.46, wpb=8291.1, bsz=301.1, num_updates=20200, lr=9.95037e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=17691
2023-07-31 16:29:34 | INFO | train_inner | epoch 014:   1149 / 1474 loss=2.103, trans_loss=5.118, nll_loss=2.345, w2v_ctc_loss=0.73, task_loss=1.984, contrastive_loss=0.386, total=4219.9, n_correct=2605.18, ppl=5.08, accuracy=61.736, wps=12303.5, ups=1.46, wpb=8439.8, bsz=325.2, num_updates=20300, lr=9.92583e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=17760
2023-07-31 16:30:42 | INFO | train_inner | epoch 014:   1249 / 1474 loss=2.098, trans_loss=5.137, nll_loss=2.368, w2v_ctc_loss=0.742, task_loss=2.437, contrastive_loss=0.065, total=4032.06, n_correct=2477.07, ppl=5.16, accuracy=61.434, wps=11947.1, ups=1.48, wpb=8064.1, bsz=274.4, num_updates=20400, lr=9.90148e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=67, gb_free=17.6, wall=17828
2023-07-31 16:31:51 | INFO | train_inner | epoch 014:   1349 / 1474 loss=2.08, trans_loss=5.123, nll_loss=2.351, w2v_ctc_loss=0.719, task_loss=1.991, contrastive_loss=0.086, total=4205.07, n_correct=2601.56, ppl=5.1, accuracy=61.867, wps=12215.7, ups=1.45, wpb=8410.1, bsz=317.3, num_updates=20500, lr=9.8773e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=17896
2023-07-31 16:32:58 | INFO | train_inner | epoch 014:   1449 / 1474 loss=2.088, trans_loss=5.128, nll_loss=2.359, w2v_ctc_loss=0.724, task_loss=2.099, contrastive_loss=0.124, total=4126.44, n_correct=2546.23, ppl=5.13, accuracy=61.705, wps=12209.8, ups=1.48, wpb=8252.9, bsz=303.9, num_updates=20600, lr=9.85329e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=67, gb_free=16.1, wall=17964
2023-07-31 16:33:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:2')
2023-07-31 16:33:39 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.218 | trans_loss 5.601 | nll_loss 2.893 | w2v_ctc_loss 1.319 | task_loss 6.884 | contrastive_loss 0.268 | total 4003.4 | n_correct 2455.8 | ppl 7.43 | accuracy 61.343 | uer 17.503 | wer 19.321 | raw_wer 19.321 | bleu 19.85 | wps 2120.5 | wpb 4003.4 | bsz 141.8 | num_updates 20625 | best_bleu 19.85
2023-07-31 16:33:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20625 updates
2023-07-31 16:33:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 16:33:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 16:34:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt (epoch 14 @ 20625 updates, score 19.85) (writing took 20.921510877087712 seconds)
2023-07-31 16:34:01 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-07-31 16:34:01 | INFO | train | epoch 014 | loss 2.083 | trans_loss 5.112 | nll_loss 2.335 | w2v_ctc_loss 0.725 | task_loss 2.102 | contrastive_loss 0.126 | total 4136.85 | n_correct 2563.25 | ppl 5.05 | accuracy 61.961 | wps 11026.7 | ups 1.33 | wpb 8273.7 | bsz 305.2 | num_updates 20625 | lr 9.84732e-05 | gnorm 0.56 | clip 0 | loss_scale 32 | train_wall 996 | gb_free 16.4 | wall 18027
2023-07-31 16:34:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 16:34:01 | INFO | fairseq.trainer | begin training epoch 15
2023-07-31 16:34:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 16:35:00 | INFO | train_inner | epoch 015:     75 / 1474 loss=2.078, trans_loss=5.098, nll_loss=2.318, w2v_ctc_loss=0.718, task_loss=2.104, contrastive_loss=0.173, total=4090.99, n_correct=2547.13, ppl=4.99, accuracy=62.262, wps=6726.8, ups=0.82, wpb=8182, bsz=300.8, num_updates=20700, lr=9.82946e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=67, gb_free=16.8, wall=18086
2023-07-31 16:36:08 | INFO | train_inner | epoch 015:    175 / 1474 loss=2.072, trans_loss=5.088, nll_loss=2.303, w2v_ctc_loss=0.725, task_loss=2.173, contrastive_loss=0.082, total=4115.56, n_correct=2569, ppl=4.93, accuracy=62.422, wps=12088.3, ups=1.47, wpb=8231.1, bsz=298.5, num_updates=20800, lr=9.80581e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=18154
2023-07-31 16:37:16 | INFO | train_inner | epoch 015:    275 / 1474 loss=2.063, trans_loss=5.089, nll_loss=2.305, w2v_ctc_loss=0.709, task_loss=2.042, contrastive_loss=0.072, total=4182.19, n_correct=2615.72, ppl=4.94, accuracy=62.544, wps=12281, ups=1.47, wpb=8364.4, bsz=310.5, num_updates=20900, lr=9.78232e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=18222
2023-07-31 16:38:24 | INFO | train_inner | epoch 015:    375 / 1474 loss=2.065, trans_loss=5.081, nll_loss=2.294, w2v_ctc_loss=0.712, task_loss=2.098, contrastive_loss=0.101, total=4172.52, n_correct=2611.42, ppl=4.9, accuracy=62.586, wps=12350.6, ups=1.48, wpb=8345, bsz=307.7, num_updates=21000, lr=9.759e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=18289
2023-07-31 16:39:31 | INFO | train_inner | epoch 015:    475 / 1474 loss=2.074, trans_loss=5.093, nll_loss=2.31, w2v_ctc_loss=0.704, task_loss=2.202, contrastive_loss=0.187, total=4076.84, n_correct=2541.15, ppl=4.96, accuracy=62.331, wps=12013.4, ups=1.47, wpb=8153.7, bsz=293.4, num_updates=21100, lr=9.73585e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=18357
2023-07-31 16:40:39 | INFO | train_inner | epoch 015:    575 / 1474 loss=2.071, trans_loss=5.092, nll_loss=2.309, w2v_ctc_loss=0.717, task_loss=2.147, contrastive_loss=0.102, total=4156.05, n_correct=2592.53, ppl=4.96, accuracy=62.38, wps=12227.8, ups=1.47, wpb=8312.1, bsz=302.8, num_updates=21200, lr=9.71286e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=67, gb_free=11.6, wall=18425
2023-07-31 16:41:48 | INFO | train_inner | epoch 015:    675 / 1474 loss=2.079, trans_loss=5.094, nll_loss=2.312, w2v_ctc_loss=0.724, task_loss=2.149, contrastive_loss=0.15, total=4118.87, n_correct=2564.73, ppl=4.97, accuracy=62.268, wps=12005.5, ups=1.46, wpb=8237.7, bsz=303, num_updates=21300, lr=9.69003e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=18494
2023-07-31 16:42:56 | INFO | train_inner | epoch 015:    775 / 1474 loss=2.072, trans_loss=5.101, nll_loss=2.321, w2v_ctc_loss=0.719, task_loss=2.114, contrastive_loss=0.084, total=4176.64, n_correct=2600.76, ppl=5, accuracy=62.269, wps=12201.8, ups=1.46, wpb=8353.3, bsz=305.3, num_updates=21400, lr=9.66736e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=68, gb_free=13.9, wall=18562
2023-07-31 16:44:04 | INFO | train_inner | epoch 015:    875 / 1474 loss=2.079, trans_loss=5.106, nll_loss=2.328, w2v_ctc_loss=0.725, task_loss=2.265, contrastive_loss=0.078, total=4056.99, n_correct=2519.99, ppl=5.02, accuracy=62.115, wps=11999.6, ups=1.48, wpb=8114, bsz=288, num_updates=21500, lr=9.64486e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=67, gb_free=17.3, wall=18630
2023-07-31 16:45:12 | INFO | train_inner | epoch 015:    975 / 1474 loss=2.076, trans_loss=5.101, nll_loss=2.322, w2v_ctc_loss=0.716, task_loss=2.084, contrastive_loss=0.162, total=4134.44, n_correct=2573.23, ppl=5, accuracy=62.239, wps=12170.1, ups=1.47, wpb=8268.9, bsz=304.8, num_updates=21600, lr=9.6225e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=67, gb_free=16, wall=18698
2023-07-31 16:46:21 | INFO | train_inner | epoch 015:   1075 / 1474 loss=2.089, trans_loss=5.107, nll_loss=2.331, w2v_ctc_loss=0.72, task_loss=1.976, contrastive_loss=0.324, total=4185.02, n_correct=2596.9, ppl=5.03, accuracy=62.052, wps=12138.7, ups=1.45, wpb=8370, bsz=324.2, num_updates=21700, lr=9.60031e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=18767
2023-07-31 16:47:29 | INFO | train_inner | epoch 015:   1175 / 1474 loss=2.059, trans_loss=5.094, nll_loss=2.316, w2v_ctc_loss=0.696, task_loss=1.876, contrastive_loss=0.127, total=4187.68, n_correct=2622.34, ppl=4.98, accuracy=62.62, wps=12396, ups=1.48, wpb=8375.4, bsz=329.7, num_updates=21800, lr=9.57826e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=18834
2023-07-31 16:48:37 | INFO | train_inner | epoch 015:   1275 / 1474 loss=2.078, trans_loss=5.105, nll_loss=2.327, w2v_ctc_loss=0.729, task_loss=2.167, contrastive_loss=0.082, total=4141.6, n_correct=2572.76, ppl=5.02, accuracy=62.12, wps=12135.7, ups=1.47, wpb=8283.2, bsz=301.1, num_updates=21900, lr=9.55637e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=68, gb_free=13.4, wall=18903
2023-07-31 16:49:44 | INFO | train_inner | epoch 015:   1375 / 1474 loss=2.069, trans_loss=5.103, nll_loss=2.324, w2v_ctc_loss=0.714, task_loss=2.175, contrastive_loss=0.065, total=4099.6, n_correct=2554.97, ppl=5.01, accuracy=62.322, wps=12132, ups=1.48, wpb=8199.2, bsz=293.2, num_updates=22000, lr=9.53463e-05, gnorm=0.558, clip=0, loss_scale=64, train_wall=67, gb_free=14.3, wall=18970
2023-07-31 16:49:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 16:50:09 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.215 | trans_loss 5.602 | nll_loss 2.887 | w2v_ctc_loss 1.308 | task_loss 6.92 | contrastive_loss 0.265 | total 4003.4 | n_correct 2458.4 | ppl 7.4 | accuracy 61.408 | uer 17.67 | wer 19.358 | raw_wer 19.358 | bleu 19.73 | wps 2142.3 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 19.85
2023-07-31 16:50:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-07-31 16:50:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_15_22000.pt
2023-07-31 16:50:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_15_22000.pt
2023-07-31 16:50:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.73) (writing took 19.48920531757176 seconds)
2023-07-31 16:51:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-31 16:51:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 16:52:02 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.24 | trans_loss 5.601 | nll_loss 2.887 | w2v_ctc_loss 1.391 | task_loss 6.896 | contrastive_loss 0.268 | total 4003.4 | n_correct 2451.7 | ppl 7.4 | accuracy 61.24 | uer 17.912 | wer 19.735 | raw_wer 19.735 | bleu 19.69 | wps 1999.1 | wpb 4003.4 | bsz 141.8 | num_updates 22098 | best_bleu 19.85
2023-07-31 16:52:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22098 updates
2023-07-31 16:52:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.6900.pt
2023-07-31 16:52:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.6900.pt
2023-07-31 16:52:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.6900.pt (epoch 15 @ 22098 updates, score 19.69) (writing took 11.690560715273023 seconds)
2023-07-31 16:52:14 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-07-31 16:52:14 | INFO | train | epoch 015 | loss 2.072 | trans_loss 5.096 | nll_loss 2.315 | w2v_ctc_loss 0.716 | task_loss 2.099 | contrastive_loss 0.132 | total 4138.87 | n_correct 2580.28 | ppl 4.98 | accuracy 62.343 | wps 11155.4 | ups 1.35 | wpb 8277.7 | bsz 305.7 | num_updates 22098 | lr 9.51346e-05 | gnorm 0.562 | clip 0 | loss_scale 32 | train_wall 996 | gb_free 16.9 | wall 19120
2023-07-31 16:52:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 16:52:14 | INFO | fairseq.trainer | begin training epoch 16
2023-07-31 16:52:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 16:52:23 | INFO | train_inner | epoch 016:      2 / 1474 loss=2.076, trans_loss=5.105, nll_loss=2.33, w2v_ctc_loss=0.716, task_loss=1.992, contrastive_loss=0.158, total=4158.15, n_correct=2589.84, ppl=5.03, accuracy=62.283, wps=5248.3, ups=0.63, wpb=8316.3, bsz=317.9, num_updates=22100, lr=9.51303e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=19129
2023-07-31 16:53:30 | INFO | train_inner | epoch 016:    102 / 1474 loss=2.053, trans_loss=5.063, nll_loss=2.272, w2v_ctc_loss=0.707, task_loss=2.017, contrastive_loss=0.103, total=4115.14, n_correct=2590.09, ppl=4.83, accuracy=62.941, wps=12178.8, ups=1.48, wpb=8230.3, bsz=313.9, num_updates=22200, lr=9.49158e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=67, gb_free=12.4, wall=19196
2023-07-31 16:54:39 | INFO | train_inner | epoch 016:    202 / 1474 loss=2.051, trans_loss=5.064, nll_loss=2.273, w2v_ctc_loss=0.699, task_loss=2.151, contrastive_loss=0.075, total=4109.58, n_correct=2591.32, ppl=4.83, accuracy=63.056, wps=12071.1, ups=1.47, wpb=8219.2, bsz=297.3, num_updates=22300, lr=9.47027e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=68, gb_free=14.9, wall=19264
2023-07-31 16:55:47 | INFO | train_inner | epoch 016:    302 / 1474 loss=2.065, trans_loss=5.076, nll_loss=2.29, w2v_ctc_loss=0.71, task_loss=2.082, contrastive_loss=0.149, total=4164.1, n_correct=2610.85, ppl=4.89, accuracy=62.699, wps=12172.3, ups=1.46, wpb=8328.2, bsz=308.6, num_updates=22400, lr=9.44911e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=19333
2023-07-31 16:56:55 | INFO | train_inner | epoch 016:    402 / 1474 loss=2.069, trans_loss=5.077, nll_loss=2.289, w2v_ctc_loss=0.716, task_loss=2.252, contrastive_loss=0.162, total=4065.22, n_correct=2549.21, ppl=4.89, accuracy=62.708, wps=11952.7, ups=1.47, wpb=8130.4, bsz=286.4, num_updates=22500, lr=9.42809e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=19401
2023-07-31 16:58:04 | INFO | train_inner | epoch 016:    502 / 1474 loss=2.056, trans_loss=5.075, nll_loss=2.289, w2v_ctc_loss=0.705, task_loss=2.007, contrastive_loss=0.108, total=4181.93, n_correct=2631.41, ppl=4.89, accuracy=62.923, wps=12143.1, ups=1.45, wpb=8363.9, bsz=320.3, num_updates=22600, lr=9.40721e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=19470
2023-07-31 16:59:11 | INFO | train_inner | epoch 016:    602 / 1474 loss=2.054, trans_loss=5.075, nll_loss=2.288, w2v_ctc_loss=0.701, task_loss=2.094, contrastive_loss=0.068, total=4122.97, n_correct=2591.06, ppl=4.88, accuracy=62.845, wps=12242.4, ups=1.48, wpb=8245.9, bsz=299, num_updates=22700, lr=9.38647e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=67, gb_free=16.1, wall=19537
2023-07-31 17:00:20 | INFO | train_inner | epoch 016:    702 / 1474 loss=2.06, trans_loss=5.082, nll_loss=2.297, w2v_ctc_loss=0.709, task_loss=2.156, contrastive_loss=0.07, total=4093.15, n_correct=2563.99, ppl=4.91, accuracy=62.641, wps=11909.3, ups=1.45, wpb=8186.3, bsz=296.5, num_updates=22800, lr=9.36586e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=68, gb_free=17.8, wall=19606
2023-07-31 17:01:29 | INFO | train_inner | epoch 016:    802 / 1474 loss=2.059, trans_loss=5.082, nll_loss=2.298, w2v_ctc_loss=0.699, task_loss=2.013, contrastive_loss=0.134, total=4183.24, n_correct=2625.63, ppl=4.92, accuracy=62.765, wps=12142.8, ups=1.45, wpb=8366.5, bsz=312.1, num_updates=22900, lr=9.34539e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=68, gb_free=17.8, wall=19675
2023-07-31 17:02:38 | INFO | train_inner | epoch 016:    902 / 1474 loss=2.061, trans_loss=5.08, nll_loss=2.296, w2v_ctc_loss=0.704, task_loss=2.071, contrastive_loss=0.126, total=4150.23, n_correct=2607.1, ppl=4.91, accuracy=62.818, wps=12062.2, ups=1.45, wpb=8300.5, bsz=306.5, num_updates=23000, lr=9.32505e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=68, gb_free=12, wall=19744
2023-07-31 17:03:46 | INFO | train_inner | epoch 016:   1002 / 1474 loss=2.072, trans_loss=5.095, nll_loss=2.314, w2v_ctc_loss=0.717, task_loss=2.161, contrastive_loss=0.125, total=4116.59, n_correct=2565.74, ppl=4.97, accuracy=62.327, wps=12040.4, ups=1.46, wpb=8233.2, bsz=300.6, num_updates=23100, lr=9.30484e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=19812
2023-07-31 17:04:55 | INFO | train_inner | epoch 016:   1102 / 1474 loss=2.074, trans_loss=5.099, nll_loss=2.32, w2v_ctc_loss=0.721, task_loss=2.227, contrastive_loss=0.101, total=4112.71, n_correct=2563.31, ppl=4.99, accuracy=62.327, wps=11877.1, ups=1.44, wpb=8225.4, bsz=295.7, num_updates=23200, lr=9.28477e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=69, gb_free=12.1, wall=19881
2023-07-31 17:06:04 | INFO | train_inner | epoch 016:   1202 / 1474 loss=2.064, trans_loss=5.088, nll_loss=2.307, w2v_ctc_loss=0.695, task_loss=2.13, contrastive_loss=0.194, total=4161.11, n_correct=2604.1, ppl=4.95, accuracy=62.582, wps=12051.4, ups=1.45, wpb=8322.2, bsz=308.2, num_updates=23300, lr=9.26482e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=19950
2023-07-31 17:07:13 | INFO | train_inner | epoch 016:   1302 / 1474 loss=2.071, trans_loss=5.092, nll_loss=2.312, w2v_ctc_loss=0.717, task_loss=2.064, contrastive_loss=0.173, total=4149.14, n_correct=2595.88, ppl=4.96, accuracy=62.564, wps=12060.4, ups=1.45, wpb=8298.3, bsz=311.9, num_updates=23400, lr=9.245e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=68, gb_free=11.2, wall=20019
2023-07-31 17:08:22 | INFO | train_inner | epoch 016:   1402 / 1474 loss=2.065, trans_loss=5.095, nll_loss=2.316, w2v_ctc_loss=0.713, task_loss=1.99, contrastive_loss=0.107, total=4200.01, n_correct=2623.15, ppl=4.98, accuracy=62.456, wps=12227.6, ups=1.46, wpb=8400, bsz=322.2, num_updates=23500, lr=9.22531e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=20088
2023-07-31 17:08:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-31 17:09:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 17:09:36 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.211 | trans_loss 5.59 | nll_loss 2.873 | w2v_ctc_loss 1.325 | task_loss 6.899 | contrastive_loss 0.26 | total 4003.4 | n_correct 2467 | ppl 7.33 | accuracy 61.623 | uer 17.344 | wer 19.004 | raw_wer 19.004 | bleu 19.88 | wps 2020.4 | wpb 4003.4 | bsz 141.8 | num_updates 23571 | best_bleu 19.88
2023-07-31 17:09:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23571 updates
2023-07-31 17:09:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 17:09:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 17:10:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt (epoch 16 @ 23571 updates, score 19.88) (writing took 26.299966797232628 seconds)
2023-07-31 17:10:03 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-07-31 17:10:03 | INFO | train | epoch 016 | loss 2.063 | trans_loss 5.082 | nll_loss 2.298 | w2v_ctc_loss 0.708 | task_loss 2.104 | contrastive_loss 0.118 | total 4136.64 | n_correct 2592.61 | ppl 4.92 | accuracy 62.674 | wps 11401.2 | ups 1.38 | wpb 8273.3 | bsz 304.9 | num_updates 23571 | lr 9.21141e-05 | gnorm 0.563 | clip 0 | loss_scale 16 | train_wall 1003 | gb_free 15.4 | wall 20189
2023-07-31 17:10:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 17:10:03 | INFO | fairseq.trainer | begin training epoch 17
2023-07-31 17:10:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 17:10:31 | INFO | train_inner | epoch 017:     29 / 1474 loss=2.061, trans_loss=5.08, nll_loss=2.295, w2v_ctc_loss=0.71, task_loss=2.256, contrastive_loss=0.066, total=4106.38, n_correct=2569.85, ppl=4.91, accuracy=62.582, wps=6355.2, ups=0.77, wpb=8212.8, bsz=288.8, num_updates=23600, lr=9.20575e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=69, gb_free=17.7, wall=20217
2023-07-31 17:11:40 | INFO | train_inner | epoch 017:    129 / 1474 loss=2.047, trans_loss=5.051, nll_loss=2.256, w2v_ctc_loss=0.703, task_loss=2.16, contrastive_loss=0.074, total=4110.37, n_correct=2599.92, ppl=4.78, accuracy=63.253, wps=12002, ups=1.46, wpb=8220.7, bsz=295.6, num_updates=23700, lr=9.1863e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=68, gb_free=16.5, wall=20286
2023-07-31 17:12:48 | INFO | train_inner | epoch 017:    229 / 1474 loss=2.051, trans_loss=5.053, nll_loss=2.261, w2v_ctc_loss=0.685, task_loss=1.962, contrastive_loss=0.242, total=4181.59, n_correct=2645.84, ppl=4.79, accuracy=63.274, wps=12261.3, ups=1.47, wpb=8363.2, bsz=322.2, num_updates=23800, lr=9.16698e-05, gnorm=0.555, clip=0, loss_scale=16, train_wall=68, gb_free=15.8, wall=20354
2023-07-31 17:13:56 | INFO | train_inner | epoch 017:    329 / 1474 loss=2.057, trans_loss=5.061, nll_loss=2.27, w2v_ctc_loss=0.697, task_loss=2.112, contrastive_loss=0.243, total=4157.97, n_correct=2623.26, ppl=4.82, accuracy=63.09, wps=12293.3, ups=1.48, wpb=8315.9, bsz=304, num_updates=23900, lr=9.14779e-05, gnorm=0.56, clip=0, loss_scale=16, train_wall=67, gb_free=15.9, wall=20421
2023-07-31 17:15:04 | INFO | train_inner | epoch 017:    429 / 1474 loss=2.045, trans_loss=5.06, nll_loss=2.269, w2v_ctc_loss=0.694, task_loss=2.099, contrastive_loss=0.073, total=4135.12, n_correct=2615.58, ppl=4.82, accuracy=63.253, wps=12001.2, ups=1.45, wpb=8270.2, bsz=306.1, num_updates=24000, lr=9.12871e-05, gnorm=0.56, clip=0, loss_scale=16, train_wall=68, gb_free=12.6, wall=20490
2023-07-31 17:15:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 17:15:29 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.228 | trans_loss 5.594 | nll_loss 2.873 | w2v_ctc_loss 1.371 | task_loss 6.976 | contrastive_loss 0.259 | total 4003.4 | n_correct 2459.8 | ppl 7.33 | accuracy 61.443 | uer 17.681 | wer 19.302 | raw_wer 19.302 | bleu 19.57 | wps 2096.8 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 19.88
2023-07-31 17:15:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-07-31 17:15:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_17_24000.pt
2023-07-31 17:15:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_17_24000.pt
2023-07-31 17:16:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.57) (writing took 34.77633043564856 seconds)
2023-07-31 17:17:14 | INFO | train_inner | epoch 017:    529 / 1474 loss=2.053, trans_loss=5.065, nll_loss=2.276, w2v_ctc_loss=0.701, task_loss=2.176, contrastive_loss=0.12, total=4185.81, n_correct=2633.95, ppl=4.84, accuracy=62.926, wps=6467.1, ups=0.77, wpb=8371.6, bsz=308.6, num_updates=24100, lr=9.10975e-05, gnorm=0.558, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=20620
2023-07-31 17:18:22 | INFO | train_inner | epoch 017:    629 / 1474 loss=2.049, trans_loss=5.07, nll_loss=2.282, w2v_ctc_loss=0.697, task_loss=2.103, contrastive_loss=0.069, total=4168.62, n_correct=2626.42, ppl=4.86, accuracy=63.005, wps=12201.9, ups=1.46, wpb=8337.2, bsz=303.2, num_updates=24200, lr=9.09091e-05, gnorm=0.556, clip=0, loss_scale=16, train_wall=68, gb_free=14.2, wall=20688
2023-07-31 17:19:31 | INFO | train_inner | epoch 017:    729 / 1474 loss=2.061, trans_loss=5.074, nll_loss=2.288, w2v_ctc_loss=0.712, task_loss=2.086, contrastive_loss=0.121, total=4167.34, n_correct=2618.95, ppl=4.88, accuracy=62.845, wps=12185.4, ups=1.46, wpb=8334.7, bsz=307.7, num_updates=24300, lr=9.07218e-05, gnorm=0.565, clip=0, loss_scale=16, train_wall=68, gb_free=9.8, wall=20757
2023-07-31 17:20:39 | INFO | train_inner | epoch 017:    829 / 1474 loss=2.054, trans_loss=5.074, nll_loss=2.286, w2v_ctc_loss=0.703, task_loss=2.116, contrastive_loss=0.081, total=4092.64, n_correct=2575.45, ppl=4.88, accuracy=62.929, wps=11978.3, ups=1.46, wpb=8185.3, bsz=296.2, num_updates=24400, lr=9.05357e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=68, gb_free=15.7, wall=20825
2023-07-31 17:21:46 | INFO | train_inner | epoch 017:    929 / 1474 loss=2.047, trans_loss=5.069, nll_loss=2.282, w2v_ctc_loss=0.693, task_loss=2.062, contrastive_loss=0.08, total=4109.5, n_correct=2589.91, ppl=4.86, accuracy=63.023, wps=12197.4, ups=1.48, wpb=8219, bsz=305.4, num_updates=24500, lr=9.03508e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=67, gb_free=16.5, wall=20892
2023-07-31 17:22:54 | INFO | train_inner | epoch 017:   1029 / 1474 loss=2.053, trans_loss=5.074, nll_loss=2.288, w2v_ctc_loss=0.705, task_loss=2.118, contrastive_loss=0.084, total=4098.36, n_correct=2577.93, ppl=4.88, accuracy=62.902, wps=12052.8, ups=1.47, wpb=8196.7, bsz=301.7, num_updates=24600, lr=9.0167e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=68, gb_free=15.7, wall=20960
2023-07-31 17:24:02 | INFO | train_inner | epoch 017:   1129 / 1474 loss=2.049, trans_loss=5.07, nll_loss=2.283, w2v_ctc_loss=0.695, task_loss=2.139, contrastive_loss=0.075, total=4100.14, n_correct=2582.18, ppl=4.87, accuracy=62.978, wps=12069.7, ups=1.47, wpb=8200.3, bsz=299.3, num_updates=24700, lr=8.99843e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=67, gb_free=16.6, wall=21028
2023-07-31 17:25:11 | INFO | train_inner | epoch 017:   1229 / 1474 loss=2.073, trans_loss=5.083, nll_loss=2.302, w2v_ctc_loss=0.693, task_loss=2.015, contrastive_loss=0.377, total=4173.98, n_correct=2612.06, ppl=4.93, accuracy=62.58, wps=12090.1, ups=1.45, wpb=8348, bsz=325.9, num_updates=24800, lr=8.98027e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=21097
2023-07-31 17:26:20 | INFO | train_inner | epoch 017:   1329 / 1474 loss=2.05, trans_loss=5.076, nll_loss=2.291, w2v_ctc_loss=0.692, task_loss=2.112, contrastive_loss=0.084, total=4146.07, n_correct=2606.35, ppl=4.89, accuracy=62.863, wps=12114.8, ups=1.46, wpb=8292.1, bsz=303.2, num_updates=24900, lr=8.96221e-05, gnorm=0.557, clip=0, loss_scale=16, train_wall=68, gb_free=16.5, wall=21166
2023-07-31 17:27:28 | INFO | train_inner | epoch 017:   1429 / 1474 loss=2.052, trans_loss=5.079, nll_loss=2.295, w2v_ctc_loss=0.698, task_loss=2.127, contrastive_loss=0.075, total=4119.23, n_correct=2588.07, ppl=4.91, accuracy=62.829, wps=12047.1, ups=1.46, wpb=8238.5, bsz=303.4, num_updates=25000, lr=8.94427e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=68, gb_free=13.1, wall=21234
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:0')
2023-07-31 17:27:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:2')
2023-07-31 17:28:23 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.231 | trans_loss 5.589 | nll_loss 2.874 | w2v_ctc_loss 1.39 | task_loss 6.953 | contrastive_loss 0.267 | total 4003.4 | n_correct 2459.8 | ppl 7.33 | accuracy 61.443 | uer 17.684 | wer 19.339 | raw_wer 19.339 | bleu 19.86 | wps 2123.3 | wpb 4003.4 | bsz 141.8 | num_updates 25045 | best_bleu 19.88
2023-07-31 17:28:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25045 updates
2023-07-31 17:28:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.8609.pt
2023-07-31 17:28:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.8609.pt
2023-07-31 17:28:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.8609.pt (epoch 17 @ 25045 updates, score 19.86) (writing took 14.245403628796339 seconds)
2023-07-31 17:28:38 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-07-31 17:28:38 | INFO | train | epoch 017 | loss 2.053 | trans_loss 5.068 | nll_loss 2.281 | w2v_ctc_loss 0.698 | task_loss 2.101 | contrastive_loss 0.128 | total 4138.65 | n_correct 2606.46 | ppl 4.86 | accuracy 62.978 | wps 10942 | ups 1.32 | wpb 8277.3 | bsz 305.7 | num_updates 25045 | lr 8.93623e-05 | gnorm 0.564 | clip 0 | loss_scale 16 | train_wall 1001 | gb_free 16.3 | wall 21304
2023-07-31 17:28:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 17:28:38 | INFO | fairseq.trainer | begin training epoch 18
2023-07-31 17:28:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 17:29:24 | INFO | train_inner | epoch 018:     55 / 1474 loss=2.05, trans_loss=5.064, nll_loss=2.275, w2v_ctc_loss=0.704, task_loss=2.153, contrastive_loss=0.082, total=4128.93, n_correct=2604.02, ppl=4.84, accuracy=63.068, wps=7138.5, ups=0.86, wpb=8257.9, bsz=301.7, num_updates=25100, lr=8.92644e-05, gnorm=0.568, clip=0, loss_scale=16, train_wall=68, gb_free=16.5, wall=21350
2023-07-31 17:30:33 | INFO | train_inner | epoch 018:    155 / 1474 loss=2.038, trans_loss=5.037, nll_loss=2.239, w2v_ctc_loss=0.675, task_loss=1.991, contrastive_loss=0.205, total=4158.38, n_correct=2643.72, ppl=4.72, accuracy=63.576, wps=12068.4, ups=1.45, wpb=8316.8, bsz=313.7, num_updates=25200, lr=8.90871e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=21419
2023-07-31 17:31:42 | INFO | train_inner | epoch 018:    255 / 1474 loss=2.029, trans_loss=5.036, nll_loss=2.238, w2v_ctc_loss=0.684, task_loss=2.036, contrastive_loss=0.076, total=4161.92, n_correct=2653.28, ppl=4.72, accuracy=63.751, wps=12081.2, ups=1.45, wpb=8323.8, bsz=312.8, num_updates=25300, lr=8.89108e-05, gnorm=0.562, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=21488
2023-07-31 17:32:50 | INFO | train_inner | epoch 018:    355 / 1474 loss=2.04, trans_loss=5.048, nll_loss=2.253, w2v_ctc_loss=0.69, task_loss=2.126, contrastive_loss=0.088, total=4167.42, n_correct=2638.97, ppl=4.77, accuracy=63.324, wps=12208, ups=1.46, wpb=8334.8, bsz=301.2, num_updates=25400, lr=8.87357e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=68, gb_free=15.3, wall=21556
2023-07-31 17:33:59 | INFO | train_inner | epoch 018:    455 / 1474 loss=2.05, trans_loss=5.052, nll_loss=2.259, w2v_ctc_loss=0.693, task_loss=2.247, contrastive_loss=0.18, total=4075.78, n_correct=2575.9, ppl=4.79, accuracy=63.2, wps=11786.1, ups=1.45, wpb=8151.6, bsz=294.2, num_updates=25500, lr=8.85615e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=69, gb_free=17.8, wall=21625
2023-07-31 17:35:08 | INFO | train_inner | epoch 018:    555 / 1474 loss=2.028, trans_loss=5.039, nll_loss=2.243, w2v_ctc_loss=0.68, task_loss=1.874, contrastive_loss=0.091, total=4218.07, n_correct=2689.22, ppl=4.73, accuracy=63.755, wps=12247.6, ups=1.45, wpb=8436.1, bsz=329.6, num_updates=25600, lr=8.83883e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=21694
2023-07-31 17:36:16 | INFO | train_inner | epoch 018:    655 / 1474 loss=2.054, trans_loss=5.067, nll_loss=2.278, w2v_ctc_loss=0.698, task_loss=2.17, contrastive_loss=0.159, total=4093.44, n_correct=2582.48, ppl=4.85, accuracy=63.088, wps=12009.8, ups=1.47, wpb=8186.9, bsz=298.5, num_updates=25700, lr=8.82162e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=68, gb_free=15.2, wall=21762
2023-07-31 17:37:25 | INFO | train_inner | epoch 018:    755 / 1474 loss=2.055, trans_loss=5.06, nll_loss=2.271, w2v_ctc_loss=0.698, task_loss=2.003, contrastive_loss=0.251, total=4202.99, n_correct=2653.98, ppl=4.83, accuracy=63.145, wps=12285.2, ups=1.46, wpb=8406, bsz=322.5, num_updates=25800, lr=8.80451e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=21831
2023-07-31 17:38:33 | INFO | train_inner | epoch 018:    855 / 1474 loss=2.043, trans_loss=5.06, nll_loss=2.269, w2v_ctc_loss=0.691, task_loss=2.116, contrastive_loss=0.072, total=4177.43, n_correct=2641.29, ppl=4.82, accuracy=63.228, wps=12207.4, ups=1.46, wpb=8354.9, bsz=304.8, num_updates=25900, lr=8.7875e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=21899
2023-07-31 17:39:42 | INFO | train_inner | epoch 018:    955 / 1474 loss=2.032, trans_loss=5.052, nll_loss=2.261, w2v_ctc_loss=0.678, task_loss=1.956, contrastive_loss=0.081, total=4138.23, n_correct=2626.4, ppl=4.79, accuracy=63.467, wps=12058.7, ups=1.46, wpb=8276.5, bsz=314.5, num_updates=26000, lr=8.77058e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=21968
2023-07-31 17:39:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 17:40:06 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.221 | trans_loss 5.589 | nll_loss 2.871 | w2v_ctc_loss 1.36 | task_loss 6.908 | contrastive_loss 0.259 | total 4003.4 | n_correct 2463.2 | ppl 7.31 | accuracy 61.528 | uer 17.517 | wer 19.321 | raw_wer 19.321 | bleu 19.74 | wps 2099.9 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 19.88
2023-07-31 17:40:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-07-31 17:40:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_18_26000.pt
2023-07-31 17:40:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_18_26000.pt
2023-07-31 17:40:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 19.74) (writing took 42.13347411341965 seconds)
2023-07-31 17:42:02 | INFO | train_inner | epoch 018:   1055 / 1474 loss=2.042, trans_loss=5.062, nll_loss=2.274, w2v_ctc_loss=0.684, task_loss=2.21, contrastive_loss=0.076, total=4133.59, n_correct=2609.92, ppl=4.84, accuracy=63.139, wps=5899.4, ups=0.71, wpb=8267.2, bsz=298.7, num_updates=26100, lr=8.75376e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=22108
2023-07-31 17:43:10 | INFO | train_inner | epoch 018:   1155 / 1474 loss=2.043, trans_loss=5.05, nll_loss=2.258, w2v_ctc_loss=0.685, task_loss=1.979, contrastive_loss=0.181, total=4154.22, n_correct=2634.62, ppl=4.78, accuracy=63.42, wps=12245.4, ups=1.47, wpb=8308.4, bsz=315.1, num_updates=26200, lr=8.73704e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=67, gb_free=14.9, wall=22176
2023-07-31 17:44:18 | INFO | train_inner | epoch 018:   1255 / 1474 loss=2.046, trans_loss=5.071, nll_loss=2.284, w2v_ctc_loss=0.689, task_loss=2.25, contrastive_loss=0.069, total=4089.17, n_correct=2575.39, ppl=4.87, accuracy=62.981, wps=12024.4, ups=1.47, wpb=8178.3, bsz=287.6, num_updates=26300, lr=8.72041e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=22244
2023-07-31 17:45:26 | INFO | train_inner | epoch 018:   1355 / 1474 loss=2.059, trans_loss=5.079, nll_loss=2.295, w2v_ctc_loss=0.709, task_loss=2.242, contrastive_loss=0.097, total=4068.84, n_correct=2552.82, ppl=4.91, accuracy=62.741, wps=11908, ups=1.46, wpb=8137.7, bsz=291.4, num_updates=26400, lr=8.70388e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=68, gb_free=15.3, wall=22312
2023-07-31 17:46:34 | INFO | train_inner | epoch 018:   1455 / 1474 loss=2.051, trans_loss=5.072, nll_loss=2.286, w2v_ctc_loss=0.699, task_loss=2.227, contrastive_loss=0.083, total=4113.23, n_correct=2587.74, ppl=4.88, accuracy=62.913, wps=12073.1, ups=1.47, wpb=8226.5, bsz=297.2, num_updates=26500, lr=8.68744e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=22380
2023-07-31 17:46:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 17:47:10 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.225 | trans_loss 5.587 | nll_loss 2.869 | w2v_ctc_loss 1.375 | task_loss 6.92 | contrastive_loss 0.267 | total 4003.4 | n_correct 2465.4 | ppl 7.31 | accuracy 61.583 | uer 17.341 | wer 19.205 | raw_wer 19.205 | bleu 19.98 | wps 2280 | wpb 4003.4 | bsz 141.8 | num_updates 26519 | best_bleu 19.98
2023-07-31 17:47:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26519 updates
2023-07-31 17:47:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 17:47:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 17:47:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt (epoch 18 @ 26519 updates, score 19.98) (writing took 20.366590436547995 seconds)
2023-07-31 17:47:31 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-07-31 17:47:31 | INFO | train | epoch 018 | loss 2.044 | trans_loss 5.056 | nll_loss 2.265 | w2v_ctc_loss 0.689 | task_loss 2.098 | contrastive_loss 0.126 | total 4138.65 | n_correct 2618.27 | ppl 4.81 | accuracy 63.264 | wps 10769.7 | ups 1.3 | wpb 8277.3 | bsz 305.7 | num_updates 26519 | lr 8.68433e-05 | gnorm 0.566 | clip 0 | loss_scale 32 | train_wall 1001 | gb_free 15.9 | wall 22437
2023-07-31 17:47:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 17:47:31 | INFO | fairseq.trainer | begin training epoch 19
2023-07-31 17:47:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 17:48:35 | INFO | train_inner | epoch 019:     81 / 1474 loss=2.034, trans_loss=5.033, nll_loss=2.233, w2v_ctc_loss=0.683, task_loss=2.097, contrastive_loss=0.133, total=4107.26, n_correct=2613.2, ppl=4.7, accuracy=63.624, wps=6823.5, ups=0.83, wpb=8214.5, bsz=297.5, num_updates=26600, lr=8.6711e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=67, gb_free=12.6, wall=22500
2023-07-31 17:49:44 | INFO | train_inner | epoch 019:    181 / 1474 loss=2.03, trans_loss=5.024, nll_loss=2.224, w2v_ctc_loss=0.689, task_loss=1.96, contrastive_loss=0.128, total=4222.18, n_correct=2698.87, ppl=4.67, accuracy=63.921, wps=12188.5, ups=1.44, wpb=8444.4, bsz=324.4, num_updates=26700, lr=8.65485e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=69, gb_free=11.5, wall=22570
2023-07-31 17:50:53 | INFO | train_inner | epoch 019:    281 / 1474 loss=2.025, trans_loss=5.027, nll_loss=2.227, w2v_ctc_loss=0.681, task_loss=2.059, contrastive_loss=0.065, total=4187.37, n_correct=2676.48, ppl=4.68, accuracy=63.918, wps=12188.7, ups=1.46, wpb=8374.7, bsz=307, num_updates=26800, lr=8.63868e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=68, gb_free=17.5, wall=22638
2023-07-31 17:52:01 | INFO | train_inner | epoch 019:    381 / 1474 loss=2.032, trans_loss=5.03, nll_loss=2.232, w2v_ctc_loss=0.673, task_loss=2.076, contrastive_loss=0.174, total=4170.67, n_correct=2657.76, ppl=4.7, accuracy=63.725, wps=12272.3, ups=1.47, wpb=8341.3, bsz=310.5, num_updates=26900, lr=8.62261e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=67, gb_free=17.2, wall=22706
2023-07-31 17:53:09 | INFO | train_inner | epoch 019:    481 / 1474 loss=2.034, trans_loss=5.041, nll_loss=2.244, w2v_ctc_loss=0.688, task_loss=2.148, contrastive_loss=0.082, total=4115.22, n_correct=2619.08, ppl=4.74, accuracy=63.644, wps=12067.2, ups=1.47, wpb=8230.4, bsz=301.9, num_updates=27000, lr=8.60663e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=68, gb_free=15.1, wall=22775
2023-07-31 17:54:18 | INFO | train_inner | epoch 019:    581 / 1474 loss=2.031, trans_loss=5.036, nll_loss=2.24, w2v_ctc_loss=0.678, task_loss=2.057, contrastive_loss=0.147, total=4129.22, n_correct=2634.35, ppl=4.72, accuracy=63.798, wps=11996.4, ups=1.45, wpb=8258.4, bsz=306, num_updates=27100, lr=8.59074e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=22844
2023-07-31 17:55:26 | INFO | train_inner | epoch 019:    681 / 1474 loss=2.019, trans_loss=5.038, nll_loss=2.242, w2v_ctc_loss=0.664, task_loss=1.914, contrastive_loss=0.073, total=4197.2, n_correct=2676.28, ppl=4.73, accuracy=63.763, wps=12254.7, ups=1.46, wpb=8394.4, bsz=320.8, num_updates=27200, lr=8.57493e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=68, gb_free=14.6, wall=22912
2023-07-31 17:56:35 | INFO | train_inner | epoch 019:    781 / 1474 loss=2.035, trans_loss=5.041, nll_loss=2.245, w2v_ctc_loss=0.689, task_loss=2.108, contrastive_loss=0.087, total=4142.6, n_correct=2634.56, ppl=4.74, accuracy=63.597, wps=12092.1, ups=1.46, wpb=8285.2, bsz=305.1, num_updates=27300, lr=8.55921e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=22981
2023-07-31 17:57:43 | INFO | train_inner | epoch 019:    881 / 1474 loss=2.038, trans_loss=5.051, nll_loss=2.258, w2v_ctc_loss=0.691, task_loss=2.139, contrastive_loss=0.068, total=4153.47, n_correct=2631.78, ppl=4.78, accuracy=63.363, wps=12208.5, ups=1.47, wpb=8306.9, bsz=303.1, num_updates=27400, lr=8.54358e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=23049
2023-07-31 17:58:52 | INFO | train_inner | epoch 019:    981 / 1474 loss=2.054, trans_loss=5.061, nll_loss=2.272, w2v_ctc_loss=0.684, task_loss=2.095, contrastive_loss=0.307, total=4101.29, n_correct=2589.78, ppl=4.83, accuracy=63.145, wps=11781.6, ups=1.44, wpb=8202.6, bsz=309.9, num_updates=27500, lr=8.52803e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=23118
2023-07-31 18:00:01 | INFO | train_inner | epoch 019:   1081 / 1474 loss=2.044, trans_loss=5.063, nll_loss=2.274, w2v_ctc_loss=0.686, task_loss=2.245, contrastive_loss=0.112, total=4036.97, n_correct=2554.78, ppl=4.84, accuracy=63.285, wps=11770.4, ups=1.46, wpb=8073.9, bsz=291, num_updates=27600, lr=8.51257e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=68, gb_free=14.6, wall=23187
2023-07-31 18:01:09 | INFO | train_inner | epoch 019:   1181 / 1474 loss=2.051, trans_loss=5.059, nll_loss=2.27, w2v_ctc_loss=0.689, task_loss=2.134, contrastive_loss=0.197, total=4137.49, n_correct=2613.11, ppl=4.82, accuracy=63.157, wps=12087.3, ups=1.46, wpb=8275, bsz=307.7, num_updates=27700, lr=8.49719e-05, gnorm=0.572, clip=0, loss_scale=64, train_wall=68, gb_free=14.8, wall=23255
2023-07-31 18:02:17 | INFO | train_inner | epoch 019:   1281 / 1474 loss=2.039, trans_loss=5.061, nll_loss=2.272, w2v_ctc_loss=0.681, task_loss=2.127, contrastive_loss=0.094, total=4141.89, n_correct=2622.48, ppl=4.83, accuracy=63.316, wps=12188.8, ups=1.47, wpb=8283.8, bsz=300.1, num_updates=27800, lr=8.48189e-05, gnorm=0.573, clip=0, loss_scale=64, train_wall=67, gb_free=15.5, wall=23323
2023-07-31 18:03:26 | INFO | train_inner | epoch 019:   1381 / 1474 loss=2.037, trans_loss=5.053, nll_loss=2.263, w2v_ctc_loss=0.686, task_loss=2.151, contrastive_loss=0.079, total=4133.26, n_correct=2622.09, ppl=4.8, accuracy=63.439, wps=11998.7, ups=1.45, wpb=8266.5, bsz=301, num_updates=27900, lr=8.46668e-05, gnorm=0.563, clip=0, loss_scale=64, train_wall=68, gb_free=16.1, wall=23392
2023-07-31 18:04:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 18:04:54 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.213 | trans_loss 5.578 | nll_loss 2.859 | w2v_ctc_loss 1.359 | task_loss 6.954 | contrastive_loss 0.26 | total 4003.4 | n_correct 2470.7 | ppl 7.25 | accuracy 61.715 | uer 17.307 | wer 19.056 | raw_wer 19.056 | bleu 19.77 | wps 2198.3 | wpb 4003.4 | bsz 141.8 | num_updates 27993 | best_bleu 19.98
2023-07-31 18:04:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27993 updates
2023-07-31 18:04:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.7702.pt
2023-07-31 18:04:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.7702.pt
2023-07-31 18:05:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.7702.pt (epoch 19 @ 27993 updates, score 19.77) (writing took 14.559501253068447 seconds)
2023-07-31 18:05:09 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-07-31 18:05:09 | INFO | train | epoch 019 | loss 2.036 | trans_loss 5.044 | nll_loss 2.25 | w2v_ctc_loss 0.683 | task_loss 2.098 | contrastive_loss 0.124 | total 4138.65 | n_correct 2630.02 | ppl 4.76 | accuracy 63.548 | wps 11530.5 | ups 1.39 | wpb 8277.3 | bsz 305.7 | num_updates 27993 | lr 8.4526e-05 | gnorm 0.567 | clip 0 | loss_scale 64 | train_wall 1004 | gb_free 17.3 | wall 23495
2023-07-31 18:05:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 18:05:09 | INFO | fairseq.trainer | begin training epoch 20
2023-07-31 18:05:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 18:05:23 | INFO | train_inner | epoch 020:      7 / 1474 loss=2.037, trans_loss=5.05, nll_loss=2.258, w2v_ctc_loss=0.677, task_loss=2.12, contrastive_loss=0.163, total=4119.08, n_correct=2613.01, ppl=4.78, accuracy=63.437, wps=7083.2, ups=0.86, wpb=8238.2, bsz=304.1, num_updates=28000, lr=8.45154e-05, gnorm=0.574, clip=0, loss_scale=64, train_wall=69, gb_free=16.1, wall=23508
2023-07-31 18:05:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 18:05:47 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.209 | trans_loss 5.58 | nll_loss 2.858 | w2v_ctc_loss 1.342 | task_loss 6.954 | contrastive_loss 0.258 | total 4003.4 | n_correct 2476.6 | ppl 7.25 | accuracy 61.862 | uer 17.177 | wer 18.959 | raw_wer 18.959 | bleu 19.99 | wps 2019.1 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 19.99
2023-07-31 18:05:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-07-31 18:05:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_20_28000.pt
2023-07-31 18:05:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_20_28000.pt
2023-07-31 18:06:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 19.99) (writing took 40.4271333925426 seconds)
2023-07-31 18:07:38 | INFO | train_inner | epoch 020:    107 / 1474 loss=2.013, trans_loss=5.009, nll_loss=2.204, w2v_ctc_loss=0.666, task_loss=2.029, contrastive_loss=0.088, total=4195.03, n_correct=2692.51, ppl=4.61, accuracy=64.183, wps=6217.3, ups=0.74, wpb=8390.1, bsz=313.7, num_updates=28100, lr=8.43649e-05, gnorm=0.561, clip=0, loss_scale=64, train_wall=68, gb_free=14.9, wall=23643
2023-07-31 18:08:46 | INFO | train_inner | epoch 020:    207 / 1474 loss=2.025, trans_loss=5.021, nll_loss=2.219, w2v_ctc_loss=0.674, task_loss=2.177, contrastive_loss=0.138, total=4154.14, n_correct=2655.87, ppl=4.65, accuracy=63.933, wps=12093.7, ups=1.46, wpb=8308.3, bsz=301, num_updates=28200, lr=8.42152e-05, gnorm=0.563, clip=0, loss_scale=64, train_wall=68, gb_free=17.2, wall=23712
2023-07-31 18:09:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-31 18:09:56 | INFO | train_inner | epoch 020:    308 / 1474 loss=2.014, trans_loss=5.015, nll_loss=2.212, w2v_ctc_loss=0.674, task_loss=1.894, contrastive_loss=0.078, total=4190.6, n_correct=2690.07, ppl=4.63, accuracy=64.193, wps=12042, ups=1.44, wpb=8381.2, bsz=326.2, num_updates=28300, lr=8.40663e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=23782
2023-07-31 18:11:04 | INFO | train_inner | epoch 020:    408 / 1474 loss=2.018, trans_loss=5.02, nll_loss=2.217, w2v_ctc_loss=0.668, task_loss=2.126, contrastive_loss=0.074, total=4114.19, n_correct=2638.19, ppl=4.65, accuracy=64.124, wps=12017.5, ups=1.46, wpb=8228.4, bsz=297.5, num_updates=28400, lr=8.39181e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=68, gb_free=15.2, wall=23850
2023-07-31 18:12:13 | INFO | train_inner | epoch 020:    508 / 1474 loss=2.03, trans_loss=5.035, nll_loss=2.237, w2v_ctc_loss=0.671, task_loss=2.159, contrastive_loss=0.16, total=4108.2, n_correct=2618.64, ppl=4.71, accuracy=63.742, wps=11978.3, ups=1.46, wpb=8216.4, bsz=299.5, num_updates=28500, lr=8.37708e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=23919
2023-07-31 18:13:21 | INFO | train_inner | epoch 020:    608 / 1474 loss=2.037, trans_loss=5.037, nll_loss=2.241, w2v_ctc_loss=0.678, task_loss=2.209, contrastive_loss=0.169, total=4092.44, n_correct=2604.14, ppl=4.73, accuracy=63.633, wps=12048.6, ups=1.47, wpb=8184.9, bsz=295.9, num_updates=28600, lr=8.36242e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=67, gb_free=17.6, wall=23987
2023-07-31 18:14:30 | INFO | train_inner | epoch 020:    708 / 1474 loss=2.027, trans_loss=5.036, nll_loss=2.238, w2v_ctc_loss=0.681, task_loss=2.104, contrastive_loss=0.066, total=4137.06, n_correct=2639.42, ppl=4.72, accuracy=63.799, wps=12012.9, ups=1.45, wpb=8274.1, bsz=300.5, num_updates=28700, lr=8.34784e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=24056
2023-07-31 18:15:38 | INFO | train_inner | epoch 020:    808 / 1474 loss=2.024, trans_loss=5.034, nll_loss=2.237, w2v_ctc_loss=0.679, task_loss=2.075, contrastive_loss=0.071, total=4146.78, n_correct=2649.31, ppl=4.71, accuracy=63.888, wps=12094.1, ups=1.46, wpb=8293.6, bsz=307.3, num_updates=28800, lr=8.33333e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=68, gb_free=15.2, wall=24124
2023-07-31 18:16:47 | INFO | train_inner | epoch 020:    908 / 1474 loss=2.05, trans_loss=5.045, nll_loss=2.252, w2v_ctc_loss=0.677, task_loss=2.002, contrastive_loss=0.367, total=4161, n_correct=2640.83, ppl=4.76, accuracy=63.466, wps=12028.9, ups=1.45, wpb=8322, bsz=323.2, num_updates=28900, lr=8.3189e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=69, gb_free=17.4, wall=24193
2023-07-31 18:17:56 | INFO | train_inner | epoch 020:   1008 / 1474 loss=2.026, trans_loss=5.039, nll_loss=2.243, w2v_ctc_loss=0.672, task_loss=2.092, contrastive_loss=0.077, total=4168.14, n_correct=2657.96, ppl=4.73, accuracy=63.768, wps=12182.8, ups=1.46, wpb=8336.3, bsz=307.3, num_updates=29000, lr=8.30455e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=24262
2023-07-31 18:19:05 | INFO | train_inner | epoch 020:   1108 / 1474 loss=2.036, trans_loss=5.043, nll_loss=2.25, w2v_ctc_loss=0.674, task_loss=2.023, contrastive_loss=0.216, total=4166.49, n_correct=2652.32, ppl=4.76, accuracy=63.658, wps=12118.9, ups=1.45, wpb=8333, bsz=315.4, num_updates=29100, lr=8.29027e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=68, gb_free=14.7, wall=24331
2023-07-31 18:20:14 | INFO | train_inner | epoch 020:   1208 / 1474 loss=2.035, trans_loss=5.041, nll_loss=2.246, w2v_ctc_loss=0.691, task_loss=2.32, contrastive_loss=0.065, total=4029.18, n_correct=2561.64, ppl=4.74, accuracy=63.577, wps=11685.6, ups=1.45, wpb=8058.4, bsz=284, num_updates=29200, lr=8.27606e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=68, gb_free=11.6, wall=24400
2023-07-31 18:21:23 | INFO | train_inner | epoch 020:   1308 / 1474 loss=2.028, trans_loss=5.045, nll_loss=2.253, w2v_ctc_loss=0.675, task_loss=2.21, contrastive_loss=0.069, total=4123.21, n_correct=2627.53, ppl=4.77, accuracy=63.725, wps=11956, ups=1.45, wpb=8246.4, bsz=297.1, num_updates=29300, lr=8.26192e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=68, gb_free=17.4, wall=24469
2023-07-31 18:22:31 | INFO | train_inner | epoch 020:   1408 / 1474 loss=2.029, trans_loss=5.043, nll_loss=2.249, w2v_ctc_loss=0.678, task_loss=2.216, contrastive_loss=0.069, total=4116.28, n_correct=2621.63, ppl=4.75, accuracy=63.689, wps=12022.4, ups=1.46, wpb=8232.6, bsz=295, num_updates=29400, lr=8.24786e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=68, gb_free=17.5, wall=24537
2023-07-31 18:23:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 18:23:40 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.198 | trans_loss 5.576 | nll_loss 2.854 | w2v_ctc_loss 1.313 | task_loss 6.883 | contrastive_loss 0.26 | total 4003.4 | n_correct 2469.4 | ppl 7.23 | accuracy 61.683 | uer 17.203 | wer 19.004 | raw_wer 19.004 | bleu 19.8 | wps 2249.3 | wpb 4003.4 | bsz 141.8 | num_updates 29466 | best_bleu 19.99
2023-07-31 18:23:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29466 updates
2023-07-31 18:23:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.8002.pt
2023-07-31 18:23:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.8002.pt
2023-07-31 18:24:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.8002.pt (epoch 20 @ 29466 updates, score 19.8) (writing took 32.126156732439995 seconds)
2023-07-31 18:24:13 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-07-31 18:24:13 | INFO | train | epoch 020 | loss 2.028 | trans_loss 5.034 | nll_loss 2.236 | w2v_ctc_loss 0.675 | task_loss 2.101 | contrastive_loss 0.123 | total 4138.8 | n_correct 2641.01 | ppl 4.71 | accuracy 63.811 | wps 10653.4 | ups 1.29 | wpb 8277.6 | bsz 305.7 | num_updates 29466 | lr 8.23862e-05 | gnorm 0.567 | clip 0 | loss_scale 32 | train_wall 1004 | gb_free 16.1 | wall 24639
2023-07-31 18:24:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 18:24:14 | INFO | fairseq.trainer | begin training epoch 21
2023-07-31 18:24:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 18:24:45 | INFO | train_inner | epoch 021:     34 / 1474 loss=2.031, trans_loss=5.037, nll_loss=2.242, w2v_ctc_loss=0.673, task_loss=2, contrastive_loss=0.192, total=4152.26, n_correct=2648.03, ppl=4.73, accuracy=63.773, wps=6188.6, ups=0.75, wpb=8304.5, bsz=316.3, num_updates=29500, lr=8.23387e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=24671
2023-07-31 18:25:54 | INFO | train_inner | epoch 021:    134 / 1474 loss=2.015, trans_loss=5.003, nll_loss=2.197, w2v_ctc_loss=0.663, task_loss=1.962, contrastive_loss=0.182, total=4195.08, n_correct=2700.35, ppl=4.58, accuracy=64.369, wps=12226.5, ups=1.46, wpb=8390.2, bsz=319.6, num_updates=29600, lr=8.21995e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=24740
2023-07-31 18:27:03 | INFO | train_inner | epoch 021:    234 / 1474 loss=2.008, trans_loss=5.007, nll_loss=2.201, w2v_ctc_loss=0.654, task_loss=2.002, contrastive_loss=0.134, total=4155.31, n_correct=2676.99, ppl=4.6, accuracy=64.423, wps=12097.4, ups=1.46, wpb=8310.6, bsz=312.6, num_updates=29700, lr=8.2061e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=24809
2023-07-31 18:28:12 | INFO | train_inner | epoch 021:    334 / 1474 loss=2.018, trans_loss=5.011, nll_loss=2.207, w2v_ctc_loss=0.67, task_loss=2.082, contrastive_loss=0.14, total=4151.51, n_correct=2666.48, ppl=4.62, accuracy=64.229, wps=11941.2, ups=1.44, wpb=8303, bsz=310.8, num_updates=29800, lr=8.19232e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=69, gb_free=15.5, wall=24878
2023-07-31 18:29:21 | INFO | train_inner | epoch 021:    434 / 1474 loss=2.008, trans_loss=5.011, nll_loss=2.207, w2v_ctc_loss=0.658, task_loss=2.035, contrastive_loss=0.061, total=4180.85, n_correct=2690.07, ppl=4.62, accuracy=64.343, wps=12222, ups=1.46, wpb=8361.7, bsz=306.8, num_updates=29900, lr=8.17861e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=24946
2023-07-31 18:30:29 | INFO | train_inner | epoch 021:    534 / 1474 loss=2.012, trans_loss=5.011, nll_loss=2.207, w2v_ctc_loss=0.668, task_loss=2.186, contrastive_loss=0.061, total=4083.98, n_correct=2624.46, ppl=4.62, accuracy=64.262, wps=11928.8, ups=1.46, wpb=8168, bsz=295.1, num_updates=30000, lr=8.16497e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=68, gb_free=12.9, wall=25015
2023-07-31 18:30:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 18:30:55 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.204 | trans_loss 5.584 | nll_loss 2.864 | w2v_ctc_loss 1.317 | task_loss 6.906 | contrastive_loss 0.254 | total 4003.4 | n_correct 2471.5 | ppl 7.28 | accuracy 61.735 | uer 17.426 | wer 19.227 | raw_wer 19.227 | bleu 19.6 | wps 1918.4 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 19.99
2023-07-31 18:30:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-07-31 18:30:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_21_30000.pt
2023-07-31 18:30:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_21_30000.pt
2023-07-31 18:31:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 19.6) (writing took 23.58300475589931 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:0')
2023-07-31 18:32:28 | INFO | train_inner | epoch 021:    634 / 1474 loss=2.022, trans_loss=5.018, nll_loss=2.216, w2v_ctc_loss=0.66, task_loss=2.079, contrastive_loss=0.235, total=4215.41, n_correct=2703.11, ppl=4.65, accuracy=64.124, wps=7094.8, ups=0.84, wpb=8430.8, bsz=315.4, num_updates=30100, lr=8.15139e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=69, gb_free=11.2, wall=25134
2023-07-31 18:33:37 | INFO | train_inner | epoch 021:    734 / 1474 loss=2.021, trans_loss=5.028, nll_loss=2.23, w2v_ctc_loss=0.667, task_loss=2.084, contrastive_loss=0.097, total=4152.97, n_correct=2657.53, ppl=4.69, accuracy=63.991, wps=12004.2, ups=1.45, wpb=8305.9, bsz=309.3, num_updates=30200, lr=8.13788e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=25203
2023-07-31 18:34:47 | INFO | train_inner | epoch 021:    834 / 1474 loss=2.024, trans_loss=5.031, nll_loss=2.232, w2v_ctc_loss=0.667, task_loss=2.221, contrastive_loss=0.108, total=4066.93, n_correct=2599.73, ppl=4.7, accuracy=63.924, wps=11718.2, ups=1.44, wpb=8133.9, bsz=294.4, num_updates=30300, lr=8.12444e-05, gnorm=0.575, clip=0, loss_scale=64, train_wall=69, gb_free=16.9, wall=25272
2023-07-31 18:35:55 | INFO | train_inner | epoch 021:    934 / 1474 loss=2.018, trans_loss=5.023, nll_loss=2.223, w2v_ctc_loss=0.669, task_loss=2.104, contrastive_loss=0.082, total=4103.34, n_correct=2626.1, ppl=4.67, accuracy=63.999, wps=11994.5, ups=1.46, wpb=8206.7, bsz=301, num_updates=30400, lr=8.11107e-05, gnorm=0.57, clip=0, loss_scale=64, train_wall=68, gb_free=13.9, wall=25341
2023-07-31 18:37:03 | INFO | train_inner | epoch 021:   1034 / 1474 loss=2.022, trans_loss=5.037, nll_loss=2.241, w2v_ctc_loss=0.668, task_loss=2.14, contrastive_loss=0.079, total=4099.86, n_correct=2618.37, ppl=4.73, accuracy=63.865, wps=12077.5, ups=1.47, wpb=8199.7, bsz=298.8, num_updates=30500, lr=8.09776e-05, gnorm=0.565, clip=0, loss_scale=64, train_wall=67, gb_free=11.2, wall=25409
2023-07-31 18:38:11 | INFO | train_inner | epoch 021:   1134 / 1474 loss=2.023, trans_loss=5.028, nll_loss=2.229, w2v_ctc_loss=0.671, task_loss=2.26, contrastive_loss=0.081, total=4120.75, n_correct=2635.97, ppl=4.69, accuracy=63.968, wps=12029.9, ups=1.46, wpb=8241.5, bsz=293.5, num_updates=30600, lr=8.08452e-05, gnorm=0.565, clip=0, loss_scale=64, train_wall=68, gb_free=15.8, wall=25477
2023-07-31 18:39:20 | INFO | train_inner | epoch 021:   1234 / 1474 loss=2.02, trans_loss=5.028, nll_loss=2.231, w2v_ctc_loss=0.664, task_loss=1.99, contrastive_loss=0.132, total=4154.73, n_correct=2654.68, ppl=4.69, accuracy=63.895, wps=12166.2, ups=1.46, wpb=8309.5, bsz=311.6, num_updates=30700, lr=8.07134e-05, gnorm=0.563, clip=0, loss_scale=64, train_wall=68, gb_free=12.5, wall=25546
2023-07-31 18:40:28 | INFO | train_inner | epoch 021:   1334 / 1474 loss=2.02, trans_loss=5.029, nll_loss=2.232, w2v_ctc_loss=0.668, task_loss=2.03, contrastive_loss=0.096, total=4147.17, n_correct=2652.77, ppl=4.7, accuracy=63.966, wps=12092.2, ups=1.46, wpb=8294.3, bsz=311.9, num_updates=30800, lr=8.05823e-05, gnorm=0.571, clip=0, loss_scale=64, train_wall=68, gb_free=16.2, wall=25614
2023-07-31 18:41:37 | INFO | train_inner | epoch 021:   1434 / 1474 loss=2.038, trans_loss=5.042, nll_loss=2.249, w2v_ctc_loss=0.686, task_loss=2.199, contrastive_loss=0.147, total=4133.93, n_correct=2626.03, ppl=4.75, accuracy=63.524, wps=11943.8, ups=1.44, wpb=8267.9, bsz=304.5, num_updates=30900, lr=8.04518e-05, gnorm=0.587, clip=0, loss_scale=64, train_wall=69, gb_free=15.5, wall=25683
2023-07-31 18:42:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:4')
2023-07-31 18:42:29 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.211 | trans_loss 5.577 | nll_loss 2.855 | w2v_ctc_loss 1.357 | task_loss 6.894 | contrastive_loss 0.255 | total 4003.4 | n_correct 2476.6 | ppl 7.24 | accuracy 61.862 | uer 17.278 | wer 19.19 | raw_wer 19.19 | bleu 19.65 | wps 2103.1 | wpb 4003.4 | bsz 141.8 | num_updates 30940 | best_bleu 19.99
2023-07-31 18:42:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30940 updates
2023-07-31 18:42:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_last.pt
2023-07-31 18:42:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_last.pt
2023-07-31 18:42:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_last.pt (epoch 21 @ 30940 updates, score 19.65) (writing took 11.508606033399701 seconds)
2023-07-31 18:42:41 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-07-31 18:42:41 | INFO | train | epoch 021 | loss 2.019 | trans_loss 5.022 | nll_loss 2.222 | w2v_ctc_loss 0.667 | task_loss 2.1 | contrastive_loss 0.121 | total 4138.65 | n_correct 2651.29 | ppl 4.66 | accuracy 64.062 | wps 11018.8 | ups 1.33 | wpb 8277.3 | bsz 305.7 | num_updates 30940 | lr 8.03998e-05 | gnorm 0.569 | clip 0 | loss_scale 64 | train_wall 1006 | gb_free 15.4 | wall 25747
2023-07-31 18:42:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 18:42:41 | INFO | fairseq.trainer | begin training epoch 22
2023-07-31 18:42:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 18:43:29 | INFO | train_inner | epoch 022:     60 / 1474 loss=2.01, trans_loss=5.008, nll_loss=2.203, w2v_ctc_loss=0.666, task_loss=2.138, contrastive_loss=0.06, total=4128.84, n_correct=2660.87, ppl=4.6, accuracy=64.446, wps=7372.5, ups=0.89, wpb=8257.7, bsz=297.7, num_updates=31000, lr=8.03219e-05, gnorm=0.573, clip=0, loss_scale=64, train_wall=68, gb_free=14.1, wall=25795
2023-07-31 18:44:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-31 18:44:39 | INFO | train_inner | epoch 022:    161 / 1474 loss=2.01, trans_loss=4.999, nll_loss=2.191, w2v_ctc_loss=0.661, task_loss=2.114, contrastive_loss=0.147, total=4123.81, n_correct=2657.63, ppl=4.57, accuracy=64.446, wps=11899.7, ups=1.44, wpb=8247.6, bsz=310.3, num_updates=31100, lr=8.01927e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=25865
2023-07-31 18:45:47 | INFO | train_inner | epoch 022:    261 / 1474 loss=1.995, trans_loss=4.993, nll_loss=2.185, w2v_ctc_loss=0.647, task_loss=1.837, contrastive_loss=0.087, total=4272.11, n_correct=2762.3, ppl=4.55, accuracy=64.659, wps=12556.5, ups=1.47, wpb=8544.2, bsz=331.4, num_updates=31200, lr=8.00641e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=68, gb_free=17.8, wall=25933
2023-07-31 18:46:56 | INFO | train_inner | epoch 022:    361 / 1474 loss=2.025, trans_loss=5.01, nll_loss=2.206, w2v_ctc_loss=0.663, task_loss=2.131, contrastive_loss=0.248, total=4178.4, n_correct=2682.58, ppl=4.61, accuracy=64.201, wps=12088.5, ups=1.45, wpb=8356.8, bsz=310, num_updates=31300, lr=7.99361e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=69, gb_free=15.3, wall=26002
2023-07-31 18:48:05 | INFO | train_inner | epoch 022:    461 / 1474 loss=2.018, trans_loss=5.014, nll_loss=2.21, w2v_ctc_loss=0.664, task_loss=2.204, contrastive_loss=0.128, total=4132.96, n_correct=2655.32, ppl=4.63, accuracy=64.247, wps=11987.7, ups=1.45, wpb=8265.9, bsz=297.5, num_updates=31400, lr=7.98087e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=26071
2023-07-31 18:49:14 | INFO | train_inner | epoch 022:    561 / 1474 loss=2.007, trans_loss=5.006, nll_loss=2.2, w2v_ctc_loss=0.662, task_loss=2.097, contrastive_loss=0.074, total=4158.17, n_correct=2680.44, ppl=4.59, accuracy=64.462, wps=12054.1, ups=1.45, wpb=8316.3, bsz=307.8, num_updates=31500, lr=7.96819e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=26140
2023-07-31 18:50:21 | INFO | train_inner | epoch 022:    661 / 1474 loss=2.004, trans_loss=5.001, nll_loss=2.195, w2v_ctc_loss=0.648, task_loss=2.005, contrastive_loss=0.155, total=4139.66, n_correct=2671.72, ppl=4.58, accuracy=64.54, wps=12289.3, ups=1.48, wpb=8279.3, bsz=311.1, num_updates=31600, lr=7.95557e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=67, gb_free=16.1, wall=26207
2023-07-31 18:51:29 | INFO | train_inner | epoch 022:    761 / 1474 loss=2.011, trans_loss=5.009, nll_loss=2.204, w2v_ctc_loss=0.666, task_loss=2.16, contrastive_loss=0.076, total=4167.89, n_correct=2680.04, ppl=4.61, accuracy=64.302, wps=12241.3, ups=1.47, wpb=8335.8, bsz=303.9, num_updates=31700, lr=7.94301e-05, gnorm=0.593, clip=0, loss_scale=32, train_wall=68, gb_free=12.7, wall=26275
2023-07-31 18:52:38 | INFO | train_inner | epoch 022:    861 / 1474 loss=2.016, trans_loss=5.021, nll_loss=2.22, w2v_ctc_loss=0.667, task_loss=2.268, contrastive_loss=0.061, total=4075.79, n_correct=2612.17, ppl=4.66, accuracy=64.09, wps=11835.5, ups=1.45, wpb=8151.6, bsz=289, num_updates=31800, lr=7.93052e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=26344
2023-07-31 18:53:47 | INFO | train_inner | epoch 022:    961 / 1474 loss=2.006, trans_loss=5.015, nll_loss=2.213, w2v_ctc_loss=0.654, task_loss=2.113, contrastive_loss=0.062, total=4134.72, n_correct=2662.23, ppl=4.64, accuracy=64.387, wps=12099.5, ups=1.46, wpb=8269.4, bsz=303.2, num_updates=31900, lr=7.91808e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=68, gb_free=14.1, wall=26413
2023-07-31 18:54:54 | INFO | train_inner | epoch 022:   1061 / 1474 loss=2.014, trans_loss=5.011, nll_loss=2.208, w2v_ctc_loss=0.654, task_loss=2.006, contrastive_loss=0.235, total=4160.57, n_correct=2676.36, ppl=4.62, accuracy=64.327, wps=12282, ups=1.48, wpb=8321.1, bsz=315.5, num_updates=32000, lr=7.90569e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=67, gb_free=17.2, wall=26480
2023-07-31 18:54:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 18:55:18 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.2 | trans_loss 5.578 | nll_loss 2.855 | w2v_ctc_loss 1.318 | task_loss 6.922 | contrastive_loss 0.254 | total 4003.4 | n_correct 2470.6 | ppl 7.24 | accuracy 61.713 | uer 16.97 | wer 18.87 | raw_wer 18.87 | bleu 19.66 | wps 2147.7 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 19.99
2023-07-31 18:55:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-07-31 18:55:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_22_32000.pt
2023-07-31 18:55:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_22_32000.pt
2023-07-31 18:55:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 19.66) (writing took 12.055962208658457 seconds)
2023-07-31 18:56:38 | INFO | train_inner | epoch 022:   1161 / 1474 loss=2.026, trans_loss=5.034, nll_loss=2.238, w2v_ctc_loss=0.673, task_loss=2.168, contrastive_loss=0.114, total=4099.59, n_correct=2618.1, ppl=4.72, accuracy=63.862, wps=7896.5, ups=0.96, wpb=8199.2, bsz=296.2, num_updates=32100, lr=7.89337e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=67, gb_free=14.9, wall=26584
2023-07-31 18:57:47 | INFO | train_inner | epoch 022:   1261 / 1474 loss=2.015, trans_loss=5.026, nll_loss=2.228, w2v_ctc_loss=0.662, task_loss=1.943, contrastive_loss=0.111, total=4182.05, n_correct=2679.9, ppl=4.69, accuracy=64.081, wps=12111.2, ups=1.45, wpb=8364.1, bsz=323, num_updates=32200, lr=7.8811e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=69, gb_free=15.5, wall=26653
2023-07-31 18:58:55 | INFO | train_inner | epoch 022:   1361 / 1474 loss=2.011, trans_loss=5.017, nll_loss=2.217, w2v_ctc_loss=0.653, task_loss=2.105, contrastive_loss=0.131, total=4062.31, n_correct=2609.35, ppl=4.65, accuracy=64.233, wps=12056.1, ups=1.48, wpb=8124.6, bsz=299, num_updates=32300, lr=7.86889e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=67, gb_free=15, wall=26721
2023-07-31 19:00:03 | INFO | train_inner | epoch 022:   1461 / 1474 loss=2.025, trans_loss=5.037, nll_loss=2.24, w2v_ctc_loss=0.675, task_loss=2.245, contrastive_loss=0.079, total=4081.88, n_correct=2607.3, ppl=4.72, accuracy=63.875, wps=12014.7, ups=1.47, wpb=8163.8, bsz=288.9, num_updates=32400, lr=7.85674e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=67, gb_free=17.2, wall=26789
2023-07-31 19:00:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 19:00:35 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.216 | trans_loss 5.576 | nll_loss 2.851 | w2v_ctc_loss 1.373 | task_loss 6.885 | contrastive_loss 0.254 | total 4003.4 | n_correct 2482.3 | ppl 7.22 | accuracy 62.005 | uer 17.217 | wer 18.974 | raw_wer 18.974 | bleu 20.13 | wps 2125.5 | wpb 4003.4 | bsz 141.8 | num_updates 32413 | best_bleu 20.13
2023-07-31 19:00:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32413 updates
2023-07-31 19:00:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 19:00:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 19:00:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt (epoch 22 @ 32413 updates, score 20.13) (writing took 20.187801526859403 seconds)
2023-07-31 19:00:56 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-07-31 19:00:56 | INFO | train | epoch 022 | loss 2.013 | trans_loss 5.013 | nll_loss 2.21 | w2v_ctc_loss 0.661 | task_loss 2.099 | contrastive_loss 0.12 | total 4138.86 | n_correct 2660.66 | ppl 4.63 | accuracy 64.285 | wps 11129.2 | ups 1.34 | wpb 8277.7 | bsz 305.7 | num_updates 32413 | lr 7.85517e-05 | gnorm 0.573 | clip 0 | loss_scale 32 | train_wall 1000 | gb_free 11.6 | wall 26842
2023-07-31 19:00:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 19:00:57 | INFO | fairseq.trainer | begin training epoch 23
2023-07-31 19:00:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 19:02:03 | INFO | train_inner | epoch 023:     87 / 1474 loss=1.999, trans_loss=4.988, nll_loss=2.178, w2v_ctc_loss=0.659, task_loss=2.148, contrastive_loss=0.069, total=4096.09, n_correct=2653.82, ppl=4.52, accuracy=64.789, wps=6783.1, ups=0.83, wpb=8192.2, bsz=301.2, num_updates=32500, lr=7.84465e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=67, gb_free=16.3, wall=26909
2023-07-31 19:03:12 | INFO | train_inner | epoch 023:    187 / 1474 loss=1.997, trans_loss=4.985, nll_loss=2.173, w2v_ctc_loss=0.65, task_loss=2.241, contrastive_loss=0.066, total=4107.77, n_correct=2662.63, ppl=4.51, accuracy=64.819, wps=11938.7, ups=1.45, wpb=8215.5, bsz=293.4, num_updates=32600, lr=7.8326e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=26978
2023-07-31 19:04:21 | INFO | train_inner | epoch 023:    287 / 1474 loss=2, trans_loss=4.992, nll_loss=2.182, w2v_ctc_loss=0.643, task_loss=2.107, contrastive_loss=0.146, total=4153.12, n_correct=2687.08, ppl=4.54, accuracy=64.7, wps=12087.3, ups=1.46, wpb=8306.2, bsz=306.4, num_updates=32700, lr=7.82062e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=27047
2023-07-31 19:05:29 | INFO | train_inner | epoch 023:    387 / 1474 loss=1.998, trans_loss=4.994, nll_loss=2.184, w2v_ctc_loss=0.65, task_loss=2.184, contrastive_loss=0.057, total=4116.7, n_correct=2663.75, ppl=4.54, accuracy=64.706, wps=12145.8, ups=1.48, wpb=8233.4, bsz=294, num_updates=32800, lr=7.80869e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=67, gb_free=15.2, wall=27115
2023-07-31 19:06:37 | INFO | train_inner | epoch 023:    487 / 1474 loss=2.005, trans_loss=4.999, nll_loss=2.192, w2v_ctc_loss=0.654, task_loss=2.041, contrastive_loss=0.12, total=4157.6, n_correct=2681.97, ppl=4.57, accuracy=64.508, wps=12264.4, ups=1.47, wpb=8315.2, bsz=313.5, num_updates=32900, lr=7.79681e-05, gnorm=0.585, clip=0, loss_scale=32, train_wall=67, gb_free=17.3, wall=27182
2023-07-31 19:07:45 | INFO | train_inner | epoch 023:    587 / 1474 loss=1.992, trans_loss=4.99, nll_loss=2.181, w2v_ctc_loss=0.645, task_loss=1.985, contrastive_loss=0.064, total=4173.42, n_correct=2703.5, ppl=4.53, accuracy=64.779, wps=12119.7, ups=1.45, wpb=8346.8, bsz=316, num_updates=33000, lr=7.78499e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=68, gb_free=12.6, wall=27251
2023-07-31 19:08:55 | INFO | train_inner | epoch 023:    687 / 1474 loss=2.002, trans_loss=4.997, nll_loss=2.189, w2v_ctc_loss=0.65, task_loss=2.105, contrastive_loss=0.105, total=4137.82, n_correct=2674.17, ppl=4.56, accuracy=64.628, wps=11946.2, ups=1.44, wpb=8275.6, bsz=302.5, num_updates=33100, lr=7.77322e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=69, gb_free=17.1, wall=27321
2023-07-31 19:10:03 | INFO | train_inner | epoch 023:    787 / 1474 loss=2.007, trans_loss=5.008, nll_loss=2.204, w2v_ctc_loss=0.658, task_loss=2.12, contrastive_loss=0.086, total=4150.99, n_correct=2675.76, ppl=4.61, accuracy=64.461, wps=12192.7, ups=1.47, wpb=8302, bsz=305.4, num_updates=33200, lr=7.76151e-05, gnorm=0.574, clip=0, loss_scale=64, train_wall=68, gb_free=16.3, wall=27389
2023-07-31 19:11:11 | INFO | train_inner | epoch 023:    887 / 1474 loss=2.006, trans_loss=5.002, nll_loss=2.197, w2v_ctc_loss=0.653, task_loss=1.919, contrastive_loss=0.168, total=4181.99, n_correct=2701.54, ppl=4.59, accuracy=64.599, wps=12294.4, ups=1.47, wpb=8364, bsz=324.7, num_updates=33300, lr=7.74984e-05, gnorm=0.569, clip=0, loss_scale=64, train_wall=68, gb_free=16.4, wall=27457
2023-07-31 19:12:20 | INFO | train_inner | epoch 023:    987 / 1474 loss=2.014, trans_loss=5.006, nll_loss=2.201, w2v_ctc_loss=0.644, task_loss=2.094, contrastive_loss=0.32, total=4168.73, n_correct=2686.85, ppl=4.6, accuracy=64.452, wps=11995.4, ups=1.44, wpb=8337.5, bsz=310.5, num_updates=33400, lr=7.73823e-05, gnorm=0.573, clip=0, loss_scale=64, train_wall=69, gb_free=10.7, wall=27526
2023-07-31 19:13:29 | INFO | train_inner | epoch 023:   1087 / 1474 loss=2.012, trans_loss=5.012, nll_loss=2.209, w2v_ctc_loss=0.667, task_loss=2.244, contrastive_loss=0.07, total=4088.49, n_correct=2625.98, ppl=4.62, accuracy=64.229, wps=11847.9, ups=1.45, wpb=8177, bsz=290, num_updates=33500, lr=7.72667e-05, gnorm=0.574, clip=0, loss_scale=64, train_wall=68, gb_free=15.8, wall=27595
2023-07-31 19:14:38 | INFO | train_inner | epoch 023:   1187 / 1474 loss=2.004, trans_loss=5.011, nll_loss=2.208, w2v_ctc_loss=0.657, task_loss=2.083, contrastive_loss=0.063, total=4162.7, n_correct=2679.95, ppl=4.62, accuracy=64.38, wps=12100.1, ups=1.45, wpb=8325.4, bsz=309.3, num_updates=33600, lr=7.71517e-05, gnorm=0.571, clip=0, loss_scale=64, train_wall=68, gb_free=16, wall=27664
2023-07-31 19:15:46 | INFO | train_inner | epoch 023:   1287 / 1474 loss=2.001, trans_loss=5.01, nll_loss=2.207, w2v_ctc_loss=0.649, task_loss=2.041, contrastive_loss=0.078, total=4135.53, n_correct=2666.94, ppl=4.62, accuracy=64.488, wps=12140, ups=1.47, wpb=8271.1, bsz=308.9, num_updates=33700, lr=7.70371e-05, gnorm=0.58, clip=0, loss_scale=64, train_wall=68, gb_free=16.7, wall=27732
2023-07-31 19:16:55 | INFO | train_inner | epoch 023:   1387 / 1474 loss=2.019, trans_loss=5.028, nll_loss=2.231, w2v_ctc_loss=0.661, task_loss=2.125, contrastive_loss=0.134, total=4143.98, n_correct=2655.96, ppl=4.7, accuracy=64.092, wps=12022.1, ups=1.45, wpb=8288, bsz=305.2, num_updates=33800, lr=7.69231e-05, gnorm=0.579, clip=0, loss_scale=64, train_wall=68, gb_free=15.9, wall=27801
2023-07-31 19:17:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 19:18:21 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.232 | trans_loss 5.578 | nll_loss 2.855 | w2v_ctc_loss 1.424 | task_loss 6.951 | contrastive_loss 0.259 | total 4003.4 | n_correct 2482.3 | ppl 7.23 | accuracy 62.005 | uer 17.256 | wer 19.034 | raw_wer 19.034 | bleu 19.83 | wps 1942.9 | wpb 4003.4 | bsz 141.8 | num_updates 33887 | best_bleu 20.13
2023-07-31 19:18:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33887 updates
2023-07-31 19:18:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.8307.pt
2023-07-31 19:18:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.8307.pt
2023-07-31 19:18:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.8307.pt (epoch 23 @ 33887 updates, score 19.83) (writing took 30.052707079797983 seconds)
2023-07-31 19:18:51 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-07-31 19:18:51 | INFO | train | epoch 023 | loss 2.005 | trans_loss 5.003 | nll_loss 2.198 | w2v_ctc_loss 0.653 | task_loss 2.101 | contrastive_loss 0.119 | total 4138.65 | n_correct 2670.13 | ppl 4.59 | accuracy 64.517 | wps 11351.8 | ups 1.37 | wpb 8277.3 | bsz 305.7 | num_updates 33887 | lr 7.68243e-05 | gnorm 0.574 | clip 0 | loss_scale 64 | train_wall 1003 | gb_free 13.6 | wall 27917
2023-07-31 19:18:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 19:18:51 | INFO | fairseq.trainer | begin training epoch 24
2023-07-31 19:18:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 19:19:08 | INFO | train_inner | epoch 024:     13 / 1474 loss=2.02, trans_loss=5.021, nll_loss=2.222, w2v_ctc_loss=0.653, task_loss=2.111, contrastive_loss=0.212, total=4085.11, n_correct=2621.42, ppl=4.67, accuracy=64.17, wps=6136.6, ups=0.75, wpb=8170.2, bsz=304.2, num_updates=33900, lr=7.68095e-05, gnorm=0.599, clip=0, loss_scale=64, train_wall=68, gb_free=12.5, wall=27934
2023-07-31 19:20:17 | INFO | train_inner | epoch 024:    113 / 1474 loss=1.996, trans_loss=4.974, nll_loss=2.16, w2v_ctc_loss=0.64, task_loss=1.943, contrastive_loss=0.228, total=4171.44, n_correct=2711.39, ppl=4.47, accuracy=64.999, wps=12224.6, ups=1.47, wpb=8342.9, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.573, clip=0, loss_scale=64, train_wall=68, gb_free=16.4, wall=28003
2023-07-31 19:20:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 19:20:41 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.22 | trans_loss 5.584 | nll_loss 2.857 | w2v_ctc_loss 1.372 | task_loss 6.933 | contrastive_loss 0.254 | total 4003.4 | n_correct 2478.3 | ppl 7.24 | accuracy 61.905 | uer 17.113 | wer 18.832 | raw_wer 18.832 | bleu 19.94 | wps 2021.2 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.13
2023-07-31 19:20:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-07-31 19:20:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_24_34000.pt
2023-07-31 19:20:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_24_34000.pt
2023-07-31 19:21:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 19.94) (writing took 34.313663735985756 seconds)
2023-07-31 19:21:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-31 19:22:26 | INFO | train_inner | epoch 024:    214 / 1474 loss=1.996, trans_loss=4.977, nll_loss=2.165, w2v_ctc_loss=0.632, task_loss=1.861, contrastive_loss=0.288, total=4237.79, n_correct=2755.02, ppl=4.48, accuracy=65.011, wps=6562, ups=0.77, wpb=8475.6, bsz=337.6, num_updates=34100, lr=7.6584e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=28132
2023-07-31 19:23:34 | INFO | train_inner | epoch 024:    314 / 1474 loss=1.99, trans_loss=4.984, nll_loss=2.173, w2v_ctc_loss=0.645, task_loss=2.046, contrastive_loss=0.059, total=4138.44, n_correct=2686.96, ppl=4.51, accuracy=64.927, wps=12178, ups=1.47, wpb=8276.9, bsz=307.1, num_updates=34200, lr=7.64719e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=67, gb_free=15.5, wall=28200
2023-07-31 19:24:43 | INFO | train_inner | epoch 024:    414 / 1474 loss=2.012, trans_loss=4.988, nll_loss=2.177, w2v_ctc_loss=0.657, task_loss=2.217, contrastive_loss=0.208, total=4153.83, n_correct=2686.38, ppl=4.52, accuracy=64.672, wps=12088.4, ups=1.46, wpb=8307.7, bsz=298.4, num_updates=34300, lr=7.63604e-05, gnorm=0.587, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=28268
2023-07-31 19:25:51 | INFO | train_inner | epoch 024:    514 / 1474 loss=1.998, trans_loss=4.988, nll_loss=2.176, w2v_ctc_loss=0.648, task_loss=2.143, contrastive_loss=0.13, total=4141.88, n_correct=2683.68, ppl=4.52, accuracy=64.794, wps=12132.8, ups=1.46, wpb=8283.8, bsz=302.6, num_updates=34400, lr=7.62493e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=68, gb_free=15.1, wall=28337
2023-07-31 19:26:59 | INFO | train_inner | epoch 024:    614 / 1474 loss=1.992, trans_loss=4.987, nll_loss=2.178, w2v_ctc_loss=0.638, task_loss=2.111, contrastive_loss=0.095, total=4162.06, n_correct=2701.21, ppl=4.52, accuracy=64.901, wps=12121.7, ups=1.46, wpb=8324.1, bsz=308.1, num_updates=34500, lr=7.61387e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=28405
2023-07-31 19:28:08 | INFO | train_inner | epoch 024:    714 / 1474 loss=2.002, trans_loss=5, nll_loss=2.193, w2v_ctc_loss=0.649, task_loss=2.174, contrastive_loss=0.102, total=4097.35, n_correct=2647.63, ppl=4.57, accuracy=64.618, wps=12017.4, ups=1.47, wpb=8194.7, bsz=293.8, num_updates=34600, lr=7.60286e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=28474
2023-07-31 19:29:16 | INFO | train_inner | epoch 024:    814 / 1474 loss=1.999, trans_loss=5.001, nll_loss=2.196, w2v_ctc_loss=0.648, task_loss=2.093, contrastive_loss=0.084, total=4124.25, n_correct=2666.37, ppl=4.58, accuracy=64.651, wps=12078.4, ups=1.46, wpb=8248.5, bsz=308.2, num_updates=34700, lr=7.5919e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=28542
2023-07-31 19:30:24 | INFO | train_inner | epoch 024:    914 / 1474 loss=2.007, trans_loss=5.007, nll_loss=2.202, w2v_ctc_loss=0.657, task_loss=2.343, contrastive_loss=0.053, total=4041.44, n_correct=2601.93, ppl=4.6, accuracy=64.381, wps=11901, ups=1.47, wpb=8082.9, bsz=280.5, num_updates=34800, lr=7.58098e-05, gnorm=0.596, clip=0, loss_scale=32, train_wall=67, gb_free=16.1, wall=28610
2023-07-31 19:31:32 | INFO | train_inner | epoch 024:   1014 / 1474 loss=1.999, trans_loss=5.003, nll_loss=2.197, w2v_ctc_loss=0.647, task_loss=2.193, contrastive_loss=0.06, total=4128.8, n_correct=2669.08, ppl=4.59, accuracy=64.645, wps=12081, ups=1.46, wpb=8257.6, bsz=296.5, num_updates=34900, lr=7.57011e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=68, gb_free=15, wall=28678
2023-07-31 19:32:41 | INFO | train_inner | epoch 024:   1114 / 1474 loss=1.998, trans_loss=4.991, nll_loss=2.182, w2v_ctc_loss=0.655, task_loss=2.03, contrastive_loss=0.105, total=4130.49, n_correct=2675.78, ppl=4.54, accuracy=64.781, wps=12035.7, ups=1.46, wpb=8261, bsz=308.9, num_updates=35000, lr=7.55929e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=28747
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:0')
2023-07-31 19:33:50 | INFO | train_inner | epoch 024:   1214 / 1474 loss=1.998, trans_loss=5, nll_loss=2.195, w2v_ctc_loss=0.645, task_loss=2.078, contrastive_loss=0.096, total=4157.47, n_correct=2688, ppl=4.58, accuracy=64.655, wps=12114.9, ups=1.46, wpb=8314.9, bsz=311.2, num_updates=35100, lr=7.54851e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=68, gb_free=12.6, wall=28815
2023-07-31 19:34:58 | INFO | train_inner | epoch 024:   1314 / 1474 loss=2.009, trans_loss=5.011, nll_loss=2.209, w2v_ctc_loss=0.663, task_loss=2.228, contrastive_loss=0.065, total=4107.23, n_correct=2643.49, ppl=4.62, accuracy=64.362, wps=12037.7, ups=1.47, wpb=8214.5, bsz=294.3, num_updates=35200, lr=7.53778e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=68, gb_free=17.5, wall=28884
2023-07-31 19:36:06 | INFO | train_inner | epoch 024:   1414 / 1474 loss=2.008, trans_loss=5.014, nll_loss=2.212, w2v_ctc_loss=0.661, task_loss=2.198, contrastive_loss=0.063, total=4094.39, n_correct=2633.22, ppl=4.63, accuracy=64.313, wps=12033.4, ups=1.47, wpb=8188.8, bsz=292.9, num_updates=35300, lr=7.5271e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=28952
2023-07-31 19:36:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:3')
2023-07-31 19:37:12 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.201 | trans_loss 5.573 | nll_loss 2.846 | w2v_ctc_loss 1.335 | task_loss 6.947 | contrastive_loss 0.252 | total 4003.4 | n_correct 2482.9 | ppl 7.19 | accuracy 62.02 | uer 16.845 | wer 18.646 | raw_wer 18.646 | bleu 19.8 | wps 2123.3 | wpb 4003.4 | bsz 141.8 | num_updates 35360 | best_bleu 20.13
2023-07-31 19:37:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35360 updates
2023-07-31 19:37:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.8004.pt
2023-07-31 19:37:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.8004.pt
2023-07-31 19:37:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_19.8004.pt (epoch 24 @ 35360 updates, score 19.8) (writing took 11.799462487921119 seconds)
2023-07-31 19:37:24 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-07-31 19:37:24 | INFO | train | epoch 024 | loss 2 | trans_loss 4.995 | nll_loss 2.187 | w2v_ctc_loss 0.648 | task_loss 2.104 | contrastive_loss 0.117 | total 4137.86 | n_correct 2677.37 | ppl 4.55 | accuracy 64.704 | wps 10952.8 | ups 1.32 | wpb 8275.7 | bsz 305.5 | num_updates 35360 | lr 7.52071e-05 | gnorm 0.576 | clip 0 | loss_scale 32 | train_wall 1001 | gb_free 16.1 | wall 29030
2023-07-31 19:37:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 19:37:24 | INFO | fairseq.trainer | begin training epoch 25
2023-07-31 19:37:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 19:37:59 | INFO | train_inner | epoch 025:     40 / 1474 loss=1.988, trans_loss=4.986, nll_loss=2.176, w2v_ctc_loss=0.642, task_loss=2.025, contrastive_loss=0.071, total=4165.57, n_correct=2708.79, ppl=4.52, accuracy=65.028, wps=7366.1, ups=0.88, wpb=8331.1, bsz=311.2, num_updates=35400, lr=7.51646e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=69, gb_free=13, wall=29065
2023-07-31 19:39:07 | INFO | train_inner | epoch 025:    140 / 1474 loss=1.977, trans_loss=4.963, nll_loss=2.145, w2v_ctc_loss=0.633, task_loss=2.041, contrastive_loss=0.07, total=4135.43, n_correct=2703.76, ppl=4.42, accuracy=65.38, wps=12169.3, ups=1.47, wpb=8270.9, bsz=308.9, num_updates=35500, lr=7.50587e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=68, gb_free=17.7, wall=29133
2023-07-31 19:39:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-31 19:40:16 | INFO | train_inner | epoch 025:    241 / 1474 loss=1.983, trans_loss=4.97, nll_loss=2.155, w2v_ctc_loss=0.638, task_loss=2.163, contrastive_loss=0.073, total=4118.02, n_correct=2684.19, ppl=4.45, accuracy=65.182, wps=11904.5, ups=1.45, wpb=8236, bsz=302.4, num_updates=35600, lr=7.49532e-05, gnorm=0.565, clip=0, loss_scale=16, train_wall=69, gb_free=16.9, wall=29202
2023-07-31 19:41:25 | INFO | train_inner | epoch 025:    341 / 1474 loss=1.991, trans_loss=4.977, nll_loss=2.162, w2v_ctc_loss=0.64, task_loss=2.232, contrastive_loss=0.101, total=4142.17, n_correct=2690.8, ppl=4.47, accuracy=64.961, wps=12000, ups=1.45, wpb=8284.3, bsz=295.5, num_updates=35700, lr=7.48481e-05, gnorm=0.579, clip=0, loss_scale=16, train_wall=69, gb_free=15.6, wall=29271
2023-07-31 19:42:34 | INFO | train_inner | epoch 025:    441 / 1474 loss=2.009, trans_loss=4.984, nll_loss=2.172, w2v_ctc_loss=0.659, task_loss=2.205, contrastive_loss=0.182, total=4167.72, n_correct=2701.6, ppl=4.51, accuracy=64.822, wps=12157.4, ups=1.46, wpb=8335.4, bsz=296.8, num_updates=35800, lr=7.47435e-05, gnorm=0.574, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=29340
2023-07-31 19:43:42 | INFO | train_inner | epoch 025:    541 / 1474 loss=1.992, trans_loss=4.99, nll_loss=2.18, w2v_ctc_loss=0.645, task_loss=2.051, contrastive_loss=0.075, total=4154.79, n_correct=2696.5, ppl=4.53, accuracy=64.901, wps=12202.3, ups=1.47, wpb=8309.6, bsz=313.5, num_updates=35900, lr=7.46393e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=68, gb_free=17.6, wall=29408
2023-07-31 19:44:49 | INFO | train_inner | epoch 025:    641 / 1474 loss=1.994, trans_loss=4.98, nll_loss=2.168, w2v_ctc_loss=0.646, task_loss=2.09, contrastive_loss=0.143, total=4156.33, n_correct=2700.14, ppl=4.49, accuracy=64.965, wps=12284.8, ups=1.48, wpb=8312.7, bsz=309.3, num_updates=36000, lr=7.45356e-05, gnorm=0.592, clip=0, loss_scale=16, train_wall=67, gb_free=16.2, wall=29475
2023-07-31 19:44:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 19:45:12 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.219 | trans_loss 5.576 | nll_loss 2.854 | w2v_ctc_loss 1.382 | task_loss 6.918 | contrastive_loss 0.257 | total 4003.4 | n_correct 2482.2 | ppl 7.23 | accuracy 62.002 | uer 17.057 | wer 18.896 | raw_wer 18.896 | bleu 19.85 | wps 2227.3 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.13
2023-07-31 19:45:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-07-31 19:45:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_25_36000.pt
2023-07-31 19:45:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_25_36000.pt
2023-07-31 19:45:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 19.85) (writing took 25.799554720520973 seconds)
2023-07-31 19:46:48 | INFO | train_inner | epoch 025:    741 / 1474 loss=1.998, trans_loss=4.986, nll_loss=2.176, w2v_ctc_loss=0.645, task_loss=2.116, contrastive_loss=0.137, total=4133.94, n_correct=2684.95, ppl=4.52, accuracy=64.949, wps=6995.3, ups=0.85, wpb=8267.9, bsz=303.3, num_updates=36100, lr=7.44323e-05, gnorm=0.581, clip=0, loss_scale=16, train_wall=68, gb_free=15, wall=29594
2023-07-31 19:47:56 | INFO | train_inner | epoch 025:    841 / 1474 loss=1.986, trans_loss=4.985, nll_loss=2.176, w2v_ctc_loss=0.639, task_loss=1.945, contrastive_loss=0.083, total=4174.24, n_correct=2717.46, ppl=4.52, accuracy=65.101, wps=12252.4, ups=1.47, wpb=8348.5, bsz=324, num_updates=36200, lr=7.43294e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=29662
2023-07-31 19:49:04 | INFO | train_inner | epoch 025:    941 / 1474 loss=1.997, trans_loss=4.992, nll_loss=2.185, w2v_ctc_loss=0.648, task_loss=1.995, contrastive_loss=0.142, total=4154.13, n_correct=2693.26, ppl=4.55, accuracy=64.833, wps=12196.2, ups=1.47, wpb=8308.3, bsz=316.7, num_updates=36300, lr=7.4227e-05, gnorm=0.578, clip=0, loss_scale=16, train_wall=68, gb_free=10.8, wall=29730
2023-07-31 19:50:13 | INFO | train_inner | epoch 025:   1041 / 1474 loss=2.005, trans_loss=5, nll_loss=2.194, w2v_ctc_loss=0.637, task_loss=2.086, contrastive_loss=0.251, total=4178.3, n_correct=2699.29, ppl=4.57, accuracy=64.603, wps=12156.1, ups=1.45, wpb=8356.6, bsz=309.7, num_updates=36400, lr=7.41249e-05, gnorm=0.577, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=29799
2023-07-31 19:51:21 | INFO | train_inner | epoch 025:   1141 / 1474 loss=1.99, trans_loss=4.992, nll_loss=2.183, w2v_ctc_loss=0.637, task_loss=2.257, contrastive_loss=0.053, total=4042.33, n_correct=2621.89, ppl=4.54, accuracy=64.861, wps=11855.9, ups=1.47, wpb=8084.7, bsz=286.5, num_updates=36500, lr=7.40233e-05, gnorm=0.586, clip=0, loss_scale=16, train_wall=68, gb_free=17.8, wall=29867
2023-07-31 19:52:29 | INFO | train_inner | epoch 025:   1241 / 1474 loss=1.994, trans_loss=4.996, nll_loss=2.189, w2v_ctc_loss=0.642, task_loss=2.135, contrastive_loss=0.064, total=4087.78, n_correct=2647.78, ppl=4.56, accuracy=64.773, wps=12027.9, ups=1.47, wpb=8175.6, bsz=295.1, num_updates=36600, lr=7.39221e-05, gnorm=0.59, clip=0, loss_scale=16, train_wall=68, gb_free=17.7, wall=29935
2023-07-31 19:53:37 | INFO | train_inner | epoch 025:   1341 / 1474 loss=2.001, trans_loss=4.995, nll_loss=2.188, w2v_ctc_loss=0.647, task_loss=2.055, contrastive_loss=0.158, total=4166.64, n_correct=2697.36, ppl=4.56, accuracy=64.737, wps=12227.4, ups=1.47, wpb=8333.3, bsz=309.3, num_updates=36700, lr=7.38213e-05, gnorm=0.594, clip=0, loss_scale=16, train_wall=68, gb_free=16.5, wall=30003
2023-07-31 19:54:46 | INFO | train_inner | epoch 025:   1441 / 1474 loss=2.009, trans_loss=5.011, nll_loss=2.209, w2v_ctc_loss=0.653, task_loss=2.146, contrastive_loss=0.129, total=4114.64, n_correct=2646.96, ppl=4.62, accuracy=64.33, wps=11955.6, ups=1.45, wpb=8229.3, bsz=304.3, num_updates=36800, lr=7.3721e-05, gnorm=0.602, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=30072
2023-07-31 19:55:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 19:55:34 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.21 | trans_loss 5.571 | nll_loss 2.845 | w2v_ctc_loss 1.371 | task_loss 6.956 | contrastive_loss 0.249 | total 4003.4 | n_correct 2483.3 | ppl 7.18 | accuracy 62.03 | uer 17.158 | wer 19.037 | raw_wer 19.037 | bleu 20.31 | wps 1961.8 | wpb 4003.4 | bsz 141.8 | num_updates 36833 | best_bleu 20.31
2023-07-31 19:55:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36833 updates
2023-07-31 19:55:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 19:55:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt
2023-07-31 19:55:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_best.pt (epoch 25 @ 36833 updates, score 20.31) (writing took 20.285996748134494 seconds)
2023-07-31 19:55:55 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-07-31 19:55:55 | INFO | train | epoch 025 | loss 1.994 | trans_loss 4.987 | nll_loss 2.177 | w2v_ctc_loss 0.644 | task_loss 2.101 | contrastive_loss 0.116 | total 4138.67 | n_correct 2685.78 | ppl 4.52 | accuracy 64.895 | wps 10980.1 | ups 1.33 | wpb 8277.3 | bsz 305.6 | num_updates 36833 | lr 7.36879e-05 | gnorm 0.58 | clip 0 | loss_scale 16 | train_wall 1001 | gb_free 14.2 | wall 30140
2023-07-31 19:55:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 19:55:55 | INFO | fairseq.trainer | begin training epoch 26
2023-07-31 19:55:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 19:56:48 | INFO | train_inner | epoch 026:     67 / 1474 loss=1.979, trans_loss=4.966, nll_loss=2.149, w2v_ctc_loss=0.634, task_loss=1.99, contrastive_loss=0.093, total=4172.16, n_correct=2727.01, ppl=4.44, accuracy=65.362, wps=6823.4, ups=0.82, wpb=8344.3, bsz=316.9, num_updates=36900, lr=7.3621e-05, gnorm=0.58, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=30194
2023-07-31 19:57:57 | INFO | train_inner | epoch 026:    167 / 1474 loss=1.982, trans_loss=4.959, nll_loss=2.142, w2v_ctc_loss=0.621, task_loss=1.857, contrastive_loss=0.267, total=4265.22, n_correct=2793.03, ppl=4.41, accuracy=65.484, wps=12418.3, ups=1.46, wpb=8530.4, bsz=338.7, num_updates=37000, lr=7.35215e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=68, gb_free=15.4, wall=30263
2023-07-31 19:59:05 | INFO | train_inner | epoch 026:    267 / 1474 loss=1.989, trans_loss=4.966, nll_loss=2.15, w2v_ctc_loss=0.642, task_loss=2.09, contrastive_loss=0.154, total=4123.94, n_correct=2687.26, ppl=4.44, accuracy=65.162, wps=12107.1, ups=1.47, wpb=8247.9, bsz=306.6, num_updates=37100, lr=7.34223e-05, gnorm=0.579, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=30331
2023-07-31 20:00:13 | INFO | train_inner | epoch 026:    367 / 1474 loss=1.984, trans_loss=4.969, nll_loss=2.154, w2v_ctc_loss=0.638, task_loss=2.006, contrastive_loss=0.115, total=4168.11, n_correct=2717.05, ppl=4.45, accuracy=65.187, wps=12230.2, ups=1.47, wpb=8336.2, bsz=315.2, num_updates=37200, lr=7.33236e-05, gnorm=0.587, clip=0, loss_scale=16, train_wall=68, gb_free=17.2, wall=30399
2023-07-31 20:01:21 | INFO | train_inner | epoch 026:    467 / 1474 loss=1.984, trans_loss=4.963, nll_loss=2.146, w2v_ctc_loss=0.634, task_loss=2.015, contrastive_loss=0.156, total=4167.53, n_correct=2723.83, ppl=4.43, accuracy=65.358, wps=12238.3, ups=1.47, wpb=8335.1, bsz=314.6, num_updates=37300, lr=7.32252e-05, gnorm=0.567, clip=0, loss_scale=16, train_wall=68, gb_free=14, wall=30467
2023-07-31 20:02:30 | INFO | train_inner | epoch 026:    567 / 1474 loss=1.989, trans_loss=4.977, nll_loss=2.164, w2v_ctc_loss=0.649, task_loss=2.111, contrastive_loss=0.077, total=4158.48, n_correct=2707.21, ppl=4.48, accuracy=65.101, wps=12129.3, ups=1.46, wpb=8317, bsz=304.4, num_updates=37400, lr=7.31272e-05, gnorm=0.574, clip=0, loss_scale=16, train_wall=68, gb_free=12.7, wall=30536
2023-07-31 20:03:38 | INFO | train_inner | epoch 026:    667 / 1474 loss=1.983, trans_loss=4.976, nll_loss=2.163, w2v_ctc_loss=0.633, task_loss=2.153, contrastive_loss=0.062, total=4129.11, n_correct=2689.22, ppl=4.48, accuracy=65.128, wps=12181.1, ups=1.48, wpb=8258.2, bsz=297.7, num_updates=37500, lr=7.30297e-05, gnorm=0.584, clip=0, loss_scale=16, train_wall=67, gb_free=13.8, wall=30604
2023-07-31 20:04:46 | INFO | train_inner | epoch 026:    767 / 1474 loss=1.995, trans_loss=4.983, nll_loss=2.171, w2v_ctc_loss=0.638, task_loss=2.112, contrastive_loss=0.176, total=4096.84, n_correct=2659.79, ppl=4.5, accuracy=64.923, wps=11973.2, ups=1.46, wpb=8193.7, bsz=300.5, num_updates=37600, lr=7.29325e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=30672
2023-07-31 20:05:54 | INFO | train_inner | epoch 026:    867 / 1474 loss=1.988, trans_loss=4.979, nll_loss=2.165, w2v_ctc_loss=0.642, task_loss=2.095, contrastive_loss=0.077, total=4176.27, n_correct=2714.62, ppl=4.49, accuracy=65.001, wps=12244.7, ups=1.47, wpb=8352.5, bsz=306.4, num_updates=37700, lr=7.28357e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=30740
2023-07-31 20:07:03 | INFO | train_inner | epoch 026:    967 / 1474 loss=1.992, trans_loss=4.988, nll_loss=2.178, w2v_ctc_loss=0.631, task_loss=2.168, contrastive_loss=0.131, total=4141.01, n_correct=2683.15, ppl=4.53, accuracy=64.795, wps=12045.4, ups=1.45, wpb=8282, bsz=299.7, num_updates=37800, lr=7.27393e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=68, gb_free=15.5, wall=30809
2023-07-31 20:08:11 | INFO | train_inner | epoch 026:   1067 / 1474 loss=1.987, trans_loss=4.984, nll_loss=2.173, w2v_ctc_loss=0.637, task_loss=2.22, contrastive_loss=0.06, total=4113.69, n_correct=2676.14, ppl=4.51, accuracy=65.054, wps=12100.1, ups=1.47, wpb=8227.4, bsz=293, num_updates=37900, lr=7.26433e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=67, gb_free=15.5, wall=30877
2023-07-31 20:09:20 | INFO | train_inner | epoch 026:   1167 / 1474 loss=1.994, trans_loss=4.991, nll_loss=2.183, w2v_ctc_loss=0.64, task_loss=2.194, contrastive_loss=0.101, total=4116.78, n_correct=2669.49, ppl=4.54, accuracy=64.844, wps=11946.9, ups=1.45, wpb=8233.6, bsz=299, num_updates=38000, lr=7.25476e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=30946
2023-07-31 20:09:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 20:09:44 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.216 | trans_loss 5.571 | nll_loss 2.844 | w2v_ctc_loss 1.389 | task_loss 6.941 | contrastive_loss 0.249 | total 4003.4 | n_correct 2485.6 | ppl 7.18 | accuracy 62.087 | uer 17.222 | wer 18.944 | raw_wer 18.944 | bleu 20.02 | wps 2082.2 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.31
2023-07-31 20:09:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-07-31 20:09:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_26_38000.pt
2023-07-31 20:09:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_26_38000.pt
2023-07-31 20:10:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 20.02) (writing took 29.599056055769324 seconds)
2023-07-31 20:11:26 | INFO | train_inner | epoch 026:   1267 / 1474 loss=2.002, trans_loss=5.002, nll_loss=2.196, w2v_ctc_loss=0.655, task_loss=2.326, contrastive_loss=0.064, total=4001.06, n_correct=2584.27, ppl=4.58, accuracy=64.59, wps=6365.1, ups=0.8, wpb=8002.1, bsz=280.6, num_updates=38100, lr=7.24524e-05, gnorm=0.6, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=31072
2023-07-31 20:12:35 | INFO | train_inner | epoch 026:   1367 / 1474 loss=1.989, trans_loss=4.994, nll_loss=2.187, w2v_ctc_loss=0.633, task_loss=2.102, contrastive_loss=0.081, total=4157.69, n_correct=2695.77, ppl=4.55, accuracy=64.838, wps=12024.9, ups=1.45, wpb=8315.4, bsz=310.5, num_updates=38200, lr=7.23575e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=31141
2023-07-31 20:13:42 | INFO | train_inner | epoch 026:   1467 / 1474 loss=1.982, trans_loss=4.986, nll_loss=2.177, w2v_ctc_loss=0.629, task_loss=1.99, contrastive_loss=0.072, total=4158.47, n_correct=2707.16, ppl=4.52, accuracy=65.1, wps=12302.1, ups=1.48, wpb=8316.9, bsz=316.5, num_updates=38300, lr=7.22629e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=67, gb_free=17.3, wall=31208
2023-07-31 20:13:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 20:14:10 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.199 | trans_loss 5.569 | nll_loss 2.846 | w2v_ctc_loss 1.338 | task_loss 6.917 | contrastive_loss 0.252 | total 4003.4 | n_correct 2486.4 | ppl 7.19 | accuracy 62.107 | uer 17.126 | wer 18.914 | raw_wer 18.914 | bleu 20.03 | wps 2185.4 | wpb 4003.4 | bsz 141.8 | num_updates 38307 | best_bleu 20.31
2023-07-31 20:14:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38307 updates
2023-07-31 20:14:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_20.0308.pt
2023-07-31 20:14:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_20.0308.pt
2023-07-31 20:14:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_20.0308.pt (epoch 26 @ 38307 updates, score 20.03) (writing took 13.8659707326442 seconds)
2023-07-31 20:14:25 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-07-31 20:14:25 | INFO | train | epoch 026 | loss 1.988 | trans_loss 4.978 | nll_loss 2.166 | w2v_ctc_loss 0.637 | task_loss 2.1 | contrastive_loss 0.115 | total 4138.65 | n_correct 2693.03 | ppl 4.49 | accuracy 65.07 | wps 10989.8 | ups 1.33 | wpb 8277.3 | bsz 305.7 | num_updates 38307 | lr 7.22563e-05 | gnorm 0.581 | clip 0 | loss_scale 32 | train_wall 1000 | gb_free 15.9 | wall 31251
2023-07-31 20:14:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 20:14:25 | INFO | fairseq.trainer | begin training epoch 27
2023-07-31 20:14:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 20:15:36 | INFO | train_inner | epoch 027:     93 / 1474 loss=1.969, trans_loss=4.943, nll_loss=2.118, w2v_ctc_loss=0.625, task_loss=2.238, contrastive_loss=0.05, total=4067.62, n_correct=2676.41, ppl=4.34, accuracy=65.798, wps=7181.7, ups=0.88, wpb=8135.2, bsz=284.4, num_updates=38400, lr=7.21688e-05, gnorm=0.593, clip=0, loss_scale=32, train_wall=68, gb_free=14.8, wall=31322
2023-07-31 20:16:44 | INFO | train_inner | epoch 027:    193 / 1474 loss=1.971, trans_loss=4.95, nll_loss=2.13, w2v_ctc_loss=0.63, task_loss=2.009, contrastive_loss=0.083, total=4185.52, n_correct=2746.02, ppl=4.38, accuracy=65.608, wps=12302.6, ups=1.47, wpb=8371, bsz=321.7, num_updates=38500, lr=7.2075e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=31390
2023-07-31 20:17:53 | INFO | train_inner | epoch 027:    293 / 1474 loss=1.975, trans_loss=4.958, nll_loss=2.139, w2v_ctc_loss=0.632, task_loss=2.091, contrastive_loss=0.064, total=4167.92, n_correct=2732.38, ppl=4.41, accuracy=65.557, wps=12113.6, ups=1.45, wpb=8335.8, bsz=306.8, num_updates=38600, lr=7.19816e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=31459
2023-07-31 20:19:01 | INFO | train_inner | epoch 027:    393 / 1474 loss=1.991, trans_loss=4.965, nll_loss=2.148, w2v_ctc_loss=0.628, task_loss=2.197, contrastive_loss=0.248, total=4075.21, n_correct=2659.32, ppl=4.43, accuracy=65.256, wps=11838.3, ups=1.45, wpb=8150.4, bsz=296, num_updates=38700, lr=7.18885e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=31527
2023-07-31 20:20:10 | INFO | train_inner | epoch 027:    493 / 1474 loss=1.985, trans_loss=4.971, nll_loss=2.157, w2v_ctc_loss=0.63, task_loss=1.915, contrastive_loss=0.185, total=4249.35, n_correct=2769.39, ppl=4.46, accuracy=65.172, wps=12344, ups=1.45, wpb=8498.7, bsz=331.9, num_updates=38800, lr=7.17958e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=68, gb_free=11.9, wall=31596
2023-07-31 20:21:18 | INFO | train_inner | epoch 027:    593 / 1474 loss=1.984, trans_loss=4.969, nll_loss=2.154, w2v_ctc_loss=0.636, task_loss=2.053, contrastive_loss=0.123, total=4133.39, n_correct=2701.24, ppl=4.45, accuracy=65.352, wps=12157.8, ups=1.47, wpb=8266.8, bsz=312, num_updates=38900, lr=7.17035e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=68, gb_free=11.9, wall=31664
2023-07-31 20:22:27 | INFO | train_inner | epoch 027:    693 / 1474 loss=1.986, trans_loss=4.973, nll_loss=2.159, w2v_ctc_loss=0.639, task_loss=2.093, contrastive_loss=0.101, total=4162.71, n_correct=2714.26, ppl=4.47, accuracy=65.204, wps=12161.3, ups=1.46, wpb=8325.4, bsz=305.4, num_updates=39000, lr=7.16115e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=31733
2023-07-31 20:23:34 | INFO | train_inner | epoch 027:    793 / 1474 loss=1.984, trans_loss=4.973, nll_loss=2.159, w2v_ctc_loss=0.638, task_loss=2.213, contrastive_loss=0.064, total=4103.81, n_correct=2674.47, ppl=4.46, accuracy=65.17, wps=12147.8, ups=1.48, wpb=8207.6, bsz=294.2, num_updates=39100, lr=7.15199e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=31800
2023-07-31 20:24:43 | INFO | train_inner | epoch 027:    893 / 1474 loss=1.978, trans_loss=4.978, nll_loss=2.164, w2v_ctc_loss=0.624, task_loss=2.191, contrastive_loss=0.053, total=4101.56, n_correct=2677.92, ppl=4.48, accuracy=65.29, wps=12007.8, ups=1.46, wpb=8203.1, bsz=292.1, num_updates=39200, lr=7.14286e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=68, gb_free=17.7, wall=31869
2023-07-31 20:25:51 | INFO | train_inner | epoch 027:    993 / 1474 loss=1.99, trans_loss=4.975, nll_loss=2.162, w2v_ctc_loss=0.629, task_loss=2.035, contrastive_loss=0.243, total=4199.56, n_correct=2737.22, ppl=4.48, accuracy=65.179, wps=12251.8, ups=1.46, wpb=8399.1, bsz=316.8, num_updates=39300, lr=7.13376e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=68, gb_free=11.5, wall=31937
2023-07-31 20:27:00 | INFO | train_inner | epoch 027:   1093 / 1474 loss=1.977, trans_loss=4.972, nll_loss=2.158, w2v_ctc_loss=0.626, task_loss=2.116, contrastive_loss=0.076, total=4150.97, n_correct=2708.31, ppl=4.46, accuracy=65.245, wps=12072.2, ups=1.45, wpb=8301.9, bsz=305, num_updates=39400, lr=7.1247e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=68, gb_free=11.9, wall=32006
2023-07-31 20:28:08 | INFO | train_inner | epoch 027:   1193 / 1474 loss=1.991, trans_loss=4.982, nll_loss=2.171, w2v_ctc_loss=0.644, task_loss=2.191, contrastive_loss=0.079, total=4103.06, n_correct=2666.35, ppl=4.5, accuracy=64.984, wps=12060.5, ups=1.47, wpb=8206.1, bsz=297.7, num_updates=39500, lr=7.11568e-05, gnorm=0.591, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=32074
2023-07-31 20:29:16 | INFO | train_inner | epoch 027:   1293 / 1474 loss=1.995, trans_loss=4.987, nll_loss=2.178, w2v_ctc_loss=0.639, task_loss=2.252, contrastive_loss=0.129, total=4062.52, n_correct=2633.89, ppl=4.52, accuracy=64.834, wps=11885.2, ups=1.46, wpb=8125, bsz=292.2, num_updates=39600, lr=7.10669e-05, gnorm=0.587, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=32142
2023-07-31 20:30:24 | INFO | train_inner | epoch 027:   1393 / 1474 loss=1.982, trans_loss=4.98, nll_loss=2.169, w2v_ctc_loss=0.625, task_loss=1.978, contrastive_loss=0.112, total=4152, n_correct=2705.56, ppl=4.5, accuracy=65.163, wps=12320.5, ups=1.48, wpb=8304, bsz=312.5, num_updates=39700, lr=7.09773e-05, gnorm=0.569, clip=0, loss_scale=64, train_wall=67, gb_free=16.6, wall=32210
2023-07-31 20:31:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 20:31:44 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.198 | trans_loss 5.568 | nll_loss 2.844 | w2v_ctc_loss 1.34 | task_loss 6.91 | contrastive_loss 0.246 | total 4003.4 | n_correct 2488.1 | ppl 7.18 | accuracy 62.15 | uer 16.752 | wer 18.601 | raw_wer 18.601 | bleu 20.02 | wps 2019.9 | wpb 4003.4 | bsz 141.8 | num_updates 39781 | best_bleu 20.31
2023-07-31 20:31:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39781 updates
2023-07-31 20:31:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_20.0202.pt
2023-07-31 20:31:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_20.0202.pt
2023-07-31 20:31:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_20.0202.pt (epoch 27 @ 39781 updates, score 20.02) (writing took 14.326614178717136 seconds)
2023-07-31 20:31:58 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-07-31 20:31:58 | INFO | train | epoch 027 | loss 1.982 | trans_loss 4.97 | nll_loss 2.155 | w2v_ctc_loss 0.631 | task_loss 2.099 | contrastive_loss 0.114 | total 4138.65 | n_correct 2701.52 | ppl 4.45 | accuracy 65.275 | wps 11578.9 | ups 1.4 | wpb 8277.3 | bsz 305.7 | num_updates 39781 | lr 7.0905e-05 | gnorm 0.579 | clip 0 | loss_scale 64 | train_wall 1001 | gb_free 17.8 | wall 32304
2023-07-31 20:31:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 20:31:59 | INFO | fairseq.trainer | begin training epoch 28
2023-07-31 20:31:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 20:32:19 | INFO | train_inner | epoch 028:     19 / 1474 loss=1.974, trans_loss=4.971, nll_loss=2.156, w2v_ctc_loss=0.624, task_loss=2.032, contrastive_loss=0.064, total=4108.43, n_correct=2687.57, ppl=4.46, accuracy=65.416, wps=7146.7, ups=0.87, wpb=8216.9, bsz=305.1, num_updates=39800, lr=7.08881e-05, gnorm=0.586, clip=0, loss_scale=64, train_wall=68, gb_free=16.3, wall=32325
2023-07-31 20:33:27 | INFO | train_inner | epoch 028:    119 / 1474 loss=1.965, trans_loss=4.94, nll_loss=2.115, w2v_ctc_loss=0.622, task_loss=2.187, contrastive_loss=0.059, total=4113.41, n_correct=2711.52, ppl=4.33, accuracy=65.919, wps=12097.6, ups=1.47, wpb=8226.8, bsz=293.9, num_updates=39900, lr=7.07992e-05, gnorm=0.578, clip=0, loss_scale=64, train_wall=67, gb_free=16.9, wall=32393
2023-07-31 20:34:35 | INFO | train_inner | epoch 028:    219 / 1474 loss=1.966, trans_loss=4.949, nll_loss=2.128, w2v_ctc_loss=0.621, task_loss=1.991, contrastive_loss=0.068, total=4191.56, n_correct=2756.78, ppl=4.37, accuracy=65.77, wps=12290.2, ups=1.47, wpb=8383.1, bsz=315.2, num_updates=40000, lr=7.07107e-05, gnorm=0.571, clip=0, loss_scale=64, train_wall=68, gb_free=15.1, wall=32461
2023-07-31 20:34:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 20:34:59 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.214 | trans_loss 5.577 | nll_loss 2.852 | w2v_ctc_loss 1.37 | task_loss 6.918 | contrastive_loss 0.245 | total 4003.4 | n_correct 2481.6 | ppl 7.22 | accuracy 61.987 | uer 16.85 | wer 18.75 | raw_wer 18.75 | bleu 19.93 | wps 2071.4 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.31
2023-07-31 20:34:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-07-31 20:34:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_28_40000.pt
2023-07-31 20:35:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_28_40000.pt
2023-07-31 20:35:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 19.93) (writing took 17.105385176837444 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:0')
2023-07-31 20:35:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-31 20:36:27 | INFO | train_inner | epoch 028:    320 / 1474 loss=1.983, trans_loss=4.956, nll_loss=2.136, w2v_ctc_loss=0.619, task_loss=2.134, contrastive_loss=0.296, total=4127.08, n_correct=2701.13, ppl=4.4, accuracy=65.449, wps=7368.3, ups=0.89, wpb=8254.2, bsz=308.8, num_updates=40100, lr=7.06225e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=69, gb_free=13.2, wall=32573
2023-07-31 20:37:35 | INFO | train_inner | epoch 028:    420 / 1474 loss=1.972, trans_loss=4.955, nll_loss=2.135, w2v_ctc_loss=0.629, task_loss=2.169, contrastive_loss=0.054, total=4089.84, n_correct=2683.08, ppl=4.39, accuracy=65.604, wps=12073.3, ups=1.48, wpb=8179.7, bsz=295.7, num_updates=40200, lr=7.05346e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=32641
2023-07-31 20:38:42 | INFO | train_inner | epoch 028:    520 / 1474 loss=1.97, trans_loss=4.954, nll_loss=2.135, w2v_ctc_loss=0.622, task_loss=2.185, contrastive_loss=0.066, total=4098.92, n_correct=2687.94, ppl=4.39, accuracy=65.577, wps=12153.6, ups=1.48, wpb=8197.8, bsz=295.7, num_updates=40300, lr=7.0447e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=67, gb_free=16.9, wall=32708
2023-07-31 20:39:51 | INFO | train_inner | epoch 028:    620 / 1474 loss=1.977, trans_loss=4.969, nll_loss=2.154, w2v_ctc_loss=0.629, task_loss=2.117, contrastive_loss=0.067, total=4180.1, n_correct=2730.86, ppl=4.45, accuracy=65.33, wps=12150.3, ups=1.45, wpb=8360.2, bsz=305.3, num_updates=40400, lr=7.03598e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=32777
2023-07-31 20:41:00 | INFO | train_inner | epoch 028:    720 / 1474 loss=1.978, trans_loss=4.966, nll_loss=2.152, w2v_ctc_loss=0.623, task_loss=1.897, contrastive_loss=0.181, total=4191.62, n_correct=2741.84, ppl=4.44, accuracy=65.412, wps=12213.2, ups=1.46, wpb=8383.2, bsz=329.2, num_updates=40500, lr=7.02728e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=32846
2023-07-31 20:42:07 | INFO | train_inner | epoch 028:    820 / 1474 loss=1.97, trans_loss=4.962, nll_loss=2.146, w2v_ctc_loss=0.622, task_loss=2.077, contrastive_loss=0.056, total=4088.91, n_correct=2683.68, ppl=4.43, accuracy=65.633, wps=12078.2, ups=1.48, wpb=8177.8, bsz=304.3, num_updates=40600, lr=7.01862e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=67, gb_free=17, wall=32913
2023-07-31 20:43:16 | INFO | train_inner | epoch 028:    920 / 1474 loss=1.987, trans_loss=4.975, nll_loss=2.161, w2v_ctc_loss=0.633, task_loss=2.17, contrastive_loss=0.123, total=4117.01, n_correct=2682.11, ppl=4.47, accuracy=65.147, wps=12045.1, ups=1.46, wpb=8234, bsz=299.7, num_updates=40700, lr=7.01e-05, gnorm=0.591, clip=0, loss_scale=32, train_wall=68, gb_free=15.3, wall=32982
2023-07-31 20:44:25 | INFO | train_inner | epoch 028:   1020 / 1474 loss=1.989, trans_loss=4.974, nll_loss=2.16, w2v_ctc_loss=0.635, task_loss=2.045, contrastive_loss=0.175, total=4182.85, n_correct=2725.77, ppl=4.47, accuracy=65.165, wps=12111, ups=1.45, wpb=8365.7, bsz=312, num_updates=40800, lr=7.0014e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=33051
2023-07-31 20:45:33 | INFO | train_inner | epoch 028:   1120 / 1474 loss=1.97, trans_loss=4.961, nll_loss=2.145, w2v_ctc_loss=0.623, task_loss=2.016, contrastive_loss=0.082, total=4220.16, n_correct=2763.85, ppl=4.42, accuracy=65.492, wps=12337.3, ups=1.46, wpb=8440.3, bsz=321, num_updates=40900, lr=6.99284e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=33119
2023-07-31 20:46:41 | INFO | train_inner | epoch 028:   1220 / 1474 loss=1.975, trans_loss=4.972, nll_loss=2.158, w2v_ctc_loss=0.623, task_loss=2.085, contrastive_loss=0.068, total=4092.46, n_correct=2676.69, ppl=4.46, accuracy=65.405, wps=12051.4, ups=1.47, wpb=8184.9, bsz=303.1, num_updates=41000, lr=6.9843e-05, gnorm=0.594, clip=0, loss_scale=32, train_wall=67, gb_free=17.6, wall=33187
2023-07-31 20:47:50 | INFO | train_inner | epoch 028:   1320 / 1474 loss=1.989, trans_loss=4.978, nll_loss=2.165, w2v_ctc_loss=0.641, task_loss=2.299, contrastive_loss=0.081, total=4084.55, n_correct=2657.28, ppl=4.48, accuracy=65.057, wps=11914.1, ups=1.46, wpb=8169.1, bsz=285.1, num_updates=41100, lr=6.9758e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=33256
2023-07-31 20:48:58 | INFO | train_inner | epoch 028:   1420 / 1474 loss=1.981, trans_loss=4.973, nll_loss=2.159, w2v_ctc_loss=0.626, task_loss=2.187, contrastive_loss=0.102, total=4154.09, n_correct=2709.94, ppl=4.47, accuracy=65.235, wps=12118.5, ups=1.46, wpb=8308.2, bsz=299.3, num_updates=41200, lr=6.96733e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=33324
2023-07-31 20:49:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:2')
2023-07-31 20:49:59 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.198 | trans_loss 5.569 | nll_loss 2.844 | w2v_ctc_loss 1.332 | task_loss 6.944 | contrastive_loss 0.256 | total 4003.4 | n_correct 2486.6 | ppl 7.18 | accuracy 62.112 | uer 16.781 | wer 18.556 | raw_wer 18.556 | bleu 20.03 | wps 2037.1 | wpb 4003.4 | bsz 141.8 | num_updates 41254 | best_bleu 20.31
2023-07-31 20:49:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41254 updates
2023-07-31 20:49:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_20.0306.pt
2023-07-31 20:50:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_20.0306.pt
2023-07-31 20:50:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_20.0306.pt (epoch 28 @ 41254 updates, score 20.03) (writing took 12.969689952209592 seconds)
2023-07-31 20:50:12 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-07-31 20:50:12 | INFO | train | epoch 028 | loss 1.976 | trans_loss 4.963 | nll_loss 2.146 | w2v_ctc_loss 0.626 | task_loss 2.102 | contrastive_loss 0.105 | total 4137.55 | n_correct 2708.27 | ppl 4.43 | accuracy 65.456 | wps 11143.1 | ups 1.35 | wpb 8275.1 | bsz 305.2 | num_updates 41254 | lr 6.96277e-05 | gnorm 0.581 | clip 0 | loss_scale 32 | train_wall 999 | gb_free 16.4 | wall 33398
2023-07-31 20:50:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 20:50:13 | INFO | fairseq.trainer | begin training epoch 29
2023-07-31 20:50:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 20:50:52 | INFO | train_inner | epoch 029:     46 / 1474 loss=1.968, trans_loss=4.948, nll_loss=2.127, w2v_ctc_loss=0.627, task_loss=2.017, contrastive_loss=0.081, total=4169.12, n_correct=2743.36, ppl=4.37, accuracy=65.802, wps=7317.5, ups=0.88, wpb=8338.2, bsz=316.4, num_updates=41300, lr=6.95889e-05, gnorm=0.589, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=33438
2023-07-31 20:51:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-31 20:52:01 | INFO | train_inner | epoch 029:    147 / 1474 loss=1.97, trans_loss=4.947, nll_loss=2.124, w2v_ctc_loss=0.623, task_loss=2.092, contrastive_loss=0.098, total=4111.12, n_correct=2701.29, ppl=4.36, accuracy=65.707, wps=12021, ups=1.46, wpb=8222.2, bsz=305.7, num_updates=41400, lr=6.95048e-05, gnorm=0.594, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=33507
2023-07-31 20:53:09 | INFO | train_inner | epoch 029:    247 / 1474 loss=1.964, trans_loss=4.939, nll_loss=2.116, w2v_ctc_loss=0.607, task_loss=1.909, contrastive_loss=0.181, total=4197.89, n_correct=2764.93, ppl=4.34, accuracy=65.865, wps=12243, ups=1.46, wpb=8395.8, bsz=329.5, num_updates=41500, lr=6.9421e-05, gnorm=0.587, clip=0, loss_scale=16, train_wall=68, gb_free=17.5, wall=33575
2023-07-31 20:54:18 | INFO | train_inner | epoch 029:    347 / 1474 loss=1.976, trans_loss=4.96, nll_loss=2.141, w2v_ctc_loss=0.631, task_loss=2.255, contrastive_loss=0.062, total=4094.4, n_correct=2679.73, ppl=4.41, accuracy=65.449, wps=11956.7, ups=1.46, wpb=8188.8, bsz=291.2, num_updates=41600, lr=6.93375e-05, gnorm=0.594, clip=0, loss_scale=16, train_wall=68, gb_free=16.5, wall=33644
2023-07-31 20:55:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-31 20:55:27 | INFO | train_inner | epoch 029:    448 / 1474 loss=1.957, trans_loss=4.936, nll_loss=2.111, w2v_ctc_loss=0.613, task_loss=2.009, contrastive_loss=0.054, total=4162.89, n_correct=2748.11, ppl=4.32, accuracy=66.014, wps=12063.4, ups=1.45, wpb=8325.8, bsz=308.9, num_updates=41700, lr=6.92543e-05, gnorm=0.588, clip=0, loss_scale=8, train_wall=69, gb_free=14.8, wall=33713
2023-07-31 20:56:35 | INFO | train_inner | epoch 029:    548 / 1474 loss=1.983, trans_loss=4.961, nll_loss=2.143, w2v_ctc_loss=0.624, task_loss=2.233, contrastive_loss=0.152, total=4159.23, n_correct=2718.21, ppl=4.42, accuracy=65.354, wps=12148.1, ups=1.46, wpb=8318.5, bsz=295.2, num_updates=41800, lr=6.91714e-05, gnorm=0.579, clip=0, loss_scale=8, train_wall=68, gb_free=16.8, wall=33781
2023-07-31 20:57:43 | INFO | train_inner | epoch 029:    648 / 1474 loss=1.97, trans_loss=4.946, nll_loss=2.126, w2v_ctc_loss=0.614, task_loss=1.983, contrastive_loss=0.223, total=4139.5, n_correct=2719.91, ppl=4.36, accuracy=65.706, wps=12171.4, ups=1.47, wpb=8279, bsz=318.8, num_updates=41900, lr=6.90889e-05, gnorm=0.58, clip=0, loss_scale=8, train_wall=68, gb_free=16.2, wall=33849
2023-07-31 20:58:52 | INFO | train_inner | epoch 029:    748 / 1474 loss=1.967, trans_loss=4.949, nll_loss=2.129, w2v_ctc_loss=0.614, task_loss=1.945, contrastive_loss=0.143, total=4241.03, n_correct=2790.54, ppl=4.37, accuracy=65.799, wps=12272.4, ups=1.45, wpb=8482.1, bsz=328.7, num_updates=42000, lr=6.90066e-05, gnorm=0.575, clip=0, loss_scale=8, train_wall=69, gb_free=15.7, wall=33918
2023-07-31 20:58:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 20:59:15 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.21 | trans_loss 5.572 | nll_loss 2.846 | w2v_ctc_loss 1.363 | task_loss 6.922 | contrastive_loss 0.255 | total 4003.4 | n_correct 2478.7 | ppl 7.19 | accuracy 61.915 | uer 16.826 | wer 18.582 | raw_wer 18.582 | bleu 20.08 | wps 2193.2 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.31
2023-07-31 20:59:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-07-31 20:59:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_29_42000.pt
2023-07-31 20:59:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_29_42000.pt
2023-07-31 20:59:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 20.08) (writing took 33.604223158210516 seconds)
2023-07-31 21:00:58 | INFO | train_inner | epoch 029:    848 / 1474 loss=1.977, trans_loss=4.971, nll_loss=2.155, w2v_ctc_loss=0.626, task_loss=2.312, contrastive_loss=0.054, total=4031.53, n_correct=2636.58, ppl=4.45, accuracy=65.399, wps=6433.4, ups=0.8, wpb=8063.1, bsz=282.9, num_updates=42100, lr=6.89246e-05, gnorm=0.641, clip=0, loss_scale=8, train_wall=67, gb_free=16.3, wall=34044
2023-07-31 21:02:06 | INFO | train_inner | epoch 029:    948 / 1474 loss=1.979, trans_loss=4.969, nll_loss=2.153, w2v_ctc_loss=0.631, task_loss=2.186, contrastive_loss=0.065, total=4082.22, n_correct=2670.41, ppl=4.45, accuracy=65.416, wps=12047.9, ups=1.48, wpb=8164.4, bsz=293.3, num_updates=42200, lr=6.88428e-05, gnorm=0.606, clip=0, loss_scale=8, train_wall=67, gb_free=16.2, wall=34111
2023-07-31 21:03:14 | INFO | train_inner | epoch 029:   1048 / 1474 loss=1.97, trans_loss=4.956, nll_loss=2.138, w2v_ctc_loss=0.615, task_loss=2.082, contrastive_loss=0.143, total=4134.44, n_correct=2713.92, ppl=4.4, accuracy=65.642, wps=12095.6, ups=1.46, wpb=8268.9, bsz=307.7, num_updates=42300, lr=6.87614e-05, gnorm=0.599, clip=0, loss_scale=8, train_wall=68, gb_free=17, wall=34180
2023-07-31 21:04:22 | INFO | train_inner | epoch 029:   1148 / 1474 loss=1.98, trans_loss=4.973, nll_loss=2.159, w2v_ctc_loss=0.631, task_loss=2.288, contrastive_loss=0.052, total=4080.4, n_correct=2667.65, ppl=4.47, accuracy=65.377, wps=11994.2, ups=1.47, wpb=8160.8, bsz=285.2, num_updates=42400, lr=6.86803e-05, gnorm=0.596, clip=0, loss_scale=8, train_wall=68, gb_free=12.1, wall=34248
2023-07-31 21:05:31 | INFO | train_inner | epoch 029:   1248 / 1474 loss=1.975, trans_loss=4.971, nll_loss=2.157, w2v_ctc_loss=0.626, task_loss=2.12, contrastive_loss=0.057, total=4158.63, n_correct=2718.69, ppl=4.46, accuracy=65.375, wps=12062.1, ups=1.45, wpb=8317.3, bsz=301.6, num_updates=42500, lr=6.85994e-05, gnorm=0.581, clip=0, loss_scale=8, train_wall=68, gb_free=16.6, wall=34317
2023-07-31 21:06:40 | INFO | train_inner | epoch 029:   1348 / 1474 loss=1.976, trans_loss=4.964, nll_loss=2.149, w2v_ctc_loss=0.622, task_loss=2.091, contrastive_loss=0.127, total=4159.66, n_correct=2723.84, ppl=4.44, accuracy=65.482, wps=12107.2, ups=1.46, wpb=8319.3, bsz=308.6, num_updates=42600, lr=6.85189e-05, gnorm=0.58, clip=0, loss_scale=8, train_wall=68, gb_free=16.6, wall=34385
2023-07-31 21:07:48 | INFO | train_inner | epoch 029:   1448 / 1474 loss=1.976, trans_loss=4.962, nll_loss=2.146, w2v_ctc_loss=0.624, task_loss=2.039, contrastive_loss=0.153, total=4169.01, n_correct=2726.68, ppl=4.43, accuracy=65.404, wps=12206.6, ups=1.46, wpb=8338, bsz=314.2, num_updates=42700, lr=6.84386e-05, gnorm=0.588, clip=0, loss_scale=8, train_wall=68, gb_free=17.8, wall=34454
2023-07-31 21:08:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 21:08:28 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.208 | trans_loss 5.573 | nll_loss 2.847 | w2v_ctc_loss 1.358 | task_loss 6.929 | contrastive_loss 0.25 | total 4003.4 | n_correct 2484.7 | ppl 7.19 | accuracy 62.065 | uer 16.707 | wer 18.459 | raw_wer 18.459 | bleu 20.07 | wps 2247.3 | wpb 4003.4 | bsz 141.8 | num_updates 42726 | best_bleu 20.31
2023-07-31 21:08:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42726 updates
2023-07-31 21:08:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_20.0702.pt
2023-07-31 21:08:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_20.0702.pt
2023-07-31 21:08:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_20.0702.pt (epoch 29 @ 42726 updates, score 20.07) (writing took 11.951704524457455 seconds)
2023-07-31 21:08:41 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-07-31 21:08:41 | INFO | train | epoch 029 | loss 1.972 | trans_loss 4.957 | nll_loss 2.138 | w2v_ctc_loss 0.621 | task_loss 2.099 | contrastive_loss 0.112 | total 4139.32 | n_correct 2714.86 | ppl 4.4 | accuracy 65.587 | wps 10995 | ups 1.33 | wpb 8278.6 | bsz 305.8 | num_updates 42726 | lr 6.84178e-05 | gnorm 0.591 | clip 0 | loss_scale 8 | train_wall 1000 | gb_free 16 | wall 34507
2023-07-31 21:08:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 21:08:41 | INFO | fairseq.trainer | begin training epoch 30
2023-07-31 21:08:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 21:09:39 | INFO | train_inner | epoch 030:     74 / 1474 loss=1.963, trans_loss=4.94, nll_loss=2.116, w2v_ctc_loss=0.606, task_loss=2.009, contrastive_loss=0.171, total=4172.13, n_correct=2751.71, ppl=4.34, accuracy=65.955, wps=7507.1, ups=0.9, wpb=8344.3, bsz=317.1, num_updates=42800, lr=6.83586e-05, gnorm=0.581, clip=0, loss_scale=8, train_wall=68, gb_free=15.8, wall=34565
2023-07-31 21:10:47 | INFO | train_inner | epoch 030:    174 / 1474 loss=1.957, trans_loss=4.924, nll_loss=2.096, w2v_ctc_loss=0.616, task_loss=1.949, contrastive_loss=0.104, total=4211.56, n_correct=2792.99, ppl=4.27, accuracy=66.317, wps=12349.8, ups=1.47, wpb=8423.1, bsz=320.5, num_updates=42900, lr=6.82789e-05, gnorm=0.585, clip=0, loss_scale=8, train_wall=68, gb_free=16.8, wall=34633
2023-07-31 21:11:55 | INFO | train_inner | epoch 030:    274 / 1474 loss=1.968, trans_loss=4.943, nll_loss=2.119, w2v_ctc_loss=0.63, task_loss=2.186, contrastive_loss=0.053, total=4115.07, n_correct=2706.41, ppl=4.34, accuracy=65.768, wps=12129.5, ups=1.47, wpb=8230.1, bsz=293.2, num_updates=43000, lr=6.81994e-05, gnorm=0.635, clip=0, loss_scale=8, train_wall=67, gb_free=15.7, wall=34701
2023-07-31 21:13:04 | INFO | train_inner | epoch 030:    374 / 1474 loss=1.955, trans_loss=4.933, nll_loss=2.107, w2v_ctc_loss=0.611, task_loss=2.081, contrastive_loss=0.057, total=4184.54, n_correct=2768.21, ppl=4.31, accuracy=66.153, wps=12204.5, ups=1.46, wpb=8369.1, bsz=309.3, num_updates=43100, lr=6.81203e-05, gnorm=0.57, clip=0, loss_scale=8, train_wall=68, gb_free=17.2, wall=34770
2023-07-31 21:14:11 | INFO | train_inner | epoch 030:    474 / 1474 loss=1.959, trans_loss=4.938, nll_loss=2.114, w2v_ctc_loss=0.606, task_loss=2.03, contrastive_loss=0.123, total=4121.08, n_correct=2720.52, ppl=4.33, accuracy=66.015, wps=12178.6, ups=1.48, wpb=8242.2, bsz=311.1, num_updates=43200, lr=6.80414e-05, gnorm=0.582, clip=0, loss_scale=8, train_wall=67, gb_free=14.8, wall=34837
2023-07-31 21:15:19 | INFO | train_inner | epoch 030:    574 / 1474 loss=1.962, trans_loss=4.946, nll_loss=2.125, w2v_ctc_loss=0.614, task_loss=2.042, contrastive_loss=0.085, total=4162.58, n_correct=2743.5, ppl=4.36, accuracy=65.909, wps=12295.1, ups=1.48, wpb=8325.2, bsz=312.1, num_updates=43300, lr=6.79628e-05, gnorm=0.579, clip=0, loss_scale=8, train_wall=67, gb_free=15.2, wall=34905
2023-07-31 21:16:27 | INFO | train_inner | epoch 030:    674 / 1474 loss=1.97, trans_loss=4.949, nll_loss=2.128, w2v_ctc_loss=0.627, task_loss=2.072, contrastive_loss=0.102, total=4192, n_correct=2754.45, ppl=4.37, accuracy=65.707, wps=12332.9, ups=1.47, wpb=8384, bsz=315.3, num_updates=43400, lr=6.78844e-05, gnorm=0.585, clip=0, loss_scale=8, train_wall=68, gb_free=15.7, wall=34973
2023-07-31 21:17:36 | INFO | train_inner | epoch 030:    774 / 1474 loss=1.985, trans_loss=4.962, nll_loss=2.146, w2v_ctc_loss=0.633, task_loss=2.146, contrastive_loss=0.18, total=4103.26, n_correct=2683.67, ppl=4.43, accuracy=65.403, wps=11968.7, ups=1.46, wpb=8206.5, bsz=302.6, num_updates=43500, lr=6.78064e-05, gnorm=0.616, clip=0, loss_scale=8, train_wall=68, gb_free=16.2, wall=35042
2023-07-31 21:18:44 | INFO | train_inner | epoch 030:    874 / 1474 loss=1.966, trans_loss=4.954, nll_loss=2.134, w2v_ctc_loss=0.614, task_loss=2.153, contrastive_loss=0.07, total=4111.51, n_correct=2703.83, ppl=4.39, accuracy=65.762, wps=12056, ups=1.47, wpb=8223, bsz=297.8, num_updates=43600, lr=6.77285e-05, gnorm=0.578, clip=0, loss_scale=8, train_wall=68, gb_free=16.2, wall=35110
2023-07-31 21:19:52 | INFO | train_inner | epoch 030:    974 / 1474 loss=1.974, trans_loss=4.962, nll_loss=2.145, w2v_ctc_loss=0.625, task_loss=2.167, contrastive_loss=0.071, total=4125.95, n_correct=2698.52, ppl=4.42, accuracy=65.404, wps=12102, ups=1.47, wpb=8251.9, bsz=298.7, num_updates=43700, lr=6.7651e-05, gnorm=0.59, clip=0, loss_scale=8, train_wall=68, gb_free=16.5, wall=35178
2023-07-31 21:21:00 | INFO | train_inner | epoch 030:   1074 / 1474 loss=1.983, trans_loss=4.966, nll_loss=2.149, w2v_ctc_loss=0.626, task_loss=2.353, contrastive_loss=0.145, total=4096.17, n_correct=2675.63, ppl=4.44, accuracy=65.32, wps=11972.3, ups=1.46, wpb=8192.3, bsz=281.5, num_updates=43800, lr=6.75737e-05, gnorm=0.595, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=35246
2023-07-31 21:22:09 | INFO | train_inner | epoch 030:   1174 / 1474 loss=1.966, trans_loss=4.955, nll_loss=2.138, w2v_ctc_loss=0.608, task_loss=2.012, contrastive_loss=0.13, total=4168.92, n_correct=2736.8, ppl=4.4, accuracy=65.648, wps=12197.9, ups=1.46, wpb=8337.8, bsz=314.8, num_updates=43900, lr=6.74967e-05, gnorm=0.579, clip=0, loss_scale=16, train_wall=68, gb_free=17.6, wall=35315
2023-07-31 21:23:17 | INFO | train_inner | epoch 030:   1274 / 1474 loss=1.977, trans_loss=4.964, nll_loss=2.147, w2v_ctc_loss=0.63, task_loss=2.326, contrastive_loss=0.063, total=4038.68, n_correct=2641.52, ppl=4.43, accuracy=65.406, wps=11825.9, ups=1.46, wpb=8077.4, bsz=284.1, num_updates=44000, lr=6.742e-05, gnorm=0.596, clip=0, loss_scale=16, train_wall=68, gb_free=14.9, wall=35383
2023-07-31 21:23:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 21:23:42 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.198 | trans_loss 5.573 | nll_loss 2.848 | w2v_ctc_loss 1.325 | task_loss 6.88 | contrastive_loss 0.252 | total 4003.4 | n_correct 2489.1 | ppl 7.2 | accuracy 62.175 | uer 16.994 | wer 18.858 | raw_wer 18.858 | bleu 19.79 | wps 1795.2 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.31
2023-07-31 21:23:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-07-31 21:23:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_30_44000.pt
2023-07-31 21:23:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_30_44000.pt
2023-07-31 21:23:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 19.79) (writing took 13.980601221323013 seconds)
2023-07-31 21:25:05 | INFO | train_inner | epoch 030:   1374 / 1474 loss=1.962, trans_loss=4.955, nll_loss=2.139, w2v_ctc_loss=0.613, task_loss=1.975, contrastive_loss=0.076, total=4167.64, n_correct=2740.45, ppl=4.4, accuracy=65.755, wps=7737, ups=0.93, wpb=8335.3, bsz=321.9, num_updates=44100, lr=6.73435e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=67, gb_free=16.6, wall=35491
2023-07-31 21:26:12 | INFO | train_inner | epoch 030:   1474 / 1474 loss=1.971, trans_loss=4.959, nll_loss=2.143, w2v_ctc_loss=0.606, task_loss=1.982, contrastive_loss=0.219, total=4117.91, n_correct=2706.11, ppl=4.42, accuracy=65.716, wps=12288.4, ups=1.49, wpb=8235.8, bsz=312.2, num_updates=44200, lr=6.72673e-05, gnorm=0.578, clip=0, loss_scale=16, train_wall=66, gb_free=17.1, wall=35558
2023-07-31 21:26:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 21:26:35 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.189 | trans_loss 5.568 | nll_loss 2.841 | w2v_ctc_loss 1.307 | task_loss 6.94 | contrastive_loss 0.25 | total 4003.4 | n_correct 2491 | ppl 7.17 | accuracy 62.222 | uer 16.797 | wer 18.72 | raw_wer 18.72 | bleu 20.13 | wps 2245.3 | wpb 4003.4 | bsz 141.8 | num_updates 44200 | best_bleu 20.31
2023-07-31 21:26:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44200 updates
2023-07-31 21:26:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_20.1307.pt
2023-07-31 21:26:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_20.1307.pt
2023-07-31 21:26:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_20.1307.pt (epoch 30 @ 44200 updates, score 20.13) (writing took 14.865991484373808 seconds)
2023-07-31 21:26:50 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-07-31 21:26:50 | INFO | train | epoch 030 | loss 1.968 | trans_loss 4.95 | nll_loss 2.129 | w2v_ctc_loss 0.618 | task_loss 2.1 | contrastive_loss 0.111 | total 4138.65 | n_correct 2721.29 | ppl 4.38 | accuracy 65.753 | wps 11199.1 | ups 1.35 | wpb 8277.3 | bsz 305.7 | num_updates 44200 | lr 6.72673e-05 | gnorm 0.588 | clip 0 | loss_scale 16 | train_wall 996 | gb_free 17.1 | wall 35596
2023-07-31 21:26:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 21:26:50 | INFO | fairseq.trainer | begin training epoch 31
2023-07-31 21:26:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 21:28:07 | INFO | train_inner | epoch 031:    100 / 1474 loss=1.961, trans_loss=4.933, nll_loss=2.105, w2v_ctc_loss=0.621, task_loss=2.215, contrastive_loss=0.065, total=4085.38, n_correct=2698.81, ppl=4.3, accuracy=66.06, wps=7084.5, ups=0.87, wpb=8170.8, bsz=293.4, num_updates=44300, lr=6.71913e-05, gnorm=0.574, clip=0, loss_scale=16, train_wall=68, gb_free=14.9, wall=35673
2023-07-31 21:29:16 | INFO | train_inner | epoch 031:    200 / 1474 loss=1.96, trans_loss=4.935, nll_loss=2.108, w2v_ctc_loss=0.615, task_loss=2.169, contrastive_loss=0.077, total=4139.51, n_correct=2733.28, ppl=4.31, accuracy=66.029, wps=12114.6, ups=1.46, wpb=8279, bsz=299.4, num_updates=44400, lr=6.71156e-05, gnorm=0.572, clip=0, loss_scale=16, train_wall=68, gb_free=11.8, wall=35741
2023-07-31 21:30:24 | INFO | train_inner | epoch 031:    300 / 1474 loss=1.96, trans_loss=4.932, nll_loss=2.105, w2v_ctc_loss=0.612, task_loss=2.146, contrastive_loss=0.122, total=4148.01, n_correct=2743.54, ppl=4.3, accuracy=66.141, wps=12084.9, ups=1.46, wpb=8296, bsz=301.1, num_updates=44500, lr=6.70402e-05, gnorm=0.591, clip=0, loss_scale=16, train_wall=68, gb_free=13.2, wall=35810
2023-07-31 21:31:32 | INFO | train_inner | epoch 031:    400 / 1474 loss=1.964, trans_loss=4.946, nll_loss=2.122, w2v_ctc_loss=0.615, task_loss=2.288, contrastive_loss=0.06, total=4095.42, n_correct=2696.05, ppl=4.35, accuracy=65.831, wps=12033.4, ups=1.47, wpb=8190.8, bsz=286.3, num_updates=44600, lr=6.6965e-05, gnorm=0.593, clip=0, loss_scale=16, train_wall=67, gb_free=13.3, wall=35878
2023-07-31 21:32:41 | INFO | train_inner | epoch 031:    500 / 1474 loss=1.963, trans_loss=4.937, nll_loss=2.113, w2v_ctc_loss=0.624, task_loss=2.188, contrastive_loss=0.07, total=4115.61, n_correct=2713.24, ppl=4.33, accuracy=65.926, wps=12009.3, ups=1.46, wpb=8231.2, bsz=300.6, num_updates=44700, lr=6.689e-05, gnorm=0.591, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=35947
2023-07-31 21:33:49 | INFO | train_inner | epoch 031:    600 / 1474 loss=1.957, trans_loss=4.938, nll_loss=2.114, w2v_ctc_loss=0.608, task_loss=2.204, contrastive_loss=0.059, total=4075.9, n_correct=2690.3, ppl=4.33, accuracy=66.005, wps=11956.5, ups=1.47, wpb=8151.8, bsz=293.3, num_updates=44800, lr=6.68153e-05, gnorm=0.589, clip=0, loss_scale=16, train_wall=68, gb_free=11.7, wall=36015
2023-07-31 21:34:57 | INFO | train_inner | epoch 031:    700 / 1474 loss=1.951, trans_loss=4.935, nll_loss=2.11, w2v_ctc_loss=0.603, task_loss=2.008, contrastive_loss=0.06, total=4208.99, n_correct=2782.21, ppl=4.32, accuracy=66.102, wps=12460.5, ups=1.48, wpb=8418, bsz=315.1, num_updates=44900, lr=6.67409e-05, gnorm=0.568, clip=0, loss_scale=16, train_wall=67, gb_free=17.8, wall=36083
2023-07-31 21:36:05 | INFO | train_inner | epoch 031:    800 / 1474 loss=1.97, trans_loss=4.951, nll_loss=2.131, w2v_ctc_loss=0.614, task_loss=2.188, contrastive_loss=0.132, total=4104.19, n_correct=2694.38, ppl=4.38, accuracy=65.649, wps=11953.2, ups=1.46, wpb=8208.4, bsz=297.4, num_updates=45000, lr=6.66667e-05, gnorm=0.606, clip=0, loss_scale=16, train_wall=68, gb_free=15.3, wall=36151
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:0')
2023-07-31 21:37:14 | INFO | train_inner | epoch 031:    900 / 1474 loss=1.964, trans_loss=4.944, nll_loss=2.121, w2v_ctc_loss=0.618, task_loss=2.219, contrastive_loss=0.076, total=4099.13, n_correct=2699.38, ppl=4.35, accuracy=65.853, wps=11965.7, ups=1.46, wpb=8198.3, bsz=294.3, num_updates=45100, lr=6.65927e-05, gnorm=0.601, clip=0, loss_scale=16, train_wall=68, gb_free=15.1, wall=36220
2023-07-31 21:38:22 | INFO | train_inner | epoch 031:   1000 / 1474 loss=1.965, trans_loss=4.951, nll_loss=2.133, w2v_ctc_loss=0.609, task_loss=1.965, contrastive_loss=0.159, total=4186.81, n_correct=2757.36, ppl=4.39, accuracy=65.858, wps=12282, ups=1.47, wpb=8373.6, bsz=320.9, num_updates=45200, lr=6.6519e-05, gnorm=0.581, clip=0, loss_scale=16, train_wall=68, gb_free=13.3, wall=36288
2023-07-31 21:39:30 | INFO | train_inner | epoch 031:   1100 / 1474 loss=1.964, trans_loss=4.948, nll_loss=2.128, w2v_ctc_loss=0.613, task_loss=2.05, contrastive_loss=0.109, total=4149.25, n_correct=2729.77, ppl=4.37, accuracy=65.789, wps=12231.6, ups=1.47, wpb=8298.5, bsz=315.2, num_updates=45300, lr=6.64455e-05, gnorm=0.611, clip=0, loss_scale=16, train_wall=67, gb_free=15.9, wall=36356
2023-07-31 21:40:38 | INFO | train_inner | epoch 031:   1200 / 1474 loss=1.969, trans_loss=4.95, nll_loss=2.132, w2v_ctc_loss=0.609, task_loss=1.978, contrastive_loss=0.222, total=4187.45, n_correct=2756.36, ppl=4.38, accuracy=65.824, wps=12343.2, ups=1.47, wpb=8374.9, bsz=320.3, num_updates=45400, lr=6.63723e-05, gnorm=0.584, clip=0, loss_scale=16, train_wall=67, gb_free=17, wall=36424
2023-07-31 21:41:45 | INFO | train_inner | epoch 031:   1300 / 1474 loss=1.959, trans_loss=4.952, nll_loss=2.133, w2v_ctc_loss=0.612, task_loss=1.884, contrastive_loss=0.067, total=4227.39, n_correct=2785.9, ppl=4.39, accuracy=65.901, wps=12488.2, ups=1.48, wpb=8454.8, bsz=326.7, num_updates=45500, lr=6.62994e-05, gnorm=0.579, clip=0, loss_scale=16, train_wall=67, gb_free=16.9, wall=36491
2023-07-31 21:42:54 | INFO | train_inner | epoch 031:   1400 / 1474 loss=1.978, trans_loss=4.954, nll_loss=2.137, w2v_ctc_loss=0.613, task_loss=1.922, contrastive_loss=0.274, total=4191.1, n_correct=2749.55, ppl=4.4, accuracy=65.604, wps=12250.5, ups=1.46, wpb=8382.2, bsz=327, num_updates=45600, lr=6.62266e-05, gnorm=0.582, clip=0, loss_scale=16, train_wall=68, gb_free=16.5, wall=36560
2023-07-31 21:43:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:2')
2023-07-31 21:44:07 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.196 | trans_loss 5.569 | nll_loss 2.843 | w2v_ctc_loss 1.328 | task_loss 6.914 | contrastive_loss 0.251 | total 4003.4 | n_correct 2490 | ppl 7.17 | accuracy 62.197 | uer 16.441 | wer 18.348 | raw_wer 18.348 | bleu 19.97 | wps 2156.7 | wpb 4003.4 | bsz 141.8 | num_updates 45674 | best_bleu 20.31
2023-07-31 21:44:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45674 updates
2023-07-31 21:44:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_last.pt
2023-07-31 21:44:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_last.pt
2023-07-31 21:44:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_last.pt (epoch 31 @ 45674 updates, score 19.97) (writing took 11.226166991516948 seconds)
2023-07-31 21:44:18 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-07-31 21:44:18 | INFO | train | epoch 031 | loss 1.963 | trans_loss 4.944 | nll_loss 2.122 | w2v_ctc_loss 0.613 | task_loss 2.101 | contrastive_loss 0.11 | total 4138.65 | n_correct 2726.86 | ppl 4.35 | accuracy 65.888 | wps 11640.2 | ups 1.41 | wpb 8277.3 | bsz 305.7 | num_updates 45674 | lr 6.61729e-05 | gnorm 0.588 | clip 0 | loss_scale 16 | train_wall 997 | gb_free 12 | wall 36644
2023-07-31 21:44:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 21:44:19 | INFO | fairseq.trainer | begin training epoch 32
2023-07-31 21:44:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 21:44:43 | INFO | train_inner | epoch 032:     26 / 1474 loss=1.962, trans_loss=4.945, nll_loss=2.123, w2v_ctc_loss=0.614, task_loss=2.216, contrastive_loss=0.055, total=4040.88, n_correct=2663.5, ppl=4.36, accuracy=65.914, wps=7374.7, ups=0.91, wpb=8081.8, bsz=288.7, num_updates=45700, lr=6.61541e-05, gnorm=0.607, clip=0, loss_scale=16, train_wall=67, gb_free=15.5, wall=36669
2023-07-31 21:45:52 | INFO | train_inner | epoch 032:    126 / 1474 loss=1.935, trans_loss=4.907, nll_loss=2.073, w2v_ctc_loss=0.59, task_loss=1.938, contrastive_loss=0.068, total=4222.14, n_correct=2817.54, ppl=4.21, accuracy=66.733, wps=12325.8, ups=1.46, wpb=8444.3, bsz=322.6, num_updates=45800, lr=6.60819e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=68, gb_free=15.4, wall=36738
2023-07-31 21:47:00 | INFO | train_inner | epoch 032:    226 / 1474 loss=1.949, trans_loss=4.927, nll_loss=2.099, w2v_ctc_loss=0.605, task_loss=1.995, contrastive_loss=0.079, total=4159.77, n_correct=2756.9, ppl=4.28, accuracy=66.275, wps=12143.2, ups=1.46, wpb=8319.5, bsz=320.8, num_updates=45900, lr=6.60098e-05, gnorm=0.591, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=36806
2023-07-31 21:48:08 | INFO | train_inner | epoch 032:    326 / 1474 loss=1.941, trans_loss=4.915, nll_loss=2.084, w2v_ctc_loss=0.594, task_loss=1.988, contrastive_loss=0.071, total=4179.65, n_correct=2782.29, ppl=4.24, accuracy=66.568, wps=12353.8, ups=1.48, wpb=8359.3, bsz=313.8, num_updates=46000, lr=6.5938e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=36874
2023-07-31 21:48:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 21:48:32 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.21 | trans_loss 5.581 | nll_loss 2.857 | w2v_ctc_loss 1.344 | task_loss 6.909 | contrastive_loss 0.259 | total 4003.4 | n_correct 2484.8 | ppl 7.25 | accuracy 62.067 | uer 16.622 | wer 18.426 | raw_wer 18.426 | bleu 19.77 | wps 2121.4 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.31
2023-07-31 21:48:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-07-31 21:48:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_32_46000.pt
2023-07-31 21:48:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_32_46000.pt
2023-07-31 21:48:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 19.77) (writing took 24.08696390874684 seconds)
2023-07-31 21:50:05 | INFO | train_inner | epoch 032:    426 / 1474 loss=1.948, trans_loss=4.922, nll_loss=2.093, w2v_ctc_loss=0.607, task_loss=2.049, contrastive_loss=0.068, total=4172.34, n_correct=2771.99, ppl=4.27, accuracy=66.437, wps=7152.1, ups=0.86, wpb=8344.7, bsz=309.9, num_updates=46100, lr=6.58665e-05, gnorm=0.593, clip=0, loss_scale=32, train_wall=68, gb_free=17.1, wall=36991
2023-07-31 21:51:14 | INFO | train_inner | epoch 032:    526 / 1474 loss=1.961, trans_loss=4.933, nll_loss=2.107, w2v_ctc_loss=0.612, task_loss=2.051, contrastive_loss=0.151, total=4191.15, n_correct=2775.4, ppl=4.31, accuracy=66.22, wps=12116.6, ups=1.45, wpb=8382.3, bsz=315.1, num_updates=46200, lr=6.57952e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=69, gb_free=14.9, wall=37060
2023-07-31 21:52:23 | INFO | train_inner | epoch 032:    626 / 1474 loss=1.96, trans_loss=4.94, nll_loss=2.116, w2v_ctc_loss=0.614, task_loss=2.196, contrastive_loss=0.075, total=4138.05, n_correct=2728.17, ppl=4.33, accuracy=65.929, wps=12036, ups=1.45, wpb=8276.1, bsz=299.5, num_updates=46300, lr=6.57241e-05, gnorm=0.591, clip=0, loss_scale=32, train_wall=68, gb_free=13.2, wall=37129
2023-07-31 21:53:31 | INFO | train_inner | epoch 032:    726 / 1474 loss=1.959, trans_loss=4.94, nll_loss=2.117, w2v_ctc_loss=0.615, task_loss=2.127, contrastive_loss=0.057, total=4156.23, n_correct=2745.44, ppl=4.34, accuracy=66.056, wps=12170.5, ups=1.46, wpb=8312.5, bsz=303, num_updates=46400, lr=6.56532e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=37197
2023-07-31 21:54:38 | INFO | train_inner | epoch 032:    826 / 1474 loss=1.953, trans_loss=4.936, nll_loss=2.111, w2v_ctc_loss=0.605, task_loss=2.179, contrastive_loss=0.053, total=4112.3, n_correct=2718.31, ppl=4.32, accuracy=66.102, wps=12197.2, ups=1.48, wpb=8224.6, bsz=293.9, num_updates=46500, lr=6.55826e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=67, gb_free=15.8, wall=37264
2023-07-31 21:55:47 | INFO | train_inner | epoch 032:    926 / 1474 loss=1.953, trans_loss=4.939, nll_loss=2.116, w2v_ctc_loss=0.599, task_loss=2.174, contrastive_loss=0.053, total=4139.37, n_correct=2732.28, ppl=4.34, accuracy=66.007, wps=12110.3, ups=1.46, wpb=8278.7, bsz=298.6, num_updates=46600, lr=6.55122e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=68, gb_free=12.7, wall=37333
2023-07-31 21:56:54 | INFO | train_inner | epoch 032:   1026 / 1474 loss=1.966, trans_loss=4.947, nll_loss=2.126, w2v_ctc_loss=0.613, task_loss=2.073, contrastive_loss=0.147, total=4121.85, n_correct=2712.36, ppl=4.36, accuracy=65.804, wps=12196.6, ups=1.48, wpb=8243.7, bsz=306.1, num_updates=46700, lr=6.5442e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=67, gb_free=16.8, wall=37400
2023-07-31 21:58:03 | INFO | train_inner | epoch 032:   1126 / 1474 loss=1.97, trans_loss=4.952, nll_loss=2.131, w2v_ctc_loss=0.614, task_loss=2.487, contrastive_loss=0.09, total=4015.59, n_correct=2638.21, ppl=4.38, accuracy=65.699, wps=11795.9, ups=1.47, wpb=8031.2, bsz=270.1, num_updates=46800, lr=6.5372e-05, gnorm=0.595, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=37468
2023-07-31 21:59:10 | INFO | train_inner | epoch 032:   1226 / 1474 loss=1.974, trans_loss=4.956, nll_loss=2.139, w2v_ctc_loss=0.61, task_loss=2.074, contrastive_loss=0.199, total=4153.44, n_correct=2726.13, ppl=4.4, accuracy=65.635, wps=12223.2, ups=1.47, wpb=8306.9, bsz=310.8, num_updates=46900, lr=6.53023e-05, gnorm=0.587, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=37536
2023-07-31 22:00:19 | INFO | train_inner | epoch 032:   1326 / 1474 loss=1.962, trans_loss=4.948, nll_loss=2.127, w2v_ctc_loss=0.614, task_loss=2.166, contrastive_loss=0.052, total=4075.86, n_correct=2683.72, ppl=4.37, accuracy=65.844, wps=11963.1, ups=1.47, wpb=8151.7, bsz=295.4, num_updates=47000, lr=6.52328e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=37605
2023-07-31 22:01:26 | INFO | train_inner | epoch 032:   1426 / 1474 loss=1.979, trans_loss=4.952, nll_loss=2.133, w2v_ctc_loss=0.618, task_loss=2.095, contrastive_loss=0.288, total=4116.4, n_correct=2704.92, ppl=4.39, accuracy=65.711, wps=12158.6, ups=1.48, wpb=8232.8, bsz=307.6, num_updates=47100, lr=6.51635e-05, gnorm=0.595, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=37672
2023-07-31 22:01:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 22:02:22 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.215 | trans_loss 5.571 | nll_loss 2.845 | w2v_ctc_loss 1.384 | task_loss 6.943 | contrastive_loss 0.257 | total 4003.4 | n_correct 2489.1 | ppl 7.19 | accuracy 62.175 | uer 16.508 | wer 18.221 | raw_wer 18.221 | bleu 20.1 | wps 2115.1 | wpb 4003.4 | bsz 141.8 | num_updates 47148 | best_bleu 20.31
2023-07-31 22:02:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47148 updates
2023-07-31 22:02:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_20.1003.pt
2023-07-31 22:02:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_20.1003.pt
2023-07-31 22:02:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint.best_bleu_20.1003.pt (epoch 32 @ 47148 updates, score 20.1) (writing took 12.278127295896411 seconds)
2023-07-31 22:02:35 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-07-31 22:02:35 | INFO | train | epoch 032 | loss 1.958 | trans_loss 4.936 | nll_loss 2.112 | w2v_ctc_loss 0.607 | task_loss 2.1 | contrastive_loss 0.109 | total 4138.65 | n_correct 2734.68 | ppl 4.32 | accuracy 66.077 | wps 11128.4 | ups 1.34 | wpb 8277.3 | bsz 305.7 | num_updates 47148 | lr 6.51303e-05 | gnorm 0.585 | clip 0 | loss_scale 32 | train_wall 997 | gb_free 16.4 | wall 37741
2023-07-31 22:02:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 22:02:35 | INFO | fairseq.trainer | begin training epoch 33
2023-07-31 22:02:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 22:03:18 | INFO | train_inner | epoch 033:     52 / 1474 loss=1.957, trans_loss=4.932, nll_loss=2.108, w2v_ctc_loss=0.602, task_loss=1.983, contrastive_loss=0.16, total=4149.21, n_correct=2742.93, ppl=4.31, accuracy=66.107, wps=7412.1, ups=0.89, wpb=8298.4, bsz=320.5, num_updates=47200, lr=6.50945e-05, gnorm=0.586, clip=0, loss_scale=32, train_wall=67, gb_free=17, wall=37784
2023-07-31 22:04:26 | INFO | train_inner | epoch 033:    152 / 1474 loss=1.943, trans_loss=4.915, nll_loss=2.082, w2v_ctc_loss=0.592, task_loss=2.258, contrastive_loss=0.043, total=4073.9, n_correct=2706.76, ppl=4.23, accuracy=66.441, wps=12026.7, ups=1.48, wpb=8147.8, bsz=284.8, num_updates=47300, lr=6.50256e-05, gnorm=0.597, clip=0, loss_scale=32, train_wall=67, gb_free=15.2, wall=37852
2023-07-31 22:05:35 | INFO | train_inner | epoch 033:    252 / 1474 loss=1.952, trans_loss=4.915, nll_loss=2.085, w2v_ctc_loss=0.597, task_loss=1.794, contrastive_loss=0.229, total=4280.14, n_correct=2846.45, ppl=4.24, accuracy=66.504, wps=12450.6, ups=1.45, wpb=8560.3, bsz=346.5, num_updates=47400, lr=6.4957e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=37921
2023-07-31 22:06:43 | INFO | train_inner | epoch 033:    352 / 1474 loss=1.951, trans_loss=4.925, nll_loss=2.097, w2v_ctc_loss=0.604, task_loss=2.144, contrastive_loss=0.077, total=4120.27, n_correct=2730.67, ppl=4.28, accuracy=66.274, wps=12155.3, ups=1.48, wpb=8240.5, bsz=300.7, num_updates=47500, lr=6.48886e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=67, gb_free=17.3, wall=37989
2023-07-31 22:07:50 | INFO | train_inner | epoch 033:    452 / 1474 loss=1.938, trans_loss=4.912, nll_loss=2.079, w2v_ctc_loss=0.597, task_loss=1.992, contrastive_loss=0.052, total=4141.22, n_correct=2756.94, ppl=4.22, accuracy=66.573, wps=12283.6, ups=1.48, wpb=8282.4, bsz=310.8, num_updates=47600, lr=6.48204e-05, gnorm=0.585, clip=0, loss_scale=32, train_wall=67, gb_free=16.4, wall=38056
2023-07-31 22:08:58 | INFO | train_inner | epoch 033:    552 / 1474 loss=1.958, trans_loss=4.933, nll_loss=2.106, w2v_ctc_loss=0.609, task_loss=2.181, contrastive_loss=0.075, total=4133.59, n_correct=2733.35, ppl=4.31, accuracy=66.125, wps=12191.7, ups=1.47, wpb=8267.2, bsz=294, num_updates=47700, lr=6.47524e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=67, gb_free=15.2, wall=38124
2023-07-31 22:10:06 | INFO | train_inner | epoch 033:    652 / 1474 loss=1.96, trans_loss=4.943, nll_loss=2.12, w2v_ctc_loss=0.605, task_loss=2.146, contrastive_loss=0.109, total=4157.63, n_correct=2739.9, ppl=4.35, accuracy=65.901, wps=12183.8, ups=1.47, wpb=8315.3, bsz=301.6, num_updates=47800, lr=6.46846e-05, gnorm=0.589, clip=0, loss_scale=32, train_wall=68, gb_free=17.7, wall=38192
2023-07-31 22:11:14 | INFO | train_inner | epoch 033:    752 / 1474 loss=1.963, trans_loss=4.938, nll_loss=2.114, w2v_ctc_loss=0.621, task_loss=2.278, contrastive_loss=0.054, total=4070.75, n_correct=2683.99, ppl=4.33, accuracy=65.934, wps=12019.5, ups=1.48, wpb=8141.5, bsz=287.2, num_updates=47900, lr=6.46171e-05, gnorm=0.596, clip=0, loss_scale=64, train_wall=67, gb_free=16.4, wall=38260
2023-07-31 22:12:22 | INFO | train_inner | epoch 033:    852 / 1474 loss=1.944, trans_loss=4.927, nll_loss=2.101, w2v_ctc_loss=0.587, task_loss=1.995, contrastive_loss=0.125, total=4130.24, n_correct=2742.08, ppl=4.29, accuracy=66.39, wps=12140.9, ups=1.47, wpb=8260.5, bsz=316.3, num_updates=48000, lr=6.45497e-05, gnorm=0.582, clip=0, loss_scale=64, train_wall=68, gb_free=16.7, wall=38328
2023-07-31 22:12:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 22:12:46 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.215 | trans_loss 5.58 | nll_loss 2.855 | w2v_ctc_loss 1.364 | task_loss 6.926 | contrastive_loss 0.255 | total 4003.4 | n_correct 2488.3 | ppl 7.24 | accuracy 62.155 | uer 16.898 | wer 18.78 | raw_wer 18.78 | bleu 20.15 | wps 2007.2 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.31
2023-07-31 22:12:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-07-31 22:12:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_33_48000.pt
2023-07-31 22:12:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_33_48000.pt
2023-07-31 22:13:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 20.15) (writing took 17.475305169820786 seconds)
2023-07-31 22:13:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-31 22:14:13 | INFO | train_inner | epoch 033:    953 / 1474 loss=1.956, trans_loss=4.933, nll_loss=2.108, w2v_ctc_loss=0.615, task_loss=2.086, contrastive_loss=0.068, total=4156.06, n_correct=2750.33, ppl=4.31, accuracy=66.176, wps=7449.7, ups=0.9, wpb=8312.1, bsz=309.6, num_updates=48100, lr=6.44826e-05, gnorm=0.587, clip=0, loss_scale=32, train_wall=68, gb_free=17.4, wall=38439
2023-07-31 22:15:22 | INFO | train_inner | epoch 033:   1053 / 1474 loss=1.962, trans_loss=4.936, nll_loss=2.112, w2v_ctc_loss=0.603, task_loss=2.124, contrastive_loss=0.174, total=4134.8, n_correct=2730.22, ppl=4.32, accuracy=66.03, wps=11988.1, ups=1.45, wpb=8269.6, bsz=306, num_updates=48200, lr=6.44157e-05, gnorm=0.599, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=38508
2023-07-31 22:16:31 | INFO | train_inner | epoch 033:   1153 / 1474 loss=1.961, trans_loss=4.942, nll_loss=2.119, w2v_ctc_loss=0.601, task_loss=2.098, contrastive_loss=0.161, total=4181.58, n_correct=2757.54, ppl=4.34, accuracy=65.945, wps=12278, ups=1.47, wpb=8363.2, bsz=310, num_updates=48300, lr=6.43489e-05, gnorm=0.597, clip=0, loss_scale=32, train_wall=68, gb_free=15, wall=38576
2023-07-31 22:17:39 | INFO | train_inner | epoch 033:   1253 / 1474 loss=1.957, trans_loss=4.938, nll_loss=2.115, w2v_ctc_loss=0.611, task_loss=2.206, contrastive_loss=0.058, total=4115.76, n_correct=2718.37, ppl=4.33, accuracy=66.048, wps=12097.6, ups=1.47, wpb=8231.5, bsz=294.7, num_updates=48400, lr=6.42824e-05, gnorm=0.597, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=38645
2023-07-31 22:18:47 | INFO | train_inner | epoch 033:   1353 / 1474 loss=1.953, trans_loss=4.937, nll_loss=2.115, w2v_ctc_loss=0.607, task_loss=2.061, contrastive_loss=0.081, total=4120.69, n_correct=2726.47, ppl=4.33, accuracy=66.165, wps=12064.9, ups=1.46, wpb=8241.4, bsz=311.9, num_updates=48500, lr=6.42161e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=38713
2023-07-31 22:19:56 | INFO | train_inner | epoch 033:   1453 / 1474 loss=1.964, trans_loss=4.94, nll_loss=2.118, w2v_ctc_loss=0.604, task_loss=2.098, contrastive_loss=0.224, total=4125.28, n_correct=2724.61, ppl=4.34, accuracy=66.047, wps=12031.1, ups=1.46, wpb=8250.6, bsz=308.7, num_updates=48600, lr=6.415e-05, gnorm=0.598, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=38781
2023-07-31 22:20:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 22:20:34 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.214 | trans_loss 5.57 | nll_loss 2.843 | w2v_ctc_loss 1.382 | task_loss 6.904 | contrastive_loss 0.26 | total 4003.4 | n_correct 2488.9 | ppl 7.18 | accuracy 62.17 | uer 16.802 | wer 18.646 | raw_wer 18.646 | bleu 19.9 | wps 2027.2 | wpb 4003.4 | bsz 141.8 | num_updates 48621 | best_bleu 20.31
2023-07-31 22:20:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48621 updates
2023-07-31 22:20:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_last.pt
2023-07-31 22:20:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_last.pt
2023-07-31 22:20:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_last.pt (epoch 33 @ 48621 updates, score 19.9) (writing took 11.17414396442473 seconds)
2023-07-31 22:20:45 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-07-31 22:20:45 | INFO | train | epoch 033 | loss 1.954 | trans_loss 4.931 | nll_loss 2.105 | w2v_ctc_loss 0.604 | task_loss 2.1 | contrastive_loss 0.108 | total 4138.56 | n_correct 2739.22 | ppl 4.3 | accuracy 66.188 | wps 11178.9 | ups 1.35 | wpb 8277.1 | bsz 305.7 | num_updates 48621 | lr 6.41362e-05 | gnorm 0.59 | clip 0 | loss_scale 32 | train_wall 997 | gb_free 17.8 | wall 38831
2023-07-31 22:20:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-31 22:20:46 | INFO | fairseq.trainer | begin training epoch 34
2023-07-31 22:20:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-31 22:21:47 | INFO | train_inner | epoch 034:     79 / 1474 loss=1.943, trans_loss=4.911, nll_loss=2.079, w2v_ctc_loss=0.602, task_loss=2.076, contrastive_loss=0.06, total=4131.47, n_correct=2750.85, ppl=4.22, accuracy=66.583, wps=7424.2, ups=0.9, wpb=8262.9, bsz=301.7, num_updates=48700, lr=6.40841e-05, gnorm=0.589, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=38893
2023-07-31 22:22:55 | INFO | train_inner | epoch 034:    179 / 1474 loss=1.941, trans_loss=4.907, nll_loss=2.074, w2v_ctc_loss=0.597, task_loss=2.19, contrastive_loss=0.062, total=4065.88, n_correct=2710.07, ppl=4.21, accuracy=66.654, wps=11943.6, ups=1.47, wpb=8131.8, bsz=295.1, num_updates=48800, lr=6.40184e-05, gnorm=0.608, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=38961
2023-07-31 22:24:04 | INFO | train_inner | epoch 034:    279 / 1474 loss=1.96, trans_loss=4.925, nll_loss=2.098, w2v_ctc_loss=0.594, task_loss=1.964, contrastive_loss=0.273, total=4246.3, n_correct=2810.43, ppl=4.28, accuracy=66.185, wps=12299.9, ups=1.45, wpb=8492.6, bsz=328.7, num_updates=48900, lr=6.39529e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=69, gb_free=17.8, wall=39030
2023-07-31 22:25:12 | INFO | train_inner | epoch 034:    379 / 1474 loss=1.943, trans_loss=4.909, nll_loss=2.076, w2v_ctc_loss=0.59, task_loss=1.997, contrastive_loss=0.162, total=4156.17, n_correct=2768.33, ppl=4.22, accuracy=66.608, wps=12236.9, ups=1.47, wpb=8312.3, bsz=316.7, num_updates=49000, lr=6.38877e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=67, gb_free=17.7, wall=39098
2023-07-31 22:26:20 | INFO | train_inner | epoch 034:    479 / 1474 loss=1.954, trans_loss=4.926, nll_loss=2.097, w2v_ctc_loss=0.611, task_loss=2.305, contrastive_loss=0.054, total=4070.55, n_correct=2697.29, ppl=4.28, accuracy=66.264, wps=11971, ups=1.47, wpb=8141.1, bsz=284.6, num_updates=49100, lr=6.38226e-05, gnorm=0.599, clip=0, loss_scale=32, train_wall=68, gb_free=17.4, wall=39166
2023-07-31 22:27:28 | INFO | train_inner | epoch 034:    579 / 1474 loss=1.944, trans_loss=4.916, nll_loss=2.085, w2v_ctc_loss=0.599, task_loss=2.13, contrastive_loss=0.057, total=4119.38, n_correct=2740.99, ppl=4.24, accuracy=66.539, wps=12129.9, ups=1.47, wpb=8238.8, bsz=300.3, num_updates=49200, lr=6.37577e-05, gnorm=0.596, clip=0, loss_scale=32, train_wall=67, gb_free=13, wall=39234
2023-07-31 22:28:36 | INFO | train_inner | epoch 034:    679 / 1474 loss=1.942, trans_loss=4.918, nll_loss=2.089, w2v_ctc_loss=0.596, task_loss=2.127, contrastive_loss=0.051, total=4124.83, n_correct=2745.6, ppl=4.25, accuracy=66.563, wps=12160.8, ups=1.47, wpb=8249.7, bsz=300.2, num_updates=49300, lr=6.3693e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=67, gb_free=14.2, wall=39302
2023-07-31 22:29:43 | INFO | train_inner | epoch 034:    779 / 1474 loss=1.954, trans_loss=4.938, nll_loss=2.114, w2v_ctc_loss=0.59, task_loss=2.205, contrastive_loss=0.122, total=4082.07, n_correct=2702.43, ppl=4.33, accuracy=66.202, wps=12065.1, ups=1.48, wpb=8164.1, bsz=295, num_updates=49400, lr=6.36285e-05, gnorm=0.598, clip=0, loss_scale=32, train_wall=67, gb_free=15.5, wall=39369
2023-07-31 22:30:52 | INFO | train_inner | epoch 034:    879 / 1474 loss=1.954, trans_loss=4.932, nll_loss=2.106, w2v_ctc_loss=0.604, task_loss=2.215, contrastive_loss=0.082, total=4100.9, n_correct=2716.36, ppl=4.31, accuracy=66.238, wps=12013.8, ups=1.46, wpb=8201.8, bsz=296.6, num_updates=49500, lr=6.35642e-05, gnorm=0.61, clip=0, loss_scale=32, train_wall=68, gb_free=12.1, wall=39438
2023-07-31 22:32:00 | INFO | train_inner | epoch 034:    979 / 1474 loss=1.953, trans_loss=4.93, nll_loss=2.104, w2v_ctc_loss=0.609, task_loss=2.061, contrastive_loss=0.078, total=4168.39, n_correct=2758.68, ppl=4.3, accuracy=66.181, wps=12243.6, ups=1.47, wpb=8336.8, bsz=311.9, num_updates=49600, lr=6.35001e-05, gnorm=0.593, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=39506
2023-07-31 22:33:07 | INFO | train_inner | epoch 034:   1079 / 1474 loss=1.952, trans_loss=4.934, nll_loss=2.11, w2v_ctc_loss=0.609, task_loss=2.033, contrastive_loss=0.057, total=4150.57, n_correct=2748.66, ppl=4.32, accuracy=66.224, wps=12266.3, ups=1.48, wpb=8301.1, bsz=308.5, num_updates=49700, lr=6.34361e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=67, gb_free=16.8, wall=39573
2023-07-31 22:34:15 | INFO | train_inner | epoch 034:   1179 / 1474 loss=1.951, trans_loss=4.933, nll_loss=2.108, w2v_ctc_loss=0.601, task_loss=2.172, contrastive_loss=0.069, total=4098.77, n_correct=2714.87, ppl=4.31, accuracy=66.236, wps=12110.5, ups=1.48, wpb=8197.5, bsz=297.1, num_updates=49800, lr=6.33724e-05, gnorm=0.601, clip=0, loss_scale=32, train_wall=67, gb_free=16.9, wall=39641
2023-07-31 22:34:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-31 22:35:23 | INFO | train_inner | epoch 034:   1280 / 1474 loss=1.948, trans_loss=4.928, nll_loss=2.102, w2v_ctc_loss=0.6, task_loss=2.113, contrastive_loss=0.054, total=4146.32, n_correct=2747.77, ppl=4.29, accuracy=66.27, wps=12155.9, ups=1.47, wpb=8292.6, bsz=301.7, num_updates=49900, lr=6.33089e-05, gnorm=0.585, clip=0, loss_scale=16, train_wall=68, gb_free=17.3, wall=39709
2023-07-31 22:36:32 | INFO | train_inner | epoch 034:   1380 / 1474 loss=1.96, trans_loss=4.938, nll_loss=2.115, w2v_ctc_loss=0.614, task_loss=2.012, contrastive_loss=0.12, total=4197.99, n_correct=2772.05, ppl=4.33, accuracy=66.033, wps=12305.7, ups=1.47, wpb=8396, bsz=321.1, num_updates=50000, lr=6.32456e-05, gnorm=0.59, clip=0, loss_scale=16, train_wall=68, gb_free=17.2, wall=39777
2023-07-31 22:36:32 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-07-31 22:36:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-31 22:36:55 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.19 | trans_loss 5.569 | nll_loss 2.843 | w2v_ctc_loss 1.308 | task_loss 6.915 | contrastive_loss 0.25 | total 4003.4 | n_correct 2490.6 | ppl 7.18 | accuracy 62.212 | uer 16.487 | wer 18.288 | raw_wer 18.288 | bleu 20.05 | wps 2157.6 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.31
2023-07-31 22:36:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-07-31 22:36:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_34_50000.pt
2023-07-31 22:36:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_34_50000.pt
2023-07-31 22:37:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_1.0mt_1.5at/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 20.05) (writing took 16.91132028400898 seconds)
2023-07-31 22:37:13 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-07-31 22:37:13 | INFO | train | epoch 034 | loss 1.95 | trans_loss 4.924 | nll_loss 2.097 | w2v_ctc_loss 0.601 | task_loss 2.114 | contrastive_loss 0.095 | total 4132.81 | n_correct 2741.87 | ppl 4.28 | accuracy 66.344 | wps 11545.8 | ups 1.4 | wpb 8265.6 | bsz 304.3 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.593 | clip 0 | loss_scale 16 | train_wall 932 | gb_free 17.2 | wall 39818
2023-07-31 22:37:13 | INFO | fairseq_cli.train | done training in 39768.7 seconds
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    raise EOFError
EOFError
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
