2023-07-03 10:28:22 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:18117
2023-07-03 10:28:23 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:18117
2023-07-03 10:28:23 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:18117
2023-07-03 10:28:23 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:18117
2023-07-03 10:28:23 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:18117
2023-07-03 10:28:23 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:18117
2023-07-03 10:28:23 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:18117
2023-07-03 10:28:23 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:18117
2023-07-03 10:28:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-03 10:28:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-03 10:28:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-03 10:28:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-03 10:28:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-03 10:28:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-03 10:28:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-03 10:28:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-03 10:28:24 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 10:28:24 | INFO | fairseq.distributed.utils | initialized host capios as rank 5
2023-07-03 10:28:24 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 10:28:24 | INFO | fairseq.distributed.utils | initialized host capios as rank 7
2023-07-03 10:28:24 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 10:28:24 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 10:28:24 | INFO | fairseq.distributed.utils | initialized host capios as rank 6
2023-07-03 10:28:24 | INFO | fairseq.distributed.utils | initialized host capios as rank 1
2023-07-03 10:28:24 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 10:28:24 | INFO | fairseq.distributed.utils | initialized host capios as rank 4
2023-07-03 10:28:24 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 10:28:24 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 10:28:24 | INFO | fairseq.distributed.utils | initialized host capios as rank 2
2023-07-03 10:28:24 | INFO | fairseq.distributed.utils | initialized host capios as rank 3
2023-07-03 10:28:24 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-03 10:28:24 | INFO | fairseq.distributed.utils | initialized host capios as rank 0
2023-07-03 10:28:26 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_scale10_valloss', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18117', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_scale10_valloss', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-03 10:28:26 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-03 10:28:26 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-03 10:28:26 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-03 10:28:26 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-03 10:28:26 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-03 10:28:31 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-03 10:28:31 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-03 10:28:31 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-03 10:28:32 | INFO | root | load pretrained hubert
2023-07-03 10:28:33 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-03 10:28:36 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-03 10:28:36 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-03 10:28:36 | INFO | root | share the sematic adapter and textual encoder
2023-07-03 10:28:36 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-03 10:28:36 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-03 10:28:36 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-03 10:28:36 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-03 10:28:36 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-03 10:28:36 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-03 10:28:36 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-03 10:28:36 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 10:28:36 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 10:28:36 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 10:28:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-03 10:28:49 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-03 10:28:49 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-03 10:28:49 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-03 10:28:49 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 10:28:49 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 10:28:49 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 10:28:49 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 10:28:49 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 10:28:49 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 10:28:49 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 10:28:49 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-03 10:28:49 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-03 10:28:49 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-03 10:28:49 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-03 10:28:49 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_last.pt
2023-07-03 10:28:49 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_last.pt
2023-07-03 10:28:49 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-03 10:28:49 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-03 10:28:49 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 10:28:49 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-03 10:28:51 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 10:28:53 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 10:28:54 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-03 10:29:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 10:29:59 | INFO | fairseq.trainer | begin training epoch 1
2023-07-03 10:29:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 10:30:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-03 10:31:17 | INFO | train_inner | epoch 001:    101 / 1474 loss=12.74, trans_loss=5.64, nll_loss=4.216, w2v_ctc_loss=13.798, task_loss=0.704, contrastive_loss=3.311, total=4200.41, n_correct=212.2, ppl=18.59, accuracy=5.052, wps=18879, ups=1.5, wpb=12542.9, bsz=467.5, num_updates=100, lr=4.098e-06, gnorm=0.572, clip=0, loss_scale=64, train_wall=71, gb_free=19, wall=148
2023-07-03 10:32:22 | INFO | train_inner | epoch 001:    201 / 1474 loss=11.389, trans_loss=5.459, nll_loss=4.049, w2v_ctc_loss=11.876, task_loss=0.692, contrastive_loss=3.286, total=4127.38, n_correct=245.01, ppl=16.55, accuracy=5.936, wps=18968.3, ups=1.54, wpb=12327, bsz=463.1, num_updates=200, lr=8.096e-06, gnorm=2.223, clip=0, loss_scale=64, train_wall=65, gb_free=19.2, wall=213
2023-07-03 10:33:26 | INFO | train_inner | epoch 001:    301 / 1474 loss=7.127, trans_loss=5.414, nll_loss=4.051, w2v_ctc_loss=5.397, task_loss=0.716, contrastive_loss=3.201, total=4079.62, n_correct=244.51, ppl=16.58, accuracy=5.993, wps=19001.6, ups=1.56, wpb=12195.4, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=2.853, clip=0, loss_scale=64, train_wall=64, gb_free=19.9, wall=277
2023-07-03 10:34:31 | INFO | train_inner | epoch 001:    401 / 1474 loss=6.373, trans_loss=5.461, nll_loss=4.128, w2v_ctc_loss=4.19, task_loss=0.624, contrastive_loss=3.234, total=4174.14, n_correct=227.71, ppl=17.48, accuracy=5.455, wps=19304.3, ups=1.55, wpb=12461.1, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=1.846, clip=0, loss_scale=64, train_wall=64, gb_free=18.9, wall=342
2023-07-03 10:35:35 | INFO | train_inner | epoch 001:    501 / 1474 loss=6.104, trans_loss=5.459, nll_loss=4.134, w2v_ctc_loss=3.785, task_loss=0.545, contrastive_loss=3.228, total=4176.18, n_correct=214.86, ppl=17.56, accuracy=5.145, wps=19427.5, ups=1.55, wpb=12513, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=0.882, clip=0, loss_scale=64, train_wall=64, gb_free=19.2, wall=406
2023-07-03 10:36:40 | INFO | train_inner | epoch 001:    601 / 1474 loss=5.957, trans_loss=5.484, nll_loss=4.172, w2v_ctc_loss=3.57, task_loss=0.498, contrastive_loss=3.281, total=4147.79, n_correct=213.46, ppl=18.03, accuracy=5.146, wps=19150.8, ups=1.55, wpb=12368.1, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.452, clip=0, loss_scale=64, train_wall=64, gb_free=18.9, wall=471
2023-07-03 10:37:44 | INFO | train_inner | epoch 001:    701 / 1474 loss=5.857, trans_loss=5.477, nll_loss=4.171, w2v_ctc_loss=3.499, task_loss=0.516, contrastive_loss=3.03, total=4152.1, n_correct=225.8, ppl=18.01, accuracy=5.438, wps=19419, ups=1.57, wpb=12373.8, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=0.369, clip=0, loss_scale=64, train_wall=63, gb_free=19.5, wall=534
2023-07-03 10:38:48 | INFO | train_inner | epoch 001:    801 / 1474 loss=5.686, trans_loss=5.433, nll_loss=4.119, w2v_ctc_loss=3.356, task_loss=0.5, contrastive_loss=2.927, total=4123.83, n_correct=250.34, ppl=17.37, accuracy=6.071, wps=19277.9, ups=1.57, wpb=12311.9, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=0.511, clip=0, loss_scale=64, train_wall=63, gb_free=19.1, wall=598
2023-07-03 10:39:51 | INFO | train_inner | epoch 001:    901 / 1474 loss=5.532, trans_loss=5.41, nll_loss=4.107, w2v_ctc_loss=3.253, task_loss=0.509, contrastive_loss=2.673, total=4163.61, n_correct=276.43, ppl=17.23, accuracy=6.639, wps=19471.2, ups=1.57, wpb=12409.7, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=0.74, clip=0, loss_scale=64, train_wall=63, gb_free=18.8, wall=662
2023-07-03 10:40:56 | INFO | train_inner | epoch 001:   1001 / 1474 loss=5.37, trans_loss=5.392, nll_loss=4.087, w2v_ctc_loss=3.11, task_loss=0.509, contrastive_loss=2.533, total=4135.34, n_correct=297.49, ppl=17, accuracy=7.194, wps=19190.7, ups=1.55, wpb=12363.9, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=0.917, clip=0, loss_scale=64, train_wall=64, gb_free=19, wall=726
2023-07-03 10:42:00 | INFO | train_inner | epoch 001:   1101 / 1474 loss=5.21, trans_loss=5.382, nll_loss=4.08, w2v_ctc_loss=2.992, task_loss=0.516, contrastive_loss=2.314, total=4147.38, n_correct=313.64, ppl=16.91, accuracy=7.562, wps=19313.2, ups=1.56, wpb=12356.9, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=1.052, clip=0, loss_scale=64, train_wall=64, gb_free=18.8, wall=790
2023-07-03 10:43:04 | INFO | train_inner | epoch 001:   1201 / 1474 loss=5.062, trans_loss=5.362, nll_loss=4.059, w2v_ctc_loss=2.878, task_loss=0.537, contrastive_loss=2.1, total=4139.9, n_correct=327.33, ppl=16.66, accuracy=7.907, wps=19357.6, ups=1.56, wpb=12386.7, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=1.026, clip=0, loss_scale=64, train_wall=64, gb_free=18.9, wall=854
2023-07-03 10:44:07 | INFO | train_inner | epoch 001:   1301 / 1474 loss=4.934, trans_loss=5.362, nll_loss=4.062, w2v_ctc_loss=2.763, task_loss=0.518, contrastive_loss=1.922, total=4046.58, n_correct=321.03, ppl=16.71, accuracy=7.933, wps=19024.9, ups=1.57, wpb=12092.5, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=1.07, clip=0, loss_scale=64, train_wall=63, gb_free=19.7, wall=918
2023-07-03 10:45:12 | INFO | train_inner | epoch 001:   1401 / 1474 loss=4.836, trans_loss=5.359, nll_loss=4.07, w2v_ctc_loss=2.66, task_loss=0.513, contrastive_loss=2.008, total=4133.18, n_correct=329.5, ppl=16.8, accuracy=7.972, wps=19150.7, ups=1.56, wpb=12300.7, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=1.166, clip=0, loss_scale=64, train_wall=64, gb_free=19.9, wall=982
2023-07-03 10:45:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-07-03 10:46:33 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 4.962 | trans_loss 10.962 | nll_loss 9.951 | w2v_ctc_loss 2.898 | task_loss 2.365 | contrastive_loss 2.331 | total 4003.4 | n_correct 372.9 | ppl 989.89 | accuracy 9.315 | uer 71.415 | wer 69.423 | raw_wer 69.423 | bleu 0.02 | wps 1420.4 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-07-03 10:46:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-07-03 10:46:33 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 10:46:36 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 10:46:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.02) (writing took 4.670854167081416 seconds)
2023-07-03 10:46:38 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-07-03 10:46:38 | INFO | train | epoch 001 | loss 6.499 | trans_loss 5.432 | nll_loss 4.105 | w2v_ctc_loss 4.694 | task_loss 0.56 | contrastive_loss 2.748 | total 4138.32 | n_correct 267.995 | ppl 17.21 | accuracy 6.476 | wps 18432.5 | ups 1.49 | wpb 12354.6 | bsz 458.3 | num_updates 1473 | lr 5.89905e-05 | gnorm 1.112 | clip 0 | loss_scale 64 | train_wall 946 | gb_free 19.2 | wall 1069
2023-07-03 10:46:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 10:46:38 | INFO | fairseq.trainer | begin training epoch 2
2023-07-03 10:46:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 10:47:04 | INFO | train_inner | epoch 002:     27 / 1474 loss=4.706, trans_loss=5.353, nll_loss=4.052, w2v_ctc_loss=2.531, task_loss=0.488, contrastive_loss=1.841, total=4162.95, n_correct=340.14, ppl=16.59, accuracy=8.171, wps=11078.8, ups=0.89, wpb=12414, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=0.985, clip=0, loss_scale=64, train_wall=64, gb_free=19.6, wall=1094
2023-07-03 10:48:07 | INFO | train_inner | epoch 002:    127 / 1474 loss=4.606, trans_loss=5.354, nll_loss=4.054, w2v_ctc_loss=2.456, task_loss=0.521, contrastive_loss=1.64, total=4155.98, n_correct=338.48, ppl=16.61, accuracy=8.144, wps=19454.6, ups=1.57, wpb=12390, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=0.992, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=1158
2023-07-03 10:49:11 | INFO | train_inner | epoch 002:    227 / 1474 loss=4.508, trans_loss=5.325, nll_loss=4.022, w2v_ctc_loss=2.338, task_loss=0.452, contrastive_loss=1.67, total=4179.21, n_correct=349.01, ppl=16.24, accuracy=8.351, wps=19659.3, ups=1.57, wpb=12488.1, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=0.927, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=1222
2023-07-03 10:50:15 | INFO | train_inner | epoch 002:    327 / 1474 loss=4.402, trans_loss=5.328, nll_loss=4.021, w2v_ctc_loss=2.274, task_loss=0.519, contrastive_loss=1.382, total=4146.1, n_correct=349.85, ppl=16.23, accuracy=8.438, wps=19311.9, ups=1.56, wpb=12381, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=0.87, clip=0, loss_scale=64, train_wall=64, gb_free=18.8, wall=1286
2023-07-03 10:51:19 | INFO | train_inner | epoch 002:    427 / 1474 loss=4.316, trans_loss=5.316, nll_loss=4.011, w2v_ctc_loss=2.215, task_loss=0.567, contrastive_loss=1.204, total=4037.99, n_correct=343.48, ppl=16.12, accuracy=8.506, wps=18952.4, ups=1.57, wpb=12079.4, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=0.877, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=1349
2023-07-03 10:52:22 | INFO | train_inner | epoch 002:    527 / 1474 loss=4.262, trans_loss=5.314, nll_loss=4.003, w2v_ctc_loss=2.121, task_loss=0.495, contrastive_loss=1.31, total=4176.97, n_correct=361.93, ppl=16.03, accuracy=8.665, wps=19591.5, ups=1.57, wpb=12475.1, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=0.849, clip=0, loss_scale=64, train_wall=63, gb_free=19.6, wall=1413
2023-07-03 10:52:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 10:52:57 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 4.662 | trans_loss 10.826 | nll_loss 9.775 | w2v_ctc_loss 2.341 | task_loss 2.365 | contrastive_loss 1.655 | total 4003.4 | n_correct 393.2 | ppl 876.34 | accuracy 9.822 | uer 61.787 | wer 59.39 | raw_wer 59.39 | bleu 0.04 | wps 1437.4 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.04
2023-07-03 10:52:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-07-03 10:52:57 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_2_2000.pt
2023-07-03 10:52:59 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_2_2000.pt
2023-07-03 10:53:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.04) (writing took 9.127581172157079 seconds)
2023-07-03 10:54:10 | INFO | train_inner | epoch 002:    627 / 1474 loss=4.179, trans_loss=5.308, nll_loss=4, w2v_ctc_loss=2.059, task_loss=0.511, contrastive_loss=1.096, total=4126.49, n_correct=359.87, ppl=16, accuracy=8.721, wps=11423.2, ups=0.93, wpb=12299.1, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=0.705, clip=0, loss_scale=128, train_wall=64, gb_free=19.2, wall=1521
2023-07-03 10:55:14 | INFO | train_inner | epoch 002:    727 / 1474 loss=4.136, trans_loss=5.29, nll_loss=3.981, w2v_ctc_loss=2.005, task_loss=0.501, contrastive_loss=1.203, total=4149.06, n_correct=368.52, ppl=15.79, accuracy=8.882, wps=19409.8, ups=1.57, wpb=12372.9, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=0.717, clip=0, loss_scale=128, train_wall=63, gb_free=19.2, wall=1584
2023-07-03 10:56:18 | INFO | train_inner | epoch 002:    827 / 1474 loss=4.081, trans_loss=5.273, nll_loss=3.959, w2v_ctc_loss=1.961, task_loss=0.513, contrastive_loss=1.149, total=4175.4, n_correct=379.88, ppl=15.55, accuracy=9.098, wps=19556.9, ups=1.57, wpb=12477.6, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=0.626, clip=0, loss_scale=128, train_wall=63, gb_free=19.8, wall=1648
2023-07-03 10:57:21 | INFO | train_inner | epoch 002:    927 / 1474 loss=4.02, trans_loss=5.261, nll_loss=3.944, w2v_ctc_loss=1.902, task_loss=0.525, contrastive_loss=1.13, total=4104.2, n_correct=376.66, ppl=15.39, accuracy=9.177, wps=19198.7, ups=1.57, wpb=12243.8, bsz=445.9, num_updates=2400, lr=9.6052e-05, gnorm=0.618, clip=0, loss_scale=128, train_wall=63, gb_free=19, wall=1712
2023-07-03 10:58:25 | INFO | train_inner | epoch 002:   1027 / 1474 loss=3.97, trans_loss=5.257, nll_loss=3.938, w2v_ctc_loss=1.854, task_loss=0.511, contrastive_loss=0.987, total=4102.5, n_correct=378.13, ppl=15.33, accuracy=9.217, wps=19374.3, ups=1.58, wpb=12270.3, bsz=456.3, num_updates=2500, lr=0.00010005, gnorm=0.564, clip=0, loss_scale=128, train_wall=63, gb_free=19.2, wall=1775
2023-07-03 10:59:29 | INFO | train_inner | epoch 002:   1127 / 1474 loss=3.949, trans_loss=5.247, nll_loss=3.927, w2v_ctc_loss=1.808, task_loss=0.465, contrastive_loss=1.198, total=4187.61, n_correct=394.23, ppl=15.21, accuracy=9.414, wps=19448.7, ups=1.56, wpb=12484.3, bsz=487.1, num_updates=2600, lr=0.000104048, gnorm=0.514, clip=0, loss_scale=128, train_wall=64, gb_free=19.5, wall=1840
2023-07-03 11:00:33 | INFO | train_inner | epoch 002:   1227 / 1474 loss=3.917, trans_loss=5.24, nll_loss=3.918, w2v_ctc_loss=1.78, task_loss=0.466, contrastive_loss=1.12, total=4221.06, n_correct=406.04, ppl=15.11, accuracy=9.619, wps=19662.9, ups=1.56, wpb=12590.1, bsz=492.8, num_updates=2700, lr=0.000108046, gnorm=0.508, clip=0, loss_scale=128, train_wall=64, gb_free=19.4, wall=1904
2023-07-03 11:01:36 | INFO | train_inner | epoch 002:   1327 / 1474 loss=3.855, trans_loss=5.226, nll_loss=3.905, w2v_ctc_loss=1.755, task_loss=0.492, contrastive_loss=0.834, total=4157.86, n_correct=405.67, ppl=14.98, accuracy=9.757, wps=19664.3, ups=1.58, wpb=12422.5, bsz=460.7, num_updates=2800, lr=0.000112044, gnorm=0.485, clip=0, loss_scale=128, train_wall=63, gb_free=19.5, wall=1967
2023-07-03 11:02:41 | INFO | train_inner | epoch 002:   1427 / 1474 loss=3.828, trans_loss=5.225, nll_loss=3.899, w2v_ctc_loss=1.725, task_loss=0.55, contrastive_loss=0.92, total=4054.34, n_correct=395.63, ppl=14.92, accuracy=9.758, wps=18789.2, ups=1.55, wpb=12128.6, bsz=438.8, num_updates=2900, lr=0.000116042, gnorm=0.458, clip=0, loss_scale=128, train_wall=64, gb_free=19.4, wall=2031
2023-07-03 11:03:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 11:03:45 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 4.246 | trans_loss 10.28 | nll_loss 9.088 | w2v_ctc_loss 1.86 | task_loss 2.365 | contrastive_loss 0.986 | total 4003.4 | n_correct 500.2 | ppl 544.22 | accuracy 12.494 | uer 51.421 | wer 50.453 | raw_wer 50.453 | bleu 0.14 | wps 1420.2 | wpb 4003.4 | bsz 141.8 | num_updates 2947 | best_bleu 0.14
2023-07-03 11:03:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2947 updates
2023-07-03 11:03:45 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 11:03:49 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 11:03:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt (epoch 2 @ 2947 updates, score 0.14) (writing took 8.15642422856763 seconds)
2023-07-03 11:03:53 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-07-03 11:03:53 | INFO | train | epoch 002 | loss 4.144 | trans_loss 5.282 | nll_loss 3.969 | w2v_ctc_loss 2.017 | task_loss 0.505 | contrastive_loss 1.205 | total 4138.65 | n_correct 372.15 | ppl 15.66 | accuracy 8.992 | wps 17591.6 | ups 1.42 | wpb 12355.8 | bsz 458.5 | num_updates 2947 | lr 0.000117921 | gnorm 0.692 | clip 0 | loss_scale 128 | train_wall 935 | gb_free 19.3 | wall 2104
2023-07-03 11:03:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 11:03:54 | INFO | fairseq.trainer | begin training epoch 3
2023-07-03 11:03:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 11:04:35 | INFO | train_inner | epoch 003:     53 / 1474 loss=3.784, trans_loss=5.205, nll_loss=3.876, w2v_ctc_loss=1.694, task_loss=0.519, contrastive_loss=0.819, total=4071.2, n_correct=409.33, ppl=14.68, accuracy=10.054, wps=10583.6, ups=0.87, wpb=12148.3, bsz=442.6, num_updates=3000, lr=0.00012004, gnorm=0.439, clip=0, loss_scale=128, train_wall=63, gb_free=19.1, wall=2146
2023-07-03 11:04:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-03 11:04:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-03 11:04:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-03 11:04:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-03 11:04:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-07-03 11:05:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-07-03 11:06:10 | INFO | train_inner | epoch 003:    159 / 1474 loss=3.336, trans_loss=4.435, nll_loss=2.869, w2v_ctc_loss=1.521, task_loss=0.488, contrastive_loss=0.737, total=4153.02, n_correct=1096.85, ppl=7.3, accuracy=26.411, wps=13114.3, ups=1.06, wpb=12404.9, bsz=460.9, num_updates=3100, lr=0.000124038, gnorm=1.516, clip=0, loss_scale=2, train_wall=94, gb_free=16.6, wall=2241
2023-07-03 11:07:41 | INFO | train_inner | epoch 003:    259 / 1474 loss=3.109, trans_loss=4.161, nll_loss=2.511, w2v_ctc_loss=1.41, task_loss=0.502, contrastive_loss=0.653, total=4155.72, n_correct=1402.98, ppl=5.7, accuracy=33.76, wps=13675.8, ups=1.1, wpb=12432.8, bsz=465.5, num_updates=3200, lr=0.000128036, gnorm=1.306, clip=0, loss_scale=2, train_wall=90, gb_free=17.8, wall=2332
2023-07-03 11:09:11 | INFO | train_inner | epoch 003:    359 / 1474 loss=3.051, trans_loss=4.118, nll_loss=2.455, w2v_ctc_loss=1.359, task_loss=0.498, contrastive_loss=0.689, total=4154.07, n_correct=1473.54, ppl=5.48, accuracy=35.472, wps=13799.2, ups=1.11, wpb=12380.5, bsz=464.9, num_updates=3300, lr=0.000132034, gnorm=1.221, clip=0, loss_scale=2, train_wall=89, gb_free=16.5, wall=2421
2023-07-03 11:10:41 | INFO | train_inner | epoch 003:    459 / 1474 loss=2.959, trans_loss=4.058, nll_loss=2.377, w2v_ctc_loss=1.297, task_loss=0.491, contrastive_loss=0.523, total=4212.17, n_correct=1582.44, ppl=5.19, accuracy=37.568, wps=13835.8, ups=1.1, wpb=12542, bsz=473.8, num_updates=3400, lr=0.000136032, gnorm=0.917, clip=0, loss_scale=2, train_wall=90, gb_free=15.9, wall=2512
2023-07-03 11:12:11 | INFO | train_inner | epoch 003:    559 / 1474 loss=2.92, trans_loss=4.04, nll_loss=2.348, w2v_ctc_loss=1.261, task_loss=0.536, contrastive_loss=0.521, total=4081.04, n_correct=1560.37, ppl=5.09, accuracy=38.235, wps=13623.7, ups=1.12, wpb=12218.5, bsz=440.1, num_updates=3500, lr=0.00014003, gnorm=1.138, clip=0, loss_scale=2, train_wall=89, gb_free=16.6, wall=2602
2023-07-03 11:13:42 | INFO | train_inner | epoch 003:    659 / 1474 loss=2.901, trans_loss=4.011, nll_loss=2.313, w2v_ctc_loss=1.235, task_loss=0.477, contrastive_loss=0.624, total=4231.09, n_correct=1669.66, ppl=4.97, accuracy=39.462, wps=13757.4, ups=1.09, wpb=12584.4, bsz=484.4, num_updates=3600, lr=0.000144028, gnorm=1.117, clip=0, loss_scale=2, train_wall=91, gb_free=16.1, wall=2693
2023-07-03 11:15:13 | INFO | train_inner | epoch 003:    759 / 1474 loss=2.846, trans_loss=3.982, nll_loss=2.274, w2v_ctc_loss=1.207, task_loss=0.48, contrastive_loss=0.384, total=4160.74, n_correct=1678.18, ppl=4.84, accuracy=40.334, wps=13795.4, ups=1.11, wpb=12443, bsz=469.2, num_updates=3700, lr=0.000148026, gnorm=1.001, clip=0, loss_scale=2, train_wall=90, gb_free=16.9, wall=2783
2023-07-03 11:16:43 | INFO | train_inner | epoch 003:    859 / 1474 loss=2.813, trans_loss=3.966, nll_loss=2.252, w2v_ctc_loss=1.176, task_loss=0.508, contrastive_loss=0.356, total=4160.47, n_correct=1704.32, ppl=4.76, accuracy=40.965, wps=13777.9, ups=1.11, wpb=12433.7, bsz=455.4, num_updates=3800, lr=0.000152024, gnorm=0.872, clip=0, loss_scale=2, train_wall=90, gb_free=16.5, wall=2874
2023-07-03 11:18:14 | INFO | train_inner | epoch 003:    959 / 1474 loss=2.775, trans_loss=3.928, nll_loss=2.203, w2v_ctc_loss=1.146, task_loss=0.489, contrastive_loss=0.378, total=4162.26, n_correct=1769.13, ppl=4.6, accuracy=42.504, wps=13690.2, ups=1.1, wpb=12406.5, bsz=467.9, num_updates=3900, lr=0.000156022, gnorm=0.767, clip=0, loss_scale=2, train_wall=90, gb_free=17.9, wall=2964
2023-07-03 11:19:43 | INFO | train_inner | epoch 003:   1059 / 1474 loss=2.752, trans_loss=3.917, nll_loss=2.187, w2v_ctc_loss=1.134, task_loss=0.534, contrastive_loss=0.327, total=4062.67, n_correct=1749.35, ppl=4.55, accuracy=43.059, wps=13598.5, ups=1.12, wpb=12146.9, bsz=443.2, num_updates=4000, lr=0.00016002, gnorm=0.719, clip=0, loss_scale=2, train_wall=89, gb_free=15.9, wall=3054
2023-07-03 11:19:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 11:20:12 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 2.7 | trans_loss 6.608 | nll_loss 4.221 | w2v_ctc_loss 1.169 | task_loss 2.366 | contrastive_loss 0.447 | total 4003.4 | n_correct 1872.3 | ppl 18.65 | accuracy 46.768 | uer 32.862 | wer 33.205 | raw_wer 33.205 | bleu 8 | wps 1766.9 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 8
2023-07-03 11:20:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-07-03 11:20:12 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_3_4000.pt
2023-07-03 11:20:15 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_3_4000.pt
2023-07-03 11:20:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 8.0) (writing took 8.949917520862073 seconds)
2023-07-03 11:21:51 | INFO | train_inner | epoch 003:   1159 / 1474 loss=2.729, trans_loss=3.907, nll_loss=2.174, w2v_ctc_loss=1.109, task_loss=0.542, contrastive_loss=0.305, total=4046.76, n_correct=1757.22, ppl=4.51, accuracy=43.423, wps=9468.9, ups=0.78, wpb=12082.2, bsz=433.9, num_updates=4100, lr=0.000164018, gnorm=0.743, clip=0, loss_scale=2, train_wall=89, gb_free=16.4, wall=3181
2023-07-03 11:23:20 | INFO | train_inner | epoch 003:   1259 / 1474 loss=2.691, trans_loss=3.884, nll_loss=2.144, w2v_ctc_loss=1.074, task_loss=0.534, contrastive_loss=0.28, total=4064.26, n_correct=1808.2, ppl=4.42, accuracy=44.49, wps=13637.8, ups=1.12, wpb=12153.9, bsz=434, num_updates=4200, lr=0.000168016, gnorm=0.643, clip=0, loss_scale=2, train_wall=89, gb_free=16.8, wall=3270
2023-07-03 11:24:50 | INFO | train_inner | epoch 003:   1359 / 1474 loss=2.682, trans_loss=3.861, nll_loss=2.117, w2v_ctc_loss=1.059, task_loss=0.507, contrastive_loss=0.394, total=4137.36, n_correct=1863.17, ppl=4.34, accuracy=45.033, wps=13637.9, ups=1.11, wpb=12333.3, bsz=461.5, num_updates=4300, lr=0.000172014, gnorm=0.634, clip=0, loss_scale=2, train_wall=90, gb_free=16.4, wall=3361
2023-07-03 11:26:21 | INFO | train_inner | epoch 003:   1459 / 1474 loss=2.659, trans_loss=3.842, nll_loss=2.093, w2v_ctc_loss=1.039, task_loss=0.477, contrastive_loss=0.369, total=4207.75, n_correct=1927.58, ppl=4.27, accuracy=45.81, wps=13767.8, ups=1.1, wpb=12569.4, bsz=476.7, num_updates=4400, lr=0.000176012, gnorm=0.657, clip=0, loss_scale=2, train_wall=91, gb_free=17.5, wall=3452
2023-07-03 11:26:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 11:27:06 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 2.622 | trans_loss 6.512 | nll_loss 4.097 | w2v_ctc_loss 1.04 | task_loss 2.365 | contrastive_loss 0.398 | total 4003.4 | n_correct 1930.7 | ppl 17.12 | accuracy 48.227 | uer 30.438 | wer 30.748 | raw_wer 30.748 | bleu 8.86 | wps 1557 | wpb 4003.4 | bsz 141.8 | num_updates 4415 | best_bleu 8.86
2023-07-03 11:27:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4415 updates
2023-07-03 11:27:06 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 11:27:10 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 11:27:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt (epoch 3 @ 4415 updates, score 8.86) (writing took 7.977346586994827 seconds)
2023-07-03 11:27:14 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-07-03 11:27:14 | INFO | train | epoch 003 | loss 2.904 | trans_loss 4.05 | nll_loss 2.363 | w2v_ctc_loss 1.232 | task_loss 0.504 | contrastive_loss 0.483 | total 4140.16 | n_correct 1603.22 | ppl 5.14 | accuracy 38.724 | wps 12956.1 | ups 1.05 | wpb 12360.5 | bsz 459 | num_updates 4415 | lr 0.000176612 | gnorm 0.924 | clip 0 | loss_scale 2 | train_wall 1309 | gb_free 16.8 | wall 3505
2023-07-03 11:27:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 11:27:14 | INFO | fairseq.trainer | begin training epoch 4
2023-07-03 11:27:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 11:28:38 | INFO | train_inner | epoch 004:     85 / 1474 loss=2.612, trans_loss=3.819, nll_loss=2.062, w2v_ctc_loss=1.016, task_loss=0.526, contrastive_loss=0.226, total=4095.18, n_correct=1904.84, ppl=4.17, accuracy=46.514, wps=8924.8, ups=0.73, wpb=12200.5, bsz=437.8, num_updates=4500, lr=0.00018001, gnorm=0.623, clip=0, loss_scale=2, train_wall=89, gb_free=12.9, wall=3589
2023-07-03 11:30:07 | INFO | train_inner | epoch 004:    185 / 1474 loss=2.593, trans_loss=3.797, nll_loss=2.03, w2v_ctc_loss=0.995, task_loss=0.476, contrastive_loss=0.248, total=4178.83, n_correct=1977.67, ppl=4.09, accuracy=47.326, wps=13977.1, ups=1.12, wpb=12477.8, bsz=469.5, num_updates=4600, lr=0.000184008, gnorm=0.611, clip=0, loss_scale=2, train_wall=89, gb_free=14.9, wall=3678
2023-07-03 11:31:37 | INFO | train_inner | epoch 004:    285 / 1474 loss=2.606, trans_loss=3.797, nll_loss=2.034, w2v_ctc_loss=0.997, task_loss=0.509, contrastive_loss=0.375, total=4142.3, n_correct=1963.45, ppl=4.09, accuracy=47.4, wps=13762.4, ups=1.11, wpb=12378.5, bsz=460.7, num_updates=4700, lr=0.000188006, gnorm=0.621, clip=0, loss_scale=2, train_wall=90, gb_free=13.6, wall=3768
2023-07-03 11:33:07 | INFO | train_inner | epoch 004:    385 / 1474 loss=2.571, trans_loss=3.79, nll_loss=2.022, w2v_ctc_loss=0.972, task_loss=0.522, contrastive_loss=0.215, total=4124.92, n_correct=1973.65, ppl=4.06, accuracy=47.847, wps=13760, ups=1.12, wpb=12295.2, bsz=444.2, num_updates=4800, lr=0.000192004, gnorm=0.565, clip=0, loss_scale=2, train_wall=89, gb_free=12.7, wall=3857
2023-07-03 11:34:37 | INFO | train_inner | epoch 004:    485 / 1474 loss=2.592, trans_loss=3.772, nll_loss=2.002, w2v_ctc_loss=0.956, task_loss=0.457, contrastive_loss=0.618, total=4216.09, n_correct=2047.21, ppl=4.01, accuracy=48.557, wps=13887.7, ups=1.1, wpb=12570.9, bsz=497.6, num_updates=4900, lr=0.000196002, gnorm=0.583, clip=0, loss_scale=2, train_wall=90, gb_free=17, wall=3948
2023-07-03 11:36:08 | INFO | train_inner | epoch 004:    585 / 1474 loss=2.564, trans_loss=3.766, nll_loss=1.993, w2v_ctc_loss=0.964, task_loss=0.468, contrastive_loss=0.29, total=4231.12, n_correct=2064.37, ppl=3.98, accuracy=48.79, wps=13934.9, ups=1.1, wpb=12619.7, bsz=490.1, num_updates=5000, lr=0.0002, gnorm=0.572, clip=0, loss_scale=2, train_wall=90, gb_free=16.3, wall=4038
tensor(0.8537, device='cuda:0')
tensor(0.8091, device='cuda:0')
2023-07-03 11:37:40 | INFO | train_inner | epoch 004:    685 / 1474 loss=2.548, trans_loss=3.769, nll_loss=1.992, w2v_ctc_loss=0.942, task_loss=0.522, contrastive_loss=0.334, total=4176.95, n_correct=2046.79, ppl=3.98, accuracy=49.002, wps=13476.8, ups=1.08, wpb=12443.4, bsz=455.2, num_updates=5100, lr=0.00019803, gnorm=0.476, clip=0, loss_scale=2, train_wall=92, gb_free=15.3, wall=4131
2023-07-03 11:39:10 | INFO | train_inner | epoch 004:    785 / 1474 loss=2.532, trans_loss=3.76, nll_loss=1.981, w2v_ctc_loss=0.94, task_loss=0.559, contrastive_loss=0.2, total=4016.91, n_correct=1980.69, ppl=3.95, accuracy=49.309, wps=13391.8, ups=1.11, wpb=12019.7, bsz=418.7, num_updates=5200, lr=0.000196116, gnorm=0.467, clip=0, loss_scale=4, train_wall=89, gb_free=16.3, wall=4221
2023-07-03 11:40:40 | INFO | train_inner | epoch 004:    885 / 1474 loss=2.54, trans_loss=3.746, nll_loss=1.969, w2v_ctc_loss=0.934, task_loss=0.506, contrastive_loss=0.381, total=4183.4, n_correct=2077.95, ppl=3.91, accuracy=49.671, wps=13796.3, ups=1.1, wpb=12485.7, bsz=465.4, num_updates=5300, lr=0.000194257, gnorm=0.484, clip=0, loss_scale=4, train_wall=90, gb_free=15.6, wall=4311
2023-07-03 11:42:11 | INFO | train_inner | epoch 004:    985 / 1474 loss=2.513, trans_loss=3.736, nll_loss=1.956, w2v_ctc_loss=0.921, task_loss=0.511, contrastive_loss=0.243, total=4128.78, n_correct=2069.95, ppl=3.88, accuracy=50.135, wps=13625.5, ups=1.11, wpb=12330.5, bsz=456.8, num_updates=5400, lr=0.00019245, gnorm=0.475, clip=0, loss_scale=4, train_wall=90, gb_free=16.1, wall=4402
2023-07-03 11:43:41 | INFO | train_inner | epoch 004:   1085 / 1474 loss=2.516, trans_loss=3.741, nll_loss=1.96, w2v_ctc_loss=0.925, task_loss=0.541, contrastive_loss=0.22, total=4080.2, n_correct=2049.42, ppl=3.89, accuracy=50.228, wps=13471.2, ups=1.11, wpb=12181.6, bsz=437.7, num_updates=5500, lr=0.000190693, gnorm=0.505, clip=0, loss_scale=4, train_wall=90, gb_free=16.4, wall=4492
2023-07-03 11:45:11 | INFO | train_inner | epoch 004:   1185 / 1474 loss=2.516, trans_loss=3.731, nll_loss=1.947, w2v_ctc_loss=0.91, task_loss=0.471, contrastive_loss=0.335, total=4163.45, n_correct=2111.88, ppl=3.86, accuracy=50.724, wps=13858.1, ups=1.11, wpb=12456, bsz=485.6, num_updates=5600, lr=0.000188982, gnorm=0.469, clip=0, loss_scale=4, train_wall=89, gb_free=15.4, wall=4582
2023-07-03 11:46:41 | INFO | train_inner | epoch 004:   1285 / 1474 loss=2.501, trans_loss=3.72, nll_loss=1.934, w2v_ctc_loss=0.9, task_loss=0.485, contrastive_loss=0.289, total=4152.41, n_correct=2124.91, ppl=3.82, accuracy=51.173, wps=13794.5, ups=1.11, wpb=12415.7, bsz=471.4, num_updates=5700, lr=0.000187317, gnorm=0.461, clip=0, loss_scale=4, train_wall=90, gb_free=13.2, wall=4672
2023-07-03 11:48:11 | INFO | train_inner | epoch 004:   1385 / 1474 loss=2.479, trans_loss=3.717, nll_loss=1.93, w2v_ctc_loss=0.895, task_loss=0.519, contrastive_loss=0.168, total=4103.57, n_correct=2097.69, ppl=3.81, accuracy=51.119, wps=13721.5, ups=1.12, wpb=12259.3, bsz=437.9, num_updates=5800, lr=0.000185695, gnorm=0.434, clip=0, loss_scale=4, train_wall=89, gb_free=17, wall=4761
2023-07-03 11:49:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.8537, device='cuda:1')
tensor(0.8091, device='cuda:1')
tensor(0.8537, device='cuda:2')
tensor(0.8091, device='cuda:2')
tensor(0.8537, device='cuda:5')
tensor(0.8091, device='cuda:5')
tensor(0.8537, device='cuda:4')
tensor(0.8091, device='cuda:4')
tensor(0.8537, device='cuda:7')
tensor(0.8091, device='cuda:7')
tensor(0.8537, device='cuda:6')
tensor(0.8091, device='cuda:6')
tensor(0.8537, device='cuda:3')
tensor(0.8091, device='cuda:3')
2023-07-03 11:50:02 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 2.407 | trans_loss 6.078 | nll_loss 3.521 | w2v_ctc_loss 0.857 | task_loss 2.365 | contrastive_loss 0.304 | total 4003.4 | n_correct 2161.7 | ppl 11.48 | accuracy 53.997 | uer 24.652 | wer 26.14 | raw_wer 26.14 | bleu 14.13 | wps 1584.5 | wpb 4003.4 | bsz 141.8 | num_updates 5889 | best_bleu 14.13
2023-07-03 11:50:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5889 updates
2023-07-03 11:50:02 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 11:50:06 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 11:50:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt (epoch 4 @ 5889 updates, score 14.13) (writing took 8.257738907355815 seconds)
2023-07-03 11:50:10 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-07-03 11:50:10 | INFO | train | epoch 004 | loss 2.544 | trans_loss 3.758 | nll_loss 1.982 | w2v_ctc_loss 0.943 | task_loss 0.505 | contrastive_loss 0.294 | total 4138.65 | n_correct 2040.39 | ppl 3.95 | accuracy 49.301 | wps 13236.2 | ups 1.07 | wpb 12355.8 | bsz 458.5 | num_updates 5889 | lr 0.000184287 | gnorm 0.521 | clip 0 | loss_scale 4 | train_wall 1322 | gb_free 15 | wall 4881
2023-07-03 11:50:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 11:50:10 | INFO | fairseq.trainer | begin training epoch 5
2023-07-03 11:50:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 11:50:28 | INFO | train_inner | epoch 005:     11 / 1474 loss=2.47, trans_loss=3.71, nll_loss=1.92, w2v_ctc_loss=0.884, task_loss=0.53, contrastive_loss=0.187, total=4031.51, n_correct=2081.72, ppl=3.78, accuracy=51.636, wps=8783.3, ups=0.73, wpb=12046.1, bsz=436.7, num_updates=5900, lr=0.000184115, gnorm=0.459, clip=0, loss_scale=4, train_wall=89, gb_free=14.5, wall=4898
2023-07-03 11:51:58 | INFO | train_inner | epoch 005:    111 / 1474 loss=2.414, trans_loss=3.655, nll_loss=1.85, w2v_ctc_loss=0.832, task_loss=0.45, contrastive_loss=0.208, total=4256.63, n_correct=2261.37, ppl=3.6, accuracy=53.126, wps=14049, ups=1.11, wpb=12709.8, bsz=500.1, num_updates=6000, lr=0.000182574, gnorm=0.411, clip=0, loss_scale=4, train_wall=90, gb_free=16.4, wall=4989
2023-07-03 11:51:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 11:52:30 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 2.41 | trans_loss 6.094 | nll_loss 3.536 | w2v_ctc_loss 0.85 | task_loss 2.365 | contrastive_loss 0.31 | total 4003.4 | n_correct 2156.3 | ppl 11.6 | accuracy 53.862 | uer 24.633 | wer 26.315 | raw_wer 26.315 | bleu 12.92 | wps 1561.8 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 14.13
2023-07-03 11:52:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-07-03 11:52:30 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_5_6000.pt
2023-07-03 11:52:32 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_5_6000.pt
2023-07-03 11:52:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 12.92) (writing took 6.1212663277983665 seconds)
2023-07-03 11:54:06 | INFO | train_inner | epoch 005:    211 / 1474 loss=2.436, trans_loss=3.663, nll_loss=1.858, w2v_ctc_loss=0.84, task_loss=0.47, contrastive_loss=0.407, total=4186.83, n_correct=2213.75, ppl=3.63, accuracy=52.874, wps=9798.8, ups=0.78, wpb=12486.7, bsz=485.3, num_updates=6100, lr=0.000181071, gnorm=0.419, clip=0, loss_scale=4, train_wall=89, gb_free=16.2, wall=5116
2023-07-03 11:55:35 | INFO | train_inner | epoch 005:    311 / 1474 loss=2.435, trans_loss=3.663, nll_loss=1.862, w2v_ctc_loss=0.855, task_loss=0.515, contrastive_loss=0.272, total=4094.07, n_correct=2157.83, ppl=3.64, accuracy=52.706, wps=13734.3, ups=1.12, wpb=12252.3, bsz=446, num_updates=6200, lr=0.000179605, gnorm=0.44, clip=0, loss_scale=4, train_wall=89, gb_free=16.3, wall=5206
2023-07-03 11:57:05 | INFO | train_inner | epoch 005:    411 / 1474 loss=2.421, trans_loss=3.653, nll_loss=1.852, w2v_ctc_loss=0.825, task_loss=0.494, contrastive_loss=0.35, total=4140.39, n_correct=2205.28, ppl=3.61, accuracy=53.263, wps=13663.8, ups=1.11, wpb=12357.1, bsz=467.9, num_updates=6300, lr=0.000178174, gnorm=0.413, clip=0, loss_scale=4, train_wall=90, gb_free=16.2, wall=5296
2023-07-03 11:58:35 | INFO | train_inner | epoch 005:    511 / 1474 loss=2.406, trans_loss=3.665, nll_loss=1.861, w2v_ctc_loss=0.829, task_loss=0.563, contrastive_loss=0.14, total=4026.21, n_correct=2133.75, ppl=3.63, accuracy=52.996, wps=13450.3, ups=1.12, wpb=12048.3, bsz=418.1, num_updates=6400, lr=0.000176777, gnorm=0.403, clip=0, loss_scale=4, train_wall=89, gb_free=17.1, wall=5386
2023-07-03 12:00:05 | INFO | train_inner | epoch 005:    611 / 1474 loss=2.41, trans_loss=3.658, nll_loss=1.852, w2v_ctc_loss=0.819, task_loss=0.524, contrastive_loss=0.308, total=4109.94, n_correct=2188.28, ppl=3.61, accuracy=53.244, wps=13523.5, ups=1.1, wpb=12248.6, bsz=449.8, num_updates=6500, lr=0.000175412, gnorm=0.408, clip=0, loss_scale=4, train_wall=90, gb_free=15.6, wall=5476
2023-07-03 12:01:35 | INFO | train_inner | epoch 005:    711 / 1474 loss=2.413, trans_loss=3.649, nll_loss=1.844, w2v_ctc_loss=0.824, task_loss=0.475, contrastive_loss=0.287, total=4176.83, n_correct=2238.11, ppl=3.59, accuracy=53.584, wps=13845.9, ups=1.11, wpb=12457.5, bsz=483.6, num_updates=6600, lr=0.000174078, gnorm=0.409, clip=0, loss_scale=4, train_wall=90, gb_free=17.1, wall=5566
2023-07-03 12:03:06 | INFO | train_inner | epoch 005:    811 / 1474 loss=2.401, trans_loss=3.653, nll_loss=1.847, w2v_ctc_loss=0.816, task_loss=0.524, contrastive_loss=0.214, total=4127.9, n_correct=2214.4, ppl=3.6, accuracy=53.645, wps=13560.6, ups=1.1, wpb=12323.4, bsz=447.5, num_updates=6700, lr=0.000172774, gnorm=0.397, clip=0, loss_scale=4, train_wall=90, gb_free=15.9, wall=5657
2023-07-03 12:04:36 | INFO | train_inner | epoch 005:    911 / 1474 loss=2.39, trans_loss=3.648, nll_loss=1.842, w2v_ctc_loss=0.811, task_loss=0.52, contrastive_loss=0.178, total=4101.19, n_correct=2207.35, ppl=3.58, accuracy=53.822, wps=13644.4, ups=1.11, wpb=12253.6, bsz=447.9, num_updates=6800, lr=0.000171499, gnorm=0.418, clip=0, loss_scale=4, train_wall=89, gb_free=17.3, wall=5747
2023-07-03 12:06:06 | INFO | train_inner | epoch 005:   1011 / 1474 loss=2.398, trans_loss=3.648, nll_loss=1.842, w2v_ctc_loss=0.812, task_loss=0.502, contrastive_loss=0.254, total=4164.27, n_correct=2247.42, ppl=3.59, accuracy=53.969, wps=13857.2, ups=1.12, wpb=12422.1, bsz=462, num_updates=6900, lr=0.000170251, gnorm=0.395, clip=0, loss_scale=4, train_wall=89, gb_free=15.2, wall=5836
2023-07-03 12:07:37 | INFO | train_inner | epoch 005:   1111 / 1474 loss=2.401, trans_loss=3.647, nll_loss=1.838, w2v_ctc_loss=0.811, task_loss=0.505, contrastive_loss=0.257, total=4168.94, n_correct=2258.11, ppl=3.58, accuracy=54.165, wps=13690.2, ups=1.1, wpb=12445, bsz=464.1, num_updates=7000, lr=0.000169031, gnorm=0.409, clip=0, loss_scale=4, train_wall=90, gb_free=16.8, wall=5927
2023-07-03 12:09:07 | INFO | train_inner | epoch 005:   1211 / 1474 loss=2.379, trans_loss=3.644, nll_loss=1.836, w2v_ctc_loss=0.799, task_loss=0.512, contrastive_loss=0.161, total=4171.16, n_correct=2262.25, ppl=3.57, accuracy=54.236, wps=13741.3, ups=1.1, wpb=12438.5, bsz=456.3, num_updates=7100, lr=0.000167836, gnorm=0.399, clip=0, loss_scale=4, train_wall=90, gb_free=16, wall=6018
2023-07-03 12:10:38 | INFO | train_inner | epoch 005:   1311 / 1474 loss=2.368, trans_loss=3.64, nll_loss=1.829, w2v_ctc_loss=0.789, task_loss=0.516, contrastive_loss=0.128, total=4126.97, n_correct=2242.48, ppl=3.55, accuracy=54.337, wps=13625.8, ups=1.1, wpb=12334.6, bsz=443.4, num_updates=7200, lr=0.000166667, gnorm=0.393, clip=0, loss_scale=8, train_wall=90, gb_free=15.7, wall=6108
2023-07-03 12:12:08 | INFO | train_inner | epoch 005:   1411 / 1474 loss=2.373, trans_loss=3.632, nll_loss=1.825, w2v_ctc_loss=0.793, task_loss=0.505, contrastive_loss=0.194, total=4138.54, n_correct=2251.48, ppl=3.54, accuracy=54.403, wps=13730, ups=1.11, wpb=12347.9, bsz=459, num_updates=7300, lr=0.000165521, gnorm=0.398, clip=0, loss_scale=8, train_wall=89, gb_free=16.9, wall=6198
2023-07-03 12:13:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 12:13:36 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 2.321 | trans_loss 5.927 | nll_loss 3.316 | w2v_ctc_loss 0.751 | task_loss 2.365 | contrastive_loss 0.296 | total 4003.4 | n_correct 2263.1 | ppl 9.96 | accuracy 56.529 | uer 22.624 | wer 24.175 | raw_wer 24.175 | bleu 15.05 | wps 1617.4 | wpb 4003.4 | bsz 141.8 | num_updates 7363 | best_bleu 15.05
2023-07-03 12:13:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7363 updates
2023-07-03 12:13:36 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 12:13:40 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 12:13:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt (epoch 5 @ 7363 updates, score 15.05) (writing took 8.665368542075157 seconds)
2023-07-03 12:13:45 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-07-03 12:13:45 | INFO | train | epoch 005 | loss 2.402 | trans_loss 3.65 | nll_loss 1.844 | w2v_ctc_loss 0.818 | task_loss 0.505 | contrastive_loss 0.24 | total 4138.65 | n_correct 2219.91 | ppl 3.59 | accuracy 53.638 | wps 12874.1 | ups 1.04 | wpb 12355.8 | bsz 458.5 | num_updates 7363 | lr 0.000164812 | gnorm 0.408 | clip 0 | loss_scale 8 | train_wall 1322 | gb_free 16.4 | wall 6295
2023-07-03 12:13:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 12:13:45 | INFO | fairseq.trainer | begin training epoch 6
2023-07-03 12:13:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 12:14:26 | INFO | train_inner | epoch 006:     37 / 1474 loss=2.358, trans_loss=3.616, nll_loss=1.8, w2v_ctc_loss=0.78, task_loss=0.518, contrastive_loss=0.189, total=4113.87, n_correct=2267.84, ppl=3.48, accuracy=55.127, wps=8858.8, ups=0.72, wpb=12273.6, bsz=447.4, num_updates=7400, lr=0.000164399, gnorm=0.404, clip=0, loss_scale=8, train_wall=90, gb_free=17.9, wall=6337
2023-07-03 12:15:56 | INFO | train_inner | epoch 006:    137 / 1474 loss=2.323, trans_loss=3.589, nll_loss=1.765, w2v_ctc_loss=0.745, task_loss=0.5, contrastive_loss=0.234, total=4161.2, n_correct=2319.74, ppl=3.4, accuracy=55.747, wps=13807.3, ups=1.11, wpb=12431.6, bsz=458.1, num_updates=7500, lr=0.000163299, gnorm=0.388, clip=0, loss_scale=8, train_wall=90, gb_free=17, wall=6427
2023-07-03 12:17:26 | INFO | train_inner | epoch 006:    237 / 1474 loss=2.334, trans_loss=3.598, nll_loss=1.779, w2v_ctc_loss=0.771, task_loss=0.542, contrastive_loss=0.141, total=4110.12, n_correct=2270.69, ppl=3.43, accuracy=55.246, wps=13660.5, ups=1.11, wpb=12274.1, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.404, clip=0, loss_scale=8, train_wall=89, gb_free=17.2, wall=6517
2023-07-03 12:18:58 | INFO | train_inner | epoch 006:    337 / 1474 loss=2.345, trans_loss=3.589, nll_loss=1.768, w2v_ctc_loss=0.745, task_loss=0.473, contrastive_loss=0.446, total=4170.52, n_correct=2329.23, ppl=3.41, accuracy=55.85, wps=13569.3, ups=1.09, wpb=12444.2, bsz=488.4, num_updates=7700, lr=0.000161165, gnorm=0.398, clip=0, loss_scale=8, train_wall=91, gb_free=15.8, wall=6609
2023-07-03 12:20:28 | INFO | train_inner | epoch 006:    437 / 1474 loss=2.318, trans_loss=3.59, nll_loss=1.769, w2v_ctc_loss=0.746, task_loss=0.485, contrastive_loss=0.156, total=4154.89, n_correct=2323.01, ppl=3.41, accuracy=55.91, wps=13830.5, ups=1.11, wpb=12406.7, bsz=470.4, num_updates=7800, lr=0.000160128, gnorm=0.393, clip=0, loss_scale=8, train_wall=89, gb_free=16.6, wall=6698
2023-07-03 12:21:58 | INFO | train_inner | epoch 006:    537 / 1474 loss=2.32, trans_loss=3.59, nll_loss=1.769, w2v_ctc_loss=0.751, task_loss=0.503, contrastive_loss=0.143, total=4174.46, n_correct=2333.51, ppl=3.41, accuracy=55.9, wps=13744.9, ups=1.1, wpb=12441.4, bsz=458.3, num_updates=7900, lr=0.000159111, gnorm=0.388, clip=0, loss_scale=8, train_wall=90, gb_free=17.3, wall=6789
2023-07-03 12:23:28 | INFO | train_inner | epoch 006:    637 / 1474 loss=2.319, trans_loss=3.594, nll_loss=1.77, w2v_ctc_loss=0.74, task_loss=0.48, contrastive_loss=0.201, total=4145.19, n_correct=2317.42, ppl=3.41, accuracy=55.906, wps=13831.7, ups=1.12, wpb=12391.8, bsz=470.9, num_updates=8000, lr=0.000158114, gnorm=0.388, clip=0, loss_scale=8, train_wall=89, gb_free=16, wall=6878
2023-07-03 12:23:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 12:23:57 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 2.304 | trans_loss 5.875 | nll_loss 3.249 | w2v_ctc_loss 0.756 | task_loss 2.365 | contrastive_loss 0.288 | total 4003.4 | n_correct 2275.8 | ppl 9.51 | accuracy 56.847 | uer 22.018 | wer 23.679 | raw_wer 23.679 | bleu 15.49 | wps 1774.4 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 15.49
2023-07-03 12:23:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-07-03 12:23:57 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_6_8000.pt
2023-07-03 12:24:00 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_6_8000.pt
2023-07-03 12:24:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 15.49) (writing took 9.194458968006074 seconds)
2023-07-03 12:25:37 | INFO | train_inner | epoch 006:    737 / 1474 loss=2.325, trans_loss=3.595, nll_loss=1.775, w2v_ctc_loss=0.754, task_loss=0.512, contrastive_loss=0.153, total=4151.01, n_correct=2322.92, ppl=3.42, accuracy=55.96, wps=9564.5, ups=0.77, wpb=12384.3, bsz=454.2, num_updates=8100, lr=0.000157135, gnorm=0.39, clip=0, loss_scale=8, train_wall=90, gb_free=13.2, wall=7008
2023-07-03 12:27:08 | INFO | train_inner | epoch 006:    837 / 1474 loss=2.318, trans_loss=3.6, nll_loss=1.779, w2v_ctc_loss=0.745, task_loss=0.534, contrastive_loss=0.135, total=4108.83, n_correct=2287.2, ppl=3.43, accuracy=55.665, wps=13568.8, ups=1.11, wpb=12275.7, bsz=439.4, num_updates=8200, lr=0.000156174, gnorm=0.391, clip=0, loss_scale=8, train_wall=90, gb_free=17.2, wall=7098
2023-07-03 12:28:38 | INFO | train_inner | epoch 006:    937 / 1474 loss=2.33, trans_loss=3.598, nll_loss=1.779, w2v_ctc_loss=0.751, task_loss=0.53, contrastive_loss=0.233, total=4076.46, n_correct=2270.9, ppl=3.43, accuracy=55.708, wps=13499.2, ups=1.11, wpb=12153.2, bsz=443, num_updates=8300, lr=0.00015523, gnorm=0.394, clip=0, loss_scale=8, train_wall=90, gb_free=12.9, wall=7188
2023-07-03 12:30:07 | INFO | train_inner | epoch 006:   1037 / 1474 loss=2.328, trans_loss=3.589, nll_loss=1.768, w2v_ctc_loss=0.739, task_loss=0.475, contrastive_loss=0.309, total=4175.9, n_correct=2345.05, ppl=3.41, accuracy=56.157, wps=13882.9, ups=1.11, wpb=12465.4, bsz=480.4, num_updates=8400, lr=0.000154303, gnorm=0.399, clip=0, loss_scale=8, train_wall=89, gb_free=14.4, wall=7278
2023-07-03 12:31:37 | INFO | train_inner | epoch 006:   1137 / 1474 loss=2.314, trans_loss=3.594, nll_loss=1.773, w2v_ctc_loss=0.741, task_loss=0.557, contrastive_loss=0.14, total=4077.2, n_correct=2283.82, ppl=3.42, accuracy=56.014, wps=13585.3, ups=1.12, wpb=12179.9, bsz=430.6, num_updates=8500, lr=0.000153393, gnorm=0.387, clip=0, loss_scale=8, train_wall=89, gb_free=16.4, wall=7368
2023-07-03 12:33:09 | INFO | train_inner | epoch 006:   1237 / 1474 loss=2.333, trans_loss=3.586, nll_loss=1.764, w2v_ctc_loss=0.732, task_loss=0.495, contrastive_loss=0.454, total=4133.46, n_correct=2323.92, ppl=3.4, accuracy=56.222, wps=13523.2, ups=1.09, wpb=12360.6, bsz=470.3, num_updates=8600, lr=0.000152499, gnorm=0.386, clip=0, loss_scale=8, train_wall=91, gb_free=12.6, wall=7459
2023-07-03 12:34:39 | INFO | train_inner | epoch 006:   1337 / 1474 loss=2.306, trans_loss=3.594, nll_loss=1.77, w2v_ctc_loss=0.731, task_loss=0.502, contrastive_loss=0.121, total=4127.77, n_correct=2328.84, ppl=3.41, accuracy=56.419, wps=13685.9, ups=1.11, wpb=12325.7, bsz=454.1, num_updates=8700, lr=0.00015162, gnorm=0.383, clip=0, loss_scale=8, train_wall=90, gb_free=17.1, wall=7549
2023-07-03 12:36:09 | INFO | train_inner | epoch 006:   1437 / 1474 loss=2.303, trans_loss=3.581, nll_loss=1.759, w2v_ctc_loss=0.734, task_loss=0.505, contrastive_loss=0.132, total=4190.32, n_correct=2373.45, ppl=3.38, accuracy=56.641, wps=13836.9, ups=1.11, wpb=12495.5, bsz=460.5, num_updates=8800, lr=0.000150756, gnorm=0.388, clip=0, loss_scale=8, train_wall=90, gb_free=17, wall=7640
2023-07-03 12:36:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 12:37:12 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 2.261 | trans_loss 5.801 | nll_loss 3.14 | w2v_ctc_loss 0.704 | task_loss 2.365 | contrastive_loss 0.279 | total 4003.4 | n_correct 2329.2 | ppl 8.81 | accuracy 58.181 | uer 20.02 | wer 21.714 | raw_wer 21.714 | bleu 16.73 | wps 1697.6 | wpb 4003.4 | bsz 141.8 | num_updates 8837 | best_bleu 16.73
2023-07-03 12:37:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8837 updates
2023-07-03 12:37:12 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 12:37:16 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 12:37:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt (epoch 6 @ 8837 updates, score 16.73) (writing took 8.792594755999744 seconds)
2023-07-03 12:37:21 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-07-03 12:37:21 | INFO | train | epoch 006 | loss 2.322 | trans_loss 3.591 | nll_loss 1.77 | w2v_ctc_loss 0.744 | task_loss 0.505 | contrastive_loss 0.213 | total 4138.65 | n_correct 2316.55 | ppl 3.41 | accuracy 55.974 | wps 12860.4 | ups 1.04 | wpb 12355.8 | bsz 458.5 | num_updates 8837 | lr 0.00015044 | gnorm 0.391 | clip 0 | loss_scale 8 | train_wall 1323 | gb_free 15.3 | wall 7711
2023-07-03 12:37:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 12:37:21 | INFO | fairseq.trainer | begin training epoch 7
2023-07-03 12:37:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 12:38:26 | INFO | train_inner | epoch 007:     63 / 1474 loss=2.277, trans_loss=3.558, nll_loss=1.727, w2v_ctc_loss=0.709, task_loss=0.491, contrastive_loss=0.146, total=4110.43, n_correct=2346.45, ppl=3.31, accuracy=57.085, wps=8956.2, ups=0.73, wpb=12276.6, bsz=462.8, num_updates=8900, lr=0.000149906, gnorm=0.383, clip=0, loss_scale=8, train_wall=89, gb_free=17.5, wall=7777
2023-07-03 12:39:56 | INFO | train_inner | epoch 007:    163 / 1474 loss=2.272, trans_loss=3.553, nll_loss=1.721, w2v_ctc_loss=0.699, task_loss=0.512, contrastive_loss=0.219, total=4109.53, n_correct=2352.24, ppl=3.3, accuracy=57.239, wps=13697, ups=1.12, wpb=12264.3, bsz=454.1, num_updates=9000, lr=0.000149071, gnorm=0.389, clip=0, loss_scale=8, train_wall=89, gb_free=13.9, wall=7866
2023-07-03 12:41:25 | INFO | train_inner | epoch 007:    263 / 1474 loss=2.264, trans_loss=3.548, nll_loss=1.712, w2v_ctc_loss=0.701, task_loss=0.505, contrastive_loss=0.127, total=4133.29, n_correct=2374.02, ppl=3.28, accuracy=57.437, wps=13772.6, ups=1.12, wpb=12339.3, bsz=455.5, num_updates=9100, lr=0.00014825, gnorm=0.38, clip=0, loss_scale=8, train_wall=89, gb_free=15.5, wall=7956
2023-07-03 12:42:56 | INFO | train_inner | epoch 007:    363 / 1474 loss=2.283, trans_loss=3.553, nll_loss=1.721, w2v_ctc_loss=0.695, task_loss=0.49, contrastive_loss=0.388, total=4194.76, n_correct=2400.39, ppl=3.3, accuracy=57.224, wps=13797.5, ups=1.1, wpb=12509.7, bsz=477.6, num_updates=9200, lr=0.000147442, gnorm=0.381, clip=0, loss_scale=8, train_wall=90, gb_free=13.3, wall=8047
2023-07-03 12:44:26 | INFO | train_inner | epoch 007:    463 / 1474 loss=2.281, trans_loss=3.552, nll_loss=1.724, w2v_ctc_loss=0.7, task_loss=0.5, contrastive_loss=0.316, total=4153.22, n_correct=2374.25, ppl=3.3, accuracy=57.166, wps=13708.2, ups=1.11, wpb=12386.6, bsz=463, num_updates=9300, lr=0.000146647, gnorm=0.388, clip=0, loss_scale=16, train_wall=90, gb_free=16.9, wall=8137
2023-07-03 12:45:56 | INFO | train_inner | epoch 007:    563 / 1474 loss=2.265, trans_loss=3.553, nll_loss=1.721, w2v_ctc_loss=0.7, task_loss=0.492, contrastive_loss=0.133, total=4168.14, n_correct=2397.26, ppl=3.3, accuracy=57.514, wps=13770.2, ups=1.11, wpb=12410.5, bsz=459.8, num_updates=9400, lr=0.000145865, gnorm=0.378, clip=0, loss_scale=16, train_wall=90, gb_free=17, wall=8227
2023-07-03 12:47:27 | INFO | train_inner | epoch 007:    663 / 1474 loss=2.26, trans_loss=3.555, nll_loss=1.721, w2v_ctc_loss=0.69, task_loss=0.503, contrastive_loss=0.122, total=4157.82, n_correct=2391.27, ppl=3.3, accuracy=57.513, wps=13738, ups=1.11, wpb=12417.8, bsz=455.4, num_updates=9500, lr=0.000145095, gnorm=0.377, clip=0, loss_scale=16, train_wall=90, gb_free=15.8, wall=8317
2023-07-03 12:48:57 | INFO | train_inner | epoch 007:    763 / 1474 loss=2.265, trans_loss=3.555, nll_loss=1.723, w2v_ctc_loss=0.697, task_loss=0.53, contrastive_loss=0.118, total=4122.1, n_correct=2367.02, ppl=3.3, accuracy=57.423, wps=13593.4, ups=1.1, wpb=12321.9, bsz=446.2, num_updates=9600, lr=0.000144338, gnorm=0.379, clip=0, loss_scale=16, train_wall=90, gb_free=15.8, wall=8408
2023-07-03 12:50:28 | INFO | train_inner | epoch 007:    863 / 1474 loss=2.263, trans_loss=3.553, nll_loss=1.72, w2v_ctc_loss=0.693, task_loss=0.511, contrastive_loss=0.137, total=4147.23, n_correct=2382.98, ppl=3.29, accuracy=57.46, wps=13704.6, ups=1.11, wpb=12392, bsz=460.9, num_updates=9700, lr=0.000143592, gnorm=0.381, clip=0, loss_scale=16, train_wall=90, gb_free=17.6, wall=8498
2023-07-03 12:51:58 | INFO | train_inner | epoch 007:    963 / 1474 loss=2.271, trans_loss=3.551, nll_loss=1.719, w2v_ctc_loss=0.69, task_loss=0.481, contrastive_loss=0.234, total=4140.14, n_correct=2387.74, ppl=3.29, accuracy=57.673, wps=13685.5, ups=1.11, wpb=12360, bsz=474.6, num_updates=9800, lr=0.000142857, gnorm=0.385, clip=0, loss_scale=16, train_wall=90, gb_free=16.1, wall=8589
2023-07-03 12:53:29 | INFO | train_inner | epoch 007:   1063 / 1474 loss=2.262, trans_loss=3.56, nll_loss=1.73, w2v_ctc_loss=0.695, task_loss=0.529, contrastive_loss=0.102, total=4103.51, n_correct=2355.32, ppl=3.32, accuracy=57.398, wps=13556.8, ups=1.11, wpb=12263.4, bsz=437.5, num_updates=9900, lr=0.000142134, gnorm=0.381, clip=0, loss_scale=16, train_wall=90, gb_free=17, wall=8679
2023-07-03 12:54:59 | INFO | train_inner | epoch 007:   1163 / 1474 loss=2.282, trans_loss=3.549, nll_loss=1.722, w2v_ctc_loss=0.692, task_loss=0.487, contrastive_loss=0.365, total=4137.04, n_correct=2380.17, ppl=3.3, accuracy=57.533, wps=13609.9, ups=1.1, wpb=12348.6, bsz=470.9, num_updates=10000, lr=0.000141421, gnorm=0.388, clip=0, loss_scale=16, train_wall=90, gb_free=16.2, wall=8770
2023-07-03 12:54:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 12:55:28 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 2.242 | trans_loss 5.757 | nll_loss 3.086 | w2v_ctc_loss 0.692 | task_loss 2.365 | contrastive_loss 0.274 | total 4003.4 | n_correct 2360.6 | ppl 8.49 | accuracy 58.965 | uer 19.154 | wer 21.002 | raw_wer 21.002 | bleu 17.43 | wps 1843.1 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 17.43
2023-07-03 12:55:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-07-03 12:55:28 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_7_10000.pt
2023-07-03 12:55:31 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_7_10000.pt
2023-07-03 12:55:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 17.43) (writing took 14.475668769795448 seconds)
tensor(0.6096, device='cuda:0')
tensor(0.5218, device='cuda:0')
2023-07-03 12:57:13 | INFO | train_inner | epoch 007:   1263 / 1474 loss=2.253, trans_loss=3.547, nll_loss=1.715, w2v_ctc_loss=0.685, task_loss=0.511, contrastive_loss=0.129, total=4129.52, n_correct=2379.98, ppl=3.28, accuracy=57.633, wps=9226.9, ups=0.75, wpb=12329.2, bsz=450.2, num_updates=10100, lr=0.00014072, gnorm=0.297, clip=0, loss_scale=16, train_wall=89, gb_free=17, wall=8904
2023-07-03 12:58:43 | INFO | train_inner | epoch 007:   1363 / 1474 loss=2.261, trans_loss=3.542, nll_loss=1.711, w2v_ctc_loss=0.691, task_loss=0.473, contrastive_loss=0.166, total=4172.87, n_correct=2419.56, ppl=3.27, accuracy=57.983, wps=13848.5, ups=1.11, wpb=12453.5, bsz=476.2, num_updates=10200, lr=0.000140028, gnorm=0.295, clip=0, loss_scale=16, train_wall=89, gb_free=17.3, wall=8994
2023-07-03 13:00:14 | INFO | train_inner | epoch 007:   1463 / 1474 loss=2.269, trans_loss=3.554, nll_loss=1.725, w2v_ctc_loss=0.691, task_loss=0.543, contrastive_loss=0.228, total=4109.42, n_correct=2366.53, ppl=3.31, accuracy=57.588, wps=13417.2, ups=1.09, wpb=12285.7, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.3, clip=0, loss_scale=16, train_wall=91, gb_free=16.6, wall=9085
2023-07-03 13:00:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.6096, device='cuda:6')
tensor(0.5218, device='cuda:6')
tensor(0.6096, device='cuda:7')
tensor(0.5218, device='cuda:7')
tensor(0.6096, device='cuda:1')
tensor(0.5218, device='cuda:1')
tensor(0.6096, device='cuda:3')
tensor(0.5218, device='cuda:3')
tensor(0.6096, device='cuda:4')
tensor(0.5218, device='cuda:4')
tensor(0.6096, device='cuda:5')
tensor(0.5218, device='cuda:5')
tensor(0.6096, device='cuda:2')
tensor(0.5218, device='cuda:2')
2023-07-03 13:00:53 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 2.238 | trans_loss 5.745 | nll_loss 3.072 | w2v_ctc_loss 0.694 | task_loss 2.366 | contrastive_loss 0.272 | total 4003.4 | n_correct 2370.5 | ppl 8.41 | accuracy 59.212 | uer 19.428 | wer 21.211 | raw_wer 21.211 | bleu 16.94 | wps 1821 | wpb 4003.4 | bsz 141.8 | num_updates 10311 | best_bleu 17.43
2023-07-03 13:00:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10311 updates
2023-07-03 13:00:53 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_16.9407.pt
2023-07-03 13:00:56 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_16.9407.pt
2023-07-03 13:00:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_16.9407.pt (epoch 7 @ 10311 updates, score 16.94) (writing took 5.672597816679627 seconds)
2023-07-03 13:00:59 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-07-03 13:00:59 | INFO | train | epoch 007 | loss 2.268 | trans_loss 3.552 | nll_loss 1.72 | w2v_ctc_loss 0.695 | task_loss 0.505 | contrastive_loss 0.197 | total 4138.65 | n_correct 2378.88 | ppl 3.29 | accuracy 57.48 | wps 12841.2 | ups 1.04 | wpb 12355.8 | bsz 458.5 | num_updates 10311 | lr 0.000139272 | gnorm 0.365 | clip 0 | loss_scale 16 | train_wall 1324 | gb_free 13.5 | wall 9130
2023-07-03 13:00:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 13:00:59 | INFO | fairseq.trainer | begin training epoch 8
2023-07-03 13:00:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 13:02:28 | INFO | train_inner | epoch 008:     89 / 1474 loss=2.224, trans_loss=3.524, nll_loss=1.681, w2v_ctc_loss=0.662, task_loss=0.535, contrastive_loss=0.125, total=4116.25, n_correct=2408.71, ppl=3.21, accuracy=58.517, wps=9200.7, ups=0.75, wpb=12265.9, bsz=443.3, num_updates=10400, lr=0.000138675, gnorm=0.296, clip=0, loss_scale=16, train_wall=89, gb_free=17.1, wall=9218
2023-07-03 13:03:58 | INFO | train_inner | epoch 008:    189 / 1474 loss=2.229, trans_loss=3.527, nll_loss=1.686, w2v_ctc_loss=0.663, task_loss=0.551, contrastive_loss=0.147, total=4037.23, n_correct=2363.02, ppl=3.22, accuracy=58.531, wps=13338.9, ups=1.11, wpb=12033.3, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.3, clip=0, loss_scale=16, train_wall=90, gb_free=13.1, wall=9309
2023-07-03 13:05:28 | INFO | train_inner | epoch 008:    289 / 1474 loss=2.22, trans_loss=3.515, nll_loss=1.671, w2v_ctc_loss=0.655, task_loss=0.474, contrastive_loss=0.141, total=4207.78, n_correct=2478.33, ppl=3.18, accuracy=58.899, wps=14007.2, ups=1.11, wpb=12570.1, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.294, clip=0, loss_scale=16, train_wall=89, gb_free=13.3, wall=9398
2023-07-03 13:07:00 | INFO | train_inner | epoch 008:    389 / 1474 loss=2.235, trans_loss=3.524, nll_loss=1.682, w2v_ctc_loss=0.671, task_loss=0.537, contrastive_loss=0.165, total=4127.24, n_correct=2413.4, ppl=3.21, accuracy=58.475, wps=13357.5, ups=1.08, wpb=12318.5, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=0.296, clip=0, loss_scale=16, train_wall=92, gb_free=12.1, wall=9491
2023-07-03 13:08:31 | INFO | train_inner | epoch 008:    489 / 1474 loss=2.255, trans_loss=3.523, nll_loss=1.683, w2v_ctc_loss=0.658, task_loss=0.452, contrastive_loss=0.428, total=4203.76, n_correct=2461.15, ppl=3.21, accuracy=58.546, wps=13857.4, ups=1.1, wpb=12567.7, bsz=504.5, num_updates=10800, lr=0.000136083, gnorm=0.305, clip=0, loss_scale=16, train_wall=90, gb_free=14.7, wall=9581
2023-07-03 13:10:01 | INFO | train_inner | epoch 008:    589 / 1474 loss=2.226, trans_loss=3.524, nll_loss=1.684, w2v_ctc_loss=0.665, task_loss=0.549, contrastive_loss=0.098, total=4062.5, n_correct=2372.24, ppl=3.21, accuracy=58.394, wps=13459.5, ups=1.11, wpb=12171.9, bsz=427.9, num_updates=10900, lr=0.000135457, gnorm=0.297, clip=0, loss_scale=16, train_wall=90, gb_free=11.7, wall=9672
2023-07-03 13:11:31 | INFO | train_inner | epoch 008:    689 / 1474 loss=2.227, trans_loss=3.52, nll_loss=1.68, w2v_ctc_loss=0.669, task_loss=0.521, contrastive_loss=0.11, total=4142.78, n_correct=2435.97, ppl=3.2, accuracy=58.8, wps=13656.8, ups=1.11, wpb=12347.9, bsz=448.6, num_updates=11000, lr=0.00013484, gnorm=0.294, clip=0, loss_scale=16, train_wall=90, gb_free=16, wall=9762
2023-07-03 13:13:01 | INFO | train_inner | epoch 008:    789 / 1474 loss=2.229, trans_loss=3.517, nll_loss=1.678, w2v_ctc_loss=0.66, task_loss=0.515, contrastive_loss=0.199, total=4118.9, n_correct=2420.35, ppl=3.2, accuracy=58.762, wps=13704.3, ups=1.11, wpb=12327.8, bsz=447.8, num_updates=11100, lr=0.000134231, gnorm=0.298, clip=0, loss_scale=16, train_wall=89, gb_free=15.3, wall=9852
2023-07-03 13:14:31 | INFO | train_inner | epoch 008:    889 / 1474 loss=2.229, trans_loss=3.519, nll_loss=1.681, w2v_ctc_loss=0.655, task_loss=0.483, contrastive_loss=0.206, total=4169.01, n_correct=2453.8, ppl=3.21, accuracy=58.858, wps=13848.8, ups=1.11, wpb=12455.3, bsz=473.7, num_updates=11200, lr=0.000133631, gnorm=0.296, clip=0, loss_scale=16, train_wall=89, gb_free=16.3, wall=9942
2023-07-03 13:16:00 | INFO | train_inner | epoch 008:    989 / 1474 loss=2.213, trans_loss=3.514, nll_loss=1.673, w2v_ctc_loss=0.65, task_loss=0.481, contrastive_loss=0.107, total=4154.69, n_correct=2451.61, ppl=3.19, accuracy=59.008, wps=13943.9, ups=1.12, wpb=12398.4, bsz=464.9, num_updates=11300, lr=0.000133038, gnorm=0.298, clip=0, loss_scale=32, train_wall=88, gb_free=17.8, wall=10031
2023-07-03 13:17:32 | INFO | train_inner | epoch 008:   1089 / 1474 loss=2.236, trans_loss=3.521, nll_loss=1.683, w2v_ctc_loss=0.657, task_loss=0.505, contrastive_loss=0.333, total=4199.1, n_correct=2462.7, ppl=3.21, accuracy=58.648, wps=13706.4, ups=1.09, wpb=12520.7, bsz=465.3, num_updates=11400, lr=0.000132453, gnorm=0.296, clip=0, loss_scale=32, train_wall=91, gb_free=13, wall=10122
2023-07-03 13:19:01 | INFO | train_inner | epoch 008:   1189 / 1474 loss=2.222, trans_loss=3.519, nll_loss=1.682, w2v_ctc_loss=0.657, task_loss=0.475, contrastive_loss=0.118, total=4177.31, n_correct=2462.39, ppl=3.21, accuracy=58.947, wps=13911.6, ups=1.12, wpb=12476.4, bsz=472.6, num_updates=11500, lr=0.000131876, gnorm=0.295, clip=0, loss_scale=32, train_wall=89, gb_free=15.1, wall=10212
2023-07-03 13:20:31 | INFO | train_inner | epoch 008:   1289 / 1474 loss=2.227, trans_loss=3.521, nll_loss=1.684, w2v_ctc_loss=0.662, task_loss=0.526, contrastive_loss=0.138, total=4063.85, n_correct=2380.4, ppl=3.21, accuracy=58.575, wps=13590.1, ups=1.12, wpb=12141.2, bsz=438.4, num_updates=11600, lr=0.000131306, gnorm=0.298, clip=0, loss_scale=32, train_wall=89, gb_free=16.9, wall=10301
2023-07-03 13:22:00 | INFO | train_inner | epoch 008:   1389 / 1474 loss=2.231, trans_loss=3.521, nll_loss=1.686, w2v_ctc_loss=0.66, task_loss=0.498, contrastive_loss=0.192, total=4141.5, n_correct=2437.35, ppl=3.22, accuracy=58.852, wps=13859.2, ups=1.12, wpb=12351.9, bsz=461.5, num_updates=11700, lr=0.000130744, gnorm=0.297, clip=0, loss_scale=32, train_wall=89, gb_free=16.7, wall=10391
2023-07-03 13:23:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 13:23:45 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 2.223 | trans_loss 5.702 | nll_loss 3.009 | w2v_ctc_loss 0.696 | task_loss 2.365 | contrastive_loss 0.274 | total 4003.4 | n_correct 2394.7 | ppl 8.05 | accuracy 59.817 | uer 18.666 | wer 20.424 | raw_wer 20.424 | bleu 17.29 | wps 1805.8 | wpb 4003.4 | bsz 141.8 | num_updates 11785 | best_bleu 17.43
2023-07-03 13:23:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11785 updates
2023-07-03 13:23:45 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_17.2907.pt
2023-07-03 13:23:47 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_17.2907.pt
2023-07-03 13:23:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_17.2907.pt (epoch 8 @ 11785 updates, score 17.29) (writing took 5.393690096680075 seconds)
2023-07-03 13:23:51 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-07-03 13:23:51 | INFO | train | epoch 008 | loss 2.229 | trans_loss 3.52 | nll_loss 1.681 | w2v_ctc_loss 0.66 | task_loss 0.505 | contrastive_loss 0.186 | total 4138.65 | n_correct 2430.25 | ppl 3.21 | accuracy 58.721 | wps 13278 | ups 1.07 | wpb 12355.8 | bsz 458.5 | num_updates 11785 | lr 0.000130272 | gnorm 0.297 | clip 0 | loss_scale 32 | train_wall 1321 | gb_free 17.1 | wall 10501
2023-07-03 13:23:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 13:23:51 | INFO | fairseq.trainer | begin training epoch 9
2023-07-03 13:23:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 13:24:13 | INFO | train_inner | epoch 009:     15 / 1474 loss=2.227, trans_loss=3.515, nll_loss=1.676, w2v_ctc_loss=0.647, task_loss=0.488, contrastive_loss=0.316, total=4139.35, n_correct=2445.32, ppl=3.19, accuracy=59.075, wps=9278.2, ups=0.75, wpb=12332.8, bsz=472.9, num_updates=11800, lr=0.000130189, gnorm=0.296, clip=0, loss_scale=32, train_wall=89, gb_free=16.4, wall=10523
2023-07-03 13:25:43 | INFO | train_inner | epoch 009:    115 / 1474 loss=2.185, trans_loss=3.487, nll_loss=1.638, w2v_ctc_loss=0.623, task_loss=0.478, contrastive_loss=0.135, total=4181.9, n_correct=2507.04, ppl=3.11, accuracy=59.95, wps=13860.3, ups=1.11, wpb=12493.2, bsz=475.9, num_updates=11900, lr=0.000129641, gnorm=0.291, clip=0, loss_scale=32, train_wall=90, gb_free=16.4, wall=10614
2023-07-03 13:27:13 | INFO | train_inner | epoch 009:    215 / 1474 loss=2.189, trans_loss=3.499, nll_loss=1.652, w2v_ctc_loss=0.629, task_loss=0.545, contrastive_loss=0.095, total=4062.07, n_correct=2422.29, ppl=3.14, accuracy=59.632, wps=13437.6, ups=1.11, wpb=12136.5, bsz=431.6, num_updates=12000, lr=0.000129099, gnorm=0.296, clip=0, loss_scale=32, train_wall=90, gb_free=15.8, wall=10704
2023-07-03 13:27:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 13:27:41 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 2.219 | trans_loss 5.716 | nll_loss 3.031 | w2v_ctc_loss 0.664 | task_loss 2.365 | contrastive_loss 0.271 | total 4003.4 | n_correct 2388 | ppl 8.17 | accuracy 59.649 | uer 18.546 | wer 20.324 | raw_wer 20.324 | bleu 17.93 | wps 1905.5 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 17.93
2023-07-03 13:27:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-07-03 13:27:41 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_9_12000.pt
2023-07-03 13:27:44 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_9_12000.pt
2023-07-03 13:27:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 17.93) (writing took 9.397698195185512 seconds)
2023-07-03 13:29:21 | INFO | train_inner | epoch 009:    315 / 1474 loss=2.183, trans_loss=3.484, nll_loss=1.635, w2v_ctc_loss=0.619, task_loss=0.471, contrastive_loss=0.143, total=4152.1, n_correct=2491.5, ppl=3.11, accuracy=60.006, wps=9713.1, ups=0.78, wpb=12422.8, bsz=476.6, num_updates=12100, lr=0.000128565, gnorm=0.289, clip=0, loss_scale=32, train_wall=89, gb_free=16.4, wall=10832
2023-07-03 13:30:53 | INFO | train_inner | epoch 009:    415 / 1474 loss=2.189, trans_loss=3.492, nll_loss=1.645, w2v_ctc_loss=0.629, task_loss=0.494, contrastive_loss=0.112, total=4203.78, n_correct=2506.35, ppl=3.13, accuracy=59.621, wps=13724.2, ups=1.09, wpb=12545.5, bsz=469.8, num_updates=12200, lr=0.000128037, gnorm=0.292, clip=0, loss_scale=32, train_wall=91, gb_free=17.2, wall=10923
2023-07-03 13:32:22 | INFO | train_inner | epoch 009:    515 / 1474 loss=2.207, trans_loss=3.503, nll_loss=1.66, w2v_ctc_loss=0.644, task_loss=0.528, contrastive_loss=0.162, total=4112.78, n_correct=2440.88, ppl=3.16, accuracy=59.349, wps=13676.7, ups=1.12, wpb=12260.1, bsz=437.7, num_updates=12300, lr=0.000127515, gnorm=0.298, clip=0, loss_scale=32, train_wall=89, gb_free=16.3, wall=11013
2023-07-03 13:33:52 | INFO | train_inner | epoch 009:    615 / 1474 loss=2.19, trans_loss=3.492, nll_loss=1.647, w2v_ctc_loss=0.628, task_loss=0.514, contrastive_loss=0.122, total=4131.32, n_correct=2466.78, ppl=3.13, accuracy=59.709, wps=13718.3, ups=1.11, wpb=12355.3, bsz=455, num_updates=12400, lr=0.000127, gnorm=0.296, clip=0, loss_scale=32, train_wall=90, gb_free=17.9, wall=11103
2023-07-03 13:35:22 | INFO | train_inner | epoch 009:    715 / 1474 loss=2.208, trans_loss=3.501, nll_loss=1.657, w2v_ctc_loss=0.639, task_loss=0.518, contrastive_loss=0.205, total=4082.11, n_correct=2427.13, ppl=3.15, accuracy=59.458, wps=13655.9, ups=1.12, wpb=12206.9, bsz=449.7, num_updates=12500, lr=0.000126491, gnorm=0.301, clip=0, loss_scale=32, train_wall=89, gb_free=17.1, wall=11192
2023-07-03 13:36:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-03 13:36:53 | INFO | train_inner | epoch 009:    816 / 1474 loss=2.202, trans_loss=3.487, nll_loss=1.643, w2v_ctc_loss=0.637, task_loss=0.467, contrastive_loss=0.202, total=4197.6, n_correct=2509.1, ppl=3.12, accuracy=59.775, wps=13710, ups=1.09, wpb=12537.8, bsz=489.3, num_updates=12600, lr=0.000125988, gnorm=0.296, clip=0, loss_scale=16, train_wall=91, gb_free=14.6, wall=11284
2023-07-03 13:38:24 | INFO | train_inner | epoch 009:    916 / 1474 loss=2.207, trans_loss=3.497, nll_loss=1.653, w2v_ctc_loss=0.631, task_loss=0.52, contrastive_loss=0.33, total=4146.05, n_correct=2473.11, ppl=3.14, accuracy=59.65, wps=13574.3, ups=1.1, wpb=12355.9, bsz=450.3, num_updates=12700, lr=0.000125491, gnorm=0.292, clip=0, loss_scale=16, train_wall=91, gb_free=17.9, wall=11375
2023-07-03 13:39:55 | INFO | train_inner | epoch 009:   1016 / 1474 loss=2.196, trans_loss=3.507, nll_loss=1.663, w2v_ctc_loss=0.634, task_loss=0.566, contrastive_loss=0.108, total=4101.48, n_correct=2432.78, ppl=3.17, accuracy=59.315, wps=13495.9, ups=1.1, wpb=12243.2, bsz=424.4, num_updates=12800, lr=0.000125, gnorm=0.293, clip=0, loss_scale=16, train_wall=90, gb_free=16.1, wall=11466
2023-07-03 13:41:25 | INFO | train_inner | epoch 009:   1116 / 1474 loss=2.196, trans_loss=3.497, nll_loss=1.651, w2v_ctc_loss=0.634, task_loss=0.476, contrastive_loss=0.132, total=4179.09, n_correct=2500.81, ppl=3.14, accuracy=59.841, wps=13853.1, ups=1.11, wpb=12439.9, bsz=474.7, num_updates=12900, lr=0.000124515, gnorm=0.295, clip=0, loss_scale=16, train_wall=89, gb_free=15.5, wall=11555
2023-07-03 13:42:56 | INFO | train_inner | epoch 009:   1216 / 1474 loss=2.199, trans_loss=3.505, nll_loss=1.658, w2v_ctc_loss=0.635, task_loss=0.533, contrastive_loss=0.114, total=4140.66, n_correct=2464.99, ppl=3.16, accuracy=59.531, wps=13637.6, ups=1.1, wpb=12405, bsz=448.1, num_updates=13000, lr=0.000124035, gnorm=0.295, clip=0, loss_scale=16, train_wall=91, gb_free=17.2, wall=11646
2023-07-03 13:44:25 | INFO | train_inner | epoch 009:   1316 / 1474 loss=2.201, trans_loss=3.491, nll_loss=1.644, w2v_ctc_loss=0.622, task_loss=0.458, contrastive_loss=0.307, total=4204.43, n_correct=2525.75, ppl=3.13, accuracy=60.074, wps=13977, ups=1.11, wpb=12539.3, bsz=492.5, num_updates=13100, lr=0.00012356, gnorm=0.294, clip=0, loss_scale=16, train_wall=89, gb_free=17.8, wall=11736
2023-07-03 13:45:55 | INFO | train_inner | epoch 009:   1416 / 1474 loss=2.199, trans_loss=3.51, nll_loss=1.667, w2v_ctc_loss=0.638, task_loss=0.549, contrastive_loss=0.093, total=4069.19, n_correct=2417.22, ppl=3.18, accuracy=59.403, wps=13576.3, ups=1.12, wpb=12152.5, bsz=427.7, num_updates=13200, lr=0.000123091, gnorm=0.298, clip=0, loss_scale=16, train_wall=89, gb_free=16.8, wall=11826
2023-07-03 13:46:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 13:47:14 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 2.213 | trans_loss 5.677 | nll_loss 2.984 | w2v_ctc_loss 0.695 | task_loss 2.365 | contrastive_loss 0.264 | total 4003.4 | n_correct 2402.6 | ppl 7.91 | accuracy 60.014 | uer 18.515 | wer 20.339 | raw_wer 20.339 | bleu 18.65 | wps 2000.1 | wpb 4003.4 | bsz 141.8 | num_updates 13258 | best_bleu 18.65
2023-07-03 13:47:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13258 updates
2023-07-03 13:47:14 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 13:47:18 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 13:47:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt (epoch 9 @ 13258 updates, score 18.65) (writing took 8.729517071973532 seconds)
2023-07-03 13:47:23 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-07-03 13:47:23 | INFO | train | epoch 009 | loss 2.197 | trans_loss 3.496 | nll_loss 1.651 | w2v_ctc_loss 0.632 | task_loss 0.506 | contrastive_loss 0.167 | total 4137.17 | n_correct 2468.99 | ppl 3.14 | accuracy 59.678 | wps 12885.6 | ups 1.04 | wpb 12352.1 | bsz 457.7 | num_updates 13258 | lr 0.000122822 | gnorm 0.295 | clip 0 | loss_scale 16 | train_wall 1323 | gb_free 12 | wall 11913
2023-07-03 13:47:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 13:47:23 | INFO | fairseq.trainer | begin training epoch 10
2023-07-03 13:47:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 13:48:08 | INFO | train_inner | epoch 010:     42 / 1474 loss=2.188, trans_loss=3.488, nll_loss=1.639, w2v_ctc_loss=0.621, task_loss=0.481, contrastive_loss=0.189, total=4100.8, n_correct=2466.5, ppl=3.11, accuracy=60.147, wps=9168.8, ups=0.75, wpb=12243.3, bsz=469.4, num_updates=13300, lr=0.000122628, gnorm=0.302, clip=0, loss_scale=16, train_wall=89, gb_free=16.4, wall=11959
2023-07-03 13:49:38 | INFO | train_inner | epoch 010:    142 / 1474 loss=2.158, trans_loss=3.469, nll_loss=1.613, w2v_ctc_loss=0.599, task_loss=0.478, contrastive_loss=0.111, total=4247.35, n_correct=2578.05, ppl=3.06, accuracy=60.698, wps=14145.4, ups=1.11, wpb=12717.5, bsz=479.6, num_updates=13400, lr=0.000122169, gnorm=0.286, clip=0, loss_scale=16, train_wall=89, gb_free=12.1, wall=12049
2023-07-03 13:51:08 | INFO | train_inner | epoch 010:    242 / 1474 loss=2.168, trans_loss=3.464, nll_loss=1.611, w2v_ctc_loss=0.605, task_loss=0.499, contrastive_loss=0.234, total=4122.82, n_correct=2502.96, ppl=3.06, accuracy=60.71, wps=13700.2, ups=1.12, wpb=12279.5, bsz=461.4, num_updates=13500, lr=0.000121716, gnorm=0.293, clip=0, loss_scale=16, train_wall=89, gb_free=16.4, wall=12139
2023-07-03 13:52:38 | INFO | train_inner | epoch 010:    342 / 1474 loss=2.164, trans_loss=3.465, nll_loss=1.613, w2v_ctc_loss=0.605, task_loss=0.509, contrastive_loss=0.146, total=4138.27, n_correct=2511.75, ppl=3.06, accuracy=60.696, wps=13698.7, ups=1.11, wpb=12378.7, bsz=453.8, num_updates=13600, lr=0.000121268, gnorm=0.293, clip=0, loss_scale=16, train_wall=90, gb_free=16.6, wall=12229
2023-07-03 13:54:10 | INFO | train_inner | epoch 010:    442 / 1474 loss=2.171, trans_loss=3.47, nll_loss=1.617, w2v_ctc_loss=0.595, task_loss=0.485, contrastive_loss=0.321, total=4196.37, n_correct=2543.98, ppl=3.07, accuracy=60.623, wps=13739.3, ups=1.1, wpb=12523.5, bsz=481.1, num_updates=13700, lr=0.000120824, gnorm=0.291, clip=0, loss_scale=16, train_wall=91, gb_free=16.6, wall=12320
2023-07-03 13:55:39 | INFO | train_inner | epoch 010:    542 / 1474 loss=2.173, trans_loss=3.482, nll_loss=1.629, w2v_ctc_loss=0.617, task_loss=0.545, contrastive_loss=0.102, total=4102.8, n_correct=2474.2, ppl=3.09, accuracy=60.305, wps=13601.2, ups=1.11, wpb=12224.8, bsz=437.8, num_updates=13800, lr=0.000120386, gnorm=0.295, clip=0, loss_scale=16, train_wall=89, gb_free=17.1, wall=12410
2023-07-03 13:57:09 | INFO | train_inner | epoch 010:    642 / 1474 loss=2.182, trans_loss=3.481, nll_loss=1.63, w2v_ctc_loss=0.612, task_loss=0.478, contrastive_loss=0.216, total=4176.56, n_correct=2523.27, ppl=3.1, accuracy=60.415, wps=13879.8, ups=1.11, wpb=12467.5, bsz=477.2, num_updates=13900, lr=0.000119952, gnorm=0.295, clip=0, loss_scale=16, train_wall=89, gb_free=16.4, wall=12500
2023-07-03 13:58:39 | INFO | train_inner | epoch 010:    742 / 1474 loss=2.176, trans_loss=3.479, nll_loss=1.629, w2v_ctc_loss=0.622, task_loss=0.505, contrastive_loss=0.099, total=4125.87, n_correct=2489.34, ppl=3.09, accuracy=60.335, wps=13792.6, ups=1.12, wpb=12315.5, bsz=454.4, num_updates=14000, lr=0.000119523, gnorm=0.298, clip=0, loss_scale=16, train_wall=89, gb_free=14.7, wall=12589
2023-07-03 13:58:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 13:59:07 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 2.215 | trans_loss 5.682 | nll_loss 2.986 | w2v_ctc_loss 0.694 | task_loss 2.365 | contrastive_loss 0.258 | total 4003.4 | n_correct 2409.5 | ppl 7.92 | accuracy 60.186 | uer 18.297 | wer 20.048 | raw_wer 20.048 | bleu 17.83 | wps 1872.8 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 18.65
2023-07-03 13:59:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-07-03 13:59:07 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_10_14000.pt
2023-07-03 13:59:10 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_10_14000.pt
2023-07-03 13:59:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 17.83) (writing took 6.851082210894674 seconds)
2023-07-03 14:00:44 | INFO | train_inner | epoch 010:    842 / 1474 loss=2.164, trans_loss=3.478, nll_loss=1.626, w2v_ctc_loss=0.604, task_loss=0.498, contrastive_loss=0.101, total=4128.44, n_correct=2498.3, ppl=3.09, accuracy=60.514, wps=9848.9, ups=0.8, wpb=12345, bsz=456.3, num_updates=14100, lr=0.000119098, gnorm=0.291, clip=0, loss_scale=16, train_wall=89, gb_free=14.9, wall=12715
2023-07-03 14:02:13 | INFO | train_inner | epoch 010:    942 / 1474 loss=2.174, trans_loss=3.474, nll_loss=1.625, w2v_ctc_loss=0.616, task_loss=0.488, contrastive_loss=0.141, total=4160.94, n_correct=2517.45, ppl=3.08, accuracy=60.502, wps=13853.3, ups=1.12, wpb=12380.2, bsz=468.1, num_updates=14200, lr=0.000118678, gnorm=0.301, clip=0, loss_scale=16, train_wall=89, gb_free=15.6, wall=12804
2023-07-03 14:03:44 | INFO | train_inner | epoch 010:   1042 / 1474 loss=2.171, trans_loss=3.48, nll_loss=1.631, w2v_ctc_loss=0.613, task_loss=0.548, contrastive_loss=0.114, total=4067.53, n_correct=2449.07, ppl=3.1, accuracy=60.21, wps=13407.8, ups=1.1, wpb=12142, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.296, clip=0, loss_scale=16, train_wall=90, gb_free=17, wall=12895
2023-07-03 14:05:13 | INFO | train_inner | epoch 010:   1142 / 1474 loss=2.172, trans_loss=3.484, nll_loss=1.636, w2v_ctc_loss=0.616, task_loss=0.563, contrastive_loss=0.094, total=4044.03, n_correct=2432.71, ppl=3.11, accuracy=60.156, wps=13529.7, ups=1.12, wpb=12072.9, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.296, clip=0, loss_scale=16, train_wall=89, gb_free=17.4, wall=12984
2023-07-03 14:06:43 | INFO | train_inner | epoch 010:   1242 / 1474 loss=2.169, trans_loss=3.477, nll_loss=1.63, w2v_ctc_loss=0.615, task_loss=0.516, contrastive_loss=0.09, total=4110.41, n_correct=2478.82, ppl=3.1, accuracy=60.306, wps=13698, ups=1.11, wpb=12302.3, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.294, clip=0, loss_scale=16, train_wall=89, gb_free=16.6, wall=13074
2023-07-03 14:08:13 | INFO | train_inner | epoch 010:   1342 / 1474 loss=2.166, trans_loss=3.475, nll_loss=1.625, w2v_ctc_loss=0.608, task_loss=0.514, contrastive_loss=0.103, total=4121.38, n_correct=2494.33, ppl=3.08, accuracy=60.522, wps=13677.9, ups=1.11, wpb=12315.5, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.293, clip=0, loss_scale=32, train_wall=90, gb_free=14.3, wall=13164
2023-07-03 14:09:43 | INFO | train_inner | epoch 010:   1442 / 1474 loss=2.192, trans_loss=3.482, nll_loss=1.636, w2v_ctc_loss=0.604, task_loss=0.476, contrastive_loss=0.357, total=4192.39, n_correct=2527.67, ppl=3.11, accuracy=60.292, wps=13797.5, ups=1.11, wpb=12477.9, bsz=482, num_updates=14700, lr=0.000116642, gnorm=0.299, clip=0, loss_scale=32, train_wall=90, gb_free=17.2, wall=13254
2023-07-03 14:10:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 14:10:39 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 2.202 | trans_loss 5.656 | nll_loss 2.95 | w2v_ctc_loss 0.683 | task_loss 2.366 | contrastive_loss 0.26 | total 4003.4 | n_correct 2417.7 | ppl 7.73 | accuracy 60.391 | uer 17.843 | wer 19.701 | raw_wer 19.701 | bleu 18.83 | wps 2007.6 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 18.83
2023-07-03 14:10:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-07-03 14:10:39 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 14:10:44 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 14:10:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt (epoch 10 @ 14732 updates, score 18.83) (writing took 8.672610266134143 seconds)
2023-07-03 14:10:48 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-07-03 14:10:48 | INFO | train | epoch 010 | loss 2.172 | trans_loss 3.476 | nll_loss 1.625 | w2v_ctc_loss 0.609 | task_loss 0.505 | contrastive_loss 0.17 | total 4138.65 | n_correct 2501.97 | ppl 3.08 | accuracy 60.454 | wps 12957.8 | ups 1.05 | wpb 12355.8 | bsz 458.5 | num_updates 14732 | lr 0.000116516 | gnorm 0.294 | clip 0 | loss_scale 32 | train_wall 1319 | gb_free 17.4 | wall 13319
2023-07-03 14:10:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 14:10:48 | INFO | fairseq.trainer | begin training epoch 11
2023-07-03 14:10:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 14:11:58 | INFO | train_inner | epoch 011:     68 / 1474 loss=2.15, trans_loss=3.456, nll_loss=1.6, w2v_ctc_loss=0.589, task_loss=0.466, contrastive_loss=0.179, total=4175.24, n_correct=2558.73, ppl=3.03, accuracy=61.283, wps=9274.8, ups=0.74, wpb=12460.8, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.286, clip=0, loss_scale=32, train_wall=89, gb_free=16.9, wall=13388
2023-07-03 14:13:28 | INFO | train_inner | epoch 011:    168 / 1474 loss=2.142, trans_loss=3.456, nll_loss=1.6, w2v_ctc_loss=0.591, task_loss=0.521, contrastive_loss=0.097, total=4087.78, n_correct=2498.5, ppl=3.03, accuracy=61.121, wps=13554, ups=1.11, wpb=12225.8, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.295, clip=0, loss_scale=32, train_wall=90, gb_free=16.7, wall=13479
2023-07-03 14:14:58 | INFO | train_inner | epoch 011:    268 / 1474 loss=2.139, trans_loss=3.455, nll_loss=1.6, w2v_ctc_loss=0.587, task_loss=0.52, contrastive_loss=0.094, total=4118.77, n_correct=2517.32, ppl=3.03, accuracy=61.118, wps=13677, ups=1.11, wpb=12285.5, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.294, clip=0, loss_scale=32, train_wall=89, gb_free=12.7, wall=13568
tensor(0.2625, device='cuda:0')
tensor(0.1612, device='cuda:0')
2023-07-03 14:16:27 | INFO | train_inner | epoch 011:    368 / 1474 loss=2.136, trans_loss=3.452, nll_loss=1.594, w2v_ctc_loss=0.583, task_loss=0.521, contrastive_loss=0.098, total=4097.83, n_correct=2514.47, ppl=3.02, accuracy=61.361, wps=13732.1, ups=1.13, wpb=12202.1, bsz=444.2, num_updates=15100, lr=0.000115087, gnorm=0.221, clip=0, loss_scale=32, train_wall=88, gb_free=16.4, wall=13657
2023-07-03 14:17:57 | INFO | train_inner | epoch 011:    468 / 1474 loss=2.16, trans_loss=3.468, nll_loss=1.611, w2v_ctc_loss=0.588, task_loss=0.531, contrastive_loss=0.258, total=4110.64, n_correct=2505.09, ppl=3.05, accuracy=60.942, wps=13533.9, ups=1.1, wpb=12265.6, bsz=450.5, num_updates=15200, lr=0.000114708, gnorm=0.223, clip=0, loss_scale=32, train_wall=90, gb_free=16.5, wall=13748
2023-07-03 14:18:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-03 14:19:28 | INFO | train_inner | epoch 011:    569 / 1474 loss=2.155, trans_loss=3.465, nll_loss=1.613, w2v_ctc_loss=0.597, task_loss=0.547, contrastive_loss=0.121, total=4058.33, n_correct=2473.91, ppl=3.06, accuracy=60.959, wps=13311.3, ups=1.1, wpb=12141.8, bsz=432.9, num_updates=15300, lr=0.000114332, gnorm=0.221, clip=0, loss_scale=16, train_wall=91, gb_free=16.7, wall=13839
2023-07-03 14:20:59 | INFO | train_inner | epoch 011:    669 / 1474 loss=2.166, trans_loss=3.46, nll_loss=1.603, w2v_ctc_loss=0.591, task_loss=0.497, contrastive_loss=0.334, total=4156.4, n_correct=2534.96, ppl=3.04, accuracy=60.989, wps=13755.3, ups=1.11, wpb=12399.3, bsz=465.3, num_updates=15400, lr=0.000113961, gnorm=0.221, clip=0, loss_scale=16, train_wall=90, gb_free=16.7, wall=13929
2023-07-03 14:22:29 | INFO | train_inner | epoch 011:    769 / 1474 loss=2.152, trans_loss=3.465, nll_loss=1.609, w2v_ctc_loss=0.597, task_loss=0.509, contrastive_loss=0.096, total=4169.17, n_correct=2545.51, ppl=3.05, accuracy=61.056, wps=13849.7, ups=1.11, wpb=12460.4, bsz=457.2, num_updates=15500, lr=0.000113592, gnorm=0.219, clip=0, loss_scale=16, train_wall=90, gb_free=12.5, wall=14019
2023-07-03 14:23:58 | INFO | train_inner | epoch 011:    869 / 1474 loss=2.15, trans_loss=3.463, nll_loss=1.611, w2v_ctc_loss=0.598, task_loss=0.528, contrastive_loss=0.083, total=4120.01, n_correct=2504.64, ppl=3.05, accuracy=60.792, wps=13704, ups=1.12, wpb=12288.7, bsz=440.2, num_updates=15600, lr=0.000113228, gnorm=0.221, clip=0, loss_scale=16, train_wall=89, gb_free=13.7, wall=14109
2023-07-03 14:25:28 | INFO | train_inner | epoch 011:    969 / 1474 loss=2.149, trans_loss=3.459, nll_loss=1.604, w2v_ctc_loss=0.594, task_loss=0.509, contrastive_loss=0.1, total=4145.45, n_correct=2532.91, ppl=3.04, accuracy=61.101, wps=13773.3, ups=1.11, wpb=12369.7, bsz=455.5, num_updates=15700, lr=0.000112867, gnorm=0.219, clip=0, loss_scale=16, train_wall=89, gb_free=17.2, wall=14199
2023-07-03 14:26:58 | INFO | train_inner | epoch 011:   1069 / 1474 loss=2.156, trans_loss=3.462, nll_loss=1.609, w2v_ctc_loss=0.598, task_loss=0.495, contrastive_loss=0.124, total=4141.18, n_correct=2528.96, ppl=3.05, accuracy=61.069, wps=13806.6, ups=1.12, wpb=12378.8, bsz=464.1, num_updates=15800, lr=0.000112509, gnorm=0.22, clip=0, loss_scale=16, train_wall=89, gb_free=16.7, wall=14288
2023-07-03 14:28:28 | INFO | train_inner | epoch 011:   1169 / 1474 loss=2.153, trans_loss=3.462, nll_loss=1.613, w2v_ctc_loss=0.598, task_loss=0.505, contrastive_loss=0.105, total=4173.93, n_correct=2543.79, ppl=3.06, accuracy=60.945, wps=13794.8, ups=1.11, wpb=12444.5, bsz=460.9, num_updates=15900, lr=0.000112154, gnorm=0.219, clip=0, loss_scale=16, train_wall=90, gb_free=17, wall=14379
2023-07-03 14:29:58 | INFO | train_inner | epoch 011:   1269 / 1474 loss=2.168, trans_loss=3.462, nll_loss=1.61, w2v_ctc_loss=0.604, task_loss=0.486, contrastive_loss=0.197, total=4174.26, n_correct=2548.48, ppl=3.05, accuracy=61.052, wps=13794.5, ups=1.11, wpb=12472, bsz=471.6, num_updates=16000, lr=0.000111803, gnorm=0.222, clip=0, loss_scale=16, train_wall=90, gb_free=17.5, wall=14469
2023-07-03 14:29:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.2625, device='cuda:4')
tensor(0.1612, device='cuda:4')
tensor(0.2625, device='cuda:7')
tensor(0.1612, device='cuda:7')
tensor(0.2625, device='cuda:3')
tensor(0.1612, device='cuda:3')
tensor(0.2625, device='cuda:2')
tensor(0.1612, device='cuda:2')
tensor(0.2625, device='cuda:5')
tensor(0.1612, device='cuda:5')
tensor(0.2625, device='cuda:6')
tensor(0.1612, device='cuda:6')
tensor(0.2625, device='cuda:1')
tensor(0.1612, device='cuda:1')
2023-07-03 14:30:27 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 2.209 | trans_loss 5.653 | nll_loss 2.949 | w2v_ctc_loss 0.708 | task_loss 2.366 | contrastive_loss 0.267 | total 4003.4 | n_correct 2425.4 | ppl 7.72 | accuracy 60.584 | uer 17.97 | wer 19.664 | raw_wer 19.664 | bleu 18.42 | wps 1910.4 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 18.83
2023-07-03 14:30:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-07-03 14:30:27 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_11_16000.pt
2023-07-03 14:30:29 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_11_16000.pt
2023-07-03 14:30:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 18.42) (writing took 6.818271658848971 seconds)
2023-07-03 14:32:05 | INFO | train_inner | epoch 011:   1369 / 1474 loss=2.173, trans_loss=3.462, nll_loss=1.608, w2v_ctc_loss=0.588, task_loss=0.466, contrastive_loss=0.414, total=4191.56, n_correct=2557.72, ppl=3.05, accuracy=61.021, wps=9898.2, ups=0.79, wpb=12516.8, bsz=491.5, num_updates=16100, lr=0.000111456, gnorm=0.218, clip=0, loss_scale=16, train_wall=90, gb_free=17.6, wall=14596
2023-07-03 14:33:36 | INFO | train_inner | epoch 011:   1469 / 1474 loss=2.149, trans_loss=3.462, nll_loss=1.609, w2v_ctc_loss=0.592, task_loss=0.486, contrastive_loss=0.108, total=4161.81, n_correct=2543.23, ppl=3.05, accuracy=61.109, wps=13709.9, ups=1.1, wpb=12429.3, bsz=469.8, num_updates=16200, lr=0.000111111, gnorm=0.217, clip=0, loss_scale=16, train_wall=90, gb_free=17, wall=14686
2023-07-03 14:33:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 14:34:08 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 2.197 | trans_loss 5.641 | nll_loss 2.931 | w2v_ctc_loss 0.684 | task_loss 2.366 | contrastive_loss 0.262 | total 4003.4 | n_correct 2431.1 | ppl 7.63 | accuracy 60.726 | uer 17.694 | wer 19.544 | raw_wer 19.544 | bleu 18.54 | wps 1853.9 | wpb 4003.4 | bsz 141.8 | num_updates 16205 | best_bleu 18.83
2023-07-03 14:34:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16205 updates
2023-07-03 14:34:09 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_18.5408.pt
2023-07-03 14:34:11 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_18.5408.pt
2023-07-03 14:34:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_18.5408.pt (epoch 11 @ 16205 updates, score 18.54) (writing took 5.44124748185277 seconds)
2023-07-03 14:34:14 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-07-03 14:34:14 | INFO | train | epoch 011 | loss 2.153 | trans_loss 3.46 | nll_loss 1.606 | w2v_ctc_loss 0.593 | task_loss 0.506 | contrastive_loss 0.158 | total 4137.55 | n_correct 2526.83 | ppl 3.04 | accuracy 61.071 | wps 12941.1 | ups 1.05 | wpb 12353 | bsz 457.9 | num_updates 16205 | lr 0.000111094 | gnorm 0.233 | clip 0 | loss_scale 16 | train_wall 1320 | gb_free 17.3 | wall 14725
2023-07-03 14:34:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 14:34:14 | INFO | fairseq.trainer | begin training epoch 12
2023-07-03 14:34:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 14:35:48 | INFO | train_inner | epoch 012:     95 / 1474 loss=2.13, trans_loss=3.435, nll_loss=1.572, w2v_ctc_loss=0.576, task_loss=0.488, contrastive_loss=0.151, total=4139.2, n_correct=2570.46, ppl=2.97, accuracy=62.1, wps=9344.6, ups=0.76, wpb=12361.4, bsz=468.8, num_updates=16300, lr=0.00011077, gnorm=0.216, clip=0, loss_scale=16, train_wall=89, gb_free=16.1, wall=14819
2023-07-03 14:37:18 | INFO | train_inner | epoch 012:    195 / 1474 loss=2.129, trans_loss=3.439, nll_loss=1.579, w2v_ctc_loss=0.58, task_loss=0.517, contrastive_loss=0.087, total=4126.87, n_correct=2548.89, ppl=2.99, accuracy=61.763, wps=13777.2, ups=1.11, wpb=12361.2, bsz=443.9, num_updates=16400, lr=0.000110432, gnorm=0.218, clip=0, loss_scale=16, train_wall=89, gb_free=16.6, wall=14908
2023-07-03 14:38:48 | INFO | train_inner | epoch 012:    295 / 1474 loss=2.127, trans_loss=3.437, nll_loss=1.578, w2v_ctc_loss=0.57, task_loss=0.473, contrastive_loss=0.127, total=4203.54, n_correct=2605.28, ppl=2.99, accuracy=61.978, wps=13831, ups=1.1, wpb=12550.7, bsz=481.6, num_updates=16500, lr=0.000110096, gnorm=0.215, clip=0, loss_scale=16, train_wall=90, gb_free=14.8, wall=14999
2023-07-03 14:40:19 | INFO | train_inner | epoch 012:    395 / 1474 loss=2.129, trans_loss=3.442, nll_loss=1.583, w2v_ctc_loss=0.577, task_loss=0.495, contrastive_loss=0.106, total=4149.28, n_correct=2565.01, ppl=3, accuracy=61.818, wps=13746.9, ups=1.11, wpb=12403.5, bsz=460.7, num_updates=16600, lr=0.000109764, gnorm=0.218, clip=0, loss_scale=16, train_wall=90, gb_free=15.4, wall=15089
2023-07-03 14:41:48 | INFO | train_inner | epoch 012:    495 / 1474 loss=2.143, trans_loss=3.455, nll_loss=1.597, w2v_ctc_loss=0.588, task_loss=0.513, contrastive_loss=0.115, total=4106.46, n_correct=2530.61, ppl=3.02, accuracy=61.625, wps=13630.2, ups=1.12, wpb=12220.6, bsz=451.8, num_updates=16700, lr=0.000109435, gnorm=0.218, clip=0, loss_scale=16, train_wall=89, gb_free=17.9, wall=15179
2023-07-03 14:43:19 | INFO | train_inner | epoch 012:    595 / 1474 loss=2.142, trans_loss=3.441, nll_loss=1.585, w2v_ctc_loss=0.581, task_loss=0.48, contrastive_loss=0.199, total=4190.91, n_correct=2588, ppl=3, accuracy=61.753, wps=13800.2, ups=1.1, wpb=12532.1, bsz=474.7, num_updates=16800, lr=0.000109109, gnorm=0.217, clip=0, loss_scale=16, train_wall=90, gb_free=16, wall=15270
2023-07-03 14:44:49 | INFO | train_inner | epoch 012:    695 / 1474 loss=2.14, trans_loss=3.439, nll_loss=1.58, w2v_ctc_loss=0.572, task_loss=0.466, contrastive_loss=0.318, total=4203.66, n_correct=2602.48, ppl=2.99, accuracy=61.91, wps=13919.8, ups=1.11, wpb=12493.6, bsz=486.5, num_updates=16900, lr=0.000108786, gnorm=0.215, clip=0, loss_scale=16, train_wall=89, gb_free=17.5, wall=15359
2023-07-03 14:46:19 | INFO | train_inner | epoch 012:    795 / 1474 loss=2.136, trans_loss=3.447, nll_loss=1.587, w2v_ctc_loss=0.583, task_loss=0.513, contrastive_loss=0.101, total=4095.72, n_correct=2532.99, ppl=3, accuracy=61.845, wps=13564.9, ups=1.11, wpb=12238.8, bsz=448.3, num_updates=17000, lr=0.000108465, gnorm=0.22, clip=0, loss_scale=16, train_wall=90, gb_free=17.3, wall=15450
2023-07-03 14:47:50 | INFO | train_inner | epoch 012:    895 / 1474 loss=2.138, trans_loss=3.444, nll_loss=1.587, w2v_ctc_loss=0.578, task_loss=0.517, contrastive_loss=0.167, total=4162.82, n_correct=2572.18, ppl=3, accuracy=61.789, wps=13698.7, ups=1.1, wpb=12435.1, bsz=458.1, num_updates=17100, lr=0.000108148, gnorm=0.218, clip=0, loss_scale=16, train_wall=90, gb_free=16.3, wall=15540
2023-07-03 14:49:20 | INFO | train_inner | epoch 012:    995 / 1474 loss=2.142, trans_loss=3.45, nll_loss=1.594, w2v_ctc_loss=0.583, task_loss=0.513, contrastive_loss=0.183, total=4117.63, n_correct=2534.82, ppl=3.02, accuracy=61.56, wps=13635.1, ups=1.11, wpb=12286.8, bsz=452.4, num_updates=17200, lr=0.000107833, gnorm=0.219, clip=0, loss_scale=16, train_wall=90, gb_free=17.1, wall=15631
2023-07-03 14:50:49 | INFO | train_inner | epoch 012:   1095 / 1474 loss=2.155, trans_loss=3.453, nll_loss=1.597, w2v_ctc_loss=0.589, task_loss=0.533, contrastive_loss=0.242, total=4046.48, n_correct=2492.09, ppl=3.02, accuracy=61.587, wps=13541.4, ups=1.12, wpb=12084, bsz=434.4, num_updates=17300, lr=0.000107521, gnorm=0.224, clip=0, loss_scale=32, train_wall=89, gb_free=16.1, wall=15720
2023-07-03 14:52:20 | INFO | train_inner | epoch 012:   1195 / 1474 loss=2.161, trans_loss=3.454, nll_loss=1.602, w2v_ctc_loss=0.6, task_loss=0.489, contrastive_loss=0.199, total=4201.13, n_correct=2572.56, ppl=3.04, accuracy=61.235, wps=13850, ups=1.1, wpb=12545, bsz=478.7, num_updates=17400, lr=0.000107211, gnorm=0.221, clip=0, loss_scale=32, train_wall=90, gb_free=17.4, wall=15810
2023-07-03 14:53:50 | INFO | train_inner | epoch 012:   1295 / 1474 loss=2.142, trans_loss=3.454, nll_loss=1.601, w2v_ctc_loss=0.59, task_loss=0.562, contrastive_loss=0.084, total=4070.27, n_correct=2505.85, ppl=3.03, accuracy=61.565, wps=13502.2, ups=1.11, wpb=12168, bsz=429.2, num_updates=17500, lr=0.000106904, gnorm=0.222, clip=0, loss_scale=32, train_wall=90, gb_free=16.1, wall=15901
2023-07-03 14:55:20 | INFO | train_inner | epoch 012:   1395 / 1474 loss=2.142, trans_loss=3.447, nll_loss=1.593, w2v_ctc_loss=0.578, task_loss=0.508, contrastive_loss=0.22, total=4139.63, n_correct=2552.79, ppl=3.02, accuracy=61.667, wps=13685.1, ups=1.11, wpb=12331.2, bsz=458.7, num_updates=17600, lr=0.0001066, gnorm=0.221, clip=0, loss_scale=32, train_wall=90, gb_free=17.2, wall=15991
2023-07-03 14:56:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 14:57:00 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 2.194 | trans_loss 5.625 | nll_loss 2.913 | w2v_ctc_loss 0.694 | task_loss 2.365 | contrastive_loss 0.257 | total 4003.4 | n_correct 2446.2 | ppl 7.53 | accuracy 61.103 | uer 17.97 | wer 19.731 | raw_wer 19.731 | bleu 18.89 | wps 1813.2 | wpb 4003.4 | bsz 141.8 | num_updates 17679 | best_bleu 18.89
2023-07-03 14:57:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17679 updates
2023-07-03 14:57:00 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 14:57:04 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 14:57:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt (epoch 12 @ 17679 updates, score 18.89) (writing took 8.920150429941714 seconds)
2023-07-03 14:57:09 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-07-03 14:57:09 | INFO | train | epoch 012 | loss 2.14 | trans_loss 3.446 | nll_loss 1.588 | w2v_ctc_loss 0.582 | task_loss 0.505 | contrastive_loss 0.162 | total 4138.65 | n_correct 2554.54 | ppl 3.01 | accuracy 61.724 | wps 13246.9 | ups 1.07 | wpb 12355.8 | bsz 458.5 | num_updates 17679 | lr 0.000106362 | gnorm 0.219 | clip 0 | loss_scale 32 | train_wall 1321 | gb_free 13.2 | wall 16100
2023-07-03 14:57:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 14:57:09 | INFO | fairseq.trainer | begin training epoch 13
2023-07-03 14:57:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 14:57:37 | INFO | train_inner | epoch 013:     21 / 1474 loss=2.14, trans_loss=3.448, nll_loss=1.592, w2v_ctc_loss=0.59, task_loss=0.526, contrastive_loss=0.095, total=4096.49, n_correct=2525.6, ppl=3.01, accuracy=61.653, wps=8954.6, ups=0.73, wpb=12243.5, bsz=443.1, num_updates=17700, lr=0.000106299, gnorm=0.219, clip=0, loss_scale=32, train_wall=90, gb_free=14.8, wall=16127
2023-07-03 14:59:08 | INFO | train_inner | epoch 013:    121 / 1474 loss=2.112, trans_loss=3.424, nll_loss=1.56, w2v_ctc_loss=0.563, task_loss=0.508, contrastive_loss=0.11, total=4160.97, n_correct=2602.1, ppl=2.95, accuracy=62.536, wps=13657.6, ups=1.1, wpb=12418.2, bsz=454.3, num_updates=17800, lr=0.000106, gnorm=0.215, clip=0, loss_scale=32, train_wall=90, gb_free=16.4, wall=16218
2023-07-03 15:00:39 | INFO | train_inner | epoch 013:    221 / 1474 loss=2.144, trans_loss=3.426, nll_loss=1.567, w2v_ctc_loss=0.568, task_loss=0.467, contrastive_loss=0.399, total=4212.08, n_correct=2627.63, ppl=2.96, accuracy=62.383, wps=13732.3, ups=1.1, wpb=12529.8, bsz=494.6, num_updates=17900, lr=0.000105703, gnorm=0.217, clip=0, loss_scale=32, train_wall=91, gb_free=14.9, wall=16310
2023-07-03 15:02:09 | INFO | train_inner | epoch 013:    321 / 1474 loss=2.114, trans_loss=3.429, nll_loss=1.565, w2v_ctc_loss=0.564, task_loss=0.525, contrastive_loss=0.091, total=4102.3, n_correct=2568.4, ppl=2.96, accuracy=62.609, wps=13583, ups=1.11, wpb=12230, bsz=441.1, num_updates=18000, lr=0.000105409, gnorm=0.219, clip=0, loss_scale=32, train_wall=90, gb_free=17.4, wall=16400
2023-07-03 15:02:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 15:02:37 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 2.189 | trans_loss 5.631 | nll_loss 2.914 | w2v_ctc_loss 0.671 | task_loss 2.365 | contrastive_loss 0.249 | total 4003.4 | n_correct 2441.8 | ppl 7.54 | accuracy 60.993 | uer 17.798 | wer 19.522 | raw_wer 19.522 | bleu 18.98 | wps 1967.8 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 18.98
2023-07-03 15:02:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-07-03 15:02:37 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_13_18000.pt
2023-07-03 15:02:39 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_13_18000.pt
2023-07-03 15:02:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 18.98) (writing took 10.228172849398106 seconds)
2023-07-03 15:04:17 | INFO | train_inner | epoch 013:    421 / 1474 loss=2.128, trans_loss=3.433, nll_loss=1.572, w2v_ctc_loss=0.571, task_loss=0.476, contrastive_loss=0.153, total=4177.29, n_correct=2610.22, ppl=2.97, accuracy=62.486, wps=9758.3, ups=0.78, wpb=12461.8, bsz=477.6, num_updates=18100, lr=0.000105118, gnorm=0.223, clip=0, loss_scale=32, train_wall=89, gb_free=17.6, wall=16527
2023-07-03 15:05:48 | INFO | train_inner | epoch 013:    521 / 1474 loss=2.131, trans_loss=3.434, nll_loss=1.572, w2v_ctc_loss=0.572, task_loss=0.491, contrastive_loss=0.202, total=4201.22, n_correct=2612.9, ppl=2.97, accuracy=62.194, wps=13786.9, ups=1.1, wpb=12536.9, bsz=478.4, num_updates=18200, lr=0.000104828, gnorm=0.218, clip=0, loss_scale=32, train_wall=90, gb_free=13.2, wall=16618
2023-07-03 15:07:18 | INFO | train_inner | epoch 013:    621 / 1474 loss=2.114, trans_loss=3.428, nll_loss=1.566, w2v_ctc_loss=0.564, task_loss=0.489, contrastive_loss=0.086, total=4161.98, n_correct=2601.87, ppl=2.96, accuracy=62.515, wps=13793.2, ups=1.11, wpb=12435.5, bsz=462.4, num_updates=18300, lr=0.000104542, gnorm=0.215, clip=0, loss_scale=32, train_wall=90, gb_free=16, wall=16708
2023-07-03 15:08:48 | INFO | train_inner | epoch 013:    721 / 1474 loss=2.127, trans_loss=3.435, nll_loss=1.574, w2v_ctc_loss=0.583, task_loss=0.56, contrastive_loss=0.085, total=4096.76, n_correct=2547.28, ppl=2.98, accuracy=62.178, wps=13576.3, ups=1.11, wpb=12226.1, bsz=426.8, num_updates=18400, lr=0.000104257, gnorm=0.219, clip=0, loss_scale=32, train_wall=90, gb_free=16.8, wall=16798
2023-07-03 15:10:19 | INFO | train_inner | epoch 013:    821 / 1474 loss=2.124, trans_loss=3.433, nll_loss=1.572, w2v_ctc_loss=0.57, task_loss=0.511, contrastive_loss=0.146, total=4121.73, n_correct=2562.22, ppl=2.97, accuracy=62.164, wps=13465.6, ups=1.09, wpb=12319.8, bsz=460, num_updates=18500, lr=0.000103975, gnorm=0.22, clip=0, loss_scale=32, train_wall=91, gb_free=15, wall=16890
2023-07-03 15:11:49 | INFO | train_inner | epoch 013:    921 / 1474 loss=2.12, trans_loss=3.436, nll_loss=1.577, w2v_ctc_loss=0.57, task_loss=0.514, contrastive_loss=0.097, total=4107.01, n_correct=2555.79, ppl=2.98, accuracy=62.23, wps=13630.7, ups=1.11, wpb=12264.1, bsz=444.7, num_updates=18600, lr=0.000103695, gnorm=0.22, clip=0, loss_scale=32, train_wall=90, gb_free=16.1, wall=16980
2023-07-03 15:13:19 | INFO | train_inner | epoch 013:   1021 / 1474 loss=2.131, trans_loss=3.432, nll_loss=1.575, w2v_ctc_loss=0.577, task_loss=0.533, contrastive_loss=0.164, total=4081.02, n_correct=2530.98, ppl=2.98, accuracy=62.018, wps=13642.4, ups=1.12, wpb=12208.8, bsz=440.1, num_updates=18700, lr=0.000103418, gnorm=0.218, clip=0, loss_scale=32, train_wall=89, gb_free=16.4, wall=17069
2023-07-03 15:14:48 | INFO | train_inner | epoch 013:   1121 / 1474 loss=2.123, trans_loss=3.431, nll_loss=1.57, w2v_ctc_loss=0.567, task_loss=0.497, contrastive_loss=0.141, total=4105.62, n_correct=2564.81, ppl=2.97, accuracy=62.471, wps=13749.9, ups=1.12, wpb=12265.4, bsz=458.9, num_updates=18800, lr=0.000103142, gnorm=0.219, clip=0, loss_scale=32, train_wall=89, gb_free=16.9, wall=17159
2023-07-03 15:16:18 | INFO | train_inner | epoch 013:   1221 / 1474 loss=2.131, trans_loss=3.443, nll_loss=1.583, w2v_ctc_loss=0.579, task_loss=0.538, contrastive_loss=0.089, total=4110.35, n_correct=2549.52, ppl=3, accuracy=62.027, wps=13629.4, ups=1.11, wpb=12287.7, bsz=442.6, num_updates=18900, lr=0.000102869, gnorm=0.222, clip=0, loss_scale=32, train_wall=90, gb_free=15.1, wall=17249
2023-07-03 15:17:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-03 15:17:49 | INFO | train_inner | epoch 013:   1322 / 1474 loss=2.121, trans_loss=3.433, nll_loss=1.575, w2v_ctc_loss=0.572, task_loss=0.51, contrastive_loss=0.091, total=4094.47, n_correct=2557.19, ppl=2.98, accuracy=62.455, wps=13424, ups=1.1, wpb=12231.7, bsz=450.2, num_updates=19000, lr=0.000102598, gnorm=0.22, clip=0, loss_scale=16, train_wall=91, gb_free=17.9, wall=17340
2023-07-03 15:19:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-03 15:19:20 | INFO | train_inner | epoch 013:   1423 / 1474 loss=2.122, trans_loss=3.439, nll_loss=1.578, w2v_ctc_loss=0.571, task_loss=0.511, contrastive_loss=0.081, total=4152, n_correct=2583.95, ppl=2.99, accuracy=62.234, wps=13658.1, ups=1.1, wpb=12395.6, bsz=455.1, num_updates=19100, lr=0.000102329, gnorm=0.219, clip=0, loss_scale=8, train_wall=90, gb_free=15.5, wall=17431
2023-07-03 15:20:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 15:20:33 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 2.184 | trans_loss 5.612 | nll_loss 2.898 | w2v_ctc_loss 0.677 | task_loss 2.365 | contrastive_loss 0.252 | total 4003.4 | n_correct 2449.1 | ppl 7.45 | accuracy 61.176 | uer 17.482 | wer 19.063 | raw_wer 19.063 | bleu 19.46 | wps 2014.9 | wpb 4003.4 | bsz 141.8 | num_updates 19151 | best_bleu 19.46
2023-07-03 15:20:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19151 updates
2023-07-03 15:20:33 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 15:20:38 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 15:20:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt (epoch 13 @ 19151 updates, score 19.46) (writing took 8.794035051018 seconds)
2023-07-03 15:20:42 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-07-03 15:20:42 | INFO | train | epoch 013 | loss 2.124 | trans_loss 3.432 | nll_loss 1.572 | w2v_ctc_loss 0.571 | task_loss 0.507 | contrastive_loss 0.139 | total 4136.12 | n_correct 2577.97 | ppl 2.97 | accuracy 62.328 | wps 12862.9 | ups 1.04 | wpb 12349.2 | bsz 457 | num_updates 19151 | lr 0.000102193 | gnorm 0.219 | clip 0 | loss_scale 8 | train_wall 1323 | gb_free 17.7 | wall 17513
2023-07-03 15:20:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 15:20:43 | INFO | fairseq.trainer | begin training epoch 14
2023-07-03 15:20:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 15:21:35 | INFO | train_inner | epoch 014:     49 / 1474 loss=2.105, trans_loss=3.412, nll_loss=1.548, w2v_ctc_loss=0.558, task_loss=0.462, contrastive_loss=0.103, total=4182.69, n_correct=2635.69, ppl=2.92, accuracy=63.014, wps=9248.9, ups=0.74, wpb=12500.6, bsz=483.4, num_updates=19200, lr=0.000102062, gnorm=0.216, clip=0, loss_scale=8, train_wall=89, gb_free=16.2, wall=17566
2023-07-03 15:23:05 | INFO | train_inner | epoch 014:    149 / 1474 loss=2.098, trans_loss=3.41, nll_loss=1.541, w2v_ctc_loss=0.553, task_loss=0.503, contrastive_loss=0.081, total=4086.4, n_correct=2587.38, ppl=2.91, accuracy=63.317, wps=13616.8, ups=1.11, wpb=12219, bsz=452.2, num_updates=19300, lr=0.000101797, gnorm=0.215, clip=0, loss_scale=8, train_wall=89, gb_free=17.1, wall=17656
2023-07-03 15:24:35 | INFO | train_inner | epoch 014:    249 / 1474 loss=2.113, trans_loss=3.422, nll_loss=1.556, w2v_ctc_loss=0.555, task_loss=0.531, contrastive_loss=0.217, total=4103.37, n_correct=2584.68, ppl=2.94, accuracy=62.989, wps=13604.8, ups=1.11, wpb=12220.3, bsz=441.1, num_updates=19400, lr=0.000101535, gnorm=0.219, clip=0, loss_scale=8, train_wall=89, gb_free=17.4, wall=17745
2023-07-03 15:26:04 | INFO | train_inner | epoch 014:    349 / 1474 loss=2.101, trans_loss=3.408, nll_loss=1.547, w2v_ctc_loss=0.555, task_loss=0.473, contrastive_loss=0.127, total=4168.35, n_correct=2630.57, ppl=2.92, accuracy=63.108, wps=13850.2, ups=1.12, wpb=12419.4, bsz=478.1, num_updates=19500, lr=0.000101274, gnorm=0.219, clip=0, loss_scale=8, train_wall=89, gb_free=16.5, wall=17835
2023-07-03 15:27:35 | INFO | train_inner | epoch 014:    449 / 1474 loss=2.104, trans_loss=3.417, nll_loss=1.553, w2v_ctc_loss=0.556, task_loss=0.498, contrastive_loss=0.102, total=4155.83, n_correct=2617.7, ppl=2.93, accuracy=62.989, wps=13722.8, ups=1.11, wpb=12381.6, bsz=460, num_updates=19600, lr=0.000101015, gnorm=0.218, clip=0, loss_scale=8, train_wall=90, gb_free=16.1, wall=17925
2023-07-03 15:29:05 | INFO | train_inner | epoch 014:    549 / 1474 loss=2.115, trans_loss=3.427, nll_loss=1.563, w2v_ctc_loss=0.566, task_loss=0.548, contrastive_loss=0.096, total=4064.87, n_correct=2544.9, ppl=2.95, accuracy=62.607, wps=13485.4, ups=1.11, wpb=12195.4, bsz=432.7, num_updates=19700, lr=0.000100759, gnorm=0.22, clip=0, loss_scale=8, train_wall=90, gb_free=17.9, wall=18016
2023-07-03 15:30:35 | INFO | train_inner | epoch 014:    649 / 1474 loss=2.117, trans_loss=3.425, nll_loss=1.562, w2v_ctc_loss=0.559, task_loss=0.5, contrastive_loss=0.181, total=4167.34, n_correct=2614.39, ppl=2.95, accuracy=62.735, wps=13788.1, ups=1.11, wpb=12436.1, bsz=461.7, num_updates=19800, lr=0.000100504, gnorm=0.219, clip=0, loss_scale=8, train_wall=90, gb_free=17.2, wall=18106
2023-07-03 15:32:06 | INFO | train_inner | epoch 014:    749 / 1474 loss=2.107, trans_loss=3.416, nll_loss=1.552, w2v_ctc_loss=0.56, task_loss=0.495, contrastive_loss=0.091, total=4142.94, n_correct=2609.76, ppl=2.93, accuracy=62.993, wps=13712.3, ups=1.11, wpb=12388, bsz=462.9, num_updates=19900, lr=0.000100251, gnorm=0.219, clip=0, loss_scale=8, train_wall=90, gb_free=16.6, wall=18196
2023-07-03 15:33:36 | INFO | train_inner | epoch 014:    849 / 1474 loss=2.116, trans_loss=3.414, nll_loss=1.552, w2v_ctc_loss=0.554, task_loss=0.479, contrastive_loss=0.241, total=4173.06, n_correct=2623.91, ppl=2.93, accuracy=62.877, wps=13753, ups=1.1, wpb=12457, bsz=478.7, num_updates=20000, lr=0.0001, gnorm=0.22, clip=0, loss_scale=8, train_wall=90, gb_free=13.1, wall=18287
2023-07-03 15:33:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 15:34:03 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 2.186 | trans_loss 5.604 | nll_loss 2.885 | w2v_ctc_loss 0.69 | task_loss 2.365 | contrastive_loss 0.261 | total 4003.4 | n_correct 2451.4 | ppl 7.39 | accuracy 61.233 | uer 17.275 | wer 19.097 | raw_wer 19.097 | bleu 19.51 | wps 2020.5 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.51
2023-07-03 15:34:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-07-03 15:34:03 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_14_20000.pt
2023-07-03 15:34:05 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_14_20000.pt
2023-07-03 15:34:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.51) (writing took 9.752994189970195 seconds)
tensor(0.0231, device='cuda:0')
tensor(0.0010, device='cuda:0')
2023-07-03 15:35:17 | INFO | train_inner | epoch 014:    949 / 1474 loss=1.433, trans_loss=5.38, nll_loss=2.729, w2v_ctc_loss=0.473, task_loss=1.468, contrastive_loss=0.233, total=4166.71, n_correct=2600.27, ppl=6.63, accuracy=62.406, wps=4208, ups=0.99, wpb=4251.2, bsz=159, num_updates=20100, lr=9.97509e-05, gnorm=0.342, clip=0, loss_scale=8, train_wall=64, gb_free=16.8, wall=18388
2023-07-03 15:36:22 | INFO | train_inner | epoch 014:   1049 / 1474 loss=1.42, trans_loss=5.437, nll_loss=2.758, w2v_ctc_loss=0.471, task_loss=1.546, contrastive_loss=0.181, total=4145.57, n_correct=2595.94, ppl=6.77, accuracy=62.62, wps=6420.2, ups=1.55, wpb=4145.6, bsz=150.6, num_updates=20200, lr=9.95037e-05, gnorm=0.34, clip=0, loss_scale=8, train_wall=64, gb_free=17.5, wall=18453
2023-07-03 15:37:26 | INFO | train_inner | epoch 014:   1149 / 1474 loss=1.437, trans_loss=5.449, nll_loss=2.775, w2v_ctc_loss=0.476, task_loss=1.44, contrastive_loss=0.729, total=4219.9, n_correct=2631.74, ppl=6.85, accuracy=62.365, wps=6580.4, ups=1.56, wpb=4219.9, bsz=162.6, num_updates=20300, lr=9.92583e-05, gnorm=0.339, clip=0, loss_scale=8, train_wall=64, gb_free=16.6, wall=18517
2023-07-03 15:38:29 | INFO | train_inner | epoch 014:   1249 / 1474 loss=1.423, trans_loss=5.457, nll_loss=2.783, w2v_ctc_loss=0.481, task_loss=1.759, contrastive_loss=0.106, total=4032.06, n_correct=2513.21, ppl=6.88, accuracy=62.331, wps=6381.7, ups=1.58, wpb=4032.1, bsz=137.2, num_updates=20400, lr=9.90148e-05, gnorm=0.348, clip=0, loss_scale=8, train_wall=63, gb_free=17.7, wall=18580
2023-07-03 15:39:32 | INFO | train_inner | epoch 014:   1349 / 1474 loss=1.416, trans_loss=5.436, nll_loss=2.758, w2v_ctc_loss=0.466, task_loss=1.436, contrastive_loss=0.139, total=4205.07, n_correct=2634.07, ppl=6.77, accuracy=62.64, wps=6646.7, ups=1.58, wpb=4205.1, bsz=158.7, num_updates=20500, lr=9.8773e-05, gnorm=0.342, clip=0, loss_scale=8, train_wall=63, gb_free=16.9, wall=18643
2023-07-03 15:40:36 | INFO | train_inner | epoch 014:   1449 / 1474 loss=1.422, trans_loss=5.447, nll_loss=2.773, w2v_ctc_loss=0.472, task_loss=1.512, contrastive_loss=0.214, total=4126.44, n_correct=2577.96, ppl=6.83, accuracy=62.474, wps=6490.9, ups=1.57, wpb=4126.4, bsz=152, num_updates=20600, lr=9.85329e-05, gnorm=0.34, clip=0, loss_scale=8, train_wall=63, gb_free=16.3, wall=18707
2023-07-03 15:40:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0231, device='cuda:7')
tensor(0.0010, device='cuda:7')
tensor(0.0231, device='cuda:4')
tensor(0.0010, device='cuda:4')
tensor(0.0231, device='cuda:6')
tensor(0.0010, device='cuda:6')
tensor(0.0231, device='cuda:1')
tensor(0.0010, device='cuda:1')
tensor(0.0231, device='cuda:5')
tensor(0.0010, device='cuda:5')
tensor(0.0231, device='cuda:3')
tensor(0.0010, device='cuda:3')
tensor(0.0231, device='cuda:2')
tensor(0.0010, device='cuda:2')
2023-07-03 15:41:20 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 2.181 | trans_loss 5.594 | nll_loss 2.876 | w2v_ctc_loss 0.688 | task_loss 2.365 | contrastive_loss 0.254 | total 4003.4 | n_correct 2456 | ppl 7.34 | accuracy 61.348 | uer 17.259 | wer 19.06 | raw_wer 19.06 | bleu 19.33 | wps 1889.7 | wpb 4003.4 | bsz 141.8 | num_updates 20625 | best_bleu 19.51
2023-07-03 15:41:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20625 updates
2023-07-03 15:41:20 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_19.3301.pt
2023-07-03 15:41:23 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_19.3301.pt
2023-07-03 15:41:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_19.3301.pt (epoch 14 @ 20625 updates, score 19.33) (writing took 5.617344839964062 seconds)
2023-07-03 15:41:26 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-07-03 15:41:26 | INFO | train | epoch 014 | loss 1.898 | trans_loss 3.817 | nll_loss 1.793 | w2v_ctc_loss 0.531 | task_loss 0.702 | contrastive_loss 0.165 | total 4138.65 | n_correct 2597.28 | ppl 3.46 | accuracy 62.757 | wps 10517.8 | ups 1.19 | wpb 8874.5 | bsz 329.7 | num_updates 20625 | lr 9.84732e-05 | gnorm 0.271 | clip 0 | loss_scale 8 | train_wall 1157 | gb_free 16.6 | wall 18757
2023-07-03 15:41:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 15:41:26 | INFO | fairseq.trainer | begin training epoch 15
2023-07-03 15:41:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 15:42:22 | INFO | train_inner | epoch 015:     75 / 1474 loss=1.413, trans_loss=5.41, nll_loss=2.723, w2v_ctc_loss=0.464, task_loss=1.521, contrastive_loss=0.317, total=4090.99, n_correct=2576.89, ppl=6.6, accuracy=62.989, wps=3849, ups=0.94, wpb=4091, bsz=150.4, num_updates=20700, lr=9.82946e-05, gnorm=0.341, clip=0, loss_scale=8, train_wall=63, gb_free=17, wall=18813
2023-07-03 15:43:26 | INFO | train_inner | epoch 015:    175 / 1474 loss=1.41, trans_loss=5.406, nll_loss=2.717, w2v_ctc_loss=0.469, task_loss=1.574, contrastive_loss=0.133, total=4115.56, n_correct=2598.3, ppl=6.58, accuracy=63.134, wps=6423.2, ups=1.56, wpb=4115.6, bsz=149.2, num_updates=20800, lr=9.80581e-05, gnorm=0.342, clip=0, loss_scale=8, train_wall=64, gb_free=17, wall=18877
2023-07-03 15:44:30 | INFO | train_inner | epoch 015:    275 / 1474 loss=1.407, trans_loss=5.4, nll_loss=2.711, w2v_ctc_loss=0.463, task_loss=1.47, contrastive_loss=0.117, total=4182.19, n_correct=2642.77, ppl=6.55, accuracy=63.191, wps=6531.3, ups=1.56, wpb=4182.2, bsz=155.2, num_updates=20900, lr=9.78232e-05, gnorm=0.338, clip=0, loss_scale=8, train_wall=64, gb_free=16.7, wall=18941
2023-07-03 15:45:34 | INFO | train_inner | epoch 015:    375 / 1474 loss=1.41, trans_loss=5.395, nll_loss=2.703, w2v_ctc_loss=0.467, task_loss=1.519, contrastive_loss=0.164, total=4172.52, n_correct=2640.08, ppl=6.51, accuracy=63.273, wps=6597, ups=1.58, wpb=4172.5, bsz=153.8, num_updates=21000, lr=9.759e-05, gnorm=0.34, clip=0, loss_scale=8, train_wall=63, gb_free=17, wall=19004
2023-07-03 15:46:37 | INFO | train_inner | epoch 015:    475 / 1474 loss=1.415, trans_loss=5.411, nll_loss=2.724, w2v_ctc_loss=0.463, task_loss=1.591, contrastive_loss=0.348, total=4076.84, n_correct=2565.64, ppl=6.61, accuracy=62.932, wps=6399.7, ups=1.57, wpb=4076.8, bsz=146.7, num_updates=21100, lr=9.73585e-05, gnorm=0.344, clip=0, loss_scale=8, train_wall=63, gb_free=17, wall=19068
2023-07-03 15:47:41 | INFO | train_inner | epoch 015:    575 / 1474 loss=1.41, trans_loss=5.405, nll_loss=2.718, w2v_ctc_loss=0.469, task_loss=1.547, contrastive_loss=0.171, total=4156.05, n_correct=2621.17, ppl=6.58, accuracy=63.069, wps=6543.7, ups=1.57, wpb=4156.1, bsz=151.4, num_updates=21200, lr=9.71286e-05, gnorm=0.339, clip=0, loss_scale=16, train_wall=63, gb_free=12.2, wall=19132
2023-07-03 15:48:45 | INFO | train_inner | epoch 015:    675 / 1474 loss=1.412, trans_loss=5.407, nll_loss=2.72, w2v_ctc_loss=0.469, task_loss=1.546, contrastive_loss=0.256, total=4118.87, n_correct=2599.14, ppl=6.59, accuracy=63.103, wps=6447.2, ups=1.57, wpb=4118.9, bsz=151.5, num_updates=21300, lr=9.69003e-05, gnorm=0.341, clip=0, loss_scale=16, train_wall=63, gb_free=17.1, wall=19196
2023-07-03 15:49:49 | INFO | train_inner | epoch 015:    775 / 1474 loss=1.414, trans_loss=5.413, nll_loss=2.728, w2v_ctc_loss=0.469, task_loss=1.524, contrastive_loss=0.135, total=4176.64, n_correct=2626.57, ppl=6.62, accuracy=62.887, wps=6540.3, ups=1.57, wpb=4176.6, bsz=152.6, num_updates=21400, lr=9.66736e-05, gnorm=0.343, clip=0, loss_scale=16, train_wall=63, gb_free=14.3, wall=19259
2023-07-03 15:50:52 | INFO | train_inner | epoch 015:    875 / 1474 loss=1.41, trans_loss=5.417, nll_loss=2.734, w2v_ctc_loss=0.472, task_loss=1.633, contrastive_loss=0.129, total=4056.99, n_correct=2548.07, ppl=6.65, accuracy=62.807, wps=6402.5, ups=1.58, wpb=4057, bsz=144, num_updates=21500, lr=9.64486e-05, gnorm=0.342, clip=0, loss_scale=16, train_wall=63, gb_free=17.5, wall=19323
2023-07-03 15:51:56 | INFO | train_inner | epoch 015:    975 / 1474 loss=1.415, trans_loss=5.405, nll_loss=2.718, w2v_ctc_loss=0.465, task_loss=1.503, contrastive_loss=0.295, total=4134.44, n_correct=2606.23, ppl=6.58, accuracy=63.037, wps=6502.5, ups=1.57, wpb=4134.4, bsz=152.4, num_updates=21600, lr=9.6225e-05, gnorm=0.337, clip=0, loss_scale=16, train_wall=63, gb_free=16.7, wall=19386
2023-07-03 15:53:00 | INFO | train_inner | epoch 015:   1075 / 1474 loss=1.425, trans_loss=5.418, nll_loss=2.737, w2v_ctc_loss=0.468, task_loss=1.42, contrastive_loss=0.613, total=4185.02, n_correct=2630.99, ppl=6.66, accuracy=62.867, wps=6520.4, ups=1.56, wpb=4185, bsz=162.1, num_updates=21700, lr=9.60031e-05, gnorm=0.339, clip=0, loss_scale=16, train_wall=64, gb_free=16.9, wall=19451
2023-07-03 15:54:03 | INFO | train_inner | epoch 015:   1175 / 1474 loss=1.406, trans_loss=5.394, nll_loss=2.707, w2v_ctc_loss=0.455, task_loss=1.348, contrastive_loss=0.221, total=4187.68, n_correct=2651.4, ppl=6.53, accuracy=63.314, wps=6658.7, ups=1.59, wpb=4187.7, bsz=164.9, num_updates=21800, lr=9.57826e-05, gnorm=0.334, clip=0, loss_scale=16, train_wall=62, gb_free=16.9, wall=19513
2023-07-03 15:55:06 | INFO | train_inner | epoch 015:   1275 / 1474 loss=1.411, trans_loss=5.411, nll_loss=2.727, w2v_ctc_loss=0.472, task_loss=1.567, contrastive_loss=0.129, total=4141.6, n_correct=2611.12, ppl=6.62, accuracy=63.046, wps=6540.5, ups=1.58, wpb=4141.6, bsz=150.5, num_updates=21900, lr=9.55637e-05, gnorm=0.339, clip=0, loss_scale=16, train_wall=63, gb_free=13.8, wall=19577
2023-07-03 15:56:10 | INFO | train_inner | epoch 015:   1375 / 1474 loss=1.41, trans_loss=5.411, nll_loss=2.725, w2v_ctc_loss=0.469, task_loss=1.575, contrastive_loss=0.107, total=4099.6, n_correct=2583.58, ppl=6.61, accuracy=63.02, wps=6453.9, ups=1.57, wpb=4099.6, bsz=146.6, num_updates=22000, lr=9.53463e-05, gnorm=0.341, clip=0, loss_scale=16, train_wall=63, gb_free=14.7, wall=19640
2023-07-03 15:56:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 15:56:35 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 2.178 | trans_loss 5.593 | nll_loss 2.871 | w2v_ctc_loss 0.678 | task_loss 2.365 | contrastive_loss 0.252 | total 4003.4 | n_correct 2461.7 | ppl 7.32 | accuracy 61.49 | uer 17.474 | wer 19.302 | raw_wer 19.302 | bleu 19.39 | wps 2052.3 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 19.51
2023-07-03 15:56:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-07-03 15:56:35 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_15_22000.pt
2023-07-03 15:56:38 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_15_22000.pt
2023-07-03 15:56:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.39) (writing took 6.814382418990135 seconds)
2023-07-03 15:57:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 15:58:13 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 2.17 | trans_loss 5.586 | nll_loss 2.863 | w2v_ctc_loss 0.661 | task_loss 2.365 | contrastive_loss 0.251 | total 4003.4 | n_correct 2456.4 | ppl 7.27 | accuracy 61.358 | uer 17.238 | wer 19.09 | raw_wer 19.09 | bleu 19.01 | wps 2053.4 | wpb 4003.4 | bsz 141.8 | num_updates 22099 | best_bleu 19.51
2023-07-03 15:58:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22099 updates
2023-07-03 15:58:13 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_19.0105.pt
2023-07-03 15:58:16 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_19.0105.pt
2023-07-03 15:58:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_19.0105.pt (epoch 15 @ 22099 updates, score 19.01) (writing took 5.566706191282719 seconds)
2023-07-03 15:58:19 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-07-03 15:58:19 | INFO | train | epoch 015 | loss 1.412 | trans_loss 5.407 | nll_loss 2.721 | w2v_ctc_loss 0.467 | task_loss 1.515 | contrastive_loss 0.231 | total 4138.65 | n_correct 2609.74 | ppl 6.59 | accuracy 63.058 | wps 6021.1 | ups 1.45 | wpb 4138.6 | bsz 152.8 | num_updates 22099 | lr 9.51325e-05 | gnorm 0.34 | clip 0 | loss_scale 16 | train_wall 932 | gb_free 17.2 | wall 19770
2023-07-03 15:58:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 15:58:19 | INFO | fairseq.trainer | begin training epoch 16
2023-07-03 15:58:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 15:58:28 | INFO | train_inner | epoch 016:      1 / 1474 loss=1.414, trans_loss=5.416, nll_loss=2.736, w2v_ctc_loss=0.468, task_loss=1.452, contrastive_loss=0.278, total=4149.9, n_correct=2612.9, ppl=6.66, accuracy=62.963, wps=2993.6, ups=0.72, wpb=4149.9, bsz=158.2, num_updates=22100, lr=9.51303e-05, gnorm=0.344, clip=0, loss_scale=16, train_wall=64, gb_free=17.6, wall=19779
2023-07-03 15:59:32 | INFO | train_inner | epoch 016:    101 / 1474 loss=1.396, trans_loss=5.362, nll_loss=2.662, w2v_ctc_loss=0.457, task_loss=1.458, contrastive_loss=0.163, total=4118.73, n_correct=2627.17, ppl=6.33, accuracy=63.786, wps=6474.3, ups=1.57, wpb=4118.7, bsz=157, num_updates=22200, lr=9.49158e-05, gnorm=0.34, clip=0, loss_scale=16, train_wall=63, gb_free=16.4, wall=19843
2023-07-03 16:00:36 | INFO | train_inner | epoch 016:    201 / 1474 loss=1.387, trans_loss=5.354, nll_loss=2.651, w2v_ctc_loss=0.447, task_loss=1.547, contrastive_loss=0.114, total=4106.45, n_correct=2624.64, ppl=6.28, accuracy=63.915, wps=6395.7, ups=1.56, wpb=4106.4, bsz=148.7, num_updates=22300, lr=9.47027e-05, gnorm=0.338, clip=0, loss_scale=16, train_wall=64, gb_free=16.6, wall=19907
2023-07-03 16:01:39 | INFO | train_inner | epoch 016:    301 / 1474 loss=1.41, trans_loss=5.38, nll_loss=2.687, w2v_ctc_loss=0.465, task_loss=1.493, contrastive_loss=0.263, total=4169.65, n_correct=2648.58, ppl=6.44, accuracy=63.52, wps=6572.5, ups=1.58, wpb=4169.6, bsz=154.9, num_updates=22400, lr=9.44911e-05, gnorm=0.344, clip=0, loss_scale=16, train_wall=63, gb_free=11.2, wall=19970
2023-07-03 16:02:43 | INFO | train_inner | epoch 016:    401 / 1474 loss=1.403, trans_loss=5.382, nll_loss=2.688, w2v_ctc_loss=0.462, task_loss=1.628, contrastive_loss=0.287, total=4063.79, n_correct=2578.42, ppl=6.45, accuracy=63.449, wps=6442.5, ups=1.59, wpb=4063.8, bsz=143.2, num_updates=22500, lr=9.42809e-05, gnorm=0.344, clip=0, loss_scale=16, train_wall=63, gb_free=13.1, wall=20033
2023-07-03 16:03:46 | INFO | train_inner | epoch 016:    501 / 1474 loss=1.403, trans_loss=5.375, nll_loss=2.682, w2v_ctc_loss=0.462, task_loss=1.456, contrastive_loss=0.175, total=4179.53, n_correct=2661.71, ppl=6.42, accuracy=63.684, wps=6550.9, ups=1.57, wpb=4179.5, bsz=159.8, num_updates=22600, lr=9.40721e-05, gnorm=0.339, clip=0, loss_scale=16, train_wall=63, gb_free=17.9, wall=20097
2023-07-03 16:04:50 | INFO | train_inner | epoch 016:    601 / 1474 loss=1.4, trans_loss=5.379, nll_loss=2.685, w2v_ctc_loss=0.461, task_loss=1.533, contrastive_loss=0.104, total=4121.37, n_correct=2618.42, ppl=6.43, accuracy=63.533, wps=6509.4, ups=1.58, wpb=4121.4, bsz=148.7, num_updates=22700, lr=9.38647e-05, gnorm=0.337, clip=0, loss_scale=16, train_wall=63, gb_free=17.9, wall=20160
2023-07-03 16:05:53 | INFO | train_inner | epoch 016:    701 / 1474 loss=1.401, trans_loss=5.381, nll_loss=2.688, w2v_ctc_loss=0.463, task_loss=1.55, contrastive_loss=0.11, total=4099.17, n_correct=2599.72, ppl=6.44, accuracy=63.421, wps=6494.6, ups=1.58, wpb=4099.2, bsz=148.7, num_updates=22800, lr=9.36586e-05, gnorm=0.341, clip=0, loss_scale=16, train_wall=63, gb_free=17, wall=20224
2023-07-03 16:06:56 | INFO | train_inner | epoch 016:    801 / 1474 loss=1.4, trans_loss=5.378, nll_loss=2.684, w2v_ctc_loss=0.452, task_loss=1.442, contrastive_loss=0.231, total=4184.53, n_correct=2652.39, ppl=6.43, accuracy=63.386, wps=6576.2, ups=1.57, wpb=4184.5, bsz=156.5, num_updates=22900, lr=9.34539e-05, gnorm=0.334, clip=0, loss_scale=16, train_wall=63, gb_free=13.7, wall=20287
2023-07-03 16:08:00 | INFO | train_inner | epoch 016:    901 / 1474 loss=1.403, trans_loss=5.382, nll_loss=2.691, w2v_ctc_loss=0.458, task_loss=1.49, contrastive_loss=0.215, total=4151.84, n_correct=2636.59, ppl=6.46, accuracy=63.504, wps=6491.7, ups=1.56, wpb=4151.8, bsz=153.5, num_updates=23000, lr=9.32505e-05, gnorm=0.341, clip=0, loss_scale=16, train_wall=63, gb_free=17, wall=20351
2023-07-03 16:09:04 | INFO | train_inner | epoch 016:   1001 / 1474 loss=1.407, trans_loss=5.395, nll_loss=2.706, w2v_ctc_loss=0.47, task_loss=1.568, contrastive_loss=0.206, total=4112.79, n_correct=2599.92, ppl=6.53, accuracy=63.215, wps=6441.9, ups=1.57, wpb=4112.8, bsz=149.8, num_updates=23100, lr=9.30484e-05, gnorm=0.34, clip=0, loss_scale=16, train_wall=63, gb_free=15.2, wall=20415
2023-07-03 16:10:08 | INFO | train_inner | epoch 016:   1101 / 1474 loss=1.406, trans_loss=5.399, nll_loss=2.712, w2v_ctc_loss=0.467, task_loss=1.623, contrastive_loss=0.162, total=4111.6, n_correct=2595.36, ppl=6.55, accuracy=63.123, wps=6446.4, ups=1.57, wpb=4111.6, bsz=147.8, num_updates=23200, lr=9.28477e-05, gnorm=0.34, clip=0, loss_scale=32, train_wall=63, gb_free=14.9, wall=20479
2023-07-03 16:11:12 | INFO | train_inner | epoch 016:   1201 / 1474 loss=1.413, trans_loss=5.401, nll_loss=2.716, w2v_ctc_loss=0.461, task_loss=2.78, contrastive_loss=0.377, total=4157.51, n_correct=2623.44, ppl=6.57, accuracy=63.101, wps=6477.5, ups=1.56, wpb=4157.5, bsz=153.3, num_updates=23300, lr=9.26482e-05, gnorm=0.349, clip=0, loss_scale=32, train_wall=64, gb_free=15.1, wall=20543
2023-07-03 16:12:16 | INFO | train_inner | epoch 016:   1301 / 1474 loss=1.414, trans_loss=5.4, nll_loss=2.715, w2v_ctc_loss=0.468, task_loss=2.059, contrastive_loss=0.344, total=4151.03, n_correct=2623.42, ppl=6.56, accuracy=63.199, wps=6515.8, ups=1.57, wpb=4151, bsz=157.2, num_updates=23400, lr=9.245e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=63, gb_free=16.8, wall=20607
2023-07-03 16:13:21 | INFO | train_inner | epoch 016:   1401 / 1474 loss=1.409, trans_loss=5.39, nll_loss=2.702, w2v_ctc_loss=0.467, task_loss=1.995, contrastive_loss=0.178, total=4201.47, n_correct=2657.64, ppl=6.51, accuracy=63.255, wps=6480.3, ups=1.54, wpb=4201.5, bsz=160.4, num_updates=23500, lr=9.22531e-05, gnorm=0.342, clip=0, loss_scale=32, train_wall=64, gb_free=16.2, wall=20671
2023-07-03 16:14:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 16:14:34 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 2.177 | trans_loss 5.58 | nll_loss 2.858 | w2v_ctc_loss 0.691 | task_loss 2.365 | contrastive_loss 0.255 | total 4003.4 | n_correct 2468.1 | ppl 7.25 | accuracy 61.65 | uer 17.466 | wer 19.03 | raw_wer 19.03 | bleu 19.53 | wps 2099.8 | wpb 4003.4 | bsz 141.8 | num_updates 23573 | best_bleu 19.53
2023-07-03 16:14:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23573 updates
2023-07-03 16:14:34 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 16:14:38 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 16:14:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt (epoch 16 @ 23573 updates, score 19.53) (writing took 8.579765937756747 seconds)
2023-07-03 16:14:43 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-07-03 16:14:43 | INFO | train | epoch 016 | loss 1.404 | trans_loss 5.383 | nll_loss 2.691 | w2v_ctc_loss 0.461 | task_loss 1.708 | contrastive_loss 0.227 | total 4138.65 | n_correct 2625.2 | ppl 6.46 | accuracy 63.431 | wps 6203.4 | ups 1.5 | wpb 4138.6 | bsz 152.8 | num_updates 23573 | lr 9.21102e-05 | gnorm 0.341 | clip 0 | loss_scale 32 | train_wall 933 | gb_free 15.6 | wall 20753
2023-07-03 16:14:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 16:14:43 | INFO | fairseq.trainer | begin training epoch 17
2023-07-03 16:14:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 16:15:08 | INFO | train_inner | epoch 017:     27 / 1474 loss=1.405, trans_loss=5.369, nll_loss=2.673, w2v_ctc_loss=0.455, task_loss=2.138, contrastive_loss=0.448, total=4145.04, n_correct=2639.96, ppl=6.38, accuracy=63.69, wps=3848.6, ups=0.93, wpb=4145, bsz=151.2, num_updates=23600, lr=9.20575e-05, gnorm=0.339, clip=0, loss_scale=32, train_wall=64, gb_free=15.8, wall=20779
2023-07-03 16:16:12 | INFO | train_inner | epoch 017:    127 / 1474 loss=1.392, trans_loss=5.344, nll_loss=2.64, w2v_ctc_loss=0.459, task_loss=2.159, contrastive_loss=0.121, total=4117.27, n_correct=2636.01, ppl=6.23, accuracy=64.023, wps=6452.6, ups=1.57, wpb=4117.3, bsz=148.1, num_updates=23700, lr=9.1863e-05, gnorm=0.336, clip=0, loss_scale=32, train_wall=63, gb_free=17.9, wall=20843
2023-07-03 16:17:16 | INFO | train_inner | epoch 017:    227 / 1474 loss=1.402, trans_loss=5.353, nll_loss=2.653, w2v_ctc_loss=0.454, task_loss=1.973, contrastive_loss=0.456, total=4159.6, n_correct=2660.26, ppl=6.29, accuracy=63.955, wps=6551.5, ups=1.58, wpb=4159.6, bsz=158.8, num_updates=23800, lr=9.16698e-05, gnorm=0.342, clip=0, loss_scale=32, train_wall=63, gb_free=17.1, wall=20907
2023-07-03 16:18:19 | INFO | train_inner | epoch 017:    327 / 1474 loss=1.4, trans_loss=5.35, nll_loss=2.648, w2v_ctc_loss=0.451, task_loss=2.081, contrastive_loss=0.461, total=4156.91, n_correct=2658.66, ppl=6.27, accuracy=63.958, wps=6568.8, ups=1.58, wpb=4156.9, bsz=152.9, num_updates=23900, lr=9.14779e-05, gnorm=0.334, clip=0, loss_scale=32, train_wall=63, gb_free=17.6, wall=20970
2023-07-03 16:19:23 | INFO | train_inner | epoch 017:    427 / 1474 loss=1.389, trans_loss=5.351, nll_loss=2.65, w2v_ctc_loss=0.454, task_loss=2.069, contrastive_loss=0.122, total=4146.43, n_correct=2653.86, ppl=6.28, accuracy=64.003, wps=6483.2, ups=1.56, wpb=4146.4, bsz=154, num_updates=24000, lr=9.12871e-05, gnorm=0.343, clip=0, loss_scale=32, train_wall=64, gb_free=16.7, wall=21034
2023-07-03 16:19:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 16:19:49 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 2.184 | trans_loss 5.588 | nll_loss 2.86 | w2v_ctc_loss 0.704 | task_loss 2.365 | contrastive_loss 0.257 | total 4003.4 | n_correct 2467.7 | ppl 7.26 | accuracy 61.64 | uer 17.344 | wer 19.116 | raw_wer 19.116 | bleu 19.5 | wps 1995.6 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 19.53
2023-07-03 16:19:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-07-03 16:19:49 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_17_24000.pt
2023-07-03 16:19:52 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_17_24000.pt
2023-07-03 16:19:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.5) (writing took 6.597837497945875 seconds)
2023-07-03 16:21:02 | INFO | train_inner | epoch 017:    527 / 1474 loss=1.401, trans_loss=5.358, nll_loss=2.659, w2v_ctc_loss=0.464, task_loss=2.184, contrastive_loss=0.207, total=4182.1, n_correct=2666.45, ppl=6.32, accuracy=63.759, wps=4242.4, ups=1.01, wpb=4182.1, bsz=153.9, num_updates=24100, lr=9.10975e-05, gnorm=0.34, clip=0, loss_scale=32, train_wall=65, gb_free=17, wall=21132
2023-07-03 16:22:06 | INFO | train_inner | epoch 017:    627 / 1474 loss=1.394, trans_loss=5.355, nll_loss=2.654, w2v_ctc_loss=0.453, task_loss=2.106, contrastive_loss=0.111, total=4167.27, n_correct=2661.45, ppl=6.3, accuracy=63.866, wps=6521.1, ups=1.56, wpb=4167.3, bsz=151.1, num_updates=24200, lr=9.09091e-05, gnorm=0.337, clip=0, loss_scale=32, train_wall=63, gb_free=11.3, wall=21196
2023-07-03 16:23:09 | INFO | train_inner | epoch 017:    727 / 1474 loss=1.403, trans_loss=5.371, nll_loss=2.676, w2v_ctc_loss=0.467, task_loss=2.069, contrastive_loss=0.203, total=4166.12, n_correct=2652.16, ppl=6.39, accuracy=63.66, wps=6526.1, ups=1.57, wpb=4166.1, bsz=154.1, num_updates=24300, lr=9.07218e-05, gnorm=0.343, clip=0, loss_scale=32, train_wall=63, gb_free=16.5, wall=21260
2023-07-03 16:24:14 | INFO | train_inner | epoch 017:    827 / 1474 loss=1.396, trans_loss=5.361, nll_loss=2.663, w2v_ctc_loss=0.46, task_loss=2.12, contrastive_loss=0.133, total=4091.64, n_correct=2612.67, ppl=6.33, accuracy=63.854, wps=6375.7, ups=1.56, wpb=4091.6, bsz=147.7, num_updates=24400, lr=9.05357e-05, gnorm=0.339, clip=0, loss_scale=32, train_wall=64, gb_free=17.4, wall=21324
2023-07-03 16:25:16 | INFO | train_inner | epoch 017:    927 / 1474 loss=1.397, trans_loss=5.364, nll_loss=2.668, w2v_ctc_loss=0.458, task_loss=2.06, contrastive_loss=0.132, total=4106.83, n_correct=2616.45, ppl=6.36, accuracy=63.71, wps=6556.5, ups=1.6, wpb=4106.8, bsz=152.3, num_updates=24500, lr=9.03508e-05, gnorm=0.342, clip=0, loss_scale=32, train_wall=62, gb_free=16, wall=21387
2023-07-03 16:26:19 | INFO | train_inner | epoch 017:   1027 / 1474 loss=1.396, trans_loss=5.358, nll_loss=2.661, w2v_ctc_loss=0.459, task_loss=2.057, contrastive_loss=0.136, total=4115.49, n_correct=2626.53, ppl=6.33, accuracy=63.821, wps=6522.7, ups=1.58, wpb=4115.5, bsz=152.9, num_updates=24600, lr=9.0167e-05, gnorm=0.344, clip=0, loss_scale=32, train_wall=63, gb_free=16.8, wall=21450
2023-07-03 16:27:22 | INFO | train_inner | epoch 017:   1127 / 1474 loss=1.39, trans_loss=5.356, nll_loss=2.656, w2v_ctc_loss=0.45, task_loss=2.176, contrastive_loss=0.111, total=4078.39, n_correct=2607.11, ppl=6.3, accuracy=63.925, wps=6492.9, ups=1.59, wpb=4078.4, bsz=146.9, num_updates=24700, lr=8.99843e-05, gnorm=0.341, clip=0, loss_scale=32, train_wall=62, gb_free=15.8, wall=21513
2023-07-03 16:28:26 | INFO | train_inner | epoch 017:   1227 / 1474 loss=1.409, trans_loss=5.377, nll_loss=2.687, w2v_ctc_loss=0.454, task_loss=2.027, contrastive_loss=0.597, total=4173.49, n_correct=2650.99, ppl=6.44, accuracy=63.52, wps=6492, ups=1.56, wpb=4173.5, bsz=161.9, num_updates=24800, lr=8.98027e-05, gnorm=0.341, clip=0, loss_scale=32, train_wall=64, gb_free=16.3, wall=21577
2023-07-03 16:29:30 | INFO | train_inner | epoch 017:   1327 / 1474 loss=1.401, trans_loss=5.367, nll_loss=2.672, w2v_ctc_loss=0.454, task_loss=2.075, contrastive_loss=0.274, total=4156.28, n_correct=2644.16, ppl=6.37, accuracy=63.618, wps=6539, ups=1.57, wpb=4156.3, bsz=154, num_updates=24900, lr=8.96221e-05, gnorm=0.343, clip=0, loss_scale=32, train_wall=63, gb_free=17.9, wall=21641
2023-07-03 16:30:34 | INFO | train_inner | epoch 017:   1427 / 1474 loss=1.391, trans_loss=5.362, nll_loss=2.666, w2v_ctc_loss=0.455, task_loss=2.109, contrastive_loss=0.12, total=4112.95, n_correct=2620.86, ppl=6.35, accuracy=63.722, wps=6418.8, ups=1.56, wpb=4112.9, bsz=151.6, num_updates=25000, lr=8.94427e-05, gnorm=0.34, clip=0, loss_scale=32, train_wall=64, gb_free=17, wall=21705
tensor(0.0231, device='cuda:0')
tensor(0.0010, device='cuda:0')
2023-07-03 16:31:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0231, device='cuda:4')
tensor(0.0010, device='cuda:4')
tensor(0.0231, device='cuda:6')
tensor(0.0010, device='cuda:6')
tensor(0.0231, device='cuda:1')
tensor(0.0010, device='cuda:1')
tensor(0.0231, device='cuda:5')
tensor(0.0010, device='cuda:5')
tensor(0.0231, device='cuda:7')
tensor(0.0010, device='cuda:7')
tensor(0.0231, device='cuda:3')
tensor(0.0010, device='cuda:3')
tensor(0.0231, device='cuda:2')
tensor(0.0010, device='cuda:2')
2023-07-03 16:31:32 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 2.175 | trans_loss 5.577 | nll_loss 2.854 | w2v_ctc_loss 0.69 | task_loss 2.365 | contrastive_loss 0.249 | total 4003.4 | n_correct 2463.5 | ppl 7.23 | accuracy 61.535 | uer 17.174 | wer 18.974 | raw_wer 18.974 | bleu 19.84 | wps 1942.7 | wpb 4003.4 | bsz 141.8 | num_updates 25047 | best_bleu 19.84
2023-07-03 16:31:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25047 updates
2023-07-03 16:31:32 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 16:31:36 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 16:31:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt (epoch 17 @ 25047 updates, score 19.84) (writing took 8.800124424044043 seconds)
2023-07-03 16:31:41 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-07-03 16:31:41 | INFO | train | epoch 017 | loss 1.397 | trans_loss 5.358 | nll_loss 2.66 | w2v_ctc_loss 0.457 | task_loss 2.092 | contrastive_loss 0.225 | total 4138.65 | n_correct 2641.52 | ppl 6.32 | accuracy 63.826 | wps 5991.7 | ups 1.45 | wpb 4138.6 | bsz 152.8 | num_updates 25047 | lr 8.93588e-05 | gnorm 0.34 | clip 0 | loss_scale 32 | train_wall 933 | gb_free 16.6 | wall 21771
2023-07-03 16:31:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 16:31:41 | INFO | fairseq.trainer | begin training epoch 18
2023-07-03 16:31:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 16:32:24 | INFO | train_inner | epoch 018:     53 / 1474 loss=1.394, trans_loss=5.35, nll_loss=2.65, w2v_ctc_loss=0.461, task_loss=2.135, contrastive_loss=0.14, total=4139.04, n_correct=2645.29, ppl=6.28, accuracy=63.911, wps=3776.6, ups=0.91, wpb=4139, bsz=151.7, num_updates=25100, lr=8.92644e-05, gnorm=0.338, clip=0, loss_scale=32, train_wall=65, gb_free=17.3, wall=21814
2023-07-03 16:33:27 | INFO | train_inner | epoch 018:    153 / 1474 loss=1.388, trans_loss=5.319, nll_loss=2.608, w2v_ctc_loss=0.44, task_loss=1.994, contrastive_loss=0.384, total=4154.85, n_correct=2676.24, ppl=6.1, accuracy=64.412, wps=6584.6, ups=1.58, wpb=4154.9, bsz=156.4, num_updates=25200, lr=8.90871e-05, gnorm=0.337, clip=0, loss_scale=32, train_wall=63, gb_free=16.9, wall=21877
2023-07-03 16:34:31 | INFO | train_inner | epoch 018:    253 / 1474 loss=1.383, trans_loss=5.313, nll_loss=2.602, w2v_ctc_loss=0.446, task_loss=2.029, contrastive_loss=0.122, total=4162.72, n_correct=2689.46, ppl=6.07, accuracy=64.608, wps=6515.4, ups=1.57, wpb=4162.7, bsz=156.5, num_updates=25300, lr=8.89108e-05, gnorm=0.335, clip=0, loss_scale=64, train_wall=63, gb_free=16.4, wall=21941
2023-07-03 16:35:34 | INFO | train_inner | epoch 018:    353 / 1474 loss=1.386, trans_loss=5.33, nll_loss=2.622, w2v_ctc_loss=0.447, task_loss=2.131, contrastive_loss=0.148, total=4161.22, n_correct=2671.99, ppl=6.16, accuracy=64.212, wps=6561.3, ups=1.58, wpb=4161.2, bsz=150.7, num_updates=25400, lr=8.87357e-05, gnorm=0.337, clip=0, loss_scale=64, train_wall=63, gb_free=14.7, wall=22005
2023-07-03 16:36:38 | INFO | train_inner | epoch 018:    453 / 1474 loss=1.393, trans_loss=5.345, nll_loss=2.643, w2v_ctc_loss=0.454, task_loss=2.228, contrastive_loss=0.333, total=4092.36, n_correct=2622.5, ppl=6.25, accuracy=64.083, wps=6395.6, ups=1.56, wpb=4092.4, bsz=147.7, num_updates=25500, lr=8.85615e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=64, gb_free=16.9, wall=22069
2023-07-03 16:37:42 | INFO | train_inner | epoch 018:    553 / 1474 loss=1.38, trans_loss=5.314, nll_loss=2.604, w2v_ctc_loss=0.442, task_loss=1.876, contrastive_loss=0.147, total=4206.45, n_correct=2715.53, ppl=6.08, accuracy=64.556, wps=6628.8, ups=1.58, wpb=4206.4, bsz=164.5, num_updates=25600, lr=8.83883e-05, gnorm=0.336, clip=0, loss_scale=64, train_wall=63, gb_free=17.9, wall=22132
2023-07-03 16:38:45 | INFO | train_inner | epoch 018:    653 / 1474 loss=1.397, trans_loss=5.354, nll_loss=2.655, w2v_ctc_loss=0.455, task_loss=2.162, contrastive_loss=0.283, total=4097.96, n_correct=2618.39, ppl=6.3, accuracy=63.895, wps=6420.6, ups=1.57, wpb=4098, bsz=149.3, num_updates=25700, lr=8.82162e-05, gnorm=0.349, clip=0, loss_scale=64, train_wall=63, gb_free=12.7, wall=22196
2023-07-03 16:39:50 | INFO | train_inner | epoch 018:    753 / 1474 loss=1.4, trans_loss=5.347, nll_loss=2.648, w2v_ctc_loss=0.457, task_loss=1.996, contrastive_loss=0.465, total=4208.5, n_correct=2695.13, ppl=6.27, accuracy=64.04, wps=6560.8, ups=1.56, wpb=4208.5, bsz=161.3, num_updates=25800, lr=8.80451e-05, gnorm=0.337, clip=0, loss_scale=64, train_wall=64, gb_free=16.4, wall=22260
2023-07-03 16:40:53 | INFO | train_inner | epoch 018:    853 / 1474 loss=1.385, trans_loss=5.336, nll_loss=2.631, w2v_ctc_loss=0.449, task_loss=2.107, contrastive_loss=0.103, total=4166.07, n_correct=2676.41, ppl=6.19, accuracy=64.243, wps=6544.1, ups=1.57, wpb=4166.1, bsz=151.2, num_updates=25900, lr=8.7875e-05, gnorm=0.338, clip=0, loss_scale=64, train_wall=63, gb_free=16.5, wall=22324
2023-07-03 16:41:56 | INFO | train_inner | epoch 018:    953 / 1474 loss=1.386, trans_loss=5.327, nll_loss=2.621, w2v_ctc_loss=0.444, task_loss=1.94, contrastive_loss=0.144, total=4141.27, n_correct=2662.14, ppl=6.15, accuracy=64.283, wps=6636.6, ups=1.6, wpb=4141.3, bsz=158, num_updates=26000, lr=8.77058e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=62, gb_free=16.2, wall=22386
2023-07-03 16:41:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 16:42:23 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 2.166 | trans_loss 5.575 | nll_loss 2.851 | w2v_ctc_loss 0.663 | task_loss 2.365 | contrastive_loss 0.246 | total 4003.4 | n_correct 2472.5 | ppl 7.21 | accuracy 61.76 | uer 17.174 | wer 18.776 | raw_wer 18.776 | bleu 19.96 | wps 2036 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 19.96
2023-07-03 16:42:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-07-03 16:42:23 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_18_26000.pt
2023-07-03 16:42:25 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_18_26000.pt
2023-07-03 16:42:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 19.96) (writing took 9.510834919288754 seconds)
2023-07-03 16:43:37 | INFO | train_inner | epoch 018:   1053 / 1474 loss=1.387, trans_loss=5.34, nll_loss=2.638, w2v_ctc_loss=0.447, task_loss=2.173, contrastive_loss=0.124, total=4134.55, n_correct=2648.56, ppl=6.22, accuracy=64.059, wps=4078.6, ups=0.99, wpb=4134.6, bsz=150.4, num_updates=26100, lr=8.75376e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=64, gb_free=16.6, wall=22488
2023-07-03 16:44:40 | INFO | train_inner | epoch 018:   1153 / 1474 loss=1.392, trans_loss=5.334, nll_loss=2.631, w2v_ctc_loss=0.451, task_loss=1.998, contrastive_loss=0.337, total=4157.63, n_correct=2670.96, ppl=6.19, accuracy=64.242, wps=6544.5, ups=1.57, wpb=4157.6, bsz=157, num_updates=26200, lr=8.73704e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=63, gb_free=17.2, wall=22551
2023-07-03 16:45:44 | INFO | train_inner | epoch 018:   1253 / 1474 loss=1.391, trans_loss=5.352, nll_loss=2.652, w2v_ctc_loss=0.452, task_loss=2.259, contrastive_loss=0.114, total=4085.66, n_correct=2611.46, ppl=6.29, accuracy=63.918, wps=6455.2, ups=1.58, wpb=4085.7, bsz=143.3, num_updates=26300, lr=8.72041e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=63, gb_free=17.6, wall=22615
2023-07-03 16:46:47 | INFO | train_inner | epoch 018:   1353 / 1474 loss=1.396, trans_loss=5.36, nll_loss=2.665, w2v_ctc_loss=0.46, task_loss=2.237, contrastive_loss=0.164, total=4065.6, n_correct=2594.61, ppl=6.34, accuracy=63.819, wps=6436.3, ups=1.58, wpb=4065.6, bsz=145.6, num_updates=26400, lr=8.70388e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=63, gb_free=13.5, wall=22678
2023-07-03 16:47:52 | INFO | train_inner | epoch 018:   1453 / 1474 loss=1.391, trans_loss=5.353, nll_loss=2.656, w2v_ctc_loss=0.456, task_loss=2.186, contrastive_loss=0.132, total=4122.48, n_correct=2631.88, ppl=6.3, accuracy=63.842, wps=6380.9, ups=1.55, wpb=4122.5, bsz=149.7, num_updates=26500, lr=8.68744e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=64, gb_free=17.3, wall=22742
2023-07-03 16:48:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 16:48:30 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 2.178 | trans_loss 5.57 | nll_loss 2.848 | w2v_ctc_loss 0.705 | task_loss 2.365 | contrastive_loss 0.257 | total 4003.4 | n_correct 2470.6 | ppl 7.2 | accuracy 61.713 | uer 17.302 | wer 19.078 | raw_wer 19.078 | bleu 19.56 | wps 2157.4 | wpb 4003.4 | bsz 141.8 | num_updates 26521 | best_bleu 19.96
2023-07-03 16:48:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26521 updates
2023-07-03 16:48:30 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_19.5600.pt
2023-07-03 16:48:33 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_19.5600.pt
2023-07-03 16:48:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_19.5600.pt (epoch 18 @ 26521 updates, score 19.56) (writing took 5.6262065400369465 seconds)
2023-07-03 16:48:36 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-07-03 16:48:36 | INFO | train | epoch 018 | loss 1.39 | trans_loss 5.338 | nll_loss 2.634 | w2v_ctc_loss 0.45 | task_loss 2.092 | contrastive_loss 0.221 | total 4138.65 | n_correct 2654.87 | ppl 6.21 | accuracy 64.148 | wps 6007.6 | ups 1.45 | wpb 4138.6 | bsz 152.8 | num_updates 26521 | lr 8.684e-05 | gnorm 0.341 | clip 0 | loss_scale 64 | train_wall 933 | gb_free 16.1 | wall 22787
2023-07-03 16:48:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 16:48:36 | INFO | fairseq.trainer | begin training epoch 19
2023-07-03 16:48:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 16:49:35 | INFO | train_inner | epoch 019:     79 / 1474 loss=1.387, trans_loss=5.314, nll_loss=2.603, w2v_ctc_loss=0.448, task_loss=2.098, contrastive_loss=0.241, total=4101.48, n_correct=2645.24, ppl=6.07, accuracy=64.495, wps=3973, ups=0.97, wpb=4101.5, bsz=148.5, num_updates=26600, lr=8.6711e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=63, gb_free=17.3, wall=22846
2023-07-03 16:50:39 | INFO | train_inner | epoch 019:    179 / 1474 loss=1.383, trans_loss=5.306, nll_loss=2.594, w2v_ctc_loss=0.453, task_loss=1.948, contrastive_loss=0.213, total=4227.39, n_correct=2735.58, ppl=6.04, accuracy=64.711, wps=6592.8, ups=1.56, wpb=4227.4, bsz=162.4, num_updates=26700, lr=8.65485e-05, gnorm=0.336, clip=0, loss_scale=64, train_wall=64, gb_free=15.8, wall=22910
2023-07-03 16:51:43 | INFO | train_inner | epoch 019:    279 / 1474 loss=1.375, trans_loss=5.297, nll_loss=2.58, w2v_ctc_loss=0.444, task_loss=2.063, contrastive_loss=0.104, total=4186.65, n_correct=2712.19, ppl=5.98, accuracy=64.782, wps=6546.5, ups=1.56, wpb=4186.6, bsz=153.2, num_updates=26800, lr=8.63868e-05, gnorm=0.331, clip=0, loss_scale=64, train_wall=64, gb_free=14.1, wall=22974
2023-07-03 16:52:47 | INFO | train_inner | epoch 019:    379 / 1474 loss=1.385, trans_loss=5.309, nll_loss=2.598, w2v_ctc_loss=0.442, task_loss=2.077, contrastive_loss=0.323, total=4165.84, n_correct=2688.71, ppl=6.05, accuracy=64.542, wps=6536, ups=1.57, wpb=4165.8, bsz=155, num_updates=26900, lr=8.62261e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=63, gb_free=16.2, wall=23037
2023-07-03 16:53:50 | INFO | train_inner | epoch 019:    479 / 1474 loss=1.38, trans_loss=5.314, nll_loss=2.604, w2v_ctc_loss=0.446, task_loss=2.13, contrastive_loss=0.132, total=4122.98, n_correct=2661.33, ppl=6.08, accuracy=64.549, wps=6494.2, ups=1.58, wpb=4123, bsz=151.3, num_updates=27000, lr=8.60663e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=63, gb_free=17.3, wall=23101
2023-07-03 16:54:54 | INFO | train_inner | epoch 019:    579 / 1474 loss=1.381, trans_loss=5.308, nll_loss=2.596, w2v_ctc_loss=0.441, task_loss=2.058, contrastive_loss=0.263, total=4121.66, n_correct=2663.6, ppl=6.05, accuracy=64.624, wps=6437.7, ups=1.56, wpb=4121.7, bsz=152.2, num_updates=27100, lr=8.59074e-05, gnorm=0.336, clip=0, loss_scale=64, train_wall=64, gb_free=17, wall=23165
2023-07-03 16:55:58 | INFO | train_inner | epoch 019:    679 / 1474 loss=1.378, trans_loss=5.307, nll_loss=2.597, w2v_ctc_loss=0.436, task_loss=1.891, contrastive_loss=0.121, total=4205.65, n_correct=2718.05, ppl=6.05, accuracy=64.629, wps=6542.3, ups=1.56, wpb=4205.6, bsz=161.5, num_updates=27200, lr=8.57493e-05, gnorm=0.333, clip=0, loss_scale=64, train_wall=64, gb_free=16.3, wall=23229
2023-07-03 16:57:02 | INFO | train_inner | epoch 019:    779 / 1474 loss=1.38, trans_loss=5.318, nll_loss=2.609, w2v_ctc_loss=0.449, task_loss=2.161, contrastive_loss=0.126, total=4120.36, n_correct=2653.25, ppl=6.1, accuracy=64.394, wps=6449.3, ups=1.57, wpb=4120.4, bsz=149.3, num_updates=27300, lr=8.55921e-05, gnorm=0.335, clip=0, loss_scale=128, train_wall=63, gb_free=14.1, wall=23293
2023-07-03 16:58:06 | INFO | train_inner | epoch 019:    879 / 1474 loss=1.386, trans_loss=5.326, nll_loss=2.62, w2v_ctc_loss=0.45, task_loss=2.086, contrastive_loss=0.126, total=4176.52, n_correct=2685.13, ppl=6.15, accuracy=64.291, wps=6549.3, ups=1.57, wpb=4176.5, bsz=154.9, num_updates=27400, lr=8.54358e-05, gnorm=0.336, clip=0, loss_scale=128, train_wall=63, gb_free=17.1, wall=23357
2023-07-03 16:58:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-03 16:59:11 | INFO | train_inner | epoch 019:    980 / 1474 loss=1.392, trans_loss=5.336, nll_loss=2.634, w2v_ctc_loss=0.447, task_loss=2.19, contrastive_loss=0.455, total=4065.32, n_correct=2610.76, ppl=6.21, accuracy=64.22, wps=6228.4, ups=1.53, wpb=4065.3, bsz=149.1, num_updates=27500, lr=8.52803e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=65, gb_free=16.4, wall=23422
2023-07-03 17:00:15 | INFO | train_inner | epoch 019:   1080 / 1474 loss=1.385, trans_loss=5.339, nll_loss=2.637, w2v_ctc_loss=0.445, task_loss=2.199, contrastive_loss=0.2, total=4042.73, n_correct=2590.91, ppl=6.22, accuracy=64.088, wps=6338.9, ups=1.57, wpb=4042.7, bsz=147, num_updates=27600, lr=8.51257e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=63, gb_free=17.4, wall=23486
2023-07-03 17:00:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-03 17:01:20 | INFO | train_inner | epoch 019:   1181 / 1474 loss=1.389, trans_loss=5.336, nll_loss=2.633, w2v_ctc_loss=0.451, task_loss=2.199, contrastive_loss=0.136, total=4114.84, n_correct=2637.21, ppl=6.2, accuracy=64.09, wps=6328.9, ups=1.54, wpb=4114.8, bsz=148.9, num_updates=27700, lr=8.49719e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=65, gb_free=15.1, wall=23551
2023-07-03 17:02:24 | INFO | train_inner | epoch 019:   1281 / 1474 loss=1.388, trans_loss=5.335, nll_loss=2.632, w2v_ctc_loss=0.445, task_loss=2.133, contrastive_loss=0.156, total=4141.89, n_correct=2658.39, ppl=6.2, accuracy=64.183, wps=6495.1, ups=1.57, wpb=4141.9, bsz=150.1, num_updates=27800, lr=8.48189e-05, gnorm=0.341, clip=0, loss_scale=32, train_wall=63, gb_free=15.9, wall=23615
2023-07-03 17:03:29 | INFO | train_inner | epoch 019:   1381 / 1474 loss=1.386, trans_loss=5.329, nll_loss=2.625, w2v_ctc_loss=0.45, task_loss=2.138, contrastive_loss=0.131, total=4133.26, n_correct=2654.83, ppl=6.17, accuracy=64.231, wps=6402.9, ups=1.55, wpb=4133.3, bsz=150.5, num_updates=27900, lr=8.46668e-05, gnorm=0.348, clip=0, loss_scale=32, train_wall=64, gb_free=16.4, wall=23679
2023-07-03 17:04:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 17:04:57 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 2.178 | trans_loss 5.571 | nll_loss 2.851 | w2v_ctc_loss 0.705 | task_loss 2.365 | contrastive_loss 0.262 | total 4003.4 | n_correct 2466.5 | ppl 7.22 | accuracy 61.61 | uer 17.071 | wer 18.862 | raw_wer 18.862 | bleu 19.82 | wps 1854.5 | wpb 4003.4 | bsz 141.8 | num_updates 27993 | best_bleu 19.96
2023-07-03 17:04:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27993 updates
2023-07-03 17:04:57 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_19.8206.pt
2023-07-03 17:04:59 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_19.8206.pt
2023-07-03 17:05:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_19.8206.pt (epoch 19 @ 27993 updates, score 19.82) (writing took 5.460665643215179 seconds)
2023-07-03 17:05:02 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-07-03 17:05:02 | INFO | train | epoch 019 | loss 1.384 | trans_loss 5.319 | nll_loss 2.611 | w2v_ctc_loss 0.446 | task_loss 2.1 | contrastive_loss 0.194 | total 4135.77 | n_correct 2664.67 | ppl 6.11 | accuracy 64.43 | wps 6172.7 | ups 1.49 | wpb 4135.8 | bsz 152.3 | num_updates 27993 | lr 8.4526e-05 | gnorm 0.339 | clip 0 | loss_scale 32 | train_wall 937 | gb_free 17.5 | wall 23773
2023-07-03 17:05:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 17:05:03 | INFO | fairseq.trainer | begin training epoch 20
2023-07-03 17:05:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 17:05:16 | INFO | train_inner | epoch 020:      7 / 1474 loss=1.386, trans_loss=5.321, nll_loss=2.615, w2v_ctc_loss=0.447, task_loss=2.116, contrastive_loss=0.3, total=4119.08, n_correct=2654.43, ppl=6.13, accuracy=64.442, wps=3848.3, ups=0.93, wpb=4119.1, bsz=152.1, num_updates=28000, lr=8.45154e-05, gnorm=0.342, clip=0, loss_scale=32, train_wall=63, gb_free=16.5, wall=23786
2023-07-03 17:05:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 17:05:44 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 2.17 | trans_loss 5.57 | nll_loss 2.848 | w2v_ctc_loss 0.681 | task_loss 2.365 | contrastive_loss 0.257 | total 4003.4 | n_correct 2473 | ppl 7.2 | accuracy 61.772 | uer 16.869 | wer 18.691 | raw_wer 18.691 | bleu 20.16 | wps 1802.6 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.16
2023-07-03 17:05:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-07-03 17:05:44 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_20_28000.pt
2023-07-03 17:05:46 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_20_28000.pt
2023-07-03 17:05:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 20.16) (writing took 9.6028314079158 seconds)
2023-07-03 17:06:58 | INFO | train_inner | epoch 020:    107 / 1474 loss=1.37, trans_loss=5.279, nll_loss=2.558, w2v_ctc_loss=0.435, task_loss=2.013, contrastive_loss=0.14, total=4195.03, n_correct=2732.95, ppl=5.89, accuracy=65.147, wps=4105.4, ups=0.98, wpb=4195, bsz=156.8, num_updates=28100, lr=8.43649e-05, gnorm=0.337, clip=0, loss_scale=32, train_wall=63, gb_free=15.3, wall=23889
2023-07-03 17:08:02 | INFO | train_inner | epoch 020:    207 / 1474 loss=1.377, trans_loss=5.293, nll_loss=2.577, w2v_ctc_loss=0.44, task_loss=2.172, contrastive_loss=0.248, total=4154.14, n_correct=2699.39, ppl=5.97, accuracy=64.981, wps=6462.3, ups=1.56, wpb=4154.1, bsz=150.5, num_updates=28200, lr=8.42152e-05, gnorm=0.343, clip=0, loss_scale=32, train_wall=64, gb_free=17.4, wall=23953
2023-07-03 17:09:05 | INFO | train_inner | epoch 020:    307 / 1474 loss=1.374, trans_loss=5.28, nll_loss=2.561, w2v_ctc_loss=0.44, task_loss=1.888, contrastive_loss=0.126, total=4188.05, n_correct=2722.44, ppl=5.9, accuracy=65.005, wps=6607.6, ups=1.58, wpb=4188.1, bsz=163.1, num_updates=28300, lr=8.40663e-05, gnorm=0.339, clip=0, loss_scale=32, train_wall=63, gb_free=15.7, wall=24016
2023-07-03 17:10:09 | INFO | train_inner | epoch 020:    407 / 1474 loss=1.369, trans_loss=5.287, nll_loss=2.569, w2v_ctc_loss=0.435, task_loss=2.129, contrastive_loss=0.12, total=4115.16, n_correct=2673.17, ppl=5.93, accuracy=64.959, wps=6476.5, ups=1.57, wpb=4115.2, bsz=148.5, num_updates=28400, lr=8.39181e-05, gnorm=0.337, clip=0, loss_scale=32, train_wall=63, gb_free=15.7, wall=24080
2023-07-03 17:11:12 | INFO | train_inner | epoch 020:    507 / 1474 loss=1.382, trans_loss=5.308, nll_loss=2.596, w2v_ctc_loss=0.439, task_loss=2.146, contrastive_loss=0.299, total=4108.46, n_correct=2654.95, ppl=6.05, accuracy=64.622, wps=6473.9, ups=1.58, wpb=4108.5, bsz=150.2, num_updates=28500, lr=8.37708e-05, gnorm=0.344, clip=0, loss_scale=32, train_wall=63, gb_free=16.6, wall=24143
2023-07-03 17:12:16 | INFO | train_inner | epoch 020:    607 / 1474 loss=1.382, trans_loss=5.306, nll_loss=2.593, w2v_ctc_loss=0.443, task_loss=2.198, contrastive_loss=0.312, total=4094.9, n_correct=2645.62, ppl=6.04, accuracy=64.608, wps=6418.5, ups=1.57, wpb=4094.9, bsz=148, num_updates=28600, lr=8.36242e-05, gnorm=0.342, clip=0, loss_scale=32, train_wall=63, gb_free=12.4, wall=24207
2023-07-03 17:13:20 | INFO | train_inner | epoch 020:    707 / 1474 loss=1.382, trans_loss=5.307, nll_loss=2.596, w2v_ctc_loss=0.448, task_loss=2.086, contrastive_loss=0.11, total=4140.23, n_correct=2676.58, ppl=6.05, accuracy=64.648, wps=6506.5, ups=1.57, wpb=4140.2, bsz=150.3, num_updates=28700, lr=8.34784e-05, gnorm=0.338, clip=0, loss_scale=32, train_wall=63, gb_free=16.4, wall=24271
2023-07-03 17:14:23 | INFO | train_inner | epoch 020:    807 / 1474 loss=1.374, trans_loss=5.299, nll_loss=2.586, w2v_ctc_loss=0.442, task_loss=2.072, contrastive_loss=0.115, total=4140.66, n_correct=2681.95, ppl=6, accuracy=64.771, wps=6561.5, ups=1.58, wpb=4140.7, bsz=152.8, num_updates=28800, lr=8.33333e-05, gnorm=0.34, clip=0, loss_scale=32, train_wall=63, gb_free=17.6, wall=24334
2023-07-03 17:15:28 | INFO | train_inner | epoch 020:    907 / 1474 loss=1.399, trans_loss=5.32, nll_loss=2.614, w2v_ctc_loss=0.444, task_loss=1.998, contrastive_loss=0.705, total=4157.15, n_correct=2679.13, ppl=6.12, accuracy=64.446, wps=6428.3, ups=1.55, wpb=4157.1, bsz=161.3, num_updates=28900, lr=8.3189e-05, gnorm=0.34, clip=0, loss_scale=32, train_wall=64, gb_free=17.8, wall=24398
2023-07-03 17:16:32 | INFO | train_inner | epoch 020:   1007 / 1474 loss=1.376, trans_loss=5.302, nll_loss=2.589, w2v_ctc_loss=0.436, task_loss=2.075, contrastive_loss=0.126, total=4171.86, n_correct=2699.72, ppl=6.02, accuracy=64.713, wps=6528.9, ups=1.56, wpb=4171.9, bsz=154.3, num_updates=29000, lr=8.30455e-05, gnorm=0.334, clip=0, loss_scale=32, train_wall=63, gb_free=16.2, wall=24462
2023-07-03 17:17:35 | INFO | train_inner | epoch 020:   1107 / 1474 loss=1.39, trans_loss=5.317, nll_loss=2.61, w2v_ctc_loss=0.445, task_loss=2.014, contrastive_loss=0.399, total=4162.96, n_correct=2685.17, ppl=6.11, accuracy=64.501, wps=6587.8, ups=1.58, wpb=4163, bsz=157.5, num_updates=29100, lr=8.29027e-05, gnorm=0.338, clip=0, loss_scale=32, train_wall=63, gb_free=17.2, wall=24526
2023-07-03 17:18:38 | INFO | train_inner | epoch 020:   1207 / 1474 loss=1.377, trans_loss=5.309, nll_loss=2.599, w2v_ctc_loss=0.449, task_loss=2.283, contrastive_loss=0.106, total=4033.74, n_correct=2603.21, ppl=6.06, accuracy=64.536, wps=6362.6, ups=1.58, wpb=4033.7, bsz=142.6, num_updates=29200, lr=8.27606e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=63, gb_free=17.4, wall=24589
2023-07-03 17:19:43 | INFO | train_inner | epoch 020:   1307 / 1474 loss=1.377, trans_loss=5.316, nll_loss=2.61, w2v_ctc_loss=0.444, task_loss=2.21, contrastive_loss=0.112, total=4124.42, n_correct=2658.73, ppl=6.1, accuracy=64.463, wps=6387.2, ups=1.55, wpb=4124.4, bsz=148.5, num_updates=29300, lr=8.26192e-05, gnorm=0.341, clip=0, loss_scale=32, train_wall=64, gb_free=16.3, wall=24654
2023-07-03 17:20:47 | INFO | train_inner | epoch 020:   1407 / 1474 loss=1.378, trans_loss=5.313, nll_loss=2.605, w2v_ctc_loss=0.443, task_loss=2.232, contrastive_loss=0.112, total=4114.1, n_correct=2652.08, ppl=6.08, accuracy=64.463, wps=6442.3, ups=1.57, wpb=4114.1, bsz=146.8, num_updates=29400, lr=8.24786e-05, gnorm=0.338, clip=0, loss_scale=32, train_wall=63, gb_free=14.7, wall=24717
2023-07-03 17:21:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 17:21:53 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 2.173 | trans_loss 5.563 | nll_loss 2.839 | w2v_ctc_loss 0.698 | task_loss 2.365 | contrastive_loss 0.252 | total 4003.4 | n_correct 2471.8 | ppl 7.16 | accuracy 61.743 | uer 17.371 | wer 19.056 | raw_wer 19.056 | bleu 19.88 | wps 2224 | wpb 4003.4 | bsz 141.8 | num_updates 29467 | best_bleu 20.16
2023-07-03 17:21:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29467 updates
2023-07-03 17:21:53 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_19.8800.pt
2023-07-03 17:21:56 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_19.8800.pt
2023-07-03 17:21:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_19.8800.pt (epoch 20 @ 29467 updates, score 19.88) (writing took 5.361694908235222 seconds)
2023-07-03 17:21:59 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-07-03 17:21:59 | INFO | train | epoch 020 | loss 1.379 | trans_loss 5.302 | nll_loss 2.59 | w2v_ctc_loss 0.441 | task_loss 2.092 | contrastive_loss 0.218 | total 4138.65 | n_correct 2677.91 | ppl 6.02 | accuracy 64.705 | wps 6000.8 | ups 1.45 | wpb 4138.6 | bsz 152.8 | num_updates 29467 | lr 8.23848e-05 | gnorm 0.34 | clip 0 | loss_scale 32 | train_wall 933 | gb_free 16.8 | wall 24790
2023-07-03 17:22:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 17:22:00 | INFO | fairseq.trainer | begin training epoch 21
2023-07-03 17:22:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 17:22:29 | INFO | train_inner | epoch 021:     33 / 1474 loss=1.38, trans_loss=5.301, nll_loss=2.59, w2v_ctc_loss=0.437, task_loss=1.976, contrastive_loss=0.354, total=4155.01, n_correct=2689.05, ppl=6.02, accuracy=64.718, wps=4072.6, ups=0.98, wpb=4155, bsz=158.8, num_updates=29500, lr=8.23387e-05, gnorm=0.339, clip=0, loss_scale=32, train_wall=63, gb_free=16.5, wall=24819
2023-07-03 17:23:32 | INFO | train_inner | epoch 021:    133 / 1474 loss=1.372, trans_loss=5.27, nll_loss=2.547, w2v_ctc_loss=0.434, task_loss=1.975, contrastive_loss=0.337, total=4186.67, n_correct=2732.13, ppl=5.85, accuracy=65.258, wps=6562.6, ups=1.57, wpb=4186.7, bsz=158.7, num_updates=29600, lr=8.21995e-05, gnorm=0.34, clip=0, loss_scale=32, train_wall=63, gb_free=13.4, wall=24883
2023-07-03 17:24:36 | INFO | train_inner | epoch 021:    233 / 1474 loss=1.369, trans_loss=5.27, nll_loss=2.549, w2v_ctc_loss=0.429, task_loss=1.967, contrastive_loss=0.245, total=4166.37, n_correct=2717.44, ppl=5.85, accuracy=65.223, wps=6592.2, ups=1.58, wpb=4166.4, bsz=157.6, num_updates=29700, lr=8.2061e-05, gnorm=0.336, clip=0, loss_scale=32, train_wall=63, gb_free=14.3, wall=24946
2023-07-03 17:25:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-03 17:25:40 | INFO | train_inner | epoch 021:    334 / 1474 loss=1.369, trans_loss=5.278, nll_loss=2.558, w2v_ctc_loss=0.441, task_loss=2.123, contrastive_loss=0.119, total=4133.32, n_correct=2691.95, ppl=5.89, accuracy=65.128, wps=6397.3, ups=1.55, wpb=4133.3, bsz=152.4, num_updates=29800, lr=8.19232e-05, gnorm=0.341, clip=0, loss_scale=32, train_wall=64, gb_free=15.8, wall=25011
2023-07-03 17:26:44 | INFO | train_inner | epoch 021:    434 / 1474 loss=1.365, trans_loss=5.27, nll_loss=2.547, w2v_ctc_loss=0.43, task_loss=2.033, contrastive_loss=0.101, total=4180.85, n_correct=2727.55, ppl=5.85, accuracy=65.239, wps=6610.5, ups=1.58, wpb=4180.9, bsz=153.4, num_updates=29900, lr=8.17861e-05, gnorm=0.336, clip=0, loss_scale=32, train_wall=63, gb_free=16, wall=25074
2023-07-03 17:27:48 | INFO | train_inner | epoch 021:    534 / 1474 loss=1.367, trans_loss=5.275, nll_loss=2.554, w2v_ctc_loss=0.438, task_loss=2.168, contrastive_loss=0.102, total=4083.98, n_correct=2660.27, ppl=5.87, accuracy=65.139, wps=6339.8, ups=1.55, wpb=4084, bsz=147.5, num_updates=30000, lr=8.16497e-05, gnorm=0.338, clip=0, loss_scale=32, train_wall=64, gb_free=13.4, wall=25139
2023-07-03 17:27:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 17:28:15 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 2.174 | trans_loss 5.576 | nll_loss 2.853 | w2v_ctc_loss 0.686 | task_loss 2.365 | contrastive_loss 0.252 | total 4003.4 | n_correct 2476.4 | ppl 7.23 | accuracy 61.857 | uer 17.174 | wer 18.843 | raw_wer 18.843 | bleu 19.87 | wps 1932.1 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.16
2023-07-03 17:28:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-07-03 17:28:15 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_21_30000.pt
2023-07-03 17:28:17 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_21_30000.pt
2023-07-03 17:28:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 19.87) (writing took 6.632801027968526 seconds)
tensor(0.0231, device='cuda:0')
tensor(0.0010, device='cuda:0')
2023-07-03 17:29:26 | INFO | train_inner | epoch 021:    634 / 1474 loss=1.379, trans_loss=5.283, nll_loss=2.566, w2v_ctc_loss=0.434, task_loss=2.064, contrastive_loss=0.445, total=4215.41, n_correct=2744.34, ppl=5.92, accuracy=65.103, wps=4280.4, ups=1.02, wpb=4215.4, bsz=157.7, num_updates=30100, lr=8.15139e-05, gnorm=0.336, clip=0, loss_scale=32, train_wall=64, gb_free=11.8, wall=25237
2023-07-03 17:30:31 | INFO | train_inner | epoch 021:    734 / 1474 loss=1.37, trans_loss=5.286, nll_loss=2.569, w2v_ctc_loss=0.433, task_loss=2.086, contrastive_loss=0.165, total=4152.97, n_correct=2700.26, ppl=5.93, accuracy=65.02, wps=6481.2, ups=1.56, wpb=4153, bsz=154.7, num_updates=30200, lr=8.13788e-05, gnorm=0.34, clip=0, loss_scale=32, train_wall=64, gb_free=16.5, wall=25301
2023-07-03 17:31:35 | INFO | train_inner | epoch 021:    834 / 1474 loss=1.374, trans_loss=5.3, nll_loss=2.586, w2v_ctc_loss=0.437, task_loss=2.216, contrastive_loss=0.192, total=4066.93, n_correct=2635.67, ppl=6.01, accuracy=64.807, wps=6341.7, ups=1.56, wpb=4066.9, bsz=147.2, num_updates=30300, lr=8.12444e-05, gnorm=0.344, clip=0, loss_scale=32, train_wall=64, gb_free=17.1, wall=25365
2023-07-03 17:32:38 | INFO | train_inner | epoch 021:    934 / 1474 loss=1.377, trans_loss=5.292, nll_loss=2.577, w2v_ctc_loss=0.442, task_loss=2.085, contrastive_loss=0.137, total=4103.34, n_correct=2660.36, ppl=5.97, accuracy=64.834, wps=6493.3, ups=1.58, wpb=4103.3, bsz=150.5, num_updates=30400, lr=8.11107e-05, gnorm=0.342, clip=0, loss_scale=32, train_wall=63, gb_free=14.3, wall=25429
2023-07-03 17:33:41 | INFO | train_inner | epoch 021:   1034 / 1474 loss=1.38, trans_loss=5.304, nll_loss=2.593, w2v_ctc_loss=0.445, task_loss=2.125, contrastive_loss=0.131, total=4099.86, n_correct=2653.23, ppl=6.03, accuracy=64.715, wps=6497.9, ups=1.58, wpb=4099.9, bsz=149.4, num_updates=30500, lr=8.09776e-05, gnorm=0.344, clip=0, loss_scale=32, train_wall=63, gb_free=11.9, wall=25492
2023-07-03 17:34:45 | INFO | train_inner | epoch 021:   1134 / 1474 loss=1.373, trans_loss=5.291, nll_loss=2.575, w2v_ctc_loss=0.437, task_loss=2.26, contrastive_loss=0.138, total=4120.75, n_correct=2674.96, ppl=5.96, accuracy=64.914, wps=6483.1, ups=1.57, wpb=4120.8, bsz=146.7, num_updates=30600, lr=8.08452e-05, gnorm=0.337, clip=0, loss_scale=32, train_wall=63, gb_free=16, wall=25555
2023-07-03 17:35:48 | INFO | train_inner | epoch 021:   1234 / 1474 loss=1.379, trans_loss=5.295, nll_loss=2.582, w2v_ctc_loss=0.439, task_loss=1.989, contrastive_loss=0.24, total=4154.73, n_correct=2692.25, ppl=5.99, accuracy=64.8, wps=6504.2, ups=1.57, wpb=4154.7, bsz=155.8, num_updates=30700, lr=8.07134e-05, gnorm=0.342, clip=0, loss_scale=32, train_wall=63, gb_free=13, wall=25619
2023-07-03 17:36:52 | INFO | train_inner | epoch 021:   1334 / 1474 loss=1.371, trans_loss=5.286, nll_loss=2.571, w2v_ctc_loss=0.436, task_loss=2.022, contrastive_loss=0.161, total=4147.17, n_correct=2693.83, ppl=5.94, accuracy=64.956, wps=6501.7, ups=1.57, wpb=4147.2, bsz=155.9, num_updates=30800, lr=8.05823e-05, gnorm=0.337, clip=0, loss_scale=32, train_wall=63, gb_free=16.4, wall=25683
2023-07-03 17:37:57 | INFO | train_inner | epoch 021:   1434 / 1474 loss=1.385, trans_loss=5.312, nll_loss=2.604, w2v_ctc_loss=0.45, task_loss=2.192, contrastive_loss=0.259, total=4133.93, n_correct=2669.58, ppl=6.08, accuracy=64.577, wps=6396.2, ups=1.55, wpb=4133.9, bsz=152.2, num_updates=30900, lr=8.04518e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=64, gb_free=15.7, wall=25748
2023-07-03 17:38:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0231, device='cuda:6')
tensor(0.0010, device='cuda:6')
tensor(0.0231, device='cuda:7')
tensor(0.0010, device='cuda:7')
tensor(0.0231, device='cuda:5')
tensor(0.0010, device='cuda:5')
tensor(0.0231, device='cuda:3')
tensor(0.0010, device='cuda:3')
tensor(0.0231, device='cuda:2')
tensor(0.0010, device='cuda:2')
tensor(0.0231, device='cuda:1')
tensor(0.0010, device='cuda:1')
tensor(0.0231, device='cuda:4')
tensor(0.0010, device='cuda:4')
2023-07-03 17:38:48 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 2.17 | trans_loss 5.57 | nll_loss 2.847 | w2v_ctc_loss 0.681 | task_loss 2.365 | contrastive_loss 0.251 | total 4003.4 | n_correct 2472.4 | ppl 7.2 | accuracy 61.758 | uer 17.148 | wer 18.944 | raw_wer 18.944 | bleu 19.78 | wps 2086.8 | wpb 4003.4 | bsz 141.8 | num_updates 30940 | best_bleu 20.16
2023-07-03 17:38:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30940 updates
2023-07-03 17:38:48 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_19.7809.pt
2023-07-03 17:38:50 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_19.7809.pt
2023-07-03 17:38:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_19.7809.pt (epoch 21 @ 30940 updates, score 19.78) (writing took 5.316048844251782 seconds)
2023-07-03 17:38:54 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-07-03 17:38:54 | INFO | train | epoch 021 | loss 1.374 | trans_loss 5.287 | nll_loss 2.57 | w2v_ctc_loss 0.437 | task_loss 2.094 | contrastive_loss 0.208 | total 4137.8 | n_correct 2688.54 | ppl 5.94 | accuracy 64.975 | wps 6007.9 | ups 1.45 | wpb 4137.8 | bsz 152.7 | num_updates 30940 | lr 8.03998e-05 | gnorm 0.34 | clip 0 | loss_scale 32 | train_wall 934 | gb_free 15.6 | wall 25804
2023-07-03 17:38:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 17:38:54 | INFO | fairseq.trainer | begin training epoch 22
2023-07-03 17:38:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 17:39:40 | INFO | train_inner | epoch 022:     60 / 1474 loss=1.364, trans_loss=5.265, nll_loss=2.542, w2v_ctc_loss=0.432, task_loss=2.119, contrastive_loss=0.099, total=4128.84, n_correct=2696.76, ppl=5.82, accuracy=65.315, wps=4003.5, ups=0.97, wpb=4128.8, bsz=148.8, num_updates=31000, lr=8.03219e-05, gnorm=0.338, clip=0, loss_scale=32, train_wall=63, gb_free=14.5, wall=25851
2023-07-03 17:40:44 | INFO | train_inner | epoch 022:    160 / 1474 loss=1.368, trans_loss=5.257, nll_loss=2.532, w2v_ctc_loss=0.435, task_loss=2.117, contrastive_loss=0.265, total=4123.35, n_correct=2700.86, ppl=5.78, accuracy=65.502, wps=6469.4, ups=1.57, wpb=4123.4, bsz=155.1, num_updates=31100, lr=8.01927e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=63, gb_free=14.9, wall=25914
2023-07-03 17:41:48 | INFO | train_inner | epoch 022:    260 / 1474 loss=1.359, trans_loss=5.243, nll_loss=2.514, w2v_ctc_loss=0.423, task_loss=1.842, contrastive_loss=0.148, total=4267.16, n_correct=2805.71, ppl=5.71, accuracy=65.751, wps=6683.8, ups=1.57, wpb=4267.2, bsz=165, num_updates=31200, lr=8.00641e-05, gnorm=0.335, clip=0, loss_scale=32, train_wall=63, gb_free=17, wall=25978
2023-07-03 17:42:53 | INFO | train_inner | epoch 022:    360 / 1474 loss=1.378, trans_loss=5.279, nll_loss=2.56, w2v_ctc_loss=0.437, task_loss=2.127, contrastive_loss=0.462, total=4180.09, n_correct=2721.96, ppl=5.9, accuracy=65.117, wps=6436.4, ups=1.54, wpb=4180.1, bsz=155, num_updates=31300, lr=7.99361e-05, gnorm=0.347, clip=0, loss_scale=32, train_wall=65, gb_free=17.7, wall=26043
2023-07-03 17:43:57 | INFO | train_inner | epoch 022:    460 / 1474 loss=1.376, trans_loss=5.279, nll_loss=2.559, w2v_ctc_loss=0.439, task_loss=2.204, contrastive_loss=0.23, total=4132.62, n_correct=2691.94, ppl=5.89, accuracy=65.139, wps=6423.7, ups=1.55, wpb=4132.6, bsz=148.6, num_updates=31400, lr=7.98087e-05, gnorm=0.343, clip=0, loss_scale=32, train_wall=64, gb_free=16.7, wall=26108
2023-07-03 17:45:02 | INFO | train_inner | epoch 022:    560 / 1474 loss=1.366, trans_loss=5.268, nll_loss=2.546, w2v_ctc_loss=0.435, task_loss=2.12, contrastive_loss=0.125, total=4155.5, n_correct=2713.56, ppl=5.84, accuracy=65.3, wps=6393.5, ups=1.54, wpb=4155.5, bsz=153.7, num_updates=31500, lr=7.96819e-05, gnorm=0.343, clip=0, loss_scale=32, train_wall=65, gb_free=16.6, wall=26173
2023-07-03 17:46:05 | INFO | train_inner | epoch 022:    660 / 1474 loss=1.366, trans_loss=5.26, nll_loss=2.536, w2v_ctc_loss=0.425, task_loss=1.969, contrastive_loss=0.29, total=4147.84, n_correct=2710.25, ppl=5.8, accuracy=65.341, wps=6595.9, ups=1.59, wpb=4147.8, bsz=156.6, num_updates=31600, lr=7.95557e-05, gnorm=0.339, clip=0, loss_scale=32, train_wall=62, gb_free=13.4, wall=26235
2023-07-03 17:47:09 | INFO | train_inner | epoch 022:    760 / 1474 loss=1.368, trans_loss=5.269, nll_loss=2.547, w2v_ctc_loss=0.436, task_loss=2.139, contrastive_loss=0.129, total=4166.89, n_correct=2721.46, ppl=5.84, accuracy=65.312, wps=6538.3, ups=1.57, wpb=4166.9, bsz=152.2, num_updates=31700, lr=7.94301e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=63, gb_free=16.1, wall=26299
2023-07-03 17:48:12 | INFO | train_inner | epoch 022:    860 / 1474 loss=1.365, trans_loss=5.282, nll_loss=2.564, w2v_ctc_loss=0.436, task_loss=2.291, contrastive_loss=0.103, total=4074.75, n_correct=2645.23, ppl=5.91, accuracy=64.918, wps=6368, ups=1.56, wpb=4074.8, bsz=144.2, num_updates=31800, lr=7.93052e-05, gnorm=0.346, clip=0, loss_scale=32, train_wall=64, gb_free=17.6, wall=26363
2023-07-03 17:49:16 | INFO | train_inner | epoch 022:    960 / 1474 loss=1.364, trans_loss=5.266, nll_loss=2.544, w2v_ctc_loss=0.427, task_loss=2.101, contrastive_loss=0.107, total=4136.34, n_correct=2702.27, ppl=5.83, accuracy=65.33, wps=6488.8, ups=1.57, wpb=4136.3, bsz=151.8, num_updates=31900, lr=7.91808e-05, gnorm=0.338, clip=0, loss_scale=64, train_wall=63, gb_free=16.8, wall=26427
2023-07-03 17:50:19 | INFO | train_inner | epoch 022:   1060 / 1474 loss=1.373, trans_loss=5.272, nll_loss=2.553, w2v_ctc_loss=0.428, task_loss=1.985, contrastive_loss=0.444, total=4157.21, n_correct=2712.87, ppl=5.87, accuracy=65.257, wps=6580.6, ups=1.58, wpb=4157.2, bsz=157.7, num_updates=32000, lr=7.90569e-05, gnorm=0.337, clip=0, loss_scale=64, train_wall=63, gb_free=12.4, wall=26490
2023-07-03 17:50:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 17:50:45 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 2.166 | trans_loss 5.563 | nll_loss 2.839 | w2v_ctc_loss 0.673 | task_loss 2.365 | contrastive_loss 0.258 | total 4003.4 | n_correct 2475.8 | ppl 7.15 | accuracy 61.842 | uer 17.044 | wer 18.884 | raw_wer 18.884 | bleu 20.17 | wps 2149.1 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.17
2023-07-03 17:50:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-07-03 17:50:45 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_22_32000.pt
2023-07-03 17:50:47 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_22_32000.pt
2023-07-03 17:50:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 20.17) (writing took 10.292844140902162 seconds)
2023-07-03 17:51:59 | INFO | train_inner | epoch 022:   1160 / 1474 loss=1.378, trans_loss=5.295, nll_loss=2.582, w2v_ctc_loss=0.437, task_loss=2.169, contrastive_loss=0.206, total=4092.91, n_correct=2653.13, ppl=5.99, accuracy=64.823, wps=4123.3, ups=1.01, wpb=4092.9, bsz=147.2, num_updates=32100, lr=7.89337e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=63, gb_free=16.2, wall=26589
2023-07-03 17:53:03 | INFO | train_inner | epoch 022:   1260 / 1474 loss=1.371, trans_loss=5.28, nll_loss=2.563, w2v_ctc_loss=0.433, task_loss=1.931, contrastive_loss=0.195, total=4182.65, n_correct=2721.01, ppl=5.91, accuracy=65.055, wps=6483.1, ups=1.55, wpb=4182.6, bsz=161.8, num_updates=32200, lr=7.8811e-05, gnorm=0.337, clip=0, loss_scale=64, train_wall=64, gb_free=16.7, wall=26654
2023-07-03 17:54:06 | INFO | train_inner | epoch 022:   1360 / 1474 loss=1.369, trans_loss=5.278, nll_loss=2.561, w2v_ctc_loss=0.432, task_loss=2.072, contrastive_loss=0.238, total=4071.58, n_correct=2651.48, ppl=5.9, accuracy=65.122, wps=6482.3, ups=1.59, wpb=4071.6, bsz=150.3, num_updates=32300, lr=7.86889e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=62, gb_free=16.9, wall=26717
2023-07-03 17:55:10 | INFO | train_inner | epoch 022:   1460 / 1474 loss=1.376, trans_loss=5.296, nll_loss=2.582, w2v_ctc_loss=0.443, task_loss=2.228, contrastive_loss=0.132, total=4077.83, n_correct=2639.9, ppl=5.99, accuracy=64.738, wps=6415, ups=1.57, wpb=4077.8, bsz=144, num_updates=32400, lr=7.85674e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=63, gb_free=16.3, wall=26780
2023-07-03 17:55:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 17:55:45 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 2.169 | trans_loss 5.56 | nll_loss 2.831 | w2v_ctc_loss 0.688 | task_loss 2.365 | contrastive_loss 0.257 | total 4003.4 | n_correct 2482.3 | ppl 7.12 | accuracy 62.005 | uer 17.041 | wer 18.806 | raw_wer 18.806 | bleu 20 | wps 1983.5 | wpb 4003.4 | bsz 141.8 | num_updates 32414 | best_bleu 20.17
2023-07-03 17:55:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32414 updates
2023-07-03 17:55:45 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_20.0009.pt
2023-07-03 17:55:48 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_20.0009.pt
2023-07-03 17:55:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_20.0009.pt (epoch 22 @ 32414 updates, score 20.0) (writing took 5.520909352693707 seconds)
2023-07-03 17:55:51 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-07-03 17:55:51 | INFO | train | epoch 022 | loss 1.369 | trans_loss 5.272 | nll_loss 2.552 | w2v_ctc_loss 0.433 | task_loss 2.092 | contrastive_loss 0.215 | total 4138.65 | n_correct 2698.8 | ppl 5.86 | accuracy 65.21 | wps 5995.1 | ups 1.45 | wpb 4138.6 | bsz 152.8 | num_updates 32414 | lr 7.85505e-05 | gnorm 0.341 | clip 0 | loss_scale 64 | train_wall 934 | gb_free 12.2 | wall 26822
2023-07-03 17:55:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 17:55:51 | INFO | fairseq.trainer | begin training epoch 23
2023-07-03 17:55:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 17:56:54 | INFO | train_inner | epoch 023:     86 / 1474 loss=1.36, trans_loss=5.247, nll_loss=2.519, w2v_ctc_loss=0.434, task_loss=2.162, contrastive_loss=0.116, total=4089.8, n_correct=2684.44, ppl=5.73, accuracy=65.637, wps=3907.5, ups=0.96, wpb=4089.8, bsz=149.7, num_updates=32500, lr=7.84465e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=63, gb_free=16.8, wall=26885
2023-07-03 17:57:58 | INFO | train_inner | epoch 023:    186 / 1474 loss=1.358, trans_loss=5.241, nll_loss=2.511, w2v_ctc_loss=0.427, task_loss=2.208, contrastive_loss=0.112, total=4117.76, n_correct=2707.42, ppl=5.7, accuracy=65.75, wps=6474.6, ups=1.57, wpb=4117.8, bsz=148, num_updates=32600, lr=7.8326e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=63, gb_free=15.7, wall=26949
2023-07-03 17:59:02 | INFO | train_inner | epoch 023:    286 / 1474 loss=1.364, trans_loss=5.252, nll_loss=2.526, w2v_ctc_loss=0.424, task_loss=2.122, contrastive_loss=0.271, total=4144.73, n_correct=2714.82, ppl=5.76, accuracy=65.501, wps=6472.4, ups=1.56, wpb=4144.7, bsz=152, num_updates=32700, lr=7.82062e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=64, gb_free=17.6, wall=27013
2023-07-03 18:00:06 | INFO | train_inner | epoch 023:    386 / 1474 loss=1.357, trans_loss=5.247, nll_loss=2.518, w2v_ctc_loss=0.426, task_loss=2.149, contrastive_loss=0.099, total=4126.79, n_correct=2712.13, ppl=5.73, accuracy=65.72, wps=6472, ups=1.57, wpb=4126.8, bsz=148.2, num_updates=32800, lr=7.80869e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=63, gb_free=17.3, wall=27076
2023-07-03 18:01:10 | INFO | train_inner | epoch 023:    486 / 1474 loss=1.362, trans_loss=5.252, nll_loss=2.524, w2v_ctc_loss=0.423, task_loss=2.043, contrastive_loss=0.209, total=4150.15, n_correct=2720.49, ppl=5.75, accuracy=65.552, wps=6452.7, ups=1.55, wpb=4150.1, bsz=156, num_updates=32900, lr=7.79681e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=64, gb_free=16.4, wall=27141
2023-07-03 18:02:13 | INFO | train_inner | epoch 023:    586 / 1474 loss=1.354, trans_loss=5.237, nll_loss=2.507, w2v_ctc_loss=0.421, task_loss=1.968, contrastive_loss=0.107, total=4174.6, n_correct=2743.45, ppl=5.68, accuracy=65.718, wps=6630.3, ups=1.59, wpb=4174.6, bsz=158.2, num_updates=33000, lr=7.78499e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=62, gb_free=16.6, wall=27204
2023-07-03 18:03:16 | INFO | train_inner | epoch 023:    686 / 1474 loss=1.364, trans_loss=5.258, nll_loss=2.534, w2v_ctc_loss=0.432, task_loss=2.109, contrastive_loss=0.185, total=4136.6, n_correct=2703.75, ppl=5.79, accuracy=65.362, wps=6529.8, ups=1.58, wpb=4136.6, bsz=150.6, num_updates=33100, lr=7.77322e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=63, gb_free=17.8, wall=27267
2023-07-03 18:04:19 | INFO | train_inner | epoch 023:    786 / 1474 loss=1.364, trans_loss=5.258, nll_loss=2.533, w2v_ctc_loss=0.429, task_loss=2.104, contrastive_loss=0.144, total=4147.22, n_correct=2716.57, ppl=5.79, accuracy=65.503, wps=6568.5, ups=1.58, wpb=4147.2, bsz=152.6, num_updates=33200, lr=7.76151e-05, gnorm=0.344, clip=0, loss_scale=64, train_wall=63, gb_free=17.4, wall=27330
2023-07-03 18:05:23 | INFO | train_inner | epoch 023:    886 / 1474 loss=1.365, trans_loss=5.248, nll_loss=2.522, w2v_ctc_loss=0.425, task_loss=1.894, contrastive_loss=0.302, total=4193.16, n_correct=2749.09, ppl=5.74, accuracy=65.561, wps=6626.2, ups=1.58, wpb=4193.2, bsz=163.6, num_updates=33300, lr=7.74984e-05, gnorm=0.336, clip=0, loss_scale=64, train_wall=63, gb_free=16.2, wall=27394
2023-07-03 18:06:26 | INFO | train_inner | epoch 023:    986 / 1474 loss=1.375, trans_loss=5.26, nll_loss=2.537, w2v_ctc_loss=0.426, task_loss=2.086, contrastive_loss=0.616, total=4164.33, n_correct=2718.81, ppl=5.8, accuracy=65.288, wps=6565.2, ups=1.58, wpb=4164.3, bsz=155.1, num_updates=33400, lr=7.73823e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=63, gb_free=17.8, wall=27457
2023-07-03 18:07:31 | INFO | train_inner | epoch 023:   1086 / 1474 loss=1.364, trans_loss=5.263, nll_loss=2.541, w2v_ctc_loss=0.435, task_loss=2.248, contrastive_loss=0.12, total=4088.37, n_correct=2670.52, ppl=5.82, accuracy=65.32, wps=6341, ups=1.55, wpb=4088.4, bsz=144.8, num_updates=33500, lr=7.72667e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=64, gb_free=15.8, wall=27521
2023-07-03 18:08:36 | INFO | train_inner | epoch 023:   1186 / 1474 loss=1.364, trans_loss=5.264, nll_loss=2.543, w2v_ctc_loss=0.433, task_loss=2.082, contrastive_loss=0.111, total=4162.3, n_correct=2715.84, ppl=5.83, accuracy=65.249, wps=6406.5, ups=1.54, wpb=4162.3, bsz=154.5, num_updates=33600, lr=7.71517e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=65, gb_free=15.8, wall=27586
2023-07-03 18:09:39 | INFO | train_inner | epoch 023:   1286 / 1474 loss=1.362, trans_loss=5.255, nll_loss=2.531, w2v_ctc_loss=0.426, task_loss=2.038, contrastive_loss=0.13, total=4131.74, n_correct=2703.65, ppl=5.78, accuracy=65.436, wps=6506.8, ups=1.57, wpb=4131.7, bsz=154.4, num_updates=33700, lr=7.70371e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=63, gb_free=17.2, wall=27650
2023-07-03 18:10:43 | INFO | train_inner | epoch 023:   1386 / 1474 loss=1.373, trans_loss=5.282, nll_loss=2.566, w2v_ctc_loss=0.434, task_loss=2.109, contrastive_loss=0.244, total=4141.25, n_correct=2695.08, ppl=5.92, accuracy=65.079, wps=6501.5, ups=1.57, wpb=4141.2, bsz=152.4, num_updates=33800, lr=7.69231e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=63, gb_free=17, wall=27714
2023-07-03 18:11:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 18:12:04 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 2.181 | trans_loss 5.557 | nll_loss 2.83 | w2v_ctc_loss 0.732 | task_loss 2.365 | contrastive_loss 0.253 | total 4003.4 | n_correct 2486.5 | ppl 7.11 | accuracy 62.11 | uer 17.004 | wer 18.791 | raw_wer 18.791 | bleu 20.24 | wps 2141 | wpb 4003.4 | bsz 141.8 | num_updates 33888 | best_bleu 20.24
2023-07-03 18:12:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33888 updates
2023-07-03 18:12:04 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 18:12:08 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 18:12:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt (epoch 23 @ 33888 updates, score 20.24) (writing took 8.42921774694696 seconds)
2023-07-03 18:12:12 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-07-03 18:12:12 | INFO | train | epoch 023 | loss 1.364 | trans_loss 5.256 | nll_loss 2.532 | w2v_ctc_loss 0.428 | task_loss 2.092 | contrastive_loss 0.214 | total 4138.65 | n_correct 2708.78 | ppl 5.78 | accuracy 65.451 | wps 6216.1 | ups 1.5 | wpb 4138.6 | bsz 152.8 | num_updates 33888 | lr 7.68231e-05 | gnorm 0.341 | clip 0 | loss_scale 64 | train_wall 933 | gb_free 14.1 | wall 27803
2023-07-03 18:12:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 18:12:13 | INFO | fairseq.trainer | begin training epoch 24
2023-07-03 18:12:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 18:12:29 | INFO | train_inner | epoch 024:     12 / 1474 loss=1.373, trans_loss=5.278, nll_loss=2.562, w2v_ctc_loss=0.427, task_loss=2.08, contrastive_loss=0.394, total=4095.53, n_correct=2665.73, ppl=5.91, accuracy=65.089, wps=3861.6, ups=0.94, wpb=4095.5, bsz=153.1, num_updates=33900, lr=7.68095e-05, gnorm=0.343, clip=0, loss_scale=128, train_wall=63, gb_free=17.5, wall=27820
2023-07-03 18:12:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-03 18:13:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-03 18:13:34 | INFO | train_inner | epoch 024:    114 / 1474 loss=1.358, trans_loss=5.224, nll_loss=2.49, w2v_ctc_loss=0.421, task_loss=1.995, contrastive_loss=0.312, total=4137.35, n_correct=2731.55, ppl=5.62, accuracy=66.022, wps=6399.8, ups=1.55, wpb=4137.4, bsz=157.3, num_updates=34000, lr=7.66965e-05, gnorm=0.343, clip=0, loss_scale=32, train_wall=64, gb_free=11.9, wall=27884
2023-07-03 18:13:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 18:14:00 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 2.169 | trans_loss 5.563 | nll_loss 2.835 | w2v_ctc_loss 0.685 | task_loss 2.365 | contrastive_loss 0.252 | total 4003.4 | n_correct 2476.1 | ppl 7.14 | accuracy 61.85 | uer 16.972 | wer 18.668 | raw_wer 18.668 | bleu 19.56 | wps 1948.2 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.24
2023-07-03 18:14:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-07-03 18:14:00 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_24_34000.pt
2023-07-03 18:14:03 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_24_34000.pt
2023-07-03 18:14:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 19.56) (writing took 5.367003412917256 seconds)
2023-07-03 18:15:10 | INFO | train_inner | epoch 024:    214 / 1474 loss=1.364, trans_loss=5.23, nll_loss=2.498, w2v_ctc_loss=0.415, task_loss=1.813, contrastive_loss=0.548, total=4252.53, n_correct=2803.73, ppl=5.65, accuracy=65.931, wps=4420.5, ups=1.04, wpb=4252.5, bsz=170.7, num_updates=34100, lr=7.6584e-05, gnorm=0.339, clip=0, loss_scale=32, train_wall=63, gb_free=17, wall=27981
2023-07-03 18:16:14 | INFO | train_inner | epoch 024:    314 / 1474 loss=1.35, trans_loss=5.225, nll_loss=2.491, w2v_ctc_loss=0.418, task_loss=2.035, contrastive_loss=0.102, total=4138.44, n_correct=2728.74, ppl=5.62, accuracy=65.936, wps=6490, ups=1.57, wpb=4138.4, bsz=153.6, num_updates=34200, lr=7.64719e-05, gnorm=0.339, clip=0, loss_scale=32, train_wall=63, gb_free=15.8, wall=28044
2023-07-03 18:17:19 | INFO | train_inner | epoch 024:    414 / 1474 loss=1.369, trans_loss=5.254, nll_loss=2.528, w2v_ctc_loss=0.431, task_loss=2.219, contrastive_loss=0.389, total=4153.83, n_correct=2720.68, ppl=5.77, accuracy=65.498, wps=6367.2, ups=1.53, wpb=4153.8, bsz=149.2, num_updates=34300, lr=7.63604e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=65, gb_free=16.4, wall=28110
2023-07-03 18:18:23 | INFO | train_inner | epoch 024:    514 / 1474 loss=1.362, trans_loss=5.245, nll_loss=2.517, w2v_ctc_loss=0.429, task_loss=2.122, contrastive_loss=0.238, total=4141.88, n_correct=2720.61, ppl=5.72, accuracy=65.685, wps=6491.9, ups=1.57, wpb=4141.9, bsz=151.3, num_updates=34400, lr=7.62493e-05, gnorm=0.342, clip=0, loss_scale=32, train_wall=63, gb_free=15.4, wall=28173
2023-07-03 18:19:26 | INFO | train_inner | epoch 024:    614 / 1474 loss=1.358, trans_loss=5.237, nll_loss=2.507, w2v_ctc_loss=0.424, task_loss=2.106, contrastive_loss=0.168, total=4162.06, n_correct=2736.81, ppl=5.68, accuracy=65.756, wps=6560.2, ups=1.58, wpb=4162.1, bsz=154.1, num_updates=34500, lr=7.61387e-05, gnorm=0.338, clip=0, loss_scale=32, train_wall=63, gb_free=16.9, wall=28237
2023-07-03 18:20:29 | INFO | train_inner | epoch 024:    714 / 1474 loss=1.36, trans_loss=5.249, nll_loss=2.522, w2v_ctc_loss=0.425, task_loss=2.173, contrastive_loss=0.189, total=4097.35, n_correct=2689.95, ppl=5.74, accuracy=65.651, wps=6473.9, ups=1.58, wpb=4097.4, bsz=146.9, num_updates=34600, lr=7.60286e-05, gnorm=0.336, clip=0, loss_scale=32, train_wall=63, gb_free=17.4, wall=28300
2023-07-03 18:21:33 | INFO | train_inner | epoch 024:    814 / 1474 loss=1.359, trans_loss=5.244, nll_loss=2.517, w2v_ctc_loss=0.422, task_loss=2.085, contrastive_loss=0.143, total=4124.25, n_correct=2710.7, ppl=5.72, accuracy=65.726, wps=6468.4, ups=1.57, wpb=4124.2, bsz=154.1, num_updates=34700, lr=7.5919e-05, gnorm=0.341, clip=0, loss_scale=32, train_wall=63, gb_free=16.6, wall=28364
2023-07-03 18:22:36 | INFO | train_inner | epoch 024:    914 / 1474 loss=1.361, trans_loss=5.258, nll_loss=2.533, w2v_ctc_loss=0.43, task_loss=2.316, contrastive_loss=0.094, total=4041.44, n_correct=2643.07, ppl=5.79, accuracy=65.399, wps=6425.3, ups=1.59, wpb=4041.4, bsz=140.3, num_updates=34800, lr=7.58098e-05, gnorm=0.344, clip=0, loss_scale=32, train_wall=62, gb_free=16.4, wall=28427
2023-07-03 18:23:40 | INFO | train_inner | epoch 024:   1014 / 1474 loss=1.354, trans_loss=5.246, nll_loss=2.518, w2v_ctc_loss=0.419, task_loss=2.18, contrastive_loss=0.102, total=4128.8, n_correct=2707.57, ppl=5.73, accuracy=65.578, wps=6455.5, ups=1.56, wpb=4128.8, bsz=148.2, num_updates=34900, lr=7.57011e-05, gnorm=0.34, clip=0, loss_scale=32, train_wall=64, gb_free=15.3, wall=28491
2023-07-03 18:24:44 | INFO | train_inner | epoch 024:   1114 / 1474 loss=1.358, trans_loss=5.24, nll_loss=2.512, w2v_ctc_loss=0.428, task_loss=2.029, contrastive_loss=0.188, total=4130.49, n_correct=2712.2, ppl=5.7, accuracy=65.663, wps=6464.2, ups=1.56, wpb=4130.5, bsz=154.4, num_updates=35000, lr=7.55929e-05, gnorm=0.343, clip=0, loss_scale=32, train_wall=63, gb_free=16.2, wall=28555
tensor(0.0231, device='cuda:0')
tensor(0.0010, device='cuda:0')
2023-07-03 18:25:48 | INFO | train_inner | epoch 024:   1214 / 1474 loss=1.357, trans_loss=5.244, nll_loss=2.517, w2v_ctc_loss=0.419, task_loss=2.073, contrastive_loss=0.166, total=4157.47, n_correct=2728.62, ppl=5.72, accuracy=65.632, wps=6462.4, ups=1.55, wpb=4157.5, bsz=155.6, num_updates=35100, lr=7.54851e-05, gnorm=0.342, clip=0, loss_scale=32, train_wall=64, gb_free=13.1, wall=28619
2023-07-03 18:26:52 | INFO | train_inner | epoch 024:   1314 / 1474 loss=1.362, trans_loss=5.249, nll_loss=2.522, w2v_ctc_loss=0.427, task_loss=2.219, contrastive_loss=0.11, total=4107.23, n_correct=2696.79, ppl=5.74, accuracy=65.66, wps=6452, ups=1.57, wpb=4107.2, bsz=147.2, num_updates=35200, lr=7.53778e-05, gnorm=0.341, clip=0, loss_scale=32, train_wall=63, gb_free=17.7, wall=28683
2023-07-03 18:27:55 | INFO | train_inner | epoch 024:   1414 / 1474 loss=1.362, trans_loss=5.255, nll_loss=2.531, w2v_ctc_loss=0.429, task_loss=2.187, contrastive_loss=0.11, total=4094.39, n_correct=2682.59, ppl=5.78, accuracy=65.519, wps=6463.6, ups=1.58, wpb=4094.4, bsz=146.4, num_updates=35300, lr=7.5271e-05, gnorm=0.339, clip=0, loss_scale=32, train_wall=63, gb_free=16.5, wall=28746
2023-07-03 18:28:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0231, device='cuda:6')
tensor(0.0010, device='cuda:6')
tensor(0.0231, device='cuda:7')
tensor(0.0010, device='cuda:7')
tensor(0.0231, device='cuda:5')
tensor(0.0010, device='cuda:5')
tensor(0.0231, device='cuda:4')
tensor(0.0010, device='cuda:4')
tensor(0.0231, device='cuda:2')
tensor(0.0010, device='cuda:2')
tensor(0.0231, device='cuda:3')
tensor(0.0010, device='cuda:3')
tensor(0.0231, device='cuda:1')
tensor(0.0010, device='cuda:1')
2023-07-03 18:28:59 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 2.172 | trans_loss 5.563 | nll_loss 2.836 | w2v_ctc_loss 0.695 | task_loss 2.365 | contrastive_loss 0.252 | total 4003.4 | n_correct 2487.5 | ppl 7.14 | accuracy 62.135 | uer 16.885 | wer 18.657 | raw_wer 18.657 | bleu 20.1 | wps 2018.1 | wpb 4003.4 | bsz 141.8 | num_updates 35360 | best_bleu 20.24
2023-07-03 18:28:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35360 updates
2023-07-03 18:28:59 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_20.1000.pt
2023-07-03 18:29:02 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_20.1000.pt
2023-07-03 18:29:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_20.1000.pt (epoch 24 @ 35360 updates, score 20.1) (writing took 5.54095012601465 seconds)
2023-07-03 18:29:05 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-07-03 18:29:05 | INFO | train | epoch 024 | loss 1.359 | trans_loss 5.243 | nll_loss 2.514 | w2v_ctc_loss 0.424 | task_loss 2.096 | contrastive_loss 0.204 | total 4136.83 | n_correct 2717.61 | ppl 5.71 | accuracy 65.693 | wps 6013.5 | ups 1.45 | wpb 4136.8 | bsz 152.6 | num_updates 35360 | lr 7.52071e-05 | gnorm 0.341 | clip 0 | loss_scale 32 | train_wall 933 | gb_free 16.3 | wall 28816
2023-07-03 18:29:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 18:29:05 | INFO | fairseq.trainer | begin training epoch 25
2023-07-03 18:29:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 18:29:39 | INFO | train_inner | epoch 025:     40 / 1474 loss=1.353, trans_loss=5.231, nll_loss=2.5, w2v_ctc_loss=0.419, task_loss=2.009, contrastive_loss=0.122, total=4165.57, n_correct=2747.7, ppl=5.66, accuracy=65.962, wps=4024.9, ups=0.97, wpb=4165.6, bsz=155.6, num_updates=35400, lr=7.51646e-05, gnorm=0.338, clip=0, loss_scale=32, train_wall=63, gb_free=13.5, wall=28849
2023-07-03 18:30:42 | INFO | train_inner | epoch 025:    140 / 1474 loss=1.348, trans_loss=5.211, nll_loss=2.473, w2v_ctc_loss=0.415, task_loss=2.031, contrastive_loss=0.118, total=4135.43, n_correct=2739.67, ppl=5.55, accuracy=66.249, wps=6508.8, ups=1.57, wpb=4135.4, bsz=154.5, num_updates=35500, lr=7.50587e-05, gnorm=0.339, clip=0, loss_scale=32, train_wall=63, gb_free=17.8, wall=28913
2023-07-03 18:31:47 | INFO | train_inner | epoch 025:    240 / 1474 loss=1.347, trans_loss=5.215, nll_loss=2.479, w2v_ctc_loss=0.417, task_loss=2.149, contrastive_loss=0.128, total=4116.13, n_correct=2721.56, ppl=5.57, accuracy=66.119, wps=6360.5, ups=1.55, wpb=4116.1, bsz=151.5, num_updates=35600, lr=7.49532e-05, gnorm=0.338, clip=0, loss_scale=32, train_wall=64, gb_free=17.4, wall=28978
2023-07-03 18:32:52 | INFO | train_inner | epoch 025:    340 / 1474 loss=1.353, trans_loss=5.224, nll_loss=2.488, w2v_ctc_loss=0.417, task_loss=2.235, contrastive_loss=0.187, total=4141.49, n_correct=2731.2, ppl=5.61, accuracy=65.947, wps=6388.5, ups=1.54, wpb=4141.5, bsz=147.1, num_updates=35700, lr=7.48481e-05, gnorm=0.34, clip=0, loss_scale=32, train_wall=64, gb_free=15.4, wall=29043
2023-07-03 18:33:56 | INFO | train_inner | epoch 025:    440 / 1474 loss=1.368, trans_loss=5.237, nll_loss=2.507, w2v_ctc_loss=0.433, task_loss=2.187, contrastive_loss=0.34, total=4167.4, n_correct=2743.37, ppl=5.68, accuracy=65.829, wps=6454.7, ups=1.55, wpb=4167.4, bsz=148.8, num_updates=35800, lr=7.47435e-05, gnorm=0.362, clip=0, loss_scale=32, train_wall=64, gb_free=16, wall=29107
2023-07-03 18:35:00 | INFO | train_inner | epoch 025:    540 / 1474 loss=1.352, trans_loss=5.231, nll_loss=2.5, w2v_ctc_loss=0.419, task_loss=2.044, contrastive_loss=0.127, total=4160.61, n_correct=2740.93, ppl=5.66, accuracy=65.878, wps=6532.9, ups=1.57, wpb=4160.6, bsz=157, num_updates=35900, lr=7.46393e-05, gnorm=0.346, clip=0, loss_scale=32, train_wall=63, gb_free=17.7, wall=29171
2023-07-03 18:36:03 | INFO | train_inner | epoch 025:    640 / 1474 loss=1.354, trans_loss=5.224, nll_loss=2.491, w2v_ctc_loss=0.42, task_loss=2.077, contrastive_loss=0.261, total=4153.68, n_correct=2741.54, ppl=5.62, accuracy=66.003, wps=6576.8, ups=1.58, wpb=4153.7, bsz=154.8, num_updates=36000, lr=7.45356e-05, gnorm=0.343, clip=0, loss_scale=32, train_wall=63, gb_free=16.6, wall=29234
2023-07-03 18:36:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 18:36:29 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 2.164 | trans_loss 5.558 | nll_loss 2.83 | w2v_ctc_loss 0.672 | task_loss 2.365 | contrastive_loss 0.256 | total 4003.4 | n_correct 2486.1 | ppl 7.11 | accuracy 62.1 | uer 16.675 | wer 18.198 | raw_wer 18.198 | bleu 19.95 | wps 2225.1 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.24
2023-07-03 18:36:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-07-03 18:36:29 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_25_36000.pt
2023-07-03 18:36:31 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_25_36000.pt
2023-07-03 18:36:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 19.95) (writing took 6.2512887003831565 seconds)
2023-07-03 18:37:40 | INFO | train_inner | epoch 025:    740 / 1474 loss=1.354, trans_loss=5.225, nll_loss=2.492, w2v_ctc_loss=0.418, task_loss=2.122, contrastive_loss=0.251, total=4128.34, n_correct=2725.54, ppl=5.62, accuracy=66.02, wps=4278.7, ups=1.04, wpb=4128.3, bsz=150.6, num_updates=36100, lr=7.44323e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=63, gb_free=17.2, wall=29330
2023-07-03 18:38:43 | INFO | train_inner | epoch 025:    840 / 1474 loss=1.356, trans_loss=5.229, nll_loss=2.498, w2v_ctc_loss=0.421, task_loss=1.918, contrastive_loss=0.147, total=4182.4, n_correct=2759.45, ppl=5.65, accuracy=65.978, wps=6576.2, ups=1.57, wpb=4182.4, bsz=163, num_updates=36200, lr=7.43294e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=63, gb_free=17.8, wall=29394
2023-07-03 18:39:48 | INFO | train_inner | epoch 025:    940 / 1474 loss=1.357, trans_loss=5.228, nll_loss=2.497, w2v_ctc_loss=0.419, task_loss=1.985, contrastive_loss=0.261, total=4155.21, n_correct=2737.94, ppl=5.64, accuracy=65.892, wps=6457, ups=1.55, wpb=4155.2, bsz=158.5, num_updates=36300, lr=7.4227e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=64, gb_free=14.4, wall=29458
2023-07-03 18:40:52 | INFO | train_inner | epoch 025:   1040 / 1474 loss=1.366, trans_loss=5.25, nll_loss=2.525, w2v_ctc_loss=0.42, task_loss=2.085, contrastive_loss=0.481, total=4177.7, n_correct=2738.93, ppl=5.75, accuracy=65.561, wps=6484.6, ups=1.55, wpb=4177.7, bsz=154.9, num_updates=36400, lr=7.41249e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=64, gb_free=15.9, wall=29523
2023-07-03 18:41:56 | INFO | train_inner | epoch 025:   1140 / 1474 loss=1.353, trans_loss=5.237, nll_loss=2.507, w2v_ctc_loss=0.418, task_loss=2.256, contrastive_loss=0.095, total=4039.24, n_correct=2655.49, ppl=5.68, accuracy=65.742, wps=6326.6, ups=1.57, wpb=4039.2, bsz=142.6, num_updates=36500, lr=7.40233e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=63, gb_free=16.6, wall=29587
2023-07-03 18:42:59 | INFO | train_inner | epoch 025:   1240 / 1474 loss=1.357, trans_loss=5.241, nll_loss=2.513, w2v_ctc_loss=0.422, task_loss=2.12, contrastive_loss=0.116, total=4090.59, n_correct=2686.17, ppl=5.71, accuracy=65.667, wps=6529.1, ups=1.6, wpb=4090.6, bsz=147.8, num_updates=36600, lr=7.39221e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=62, gb_free=17.4, wall=29649
2023-07-03 18:44:02 | INFO | train_inner | epoch 025:   1340 / 1474 loss=1.361, trans_loss=5.231, nll_loss=2.5, w2v_ctc_loss=0.42, task_loss=2.032, contrastive_loss=0.3, total=4164.34, n_correct=2741.05, ppl=5.66, accuracy=65.822, wps=6542.9, ups=1.57, wpb=4164.3, bsz=155.1, num_updates=36700, lr=7.38213e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=63, gb_free=17.1, wall=29713
2023-07-03 18:45:07 | INFO | train_inner | epoch 025:   1440 / 1474 loss=1.36, trans_loss=5.257, nll_loss=2.533, w2v_ctc_loss=0.423, task_loss=2.183, contrastive_loss=0.202, total=4099.11, n_correct=2682.2, ppl=5.79, accuracy=65.434, wps=6355.2, ups=1.55, wpb=4099.1, bsz=149.7, num_updates=36800, lr=7.3721e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=64, gb_free=12.6, wall=29778
2023-07-03 18:45:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 18:45:53 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 2.164 | trans_loss 5.553 | nll_loss 2.829 | w2v_ctc_loss 0.677 | task_loss 2.365 | contrastive_loss 0.26 | total 4003.4 | n_correct 2483.3 | ppl 7.1 | accuracy 62.03 | uer 16.76 | wer 18.575 | raw_wer 18.575 | bleu 20.11 | wps 2315.4 | wpb 4003.4 | bsz 141.8 | num_updates 36834 | best_bleu 20.24
2023-07-03 18:45:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36834 updates
2023-07-03 18:45:53 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_20.1108.pt
2023-07-03 18:45:56 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_20.1108.pt
2023-07-03 18:45:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_20.1108.pt (epoch 25 @ 36834 updates, score 20.11) (writing took 5.578336326405406 seconds)
2023-07-03 18:45:59 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-07-03 18:45:59 | INFO | train | epoch 025 | loss 1.356 | trans_loss 5.231 | nll_loss 2.5 | w2v_ctc_loss 0.42 | task_loss 2.092 | contrastive_loss 0.213 | total 4138.65 | n_correct 2726.46 | ppl 5.66 | accuracy 65.878 | wps 6016.8 | ups 1.45 | wpb 4138.6 | bsz 152.8 | num_updates 36834 | lr 7.36869e-05 | gnorm 0.343 | clip 0 | loss_scale 64 | train_wall 936 | gb_free 14.6 | wall 29830
2023-07-03 18:45:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 18:45:59 | INFO | fairseq.trainer | begin training epoch 26
2023-07-03 18:45:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 18:46:50 | INFO | train_inner | epoch 026:     66 / 1474 loss=1.344, trans_loss=5.204, nll_loss=2.465, w2v_ctc_loss=0.412, task_loss=1.962, contrastive_loss=0.172, total=4180.21, n_correct=2771.01, ppl=5.52, accuracy=66.289, wps=4071.6, ups=0.97, wpb=4180.2, bsz=159.2, num_updates=36900, lr=7.3621e-05, gnorm=0.336, clip=0, loss_scale=64, train_wall=63, gb_free=17.2, wall=29880
2023-07-03 18:47:54 | INFO | train_inner | epoch 026:    166 / 1474 loss=1.355, trans_loss=5.2, nll_loss=2.46, w2v_ctc_loss=0.407, task_loss=1.829, contrastive_loss=0.538, total=4270.78, n_correct=2841.01, ppl=5.5, accuracy=66.522, wps=6608.9, ups=1.55, wpb=4270.8, bsz=170.2, num_updates=37000, lr=7.35215e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=64, gb_free=15.5, wall=29945
2023-07-03 18:48:59 | INFO | train_inner | epoch 026:    266 / 1474 loss=1.351, trans_loss=5.205, nll_loss=2.464, w2v_ctc_loss=0.416, task_loss=2.074, contrastive_loss=0.287, total=4125.04, n_correct=2737.69, ppl=5.52, accuracy=66.368, wps=6388.9, ups=1.55, wpb=4125, bsz=153.6, num_updates=37100, lr=7.34223e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=64, gb_free=15.4, wall=30009
2023-07-03 18:50:03 | INFO | train_inner | epoch 026:    366 / 1474 loss=1.35, trans_loss=5.21, nll_loss=2.473, w2v_ctc_loss=0.416, task_loss=2.003, contrastive_loss=0.205, total=4165.74, n_correct=2756.03, ppl=5.55, accuracy=66.159, wps=6510.4, ups=1.56, wpb=4165.7, bsz=157.3, num_updates=37200, lr=7.33236e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=64, gb_free=17, wall=30073
2023-07-03 18:51:06 | INFO | train_inner | epoch 026:    466 / 1474 loss=1.353, trans_loss=5.205, nll_loss=2.465, w2v_ctc_loss=0.415, task_loss=1.986, contrastive_loss=0.295, total=4170.23, n_correct=2765.62, ppl=5.52, accuracy=66.318, wps=6618, ups=1.59, wpb=4170.2, bsz=157.7, num_updates=37300, lr=7.32252e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=63, gb_free=17.9, wall=30136
2023-07-03 18:52:09 | INFO | train_inner | epoch 026:    566 / 1474 loss=1.35, trans_loss=5.221, nll_loss=2.486, w2v_ctc_loss=0.424, task_loss=2.102, contrastive_loss=0.138, total=4155.02, n_correct=2741.67, ppl=5.6, accuracy=65.985, wps=6537.3, ups=1.57, wpb=4155, bsz=151.9, num_updates=37400, lr=7.31272e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=63, gb_free=17.9, wall=30200
2023-07-03 18:53:13 | INFO | train_inner | epoch 026:    666 / 1474 loss=1.349, trans_loss=5.216, nll_loss=2.481, w2v_ctc_loss=0.416, task_loss=2.134, contrastive_loss=0.11, total=4136.96, n_correct=2733.41, ppl=5.58, accuracy=66.073, wps=6509.8, ups=1.57, wpb=4137, bsz=149.6, num_updates=37500, lr=7.30297e-05, gnorm=0.344, clip=0, loss_scale=64, train_wall=63, gb_free=15.6, wall=30264
2023-07-03 18:54:16 | INFO | train_inner | epoch 026:    766 / 1474 loss=1.356, trans_loss=5.224, nll_loss=2.49, w2v_ctc_loss=0.415, task_loss=2.131, contrastive_loss=0.331, total=4086.28, n_correct=2694.88, ppl=5.62, accuracy=65.949, wps=6465.2, ups=1.58, wpb=4086.3, bsz=149.2, num_updates=37600, lr=7.29325e-05, gnorm=0.348, clip=0, loss_scale=64, train_wall=63, gb_free=15.3, wall=30327
2023-07-03 18:55:20 | INFO | train_inner | epoch 026:    866 / 1474 loss=1.354, trans_loss=5.217, nll_loss=2.48, w2v_ctc_loss=0.421, task_loss=2.067, contrastive_loss=0.137, total=4183.26, n_correct=2764.33, ppl=5.58, accuracy=66.081, wps=6555.8, ups=1.57, wpb=4183.3, bsz=154.1, num_updates=37700, lr=7.28357e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=63, gb_free=17.5, wall=30391
2023-07-03 18:56:24 | INFO | train_inner | epoch 026:    966 / 1474 loss=1.354, trans_loss=5.23, nll_loss=2.498, w2v_ctc_loss=0.413, task_loss=2.157, contrastive_loss=0.247, total=4137.96, n_correct=2723.35, ppl=5.65, accuracy=65.814, wps=6410.6, ups=1.55, wpb=4138, bsz=149.5, num_updates=37800, lr=7.27393e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=64, gb_free=17.1, wall=30455
2023-07-03 18:57:29 | INFO | train_inner | epoch 026:   1066 / 1474 loss=1.348, trans_loss=5.22, nll_loss=2.486, w2v_ctc_loss=0.417, task_loss=2.201, contrastive_loss=0.109, total=4120.53, n_correct=2718.96, ppl=5.6, accuracy=65.986, wps=6427, ups=1.56, wpb=4120.5, bsz=147.1, num_updates=37900, lr=7.26433e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=64, gb_free=16.8, wall=30519
2023-07-03 18:58:33 | INFO | train_inner | epoch 026:   1166 / 1474 loss=1.356, trans_loss=5.231, nll_loss=2.5, w2v_ctc_loss=0.42, task_loss=2.196, contrastive_loss=0.189, total=4113.86, n_correct=2710.12, ppl=5.66, accuracy=65.878, wps=6408.4, ups=1.56, wpb=4113.9, bsz=149.2, num_updates=38000, lr=7.25476e-05, gnorm=0.344, clip=0, loss_scale=64, train_wall=64, gb_free=16.8, wall=30583
2023-07-03 18:58:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 18:58:59 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 2.171 | trans_loss 5.557 | nll_loss 2.828 | w2v_ctc_loss 0.695 | task_loss 2.365 | contrastive_loss 0.256 | total 4003.4 | n_correct 2485.7 | ppl 7.1 | accuracy 62.09 | uer 16.861 | wer 18.597 | raw_wer 18.597 | bleu 20.1 | wps 2027.5 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.24
2023-07-03 18:58:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-07-03 18:58:59 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_26_38000.pt
2023-07-03 18:59:01 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_26_38000.pt
2023-07-03 18:59:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 20.1) (writing took 8.490041512064636 seconds)
2023-07-03 19:00:11 | INFO | train_inner | epoch 026:   1266 / 1474 loss=1.358, trans_loss=5.251, nll_loss=2.525, w2v_ctc_loss=0.43, task_loss=2.341, contrastive_loss=0.112, total=3996.19, n_correct=2617.2, ppl=5.75, accuracy=65.492, wps=4051.7, ups=1.01, wpb=3996.2, bsz=139.6, num_updates=38100, lr=7.24524e-05, gnorm=0.351, clip=0, loss_scale=128, train_wall=63, gb_free=17.8, wall=30682
2023-07-03 19:01:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-03 19:01:16 | INFO | train_inner | epoch 026:   1367 / 1474 loss=1.35, trans_loss=5.227, nll_loss=2.495, w2v_ctc_loss=0.412, task_loss=2.096, contrastive_loss=0.14, total=4149.59, n_correct=2736.47, ppl=5.64, accuracy=65.946, wps=6385, ups=1.54, wpb=4149.6, bsz=155.3, num_updates=38200, lr=7.23575e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=65, gb_free=16.5, wall=30747
2023-07-03 19:02:20 | INFO | train_inner | epoch 026:   1467 / 1474 loss=1.346, trans_loss=5.217, nll_loss=2.482, w2v_ctc_loss=0.409, task_loss=1.992, contrastive_loss=0.128, total=4158.47, n_correct=2750.67, ppl=5.59, accuracy=66.146, wps=6581.9, ups=1.58, wpb=4158.5, bsz=158.3, num_updates=38300, lr=7.22629e-05, gnorm=0.338, clip=0, loss_scale=64, train_wall=63, gb_free=17.5, wall=30810
2023-07-03 19:02:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 19:02:51 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 2.164 | trans_loss 5.555 | nll_loss 2.833 | w2v_ctc_loss 0.674 | task_loss 2.365 | contrastive_loss 0.264 | total 4003.4 | n_correct 2493.1 | ppl 7.12 | accuracy 62.275 | uer 17.073 | wer 18.94 | raw_wer 18.94 | bleu 20.46 | wps 1941.4 | wpb 4003.4 | bsz 141.8 | num_updates 38307 | best_bleu 20.46
2023-07-03 19:02:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38307 updates
2023-07-03 19:02:51 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 19:02:55 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 19:02:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt (epoch 26 @ 38307 updates, score 20.46) (writing took 8.560911079868674 seconds)
2023-07-03 19:03:00 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-07-03 19:03:00 | INFO | train | epoch 026 | loss 1.352 | trans_loss 5.218 | nll_loss 2.483 | w2v_ctc_loss 0.416 | task_loss 2.091 | contrastive_loss 0.211 | total 4137.92 | n_correct 2734.13 | ppl 5.59 | accuracy 66.075 | wps 5972.6 | ups 1.44 | wpb 4137.9 | bsz 152.8 | num_updates 38307 | lr 7.22563e-05 | gnorm 0.342 | clip 0 | loss_scale 64 | train_wall 934 | gb_free 16.2 | wall 30850
2023-07-03 19:03:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 19:03:00 | INFO | fairseq.trainer | begin training epoch 27
2023-07-03 19:03:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 19:04:07 | INFO | train_inner | epoch 027:     93 / 1474 loss=1.337, trans_loss=5.177, nll_loss=2.427, w2v_ctc_loss=0.405, task_loss=2.242, contrastive_loss=0.091, total=4067.62, n_correct=2716.3, ppl=5.38, accuracy=66.779, wps=3801.5, ups=0.93, wpb=4067.6, bsz=142.2, num_updates=38400, lr=7.21688e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=63, gb_free=15.1, wall=30917
2023-07-03 19:05:11 | INFO | train_inner | epoch 027:    193 / 1474 loss=1.341, trans_loss=5.185, nll_loss=2.44, w2v_ctc_loss=0.411, task_loss=1.986, contrastive_loss=0.143, total=4185.52, n_correct=2788.68, ppl=5.43, accuracy=66.627, wps=6464.5, ups=1.54, wpb=4185.5, bsz=160.8, num_updates=38500, lr=7.2075e-05, gnorm=0.338, clip=0, loss_scale=64, train_wall=64, gb_free=17.7, wall=30982
2023-07-03 19:06:16 | INFO | train_inner | epoch 027:    293 / 1474 loss=1.343, trans_loss=5.198, nll_loss=2.457, w2v_ctc_loss=0.414, task_loss=2.085, contrastive_loss=0.111, total=4167.92, n_correct=2770.78, ppl=5.49, accuracy=66.479, wps=6492, ups=1.56, wpb=4167.9, bsz=153.4, num_updates=38600, lr=7.19816e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=64, gb_free=17, wall=31046
2023-07-03 19:07:20 | INFO | train_inner | epoch 027:    393 / 1474 loss=1.355, trans_loss=5.213, nll_loss=2.476, w2v_ctc_loss=0.414, task_loss=2.201, contrastive_loss=0.477, total=4075.21, n_correct=2695.02, ppl=5.56, accuracy=66.132, wps=6313.5, ups=1.55, wpb=4075.2, bsz=148, num_updates=38700, lr=7.18885e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=64, gb_free=17.8, wall=31111
2023-07-03 19:08:24 | INFO | train_inner | epoch 027:    493 / 1474 loss=1.355, trans_loss=5.214, nll_loss=2.479, w2v_ctc_loss=0.415, task_loss=1.908, contrastive_loss=0.344, total=4249.35, n_correct=2809.69, ppl=5.58, accuracy=66.12, wps=6632.3, ups=1.56, wpb=4249.4, bsz=166, num_updates=38800, lr=7.17958e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=64, gb_free=12.4, wall=31175
2023-07-03 19:09:28 | INFO | train_inner | epoch 027:    593 / 1474 loss=1.347, trans_loss=5.203, nll_loss=2.464, w2v_ctc_loss=0.413, task_loss=2.062, contrastive_loss=0.226, total=4133.39, n_correct=2745.29, ppl=5.52, accuracy=66.417, wps=6520.5, ups=1.58, wpb=4133.4, bsz=156, num_updates=38900, lr=7.17035e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=63, gb_free=12.5, wall=31238
2023-07-03 19:10:31 | INFO | train_inner | epoch 027:    693 / 1474 loss=1.35, trans_loss=5.213, nll_loss=2.476, w2v_ctc_loss=0.414, task_loss=2.085, contrastive_loss=0.186, total=4162.71, n_correct=2751.98, ppl=5.57, accuracy=66.11, wps=6533.5, ups=1.57, wpb=4162.7, bsz=152.7, num_updates=39000, lr=7.16115e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=63, gb_free=16.5, wall=31302
2023-07-03 19:11:35 | INFO | train_inner | epoch 027:    793 / 1474 loss=1.346, trans_loss=5.205, nll_loss=2.466, w2v_ctc_loss=0.414, task_loss=2.194, contrastive_loss=0.114, total=4103.81, n_correct=2715.54, ppl=5.53, accuracy=66.171, wps=6437.7, ups=1.57, wpb=4103.8, bsz=147.1, num_updates=39100, lr=7.15199e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=63, gb_free=16.7, wall=31366
2023-07-03 19:12:39 | INFO | train_inner | epoch 027:    893 / 1474 loss=1.348, trans_loss=5.213, nll_loss=2.476, w2v_ctc_loss=0.41, task_loss=2.182, contrastive_loss=0.098, total=4101.56, n_correct=2711, ppl=5.56, accuracy=66.097, wps=6445.1, ups=1.57, wpb=4101.6, bsz=146.1, num_updates=39200, lr=7.14286e-05, gnorm=0.344, clip=0, loss_scale=64, train_wall=63, gb_free=17.8, wall=31429
2023-07-03 19:13:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-03 19:13:44 | INFO | train_inner | epoch 027:    994 / 1474 loss=1.351, trans_loss=5.212, nll_loss=2.476, w2v_ctc_loss=0.41, task_loss=2.055, contrastive_loss=0.432, total=4178.51, n_correct=2764.92, ppl=5.57, accuracy=66.17, wps=6380.3, ups=1.53, wpb=4178.5, bsz=155.6, num_updates=39300, lr=7.13376e-05, gnorm=0.339, clip=0, loss_scale=32, train_wall=65, gb_free=17, wall=31495
2023-07-03 19:14:48 | INFO | train_inner | epoch 027:   1094 / 1474 loss=1.345, trans_loss=5.21, nll_loss=2.472, w2v_ctc_loss=0.411, task_loss=2.114, contrastive_loss=0.131, total=4147.99, n_correct=2743.56, ppl=5.55, accuracy=66.142, wps=6489.9, ups=1.56, wpb=4148, bsz=152.4, num_updates=39400, lr=7.1247e-05, gnorm=0.34, clip=0, loss_scale=32, train_wall=63, gb_free=16.3, wall=31559
2023-07-03 19:15:52 | INFO | train_inner | epoch 027:   1194 / 1474 loss=1.35, trans_loss=5.22, nll_loss=2.486, w2v_ctc_loss=0.417, task_loss=2.189, contrastive_loss=0.139, total=4104.84, n_correct=2709.23, ppl=5.6, accuracy=66.001, wps=6451.9, ups=1.57, wpb=4104.8, bsz=148.6, num_updates=39500, lr=7.11568e-05, gnorm=0.341, clip=0, loss_scale=32, train_wall=63, gb_free=12.7, wall=31622
2023-07-03 19:16:55 | INFO | train_inner | epoch 027:   1294 / 1474 loss=1.353, trans_loss=5.226, nll_loss=2.493, w2v_ctc_loss=0.417, task_loss=2.219, contrastive_loss=0.249, total=4062.86, n_correct=2680.07, ppl=5.63, accuracy=65.965, wps=6408.9, ups=1.58, wpb=4062.9, bsz=146.8, num_updates=39600, lr=7.10669e-05, gnorm=0.349, clip=0, loss_scale=32, train_wall=63, gb_free=16.8, wall=31686
2023-07-03 19:17:58 | INFO | train_inner | epoch 027:   1394 / 1474 loss=1.352, trans_loss=5.215, nll_loss=2.48, w2v_ctc_loss=0.414, task_loss=1.971, contrastive_loss=0.216, total=4157.6, n_correct=2746.44, ppl=5.58, accuracy=66.058, wps=6605.8, ups=1.59, wpb=4157.6, bsz=157, num_updates=39700, lr=7.09773e-05, gnorm=0.343, clip=0, loss_scale=32, train_wall=62, gb_free=17.7, wall=31749
2023-07-03 19:18:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 19:19:14 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 2.165 | trans_loss 5.549 | nll_loss 2.82 | w2v_ctc_loss 0.685 | task_loss 2.365 | contrastive_loss 0.255 | total 4003.4 | n_correct 2488.9 | ppl 7.06 | accuracy 62.17 | uer 17.002 | wer 18.907 | raw_wer 18.907 | bleu 20.23 | wps 2222.3 | wpb 4003.4 | bsz 141.8 | num_updates 39780 | best_bleu 20.46
2023-07-03 19:19:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39780 updates
2023-07-03 19:19:14 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_20.2303.pt
2023-07-03 19:19:16 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_20.2303.pt
2023-07-03 19:19:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_20.2303.pt (epoch 27 @ 39780 updates, score 20.23) (writing took 5.684855836909264 seconds)
2023-07-03 19:19:20 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-07-03 19:19:20 | INFO | train | epoch 027 | loss 1.348 | trans_loss 5.208 | nll_loss 2.469 | w2v_ctc_loss 0.413 | task_loss 2.094 | contrastive_loss 0.208 | total 4137.21 | n_correct 2739.91 | ppl 5.54 | accuracy 66.226 | wps 6216.2 | ups 1.5 | wpb 4137.2 | bsz 152.6 | num_updates 39780 | lr 7.09059e-05 | gnorm 0.343 | clip 0 | loss_scale 32 | train_wall 935 | gb_free 17.9 | wall 31831
2023-07-03 19:19:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 19:19:20 | INFO | fairseq.trainer | begin training epoch 28
2023-07-03 19:19:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 19:19:41 | INFO | train_inner | epoch 028:     20 / 1474 loss=1.345, trans_loss=5.203, nll_loss=2.464, w2v_ctc_loss=0.408, task_loss=2.025, contrastive_loss=0.112, total=4107.3, n_correct=2721.3, ppl=5.52, accuracy=66.255, wps=3996.1, ups=0.97, wpb=4107.3, bsz=152.3, num_updates=39800, lr=7.08881e-05, gnorm=0.352, clip=0, loss_scale=32, train_wall=63, gb_free=17.4, wall=31852
2023-07-03 19:20:45 | INFO | train_inner | epoch 028:    120 / 1474 loss=1.339, trans_loss=5.174, nll_loss=2.425, w2v_ctc_loss=0.41, task_loss=2.199, contrastive_loss=0.106, total=4112.44, n_correct=2747.64, ppl=5.37, accuracy=66.813, wps=6445.1, ups=1.57, wpb=4112.4, bsz=146.3, num_updates=39900, lr=7.07992e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=63, gb_free=14.1, wall=31915
2023-07-03 19:21:48 | INFO | train_inner | epoch 028:    220 / 1474 loss=1.336, trans_loss=5.177, nll_loss=2.429, w2v_ctc_loss=0.403, task_loss=1.971, contrastive_loss=0.123, total=4193.3, n_correct=2800.61, ppl=5.39, accuracy=66.788, wps=6597.2, ups=1.57, wpb=4193.3, bsz=158.2, num_updates=40000, lr=7.07107e-05, gnorm=0.337, clip=0, loss_scale=32, train_wall=63, gb_free=17.1, wall=31979
2023-07-03 19:21:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 19:22:15 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 2.181 | trans_loss 5.558 | nll_loss 2.831 | w2v_ctc_loss 0.726 | task_loss 2.365 | contrastive_loss 0.261 | total 4003.4 | n_correct 2490 | ppl 7.12 | accuracy 62.197 | uer 16.996 | wer 18.78 | raw_wer 18.78 | bleu 20.39 | wps 1940.6 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.46
2023-07-03 19:22:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-07-03 19:22:15 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_28_40000.pt
2023-07-03 19:22:17 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_28_40000.pt
2023-07-03 19:22:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 20.39) (writing took 6.849940470419824 seconds)
tensor(0.0231, device='cuda:0')
tensor(0.0010, device='cuda:0')
2023-07-03 19:23:26 | INFO | train_inner | epoch 028:    320 / 1474 loss=1.357, trans_loss=5.192, nll_loss=2.449, w2v_ctc_loss=0.401, task_loss=2.085, contrastive_loss=0.775, total=4138.69, n_correct=2751.64, ppl=5.46, accuracy=66.486, wps=4215.3, ups=1.02, wpb=4138.7, bsz=157.2, num_updates=40100, lr=7.06225e-05, gnorm=0.343, clip=0, loss_scale=32, train_wall=64, gb_free=13.6, wall=32077
2023-07-03 19:24:30 | INFO | train_inner | epoch 028:    420 / 1474 loss=1.342, trans_loss=5.195, nll_loss=2.453, w2v_ctc_loss=0.413, task_loss=2.157, contrastive_loss=0.099, total=4089.84, n_correct=2717.81, ppl=5.47, accuracy=66.453, wps=6470.7, ups=1.58, wpb=4089.8, bsz=147.8, num_updates=40200, lr=7.05346e-05, gnorm=0.346, clip=0, loss_scale=32, train_wall=63, gb_free=16.9, wall=32140
2023-07-03 19:25:33 | INFO | train_inner | epoch 028:    520 / 1474 loss=1.339, trans_loss=5.185, nll_loss=2.44, w2v_ctc_loss=0.407, task_loss=2.172, contrastive_loss=0.119, total=4098.92, n_correct=2729.9, ppl=5.43, accuracy=66.6, wps=6473.8, ups=1.58, wpb=4098.9, bsz=147.8, num_updates=40300, lr=7.0447e-05, gnorm=0.343, clip=0, loss_scale=32, train_wall=63, gb_free=17.1, wall=32204
2023-07-03 19:26:37 | INFO | train_inner | epoch 028:    620 / 1474 loss=1.342, trans_loss=5.196, nll_loss=2.454, w2v_ctc_loss=0.409, task_loss=2.106, contrastive_loss=0.119, total=4180.1, n_correct=2775.36, ppl=5.48, accuracy=66.395, wps=6532.3, ups=1.56, wpb=4180.1, bsz=152.7, num_updates=40400, lr=7.03598e-05, gnorm=0.341, clip=0, loss_scale=32, train_wall=64, gb_free=16.7, wall=32268
2023-07-03 19:27:41 | INFO | train_inner | epoch 028:    720 / 1474 loss=1.348, trans_loss=5.197, nll_loss=2.458, w2v_ctc_loss=0.405, task_loss=1.883, contrastive_loss=0.347, total=4191.62, n_correct=2787.14, ppl=5.49, accuracy=66.493, wps=6549.1, ups=1.56, wpb=4191.6, bsz=164.6, num_updates=40500, lr=7.02728e-05, gnorm=0.336, clip=0, loss_scale=32, train_wall=64, gb_free=17.2, wall=32332
2023-07-03 19:28:44 | INFO | train_inner | epoch 028:    820 / 1474 loss=1.343, trans_loss=5.195, nll_loss=2.454, w2v_ctc_loss=0.409, task_loss=2.064, contrastive_loss=0.106, total=4088.91, n_correct=2721.86, ppl=5.48, accuracy=66.567, wps=6454.9, ups=1.58, wpb=4088.9, bsz=152.2, num_updates=40600, lr=7.01862e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=63, gb_free=17.2, wall=32395
2023-07-03 19:29:49 | INFO | train_inner | epoch 028:    920 / 1474 loss=1.346, trans_loss=5.208, nll_loss=2.47, w2v_ctc_loss=0.412, task_loss=2.164, contrastive_loss=0.229, total=4117.01, n_correct=2726.34, ppl=5.54, accuracy=66.221, wps=6353.5, ups=1.54, wpb=4117, bsz=149.8, num_updates=40700, lr=7.01e-05, gnorm=0.342, clip=0, loss_scale=32, train_wall=64, gb_free=15.6, wall=32460
2023-07-03 19:30:53 | INFO | train_inner | epoch 028:   1020 / 1474 loss=1.352, trans_loss=5.208, nll_loss=2.472, w2v_ctc_loss=0.415, task_loss=2.041, contrastive_loss=0.329, total=4182.85, n_correct=2765.26, ppl=5.55, accuracy=66.109, wps=6515.8, ups=1.56, wpb=4182.9, bsz=156, num_updates=40800, lr=7.0014e-05, gnorm=0.346, clip=0, loss_scale=32, train_wall=64, gb_free=16.7, wall=32524
2023-07-03 19:31:57 | INFO | train_inner | epoch 028:   1120 / 1474 loss=1.341, trans_loss=5.191, nll_loss=2.449, w2v_ctc_loss=0.406, task_loss=2.01, contrastive_loss=0.148, total=4220.16, n_correct=2801.81, ppl=5.46, accuracy=66.391, wps=6609.9, ups=1.57, wpb=4220.2, bsz=160.5, num_updates=40900, lr=6.99284e-05, gnorm=0.343, clip=0, loss_scale=32, train_wall=63, gb_free=16.4, wall=32588
2023-07-03 19:33:00 | INFO | train_inner | epoch 028:   1220 / 1474 loss=1.34, trans_loss=5.199, nll_loss=2.459, w2v_ctc_loss=0.404, task_loss=2.084, contrastive_loss=0.117, total=4092.46, n_correct=2717.86, ppl=5.5, accuracy=66.411, wps=6467.3, ups=1.58, wpb=4092.5, bsz=151.5, num_updates=41000, lr=6.9843e-05, gnorm=0.339, clip=0, loss_scale=32, train_wall=63, gb_free=17.8, wall=32651
2023-07-03 19:34:05 | INFO | train_inner | epoch 028:   1320 / 1474 loss=1.346, trans_loss=5.208, nll_loss=2.47, w2v_ctc_loss=0.416, task_loss=2.296, contrastive_loss=0.15, total=4084.55, n_correct=2703.81, ppl=5.54, accuracy=66.196, wps=6366.7, ups=1.56, wpb=4084.6, bsz=142.6, num_updates=41100, lr=6.9758e-05, gnorm=0.348, clip=0, loss_scale=32, train_wall=64, gb_free=15.9, wall=32715
2023-07-03 19:35:09 | INFO | train_inner | epoch 028:   1420 / 1474 loss=1.349, trans_loss=5.213, nll_loss=2.477, w2v_ctc_loss=0.413, task_loss=2.19, contrastive_loss=0.198, total=4154.09, n_correct=2745.88, ppl=5.57, accuracy=66.101, wps=6458.5, ups=1.55, wpb=4154.1, bsz=149.7, num_updates=41200, lr=6.96733e-05, gnorm=0.341, clip=0, loss_scale=32, train_wall=64, gb_free=16.2, wall=32780
2023-07-03 19:35:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0231, device='cuda:4')
tensor(0.0010, device='cuda:4')
tensor(0.0231, device='cuda:6')
tensor(0.0010, device='cuda:6')
tensor(0.0231, device='cuda:2')
tensor(0.0010, device='cuda:2')
tensor(0.0231, device='cuda:5')
tensor(0.0010, device='cuda:5')
tensor(0.0231, device='cuda:1')
tensor(0.0010, device='cuda:1')
tensor(0.0231, device='cuda:7')
tensor(0.0010, device='cuda:7')
tensor(0.0231, device='cuda:3')
tensor(0.0010, device='cuda:3')
2023-07-03 19:36:09 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 2.169 | trans_loss 5.553 | nll_loss 2.825 | w2v_ctc_loss 0.692 | task_loss 2.365 | contrastive_loss 0.258 | total 4003.4 | n_correct 2488.1 | ppl 7.09 | accuracy 62.15 | uer 16.728 | wer 18.65 | raw_wer 18.65 | bleu 19.99 | wps 2160.4 | wpb 4003.4 | bsz 141.8 | num_updates 41254 | best_bleu 20.46
2023-07-03 19:36:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41254 updates
2023-07-03 19:36:09 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_19.9902.pt
2023-07-03 19:36:11 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_19.9902.pt
2023-07-03 19:36:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_19.9902.pt (epoch 28 @ 41254 updates, score 19.99) (writing took 5.45194155909121 seconds)
2023-07-03 19:36:14 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-07-03 19:36:14 | INFO | train | epoch 028 | loss 1.344 | trans_loss 5.195 | nll_loss 2.453 | w2v_ctc_loss 0.409 | task_loss 2.092 | contrastive_loss 0.21 | total 4138.65 | n_correct 2749.99 | ppl 5.48 | accuracy 66.447 | wps 6013.7 | ups 1.45 | wpb 4138.6 | bsz 152.8 | num_updates 41254 | lr 6.96277e-05 | gnorm 0.343 | clip 0 | loss_scale 32 | train_wall 934 | gb_free 16.7 | wall 32845
2023-07-03 19:36:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 19:36:15 | INFO | fairseq.trainer | begin training epoch 29
2023-07-03 19:36:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 19:36:53 | INFO | train_inner | epoch 029:     46 / 1474 loss=1.339, trans_loss=5.176, nll_loss=2.43, w2v_ctc_loss=0.409, task_loss=2.003, contrastive_loss=0.144, total=4169.12, n_correct=2783.43, ppl=5.39, accuracy=66.763, wps=4024.3, ups=0.97, wpb=4169.1, bsz=158.2, num_updates=41300, lr=6.95889e-05, gnorm=0.344, clip=0, loss_scale=64, train_wall=64, gb_free=16.6, wall=32883
2023-07-03 19:37:57 | INFO | train_inner | epoch 029:    146 / 1474 loss=1.34, trans_loss=5.18, nll_loss=2.434, w2v_ctc_loss=0.408, task_loss=2.087, contrastive_loss=0.179, total=4105.72, n_correct=2739.97, ppl=5.4, accuracy=66.735, wps=6386.2, ups=1.56, wpb=4105.7, bsz=152, num_updates=41400, lr=6.95048e-05, gnorm=0.348, clip=0, loss_scale=64, train_wall=64, gb_free=16.2, wall=32948
2023-07-03 19:39:02 | INFO | train_inner | epoch 029:    246 / 1474 loss=1.339, trans_loss=5.168, nll_loss=2.419, w2v_ctc_loss=0.398, task_loss=1.915, contrastive_loss=0.348, total=4199.67, n_correct=2812.63, ppl=5.35, accuracy=66.973, wps=6475.6, ups=1.54, wpb=4199.7, bsz=165.3, num_updates=41500, lr=6.9421e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=64, gb_free=15.8, wall=33012
2023-07-03 19:40:06 | INFO | train_inner | epoch 029:    346 / 1474 loss=1.34, trans_loss=5.188, nll_loss=2.444, w2v_ctc_loss=0.413, task_loss=2.244, contrastive_loss=0.112, total=4095.17, n_correct=2727.44, ppl=5.44, accuracy=66.601, wps=6416.2, ups=1.57, wpb=4095.2, bsz=145.6, num_updates=41600, lr=6.93375e-05, gnorm=0.344, clip=0, loss_scale=64, train_wall=63, gb_free=16.8, wall=33076
2023-07-03 19:41:09 | INFO | train_inner | epoch 029:    446 / 1474 loss=1.332, trans_loss=5.163, nll_loss=2.411, w2v_ctc_loss=0.401, task_loss=2.012, contrastive_loss=0.099, total=4157.44, n_correct=2786.45, ppl=5.32, accuracy=67.023, wps=6528, ups=1.57, wpb=4157.4, bsz=153.9, num_updates=41700, lr=6.92543e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=63, gb_free=16.7, wall=33140
2023-07-03 19:41:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-03 19:42:14 | INFO | train_inner | epoch 029:    547 / 1474 loss=1.347, trans_loss=5.199, nll_loss=2.458, w2v_ctc_loss=0.411, task_loss=2.27, contrastive_loss=0.176, total=4136.1, n_correct=2745.39, ppl=5.49, accuracy=66.376, wps=6378.9, ups=1.54, wpb=4136.1, bsz=144.6, num_updates=41800, lr=6.91714e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=64, gb_free=15.6, wall=33205
2023-07-03 19:43:18 | INFO | train_inner | epoch 029:    647 / 1474 loss=1.342, trans_loss=5.176, nll_loss=2.43, w2v_ctc_loss=0.402, task_loss=1.956, contrastive_loss=0.432, total=4145.39, n_correct=2768.66, ppl=5.39, accuracy=66.789, wps=6502.8, ups=1.57, wpb=4145.4, bsz=159.6, num_updates=41900, lr=6.90889e-05, gnorm=0.344, clip=0, loss_scale=32, train_wall=63, gb_free=17.5, wall=33269
2023-07-03 19:44:22 | INFO | train_inner | epoch 029:    747 / 1474 loss=1.339, trans_loss=5.178, nll_loss=2.432, w2v_ctc_loss=0.403, task_loss=1.932, contrastive_loss=0.266, total=4242.46, n_correct=2832.9, ppl=5.4, accuracy=66.775, wps=6578.3, ups=1.55, wpb=4242.5, bsz=164.9, num_updates=42000, lr=6.90066e-05, gnorm=0.341, clip=0, loss_scale=32, train_wall=64, gb_free=16.8, wall=33333
2023-07-03 19:44:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 19:44:47 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 2.179 | trans_loss 5.558 | nll_loss 2.828 | w2v_ctc_loss 0.72 | task_loss 2.365 | contrastive_loss 0.267 | total 4003.4 | n_correct 2484.3 | ppl 7.1 | accuracy 62.055 | uer 16.8 | wer 18.538 | raw_wer 18.538 | bleu 20.05 | wps 2289.7 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.46
2023-07-03 19:44:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-07-03 19:44:47 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_29_42000.pt
2023-07-03 19:44:49 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_29_42000.pt
2023-07-03 19:44:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 20.05) (writing took 6.509633149951696 seconds)
2023-07-03 19:45:58 | INFO | train_inner | epoch 029:    847 / 1474 loss=1.341, trans_loss=5.2, nll_loss=2.459, w2v_ctc_loss=0.406, task_loss=2.324, contrastive_loss=0.101, total=4027.03, n_correct=2671.34, ppl=5.5, accuracy=66.335, wps=4225.7, ups=1.05, wpb=4027, bsz=140.2, num_updates=42100, lr=6.89246e-05, gnorm=0.35, clip=0, loss_scale=32, train_wall=63, gb_free=17.5, wall=33428
2023-07-03 19:47:01 | INFO | train_inner | epoch 029:    947 / 1474 loss=1.342, trans_loss=5.196, nll_loss=2.456, w2v_ctc_loss=0.411, task_loss=2.137, contrastive_loss=0.121, total=4086.72, n_correct=2717.9, ppl=5.49, accuracy=66.506, wps=6447, ups=1.58, wpb=4086.7, bsz=148.2, num_updates=42200, lr=6.88428e-05, gnorm=0.342, clip=0, loss_scale=32, train_wall=63, gb_free=15.6, wall=33492
2023-07-03 19:48:05 | INFO | train_inner | epoch 029:   1047 / 1474 loss=1.342, trans_loss=5.188, nll_loss=2.446, w2v_ctc_loss=0.406, task_loss=2.095, contrastive_loss=0.269, total=4139.4, n_correct=2756.38, ppl=5.45, accuracy=66.589, wps=6486.3, ups=1.57, wpb=4139.4, bsz=153.7, num_updates=42300, lr=6.87614e-05, gnorm=0.344, clip=0, loss_scale=32, train_wall=63, gb_free=15.8, wall=33556
2023-07-03 19:49:08 | INFO | train_inner | epoch 029:   1147 / 1474 loss=1.34, trans_loss=5.196, nll_loss=2.454, w2v_ctc_loss=0.409, task_loss=2.276, contrastive_loss=0.091, total=4072.33, n_correct=2703.91, ppl=5.48, accuracy=66.397, wps=6405, ups=1.57, wpb=4072.3, bsz=142, num_updates=42400, lr=6.86803e-05, gnorm=0.344, clip=0, loss_scale=32, train_wall=63, gb_free=17, wall=33619
2023-07-03 19:50:12 | INFO | train_inner | epoch 029:   1247 / 1474 loss=1.344, trans_loss=5.198, nll_loss=2.458, w2v_ctc_loss=0.412, task_loss=2.114, contrastive_loss=0.11, total=4160.52, n_correct=2763, ppl=5.5, accuracy=66.41, wps=6516.8, ups=1.57, wpb=4160.5, bsz=150.8, num_updates=42500, lr=6.85994e-05, gnorm=0.349, clip=0, loss_scale=32, train_wall=63, gb_free=15.8, wall=33683
2023-07-03 19:51:17 | INFO | train_inner | epoch 029:   1347 / 1474 loss=1.347, trans_loss=5.193, nll_loss=2.452, w2v_ctc_loss=0.409, task_loss=2.071, contrastive_loss=0.235, total=4168.02, n_correct=2772.39, ppl=5.47, accuracy=66.516, wps=6475.8, ups=1.55, wpb=4168, bsz=155.1, num_updates=42600, lr=6.85189e-05, gnorm=0.343, clip=0, loss_scale=32, train_wall=64, gb_free=16.7, wall=33747
2023-07-03 19:52:20 | INFO | train_inner | epoch 029:   1447 / 1474 loss=1.346, trans_loss=5.19, nll_loss=2.448, w2v_ctc_loss=0.408, task_loss=2.045, contrastive_loss=0.297, total=4166.06, n_correct=2774.3, ppl=5.46, accuracy=66.593, wps=6548.9, ups=1.57, wpb=4166.1, bsz=156.6, num_updates=42700, lr=6.84386e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=63, gb_free=17, wall=33811
2023-07-03 19:52:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 19:53:03 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 2.168 | trans_loss 5.554 | nll_loss 2.823 | w2v_ctc_loss 0.689 | task_loss 2.365 | contrastive_loss 0.264 | total 4003.4 | n_correct 2496.2 | ppl 7.07 | accuracy 62.352 | uer 16.877 | wer 18.75 | raw_wer 18.75 | bleu 20.23 | wps 2167.1 | wpb 4003.4 | bsz 141.8 | num_updates 42727 | best_bleu 20.46
2023-07-03 19:53:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42727 updates
2023-07-03 19:53:03 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_20.2308.pt
2023-07-03 19:53:05 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_20.2308.pt
2023-07-03 19:53:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_20.2308.pt (epoch 29 @ 42727 updates, score 20.23) (writing took 5.4799589747563004 seconds)
2023-07-03 19:53:08 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-07-03 19:53:08 | INFO | train | epoch 029 | loss 1.341 | trans_loss 5.186 | nll_loss 2.442 | w2v_ctc_loss 0.407 | task_loss 2.094 | contrastive_loss 0.203 | total 4137.69 | n_correct 2756.9 | ppl 5.43 | accuracy 66.629 | wps 6010.2 | ups 1.45 | wpb 4137.7 | bsz 152.7 | num_updates 42727 | lr 6.8417e-05 | gnorm 0.344 | clip 0 | loss_scale 32 | train_wall 936 | gb_free 16.4 | wall 33859
2023-07-03 19:53:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 19:53:09 | INFO | fairseq.trainer | begin training epoch 30
2023-07-03 19:53:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 19:54:04 | INFO | train_inner | epoch 030:     73 / 1474 loss=1.338, trans_loss=5.167, nll_loss=2.416, w2v_ctc_loss=0.396, task_loss=1.993, contrastive_loss=0.328, total=4175.11, n_correct=2796.88, ppl=5.34, accuracy=66.989, wps=4024.9, ups=0.96, wpb=4175.1, bsz=159.3, num_updates=42800, lr=6.83586e-05, gnorm=0.343, clip=0, loss_scale=32, train_wall=63, gb_free=17.3, wall=33915
2023-07-03 19:55:08 | INFO | train_inner | epoch 030:    173 / 1474 loss=1.332, trans_loss=5.151, nll_loss=2.396, w2v_ctc_loss=0.403, task_loss=1.964, contrastive_loss=0.191, total=4202.64, n_correct=2825.26, ppl=5.26, accuracy=67.226, wps=6578.1, ups=1.57, wpb=4202.6, bsz=159.2, num_updates=42900, lr=6.82789e-05, gnorm=0.339, clip=0, loss_scale=32, train_wall=63, gb_free=16.9, wall=33979
2023-07-03 19:56:11 | INFO | train_inner | epoch 030:    273 / 1474 loss=1.334, trans_loss=5.166, nll_loss=2.415, w2v_ctc_loss=0.406, task_loss=2.157, contrastive_loss=0.098, total=4120.21, n_correct=2757.53, ppl=5.33, accuracy=66.927, wps=6495, ups=1.58, wpb=4120.2, bsz=147.5, num_updates=43000, lr=6.81994e-05, gnorm=0.343, clip=0, loss_scale=32, train_wall=63, gb_free=15.6, wall=34042
2023-07-03 19:57:16 | INFO | train_inner | epoch 030:    373 / 1474 loss=1.33, trans_loss=5.154, nll_loss=2.399, w2v_ctc_loss=0.401, task_loss=2.093, contrastive_loss=0.108, total=4178.23, n_correct=2807.53, ppl=5.28, accuracy=67.194, wps=6489.3, ups=1.55, wpb=4178.2, bsz=153.8, num_updates=43100, lr=6.81203e-05, gnorm=0.338, clip=0, loss_scale=32, train_wall=64, gb_free=10.6, wall=34106
2023-07-03 19:58:18 | INFO | train_inner | epoch 030:    473 / 1474 loss=1.336, trans_loss=5.17, nll_loss=2.421, w2v_ctc_loss=0.4, task_loss=2, contrastive_loss=0.236, total=4124.47, n_correct=2758.59, ppl=5.36, accuracy=66.884, wps=6588.7, ups=1.6, wpb=4124.5, bsz=156.3, num_updates=43200, lr=6.80414e-05, gnorm=0.348, clip=0, loss_scale=32, train_wall=62, gb_free=17.7, wall=34169
2023-07-03 19:59:22 | INFO | train_inner | epoch 030:    573 / 1474 loss=1.334, trans_loss=5.17, nll_loss=2.422, w2v_ctc_loss=0.401, task_loss=2.032, contrastive_loss=0.157, total=4168.41, n_correct=2789.97, ppl=5.36, accuracy=66.931, wps=6504.5, ups=1.56, wpb=4168.4, bsz=156.2, num_updates=43300, lr=6.79628e-05, gnorm=0.341, clip=0, loss_scale=32, train_wall=64, gb_free=17.4, wall=34233
2023-07-03 20:00:27 | INFO | train_inner | epoch 030:    673 / 1474 loss=1.338, trans_loss=5.172, nll_loss=2.424, w2v_ctc_loss=0.406, task_loss=2.067, contrastive_loss=0.185, total=4187.95, n_correct=2795.67, ppl=5.37, accuracy=66.755, wps=6512.3, ups=1.56, wpb=4187.9, bsz=157.5, num_updates=43400, lr=6.78844e-05, gnorm=0.346, clip=0, loss_scale=32, train_wall=64, gb_free=16.1, wall=34297
2023-07-03 20:01:31 | INFO | train_inner | epoch 030:    773 / 1474 loss=1.349, trans_loss=5.194, nll_loss=2.453, w2v_ctc_loss=0.411, task_loss=2.133, contrastive_loss=0.346, total=4105.32, n_correct=2728.47, ppl=5.48, accuracy=66.462, wps=6361.5, ups=1.55, wpb=4105.3, bsz=151.3, num_updates=43500, lr=6.78064e-05, gnorm=0.353, clip=0, loss_scale=32, train_wall=64, gb_free=13.4, wall=34362
2023-07-03 20:02:35 | INFO | train_inner | epoch 030:    873 / 1474 loss=1.337, trans_loss=5.18, nll_loss=2.435, w2v_ctc_loss=0.402, task_loss=2.154, contrastive_loss=0.131, total=4102.11, n_correct=2736.7, ppl=5.41, accuracy=66.714, wps=6444, ups=1.57, wpb=4102.1, bsz=147.8, num_updates=43600, lr=6.77285e-05, gnorm=0.342, clip=0, loss_scale=32, train_wall=63, gb_free=17.5, wall=34426
2023-07-03 20:03:39 | INFO | train_inner | epoch 030:    973 / 1474 loss=1.343, trans_loss=5.191, nll_loss=2.448, w2v_ctc_loss=0.412, task_loss=2.155, contrastive_loss=0.134, total=4129.98, n_correct=2746.42, ppl=5.46, accuracy=66.5, wps=6474.6, ups=1.57, wpb=4130, bsz=150.2, num_updates=43700, lr=6.7651e-05, gnorm=0.344, clip=0, loss_scale=32, train_wall=63, gb_free=16.8, wall=34489
2023-07-03 20:04:43 | INFO | train_inner | epoch 030:   1073 / 1474 loss=1.345, trans_loss=5.192, nll_loss=2.448, w2v_ctc_loss=0.406, task_loss=2.34, contrastive_loss=0.285, total=4101.17, n_correct=2724.44, ppl=5.46, accuracy=66.431, wps=6380.6, ups=1.56, wpb=4101.2, bsz=141.2, num_updates=43800, lr=6.75737e-05, gnorm=0.344, clip=0, loss_scale=64, train_wall=64, gb_free=15.9, wall=34554
2023-07-03 20:05:47 | INFO | train_inner | epoch 030:   1173 / 1474 loss=1.338, trans_loss=5.179, nll_loss=2.434, w2v_ctc_loss=0.4, task_loss=2.021, contrastive_loss=0.249, total=4168.36, n_correct=2781.96, ppl=5.4, accuracy=66.74, wps=6535.1, ups=1.57, wpb=4168.4, bsz=157, num_updates=43900, lr=6.74967e-05, gnorm=0.344, clip=0, loss_scale=64, train_wall=63, gb_free=16.2, wall=34618
2023-07-03 20:06:51 | INFO | train_inner | epoch 030:   1273 / 1474 loss=1.338, trans_loss=5.192, nll_loss=2.449, w2v_ctc_loss=0.409, task_loss=2.322, contrastive_loss=0.116, total=4036.17, n_correct=2683.21, ppl=5.46, accuracy=66.479, wps=6254.2, ups=1.55, wpb=4036.2, bsz=142.1, num_updates=44000, lr=6.742e-05, gnorm=0.348, clip=0, loss_scale=64, train_wall=64, gb_free=15.9, wall=34682
2023-07-03 20:06:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 20:07:17 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 2.165 | trans_loss 5.547 | nll_loss 2.815 | w2v_ctc_loss 0.687 | task_loss 2.365 | contrastive_loss 0.253 | total 4003.4 | n_correct 2496.1 | ppl 7.04 | accuracy 62.35 | uer 16.508 | wer 18.336 | raw_wer 18.336 | bleu 19.94 | wps 2022.2 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.46
2023-07-03 20:07:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-07-03 20:07:17 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_30_44000.pt
2023-07-03 20:07:19 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_30_44000.pt
2023-07-03 20:07:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 19.94) (writing took 5.458315507043153 seconds)
2023-07-03 20:08:27 | INFO | train_inner | epoch 030:   1373 / 1474 loss=1.333, trans_loss=5.172, nll_loss=2.426, w2v_ctc_loss=0.4, task_loss=1.96, contrastive_loss=0.138, total=4165.07, n_correct=2784.19, ppl=5.37, accuracy=66.846, wps=4372, ups=1.05, wpb=4165.1, bsz=160.8, num_updates=44100, lr=6.73435e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=63, gb_free=16.9, wall=34777
2023-07-03 20:09:30 | INFO | train_inner | epoch 030:   1473 / 1474 loss=1.345, trans_loss=5.183, nll_loss=2.439, w2v_ctc_loss=0.399, task_loss=1.966, contrastive_loss=0.427, total=4141.76, n_correct=2762.25, ppl=5.42, accuracy=66.693, wps=6509.4, ups=1.57, wpb=4141.8, bsz=157.2, num_updates=44200, lr=6.72673e-05, gnorm=0.344, clip=0, loss_scale=64, train_wall=63, gb_free=16.6, wall=34841
2023-07-03 20:09:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 20:09:57 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 2.166 | trans_loss 5.555 | nll_loss 2.829 | w2v_ctc_loss 0.682 | task_loss 2.365 | contrastive_loss 0.252 | total 4003.4 | n_correct 2491.8 | ppl 7.1 | accuracy 62.242 | uer 16.603 | wer 18.527 | raw_wer 18.527 | bleu 20.35 | wps 2011.2 | wpb 4003.4 | bsz 141.8 | num_updates 44201 | best_bleu 20.46
2023-07-03 20:09:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44201 updates
2023-07-03 20:09:57 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_20.3507.pt
2023-07-03 20:10:00 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_20.3507.pt
2023-07-03 20:10:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_20.3507.pt (epoch 30 @ 44201 updates, score 20.35) (writing took 5.473615569993854 seconds)
2023-07-03 20:10:03 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-07-03 20:10:03 | INFO | train | epoch 030 | loss 1.338 | trans_loss 5.175 | nll_loss 2.428 | w2v_ctc_loss 0.403 | task_loss 2.092 | contrastive_loss 0.211 | total 4138.65 | n_correct 2764.09 | ppl 5.38 | accuracy 66.787 | wps 6013.2 | ups 1.45 | wpb 4138.6 | bsz 152.8 | num_updates 44201 | lr 6.72665e-05 | gnorm 0.344 | clip 0 | loss_scale 64 | train_wall 935 | gb_free 17.3 | wall 34874
2023-07-03 20:10:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 20:10:03 | INFO | fairseq.trainer | begin training epoch 31
2023-07-03 20:10:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 20:11:15 | INFO | train_inner | epoch 031:     99 / 1474 loss=1.33, trans_loss=5.16, nll_loss=2.407, w2v_ctc_loss=0.404, task_loss=2.228, contrastive_loss=0.106, total=4054.44, n_correct=2721.33, ppl=5.3, accuracy=67.12, wps=3888.4, ups=0.96, wpb=4054.4, bsz=144.1, num_updates=44300, lr=6.71913e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=63, gb_free=16.7, wall=34945
2023-07-03 20:12:19 | INFO | train_inner | epoch 031:    199 / 1474 loss=1.331, trans_loss=5.156, nll_loss=2.401, w2v_ctc_loss=0.398, task_loss=2.14, contrastive_loss=0.16, total=4147.4, n_correct=2783.07, ppl=5.28, accuracy=67.104, wps=6466.1, ups=1.56, wpb=4147.4, bsz=151.1, num_updates=44400, lr=6.71156e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=64, gb_free=16.9, wall=35009
2023-07-03 20:13:23 | INFO | train_inner | epoch 031:    299 / 1474 loss=1.337, trans_loss=5.165, nll_loss=2.414, w2v_ctc_loss=0.404, task_loss=2.144, contrastive_loss=0.239, total=4149.21, n_correct=2780.33, ppl=5.33, accuracy=67.009, wps=6458.2, ups=1.56, wpb=4149.2, bsz=150.8, num_updates=44500, lr=6.70402e-05, gnorm=0.344, clip=0, loss_scale=64, train_wall=64, gb_free=16.3, wall=35074
2023-07-03 20:14:27 | INFO | train_inner | epoch 031:    399 / 1474 loss=1.333, trans_loss=5.165, nll_loss=2.413, w2v_ctc_loss=0.399, task_loss=2.293, contrastive_loss=0.113, total=4092.62, n_correct=2741.43, ppl=5.32, accuracy=66.985, wps=6409.5, ups=1.57, wpb=4092.6, bsz=142.8, num_updates=44600, lr=6.6965e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=63, gb_free=17.3, wall=35138
2023-07-03 20:15:31 | INFO | train_inner | epoch 031:    499 / 1474 loss=1.332, trans_loss=5.16, nll_loss=2.408, w2v_ctc_loss=0.404, task_loss=2.185, contrastive_loss=0.129, total=4111.85, n_correct=2755.69, ppl=5.31, accuracy=67.018, wps=6417.3, ups=1.56, wpb=4111.9, bsz=150.1, num_updates=44700, lr=6.689e-05, gnorm=0.347, clip=0, loss_scale=64, train_wall=64, gb_free=11.5, wall=35202
2023-07-03 20:16:35 | INFO | train_inner | epoch 031:    599 / 1474 loss=1.332, trans_loss=5.163, nll_loss=2.412, w2v_ctc_loss=0.4, task_loss=2.184, contrastive_loss=0.113, total=4083.44, n_correct=2739.06, ppl=5.32, accuracy=67.077, wps=6390.1, ups=1.56, wpb=4083.4, bsz=147.3, num_updates=44800, lr=6.68153e-05, gnorm=0.35, clip=0, loss_scale=64, train_wall=63, gb_free=16.9, wall=35265
2023-07-03 20:17:39 | INFO | train_inner | epoch 031:    699 / 1474 loss=1.326, trans_loss=5.151, nll_loss=2.397, w2v_ctc_loss=0.392, task_loss=1.991, contrastive_loss=0.113, total=4213.98, n_correct=2828.96, ppl=5.27, accuracy=67.133, wps=6556.3, ups=1.56, wpb=4214, bsz=157.8, num_updates=44900, lr=6.67409e-05, gnorm=0.336, clip=0, loss_scale=64, train_wall=64, gb_free=16.6, wall=35330
2023-07-03 20:18:43 | INFO | train_inner | epoch 031:    799 / 1474 loss=1.334, trans_loss=5.174, nll_loss=2.426, w2v_ctc_loss=0.4, task_loss=2.189, contrastive_loss=0.253, total=4097.37, n_correct=2736.85, ppl=5.37, accuracy=66.795, wps=6398.1, ups=1.56, wpb=4097.4, bsz=147.9, num_updates=45000, lr=6.66667e-05, gnorm=0.35, clip=0, loss_scale=64, train_wall=64, gb_free=13.3, wall=35394
tensor(0.0231, device='cuda:0')
tensor(0.0010, device='cuda:0')
2023-07-03 20:19:47 | INFO | train_inner | epoch 031:    899 / 1474 loss=1.331, trans_loss=5.16, nll_loss=2.408, w2v_ctc_loss=0.396, task_loss=2.183, contrastive_loss=0.141, total=4096.72, n_correct=2746.29, ppl=5.31, accuracy=67.036, wps=6430.2, ups=1.57, wpb=4096.7, bsz=148, num_updates=45100, lr=6.65927e-05, gnorm=0.349, clip=0, loss_scale=64, train_wall=63, gb_free=17.4, wall=35458
2023-07-03 20:20:50 | INFO | train_inner | epoch 031:    999 / 1474 loss=1.342, trans_loss=5.174, nll_loss=2.427, w2v_ctc_loss=0.399, task_loss=1.966, contrastive_loss=0.309, total=4187.84, n_correct=2801.84, ppl=5.38, accuracy=66.904, wps=6618.4, ups=1.58, wpb=4187.8, bsz=159.7, num_updates=45200, lr=6.6519e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=63, gb_free=17.4, wall=35521
2023-07-03 20:21:54 | INFO | train_inner | epoch 031:   1099 / 1474 loss=1.333, trans_loss=5.169, nll_loss=2.421, w2v_ctc_loss=0.396, task_loss=2.058, contrastive_loss=0.202, total=4149.44, n_correct=2776.19, ppl=5.36, accuracy=66.905, wps=6543.1, ups=1.58, wpb=4149.4, bsz=157.5, num_updates=45300, lr=6.64455e-05, gnorm=0.348, clip=0, loss_scale=64, train_wall=63, gb_free=17.7, wall=35584
2023-07-03 20:22:57 | INFO | train_inner | epoch 031:   1199 / 1474 loss=1.344, trans_loss=5.177, nll_loss=2.431, w2v_ctc_loss=0.402, task_loss=1.951, contrastive_loss=0.434, total=4189.76, n_correct=2799.59, ppl=5.39, accuracy=66.82, wps=6598.3, ups=1.57, wpb=4189.8, bsz=160.6, num_updates=45400, lr=6.63723e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=63, gb_free=13.6, wall=35648
2023-07-03 20:24:01 | INFO | train_inner | epoch 031:   1299 / 1474 loss=1.334, trans_loss=5.165, nll_loss=2.416, w2v_ctc_loss=0.401, task_loss=1.867, contrastive_loss=0.126, total=4227.44, n_correct=2828.58, ppl=5.34, accuracy=66.91, wps=6639.9, ups=1.57, wpb=4227.4, bsz=163.2, num_updates=45500, lr=6.62994e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=63, gb_free=16.7, wall=35711
2023-07-03 20:25:05 | INFO | train_inner | epoch 031:   1399 / 1474 loss=1.346, trans_loss=5.178, nll_loss=2.434, w2v_ctc_loss=0.4, task_loss=1.914, contrastive_loss=0.533, total=4186.05, n_correct=2796.21, ppl=5.4, accuracy=66.798, wps=6539.3, ups=1.56, wpb=4186.1, bsz=163.3, num_updates=45600, lr=6.62266e-05, gnorm=0.348, clip=0, loss_scale=64, train_wall=64, gb_free=17.6, wall=35775
2023-07-03 20:25:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0231, device='cuda:7')
tensor(0.0010, device='cuda:7')
tensor(0.0231, device='cuda:4')
tensor(0.0010, device='cuda:4')
tensor(0.0231, device='cuda:1')
tensor(0.0010, device='cuda:1')
tensor(0.0231, device='cuda:2')
tensor(0.0010, device='cuda:2')
tensor(0.0231, device='cuda:5')
tensor(0.0010, device='cuda:5')
tensor(0.0231, device='cuda:3')
tensor(0.0010, device='cuda:3')
tensor(0.0231, device='cuda:6')
tensor(0.0010, device='cuda:6')
2023-07-03 20:26:20 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 2.168 | trans_loss 5.55 | nll_loss 2.82 | w2v_ctc_loss 0.693 | task_loss 2.365 | contrastive_loss 0.261 | total 4003.4 | n_correct 2495.7 | ppl 7.06 | accuracy 62.34 | uer 16.694 | wer 18.657 | raw_wer 18.657 | bleu 20.34 | wps 1885.6 | wpb 4003.4 | bsz 141.8 | num_updates 45675 | best_bleu 20.46
2023-07-03 20:26:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45675 updates
2023-07-03 20:26:20 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_20.3408.pt
2023-07-03 20:26:23 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_20.3408.pt
2023-07-03 20:26:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint.best_bleu_20.3408.pt (epoch 31 @ 45675 updates, score 20.34) (writing took 5.554456381127238 seconds)
2023-07-03 20:26:26 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-07-03 20:26:26 | INFO | train | epoch 031 | loss 1.335 | trans_loss 5.166 | nll_loss 2.416 | w2v_ctc_loss 0.4 | task_loss 2.092 | contrastive_loss 0.21 | total 4138.65 | n_correct 2771.38 | ppl 5.34 | accuracy 66.963 | wps 6204.5 | ups 1.5 | wpb 4138.6 | bsz 152.8 | num_updates 45675 | lr 6.61722e-05 | gnorm 0.345 | clip 0 | loss_scale 64 | train_wall 934 | gb_free 12.5 | wall 35857
2023-07-03 20:26:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 20:26:26 | INFO | fairseq.trainer | begin training epoch 32
2023-07-03 20:26:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 20:26:50 | INFO | train_inner | epoch 032:     25 / 1474 loss=1.33, trans_loss=5.162, nll_loss=2.412, w2v_ctc_loss=0.398, task_loss=2.21, contrastive_loss=0.105, total=4042.6, n_correct=2707.17, ppl=5.32, accuracy=66.966, wps=3831.9, ups=0.95, wpb=4042.6, bsz=144.4, num_updates=45700, lr=6.61541e-05, gnorm=0.35, clip=0, loss_scale=64, train_wall=63, gb_free=16.5, wall=35881
2023-07-03 20:27:55 | INFO | train_inner | epoch 032:    125 / 1474 loss=1.317, trans_loss=5.118, nll_loss=2.354, w2v_ctc_loss=0.385, task_loss=1.936, contrastive_loss=0.127, total=4227.68, n_correct=2863.65, ppl=5.11, accuracy=67.736, wps=6568.3, ups=1.55, wpb=4227.7, bsz=161.6, num_updates=45800, lr=6.60819e-05, gnorm=0.337, clip=0, loss_scale=64, train_wall=64, gb_free=16.7, wall=35945
2023-07-03 20:28:59 | INFO | train_inner | epoch 032:    225 / 1474 loss=1.322, trans_loss=5.143, nll_loss=2.386, w2v_ctc_loss=0.393, task_loss=1.995, contrastive_loss=0.144, total=4157.32, n_correct=2799.51, ppl=5.23, accuracy=67.339, wps=6500.5, ups=1.56, wpb=4157.3, bsz=160.3, num_updates=45900, lr=6.60098e-05, gnorm=0.338, clip=0, loss_scale=128, train_wall=63, gb_free=17.3, wall=36009
2023-07-03 20:30:02 | INFO | train_inner | epoch 032:    325 / 1474 loss=1.321, trans_loss=5.126, nll_loss=2.364, w2v_ctc_loss=0.385, task_loss=1.978, contrastive_loss=0.128, total=4183.45, n_correct=2828.76, ppl=5.15, accuracy=67.618, wps=6609, ups=1.58, wpb=4183.4, bsz=157.2, num_updates=46000, lr=6.5938e-05, gnorm=0.338, clip=0, loss_scale=128, train_wall=63, gb_free=17.7, wall=36073
2023-07-03 20:30:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 20:30:27 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 2.176 | trans_loss 5.553 | nll_loss 2.824 | w2v_ctc_loss 0.713 | task_loss 2.365 | contrastive_loss 0.268 | total 4003.4 | n_correct 2499.3 | ppl 7.08 | accuracy 62.429 | uer 16.638 | wer 18.541 | raw_wer 18.541 | bleu 20.25 | wps 2099.4 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.46
2023-07-03 20:30:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-07-03 20:30:27 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_32_46000.pt
2023-07-03 20:30:29 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_32_46000.pt
2023-07-03 20:30:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 20.25) (writing took 6.551932450849563 seconds)
2023-07-03 20:31:39 | INFO | train_inner | epoch 032:    425 / 1474 loss=1.326, trans_loss=5.143, nll_loss=2.387, w2v_ctc_loss=0.395, task_loss=2.078, contrastive_loss=0.122, total=4157.28, n_correct=2800.42, ppl=5.23, accuracy=67.362, wps=4298.1, ups=1.03, wpb=4157.3, bsz=152.9, num_updates=46100, lr=6.58665e-05, gnorm=0.343, clip=0, loss_scale=128, train_wall=64, gb_free=15.1, wall=36169
2023-07-03 20:32:43 | INFO | train_inner | epoch 032:    525 / 1474 loss=1.336, trans_loss=5.159, nll_loss=2.407, w2v_ctc_loss=0.401, task_loss=2.031, contrastive_loss=0.294, total=4198.93, n_correct=2819.89, ppl=5.3, accuracy=67.157, wps=6510.1, ups=1.55, wpb=4198.9, bsz=158.8, num_updates=46200, lr=6.57952e-05, gnorm=0.342, clip=0, loss_scale=128, train_wall=64, gb_free=17.4, wall=36234
2023-07-03 20:33:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-03 20:33:49 | INFO | train_inner | epoch 032:    626 / 1474 loss=1.333, trans_loss=5.164, nll_loss=2.414, w2v_ctc_loss=0.403, task_loss=2.196, contrastive_loss=0.145, total=4136.74, n_correct=2768.5, ppl=5.33, accuracy=66.925, wps=6309.1, ups=1.53, wpb=4136.7, bsz=149, num_updates=46300, lr=6.57241e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=65, gb_free=13.7, wall=36299
2023-07-03 20:34:53 | INFO | train_inner | epoch 032:    726 / 1474 loss=1.335, trans_loss=5.16, nll_loss=2.409, w2v_ctc_loss=0.407, task_loss=2.118, contrastive_loss=0.111, total=4156.23, n_correct=2785.96, ppl=5.31, accuracy=67.031, wps=6464.3, ups=1.56, wpb=4156.2, bsz=151.5, num_updates=46400, lr=6.56532e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=64, gb_free=16.8, wall=36364
2023-07-03 20:35:56 | INFO | train_inner | epoch 032:    826 / 1474 loss=1.323, trans_loss=5.145, nll_loss=2.388, w2v_ctc_loss=0.39, task_loss=2.17, contrastive_loss=0.103, total=4112.3, n_correct=2766.51, ppl=5.24, accuracy=67.274, wps=6497.4, ups=1.58, wpb=4112.3, bsz=147, num_updates=46500, lr=6.55826e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=63, gb_free=16.1, wall=36427
2023-07-03 20:37:00 | INFO | train_inner | epoch 032:    926 / 1474 loss=1.33, trans_loss=5.156, nll_loss=2.404, w2v_ctc_loss=0.397, task_loss=2.168, contrastive_loss=0.103, total=4139.37, n_correct=2775.8, ppl=5.29, accuracy=67.059, wps=6498.4, ups=1.57, wpb=4139.4, bsz=149.3, num_updates=46600, lr=6.55122e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=63, gb_free=13.2, wall=36491
2023-07-03 20:38:03 | INFO | train_inner | epoch 032:   1026 / 1474 loss=1.332, trans_loss=5.164, nll_loss=2.413, w2v_ctc_loss=0.393, task_loss=2.052, contrastive_loss=0.287, total=4121.85, n_correct=2757.39, ppl=5.33, accuracy=66.897, wps=6500.9, ups=1.58, wpb=4121.9, bsz=153, num_updates=46700, lr=6.5442e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=63, gb_free=17.1, wall=36554
2023-07-03 20:38:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-03 20:39:08 | INFO | train_inner | epoch 032:   1127 / 1474 loss=1.337, trans_loss=5.18, nll_loss=2.434, w2v_ctc_loss=0.401, task_loss=2.527, contrastive_loss=0.176, total=4007.05, n_correct=2667.02, ppl=5.4, accuracy=66.558, wps=6161.2, ups=1.54, wpb=4007.1, bsz=133.8, num_updates=46800, lr=6.5372e-05, gnorm=0.351, clip=0, loss_scale=32, train_wall=65, gb_free=14.7, wall=36619
2023-07-03 20:40:12 | INFO | train_inner | epoch 032:   1227 / 1474 loss=1.346, trans_loss=5.182, nll_loss=2.439, w2v_ctc_loss=0.401, task_loss=2.037, contrastive_loss=0.384, total=4158.99, n_correct=2772.87, ppl=5.42, accuracy=66.672, wps=6508.1, ups=1.56, wpb=4159, bsz=156.1, num_updates=46900, lr=6.53023e-05, gnorm=0.354, clip=0, loss_scale=32, train_wall=63, gb_free=16.4, wall=36683
2023-07-03 20:41:16 | INFO | train_inner | epoch 032:   1327 / 1474 loss=1.332, trans_loss=5.164, nll_loss=2.414, w2v_ctc_loss=0.399, task_loss=2.131, contrastive_loss=0.106, total=4079.56, n_correct=2733.5, ppl=5.33, accuracy=67.005, wps=6447.5, ups=1.58, wpb=4079.6, bsz=149, num_updates=47000, lr=6.52328e-05, gnorm=0.347, clip=0, loss_scale=32, train_wall=63, gb_free=17.3, wall=36746
2023-07-03 20:42:19 | INFO | train_inner | epoch 032:   1427 / 1474 loss=1.347, trans_loss=5.179, nll_loss=2.434, w2v_ctc_loss=0.402, task_loss=2.119, contrastive_loss=0.573, total=4107.37, n_correct=2741.01, ppl=5.4, accuracy=66.734, wps=6467.3, ups=1.57, wpb=4107.4, bsz=152.1, num_updates=47100, lr=6.51635e-05, gnorm=0.344, clip=0, loss_scale=32, train_wall=63, gb_free=17.5, wall=36810
2023-07-03 20:42:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 20:43:16 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 2.174 | trans_loss 5.553 | nll_loss 2.823 | w2v_ctc_loss 0.71 | task_loss 2.365 | contrastive_loss 0.262 | total 4003.4 | n_correct 2494 | ppl 7.08 | accuracy 62.297 | uer 16.678 | wer 18.523 | raw_wer 18.523 | bleu 20.07 | wps 1890.7 | wpb 4003.4 | bsz 141.8 | num_updates 47147 | best_bleu 20.46
2023-07-03 20:43:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47147 updates
2023-07-03 20:43:16 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_last.pt
2023-07-03 20:43:20 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_last.pt
2023-07-03 20:43:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_last.pt (epoch 32 @ 47147 updates, score 20.07) (writing took 4.265380972996354 seconds)
2023-07-03 20:43:20 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-07-03 20:43:20 | INFO | train | epoch 032 | loss 1.331 | trans_loss 5.156 | nll_loss 2.403 | w2v_ctc_loss 0.396 | task_loss 2.094 | contrastive_loss 0.211 | total 4138.12 | n_correct 2776.73 | ppl 5.29 | accuracy 67.101 | wps 6006 | ups 1.45 | wpb 4138.1 | bsz 152.7 | num_updates 47147 | lr 6.5131e-05 | gnorm 0.344 | clip 0 | loss_scale 32 | train_wall 934 | gb_free 16.8 | wall 36871
2023-07-03 20:43:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 20:43:21 | INFO | fairseq.trainer | begin training epoch 33
2023-07-03 20:43:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 20:44:03 | INFO | train_inner | epoch 033:     53 / 1474 loss=1.334, trans_loss=5.151, nll_loss=2.398, w2v_ctc_loss=0.395, task_loss=1.978, contrastive_loss=0.317, total=4146.91, n_correct=2785.93, ppl=5.27, accuracy=67.181, wps=3994.5, ups=0.96, wpb=4146.9, bsz=159.9, num_updates=47200, lr=6.50945e-05, gnorm=0.346, clip=0, loss_scale=32, train_wall=63, gb_free=16.3, wall=36914
2023-07-03 20:45:06 | INFO | train_inner | epoch 033:    153 / 1474 loss=1.317, trans_loss=5.131, nll_loss=2.37, w2v_ctc_loss=0.386, task_loss=2.245, contrastive_loss=0.087, total=4073.36, n_correct=2749.35, ppl=5.17, accuracy=67.496, wps=6442.2, ups=1.58, wpb=4073.4, bsz=142.6, num_updates=47300, lr=6.50256e-05, gnorm=0.346, clip=0, loss_scale=32, train_wall=63, gb_free=16.9, wall=36977
2023-07-03 20:46:10 | INFO | train_inner | epoch 033:    253 / 1474 loss=1.329, trans_loss=5.133, nll_loss=2.376, w2v_ctc_loss=0.387, task_loss=1.771, contrastive_loss=0.438, total=4283.64, n_correct=2893.59, ppl=5.19, accuracy=67.55, wps=6690.9, ups=1.56, wpb=4283.6, bsz=173.8, num_updates=47400, lr=6.4957e-05, gnorm=0.336, clip=0, loss_scale=32, train_wall=64, gb_free=16.5, wall=37041
2023-07-03 20:47:14 | INFO | train_inner | epoch 033:    353 / 1474 loss=1.331, trans_loss=5.148, nll_loss=2.393, w2v_ctc_loss=0.397, task_loss=2.135, contrastive_loss=0.148, total=4131.27, n_correct=2778.5, ppl=5.25, accuracy=67.255, wps=6468.5, ups=1.57, wpb=4131.3, bsz=151.1, num_updates=47500, lr=6.48886e-05, gnorm=0.347, clip=0, loss_scale=32, train_wall=63, gb_free=16.4, wall=37105
2023-07-03 20:48:17 | INFO | train_inner | epoch 033:    453 / 1474 loss=1.316, trans_loss=5.117, nll_loss=2.353, w2v_ctc_loss=0.383, task_loss=1.98, contrastive_loss=0.101, total=4135.1, n_correct=2799.21, ppl=5.11, accuracy=67.694, wps=6598.2, ups=1.6, wpb=4135.1, bsz=154.8, num_updates=47600, lr=6.48204e-05, gnorm=0.337, clip=0, loss_scale=32, train_wall=62, gb_free=15.8, wall=37167
2023-07-03 20:49:21 | INFO | train_inner | epoch 033:    553 / 1474 loss=1.331, trans_loss=5.15, nll_loss=2.394, w2v_ctc_loss=0.395, task_loss=2.172, contrastive_loss=0.146, total=4132.78, n_correct=2777.5, ppl=5.26, accuracy=67.207, wps=6459.4, ups=1.56, wpb=4132.8, bsz=147.1, num_updates=47700, lr=6.47524e-05, gnorm=0.344, clip=0, loss_scale=32, train_wall=63, gb_free=17.9, wall=37231
2023-07-03 20:50:25 | INFO | train_inner | epoch 033:    653 / 1474 loss=1.333, trans_loss=5.162, nll_loss=2.411, w2v_ctc_loss=0.396, task_loss=2.157, contrastive_loss=0.212, total=4156.26, n_correct=2784.73, ppl=5.32, accuracy=67.001, wps=6468.7, ups=1.56, wpb=4156.3, bsz=150.4, num_updates=47800, lr=6.46846e-05, gnorm=0.348, clip=0, loss_scale=32, train_wall=64, gb_free=16.3, wall=37296
2023-07-03 20:51:29 | INFO | train_inner | epoch 033:    753 / 1474 loss=1.332, trans_loss=5.158, nll_loss=2.405, w2v_ctc_loss=0.402, task_loss=2.255, contrastive_loss=0.104, total=4074.99, n_correct=2732.37, ppl=5.29, accuracy=67.052, wps=6404.1, ups=1.57, wpb=4075, bsz=144.1, num_updates=47900, lr=6.46171e-05, gnorm=0.347, clip=0, loss_scale=32, train_wall=63, gb_free=16.5, wall=37359
2023-07-03 20:52:32 | INFO | train_inner | epoch 033:    853 / 1474 loss=1.321, trans_loss=5.136, nll_loss=2.379, w2v_ctc_loss=0.384, task_loss=2.009, contrastive_loss=0.246, total=4127.6, n_correct=2788.03, ppl=5.2, accuracy=67.546, wps=6549.1, ups=1.59, wpb=4127.6, bsz=157.7, num_updates=48000, lr=6.45497e-05, gnorm=0.34, clip=0, loss_scale=32, train_wall=63, gb_free=16.4, wall=37422
2023-07-03 20:52:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 20:52:57 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 2.167 | trans_loss 5.553 | nll_loss 2.822 | w2v_ctc_loss 0.69 | task_loss 2.365 | contrastive_loss 0.251 | total 4003.4 | n_correct 2487.4 | ppl 7.07 | accuracy 62.132 | uer 16.611 | wer 18.377 | raw_wer 18.377 | bleu 20.04 | wps 2056 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.46
2023-07-03 20:52:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-07-03 20:52:57 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_33_48000.pt
2023-07-03 20:53:00 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_33_48000.pt
2023-07-03 20:53:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 20.04) (writing took 5.3491429830901325 seconds)
2023-07-03 20:54:06 | INFO | train_inner | epoch 033:    953 / 1474 loss=1.327, trans_loss=5.149, nll_loss=2.395, w2v_ctc_loss=0.399, task_loss=2.071, contrastive_loss=0.128, total=4157.37, n_correct=2795.43, ppl=5.26, accuracy=67.24, wps=4384.9, ups=1.05, wpb=4157.4, bsz=155, num_updates=48100, lr=6.44826e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=63, gb_free=17.5, wall=37517
2023-07-03 20:55:11 | INFO | train_inner | epoch 033:   1053 / 1474 loss=1.336, trans_loss=5.156, nll_loss=2.404, w2v_ctc_loss=0.398, task_loss=2.124, contrastive_loss=0.341, total=4134.8, n_correct=2774.12, ppl=5.29, accuracy=67.092, wps=6444.8, ups=1.56, wpb=4134.8, bsz=153, num_updates=48200, lr=6.44157e-05, gnorm=0.349, clip=0, loss_scale=32, train_wall=64, gb_free=15.9, wall=37581
2023-07-03 20:56:15 | INFO | train_inner | epoch 033:   1153 / 1474 loss=1.334, trans_loss=5.156, nll_loss=2.404, w2v_ctc_loss=0.391, task_loss=2.086, contrastive_loss=0.316, total=4181.58, n_correct=2803.06, ppl=5.29, accuracy=67.034, wps=6533.4, ups=1.56, wpb=4181.6, bsz=155, num_updates=48300, lr=6.43489e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=64, gb_free=15.4, wall=37645
2023-07-03 20:57:19 | INFO | train_inner | epoch 033:   1253 / 1474 loss=1.328, trans_loss=5.154, nll_loss=2.401, w2v_ctc_loss=0.397, task_loss=2.203, contrastive_loss=0.115, total=4115.76, n_correct=2763.57, ppl=5.28, accuracy=67.146, wps=6430.4, ups=1.56, wpb=4115.8, bsz=147.3, num_updates=48400, lr=6.42824e-05, gnorm=0.348, clip=0, loss_scale=32, train_wall=64, gb_free=16.9, wall=37709
2023-07-03 20:58:23 | INFO | train_inner | epoch 033:   1353 / 1474 loss=1.326, trans_loss=5.154, nll_loss=2.402, w2v_ctc_loss=0.396, task_loss=2.047, contrastive_loss=0.154, total=4120.69, n_correct=2769.84, ppl=5.29, accuracy=67.218, wps=6450, ups=1.57, wpb=4120.7, bsz=156, num_updates=48500, lr=6.42161e-05, gnorm=0.344, clip=0, loss_scale=32, train_wall=63, gb_free=17.1, wall=37773
2023-07-03 20:59:27 | INFO | train_inner | epoch 033:   1453 / 1474 loss=1.338, trans_loss=5.16, nll_loss=2.411, w2v_ctc_loss=0.395, task_loss=2.076, contrastive_loss=0.446, total=4125.28, n_correct=2765.85, ppl=5.32, accuracy=67.046, wps=6416.4, ups=1.56, wpb=4125.3, bsz=154.3, num_updates=48600, lr=6.415e-05, gnorm=0.349, clip=0, loss_scale=32, train_wall=64, gb_free=17.1, wall=37838
2023-07-03 20:59:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 21:00:05 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 2.176 | trans_loss 5.554 | nll_loss 2.822 | w2v_ctc_loss 0.715 | task_loss 2.365 | contrastive_loss 0.255 | total 4003.4 | n_correct 2491.2 | ppl 7.07 | accuracy 62.227 | uer 16.68 | wer 18.53 | raw_wer 18.53 | bleu 20.57 | wps 2143.5 | wpb 4003.4 | bsz 141.8 | num_updates 48621 | best_bleu 20.57
2023-07-03 21:00:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48621 updates
2023-07-03 21:00:05 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 21:00:09 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt
2023-07-03 21:00:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_best.pt (epoch 33 @ 48621 updates, score 20.57) (writing took 8.61067401431501 seconds)
2023-07-03 21:00:14 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-07-03 21:00:14 | INFO | train | epoch 033 | loss 1.329 | trans_loss 5.147 | nll_loss 2.392 | w2v_ctc_loss 0.393 | task_loss 2.092 | contrastive_loss 0.211 | total 4138.65 | n_correct 2783.71 | ppl 5.25 | accuracy 67.261 | wps 6016.5 | ups 1.45 | wpb 4138.6 | bsz 152.8 | num_updates 48621 | lr 6.41362e-05 | gnorm 0.345 | clip 0 | loss_scale 32 | train_wall 932 | gb_free 18 | wall 37885
2023-07-03 21:00:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-03 21:00:14 | INFO | fairseq.trainer | begin training epoch 34
2023-07-03 21:00:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-03 21:01:13 | INFO | train_inner | epoch 034:     79 / 1474 loss=1.318, trans_loss=5.12, nll_loss=2.356, w2v_ctc_loss=0.388, task_loss=2.074, contrastive_loss=0.119, total=4131.47, n_correct=2797.92, ppl=5.12, accuracy=67.722, wps=3894.1, ups=0.94, wpb=4131.5, bsz=150.8, num_updates=48700, lr=6.40841e-05, gnorm=0.344, clip=0, loss_scale=32, train_wall=63, gb_free=16.8, wall=37944
2023-07-03 21:02:17 | INFO | train_inner | epoch 034:    179 / 1474 loss=1.319, trans_loss=5.125, nll_loss=2.362, w2v_ctc_loss=0.392, task_loss=2.186, contrastive_loss=0.122, total=4065.88, n_correct=2752.76, ppl=5.14, accuracy=67.704, wps=6379.5, ups=1.57, wpb=4065.9, bsz=147.5, num_updates=48800, lr=6.40184e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=63, gb_free=16.2, wall=38007
2023-07-03 21:02:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-03 21:03:22 | INFO | train_inner | epoch 034:    280 / 1474 loss=1.333, trans_loss=5.146, nll_loss=2.391, w2v_ctc_loss=0.393, task_loss=1.998, contrastive_loss=0.328, total=4224.99, n_correct=2842.22, ppl=5.25, accuracy=67.272, wps=6500.6, ups=1.54, wpb=4225, bsz=160.8, num_updates=48900, lr=6.39529e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=64, gb_free=16.7, wall=38072
2023-07-03 21:04:25 | INFO | train_inner | epoch 034:    380 / 1474 loss=1.323, trans_loss=5.123, nll_loss=2.361, w2v_ctc_loss=0.385, task_loss=1.994, contrastive_loss=0.315, total=4152.22, n_correct=2810.81, ppl=5.14, accuracy=67.694, wps=6517.9, ups=1.57, wpb=4152.2, bsz=158.1, num_updates=49000, lr=6.38877e-05, gnorm=0.343, clip=0, loss_scale=32, train_wall=63, gb_free=16.1, wall=38136
2023-07-03 21:05:29 | INFO | train_inner | epoch 034:    480 / 1474 loss=1.325, trans_loss=5.142, nll_loss=2.384, w2v_ctc_loss=0.395, task_loss=2.273, contrastive_loss=0.108, total=4080.7, n_correct=2749.14, ppl=5.22, accuracy=67.369, wps=6375, ups=1.56, wpb=4080.7, bsz=143.3, num_updates=49100, lr=6.38226e-05, gnorm=0.344, clip=0, loss_scale=32, train_wall=64, gb_free=15.9, wall=38200
2023-07-03 21:06:33 | INFO | train_inner | epoch 034:    580 / 1474 loss=1.322, trans_loss=5.127, nll_loss=2.366, w2v_ctc_loss=0.391, task_loss=2.124, contrastive_loss=0.112, total=4126.98, n_correct=2793.26, ppl=5.16, accuracy=67.683, wps=6491.5, ups=1.57, wpb=4127, bsz=150.1, num_updates=49200, lr=6.37577e-05, gnorm=0.343, clip=0, loss_scale=32, train_wall=63, gb_free=16.4, wall=38264
2023-07-03 21:07:37 | INFO | train_inner | epoch 034:    680 / 1474 loss=1.32, trans_loss=5.13, nll_loss=2.37, w2v_ctc_loss=0.389, task_loss=2.161, contrastive_loss=0.101, total=4110.23, n_correct=2776.73, ppl=5.17, accuracy=67.557, wps=6428.9, ups=1.56, wpb=4110.2, bsz=148.6, num_updates=49300, lr=6.3693e-05, gnorm=0.347, clip=0, loss_scale=32, train_wall=63, gb_free=16.5, wall=38328
2023-07-03 21:08:40 | INFO | train_inner | epoch 034:    780 / 1474 loss=1.329, trans_loss=5.154, nll_loss=2.402, w2v_ctc_loss=0.386, task_loss=2.17, contrastive_loss=0.24, total=4087.05, n_correct=2743.45, ppl=5.28, accuracy=67.125, wps=6445.8, ups=1.58, wpb=4087.1, bsz=148.7, num_updates=49400, lr=6.36285e-05, gnorm=0.346, clip=0, loss_scale=32, train_wall=63, gb_free=16.3, wall=38391
2023-07-03 21:09:44 | INFO | train_inner | epoch 034:    880 / 1474 loss=1.325, trans_loss=5.142, nll_loss=2.385, w2v_ctc_loss=0.391, task_loss=2.226, contrastive_loss=0.158, total=4088.94, n_correct=2757.15, ppl=5.22, accuracy=67.429, wps=6396.8, ups=1.56, wpb=4088.9, bsz=147.1, num_updates=49500, lr=6.35642e-05, gnorm=0.35, clip=0, loss_scale=32, train_wall=63, gb_free=15.1, wall=38455
2023-07-03 21:10:48 | INFO | train_inner | epoch 034:    980 / 1474 loss=1.326, trans_loss=5.144, nll_loss=2.389, w2v_ctc_loss=0.395, task_loss=2.044, contrastive_loss=0.149, total=4175.9, n_correct=2810.73, ppl=5.24, accuracy=67.308, wps=6513.1, ups=1.56, wpb=4175.9, bsz=156.3, num_updates=49600, lr=6.35001e-05, gnorm=0.349, clip=0, loss_scale=32, train_wall=64, gb_free=14.1, wall=38519
2023-07-03 21:11:52 | INFO | train_inner | epoch 034:   1080 / 1474 loss=1.328, trans_loss=5.145, nll_loss=2.389, w2v_ctc_loss=0.395, task_loss=2.017, contrastive_loss=0.115, total=4152.17, n_correct=2791.38, ppl=5.24, accuracy=67.227, wps=6526.7, ups=1.57, wpb=4152.2, bsz=154.5, num_updates=49700, lr=6.34361e-05, gnorm=0.347, clip=0, loss_scale=32, train_wall=63, gb_free=14.8, wall=38583
2023-07-03 21:12:56 | INFO | train_inner | epoch 034:   1180 / 1474 loss=1.325, trans_loss=5.142, nll_loss=2.386, w2v_ctc_loss=0.391, task_loss=2.143, contrastive_loss=0.138, total=4101.68, n_correct=2760.13, ppl=5.23, accuracy=67.293, wps=6452.2, ups=1.57, wpb=4101.7, bsz=149, num_updates=49800, lr=6.33724e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=63, gb_free=16.4, wall=38646
2023-07-03 21:14:00 | INFO | train_inner | epoch 034:   1280 / 1474 loss=1.321, trans_loss=5.139, nll_loss=2.381, w2v_ctc_loss=0.39, task_loss=2.118, contrastive_loss=0.107, total=4146.01, n_correct=2791.76, ppl=5.21, accuracy=67.336, wps=6475.5, ups=1.56, wpb=4146, bsz=150.3, num_updates=49900, lr=6.33089e-05, gnorm=0.348, clip=0, loss_scale=32, train_wall=64, gb_free=17.4, wall=38710
2023-07-03 21:15:04 | INFO | train_inner | epoch 034:   1380 / 1474 loss=1.331, trans_loss=5.155, nll_loss=2.403, w2v_ctc_loss=0.396, task_loss=1.99, contrastive_loss=0.233, total=4197.99, n_correct=2816.06, ppl=5.29, accuracy=67.081, wps=6525.9, ups=1.55, wpb=4198, bsz=160.6, num_updates=50000, lr=6.32456e-05, gnorm=0.344, clip=0, loss_scale=32, train_wall=64, gb_free=17.4, wall=38775
2023-07-03 21:15:04 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-07-03 21:15:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-03 21:15:29 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 2.163 | trans_loss 5.544 | nll_loss 2.811 | w2v_ctc_loss 0.683 | task_loss 2.365 | contrastive_loss 0.254 | total 4003.4 | n_correct 2499.1 | ppl 7.02 | accuracy 62.424 | uer 16.402 | wer 18.202 | raw_wer 18.202 | bleu 20.09 | wps 2061.7 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.57
2023-07-03 21:15:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-07-03 21:15:29 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_34_50000.pt
2023-07-03 21:15:31 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_34_50000.pt
2023-07-03 21:15:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10_valloss/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 20.09) (writing took 5.150774964131415 seconds)
2023-07-03 21:15:35 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-07-03 21:15:35 | INFO | train | epoch 034 | loss 1.325 | trans_loss 5.138 | nll_loss 2.38 | w2v_ctc_loss 0.391 | task_loss 2.108 | contrastive_loss 0.17 | total 4131.55 | n_correct 2785.32 | ppl 5.21 | accuracy 67.416 | wps 6191.1 | ups 1.5 | wpb 4131.6 | bsz 151.9 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.346 | clip 0 | loss_scale 32 | train_wall 875 | gb_free 17.4 | wall 38805
2023-07-03 21:15:35 | INFO | fairseq_cli.train | done training in 38735.8 seconds
/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-07-06 02:43:10 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:10453
2023-07-06 02:43:10 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:10453
2023-07-06 02:43:11 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:10453
2023-07-06 02:43:11 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:10453
2023-07-06 02:43:11 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:10453
2023-07-06 02:43:11 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:10453
2023-07-06 02:43:11 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:10453
2023-07-06 02:43:11 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:10453
2023-07-06 02:43:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-06 02:43:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-06 02:43:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-06 02:43:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-06 02:43:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-06 02:43:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-06 02:43:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-06 02:43:12 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-06 02:43:12 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-06 02:43:12 | INFO | fairseq.distributed.utils | initialized host capios as rank 2
2023-07-06 02:43:12 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-06 02:43:12 | INFO | fairseq.distributed.utils | initialized host capios as rank 0
2023-07-06 02:43:12 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-06 02:43:12 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-06 02:43:12 | INFO | fairseq.distributed.utils | initialized host capios as rank 3
2023-07-06 02:43:12 | INFO | fairseq.distributed.utils | initialized host capios as rank 4
2023-07-06 02:43:12 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-06 02:43:12 | INFO | fairseq.distributed.utils | initialized host capios as rank 5
2023-07-06 02:43:12 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-06 02:43:12 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-06 02:43:12 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-06 02:43:12 | INFO | fairseq.distributed.utils | initialized host capios as rank 6
2023-07-06 02:43:12 | INFO | fairseq.distributed.utils | initialized host capios as rank 1
2023-07-06 02:43:12 | INFO | fairseq.distributed.utils | initialized host capios as rank 7
2023-07-06 02:43:14 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_valloss', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:10453', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_valloss', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_valloss', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_valloss', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_valloss', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_valloss', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_valloss', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_valloss', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-06 02:43:14 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-06 02:43:14 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-06 02:43:14 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-06 02:43:14 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-06 02:43:14 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-06 02:43:19 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-06 02:43:19 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-06 02:43:19 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-06 02:43:20 | INFO | root | load pretrained hubert
2023-07-06 02:43:24 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-06 02:43:24 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-06 02:43:28 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-06 02:43:28 | INFO | root | share the sematic adapter and textual encoder
2023-07-06 02:43:28 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-06 02:43:28 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-06 02:43:28 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-06 02:43:28 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-06 02:43:28 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-06 02:43:28 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-06 02:43:28 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-06 02:43:28 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-06 02:43:28 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-06 02:43:28 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-06 02:43:34 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-06 02:43:35 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-06 02:43:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-06 02:43:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-06 02:43:36 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-06 02:43:36 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-06 02:43:36 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-06 02:43:36 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-06 02:43:36 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-06 02:43:36 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-06 02:43:36 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-06 02:43:36 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-06 02:43:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-06 02:43:36 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-06 02:43:36 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-06 02:43:36 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint_last.pt
2023-07-06 02:43:40 | INFO | fairseq.trainer | load the task parameters
2023-07-06 02:43:41 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint_last.pt (epoch 34 @ 50000 updates)
2023-07-06 02:43:41 | INFO | fairseq.trainer | loading train data for epoch 34
2023-07-06 02:43:41 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-06 02:43:41 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-06 02:43:41 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-06 02:43:42 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-06 02:43:44 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-06 02:43:47 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-06 02:44:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 02:44:52 | INFO | fairseq.trainer | begin training epoch 34
2023-07-06 02:44:52 | INFO | fairseq_cli.train | Start iterating over samples
1.0
1.0
2023-07-06 02:46:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
1.0
1.0
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
1.0
1.0
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
1.0
1.0
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
1.0
1.0
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
1.0
1.0
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
1.0
1.0
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
1.0
1.0
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-07-06 02:46:33 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 2.173 | trans_loss 5.561 | nll_loss 2.838 | w2v_ctc_loss 0.698 | task_loss 2.365 | contrastive_loss 0.259 | total 4003.4 | n_correct 2488.9 | ppl 7.15 | accuracy 62.17 | uer 16.991 | wer 18.773 | raw_wer 18.773 | bleu 20.38 | wps 2015.6 | wpb 4003.4 | bsz 141.8 | num_updates 50094 | best_bleu 20.57
2023-07-06 02:46:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50094 updates
2023-07-06 02:46:33 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint.best_bleu_20.3806.pt
2023-07-06 02:46:36 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint.best_bleu_20.3806.pt
2023-07-06 02:46:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint.best_bleu_20.3806.pt (epoch 34 @ 50094 updates, score 20.38) (writing took 5.076821437003673 seconds)
2023-07-06 02:46:38 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-07-06 02:46:39 | INFO | train | epoch 034 | loss 1.326 | trans_loss 5.139 | nll_loss 2.381 | w2v_ctc_loss 0.391 | task_loss 2.094 | contrastive_loss 0.195 | total 4137.27 | n_correct 2788.32 | ppl 5.21 | accuracy 67.395 | wps 5580.1 | ups 1.35 | wpb 4139.7 | bsz 152.6 | num_updates 50094 | lr 6.31862e-05 | gnorm 0.346 | clip 0 | loss_scale 32 | train_wall 943 | gb_free 17.5 | wall 0
2023-07-06 02:46:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 02:46:39 | INFO | fairseq.trainer | begin training epoch 35
2023-07-06 02:46:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 02:46:50 | INFO | train_inner | epoch 035:      6 / 1474 loss=1.347, trans_loss=5.147, nll_loss=2.394, w2v_ctc_loss=0.387, task_loss=1.925, contrastive_loss=0.511, total=4206.43, n_correct=2825.16, ppl=5.25, accuracy=67.163, wps=1979.9, ups=0.47, wpb=4242.4, bsz=163.4, num_updates=50100, lr=6.31824e-05, gnorm=0.346, clip=0, loss_scale=32, train_wall=72, gb_free=17.9, wall=0
2023-07-06 02:47:53 | INFO | train_inner | epoch 035:    106 / 1474 loss=1.321, trans_loss=5.116, nll_loss=2.352, w2v_ctc_loss=0.381, task_loss=2.011, contrastive_loss=0.392, total=4171.34, n_correct=2826.63, ppl=5.1, accuracy=67.763, wps=6614.3, ups=1.59, wpb=4171.3, bsz=156.8, num_updates=50200, lr=6.31194e-05, gnorm=0.343, clip=0, loss_scale=32, train_wall=63, gb_free=15.9, wall=0
2023-07-06 02:48:54 | INFO | train_inner | epoch 035:    206 / 1474 loss=1.313, trans_loss=5.109, nll_loss=2.343, w2v_ctc_loss=0.381, task_loss=1.967, contrastive_loss=0.109, total=4167.37, n_correct=2832.73, ppl=5.07, accuracy=67.974, wps=6795.7, ups=1.63, wpb=4167.4, bsz=158, num_updates=50300, lr=6.30567e-05, gnorm=0.343, clip=0, loss_scale=32, train_wall=61, gb_free=13.9, wall=0
2023-07-06 02:49:56 | INFO | train_inner | epoch 035:    306 / 1474 loss=1.324, trans_loss=5.127, nll_loss=2.365, w2v_ctc_loss=0.388, task_loss=2.177, contrastive_loss=0.437, total=4114.35, n_correct=2781.59, ppl=5.15, accuracy=67.607, wps=6641.2, ups=1.61, wpb=4114.4, bsz=150, num_updates=50400, lr=6.29941e-05, gnorm=0.352, clip=0, loss_scale=32, train_wall=62, gb_free=12.8, wall=0
2023-07-06 02:50:58 | INFO | train_inner | epoch 035:    406 / 1474 loss=1.325, trans_loss=5.131, nll_loss=2.37, w2v_ctc_loss=0.394, task_loss=2.319, contrastive_loss=0.114, total=4069.11, n_correct=2746.19, ppl=5.17, accuracy=67.489, wps=6620.4, ups=1.63, wpb=4069.1, bsz=141.8, num_updates=50500, lr=6.29317e-05, gnorm=0.353, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=0
2023-07-06 02:51:59 | INFO | train_inner | epoch 035:    506 / 1474 loss=1.326, trans_loss=5.13, nll_loss=2.369, w2v_ctc_loss=0.386, task_loss=2.122, contrastive_loss=0.256, total=4158.81, n_correct=2811.81, ppl=5.16, accuracy=67.611, wps=6742.6, ups=1.62, wpb=4158.8, bsz=152.5, num_updates=50600, lr=6.28695e-05, gnorm=0.349, clip=0, loss_scale=32, train_wall=61, gb_free=16.5, wall=0
2023-07-06 02:53:00 | INFO | train_inner | epoch 035:    606 / 1474 loss=1.32, trans_loss=5.122, nll_loss=2.359, w2v_ctc_loss=0.382, task_loss=2.07, contrastive_loss=0.273, total=4167.77, n_correct=2823.81, ppl=5.13, accuracy=67.753, wps=6830.3, ups=1.64, wpb=4167.8, bsz=154.8, num_updates=50700, lr=6.28074e-05, gnorm=0.343, clip=0, loss_scale=32, train_wall=61, gb_free=16.4, wall=0
2023-07-06 02:54:02 | INFO | train_inner | epoch 035:    706 / 1474 loss=1.325, trans_loss=5.134, nll_loss=2.375, w2v_ctc_loss=0.395, task_loss=2.194, contrastive_loss=0.132, total=4084.16, n_correct=2757.1, ppl=5.19, accuracy=67.507, wps=6618.2, ups=1.62, wpb=4084.2, bsz=147.4, num_updates=50800, lr=6.27456e-05, gnorm=0.352, clip=0, loss_scale=32, train_wall=61, gb_free=17.2, wall=0
2023-07-06 02:55:04 | INFO | train_inner | epoch 035:    806 / 1474 loss=1.32, trans_loss=5.127, nll_loss=2.366, w2v_ctc_loss=0.39, task_loss=2.057, contrastive_loss=0.146, total=4151.07, n_correct=2804.85, ppl=5.16, accuracy=67.569, wps=6691.9, ups=1.61, wpb=4151.1, bsz=155.8, num_updates=50900, lr=6.26839e-05, gnorm=0.344, clip=0, loss_scale=32, train_wall=62, gb_free=17.1, wall=0
2023-07-06 02:56:06 | INFO | train_inner | epoch 035:    906 / 1474 loss=1.323, trans_loss=5.131, nll_loss=2.371, w2v_ctc_loss=0.393, task_loss=2.213, contrastive_loss=0.108, total=4097.72, n_correct=2766.84, ppl=5.17, accuracy=67.521, wps=6619.5, ups=1.62, wpb=4097.7, bsz=146.5, num_updates=51000, lr=6.26224e-05, gnorm=0.349, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=0
2023-07-06 02:57:07 | INFO | train_inner | epoch 035:   1006 / 1474 loss=1.332, trans_loss=5.145, nll_loss=2.391, w2v_ctc_loss=0.39, task_loss=2.123, contrastive_loss=0.358, total=4141.74, n_correct=2785.1, ppl=5.25, accuracy=67.245, wps=6746, ups=1.63, wpb=4141.7, bsz=153.1, num_updates=51100, lr=6.25611e-05, gnorm=0.349, clip=0, loss_scale=32, train_wall=61, gb_free=17.7, wall=0
2023-07-06 02:58:08 | INFO | train_inner | epoch 035:   1106 / 1474 loss=1.325, trans_loss=5.136, nll_loss=2.378, w2v_ctc_loss=0.394, task_loss=2.001, contrastive_loss=0.124, total=4182.91, n_correct=2821.9, ppl=5.2, accuracy=67.463, wps=6848.9, ups=1.64, wpb=4182.9, bsz=155.7, num_updates=51200, lr=6.25e-05, gnorm=0.349, clip=0, loss_scale=32, train_wall=61, gb_free=10.7, wall=0
2023-07-06 02:59:09 | INFO | train_inner | epoch 035:   1206 / 1474 loss=1.325, trans_loss=5.13, nll_loss=2.371, w2v_ctc_loss=0.384, task_loss=1.937, contrastive_loss=0.231, total=4207.87, n_correct=2842.69, ppl=5.17, accuracy=67.557, wps=6933.2, ups=1.65, wpb=4207.9, bsz=160.2, num_updates=51300, lr=6.24391e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=60, gb_free=15.1, wall=0
2023-07-06 03:00:11 | INFO | train_inner | epoch 035:   1306 / 1474 loss=1.322, trans_loss=5.139, nll_loss=2.383, w2v_ctc_loss=0.392, task_loss=2.004, contrastive_loss=0.13, total=4141.67, n_correct=2793.84, ppl=5.22, accuracy=67.457, wps=6656.7, ups=1.61, wpb=4141.7, bsz=157, num_updates=51400, lr=6.23783e-05, gnorm=0.348, clip=0, loss_scale=32, train_wall=62, gb_free=16.5, wall=0
2023-07-06 03:01:12 | INFO | train_inner | epoch 035:   1406 / 1474 loss=1.322, trans_loss=5.143, nll_loss=2.386, w2v_ctc_loss=0.388, task_loss=2.285, contrastive_loss=0.106, total=4057.93, n_correct=2729.56, ppl=5.23, accuracy=67.265, wps=6636.4, ups=1.64, wpb=4057.9, bsz=142.8, num_updates=51500, lr=6.23177e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=61, gb_free=15.6, wall=0
2023-07-06 03:01:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-06 03:02:19 | INFO | dev_st | epoch 035 | valid on 'dev_st' subset | loss 2.175 | trans_loss 5.55 | nll_loss 2.819 | w2v_ctc_loss 0.714 | task_loss 2.365 | contrastive_loss 0.264 | total 4003.4 | n_correct 2495 | ppl 7.05 | accuracy 62.322 | uer 16.593 | wer 18.377 | raw_wer 18.377 | bleu 20.23 | wps 2071.5 | wpb 4003.4 | bsz 141.8 | num_updates 51568 | best_bleu 20.57
2023-07-06 03:02:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 51568 updates
2023-07-06 03:02:19 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint_last.pt
2023-07-06 03:02:23 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint_last.pt
2023-07-06 03:02:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint_last.pt (epoch 35 @ 51568 updates, score 20.23) (writing took 4.0637043839960825 seconds)
2023-07-06 03:02:23 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-07-06 03:02:23 | INFO | train | epoch 035 | loss 1.323 | trans_loss 5.13 | nll_loss 2.37 | w2v_ctc_loss 0.388 | task_loss 2.092 | contrastive_loss 0.21 | total 4138.65 | n_correct 2795.96 | ppl 5.17 | accuracy 67.557 | wps 6456.2 | ups 1.56 | wpb 4138.6 | bsz 152.8 | num_updates 51568 | lr 6.22766e-05 | gnorm 0.347 | clip 0 | loss_scale 32 | train_wall 902 | gb_free 17.4 | wall 0
2023-07-06 03:02:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 03:02:24 | INFO | fairseq.trainer | begin training epoch 36
2023-07-06 03:02:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 03:02:50 | INFO | train_inner | epoch 036:     32 / 1474 loss=1.32, trans_loss=5.121, nll_loss=2.36, w2v_ctc_loss=0.385, task_loss=2.034, contrastive_loss=0.192, total=4128.66, n_correct=2793.76, ppl=5.13, accuracy=67.667, wps=4214.5, ups=1.02, wpb=4128.7, bsz=154.5, num_updates=51600, lr=6.22573e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=0
2023-07-06 03:03:52 | INFO | train_inner | epoch 036:    132 / 1474 loss=1.317, trans_loss=5.112, nll_loss=2.346, w2v_ctc_loss=0.387, task_loss=2.179, contrastive_loss=0.127, total=4101.15, n_correct=2784.26, ppl=5.08, accuracy=67.89, wps=6700.8, ups=1.63, wpb=4101.1, bsz=149.4, num_updates=51700, lr=6.2197e-05, gnorm=0.349, clip=0, loss_scale=32, train_wall=61, gb_free=16.7, wall=0
2023-07-06 03:04:53 | INFO | train_inner | epoch 036:    232 / 1474 loss=1.317, trans_loss=5.112, nll_loss=2.346, w2v_ctc_loss=0.383, task_loss=2.123, contrastive_loss=0.151, total=4153.27, n_correct=2820.66, ppl=5.08, accuracy=67.914, wps=6769.9, ups=1.63, wpb=4153.3, bsz=151.8, num_updates=51800, lr=6.2137e-05, gnorm=0.346, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=0
2023-07-06 03:05:53 | INFO | train_inner | epoch 036:    332 / 1474 loss=1.31, trans_loss=5.103, nll_loss=2.335, w2v_ctc_loss=0.372, task_loss=1.985, contrastive_loss=0.101, total=4162.11, n_correct=2831.27, ppl=5.05, accuracy=68.025, wps=6899.5, ups=1.66, wpb=4162.1, bsz=155.1, num_updates=51900, lr=6.20771e-05, gnorm=0.342, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=0
2023-07-06 03:06:55 | INFO | train_inner | epoch 036:    432 / 1474 loss=1.324, trans_loss=5.113, nll_loss=2.349, w2v_ctc_loss=0.383, task_loss=1.83, contrastive_loss=0.343, total=4234.05, n_correct=2875.65, ppl=5.09, accuracy=67.917, wps=6901.4, ups=1.63, wpb=4234.1, bsz=166.6, num_updates=52000, lr=6.20174e-05, gnorm=0.347, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=0
2023-07-06 03:06:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-06 03:07:20 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 2.18 | trans_loss 5.557 | nll_loss 2.833 | w2v_ctc_loss 0.722 | task_loss 2.365 | contrastive_loss 0.272 | total 4003.4 | n_correct 2489.9 | ppl 7.12 | accuracy 62.195 | uer 16.922 | wer 18.791 | raw_wer 18.791 | bleu 19.99 | wps 2000.5 | wpb 4003.4 | bsz 141.8 | num_updates 52000 | best_bleu 20.57
2023-07-06 03:07:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 52000 updates
2023-07-06 03:07:20 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint_36_52000.pt
2023-07-06 03:07:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint_36_52000.pt
2023-07-06 03:07:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint_36_52000.pt (epoch 36 @ 52000 updates, score 19.99) (writing took 4.969155426995712 seconds)
2023-07-06 03:08:27 | INFO | train_inner | epoch 036:    532 / 1474 loss=1.328, trans_loss=5.127, nll_loss=2.367, w2v_ctc_loss=0.381, task_loss=2.09, contrastive_loss=0.628, total=4149.22, n_correct=2803.83, ppl=5.16, accuracy=67.575, wps=4502, ups=1.09, wpb=4149.2, bsz=156.2, num_updates=52100, lr=6.19578e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=61, gb_free=17.9, wall=0
2023-07-06 03:09:28 | INFO | train_inner | epoch 036:    632 / 1474 loss=1.316, trans_loss=5.104, nll_loss=2.337, w2v_ctc_loss=0.381, task_loss=2.015, contrastive_loss=0.263, total=4179.05, n_correct=2842.82, ppl=5.05, accuracy=68.026, wps=6865.7, ups=1.64, wpb=4179.1, bsz=158.4, num_updates=52200, lr=6.18984e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=60, gb_free=17.3, wall=0
2023-07-06 03:10:29 | INFO | train_inner | epoch 036:    732 / 1474 loss=1.321, trans_loss=5.13, nll_loss=2.37, w2v_ctc_loss=0.388, task_loss=2.032, contrastive_loss=0.133, total=4180.07, n_correct=2825.09, ppl=5.17, accuracy=67.585, wps=6839.4, ups=1.64, wpb=4180.1, bsz=157.8, num_updates=52300, lr=6.18392e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=61, gb_free=14, wall=0
2023-07-06 03:11:30 | INFO | train_inner | epoch 036:    832 / 1474 loss=1.335, trans_loss=5.14, nll_loss=2.384, w2v_ctc_loss=0.385, task_loss=1.958, contrastive_loss=0.465, total=4178.14, n_correct=2815.69, ppl=5.22, accuracy=67.391, wps=6847.9, ups=1.64, wpb=4178.1, bsz=160.9, num_updates=52400, lr=6.17802e-05, gnorm=0.354, clip=0, loss_scale=64, train_wall=61, gb_free=16.5, wall=0
2023-07-06 03:12:31 | INFO | train_inner | epoch 036:    932 / 1474 loss=1.315, trans_loss=5.118, nll_loss=2.355, w2v_ctc_loss=0.384, task_loss=2.116, contrastive_loss=0.111, total=4175.34, n_correct=2827.01, ppl=5.12, accuracy=67.707, wps=6855.5, ups=1.64, wpb=4175.3, bsz=152.7, num_updates=52500, lr=6.17213e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=60, gb_free=17.7, wall=0
2023-07-06 03:13:32 | INFO | train_inner | epoch 036:   1032 / 1474 loss=1.317, trans_loss=5.125, nll_loss=2.363, w2v_ctc_loss=0.384, task_loss=2.161, contrastive_loss=0.102, total=4176.5, n_correct=2825.47, ppl=5.14, accuracy=67.652, wps=6818.2, ups=1.63, wpb=4176.5, bsz=150.8, num_updates=52600, lr=6.16626e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=61, gb_free=16.5, wall=0
2023-07-06 03:14:33 | INFO | train_inner | epoch 036:   1132 / 1474 loss=1.319, trans_loss=5.123, nll_loss=2.362, w2v_ctc_loss=0.392, task_loss=2.094, contrastive_loss=0.133, total=4130.46, n_correct=2791.79, ppl=5.14, accuracy=67.59, wps=6762.4, ups=1.64, wpb=4130.5, bsz=153.3, num_updates=52700, lr=6.16041e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=61, gb_free=17.9, wall=0
2023-07-06 03:15:34 | INFO | train_inner | epoch 036:   1232 / 1474 loss=1.32, trans_loss=5.13, nll_loss=2.369, w2v_ctc_loss=0.394, task_loss=2.323, contrastive_loss=0.095, total=4051.75, n_correct=2735.21, ppl=5.17, accuracy=67.507, wps=6691.8, ups=1.65, wpb=4051.8, bsz=140, num_updates=52800, lr=6.15457e-05, gnorm=0.35, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=0
2023-07-06 03:16:34 | INFO | train_inner | epoch 036:   1332 / 1474 loss=1.32, trans_loss=5.127, nll_loss=2.366, w2v_ctc_loss=0.387, task_loss=2.089, contrastive_loss=0.118, total=4108.74, n_correct=2776.25, ppl=5.15, accuracy=67.569, wps=6835, ups=1.66, wpb=4108.7, bsz=152.6, num_updates=52900, lr=6.14875e-05, gnorm=0.35, clip=0, loss_scale=64, train_wall=60, gb_free=16.1, wall=0
2023-07-06 03:17:35 | INFO | train_inner | epoch 036:   1432 / 1474 loss=1.328, trans_loss=5.145, nll_loss=2.389, w2v_ctc_loss=0.394, task_loss=2.355, contrastive_loss=0.218, total=4048.28, n_correct=2721.99, ppl=5.24, accuracy=67.238, wps=6612.5, ups=1.63, wpb=4048.3, bsz=139.4, num_updates=53000, lr=6.14295e-05, gnorm=0.353, clip=0, loss_scale=64, train_wall=61, gb_free=11.3, wall=0
2023-07-06 03:18:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-06 03:18:24 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 2.181 | trans_loss 5.554 | nll_loss 2.825 | w2v_ctc_loss 0.732 | task_loss 2.365 | contrastive_loss 0.265 | total 4003.4 | n_correct 2497.9 | ppl 7.09 | accuracy 62.394 | uer 16.593 | wer 18.355 | raw_wer 18.355 | bleu 20.38 | wps 2158.7 | wpb 4003.4 | bsz 141.8 | num_updates 53042 | best_bleu 20.57
2023-07-06 03:18:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 53042 updates
2023-07-06 03:18:24 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint.best_bleu_20.3802.pt
2023-07-06 03:18:27 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint.best_bleu_20.3802.pt
2023-07-06 03:18:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint.best_bleu_20.3802.pt (epoch 36 @ 53042 updates, score 20.38) (writing took 5.121800723005435 seconds)
2023-07-06 03:18:30 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-07-06 03:18:30 | INFO | train | epoch 036 | loss 1.32 | trans_loss 5.121 | nll_loss 2.359 | w2v_ctc_loss 0.385 | task_loss 2.092 | contrastive_loss 0.212 | total 4138.65 | n_correct 2801.67 | ppl 5.13 | accuracy 67.695 | wps 6314.2 | ups 1.53 | wpb 4138.6 | bsz 152.8 | num_updates 53042 | lr 6.14052e-05 | gnorm 0.347 | clip 0 | loss_scale 64 | train_wall 891 | gb_free 17 | wall 0
2023-07-06 03:18:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 03:18:30 | INFO | fairseq.trainer | begin training epoch 37
2023-07-06 03:18:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 03:19:13 | INFO | train_inner | epoch 037:     58 / 1474 loss=1.311, trans_loss=5.101, nll_loss=2.333, w2v_ctc_loss=0.378, task_loss=2.097, contrastive_loss=0.128, total=4092.98, n_correct=2783.79, ppl=5.04, accuracy=68.014, wps=4178, ups=1.02, wpb=4093, bsz=150, num_updates=53100, lr=6.13716e-05, gnorm=0.349, clip=0, loss_scale=64, train_wall=60, gb_free=15.5, wall=0
2023-07-06 03:20:15 | INFO | train_inner | epoch 037:    158 / 1474 loss=1.318, trans_loss=5.11, nll_loss=2.344, w2v_ctc_loss=0.383, task_loss=2.128, contrastive_loss=0.23, total=4124.56, n_correct=2805.39, ppl=5.08, accuracy=68.017, wps=6665.3, ups=1.62, wpb=4124.6, bsz=153.4, num_updates=53200, lr=6.13139e-05, gnorm=0.35, clip=0, loss_scale=64, train_wall=61, gb_free=16.5, wall=0
2023-07-06 03:21:16 | INFO | train_inner | epoch 037:    258 / 1474 loss=1.308, trans_loss=5.091, nll_loss=2.32, w2v_ctc_loss=0.372, task_loss=1.956, contrastive_loss=0.117, total=4188.93, n_correct=2858.01, ppl=4.99, accuracy=68.228, wps=6881.3, ups=1.64, wpb=4188.9, bsz=159.7, num_updates=53300, lr=6.12564e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=60, gb_free=15.1, wall=0
2023-07-06 03:22:16 | INFO | train_inner | epoch 037:    358 / 1474 loss=1.32, trans_loss=5.11, nll_loss=2.343, w2v_ctc_loss=0.389, task_loss=2.113, contrastive_loss=0.136, total=4171.05, n_correct=2831.85, ppl=5.07, accuracy=67.893, wps=6884.4, ups=1.65, wpb=4171.1, bsz=152.9, num_updates=53400, lr=6.1199e-05, gnorm=0.348, clip=0, loss_scale=64, train_wall=60, gb_free=16.1, wall=0
2023-07-06 03:22:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-06 03:23:18 | INFO | train_inner | epoch 037:    459 / 1474 loss=1.326, trans_loss=5.121, nll_loss=2.359, w2v_ctc_loss=0.385, task_loss=2.056, contrastive_loss=0.338, total=4159.53, n_correct=2818.06, ppl=5.13, accuracy=67.749, wps=6728.5, ups=1.62, wpb=4159.5, bsz=155.4, num_updates=53500, lr=6.11418e-05, gnorm=0.351, clip=0, loss_scale=32, train_wall=61, gb_free=14.1, wall=0
2023-07-06 03:24:19 | INFO | train_inner | epoch 037:    559 / 1474 loss=1.31, trans_loss=5.1, nll_loss=2.331, w2v_ctc_loss=0.381, task_loss=2.164, contrastive_loss=0.11, total=4092.13, n_correct=2786.69, ppl=5.03, accuracy=68.099, wps=6704.2, ups=1.64, wpb=4092.1, bsz=149.9, num_updates=53600, lr=6.10847e-05, gnorm=0.344, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=0
2023-07-06 03:25:20 | INFO | train_inner | epoch 037:    659 / 1474 loss=1.319, trans_loss=5.124, nll_loss=2.361, w2v_ctc_loss=0.392, task_loss=2.194, contrastive_loss=0.13, total=4102.49, n_correct=2771.74, ppl=5.14, accuracy=67.562, wps=6753.1, ups=1.65, wpb=4102.5, bsz=146, num_updates=53700, lr=6.10278e-05, gnorm=0.354, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=0
2023-07-06 03:26:21 | INFO | train_inner | epoch 037:    759 / 1474 loss=1.317, trans_loss=5.117, nll_loss=2.354, w2v_ctc_loss=0.383, task_loss=2.09, contrastive_loss=0.245, total=4123.95, n_correct=2793.98, ppl=5.11, accuracy=67.75, wps=6791.8, ups=1.65, wpb=4123.9, bsz=152.4, num_updates=53800, lr=6.09711e-05, gnorm=0.35, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=0
2023-07-06 03:27:21 | INFO | train_inner | epoch 037:    859 / 1474 loss=1.312, trans_loss=5.1, nll_loss=2.332, w2v_ctc_loss=0.375, task_loss=1.962, contrastive_loss=0.113, total=4159.03, n_correct=2830.39, ppl=5.03, accuracy=68.054, wps=6837.6, ups=1.64, wpb=4159, bsz=157.9, num_updates=53900, lr=6.09145e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=0
2023-07-06 03:28:22 | INFO | train_inner | epoch 037:    959 / 1474 loss=1.319, trans_loss=5.126, nll_loss=2.365, w2v_ctc_loss=0.389, task_loss=2.234, contrastive_loss=0.125, total=4097.89, n_correct=2773.84, ppl=5.15, accuracy=67.689, wps=6773, ups=1.65, wpb=4097.9, bsz=146.2, num_updates=54000, lr=6.08581e-05, gnorm=0.35, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=0
2023-07-06 03:28:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-06 03:28:46 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 2.189 | trans_loss 5.567 | nll_loss 2.843 | w2v_ctc_loss 0.74 | task_loss 2.365 | contrastive_loss 0.273 | total 4003.4 | n_correct 2494.6 | ppl 7.18 | accuracy 62.312 | uer 16.89 | wer 18.851 | raw_wer 18.851 | bleu 20.26 | wps 2219.3 | wpb 4003.4 | bsz 141.8 | num_updates 54000 | best_bleu 20.57
2023-07-06 03:28:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54000 updates
2023-07-06 03:28:46 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint_37_54000.pt
2023-07-06 03:28:48 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint_37_54000.pt
2023-07-06 03:28:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint_37_54000.pt (epoch 37 @ 54000 updates, score 20.26) (writing took 6.002979523997055 seconds)
2023-07-06 03:29:53 | INFO | train_inner | epoch 037:   1059 / 1474 loss=1.319, trans_loss=5.112, nll_loss=2.348, w2v_ctc_loss=0.379, task_loss=1.96, contrastive_loss=0.378, total=4162.64, n_correct=2824.99, ppl=5.09, accuracy=67.865, wps=4574.7, ups=1.1, wpb=4162.6, bsz=159.9, num_updates=54100, lr=6.08018e-05, gnorm=0.346, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=0
2023-07-06 03:30:54 | INFO | train_inner | epoch 037:   1159 / 1474 loss=1.325, trans_loss=5.128, nll_loss=2.368, w2v_ctc_loss=0.382, task_loss=2.029, contrastive_loss=0.436, total=4176.35, n_correct=2822.67, ppl=5.16, accuracy=67.587, wps=6877.3, ups=1.65, wpb=4176.4, bsz=156.1, num_updates=54200, lr=6.07457e-05, gnorm=0.344, clip=0, loss_scale=32, train_wall=60, gb_free=16.2, wall=0
2023-07-06 03:31:54 | INFO | train_inner | epoch 037:   1259 / 1474 loss=1.316, trans_loss=5.118, nll_loss=2.355, w2v_ctc_loss=0.379, task_loss=2.028, contrastive_loss=0.132, total=4167.2, n_correct=2822.25, ppl=5.12, accuracy=67.725, wps=6890.1, ups=1.65, wpb=4167.2, bsz=155.9, num_updates=54300, lr=6.06897e-05, gnorm=0.346, clip=0, loss_scale=32, train_wall=60, gb_free=16.2, wall=0
2023-07-06 03:32:56 | INFO | train_inner | epoch 037:   1359 / 1474 loss=1.324, trans_loss=5.129, nll_loss=2.368, w2v_ctc_loss=0.396, task_loss=2.296, contrastive_loss=0.112, total=4072.63, n_correct=2750.17, ppl=5.16, accuracy=67.528, wps=6623.6, ups=1.63, wpb=4072.6, bsz=143, num_updates=54400, lr=6.06339e-05, gnorm=0.351, clip=0, loss_scale=32, train_wall=61, gb_free=16.1, wall=0
2023-07-06 03:33:56 | INFO | train_inner | epoch 037:   1459 / 1474 loss=1.318, trans_loss=5.123, nll_loss=2.361, w2v_ctc_loss=0.381, task_loss=2.076, contrastive_loss=0.173, total=4155.97, n_correct=2813.59, ppl=5.14, accuracy=67.7, wps=6836.2, ups=1.64, wpb=4156, bsz=152.6, num_updates=54500, lr=6.05783e-05, gnorm=0.344, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=0
2023-07-06 03:34:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-06 03:34:31 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 2.177 | trans_loss 5.551 | nll_loss 2.822 | w2v_ctc_loss 0.72 | task_loss 2.365 | contrastive_loss 0.266 | total 4003.4 | n_correct 2497.6 | ppl 7.07 | accuracy 62.387 | uer 16.436 | wer 18.247 | raw_wer 18.247 | bleu 20.33 | wps 2167.9 | wpb 4003.4 | bsz 141.8 | num_updates 54515 | best_bleu 20.57
2023-07-06 03:34:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54515 updates
2023-07-06 03:34:31 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint.best_bleu_20.3303.pt
2023-07-06 03:34:33 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint.best_bleu_20.3303.pt
2023-07-06 03:34:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint.best_bleu_20.3303.pt (epoch 37 @ 54515 updates, score 20.33) (writing took 5.03593080000428 seconds)
2023-07-06 03:34:36 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-07-06 03:34:36 | INFO | train | epoch 037 | loss 1.318 | trans_loss 5.114 | nll_loss 2.35 | w2v_ctc_loss 0.383 | task_loss 2.095 | contrastive_loss 0.196 | total 4137.21 | n_correct 2806.15 | ppl 5.1 | accuracy 67.827 | wps 6308.5 | ups 1.52 | wpb 4137.2 | bsz 152.6 | num_updates 54515 | lr 6.05699e-05 | gnorm 0.348 | clip 0 | loss_scale 32 | train_wall 891 | gb_free 13.2 | wall 0
2023-07-06 03:34:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 03:34:36 | INFO | fairseq.trainer | begin training epoch 38
2023-07-06 03:34:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 03:35:35 | INFO | train_inner | epoch 038:     85 / 1474 loss=1.309, trans_loss=5.094, nll_loss=2.322, w2v_ctc_loss=0.377, task_loss=2.184, contrastive_loss=0.103, total=4085.19, n_correct=2791.48, ppl=5, accuracy=68.332, wps=4161.6, ups=1.02, wpb=4085.2, bsz=146.8, num_updates=54600, lr=6.05228e-05, gnorm=0.353, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=0
2023-07-06 03:36:35 | INFO | train_inner | epoch 038:    185 / 1474 loss=1.309, trans_loss=5.096, nll_loss=2.325, w2v_ctc_loss=0.379, task_loss=2.193, contrastive_loss=0.11, total=4081.12, n_correct=2777.08, ppl=5.01, accuracy=68.047, wps=6740.3, ups=1.65, wpb=4081.1, bsz=146.3, num_updates=54700, lr=6.04674e-05, gnorm=0.35, clip=0, loss_scale=32, train_wall=60, gb_free=17, wall=0
2023-07-06 03:37:35 | INFO | train_inner | epoch 038:    285 / 1474 loss=1.309, trans_loss=5.096, nll_loss=2.325, w2v_ctc_loss=0.375, task_loss=2.185, contrastive_loss=0.147, total=4073.75, n_correct=2777.93, ppl=5.01, accuracy=68.191, wps=6761.4, ups=1.66, wpb=4073.8, bsz=147.9, num_updates=54800, lr=6.04122e-05, gnorm=0.351, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=0
2023-07-06 03:38:36 | INFO | train_inner | epoch 038:    385 / 1474 loss=1.312, trans_loss=5.098, nll_loss=2.329, w2v_ctc_loss=0.381, task_loss=2.073, contrastive_loss=0.149, total=4173.43, n_correct=2844.56, ppl=5.02, accuracy=68.159, wps=6854.2, ups=1.64, wpb=4173.4, bsz=154.1, num_updates=54900, lr=6.03572e-05, gnorm=0.347, clip=0, loss_scale=32, train_wall=60, gb_free=14.1, wall=0
2023-07-06 03:39:37 | INFO | train_inner | epoch 038:    485 / 1474 loss=1.313, trans_loss=5.098, nll_loss=2.328, w2v_ctc_loss=0.38, task_loss=2.017, contrastive_loss=0.143, total=4192.03, n_correct=2855.59, ppl=5.02, accuracy=68.12, wps=6892.2, ups=1.64, wpb=4192, bsz=156, num_updates=55000, lr=6.03023e-05, gnorm=0.351, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=0
1.0
1.0
2023-07-06 03:40:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-06 03:40:39 | INFO | train_inner | epoch 038:    586 / 1474 loss=1.32, trans_loss=5.116, nll_loss=2.35, w2v_ctc_loss=0.383, task_loss=2.153, contrastive_loss=0.26, total=4149.77, n_correct=2812.91, ppl=5.1, accuracy=67.785, wps=6667.7, ups=1.61, wpb=4149.8, bsz=150.4, num_updates=55100, lr=6.02475e-05, gnorm=0.349, clip=0, loss_scale=16, train_wall=62, gb_free=15.2, wall=0
2023-07-06 03:41:40 | INFO | train_inner | epoch 038:    686 / 1474 loss=1.314, trans_loss=5.094, nll_loss=2.324, w2v_ctc_loss=0.373, task_loss=1.981, contrastive_loss=0.443, total=4173.18, n_correct=2843.84, ppl=5.01, accuracy=68.146, wps=6870.2, ups=1.65, wpb=4173.2, bsz=160.9, num_updates=55200, lr=6.01929e-05, gnorm=0.347, clip=0, loss_scale=16, train_wall=60, gb_free=17.1, wall=0
2023-07-06 03:42:41 | INFO | train_inner | epoch 038:    786 / 1474 loss=1.314, trans_loss=5.096, nll_loss=2.327, w2v_ctc_loss=0.375, task_loss=1.912, contrastive_loss=0.296, total=4187.51, n_correct=2851.72, ppl=5.02, accuracy=68.101, wps=6894.6, ups=1.65, wpb=4187.5, bsz=163.6, num_updates=55300, lr=6.01385e-05, gnorm=0.351, clip=0, loss_scale=16, train_wall=60, gb_free=17, wall=0
2023-07-06 03:43:41 | INFO | train_inner | epoch 038:    886 / 1474 loss=1.309, trans_loss=5.096, nll_loss=2.328, w2v_ctc_loss=0.38, task_loss=1.975, contrastive_loss=0.117, total=4124.92, n_correct=2808.42, ppl=5.02, accuracy=68.084, wps=6895.4, ups=1.67, wpb=4124.9, bsz=155.8, num_updates=55400, lr=6.00842e-05, gnorm=0.345, clip=0, loss_scale=16, train_wall=59, gb_free=13.6, wall=0
2023-07-06 03:44:41 | INFO | train_inner | epoch 038:    986 / 1474 loss=1.313, trans_loss=5.117, nll_loss=2.353, w2v_ctc_loss=0.38, task_loss=2.111, contrastive_loss=0.185, total=4110.21, n_correct=2785.99, ppl=5.11, accuracy=67.782, wps=6832.1, ups=1.66, wpb=4110.2, bsz=150.3, num_updates=55500, lr=6.003e-05, gnorm=0.344, clip=0, loss_scale=16, train_wall=60, gb_free=17, wall=0
2023-07-06 03:45:42 | INFO | train_inner | epoch 038:   1086 / 1474 loss=1.319, trans_loss=5.106, nll_loss=2.341, w2v_ctc_loss=0.38, task_loss=1.898, contrastive_loss=0.245, total=4250.47, n_correct=2886.08, ppl=5.07, accuracy=67.9, wps=6934.1, ups=1.63, wpb=4250.5, bsz=164.7, num_updates=55600, lr=5.9976e-05, gnorm=0.345, clip=0, loss_scale=16, train_wall=61, gb_free=15.9, wall=0
2023-07-06 03:46:43 | INFO | train_inner | epoch 038:   1186 / 1474 loss=1.32, trans_loss=5.125, nll_loss=2.364, w2v_ctc_loss=0.39, task_loss=2.272, contrastive_loss=0.128, total=4090.6, n_correct=2764.14, ppl=5.15, accuracy=67.573, wps=6682.5, ups=1.63, wpb=4090.6, bsz=145.1, num_updates=55700, lr=5.99222e-05, gnorm=0.353, clip=0, loss_scale=16, train_wall=61, gb_free=16.3, wall=0
2023-07-06 03:47:44 | INFO | train_inner | epoch 038:   1286 / 1474 loss=1.32, trans_loss=5.123, nll_loss=2.361, w2v_ctc_loss=0.385, task_loss=2.242, contrastive_loss=0.117, total=4140.1, n_correct=2799.23, ppl=5.14, accuracy=67.613, wps=6796.5, ups=1.64, wpb=4140.1, bsz=147.2, num_updates=55800, lr=5.98684e-05, gnorm=0.349, clip=0, loss_scale=16, train_wall=60, gb_free=15.7, wall=0
2023-07-06 03:48:45 | INFO | train_inner | epoch 038:   1386 / 1474 loss=1.324, trans_loss=5.121, nll_loss=2.359, w2v_ctc_loss=0.386, task_loss=2.083, contrastive_loss=0.226, total=4145.35, n_correct=2804.22, ppl=5.13, accuracy=67.647, wps=6857.1, ups=1.65, wpb=4145.4, bsz=154.2, num_updates=55900, lr=5.98149e-05, gnorm=0.35, clip=0, loss_scale=16, train_wall=60, gb_free=15.9, wall=0
2023-07-06 03:49:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
2023-07-06 03:50:03 | INFO | dev_st | epoch 038 | valid on 'dev_st' subset | loss 2.177 | trans_loss 5.562 | nll_loss 2.836 | w2v_ctc_loss 0.708 | task_loss 2.365 | contrastive_loss 0.266 | total 4003.4 | n_correct 2492 | ppl 7.14 | accuracy 62.247 | uer 16.526 | wer 18.329 | raw_wer 18.329 | bleu 20.28 | wps 2219.9 | wpb 4003.4 | bsz 141.8 | num_updates 55988 | best_bleu 20.57
2023-07-06 03:50:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 55988 updates
2023-07-06 03:50:03 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint.best_bleu_20.2801.pt
2023-07-06 03:50:05 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint.best_bleu_20.2801.pt
2023-07-06 03:50:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint.best_bleu_20.2801.pt (epoch 38 @ 55988 updates, score 20.28) (writing took 5.15103574800014 seconds)
2023-07-06 03:50:08 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-07-06 03:50:08 | INFO | train | epoch 038 | loss 1.315 | trans_loss 5.106 | nll_loss 2.339 | w2v_ctc_loss 0.38 | task_loss 2.095 | contrastive_loss 0.198 | total 4137.12 | n_correct 2811.29 | ppl 5.06 | accuracy 67.953 | wps 6532.7 | ups 1.58 | wpb 4137.1 | bsz 152.6 | num_updates 55988 | lr 5.97678e-05 | gnorm 0.349 | clip 0 | loss_scale 16 | train_wall 888 | gb_free 16.8 | wall 0
2023-07-06 03:50:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 03:50:09 | INFO | fairseq.trainer | begin training epoch 39
2023-07-06 03:50:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 03:50:23 | INFO | train_inner | epoch 039:     12 / 1474 loss=1.319, trans_loss=5.116, nll_loss=2.352, w2v_ctc_loss=0.383, task_loss=2.233, contrastive_loss=0.242, total=4040.68, n_correct=2737.75, ppl=5.1, accuracy=67.755, wps=4104.8, ups=1.02, wpb=4040.7, bsz=143.6, num_updates=56000, lr=5.97614e-05, gnorm=0.354, clip=0, loss_scale=16, train_wall=59, gb_free=16.3, wall=0
2023-07-06 03:50:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-06 03:50:47 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 2.176 | trans_loss 5.552 | nll_loss 2.819 | w2v_ctc_loss 0.713 | task_loss 2.365 | contrastive_loss 0.264 | total 4003.4 | n_correct 2501.3 | ppl 7.06 | accuracy 62.479 | uer 16.481 | wer 18.288 | raw_wer 18.288 | bleu 20.3 | wps 2345.6 | wpb 4003.4 | bsz 141.8 | num_updates 56000 | best_bleu 20.57
2023-07-06 03:50:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 56000 updates
2023-07-06 03:50:47 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint_39_56000.pt
2023-07-06 03:50:49 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint_39_56000.pt
2023-07-06 03:50:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint_39_56000.pt (epoch 39 @ 56000 updates, score 20.3) (writing took 6.261278855003184 seconds)
2023-07-06 03:51:53 | INFO | train_inner | epoch 039:    112 / 1474 loss=1.304, trans_loss=5.076, nll_loss=2.298, w2v_ctc_loss=0.375, task_loss=2.237, contrastive_loss=0.105, total=4056.32, n_correct=2776.15, ppl=4.92, accuracy=68.44, wps=4509.7, ups=1.11, wpb=4056.3, bsz=143, num_updates=56100, lr=5.97081e-05, gnorm=0.345, clip=0, loss_scale=16, train_wall=59, gb_free=15.9, wall=0
2023-07-06 03:52:55 | INFO | train_inner | epoch 039:    212 / 1474 loss=1.304, trans_loss=5.075, nll_loss=2.298, w2v_ctc_loss=0.373, task_loss=2.13, contrastive_loss=0.106, total=4133.67, n_correct=2829.08, ppl=4.92, accuracy=68.44, wps=6696.9, ups=1.62, wpb=4133.7, bsz=150.3, num_updates=56200, lr=5.9655e-05, gnorm=0.345, clip=0, loss_scale=16, train_wall=61, gb_free=16.7, wall=0
2023-07-06 03:53:55 | INFO | train_inner | epoch 039:    312 / 1474 loss=1.303, trans_loss=5.077, nll_loss=2.3, w2v_ctc_loss=0.375, task_loss=2.141, contrastive_loss=0.116, total=4134.37, n_correct=2831.29, ppl=4.93, accuracy=68.482, wps=6830.5, ups=1.65, wpb=4134.4, bsz=149.4, num_updates=56300, lr=5.9602e-05, gnorm=0.344, clip=0, loss_scale=16, train_wall=60, gb_free=16.5, wall=0
2023-07-06 03:54:57 | INFO | train_inner | epoch 039:    412 / 1474 loss=1.316, trans_loss=5.098, nll_loss=2.329, w2v_ctc_loss=0.379, task_loss=2.053, contrastive_loss=0.409, total=4130.57, n_correct=2812.45, ppl=5.03, accuracy=68.089, wps=6749.6, ups=1.63, wpb=4130.6, bsz=156.9, num_updates=56400, lr=5.95491e-05, gnorm=0.349, clip=0, loss_scale=16, train_wall=61, gb_free=16.6, wall=0
2023-07-06 03:55:58 | INFO | train_inner | epoch 039:    512 / 1474 loss=1.313, trans_loss=5.096, nll_loss=2.325, w2v_ctc_loss=0.374, task_loss=2.073, contrastive_loss=0.431, total=4144.84, n_correct=2823.12, ppl=5.01, accuracy=68.112, wps=6786.3, ups=1.64, wpb=4144.8, bsz=155.4, num_updates=56500, lr=5.94964e-05, gnorm=0.344, clip=0, loss_scale=16, train_wall=61, gb_free=16.7, wall=0
2023-07-06 03:56:58 | INFO | train_inner | epoch 039:    612 / 1474 loss=1.314, trans_loss=5.102, nll_loss=2.334, w2v_ctc_loss=0.375, task_loss=2.108, contrastive_loss=0.222, total=4133.85, n_correct=2813.17, ppl=5.04, accuracy=68.052, wps=6837.2, ups=1.65, wpb=4133.9, bsz=151.9, num_updates=56600, lr=5.94438e-05, gnorm=0.349, clip=0, loss_scale=16, train_wall=60, gb_free=17, wall=0
2023-07-06 03:57:58 | INFO | train_inner | epoch 039:    712 / 1474 loss=1.316, trans_loss=5.101, nll_loss=2.333, w2v_ctc_loss=0.376, task_loss=2.036, contrastive_loss=0.21, total=4137.3, n_correct=2817.31, ppl=5.04, accuracy=68.095, wps=6949.6, ups=1.68, wpb=4137.3, bsz=152.9, num_updates=56700, lr=5.93914e-05, gnorm=0.348, clip=0, loss_scale=16, train_wall=59, gb_free=16.2, wall=0
2023-07-06 03:59:00 | INFO | train_inner | epoch 039:    812 / 1474 loss=1.313, trans_loss=5.101, nll_loss=2.332, w2v_ctc_loss=0.382, task_loss=2.122, contrastive_loss=0.132, total=4165.72, n_correct=2837.24, ppl=5.04, accuracy=68.109, wps=6678.9, ups=1.6, wpb=4165.7, bsz=153.7, num_updates=56800, lr=5.93391e-05, gnorm=0.347, clip=0, loss_scale=16, train_wall=62, gb_free=15.5, wall=0
2023-07-06 04:00:00 | INFO | train_inner | epoch 039:    912 / 1474 loss=1.312, trans_loss=5.106, nll_loss=2.339, w2v_ctc_loss=0.379, task_loss=2.151, contrastive_loss=0.137, total=4131.2, n_correct=2806.6, ppl=5.06, accuracy=67.937, wps=6844.6, ups=1.66, wpb=4131.2, bsz=150.3, num_updates=56900, lr=5.92869e-05, gnorm=0.351, clip=0, loss_scale=16, train_wall=60, gb_free=12.6, wall=0
2023-07-06 04:01:02 | INFO | train_inner | epoch 039:   1012 / 1474 loss=1.323, trans_loss=5.117, nll_loss=2.354, w2v_ctc_loss=0.379, task_loss=2.041, contrastive_loss=0.359, total=4199.31, n_correct=2849.58, ppl=5.11, accuracy=67.858, wps=6840.5, ups=1.63, wpb=4199.3, bsz=159.6, num_updates=57000, lr=5.92349e-05, gnorm=0.354, clip=0, loss_scale=16, train_wall=61, gb_free=16.8, wall=0
2023-07-06 04:02:03 | INFO | train_inner | epoch 039:   1112 / 1474 loss=1.315, trans_loss=5.096, nll_loss=2.326, w2v_ctc_loss=0.375, task_loss=1.958, contrastive_loss=0.305, total=4192.7, n_correct=2858.12, ppl=5.02, accuracy=68.169, wps=6911.3, ups=1.65, wpb=4192.7, bsz=160.9, num_updates=57100, lr=5.9183e-05, gnorm=0.348, clip=0, loss_scale=32, train_wall=60, gb_free=12.4, wall=0
2023-07-06 04:03:03 | INFO | train_inner | epoch 039:   1212 / 1474 loss=1.315, trans_loss=5.112, nll_loss=2.348, w2v_ctc_loss=0.379, task_loss=2.078, contrastive_loss=0.195, total=4126.68, n_correct=2798.84, ppl=5.09, accuracy=67.823, wps=6850.8, ups=1.66, wpb=4126.7, bsz=154.6, num_updates=57200, lr=5.91312e-05, gnorm=0.349, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=0
2023-07-06 04:04:03 | INFO | train_inner | epoch 039:   1312 / 1474 loss=1.315, trans_loss=5.105, nll_loss=2.339, w2v_ctc_loss=0.38, task_loss=2.003, contrastive_loss=0.16, total=4176.04, n_correct=2838.15, ppl=5.06, accuracy=67.963, wps=6919.3, ups=1.66, wpb=4176, bsz=157.7, num_updates=57300, lr=5.90796e-05, gnorm=0.344, clip=0, loss_scale=32, train_wall=60, gb_free=17.4, wall=0
2023-07-06 04:05:04 | INFO | train_inner | epoch 039:   1412 / 1474 loss=1.313, trans_loss=5.109, nll_loss=2.342, w2v_ctc_loss=0.381, task_loss=2.292, contrastive_loss=0.093, total=4055.22, n_correct=2751.92, ppl=5.07, accuracy=67.861, wps=6631.9, ups=1.64, wpb=4055.2, bsz=139.2, num_updates=57400, lr=5.90281e-05, gnorm=0.35, clip=0, loss_scale=32, train_wall=61, gb_free=15.1, wall=0
2023-07-06 04:05:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-06 04:06:08 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 2.175 | trans_loss 5.554 | nll_loss 2.825 | w2v_ctc_loss 0.708 | task_loss 2.365 | contrastive_loss 0.264 | total 4003.4 | n_correct 2506.1 | ppl 7.09 | accuracy 62.599 | uer 16.41 | wer 18.169 | raw_wer 18.169 | bleu 20.47 | wps 2052.9 | wpb 4003.4 | bsz 141.8 | num_updates 57462 | best_bleu 20.57
2023-07-06 04:06:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 57462 updates
2023-07-06 04:06:08 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint.best_bleu_20.4706.pt
2023-07-06 04:06:11 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint.best_bleu_20.4706.pt
2023-07-06 04:06:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint.best_bleu_20.4706.pt (epoch 39 @ 57462 updates, score 20.47) (writing took 5.23934778101102 seconds)
2023-07-06 04:06:14 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-07-06 04:06:14 | INFO | train | epoch 039 | loss 1.313 | trans_loss 5.099 | nll_loss 2.329 | w2v_ctc_loss 0.377 | task_loss 2.092 | contrastive_loss 0.212 | total 4138.65 | n_correct 2818.17 | ppl 5.03 | accuracy 68.094 | wps 6318.3 | ups 1.53 | wpb 4138.6 | bsz 152.8 | num_updates 57462 | lr 5.89963e-05 | gnorm 0.348 | clip 0 | loss_scale 32 | train_wall 889 | gb_free 15.7 | wall 0
2023-07-06 04:06:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 04:06:14 | INFO | fairseq.trainer | begin training epoch 40
2023-07-06 04:06:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 04:06:45 | INFO | train_inner | epoch 040:     38 / 1474 loss=1.309, trans_loss=5.1, nll_loss=2.333, w2v_ctc_loss=0.372, task_loss=2.018, contrastive_loss=0.139, total=4169.65, n_correct=2840.01, ppl=5.04, accuracy=68.111, wps=4149.4, ups=1, wpb=4169.6, bsz=156, num_updates=57500, lr=5.89768e-05, gnorm=0.349, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=0
2023-07-06 04:07:45 | INFO | train_inner | epoch 040:    138 / 1474 loss=1.301, trans_loss=5.062, nll_loss=2.281, w2v_ctc_loss=0.371, task_loss=2.092, contrastive_loss=0.12, total=4150.02, n_correct=2849.35, ppl=4.86, accuracy=68.659, wps=6874.4, ups=1.66, wpb=4150, bsz=152.6, num_updates=57600, lr=5.89256e-05, gnorm=0.344, clip=0, loss_scale=32, train_wall=60, gb_free=17.9, wall=0
2023-07-06 04:08:45 | INFO | train_inner | epoch 040:    238 / 1474 loss=1.303, trans_loss=5.076, nll_loss=2.3, w2v_ctc_loss=0.375, task_loss=2.147, contrastive_loss=0.123, total=4101.15, n_correct=2806.91, ppl=4.92, accuracy=68.442, wps=6822.2, ups=1.66, wpb=4101.1, bsz=149.9, num_updates=57700, lr=5.88745e-05, gnorm=0.349, clip=0, loss_scale=32, train_wall=60, gb_free=10.8, wall=0
2023-07-06 04:09:45 | INFO | train_inner | epoch 040:    338 / 1474 loss=1.307, trans_loss=5.082, nll_loss=2.309, w2v_ctc_loss=0.374, task_loss=1.925, contrastive_loss=0.142, total=4161.74, n_correct=2848.94, ppl=4.95, accuracy=68.456, wps=6935.2, ups=1.67, wpb=4161.7, bsz=160.6, num_updates=57800, lr=5.88235e-05, gnorm=0.352, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=0
2023-07-06 04:10:46 | INFO | train_inner | epoch 040:    438 / 1474 loss=1.312, trans_loss=5.091, nll_loss=2.319, w2v_ctc_loss=0.377, task_loss=2.093, contrastive_loss=0.301, total=4141.51, n_correct=2825.66, ppl=4.99, accuracy=68.228, wps=6800.8, ups=1.64, wpb=4141.5, bsz=155.3, num_updates=57900, lr=5.87727e-05, gnorm=0.351, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=0
2023-07-06 04:11:47 | INFO | train_inner | epoch 040:    538 / 1474 loss=1.309, trans_loss=5.081, nll_loss=2.308, w2v_ctc_loss=0.368, task_loss=2.026, contrastive_loss=0.347, total=4167.53, n_correct=2850.24, ppl=4.95, accuracy=68.392, wps=6811, ups=1.63, wpb=4167.5, bsz=157.8, num_updates=58000, lr=5.8722e-05, gnorm=0.343, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=0
2023-07-06 04:11:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-06 04:12:14 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 2.184 | trans_loss 5.557 | nll_loss 2.83 | w2v_ctc_loss 0.737 | task_loss 2.365 | contrastive_loss 0.262 | total 4003.4 | n_correct 2497.9 | ppl 7.11 | accuracy 62.394 | uer 16.548 | wer 18.392 | raw_wer 18.392 | bleu 20.33 | wps 1945.1 | wpb 4003.4 | bsz 141.8 | num_updates 58000 | best_bleu 20.57
2023-07-06 04:12:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58000 updates
2023-07-06 04:12:14 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint_40_58000.pt
2023-07-06 04:12:16 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint_40_58000.pt
2023-07-06 04:12:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint_40_58000.pt (epoch 40 @ 58000 updates, score 20.33) (writing took 7.879777098991326 seconds)
2023-07-06 04:13:22 | INFO | train_inner | epoch 040:    638 / 1474 loss=1.309, trans_loss=5.097, nll_loss=2.327, w2v_ctc_loss=0.38, task_loss=2.172, contrastive_loss=0.147, total=4118.6, n_correct=2803.22, ppl=5.02, accuracy=68.062, wps=4356, ups=1.06, wpb=4118.6, bsz=149.2, num_updates=58100, lr=5.86715e-05, gnorm=0.351, clip=0, loss_scale=32, train_wall=60, gb_free=12.7, wall=0
2023-07-06 04:14:22 | INFO | train_inner | epoch 040:    738 / 1474 loss=1.308, trans_loss=5.09, nll_loss=2.318, w2v_ctc_loss=0.375, task_loss=2.025, contrastive_loss=0.107, total=4137.91, n_correct=2824.16, ppl=4.99, accuracy=68.251, wps=6885.3, ups=1.66, wpb=4137.9, bsz=154.2, num_updates=58200, lr=5.8621e-05, gnorm=0.347, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=0
2023-07-06 04:15:23 | INFO | train_inner | epoch 040:    838 / 1474 loss=1.318, trans_loss=5.094, nll_loss=2.326, w2v_ctc_loss=0.371, task_loss=1.892, contrastive_loss=0.533, total=4214.92, n_correct=2877.23, ppl=5.01, accuracy=68.263, wps=6880.7, ups=1.63, wpb=4214.9, bsz=164.6, num_updates=58300, lr=5.85707e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=61, gb_free=16.8, wall=0
2023-07-06 04:16:24 | INFO | train_inner | epoch 040:    938 / 1474 loss=1.312, trans_loss=5.102, nll_loss=2.333, w2v_ctc_loss=0.384, task_loss=2.205, contrastive_loss=0.16, total=4092.24, n_correct=2780.99, ppl=5.04, accuracy=67.958, wps=6750, ups=1.65, wpb=4092.2, bsz=146.8, num_updates=58400, lr=5.85206e-05, gnorm=0.353, clip=0, loss_scale=32, train_wall=60, gb_free=15.2, wall=0
2023-07-06 04:17:25 | INFO | train_inner | epoch 040:   1038 / 1474 loss=1.318, trans_loss=5.117, nll_loss=2.353, w2v_ctc_loss=0.381, task_loss=2.271, contrastive_loss=0.201, total=4119.93, n_correct=2794.48, ppl=5.11, accuracy=67.828, wps=6768.4, ups=1.64, wpb=4119.9, bsz=143.8, num_updates=58500, lr=5.84705e-05, gnorm=0.352, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=0
2023-07-06 04:18:26 | INFO | train_inner | epoch 040:   1138 / 1474 loss=1.312, trans_loss=5.105, nll_loss=2.338, w2v_ctc_loss=0.382, task_loss=2.18, contrastive_loss=0.132, total=4124.74, n_correct=2800.74, ppl=5.06, accuracy=67.901, wps=6727, ups=1.63, wpb=4124.7, bsz=149.2, num_updates=58600, lr=5.84206e-05, gnorm=0.35, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=0
2023-07-06 04:19:27 | INFO | train_inner | epoch 040:   1238 / 1474 loss=1.313, trans_loss=5.091, nll_loss=2.32, w2v_ctc_loss=0.375, task_loss=2.057, contrastive_loss=0.254, total=4198.52, n_correct=2865.92, ppl=4.99, accuracy=68.26, wps=6869.9, ups=1.64, wpb=4198.5, bsz=155.4, num_updates=58700, lr=5.83708e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=61, gb_free=17.2, wall=0
2023-07-06 04:20:28 | INFO | train_inner | epoch 040:   1338 / 1474 loss=1.312, trans_loss=5.097, nll_loss=2.328, w2v_ctc_loss=0.371, task_loss=2.106, contrastive_loss=0.262, total=4124.38, n_correct=2810.06, ppl=5.02, accuracy=68.133, wps=6819.1, ups=1.65, wpb=4124.4, bsz=153, num_updates=58800, lr=5.83212e-05, gnorm=0.35, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=0
2023-07-06 04:21:28 | INFO | train_inner | epoch 040:   1438 / 1474 loss=1.315, trans_loss=5.102, nll_loss=2.334, w2v_ctc_loss=0.378, task_loss=2.095, contrastive_loss=0.195, total=4121.8, n_correct=2805.22, ppl=5.04, accuracy=68.058, wps=6783, ups=1.65, wpb=4121.8, bsz=152.2, num_updates=58900, lr=5.82717e-05, gnorm=0.347, clip=0, loss_scale=32, train_wall=60, gb_free=15.8, wall=0
2023-07-06 04:21:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-06 04:22:15 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 2.181 | trans_loss 5.554 | nll_loss 2.823 | w2v_ctc_loss 0.726 | task_loss 2.365 | contrastive_loss 0.271 | total 4003.4 | n_correct 2496.2 | ppl 7.08 | accuracy 62.352 | uer 16.545 | wer 18.28 | raw_wer 18.28 | bleu 20.26 | wps 2160.6 | wpb 4003.4 | bsz 141.8 | num_updates 58936 | best_bleu 20.57
2023-07-06 04:22:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58936 updates
2023-07-06 04:22:15 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint_last.pt
2023-07-06 04:22:19 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint_last.pt
2023-07-06 04:22:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint_last.pt (epoch 40 @ 58936 updates, score 20.26) (writing took 4.036885068999254 seconds)
2023-07-06 04:22:19 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-07-06 04:22:19 | INFO | train | epoch 040 | loss 1.311 | trans_loss 5.092 | nll_loss 2.321 | w2v_ctc_loss 0.375 | task_loss 2.092 | contrastive_loss 0.213 | total 4138.65 | n_correct 2823.1 | ppl 5 | accuracy 68.213 | wps 6321.5 | ups 1.53 | wpb 4138.6 | bsz 152.8 | num_updates 58936 | lr 5.82539e-05 | gnorm 0.349 | clip 0 | loss_scale 32 | train_wall 887 | gb_free 16 | wall 0
2023-07-06 04:22:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 04:22:19 | INFO | fairseq.trainer | begin training epoch 41
2023-07-06 04:22:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 04:23:06 | INFO | train_inner | epoch 041:     64 / 1474 loss=1.309, trans_loss=5.079, nll_loss=2.305, w2v_ctc_loss=0.375, task_loss=2.163, contrastive_loss=0.134, total=4088.95, n_correct=2795.53, ppl=4.94, accuracy=68.368, wps=4208.7, ups=1.03, wpb=4089, bsz=147.8, num_updates=59000, lr=5.82223e-05, gnorm=0.348, clip=0, loss_scale=32, train_wall=59, gb_free=17.1, wall=0
2023-07-06 04:24:06 | INFO | train_inner | epoch 041:    164 / 1474 loss=1.299, trans_loss=5.056, nll_loss=2.273, w2v_ctc_loss=0.364, task_loss=2.03, contrastive_loss=0.245, total=4141.51, n_correct=2848.83, ppl=4.83, accuracy=68.787, wps=6832.5, ups=1.65, wpb=4141.5, bsz=155.7, num_updates=59100, lr=5.8173e-05, gnorm=0.346, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=0
2023-07-06 04:25:06 | INFO | train_inner | epoch 041:    264 / 1474 loss=1.307, trans_loss=5.075, nll_loss=2.3, w2v_ctc_loss=0.368, task_loss=1.941, contrastive_loss=0.236, total=4181.72, n_correct=2865.73, ppl=4.92, accuracy=68.53, wps=6946.3, ups=1.66, wpb=4181.7, bsz=159.6, num_updates=59200, lr=5.81238e-05, gnorm=0.353, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=0
2023-07-06 04:26:07 | INFO | train_inner | epoch 041:    364 / 1474 loss=1.305, trans_loss=5.074, nll_loss=2.298, w2v_ctc_loss=0.375, task_loss=2.088, contrastive_loss=0.147, total=4147.02, n_correct=2841.79, ppl=4.92, accuracy=68.526, wps=6830.2, ups=1.65, wpb=4147, bsz=152.5, num_updates=59300, lr=5.80748e-05, gnorm=0.35, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=0
2023-07-06 04:27:08 | INFO | train_inner | epoch 041:    464 / 1474 loss=1.301, trans_loss=5.07, nll_loss=2.292, w2v_ctc_loss=0.368, task_loss=2.102, contrastive_loss=0.116, total=4144.36, n_correct=2840.37, ppl=4.9, accuracy=68.536, wps=6827.8, ups=1.65, wpb=4144.4, bsz=151.4, num_updates=59400, lr=5.80259e-05, gnorm=0.349, clip=0, loss_scale=64, train_wall=60, gb_free=16.1, wall=0
2023-07-06 04:28:08 | INFO | train_inner | epoch 041:    564 / 1474 loss=1.304, trans_loss=5.076, nll_loss=2.299, w2v_ctc_loss=0.374, task_loss=2.094, contrastive_loss=0.146, total=4145.19, n_correct=2839.71, ppl=4.92, accuracy=68.506, wps=6869, ups=1.66, wpb=4145.2, bsz=153.6, num_updates=59500, lr=5.79771e-05, gnorm=0.35, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=0
2023-07-06 04:29:08 | INFO | train_inner | epoch 041:    664 / 1474 loss=1.302, trans_loss=5.069, nll_loss=2.291, w2v_ctc_loss=0.368, task_loss=1.968, contrastive_loss=0.12, total=4189.74, n_correct=2874.49, ppl=4.9, accuracy=68.608, wps=6969.5, ups=1.66, wpb=4189.7, bsz=159, num_updates=59600, lr=5.79284e-05, gnorm=0.347, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=0
2023-07-06 04:30:09 | INFO | train_inner | epoch 041:    764 / 1474 loss=1.307, trans_loss=5.084, nll_loss=2.31, w2v_ctc_loss=0.372, task_loss=2.114, contrastive_loss=0.114, total=4150.75, n_correct=2836.03, ppl=4.96, accuracy=68.326, wps=6865.8, ups=1.65, wpb=4150.8, bsz=150.4, num_updates=59700, lr=5.78799e-05, gnorm=0.352, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=0
2023-07-06 04:31:09 | INFO | train_inner | epoch 041:    864 / 1474 loss=1.31, trans_loss=5.087, nll_loss=2.314, w2v_ctc_loss=0.376, task_loss=2.17, contrastive_loss=0.12, total=4108.1, n_correct=2807.04, ppl=4.97, accuracy=68.329, wps=6783.5, ups=1.65, wpb=4108.1, bsz=147.9, num_updates=59800, lr=5.78315e-05, gnorm=0.353, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=0
2023-07-06 04:32:11 | INFO | train_inner | epoch 041:    964 / 1474 loss=1.317, trans_loss=5.1, nll_loss=2.331, w2v_ctc_loss=0.38, task_loss=2.177, contrastive_loss=0.3, total=4122.2, n_correct=2806.79, ppl=5.03, accuracy=68.09, wps=6727.1, ups=1.63, wpb=4122.2, bsz=149.6, num_updates=59900, lr=5.77832e-05, gnorm=0.35, clip=0, loss_scale=64, train_wall=61, gb_free=15.2, wall=0
2023-07-06 04:33:11 | INFO | train_inner | epoch 041:   1064 / 1474 loss=1.31, trans_loss=5.099, nll_loss=2.331, w2v_ctc_loss=0.375, task_loss=2.08, contrastive_loss=0.125, total=4133.83, n_correct=2813.16, ppl=5.03, accuracy=68.052, wps=6891.8, ups=1.67, wpb=4133.8, bsz=152, num_updates=60000, lr=5.7735e-05, gnorm=0.349, clip=0, loss_scale=64, train_wall=60, gb_free=12.8, wall=0
2023-07-06 04:33:11 | INFO | fairseq_cli.train | Stopping training due to num_updates: 60000 >= max_update: 60000
2023-07-06 04:33:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-06 04:33:34 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 2.173 | trans_loss 5.551 | nll_loss 2.824 | w2v_ctc_loss 0.705 | task_loss 2.365 | contrastive_loss 0.276 | total 4003.4 | n_correct 2499.8 | ppl 7.08 | accuracy 62.442 | uer 16.412 | wer 18.12 | raw_wer 18.12 | bleu 20.42 | wps 2288.9 | wpb 4003.4 | bsz 141.8 | num_updates 60000 | best_bleu 20.57
2023-07-06 04:33:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 60000 updates
2023-07-06 04:33:34 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint_41_60000.pt
2023-07-06 04:33:36 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint_41_60000.pt
2023-07-06 04:33:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_valloss/checkpoint_41_60000.pt (epoch 41 @ 60000 updates, score 20.42) (writing took 6.054881199990632 seconds)
2023-07-06 04:33:41 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-07-06 04:33:41 | INFO | train | epoch 041 | loss 1.306 | trans_loss 5.079 | nll_loss 2.303 | w2v_ctc_loss 0.372 | task_loss 2.079 | contrastive_loss 0.166 | total 4144.26 | n_correct 2836.09 | ppl 4.94 | accuracy 68.434 | wps 6467.8 | ups 1.56 | wpb 4144.3 | bsz 153 | num_updates 60000 | lr 5.7735e-05 | gnorm 0.35 | clip 0 | loss_scale 64 | train_wall 639 | gb_free 12.8 | wall 0
2023-07-06 04:33:41 | INFO | fairseq_cli.train | done training in 6529.0 seconds
/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 320 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
