2023-08-08 13:42:10 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:13874
2023-08-08 13:42:10 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:13874
2023-08-08 13:42:10 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:13874
2023-08-08 13:42:10 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:13874
2023-08-08 13:42:10 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:13874
2023-08-08 13:42:10 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-08 13:42:11 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:13874
2023-08-08 13:42:11 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:13874
2023-08-08 13:42:11 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:13874
2023-08-08 13:42:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-08 13:42:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-08 13:42:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-08 13:42:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-08 13:42:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-08 13:42:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-08 13:42:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-08 13:42:11 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-08 13:42:11 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-08-08 13:42:11 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-08 13:42:11 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-08-08 13:42:11 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-08 13:42:11 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-08-08 13:42:11 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-08 13:42:11 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-08-08 13:42:11 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-08 13:42:11 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-08 13:42:11 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-08 13:42:11 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-08 13:42:11 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-08-08 13:42:11 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-08-08 13:42:11 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-08-08 13:42:11 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-08-08 13:42:16 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13874', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=2.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=2.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=2.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-08 13:42:16 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-08 13:42:16 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-08 13:42:16 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-08 13:42:16 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-08 13:42:16 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-08 13:42:21 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-08 13:42:21 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-08 13:42:21 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-08 13:42:23 | INFO | root | load pretrained hubert
2023-08-08 13:42:25 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-08 13:42:26 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-08 13:42:30 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-08 13:42:30 | INFO | root | share the sematic adapter and textual encoder
2023-08-08 13:42:30 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-08 13:42:30 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-08 13:42:30 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-08 13:42:30 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-08 13:42:30 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-08-08 13:42:30 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-08 13:42:30 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-08 13:42:30 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-08 13:42:30 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-08 13:42:30 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-08 13:42:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-08 13:42:35 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-08 13:42:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-08 13:42:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-08 13:42:36 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-08 13:42:36 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-08 13:42:36 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-08 13:42:36 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-08 13:42:36 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-08 13:42:36 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-08 13:42:36 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-08 13:42:36 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-08 13:42:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-08 13:42:36 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-08 13:42:36 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-08 13:42:36 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_last.pt
2023-08-08 13:42:36 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_last.pt
2023-08-08 13:42:36 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-08 13:42:36 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-08 13:42:36 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-08 13:42:36 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-08 13:42:37 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-08 13:42:39 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-08 13:43:27 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-08 13:43:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 13:43:27 | INFO | fairseq.trainer | begin training epoch 1
2023-08-08 13:43:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 13:44:42 | INFO | train_inner | epoch 001:    100 / 1474 loss=21.471, trans_loss=5.599, nll_loss=4.163, w2v_ctc_loss=23.052, task_loss=0, contrastive_loss=3.325, total=4207.04, n_correct=209.18, ppl=17.92, accuracy=4.972, wps=20394.3, ups=1.62, wpb=12551.1, bsz=471.4, num_updates=100, lr=4.098e-06, gnorm=0.985, clip=0, loss_scale=128, train_wall=67, gb_free=19.5, wall=126
2023-08-08 13:45:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-08 13:45:44 | INFO | train_inner | epoch 001:    201 / 1474 loss=19.322, trans_loss=5.468, nll_loss=4.052, w2v_ctc_loss=19.995, task_loss=0, contrastive_loss=3.285, total=4123.37, n_correct=224.25, ppl=16.59, accuracy=5.439, wps=19836.2, ups=1.61, wpb=12310.5, bsz=462.6, num_updates=200, lr=8.096e-06, gnorm=3.613, clip=0, loss_scale=64, train_wall=62, gb_free=19.2, wall=188
2023-08-08 13:46:45 | INFO | train_inner | epoch 001:    301 / 1474 loss=12.12, trans_loss=5.49, nll_loss=4.133, w2v_ctc_loss=9.022, task_loss=0, contrastive_loss=3.202, total=4079.62, n_correct=204.17, ppl=17.55, accuracy=5.005, wps=20178.5, ups=1.66, wpb=12186.7, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=4.754, clip=0, loss_scale=64, train_wall=60, gb_free=19.9, wall=249
2023-08-08 13:47:46 | INFO | train_inner | epoch 001:    401 / 1474 loss=10.842, trans_loss=5.514, nll_loss=4.186, w2v_ctc_loss=6.977, task_loss=0, contrastive_loss=3.233, total=4174.14, n_correct=196.19, ppl=18.21, accuracy=4.7, wps=20459.1, ups=1.64, wpb=12463.5, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=3.016, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=310
2023-08-08 13:48:46 | INFO | train_inner | epoch 001:    501 / 1474 loss=10.399, trans_loss=5.499, nll_loss=4.181, w2v_ctc_loss=6.338, task_loss=0, contrastive_loss=3.217, total=4176.18, n_correct=187.3, ppl=18.14, accuracy=4.485, wps=20657.4, ups=1.66, wpb=12479.7, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=1.497, clip=0, loss_scale=64, train_wall=60, gb_free=19.2, wall=370
2023-08-08 13:49:48 | INFO | train_inner | epoch 001:    601 / 1474 loss=10.099, trans_loss=5.521, nll_loss=4.209, w2v_ctc_loss=5.978, task_loss=0, contrastive_loss=3.257, total=4147.79, n_correct=193.61, ppl=18.49, accuracy=4.668, wps=20004.1, ups=1.62, wpb=12371.6, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.936, clip=0, loss_scale=64, train_wall=61, gb_free=19, wall=432
2023-08-08 13:50:48 | INFO | train_inner | epoch 001:    701 / 1474 loss=9.812, trans_loss=5.502, nll_loss=4.196, w2v_ctc_loss=5.873, task_loss=0, contrastive_loss=2.983, total=4152.1, n_correct=217.76, ppl=18.32, accuracy=5.245, wps=20579.1, ups=1.66, wpb=12395.5, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=1.098, clip=0, loss_scale=64, train_wall=60, gb_free=19.5, wall=492
2023-08-08 13:51:49 | INFO | train_inner | epoch 001:    801 / 1474 loss=9.504, trans_loss=5.445, nll_loss=4.138, w2v_ctc_loss=5.715, task_loss=0, contrastive_loss=2.897, total=4123.83, n_correct=256.23, ppl=17.6, accuracy=6.213, wps=20323.8, ups=1.65, wpb=12306.1, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=1.591, clip=0, loss_scale=64, train_wall=60, gb_free=19.2, wall=553
2023-08-08 13:52:49 | INFO | train_inner | epoch 001:    901 / 1474 loss=9.215, trans_loss=5.42, nll_loss=4.117, w2v_ctc_loss=5.621, task_loss=0, contrastive_loss=2.686, total=4163.61, n_correct=268.27, ppl=17.36, accuracy=6.443, wps=20593.7, ups=1.66, wpb=12433.9, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=2.448, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=613
2023-08-08 13:53:50 | INFO | train_inner | epoch 001:   1001 / 1474 loss=8.925, trans_loss=5.404, nll_loss=4.105, w2v_ctc_loss=5.483, task_loss=0, contrastive_loss=2.56, total=4135.34, n_correct=287.71, ppl=17.21, accuracy=6.957, wps=20182.3, ups=1.63, wpb=12353.2, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=2.649, clip=0, loss_scale=64, train_wall=61, gb_free=19, wall=674
2023-08-08 13:54:51 | INFO | train_inner | epoch 001:   1101 / 1474 loss=8.595, trans_loss=5.397, nll_loss=4.098, w2v_ctc_loss=5.339, task_loss=0, contrastive_loss=2.368, total=4147.38, n_correct=309.86, ppl=17.13, accuracy=7.471, wps=20349.1, ups=1.65, wpb=12367, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=3.045, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=735
2023-08-08 13:55:51 | INFO | train_inner | epoch 001:   1201 / 1474 loss=8.308, trans_loss=5.38, nll_loss=4.085, w2v_ctc_loss=5.217, task_loss=0, contrastive_loss=2.172, total=4139.9, n_correct=315.34, ppl=16.97, accuracy=7.617, wps=20458.9, ups=1.65, wpb=12366.5, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=3.17, clip=0, loss_scale=64, train_wall=60, gb_free=19, wall=795
2023-08-08 13:56:52 | INFO | train_inner | epoch 001:   1301 / 1474 loss=8.035, trans_loss=5.378, nll_loss=4.084, w2v_ctc_loss=5.049, task_loss=0, contrastive_loss=2.003, total=4046.58, n_correct=314.44, ppl=16.96, accuracy=7.771, wps=20097.7, ups=1.66, wpb=12081.6, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=3.322, clip=0, loss_scale=64, train_wall=60, gb_free=19.7, wall=856
2023-08-08 13:57:52 | INFO | train_inner | epoch 001:   1401 / 1474 loss=7.782, trans_loss=5.374, nll_loss=4.083, w2v_ctc_loss=4.856, task_loss=0, contrastive_loss=2.076, total=4133.18, n_correct=324.12, ppl=16.95, accuracy=7.842, wps=20463.1, ups=1.66, wpb=12350, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=3.262, clip=0, loss_scale=64, train_wall=60, gb_free=19.9, wall=916
2023-08-08 13:58:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 13:59:14 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 10.778 | trans_loss 11.006 | nll_loss 10.017 | w2v_ctc_loss 6.493 | task_loss 0 | contrastive_loss 2.512 | total 4003.4 | n_correct 364.2 | ppl 1036.25 | accuracy 9.097 | uer 79.367 | wer 78.864 | raw_wer 78.864 | bleu 0.02 | wps 1232 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-08-08 13:59:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-08-08 13:59:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 13:59:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 13:59:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.02) (writing took 6.29944858327508 seconds)
2023-08-08 13:59:20 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-08 13:59:20 | INFO | train | epoch 001 | loss 10.87 | trans_loss 5.452 | nll_loss 4.128 | w2v_ctc_loss 8.022 | task_loss 0 | contrastive_loss 2.767 | total 4138.5 | n_correct 254.589 | ppl 17.49 | accuracy 6.152 | wps 19369.3 | ups 1.57 | wpb 12355.3 | bsz 458.5 | num_updates 1473 | lr 5.89905e-05 | gnorm 2.551 | clip 0 | loss_scale 64 | train_wall 894 | gb_free 19.2 | wall 1004
2023-08-08 13:59:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 13:59:20 | INFO | fairseq.trainer | begin training epoch 2
2023-08-08 13:59:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 13:59:46 | INFO | train_inner | epoch 002:     27 / 1474 loss=7.53, trans_loss=5.367, nll_loss=4.07, w2v_ctc_loss=4.661, task_loss=0, contrastive_loss=1.922, total=4162.95, n_correct=331.51, ppl=16.8, accuracy=7.963, wps=10910.8, ups=0.88, wpb=12416.8, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=3.026, clip=0, loss_scale=64, train_wall=60, gb_free=19.7, wall=1030
2023-08-08 14:00:46 | INFO | train_inner | epoch 002:    127 / 1474 loss=7.251, trans_loss=5.366, nll_loss=4.068, w2v_ctc_loss=4.527, task_loss=0, contrastive_loss=1.71, total=4155.98, n_correct=330.99, ppl=16.77, accuracy=7.964, wps=20460.4, ups=1.65, wpb=12394.8, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=3.015, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=1090
2023-08-08 14:01:46 | INFO | train_inner | epoch 002:    227 / 1474 loss=7.055, trans_loss=5.347, nll_loss=4.05, w2v_ctc_loss=4.309, task_loss=0, contrastive_loss=1.731, total=4179.21, n_correct=337.26, ppl=16.56, accuracy=8.07, wps=20753.2, ups=1.66, wpb=12484.6, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=2.748, clip=0, loss_scale=64, train_wall=60, gb_free=19, wall=1151
2023-08-08 14:02:47 | INFO | train_inner | epoch 002:    327 / 1474 loss=6.752, trans_loss=5.352, nll_loss=4.052, w2v_ctc_loss=4.187, task_loss=0, contrastive_loss=1.435, total=4146.1, n_correct=336.21, ppl=16.59, accuracy=8.109, wps=20529.6, ups=1.66, wpb=12374.1, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=2.692, clip=0, loss_scale=64, train_wall=60, gb_free=18.8, wall=1211
2023-08-08 14:03:47 | INFO | train_inner | epoch 002:    427 / 1474 loss=6.497, trans_loss=5.348, nll_loss=4.051, w2v_ctc_loss=4.061, task_loss=0, contrastive_loss=1.24, total=4037.99, n_correct=330.4, ppl=16.58, accuracy=8.182, wps=19893.5, ups=1.65, wpb=12069.2, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=2.608, clip=0, loss_scale=64, train_wall=60, gb_free=19, wall=1271
2023-08-08 14:04:48 | INFO | train_inner | epoch 002:    527 / 1474 loss=6.374, trans_loss=5.334, nll_loss=4.03, w2v_ctc_loss=3.871, task_loss=0, contrastive_loss=1.33, total=4176.97, n_correct=350.7, ppl=16.33, accuracy=8.396, wps=20438.2, ups=1.64, wpb=12463.5, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=2.426, clip=0, loss_scale=64, train_wall=61, gb_free=19.6, wall=1332
2023-08-08 14:04:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 14:05:26 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 9.87 | trans_loss 10.891 | nll_loss 9.861 | w2v_ctc_loss 5.171 | task_loss 0 | contrastive_loss 1.682 | total 4003.4 | n_correct 390.5 | ppl 929.63 | accuracy 9.754 | uer 66.788 | wer 64.133 | raw_wer 64.133 | bleu 0.03 | wps 1225.1 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.03
2023-08-08 14:05:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-08 14:05:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_2_2000.pt
2023-08-08 14:05:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_2_2000.pt
2023-08-08 14:05:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.03) (writing took 26.025691470131278 seconds)
2023-08-08 14:06:53 | INFO | train_inner | epoch 002:    627 / 1474 loss=6.146, trans_loss=5.326, nll_loss=4.019, w2v_ctc_loss=3.734, task_loss=0, contrastive_loss=1.124, total=4126.49, n_correct=356.4, ppl=16.21, accuracy=8.637, wps=9913.2, ups=0.8, wpb=12314.9, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=2.083, clip=0, loss_scale=64, train_wall=60, gb_free=19.2, wall=1457
2023-08-08 14:07:53 | INFO | train_inner | epoch 002:    727 / 1474 loss=6.047, trans_loss=5.312, nll_loss=4.005, w2v_ctc_loss=3.616, task_loss=0, contrastive_loss=1.22, total=4149.06, n_correct=360.7, ppl=16.06, accuracy=8.694, wps=20635.4, ups=1.67, wpb=12386.4, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=2.021, clip=0, loss_scale=64, train_wall=60, gb_free=19.2, wall=1517
2023-08-08 14:08:53 | INFO | train_inner | epoch 002:    827 / 1474 loss=5.89, trans_loss=5.301, nll_loss=3.993, w2v_ctc_loss=3.52, task_loss=0, contrastive_loss=1.155, total=4175.4, n_correct=371.05, ppl=15.92, accuracy=8.887, wps=20760.2, ups=1.66, wpb=12471.9, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=1.716, clip=0, loss_scale=128, train_wall=60, gb_free=19.8, wall=1577
2023-08-08 14:09:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-08 14:09:55 | INFO | train_inner | epoch 002:    928 / 1474 loss=5.722, trans_loss=5.283, nll_loss=3.969, w2v_ctc_loss=3.4, task_loss=0, contrastive_loss=1.075, total=4087.96, n_correct=366.51, ppl=15.66, accuracy=8.966, wps=19634.5, ups=1.61, wpb=12205.3, bsz=439.8, num_updates=2400, lr=9.6052e-05, gnorm=1.721, clip=0, loss_scale=64, train_wall=62, gb_free=18.9, wall=1639
2023-08-08 14:10:55 | INFO | train_inner | epoch 002:   1028 / 1474 loss=5.601, trans_loss=5.272, nll_loss=3.957, w2v_ctc_loss=3.302, task_loss=0, contrastive_loss=0.982, total=4101.19, n_correct=375.76, ppl=15.53, accuracy=9.162, wps=20386.4, ups=1.66, wpb=12245.2, bsz=454.5, num_updates=2500, lr=0.00010005, gnorm=1.498, clip=0, loss_scale=64, train_wall=60, gb_free=19, wall=1699
2023-08-08 14:11:55 | INFO | train_inner | epoch 002:   1128 / 1474 loss=5.576, trans_loss=5.263, nll_loss=3.945, w2v_ctc_loss=3.2, task_loss=0, contrastive_loss=1.188, total=4192.73, n_correct=390.05, ppl=15.4, accuracy=9.303, wps=20687.9, ups=1.65, wpb=12513.6, bsz=488.9, num_updates=2600, lr=0.000104048, gnorm=1.426, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=1760
2023-08-08 14:12:56 | INFO | train_inner | epoch 002:   1228 / 1474 loss=5.478, trans_loss=5.251, nll_loss=3.93, w2v_ctc_loss=3.135, task_loss=0, contrastive_loss=1.109, total=4219.96, n_correct=401.15, ppl=15.24, accuracy=9.506, wps=20782.8, ups=1.65, wpb=12591.9, bsz=491.8, num_updates=2700, lr=0.000108046, gnorm=1.382, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=1820
2023-08-08 14:13:56 | INFO | train_inner | epoch 002:   1328 / 1474 loss=5.29, trans_loss=5.23, nll_loss=3.906, w2v_ctc_loss=3.081, task_loss=0, contrastive_loss=0.813, total=4163.26, n_correct=410.56, ppl=14.99, accuracy=9.862, wps=20655.7, ups=1.66, wpb=12441.6, bsz=463, num_updates=2800, lr=0.000112044, gnorm=1.235, clip=0, loss_scale=64, train_wall=60, gb_free=19, wall=1880
2023-08-08 14:14:57 | INFO | train_inner | epoch 002:   1428 / 1474 loss=5.223, trans_loss=5.237, nll_loss=3.914, w2v_ctc_loss=3.026, task_loss=0, contrastive_loss=0.897, total=4049.42, n_correct=393.06, ppl=15.08, accuracy=9.707, wps=19830.4, ups=1.64, wpb=12091.6, bsz=437.6, num_updates=2900, lr=0.000116042, gnorm=1.151, clip=0, loss_scale=64, train_wall=60, gb_free=19.2, wall=1941
2023-08-08 14:15:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 14:16:03 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.745 | trans_loss 10.303 | nll_loss 9.119 | w2v_ctc_loss 3.927 | task_loss 0 | contrastive_loss 0.972 | total 4003.4 | n_correct 492.7 | ppl 556.09 | accuracy 12.307 | uer 54.718 | wer 53.145 | raw_wer 53.145 | bleu 0.12 | wps 1202.9 | wpb 4003.4 | bsz 141.8 | num_updates 2946 | best_bleu 0.12
2023-08-08 14:16:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2946 updates
2023-08-08 14:16:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 14:16:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 14:16:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt (epoch 2 @ 2946 updates, score 0.12) (writing took 24.922158148139715 seconds)
2023-08-08 14:16:28 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-08 14:16:28 | INFO | train | epoch 002 | loss 6.063 | trans_loss 5.301 | nll_loss 3.991 | w2v_ctc_loss 3.638 | task_loss 0 | contrastive_loss 1.218 | total 4137.79 | n_correct 365.405 | ppl 15.9 | accuracy 8.831 | wps 17705.6 | ups 1.43 | wpb 12353.3 | bsz 458.1 | num_updates 2946 | lr 0.000117881 | gnorm 1.974 | clip 0 | loss_scale 64 | train_wall 884 | gb_free 19.3 | wall 2032
2023-08-08 14:16:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 14:16:28 | INFO | fairseq.trainer | begin training epoch 3
2023-08-08 14:16:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 14:17:09 | INFO | train_inner | epoch 003:     54 / 1474 loss=5.114, trans_loss=5.211, nll_loss=3.883, w2v_ctc_loss=2.953, task_loss=0, contrastive_loss=0.795, total=4067, n_correct=411.58, ppl=14.75, accuracy=10.12, wps=9239.1, ups=0.76, wpb=12142, bsz=441.4, num_updates=3000, lr=0.00012004, gnorm=1.12, clip=0, loss_scale=64, train_wall=60, gb_free=19.2, wall=2073
2023-08-08 14:17:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-08 14:17:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-08 14:17:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-08 14:17:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-08 14:17:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-08 14:18:30 | INFO | train_inner | epoch 003:    159 / 1474 loss=4.294, trans_loss=4.516, nll_loss=2.973, w2v_ctc_loss=2.597, task_loss=0, contrastive_loss=0.668, total=4133.12, n_correct=1039.95, ppl=7.85, accuracy=25.161, wps=15136.6, ups=1.23, wpb=12341.6, bsz=452.9, num_updates=3100, lr=0.000124038, gnorm=2.355, clip=2, loss_scale=2, train_wall=81, gb_free=16.7, wall=2154
2023-08-08 14:19:50 | INFO | train_inner | epoch 003:    259 / 1474 loss=3.759, trans_loss=4.231, nll_loss=2.6, w2v_ctc_loss=2.293, task_loss=0, contrastive_loss=0.587, total=4155.72, n_correct=1347.91, ppl=6.06, accuracy=32.435, wps=15545.9, ups=1.25, wpb=12415.9, bsz=465.5, num_updates=3200, lr=0.000128036, gnorm=1.53, clip=0, loss_scale=2, train_wall=79, gb_free=17.8, wall=2234
2023-08-08 14:21:09 | INFO | train_inner | epoch 003:    359 / 1474 loss=3.593, trans_loss=4.145, nll_loss=2.483, w2v_ctc_loss=2.167, task_loss=0, contrastive_loss=0.631, total=4154.07, n_correct=1466.69, ppl=5.59, accuracy=35.307, wps=15739.9, ups=1.27, wpb=12396.6, bsz=464.9, num_updates=3300, lr=0.000132034, gnorm=1.431, clip=0, loss_scale=2, train_wall=78, gb_free=15.9, wall=2313
2023-08-08 14:22:27 | INFO | train_inner | epoch 003:    459 / 1474 loss=3.407, trans_loss=4.074, nll_loss=2.39, w2v_ctc_loss=2.066, task_loss=0, contrastive_loss=0.469, total=4212.17, n_correct=1594.47, ppl=5.24, accuracy=37.854, wps=15983.1, ups=1.27, wpb=12572.6, bsz=473.8, num_updates=3400, lr=0.000136032, gnorm=1.306, clip=0, loss_scale=2, train_wall=78, gb_free=16, wall=2392
2023-08-08 14:23:46 | INFO | train_inner | epoch 003:    559 / 1474 loss=3.27, trans_loss=4.026, nll_loss=2.329, w2v_ctc_loss=1.976, task_loss=0, contrastive_loss=0.459, total=4081.04, n_correct=1609.59, ppl=5.02, accuracy=39.441, wps=15596.3, ups=1.28, wpb=12190.8, bsz=440.1, num_updates=3500, lr=0.00014003, gnorm=1.237, clip=0, loss_scale=2, train_wall=78, gb_free=16.7, wall=2470
2023-08-08 14:25:05 | INFO | train_inner | epoch 003:    659 / 1474 loss=3.217, trans_loss=3.979, nll_loss=2.262, w2v_ctc_loss=1.898, task_loss=0, contrastive_loss=0.565, total=4231.09, n_correct=1750.14, ppl=4.8, accuracy=41.364, wps=15870.6, ups=1.26, wpb=12615.6, bsz=484.4, num_updates=3600, lr=0.000144028, gnorm=1.188, clip=0, loss_scale=2, train_wall=79, gb_free=16.2, wall=2549
2023-08-08 14:26:24 | INFO | train_inner | epoch 003:    759 / 1474 loss=3.087, trans_loss=3.94, nll_loss=2.217, w2v_ctc_loss=1.861, task_loss=0, contrastive_loss=0.32, total=4160.74, n_correct=1774.73, ppl=4.65, accuracy=42.654, wps=15767.3, ups=1.27, wpb=12428.5, bsz=469.2, num_updates=3700, lr=0.000148026, gnorm=1.135, clip=0, loss_scale=2, train_wall=78, gb_free=17, wall=2628
2023-08-08 14:27:42 | INFO | train_inner | epoch 003:    859 / 1474 loss=3.015, trans_loss=3.922, nll_loss=2.191, w2v_ctc_loss=1.814, task_loss=0, contrastive_loss=0.291, total=4160.47, n_correct=1813.35, ppl=4.57, accuracy=43.585, wps=15831.9, ups=1.27, wpb=12423.6, bsz=455.4, num_updates=3800, lr=0.000152024, gnorm=1.107, clip=0, loss_scale=2, train_wall=78, gb_free=16.6, wall=2707
2023-08-08 14:29:01 | INFO | train_inner | epoch 003:    959 / 1474 loss=2.983, trans_loss=3.898, nll_loss=2.159, w2v_ctc_loss=1.784, task_loss=0, contrastive_loss=0.319, total=4162.26, n_correct=1863.42, ppl=4.47, accuracy=44.769, wps=15760.2, ups=1.27, wpb=12416.1, bsz=467.9, num_updates=3900, lr=0.000156022, gnorm=1.094, clip=0, loss_scale=2, train_wall=78, gb_free=17.9, wall=2785
2023-08-08 14:30:20 | INFO | train_inner | epoch 003:   1059 / 1474 loss=2.931, trans_loss=3.875, nll_loss=2.131, w2v_ctc_loss=1.768, task_loss=0, contrastive_loss=0.276, total=4062.67, n_correct=1840.14, ppl=4.38, accuracy=45.294, wps=15445.1, ups=1.27, wpb=12131.7, bsz=443.2, num_updates=4000, lr=0.00016002, gnorm=1.08, clip=0, loss_scale=2, train_wall=78, gb_free=15.9, wall=2864
2023-08-08 14:30:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 14:30:51 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.214 | trans_loss 6.338 | nll_loss 3.85 | w2v_ctc_loss 2.174 | task_loss 0 | contrastive_loss 0.395 | total 4003.4 | n_correct 2008.6 | ppl 14.42 | accuracy 50.172 | uer 29.849 | wer 30.476 | raw_wer 30.476 | bleu 12 | wps 1466.5 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 12
2023-08-08 14:30:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-08 14:30:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_3_4000.pt
2023-08-08 14:30:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_3_4000.pt
2023-08-08 14:31:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 12.0) (writing took 49.01367224007845 seconds)
2023-08-08 14:32:59 | INFO | train_inner | epoch 003:   1159 / 1474 loss=2.88, trans_loss=3.868, nll_loss=2.121, w2v_ctc_loss=1.725, task_loss=0, contrastive_loss=0.255, total=4046.76, n_correct=1852.61, ppl=4.35, accuracy=45.78, wps=7603.9, ups=0.63, wpb=12078.6, bsz=433.9, num_updates=4100, lr=0.000164018, gnorm=1.043, clip=0, loss_scale=2, train_wall=78, gb_free=16.5, wall=3023
2023-08-08 14:34:16 | INFO | train_inner | epoch 003:   1259 / 1474 loss=2.826, trans_loss=3.843, nll_loss=2.09, w2v_ctc_loss=1.688, task_loss=0, contrastive_loss=0.237, total=4064.26, n_correct=1897.37, ppl=4.26, accuracy=46.684, wps=15623.4, ups=1.29, wpb=12137.6, bsz=434, num_updates=4200, lr=0.000168016, gnorm=1.012, clip=0, loss_scale=2, train_wall=77, gb_free=16.9, wall=3100
2023-08-08 14:35:35 | INFO | train_inner | epoch 003:   1359 / 1474 loss=2.835, trans_loss=3.828, nll_loss=2.07, w2v_ctc_loss=1.656, task_loss=0, contrastive_loss=0.347, total=4137.36, n_correct=1955.66, ppl=4.2, accuracy=47.268, wps=15652.4, ups=1.27, wpb=12352.2, bsz=461.5, num_updates=4300, lr=0.000172014, gnorm=1.044, clip=0, loss_scale=2, train_wall=78, gb_free=16.5, wall=3179
2023-08-08 14:36:55 | INFO | train_inner | epoch 003:   1459 / 1474 loss=2.805, trans_loss=3.815, nll_loss=2.055, w2v_ctc_loss=1.637, task_loss=0, contrastive_loss=0.326, total=4207.75, n_correct=2015.81, ppl=4.16, accuracy=47.907, wps=15842.8, ups=1.26, wpb=12567.9, bsz=476.7, num_updates=4400, lr=0.000176012, gnorm=1.012, clip=0, loss_scale=2, train_wall=79, gb_free=17.5, wall=3259
2023-08-08 14:37:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 14:37:36 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.054 | trans_loss 6.218 | nll_loss 3.699 | w2v_ctc_loss 1.963 | task_loss 0 | contrastive_loss 0.363 | total 4003.4 | n_correct 2088.5 | ppl 12.99 | accuracy 52.168 | uer 29.002 | wer 29.496 | raw_wer 29.496 | bleu 13.34 | wps 1530.8 | wpb 4003.4 | bsz 141.8 | num_updates 4415 | best_bleu 13.34
2023-08-08 14:37:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4415 updates
2023-08-08 14:37:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 14:37:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 14:38:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt (epoch 3 @ 4415 updates, score 13.34) (writing took 26.338177870959044 seconds)
2023-08-08 14:38:03 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-08 14:38:03 | INFO | train | epoch 003 | loss 3.273 | trans_loss 4.04 | nll_loss 2.347 | w2v_ctc_loss 1.959 | task_loss 0 | contrastive_loss 0.428 | total 4138.49 | n_correct 1656.44 | ppl 5.09 | accuracy 40.025 | wps 14017.3 | ups 1.13 | wpb 12355.4 | bsz 458.3 | num_updates 4415 | lr 0.000176612 | gnorm 1.247 | clip 0.1 | loss_scale 2 | train_wall 1143 | gb_free 16.6 | wall 3327
2023-08-08 14:38:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 14:38:03 | INFO | fairseq.trainer | begin training epoch 4
2023-08-08 14:38:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 14:39:17 | INFO | train_inner | epoch 004:     85 / 1474 loss=2.689, trans_loss=3.786, nll_loss=2.013, w2v_ctc_loss=1.588, task_loss=0, contrastive_loss=0.183, total=4095.18, n_correct=1995.17, ppl=4.04, accuracy=48.72, wps=8557.2, ups=0.7, wpb=12222.9, bsz=437.8, num_updates=4500, lr=0.00018001, gnorm=0.959, clip=0, loss_scale=2, train_wall=78, gb_free=13, wall=3402
2023-08-08 14:40:35 | INFO | train_inner | epoch 004:    185 / 1474 loss=2.68, trans_loss=3.767, nll_loss=1.99, w2v_ctc_loss=1.568, task_loss=0, contrastive_loss=0.209, total=4178.83, n_correct=2067.19, ppl=3.97, accuracy=49.468, wps=16075.7, ups=1.29, wpb=12476.1, bsz=469.5, num_updates=4600, lr=0.000184008, gnorm=0.97, clip=0, loss_scale=2, train_wall=77, gb_free=14.9, wall=3479
2023-08-08 14:41:54 | INFO | train_inner | epoch 004:    285 / 1474 loss=2.712, trans_loss=3.771, nll_loss=1.997, w2v_ctc_loss=1.568, task_loss=0, contrastive_loss=0.336, total=4142.3, n_correct=2045.84, ppl=3.99, accuracy=49.389, wps=15728.8, ups=1.27, wpb=12373.8, bsz=460.7, num_updates=4700, lr=0.000188006, gnorm=0.963, clip=0, loss_scale=2, train_wall=78, gb_free=13.6, wall=3558
2023-08-08 14:43:13 | INFO | train_inner | epoch 004:    385 / 1474 loss=2.649, trans_loss=3.772, nll_loss=1.996, w2v_ctc_loss=1.547, task_loss=0, contrastive_loss=0.182, total=4124.92, n_correct=2042.98, ppl=3.99, accuracy=49.528, wps=15577.4, ups=1.27, wpb=12307.7, bsz=444.2, num_updates=4800, lr=0.000192004, gnorm=0.944, clip=0, loss_scale=2, train_wall=78, gb_free=12.8, wall=3637
2023-08-08 14:44:32 | INFO | train_inner | epoch 004:    485 / 1474 loss=2.744, trans_loss=3.753, nll_loss=1.973, w2v_ctc_loss=1.517, task_loss=0, contrastive_loss=0.573, total=4216.09, n_correct=2117.17, ppl=3.93, accuracy=50.216, wps=15823.3, ups=1.26, wpb=12585.8, bsz=497.6, num_updates=4900, lr=0.000196002, gnorm=0.954, clip=0, loss_scale=2, train_wall=79, gb_free=17, wall=3716
2023-08-08 14:45:51 | INFO | train_inner | epoch 004:    585 / 1474 loss=2.654, trans_loss=3.747, nll_loss=1.967, w2v_ctc_loss=1.533, task_loss=0, contrastive_loss=0.254, total=4231.12, n_correct=2140.24, ppl=3.91, accuracy=50.583, wps=16070.7, ups=1.27, wpb=12629.4, bsz=490.1, num_updates=5000, lr=0.0002, gnorm=0.937, clip=0, loss_scale=2, train_wall=78, gb_free=16.3, wall=3795
mt_weight tensor(0.5000)
asr_weight tensor(0.4697, device='cuda:0')
2023-08-08 14:47:10 | INFO | train_inner | epoch 004:    685 / 1474 loss=2.617, trans_loss=3.75, nll_loss=1.966, w2v_ctc_loss=1.494, task_loss=0, contrastive_loss=0.298, total=4176.95, n_correct=2122.91, ppl=3.91, accuracy=50.824, wps=15692.9, ups=1.26, wpb=12451, bsz=455.2, num_updates=5100, lr=0.00019803, gnorm=0.581, clip=0, loss_scale=4, train_wall=79, gb_free=15.3, wall=3874
2023-08-08 14:48:29 | INFO | train_inner | epoch 004:    785 / 1474 loss=2.577, trans_loss=3.741, nll_loss=1.958, w2v_ctc_loss=1.505, task_loss=0, contrastive_loss=0.17, total=4016.91, n_correct=2048.8, ppl=3.89, accuracy=51.004, wps=15236.1, ups=1.27, wpb=11995.1, bsz=418.7, num_updates=5200, lr=0.000196116, gnorm=0.58, clip=0, loss_scale=4, train_wall=78, gb_free=16.3, wall=3953
2023-08-08 14:49:48 | INFO | train_inner | epoch 004:    885 / 1474 loss=2.63, trans_loss=3.727, nll_loss=1.942, w2v_ctc_loss=1.499, task_loss=0, contrastive_loss=0.345, total=4183.4, n_correct=2146.68, ppl=3.84, accuracy=51.314, wps=15776, ups=1.26, wpb=12493.2, bsz=465.4, num_updates=5300, lr=0.000194257, gnorm=0.589, clip=0, loss_scale=4, train_wall=79, gb_free=15.7, wall=4032
2023-08-08 14:51:07 | INFO | train_inner | epoch 004:    985 / 1474 loss=2.566, trans_loss=3.719, nll_loss=1.932, w2v_ctc_loss=1.478, task_loss=0, contrastive_loss=0.214, total=4128.78, n_correct=2135.99, ppl=3.82, accuracy=51.734, wps=15579.9, ups=1.26, wpb=12332, bsz=456.8, num_updates=5400, lr=0.00019245, gnorm=0.576, clip=0, loss_scale=4, train_wall=79, gb_free=16.2, wall=4111
2023-08-08 14:52:26 | INFO | train_inner | epoch 004:   1085 / 1474 loss=2.561, trans_loss=3.726, nll_loss=1.94, w2v_ctc_loss=1.482, task_loss=0, contrastive_loss=0.193, total=4080.2, n_correct=2107.72, ppl=3.84, accuracy=51.657, wps=15517.6, ups=1.27, wpb=12179.1, bsz=437.7, num_updates=5500, lr=0.000190693, gnorm=0.574, clip=0, loss_scale=4, train_wall=78, gb_free=16.4, wall=4190
2023-08-08 14:53:45 | INFO | train_inner | epoch 004:   1185 / 1474 loss=2.592, trans_loss=3.715, nll_loss=1.929, w2v_ctc_loss=1.473, task_loss=0, contrastive_loss=0.303, total=4163.45, n_correct=2161.45, ppl=3.81, accuracy=51.915, wps=15678.5, ups=1.26, wpb=12436, bsz=485.6, num_updates=5600, lr=0.000188982, gnorm=0.583, clip=0, loss_scale=4, train_wall=79, gb_free=15.4, wall=4269
2023-08-08 14:55:04 | INFO | train_inner | epoch 004:   1285 / 1474 loss=2.557, trans_loss=3.704, nll_loss=1.913, w2v_ctc_loss=1.456, task_loss=0, contrastive_loss=0.266, total=4152.41, n_correct=2180.36, ppl=3.77, accuracy=52.508, wps=15790.1, ups=1.27, wpb=12401.3, bsz=471.4, num_updates=5700, lr=0.000187317, gnorm=0.578, clip=0, loss_scale=4, train_wall=78, gb_free=13.2, wall=4348
2023-08-08 14:56:21 | INFO | train_inner | epoch 004:   1385 / 1474 loss=2.502, trans_loss=3.703, nll_loss=1.913, w2v_ctc_loss=1.448, task_loss=0, contrastive_loss=0.148, total=4103.57, n_correct=2157.49, ppl=3.76, accuracy=52.576, wps=15874.3, ups=1.3, wpb=12255.2, bsz=437.9, num_updates=5800, lr=0.000185695, gnorm=0.559, clip=0, loss_scale=4, train_wall=77, gb_free=16.9, wall=4425
2023-08-08 14:57:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.4697, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.4697, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.4697, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.4697, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.4697, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.4697, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.4697, device='cuda:1')
2023-08-08 14:57:54 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.698 | trans_loss 5.894 | nll_loss 3.266 | w2v_ctc_loss 1.621 | task_loss 0 | contrastive_loss 0.294 | total 4003.4 | n_correct 2274.9 | ppl 9.62 | accuracy 56.824 | uer 23.34 | wer 25.04 | raw_wer 25.04 | bleu 16.99 | wps 2092.7 | wpb 4003.4 | bsz 141.8 | num_updates 5889 | best_bleu 16.99
2023-08-08 14:57:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5889 updates
2023-08-08 14:57:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 14:58:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 14:58:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt (epoch 4 @ 5889 updates, score 16.99) (writing took 25.051530670374632 seconds)
2023-08-08 14:58:19 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-08 14:58:19 | INFO | train | epoch 004 | loss 2.615 | trans_loss 3.738 | nll_loss 1.955 | w2v_ctc_loss 1.505 | task_loss 0 | contrastive_loss 0.261 | total 4138.65 | n_correct 2108.9 | ppl 3.88 | accuracy 50.956 | wps 14974.5 | ups 1.21 | wpb 12355.8 | bsz 458.5 | num_updates 5889 | lr 0.000184287 | gnorm 0.726 | clip 0 | loss_scale 4 | train_wall 1151 | gb_free 15.1 | wall 4543
2023-08-08 14:58:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 14:58:19 | INFO | fairseq.trainer | begin training epoch 5
2023-08-08 14:58:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 14:58:35 | INFO | train_inner | epoch 005:     11 / 1474 loss=2.485, trans_loss=3.693, nll_loss=1.899, w2v_ctc_loss=1.421, task_loss=0, contrastive_loss=0.165, total=4031.51, n_correct=2131.32, ppl=3.73, accuracy=52.867, wps=8966.7, ups=0.74, wpb=12037.5, bsz=436.7, num_updates=5900, lr=0.000184115, gnorm=0.56, clip=0, loss_scale=4, train_wall=77, gb_free=14.5, wall=4559
2023-08-08 14:59:54 | INFO | train_inner | epoch 005:    111 / 1474 loss=2.422, trans_loss=3.639, nll_loss=1.828, w2v_ctc_loss=1.345, task_loss=0, contrastive_loss=0.184, total=4256.63, n_correct=2322.84, ppl=3.55, accuracy=54.57, wps=16031.2, ups=1.26, wpb=12710, bsz=500.1, num_updates=6000, lr=0.000182574, gnorm=0.54, clip=0, loss_scale=4, train_wall=79, gb_free=16.4, wall=4638
2023-08-08 14:59:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 15:00:20 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.696 | trans_loss 5.889 | nll_loss 3.253 | w2v_ctc_loss 1.624 | task_loss 0 | contrastive_loss 0.295 | total 4003.4 | n_correct 2280.1 | ppl 9.53 | accuracy 56.954 | uer 23.141 | wer 24.757 | raw_wer 24.757 | bleu 16.66 | wps 1922.7 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 16.99
2023-08-08 15:00:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-08-08 15:00:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_5_6000.pt
2023-08-08 15:00:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_5_6000.pt
2023-08-08 15:00:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 16.66) (writing took 23.76010919548571 seconds)
2023-08-08 15:02:01 | INFO | train_inner | epoch 005:    211 / 1474 loss=2.483, trans_loss=3.653, nll_loss=1.845, w2v_ctc_loss=1.362, task_loss=0, contrastive_loss=0.384, total=4186.83, n_correct=2270.86, ppl=3.59, accuracy=54.238, wps=9865.9, ups=0.79, wpb=12492.2, bsz=485.3, num_updates=6100, lr=0.000181071, gnorm=0.554, clip=0, loss_scale=4, train_wall=77, gb_free=16.2, wall=4765
2023-08-08 15:03:18 | INFO | train_inner | epoch 005:    311 / 1474 loss=2.446, trans_loss=3.646, nll_loss=1.841, w2v_ctc_loss=1.379, task_loss=0, contrastive_loss=0.239, total=4094.07, n_correct=2215.94, ppl=3.58, accuracy=54.126, wps=15806.3, ups=1.29, wpb=12241.2, bsz=446, num_updates=6200, lr=0.000179605, gnorm=0.546, clip=0, loss_scale=4, train_wall=77, gb_free=16.4, wall=4843
2023-08-08 15:04:37 | INFO | train_inner | epoch 005:    411 / 1474 loss=2.459, trans_loss=3.641, nll_loss=1.834, w2v_ctc_loss=1.348, task_loss=0, contrastive_loss=0.322, total=4140.39, n_correct=2257.27, ppl=3.57, accuracy=54.518, wps=15679.3, ups=1.27, wpb=12372.8, bsz=467.9, num_updates=6300, lr=0.000178174, gnorm=0.556, clip=0, loss_scale=4, train_wall=78, gb_free=16.3, wall=4921
2023-08-08 15:05:56 | INFO | train_inner | epoch 005:    511 / 1474 loss=2.384, trans_loss=3.649, nll_loss=1.843, w2v_ctc_loss=1.349, task_loss=0, contrastive_loss=0.121, total=4026.21, n_correct=2185.17, ppl=3.59, accuracy=54.274, wps=15392.4, ups=1.28, wpb=12028.8, bsz=418.1, num_updates=6400, lr=0.000176777, gnorm=0.533, clip=0, loss_scale=4, train_wall=78, gb_free=17.2, wall=5000
2023-08-08 15:07:14 | INFO | train_inner | epoch 005:    611 / 1474 loss=2.436, trans_loss=3.656, nll_loss=1.849, w2v_ctc_loss=1.343, task_loss=0, contrastive_loss=0.29, total=4109.94, n_correct=2230.98, ppl=3.6, accuracy=54.283, wps=15669.6, ups=1.28, wpb=12260.2, bsz=449.8, num_updates=6500, lr=0.000175412, gnorm=0.558, clip=0, loss_scale=4, train_wall=78, gb_free=15.6, wall=5078
2023-08-08 15:08:32 | INFO | train_inner | epoch 005:    711 / 1474 loss=2.441, trans_loss=3.648, nll_loss=1.842, w2v_ctc_loss=1.344, task_loss=0, contrastive_loss=0.265, total=4176.83, n_correct=2281.83, ppl=3.58, accuracy=54.631, wps=15852.3, ups=1.27, wpb=12467.5, bsz=483.6, num_updates=6600, lr=0.000174078, gnorm=0.547, clip=0, loss_scale=4, train_wall=78, gb_free=17.2, wall=5157
2023-08-08 15:09:51 | INFO | train_inner | epoch 005:    811 / 1474 loss=2.4, trans_loss=3.648, nll_loss=1.84, w2v_ctc_loss=1.336, task_loss=0, contrastive_loss=0.193, total=4127.9, n_correct=2258.02, ppl=3.58, accuracy=54.701, wps=15638, ups=1.27, wpb=12321.2, bsz=447.5, num_updates=6700, lr=0.000172774, gnorm=0.534, clip=0, loss_scale=4, train_wall=78, gb_free=16, wall=5235
2023-08-08 15:11:10 | INFO | train_inner | epoch 005:    911 / 1474 loss=2.37, trans_loss=3.638, nll_loss=1.83, w2v_ctc_loss=1.321, task_loss=0, contrastive_loss=0.156, total=4101.19, n_correct=2255.99, ppl=3.56, accuracy=55.008, wps=15569.7, ups=1.27, wpb=12245.9, bsz=447.9, num_updates=6800, lr=0.000171499, gnorm=0.531, clip=0, loss_scale=4, train_wall=78, gb_free=17.4, wall=5314
2023-08-08 15:12:28 | INFO | train_inner | epoch 005:   1011 / 1474 loss=2.396, trans_loss=3.641, nll_loss=1.833, w2v_ctc_loss=1.326, task_loss=0, contrastive_loss=0.234, total=4164.27, n_correct=2287.61, ppl=3.56, accuracy=54.934, wps=15960.2, ups=1.28, wpb=12430.2, bsz=462, num_updates=6900, lr=0.000170251, gnorm=0.53, clip=0, loss_scale=4, train_wall=77, gb_free=15.2, wall=5392
2023-08-08 15:13:47 | INFO | train_inner | epoch 005:   1111 / 1474 loss=2.412, trans_loss=3.643, nll_loss=1.834, w2v_ctc_loss=1.334, task_loss=0, contrastive_loss=0.238, total=4168.94, n_correct=2293.84, ppl=3.57, accuracy=55.022, wps=15760, ups=1.27, wpb=12436.1, bsz=464.1, num_updates=7000, lr=0.000169031, gnorm=0.535, clip=0, loss_scale=4, train_wall=78, gb_free=16.8, wall=5471
2023-08-08 15:15:05 | INFO | train_inner | epoch 005:   1211 / 1474 loss=2.358, trans_loss=3.637, nll_loss=1.827, w2v_ctc_loss=1.311, task_loss=0, contrastive_loss=0.145, total=4171.16, n_correct=2303.29, ppl=3.55, accuracy=55.219, wps=15833.5, ups=1.27, wpb=12443.2, bsz=456.3, num_updates=7100, lr=0.000167836, gnorm=0.531, clip=0, loss_scale=4, train_wall=78, gb_free=16.1, wall=5549
2023-08-08 15:16:25 | INFO | train_inner | epoch 005:   1311 / 1474 loss=2.334, trans_loss=3.636, nll_loss=1.827, w2v_ctc_loss=1.296, task_loss=0, contrastive_loss=0.115, total=4126.97, n_correct=2279.38, ppl=3.55, accuracy=55.231, wps=15530.1, ups=1.26, wpb=12317.9, bsz=443.4, num_updates=7200, lr=0.000166667, gnorm=0.523, clip=0, loss_scale=8, train_wall=79, gb_free=15.7, wall=5629
2023-08-08 15:17:43 | INFO | train_inner | epoch 005:   1411 / 1474 loss=2.358, trans_loss=3.636, nll_loss=1.829, w2v_ctc_loss=1.296, task_loss=0, contrastive_loss=0.175, total=4138.54, n_correct=2285.88, ppl=3.55, accuracy=55.234, wps=15773.2, ups=1.28, wpb=12359.3, bsz=459, num_updates=7300, lr=0.000165521, gnorm=0.522, clip=0, loss_scale=8, train_wall=78, gb_free=17, wall=5707
2023-08-08 15:18:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 15:18:55 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.58 | trans_loss 5.798 | nll_loss 3.145 | w2v_ctc_loss 1.463 | task_loss 0 | contrastive_loss 0.286 | total 4003.4 | n_correct 2331.4 | ppl 8.85 | accuracy 58.235 | uer 21.355 | wer 22.986 | raw_wer 22.986 | bleu 17.34 | wps 2271.1 | wpb 4003.4 | bsz 141.8 | num_updates 7363 | best_bleu 17.34
2023-08-08 15:18:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7363 updates
2023-08-08 15:18:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 15:19:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 15:19:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt (epoch 5 @ 7363 updates, score 17.34) (writing took 25.736482612788677 seconds)
2023-08-08 15:19:21 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-08 15:19:21 | INFO | train | epoch 005 | loss 2.406 | trans_loss 3.643 | nll_loss 1.835 | w2v_ctc_loss 1.335 | task_loss 0 | contrastive_loss 0.219 | total 4138.65 | n_correct 2265.32 | ppl 3.57 | accuracy 54.736 | wps 14434.7 | ups 1.17 | wpb 12355.8 | bsz 458.5 | num_updates 7363 | lr 0.000164812 | gnorm 0.539 | clip 0 | loss_scale 8 | train_wall 1149 | gb_free 16.5 | wall 5805
2023-08-08 15:19:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 15:19:21 | INFO | fairseq.trainer | begin training epoch 6
2023-08-08 15:19:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 15:19:58 | INFO | train_inner | epoch 006:     37 / 1474 loss=2.343, trans_loss=3.613, nll_loss=1.797, w2v_ctc_loss=1.293, task_loss=0, contrastive_loss=0.172, total=4113.87, n_correct=2297.33, ppl=3.48, accuracy=55.844, wps=9059.4, ups=0.74, wpb=12276.7, bsz=447.4, num_updates=7400, lr=0.000164399, gnorm=0.54, clip=0, loss_scale=8, train_wall=78, gb_free=18, wall=5843
2023-08-08 15:21:17 | INFO | train_inner | epoch 006:    137 / 1474 loss=2.297, trans_loss=3.579, nll_loss=1.754, w2v_ctc_loss=1.238, task_loss=0, contrastive_loss=0.214, total=4161.2, n_correct=2359.52, ppl=3.37, accuracy=56.703, wps=15825.4, ups=1.27, wpb=12428.5, bsz=458.1, num_updates=7500, lr=0.000163299, gnorm=0.515, clip=0, loss_scale=8, train_wall=78, gb_free=17.1, wall=5921
2023-08-08 15:22:36 | INFO | train_inner | epoch 006:    237 / 1474 loss=2.296, trans_loss=3.593, nll_loss=1.773, w2v_ctc_loss=1.269, task_loss=0, contrastive_loss=0.126, total=4110.12, n_correct=2313.76, ppl=3.42, accuracy=56.294, wps=15529.4, ups=1.26, wpb=12279.2, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.513, clip=0, loss_scale=8, train_wall=79, gb_free=17.3, wall=6000
2023-08-08 15:23:55 | INFO | train_inner | epoch 006:    337 / 1474 loss=2.359, trans_loss=3.58, nll_loss=1.757, w2v_ctc_loss=1.222, task_loss=0, contrastive_loss=0.42, total=4170.52, n_correct=2367.17, ppl=3.38, accuracy=56.76, wps=15684.3, ups=1.26, wpb=12453.1, bsz=488.4, num_updates=7700, lr=0.000161165, gnorm=0.53, clip=0, loss_scale=8, train_wall=79, gb_free=15.9, wall=6080
2023-08-08 15:25:14 | INFO | train_inner | epoch 006:    437 / 1474 loss=2.272, trans_loss=3.584, nll_loss=1.761, w2v_ctc_loss=1.231, task_loss=0, contrastive_loss=0.139, total=4154.89, n_correct=2361.27, ppl=3.39, accuracy=56.831, wps=15874.5, ups=1.28, wpb=12405.6, bsz=470.4, num_updates=7800, lr=0.000160128, gnorm=0.515, clip=0, loss_scale=8, train_wall=78, gb_free=16.6, wall=6158
2023-08-08 15:26:32 | INFO | train_inner | epoch 006:    537 / 1474 loss=2.273, trans_loss=3.59, nll_loss=1.768, w2v_ctc_loss=1.242, task_loss=0, contrastive_loss=0.128, total=4174.46, n_correct=2375.29, ppl=3.41, accuracy=56.901, wps=15905.3, ups=1.28, wpb=12460.1, bsz=458.3, num_updates=7900, lr=0.000159111, gnorm=0.518, clip=0, loss_scale=8, train_wall=78, gb_free=17.3, wall=6236
2023-08-08 15:27:51 | INFO | train_inner | epoch 006:    637 / 1474 loss=2.283, trans_loss=3.59, nll_loss=1.77, w2v_ctc_loss=1.225, task_loss=0, contrastive_loss=0.183, total=4145.19, n_correct=2354.43, ppl=3.41, accuracy=56.799, wps=15754.8, ups=1.27, wpb=12372.7, bsz=470.9, num_updates=8000, lr=0.000158114, gnorm=0.515, clip=0, loss_scale=8, train_wall=78, gb_free=16, wall=6315
2023-08-08 15:27:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 15:28:14 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.573 | trans_loss 5.773 | nll_loss 3.101 | w2v_ctc_loss 1.514 | task_loss 0 | contrastive_loss 0.274 | total 4003.4 | n_correct 2345.8 | ppl 8.58 | accuracy 58.595 | uer 21.628 | wer 23.716 | raw_wer 23.716 | bleu 17.88 | wps 2157 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 17.88
2023-08-08 15:28:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-08-08 15:28:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_6_8000.pt
2023-08-08 15:28:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_6_8000.pt
2023-08-08 15:28:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 17.88) (writing took 43.721327375620604 seconds)
2023-08-08 15:30:17 | INFO | train_inner | epoch 006:    737 / 1474 loss=2.278, trans_loss=3.594, nll_loss=1.775, w2v_ctc_loss=1.242, task_loss=0, contrastive_loss=0.137, total=4151.01, n_correct=2353.77, ppl=3.42, accuracy=56.704, wps=8487.7, ups=0.68, wpb=12393.7, bsz=454.2, num_updates=8100, lr=0.000157135, gnorm=0.51, clip=0, loss_scale=8, train_wall=78, gb_free=13.3, wall=6461
2023-08-08 15:31:35 | INFO | train_inner | epoch 006:    837 / 1474 loss=2.269, trans_loss=3.604, nll_loss=1.787, w2v_ctc_loss=1.235, task_loss=0, contrastive_loss=0.12, total=4108.83, n_correct=2320.12, ppl=3.45, accuracy=56.467, wps=15589.3, ups=1.27, wpb=12267.1, bsz=439.4, num_updates=8200, lr=0.000156174, gnorm=0.51, clip=0, loss_scale=8, train_wall=78, gb_free=17.2, wall=6539
2023-08-08 15:32:54 | INFO | train_inner | epoch 006:    937 / 1474 loss=2.305, trans_loss=3.602, nll_loss=1.785, w2v_ctc_loss=1.239, task_loss=0, contrastive_loss=0.217, total=4076.46, n_correct=2305.1, ppl=3.45, accuracy=56.547, wps=15446.6, ups=1.27, wpb=12166, bsz=443, num_updates=8300, lr=0.00015523, gnorm=0.526, clip=0, loss_scale=8, train_wall=78, gb_free=12.9, wall=6618
2023-08-08 15:34:13 | INFO | train_inner | epoch 006:   1037 / 1474 loss=2.307, trans_loss=3.587, nll_loss=1.767, w2v_ctc_loss=1.217, task_loss=0, contrastive_loss=0.289, total=4175.9, n_correct=2377.42, ppl=3.4, accuracy=56.932, wps=15851.8, ups=1.27, wpb=12465, bsz=480.4, num_updates=8400, lr=0.000154303, gnorm=0.527, clip=0, loss_scale=8, train_wall=78, gb_free=14.4, wall=6697
2023-08-08 15:35:31 | INFO | train_inner | epoch 006:   1137 / 1474 loss=2.262, trans_loss=3.593, nll_loss=1.773, w2v_ctc_loss=1.23, task_loss=0, contrastive_loss=0.126, total=4077.2, n_correct=2314.82, ppl=3.42, accuracy=56.775, wps=15617.8, ups=1.28, wpb=12172.7, bsz=430.6, num_updates=8500, lr=0.000153393, gnorm=0.514, clip=0, loss_scale=8, train_wall=77, gb_free=16.5, wall=6775
2023-08-08 15:36:49 | INFO | train_inner | epoch 006:   1237 / 1474 loss=2.345, trans_loss=3.586, nll_loss=1.768, w2v_ctc_loss=1.218, task_loss=0, contrastive_loss=0.435, total=4133.46, n_correct=2349.21, ppl=3.41, accuracy=56.834, wps=15645, ups=1.27, wpb=12346.4, bsz=470.3, num_updates=8600, lr=0.000152499, gnorm=0.521, clip=0, loss_scale=8, train_wall=78, gb_free=12.7, wall=6854
2023-08-08 15:38:08 | INFO | train_inner | epoch 006:   1337 / 1474 loss=2.247, trans_loss=3.594, nll_loss=1.773, w2v_ctc_loss=1.215, task_loss=0, contrastive_loss=0.112, total=4127.77, n_correct=2354.04, ppl=3.42, accuracy=57.029, wps=15736, ups=1.28, wpb=12312.7, bsz=454.1, num_updates=8700, lr=0.00015162, gnorm=0.517, clip=0, loss_scale=8, train_wall=78, gb_free=17.2, wall=6932
2023-08-08 15:39:27 | INFO | train_inner | epoch 006:   1437 / 1474 loss=2.243, trans_loss=3.584, nll_loss=1.763, w2v_ctc_loss=1.213, task_loss=0, contrastive_loss=0.116, total=4190.32, n_correct=2401.09, ppl=3.39, accuracy=57.301, wps=15782.5, ups=1.26, wpb=12507.6, bsz=460.5, num_updates=8800, lr=0.000150756, gnorm=0.5, clip=0, loss_scale=8, train_wall=79, gb_free=17, wall=7011
2023-08-08 15:39:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 15:40:18 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.519 | trans_loss 5.726 | nll_loss 3.051 | w2v_ctc_loss 1.456 | task_loss 0 | contrastive_loss 0.262 | total 4003.4 | n_correct 2375.5 | ppl 8.29 | accuracy 59.337 | uer 20.328 | wer 22.005 | raw_wer 22.005 | bleu 18.36 | wps 2304.2 | wpb 4003.4 | bsz 141.8 | num_updates 8837 | best_bleu 18.36
2023-08-08 15:40:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8837 updates
2023-08-08 15:40:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 15:40:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 15:40:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt (epoch 6 @ 8837 updates, score 18.36) (writing took 26.10830583795905 seconds)
2023-08-08 15:40:44 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-08 15:40:44 | INFO | train | epoch 006 | loss 2.287 | trans_loss 3.59 | nll_loss 1.769 | w2v_ctc_loss 1.231 | task_loss 0 | contrastive_loss 0.196 | total 4138.65 | n_correct 2350.45 | ppl 3.41 | accuracy 56.793 | wps 14192 | ups 1.15 | wpb 12355.8 | bsz 458.5 | num_updates 8837 | lr 0.00015044 | gnorm 0.516 | clip 0 | loss_scale 8 | train_wall 1150 | gb_free 15.4 | wall 7088
2023-08-08 15:40:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 15:40:44 | INFO | fairseq.trainer | begin training epoch 7
2023-08-08 15:40:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 15:41:42 | INFO | train_inner | epoch 007:     63 / 1474 loss=2.214, trans_loss=3.562, nll_loss=1.734, w2v_ctc_loss=1.182, task_loss=0, contrastive_loss=0.13, total=4110.43, n_correct=2378.02, ppl=3.33, accuracy=57.853, wps=9089.7, ups=0.74, wpb=12272.9, bsz=462.8, num_updates=8900, lr=0.000149906, gnorm=0.509, clip=0, loss_scale=8, train_wall=77, gb_free=17.5, wall=7146
2023-08-08 15:43:00 | INFO | train_inner | epoch 007:    163 / 1474 loss=2.218, trans_loss=3.551, nll_loss=1.72, w2v_ctc_loss=1.168, task_loss=0, contrastive_loss=0.201, total=4109.53, n_correct=2386.69, ppl=3.29, accuracy=58.077, wps=15712.9, ups=1.28, wpb=12269.6, bsz=454.1, num_updates=9000, lr=0.000149071, gnorm=0.51, clip=0, loss_scale=8, train_wall=78, gb_free=13.9, wall=7224
2023-08-08 15:44:18 | INFO | train_inner | epoch 007:    263 / 1474 loss=2.19, trans_loss=3.545, nll_loss=1.711, w2v_ctc_loss=1.17, task_loss=0, contrastive_loss=0.111, total=4133.29, n_correct=2413.99, ppl=3.27, accuracy=58.404, wps=15762.2, ups=1.28, wpb=12335.8, bsz=455.5, num_updates=9100, lr=0.00014825, gnorm=0.504, clip=0, loss_scale=8, train_wall=78, gb_free=15.6, wall=7303
2023-08-08 15:45:38 | INFO | train_inner | epoch 007:    363 / 1474 loss=2.265, trans_loss=3.556, nll_loss=1.725, w2v_ctc_loss=1.163, task_loss=0, contrastive_loss=0.375, total=4194.76, n_correct=2434.02, ppl=3.31, accuracy=58.025, wps=15790.9, ups=1.26, wpb=12518.2, bsz=477.6, num_updates=9200, lr=0.000147442, gnorm=0.512, clip=0, loss_scale=16, train_wall=79, gb_free=13.3, wall=7382
2023-08-08 15:46:56 | INFO | train_inner | epoch 007:    463 / 1474 loss=2.24, trans_loss=3.555, nll_loss=1.726, w2v_ctc_loss=1.159, task_loss=0, contrastive_loss=0.295, total=4153.22, n_correct=2409.7, ppl=3.31, accuracy=58.02, wps=15869.5, ups=1.28, wpb=12403.3, bsz=463, num_updates=9300, lr=0.000146647, gnorm=0.507, clip=0, loss_scale=16, train_wall=78, gb_free=17, wall=7460
2023-08-08 15:48:14 | INFO | train_inner | epoch 007:    563 / 1474 loss=2.191, trans_loss=3.555, nll_loss=1.723, w2v_ctc_loss=1.164, task_loss=0, contrastive_loss=0.117, total=4168.14, n_correct=2428.11, ppl=3.3, accuracy=58.254, wps=15852.4, ups=1.27, wpb=12434.7, bsz=459.8, num_updates=9400, lr=0.000145865, gnorm=0.51, clip=0, loss_scale=16, train_wall=78, gb_free=17, wall=7538
2023-08-08 15:49:33 | INFO | train_inner | epoch 007:    663 / 1474 loss=2.18, trans_loss=3.552, nll_loss=1.721, w2v_ctc_loss=1.156, task_loss=0, contrastive_loss=0.107, total=4157.82, n_correct=2424.68, ppl=3.3, accuracy=58.316, wps=15745.6, ups=1.27, wpb=12406.4, bsz=455.4, num_updates=9500, lr=0.000145095, gnorm=0.501, clip=0, loss_scale=16, train_wall=78, gb_free=15.8, wall=7617
2023-08-08 15:50:52 | INFO | train_inner | epoch 007:    763 / 1474 loss=2.18, trans_loss=3.551, nll_loss=1.72, w2v_ctc_loss=1.157, task_loss=0, contrastive_loss=0.104, total=4122.1, n_correct=2394.92, ppl=3.29, accuracy=58.1, wps=15575.8, ups=1.27, wpb=12308.4, bsz=446.2, num_updates=9600, lr=0.000144338, gnorm=0.505, clip=0, loss_scale=16, train_wall=78, gb_free=15.8, wall=7696
2023-08-08 15:52:11 | INFO | train_inner | epoch 007:    863 / 1474 loss=2.188, trans_loss=3.559, nll_loss=1.73, w2v_ctc_loss=1.157, task_loss=0, contrastive_loss=0.122, total=4147.23, n_correct=2406.71, ppl=3.32, accuracy=58.032, wps=15723.1, ups=1.27, wpb=12377.6, bsz=460.9, num_updates=9700, lr=0.000143592, gnorm=0.507, clip=0, loss_scale=16, train_wall=78, gb_free=17.6, wall=7775
2023-08-08 15:53:30 | INFO | train_inner | epoch 007:    963 / 1474 loss=2.21, trans_loss=3.552, nll_loss=1.724, w2v_ctc_loss=1.145, task_loss=0, contrastive_loss=0.214, total=4140.14, n_correct=2414.12, ppl=3.3, accuracy=58.31, wps=15676.8, ups=1.27, wpb=12359.1, bsz=474.6, num_updates=9800, lr=0.000142857, gnorm=0.514, clip=0, loss_scale=16, train_wall=78, gb_free=16.2, wall=7854
2023-08-08 15:54:48 | INFO | train_inner | epoch 007:   1063 / 1474 loss=2.178, trans_loss=3.564, nll_loss=1.738, w2v_ctc_loss=1.16, task_loss=0, contrastive_loss=0.091, total=4103.51, n_correct=2378.77, ppl=3.34, accuracy=57.969, wps=15623.4, ups=1.28, wpb=12251.1, bsz=437.5, num_updates=9900, lr=0.000142134, gnorm=0.507, clip=0, loss_scale=16, train_wall=78, gb_free=17, wall=7932
2023-08-08 15:56:08 | INFO | train_inner | epoch 007:   1163 / 1474 loss=2.255, trans_loss=3.549, nll_loss=1.723, w2v_ctc_loss=1.149, task_loss=0, contrastive_loss=0.344, total=4137.04, n_correct=2412.9, ppl=3.3, accuracy=58.324, wps=15544.2, ups=1.26, wpb=12361.6, bsz=470.9, num_updates=10000, lr=0.000141421, gnorm=0.51, clip=0, loss_scale=16, train_wall=79, gb_free=16.2, wall=8012
2023-08-08 15:56:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 15:56:31 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.466 | trans_loss 5.682 | nll_loss 2.995 | w2v_ctc_loss 1.393 | task_loss 0 | contrastive_loss 0.254 | total 4003.4 | n_correct 2401.9 | ppl 7.97 | accuracy 59.997 | uer 19.199 | wer 20.928 | raw_wer 20.928 | bleu 18.55 | wps 2229.5 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 18.55
2023-08-08 15:56:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-08-08 15:56:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_7_10000.pt
2023-08-08 15:56:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_7_10000.pt
2023-08-08 15:57:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 18.55) (writing took 43.162858579307795 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:0')
2023-08-08 15:58:32 | INFO | train_inner | epoch 007:   1263 / 1474 loss=2.171, trans_loss=3.557, nll_loss=1.731, w2v_ctc_loss=1.142, task_loss=0, contrastive_loss=0.116, total=4129.52, n_correct=2402.48, ppl=3.32, accuracy=58.178, wps=8533.7, ups=0.69, wpb=12331.4, bsz=450.2, num_updates=10100, lr=0.00014072, gnorm=0.409, clip=0, loss_scale=16, train_wall=77, gb_free=16.9, wall=8156
2023-08-08 15:59:50 | INFO | train_inner | epoch 007:   1363 / 1474 loss=2.197, trans_loss=3.55, nll_loss=1.722, w2v_ctc_loss=1.155, task_loss=0, contrastive_loss=0.151, total=4172.87, n_correct=2438.46, ppl=3.3, accuracy=58.436, wps=16000.1, ups=1.28, wpb=12458.1, bsz=476.2, num_updates=10200, lr=0.000140028, gnorm=0.412, clip=0, loss_scale=16, train_wall=77, gb_free=17.3, wall=8234
2023-08-08 16:01:10 | INFO | train_inner | epoch 007:   1463 / 1474 loss=2.208, trans_loss=3.554, nll_loss=1.729, w2v_ctc_loss=1.152, task_loss=0, contrastive_loss=0.217, total=4109.42, n_correct=2387.7, ppl=3.32, accuracy=58.103, wps=15280, ups=1.24, wpb=12278.1, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.415, clip=0, loss_scale=16, train_wall=80, gb_free=16.7, wall=8314
2023-08-08 16:01:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:6')
2023-08-08 16:01:40 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.472 | trans_loss 5.685 | nll_loss 2.995 | w2v_ctc_loss 1.396 | task_loss 0 | contrastive_loss 0.267 | total 4003.4 | n_correct 2394.6 | ppl 7.97 | accuracy 59.814 | uer 19.539 | wer 21.334 | raw_wer 21.334 | bleu 18.71 | wps 2445.5 | wpb 4003.4 | bsz 141.8 | num_updates 10311 | best_bleu 18.71
2023-08-08 16:01:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10311 updates
2023-08-08 16:01:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 16:01:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 16:02:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt (epoch 7 @ 10311 updates, score 18.71) (writing took 24.578903306275606 seconds)
2023-08-08 16:02:05 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-08 16:02:05 | INFO | train | epoch 007 | loss 2.205 | trans_loss 3.553 | nll_loss 1.724 | w2v_ctc_loss 1.158 | task_loss 0 | contrastive_loss 0.181 | total 4138.65 | n_correct 2408.11 | ppl 3.3 | accuracy 58.186 | wps 14218.8 | ups 1.15 | wpb 12355.8 | bsz 458.5 | num_updates 10311 | lr 0.000139272 | gnorm 0.488 | clip 0 | loss_scale 16 | train_wall 1151 | gb_free 13.5 | wall 8369
2023-08-08 16:02:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 16:02:05 | INFO | fairseq.trainer | begin training epoch 8
2023-08-08 16:02:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 16:03:23 | INFO | train_inner | epoch 008:     89 / 1474 loss=2.134, trans_loss=3.531, nll_loss=1.691, w2v_ctc_loss=1.111, task_loss=0, contrastive_loss=0.109, total=4116.25, n_correct=2432.59, ppl=3.23, accuracy=59.097, wps=9240.3, ups=0.75, wpb=12273, bsz=443.3, num_updates=10400, lr=0.000138675, gnorm=0.407, clip=0, loss_scale=16, train_wall=78, gb_free=17.2, wall=8447
2023-08-08 16:04:41 | INFO | train_inner | epoch 008:    189 / 1474 loss=2.138, trans_loss=3.523, nll_loss=1.682, w2v_ctc_loss=1.111, task_loss=0, contrastive_loss=0.13, total=4037.23, n_correct=2392.1, ppl=3.21, accuracy=59.251, wps=15495.5, ups=1.29, wpb=12041.5, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.416, clip=0, loss_scale=16, train_wall=77, gb_free=13.1, wall=8525
2023-08-08 16:05:59 | INFO | train_inner | epoch 008:    289 / 1474 loss=2.142, trans_loss=3.518, nll_loss=1.678, w2v_ctc_loss=1.113, task_loss=0, contrastive_loss=0.126, total=4207.78, n_correct=2499.6, ppl=3.2, accuracy=59.404, wps=16100, ups=1.28, wpb=12556.5, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.409, clip=0, loss_scale=16, train_wall=78, gb_free=13.4, wall=8603
2023-08-08 16:07:18 | INFO | train_inner | epoch 008:    389 / 1474 loss=2.158, trans_loss=3.528, nll_loss=1.69, w2v_ctc_loss=1.129, task_loss=0, contrastive_loss=0.152, total=4127.24, n_correct=2437.01, ppl=3.23, accuracy=59.047, wps=15525.4, ups=1.26, wpb=12316.2, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=0.411, clip=0, loss_scale=16, train_wall=79, gb_free=12.2, wall=8682
2023-08-08 16:08:37 | INFO | train_inner | epoch 008:    489 / 1474 loss=2.235, trans_loss=3.522, nll_loss=1.686, w2v_ctc_loss=1.106, task_loss=0, contrastive_loss=0.405, total=4203.76, n_correct=2489.63, ppl=3.22, accuracy=59.224, wps=15905.8, ups=1.27, wpb=12548.2, bsz=504.5, num_updates=10800, lr=0.000136083, gnorm=0.417, clip=0, loss_scale=16, train_wall=78, gb_free=14.8, wall=8761
2023-08-08 16:09:56 | INFO | train_inner | epoch 008:    589 / 1474 loss=2.136, trans_loss=3.525, nll_loss=1.692, w2v_ctc_loss=1.126, task_loss=0, contrastive_loss=0.089, total=4062.5, n_correct=2391.74, ppl=3.23, accuracy=58.874, wps=15432.2, ups=1.27, wpb=12145.4, bsz=427.9, num_updates=10900, lr=0.000135457, gnorm=0.409, clip=0, loss_scale=16, train_wall=78, gb_free=11.7, wall=8840
2023-08-08 16:11:14 | INFO | train_inner | epoch 008:    689 / 1474 loss=2.129, trans_loss=3.52, nll_loss=1.681, w2v_ctc_loss=1.119, task_loss=0, contrastive_loss=0.099, total=4142.78, n_correct=2461.13, ppl=3.21, accuracy=59.408, wps=15737, ups=1.27, wpb=12364.4, bsz=448.6, num_updates=11000, lr=0.00013484, gnorm=0.406, clip=0, loss_scale=16, train_wall=78, gb_free=16, wall=8918
2023-08-08 16:12:33 | INFO | train_inner | epoch 008:    789 / 1474 loss=2.153, trans_loss=3.52, nll_loss=1.686, w2v_ctc_loss=1.113, task_loss=0, contrastive_loss=0.185, total=4118.9, n_correct=2436.92, ppl=3.22, accuracy=59.164, wps=15662.5, ups=1.27, wpb=12310.9, bsz=447.8, num_updates=11100, lr=0.000134231, gnorm=0.416, clip=0, loss_scale=16, train_wall=78, gb_free=15.4, wall=8997
2023-08-08 16:12:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-08 16:13:52 | INFO | train_inner | epoch 008:    890 / 1474 loss=2.128, trans_loss=3.523, nll_loss=1.689, w2v_ctc_loss=1.106, task_loss=0, contrastive_loss=0.111, total=4145.6, n_correct=2459.17, ppl=3.23, accuracy=59.32, wps=15643.2, ups=1.26, wpb=12381.5, bsz=460.7, num_updates=11200, lr=0.000133631, gnorm=0.407, clip=0, loss_scale=8, train_wall=79, gb_free=14.7, wall=9076
2023-08-08 16:15:10 | INFO | train_inner | epoch 008:    990 / 1474 loss=2.118, trans_loss=3.523, nll_loss=1.688, w2v_ctc_loss=1.101, task_loss=0, contrastive_loss=0.096, total=4150.39, n_correct=2466.02, ppl=3.22, accuracy=59.417, wps=15904.1, ups=1.28, wpb=12390.2, bsz=462.8, num_updates=11300, lr=0.000133038, gnorm=0.408, clip=0, loss_scale=8, train_wall=77, gb_free=17.5, wall=9154
2023-08-08 16:16:29 | INFO | train_inner | epoch 008:   1090 / 1474 loss=2.179, trans_loss=3.528, nll_loss=1.694, w2v_ctc_loss=1.101, task_loss=0, contrastive_loss=0.318, total=4197.39, n_correct=2483.65, ppl=3.23, accuracy=59.171, wps=15906, ups=1.27, wpb=12529.5, bsz=466.4, num_updates=11400, lr=0.000132453, gnorm=0.408, clip=0, loss_scale=8, train_wall=78, gb_free=17, wall=9233
2023-08-08 16:17:47 | INFO | train_inner | epoch 008:   1190 / 1474 loss=2.127, trans_loss=3.521, nll_loss=1.687, w2v_ctc_loss=1.104, task_loss=0, contrastive_loss=0.105, total=4180.55, n_correct=2483.6, ppl=3.22, accuracy=59.408, wps=15972.1, ups=1.28, wpb=12487.2, bsz=472.7, num_updates=11500, lr=0.000131876, gnorm=0.41, clip=0, loss_scale=8, train_wall=78, gb_free=17.5, wall=9311
2023-08-08 16:19:05 | INFO | train_inner | epoch 008:   1290 / 1474 loss=2.141, trans_loss=3.529, nll_loss=1.697, w2v_ctc_loss=1.117, task_loss=0, contrastive_loss=0.127, total=4062.6, n_correct=2396.28, ppl=3.24, accuracy=58.984, wps=15514.7, ups=1.28, wpb=12135.3, bsz=437.8, num_updates=11600, lr=0.000131306, gnorm=0.411, clip=0, loss_scale=8, train_wall=78, gb_free=13.4, wall=9389
2023-08-08 16:20:23 | INFO | train_inner | epoch 008:   1390 / 1474 loss=2.158, trans_loss=3.529, nll_loss=1.697, w2v_ctc_loss=1.106, task_loss=0, contrastive_loss=0.191, total=4159.11, n_correct=2464.16, ppl=3.24, accuracy=59.247, wps=15934, ups=1.28, wpb=12419, bsz=468.7, num_updates=11700, lr=0.000130744, gnorm=0.409, clip=0, loss_scale=8, train_wall=77, gb_free=13.6, wall=9467
2023-08-08 16:21:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 16:21:51 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.45 | trans_loss 5.658 | nll_loss 2.957 | w2v_ctc_loss 1.402 | task_loss 0 | contrastive_loss 0.25 | total 4003.4 | n_correct 2416.4 | ppl 7.77 | accuracy 60.359 | uer 18.862 | wer 20.633 | raw_wer 20.633 | bleu 19 | wps 2387 | wpb 4003.4 | bsz 141.8 | num_updates 11784 | best_bleu 19
2023-08-08 16:21:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11784 updates
2023-08-08 16:21:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 16:22:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 16:22:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt (epoch 8 @ 11784 updates, score 19.0) (writing took 24.638666313141584 seconds)
2023-08-08 16:22:16 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-08 16:22:16 | INFO | train | epoch 008 | loss 2.148 | trans_loss 3.524 | nll_loss 1.689 | w2v_ctc_loss 1.111 | task_loss 0 | contrastive_loss 0.166 | total 4136.97 | n_correct 2450.25 | ppl 3.22 | accuracy 59.228 | wps 15020.7 | ups 1.22 | wpb 12350.7 | bsz 457.6 | num_updates 11784 | lr 0.000130277 | gnorm 0.41 | clip 0 | loss_scale 8 | train_wall 1148 | gb_free 17.1 | wall 9580
2023-08-08 16:22:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 16:22:16 | INFO | fairseq.trainer | begin training epoch 9
2023-08-08 16:22:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 16:22:37 | INFO | train_inner | epoch 009:     16 / 1474 loss=2.16, trans_loss=3.521, nll_loss=1.685, w2v_ctc_loss=1.09, task_loss=0, contrastive_loss=0.285, total=4121.25, n_correct=2451.6, ppl=3.22, accuracy=59.487, wps=9207.7, ups=0.75, wpb=12298.5, bsz=466, num_updates=11800, lr=0.000130189, gnorm=0.413, clip=0, loss_scale=8, train_wall=78, gb_free=17.8, wall=9601
2023-08-08 16:23:55 | INFO | train_inner | epoch 009:    116 / 1474 loss=2.087, trans_loss=3.486, nll_loss=1.64, w2v_ctc_loss=1.063, task_loss=0, contrastive_loss=0.122, total=4191.82, n_correct=2535.21, ppl=3.12, accuracy=60.48, wps=15975.7, ups=1.28, wpb=12518.2, bsz=479.9, num_updates=11900, lr=0.000129641, gnorm=0.404, clip=0, loss_scale=8, train_wall=78, gb_free=16.1, wall=9679
2023-08-08 16:25:14 | INFO | train_inner | epoch 009:    216 / 1474 loss=2.074, trans_loss=3.493, nll_loss=1.649, w2v_ctc_loss=1.065, task_loss=0, contrastive_loss=0.084, total=4061.27, n_correct=2445.68, ppl=3.14, accuracy=60.22, wps=15441.8, ups=1.27, wpb=12126.5, bsz=431.4, num_updates=12000, lr=0.000129099, gnorm=0.407, clip=0, loss_scale=8, train_wall=78, gb_free=17.7, wall=9758
2023-08-08 16:25:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 16:25:35 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.444 | trans_loss 5.66 | nll_loss 2.961 | w2v_ctc_loss 1.379 | task_loss 0 | contrastive_loss 0.247 | total 4003.4 | n_correct 2414.5 | ppl 7.79 | accuracy 60.311 | uer 18.785 | wer 20.7 | raw_wer 20.7 | bleu 18.82 | wps 2446.1 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 19
2023-08-08 16:25:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-08-08 16:25:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_9_12000.pt
2023-08-08 16:25:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_9_12000.pt
2023-08-08 16:26:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.82) (writing took 29.660855883732438 seconds)
2023-08-08 16:27:24 | INFO | train_inner | epoch 009:    316 / 1474 loss=2.082, trans_loss=3.482, nll_loss=1.637, w2v_ctc_loss=1.054, task_loss=0, contrastive_loss=0.131, total=4146.43, n_correct=2513.87, ppl=3.11, accuracy=60.627, wps=9522.5, ups=0.77, wpb=12389.9, bsz=474.6, num_updates=12100, lr=0.000128565, gnorm=0.409, clip=0, loss_scale=8, train_wall=77, gb_free=16.4, wall=9888
2023-08-08 16:28:43 | INFO | train_inner | epoch 009:    416 / 1474 loss=2.079, trans_loss=3.498, nll_loss=1.655, w2v_ctc_loss=1.063, task_loss=0, contrastive_loss=0.097, total=4194.84, n_correct=2521.6, ppl=3.15, accuracy=60.112, wps=15866.4, ups=1.27, wpb=12524.6, bsz=466.7, num_updates=12200, lr=0.000128037, gnorm=0.403, clip=0, loss_scale=8, train_wall=78, gb_free=16.3, wall=9967
2023-08-08 16:30:01 | INFO | train_inner | epoch 009:    516 / 1474 loss=2.115, trans_loss=3.505, nll_loss=1.663, w2v_ctc_loss=1.088, task_loss=0, contrastive_loss=0.149, total=4124.3, n_correct=2470.97, ppl=3.17, accuracy=59.912, wps=15654.2, ups=1.27, wpb=12310.3, bsz=439.5, num_updates=12300, lr=0.000127515, gnorm=0.407, clip=0, loss_scale=8, train_wall=78, gb_free=12, wall=10045
2023-08-08 16:31:20 | INFO | train_inner | epoch 009:    616 / 1474 loss=2.078, trans_loss=3.493, nll_loss=1.652, w2v_ctc_loss=1.061, task_loss=0, contrastive_loss=0.11, total=4120.96, n_correct=2479.04, ppl=3.14, accuracy=60.157, wps=15666.4, ups=1.27, wpb=12316.4, bsz=453.4, num_updates=12400, lr=0.000127, gnorm=0.409, clip=0, loss_scale=8, train_wall=78, gb_free=16.3, wall=10124
2023-08-08 16:32:37 | INFO | train_inner | epoch 009:    716 / 1474 loss=2.122, trans_loss=3.504, nll_loss=1.666, w2v_ctc_loss=1.082, task_loss=0, contrastive_loss=0.191, total=4088.53, n_correct=2451.08, ppl=3.17, accuracy=59.95, wps=15762, ups=1.29, wpb=12213.7, bsz=451.4, num_updates=12500, lr=0.000126491, gnorm=0.416, clip=0, loss_scale=8, train_wall=77, gb_free=17.2, wall=10202
2023-08-08 16:33:56 | INFO | train_inner | epoch 009:    816 / 1474 loss=2.179, trans_loss=3.499, nll_loss=1.662, w2v_ctc_loss=1.078, task_loss=0, contrastive_loss=0.335, total=4220.43, n_correct=2532.31, ppl=3.16, accuracy=60.001, wps=16001.2, ups=1.27, wpb=12611.1, bsz=501.1, num_updates=12600, lr=0.000125988, gnorm=0.423, clip=0, loss_scale=8, train_wall=78, gb_free=14.6, wall=10280
2023-08-08 16:35:16 | INFO | train_inner | epoch 009:    916 / 1474 loss=2.14, trans_loss=3.504, nll_loss=1.662, w2v_ctc_loss=1.072, task_loss=0, contrastive_loss=0.316, total=4146.05, n_correct=2487.63, ppl=3.16, accuracy=60, wps=15523.8, ups=1.25, wpb=12371.5, bsz=450.3, num_updates=12700, lr=0.000125491, gnorm=0.407, clip=0, loss_scale=8, train_wall=79, gb_free=17.9, wall=10360
2023-08-08 16:36:34 | INFO | train_inner | epoch 009:   1016 / 1474 loss=2.089, trans_loss=3.512, nll_loss=1.673, w2v_ctc_loss=1.077, task_loss=0, contrastive_loss=0.098, total=4101.48, n_correct=2452.28, ppl=3.19, accuracy=59.79, wps=15620.1, ups=1.28, wpb=12241.7, bsz=424.4, num_updates=12800, lr=0.000125, gnorm=0.406, clip=0, loss_scale=8, train_wall=78, gb_free=16.1, wall=10438
2023-08-08 16:37:52 | INFO | train_inner | epoch 009:   1116 / 1474 loss=2.096, trans_loss=3.509, nll_loss=1.666, w2v_ctc_loss=1.071, task_loss=0, contrastive_loss=0.12, total=4179.09, n_correct=2513.91, ppl=3.17, accuracy=60.154, wps=15953.5, ups=1.28, wpb=12457.7, bsz=474.7, num_updates=12900, lr=0.000124515, gnorm=0.408, clip=0, loss_scale=8, train_wall=78, gb_free=15.5, wall=10517
2023-08-08 16:39:11 | INFO | train_inner | epoch 009:   1216 / 1474 loss=2.097, trans_loss=3.508, nll_loss=1.67, w2v_ctc_loss=1.083, task_loss=0, contrastive_loss=0.104, total=4140.66, n_correct=2480.83, ppl=3.18, accuracy=59.914, wps=15704.6, ups=1.27, wpb=12363.4, bsz=448.1, num_updates=13000, lr=0.000124035, gnorm=0.41, clip=0, loss_scale=8, train_wall=78, gb_free=17.2, wall=10595
2023-08-08 16:40:30 | INFO | train_inner | epoch 009:   1316 / 1474 loss=2.145, trans_loss=3.502, nll_loss=1.662, w2v_ctc_loss=1.063, task_loss=0, contrastive_loss=0.294, total=4204.43, n_correct=2530.26, ppl=3.17, accuracy=60.181, wps=15958.8, ups=1.27, wpb=12544.9, bsz=492.5, num_updates=13100, lr=0.00012356, gnorm=0.407, clip=0, loss_scale=8, train_wall=78, gb_free=17.8, wall=10674
2023-08-08 16:41:48 | INFO | train_inner | epoch 009:   1416 / 1474 loss=2.087, trans_loss=3.517, nll_loss=1.681, w2v_ctc_loss=1.077, task_loss=0, contrastive_loss=0.083, total=4069.19, n_correct=2433.81, ppl=3.21, accuracy=59.811, wps=15563.9, ups=1.28, wpb=12143.2, bsz=427.7, num_updates=13200, lr=0.000123091, gnorm=0.407, clip=0, loss_scale=16, train_wall=78, gb_free=16.7, wall=10752
2023-08-08 16:42:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 16:42:55 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.416 | trans_loss 5.632 | nll_loss 2.929 | w2v_ctc_loss 1.346 | task_loss 0 | contrastive_loss 0.256 | total 4003.4 | n_correct 2431.4 | ppl 7.62 | accuracy 60.733 | uer 18.477 | wer 20.406 | raw_wer 20.406 | bleu 19.01 | wps 2293.7 | wpb 4003.4 | bsz 141.8 | num_updates 13258 | best_bleu 19.01
2023-08-08 16:42:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13258 updates
2023-08-08 16:42:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 16:43:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 16:43:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt (epoch 9 @ 13258 updates, score 19.01) (writing took 25.37322752736509 seconds)
2023-08-08 16:43:21 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-08 16:43:21 | INFO | train | epoch 009 | loss 2.106 | trans_loss 3.501 | nll_loss 1.66 | w2v_ctc_loss 1.071 | task_loss 0 | contrastive_loss 0.165 | total 4138.65 | n_correct 2487.17 | ppl 3.16 | accuracy 60.096 | wps 14404.5 | ups 1.17 | wpb 12355.8 | bsz 458.5 | num_updates 13258 | lr 0.000122822 | gnorm 0.409 | clip 0 | loss_scale 16 | train_wall 1148 | gb_free 12 | wall 10845
2023-08-08 16:43:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 16:43:21 | INFO | fairseq.trainer | begin training epoch 10
2023-08-08 16:43:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 16:44:01 | INFO | train_inner | epoch 010:     42 / 1474 loss=2.096, trans_loss=3.494, nll_loss=1.651, w2v_ctc_loss=1.05, task_loss=0, contrastive_loss=0.178, total=4100.8, n_correct=2481.12, ppl=3.14, accuracy=60.503, wps=9179.7, ups=0.75, wpb=12238.2, bsz=469.4, num_updates=13300, lr=0.000122628, gnorm=0.41, clip=0, loss_scale=16, train_wall=77, gb_free=16.4, wall=10885
2023-08-08 16:45:20 | INFO | train_inner | epoch 010:    142 / 1474 loss=2.036, trans_loss=3.467, nll_loss=1.616, w2v_ctc_loss=1.021, task_loss=0, contrastive_loss=0.101, total=4247.35, n_correct=2599.42, ppl=3.07, accuracy=61.201, wps=16069.7, ups=1.27, wpb=12684.5, bsz=479.6, num_updates=13400, lr=0.000122169, gnorm=0.398, clip=0, loss_scale=16, train_wall=78, gb_free=12.1, wall=10964
2023-08-08 16:46:39 | INFO | train_inner | epoch 010:    242 / 1474 loss=2.08, trans_loss=3.47, nll_loss=1.619, w2v_ctc_loss=1.034, task_loss=0, contrastive_loss=0.225, total=4122.82, n_correct=2521.58, ppl=3.07, accuracy=61.162, wps=15675.2, ups=1.27, wpb=12303.3, bsz=461.4, num_updates=13500, lr=0.000121716, gnorm=0.404, clip=0, loss_scale=16, train_wall=78, gb_free=16.5, wall=11043
2023-08-08 16:47:57 | INFO | train_inner | epoch 010:    342 / 1474 loss=2.05, trans_loss=3.469, nll_loss=1.623, w2v_ctc_loss=1.027, task_loss=0, contrastive_loss=0.138, total=4138.27, n_correct=2519.71, ppl=3.08, accuracy=60.888, wps=15796.8, ups=1.28, wpb=12371, bsz=453.8, num_updates=13600, lr=0.000121268, gnorm=0.405, clip=0, loss_scale=16, train_wall=78, gb_free=16.6, wall=11121
2023-08-08 16:49:16 | INFO | train_inner | epoch 010:    442 / 1474 loss=2.092, trans_loss=3.475, nll_loss=1.627, w2v_ctc_loss=1.018, task_loss=0, contrastive_loss=0.309, total=4196.37, n_correct=2558.9, ppl=3.09, accuracy=60.979, wps=15841.7, ups=1.26, wpb=12528, bsz=481.1, num_updates=13700, lr=0.000120824, gnorm=0.403, clip=0, loss_scale=16, train_wall=79, gb_free=16.2, wall=11200
2023-08-08 16:50:35 | INFO | train_inner | epoch 010:    542 / 1474 loss=2.057, trans_loss=3.487, nll_loss=1.639, w2v_ctc_loss=1.049, task_loss=0, contrastive_loss=0.09, total=4102.8, n_correct=2489.24, ppl=3.11, accuracy=60.672, wps=15550.4, ups=1.27, wpb=12234.1, bsz=437.8, num_updates=13800, lr=0.000120386, gnorm=0.405, clip=0, loss_scale=16, train_wall=78, gb_free=17.2, wall=11279
2023-08-08 16:51:54 | INFO | train_inner | epoch 010:    642 / 1474 loss=2.092, trans_loss=3.485, nll_loss=1.639, w2v_ctc_loss=1.043, task_loss=0, contrastive_loss=0.205, total=4176.56, n_correct=2538.92, ppl=3.12, accuracy=60.79, wps=15780.1, ups=1.27, wpb=12464, bsz=477.2, num_updates=13900, lr=0.000119952, gnorm=0.407, clip=0, loss_scale=16, train_wall=78, gb_free=16.4, wall=11358
2023-08-08 16:53:11 | INFO | train_inner | epoch 010:    742 / 1474 loss=2.065, trans_loss=3.486, nll_loss=1.641, w2v_ctc_loss=1.059, task_loss=0, contrastive_loss=0.089, total=4125.87, n_correct=2503.67, ppl=3.12, accuracy=60.682, wps=15867.4, ups=1.29, wpb=12315.3, bsz=454.4, num_updates=14000, lr=0.000119523, gnorm=0.411, clip=0, loss_scale=16, train_wall=77, gb_free=14.8, wall=11435
2023-08-08 16:53:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 16:53:34 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.422 | trans_loss 5.631 | nll_loss 2.922 | w2v_ctc_loss 1.367 | task_loss 0 | contrastive_loss 0.259 | total 4003.4 | n_correct 2441.1 | ppl 7.58 | accuracy 60.976 | uer 18.799 | wer 20.484 | raw_wer 20.484 | bleu 19.29 | wps 2303.3 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 19.29
2023-08-08 16:53:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-08-08 16:53:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_10_14000.pt
2023-08-08 16:53:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_10_14000.pt
2023-08-08 16:54:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 19.29) (writing took 40.57735710591078 seconds)
2023-08-08 16:55:34 | INFO | train_inner | epoch 010:    842 / 1474 loss=2.045, trans_loss=3.48, nll_loss=1.635, w2v_ctc_loss=1.033, task_loss=0, contrastive_loss=0.092, total=4128.44, n_correct=2513.92, ppl=3.1, accuracy=60.893, wps=8666.5, ups=0.7, wpb=12327.8, bsz=456.3, num_updates=14100, lr=0.000119098, gnorm=0.404, clip=0, loss_scale=16, train_wall=78, gb_free=14.9, wall=11578
2023-08-08 16:56:52 | INFO | train_inner | epoch 010:    942 / 1474 loss=2.063, trans_loss=3.481, nll_loss=1.633, w2v_ctc_loss=1.037, task_loss=0, contrastive_loss=0.129, total=4160.94, n_correct=2537.36, ppl=3.1, accuracy=60.98, wps=15888.7, ups=1.28, wpb=12411.1, bsz=468.1, num_updates=14200, lr=0.000118678, gnorm=0.407, clip=0, loss_scale=16, train_wall=78, gb_free=15.7, wall=11656
2023-08-08 16:58:10 | INFO | train_inner | epoch 010:   1042 / 1474 loss=2.054, trans_loss=3.485, nll_loss=1.641, w2v_ctc_loss=1.041, task_loss=0, contrastive_loss=0.103, total=4067.53, n_correct=2462.25, ppl=3.12, accuracy=60.534, wps=15502.8, ups=1.28, wpb=12145, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.412, clip=0, loss_scale=16, train_wall=78, gb_free=17, wall=11734
2023-08-08 16:59:28 | INFO | train_inner | epoch 010:   1142 / 1474 loss=2.06, trans_loss=3.493, nll_loss=1.65, w2v_ctc_loss=1.055, task_loss=0, contrastive_loss=0.087, total=4044.03, n_correct=2443.55, ppl=3.14, accuracy=60.424, wps=15546.4, ups=1.29, wpb=12074.4, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.407, clip=0, loss_scale=16, train_wall=77, gb_free=17.4, wall=11812
2023-08-08 17:00:46 | INFO | train_inner | epoch 010:   1242 / 1474 loss=2.053, trans_loss=3.481, nll_loss=1.64, w2v_ctc_loss=1.05, task_loss=0, contrastive_loss=0.083, total=4110.41, n_correct=2495.16, ppl=3.12, accuracy=60.703, wps=15769.3, ups=1.28, wpb=12291.6, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.407, clip=0, loss_scale=16, train_wall=77, gb_free=16.6, wall=11890
2023-08-08 17:02:04 | INFO | train_inner | epoch 010:   1342 / 1474 loss=2.055, trans_loss=3.49, nll_loss=1.649, w2v_ctc_loss=1.044, task_loss=0, contrastive_loss=0.094, total=4121.38, n_correct=2499.51, ppl=3.14, accuracy=60.647, wps=15625.3, ups=1.27, wpb=12308.4, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.407, clip=0, loss_scale=16, train_wall=78, gb_free=14.3, wall=11968
2023-08-08 17:03:24 | INFO | train_inner | epoch 010:   1442 / 1474 loss=2.134, trans_loss=3.493, nll_loss=1.65, w2v_ctc_loss=1.028, task_loss=0, contrastive_loss=0.338, total=4192.39, n_correct=2541.22, ppl=3.14, accuracy=60.615, wps=15753.8, ups=1.26, wpb=12506.1, bsz=482, num_updates=14700, lr=0.000116642, gnorm=0.418, clip=0, loss_scale=16, train_wall=79, gb_free=17.2, wall=12048
2023-08-08 17:03:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 17:04:10 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.415 | trans_loss 5.612 | nll_loss 2.899 | w2v_ctc_loss 1.397 | task_loss 0 | contrastive_loss 0.253 | total 4003.4 | n_correct 2445.8 | ppl 7.46 | accuracy 61.093 | uer 18.146 | wer 19.94 | raw_wer 19.94 | bleu 19.5 | wps 2379.3 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 19.5
2023-08-08 17:04:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-08-08 17:04:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 17:04:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 17:04:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt (epoch 10 @ 14732 updates, score 19.5) (writing took 28.40623457171023 seconds)
2023-08-08 17:04:39 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-08 17:04:39 | INFO | train | epoch 010 | loss 2.068 | trans_loss 3.481 | nll_loss 1.635 | w2v_ctc_loss 1.037 | task_loss 0 | contrastive_loss 0.159 | total 4138.65 | n_correct 2516.77 | ppl 3.11 | accuracy 60.812 | wps 14241.1 | ups 1.15 | wpb 12355.8 | bsz 458.5 | num_updates 14732 | lr 0.000116516 | gnorm 0.407 | clip 0 | loss_scale 16 | train_wall 1149 | gb_free 17.4 | wall 12124
2023-08-08 17:04:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 17:04:40 | INFO | fairseq.trainer | begin training epoch 11
2023-08-08 17:04:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 17:05:39 | INFO | train_inner | epoch 011:     68 / 1474 loss=2.038, trans_loss=3.457, nll_loss=1.603, w2v_ctc_loss=1.009, task_loss=0, contrastive_loss=0.167, total=4175.24, n_correct=2572.09, ppl=3.04, accuracy=61.603, wps=9185.6, ups=0.74, wpb=12463.5, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.402, clip=0, loss_scale=16, train_wall=77, gb_free=17, wall=12184
2023-08-08 17:06:58 | INFO | train_inner | epoch 011:    168 / 1474 loss=2.014, trans_loss=3.457, nll_loss=1.606, w2v_ctc_loss=1.011, task_loss=0, contrastive_loss=0.088, total=4087.78, n_correct=2511.89, ppl=3.04, accuracy=61.449, wps=15610.2, ups=1.28, wpb=12214.2, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.405, clip=0, loss_scale=16, train_wall=78, gb_free=16.7, wall=12262
2023-08-08 17:08:16 | INFO | train_inner | epoch 011:    268 / 1474 loss=2.007, trans_loss=3.457, nll_loss=1.605, w2v_ctc_loss=1.004, task_loss=0, contrastive_loss=0.085, total=4118.77, n_correct=2536.88, ppl=3.04, accuracy=61.593, wps=15707.1, ups=1.28, wpb=12299.1, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.402, clip=0, loss_scale=16, train_wall=78, gb_free=12.7, wall=12340
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:0')
2023-08-08 17:09:12 | INFO | train_inner | epoch 011:    368 / 1474 loss=2.176, trans_loss=5.138, nll_loss=2.389, w2v_ctc_loss=0.76, task_loss=0, contrastive_loss=0.068, total=4097.83, n_correct=2516.74, ppl=5.24, accuracy=61.416, wps=14816.9, ups=1.8, wpb=8240.8, bsz=298, num_updates=15100, lr=0.000115087, gnorm=0.539, clip=0, loss_scale=16, train_wall=55, gb_free=15.8, wall=12396
2023-08-08 17:10:07 | INFO | train_inner | epoch 011:    468 / 1474 loss=2.203, trans_loss=5.177, nll_loss=2.415, w2v_ctc_loss=0.758, task_loss=0, contrastive_loss=0.183, total=4110.64, n_correct=2518.78, ppl=5.33, accuracy=61.275, wps=14804.3, ups=1.8, wpb=8221.3, bsz=300.4, num_updates=15200, lr=0.000114708, gnorm=0.544, clip=0, loss_scale=16, train_wall=55, gb_free=16.6, wall=12451
2023-08-08 17:11:03 | INFO | train_inner | epoch 011:    568 / 1474 loss=2.202, trans_loss=5.175, nll_loss=2.414, w2v_ctc_loss=0.768, task_loss=0, contrastive_loss=0.181, total=4071.69, n_correct=2490.54, ppl=5.33, accuracy=61.167, wps=14585.4, ups=1.79, wpb=8143.4, bsz=293.7, num_updates=15300, lr=0.000114332, gnorm=0.548, clip=0, loss_scale=32, train_wall=55, gb_free=16.2, wall=12507
2023-08-08 17:11:59 | INFO | train_inner | epoch 011:    668 / 1474 loss=2.213, trans_loss=5.178, nll_loss=2.418, w2v_ctc_loss=0.766, task_loss=0, contrastive_loss=0.237, total=4157.2, n_correct=2539.27, ppl=5.34, accuracy=61.081, wps=14809.6, ups=1.78, wpb=8314.4, bsz=309.6, num_updates=15400, lr=0.000113961, gnorm=0.535, clip=0, loss_scale=32, train_wall=56, gb_free=17, wall=12563
2023-08-08 17:12:55 | INFO | train_inner | epoch 011:    768 / 1474 loss=2.195, trans_loss=5.186, nll_loss=2.43, w2v_ctc_loss=0.778, task_loss=0, contrastive_loss=0.066, total=4174.91, n_correct=2554.54, ppl=5.39, accuracy=61.188, wps=14873.4, ups=1.78, wpb=8349.8, bsz=306.9, num_updates=15500, lr=0.000113592, gnorm=0.54, clip=0, loss_scale=32, train_wall=56, gb_free=17.3, wall=12619
2023-08-08 17:13:51 | INFO | train_inner | epoch 011:    868 / 1474 loss=2.191, trans_loss=5.188, nll_loss=2.432, w2v_ctc_loss=0.771, task_loss=0, contrastive_loss=0.057, total=4118.44, n_correct=2512.98, ppl=5.4, accuracy=61.018, wps=14893.1, ups=1.81, wpb=8236.9, bsz=293.7, num_updates=15600, lr=0.000113228, gnorm=0.543, clip=0, loss_scale=32, train_wall=55, gb_free=11.4, wall=12675
2023-08-08 17:14:46 | INFO | train_inner | epoch 011:    968 / 1474 loss=2.192, trans_loss=5.185, nll_loss=2.429, w2v_ctc_loss=0.775, task_loss=0, contrastive_loss=0.068, total=4140.92, n_correct=2531.65, ppl=5.39, accuracy=61.137, wps=14901.9, ups=1.8, wpb=8281.8, bsz=301.9, num_updates=15700, lr=0.000112867, gnorm=0.54, clip=0, loss_scale=32, train_wall=55, gb_free=15.9, wall=12730
2023-08-08 17:15:42 | INFO | train_inner | epoch 011:   1068 / 1474 loss=2.193, trans_loss=5.18, nll_loss=2.423, w2v_ctc_loss=0.775, task_loss=0, contrastive_loss=0.085, total=4136.99, n_correct=2536.83, ppl=5.36, accuracy=61.321, wps=14842.4, ups=1.79, wpb=8274, bsz=308.8, num_updates=15800, lr=0.000112509, gnorm=0.545, clip=0, loss_scale=32, train_wall=55, gb_free=17.9, wall=12786
2023-08-08 17:16:38 | INFO | train_inner | epoch 011:   1168 / 1474 loss=2.194, trans_loss=5.187, nll_loss=2.432, w2v_ctc_loss=0.774, task_loss=0, contrastive_loss=0.073, total=4185.65, n_correct=2556.44, ppl=5.4, accuracy=61.076, wps=14958.8, ups=1.79, wpb=8371.3, bsz=309.8, num_updates=15900, lr=0.000112154, gnorm=0.536, clip=0, loss_scale=32, train_wall=55, gb_free=14.4, wall=12842
2023-08-08 17:17:34 | INFO | train_inner | epoch 011:   1268 / 1474 loss=2.204, trans_loss=5.182, nll_loss=2.426, w2v_ctc_loss=0.776, task_loss=0, contrastive_loss=0.137, total=4171.89, n_correct=2551.32, ppl=5.37, accuracy=61.155, wps=14967.3, ups=1.79, wpb=8343.8, bsz=314.1, num_updates=16000, lr=0.000111803, gnorm=0.55, clip=0, loss_scale=32, train_wall=55, gb_free=16.2, wall=12898
2023-08-08 17:17:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:4')
2023-08-08 17:17:56 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.408 | trans_loss 5.609 | nll_loss 2.899 | w2v_ctc_loss 1.376 | task_loss 0 | contrastive_loss 0.253 | total 4003.4 | n_correct 2448.1 | ppl 7.46 | accuracy 61.151 | uer 18.037 | wer 19.865 | raw_wer 19.865 | bleu 18.92 | wps 2395.2 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.5
2023-08-08 17:17:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-08-08 17:17:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_11_16000.pt
2023-08-08 17:18:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_11_16000.pt
2023-08-08 17:18:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 18.92) (writing took 38.15926508978009 seconds)
2023-08-08 17:19:31 | INFO | train_inner | epoch 011:   1368 / 1474 loss=2.223, trans_loss=5.183, nll_loss=2.428, w2v_ctc_loss=0.762, task_loss=0, contrastive_loss=0.3, total=4190.34, n_correct=2562.94, ppl=5.38, accuracy=61.163, wps=7164.2, ups=0.85, wpb=8380.7, bsz=327.9, num_updates=16100, lr=0.000111456, gnorm=0.543, clip=0, loss_scale=32, train_wall=56, gb_free=17.3, wall=13015
2023-08-08 17:20:27 | INFO | train_inner | epoch 011:   1468 / 1474 loss=2.191, trans_loss=5.186, nll_loss=2.432, w2v_ctc_loss=0.769, task_loss=0, contrastive_loss=0.076, total=4158.39, n_correct=2541.37, ppl=5.39, accuracy=61.114, wps=14854.6, ups=1.79, wpb=8316.8, bsz=312, num_updates=16200, lr=0.000111111, gnorm=0.541, clip=0, loss_scale=32, train_wall=55, gb_free=17.1, wall=13071
2023-08-08 17:20:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 17:20:53 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.403 | trans_loss 5.599 | nll_loss 2.888 | w2v_ctc_loss 1.383 | task_loss 0 | contrastive_loss 0.25 | total 4003.4 | n_correct 2450.1 | ppl 7.4 | accuracy 61.2 | uer 18.233 | wer 19.884 | raw_wer 19.884 | bleu 19.27 | wps 2246 | wpb 4003.4 | bsz 141.8 | num_updates 16206 | best_bleu 19.5
2023-08-08 17:20:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16206 updates
2023-08-08 17:20:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.2705.pt
2023-08-08 17:20:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.2705.pt
2023-08-08 17:21:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.2705.pt (epoch 11 @ 16206 updates, score 19.27) (writing took 19.111434936523438 seconds)
2023-08-08 17:21:12 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-08 17:21:12 | INFO | train | epoch 011 | loss 2.152 | trans_loss 4.75 | nll_loss 2.218 | w2v_ctc_loss 0.829 | task_loss 0 | contrastive_loss 0.118 | total 4138.65 | n_correct 2535.07 | ppl 4.65 | accuracy 61.253 | wps 13396.8 | ups 1.48 | wpb 9021 | bsz 333.4 | num_updates 16206 | lr 0.000111091 | gnorm 0.517 | clip 0 | loss_scale 32 | train_wall 875 | gb_free 17.5 | wall 13116
2023-08-08 17:21:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 17:21:12 | INFO | fairseq.trainer | begin training epoch 12
2023-08-08 17:21:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 17:22:12 | INFO | train_inner | epoch 012:     94 / 1474 loss=2.167, trans_loss=5.127, nll_loss=2.353, w2v_ctc_loss=0.749, task_loss=0, contrastive_loss=0.108, total=4146.82, n_correct=2582.65, ppl=5.11, accuracy=62.28, wps=7850.3, ups=0.95, wpb=8293.6, bsz=313.9, num_updates=16300, lr=0.00011077, gnorm=0.53, clip=0, loss_scale=32, train_wall=55, gb_free=16, wall=13176
2023-08-08 17:23:08 | INFO | train_inner | epoch 012:    194 / 1474 loss=2.166, trans_loss=5.138, nll_loss=2.367, w2v_ctc_loss=0.759, task_loss=0, contrastive_loss=0.06, total=4120.68, n_correct=2551.91, ppl=5.16, accuracy=61.929, wps=14843.7, ups=1.8, wpb=8241.4, bsz=294.7, num_updates=16400, lr=0.000110432, gnorm=0.537, clip=0, loss_scale=32, train_wall=55, gb_free=15.9, wall=13232
2023-08-08 17:24:04 | INFO | train_inner | epoch 012:    294 / 1474 loss=2.166, trans_loss=5.137, nll_loss=2.366, w2v_ctc_loss=0.746, task_loss=0, contrastive_loss=0.087, total=4199.46, n_correct=2603.48, ppl=5.16, accuracy=61.996, wps=15072.6, ups=1.79, wpb=8398.9, bsz=320.3, num_updates=16500, lr=0.000110096, gnorm=0.538, clip=0, loss_scale=32, train_wall=55, gb_free=16.8, wall=13288
2023-08-08 17:25:00 | INFO | train_inner | epoch 012:    394 / 1474 loss=2.169, trans_loss=5.146, nll_loss=2.379, w2v_ctc_loss=0.755, task_loss=0, contrastive_loss=0.073, total=4151.14, n_correct=2568.41, ppl=5.2, accuracy=61.872, wps=14739.9, ups=1.78, wpb=8302.3, bsz=307.8, num_updates=16600, lr=0.000109764, gnorm=0.542, clip=0, loss_scale=32, train_wall=56, gb_free=17.4, wall=13344
2023-08-08 17:25:56 | INFO | train_inner | epoch 012:    494 / 1474 loss=2.18, trans_loss=5.16, nll_loss=2.397, w2v_ctc_loss=0.766, task_loss=0, contrastive_loss=0.08, total=4110.49, n_correct=2536.06, ppl=5.27, accuracy=61.697, wps=14752.2, ups=1.79, wpb=8221, bsz=302.2, num_updates=16700, lr=0.000109435, gnorm=0.539, clip=0, loss_scale=32, train_wall=55, gb_free=14.3, wall=13400
2023-08-08 17:26:52 | INFO | train_inner | epoch 012:    594 / 1474 loss=2.181, trans_loss=5.149, nll_loss=2.383, w2v_ctc_loss=0.757, task_loss=0, contrastive_loss=0.144, total=4189.92, n_correct=2593.16, ppl=5.22, accuracy=61.89, wps=14957.2, ups=1.78, wpb=8379.8, bsz=315.1, num_updates=16800, lr=0.000109109, gnorm=0.542, clip=0, loss_scale=32, train_wall=56, gb_free=15.2, wall=13456
2023-08-08 17:27:47 | INFO | train_inner | epoch 012:    694 / 1474 loss=2.184, trans_loss=5.147, nll_loss=2.381, w2v_ctc_loss=0.739, task_loss=0, contrastive_loss=0.233, total=4206.3, n_correct=2610.68, ppl=5.21, accuracy=62.066, wps=15230.4, ups=1.81, wpb=8412.6, bsz=325.7, num_updates=16900, lr=0.000108786, gnorm=0.533, clip=0, loss_scale=32, train_wall=55, gb_free=16.5, wall=13511
2023-08-08 17:28:43 | INFO | train_inner | epoch 012:    794 / 1474 loss=2.171, trans_loss=5.15, nll_loss=2.384, w2v_ctc_loss=0.759, task_loss=0, contrastive_loss=0.07, total=4085.96, n_correct=2524.37, ppl=5.22, accuracy=61.782, wps=14606.8, ups=1.79, wpb=8171.9, bsz=297.1, num_updates=17000, lr=0.000108465, gnorm=0.549, clip=0, loss_scale=32, train_wall=55, gb_free=16.3, wall=13567
2023-08-08 17:29:39 | INFO | train_inner | epoch 012:    894 / 1474 loss=2.18, trans_loss=5.154, nll_loss=2.389, w2v_ctc_loss=0.754, task_loss=0, contrastive_loss=0.12, total=4169.74, n_correct=2575.09, ppl=5.24, accuracy=61.757, wps=14873.6, ups=1.78, wpb=8339.5, bsz=306.4, num_updates=17100, lr=0.000108148, gnorm=0.542, clip=0, loss_scale=32, train_wall=56, gb_free=16.3, wall=13623
2023-08-08 17:30:34 | INFO | train_inner | epoch 012:    994 / 1474 loss=2.185, trans_loss=5.165, nll_loss=2.404, w2v_ctc_loss=0.762, task_loss=0, contrastive_loss=0.131, total=4117.67, n_correct=2534.82, ppl=5.29, accuracy=61.56, wps=14846.3, ups=1.8, wpb=8235.3, bsz=301.4, num_updates=17200, lr=0.000107833, gnorm=0.547, clip=0, loss_scale=32, train_wall=55, gb_free=17.9, wall=13678
2023-08-08 17:31:30 | INFO | train_inner | epoch 012:   1094 / 1474 loss=2.197, trans_loss=5.171, nll_loss=2.412, w2v_ctc_loss=0.766, task_loss=0, contrastive_loss=0.176, total=4047.61, n_correct=2486.89, ppl=5.32, accuracy=61.441, wps=14585.8, ups=1.8, wpb=8095.2, bsz=290.4, num_updates=17300, lr=0.000107521, gnorm=0.553, clip=0, loss_scale=64, train_wall=55, gb_free=16.8, wall=13734
2023-08-08 17:32:26 | INFO | train_inner | epoch 012:   1194 / 1474 loss=2.197, trans_loss=5.177, nll_loss=2.421, w2v_ctc_loss=0.772, task_loss=0, contrastive_loss=0.129, total=4184.55, n_correct=2567.69, ppl=5.36, accuracy=61.361, wps=14896.6, ups=1.78, wpb=8369.1, bsz=314.3, num_updates=17400, lr=0.000107211, gnorm=0.538, clip=0, loss_scale=64, train_wall=56, gb_free=16.9, wall=13790
2023-08-08 17:33:22 | INFO | train_inner | epoch 012:   1294 / 1474 loss=2.188, trans_loss=5.171, nll_loss=2.412, w2v_ctc_loss=0.779, task_loss=0, contrastive_loss=0.076, total=4086.33, n_correct=2510.27, ppl=5.32, accuracy=61.431, wps=14682.5, ups=1.8, wpb=8172.7, bsz=291.4, num_updates=17500, lr=0.000106904, gnorm=0.545, clip=0, loss_scale=64, train_wall=55, gb_free=16.9, wall=13846
2023-08-08 17:34:17 | INFO | train_inner | epoch 012:   1394 / 1474 loss=2.189, trans_loss=5.171, nll_loss=2.413, w2v_ctc_loss=0.754, task_loss=0, contrastive_loss=0.16, total=4134.89, n_correct=2540.31, ppl=5.32, accuracy=61.436, wps=14916.8, ups=1.8, wpb=8269.8, bsz=304.4, num_updates=17600, lr=0.0001066, gnorm=0.549, clip=0, loss_scale=64, train_wall=55, gb_free=17.5, wall=13901
2023-08-08 17:35:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 17:35:24 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.407 | trans_loss 5.596 | nll_loss 2.883 | w2v_ctc_loss 1.406 | task_loss 0 | contrastive_loss 0.251 | total 4003.4 | n_correct 2457.3 | ppl 7.37 | accuracy 61.38 | uer 18.464 | wer 20.174 | raw_wer 20.174 | bleu 19.74 | wps 2209.7 | wpb 4003.4 | bsz 141.8 | num_updates 17680 | best_bleu 19.74
2023-08-08 17:35:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17680 updates
2023-08-08 17:35:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 17:35:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 17:35:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt (epoch 12 @ 17680 updates, score 19.74) (writing took 24.021622963249683 seconds)
2023-08-08 17:35:49 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-08 17:35:49 | INFO | train | epoch 012 | loss 2.18 | trans_loss 5.155 | nll_loss 2.391 | w2v_ctc_loss 0.758 | task_loss 0 | contrastive_loss 0.116 | total 4138.65 | n_correct 2555.35 | ppl 5.25 | accuracy 61.744 | wps 13913.5 | ups 1.68 | wpb 8277.3 | bsz 305.7 | num_updates 17680 | lr 0.000106359 | gnorm 0.542 | clip 0 | loss_scale 64 | train_wall 815 | gb_free 13.3 | wall 13993
2023-08-08 17:35:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 17:35:49 | INFO | fairseq.trainer | begin training epoch 13
2023-08-08 17:35:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 17:36:08 | INFO | train_inner | epoch 013:     20 / 1474 loss=2.179, trans_loss=5.168, nll_loss=2.409, w2v_ctc_loss=0.766, task_loss=0, contrastive_loss=0.067, total=4104.86, n_correct=2529.16, ppl=5.31, accuracy=61.614, wps=7418.3, ups=0.9, wpb=8209.7, bsz=296.8, num_updates=17700, lr=0.000106299, gnorm=0.547, clip=0, loss_scale=64, train_wall=55, gb_free=15, wall=14012
2023-08-08 17:37:04 | INFO | train_inner | epoch 013:    120 / 1474 loss=2.153, trans_loss=5.119, nll_loss=2.343, w2v_ctc_loss=0.741, task_loss=0, contrastive_loss=0.077, total=4161.2, n_correct=2601.05, ppl=5.07, accuracy=62.507, wps=14883.5, ups=1.79, wpb=8322.4, bsz=302.9, num_updates=17800, lr=0.000106, gnorm=0.534, clip=0, loss_scale=64, train_wall=55, gb_free=16.5, wall=14068
2023-08-08 17:37:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-08 17:38:00 | INFO | train_inner | epoch 013:    221 / 1474 loss=2.176, trans_loss=5.126, nll_loss=2.354, w2v_ctc_loss=0.743, task_loss=0, contrastive_loss=0.231, total=4191.48, n_correct=2612.44, ppl=5.11, accuracy=62.327, wps=14828.5, ups=1.77, wpb=8383, bsz=324.2, num_updates=17900, lr=0.000105703, gnorm=0.541, clip=0, loss_scale=32, train_wall=56, gb_free=15, wall=14124
2023-08-08 17:38:56 | INFO | train_inner | epoch 013:    321 / 1474 loss=2.149, trans_loss=5.12, nll_loss=2.344, w2v_ctc_loss=0.738, task_loss=0, contrastive_loss=0.063, total=4102.3, n_correct=2564.83, ppl=5.08, accuracy=62.522, wps=14685.6, ups=1.79, wpb=8204.6, bsz=294.1, num_updates=18000, lr=0.000105409, gnorm=0.534, clip=0, loss_scale=32, train_wall=55, gb_free=17.5, wall=14180
2023-08-08 17:38:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 17:39:19 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.409 | trans_loss 5.602 | nll_loss 2.886 | w2v_ctc_loss 1.394 | task_loss 0 | contrastive_loss 0.257 | total 4003.4 | n_correct 2446 | ppl 7.39 | accuracy 61.098 | uer 18.172 | wer 19.94 | raw_wer 19.94 | bleu 19.44 | wps 2288.1 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.74
2023-08-08 17:39:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-08-08 17:39:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_13_18000.pt
2023-08-08 17:39:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_13_18000.pt
2023-08-08 17:39:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.44) (writing took 21.006860507652164 seconds)
2023-08-08 17:40:36 | INFO | train_inner | epoch 013:    421 / 1474 loss=2.164, trans_loss=5.126, nll_loss=2.354, w2v_ctc_loss=0.749, task_loss=0, contrastive_loss=0.109, total=4177.29, n_correct=2605.92, ppl=5.11, accuracy=62.383, wps=8339.7, ups=1, wpb=8354.6, bsz=318.4, num_updates=18100, lr=0.000105118, gnorm=0.541, clip=0, loss_scale=32, train_wall=55, gb_free=17.8, wall=14280
2023-08-08 17:41:32 | INFO | train_inner | epoch 013:    521 / 1474 loss=2.171, trans_loss=5.136, nll_loss=2.367, w2v_ctc_loss=0.749, task_loss=0, contrastive_loss=0.144, total=4201.22, n_correct=2610.16, ppl=5.16, accuracy=62.129, wps=15027.5, ups=1.79, wpb=8402.4, bsz=319, num_updates=18200, lr=0.000104828, gnorm=0.546, clip=0, loss_scale=32, train_wall=55, gb_free=13.4, wall=14336
2023-08-08 17:42:28 | INFO | train_inner | epoch 013:    621 / 1474 loss=2.154, trans_loss=5.131, nll_loss=2.36, w2v_ctc_loss=0.744, task_loss=0, contrastive_loss=0.061, total=4161.98, n_correct=2594.39, ppl=5.13, accuracy=62.335, wps=14967.7, ups=1.8, wpb=8324, bsz=308.3, num_updates=18300, lr=0.000104542, gnorm=0.543, clip=0, loss_scale=32, train_wall=55, gb_free=16.2, wall=14392
2023-08-08 17:43:24 | INFO | train_inner | epoch 013:    721 / 1474 loss=2.168, trans_loss=5.144, nll_loss=2.376, w2v_ctc_loss=0.768, task_loss=0, contrastive_loss=0.059, total=4096.76, n_correct=2535.95, ppl=5.19, accuracy=61.901, wps=14691.1, ups=1.79, wpb=8193.5, bsz=284.6, num_updates=18400, lr=0.000104257, gnorm=0.546, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=14448
2023-08-08 17:44:20 | INFO | train_inner | epoch 013:    821 / 1474 loss=2.171, trans_loss=5.142, nll_loss=2.375, w2v_ctc_loss=0.751, task_loss=0, contrastive_loss=0.104, total=4121.73, n_correct=2556, ppl=5.19, accuracy=62.013, wps=14667.5, ups=1.78, wpb=8243.5, bsz=306.7, num_updates=18500, lr=0.000103975, gnorm=0.554, clip=0, loss_scale=32, train_wall=56, gb_free=15.2, wall=14504
2023-08-08 17:45:15 | INFO | train_inner | epoch 013:    921 / 1474 loss=2.164, trans_loss=5.146, nll_loss=2.38, w2v_ctc_loss=0.754, task_loss=0, contrastive_loss=0.069, total=4107.01, n_correct=2550.67, ppl=5.2, accuracy=62.105, wps=14762, ups=1.8, wpb=8214, bsz=296.5, num_updates=18600, lr=0.000103695, gnorm=0.545, clip=0, loss_scale=32, train_wall=55, gb_free=16.3, wall=14560
2023-08-08 17:46:11 | INFO | train_inner | epoch 013:   1021 / 1474 loss=2.173, trans_loss=5.145, nll_loss=2.379, w2v_ctc_loss=0.756, task_loss=0, contrastive_loss=0.119, total=4081.02, n_correct=2528.33, ppl=5.2, accuracy=61.953, wps=14724.1, ups=1.8, wpb=8162, bsz=293.4, num_updates=18700, lr=0.000103418, gnorm=0.559, clip=0, loss_scale=32, train_wall=55, gb_free=16.6, wall=14615
2023-08-08 17:47:07 | INFO | train_inner | epoch 013:   1121 / 1474 loss=2.163, trans_loss=5.137, nll_loss=2.369, w2v_ctc_loss=0.745, task_loss=0, contrastive_loss=0.102, total=4105.62, n_correct=2555.14, ppl=5.17, accuracy=62.235, wps=14728.8, ups=1.79, wpb=8211.2, bsz=305.9, num_updates=18800, lr=0.000103142, gnorm=0.542, clip=0, loss_scale=32, train_wall=55, gb_free=17, wall=14671
2023-08-08 17:48:03 | INFO | train_inner | epoch 013:   1221 / 1474 loss=2.166, trans_loss=5.15, nll_loss=2.386, w2v_ctc_loss=0.758, task_loss=0, contrastive_loss=0.061, total=4110.35, n_correct=2547.84, ppl=5.23, accuracy=61.986, wps=14717.5, ups=1.79, wpb=8220.7, bsz=295.1, num_updates=18900, lr=0.000102869, gnorm=0.545, clip=0, loss_scale=32, train_wall=55, gb_free=15.2, wall=14727
2023-08-08 17:48:58 | INFO | train_inner | epoch 013:   1321 / 1474 loss=2.171, trans_loss=5.136, nll_loss=2.369, w2v_ctc_loss=0.749, task_loss=0, contrastive_loss=0.158, total=4112.2, n_correct=2560.29, ppl=5.17, accuracy=62.261, wps=14700.4, ups=1.79, wpb=8224.4, bsz=308.2, num_updates=19000, lr=0.000102598, gnorm=0.547, clip=0, loss_scale=32, train_wall=55, gb_free=17.9, wall=14783
2023-08-08 17:49:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-08 17:49:55 | INFO | train_inner | epoch 013:   1422 / 1474 loss=2.162, trans_loss=5.148, nll_loss=2.384, w2v_ctc_loss=0.749, task_loss=0, contrastive_loss=0.057, total=4156.59, n_correct=2576.56, ppl=5.22, accuracy=61.987, wps=14767.8, ups=1.78, wpb=8313.2, bsz=303.4, num_updates=19100, lr=0.000102329, gnorm=0.537, clip=0, loss_scale=16, train_wall=56, gb_free=16.4, wall=14839
2023-08-08 17:50:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 17:50:47 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.389 | trans_loss 5.588 | nll_loss 2.875 | w2v_ctc_loss 1.371 | task_loss 0 | contrastive_loss 0.241 | total 4003.4 | n_correct 2455.9 | ppl 7.33 | accuracy 61.345 | uer 18.278 | wer 19.996 | raw_wer 19.996 | bleu 19.33 | wps 2160.7 | wpb 4003.4 | bsz 141.8 | num_updates 19152 | best_bleu 19.74
2023-08-08 17:50:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19152 updates
2023-08-08 17:50:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.3301.pt
2023-08-08 17:50:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.3301.pt
2023-08-08 17:51:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.3301.pt (epoch 13 @ 19152 updates, score 19.33) (writing took 17.757426787167788 seconds)
2023-08-08 17:51:07 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-08 17:51:07 | INFO | train | epoch 013 | loss 2.164 | trans_loss 5.136 | nll_loss 2.367 | w2v_ctc_loss 0.75 | task_loss 0 | contrastive_loss 0.101 | total 4136.14 | n_correct 2572.72 | ppl 5.16 | accuracy 62.201 | wps 13271.6 | ups 1.6 | wpb 8272.3 | bsz 304.8 | num_updates 19152 | lr 0.00010219 | gnorm 0.543 | clip 0 | loss_scale 16 | train_wall 815 | gb_free 17.9 | wall 14911
2023-08-08 17:51:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 17:51:07 | INFO | fairseq.trainer | begin training epoch 14
2023-08-08 17:51:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 17:51:40 | INFO | train_inner | epoch 014:     48 / 1474 loss=2.143, trans_loss=5.105, nll_loss=2.329, w2v_ctc_loss=0.737, task_loss=0, contrastive_loss=0.074, total=4179.66, n_correct=2630.76, ppl=5.02, accuracy=62.942, wps=7913.6, ups=0.95, wpb=8359.3, bsz=322, num_updates=19200, lr=0.000102062, gnorm=0.54, clip=0, loss_scale=16, train_wall=55, gb_free=11.2, wall=14945
2023-08-08 17:52:36 | INFO | train_inner | epoch 014:    148 / 1474 loss=2.135, trans_loss=5.091, nll_loss=2.309, w2v_ctc_loss=0.738, task_loss=0, contrastive_loss=0.058, total=4081.01, n_correct=2578.61, ppl=4.95, accuracy=63.186, wps=14631.8, ups=1.79, wpb=8162, bsz=300.6, num_updates=19300, lr=0.000101797, gnorm=0.536, clip=0, loss_scale=16, train_wall=55, gb_free=16.3, wall=15000
2023-08-08 17:53:32 | INFO | train_inner | epoch 014:    248 / 1474 loss=2.156, trans_loss=5.112, nll_loss=2.336, w2v_ctc_loss=0.739, task_loss=0, contrastive_loss=0.158, total=4109.83, n_correct=2578.32, ppl=5.05, accuracy=62.735, wps=14863.7, ups=1.81, wpb=8219.7, bsz=295.2, num_updates=19400, lr=0.000101535, gnorm=0.538, clip=0, loss_scale=16, train_wall=55, gb_free=15.9, wall=15056
2023-08-08 17:54:27 | INFO | train_inner | epoch 014:    348 / 1474 loss=2.144, trans_loss=5.105, nll_loss=2.328, w2v_ctc_loss=0.735, task_loss=0, contrastive_loss=0.09, total=4171.83, n_correct=2625.24, ppl=5.02, accuracy=62.928, wps=15060.3, ups=1.81, wpb=8343.7, bsz=319.7, num_updates=19500, lr=0.000101274, gnorm=0.542, clip=0, loss_scale=16, train_wall=55, gb_free=17, wall=15111
2023-08-08 17:55:23 | INFO | train_inner | epoch 014:    448 / 1474 loss=2.143, trans_loss=5.116, nll_loss=2.341, w2v_ctc_loss=0.733, task_loss=0, contrastive_loss=0.067, total=4142.75, n_correct=2594.39, ppl=5.07, accuracy=62.625, wps=14867.5, ups=1.79, wpb=8285.5, bsz=302.2, num_updates=19600, lr=0.000101015, gnorm=0.545, clip=0, loss_scale=16, train_wall=55, gb_free=17, wall=15167
2023-08-08 17:56:19 | INFO | train_inner | epoch 014:    548 / 1474 loss=2.155, trans_loss=5.12, nll_loss=2.345, w2v_ctc_loss=0.755, task_loss=0, contrastive_loss=0.075, total=4073.76, n_correct=2545.82, ppl=5.08, accuracy=62.493, wps=14519.5, ups=1.78, wpb=8147.5, bsz=290.9, num_updates=19700, lr=0.000100759, gnorm=0.552, clip=0, loss_scale=16, train_wall=56, gb_free=15.8, wall=15223
2023-08-08 17:57:15 | INFO | train_inner | epoch 014:    648 / 1474 loss=2.155, trans_loss=5.119, nll_loss=2.346, w2v_ctc_loss=0.735, task_loss=0, contrastive_loss=0.131, total=4158.79, n_correct=2603.58, ppl=5.08, accuracy=62.604, wps=14896.2, ups=1.79, wpb=8317.6, bsz=306.8, num_updates=19800, lr=0.000100504, gnorm=0.54, clip=0, loss_scale=16, train_wall=55, gb_free=17.5, wall=15279
2023-08-08 17:58:10 | INFO | train_inner | epoch 014:    748 / 1474 loss=2.139, trans_loss=5.106, nll_loss=2.329, w2v_ctc_loss=0.733, task_loss=0, contrastive_loss=0.064, total=4145.47, n_correct=2605.88, ppl=5.03, accuracy=62.861, wps=14913.9, ups=1.8, wpb=8290.9, bsz=309.6, num_updates=19900, lr=0.000100251, gnorm=0.532, clip=0, loss_scale=16, train_wall=55, gb_free=16.4, wall=15334
2023-08-08 17:59:06 | INFO | train_inner | epoch 014:    848 / 1474 loss=2.161, trans_loss=5.111, nll_loss=2.337, w2v_ctc_loss=0.735, task_loss=0, contrastive_loss=0.172, total=4171.1, n_correct=2618.67, ppl=5.05, accuracy=62.781, wps=15037.8, ups=1.8, wpb=8342.2, bsz=319.7, num_updates=20000, lr=0.0001, gnorm=0.549, clip=0, loss_scale=16, train_wall=55, gb_free=16.9, wall=15390
2023-08-08 17:59:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 17:59:27 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.396 | trans_loss 5.585 | nll_loss 2.868 | w2v_ctc_loss 1.4 | task_loss 0 | contrastive_loss 0.247 | total 4003.4 | n_correct 2463.1 | ppl 7.3 | accuracy 61.525 | uer 17.949 | wer 19.559 | raw_wer 19.559 | bleu 19.49 | wps 2454.6 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.74
2023-08-08 17:59:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-08-08 17:59:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_14_20000.pt
2023-08-08 17:59:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_14_20000.pt
2023-08-08 17:59:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.49) (writing took 31.88998181372881 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:0')
2023-08-08 18:00:56 | INFO | train_inner | epoch 014:    948 / 1474 loss=2.155, trans_loss=5.121, nll_loss=2.349, w2v_ctc_loss=0.738, task_loss=0, contrastive_loss=0.113, total=4167.75, n_correct=2601.58, ppl=5.1, accuracy=62.422, wps=7533, ups=0.9, wpb=8335.5, bsz=310.1, num_updates=20100, lr=9.97509e-05, gnorm=0.556, clip=0, loss_scale=16, train_wall=56, gb_free=16.5, wall=15500
2023-08-08 18:01:52 | INFO | train_inner | epoch 014:   1048 / 1474 loss=2.151, trans_loss=5.126, nll_loss=2.355, w2v_ctc_loss=0.736, task_loss=0, contrastive_loss=0.085, total=4143.92, n_correct=2590.91, ppl=5.12, accuracy=62.523, wps=14803.9, ups=1.79, wpb=8287.8, bsz=300.7, num_updates=20200, lr=9.95037e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=56, gb_free=16.3, wall=15556
2023-08-08 18:02:49 | INFO | train_inner | epoch 014:   1148 / 1474 loss=2.193, trans_loss=5.124, nll_loss=2.355, w2v_ctc_loss=0.746, task_loss=0, contrastive_loss=0.354, total=4228.69, n_correct=2638.79, ppl=5.11, accuracy=62.402, wps=15029, ups=1.78, wpb=8457.4, bsz=327.2, num_updates=20300, lr=9.92583e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=56, gb_free=16, wall=15613
2023-08-08 18:03:44 | INFO | train_inner | epoch 014:   1248 / 1474 loss=2.157, trans_loss=5.143, nll_loss=2.376, w2v_ctc_loss=0.755, task_loss=0, contrastive_loss=0.049, total=4021.19, n_correct=2500.41, ppl=5.19, accuracy=62.181, wps=14577.9, ups=1.81, wpb=8042.4, bsz=271.7, num_updates=20400, lr=9.90148e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=55, gb_free=16.6, wall=15668
2023-08-08 18:04:40 | INFO | train_inner | epoch 014:   1348 / 1474 loss=2.148, trans_loss=5.129, nll_loss=2.361, w2v_ctc_loss=0.733, task_loss=0, contrastive_loss=0.065, total=4213.9, n_correct=2633.34, ppl=5.14, accuracy=62.492, wps=14958.2, ups=1.77, wpb=8427.8, bsz=319.4, num_updates=20500, lr=9.8773e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=56, gb_free=16.4, wall=15724
2023-08-08 18:05:36 | INFO | train_inner | epoch 014:   1448 / 1474 loss=2.158, trans_loss=5.136, nll_loss=2.369, w2v_ctc_loss=0.739, task_loss=0, contrastive_loss=0.102, total=4130.28, n_correct=2576.56, ppl=5.17, accuracy=62.382, wps=14911.4, ups=1.81, wpb=8260.6, bsz=304.1, num_updates=20600, lr=9.85329e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=55, gb_free=15.6, wall=15780
2023-08-08 18:05:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:2')
2023-08-08 18:06:13 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.385 | trans_loss 5.586 | nll_loss 2.871 | w2v_ctc_loss 1.361 | task_loss 0 | contrastive_loss 0.249 | total 4003.4 | n_correct 2463.7 | ppl 7.32 | accuracy 61.54 | uer 17.803 | wer 19.474 | raw_wer 19.474 | bleu 19.66 | wps 2249.7 | wpb 4003.4 | bsz 141.8 | num_updates 20626 | best_bleu 19.74
2023-08-08 18:06:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20626 updates
2023-08-08 18:06:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.6605.pt
2023-08-08 18:06:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.6605.pt
2023-08-08 18:06:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.6605.pt (epoch 14 @ 20626 updates, score 19.66) (writing took 19.810702661052346 seconds)
2023-08-08 18:06:33 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-08 18:06:33 | INFO | train | epoch 014 | loss 2.153 | trans_loss 5.118 | nll_loss 2.345 | w2v_ctc_loss 0.74 | task_loss 0 | contrastive_loss 0.113 | total 4138.65 | n_correct 2591.78 | ppl 5.08 | accuracy 62.624 | wps 13166.6 | ups 1.59 | wpb 8277.3 | bsz 305.7 | num_updates 20626 | lr 9.84708e-05 | gnorm 0.543 | clip 0 | loss_scale 16 | train_wall 815 | gb_free 16.6 | wall 15837
2023-08-08 18:06:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 18:06:34 | INFO | fairseq.trainer | begin training epoch 15
2023-08-08 18:06:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 18:07:22 | INFO | train_inner | epoch 015:     74 / 1474 loss=2.149, trans_loss=5.106, nll_loss=2.329, w2v_ctc_loss=0.731, task_loss=0, contrastive_loss=0.153, total=4083.88, n_correct=2570.17, ppl=5.02, accuracy=62.935, wps=7701.2, ups=0.94, wpb=8167.8, bsz=300.2, num_updates=20700, lr=9.82946e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=55, gb_free=16.1, wall=15886
2023-08-08 18:08:17 | INFO | train_inner | epoch 015:    174 / 1474 loss=2.135, trans_loss=5.094, nll_loss=2.313, w2v_ctc_loss=0.738, task_loss=0, contrastive_loss=0.062, total=4115.73, n_correct=2597.4, ppl=4.97, accuracy=63.109, wps=14754.1, ups=1.79, wpb=8231.5, bsz=297.8, num_updates=20800, lr=9.80581e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=55, gb_free=17.1, wall=15941
2023-08-08 18:09:13 | INFO | train_inner | epoch 015:    274 / 1474 loss=2.127, trans_loss=5.094, nll_loss=2.314, w2v_ctc_loss=0.723, task_loss=0, contrastive_loss=0.054, total=4193.15, n_correct=2651.75, ppl=4.97, accuracy=63.24, wps=15035.9, ups=1.79, wpb=8386.3, bsz=312.6, num_updates=20900, lr=9.78232e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=55, gb_free=13.3, wall=15997
2023-08-08 18:10:09 | INFO | train_inner | epoch 015:    374 / 1474 loss=2.132, trans_loss=5.087, nll_loss=2.304, w2v_ctc_loss=0.729, task_loss=0, contrastive_loss=0.077, total=4167.66, n_correct=2630.72, ppl=4.94, accuracy=63.122, wps=14884, ups=1.79, wpb=8335.3, bsz=306, num_updates=21000, lr=9.759e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=55, gb_free=16.4, wall=16053
2023-08-08 18:11:05 | INFO | train_inner | epoch 015:    474 / 1474 loss=2.146, trans_loss=5.1, nll_loss=2.32, w2v_ctc_loss=0.717, task_loss=0, contrastive_loss=0.17, total=4074.53, n_correct=2561.06, ppl=4.99, accuracy=62.855, wps=14566.2, ups=1.79, wpb=8149.1, bsz=294.2, num_updates=21100, lr=9.73585e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=55, gb_free=16.1, wall=16109
2023-08-08 18:12:01 | INFO | train_inner | epoch 015:    574 / 1474 loss=2.131, trans_loss=5.095, nll_loss=2.315, w2v_ctc_loss=0.731, task_loss=0, contrastive_loss=0.06, total=4140.59, n_correct=2612.4, ppl=4.98, accuracy=63.092, wps=14889.7, ups=1.8, wpb=8281.2, bsz=298.8, num_updates=21200, lr=9.71286e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=55, gb_free=12.7, wall=16165
2023-08-08 18:12:56 | INFO | train_inner | epoch 015:    674 / 1474 loss=2.148, trans_loss=5.098, nll_loss=2.319, w2v_ctc_loss=0.734, task_loss=0, contrastive_loss=0.139, total=4134.99, n_correct=2610.26, ppl=4.99, accuracy=63.126, wps=14867.9, ups=1.8, wpb=8270, bsz=307.1, num_updates=21300, lr=9.69003e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=55, gb_free=11.3, wall=16220
2023-08-08 18:13:52 | INFO | train_inner | epoch 015:    774 / 1474 loss=2.139, trans_loss=5.108, nll_loss=2.331, w2v_ctc_loss=0.736, task_loss=0, contrastive_loss=0.063, total=4173.66, n_correct=2623.23, ppl=5.03, accuracy=62.852, wps=14943.8, ups=1.79, wpb=8347.3, bsz=305, num_updates=21400, lr=9.66736e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=55, gb_free=17, wall=16276
2023-08-08 18:14:47 | INFO | train_inner | epoch 015:    874 / 1474 loss=2.141, trans_loss=5.112, nll_loss=2.337, w2v_ctc_loss=0.739, task_loss=0, contrastive_loss=0.059, total=4059.35, n_correct=2549.81, ppl=5.05, accuracy=62.813, wps=14709.4, ups=1.81, wpb=8118.7, bsz=288.3, num_updates=21500, lr=9.64486e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=55, gb_free=15.8, wall=16332
2023-08-08 18:15:43 | INFO | train_inner | epoch 015:    974 / 1474 loss=2.144, trans_loss=5.106, nll_loss=2.33, w2v_ctc_loss=0.726, task_loss=0, contrastive_loss=0.14, total=4122.87, n_correct=2593.41, ppl=5.03, accuracy=62.903, wps=14852, ups=1.8, wpb=8245.7, bsz=301.7, num_updates=21600, lr=9.6225e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=55, gb_free=17.9, wall=16387
2023-08-08 18:16:39 | INFO | train_inner | epoch 015:   1074 / 1474 loss=2.175, trans_loss=5.114, nll_loss=2.341, w2v_ctc_loss=0.734, task_loss=0, contrastive_loss=0.298, total=4192.24, n_correct=2630.21, ppl=5.07, accuracy=62.74, wps=14892.5, ups=1.78, wpb=8384.5, bsz=325.2, num_updates=21700, lr=9.60031e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=56, gb_free=17.5, wall=16443
2023-08-08 18:17:35 | INFO | train_inner | epoch 015:   1174 / 1474 loss=2.133, trans_loss=5.1, nll_loss=2.325, w2v_ctc_loss=0.713, task_loss=0, contrastive_loss=0.105, total=4185, n_correct=2646.64, ppl=5.01, accuracy=63.241, wps=15151.6, ups=1.81, wpb=8370, bsz=329.3, num_updates=21800, lr=9.57826e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=55, gb_free=16.6, wall=16499
2023-08-08 18:18:30 | INFO | train_inner | epoch 015:   1274 / 1474 loss=2.142, trans_loss=5.11, nll_loss=2.335, w2v_ctc_loss=0.74, task_loss=0, contrastive_loss=0.064, total=4152.04, n_correct=2607.97, ppl=5.05, accuracy=62.812, wps=14859.3, ups=1.79, wpb=8304.1, bsz=303.7, num_updates=21900, lr=9.55637e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=55, gb_free=16.7, wall=16554
2023-08-08 18:19:26 | INFO | train_inner | epoch 015:   1374 / 1474 loss=2.133, trans_loss=5.111, nll_loss=2.337, w2v_ctc_loss=0.727, task_loss=0, contrastive_loss=0.05, total=4100.21, n_correct=2578.24, ppl=5.05, accuracy=62.881, wps=14729.9, ups=1.8, wpb=8200.4, bsz=293.6, num_updates=22000, lr=9.53463e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=55, gb_free=17.8, wall=16610
2023-08-08 18:19:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 18:19:50 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.371 | trans_loss 5.581 | nll_loss 2.858 | w2v_ctc_loss 1.321 | task_loss 0 | contrastive_loss 0.257 | total 4003.4 | n_correct 2467.4 | ppl 7.25 | accuracy 61.633 | uer 17.617 | wer 19.574 | raw_wer 19.574 | bleu 19.52 | wps 2133.3 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 19.74
2023-08-08 18:19:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-08-08 18:19:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_15_22000.pt
2023-08-08 18:19:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_15_22000.pt
2023-08-08 18:20:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.52) (writing took 35.94473992846906 seconds)
2023-08-08 18:21:23 | INFO | train_inner | epoch 015:   1474 / 1474 loss=2.153, trans_loss=5.116, nll_loss=2.346, w2v_ctc_loss=0.732, task_loss=0, contrastive_loss=0.135, total=4141.17, n_correct=2601.87, ppl=5.08, accuracy=62.829, wps=7062.2, ups=0.85, wpb=8282.3, bsz=314.3, num_updates=22100, lr=9.51303e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=56, gb_free=17.1, wall=16727
2023-08-08 18:21:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 18:21:46 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.4 | trans_loss 5.577 | nll_loss 2.857 | w2v_ctc_loss 1.421 | task_loss 0 | contrastive_loss 0.261 | total 4003.4 | n_correct 2471.3 | ppl 7.25 | accuracy 61.73 | uer 17.636 | wer 19.351 | raw_wer 19.351 | bleu 19.63 | wps 2220.5 | wpb 4003.4 | bsz 141.8 | num_updates 22100 | best_bleu 19.74
2023-08-08 18:21:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22100 updates
2023-08-08 18:21:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.6309.pt
2023-08-08 18:21:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.6309.pt
2023-08-08 18:22:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.6309.pt (epoch 15 @ 22100 updates, score 19.63) (writing took 14.14401524886489 seconds)
2023-08-08 18:22:01 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-08 18:22:01 | INFO | train | epoch 015 | loss 2.141 | trans_loss 5.102 | nll_loss 2.325 | w2v_ctc_loss 0.729 | task_loss 0 | contrastive_loss 0.11 | total 4138.65 | n_correct 2606.98 | ppl 5.01 | accuracy 62.991 | wps 13152.8 | ups 1.59 | wpb 8277.3 | bsz 305.7 | num_updates 22100 | lr 9.51303e-05 | gnorm 0.543 | clip 0 | loss_scale 32 | train_wall 814 | gb_free 17.1 | wall 16765
2023-08-08 18:22:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 18:22:01 | INFO | fairseq.trainer | begin training epoch 16
2023-08-08 18:22:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 18:23:04 | INFO | train_inner | epoch 016:    100 / 1474 loss=2.12, trans_loss=5.073, nll_loss=2.287, w2v_ctc_loss=0.718, task_loss=0, contrastive_loss=0.077, total=4126.22, n_correct=2624.83, ppl=4.88, accuracy=63.613, wps=8212.9, ups=1, wpb=8252.4, bsz=315.6, num_updates=22200, lr=9.49158e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=55, gb_free=16.4, wall=16828
2023-08-08 18:23:59 | INFO | train_inner | epoch 016:    200 / 1474 loss=2.111, trans_loss=5.069, nll_loss=2.282, w2v_ctc_loss=0.71, task_loss=0, contrastive_loss=0.055, total=4100.6, n_correct=2612.6, ppl=4.86, accuracy=63.713, wps=14859.1, ups=1.81, wpb=8201.2, bsz=296.8, num_updates=22300, lr=9.47027e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=55, gb_free=13.2, wall=16883
2023-08-08 18:24:55 | INFO | train_inner | epoch 016:    300 / 1474 loss=2.134, trans_loss=5.081, nll_loss=2.298, w2v_ctc_loss=0.724, task_loss=0, contrastive_loss=0.126, total=4166.94, n_correct=2641.54, ppl=4.92, accuracy=63.393, wps=14790.5, ups=1.77, wpb=8333.9, bsz=308.9, num_updates=22400, lr=9.44911e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=56, gb_free=17.4, wall=16939
2023-08-08 18:25:51 | INFO | train_inner | epoch 016:    400 / 1474 loss=2.135, trans_loss=5.082, nll_loss=2.298, w2v_ctc_loss=0.727, task_loss=0, contrastive_loss=0.139, total=4073.3, n_correct=2579.51, ppl=4.92, accuracy=63.327, wps=14716.9, ups=1.81, wpb=8146.6, bsz=288.1, num_updates=22500, lr=9.42809e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=55, gb_free=17.2, wall=16995
2023-08-08 18:26:47 | INFO | train_inner | epoch 016:    500 / 1474 loss=2.123, trans_loss=5.079, nll_loss=2.296, w2v_ctc_loss=0.717, task_loss=0, contrastive_loss=0.084, total=4174.67, n_correct=2655.13, ppl=4.91, accuracy=63.601, wps=14792.9, ups=1.77, wpb=8349.3, bsz=319.1, num_updates=22600, lr=9.40721e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=56, gb_free=16.3, wall=17051
2023-08-08 18:27:43 | INFO | train_inner | epoch 016:    600 / 1474 loss=2.119, trans_loss=5.084, nll_loss=2.301, w2v_ctc_loss=0.717, task_loss=0, contrastive_loss=0.05, total=4124.65, n_correct=2616.52, ppl=4.93, accuracy=63.436, wps=14893.2, ups=1.81, wpb=8249.3, bsz=297.6, num_updates=22700, lr=9.38647e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=55, gb_free=16.6, wall=17107
2023-08-08 18:28:38 | INFO | train_inner | epoch 016:    700 / 1474 loss=2.122, trans_loss=5.089, nll_loss=2.308, w2v_ctc_loss=0.72, task_loss=0, contrastive_loss=0.053, total=4095.49, n_correct=2595.15, ppl=4.95, accuracy=63.366, wps=14654.9, ups=1.79, wpb=8191, bsz=296.3, num_updates=22800, lr=9.36586e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=55, gb_free=16.4, wall=17163
2023-08-08 18:29:34 | INFO | train_inner | epoch 016:    800 / 1474 loss=2.13, trans_loss=5.089, nll_loss=2.309, w2v_ctc_loss=0.715, task_loss=0, contrastive_loss=0.112, total=4174.94, n_correct=2642.53, ppl=4.95, accuracy=63.295, wps=15030.9, ups=1.8, wpb=8349.9, bsz=310.9, num_updates=22900, lr=9.34539e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=55, gb_free=16.7, wall=17218
2023-08-08 18:30:30 | INFO | train_inner | epoch 016:    900 / 1474 loss=2.127, trans_loss=5.086, nll_loss=2.305, w2v_ctc_loss=0.715, task_loss=0, contrastive_loss=0.104, total=4163.19, n_correct=2643.81, ppl=4.94, accuracy=63.504, wps=14971.9, ups=1.8, wpb=8326.4, bsz=310.6, num_updates=23000, lr=9.32505e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=55, gb_free=17, wall=17274
2023-08-08 18:31:25 | INFO | train_inner | epoch 016:   1000 / 1474 loss=2.14, trans_loss=5.102, nll_loss=2.324, w2v_ctc_loss=0.735, task_loss=0, contrastive_loss=0.1, total=4103.45, n_correct=2585.44, ppl=5.01, accuracy=63.006, wps=14737.4, ups=1.8, wpb=8206.9, bsz=298.1, num_updates=23100, lr=9.30484e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=55, gb_free=15.3, wall=17329
2023-08-08 18:32:22 | INFO | train_inner | epoch 016:   1100 / 1474 loss=2.14, trans_loss=5.106, nll_loss=2.331, w2v_ctc_loss=0.736, task_loss=0, contrastive_loss=0.079, total=4119.27, n_correct=2589.73, ppl=5.03, accuracy=62.869, wps=14593.8, ups=1.77, wpb=8238.5, bsz=295.3, num_updates=23200, lr=9.28477e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=56, gb_free=18.1, wall=17386
2023-08-08 18:33:18 | INFO | train_inner | epoch 016:   1200 / 1474 loss=2.141, trans_loss=5.097, nll_loss=2.32, w2v_ctc_loss=0.713, task_loss=0, contrastive_loss=0.172, total=4165.11, n_correct=2628.44, ppl=4.99, accuracy=63.106, wps=14945.1, ups=1.79, wpb=8330.2, bsz=308.7, num_updates=23300, lr=9.26482e-05, gnorm=0.54, clip=0, loss_scale=64, train_wall=55, gb_free=16.9, wall=17442
2023-08-08 18:34:13 | INFO | train_inner | epoch 016:   1300 / 1474 loss=2.145, trans_loss=5.1, nll_loss=2.323, w2v_ctc_loss=0.73, task_loss=0, contrastive_loss=0.152, total=4134.61, n_correct=2611.81, ppl=5, accuracy=63.169, wps=14788.3, ups=1.79, wpb=8269.2, bsz=310.8, num_updates=23400, lr=9.245e-05, gnorm=0.54, clip=0, loss_scale=64, train_wall=55, gb_free=17, wall=17498
2023-08-08 18:35:09 | INFO | train_inner | epoch 016:   1400 / 1474 loss=2.135, trans_loss=5.1, nll_loss=2.325, w2v_ctc_loss=0.728, task_loss=0, contrastive_loss=0.083, total=4206.33, n_correct=2653.83, ppl=5.01, accuracy=63.091, wps=15076, ups=1.79, wpb=8412.7, bsz=322.2, num_updates=23500, lr=9.22531e-05, gnorm=0.549, clip=0, loss_scale=64, train_wall=55, gb_free=15.9, wall=17553
2023-08-08 18:35:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 18:36:14 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.387 | trans_loss 5.571 | nll_loss 2.85 | w2v_ctc_loss 1.395 | task_loss 0 | contrastive_loss 0.258 | total 4003.4 | n_correct 2472.8 | ppl 7.21 | accuracy 61.767 | uer 17.745 | wer 19.548 | raw_wer 19.548 | bleu 19.89 | wps 2230 | wpb 4003.4 | bsz 141.8 | num_updates 23574 | best_bleu 19.89
2023-08-08 18:36:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23574 updates
2023-08-08 18:36:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 18:36:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 18:36:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt (epoch 16 @ 23574 updates, score 19.89) (writing took 24.209324039518833 seconds)
2023-08-08 18:36:38 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-08 18:36:38 | INFO | train | epoch 016 | loss 2.131 | trans_loss 5.089 | nll_loss 2.308 | w2v_ctc_loss 0.722 | task_loss 0 | contrastive_loss 0.108 | total 4138.65 | n_correct 2620.42 | ppl 4.95 | accuracy 63.316 | wps 13902.4 | ups 1.68 | wpb 8277.3 | bsz 305.7 | num_updates 23574 | lr 9.21082e-05 | gnorm 0.546 | clip 0 | loss_scale 64 | train_wall 815 | gb_free 15.8 | wall 17643
2023-08-08 18:36:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 18:36:39 | INFO | fairseq.trainer | begin training epoch 17
2023-08-08 18:36:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 18:37:01 | INFO | train_inner | epoch 017:     26 / 1474 loss=2.139, trans_loss=5.083, nll_loss=2.301, w2v_ctc_loss=0.716, task_loss=0, contrastive_loss=0.219, total=4152.31, n_correct=2635.99, ppl=4.93, accuracy=63.482, wps=7443.6, ups=0.9, wpb=8304.6, bsz=304.6, num_updates=23600, lr=9.20575e-05, gnorm=0.545, clip=0, loss_scale=64, train_wall=56, gb_free=14.2, wall=17665
2023-08-08 18:37:56 | INFO | train_inner | epoch 017:    126 / 1474 loss=2.111, trans_loss=5.061, nll_loss=2.272, w2v_ctc_loss=0.718, task_loss=0, contrastive_loss=0.057, total=4118.91, n_correct=2629.17, ppl=4.83, accuracy=63.832, wps=14904.2, ups=1.81, wpb=8237.8, bsz=295.8, num_updates=23700, lr=9.1863e-05, gnorm=0.55, clip=0, loss_scale=64, train_wall=55, gb_free=16.7, wall=17720
2023-08-08 18:38:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-08 18:38:52 | INFO | train_inner | epoch 017:    227 / 1474 loss=2.111, trans_loss=5.055, nll_loss=2.265, w2v_ctc_loss=0.701, task_loss=0, contrastive_loss=0.11, total=4123.81, n_correct=2639.96, ppl=4.81, accuracy=64.017, wps=14696.8, ups=1.78, wpb=8247.6, bsz=308.2, num_updates=23800, lr=9.16698e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=56, gb_free=17.1, wall=17776
2023-08-08 18:39:48 | INFO | train_inner | epoch 017:    327 / 1474 loss=2.13, trans_loss=5.067, nll_loss=2.28, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.226, total=4156.91, n_correct=2649.93, ppl=4.86, accuracy=63.748, wps=14930.5, ups=1.8, wpb=8313.8, bsz=305.7, num_updates=23900, lr=9.14779e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=55, gb_free=17.8, wall=17832
2023-08-08 18:40:44 | INFO | train_inner | epoch 017:    427 / 1474 loss=2.107, trans_loss=5.066, nll_loss=2.279, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.054, total=4146.43, n_correct=2649.14, ppl=4.85, accuracy=63.89, wps=14790, ups=1.78, wpb=8292.9, bsz=308, num_updates=24000, lr=9.12871e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=56, gb_free=16.5, wall=17888
2023-08-08 18:40:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 18:41:07 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.4 | trans_loss 5.575 | nll_loss 2.851 | w2v_ctc_loss 1.431 | task_loss 0 | contrastive_loss 0.252 | total 4003.4 | n_correct 2475.3 | ppl 7.22 | accuracy 61.83 | uer 17.83 | wer 19.619 | raw_wer 19.619 | bleu 19.5 | wps 2192.6 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 19.89
2023-08-08 18:41:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-08-08 18:41:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_17_24000.pt
2023-08-08 18:41:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_17_24000.pt
2023-08-08 18:41:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.5) (writing took 17.306461941450834 seconds)
2023-08-08 18:42:22 | INFO | train_inner | epoch 017:    527 / 1474 loss=2.12, trans_loss=5.072, nll_loss=2.287, w2v_ctc_loss=0.715, task_loss=0, contrastive_loss=0.096, total=4182.1, n_correct=2660, ppl=4.88, accuracy=63.604, wps=8551.8, ups=1.02, wpb=8364.2, bsz=307.9, num_updates=24100, lr=9.10975e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=56, gb_free=17, wall=17986
2023-08-08 18:43:17 | INFO | train_inner | epoch 017:    627 / 1474 loss=2.111, trans_loss=5.076, nll_loss=2.291, w2v_ctc_loss=0.711, task_loss=0, contrastive_loss=0.05, total=4167.27, n_correct=2653.78, ppl=4.9, accuracy=63.681, wps=14966.2, ups=1.8, wpb=8334.5, bsz=302.2, num_updates=24200, lr=9.09091e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=55, gb_free=11.4, wall=18042
2023-08-08 18:44:13 | INFO | train_inner | epoch 017:    727 / 1474 loss=2.127, trans_loss=5.079, nll_loss=2.297, w2v_ctc_loss=0.725, task_loss=0, contrastive_loss=0.094, total=4166.12, n_correct=2648.52, ppl=4.91, accuracy=63.573, wps=14952.1, ups=1.79, wpb=8332.2, bsz=308.1, num_updates=24300, lr=9.07218e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=55, gb_free=16.6, wall=18097
2023-08-08 18:45:08 | INFO | train_inner | epoch 017:    827 / 1474 loss=2.116, trans_loss=5.08, nll_loss=2.296, w2v_ctc_loss=0.714, task_loss=0, contrastive_loss=0.061, total=4091.64, n_correct=2601.04, ppl=4.91, accuracy=63.57, wps=14811.5, ups=1.81, wpb=8183.3, bsz=295.3, num_updates=24400, lr=9.05357e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=55, gb_free=17.6, wall=18153
2023-08-08 18:46:04 | INFO | train_inner | epoch 017:    927 / 1474 loss=2.113, trans_loss=5.079, nll_loss=2.296, w2v_ctc_loss=0.707, task_loss=0, contrastive_loss=0.059, total=4106.83, n_correct=2611.79, ppl=4.91, accuracy=63.596, wps=14911, ups=1.82, wpb=8213.7, bsz=304.6, num_updates=24500, lr=9.03508e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=55, gb_free=16.1, wall=18208
2023-08-08 18:46:59 | INFO | train_inner | epoch 017:   1027 / 1474 loss=2.116, trans_loss=5.078, nll_loss=2.295, w2v_ctc_loss=0.715, task_loss=0, contrastive_loss=0.063, total=4115.49, n_correct=2621.37, ppl=4.91, accuracy=63.695, wps=14850.2, ups=1.8, wpb=8231, bsz=305.8, num_updates=24600, lr=9.0167e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=18263
2023-08-08 18:47:54 | INFO | train_inner | epoch 017:   1127 / 1474 loss=2.112, trans_loss=5.078, nll_loss=2.296, w2v_ctc_loss=0.708, task_loss=0, contrastive_loss=0.051, total=4078.39, n_correct=2596.11, ppl=4.91, accuracy=63.655, wps=14725.2, ups=1.81, wpb=8156.8, bsz=293.7, num_updates=24700, lr=8.99843e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=55, gb_free=15.9, wall=18319
2023-08-08 18:48:51 | INFO | train_inner | epoch 017:   1227 / 1474 loss=2.153, trans_loss=5.086, nll_loss=2.308, w2v_ctc_loss=0.709, task_loss=0, contrastive_loss=0.288, total=4173.49, n_correct=2638.73, ppl=4.95, accuracy=63.226, wps=14765.2, ups=1.77, wpb=8347, bsz=323.7, num_updates=24800, lr=8.98027e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=56, gb_free=16.4, wall=18375
2023-08-08 18:49:47 | INFO | train_inner | epoch 017:   1327 / 1474 loss=2.124, trans_loss=5.083, nll_loss=2.303, w2v_ctc_loss=0.701, task_loss=0, contrastive_loss=0.132, total=4156.28, n_correct=2639.7, ppl=4.93, accuracy=63.511, wps=14910.8, ups=1.79, wpb=8312.6, bsz=308, num_updates=24900, lr=8.96221e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=55, gb_free=18.1, wall=18431
2023-08-08 18:50:43 | INFO | train_inner | epoch 017:   1427 / 1474 loss=2.115, trans_loss=5.086, nll_loss=2.306, w2v_ctc_loss=0.709, task_loss=0, contrastive_loss=0.055, total=4112.95, n_correct=2611.47, ppl=4.95, accuracy=63.494, wps=14696.7, ups=1.79, wpb=8225.9, bsz=303.2, num_updates=25000, lr=8.94427e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=55, gb_free=17.2, wall=18487
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:0')
2023-08-08 18:51:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:7')
2023-08-08 18:51:32 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.379 | trans_loss 5.561 | nll_loss 2.838 | w2v_ctc_loss 1.401 | task_loss 0 | contrastive_loss 0.247 | total 4003.4 | n_correct 2470.3 | ppl 7.15 | accuracy 61.705 | uer 17.498 | wer 19.455 | raw_wer 19.455 | bleu 19.79 | wps 2013.2 | wpb 4003.4 | bsz 141.8 | num_updates 25047 | best_bleu 19.89
2023-08-08 18:51:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25047 updates
2023-08-08 18:51:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.7906.pt
2023-08-08 18:51:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.7906.pt
2023-08-08 18:51:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.7906.pt (epoch 17 @ 25047 updates, score 19.79) (writing took 17.53505175933242 seconds)
2023-08-08 18:51:50 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-08 18:51:50 | INFO | train | epoch 017 | loss 2.119 | trans_loss 5.075 | nll_loss 2.291 | w2v_ctc_loss 0.711 | task_loss 0 | contrastive_loss 0.099 | total 4136.62 | n_correct 2633.06 | ppl 4.89 | accuracy 63.652 | wps 13368.1 | ups 1.62 | wpb 8273.2 | bsz 305.1 | num_updates 25047 | lr 8.93588e-05 | gnorm 0.544 | clip 0 | loss_scale 32 | train_wall 814 | gb_free 16.6 | wall 18554
2023-08-08 18:51:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 18:51:50 | INFO | fairseq.trainer | begin training epoch 18
2023-08-08 18:51:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 18:52:28 | INFO | train_inner | epoch 018:     53 / 1474 loss=2.114, trans_loss=5.071, nll_loss=2.286, w2v_ctc_loss=0.718, task_loss=0, contrastive_loss=0.063, total=4139.04, n_correct=2638.17, ppl=4.88, accuracy=63.739, wps=7848.7, ups=0.95, wpb=8278.1, bsz=303.3, num_updates=25100, lr=8.92644e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=56, gb_free=17.3, wall=18592
2023-08-08 18:53:24 | INFO | train_inner | epoch 018:    153 / 1474 loss=2.111, trans_loss=5.043, nll_loss=2.248, w2v_ctc_loss=0.686, task_loss=0, contrastive_loss=0.183, total=4154.85, n_correct=2670.38, ppl=4.75, accuracy=64.271, wps=14828.5, ups=1.78, wpb=8309.7, bsz=312.7, num_updates=25200, lr=8.90871e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=56, gb_free=17, wall=18648
2023-08-08 18:54:20 | INFO | train_inner | epoch 018:    253 / 1474 loss=2.095, trans_loss=5.045, nll_loss=2.252, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.056, total=4162.72, n_correct=2683.26, ppl=4.76, accuracy=64.459, wps=14947.5, ups=1.8, wpb=8325.4, bsz=312.9, num_updates=25300, lr=8.89108e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=55, gb_free=16.4, wall=18704
2023-08-08 18:55:16 | INFO | train_inner | epoch 018:    353 / 1474 loss=2.103, trans_loss=5.055, nll_loss=2.265, w2v_ctc_loss=0.703, task_loss=0, contrastive_loss=0.068, total=4161.22, n_correct=2666.21, ppl=4.81, accuracy=64.073, wps=14837.4, ups=1.78, wpb=8322.4, bsz=301.5, num_updates=25400, lr=8.87357e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=56, gb_free=14.8, wall=18760
2023-08-08 18:56:12 | INFO | train_inner | epoch 018:    453 / 1474 loss=2.116, trans_loss=5.059, nll_loss=2.27, w2v_ctc_loss=0.701, task_loss=0, contrastive_loss=0.158, total=4092.36, n_correct=2615.91, ppl=4.82, accuracy=63.922, wps=14579.3, ups=1.78, wpb=8184.7, bsz=295.3, num_updates=25500, lr=8.85615e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=56, gb_free=16.8, wall=18816
2023-08-08 18:57:08 | INFO | train_inner | epoch 018:    553 / 1474 loss=2.096, trans_loss=5.045, nll_loss=2.254, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.068, total=4206.45, n_correct=2707.64, ppl=4.77, accuracy=64.369, wps=15066.6, ups=1.79, wpb=8412.9, bsz=328.9, num_updates=25600, lr=8.83883e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=55, gb_free=18.1, wall=18872
2023-08-08 18:58:03 | INFO | train_inner | epoch 018:    653 / 1474 loss=2.118, trans_loss=5.07, nll_loss=2.285, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.134, total=4097.96, n_correct=2612.79, ppl=4.87, accuracy=63.758, wps=14801.6, ups=1.81, wpb=8195.9, bsz=298.6, num_updates=25700, lr=8.82162e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=55, gb_free=12.6, wall=18927
2023-08-08 18:59:00 | INFO | train_inner | epoch 018:    753 / 1474 loss=2.133, trans_loss=5.067, nll_loss=2.282, w2v_ctc_loss=0.713, task_loss=0, contrastive_loss=0.225, total=4208.5, n_correct=2684.24, ppl=4.86, accuracy=63.781, wps=14941.7, ups=1.78, wpb=8417, bsz=322.6, num_updates=25800, lr=8.80451e-05, gnorm=0.541, clip=0, loss_scale=64, train_wall=56, gb_free=16.5, wall=18984
2023-08-08 18:59:56 | INFO | train_inner | epoch 018:    853 / 1474 loss=2.103, trans_loss=5.067, nll_loss=2.28, w2v_ctc_loss=0.703, task_loss=0, contrastive_loss=0.046, total=4166.07, n_correct=2659.64, ppl=4.86, accuracy=63.841, wps=14843.9, ups=1.78, wpb=8332.1, bsz=302.4, num_updates=25900, lr=8.7875e-05, gnorm=0.543, clip=0, loss_scale=64, train_wall=56, gb_free=16.1, wall=19040
2023-08-08 19:00:51 | INFO | train_inner | epoch 018:    953 / 1474 loss=2.101, trans_loss=5.059, nll_loss=2.271, w2v_ctc_loss=0.692, task_loss=0, contrastive_loss=0.069, total=4141.27, n_correct=2650.08, ppl=4.83, accuracy=63.992, wps=14892.3, ups=1.8, wpb=8282.5, bsz=316, num_updates=26000, lr=8.77058e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=55, gb_free=16.3, wall=19096
2023-08-08 19:00:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 19:01:15 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.379 | trans_loss 5.569 | nll_loss 2.843 | w2v_ctc_loss 1.383 | task_loss 0 | contrastive_loss 0.246 | total 4003.4 | n_correct 2474.1 | ppl 7.18 | accuracy 61.8 | uer 17.644 | wer 19.418 | raw_wer 19.418 | bleu 19.71 | wps 2124.5 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 19.89
2023-08-08 19:01:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-08-08 19:01:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_18_26000.pt
2023-08-08 19:01:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_18_26000.pt
2023-08-08 19:01:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 19.71) (writing took 32.73450067266822 seconds)
2023-08-08 19:02:44 | INFO | train_inner | epoch 018:   1053 / 1474 loss=2.103, trans_loss=5.066, nll_loss=2.281, w2v_ctc_loss=0.695, task_loss=0, contrastive_loss=0.058, total=4134.55, n_correct=2643.1, ppl=4.86, accuracy=63.927, wps=7317.7, ups=0.88, wpb=8269.1, bsz=300.8, num_updates=26100, lr=8.75376e-05, gnorm=0.54, clip=0, loss_scale=64, train_wall=55, gb_free=16.1, wall=19209
2023-08-08 19:03:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-08 19:03:41 | INFO | train_inner | epoch 018:   1154 / 1474 loss=2.098, trans_loss=5.053, nll_loss=2.263, w2v_ctc_loss=0.701, task_loss=0, contrastive_loss=0.052, total=4136.34, n_correct=2654.85, ppl=4.8, accuracy=64.184, wps=14669.2, ups=1.77, wpb=8272.7, bsz=306.2, num_updates=26200, lr=8.73704e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=56, gb_free=15.5, wall=19265
2023-08-08 19:04:37 | INFO | train_inner | epoch 018:   1254 / 1474 loss=2.106, trans_loss=5.078, nll_loss=2.295, w2v_ctc_loss=0.701, task_loss=0, contrastive_loss=0.051, total=4087.62, n_correct=2604.35, ppl=4.91, accuracy=63.713, wps=14651.3, ups=1.79, wpb=8175.2, bsz=287.1, num_updates=26300, lr=8.72041e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=19321
2023-08-08 19:05:32 | INFO | train_inner | epoch 018:   1354 / 1474 loss=2.122, trans_loss=5.084, nll_loss=2.304, w2v_ctc_loss=0.722, task_loss=0, contrastive_loss=0.074, total=4070.69, n_correct=2583.81, ppl=4.94, accuracy=63.474, wps=14643.4, ups=1.8, wpb=8141.4, bsz=291.7, num_updates=26400, lr=8.70388e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=55, gb_free=17.7, wall=19376
2023-08-08 19:06:28 | INFO | train_inner | epoch 018:   1454 / 1474 loss=2.112, trans_loss=5.078, nll_loss=2.296, w2v_ctc_loss=0.709, task_loss=0, contrastive_loss=0.061, total=4113.2, n_correct=2617.8, ppl=4.91, accuracy=63.644, wps=14759.6, ups=1.79, wpb=8226.4, bsz=297.5, num_updates=26500, lr=8.68744e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=55, gb_free=16.7, wall=19432
2023-08-08 19:06:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 19:07:02 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.4 | trans_loss 5.567 | nll_loss 2.842 | w2v_ctc_loss 1.46 | task_loss 0 | contrastive_loss 0.245 | total 4003.4 | n_correct 2476.8 | ppl 7.17 | accuracy 61.867 | uer 17.461 | wer 19.213 | raw_wer 19.213 | bleu 19.76 | wps 2255.9 | wpb 4003.4 | bsz 141.8 | num_updates 26520 | best_bleu 19.89
2023-08-08 19:07:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26520 updates
2023-08-08 19:07:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.7605.pt
2023-08-08 19:07:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.7605.pt
2023-08-08 19:07:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.7605.pt (epoch 18 @ 26520 updates, score 19.76) (writing took 21.33311979100108 seconds)
2023-08-08 19:07:24 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-08 19:07:24 | INFO | train | epoch 018 | loss 2.109 | trans_loss 5.062 | nll_loss 2.274 | w2v_ctc_loss 0.702 | task_loss 0 | contrastive_loss 0.096 | total 4137.4 | n_correct 2646.21 | ppl 4.84 | accuracy 63.958 | wps 13057.5 | ups 1.58 | wpb 8274.8 | bsz 305.2 | num_updates 26520 | lr 8.68417e-05 | gnorm 0.544 | clip 0 | loss_scale 32 | train_wall 817 | gb_free 16.2 | wall 19488
2023-08-08 19:07:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 19:07:24 | INFO | fairseq.trainer | begin training epoch 19
2023-08-08 19:07:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 19:08:16 | INFO | train_inner | epoch 019:     80 / 1474 loss=2.099, trans_loss=5.039, nll_loss=2.244, w2v_ctc_loss=0.695, task_loss=0, contrastive_loss=0.11, total=4102.06, n_correct=2635.54, ppl=4.74, accuracy=64.249, wps=7590.7, ups=0.93, wpb=8204.1, bsz=296.9, num_updates=26600, lr=8.6711e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=55, gb_free=17.8, wall=19540
2023-08-08 19:09:12 | INFO | train_inner | epoch 019:    180 / 1474 loss=2.099, trans_loss=5.03, nll_loss=2.233, w2v_ctc_loss=0.703, task_loss=0, contrastive_loss=0.099, total=4227.7, n_correct=2730.56, ppl=4.7, accuracy=64.587, wps=15096.9, ups=1.79, wpb=8455.4, bsz=324.8, num_updates=26700, lr=8.65485e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=56, gb_free=17.3, wall=19596
2023-08-08 19:10:08 | INFO | train_inner | epoch 019:    280 / 1474 loss=2.086, trans_loss=5.033, nll_loss=2.236, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.048, total=4187.34, n_correct=2705.02, ppl=4.71, accuracy=64.6, wps=14968.5, ups=1.79, wpb=8374.7, bsz=306.4, num_updates=26800, lr=8.63868e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=56, gb_free=16.2, wall=19652
2023-08-08 19:11:04 | INFO | train_inner | epoch 019:    380 / 1474 loss=2.104, trans_loss=5.038, nll_loss=2.243, w2v_ctc_loss=0.686, task_loss=0, contrastive_loss=0.155, total=4170.52, n_correct=2689.77, ppl=4.73, accuracy=64.495, wps=15029.6, ups=1.8, wpb=8341, bsz=311, num_updates=26900, lr=8.62261e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=55, gb_free=16.6, wall=19708
2023-08-08 19:11:59 | INFO | train_inner | epoch 019:    480 / 1474 loss=2.096, trans_loss=5.047, nll_loss=2.255, w2v_ctc_loss=0.699, task_loss=0, contrastive_loss=0.062, total=4113.89, n_correct=2644.23, ppl=4.77, accuracy=64.276, wps=14874.7, ups=1.81, wpb=8227.8, bsz=301.5, num_updates=27000, lr=8.60663e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=55, gb_free=17.5, wall=19763
2023-08-08 19:12:54 | INFO | train_inner | epoch 019:    580 / 1474 loss=2.098, trans_loss=5.043, nll_loss=2.25, w2v_ctc_loss=0.691, task_loss=0, contrastive_loss=0.125, total=4128.58, n_correct=2657.39, ppl=4.76, accuracy=64.366, wps=14868.9, ups=1.8, wpb=8257.2, bsz=306.2, num_updates=27100, lr=8.59074e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=19818
2023-08-08 19:13:50 | INFO | train_inner | epoch 019:    680 / 1474 loss=2.084, trans_loss=5.044, nll_loss=2.252, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.054, total=4201.56, n_correct=2708.5, ppl=4.76, accuracy=64.464, wps=15137.4, ups=1.8, wpb=8403.1, bsz=321.5, num_updates=27200, lr=8.57493e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=55, gb_free=18.1, wall=19874
2023-08-08 19:14:46 | INFO | train_inner | epoch 019:    780 / 1474 loss=2.095, trans_loss=5.046, nll_loss=2.253, w2v_ctc_loss=0.701, task_loss=0, contrastive_loss=0.058, total=4124.03, n_correct=2653.61, ppl=4.77, accuracy=64.345, wps=14751.1, ups=1.79, wpb=8248.1, bsz=299, num_updates=27300, lr=8.55921e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=55, gb_free=17.8, wall=19930
2023-08-08 19:15:42 | INFO | train_inner | epoch 019:    880 / 1474 loss=2.1, trans_loss=5.059, nll_loss=2.271, w2v_ctc_loss=0.7, task_loss=0, contrastive_loss=0.056, total=4177.8, n_correct=2676.27, ppl=4.83, accuracy=64.059, wps=14931, ups=1.79, wpb=8355.6, bsz=309.6, num_updates=27400, lr=8.54358e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=55, gb_free=15.2, wall=19986
2023-08-08 19:16:38 | INFO | train_inner | epoch 019:    980 / 1474 loss=2.133, trans_loss=5.067, nll_loss=2.283, w2v_ctc_loss=0.696, task_loss=0, contrastive_loss=0.285, total=4084.26, n_correct=2609.15, ppl=4.87, accuracy=63.883, wps=14432.1, ups=1.77, wpb=8168.5, bsz=305.8, num_updates=27500, lr=8.52803e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=56, gb_free=16.3, wall=20042
2023-08-08 19:17:34 | INFO | train_inner | epoch 019:   1080 / 1474 loss=2.106, trans_loss=5.066, nll_loss=2.281, w2v_ctc_loss=0.695, task_loss=0, contrastive_loss=0.092, total=4042.73, n_correct=2586.56, ppl=4.86, accuracy=63.981, wps=14509, ups=1.79, wpb=8085.5, bsz=294, num_updates=27600, lr=8.51257e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=55, gb_free=17.6, wall=20098
2023-08-08 19:18:30 | INFO | train_inner | epoch 019:   1180 / 1474 loss=2.126, trans_loss=5.068, nll_loss=2.284, w2v_ctc_loss=0.705, task_loss=0, contrastive_loss=0.175, total=4140.95, n_correct=2639.13, ppl=4.87, accuracy=63.732, wps=14778.1, ups=1.78, wpb=8281.9, bsz=307.9, num_updates=27700, lr=8.49719e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=56, gb_free=13.3, wall=20154
2023-08-08 19:19:26 | INFO | train_inner | epoch 019:   1280 / 1474 loss=2.101, trans_loss=5.068, nll_loss=2.283, w2v_ctc_loss=0.688, task_loss=0, contrastive_loss=0.073, total=4135.79, n_correct=2648.28, ppl=4.87, accuracy=64.033, wps=14896.9, ups=1.8, wpb=8271.6, bsz=299.5, num_updates=27800, lr=8.48189e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=55, gb_free=18.1, wall=20210
2023-08-08 19:20:22 | INFO | train_inner | epoch 019:   1380 / 1474 loss=2.1, trans_loss=5.061, nll_loss=2.275, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.06, total=4138.67, n_correct=2650.6, ppl=4.84, accuracy=64.045, wps=14826.7, ups=1.79, wpb=8277.3, bsz=301.6, num_updates=27900, lr=8.46668e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=55, gb_free=16.8, wall=20266
2023-08-08 19:21:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 19:21:37 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.384 | trans_loss 5.557 | nll_loss 2.833 | w2v_ctc_loss 1.429 | task_loss 0 | contrastive_loss 0.247 | total 4003.4 | n_correct 2482.1 | ppl 7.13 | accuracy 62 | uer 17.424 | wer 19.153 | raw_wer 19.153 | bleu 20.22 | wps 2273 | wpb 4003.4 | bsz 141.8 | num_updates 27994 | best_bleu 20.22
2023-08-08 19:21:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27994 updates
2023-08-08 19:21:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 19:21:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 19:22:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt (epoch 19 @ 27994 updates, score 20.22) (writing took 24.07254389859736 seconds)
2023-08-08 19:22:02 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-08 19:22:02 | INFO | train | epoch 019 | loss 2.102 | trans_loss 5.051 | nll_loss 2.26 | w2v_ctc_loss 0.695 | task_loss 0 | contrastive_loss 0.103 | total 4138.65 | n_correct 2658.1 | ppl 4.79 | accuracy 64.226 | wps 13895.3 | ups 1.68 | wpb 8277.3 | bsz 305.7 | num_updates 27994 | lr 8.45245e-05 | gnorm 0.545 | clip 0 | loss_scale 32 | train_wall 815 | gb_free 17.7 | wall 20366
2023-08-08 19:22:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 19:22:02 | INFO | fairseq.trainer | begin training epoch 20
2023-08-08 19:22:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 19:22:12 | INFO | train_inner | epoch 020:      6 / 1474 loss=2.105, trans_loss=5.055, nll_loss=2.267, w2v_ctc_loss=0.689, task_loss=0, contrastive_loss=0.145, total=4117.61, n_correct=2642.96, ppl=4.81, accuracy=64.187, wps=7429.7, ups=0.9, wpb=8235.2, bsz=303, num_updates=28000, lr=8.45154e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=55, gb_free=16.7, wall=20376
2023-08-08 19:22:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 19:22:34 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.372 | trans_loss 5.559 | nll_loss 2.832 | w2v_ctc_loss 1.386 | task_loss 0 | contrastive_loss 0.245 | total 4003.4 | n_correct 2486.6 | ppl 7.12 | accuracy 62.112 | uer 17.461 | wer 19.175 | raw_wer 19.175 | bleu 20.32 | wps 2250.3 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.32
2023-08-08 19:22:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-08-08 19:22:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_20_28000.pt
2023-08-08 19:22:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_20_28000.pt
2023-08-08 19:22:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 20.32) (writing took 24.834985613822937 seconds)
2023-08-08 19:23:56 | INFO | train_inner | epoch 020:    106 / 1474 loss=2.076, trans_loss=5.017, nll_loss=2.216, w2v_ctc_loss=0.677, task_loss=0, contrastive_loss=0.064, total=4192.82, n_correct=2724.64, ppl=4.65, accuracy=64.983, wps=8063.8, ups=0.96, wpb=8385.6, bsz=312.8, num_updates=28100, lr=8.43649e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=56, gb_free=16.5, wall=20480
2023-08-08 19:24:53 | INFO | train_inner | epoch 020:    206 / 1474 loss=2.088, trans_loss=5.027, nll_loss=2.229, w2v_ctc_loss=0.683, task_loss=0, contrastive_loss=0.117, total=4155.9, n_correct=2689.68, ppl=4.69, accuracy=64.72, wps=14784.2, ups=1.78, wpb=8311.8, bsz=302.3, num_updates=28200, lr=8.42152e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=56, gb_free=12.3, wall=20537
2023-08-08 19:25:48 | INFO | train_inner | epoch 020:    306 / 1474 loss=2.08, trans_loss=5.02, nll_loss=2.221, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.057, total=4192.69, n_correct=2722.71, ppl=4.66, accuracy=64.939, wps=15107, ups=1.8, wpb=8385.4, bsz=327.6, num_updates=28300, lr=8.40663e-05, gnorm=0.544, clip=0, loss_scale=64, train_wall=55, gb_free=17.3, wall=20592
2023-08-08 19:26:43 | INFO | train_inner | epoch 020:    406 / 1474 loss=2.079, trans_loss=5.028, nll_loss=2.231, w2v_ctc_loss=0.678, task_loss=0, contrastive_loss=0.055, total=4116.96, n_correct=2667, ppl=4.69, accuracy=64.781, wps=14925.2, ups=1.81, wpb=8233.9, bsz=296.8, num_updates=28400, lr=8.39181e-05, gnorm=0.545, clip=0, loss_scale=64, train_wall=55, gb_free=13.2, wall=20647
2023-08-08 19:27:39 | INFO | train_inner | epoch 020:    506 / 1474 loss=2.097, trans_loss=5.043, nll_loss=2.25, w2v_ctc_loss=0.682, task_loss=0, contrastive_loss=0.142, total=4100.73, n_correct=2641.06, ppl=4.76, accuracy=64.405, wps=14727.5, ups=1.8, wpb=8201.5, bsz=298.4, num_updates=28500, lr=8.37708e-05, gnorm=0.545, clip=0, loss_scale=64, train_wall=55, gb_free=16.5, wall=20703
2023-08-08 19:27:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-08 19:28:35 | INFO | train_inner | epoch 020:    607 / 1474 loss=2.095, trans_loss=5.041, nll_loss=2.247, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.098, total=4090.01, n_correct=2632.13, ppl=4.75, accuracy=64.355, wps=14534.3, ups=1.78, wpb=8180, bsz=293.7, num_updates=28600, lr=8.36242e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=56, gb_free=12.5, wall=20759
2023-08-08 19:29:31 | INFO | train_inner | epoch 020:    707 / 1474 loss=2.088, trans_loss=5.042, nll_loss=2.249, w2v_ctc_loss=0.693, task_loss=0, contrastive_loss=0.049, total=4140.23, n_correct=2667.76, ppl=4.75, accuracy=64.435, wps=14950.3, ups=1.81, wpb=8280.5, bsz=300.6, num_updates=28700, lr=8.34784e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=55, gb_free=16.4, wall=20815
2023-08-08 19:30:26 | INFO | train_inner | epoch 020:    807 / 1474 loss=2.088, trans_loss=5.042, nll_loss=2.249, w2v_ctc_loss=0.693, task_loss=0, contrastive_loss=0.052, total=4140.66, n_correct=2673.49, ppl=4.75, accuracy=64.567, wps=14940.4, ups=1.8, wpb=8281.3, bsz=305.6, num_updates=28800, lr=8.33333e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=55, gb_free=17.8, wall=20870
2023-08-08 19:31:22 | INFO | train_inner | epoch 020:    907 / 1474 loss=2.138, trans_loss=5.052, nll_loss=2.264, w2v_ctc_loss=0.692, task_loss=0, contrastive_loss=0.343, total=4157.15, n_correct=2667.58, ppl=4.8, accuracy=64.168, wps=14803.1, ups=1.78, wpb=8314.3, bsz=322.6, num_updates=28900, lr=8.3189e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=56, gb_free=18, wall=20926
2023-08-08 19:32:18 | INFO | train_inner | epoch 020:   1007 / 1474 loss=2.085, trans_loss=5.042, nll_loss=2.25, w2v_ctc_loss=0.68, task_loss=0, contrastive_loss=0.058, total=4171.86, n_correct=2690.95, ppl=4.76, accuracy=64.502, wps=14896.6, ups=1.79, wpb=8343.7, bsz=308.6, num_updates=29000, lr=8.30455e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=56, gb_free=15.9, wall=20982
2023-08-08 19:33:14 | INFO | train_inner | epoch 020:   1107 / 1474 loss=2.111, trans_loss=5.049, nll_loss=2.259, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.189, total=4162.96, n_correct=2679.47, ppl=4.79, accuracy=64.365, wps=14955.1, ups=1.8, wpb=8325.9, bsz=314.9, num_updates=29100, lr=8.29027e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=55, gb_free=17.3, wall=21038
2023-08-08 19:34:09 | INFO | train_inner | epoch 020:   1207 / 1474 loss=2.09, trans_loss=5.043, nll_loss=2.251, w2v_ctc_loss=0.699, task_loss=0, contrastive_loss=0.047, total=4033.74, n_correct=2593.9, ppl=4.76, accuracy=64.305, wps=14562.5, ups=1.81, wpb=8067.5, bsz=285.2, num_updates=29200, lr=8.27606e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=55, gb_free=17.5, wall=21093
2023-08-08 19:35:05 | INFO | train_inner | epoch 020:   1307 / 1474 loss=2.089, trans_loss=5.053, nll_loss=2.264, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.051, total=4124.42, n_correct=2653.42, ppl=4.8, accuracy=64.334, wps=14760.2, ups=1.79, wpb=8248.8, bsz=297, num_updates=29300, lr=8.26192e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=55, gb_free=16.2, wall=21149
2023-08-08 19:36:01 | INFO | train_inner | epoch 020:   1407 / 1474 loss=2.089, trans_loss=5.052, nll_loss=2.262, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.05, total=4114.1, n_correct=2645.06, ppl=4.8, accuracy=64.293, wps=14750, ups=1.79, wpb=8228.2, bsz=293.7, num_updates=29400, lr=8.24786e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=55, gb_free=14.9, wall=21205
2023-08-08 19:36:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 19:37:02 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.359 | trans_loss 5.554 | nll_loss 2.829 | w2v_ctc_loss 1.353 | task_loss 0 | contrastive_loss 0.247 | total 4003.4 | n_correct 2481.6 | ppl 7.11 | accuracy 61.987 | uer 17.27 | wer 19.186 | raw_wer 19.186 | bleu 20.06 | wps 2058.4 | wpb 4003.4 | bsz 141.8 | num_updates 29467 | best_bleu 20.32
2023-08-08 19:37:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29467 updates
2023-08-08 19:37:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_20.0603.pt
2023-08-08 19:37:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_20.0603.pt
2023-08-08 19:37:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_20.0603.pt (epoch 20 @ 29467 updates, score 20.06) (writing took 16.6878079790622 seconds)
2023-08-08 19:37:19 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-08 19:37:19 | INFO | train | epoch 020 | loss 2.093 | trans_loss 5.04 | nll_loss 2.247 | w2v_ctc_loss 0.687 | task_loss 0 | contrastive_loss 0.099 | total 4138.21 | n_correct 2669.22 | ppl 4.75 | accuracy 64.502 | wps 13284.8 | ups 1.61 | wpb 8276.4 | bsz 305.5 | num_updates 29467 | lr 8.23848e-05 | gnorm 0.546 | clip 0 | loss_scale 32 | train_wall 814 | gb_free 16.4 | wall 21283
2023-08-08 19:37:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 19:37:20 | INFO | fairseq.trainer | begin training epoch 21
2023-08-08 19:37:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 19:37:47 | INFO | train_inner | epoch 021:     33 / 1474 loss=2.105, trans_loss=5.045, nll_loss=2.254, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.169, total=4155.01, n_correct=2674.62, ppl=4.77, accuracy=64.371, wps=7875.2, ups=0.95, wpb=8310, bsz=317.6, num_updates=29500, lr=8.23387e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=55, gb_free=16.6, wall=21311
2023-08-08 19:38:42 | INFO | train_inner | epoch 021:    133 / 1474 loss=2.087, trans_loss=5.01, nll_loss=2.207, w2v_ctc_loss=0.675, task_loss=0, contrastive_loss=0.161, total=4186.67, n_correct=2721.42, ppl=4.62, accuracy=65.002, wps=14971.4, ups=1.79, wpb=8373.3, bsz=317.4, num_updates=29600, lr=8.21995e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=55, gb_free=13.5, wall=21367
2023-08-08 19:39:38 | INFO | train_inner | epoch 021:    233 / 1474 loss=2.074, trans_loss=5.015, nll_loss=2.214, w2v_ctc_loss=0.665, task_loss=0, contrastive_loss=0.114, total=4166.37, n_correct=2711.15, ppl=4.64, accuracy=65.072, wps=14945.5, ups=1.79, wpb=8332.7, bsz=315.2, num_updates=29700, lr=8.2061e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=55, gb_free=14.5, wall=21422
2023-08-08 19:40:34 | INFO | train_inner | epoch 021:    333 / 1474 loss=2.084, trans_loss=5.018, nll_loss=2.218, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.113, total=4132.25, n_correct=2680.12, ppl=4.65, accuracy=64.859, wps=14720.3, ups=1.78, wpb=8264.5, bsz=305, num_updates=29800, lr=8.19232e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=56, gb_free=17, wall=21478
2023-08-08 19:41:30 | INFO | train_inner | epoch 021:    433 / 1474 loss=2.069, trans_loss=5.019, nll_loss=2.219, w2v_ctc_loss=0.668, task_loss=0, contrastive_loss=0.049, total=4195.53, n_correct=2725.82, ppl=4.65, accuracy=64.97, wps=15113.7, ups=1.8, wpb=8391.1, bsz=311.6, num_updates=29900, lr=8.17861e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=55, gb_free=16.6, wall=21534
2023-08-08 19:42:26 | INFO | train_inner | epoch 021:    533 / 1474 loss=2.07, trans_loss=5.017, nll_loss=2.216, w2v_ctc_loss=0.678, task_loss=0, contrastive_loss=0.044, total=4085.05, n_correct=2651.89, ppl=4.65, accuracy=64.917, wps=14679.1, ups=1.8, wpb=8170.1, bsz=296.1, num_updates=30000, lr=8.16497e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=55, gb_free=16.6, wall=21590
2023-08-08 19:42:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 19:42:48 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.364 | trans_loss 5.563 | nll_loss 2.837 | w2v_ctc_loss 1.346 | task_loss 0 | contrastive_loss 0.247 | total 4003.4 | n_correct 2481.1 | ppl 7.14 | accuracy 61.975 | uer 17.312 | wer 19.086 | raw_wer 19.086 | bleu 20.02 | wps 2220.8 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.32
2023-08-08 19:42:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-08-08 19:42:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_21_30000.pt
2023-08-08 19:42:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_21_30000.pt
2023-08-08 19:43:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 20.02) (writing took 35.51231128722429 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:0')
2023-08-08 19:44:21 | INFO | train_inner | epoch 021:    633 / 1474 loss=2.094, trans_loss=5.025, nll_loss=2.227, w2v_ctc_loss=0.671, task_loss=0, contrastive_loss=0.214, total=4220.3, n_correct=2736.66, ppl=4.68, accuracy=64.845, wps=7315.4, ups=0.87, wpb=8440.6, bsz=315.8, num_updates=30100, lr=8.15139e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=56, gb_free=16, wall=21705
2023-08-08 19:45:17 | INFO | train_inner | epoch 021:    733 / 1474 loss=2.084, trans_loss=5.036, nll_loss=2.242, w2v_ctc_loss=0.677, task_loss=0, contrastive_loss=0.073, total=4148.18, n_correct=2679.2, ppl=4.73, accuracy=64.587, wps=14868.2, ups=1.79, wpb=8296.4, bsz=308.3, num_updates=30200, lr=8.13788e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=55, gb_free=12.4, wall=21761
2023-08-08 19:46:13 | INFO | train_inner | epoch 021:    833 / 1474 loss=2.088, trans_loss=5.039, nll_loss=2.245, w2v_ctc_loss=0.68, task_loss=0, contrastive_loss=0.087, total=4062.56, n_correct=2620.97, ppl=4.74, accuracy=64.515, wps=14529, ups=1.79, wpb=8125.1, bsz=293, num_updates=30300, lr=8.12444e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=55, gb_free=16.5, wall=21817
2023-08-08 19:47:08 | INFO | train_inner | epoch 021:    933 / 1474 loss=2.079, trans_loss=5.029, nll_loss=2.233, w2v_ctc_loss=0.679, task_loss=0, contrastive_loss=0.06, total=4103.66, n_correct=2652.7, ppl=4.7, accuracy=64.642, wps=14850.5, ups=1.81, wpb=8207.3, bsz=301.5, num_updates=30400, lr=8.11107e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=55, gb_free=17.4, wall=21872
2023-08-08 19:48:04 | INFO | train_inner | epoch 021:   1033 / 1474 loss=2.085, trans_loss=5.046, nll_loss=2.255, w2v_ctc_loss=0.68, task_loss=0, contrastive_loss=0.058, total=4100.54, n_correct=2644.67, ppl=4.77, accuracy=64.496, wps=14747.5, ups=1.8, wpb=8201.1, bsz=298.2, num_updates=30500, lr=8.09776e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=55, gb_free=18.1, wall=21928
2023-08-08 19:48:59 | INFO | train_inner | epoch 021:   1133 / 1474 loss=2.081, trans_loss=5.035, nll_loss=2.24, w2v_ctc_loss=0.68, task_loss=0, contrastive_loss=0.061, total=4119.98, n_correct=2660.05, ppl=4.72, accuracy=64.565, wps=14887, ups=1.81, wpb=8240, bsz=294, num_updates=30600, lr=8.08452e-05, gnorm=0.549, clip=0, loss_scale=64, train_wall=55, gb_free=18.1, wall=21983
2023-08-08 19:49:54 | INFO | train_inner | epoch 021:   1233 / 1474 loss=2.088, trans_loss=5.034, nll_loss=2.24, w2v_ctc_loss=0.677, task_loss=0, contrastive_loss=0.111, total=4161.49, n_correct=2692.94, ppl=4.72, accuracy=64.711, wps=15018.6, ups=1.8, wpb=8323, bsz=313, num_updates=30700, lr=8.07134e-05, gnorm=0.549, clip=0, loss_scale=64, train_wall=55, gb_free=17, wall=22038
2023-08-08 19:50:50 | INFO | train_inner | epoch 021:   1333 / 1474 loss=2.086, trans_loss=5.037, nll_loss=2.246, w2v_ctc_loss=0.683, task_loss=0, contrastive_loss=0.073, total=4141.76, n_correct=2678.08, ppl=4.74, accuracy=64.66, wps=14905.1, ups=1.8, wpb=8283.5, bsz=311.7, num_updates=30800, lr=8.05823e-05, gnorm=0.55, clip=0, loss_scale=64, train_wall=55, gb_free=17.6, wall=22094
2023-08-08 19:51:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-08 19:51:47 | INFO | train_inner | epoch 021:   1434 / 1474 loss=2.094, trans_loss=5.046, nll_loss=2.255, w2v_ctc_loss=0.7, task_loss=0, contrastive_loss=0.062, total=4116, n_correct=2647.34, ppl=4.77, accuracy=64.318, wps=14412, ups=1.75, wpb=8232, bsz=296.9, num_updates=30900, lr=8.04518e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=57, gb_free=15.9, wall=22151
2023-08-08 19:52:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:6')
2023-08-08 19:52:33 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.37 | trans_loss 5.568 | nll_loss 2.846 | w2v_ctc_loss 1.346 | task_loss 0 | contrastive_loss 0.255 | total 4003.4 | n_correct 2479.6 | ppl 7.19 | accuracy 61.937 | uer 17.58 | wer 19.444 | raw_wer 19.444 | bleu 19.92 | wps 2216.4 | wpb 4003.4 | bsz 141.8 | num_updates 30940 | best_bleu 20.32
2023-08-08 19:52:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30940 updates
2023-08-08 19:52:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.9208.pt
2023-08-08 19:52:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.9208.pt
2023-08-08 19:52:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.9208.pt (epoch 21 @ 30940 updates, score 19.92) (writing took 14.206263612955809 seconds)
2023-08-08 19:52:47 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-08 19:52:47 | INFO | train | epoch 021 | loss 2.084 | trans_loss 5.029 | nll_loss 2.233 | w2v_ctc_loss 0.678 | task_loss 0 | contrastive_loss 0.096 | total 4137.4 | n_correct 2677.83 | ppl 4.7 | accuracy 64.723 | wps 13135.2 | ups 1.59 | wpb 8274.8 | bsz 305.2 | num_updates 30940 | lr 8.03998e-05 | gnorm 0.546 | clip 0 | loss_scale 32 | train_wall 815 | gb_free 15.7 | wall 22211
2023-08-08 19:52:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 19:52:47 | INFO | fairseq.trainer | begin training epoch 22
2023-08-08 19:52:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 19:53:28 | INFO | train_inner | epoch 022:     60 / 1474 loss=2.07, trans_loss=5.016, nll_loss=2.215, w2v_ctc_loss=0.679, task_loss=0, contrastive_loss=0.044, total=4128.84, n_correct=2688.57, ppl=4.64, accuracy=65.117, wps=8184.9, ups=0.99, wpb=8257.7, bsz=297.7, num_updates=31000, lr=8.03219e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=55, gb_free=14.6, wall=22252
2023-08-08 19:54:24 | INFO | train_inner | epoch 022:    160 / 1474 loss=2.077, trans_loss=5.005, nll_loss=2.202, w2v_ctc_loss=0.672, task_loss=0, contrastive_loss=0.125, total=4123.35, n_correct=2687.84, ppl=4.6, accuracy=65.186, wps=14754.2, ups=1.79, wpb=8246.7, bsz=310.3, num_updates=31100, lr=8.01927e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=55, gb_free=15.1, wall=22308
2023-08-08 19:55:20 | INFO | train_inner | epoch 022:    260 / 1474 loss=2.06, trans_loss=4.999, nll_loss=2.195, w2v_ctc_loss=0.659, task_loss=0, contrastive_loss=0.065, total=4267.16, n_correct=2792.4, ppl=4.58, accuracy=65.439, wps=15288.4, ups=1.79, wpb=8534.3, bsz=329.9, num_updates=31200, lr=8.00641e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=22364
2023-08-08 19:55:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-08 19:56:17 | INFO | train_inner | epoch 022:    361 / 1474 loss=2.086, trans_loss=5.014, nll_loss=2.213, w2v_ctc_loss=0.675, task_loss=0, contrastive_loss=0.161, total=4163.56, n_correct=2708.16, ppl=4.64, accuracy=65.044, wps=14588.7, ups=1.75, wpb=8327.1, bsz=304, num_updates=31300, lr=7.99361e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=57, gb_free=15.5, wall=22421
2023-08-08 19:57:12 | INFO | train_inner | epoch 022:    461 / 1474 loss=2.081, trans_loss=5.021, nll_loss=2.221, w2v_ctc_loss=0.674, task_loss=0, contrastive_loss=0.103, total=4132.96, n_correct=2684.98, ppl=4.66, accuracy=64.965, wps=14904.3, ups=1.8, wpb=8265.9, bsz=297.5, num_updates=31400, lr=7.98087e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=55, gb_free=17.3, wall=22476
2023-08-08 19:58:08 | INFO | train_inner | epoch 022:    561 / 1474 loss=2.068, trans_loss=5.012, nll_loss=2.21, w2v_ctc_loss=0.673, task_loss=0, contrastive_loss=0.053, total=4158.17, n_correct=2709.44, ppl=4.63, accuracy=65.159, wps=14897.8, ups=1.79, wpb=8316.3, bsz=307.8, num_updates=31500, lr=7.96819e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=55, gb_free=16.9, wall=22532
2023-08-08 19:59:04 | INFO | train_inner | epoch 022:    661 / 1474 loss=2.074, trans_loss=5.009, nll_loss=2.208, w2v_ctc_loss=0.66, task_loss=0, contrastive_loss=0.138, total=4139.66, n_correct=2696.7, ppl=4.62, accuracy=65.143, wps=14921.1, ups=1.8, wpb=8279.3, bsz=311.1, num_updates=31600, lr=7.95557e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=55, gb_free=16.4, wall=22588
2023-08-08 19:59:59 | INFO | train_inner | epoch 022:    761 / 1474 loss=2.07, trans_loss=5.016, nll_loss=2.216, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.055, total=4167.89, n_correct=2708.31, ppl=4.65, accuracy=64.98, wps=14898.8, ups=1.79, wpb=8335.8, bsz=303.9, num_updates=31700, lr=7.94301e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=55, gb_free=13.3, wall=22644
2023-08-08 20:00:55 | INFO | train_inner | epoch 022:    861 / 1474 loss=2.073, trans_loss=5.026, nll_loss=2.229, w2v_ctc_loss=0.677, task_loss=0, contrastive_loss=0.044, total=4075.79, n_correct=2641.36, ppl=4.69, accuracy=64.806, wps=14608, ups=1.79, wpb=8151.6, bsz=289, num_updates=31800, lr=7.93052e-05, gnorm=0.553, clip=0, loss_scale=16, train_wall=55, gb_free=16.6, wall=22699
2023-08-08 20:01:51 | INFO | train_inner | epoch 022:    961 / 1474 loss=2.066, trans_loss=5.02, nll_loss=2.222, w2v_ctc_loss=0.665, task_loss=0, contrastive_loss=0.045, total=4134.72, n_correct=2688.49, ppl=4.66, accuracy=65.022, wps=14894.3, ups=1.8, wpb=8269.4, bsz=303.2, num_updates=31900, lr=7.91808e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=55, gb_free=14.7, wall=22755
2023-08-08 20:02:46 | INFO | train_inner | epoch 022:   1061 / 1474 loss=2.089, trans_loss=5.02, nll_loss=2.222, w2v_ctc_loss=0.668, task_loss=0, contrastive_loss=0.212, total=4160.57, n_correct=2703.42, ppl=4.66, accuracy=64.977, wps=14998.8, ups=1.8, wpb=8321.1, bsz=315.5, num_updates=32000, lr=7.90569e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=55, gb_free=17.5, wall=22810
2023-08-08 20:02:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 20:03:11 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.378 | trans_loss 5.559 | nll_loss 2.832 | w2v_ctc_loss 1.408 | task_loss 0 | contrastive_loss 0.24 | total 4003.4 | n_correct 2483.9 | ppl 7.12 | accuracy 62.045 | uer 17.193 | wer 19.045 | raw_wer 19.045 | bleu 19.76 | wps 1957.6 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.32
2023-08-08 20:03:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-08-08 20:03:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_22_32000.pt
2023-08-08 20:03:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_22_32000.pt
2023-08-08 20:03:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 19.76) (writing took 33.92122222110629 seconds)
2023-08-08 20:04:41 | INFO | train_inner | epoch 022:   1161 / 1474 loss=2.09, trans_loss=5.042, nll_loss=2.251, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.095, total=4099.59, n_correct=2646.33, ppl=4.76, accuracy=64.551, wps=7121.8, ups=0.87, wpb=8199.2, bsz=296.2, num_updates=32100, lr=7.89337e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=55, gb_free=15.4, wall=22926
2023-08-08 20:05:37 | INFO | train_inner | epoch 022:   1261 / 1474 loss=2.083, trans_loss=5.033, nll_loss=2.24, w2v_ctc_loss=0.675, task_loss=0, contrastive_loss=0.086, total=4182.05, n_correct=2709.01, ppl=4.72, accuracy=64.777, wps=15098.7, ups=1.81, wpb=8364.1, bsz=323, num_updates=32200, lr=7.8811e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=55, gb_free=15.8, wall=22981
2023-08-08 20:06:33 | INFO | train_inner | epoch 022:   1361 / 1474 loss=2.076, trans_loss=5.024, nll_loss=2.228, w2v_ctc_loss=0.666, task_loss=0, contrastive_loss=0.112, total=4062.31, n_correct=2636.86, ppl=4.69, accuracy=64.91, wps=14574, ups=1.79, wpb=8124.6, bsz=299, num_updates=32300, lr=7.86889e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=55, gb_free=15.4, wall=23037
2023-08-08 20:07:28 | INFO | train_inner | epoch 022:   1461 / 1474 loss=2.084, trans_loss=5.042, nll_loss=2.25, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.059, total=4081.88, n_correct=2633.12, ppl=4.76, accuracy=64.508, wps=14630.1, ups=1.79, wpb=8163.8, bsz=288.9, num_updates=32400, lr=7.85674e-05, gnorm=0.558, clip=0, loss_scale=16, train_wall=55, gb_free=17.5, wall=23092
2023-08-08 20:07:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 20:07:58 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.371 | trans_loss 5.552 | nll_loss 2.821 | w2v_ctc_loss 1.396 | task_loss 0 | contrastive_loss 0.244 | total 4003.4 | n_correct 2494.7 | ppl 7.07 | accuracy 62.315 | uer 17.371 | wer 19.235 | raw_wer 19.235 | bleu 20.34 | wps 2322 | wpb 4003.4 | bsz 141.8 | num_updates 32413 | best_bleu 20.34
2023-08-08 20:07:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32413 updates
2023-08-08 20:07:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 20:08:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt
2023-08-08 20:08:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_best.pt (epoch 22 @ 32413 updates, score 20.34) (writing took 24.443757759407163 seconds)
2023-08-08 20:08:23 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-08 20:08:23 | INFO | train | epoch 022 | loss 2.077 | trans_loss 5.019 | nll_loss 2.221 | w2v_ctc_loss 0.672 | task_loss 0 | contrastive_loss 0.095 | total 4137.49 | n_correct 2688.63 | ppl 4.66 | accuracy 64.982 | wps 13029.4 | ups 1.57 | wpb 8275 | bsz 305.2 | num_updates 32413 | lr 7.85517e-05 | gnorm 0.549 | clip 0 | loss_scale 16 | train_wall 814 | gb_free 12.3 | wall 23147
2023-08-08 20:08:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 20:08:23 | INFO | fairseq.trainer | begin training epoch 23
2023-08-08 20:08:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 20:09:20 | INFO | train_inner | epoch 023:     87 / 1474 loss=2.059, trans_loss=4.994, nll_loss=2.188, w2v_ctc_loss=0.67, task_loss=0, contrastive_loss=0.05, total=4096.09, n_correct=2681.18, ppl=4.56, accuracy=65.457, wps=7363.6, ups=0.9, wpb=8192.2, bsz=301.2, num_updates=32500, lr=7.84465e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=56, gb_free=16.6, wall=23204
2023-08-08 20:10:15 | INFO | train_inner | epoch 023:    187 / 1474 loss=2.054, trans_loss=4.993, nll_loss=2.185, w2v_ctc_loss=0.657, task_loss=0, contrastive_loss=0.048, total=4107.77, n_correct=2691.74, ppl=4.55, accuracy=65.528, wps=14751.9, ups=1.8, wpb=8215.5, bsz=293.4, num_updates=32600, lr=7.8326e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=55, gb_free=16.7, wall=23259
2023-08-08 20:11:11 | INFO | train_inner | epoch 023:    287 / 1474 loss=2.067, trans_loss=5.001, nll_loss=2.196, w2v_ctc_loss=0.654, task_loss=0, contrastive_loss=0.123, total=4153.12, n_correct=2712.11, ppl=4.58, accuracy=65.303, wps=14795.6, ups=1.78, wpb=8306.2, bsz=306.4, num_updates=32700, lr=7.82062e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=56, gb_free=17.2, wall=23316
2023-08-08 20:12:07 | INFO | train_inner | epoch 023:    387 / 1474 loss=2.057, trans_loss=5.002, nll_loss=2.197, w2v_ctc_loss=0.661, task_loss=0, contrastive_loss=0.041, total=4116.7, n_correct=2689.31, ppl=4.58, accuracy=65.327, wps=14881.1, ups=1.81, wpb=8233.4, bsz=294, num_updates=32800, lr=7.80869e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=55, gb_free=15.7, wall=23371
2023-08-08 20:13:03 | INFO | train_inner | epoch 023:    487 / 1474 loss=2.071, trans_loss=5.005, nll_loss=2.203, w2v_ctc_loss=0.667, task_loss=0, contrastive_loss=0.097, total=4157.6, n_correct=2711.61, ppl=4.6, accuracy=65.221, wps=14915.6, ups=1.79, wpb=8315.2, bsz=313.5, num_updates=32900, lr=7.79681e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=55, gb_free=17.6, wall=23427
2023-08-08 20:13:58 | INFO | train_inner | epoch 023:    587 / 1474 loss=2.052, trans_loss=4.995, nll_loss=2.189, w2v_ctc_loss=0.656, task_loss=0, contrastive_loss=0.046, total=4173.42, n_correct=2733.52, ppl=4.56, accuracy=65.498, wps=15029.8, ups=1.8, wpb=8346.8, bsz=316, num_updates=33000, lr=7.78499e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=55, gb_free=13.1, wall=23482
2023-08-08 20:14:54 | INFO | train_inner | epoch 023:    687 / 1474 loss=2.064, trans_loss=5.002, nll_loss=2.198, w2v_ctc_loss=0.661, task_loss=0, contrastive_loss=0.083, total=4137.82, n_correct=2704.43, ppl=4.59, accuracy=65.359, wps=14889.9, ups=1.8, wpb=8275.6, bsz=302.5, num_updates=33100, lr=7.77322e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=55, gb_free=17.4, wall=23538
2023-08-08 20:15:49 | INFO | train_inner | epoch 023:    787 / 1474 loss=2.067, trans_loss=5.013, nll_loss=2.212, w2v_ctc_loss=0.667, task_loss=0, contrastive_loss=0.064, total=4150.99, n_correct=2704.24, ppl=4.63, accuracy=65.147, wps=14996, ups=1.81, wpb=8302, bsz=305.4, num_updates=33200, lr=7.76151e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=55, gb_free=16.5, wall=23593
2023-08-08 20:16:45 | INFO | train_inner | epoch 023:    887 / 1474 loss=2.074, trans_loss=5.006, nll_loss=2.204, w2v_ctc_loss=0.662, task_loss=0, contrastive_loss=0.14, total=4181.99, n_correct=2733.16, ppl=4.61, accuracy=65.355, wps=14984, ups=1.79, wpb=8364, bsz=324.7, num_updates=33300, lr=7.74984e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=55, gb_free=16.7, wall=23649
2023-08-08 20:17:41 | INFO | train_inner | epoch 023:    987 / 1474 loss=2.092, trans_loss=5.011, nll_loss=2.211, w2v_ctc_loss=0.654, task_loss=0, contrastive_loss=0.304, total=4168.73, n_correct=2715.82, ppl=4.63, accuracy=65.147, wps=14858.2, ups=1.78, wpb=8337.5, bsz=310.5, num_updates=33400, lr=7.73823e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=56, gb_free=11.5, wall=23705
2023-08-08 20:18:37 | INFO | train_inner | epoch 023:   1087 / 1474 loss=2.07, trans_loss=5.018, nll_loss=2.219, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.052, total=4088.49, n_correct=2660.46, ppl=4.66, accuracy=65.072, wps=14673.6, ups=1.79, wpb=8177, bsz=290, num_updates=33500, lr=7.72667e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=55, gb_free=16.1, wall=23761
2023-08-08 20:19:33 | INFO | train_inner | epoch 023:   1187 / 1474 loss=2.066, trans_loss=5.018, nll_loss=2.22, w2v_ctc_loss=0.669, task_loss=0, contrastive_loss=0.046, total=4162.7, n_correct=2706.35, ppl=4.66, accuracy=65.014, wps=14880.4, ups=1.79, wpb=8325.4, bsz=309.3, num_updates=33600, lr=7.71517e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=55, gb_free=16.3, wall=23817
2023-08-08 20:20:28 | INFO | train_inner | epoch 023:   1287 / 1474 loss=2.062, trans_loss=5.015, nll_loss=2.216, w2v_ctc_loss=0.658, task_loss=0, contrastive_loss=0.056, total=4135.53, n_correct=2697.1, ppl=4.65, accuracy=65.218, wps=14950.1, ups=1.81, wpb=8271.1, bsz=308.9, num_updates=33700, lr=7.70371e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=55, gb_free=17.1, wall=23872
2023-08-08 20:21:24 | INFO | train_inner | epoch 023:   1387 / 1474 loss=2.084, trans_loss=5.036, nll_loss=2.244, w2v_ctc_loss=0.669, task_loss=0, contrastive_loss=0.111, total=4143.98, n_correct=2684.05, ppl=4.74, accuracy=64.77, wps=14776.9, ups=1.78, wpb=8288, bsz=305.2, num_updates=33800, lr=7.69231e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=56, gb_free=16.2, wall=23928
2023-08-08 20:22:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 20:22:35 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.368 | trans_loss 5.556 | nll_loss 2.83 | w2v_ctc_loss 1.384 | task_loss 0 | contrastive_loss 0.243 | total 4003.4 | n_correct 2482.2 | ppl 7.11 | accuracy 62.002 | uer 16.946 | wer 18.694 | raw_wer 18.694 | bleu 19.92 | wps 2243.7 | wpb 4003.4 | bsz 141.8 | num_updates 33887 | best_bleu 20.34
2023-08-08 20:22:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33887 updates
2023-08-08 20:22:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.9209.pt
2023-08-08 20:22:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.9209.pt
2023-08-08 20:22:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.9209.pt (epoch 23 @ 33887 updates, score 19.92) (writing took 13.950567403808236 seconds)
2023-08-08 20:22:49 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-08 20:22:49 | INFO | train | epoch 023 | loss 2.069 | trans_loss 5.009 | nll_loss 2.208 | w2v_ctc_loss 0.663 | task_loss 0 | contrastive_loss 0.098 | total 4138.65 | n_correct 2699.29 | ppl 4.62 | accuracy 65.222 | wps 14081.8 | ups 1.7 | wpb 8277.3 | bsz 305.7 | num_updates 33887 | lr 7.68243e-05 | gnorm 0.549 | clip 0 | loss_scale 32 | train_wall 814 | gb_free 14.1 | wall 24013
2023-08-08 20:22:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 20:22:49 | INFO | fairseq.trainer | begin training epoch 24
2023-08-08 20:22:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 20:23:04 | INFO | train_inner | epoch 024:     13 / 1474 loss=2.089, trans_loss=5.023, nll_loss=2.227, w2v_ctc_loss=0.661, task_loss=0, contrastive_loss=0.189, total=4085.11, n_correct=2654.41, ppl=4.68, accuracy=64.978, wps=8170.3, ups=1, wpb=8170.2, bsz=304.2, num_updates=33900, lr=7.68095e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=55, gb_free=13.1, wall=24028
2023-08-08 20:24:00 | INFO | train_inner | epoch 024:    113 / 1474 loss=2.071, trans_loss=4.981, nll_loss=2.171, w2v_ctc_loss=0.651, task_loss=0, contrastive_loss=0.207, total=4171.44, n_correct=2739.16, ppl=4.5, accuracy=65.665, wps=14840.9, ups=1.78, wpb=8342.9, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=56, gb_free=16.7, wall=24084
2023-08-08 20:24:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 20:24:24 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.364 | trans_loss 5.561 | nll_loss 2.83 | w2v_ctc_loss 1.358 | task_loss 0 | contrastive_loss 0.243 | total 4003.4 | n_correct 2485 | ppl 7.11 | accuracy 62.072 | uer 17.087 | wer 18.899 | raw_wer 18.899 | bleu 19.96 | wps 2136.5 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.34
2023-08-08 20:24:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-08-08 20:24:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_24_34000.pt
2023-08-08 20:24:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_24_34000.pt
2023-08-08 20:24:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 19.96) (writing took 33.730746326968074 seconds)
2023-08-08 20:25:54 | INFO | train_inner | epoch 024:    213 / 1474 loss=2.076, trans_loss=4.986, nll_loss=2.179, w2v_ctc_loss=0.64, task_loss=0, contrastive_loss=0.259, total=4251.29, n_correct=2794.56, ppl=4.53, accuracy=65.734, wps=7447, ups=0.88, wpb=8502.6, bsz=340.8, num_updates=34100, lr=7.6584e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=56, gb_free=17, wall=24199
2023-08-08 20:26:50 | INFO | train_inner | epoch 024:    313 / 1474 loss=2.049, trans_loss=4.99, nll_loss=2.182, w2v_ctc_loss=0.654, task_loss=0, contrastive_loss=0.043, total=4128.18, n_correct=2711.36, ppl=4.54, accuracy=65.679, wps=14813.4, ups=1.79, wpb=8256.4, bsz=305.5, num_updates=34200, lr=7.64719e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=55, gb_free=16.5, wall=24254
2023-08-08 20:27:46 | INFO | train_inner | epoch 024:    413 / 1474 loss=2.081, trans_loss=4.998, nll_loss=2.193, w2v_ctc_loss=0.665, task_loss=0, contrastive_loss=0.182, total=4158.92, n_correct=2716.36, ppl=4.57, accuracy=65.314, wps=14892.2, ups=1.79, wpb=8317.8, bsz=299.7, num_updates=34300, lr=7.63604e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=24310
2023-08-08 20:28:42 | INFO | train_inner | epoch 024:    513 / 1474 loss=2.062, trans_loss=4.995, nll_loss=2.188, w2v_ctc_loss=0.659, task_loss=0, contrastive_loss=0.11, total=4144.91, n_correct=2714.91, ppl=4.56, accuracy=65.5, wps=14782, ups=1.78, wpb=8289.8, bsz=303.3, num_updates=34400, lr=7.62493e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=56, gb_free=17.2, wall=24366
2023-08-08 20:29:38 | INFO | train_inner | epoch 024:    613 / 1474 loss=2.053, trans_loss=4.993, nll_loss=2.187, w2v_ctc_loss=0.649, task_loss=0, contrastive_loss=0.071, total=4165.3, n_correct=2730.1, ppl=4.55, accuracy=65.544, wps=15056.3, ups=1.81, wpb=8330.6, bsz=307.7, num_updates=34500, lr=7.61387e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=55, gb_free=15.9, wall=24422
2023-08-08 20:30:33 | INFO | train_inner | epoch 024:    713 / 1474 loss=2.063, trans_loss=5.007, nll_loss=2.204, w2v_ctc_loss=0.658, task_loss=0, contrastive_loss=0.087, total=4102.21, n_correct=2681.36, ppl=4.61, accuracy=65.364, wps=14669.2, ups=1.79, wpb=8204.4, bsz=295.1, num_updates=34600, lr=7.60286e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=55, gb_free=17.1, wall=24478
2023-08-08 20:31:29 | INFO | train_inner | epoch 024:    813 / 1474 loss=2.058, trans_loss=5.006, nll_loss=2.204, w2v_ctc_loss=0.655, task_loss=0, contrastive_loss=0.062, total=4110.6, n_correct=2687.84, ppl=4.61, accuracy=65.388, wps=14672.1, ups=1.78, wpb=8221.2, bsz=305.3, num_updates=34700, lr=7.5919e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=56, gb_free=16.7, wall=24534
2023-08-08 20:32:26 | INFO | train_inner | epoch 024:    913 / 1474 loss=2.063, trans_loss=5.016, nll_loss=2.215, w2v_ctc_loss=0.667, task_loss=0, contrastive_loss=0.039, total=4043.03, n_correct=2628.58, ppl=4.64, accuracy=65.015, wps=14403.5, ups=1.78, wpb=8086.1, bsz=281, num_updates=34800, lr=7.58098e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=56, gb_free=11.8, wall=24590
2023-08-08 20:33:21 | INFO | train_inner | epoch 024:   1013 / 1474 loss=2.057, trans_loss=5.01, nll_loss=2.21, w2v_ctc_loss=0.656, task_loss=0, contrastive_loss=0.043, total=4136.81, n_correct=2702.96, ppl=4.63, accuracy=65.339, wps=14992.3, ups=1.81, wpb=8273.6, bsz=298.4, num_updates=34900, lr=7.57011e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=55, gb_free=17.1, wall=24645
2023-08-08 20:34:17 | INFO | train_inner | epoch 024:   1113 / 1474 loss=2.061, trans_loss=4.998, nll_loss=2.195, w2v_ctc_loss=0.662, task_loss=0, contrastive_loss=0.082, total=4135.73, n_correct=2705.95, ppl=4.58, accuracy=65.429, wps=14849.5, ups=1.8, wpb=8271.5, bsz=308.9, num_updates=35000, lr=7.55929e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=55, gb_free=17.3, wall=24701
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:0')
2023-08-08 20:35:12 | INFO | train_inner | epoch 024:   1213 / 1474 loss=2.063, trans_loss=5.008, nll_loss=2.207, w2v_ctc_loss=0.657, task_loss=0, contrastive_loss=0.073, total=4148.3, n_correct=2710.45, ppl=4.62, accuracy=65.339, wps=14897.6, ups=1.8, wpb=8296.6, bsz=310.8, num_updates=35100, lr=7.54851e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=24756
2023-08-08 20:36:09 | INFO | train_inner | epoch 024:   1313 / 1474 loss=2.066, trans_loss=5.017, nll_loss=2.218, w2v_ctc_loss=0.671, task_loss=0, contrastive_loss=0.047, total=4110.05, n_correct=2674.97, ppl=4.65, accuracy=65.084, wps=14579.8, ups=1.77, wpb=8220.1, bsz=294.3, num_updates=35200, lr=7.53778e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=56, gb_free=17.5, wall=24813
2023-08-08 20:37:04 | INFO | train_inner | epoch 024:   1413 / 1474 loss=2.066, trans_loss=5.018, nll_loss=2.22, w2v_ctc_loss=0.672, task_loss=0, contrastive_loss=0.047, total=4090.91, n_correct=2662.67, ppl=4.66, accuracy=65.087, wps=14887.5, ups=1.82, wpb=8181.8, bsz=292.7, num_updates=35300, lr=7.5271e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=55, gb_free=16.2, wall=24868
2023-08-08 20:37:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2377, device='cuda:5')
2023-08-08 20:38:00 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.355 | trans_loss 5.548 | nll_loss 2.817 | w2v_ctc_loss 1.363 | task_loss 0 | contrastive_loss 0.239 | total 4003.4 | n_correct 2491.4 | ppl 7.05 | accuracy 62.232 | uer 16.956 | wer 18.881 | raw_wer 18.881 | bleu 19.98 | wps 2347.7 | wpb 4003.4 | bsz 141.8 | num_updates 35361 | best_bleu 20.34
2023-08-08 20:38:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35361 updates
2023-08-08 20:38:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.9802.pt
2023-08-08 20:38:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.9802.pt
2023-08-08 20:38:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_19.9802.pt (epoch 24 @ 35361 updates, score 19.98) (writing took 18.192689632996917 seconds)
2023-08-08 20:38:19 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-08 20:38:19 | INFO | train | epoch 024 | loss 2.063 | trans_loss 5.001 | nll_loss 2.198 | w2v_ctc_loss 0.658 | task_loss 0 | contrastive_loss 0.097 | total 4138.65 | n_correct 2706.74 | ppl 4.59 | accuracy 65.402 | wps 13125 | ups 1.59 | wpb 8277.3 | bsz 305.7 | num_updates 35361 | lr 7.5206e-05 | gnorm 0.551 | clip 0 | loss_scale 64 | train_wall 816 | gb_free 16.4 | wall 24943
2023-08-08 20:38:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 20:38:19 | INFO | fairseq.trainer | begin training epoch 25
2023-08-08 20:38:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 20:38:49 | INFO | train_inner | epoch 025:     39 / 1474 loss=2.047, trans_loss=4.99, nll_loss=2.183, w2v_ctc_loss=0.65, task_loss=0, contrastive_loss=0.051, total=4166.95, n_correct=2739.45, ppl=4.54, accuracy=65.742, wps=7917.2, ups=0.95, wpb=8333.9, bsz=312, num_updates=35400, lr=7.51646e-05, gnorm=0.543, clip=0, loss_scale=64, train_wall=55, gb_free=16.8, wall=24973
2023-08-08 20:39:44 | INFO | train_inner | epoch 025:    139 / 1474 loss=2.04, trans_loss=4.974, nll_loss=2.162, w2v_ctc_loss=0.644, task_loss=0, contrastive_loss=0.051, total=4133.64, n_correct=2726.69, ppl=4.48, accuracy=65.963, wps=14866.6, ups=1.8, wpb=8267.3, bsz=307.7, num_updates=35500, lr=7.50587e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=55, gb_free=16.1, wall=25029
2023-08-08 20:40:40 | INFO | train_inner | epoch 025:    239 / 1474 loss=2.042, trans_loss=4.978, nll_loss=2.167, w2v_ctc_loss=0.648, task_loss=0, contrastive_loss=0.053, total=4114.53, n_correct=2711.64, ppl=4.49, accuracy=65.904, wps=14692, ups=1.79, wpb=8229.1, bsz=302.7, num_updates=35600, lr=7.49532e-05, gnorm=0.543, clip=0, loss_scale=64, train_wall=55, gb_free=17.3, wall=25085
2023-08-08 20:41:36 | INFO | train_inner | epoch 025:    339 / 1474 loss=2.052, trans_loss=4.984, nll_loss=2.174, w2v_ctc_loss=0.652, task_loss=0, contrastive_loss=0.084, total=4148.7, n_correct=2725.83, ppl=4.51, accuracy=65.703, wps=14881.4, ups=1.79, wpb=8297.4, bsz=295.1, num_updates=35700, lr=7.48481e-05, gnorm=0.55, clip=0, loss_scale=64, train_wall=55, gb_free=16.5, wall=25140
2023-08-08 20:42:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-08 20:42:33 | INFO | train_inner | epoch 025:    440 / 1474 loss=2.055, trans_loss=4.99, nll_loss=2.182, w2v_ctc_loss=0.669, task_loss=0, contrastive_loss=0.043, total=4142.33, n_correct=2714.43, ppl=4.54, accuracy=65.529, wps=14528.4, ups=1.75, wpb=8284.7, bsz=289.3, num_updates=35800, lr=7.47435e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=56, gb_free=16.1, wall=25197
2023-08-08 20:43:29 | INFO | train_inner | epoch 025:    540 / 1474 loss=2.053, trans_loss=4.995, nll_loss=2.19, w2v_ctc_loss=0.655, task_loss=0, contrastive_loss=0.053, total=4160.61, n_correct=2731.06, ppl=4.56, accuracy=65.641, wps=14921.9, ups=1.79, wpb=8321.2, bsz=313.9, num_updates=35900, lr=7.46393e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=55, gb_free=17.8, wall=25253
2023-08-08 20:44:25 | INFO | train_inner | epoch 025:    640 / 1474 loss=2.06, trans_loss=4.988, nll_loss=2.181, w2v_ctc_loss=0.658, task_loss=0, contrastive_loss=0.119, total=4153.68, n_correct=2725.91, ppl=4.53, accuracy=65.626, wps=14926.7, ups=1.8, wpb=8307.4, bsz=309.6, num_updates=36000, lr=7.45356e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=55, gb_free=16.8, wall=25309
2023-08-08 20:44:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 20:44:48 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.38 | trans_loss 5.552 | nll_loss 2.82 | w2v_ctc_loss 1.433 | task_loss 0 | contrastive_loss 0.241 | total 4003.4 | n_correct 2491.6 | ppl 7.06 | accuracy 62.237 | uer 17.11 | wer 19.056 | raw_wer 19.056 | bleu 19.94 | wps 2250.2 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.34
2023-08-08 20:44:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-08-08 20:44:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_25_36000.pt
2023-08-08 20:44:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_25_36000.pt
2023-08-08 20:45:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 19.94) (writing took 20.097802970558405 seconds)
2023-08-08 20:46:04 | INFO | train_inner | epoch 025:    740 / 1474 loss=2.061, trans_loss=4.99, nll_loss=2.183, w2v_ctc_loss=0.656, task_loss=0, contrastive_loss=0.113, total=4128.34, n_correct=2708.23, ppl=4.54, accuracy=65.601, wps=8300.7, ups=1.01, wpb=8256.7, bsz=301.3, num_updates=36100, lr=7.44323e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=55, gb_free=17.3, wall=25408
2023-08-08 20:47:00 | INFO | train_inner | epoch 025:    840 / 1474 loss=2.051, trans_loss=4.994, nll_loss=2.188, w2v_ctc_loss=0.649, task_loss=0, contrastive_loss=0.061, total=4182.4, n_correct=2746.2, ppl=4.56, accuracy=65.661, wps=14994.4, ups=1.79, wpb=8364.8, bsz=326, num_updates=36200, lr=7.43294e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=55, gb_free=18, wall=25464
2023-08-08 20:47:56 | INFO | train_inner | epoch 025:    940 / 1474 loss=2.062, trans_loss=4.996, nll_loss=2.193, w2v_ctc_loss=0.656, task_loss=0, contrastive_loss=0.117, total=4155.21, n_correct=2726.46, ppl=4.57, accuracy=65.615, wps=14870.7, ups=1.79, wpb=8310.4, bsz=317, num_updates=36300, lr=7.4227e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=55, gb_free=14.5, wall=25520
2023-08-08 20:48:52 | INFO | train_inner | epoch 025:   1040 / 1474 loss=2.075, trans_loss=5.004, nll_loss=2.202, w2v_ctc_loss=0.645, task_loss=0, contrastive_loss=0.228, total=4177.7, n_correct=2731.2, ppl=4.6, accuracy=65.376, wps=14868.3, ups=1.78, wpb=8355.4, bsz=309.8, num_updates=36400, lr=7.41249e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=56, gb_free=16, wall=25576
2023-08-08 20:49:47 | INFO | train_inner | epoch 025:   1140 / 1474 loss=2.046, trans_loss=4.999, nll_loss=2.194, w2v_ctc_loss=0.645, task_loss=0, contrastive_loss=0.038, total=4039.24, n_correct=2649.31, ppl=4.58, accuracy=65.589, wps=14621, ups=1.81, wpb=8078.5, bsz=285.2, num_updates=36500, lr=7.40233e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=55, gb_free=16.8, wall=25631
2023-08-08 20:50:43 | INFO | train_inner | epoch 025:   1240 / 1474 loss=2.051, trans_loss=5.002, nll_loss=2.199, w2v_ctc_loss=0.651, task_loss=0, contrastive_loss=0.046, total=4090.59, n_correct=2675.69, ppl=4.59, accuracy=65.411, wps=14771.1, ups=1.81, wpb=8181.2, bsz=295.7, num_updates=36600, lr=7.39221e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=55, gb_free=17.6, wall=25687
2023-08-08 20:51:39 | INFO | train_inner | epoch 025:   1340 / 1474 loss=2.065, trans_loss=4.999, nll_loss=2.196, w2v_ctc_loss=0.654, task_loss=0, contrastive_loss=0.139, total=4164.34, n_correct=2728.35, ppl=4.58, accuracy=65.517, wps=14920.8, ups=1.79, wpb=8328.7, bsz=310.1, num_updates=36700, lr=7.38213e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=55, gb_free=17.1, wall=25743
2023-08-08 20:52:35 | INFO | train_inner | epoch 025:   1440 / 1474 loss=2.068, trans_loss=5.018, nll_loss=2.22, w2v_ctc_loss=0.66, task_loss=0, contrastive_loss=0.087, total=4099.11, n_correct=2666.75, ppl=4.66, accuracy=65.057, wps=14601.8, ups=1.78, wpb=8198.2, bsz=299.3, num_updates=36800, lr=7.3721e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=56, gb_free=12.8, wall=25799
2023-08-08 20:52:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 20:53:17 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.364 | trans_loss 5.545 | nll_loss 2.818 | w2v_ctc_loss 1.391 | task_loss 0 | contrastive_loss 0.244 | total 4003.4 | n_correct 2490.8 | ppl 7.05 | accuracy 62.217 | uer 17.124 | wer 19.015 | raw_wer 19.015 | bleu 19.89 | wps 2133.2 | wpb 4003.4 | bsz 141.8 | num_updates 36834 | best_bleu 20.34
2023-08-08 20:53:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36834 updates
2023-08-08 20:53:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_last.pt
2023-08-08 20:53:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_last.pt
2023-08-08 20:53:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_last.pt (epoch 25 @ 36834 updates, score 19.89) (writing took 13.842351853847504 seconds)
2023-08-08 20:53:31 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-08 20:53:31 | INFO | train | epoch 025 | loss 2.056 | trans_loss 4.993 | nll_loss 2.188 | w2v_ctc_loss 0.653 | task_loss 0 | contrastive_loss 0.087 | total 4137.25 | n_correct 2713.62 | ppl 4.56 | accuracy 65.59 | wps 13357.9 | ups 1.61 | wpb 8274.5 | bsz 305.1 | num_updates 36834 | lr 7.36869e-05 | gnorm 0.553 | clip 0 | loss_scale 32 | train_wall 814 | gb_free 14.7 | wall 25855
2023-08-08 20:53:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 20:53:32 | INFO | fairseq.trainer | begin training epoch 26
2023-08-08 20:53:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 20:54:17 | INFO | train_inner | epoch 026:     66 / 1474 loss=2.043, trans_loss=4.972, nll_loss=2.161, w2v_ctc_loss=0.645, task_loss=0, contrastive_loss=0.072, total=4180.21, n_correct=2759.22, ppl=4.47, accuracy=66.007, wps=8190.6, ups=0.98, wpb=8360.4, bsz=318.3, num_updates=36900, lr=7.3621e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=55, gb_free=17.2, wall=25901
2023-08-08 20:55:13 | INFO | train_inner | epoch 026:    166 / 1474 loss=2.065, trans_loss=4.97, nll_loss=2.159, w2v_ctc_loss=0.633, task_loss=0, contrastive_loss=0.258, total=4270.78, n_correct=2821.63, ppl=4.46, accuracy=66.068, wps=15323.5, ups=1.79, wpb=8541.6, bsz=340.4, num_updates=37000, lr=7.35215e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=55, gb_free=15.6, wall=25957
2023-08-08 20:56:08 | INFO | train_inner | epoch 026:    266 / 1474 loss=2.053, trans_loss=4.973, nll_loss=2.161, w2v_ctc_loss=0.653, task_loss=0, contrastive_loss=0.129, total=4125.04, n_correct=2721.43, ppl=4.47, accuracy=65.973, wps=14816.5, ups=1.8, wpb=8250.1, bsz=307.1, num_updates=37100, lr=7.34223e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=55, gb_free=15.6, wall=26012
2023-08-08 20:57:04 | INFO | train_inner | epoch 026:    366 / 1474 loss=2.047, trans_loss=4.973, nll_loss=2.162, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.088, total=4165.74, n_correct=2749.02, ppl=4.48, accuracy=65.991, wps=14973.6, ups=1.8, wpb=8331.5, bsz=314.7, num_updates=37200, lr=7.33236e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=55, gb_free=17.1, wall=26068
2023-08-08 20:57:59 | INFO | train_inner | epoch 026:    466 / 1474 loss=2.051, trans_loss=4.969, nll_loss=2.157, w2v_ctc_loss=0.644, task_loss=0, contrastive_loss=0.137, total=4170.23, n_correct=2754.54, ppl=4.46, accuracy=66.052, wps=15026.4, ups=1.8, wpb=8340.5, bsz=315.4, num_updates=37300, lr=7.32252e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=55, gb_free=18, wall=26123
2023-08-08 20:58:55 | INFO | train_inner | epoch 026:    566 / 1474 loss=2.051, trans_loss=4.986, nll_loss=2.177, w2v_ctc_loss=0.661, task_loss=0, contrastive_loss=0.058, total=4155.02, n_correct=2734.64, ppl=4.52, accuracy=65.815, wps=14936.5, ups=1.8, wpb=8310, bsz=303.9, num_updates=37400, lr=7.31272e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=55, gb_free=18.1, wall=26179
2023-08-08 20:59:51 | INFO | train_inner | epoch 026:    666 / 1474 loss=2.04, trans_loss=4.982, nll_loss=2.173, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.044, total=4136.96, n_correct=2723.47, ppl=4.51, accuracy=65.833, wps=14822.1, ups=1.79, wpb=8273.9, bsz=299.2, num_updates=37500, lr=7.30297e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=55, gb_free=15.7, wall=26235
2023-08-08 21:00:46 | INFO | train_inner | epoch 026:    766 / 1474 loss=2.063, trans_loss=4.989, nll_loss=2.183, w2v_ctc_loss=0.648, task_loss=0, contrastive_loss=0.155, total=4086.28, n_correct=2681.95, ppl=4.54, accuracy=65.633, wps=14684.6, ups=1.8, wpb=8172.6, bsz=298.5, num_updates=37600, lr=7.29325e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=55, gb_free=15.4, wall=26291
2023-08-08 21:01:42 | INFO | train_inner | epoch 026:    866 / 1474 loss=2.049, trans_loss=4.987, nll_loss=2.179, w2v_ctc_loss=0.652, task_loss=0, contrastive_loss=0.057, total=4183.26, n_correct=2748.36, ppl=4.53, accuracy=65.699, wps=15085.4, ups=1.8, wpb=8366.5, bsz=308.1, num_updates=37700, lr=7.28357e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=55, gb_free=17.6, wall=26346
2023-08-08 21:02:38 | INFO | train_inner | epoch 026:    966 / 1474 loss=2.053, trans_loss=4.995, nll_loss=2.19, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.111, total=4137.96, n_correct=2713.04, ppl=4.56, accuracy=65.565, wps=14797.8, ups=1.79, wpb=8275.9, bsz=299, num_updates=37800, lr=7.27393e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=55, gb_free=17.2, wall=26402
2023-08-08 21:03:34 | INFO | train_inner | epoch 026:   1066 / 1474 loss=2.043, trans_loss=4.99, nll_loss=2.184, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.044, total=4120.53, n_correct=2709.32, ppl=4.54, accuracy=65.752, wps=14787.5, ups=1.79, wpb=8241.1, bsz=294.3, num_updates=37900, lr=7.26433e-05, gnorm=0.543, clip=0, loss_scale=64, train_wall=55, gb_free=16.9, wall=26458
2023-08-08 21:04:29 | INFO | train_inner | epoch 026:   1166 / 1474 loss=2.053, trans_loss=4.997, nll_loss=2.193, w2v_ctc_loss=0.648, task_loss=0, contrastive_loss=0.082, total=4113.86, n_correct=2697.65, ppl=4.57, accuracy=65.575, wps=14745.8, ups=1.79, wpb=8227.7, bsz=298.5, num_updates=38000, lr=7.25476e-05, gnorm=0.555, clip=0, loss_scale=64, train_wall=55, gb_free=16.8, wall=26514
2023-08-08 21:04:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 21:04:53 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.361 | trans_loss 5.548 | nll_loss 2.818 | w2v_ctc_loss 1.382 | task_loss 0 | contrastive_loss 0.234 | total 4003.4 | n_correct 2494.2 | ppl 7.05 | accuracy 62.302 | uer 16.988 | wer 18.773 | raw_wer 18.773 | bleu 20.03 | wps 2123.1 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.34
2023-08-08 21:04:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-08-08 21:04:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_26_38000.pt
2023-08-08 21:04:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_26_38000.pt
2023-08-08 21:05:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 20.03) (writing took 39.213788172230124 seconds)
2023-08-08 21:06:29 | INFO | train_inner | epoch 026:   1266 / 1474 loss=2.06, trans_loss=5.011, nll_loss=2.209, w2v_ctc_loss=0.668, task_loss=0, contrastive_loss=0.046, total=3996.19, n_correct=2606.56, ppl=4.63, accuracy=65.226, wps=6676.7, ups=0.84, wpb=7992.4, bsz=279.3, num_updates=38100, lr=7.24524e-05, gnorm=0.565, clip=0, loss_scale=64, train_wall=55, gb_free=18, wall=26633
2023-08-08 21:07:25 | INFO | train_inner | epoch 026:   1366 / 1474 loss=2.048, trans_loss=4.998, nll_loss=2.195, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.057, total=4159.74, n_correct=2731.67, ppl=4.58, accuracy=65.669, wps=14891, ups=1.79, wpb=8319.5, bsz=311.4, num_updates=38200, lr=7.23575e-05, gnorm=0.553, clip=0, loss_scale=64, train_wall=55, gb_free=17.5, wall=26689
2023-08-08 21:08:21 | INFO | train_inner | epoch 026:   1466 / 1474 loss=2.043, trans_loss=4.993, nll_loss=2.189, w2v_ctc_loss=0.638, task_loss=0, contrastive_loss=0.053, total=4165.66, n_correct=2741.62, ppl=4.56, accuracy=65.815, wps=14873.3, ups=1.79, wpb=8331.3, bsz=317.5, num_updates=38300, lr=7.22629e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=56, gb_free=16.5, wall=26745
2023-08-08 21:08:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-08 21:08:48 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.355 | trans_loss 5.551 | nll_loss 2.822 | w2v_ctc_loss 1.356 | task_loss 0 | contrastive_loss 0.239 | total 4003.4 | n_correct 2494.6 | ppl 7.07 | accuracy 62.312 | uer 17.073 | wer 18.795 | raw_wer 18.795 | bleu 20.12 | wps 2367.9 | wpb 4003.4 | bsz 141.8 | num_updates 38308 | best_bleu 20.34
2023-08-08 21:08:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38308 updates
2023-08-08 21:08:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_20.1207.pt
2023-08-08 21:08:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_20.1207.pt
2023-08-08 21:09:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_20.1207.pt (epoch 26 @ 38308 updates, score 20.12) (writing took 19.546306723728776 seconds)
2023-08-08 21:09:07 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-08 21:09:08 | INFO | train | epoch 026 | loss 2.05 | trans_loss 4.985 | nll_loss 2.177 | w2v_ctc_loss 0.647 | task_loss 0 | contrastive_loss 0.094 | total 4138.65 | n_correct 2722.99 | ppl 4.52 | accuracy 65.794 | wps 13032.5 | ups 1.57 | wpb 8277.3 | bsz 305.7 | num_updates 38308 | lr 7.22554e-05 | gnorm 0.552 | clip 0 | loss_scale 64 | train_wall 815 | gb_free 16.2 | wall 26792
2023-08-08 21:09:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-08 21:09:08 | INFO | fairseq.trainer | begin training epoch 27
2023-08-08 21:09:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-08 21:10:06 | INFO | train_inner | epoch 027:     92 / 1474 loss=2.021, trans_loss=4.951, nll_loss=2.131, w2v_ctc_loss=0.63, task_loss=0, contrastive_loss=0.035, total=4054.57, n_correct=2693.12, ppl=4.38, accuracy=66.422, wps=7727.2, ups=0.95, wpb=8109.1, bsz=282.4, num_updates=38400, lr=7.21688e-05, gnorm=0.562, clip=0, loss_scale=64, train_wall=54, gb_free=16.5, wall=26850
2023-08-08 21:11:02 | INFO | train_inner | epoch 027:    192 / 1474 loss=2.032, trans_loss=4.957, nll_loss=2.14, w2v_ctc_loss=0.64, task_loss=0, contrastive_loss=0.059, total=4195.2, n_correct=2784.36, ppl=4.41, accuracy=66.37, wps=14921.3, ups=1.78, wpb=8390.4, bsz=323.2, num_updates=38500, lr=7.2075e-05, gnorm=0.556, clip=0, loss_scale=64, train_wall=56, gb_free=17.4, wall=26906
2023-08-08 21:11:58 | INFO | train_inner | epoch 027:    292 / 1474 loss=2.031, trans_loss=4.964, nll_loss=2.149, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.045, total=4162.23, n_correct=2756.27, ppl=4.44, accuracy=66.221, wps=15008.1, ups=1.8, wpb=8324.5, bsz=305.5, num_updates=38600, lr=7.19816e-05, gnorm=0.544, clip=0, loss_scale=64, train_wall=55, gb_free=17.4, wall=26962
2023-08-08 21:12:54 | INFO | train_inner | epoch 027:    392 / 1474 loss=2.06, trans_loss=4.974, nll_loss=2.162, w2v_ctc_loss=0.636, task_loss=0, contrastive_loss=0.222, total=4079.05, n_correct=2692.86, ppl=4.48, accuracy=66.017, wps=14425.3, ups=1.77, wpb=8158.1, bsz=297.1, num_updates=38700, lr=7.18885e-05, gnorm=0.553, clip=0, loss_scale=64, train_wall=56, gb_free=17.1, wall=27018
2023-08-08 21:13:50 | INFO | train_inner | epoch 027:    492 / 1474 loss=2.056, trans_loss=4.978, nll_loss=2.17, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.16, total=4243.25, n_correct=2800.18, ppl=4.5, accuracy=65.991, wps=15166.8, ups=1.79, wpb=8486.5, bsz=331, num_updates=38800, lr=7.17958e-05, gnorm=0.546, clip=0, loss_scale=64, train_wall=55, gb_free=16.1, wall=27074
2023-08-08 21:14:46 | INFO | train_inner | epoch 027:    592 / 1474 loss=2.048, trans_loss=4.975, nll_loss=2.164, w2v_ctc_loss=0.644, task_loss=0, contrastive_loss=0.101, total=4137.92, n_correct=2729.79, ppl=4.48, accuracy=65.97, wps=14807.3, ups=1.79, wpb=8275.8, bsz=313.5, num_updates=38900, lr=7.17035e-05, gnorm=0.559, clip=0, loss_scale=64, train_wall=55, gb_free=16.2, wall=27130
2023-08-08 21:15:42 | INFO | train_inner | epoch 027:    692 / 1474 loss=2.048, trans_loss=4.984, nll_loss=2.175, w2v_ctc_loss=0.648, task_loss=0, contrastive_loss=0.079, total=4158.48, n_correct=2737.66, ppl=4.52, accuracy=65.833, wps=14988.3, ups=1.8, wpb=8317, bsz=304.1, num_updates=39000, lr=7.16115e-05, gnorm=0.549, clip=0, loss_scale=64, train_wall=55, gb_free=15.9, wall=27186
2023-08-08 21:16:37 | INFO | train_inner | epoch 027:    792 / 1474 loss=2.042, trans_loss=4.981, nll_loss=2.172, w2v_ctc_loss=0.649, task_loss=0, contrastive_loss=0.045, total=4100.88, n_correct=2701.14, ppl=4.51, accuracy=65.867, wps=14813.8, ups=1.81, wpb=8201.8, bsz=292.2, num_updates=39100, lr=7.15199e-05, gnorm=0.558, clip=0, loss_scale=64, train_wall=55, gb_free=16.1, wall=27241
2023-08-08 21:17:32 | INFO | train_inner | epoch 027:    892 / 1474 loss=2.034, trans_loss=4.984, nll_loss=2.175, w2v_ctc_loss=0.632, task_loss=0, contrastive_loss=0.039, total=4111.94, n_correct=2711.87, ppl=4.51, accuracy=65.951, wps=14865.3, ups=1.81, wpb=8223.9, bsz=294.9, num_updates=39200, lr=7.14286e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=55, gb_free=16.3, wall=27296
2023-08-08 21:18:28 | INFO | train_inner | epoch 027:    992 / 1474 loss=2.06, trans_loss=4.98, nll_loss=2.172, w2v_ctc_loss=0.638, task_loss=0, contrastive_loss=0.221, total=4189.27, n_correct=2760.22, ppl=4.51, accuracy=65.888, wps=14947.3, ups=1.78, wpb=8378.5, bsz=314.9, num_updates=39300, lr=7.13376e-05, gnorm=0.545, clip=0, loss_scale=64, train_wall=56, gb_free=14.7, wall=27352
2023-08-08 21:19:24 | INFO | train_inner | epoch 027:   1092 / 1474 loss=2.035, trans_loss=4.977, nll_loss=2.167, w2v_ctc_loss=0.633, task_loss=0, contrastive_loss=0.055, total=4160.42, n_correct=2747.01, ppl=4.49, accuracy=66.027, wps=15048, ups=1.81, wpb=8320.8, bsz=307.3, num_updates=39400, lr=7.1247e-05, gnorm=0.546, clip=0, loss_scale=64, train_wall=55, gb_free=17.2, wall=27408
2023-08-08 21:20:20 | INFO | train_inner | epoch 027:   1192 / 1474 loss=2.049, trans_loss=4.989, nll_loss=2.183, w2v_ctc_loss=0.655, task_loss=0, contrastive_loss=0.058, total=4103.72, n_correct=2696.63, ppl=4.54, accuracy=65.712, wps=14661.3, ups=1.79, wpb=8207.4, bsz=297.1, num_updates=39500, lr=7.11568e-05, gnorm=0.555, clip=0, loss_scale=64, train_wall=56, gb_free=17.9, wall=27464
2023-08-08 21:21:15 | INFO | train_inner | epoch 027:   1292 / 1474 loss=2.057, trans_loss=4.994, nll_loss=2.19, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.111, total=4065.94, n_correct=2664.51, ppl=4.56, accuracy=65.532, wps=14701.4, ups=1.81, wpb=8131.9, bsz=292.4, num_updates=39600, lr=7.10669e-05, gnorm=0.561, clip=0, loss_scale=64, train_wall=55, gb_free=16.4, wall=27519
2023-08-08 21:22:10 | INFO | train_inner | epoch 027:   1392 / 1474 loss=2.044, trans_loss=4.986, nll_loss=2.179, w2v_ctc_loss=0.634, task_loss=0, contrastive_loss=0.092, total=4149.21, n_correct=2736.27, ppl=4.53, accuracy=65.947, wps=15015.9, ups=1.81, wpb=8298.4, bsz=312.6, num_updates=39700, lr=7.09773e-05, gnorm=0.545, clip=0, loss_scale=64, train_wall=55, gb_free=17.1, wall=27574
2023-08-08 21:22:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 265, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 30, in <module>
    from fairseq import checkpoint_utils, options, quantization_utils, tasks, utils
  File "/mnt/zhangyh/fairseq-AT/fairseq/__init__.py", line 32, in <module>
    import fairseq.criterions  # noqa
  File "/mnt/zhangyh/fairseq-AT/fairseq/criterions/__init__.py", line 35, in <module>
    importlib.import_module("fairseq.criterions." + file_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/criterions/ctc.py", line 21, in <module>
    from fairseq.tasks import FairseqTask
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/__init__.py", line 136, in <module>
    import_tasks(tasks_dir, "fairseq.tasks")
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/__init__.py", line 117, in import_tasks
    importlib.import_module(namespace + "." + task_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/online_backtranslation.py", line 34, in <module>
    from fairseq.sequence_generator import SequenceGenerator
  File "/mnt/zhangyh/fairseq-AT/fairseq/sequence_generator.py", line 16, in <module>
    from fairseq.models import FairseqIncrementalDecoder
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/__init__.py", line 235, in <module>
    import_models(models_dir, "fairseq.models")
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/__init__.py", line 217, in import_models
    importlib.import_module(namespace + "." + model_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/__init__.py", line 6, in <module>
    from .s2s_conformer import *  # noqa
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/s2s_conformer.py", line 13, in <module>
    from fairseq.models.speech_to_speech.s2s_transformer import (
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/s2s_transformer.py", line 23, in <module>
    from fairseq.models.speech_to_text import S2TTransformerEncoder
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_text/__init__.py", line 14, in <module>
    from .s2t_joint import *
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_text/s2t_joint.py", line 956
    mixup_sent_index = mixup_sent_mask.nonzero(as_tuple=False)
    ^
IndentationError: expected an indented block
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 265, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 30, in <module>
    from fairseq import checkpoint_utils, options, quantization_utils, tasks, utils
  File "/mnt/zhangyh/fairseq-AT/fairseq/__init__.py", line 32, in <module>
    import fairseq.criterions  # noqa
  File "/mnt/zhangyh/fairseq-AT/fairseq/criterions/__init__.py", line 35, in <module>
    importlib.import_module("fairseq.criterions." + file_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/criterions/ctc.py", line 21, in <module>
    from fairseq.tasks import FairseqTask
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/__init__.py", line 136, in <module>
    import_tasks(tasks_dir, "fairseq.tasks")
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/__init__.py", line 117, in import_tasks
    importlib.import_module(namespace + "." + task_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/online_backtranslation.py", line 34, in <module>
    from fairseq.sequence_generator import SequenceGenerator
  File "/mnt/zhangyh/fairseq-AT/fairseq/sequence_generator.py", line 16, in <module>
    from fairseq.models import FairseqIncrementalDecoder
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/__init__.py", line 235, in <module>
    import_models(models_dir, "fairseq.models")
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/__init__.py", line 217, in import_models
    importlib.import_module(namespace + "." + model_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/__init__.py", line 6, in <module>
    from .s2s_conformer import *  # noqa
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/s2s_conformer.py", line 13, in <module>
    from fairseq.models.speech_to_speech.s2s_transformer import (
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/s2s_transformer.py", line 23, in <module>
    from fairseq.models.speech_to_text import S2TTransformerEncoder
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_text/__init__.py", line 14, in <module>
    from .s2t_joint import *
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_text/s2t_joint.py", line 956
    mixup_sent_index = mixup_sent_mask.nonzero(as_tuple=False)
    ^
IndentationError: expected an indented block
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 265, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 30, in <module>
    from fairseq import checkpoint_utils, options, quantization_utils, tasks, utils
  File "/mnt/zhangyh/fairseq-AT/fairseq/__init__.py", line 32, in <module>
    import fairseq.criterions  # noqa
  File "/mnt/zhangyh/fairseq-AT/fairseq/criterions/__init__.py", line 35, in <module>
    importlib.import_module("fairseq.criterions." + file_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/criterions/ctc.py", line 21, in <module>
    from fairseq.tasks import FairseqTask
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/__init__.py", line 136, in <module>
    import_tasks(tasks_dir, "fairseq.tasks")
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/__init__.py", line 117, in import_tasks
    importlib.import_module(namespace + "." + task_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/online_backtranslation.py", line 34, in <module>
    from fairseq.sequence_generator import SequenceGenerator
  File "/mnt/zhangyh/fairseq-AT/fairseq/sequence_generator.py", line 16, in <module>
    from fairseq.models import FairseqIncrementalDecoder
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/__init__.py", line 235, in <module>
    import_models(models_dir, "fairseq.models")
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/__init__.py", line 217, in import_models
    importlib.import_module(namespace + "." + model_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/__init__.py", line 6, in <module>
    from .s2s_conformer import *  # noqa
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/s2s_conformer.py", line 13, in <module>
    from fairseq.models.speech_to_speech.s2s_transformer import (
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/s2s_transformer.py", line 23, in <module>
    from fairseq.models.speech_to_text import S2TTransformerEncoder
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_text/__init__.py", line 14, in <module>
    from .s2t_joint import *
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_text/s2t_joint.py", line 956
    mixup_sent_index = mixup_sent_mask.nonzero(as_tuple=False)
    ^
IndentationError: expected an indented block
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 265, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 30, in <module>
    from fairseq import checkpoint_utils, options, quantization_utils, tasks, utils
  File "/mnt/zhangyh/fairseq-AT/fairseq/__init__.py", line 32, in <module>
    import fairseq.criterions  # noqa
  File "/mnt/zhangyh/fairseq-AT/fairseq/criterions/__init__.py", line 35, in <module>
    importlib.import_module("fairseq.criterions." + file_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/criterions/ctc.py", line 21, in <module>
    from fairseq.tasks import FairseqTask
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/__init__.py", line 136, in <module>
    import_tasks(tasks_dir, "fairseq.tasks")
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/__init__.py", line 117, in import_tasks
    importlib.import_module(namespace + "." + task_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/online_backtranslation.py", line 34, in <module>
    from fairseq.sequence_generator import SequenceGenerator
  File "/mnt/zhangyh/fairseq-AT/fairseq/sequence_generator.py", line 16, in <module>
    from fairseq.models import FairseqIncrementalDecoder
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/__init__.py", line 235, in <module>
    import_models(models_dir, "fairseq.models")
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/__init__.py", line 217, in import_models
    importlib.import_module(namespace + "." + model_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/__init__.py", line 6, in <module>
    from .s2s_conformer import *  # noqa
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/s2s_conformer.py", line 13, in <module>
    from fairseq.models.speech_to_speech.s2s_transformer import (
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/s2s_transformer.py", line 23, in <module>
    from fairseq.models.speech_to_text import S2TTransformerEncoder
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_text/__init__.py", line 14, in <module>
    from .s2t_joint import *
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_text/s2t_joint.py", line 956
    mixup_sent_index = mixup_sent_mask.nonzero(as_tuple=False)
    ^
IndentationError: expected an indented block
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 265, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 30, in <module>
    from fairseq import checkpoint_utils, options, quantization_utils, tasks, utils
  File "/mnt/zhangyh/fairseq-AT/fairseq/__init__.py", line 32, in <module>
    import fairseq.criterions  # noqa
  File "/mnt/zhangyh/fairseq-AT/fairseq/criterions/__init__.py", line 35, in <module>
    importlib.import_module("fairseq.criterions." + file_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/criterions/ctc.py", line 21, in <module>
    from fairseq.tasks import FairseqTask
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/__init__.py", line 136, in <module>
    import_tasks(tasks_dir, "fairseq.tasks")
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/__init__.py", line 117, in import_tasks
    importlib.import_module(namespace + "." + task_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/online_backtranslation.py", line 34, in <module>
    from fairseq.sequence_generator import SequenceGenerator
  File "/mnt/zhangyh/fairseq-AT/fairseq/sequence_generator.py", line 16, in <module>
    from fairseq.models import FairseqIncrementalDecoder
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/__init__.py", line 235, in <module>
    import_models(models_dir, "fairseq.models")
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/__init__.py", line 217, in import_models
    importlib.import_module(namespace + "." + model_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/__init__.py", line 6, in <module>
    from .s2s_conformer import *  # noqa
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/s2s_conformer.py", line 13, in <module>
    from fairseq.models.speech_to_speech.s2s_transformer import (
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/s2s_transformer.py", line 23, in <module>
    from fairseq.models.speech_to_text import S2TTransformerEncoder
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_text/__init__.py", line 14, in <module>
    from .s2t_joint import *
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_text/s2t_joint.py", line 956
    mixup_sent_index = mixup_sent_mask.nonzero(as_tuple=False)
    ^
IndentationError: expected an indented block
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 265, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 30, in <module>
    from fairseq import checkpoint_utils, options, quantization_utils, tasks, utils
  File "/mnt/zhangyh/fairseq-AT/fairseq/__init__.py", line 32, in <module>
    import fairseq.criterions  # noqa
  File "/mnt/zhangyh/fairseq-AT/fairseq/criterions/__init__.py", line 35, in <module>
    importlib.import_module("fairseq.criterions." + file_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/criterions/ctc.py", line 21, in <module>
    from fairseq.tasks import FairseqTask
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/__init__.py", line 136, in <module>
    import_tasks(tasks_dir, "fairseq.tasks")
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/__init__.py", line 117, in import_tasks
    importlib.import_module(namespace + "." + task_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/online_backtranslation.py", line 34, in <module>
    from fairseq.sequence_generator import SequenceGenerator
  File "/mnt/zhangyh/fairseq-AT/fairseq/sequence_generator.py", line 16, in <module>
    from fairseq.models import FairseqIncrementalDecoder
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/__init__.py", line 235, in <module>
    import_models(models_dir, "fairseq.models")
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/__init__.py", line 217, in import_models
    importlib.import_module(namespace + "." + model_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/__init__.py", line 6, in <module>
    from .s2s_conformer import *  # noqa
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/s2s_conformer.py", line 13, in <module>
    from fairseq.models.speech_to_speech.s2s_transformer import (
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/s2s_transformer.py", line 23, in <module>
    from fairseq.models.speech_to_text import S2TTransformerEncoder
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_text/__init__.py", line 14, in <module>
    from .s2t_joint import *
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_text/s2t_joint.py", line 956
    mixup_sent_index = mixup_sent_mask.nonzero(as_tuple=False)
    ^
IndentationError: expected an indented block
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 265, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 30, in <module>
    from fairseq import checkpoint_utils, options, quantization_utils, tasks, utils
  File "/mnt/zhangyh/fairseq-AT/fairseq/__init__.py", line 32, in <module>
    import fairseq.criterions  # noqa
  File "/mnt/zhangyh/fairseq-AT/fairseq/criterions/__init__.py", line 35, in <module>
    importlib.import_module("fairseq.criterions." + file_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/criterions/ctc.py", line 21, in <module>
    from fairseq.tasks import FairseqTask
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/__init__.py", line 136, in <module>
    import_tasks(tasks_dir, "fairseq.tasks")
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/__init__.py", line 117, in import_tasks
    importlib.import_module(namespace + "." + task_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/online_backtranslation.py", line 34, in <module>
    from fairseq.sequence_generator import SequenceGenerator
  File "/mnt/zhangyh/fairseq-AT/fairseq/sequence_generator.py", line 16, in <module>
    from fairseq.models import FairseqIncrementalDecoder
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/__init__.py", line 235, in <module>
    import_models(models_dir, "fairseq.models")
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/__init__.py", line 217, in import_models
    importlib.import_module(namespace + "." + model_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/__init__.py", line 6, in <module>
    from .s2s_conformer import *  # noqa
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/s2s_conformer.py", line 13, in <module>
    from fairseq.models.speech_to_speech.s2s_transformer import (
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/s2s_transformer.py", line 23, in <module>
    from fairseq.models.speech_to_text import S2TTransformerEncoder
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_text/__init__.py", line 14, in <module>
    from .s2t_joint import *
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_text/s2t_joint.py", line 956
    mixup_sent_index = mixup_sent_mask.nonzero(as_tuple=False)
    ^
IndentationError: expected an indented block
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 265, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 30, in <module>
    from fairseq import checkpoint_utils, options, quantization_utils, tasks, utils
  File "/mnt/zhangyh/fairseq-AT/fairseq/__init__.py", line 32, in <module>
    import fairseq.criterions  # noqa
  File "/mnt/zhangyh/fairseq-AT/fairseq/criterions/__init__.py", line 35, in <module>
    importlib.import_module("fairseq.criterions." + file_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/criterions/ctc.py", line 21, in <module>
    from fairseq.tasks import FairseqTask
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/__init__.py", line 136, in <module>
    import_tasks(tasks_dir, "fairseq.tasks")
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/__init__.py", line 117, in import_tasks
    importlib.import_module(namespace + "." + task_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/online_backtranslation.py", line 34, in <module>
    from fairseq.sequence_generator import SequenceGenerator
  File "/mnt/zhangyh/fairseq-AT/fairseq/sequence_generator.py", line 16, in <module>
    from fairseq.models import FairseqIncrementalDecoder
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/__init__.py", line 235, in <module>
    import_models(models_dir, "fairseq.models")
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/__init__.py", line 217, in import_models
    importlib.import_module(namespace + "." + model_name)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/__init__.py", line 6, in <module>
    from .s2s_conformer import *  # noqa
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/s2s_conformer.py", line 13, in <module>
    from fairseq.models.speech_to_speech.s2s_transformer import (
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_speech/s2s_transformer.py", line 23, in <module>
    from fairseq.models.speech_to_text import S2TTransformerEncoder
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_text/__init__.py", line 14, in <module>
    from .s2t_joint import *
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_text/s2t_joint.py", line 956
    mixup_sent_index = mixup_sent_mask.nonzero(as_tuple=False)
    ^
IndentationError: expected an indented block
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 240, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 198, in start_processes
    while not context.join():
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 5 terminated with signal SIGTERM
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1249 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-08-09 11:23:36 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:11480
2023-08-09 11:23:36 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11480
2023-08-09 11:23:36 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11480
2023-08-09 11:23:36 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:11480
2023-08-09 11:23:36 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11480
2023-08-09 11:23:36 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11480
2023-08-09 11:23:36 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:11480
2023-08-09 11:23:36 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:11480
2023-08-09 11:23:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-09 11:23:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-09 11:23:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-09 11:23:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-09 11:23:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-09 11:23:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-09 11:23:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-09 11:23:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-09 11:23:37 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-09 11:23:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-08-09 11:23:37 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-09 11:23:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-08-09 11:23:37 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-09 11:23:37 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-09 11:23:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-08-09 11:23:37 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-09 11:23:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-08-09 11:23:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-08-09 11:23:37 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-09 11:23:37 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-09 11:23:37 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-09 11:23:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-08-09 11:23:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-08-09 11:23:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-08-09 11:23:41 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11480', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=2.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=2.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=2.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-09 11:23:41 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-09 11:23:41 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-09 11:23:41 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-09 11:23:41 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-09 11:23:41 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-09 11:23:46 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-09 11:23:46 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-09 11:23:46 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-09 11:23:48 | INFO | root | load pretrained hubert
2023-08-09 11:23:48 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-09 11:23:50 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-09 11:23:52 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-09 11:23:52 | INFO | root | share the sematic adapter and textual encoder
2023-08-09 11:23:52 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-09 11:23:52 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-09 11:23:52 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-09 11:23:52 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-09 11:23:52 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-08-09 11:23:53 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-09 11:23:53 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-09 11:23:53 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-09 11:23:53 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-09 11:23:53 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-09 11:23:58 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-09 11:23:59 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-09 11:23:59 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-09 11:24:00 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-09 11:24:00 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-09 11:24:00 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-09 11:24:00 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-09 11:24:00 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-09 11:24:00 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-09 11:24:00 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-09 11:24:00 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-09 11:24:00 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-09 11:24:00 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-09 11:24:00 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-09 11:24:00 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-09 11:24:00 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_last.pt
2023-08-09 11:24:03 | INFO | fairseq.trainer | load the task parameters
asr_weight tensor(0.2377)
mt_weight tensor(0.5000)
2023-08-09 11:24:03 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-09 11:24:04 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_last.pt (epoch 27 @ 38308 updates)
2023-08-09 11:24:04 | INFO | fairseq.trainer | loading train data for epoch 27
2023-08-09 11:24:04 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-09 11:24:04 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-09 11:24:04 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-09 11:24:09 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-09 11:24:13 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-09 11:24:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-09 11:24:59 | INFO | fairseq.trainer | begin training epoch 27
2023-08-09 11:24:59 | INFO | fairseq_cli.train | Start iterating over samples
asr_weight tensor(0.2377)
mt_weight tensor(0.5000)
asr_weight tensor(0.2377)
mt_weight tensor(0.5000)
asr_weight tensor(0.2377)
mt_weight tensor(0.5000)
asr_weight tensor(0.2377)
mt_weight tensor(0.5000)
asr_weight tensor(0.2377)
mt_weight tensor(0.5000)
asr_weight tensor(0.2377)
mt_weight tensor(0.5000)
asr_weight tensor(0.2377)
mt_weight tensor(0.5000)
2023-08-09 11:26:11 | INFO | train_inner | epoch 027:     92 / 1474 loss=2.02, trans_loss=4.948, nll_loss=2.127, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.035, total=4095.52, n_correct=2724.53, ppl=4.37, accuracy=66.525, wps=14342.5, ups=1.75, wpb=8191, bsz=288.7, num_updates=38400, lr=7.21688e-05, gnorm=0.555, clip=0, loss_scale=64, train_wall=63, gb_free=16.5, wall=131
2023-08-09 11:27:08 | INFO | train_inner | epoch 027:    192 / 1474 loss=2.03, trans_loss=4.955, nll_loss=2.138, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.06, total=4195.2, n_correct=2785.98, ppl=4.4, accuracy=66.409, wps=14735.6, ups=1.76, wpb=8390.4, bsz=323.2, num_updates=38500, lr=7.2075e-05, gnorm=0.556, clip=0, loss_scale=64, train_wall=57, gb_free=17.4, wall=188
2023-08-09 11:28:05 | INFO | train_inner | epoch 027:    292 / 1474 loss=2.033, trans_loss=4.965, nll_loss=2.15, w2v_ctc_loss=0.64, task_loss=0, contrastive_loss=0.046, total=4162.23, n_correct=2760.26, ppl=4.44, accuracy=66.317, wps=14614.6, ups=1.76, wpb=8324.5, bsz=305.5, num_updates=38600, lr=7.19816e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=56, gb_free=17.4, wall=245
2023-08-09 11:29:02 | INFO | train_inner | epoch 027:    392 / 1474 loss=2.064, trans_loss=4.976, nll_loss=2.165, w2v_ctc_loss=0.645, task_loss=0, contrastive_loss=0.224, total=4079.05, n_correct=2688.45, ppl=4.49, accuracy=65.909, wps=14255.3, ups=1.75, wpb=8158.1, bsz=297.1, num_updates=38700, lr=7.18885e-05, gnorm=0.559, clip=0, loss_scale=64, train_wall=57, gb_free=17.1, wall=302
2023-08-09 11:29:59 | INFO | train_inner | epoch 027:    492 / 1474 loss=2.057, trans_loss=4.979, nll_loss=2.17, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.161, total=4243.25, n_correct=2798.02, ppl=4.5, accuracy=65.94, wps=14733.6, ups=1.74, wpb=8486.5, bsz=331, num_updates=38800, lr=7.17958e-05, gnorm=0.545, clip=0, loss_scale=64, train_wall=57, gb_free=16.1, wall=360
2023-08-09 11:30:56 | INFO | train_inner | epoch 027:    592 / 1474 loss=2.047, trans_loss=4.974, nll_loss=2.163, w2v_ctc_loss=0.644, task_loss=0, contrastive_loss=0.101, total=4137.92, n_correct=2734.51, ppl=4.48, accuracy=66.084, wps=14598.1, ups=1.76, wpb=8275.8, bsz=313.5, num_updates=38900, lr=7.17035e-05, gnorm=0.555, clip=0, loss_scale=64, train_wall=56, gb_free=16.2, wall=416
2023-08-09 11:31:52 | INFO | train_inner | epoch 027:    692 / 1474 loss=2.045, trans_loss=4.981, nll_loss=2.172, w2v_ctc_loss=0.645, task_loss=0, contrastive_loss=0.078, total=4158.48, n_correct=2739.47, ppl=4.51, accuracy=65.877, wps=14777.2, ups=1.78, wpb=8317, bsz=304.1, num_updates=39000, lr=7.16115e-05, gnorm=0.553, clip=0, loss_scale=64, train_wall=56, gb_free=15.9, wall=473
2023-08-09 11:32:49 | INFO | train_inner | epoch 027:    792 / 1474 loss=2.041, trans_loss=4.98, nll_loss=2.171, w2v_ctc_loss=0.65, task_loss=0, contrastive_loss=0.044, total=4100.88, n_correct=2702.01, ppl=4.5, accuracy=65.889, wps=14557.3, ups=1.77, wpb=8201.8, bsz=292.2, num_updates=39100, lr=7.15199e-05, gnorm=0.552, clip=0, loss_scale=64, train_wall=56, gb_free=16, wall=529
2023-08-09 11:33:46 | INFO | train_inner | epoch 027:    892 / 1474 loss=2.035, trans_loss=4.984, nll_loss=2.175, w2v_ctc_loss=0.634, task_loss=0, contrastive_loss=0.039, total=4111.94, n_correct=2711.41, ppl=4.52, accuracy=65.94, wps=14335.9, ups=1.74, wpb=8223.9, bsz=294.9, num_updates=39200, lr=7.14286e-05, gnorm=0.546, clip=0, loss_scale=64, train_wall=57, gb_free=16.2, wall=586
2023-08-09 11:34:43 | INFO | train_inner | epoch 027:    992 / 1474 loss=2.062, trans_loss=4.981, nll_loss=2.173, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.222, total=4189.27, n_correct=2758.43, ppl=4.51, accuracy=65.845, wps=14722.6, ups=1.76, wpb=8378.5, bsz=314.9, num_updates=39300, lr=7.13376e-05, gnorm=0.548, clip=0, loss_scale=64, train_wall=56, gb_free=14.7, wall=643
2023-08-09 11:35:40 | INFO | train_inner | epoch 027:   1092 / 1474 loss=2.039, trans_loss=4.98, nll_loss=2.172, w2v_ctc_loss=0.64, task_loss=0, contrastive_loss=0.055, total=4160.42, n_correct=2742.74, ppl=4.51, accuracy=65.925, wps=14705.1, ups=1.77, wpb=8320.8, bsz=307.3, num_updates=39400, lr=7.1247e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=56, gb_free=17.2, wall=700
2023-08-09 11:36:36 | INFO | train_inner | epoch 027:   1192 / 1474 loss=2.046, trans_loss=4.988, nll_loss=2.182, w2v_ctc_loss=0.649, task_loss=0, contrastive_loss=0.056, total=4103.72, n_correct=2697.33, ppl=4.54, accuracy=65.729, wps=14544.5, ups=1.77, wpb=8207.4, bsz=297.1, num_updates=39500, lr=7.11568e-05, gnorm=0.555, clip=0, loss_scale=64, train_wall=56, gb_free=17.9, wall=756
2023-08-09 11:37:33 | INFO | train_inner | epoch 027:   1292 / 1474 loss=2.058, trans_loss=4.995, nll_loss=2.191, w2v_ctc_loss=0.649, task_loss=0, contrastive_loss=0.109, total=4065.94, n_correct=2662.95, ppl=4.57, accuracy=65.494, wps=14326.4, ups=1.76, wpb=8131.9, bsz=292.4, num_updates=39600, lr=7.10669e-05, gnorm=0.56, clip=0, loss_scale=64, train_wall=56, gb_free=16.4, wall=813
2023-08-09 11:38:29 | INFO | train_inner | epoch 027:   1392 / 1474 loss=2.049, trans_loss=4.988, nll_loss=2.183, w2v_ctc_loss=0.643, task_loss=0, contrastive_loss=0.092, total=4149.21, n_correct=2729.58, ppl=4.54, accuracy=65.786, wps=14786.4, ups=1.78, wpb=8298.4, bsz=312.6, num_updates=39700, lr=7.09773e-05, gnorm=0.554, clip=0, loss_scale=64, train_wall=56, gb_free=17.1, wall=869
2023-08-09 11:39:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-09 11:39:38 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.357 | trans_loss 5.55 | nll_loss 2.82 | w2v_ctc_loss 1.363 | task_loss 0 | contrastive_loss 0.241 | total 4003.4 | n_correct 2496.3 | ppl 7.06 | accuracy 62.354 | uer 17.198 | wer 18.925 | raw_wer 18.925 | bleu 20.3 | wps 2230.6 | wpb 4003.4 | bsz 141.8 | num_updates 39782 | best_bleu 20.34
2023-08-09 11:39:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39782 updates
2023-08-09 11:39:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_20.3005.pt
2023-08-09 11:39:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_20.3005.pt
2023-08-09 11:40:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_20.3005.pt (epoch 27 @ 39782 updates, score 20.3) (writing took 30.712668163701892 seconds)
2023-08-09 11:40:10 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-09 11:40:10 | INFO | train | epoch 027 | loss 2.045 | trans_loss 4.977 | nll_loss 2.167 | w2v_ctc_loss 0.642 | task_loss 0 | contrastive_loss 0.093 | total 4138.65 | n_correct 2730.22 | ppl 4.49 | accuracy 65.969 | wps 13687.3 | ups 1.65 | wpb 8277.3 | bsz 305.7 | num_updates 39782 | lr 7.09042e-05 | gnorm 0.553 | clip 0 | loss_scale 64 | train_wall 841 | gb_free 18.1 | wall 970
2023-08-09 11:40:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-09 11:40:10 | INFO | fairseq.trainer | begin training epoch 28
2023-08-09 11:40:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-09 11:40:27 | INFO | train_inner | epoch 028:     18 / 1474 loss=2.036, trans_loss=4.979, nll_loss=2.171, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.045, total=4106.72, n_correct=2709.26, ppl=4.5, accuracy=65.971, wps=6953.6, ups=0.85, wpb=8213.4, bsz=305, num_updates=39800, lr=7.08881e-05, gnorm=0.553, clip=0, loss_scale=64, train_wall=56, gb_free=16.3, wall=987
2023-08-09 11:41:23 | INFO | train_inner | epoch 028:    118 / 1474 loss=2.022, trans_loss=4.948, nll_loss=2.128, w2v_ctc_loss=0.634, task_loss=0, contrastive_loss=0.042, total=4103.42, n_correct=2730.41, ppl=4.37, accuracy=66.54, wps=14569.9, ups=1.78, wpb=8206.8, bsz=292, num_updates=39900, lr=7.07992e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=56, gb_free=16.4, wall=1044
2023-08-09 11:42:20 | INFO | train_inner | epoch 028:    218 / 1474 loss=2.021, trans_loss=4.952, nll_loss=2.134, w2v_ctc_loss=0.623, task_loss=0, contrastive_loss=0.049, total=4200.12, n_correct=2796.64, ppl=4.39, accuracy=66.585, wps=14740.6, ups=1.75, wpb=8400.2, bsz=317.8, num_updates=40000, lr=7.07107e-05, gnorm=0.54, clip=0, loss_scale=64, train_wall=57, gb_free=11.6, wall=1101
2023-08-09 11:42:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-09 11:42:44 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.374 | trans_loss 5.553 | nll_loss 2.825 | w2v_ctc_loss 1.408 | task_loss 0 | contrastive_loss 0.24 | total 4003.4 | n_correct 2497.3 | ppl 7.09 | accuracy 62.379 | uer 17.219 | wer 18.944 | raw_wer 18.944 | bleu 20.09 | wps 2197.6 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.34
2023-08-09 11:42:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-08-09 11:42:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_28_40000.pt
2023-08-09 11:42:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_28_40000.pt
2023-08-09 11:43:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 20.09) (writing took 36.517623510211706 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2377)
2023-08-09 11:44:22 | INFO | train_inner | epoch 028:    318 / 1474 loss=2.074, trans_loss=4.965, nll_loss=2.152, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.377, total=4147.36, n_correct=2740.74, ppl=4.44, accuracy=66.084, wps=6840.6, ups=0.82, wpb=8294.7, bsz=315.4, num_updates=40100, lr=7.06225e-05, gnorm=0.562, clip=0, loss_scale=64, train_wall=56, gb_free=17, wall=1222
2023-08-09 11:45:17 | INFO | train_inner | epoch 028:    418 / 1474 loss=2.031, trans_loss=4.964, nll_loss=2.149, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.038, total=4087.34, n_correct=2707.99, ppl=4.44, accuracy=66.253, wps=14699.1, ups=1.8, wpb=8174.7, bsz=295.1, num_updates=40200, lr=7.05346e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=55, gb_free=17.1, wall=1278
2023-08-09 11:46:14 | INFO | train_inner | epoch 028:    518 / 1474 loss=2.029, trans_loss=4.964, nll_loss=2.149, w2v_ctc_loss=0.632, task_loss=0, contrastive_loss=0.049, total=4099.71, n_correct=2713.15, ppl=4.43, accuracy=66.179, wps=14514.6, ups=1.77, wpb=8199.4, bsz=296.2, num_updates=40300, lr=7.0447e-05, gnorm=0.553, clip=0, loss_scale=64, train_wall=56, gb_free=15.5, wall=1334
2023-08-09 11:47:11 | INFO | train_inner | epoch 028:    618 / 1474 loss=2.034, trans_loss=4.975, nll_loss=2.164, w2v_ctc_loss=0.638, task_loss=0, contrastive_loss=0.049, total=4177.06, n_correct=2757.64, ppl=4.48, accuracy=66.019, wps=14648.2, ups=1.75, wpb=8354.1, bsz=304.1, num_updates=40400, lr=7.03598e-05, gnorm=0.553, clip=0, loss_scale=128, train_wall=56, gb_free=17.5, wall=1391
2023-08-09 11:47:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-09 11:48:08 | INFO | train_inner | epoch 028:    719 / 1474 loss=2.048, trans_loss=4.973, nll_loss=2.163, w2v_ctc_loss=0.638, task_loss=0, contrastive_loss=0.143, total=4159.81, n_correct=2751.53, ppl=4.48, accuracy=66.146, wps=14453.2, ups=1.74, wpb=8319.6, bsz=320.3, num_updates=40500, lr=7.02728e-05, gnorm=0.552, clip=0, loss_scale=64, train_wall=57, gb_free=16.3, wall=1449
2023-08-09 11:49:04 | INFO | train_inner | epoch 028:    819 / 1474 loss=2.028, trans_loss=4.968, nll_loss=2.156, w2v_ctc_loss=0.633, task_loss=0, contrastive_loss=0.042, total=4096.2, n_correct=2718.19, ppl=4.46, accuracy=66.359, wps=14645.6, ups=1.79, wpb=8192.4, bsz=307, num_updates=40600, lr=7.01862e-05, gnorm=0.553, clip=0, loss_scale=64, train_wall=55, gb_free=16.1, wall=1505
2023-08-09 11:50:02 | INFO | train_inner | epoch 028:    919 / 1474 loss=2.046, trans_loss=4.979, nll_loss=2.17, w2v_ctc_loss=0.64, task_loss=0, contrastive_loss=0.101, total=4120.27, n_correct=2719.71, ppl=4.5, accuracy=66.008, wps=14344, ups=1.74, wpb=8240.5, bsz=300.8, num_updates=40700, lr=7.01e-05, gnorm=0.558, clip=0, loss_scale=64, train_wall=57, gb_free=17.7, wall=1562
2023-08-09 11:50:58 | INFO | train_inner | epoch 028:   1019 / 1474 loss=2.054, trans_loss=4.977, nll_loss=2.168, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.15, total=4177.86, n_correct=2754.87, ppl=4.49, accuracy=65.94, wps=14748.8, ups=1.77, wpb=8355.7, bsz=311.1, num_updates=40800, lr=7.0014e-05, gnorm=0.559, clip=0, loss_scale=64, train_wall=56, gb_free=16.7, wall=1619
2023-08-09 11:51:55 | INFO | train_inner | epoch 028:   1119 / 1474 loss=2.035, trans_loss=4.97, nll_loss=2.159, w2v_ctc_loss=0.636, task_loss=0, contrastive_loss=0.057, total=4210.86, n_correct=2784.63, ppl=4.47, accuracy=66.13, wps=14984.9, ups=1.78, wpb=8421.7, bsz=318.9, num_updates=40900, lr=6.99284e-05, gnorm=0.553, clip=0, loss_scale=64, train_wall=56, gb_free=17.8, wall=1675
2023-08-09 11:52:50 | INFO | train_inner | epoch 028:   1219 / 1474 loss=2.03, trans_loss=4.976, nll_loss=2.166, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.047, total=4104.61, n_correct=2714.23, ppl=4.49, accuracy=66.126, wps=14753.6, ups=1.8, wpb=8209.2, bsz=305.6, num_updates=41000, lr=6.9843e-05, gnorm=0.548, clip=0, loss_scale=64, train_wall=55, gb_free=16.8, wall=1731
2023-08-09 11:53:47 | INFO | train_inner | epoch 028:   1319 / 1474 loss=2.043, trans_loss=4.984, nll_loss=2.176, w2v_ctc_loss=0.646, task_loss=0, contrastive_loss=0.062, total=4087.78, n_correct=2690.5, ppl=4.52, accuracy=65.818, wps=14396.8, ups=1.76, wpb=8175.6, bsz=285.1, num_updates=41100, lr=6.9758e-05, gnorm=0.556, clip=0, loss_scale=64, train_wall=56, gb_free=15.3, wall=1787
2023-08-09 11:54:44 | INFO | train_inner | epoch 028:   1419 / 1474 loss=2.045, trans_loss=4.983, nll_loss=2.175, w2v_ctc_loss=0.64, task_loss=0, contrastive_loss=0.084, total=4145.03, n_correct=2729.37, ppl=4.51, accuracy=65.847, wps=14593.3, ups=1.76, wpb=8290.1, bsz=297.6, num_updates=41200, lr=6.96733e-05, gnorm=0.556, clip=0, loss_scale=64, train_wall=56, gb_free=17.9, wall=1844
2023-08-09 11:55:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2377)
mt_weight tensor(0.5000)
asr_weight tensor(0.2377)
mt_weight tensor(0.5000)
asr_weight tensor(0.2377)
mt_weight tensor(0.5000)
asr_weight tensor(0.2377)
mt_weight tensor(0.5000)
asr_weight tensor(0.2377)
mt_weight tensor(0.5000)
asr_weight tensor(0.2377)
mt_weight tensor(0.5000)
asr_weight tensor(0.2377)
2023-08-09 11:55:38 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.382 | trans_loss 5.55 | nll_loss 2.818 | w2v_ctc_loss 1.447 | task_loss 0 | contrastive_loss 0.241 | total 4003.4 | n_correct 2496.3 | ppl 7.05 | accuracy 62.354 | uer 16.967 | wer 18.788 | raw_wer 18.788 | bleu 20.25 | wps 2081.8 | wpb 4003.4 | bsz 141.8 | num_updates 41255 | best_bleu 20.34
2023-08-09 11:55:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41255 updates
2023-08-09 11:55:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_20.2506.pt
2023-08-09 11:55:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_20.2506.pt
2023-08-09 11:55:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_20.2506.pt (epoch 28 @ 41255 updates, score 20.25) (writing took 20.702771324664354 seconds)
2023-08-09 11:55:59 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-09 11:56:00 | INFO | train | epoch 028 | loss 2.038 | trans_loss 4.97 | nll_loss 2.157 | w2v_ctc_loss 0.635 | task_loss 0 | contrastive_loss 0.091 | total 4136.87 | n_correct 2736.91 | ppl 4.46 | accuracy 66.159 | wps 12829.6 | ups 1.55 | wpb 8273.7 | bsz 305.2 | num_updates 41255 | lr 6.96268e-05 | gnorm 0.553 | clip 0 | loss_scale 64 | train_wall 825 | gb_free 16.7 | wall 1920
2023-08-09 11:56:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-09 11:56:00 | INFO | fairseq.trainer | begin training epoch 29
2023-08-09 11:56:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-09 11:56:33 | INFO | train_inner | epoch 029:     45 / 1474 loss=2.027, trans_loss=4.955, nll_loss=2.14, w2v_ctc_loss=0.636, task_loss=0, contrastive_loss=0.052, total=4163.06, n_correct=2771.92, ppl=4.41, accuracy=66.584, wps=7653.2, ups=0.92, wpb=8326.1, bsz=314, num_updates=41300, lr=6.95889e-05, gnorm=0.55, clip=0, loss_scale=64, train_wall=56, gb_free=16.4, wall=1953
2023-08-09 11:57:29 | INFO | train_inner | epoch 029:    145 / 1474 loss=2.027, trans_loss=4.95, nll_loss=2.132, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.08, total=4116.29, n_correct=2741.33, ppl=4.38, accuracy=66.597, wps=14600.5, ups=1.77, wpb=8232.6, bsz=308.5, num_updates=41400, lr=6.95048e-05, gnorm=0.558, clip=0, loss_scale=64, train_wall=56, gb_free=14.4, wall=2009
2023-08-09 11:58:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-09 11:58:27 | INFO | train_inner | epoch 029:    246 / 1474 loss=2.02, trans_loss=4.945, nll_loss=2.125, w2v_ctc_loss=0.626, task_loss=0, contrastive_loss=0.056, total=4170.42, n_correct=2780.74, ppl=4.36, accuracy=66.678, wps=14472.5, ups=1.74, wpb=8340.8, bsz=321.4, num_updates=41500, lr=6.9421e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=57, gb_free=15.9, wall=2067
2023-08-09 11:59:23 | INFO | train_inner | epoch 029:    346 / 1474 loss=2.029, trans_loss=4.964, nll_loss=2.15, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.043, total=4095.17, n_correct=2711.54, ppl=4.44, accuracy=66.213, wps=14652, ups=1.79, wpb=8190.3, bsz=291.2, num_updates=41600, lr=6.93375e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=55, gb_free=17, wall=2123
2023-08-09 12:00:18 | INFO | train_inner | epoch 029:    446 / 1474 loss=2.015, trans_loss=4.943, nll_loss=2.122, w2v_ctc_loss=0.623, task_loss=0, contrastive_loss=0.039, total=4157.44, n_correct=2773.89, ppl=4.35, accuracy=66.721, wps=14997.8, ups=1.8, wpb=8314.9, bsz=307.7, num_updates=41700, lr=6.92543e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=55, gb_free=16.8, wall=2178
2023-08-09 12:01:15 | INFO | train_inner | epoch 029:    546 / 1474 loss=2.043, trans_loss=4.968, nll_loss=2.154, w2v_ctc_loss=0.632, task_loss=0, contrastive_loss=0.129, total=4150.87, n_correct=2745.49, ppl=4.45, accuracy=66.143, wps=14673.1, ups=1.77, wpb=8301.7, bsz=294.9, num_updates=41800, lr=6.91714e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=56, gb_free=16.1, wall=2235
2023-08-09 12:02:12 | INFO | train_inner | epoch 029:    646 / 1474 loss=2.041, trans_loss=4.953, nll_loss=2.138, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.2, total=4143.02, n_correct=2758.16, ppl=4.4, accuracy=66.574, wps=14438.2, ups=1.74, wpb=8286, bsz=318.6, num_updates=41900, lr=6.90889e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=57, gb_free=17.4, wall=2292
2023-08-09 12:03:09 | INFO | train_inner | epoch 029:    746 / 1474 loss=2.04, trans_loss=4.959, nll_loss=2.145, w2v_ctc_loss=0.634, task_loss=0, contrastive_loss=0.119, total=4249.79, n_correct=2819.22, ppl=4.42, accuracy=66.338, wps=14991.5, ups=1.76, wpb=8499.6, bsz=330, num_updates=42000, lr=6.90066e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=2349
2023-08-09 12:03:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-09 12:03:32 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.376 | trans_loss 5.554 | nll_loss 2.826 | w2v_ctc_loss 1.411 | task_loss 0 | contrastive_loss 0.247 | total 4003.4 | n_correct 2491.7 | ppl 7.09 | accuracy 62.24 | uer 17.341 | wer 19.164 | raw_wer 19.164 | bleu 19.93 | wps 2267.1 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.34
2023-08-09 12:03:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-08-09 12:03:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_29_42000.pt
2023-08-09 12:03:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_29_42000.pt
2023-08-09 12:04:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 19.93) (writing took 30.216536501422524 seconds)
2023-08-09 12:04:58 | INFO | train_inner | epoch 029:    846 / 1474 loss=2.032, trans_loss=4.978, nll_loss=2.168, w2v_ctc_loss=0.633, task_loss=0, contrastive_loss=0.038, total=4027.19, n_correct=2657.81, ppl=4.49, accuracy=65.997, wps=7373.3, ups=0.92, wpb=8054.4, bsz=280.6, num_updates=42100, lr=6.89246e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=55, gb_free=17.6, wall=2458
2023-08-09 12:05:53 | INFO | train_inner | epoch 029:    946 / 1474 loss=2.032, trans_loss=4.976, nll_loss=2.166, w2v_ctc_loss=0.636, task_loss=0, contrastive_loss=0.047, total=4082.14, n_correct=2698.37, ppl=4.49, accuracy=66.102, wps=14715.4, ups=1.8, wpb=8164.3, bsz=296.3, num_updates=42200, lr=6.88428e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=55, gb_free=15.7, wall=2514
2023-08-09 12:06:51 | INFO | train_inner | epoch 029:   1046 / 1474 loss=2.036, trans_loss=4.963, nll_loss=2.149, w2v_ctc_loss=0.63, task_loss=0, contrastive_loss=0.119, total=4148.18, n_correct=2747.37, ppl=4.43, accuracy=66.231, wps=14512.6, ups=1.75, wpb=8296.4, bsz=308.2, num_updates=42300, lr=6.87614e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=57, gb_free=16.3, wall=2571
2023-08-09 12:07:47 | INFO | train_inner | epoch 029:   1146 / 1474 loss=2.034, trans_loss=4.98, nll_loss=2.171, w2v_ctc_loss=0.643, task_loss=0, contrastive_loss=0.035, total=4063.95, n_correct=2680.04, ppl=4.5, accuracy=65.947, wps=14532.8, ups=1.79, wpb=8127.9, bsz=283, num_updates=42400, lr=6.86803e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=55, gb_free=13.8, wall=2627
2023-08-09 12:08:43 | INFO | train_inner | epoch 029:   1246 / 1474 loss=2.032, trans_loss=4.978, nll_loss=2.169, w2v_ctc_loss=0.635, task_loss=0, contrastive_loss=0.041, total=4158.81, n_correct=2750.64, ppl=4.5, accuracy=66.14, wps=14811.1, ups=1.78, wpb=8317.6, bsz=301.2, num_updates=42500, lr=6.85994e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=56, gb_free=16, wall=2683
2023-08-09 12:09:39 | INFO | train_inner | epoch 029:   1346 / 1474 loss=2.038, trans_loss=4.97, nll_loss=2.159, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.104, total=4166.34, n_correct=2756.62, ppl=4.47, accuracy=66.164, wps=14823.5, ups=1.78, wpb=8332.7, bsz=310.7, num_updates=42600, lr=6.85189e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=56, gb_free=18.1, wall=2739
2023-08-09 12:10:36 | INFO | train_inner | epoch 029:   1446 / 1474 loss=2.043, trans_loss=4.971, nll_loss=2.161, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.136, total=4162.2, n_correct=2752.72, ppl=4.47, accuracy=66.136, wps=14596.5, ups=1.75, wpb=8324.4, bsz=311.5, num_updates=42700, lr=6.84386e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=57, gb_free=17.6, wall=2796
2023-08-09 12:10:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-09 12:11:14 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.385 | trans_loss 5.549 | nll_loss 2.818 | w2v_ctc_loss 1.455 | task_loss 0 | contrastive_loss 0.244 | total 4003.4 | n_correct 2501.9 | ppl 7.05 | accuracy 62.494 | uer 16.954 | wer 18.72 | raw_wer 18.72 | bleu 20.28 | wps 2306.8 | wpb 4003.4 | bsz 141.8 | num_updates 42728 | best_bleu 20.34
2023-08-09 12:11:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42728 updates
2023-08-09 12:11:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_20.2803.pt
2023-08-09 12:11:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_20.2803.pt
2023-08-09 12:11:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_20.2803.pt (epoch 29 @ 42728 updates, score 20.28) (writing took 15.584853580221534 seconds)
2023-08-09 12:11:30 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-09 12:11:30 | INFO | train | epoch 029 | loss 2.032 | trans_loss 4.963 | nll_loss 2.149 | w2v_ctc_loss 0.631 | task_loss 0 | contrastive_loss 0.084 | total 4136.74 | n_correct 2742.9 | ppl 4.44 | accuracy 66.306 | wps 13095.6 | ups 1.58 | wpb 8273.5 | bsz 305.1 | num_updates 42728 | lr 6.84162e-05 | gnorm 0.555 | clip 0 | loss_scale 32 | train_wall 823 | gb_free 16.3 | wall 2850
2023-08-09 12:11:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-09 12:11:30 | INFO | fairseq.trainer | begin training epoch 30
2023-08-09 12:11:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-09 12:12:18 | INFO | train_inner | epoch 030:     72 / 1474 loss=2.027, trans_loss=4.944, nll_loss=2.125, w2v_ctc_loss=0.609, task_loss=0, contrastive_loss=0.149, total=4182.65, n_correct=2791.5, ppl=4.36, accuracy=66.74, wps=8184.8, ups=0.98, wpb=8365.3, bsz=320.5, num_updates=42800, lr=6.83586e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=56, gb_free=13.9, wall=2899
2023-08-09 12:13:14 | INFO | train_inner | epoch 030:    172 / 1474 loss=2.016, trans_loss=4.93, nll_loss=2.106, w2v_ctc_loss=0.621, task_loss=0, contrastive_loss=0.081, total=4203.05, n_correct=2816.77, ppl=4.3, accuracy=67.017, wps=15038.8, ups=1.79, wpb=8406.1, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=55, gb_free=17.7, wall=2954
2023-08-09 12:14:10 | INFO | train_inner | epoch 030:    272 / 1474 loss=2.019, trans_loss=4.947, nll_loss=2.127, w2v_ctc_loss=0.631, task_loss=0, contrastive_loss=0.037, total=4116.93, n_correct=2744.59, ppl=4.37, accuracy=66.666, wps=14774.6, ups=1.79, wpb=8233.9, bsz=295.1, num_updates=43000, lr=6.81994e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=55, gb_free=17.2, wall=3010
2023-08-09 12:15:07 | INFO | train_inner | epoch 030:    372 / 1474 loss=2.014, trans_loss=4.941, nll_loss=2.12, w2v_ctc_loss=0.621, task_loss=0, contrastive_loss=0.04, total=4173.13, n_correct=2787.22, ppl=4.35, accuracy=66.79, wps=14507, ups=1.74, wpb=8346.3, bsz=305.6, num_updates=43100, lr=6.81203e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=57, gb_free=12.4, wall=3068
2023-08-09 12:16:03 | INFO | train_inner | epoch 030:    472 / 1474 loss=2.026, trans_loss=4.947, nll_loss=2.129, w2v_ctc_loss=0.621, task_loss=0, contrastive_loss=0.101, total=4135.2, n_correct=2756.53, ppl=4.37, accuracy=66.66, wps=14840, ups=1.79, wpb=8270.4, bsz=314.8, num_updates=43200, lr=6.80414e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=55, gb_free=17.2, wall=3123
2023-08-09 12:16:59 | INFO | train_inner | epoch 030:    572 / 1474 loss=2.021, trans_loss=4.953, nll_loss=2.136, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.063, total=4168.65, n_correct=2778.52, ppl=4.4, accuracy=66.653, wps=14925.6, ups=1.79, wpb=8337.3, bsz=312.1, num_updates=43300, lr=6.79628e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=55, gb_free=16.2, wall=3179
2023-08-09 12:17:55 | INFO | train_inner | epoch 030:    672 / 1474 loss=2.026, trans_loss=4.952, nll_loss=2.136, w2v_ctc_loss=0.626, task_loss=0, contrastive_loss=0.074, total=4183.65, n_correct=2783.77, ppl=4.4, accuracy=66.539, wps=14850.3, ups=1.77, wpb=8367.3, bsz=314.5, num_updates=43400, lr=6.78844e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=56, gb_free=17.1, wall=3236
2023-08-09 12:18:52 | INFO | train_inner | epoch 030:    772 / 1474 loss=2.04, trans_loss=4.961, nll_loss=2.147, w2v_ctc_loss=0.626, task_loss=0, contrastive_loss=0.156, total=4106.9, n_correct=2726.36, ppl=4.43, accuracy=66.385, wps=14427.5, ups=1.76, wpb=8213.8, bsz=302.9, num_updates=43500, lr=6.78064e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=56, gb_free=12.5, wall=3293
2023-08-09 12:19:48 | INFO | train_inner | epoch 030:    872 / 1474 loss=2.023, trans_loss=4.963, nll_loss=2.148, w2v_ctc_loss=0.623, task_loss=0, contrastive_loss=0.042, total=4089.18, n_correct=2712.48, ppl=4.43, accuracy=66.333, wps=14667.7, ups=1.79, wpb=8178.4, bsz=291.4, num_updates=43600, lr=6.77285e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=55, gb_free=16.7, wall=3348
2023-08-09 12:20:44 | INFO | train_inner | epoch 030:    972 / 1474 loss=2.026, trans_loss=4.961, nll_loss=2.147, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.059, total=4140.03, n_correct=2746.29, ppl=4.43, accuracy=66.335, wps=14823.6, ups=1.79, wpb=8280.1, bsz=303.9, num_updates=43700, lr=6.7651e-05, gnorm=0.556, clip=0, loss_scale=64, train_wall=55, gb_free=14.3, wall=3404
2023-08-09 12:21:40 | INFO | train_inner | epoch 030:   1072 / 1474 loss=2.039, trans_loss=4.974, nll_loss=2.162, w2v_ctc_loss=0.63, task_loss=0, contrastive_loss=0.129, total=4101.12, n_correct=2711.09, ppl=4.48, accuracy=66.106, wps=14500.6, ups=1.77, wpb=8202.2, bsz=282.8, num_updates=43800, lr=6.75737e-05, gnorm=0.553, clip=0, loss_scale=64, train_wall=56, gb_free=16.8, wall=3461
2023-08-09 12:21:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-09 12:22:38 | INFO | train_inner | epoch 030:   1173 / 1474 loss=2.018, trans_loss=4.957, nll_loss=2.143, w2v_ctc_loss=0.617, task_loss=0, contrastive_loss=0.046, total=4154.23, n_correct=2763.33, ppl=4.42, accuracy=66.518, wps=14476, ups=1.74, wpb=8308.5, bsz=308.5, num_updates=43900, lr=6.74967e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=16.2, wall=3518
2023-08-09 12:23:34 | INFO | train_inner | epoch 030:   1273 / 1474 loss=2.03, trans_loss=4.969, nll_loss=2.157, w2v_ctc_loss=0.635, task_loss=0, contrastive_loss=0.045, total=4036.17, n_correct=2668.65, ppl=4.46, accuracy=66.118, wps=14467, ups=1.79, wpb=8072.3, bsz=284.3, num_updates=44000, lr=6.742e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=55, gb_free=16.1, wall=3574
2023-08-09 12:23:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-09 12:23:58 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.373 | trans_loss 5.546 | nll_loss 2.812 | w2v_ctc_loss 1.423 | task_loss 0 | contrastive_loss 0.246 | total 4003.4 | n_correct 2506.9 | ppl 7.02 | accuracy 62.619 | uer 16.837 | wer 18.564 | raw_wer 18.564 | bleu 20.31 | wps 2065.6 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.34
2023-08-09 12:23:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-08-09 12:23:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_30_44000.pt
2023-08-09 12:24:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_30_44000.pt
2023-08-09 12:24:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 20.31) (writing took 15.013009717687964 seconds)
2023-08-09 12:25:09 | INFO | train_inner | epoch 030:   1373 / 1474 loss=2.024, trans_loss=4.96, nll_loss=2.148, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.053, total=4165.07, n_correct=2769.16, ppl=4.43, accuracy=66.485, wps=8707.5, ups=1.05, wpb=8330.1, bsz=321.6, num_updates=44100, lr=6.73435e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=3670
2023-08-09 12:26:05 | INFO | train_inner | epoch 030:   1473 / 1474 loss=2.047, trans_loss=4.97, nll_loss=2.16, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.201, total=4141.76, n_correct=2743.98, ppl=4.47, accuracy=66.252, wps=14882.8, ups=1.8, wpb=8283.5, bsz=314.3, num_updates=44200, lr=6.72673e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=55, gb_free=16.6, wall=3725
2023-08-09 12:26:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-09 12:26:29 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.371 | trans_loss 5.554 | nll_loss 2.824 | w2v_ctc_loss 1.393 | task_loss 0 | contrastive_loss 0.252 | total 4003.4 | n_correct 2499.6 | ppl 7.08 | accuracy 62.437 | uer 16.927 | wer 18.739 | raw_wer 18.739 | bleu 20.14 | wps 2160.8 | wpb 4003.4 | bsz 141.8 | num_updates 44201 | best_bleu 20.34
2023-08-09 12:26:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44201 updates
2023-08-09 12:26:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_20.1408.pt
2023-08-09 12:26:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_20.1408.pt
2023-08-09 12:27:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_20.1408.pt (epoch 30 @ 44201 updates, score 20.14) (writing took 36.2757645919919 seconds)
2023-08-09 12:27:08 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-09 12:27:08 | INFO | train | epoch 030 | loss 2.026 | trans_loss 4.955 | nll_loss 2.139 | w2v_ctc_loss 0.624 | task_loss 0 | contrastive_loss 0.086 | total 4137.63 | n_correct 2751.81 | ppl 4.41 | accuracy 66.507 | wps 12999.6 | ups 1.57 | wpb 8275.3 | bsz 305.3 | num_updates 44201 | lr 6.72665e-05 | gnorm 0.555 | clip 0 | loss_scale 32 | train_wall 821 | gb_free 17.4 | wall 3788
2023-08-09 12:27:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-09 12:27:08 | INFO | fairseq.trainer | begin training epoch 31
2023-08-09 12:27:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-09 12:28:12 | INFO | train_inner | epoch 031:     99 / 1474 loss=2.015, trans_loss=4.939, nll_loss=2.116, w2v_ctc_loss=0.628, task_loss=0, contrastive_loss=0.04, total=4054.44, n_correct=2709.71, ppl=4.34, accuracy=66.833, wps=6376.8, ups=0.79, wpb=8108.9, bsz=288.2, num_updates=44300, lr=6.71913e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=56, gb_free=16.7, wall=3852
2023-08-09 12:29:08 | INFO | train_inner | epoch 031:    199 / 1474 loss=2.017, trans_loss=4.941, nll_loss=2.119, w2v_ctc_loss=0.621, task_loss=0, contrastive_loss=0.065, total=4147.4, n_correct=2770.58, ppl=4.35, accuracy=66.803, wps=14829.6, ups=1.79, wpb=8294.8, bsz=302.2, num_updates=44400, lr=6.71156e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=55, gb_free=17.1, wall=3908
2023-08-09 12:30:04 | INFO | train_inner | epoch 031:    299 / 1474 loss=2.022, trans_loss=4.94, nll_loss=2.119, w2v_ctc_loss=0.621, task_loss=0, contrastive_loss=0.105, total=4149.21, n_correct=2769.92, ppl=4.34, accuracy=66.758, wps=14770.8, ups=1.78, wpb=8298.4, bsz=301.6, num_updates=44500, lr=6.70402e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=56, gb_free=16.5, wall=3965
2023-08-09 12:31:00 | INFO | train_inner | epoch 031:    399 / 1474 loss=2.016, trans_loss=4.951, nll_loss=2.132, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.043, total=4092.62, n_correct=2727.26, ppl=4.38, accuracy=66.638, wps=14584.4, ups=1.78, wpb=8185.2, bsz=285.6, num_updates=44600, lr=6.6965e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=56, gb_free=17.5, wall=4021
2023-08-09 12:31:57 | INFO | train_inner | epoch 031:    499 / 1474 loss=2.014, trans_loss=4.941, nll_loss=2.119, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.05, total=4111.85, n_correct=2747.35, ppl=4.35, accuracy=66.815, wps=14502.8, ups=1.76, wpb=8223.7, bsz=300.3, num_updates=44700, lr=6.689e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=56, gb_free=11.6, wall=4077
2023-08-09 12:32:53 | INFO | train_inner | epoch 031:    599 / 1474 loss=2.013, trans_loss=4.945, nll_loss=2.125, w2v_ctc_loss=0.615, task_loss=0, contrastive_loss=0.041, total=4083.44, n_correct=2724.31, ppl=4.36, accuracy=66.716, wps=14628.6, ups=1.79, wpb=8166.9, bsz=294.5, num_updates=44800, lr=6.68153e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=55, gb_free=17, wall=4133
2023-08-09 12:33:48 | INFO | train_inner | epoch 031:    699 / 1474 loss=2.009, trans_loss=4.942, nll_loss=2.122, w2v_ctc_loss=0.612, task_loss=0, contrastive_loss=0.042, total=4213.98, n_correct=2816.37, ppl=4.35, accuracy=66.834, wps=15173.5, ups=1.8, wpb=8428, bsz=315.7, num_updates=44900, lr=6.67409e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=55, gb_free=16.5, wall=4189
2023-08-09 12:34:45 | INFO | train_inner | epoch 031:    799 / 1474 loss=2.033, trans_loss=4.96, nll_loss=2.145, w2v_ctc_loss=0.626, task_loss=0, contrastive_loss=0.109, total=4097.37, n_correct=2717.85, ppl=4.42, accuracy=66.332, wps=14579.6, ups=1.78, wpb=8194.7, bsz=295.8, num_updates=45000, lr=6.66667e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=56, gb_free=13.5, wall=4245
mt_weight tensor(0.5000)
asr_weight tensor(0.2377)
2023-08-09 12:35:41 | INFO | train_inner | epoch 031:    899 / 1474 loss=2.016, trans_loss=4.945, nll_loss=2.126, w2v_ctc_loss=0.619, task_loss=0, contrastive_loss=0.055, total=4096.72, n_correct=2732, ppl=4.37, accuracy=66.687, wps=14571.3, ups=1.78, wpb=8193.4, bsz=296.1, num_updates=45100, lr=6.65927e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=56, gb_free=17.5, wall=4301
2023-08-09 12:36:37 | INFO | train_inner | epoch 031:    999 / 1474 loss=2.03, trans_loss=4.956, nll_loss=2.141, w2v_ctc_loss=0.614, task_loss=0, contrastive_loss=0.137, total=4187.84, n_correct=2790.19, ppl=4.41, accuracy=66.626, wps=14893, ups=1.78, wpb=8375.7, bsz=319.5, num_updates=45200, lr=6.6519e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=56, gb_free=17.6, wall=4358
2023-08-09 12:37:33 | INFO | train_inner | epoch 031:   1099 / 1474 loss=2.024, trans_loss=4.951, nll_loss=2.134, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.085, total=4149.44, n_correct=2765.31, ppl=4.39, accuracy=66.643, wps=14895.8, ups=1.79, wpb=8298.9, bsz=315, num_updates=45300, lr=6.64455e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=55, gb_free=17.9, wall=4413
2023-08-09 12:38:29 | INFO | train_inner | epoch 031:   1199 / 1474 loss=2.044, trans_loss=4.961, nll_loss=2.149, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.202, total=4189.76, n_correct=2780.66, ppl=4.43, accuracy=66.368, wps=14936.9, ups=1.78, wpb=8379.5, bsz=321.3, num_updates=45400, lr=6.63723e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=56, gb_free=13.7, wall=4469
2023-08-09 12:39:26 | INFO | train_inner | epoch 031:   1299 / 1474 loss=2.022, trans_loss=4.958, nll_loss=2.143, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.048, total=4227.44, n_correct=2816.44, ppl=4.42, accuracy=66.623, wps=14906.1, ups=1.76, wpb=8454.9, bsz=326.3, num_updates=45500, lr=6.62994e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=56, gb_free=16.6, wall=4526
2023-08-09 12:40:22 | INFO | train_inner | epoch 031:   1399 / 1474 loss=2.051, trans_loss=4.956, nll_loss=2.143, w2v_ctc_loss=0.617, task_loss=0, contrastive_loss=0.248, total=4186.05, n_correct=2781.96, ppl=4.42, accuracy=66.458, wps=14935.7, ups=1.78, wpb=8372.1, bsz=326.6, num_updates=45600, lr=6.62266e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=56, gb_free=17.8, wall=4582
2023-08-09 12:41:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2377)
mt_weight tensor(0.5000)
asr_weight tensor(0.2377)
mt_weight tensor(0.5000)
asr_weight tensor(0.2377)
mt_weight tensor(0.5000)
asr_weight tensor(0.2377)
mt_weight tensor(0.5000)
asr_weight tensor(0.2377)
mt_weight tensor(0.5000)
asr_weight tensor(0.2377)
mt_weight tensor(0.5000)
asr_weight tensor(0.2377)
2023-08-09 12:41:26 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.368 | trans_loss 5.547 | nll_loss 2.816 | w2v_ctc_loss 1.407 | task_loss 0 | contrastive_loss 0.242 | total 4003.4 | n_correct 2503.2 | ppl 7.04 | accuracy 62.527 | uer 16.741 | wer 18.553 | raw_wer 18.553 | bleu 20.33 | wps 2222.6 | wpb 4003.4 | bsz 141.8 | num_updates 45675 | best_bleu 20.34
2023-08-09 12:41:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45675 updates
2023-08-09 12:41:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_20.3307.pt
2023-08-09 12:41:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_20.3307.pt
2023-08-09 12:42:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint.best_bleu_20.3307.pt (epoch 31 @ 45675 updates, score 20.33) (writing took 36.44872625172138 seconds)
2023-08-09 12:42:03 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-09 12:42:03 | INFO | train | epoch 031 | loss 2.023 | trans_loss 4.95 | nll_loss 2.132 | w2v_ctc_loss 0.621 | task_loss 0 | contrastive_loss 0.09 | total 4138.65 | n_correct 2758.15 | ppl 4.38 | accuracy 66.644 | wps 13624.5 | ups 1.65 | wpb 8277.3 | bsz 305.7 | num_updates 45675 | lr 6.61722e-05 | gnorm 0.556 | clip 0 | loss_scale 32 | train_wall 821 | gb_free 12.6 | wall 4684
2023-08-09 12:42:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-09 12:42:04 | INFO | fairseq.trainer | begin training epoch 32
2023-08-09 12:42:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-09 12:42:25 | INFO | train_inner | epoch 032:     25 / 1474 loss=2.013, trans_loss=4.949, nll_loss=2.132, w2v_ctc_loss=0.619, task_loss=0, contrastive_loss=0.038, total=4042.6, n_correct=2697.81, ppl=4.38, accuracy=66.735, wps=6547.8, ups=0.81, wpb=8085.2, bsz=288.7, num_updates=45700, lr=6.61541e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=56, gb_free=16.7, wall=4706
2023-08-09 12:43:22 | INFO | train_inner | epoch 032:    125 / 1474 loss=1.996, trans_loss=4.915, nll_loss=2.087, w2v_ctc_loss=0.601, task_loss=0, contrastive_loss=0.047, total=4227.68, n_correct=2847.36, ppl=4.25, accuracy=67.35, wps=14831.3, ups=1.75, wpb=8455.4, bsz=323.3, num_updates=45800, lr=6.60819e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=57, gb_free=16.3, wall=4763
2023-08-09 12:44:19 | INFO | train_inner | epoch 032:    225 / 1474 loss=2.005, trans_loss=4.929, nll_loss=2.105, w2v_ctc_loss=0.609, task_loss=0, contrastive_loss=0.056, total=4157.32, n_correct=2790.7, ppl=4.3, accuracy=67.127, wps=14636.1, ups=1.76, wpb=8314.6, bsz=320.6, num_updates=45900, lr=6.60098e-05, gnorm=0.557, clip=0, loss_scale=64, train_wall=56, gb_free=17.5, wall=4819
2023-08-09 12:45:15 | INFO | train_inner | epoch 032:    325 / 1474 loss=2.001, trans_loss=4.922, nll_loss=2.096, w2v_ctc_loss=0.605, task_loss=0, contrastive_loss=0.05, total=4183.45, n_correct=2816.43, ppl=4.28, accuracy=67.323, wps=15051.7, ups=1.8, wpb=8366.9, bsz=314.4, num_updates=46000, lr=6.5938e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=55, gb_free=17.8, wall=4875
2023-08-09 12:45:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-09 12:45:37 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.392 | trans_loss 5.555 | nll_loss 2.824 | w2v_ctc_loss 1.464 | task_loss 0 | contrastive_loss 0.245 | total 4003.4 | n_correct 2499.6 | ppl 7.08 | accuracy 62.437 | uer 17.087 | wer 18.966 | raw_wer 18.966 | bleu 20.34 | wps 2286.2 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.34
2023-08-09 12:45:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-08-09 12:45:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_32_46000.pt
2023-08-09 12:45:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_32_46000.pt
2023-08-09 12:46:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 20.34) (writing took 51.32746744155884 seconds)
2023-08-09 12:47:26 | INFO | train_inner | epoch 032:    425 / 1474 loss=2.009, trans_loss=4.932, nll_loss=2.11, w2v_ctc_loss=0.618, task_loss=0, contrastive_loss=0.047, total=4157.28, n_correct=2785.87, ppl=4.32, accuracy=67.012, wps=6345, ups=0.76, wpb=8314.6, bsz=305.9, num_updates=46100, lr=6.58665e-05, gnorm=0.557, clip=0, loss_scale=64, train_wall=56, gb_free=15.2, wall=5006
2023-08-09 12:48:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-09 12:48:24 | INFO | train_inner | epoch 032:    526 / 1474 loss=2.019, trans_loss=4.942, nll_loss=2.122, w2v_ctc_loss=0.626, task_loss=0, contrastive_loss=0.065, total=4183.19, n_correct=2795.74, ppl=4.35, accuracy=66.833, wps=14463.7, ups=1.73, wpb=8366.4, bsz=311.9, num_updates=46200, lr=6.57952e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=57, gb_free=15.4, wall=5064
2023-08-09 12:49:20 | INFO | train_inner | epoch 032:    626 / 1474 loss=2.018, trans_loss=4.948, nll_loss=2.13, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.055, total=4138.05, n_correct=2761.22, ppl=4.38, accuracy=66.728, wps=14628.9, ups=1.77, wpb=8276.1, bsz=299.5, num_updates=46300, lr=6.57241e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=56, gb_free=13.8, wall=5120
2023-08-09 12:50:16 | INFO | train_inner | epoch 032:    726 / 1474 loss=2.013, trans_loss=4.945, nll_loss=2.126, w2v_ctc_loss=0.621, task_loss=0, contrastive_loss=0.04, total=4156.23, n_correct=2776.42, ppl=4.36, accuracy=66.801, wps=14796.2, ups=1.78, wpb=8312.5, bsz=303, num_updates=46400, lr=6.56532e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=5177
2023-08-09 12:51:12 | INFO | train_inner | epoch 032:    826 / 1474 loss=2.007, trans_loss=4.943, nll_loss=2.123, w2v_ctc_loss=0.609, task_loss=0, contrastive_loss=0.037, total=4112.3, n_correct=2748.72, ppl=4.36, accuracy=66.841, wps=14755.6, ups=1.79, wpb=8224.6, bsz=293.9, num_updates=46500, lr=6.55826e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=55, gb_free=16.2, wall=5232
2023-08-09 12:52:09 | INFO | train_inner | epoch 032:    926 / 1474 loss=2.01, trans_loss=4.948, nll_loss=2.129, w2v_ctc_loss=0.612, task_loss=0, contrastive_loss=0.037, total=4139.37, n_correct=2760.53, ppl=4.38, accuracy=66.69, wps=14588.2, ups=1.76, wpb=8278.7, bsz=298.6, num_updates=46600, lr=6.55122e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=56, gb_free=13.3, wall=5289
2023-08-09 12:53:05 | INFO | train_inner | epoch 032:   1026 / 1474 loss=2.023, trans_loss=4.95, nll_loss=2.132, w2v_ctc_loss=0.613, task_loss=0, contrastive_loss=0.129, total=4121.85, n_correct=2748.89, ppl=4.38, accuracy=66.691, wps=14712.6, ups=1.78, wpb=8243.7, bsz=306.1, num_updates=46700, lr=6.5442e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=56, gb_free=17.1, wall=5345
2023-08-09 12:54:01 | INFO | train_inner | epoch 032:   1126 / 1474 loss=2.026, trans_loss=4.96, nll_loss=2.144, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.072, total=4015.59, n_correct=2664.3, ppl=4.42, accuracy=66.349, wps=14277.1, ups=1.78, wpb=8031.2, bsz=270.1, num_updates=46800, lr=6.5372e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=56, gb_free=17.5, wall=5401
2023-08-09 12:54:57 | INFO | train_inner | epoch 032:   1226 / 1474 loss=2.045, trans_loss=4.966, nll_loss=2.154, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.173, total=4153.44, n_correct=2752.55, ppl=4.45, accuracy=66.272, wps=14751.9, ups=1.78, wpb=8306.9, bsz=310.8, num_updates=46900, lr=6.53023e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=56, gb_free=16.6, wall=5458
2023-08-09 12:55:54 | INFO | train_inner | epoch 032:   1326 / 1474 loss=2.02, trans_loss=4.956, nll_loss=2.14, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.037, total=4075.86, n_correct=2711.11, ppl=4.41, accuracy=66.516, wps=14346.6, ups=1.76, wpb=8151.7, bsz=295.4, num_updates=47000, lr=6.52328e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=56, gb_free=17.1, wall=5515
2023-08-09 12:56:50 | INFO | train_inner | epoch 032:   1426 / 1474 loss=2.047, trans_loss=4.956, nll_loss=2.141, w2v_ctc_loss=0.621, task_loss=0, contrastive_loss=0.268, total=4116.4, n_correct=2736.69, ppl=4.41, accuracy=66.483, wps=14715.8, ups=1.79, wpb=8232.8, bsz=307.6, num_updates=47100, lr=6.51635e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=55, gb_free=17, wall=5571
2023-08-09 12:57:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-09 12:57:40 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.36 | trans_loss 5.547 | nll_loss 2.818 | w2v_ctc_loss 1.381 | task_loss 0 | contrastive_loss 0.242 | total 4003.4 | n_correct 2503.3 | ppl 7.05 | accuracy 62.529 | uer 16.656 | wer 18.493 | raw_wer 18.493 | bleu 20.1 | wps 2199.6 | wpb 4003.4 | bsz 141.8 | num_updates 47148 | best_bleu 20.34
2023-08-09 12:57:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47148 updates
2023-08-09 12:57:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_last.pt
2023-08-09 12:57:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_last.pt
2023-08-09 12:57:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_last.pt (epoch 32 @ 47148 updates, score 20.1) (writing took 13.154881618916988 seconds)
2023-08-09 12:57:53 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-09 12:57:53 | INFO | train | epoch 032 | loss 2.018 | trans_loss 4.943 | nll_loss 2.124 | w2v_ctc_loss 0.616 | task_loss 0 | contrastive_loss 0.085 | total 4137.37 | n_correct 2763.62 | ppl 4.36 | accuracy 66.797 | wps 12829.6 | ups 1.55 | wpb 8274.7 | bsz 305.2 | num_updates 47148 | lr 6.51303e-05 | gnorm 0.558 | clip 0 | loss_scale 32 | train_wall 824 | gb_free 16.7 | wall 5634
2023-08-09 12:57:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-09 12:57:54 | INFO | fairseq.trainer | begin training epoch 33
2023-08-09 12:57:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-09 12:58:30 | INFO | train_inner | epoch 033:     52 / 1474 loss=2.023, trans_loss=4.937, nll_loss=2.116, w2v_ctc_loss=0.61, task_loss=0, contrastive_loss=0.14, total=4149.21, n_correct=2777.18, ppl=4.34, accuracy=66.933, wps=8287.7, ups=1, wpb=8298.4, bsz=320.5, num_updates=47200, lr=6.50945e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=56, gb_free=17.3, wall=5671
2023-08-09 12:59:26 | INFO | train_inner | epoch 033:    152 / 1474 loss=1.994, trans_loss=4.921, nll_loss=2.093, w2v_ctc_loss=0.6, task_loss=0, contrastive_loss=0.031, total=4073.9, n_correct=2738.64, ppl=4.27, accuracy=67.224, wps=14618.6, ups=1.79, wpb=8147.8, bsz=284.8, num_updates=47300, lr=6.50256e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=55, gb_free=15.6, wall=5726
2023-08-09 13:00:23 | INFO | train_inner | epoch 033:    252 / 1474 loss=2.027, trans_loss=4.92, nll_loss=2.096, w2v_ctc_loss=0.605, task_loss=0, contrastive_loss=0.197, total=4280.14, n_correct=2880.24, ppl=4.27, accuracy=67.293, wps=15088.6, ups=1.76, wpb=8560.3, bsz=346.5, num_updates=47400, lr=6.4957e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=56, gb_free=16.8, wall=5783
2023-08-09 13:01:19 | INFO | train_inner | epoch 033:    352 / 1474 loss=2.007, trans_loss=4.933, nll_loss=2.109, w2v_ctc_loss=0.611, task_loss=0, contrastive_loss=0.055, total=4120.27, n_correct=2759.21, ppl=4.32, accuracy=66.967, wps=14697.7, ups=1.78, wpb=8240.5, bsz=300.7, num_updates=47500, lr=6.48886e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=56, gb_free=17.6, wall=5839
2023-08-09 13:02:14 | INFO | train_inner | epoch 033:    452 / 1474 loss=1.992, trans_loss=4.918, nll_loss=2.09, w2v_ctc_loss=0.598, task_loss=0, contrastive_loss=0.036, total=4141.22, n_correct=2787.28, ppl=4.26, accuracy=67.306, wps=14927.7, ups=1.8, wpb=8282.4, bsz=310.8, num_updates=47600, lr=6.48204e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=55, gb_free=16.7, wall=5895
2023-08-09 13:03:10 | INFO | train_inner | epoch 033:    552 / 1474 loss=2.014, trans_loss=4.941, nll_loss=2.119, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.055, total=4133.59, n_correct=2761.93, ppl=4.35, accuracy=66.817, wps=14743.8, ups=1.78, wpb=8267.2, bsz=294, num_updates=47700, lr=6.47524e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=56, gb_free=15.6, wall=5951
2023-08-09 13:04:07 | INFO | train_inner | epoch 033:    652 / 1474 loss=2.02, trans_loss=4.95, nll_loss=2.131, w2v_ctc_loss=0.615, task_loss=0, contrastive_loss=0.091, total=4157.63, n_correct=2774.53, ppl=4.38, accuracy=66.733, wps=14683.9, ups=1.77, wpb=8315.3, bsz=301.6, num_updates=47800, lr=6.46846e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=56, gb_free=18, wall=6007
2023-08-09 13:05:03 | INFO | train_inner | epoch 033:    752 / 1474 loss=2.021, trans_loss=4.95, nll_loss=2.132, w2v_ctc_loss=0.635, task_loss=0, contrastive_loss=0.038, total=4070.75, n_correct=2710.98, ppl=4.38, accuracy=66.597, wps=14578.9, ups=1.79, wpb=8141.5, bsz=287.2, num_updates=47900, lr=6.46171e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=55, gb_free=16.7, wall=6063
2023-08-09 13:05:59 | INFO | train_inner | epoch 033:    852 / 1474 loss=2.008, trans_loss=4.932, nll_loss=2.11, w2v_ctc_loss=0.6, task_loss=0, contrastive_loss=0.104, total=4130.24, n_correct=2776.48, ppl=4.32, accuracy=67.223, wps=14821.2, ups=1.79, wpb=8260.5, bsz=316.3, num_updates=48000, lr=6.45497e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=6119
2023-08-09 13:05:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-09 13:06:21 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.374 | trans_loss 5.552 | nll_loss 2.82 | w2v_ctc_loss 1.413 | task_loss 0 | contrastive_loss 0.241 | total 4003.4 | n_correct 2497.5 | ppl 7.06 | accuracy 62.384 | uer 16.877 | wer 18.676 | raw_wer 18.676 | bleu 20.41 | wps 2364.2 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.41
2023-08-09 13:06:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-08-09 13:06:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_33_48000.pt
2023-08-09 13:06:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_33_48000.pt
2023-08-09 13:07:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 20.41) (writing took 46.91091723181307 seconds)
2023-08-09 13:08:04 | INFO | train_inner | epoch 033:    952 / 1474 loss=2.014, trans_loss=4.944, nll_loss=2.125, w2v_ctc_loss=0.621, task_loss=0, contrastive_loss=0.048, total=4151.18, n_correct=2775.41, ppl=4.36, accuracy=66.858, wps=6602.7, ups=0.8, wpb=8302.4, bsz=308.3, num_updates=48100, lr=6.44826e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=56, gb_free=11.9, wall=6245
2023-08-09 13:09:01 | INFO | train_inner | epoch 033:   1052 / 1474 loss=2.026, trans_loss=4.941, nll_loss=2.121, w2v_ctc_loss=0.612, task_loss=0, contrastive_loss=0.153, total=4140.1, n_correct=2764.42, ppl=4.35, accuracy=66.772, wps=14586, ups=1.76, wpb=8280.2, bsz=307.6, num_updates=48200, lr=6.44157e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=56, gb_free=12.3, wall=6302
2023-08-09 13:09:57 | INFO | train_inner | epoch 033:   1152 / 1474 loss=2.021, trans_loss=4.947, nll_loss=2.129, w2v_ctc_loss=0.604, task_loss=0, contrastive_loss=0.14, total=4182.67, n_correct=2792.56, ppl=4.37, accuracy=66.765, wps=14884.4, ups=1.78, wpb=8365.3, bsz=309.5, num_updates=48300, lr=6.43489e-05, gnorm=0.56, clip=0, loss_scale=64, train_wall=56, gb_free=17.8, wall=6358
2023-08-09 13:10:53 | INFO | train_inner | epoch 033:   1252 / 1474 loss=2.013, trans_loss=4.943, nll_loss=2.124, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.043, total=4110.02, n_correct=2746.48, ppl=4.36, accuracy=66.824, wps=14705.8, ups=1.79, wpb=8220, bsz=294.4, num_updates=48400, lr=6.42824e-05, gnorm=0.564, clip=0, loss_scale=64, train_wall=55, gb_free=17, wall=6414
2023-08-09 13:11:50 | INFO | train_inner | epoch 033:   1352 / 1474 loss=2.014, trans_loss=4.946, nll_loss=2.129, w2v_ctc_loss=0.616, task_loss=0, contrastive_loss=0.059, total=4128.82, n_correct=2758.75, ppl=4.37, accuracy=66.817, wps=14653.3, ups=1.77, wpb=8257.6, bsz=312.4, num_updates=48500, lr=6.42161e-05, gnorm=0.556, clip=0, loss_scale=64, train_wall=56, gb_free=16.3, wall=6470
2023-08-09 13:12:46 | INFO | train_inner | epoch 033:   1452 / 1474 loss=2.029, trans_loss=4.943, nll_loss=2.126, w2v_ctc_loss=0.608, task_loss=0, contrastive_loss=0.206, total=4123.47, n_correct=2752.85, ppl=4.36, accuracy=66.761, wps=14629.1, ups=1.77, wpb=8246.9, bsz=308.9, num_updates=48600, lr=6.415e-05, gnorm=0.559, clip=0, loss_scale=64, train_wall=56, gb_free=16.8, wall=6526
2023-08-09 13:12:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-09 13:13:20 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.37 | trans_loss 5.551 | nll_loss 2.817 | w2v_ctc_loss 1.4 | task_loss 0 | contrastive_loss 0.246 | total 4003.4 | n_correct 2499.6 | ppl 7.05 | accuracy 62.437 | uer 16.909 | wer 18.735 | raw_wer 18.735 | bleu 20.06 | wps 2437.8 | wpb 4003.4 | bsz 141.8 | num_updates 48622 | best_bleu 20.41
2023-08-09 13:13:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48622 updates
2023-08-09 13:13:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_last.pt
2023-08-09 13:13:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_last.pt
2023-08-09 13:13:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_last.pt (epoch 33 @ 48622 updates, score 20.06) (writing took 13.141386359930038 seconds)
2023-08-09 13:13:33 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-09 13:13:33 | INFO | train | epoch 033 | loss 2.014 | trans_loss 4.937 | nll_loss 2.116 | w2v_ctc_loss 0.612 | task_loss 0 | contrastive_loss 0.089 | total 4138.65 | n_correct 2770.22 | ppl 4.34 | accuracy 66.935 | wps 12985.1 | ups 1.57 | wpb 8277.3 | bsz 305.7 | num_updates 48622 | lr 6.41355e-05 | gnorm 0.56 | clip 0 | loss_scale 64 | train_wall 820 | gb_free 18.1 | wall 6573
2023-08-09 13:13:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-09 13:13:33 | INFO | fairseq.trainer | begin training epoch 34
2023-08-09 13:13:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-09 13:14:24 | INFO | train_inner | epoch 034:     78 / 1474 loss=1.994, trans_loss=4.917, nll_loss=2.089, w2v_ctc_loss=0.602, task_loss=0, contrastive_loss=0.043, total=4128.94, n_correct=2782.06, ppl=4.25, accuracy=67.38, wps=8391.6, ups=1.02, wpb=8257.9, bsz=302.1, num_updates=48700, lr=6.40841e-05, gnorm=0.563, clip=0, loss_scale=64, train_wall=55, gb_free=15.6, wall=6625
2023-08-09 13:15:20 | INFO | train_inner | epoch 034:    178 / 1474 loss=1.994, trans_loss=4.913, nll_loss=2.084, w2v_ctc_loss=0.603, task_loss=0, contrastive_loss=0.044, total=4071.22, n_correct=2745.19, ppl=4.24, accuracy=67.429, wps=14556.4, ups=1.79, wpb=8142.4, bsz=295.1, num_updates=48800, lr=6.40184e-05, gnorm=0.562, clip=0, loss_scale=64, train_wall=55, gb_free=15.9, wall=6681
2023-08-09 13:16:17 | INFO | train_inner | epoch 034:    278 / 1474 loss=2.034, trans_loss=4.931, nll_loss=2.109, w2v_ctc_loss=0.604, task_loss=0, contrastive_loss=0.244, total=4237.89, n_correct=2837.41, ppl=4.32, accuracy=66.953, wps=14973.5, ups=1.77, wpb=8475.8, bsz=326.9, num_updates=48900, lr=6.39529e-05, gnorm=0.554, clip=0, loss_scale=64, train_wall=56, gb_free=11.1, wall=6737
2023-08-09 13:17:14 | INFO | train_inner | epoch 034:    378 / 1474 loss=2.009, trans_loss=4.914, nll_loss=2.087, w2v_ctc_loss=0.603, task_loss=0, contrastive_loss=0.136, total=4167, n_correct=2809.24, ppl=4.25, accuracy=67.416, wps=14705.8, ups=1.76, wpb=8334, bsz=319, num_updates=49000, lr=6.38877e-05, gnorm=0.553, clip=0, loss_scale=64, train_wall=56, gb_free=17.6, wall=6794
2023-08-09 13:18:09 | INFO | train_inner | epoch 034:    478 / 1474 loss=2.004, trans_loss=4.931, nll_loss=2.107, w2v_ctc_loss=0.615, task_loss=0, contrastive_loss=0.038, total=4071.65, n_correct=2730.01, ppl=4.31, accuracy=67.049, wps=14631, ups=1.8, wpb=8143.3, bsz=284.8, num_updates=49100, lr=6.38226e-05, gnorm=0.561, clip=0, loss_scale=64, train_wall=55, gb_free=12.1, wall=6850
2023-08-09 13:19:05 | INFO | train_inner | epoch 034:    578 / 1474 loss=1.991, trans_loss=4.916, nll_loss=2.088, w2v_ctc_loss=0.595, task_loss=0, contrastive_loss=0.039, total=4110.13, n_correct=2772.19, ppl=4.25, accuracy=67.448, wps=14883.7, ups=1.81, wpb=8220.3, bsz=299, num_updates=49200, lr=6.37577e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=55, gb_free=16.9, wall=6905
2023-08-09 13:20:00 | INFO | train_inner | epoch 034:    678 / 1474 loss=1.996, trans_loss=4.925, nll_loss=2.101, w2v_ctc_loss=0.602, task_loss=0, contrastive_loss=0.035, total=4128.65, n_correct=2775.94, ppl=4.29, accuracy=67.236, wps=14816.9, ups=1.79, wpb=8257.3, bsz=300.7, num_updates=49300, lr=6.3693e-05, gnorm=0.552, clip=0, loss_scale=64, train_wall=55, gb_free=18.1, wall=6961
2023-08-09 13:20:57 | INFO | train_inner | epoch 034:    778 / 1474 loss=2.012, trans_loss=4.943, nll_loss=2.124, w2v_ctc_loss=0.599, task_loss=0, contrastive_loss=0.105, total=4075.69, n_correct=2724.27, ppl=4.36, accuracy=66.842, wps=14262.1, ups=1.75, wpb=8151.4, bsz=294.5, num_updates=49400, lr=6.36285e-05, gnorm=0.563, clip=0, loss_scale=64, train_wall=57, gb_free=17.6, wall=7018
2023-08-09 13:21:54 | INFO | train_inner | epoch 034:    878 / 1474 loss=2.01, trans_loss=4.94, nll_loss=2.121, w2v_ctc_loss=0.611, task_loss=0, contrastive_loss=0.061, total=4104.97, n_correct=2749.24, ppl=4.35, accuracy=66.973, wps=14611.7, ups=1.78, wpb=8209.9, bsz=296.3, num_updates=49500, lr=6.35642e-05, gnorm=0.567, clip=0, loss_scale=64, train_wall=56, gb_free=18.1, wall=7074
2023-08-09 13:22:49 | INFO | train_inner | epoch 034:    978 / 1474 loss=2.009, trans_loss=4.937, nll_loss=2.117, w2v_ctc_loss=0.612, task_loss=0, contrastive_loss=0.056, total=4168.94, n_correct=2790.75, ppl=4.34, accuracy=66.941, wps=14990.9, ups=1.8, wpb=8337.9, bsz=312.8, num_updates=49600, lr=6.35001e-05, gnorm=0.566, clip=0, loss_scale=64, train_wall=55, gb_free=15.3, wall=7130
2023-08-09 13:23:45 | INFO | train_inner | epoch 034:   1078 / 1474 loss=2.01, trans_loss=4.941, nll_loss=2.121, w2v_ctc_loss=0.617, task_loss=0, contrastive_loss=0.041, total=4155.12, n_correct=2780.59, ppl=4.35, accuracy=66.92, wps=14946.3, ups=1.8, wpb=8310.2, bsz=309.1, num_updates=49700, lr=6.34361e-05, gnorm=0.563, clip=0, loss_scale=64, train_wall=55, gb_free=17, wall=7185
2023-08-09 13:24:42 | INFO | train_inner | epoch 034:   1178 / 1474 loss=2.009, trans_loss=4.94, nll_loss=2.119, w2v_ctc_loss=0.612, task_loss=0, contrastive_loss=0.051, total=4096.48, n_correct=2741.89, ppl=4.34, accuracy=66.933, wps=14385.6, ups=1.76, wpb=8193, bsz=297.2, num_updates=49800, lr=6.33724e-05, gnorm=0.564, clip=0, loss_scale=64, train_wall=57, gb_free=16.9, wall=7242
2023-08-09 13:25:37 | INFO | train_inner | epoch 034:   1278 / 1474 loss=2.004, trans_loss=4.938, nll_loss=2.118, w2v_ctc_loss=0.609, task_loss=0, contrastive_loss=0.037, total=4149.03, n_correct=2773.82, ppl=4.34, accuracy=66.855, wps=14976.7, ups=1.8, wpb=8298.1, bsz=299.7, num_updates=49900, lr=6.33089e-05, gnorm=0.555, clip=0, loss_scale=64, train_wall=55, gb_free=16.8, wall=7298
2023-08-09 13:25:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-09 13:26:34 | INFO | train_inner | epoch 034:   1379 / 1474 loss=2.01, trans_loss=4.939, nll_loss=2.119, w2v_ctc_loss=0.617, task_loss=0, contrastive_loss=0.048, total=4180.82, n_correct=2796.9, ppl=4.34, accuracy=66.898, wps=14715.8, ups=1.76, wpb=8361.6, bsz=316.5, num_updates=50000, lr=6.32456e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=56, gb_free=16.3, wall=7354
2023-08-09 13:26:34 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-09 13:26:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-09 13:26:57 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.366 | trans_loss 5.546 | nll_loss 2.812 | w2v_ctc_loss 1.403 | task_loss 0 | contrastive_loss 0.24 | total 4003.4 | n_correct 2500.1 | ppl 7.02 | accuracy 62.449 | uer 16.773 | wer 18.605 | raw_wer 18.605 | bleu 20.47 | wps 2309 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.47
2023-08-09 13:26:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-08-09 13:26:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_34_50000.pt
2023-08-09 13:27:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_34_50000.pt
2023-08-09 13:27:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0808_baseline_alpha2.0/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 20.47) (writing took 26.20066576451063 seconds)
2023-08-09 13:27:24 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-09 13:27:24 | INFO | train | epoch 034 | loss 2.006 | trans_loss 4.93 | nll_loss 2.107 | w2v_ctc_loss 0.607 | task_loss 0 | contrastive_loss 0.072 | total 4131.92 | n_correct 2772.25 | ppl 4.31 | accuracy 67.094 | wps 13709.8 | ups 1.66 | wpb 8263.8 | bsz 303.9 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.559 | clip 0 | loss_scale 32 | train_wall 767 | gb_free 16.3 | wall 7404
2023-08-09 13:27:24 | INFO | fairseq_cli.train | done training in 7344.5 seconds
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    raise EOFError
EOFError
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    raise EOFError
EOFError
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 336 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
