2023-07-09 10:13:08 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11363
2023-07-09 10:13:08 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:11363
2023-07-09 10:13:08 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11363
2023-07-09 10:13:08 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11363
2023-07-09 10:13:08 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:11363
2023-07-09 10:13:08 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11363
2023-07-09 10:13:08 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:11363
2023-07-09 10:13:08 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:11363
2023-07-09 10:13:08 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-09 10:13:08 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-09 10:13:08 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-09 10:13:08 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-09 10:13:08 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-09 10:13:08 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-09 10:13:08 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-09 10:13:08 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-09 10:13:08 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-09 10:13:08 | INFO | fairseq.distributed.utils | initialized host capios as rank 6
2023-07-09 10:13:08 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-09 10:13:08 | INFO | fairseq.distributed.utils | initialized host capios as rank 0
2023-07-09 10:13:08 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-09 10:13:08 | INFO | fairseq.distributed.utils | initialized host capios as rank 7
2023-07-09 10:13:08 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-09 10:13:08 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-09 10:13:08 | INFO | fairseq.distributed.utils | initialized host capios as rank 3
2023-07-09 10:13:08 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-09 10:13:08 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-09 10:13:08 | INFO | fairseq.distributed.utils | initialized host capios as rank 1
2023-07-09 10:13:08 | INFO | fairseq.distributed.utils | initialized host capios as rank 2
2023-07-09 10:13:08 | INFO | fairseq.distributed.utils | initialized host capios as rank 5
2023-07-09 10:13:08 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-09 10:13:08 | INFO | fairseq.distributed.utils | initialized host capios as rank 4
2023-07-09 10:13:10 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11363', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=True, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=True, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=True, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-09 10:13:10 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-09 10:13:10 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-09 10:13:10 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-09 10:13:10 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-09 10:13:10 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-09 10:13:15 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-09 10:13:15 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-09 10:13:15 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-09 10:13:16 | INFO | root | load pretrained hubert
2023-07-09 10:13:19 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-09 10:13:20 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-09 10:13:21 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-09 10:13:21 | INFO | root | share the sematic adapter and textual encoder
2023-07-09 10:13:21 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-09 10:13:21 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-09 10:13:21 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-09 10:13:21 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-09 10:13:21 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-09 10:13:21 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-09 10:13:21 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-09 10:13:21 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-09 10:13:21 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-09 10:13:21 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-09 10:13:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-09 10:13:27 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-09 10:13:27 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-09 10:13:28 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-09 10:13:28 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-09 10:13:28 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-09 10:13:28 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-09 10:13:28 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-09 10:13:28 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-09 10:13:28 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-09 10:13:28 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-09 10:13:28 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-09 10:13:28 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-09 10:13:28 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-09 10:13:28 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-09 10:13:28 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_last.pt
2023-07-09 10:13:28 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_last.pt
2023-07-09 10:13:28 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-09 10:13:28 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-09 10:13:28 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-09 10:13:28 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-09 10:13:29 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-09 10:13:31 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-09 10:13:33 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-09 10:14:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 10:14:37 | INFO | fairseq.trainer | begin training epoch 1
2023-07-09 10:14:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 10:15:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-09 10:15:51 | INFO | train_inner | epoch 001:    101 / 1474 loss=12.854, trans_loss=5.64, nll_loss=4.216, w2v_ctc_loss=13.798, task_loss=0.704, contrastive_loss=3.311, total=4200.41, n_correct=212.19, ppl=18.59, accuracy=5.052, wps=20193.5, ups=1.61, wpb=12542.9, bsz=467.5, num_updates=100, lr=4.098e-06, gnorm=0.572, clip=0, loss_scale=64, train_wall=65, gb_free=19, wall=143
2023-07-09 10:16:52 | INFO | train_inner | epoch 001:    201 / 1474 loss=11.505, trans_loss=5.459, nll_loss=4.049, w2v_ctc_loss=11.876, task_loss=0.692, contrastive_loss=3.286, total=4127.38, n_correct=244.96, ppl=16.55, accuracy=5.935, wps=20219.6, ups=1.64, wpb=12327, bsz=463.1, num_updates=200, lr=8.096e-06, gnorm=2.223, clip=0, loss_scale=64, train_wall=61, gb_free=19.2, wall=204
2023-07-09 10:17:52 | INFO | train_inner | epoch 001:    301 / 1474 loss=7.245, trans_loss=5.414, nll_loss=4.051, w2v_ctc_loss=5.397, task_loss=0.716, contrastive_loss=3.201, total=4079.62, n_correct=244.51, ppl=16.58, accuracy=5.993, wps=20151.8, ups=1.65, wpb=12195.4, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=2.853, clip=0, loss_scale=64, train_wall=60, gb_free=19.9, wall=264
2023-07-09 10:18:53 | INFO | train_inner | epoch 001:    401 / 1474 loss=6.488, trans_loss=5.459, nll_loss=4.126, w2v_ctc_loss=4.19, task_loss=0.624, contrastive_loss=3.234, total=4174.14, n_correct=227.88, ppl=17.46, accuracy=5.459, wps=20578.7, ups=1.65, wpb=12461.1, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=1.846, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=325
2023-07-09 10:19:54 | INFO | train_inner | epoch 001:    501 / 1474 loss=6.219, trans_loss=5.459, nll_loss=4.134, w2v_ctc_loss=3.785, task_loss=0.545, contrastive_loss=3.228, total=4176.18, n_correct=215.7, ppl=17.55, accuracy=5.165, wps=20529.9, ups=1.64, wpb=12513, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=0.882, clip=0, loss_scale=64, train_wall=61, gb_free=19.2, wall=386
2023-07-09 10:20:54 | INFO | train_inner | epoch 001:    601 / 1474 loss=6.072, trans_loss=5.484, nll_loss=4.172, w2v_ctc_loss=3.57, task_loss=0.498, contrastive_loss=3.281, total=4147.79, n_correct=213.19, ppl=18.02, accuracy=5.14, wps=20327.3, ups=1.64, wpb=12368.1, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.452, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=446
2023-07-09 10:21:55 | INFO | train_inner | epoch 001:    701 / 1474 loss=5.972, trans_loss=5.476, nll_loss=4.169, w2v_ctc_loss=3.499, task_loss=0.516, contrastive_loss=3.03, total=4152.1, n_correct=226.74, ppl=17.99, accuracy=5.461, wps=20503.3, ups=1.66, wpb=12373.8, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=0.371, clip=0, loss_scale=64, train_wall=60, gb_free=19.5, wall=507
2023-07-09 10:22:56 | INFO | train_inner | epoch 001:    801 / 1474 loss=5.803, trans_loss=5.431, nll_loss=4.116, w2v_ctc_loss=3.356, task_loss=0.5, contrastive_loss=2.928, total=4123.83, n_correct=252, ppl=17.34, accuracy=6.111, wps=20185.4, ups=1.64, wpb=12311.9, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=0.514, clip=0, loss_scale=64, train_wall=61, gb_free=19.1, wall=568
2023-07-09 10:23:56 | INFO | train_inner | epoch 001:    901 / 1474 loss=5.648, trans_loss=5.409, nll_loss=4.105, w2v_ctc_loss=3.253, task_loss=0.509, contrastive_loss=2.674, total=4163.61, n_correct=277.04, ppl=17.21, accuracy=6.654, wps=20571.2, ups=1.66, wpb=12409.7, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=0.746, clip=0, loss_scale=64, train_wall=60, gb_free=18.8, wall=628
2023-07-09 10:24:57 | INFO | train_inner | epoch 001:   1001 / 1474 loss=5.486, trans_loss=5.391, nll_loss=4.086, w2v_ctc_loss=3.111, task_loss=0.509, contrastive_loss=2.534, total=4135.34, n_correct=297.81, ppl=16.99, accuracy=7.202, wps=20279.7, ups=1.64, wpb=12363.9, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=0.909, clip=0, loss_scale=64, train_wall=61, gb_free=19, wall=689
2023-07-09 10:25:57 | INFO | train_inner | epoch 001:   1101 / 1474 loss=5.327, trans_loss=5.381, nll_loss=4.078, w2v_ctc_loss=2.993, task_loss=0.516, contrastive_loss=2.315, total=4147.38, n_correct=314.27, ppl=16.89, accuracy=7.578, wps=20435.8, ups=1.65, wpb=12356.9, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=1.054, clip=0, loss_scale=64, train_wall=60, gb_free=18.8, wall=750
2023-07-09 10:26:58 | INFO | train_inner | epoch 001:   1201 / 1474 loss=5.178, trans_loss=5.36, nll_loss=4.057, w2v_ctc_loss=2.879, task_loss=0.537, contrastive_loss=2.102, total=4139.9, n_correct=327.83, ppl=16.64, accuracy=7.919, wps=20446.5, ups=1.65, wpb=12386.7, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=1.028, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=810
2023-07-09 10:27:58 | INFO | train_inner | epoch 001:   1301 / 1474 loss=5.053, trans_loss=5.361, nll_loss=4.06, w2v_ctc_loss=2.764, task_loss=0.518, contrastive_loss=1.923, total=4046.58, n_correct=320.82, ppl=16.68, accuracy=7.928, wps=20105.1, ups=1.66, wpb=12092.5, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=1.065, clip=0, loss_scale=64, train_wall=60, gb_free=19.7, wall=870
2023-07-09 10:28:59 | INFO | train_inner | epoch 001:   1401 / 1474 loss=4.952, trans_loss=5.358, nll_loss=4.069, w2v_ctc_loss=2.66, task_loss=0.513, contrastive_loss=2.008, total=4133.18, n_correct=330.03, ppl=16.78, accuracy=7.985, wps=20252, ups=1.65, wpb=12300.7, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=1.162, clip=0, loss_scale=64, train_wall=60, gb_free=19.9, wall=931
2023-07-09 10:29:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-07-09 10:30:17 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 5.256 | trans_loss 10.959 | nll_loss 9.948 | w2v_ctc_loss 2.898 | task_loss 2.365 | contrastive_loss 2.331 | total 4003.4 | n_correct 373.5 | ppl 987.54 | accuracy 9.33 | uer 71.425 | wer 69.405 | raw_wer 69.405 | bleu 0.02 | wps 1464.8 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-07-09 10:30:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-07-09 10:30:17 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 10:30:20 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 10:30:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.02) (writing took 4.864804640994407 seconds)
2023-07-09 10:30:22 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-07-09 10:30:22 | INFO | train | epoch 001 | loss 6.615 | trans_loss 5.431 | nll_loss 4.104 | w2v_ctc_loss 4.694 | task_loss 0.56 | contrastive_loss 2.749 | total 4138.32 | n_correct 268.335 | ppl 17.19 | accuracy 6.484 | wps 19487.9 | ups 1.58 | wpb 12354.6 | bsz 458.3 | num_updates 1473 | lr 5.89905e-05 | gnorm 1.111 | clip 0 | loss_scale 64 | train_wall 892 | gb_free 19.2 | wall 1014
2023-07-09 10:30:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 10:30:22 | INFO | fairseq.trainer | begin training epoch 2
2023-07-09 10:30:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 10:30:46 | INFO | train_inner | epoch 002:     27 / 1474 loss=4.821, trans_loss=5.352, nll_loss=4.051, w2v_ctc_loss=2.531, task_loss=0.488, contrastive_loss=1.84, total=4162.95, n_correct=340.22, ppl=16.58, accuracy=8.173, wps=11545.5, ups=0.93, wpb=12414, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=0.983, clip=0, loss_scale=64, train_wall=60, gb_free=19.6, wall=1039
2023-07-09 10:31:47 | INFO | train_inner | epoch 002:    127 / 1474 loss=4.721, trans_loss=5.353, nll_loss=4.053, w2v_ctc_loss=2.456, task_loss=0.521, contrastive_loss=1.64, total=4155.98, n_correct=339.37, ppl=16.59, accuracy=8.166, wps=20326.3, ups=1.64, wpb=12390, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=0.993, clip=0, loss_scale=64, train_wall=61, gb_free=18.9, wall=1099
2023-07-09 10:32:49 | INFO | train_inner | epoch 002:    227 / 1474 loss=4.622, trans_loss=5.324, nll_loss=4.021, w2v_ctc_loss=2.338, task_loss=0.452, contrastive_loss=1.67, total=4179.21, n_correct=349.51, ppl=16.24, accuracy=8.363, wps=20366.2, ups=1.63, wpb=12488.1, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=0.922, clip=0, loss_scale=64, train_wall=61, gb_free=19, wall=1161
2023-07-09 10:33:50 | INFO | train_inner | epoch 002:    327 / 1474 loss=4.517, trans_loss=5.327, nll_loss=4.02, w2v_ctc_loss=2.274, task_loss=0.519, contrastive_loss=1.381, total=4146.1, n_correct=349.46, ppl=16.22, accuracy=8.429, wps=20097.3, ups=1.62, wpb=12381, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=0.867, clip=0, loss_scale=64, train_wall=61, gb_free=18.8, wall=1222
2023-07-09 10:34:51 | INFO | train_inner | epoch 002:    427 / 1474 loss=4.434, trans_loss=5.315, nll_loss=4.01, w2v_ctc_loss=2.215, task_loss=0.567, contrastive_loss=1.204, total=4037.99, n_correct=343.1, ppl=16.11, accuracy=8.497, wps=19971.8, ups=1.65, wpb=12079.4, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=0.877, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=1283
2023-07-09 10:35:51 | INFO | train_inner | epoch 002:    527 / 1474 loss=4.375, trans_loss=5.313, nll_loss=4.002, w2v_ctc_loss=2.12, task_loss=0.495, contrastive_loss=1.309, total=4176.97, n_correct=362.77, ppl=16.02, accuracy=8.685, wps=20631.2, ups=1.65, wpb=12475.1, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=0.847, clip=0, loss_scale=64, train_wall=60, gb_free=19.6, wall=1343
2023-07-09 10:35:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 10:36:26 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 4.956 | trans_loss 10.824 | nll_loss 9.773 | w2v_ctc_loss 2.341 | task_loss 2.365 | contrastive_loss 1.653 | total 4003.4 | n_correct 396.3 | ppl 874.99 | accuracy 9.899 | uer 61.747 | wer 59.379 | raw_wer 59.379 | bleu 0.03 | wps 1459.3 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.03
2023-07-09 10:36:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-07-09 10:36:26 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_2_2000.pt
2023-07-09 10:36:28 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_2_2000.pt
2023-07-09 10:36:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.03) (writing took 8.895969775010599 seconds)
2023-07-09 10:37:35 | INFO | train_inner | epoch 002:    627 / 1474 loss=4.294, trans_loss=5.306, nll_loss=3.998, w2v_ctc_loss=2.058, task_loss=0.511, contrastive_loss=1.095, total=4126.49, n_correct=360.22, ppl=15.98, accuracy=8.729, wps=11900.9, ups=0.97, wpb=12299.1, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=0.706, clip=0, loss_scale=128, train_wall=60, gb_free=19.2, wall=1447
2023-07-09 10:38:34 | INFO | train_inner | epoch 002:    727 / 1474 loss=4.25, trans_loss=5.288, nll_loss=3.979, w2v_ctc_loss=2.005, task_loss=0.501, contrastive_loss=1.202, total=4149.06, n_correct=370.28, ppl=15.77, accuracy=8.924, wps=20693.3, ups=1.67, wpb=12372.9, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=0.715, clip=0, loss_scale=128, train_wall=59, gb_free=19.2, wall=1506
2023-07-09 10:39:35 | INFO | train_inner | epoch 002:    827 / 1474 loss=4.195, trans_loss=5.272, nll_loss=3.957, w2v_ctc_loss=1.961, task_loss=0.513, contrastive_loss=1.148, total=4175.4, n_correct=379.13, ppl=15.53, accuracy=9.08, wps=20603.9, ups=1.65, wpb=12477.6, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=0.626, clip=0, loss_scale=128, train_wall=60, gb_free=19.8, wall=1567
2023-07-09 10:40:35 | INFO | train_inner | epoch 002:    927 / 1474 loss=4.135, trans_loss=5.26, nll_loss=3.943, w2v_ctc_loss=1.901, task_loss=0.525, contrastive_loss=1.13, total=4104.2, n_correct=377.29, ppl=15.38, accuracy=9.193, wps=20255.7, ups=1.65, wpb=12243.8, bsz=445.9, num_updates=2400, lr=9.6052e-05, gnorm=0.618, clip=0, loss_scale=128, train_wall=60, gb_free=19, wall=1628
2023-07-09 10:41:36 | INFO | train_inner | epoch 002:   1027 / 1474 loss=4.085, trans_loss=5.256, nll_loss=3.937, w2v_ctc_loss=1.854, task_loss=0.511, contrastive_loss=0.986, total=4102.5, n_correct=377.9, ppl=15.32, accuracy=9.211, wps=20429.9, ups=1.66, wpb=12270.3, bsz=456.3, num_updates=2500, lr=0.00010005, gnorm=0.564, clip=0, loss_scale=128, train_wall=60, gb_free=19.2, wall=1688
2023-07-09 10:42:36 | INFO | train_inner | epoch 002:   1127 / 1474 loss=4.063, trans_loss=5.245, nll_loss=3.926, w2v_ctc_loss=1.808, task_loss=0.465, contrastive_loss=1.198, total=4187.61, n_correct=395.38, ppl=15.2, accuracy=9.442, wps=20639.5, ups=1.65, wpb=12484.3, bsz=487.1, num_updates=2600, lr=0.000104048, gnorm=0.514, clip=0, loss_scale=128, train_wall=60, gb_free=19.5, wall=1748
2023-07-09 10:43:37 | INFO | train_inner | epoch 002:   1227 / 1474 loss=4.029, trans_loss=5.238, nll_loss=3.916, w2v_ctc_loss=1.78, task_loss=0.466, contrastive_loss=1.119, total=4221.06, n_correct=407.42, ppl=15.1, accuracy=9.652, wps=20585.4, ups=1.64, wpb=12590.1, bsz=492.8, num_updates=2700, lr=0.000108046, gnorm=0.508, clip=0, loss_scale=128, train_wall=61, gb_free=19.4, wall=1809
2023-07-09 10:44:38 | INFO | train_inner | epoch 002:   1327 / 1474 loss=3.969, trans_loss=5.224, nll_loss=3.903, w2v_ctc_loss=1.755, task_loss=0.492, contrastive_loss=0.834, total=4157.86, n_correct=406.95, ppl=14.96, accuracy=9.787, wps=20579.6, ups=1.66, wpb=12422.5, bsz=460.7, num_updates=2800, lr=0.000112044, gnorm=0.484, clip=0, loss_scale=128, train_wall=60, gb_free=19.5, wall=1870
2023-07-09 10:45:38 | INFO | train_inner | epoch 002:   1427 / 1474 loss=3.944, trans_loss=5.222, nll_loss=3.896, w2v_ctc_loss=1.725, task_loss=0.55, contrastive_loss=0.92, total=4054.34, n_correct=396.77, ppl=14.88, accuracy=9.786, wps=20022, ups=1.65, wpb=12128.6, bsz=438.8, num_updates=2900, lr=0.000116042, gnorm=0.457, clip=0, loss_scale=128, train_wall=60, gb_free=19.4, wall=1930
2023-07-09 10:46:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 10:46:41 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 4.537 | trans_loss 10.273 | nll_loss 9.08 | w2v_ctc_loss 1.86 | task_loss 2.365 | contrastive_loss 0.985 | total 4003.4 | n_correct 503 | ppl 541.16 | accuracy 12.564 | uer 51.403 | wer 50.438 | raw_wer 50.438 | bleu 0.13 | wps 1447.4 | wpb 4003.4 | bsz 141.8 | num_updates 2947 | best_bleu 0.13
2023-07-09 10:46:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2947 updates
2023-07-09 10:46:41 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 10:46:45 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 10:46:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt (epoch 2 @ 2947 updates, score 0.13) (writing took 8.160677667998243 seconds)
2023-07-09 10:46:49 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-07-09 10:46:49 | INFO | train | epoch 002 | loss 4.259 | trans_loss 5.281 | nll_loss 3.968 | w2v_ctc_loss 2.017 | task_loss 0.505 | contrastive_loss 1.205 | total 4138.65 | n_correct 372.813 | ppl 15.65 | accuracy 9.008 | wps 18459.4 | ups 1.49 | wpb 12355.8 | bsz 458.5 | num_updates 2947 | lr 0.000117921 | gnorm 0.692 | clip 0 | loss_scale 128 | train_wall 887 | gb_free 19.3 | wall 2001
2023-07-09 10:46:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 10:46:49 | INFO | fairseq.trainer | begin training epoch 3
2023-07-09 10:46:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 10:47:29 | INFO | train_inner | epoch 003:     53 / 1474 loss=3.899, trans_loss=5.202, nll_loss=3.873, w2v_ctc_loss=1.694, task_loss=0.519, contrastive_loss=0.818, total=4071.2, n_correct=412.21, ppl=14.65, accuracy=10.125, wps=11004.9, ups=0.91, wpb=12148.3, bsz=442.6, num_updates=3000, lr=0.00012004, gnorm=0.441, clip=0, loss_scale=128, train_wall=60, gb_free=19.1, wall=2041
2023-07-09 10:47:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-09 10:47:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-09 10:47:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-09 10:47:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-09 10:47:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-07-09 10:48:58 | INFO | train_inner | epoch 003:    158 / 1474 loss=3.421, trans_loss=4.47, nll_loss=2.916, w2v_ctc_loss=1.478, task_loss=0.491, contrastive_loss=0.687, total=4144.18, n_correct=1070.73, ppl=7.55, accuracy=25.837, wps=13766.9, ups=1.11, wpb=12381.7, bsz=458.6, num_updates=3100, lr=0.000124038, gnorm=1.033, clip=0, loss_scale=4, train_wall=90, gb_free=16.7, wall=2131
2023-07-09 10:50:26 | INFO | train_inner | epoch 003:    258 / 1474 loss=3.156, trans_loss=4.188, nll_loss=2.545, w2v_ctc_loss=1.313, task_loss=0.5, contrastive_loss=0.601, total=4161.13, n_correct=1379.52, ppl=5.84, accuracy=33.153, wps=14228.1, ups=1.14, wpb=12444.3, bsz=467, num_updates=3200, lr=0.000128036, gnorm=0.695, clip=0, loss_scale=4, train_wall=87, gb_free=17.3, wall=2218
2023-07-09 10:51:52 | INFO | train_inner | epoch 003:    358 / 1474 loss=3.074, trans_loss=4.099, nll_loss=2.428, w2v_ctc_loss=1.253, task_loss=0.502, contrastive_loss=0.636, total=4150.02, n_correct=1502.06, ppl=5.38, accuracy=36.194, wps=14302.7, ups=1.16, wpb=12369, bsz=461.6, num_updates=3300, lr=0.000132034, gnorm=0.721, clip=0, loss_scale=4, train_wall=86, gb_free=17.3, wall=2304
2023-07-09 10:53:20 | INFO | train_inner | epoch 003:    458 / 1474 loss=2.989, trans_loss=4.024, nll_loss=2.331, w2v_ctc_loss=1.203, task_loss=0.488, contrastive_loss=0.493, total=4209.57, n_correct=1632.18, ppl=5.03, accuracy=38.773, wps=14373.4, ups=1.15, wpb=12537.6, bsz=476.8, num_updates=3400, lr=0.000136032, gnorm=0.674, clip=0, loss_scale=4, train_wall=87, gb_free=16.2, wall=2392
2023-07-09 10:54:46 | INFO | train_inner | epoch 003:    558 / 1474 loss=2.917, trans_loss=3.98, nll_loss=2.267, w2v_ctc_loss=1.142, task_loss=0.535, contrastive_loss=0.461, total=4088.48, n_correct=1656.07, ppl=4.81, accuracy=40.506, wps=14126.3, ups=1.15, wpb=12237.1, bsz=439.7, num_updates=3500, lr=0.00014003, gnorm=0.614, clip=0, loss_scale=4, train_wall=86, gb_free=17.8, wall=2478
2023-07-09 10:56:15 | INFO | train_inner | epoch 003:    658 / 1474 loss=2.88, trans_loss=3.934, nll_loss=2.21, w2v_ctc_loss=1.107, task_loss=0.481, contrastive_loss=0.569, total=4221.58, n_correct=1787.6, ppl=4.63, accuracy=42.344, wps=14223.8, ups=1.13, wpb=12558.6, bsz=481.9, num_updates=3600, lr=0.000144028, gnorm=0.578, clip=0, loss_scale=4, train_wall=88, gb_free=16.5, wall=2567
2023-07-09 10:57:41 | INFO | train_inner | epoch 003:    758 / 1474 loss=2.829, trans_loss=3.9, nll_loss=2.166, w2v_ctc_loss=1.083, task_loss=0.477, contrastive_loss=0.334, total=4167.41, n_correct=1812.58, ppl=4.49, accuracy=43.494, wps=14472.1, ups=1.16, wpb=12462.8, bsz=472.6, num_updates=3700, lr=0.000148026, gnorm=0.586, clip=0, loss_scale=4, train_wall=86, gb_free=16.5, wall=2653
2023-07-09 10:59:07 | INFO | train_inner | epoch 003:    858 / 1474 loss=2.795, trans_loss=3.881, nll_loss=2.14, w2v_ctc_loss=1.055, task_loss=0.506, contrastive_loss=0.299, total=4165.53, n_correct=1844.04, ppl=4.41, accuracy=44.269, wps=14345.1, ups=1.15, wpb=12445.3, bsz=456.1, num_updates=3800, lr=0.000152024, gnorm=0.569, clip=0, loss_scale=4, train_wall=86, gb_free=17.2, wall=2739
2023-07-09 11:00:34 | INFO | train_inner | epoch 003:    958 / 1474 loss=2.778, trans_loss=3.854, nll_loss=2.105, w2v_ctc_loss=1.044, task_loss=0.486, contrastive_loss=0.334, total=4162.3, n_correct=1890.38, ppl=4.3, accuracy=45.417, wps=14296.2, ups=1.15, wpb=12408.5, bsz=469.2, num_updates=3900, lr=0.000156022, gnorm=0.568, clip=0, loss_scale=4, train_wall=86, gb_free=16.9, wall=2826
2023-07-09 11:02:01 | INFO | train_inner | epoch 003:   1058 / 1474 loss=2.761, trans_loss=3.844, nll_loss=2.092, w2v_ctc_loss=1.032, task_loss=0.535, contrastive_loss=0.288, total=4069.95, n_correct=1866.31, ppl=4.26, accuracy=45.856, wps=14082.8, ups=1.16, wpb=12168.2, bsz=443.6, num_updates=4000, lr=0.00016002, gnorm=0.561, clip=0, loss_scale=4, train_wall=86, gb_free=16.5, wall=2913
2023-07-09 11:02:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 11:02:34 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 2.882 | trans_loss 6.444 | nll_loss 4.002 | w2v_ctc_loss 1.025 | task_loss 2.365 | contrastive_loss 0.404 | total 4003.4 | n_correct 1935.7 | ppl 16.02 | accuracy 48.351 | uer 29.191 | wer 30.122 | raw_wer 30.122 | bleu 6.79 | wps 1515.1 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 6.79
2023-07-09 11:02:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-07-09 11:02:34 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_3_4000.pt
2023-07-09 11:02:36 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_3_4000.pt
2023-07-09 11:02:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 6.79) (writing took 8.866768487991067 seconds)
2023-07-09 11:04:09 | INFO | train_inner | epoch 003:   1158 / 1474 loss=2.738, trans_loss=3.836, nll_loss=2.081, w2v_ctc_loss=1.008, task_loss=0.544, contrastive_loss=0.269, total=4038.49, n_correct=1866.92, ppl=4.23, accuracy=46.228, wps=9415.8, ups=0.78, wpb=12064, bsz=432.5, num_updates=4100, lr=0.000164018, gnorm=0.551, clip=0, loss_scale=4, train_wall=86, gb_free=16.6, wall=3041
2023-07-09 11:05:35 | INFO | train_inner | epoch 003:   1258 / 1474 loss=2.715, trans_loss=3.818, nll_loss=2.059, w2v_ctc_loss=0.989, task_loss=0.534, contrastive_loss=0.253, total=4064.31, n_correct=1912.55, ppl=4.17, accuracy=47.057, wps=14071.2, ups=1.16, wpb=12147.9, bsz=433.9, num_updates=4200, lr=0.000168016, gnorm=0.548, clip=0, loss_scale=4, train_wall=86, gb_free=17.5, wall=3127
2023-07-09 11:07:02 | INFO | train_inner | epoch 003:   1358 / 1474 loss=2.708, trans_loss=3.798, nll_loss=2.036, w2v_ctc_loss=0.977, task_loss=0.508, contrastive_loss=0.366, total=4134.58, n_correct=1964.5, ppl=4.1, accuracy=47.514, wps=14166.7, ups=1.15, wpb=12326.9, bsz=460.7, num_updates=4300, lr=0.000172014, gnorm=0.546, clip=0, loss_scale=4, train_wall=87, gb_free=17.9, wall=3214
2023-07-09 11:08:29 | INFO | train_inner | epoch 003:   1458 / 1474 loss=2.685, trans_loss=3.783, nll_loss=2.017, w2v_ctc_loss=0.958, task_loss=0.476, contrastive_loss=0.344, total=4209.94, n_correct=2032.64, ppl=4.05, accuracy=48.282, wps=14446.8, ups=1.15, wpb=12573.7, bsz=477.4, num_updates=4400, lr=0.000176012, gnorm=0.534, clip=0, loss_scale=4, train_wall=87, gb_free=17.2, wall=3301
2023-07-09 11:08:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 11:09:15 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 2.807 | trans_loss 6.329 | nll_loss 3.85 | w2v_ctc_loss 0.928 | task_loss 2.365 | contrastive_loss 0.368 | total 4003.4 | n_correct 2013 | ppl 14.42 | accuracy 50.282 | uer 28.23 | wer 28.94 | raw_wer 28.94 | bleu 7.84 | wps 1551.1 | wpb 4003.4 | bsz 141.8 | num_updates 4416 | best_bleu 7.84
2023-07-09 11:09:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4416 updates
2023-07-09 11:09:15 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 11:09:19 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 11:09:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt (epoch 3 @ 4416 updates, score 7.84) (writing took 8.224349319993053 seconds)
2023-07-09 11:09:23 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-07-09 11:09:23 | INFO | train | epoch 003 | loss 2.923 | trans_loss 4.001 | nll_loss 2.299 | w2v_ctc_loss 1.136 | task_loss 0.504 | contrastive_loss 0.441 | total 4140.05 | n_correct 1684.71 | ppl 4.92 | accuracy 40.693 | wps 13406.4 | ups 1.08 | wpb 12360.2 | bsz 459 | num_updates 4416 | lr 0.000176652 | gnorm 0.619 | clip 0 | loss_scale 4 | train_wall 1258 | gb_free 16.8 | wall 3355
2023-07-09 11:09:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 11:09:24 | INFO | fairseq.trainer | begin training epoch 4
2023-07-09 11:09:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 11:10:44 | INFO | train_inner | epoch 004:     84 / 1474 loss=2.637, trans_loss=3.755, nll_loss=1.979, w2v_ctc_loss=0.932, task_loss=0.522, contrastive_loss=0.201, total=4099.41, n_correct=2010.05, ppl=3.94, accuracy=49.033, wps=9074.7, ups=0.74, wpb=12215.8, bsz=439.5, num_updates=4500, lr=0.00018001, gnorm=0.521, clip=0, loss_scale=4, train_wall=86, gb_free=16.6, wall=3436
2023-07-09 11:12:10 | INFO | train_inner | epoch 004:    184 / 1474 loss=2.625, trans_loss=3.74, nll_loss=1.958, w2v_ctc_loss=0.921, task_loss=0.478, contrastive_loss=0.224, total=4175.15, n_correct=2074.87, ppl=3.88, accuracy=49.696, wps=14386.8, ups=1.15, wpb=12466.1, bsz=468.3, num_updates=4600, lr=0.000184008, gnorm=0.531, clip=0, loss_scale=4, train_wall=86, gb_free=16.8, wall=3522
2023-07-09 11:13:37 | INFO | train_inner | epoch 004:    284 / 1474 loss=2.637, trans_loss=3.742, nll_loss=1.962, w2v_ctc_loss=0.918, task_loss=0.504, contrastive_loss=0.354, total=4145.23, n_correct=2056.64, ppl=3.9, accuracy=49.615, wps=14292.9, ups=1.15, wpb=12387.3, bsz=463, num_updates=4700, lr=0.000188006, gnorm=0.523, clip=0, loss_scale=4, train_wall=86, gb_free=16.1, wall=3609
2023-07-09 11:15:04 | INFO | train_inner | epoch 004:    384 / 1474 loss=2.614, trans_loss=3.739, nll_loss=1.958, w2v_ctc_loss=0.909, task_loss=0.524, contrastive_loss=0.198, total=4127.66, n_correct=2059.77, ppl=3.88, accuracy=49.902, wps=14238.7, ups=1.16, wpb=12298.8, bsz=443.5, num_updates=4800, lr=0.000192004, gnorm=0.515, clip=0, loss_scale=4, train_wall=86, gb_free=17.6, wall=3696
2023-07-09 11:16:31 | INFO | train_inner | epoch 004:    484 / 1474 loss=2.627, trans_loss=3.72, nll_loss=1.936, w2v_ctc_loss=0.887, task_loss=0.457, contrastive_loss=0.594, total=4218.78, n_correct=2131.86, ppl=3.83, accuracy=50.533, wps=14425.5, ups=1.15, wpb=12578.2, bsz=497.8, num_updates=4900, lr=0.000196002, gnorm=0.509, clip=0, loss_scale=4, train_wall=87, gb_free=16.6, wall=3783
2023-07-09 11:17:57 | INFO | train_inner | epoch 004:    584 / 1474 loss=2.607, trans_loss=3.718, nll_loss=1.934, w2v_ctc_loss=0.904, task_loss=0.474, contrastive_loss=0.27, total=4217.52, n_correct=2138.58, ppl=3.82, accuracy=50.707, wps=14519.2, ups=1.15, wpb=12583.6, bsz=485.9, num_updates=5000, lr=0.0002, gnorm=0.514, clip=0, loss_scale=4, train_wall=86, gb_free=16.3, wall=3869
tensor(0.8435, device='cuda:0')
tensor(0.7986, device='cuda:0')
2023-07-09 11:19:25 | INFO | train_inner | epoch 004:    684 / 1474 loss=2.592, trans_loss=3.72, nll_loss=1.932, w2v_ctc_loss=0.882, task_loss=0.519, contrastive_loss=0.317, total=4176.39, n_correct=2131.77, ppl=3.82, accuracy=51.043, wps=14172.8, ups=1.14, wpb=12440.1, bsz=455.8, num_updates=5100, lr=0.00019803, gnorm=0.429, clip=0, loss_scale=8, train_wall=87, gb_free=17.2, wall=3957
2023-07-09 11:20:52 | INFO | train_inner | epoch 004:    784 / 1474 loss=2.586, trans_loss=3.714, nll_loss=1.926, w2v_ctc_loss=0.886, task_loss=0.558, contrastive_loss=0.191, total=4026.63, n_correct=2057.04, ppl=3.8, accuracy=51.086, wps=13906.3, ups=1.15, wpb=12049.9, bsz=420.6, num_updates=5200, lr=0.000196116, gnorm=0.435, clip=0, loss_scale=8, train_wall=86, gb_free=13.5, wall=4044
2023-07-09 11:22:19 | INFO | train_inner | epoch 004:    884 / 1474 loss=2.591, trans_loss=3.701, nll_loss=1.913, w2v_ctc_loss=0.88, task_loss=0.505, contrastive_loss=0.376, total=4186.04, n_correct=2153.2, ppl=3.77, accuracy=51.438, wps=14351.2, ups=1.15, wpb=12493.4, bsz=466.3, num_updates=5300, lr=0.000194257, gnorm=0.432, clip=0, loss_scale=8, train_wall=87, gb_free=17.8, wall=4131
2023-07-09 11:23:46 | INFO | train_inner | epoch 004:    984 / 1474 loss=2.563, trans_loss=3.692, nll_loss=1.901, w2v_ctc_loss=0.865, task_loss=0.51, contrastive_loss=0.229, total=4125.02, n_correct=2140.32, ppl=3.73, accuracy=51.886, wps=14093.8, ups=1.14, wpb=12319.9, bsz=457.1, num_updates=5400, lr=0.00019245, gnorm=0.427, clip=0, loss_scale=8, train_wall=87, gb_free=13.1, wall=4218
2023-07-09 11:25:13 | INFO | train_inner | epoch 004:   1084 / 1474 loss=2.566, trans_loss=3.698, nll_loss=1.907, w2v_ctc_loss=0.867, task_loss=0.545, contrastive_loss=0.206, total=4075.6, n_correct=2109.32, ppl=3.75, accuracy=51.755, wps=14006.3, ups=1.15, wpb=12166.1, bsz=435.7, num_updates=5500, lr=0.000190693, gnorm=0.423, clip=0, loss_scale=8, train_wall=86, gb_free=16.2, wall=4305
2023-07-09 11:26:39 | INFO | train_inner | epoch 004:   1184 / 1474 loss=2.568, trans_loss=3.689, nll_loss=1.898, w2v_ctc_loss=0.859, task_loss=0.473, contrastive_loss=0.316, total=4161.18, n_correct=2179.16, ppl=3.73, accuracy=52.369, wps=14453.4, ups=1.16, wpb=12451.8, bsz=483.4, num_updates=5600, lr=0.000188982, gnorm=0.423, clip=0, loss_scale=8, train_wall=86, gb_free=16.9, wall=4391
2023-07-09 11:28:06 | INFO | train_inner | epoch 004:   1284 / 1474 loss=2.557, trans_loss=3.683, nll_loss=1.889, w2v_ctc_loss=0.851, task_loss=0.484, contrastive_loss=0.283, total=4156.53, n_correct=2184.11, ppl=3.71, accuracy=52.546, wps=14410.1, ups=1.16, wpb=12424.6, bsz=472.7, num_updates=5700, lr=0.000187317, gnorm=0.427, clip=0, loss_scale=8, train_wall=86, gb_free=16.2, wall=4478
2023-07-09 11:29:31 | INFO | train_inner | epoch 004:   1384 / 1474 loss=2.54, trans_loss=3.679, nll_loss=1.885, w2v_ctc_loss=0.851, task_loss=0.52, contrastive_loss=0.159, total=4101.23, n_correct=2160.02, ppl=3.69, accuracy=52.668, wps=14374.1, ups=1.17, wpb=12255, bsz=437.6, num_updates=5800, lr=0.000185695, gnorm=0.408, clip=0, loss_scale=8, train_wall=85, gb_free=15.8, wall=4563
2023-07-09 11:30:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.8435, device='cuda:5')
tensor(0.7986, device='cuda:5')
tensor(0.8435, device='cuda:4')
tensor(0.7986, device='cuda:4')
tensor(0.8435, device='cuda:2')
tensor(0.7986, device='cuda:2')
tensor(0.8435, device='cuda:7')
tensor(0.7986, device='cuda:7')
tensor(0.8435, device='cuda:1')
tensor(0.7986, device='cuda:1')
tensor(0.8435, device='cuda:6')
tensor(0.7986, device='cuda:6')
tensor(0.8435, device='cuda:3')
tensor(0.7986, device='cuda:3')
2023-07-09 11:31:17 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 2.621 | trans_loss 5.954 | nll_loss 3.349 | w2v_ctc_loss 0.803 | task_loss 2.365 | contrastive_loss 0.31 | total 4003.4 | n_correct 2241.1 | ppl 10.19 | accuracy 55.98 | uer 22.756 | wer 24.436 | raw_wer 24.436 | bleu 14.03 | wps 1796.6 | wpb 4003.4 | bsz 141.8 | num_updates 5890 | best_bleu 14.03
2023-07-09 11:31:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5890 updates
2023-07-09 11:31:17 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 11:31:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 11:31:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt (epoch 4 @ 5890 updates, score 14.03) (writing took 8.284507781994762 seconds)
2023-07-09 11:31:26 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-07-09 11:31:26 | INFO | train | epoch 004 | loss 2.589 | trans_loss 3.711 | nll_loss 1.923 | w2v_ctc_loss 0.883 | task_loss 0.505 | contrastive_loss 0.278 | total 4138.65 | n_correct 2117.38 | ppl 3.79 | accuracy 51.161 | wps 13771.4 | ups 1.11 | wpb 12355.8 | bsz 458.5 | num_updates 5890 | lr 0.000184271 | gnorm 0.462 | clip 0 | loss_scale 8 | train_wall 1271 | gb_free 15 | wall 4678
2023-07-09 11:31:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 11:31:26 | INFO | fairseq.trainer | begin training epoch 5
2023-07-09 11:31:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 11:31:42 | INFO | train_inner | epoch 005:     10 / 1474 loss=2.529, trans_loss=3.673, nll_loss=1.877, w2v_ctc_loss=0.836, task_loss=0.526, contrastive_loss=0.176, total=4037.7, n_correct=2139.93, ppl=3.67, accuracy=52.999, wps=9210.2, ups=0.76, wpb=12062.8, bsz=439.3, num_updates=5900, lr=0.000184115, gnorm=0.415, clip=0, loss_scale=8, train_wall=85, gb_free=17, wall=4694
2023-07-09 11:33:09 | INFO | train_inner | epoch 005:    110 / 1474 loss=2.469, trans_loss=3.62, nll_loss=1.809, w2v_ctc_loss=0.785, task_loss=0.455, contrastive_loss=0.185, total=4247.37, n_correct=2314.29, ppl=3.5, accuracy=54.488, wps=14584.9, ups=1.15, wpb=12683.8, bsz=495.1, num_updates=6000, lr=0.000182574, gnorm=0.395, clip=0, loss_scale=8, train_wall=87, gb_free=16.9, wall=4781
2023-07-09 11:33:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 11:33:38 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 2.606 | trans_loss 5.934 | nll_loss 3.321 | w2v_ctc_loss 0.781 | task_loss 2.365 | contrastive_loss 0.308 | total 4003.4 | n_correct 2251.2 | ppl 10 | accuracy 56.232 | uer 22.573 | wer 24.093 | raw_wer 24.093 | bleu 14.2 | wps 1797.3 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 14.2
2023-07-09 11:33:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-07-09 11:33:38 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_5_6000.pt
2023-07-09 11:33:40 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_5_6000.pt
2023-07-09 11:33:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 14.2) (writing took 8.91100527800154 seconds)
2023-07-09 11:35:12 | INFO | train_inner | epoch 005:    210 / 1474 loss=2.497, trans_loss=3.629, nll_loss=1.819, w2v_ctc_loss=0.797, task_loss=0.467, contrastive_loss=0.407, total=4189.85, n_correct=2275.64, ppl=3.53, accuracy=54.313, wps=10123.4, ups=0.81, wpb=12492.8, bsz=488.2, num_updates=6100, lr=0.000181071, gnorm=0.402, clip=0, loss_scale=8, train_wall=85, gb_free=17.9, wall=4904
2023-07-09 11:36:38 | INFO | train_inner | epoch 005:    310 / 1474 loss=2.494, trans_loss=3.629, nll_loss=1.822, w2v_ctc_loss=0.809, task_loss=0.517, contrastive_loss=0.253, total=4090.1, n_correct=2211.25, ppl=3.54, accuracy=54.063, wps=14264.7, ups=1.17, wpb=12240, bsz=443.9, num_updates=6200, lr=0.000179605, gnorm=0.409, clip=0, loss_scale=8, train_wall=85, gb_free=16.4, wall=4990
2023-07-09 11:38:05 | INFO | train_inner | epoch 005:    410 / 1474 loss=2.484, trans_loss=3.621, nll_loss=1.815, w2v_ctc_loss=0.785, task_loss=0.487, contrastive_loss=0.337, total=4147.17, n_correct=2262.26, ppl=3.52, accuracy=54.549, wps=14279.3, ups=1.15, wpb=12381.8, bsz=472.5, num_updates=6300, lr=0.000178174, gnorm=0.406, clip=0, loss_scale=8, train_wall=86, gb_free=15, wall=5077
2023-07-09 11:39:31 | INFO | train_inner | epoch 005:    510 / 1474 loss=2.474, trans_loss=3.634, nll_loss=1.826, w2v_ctc_loss=0.791, task_loss=0.568, contrastive_loss=0.131, total=4026.81, n_correct=2183.01, ppl=3.55, accuracy=54.212, wps=13942.7, ups=1.16, wpb=12047.2, bsz=416.6, num_updates=6400, lr=0.000176777, gnorm=0.404, clip=0, loss_scale=8, train_wall=86, gb_free=17.5, wall=5163
2023-07-09 11:40:58 | INFO | train_inner | epoch 005:    610 / 1474 loss=2.477, trans_loss=3.627, nll_loss=1.818, w2v_ctc_loss=0.783, task_loss=0.521, contrastive_loss=0.302, total=4107.75, n_correct=2233.28, ppl=3.53, accuracy=54.367, wps=14096.6, ups=1.15, wpb=12245.3, bsz=451.2, num_updates=6500, lr=0.000175412, gnorm=0.407, clip=0, loss_scale=8, train_wall=86, gb_free=16.3, wall=5250
2023-07-09 11:42:24 | INFO | train_inner | epoch 005:    710 / 1474 loss=2.481, trans_loss=3.622, nll_loss=1.814, w2v_ctc_loss=0.79, task_loss=0.479, contrastive_loss=0.283, total=4178.85, n_correct=2279.38, ppl=3.52, accuracy=54.546, wps=14434.9, ups=1.16, wpb=12462.3, bsz=480.9, num_updates=6600, lr=0.000174078, gnorm=0.401, clip=0, loss_scale=8, train_wall=86, gb_free=17.8, wall=5336
2023-07-09 11:43:52 | INFO | train_inner | epoch 005:    810 / 1474 loss=2.47, trans_loss=3.626, nll_loss=1.817, w2v_ctc_loss=0.782, task_loss=0.521, contrastive_loss=0.206, total=4127.73, n_correct=2255.28, ppl=3.52, accuracy=54.637, wps=14070.5, ups=1.14, wpb=12320.4, bsz=449.2, num_updates=6700, lr=0.000172774, gnorm=0.396, clip=0, loss_scale=8, train_wall=87, gb_free=15.4, wall=5424
2023-07-09 11:45:18 | INFO | train_inner | epoch 005:    910 / 1474 loss=2.458, trans_loss=3.621, nll_loss=1.812, w2v_ctc_loss=0.776, task_loss=0.523, contrastive_loss=0.166, total=4095.48, n_correct=2244.68, ppl=3.51, accuracy=54.809, wps=14185, ups=1.16, wpb=12237.9, bsz=445.3, num_updates=6800, lr=0.000171499, gnorm=0.398, clip=0, loss_scale=8, train_wall=86, gb_free=15.8, wall=5510
2023-07-09 11:46:44 | INFO | train_inner | epoch 005:   1010 / 1474 loss=2.468, trans_loss=3.622, nll_loss=1.815, w2v_ctc_loss=0.781, task_loss=0.5, contrastive_loss=0.25, total=4165.12, n_correct=2286.06, ppl=3.52, accuracy=54.886, wps=14454.2, ups=1.16, wpb=12426.3, bsz=463.5, num_updates=6900, lr=0.000170251, gnorm=0.391, clip=0, loss_scale=8, train_wall=86, gb_free=15.9, wall=5596
2023-07-09 11:48:12 | INFO | train_inner | epoch 005:   1110 / 1474 loss=2.47, trans_loss=3.622, nll_loss=1.811, w2v_ctc_loss=0.779, task_loss=0.502, contrastive_loss=0.25, total=4176.72, n_correct=2300.39, ppl=3.51, accuracy=55.076, wps=14239.4, ups=1.14, wpb=12467.3, bsz=466.1, num_updates=7000, lr=0.000169031, gnorm=0.39, clip=0, loss_scale=8, train_wall=87, gb_free=16.9, wall=5684
2023-07-09 11:49:39 | INFO | train_inner | epoch 005:   1210 / 1474 loss=2.452, trans_loss=3.621, nll_loss=1.811, w2v_ctc_loss=0.77, task_loss=0.515, contrastive_loss=0.154, total=4164.13, n_correct=2297.26, ppl=3.51, accuracy=55.168, wps=14287.9, ups=1.15, wpb=12416.1, bsz=453.8, num_updates=7100, lr=0.000167836, gnorm=0.398, clip=0, loss_scale=16, train_wall=86, gb_free=17.1, wall=5771
2023-07-09 11:51:05 | INFO | train_inner | epoch 005:   1310 / 1474 loss=2.441, trans_loss=3.616, nll_loss=1.804, w2v_ctc_loss=0.761, task_loss=0.513, contrastive_loss=0.123, total=4134.91, n_correct=2285.38, ppl=3.49, accuracy=55.27, wps=14334.5, ups=1.16, wpb=12356.4, bsz=445.6, num_updates=7200, lr=0.000166667, gnorm=0.388, clip=0, loss_scale=16, train_wall=86, gb_free=16.6, wall=5857
2023-07-09 11:52:31 | INFO | train_inner | epoch 005:   1410 / 1474 loss=2.445, trans_loss=3.609, nll_loss=1.8, w2v_ctc_loss=0.763, task_loss=0.506, contrastive_loss=0.187, total=4134.37, n_correct=2282.44, ppl=3.48, accuracy=55.206, wps=14290.8, ups=1.16, wpb=12339.9, bsz=458.5, num_updates=7300, lr=0.000165521, gnorm=0.395, clip=0, loss_scale=16, train_wall=86, gb_free=17.9, wall=5943
2023-07-09 11:53:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 11:53:57 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 2.551 | trans_loss 5.854 | nll_loss 3.222 | w2v_ctc_loss 0.727 | task_loss 2.365 | contrastive_loss 0.298 | total 4003.4 | n_correct 2300.7 | ppl 9.33 | accuracy 57.469 | uer 21.331 | wer 22.844 | raw_wer 22.844 | bleu 15.69 | wps 1692.4 | wpb 4003.4 | bsz 141.8 | num_updates 7364 | best_bleu 15.69
2023-07-09 11:53:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7364 updates
2023-07-09 11:53:57 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 11:54:01 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 11:54:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt (epoch 5 @ 7364 updates, score 15.69) (writing took 8.306651304999832 seconds)
2023-07-09 11:54:05 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-07-09 11:54:05 | INFO | train | epoch 005 | loss 2.469 | trans_loss 3.622 | nll_loss 1.813 | w2v_ctc_loss 0.782 | task_loss 0.505 | contrastive_loss 0.231 | total 4138.65 | n_correct 2264.32 | ppl 3.51 | accuracy 54.712 | wps 13397.9 | ups 1.08 | wpb 12355.8 | bsz 458.5 | num_updates 7364 | lr 0.0001648 | gnorm 0.399 | clip 0 | loss_scale 16 | train_wall 1269 | gb_free 16.4 | wall 6037
2023-07-09 11:54:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 11:54:05 | INFO | fairseq.trainer | begin training epoch 6
2023-07-09 11:54:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 11:54:44 | INFO | train_inner | epoch 006:     36 / 1474 loss=2.43, trans_loss=3.593, nll_loss=1.777, w2v_ctc_loss=0.751, task_loss=0.517, contrastive_loss=0.183, total=4115.45, n_correct=2299.94, ppl=3.43, accuracy=55.886, wps=9219.6, ups=0.75, wpb=12279.2, bsz=447.9, num_updates=7400, lr=0.000164399, gnorm=0.4, clip=0, loss_scale=16, train_wall=86, gb_free=16.6, wall=6076
2023-07-09 11:56:11 | INFO | train_inner | epoch 006:    136 / 1474 loss=2.398, trans_loss=3.567, nll_loss=1.744, w2v_ctc_loss=0.72, task_loss=0.503, contrastive_loss=0.226, total=4154.25, n_correct=2348.1, ppl=3.35, accuracy=56.523, wps=14307.5, ups=1.15, wpb=12409.6, bsz=456.1, num_updates=7500, lr=0.000163299, gnorm=0.391, clip=0, loss_scale=16, train_wall=86, gb_free=15.7, wall=6163
2023-07-09 11:57:38 | INFO | train_inner | epoch 006:    236 / 1474 loss=2.408, trans_loss=3.575, nll_loss=1.756, w2v_ctc_loss=0.744, task_loss=0.542, contrastive_loss=0.135, total=4112.66, n_correct=2305.99, ppl=3.38, accuracy=56.071, wps=14175.5, ups=1.15, wpb=12281.7, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.39, clip=0, loss_scale=16, train_wall=86, gb_free=16.3, wall=6250
2023-07-09 11:59:06 | INFO | train_inner | epoch 006:    336 / 1474 loss=2.417, trans_loss=3.566, nll_loss=1.745, w2v_ctc_loss=0.718, task_loss=0.469, contrastive_loss=0.441, total=4177.51, n_correct=2362.27, ppl=3.35, accuracy=56.547, wps=14081.7, ups=1.13, wpb=12463.7, bsz=491.3, num_updates=7700, lr=0.000161165, gnorm=0.39, clip=0, loss_scale=16, train_wall=88, gb_free=16.2, wall=6338
2023-07-09 12:00:32 | INFO | train_inner | epoch 006:    436 / 1474 loss=2.391, trans_loss=3.568, nll_loss=1.746, w2v_ctc_loss=0.719, task_loss=0.485, contrastive_loss=0.151, total=4154.57, n_correct=2354.39, ppl=3.35, accuracy=56.67, wps=14383.8, ups=1.16, wpb=12407.2, bsz=470.2, num_updates=7800, lr=0.000160128, gnorm=0.386, clip=0, loss_scale=16, train_wall=86, gb_free=16.3, wall=6424
2023-07-09 12:01:59 | INFO | train_inner | epoch 006:    536 / 1474 loss=2.395, trans_loss=3.571, nll_loss=1.75, w2v_ctc_loss=0.727, task_loss=0.509, contrastive_loss=0.137, total=4167.79, n_correct=2363.26, ppl=3.36, accuracy=56.703, wps=14343, ups=1.15, wpb=12419.2, bsz=455.2, num_updates=7900, lr=0.000159111, gnorm=0.386, clip=0, loss_scale=16, train_wall=86, gb_free=15.9, wall=6511
2023-07-09 12:03:25 | INFO | train_inner | epoch 006:    636 / 1474 loss=2.394, trans_loss=3.573, nll_loss=1.75, w2v_ctc_loss=0.716, task_loss=0.478, contrastive_loss=0.194, total=4146.17, n_correct=2347.29, ppl=3.36, accuracy=56.613, wps=14389.2, ups=1.16, wpb=12395.5, bsz=471.6, num_updates=8000, lr=0.000158114, gnorm=0.387, clip=0, loss_scale=16, train_wall=86, gb_free=16.7, wall=6597
2023-07-09 12:03:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 12:03:55 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 2.533 | trans_loss 5.816 | nll_loss 3.169 | w2v_ctc_loss 0.732 | task_loss 2.365 | contrastive_loss 0.275 | total 4003.4 | n_correct 2317.7 | ppl 8.99 | accuracy 57.893 | uer 20.577 | wer 22.229 | raw_wer 22.229 | bleu 16.25 | wps 1762.8 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 16.25
2023-07-09 12:03:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-07-09 12:03:55 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_6_8000.pt
2023-07-09 12:03:57 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_6_8000.pt
2023-07-09 12:04:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 16.25) (writing took 9.789138264983194 seconds)
2023-07-09 12:05:31 | INFO | train_inner | epoch 006:    736 / 1474 loss=2.4, trans_loss=3.575, nll_loss=1.757, w2v_ctc_loss=0.731, task_loss=0.513, contrastive_loss=0.148, total=4148.65, n_correct=2345.91, ppl=3.38, accuracy=56.546, wps=9819.1, ups=0.79, wpb=12378.4, bsz=453.7, num_updates=8100, lr=0.000157135, gnorm=0.388, clip=0, loss_scale=16, train_wall=87, gb_free=15.8, wall=6723
2023-07-09 12:06:58 | INFO | train_inner | epoch 006:    836 / 1474 loss=2.395, trans_loss=3.581, nll_loss=1.762, w2v_ctc_loss=0.721, task_loss=0.531, contrastive_loss=0.13, total=4114.34, n_correct=2318.39, ppl=3.39, accuracy=56.349, wps=14170.6, ups=1.15, wpb=12292.5, bsz=441.6, num_updates=8200, lr=0.000156174, gnorm=0.39, clip=0, loss_scale=16, train_wall=86, gb_free=15.3, wall=6810
2023-07-09 12:08:25 | INFO | train_inner | epoch 006:    936 / 1474 loss=2.408, trans_loss=3.578, nll_loss=1.761, w2v_ctc_loss=0.729, task_loss=0.526, contrastive_loss=0.228, total=4081.53, n_correct=2301.56, ppl=3.39, accuracy=56.39, wps=14046.7, ups=1.15, wpb=12166.1, bsz=444.5, num_updates=8300, lr=0.00015523, gnorm=0.395, clip=0, loss_scale=16, train_wall=86, gb_free=17.9, wall=6897
2023-07-09 12:09:51 | INFO | train_inner | epoch 006:   1036 / 1474 loss=2.403, trans_loss=3.571, nll_loss=1.751, w2v_ctc_loss=0.716, task_loss=0.48, contrastive_loss=0.301, total=4165.84, n_correct=2366.55, ppl=3.37, accuracy=56.808, wps=14387, ups=1.16, wpb=12437.3, bsz=477.2, num_updates=8400, lr=0.000154303, gnorm=0.388, clip=0, loss_scale=16, train_wall=86, gb_free=17, wall=6983
2023-07-09 12:11:17 | INFO | train_inner | epoch 006:   1136 / 1474 loss=2.394, trans_loss=3.578, nll_loss=1.759, w2v_ctc_loss=0.72, task_loss=0.561, contrastive_loss=0.132, total=4072.29, n_correct=2306.85, ppl=3.38, accuracy=56.647, wps=14086.2, ups=1.16, wpb=12165.1, bsz=428, num_updates=8500, lr=0.000153393, gnorm=0.39, clip=0, loss_scale=16, train_wall=86, gb_free=17.1, wall=7069
2023-07-09 12:12:45 | INFO | train_inner | epoch 006:   1236 / 1474 loss=2.41, trans_loss=3.569, nll_loss=1.75, w2v_ctc_loss=0.71, task_loss=0.489, contrastive_loss=0.448, total=4141.55, n_correct=2356.57, ppl=3.36, accuracy=56.901, wps=14167.4, ups=1.14, wpb=12385.8, bsz=474.8, num_updates=8600, lr=0.000152499, gnorm=0.385, clip=0, loss_scale=16, train_wall=87, gb_free=13.5, wall=7157
2023-07-09 12:14:11 | INFO | train_inner | epoch 006:   1336 / 1474 loss=2.382, trans_loss=3.576, nll_loss=1.755, w2v_ctc_loss=0.708, task_loss=0.504, contrastive_loss=0.118, total=4125.31, n_correct=2352.9, ppl=3.37, accuracy=57.036, wps=14314.5, ups=1.16, wpb=12316, bsz=452.6, num_updates=8700, lr=0.00015162, gnorm=0.383, clip=0, loss_scale=16, train_wall=86, gb_free=17.8, wall=7243
2023-07-09 12:15:38 | INFO | train_inner | epoch 006:   1436 / 1474 loss=2.38, trans_loss=3.565, nll_loss=1.745, w2v_ctc_loss=0.715, task_loss=0.504, contrastive_loss=0.125, total=4196.2, n_correct=2398.19, ppl=3.35, accuracy=57.151, wps=14327.5, ups=1.14, wpb=12515.5, bsz=461.5, num_updates=8800, lr=0.000150756, gnorm=0.381, clip=0, loss_scale=16, train_wall=87, gb_free=11.8, wall=7330
2023-07-09 12:16:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 12:16:40 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 2.509 | trans_loss 5.786 | nll_loss 3.124 | w2v_ctc_loss 0.702 | task_loss 2.366 | contrastive_loss 0.279 | total 4003.4 | n_correct 2334.9 | ppl 8.72 | accuracy 58.323 | uer 19.752 | wer 21.431 | raw_wer 21.431 | bleu 16.46 | wps 1815.5 | wpb 4003.4 | bsz 141.8 | num_updates 8838 | best_bleu 16.46
2023-07-09 12:16:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8838 updates
2023-07-09 12:16:40 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 12:16:44 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 12:16:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt (epoch 6 @ 8838 updates, score 16.46) (writing took 8.275210794003215 seconds)
2023-07-09 12:16:48 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-07-09 12:16:48 | INFO | train | epoch 006 | loss 2.397 | trans_loss 3.572 | nll_loss 1.751 | w2v_ctc_loss 0.72 | task_loss 0.505 | contrastive_loss 0.207 | total 4138.65 | n_correct 2344.97 | ppl 3.37 | accuracy 56.66 | wps 13363.5 | ups 1.08 | wpb 12355.8 | bsz 458.5 | num_updates 8838 | lr 0.000150431 | gnorm 0.388 | clip 0 | loss_scale 16 | train_wall 1273 | gb_free 15.3 | wall 7400
2023-07-09 12:16:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 12:16:48 | INFO | fairseq.trainer | begin training epoch 7
2023-07-09 12:16:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 12:17:50 | INFO | train_inner | epoch 007:     62 / 1474 loss=2.355, trans_loss=3.542, nll_loss=1.714, w2v_ctc_loss=0.689, task_loss=0.491, contrastive_loss=0.139, total=4108.19, n_correct=2369.47, ppl=3.28, accuracy=57.677, wps=9306, ups=0.76, wpb=12269.7, bsz=461.9, num_updates=8900, lr=0.000149906, gnorm=0.38, clip=0, loss_scale=16, train_wall=86, gb_free=17.2, wall=7462
2023-07-09 12:19:16 | INFO | train_inner | epoch 007:    162 / 1474 loss=2.348, trans_loss=3.534, nll_loss=1.704, w2v_ctc_loss=0.678, task_loss=0.512, contrastive_loss=0.217, total=4106.05, n_correct=2376.33, ppl=3.26, accuracy=57.874, wps=14216.5, ups=1.16, wpb=12254.3, bsz=455.4, num_updates=9000, lr=0.000149071, gnorm=0.385, clip=0, loss_scale=16, train_wall=86, gb_free=16.8, wall=7548
2023-07-09 12:20:43 | INFO | train_inner | epoch 007:    262 / 1474 loss=2.341, trans_loss=3.532, nll_loss=1.7, w2v_ctc_loss=0.681, task_loss=0.511, contrastive_loss=0.12, total=4129.3, n_correct=2394.97, ppl=3.25, accuracy=57.999, wps=14276.2, ups=1.16, wpb=12322.9, bsz=451.8, num_updates=9100, lr=0.00014825, gnorm=0.379, clip=0, loss_scale=16, train_wall=86, gb_free=17.4, wall=7635
2023-07-09 12:21:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-09 12:22:11 | INFO | train_inner | epoch 007:    363 / 1474 loss=2.357, trans_loss=3.538, nll_loss=1.709, w2v_ctc_loss=0.675, task_loss=0.492, contrastive_loss=0.367, total=4190.91, n_correct=2421.95, ppl=3.27, accuracy=57.791, wps=14229.6, ups=1.14, wpb=12505.3, bsz=474.7, num_updates=9200, lr=0.000147442, gnorm=0.38, clip=0, loss_scale=16, train_wall=87, gb_free=13.3, wall=7723
2023-07-09 12:23:37 | INFO | train_inner | epoch 007:    463 / 1474 loss=2.358, trans_loss=3.536, nll_loss=1.71, w2v_ctc_loss=0.68, task_loss=0.5, contrastive_loss=0.305, total=4153.22, n_correct=2397.08, ppl=3.27, accuracy=57.716, wps=14272.7, ups=1.15, wpb=12386.6, bsz=463, num_updates=9300, lr=0.000146647, gnorm=0.379, clip=0, loss_scale=16, train_wall=86, gb_free=16.9, wall=7809
2023-07-09 12:25:04 | INFO | train_inner | epoch 007:    563 / 1474 loss=2.342, trans_loss=3.536, nll_loss=1.708, w2v_ctc_loss=0.68, task_loss=0.492, contrastive_loss=0.128, total=4168.14, n_correct=2421.7, ppl=3.27, accuracy=58.1, wps=14300.7, ups=1.15, wpb=12410.5, bsz=459.8, num_updates=9400, lr=0.000145865, gnorm=0.377, clip=0, loss_scale=16, train_wall=86, gb_free=17, wall=7896
2023-07-09 12:26:31 | INFO | train_inner | epoch 007:    663 / 1474 loss=2.337, trans_loss=3.539, nll_loss=1.709, w2v_ctc_loss=0.672, task_loss=0.503, contrastive_loss=0.117, total=4157.82, n_correct=2415.9, ppl=3.27, accuracy=58.105, wps=14289.2, ups=1.15, wpb=12417.8, bsz=455.4, num_updates=9500, lr=0.000145095, gnorm=0.379, clip=0, loss_scale=16, train_wall=86, gb_free=15.8, wall=7983
2023-07-09 12:27:58 | INFO | train_inner | epoch 007:    763 / 1474 loss=2.342, trans_loss=3.539, nll_loss=1.71, w2v_ctc_loss=0.678, task_loss=0.53, contrastive_loss=0.113, total=4122.1, n_correct=2390.82, ppl=3.27, accuracy=58, wps=14130.5, ups=1.15, wpb=12321.9, bsz=446.2, num_updates=9600, lr=0.000144338, gnorm=0.38, clip=0, loss_scale=16, train_wall=87, gb_free=15.8, wall=8070
2023-07-09 12:29:25 | INFO | train_inner | epoch 007:    863 / 1474 loss=2.34, trans_loss=3.538, nll_loss=1.708, w2v_ctc_loss=0.674, task_loss=0.511, contrastive_loss=0.132, total=4147.23, n_correct=2405.74, ppl=3.27, accuracy=58.008, wps=14210.2, ups=1.15, wpb=12392, bsz=460.9, num_updates=9700, lr=0.000143592, gnorm=0.382, clip=0, loss_scale=16, train_wall=87, gb_free=17.6, wall=8157
2023-07-09 12:30:52 | INFO | train_inner | epoch 007:    963 / 1474 loss=2.348, trans_loss=3.536, nll_loss=1.708, w2v_ctc_loss=0.673, task_loss=0.481, contrastive_loss=0.229, total=4140.14, n_correct=2411.77, ppl=3.27, accuracy=58.253, wps=14258.6, ups=1.15, wpb=12360, bsz=474.6, num_updates=9800, lr=0.000142857, gnorm=0.385, clip=0, loss_scale=16, train_wall=86, gb_free=16.1, wall=8244
2023-07-09 12:32:19 | INFO | train_inner | epoch 007:   1063 / 1474 loss=2.342, trans_loss=3.545, nll_loss=1.719, w2v_ctc_loss=0.678, task_loss=0.529, contrastive_loss=0.098, total=4103.51, n_correct=2374.52, ppl=3.29, accuracy=57.866, wps=14112.9, ups=1.15, wpb=12263.4, bsz=437.5, num_updates=9900, lr=0.000142134, gnorm=0.381, clip=0, loss_scale=16, train_wall=86, gb_free=16.9, wall=8331
2023-07-09 12:33:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-09 12:33:47 | INFO | train_inner | epoch 007:   1164 / 1474 loss=2.354, trans_loss=3.533, nll_loss=1.71, w2v_ctc_loss=0.674, task_loss=0.5, contrastive_loss=0.307, total=4115.79, n_correct=2390.72, ppl=3.27, accuracy=58.087, wps=14033.3, ups=1.14, wpb=12285.3, bsz=460.5, num_updates=10000, lr=0.000141421, gnorm=0.391, clip=0, loss_scale=8, train_wall=87, gb_free=16.7, wall=8419
2023-07-09 12:33:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 12:34:13 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 2.48 | trans_loss 5.727 | nll_loss 3.051 | w2v_ctc_loss 0.697 | task_loss 2.365 | contrastive_loss 0.279 | total 4003.4 | n_correct 2374.4 | ppl 8.29 | accuracy 59.31 | uer 18.878 | wer 20.808 | raw_wer 20.808 | bleu 18.13 | wps 2085.5 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 18.13
2023-07-09 12:34:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-07-09 12:34:13 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_7_10000.pt
2023-07-09 12:34:15 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_7_10000.pt
2023-07-09 12:34:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 18.13) (writing took 9.026249368005665 seconds)
tensor(0.5842, device='cuda:0')
tensor(0.4665, device='cuda:0')
2023-07-09 12:35:49 | INFO | train_inner | epoch 007:   1264 / 1474 loss=2.332, trans_loss=3.531, nll_loss=1.704, w2v_ctc_loss=0.67, task_loss=0.514, contrastive_loss=0.123, total=4129.16, n_correct=2400.83, ppl=3.26, accuracy=58.143, wps=10091.1, ups=0.82, wpb=12327, bsz=448.9, num_updates=10100, lr=0.00014072, gnorm=0.286, clip=0, loss_scale=8, train_wall=86, gb_free=16.9, wall=8541
2023-07-09 12:37:15 | INFO | train_inner | epoch 007:   1364 / 1474 loss=2.339, trans_loss=3.528, nll_loss=1.7, w2v_ctc_loss=0.675, task_loss=0.47, contrastive_loss=0.163, total=4177.71, n_correct=2439.64, ppl=3.25, accuracy=58.397, wps=14428.9, ups=1.16, wpb=12468.2, bsz=478.6, num_updates=10200, lr=0.000140028, gnorm=0.288, clip=0, loss_scale=8, train_wall=86, gb_free=17, wall=8627
2023-07-09 12:38:43 | INFO | train_inner | epoch 007:   1464 / 1474 loss=2.348, trans_loss=3.54, nll_loss=1.716, w2v_ctc_loss=0.673, task_loss=0.544, contrastive_loss=0.225, total=4107.01, n_correct=2382.91, ppl=3.29, accuracy=58.021, wps=13905.9, ups=1.13, wpb=12279.4, bsz=442.8, num_updates=10300, lr=0.000139347, gnorm=0.291, clip=0, loss_scale=8, train_wall=88, gb_free=13.5, wall=8715
2023-07-09 12:38:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.5842, device='cuda:7')
tensor(0.4665, device='cuda:7')
tensor(0.5842, device='cuda:6')
tensor(0.4665, device='cuda:6')
tensor(0.5842, device='cuda:1')
tensor(0.4665, device='cuda:1')
tensor(0.5842, device='cuda:4')
tensor(0.4665, device='cuda:4')
tensor(0.5842, device='cuda:5')
tensor(0.4665, device='cuda:5')
tensor(0.5842, device='cuda:2')
tensor(0.4665, device='cuda:2')
tensor(0.5842, device='cuda:3')
tensor(0.4665, device='cuda:3')
2023-07-09 12:39:21 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 2.471 | trans_loss 5.715 | nll_loss 3.037 | w2v_ctc_loss 0.69 | task_loss 2.365 | contrastive_loss 0.268 | total 4003.4 | n_correct 2373.7 | ppl 8.21 | accuracy 59.292 | uer 18.865 | wer 20.689 | raw_wer 20.689 | bleu 17.43 | wps 1835.1 | wpb 4003.4 | bsz 141.8 | num_updates 10310 | best_bleu 18.13
2023-07-09 12:39:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10310 updates
2023-07-09 12:39:21 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_17.4307.pt
2023-07-09 12:39:23 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_17.4307.pt
2023-07-09 12:39:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_17.4307.pt (epoch 7 @ 10310 updates, score 17.43) (writing took 5.139918307977496 seconds)
2023-07-09 12:39:26 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-07-09 12:39:26 | INFO | train | epoch 007 | loss 2.345 | trans_loss 3.536 | nll_loss 1.708 | w2v_ctc_loss 0.676 | task_loss 0.506 | contrastive_loss 0.187 | total 4136.54 | n_correct 2400.12 | ppl 3.27 | accuracy 58.022 | wps 13385.9 | ups 1.08 | wpb 12349.9 | bsz 457.4 | num_updates 10310 | lr 0.000139279 | gnorm 0.362 | clip 0 | loss_scale 8 | train_wall 1274 | gb_free 13.5 | wall 8758
2023-07-09 12:39:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 12:39:26 | INFO | fairseq.trainer | begin training epoch 8
2023-07-09 12:39:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 12:40:52 | INFO | train_inner | epoch 008:     90 / 1474 loss=2.304, trans_loss=3.512, nll_loss=1.673, w2v_ctc_loss=0.646, task_loss=0.539, contrastive_loss=0.12, total=4106.01, n_correct=2416.72, ppl=3.19, accuracy=58.858, wps=9532.5, ups=0.78, wpb=12235.6, bsz=440.9, num_updates=10400, lr=0.000138675, gnorm=0.284, clip=0, loss_scale=8, train_wall=86, gb_free=17.2, wall=8844
2023-07-09 12:42:18 | INFO | train_inner | epoch 008:    190 / 1474 loss=2.311, trans_loss=3.513, nll_loss=1.677, w2v_ctc_loss=0.648, task_loss=0.549, contrastive_loss=0.142, total=4043.12, n_correct=2382.2, ppl=3.2, accuracy=58.92, wps=13954.9, ups=1.16, wpb=12051.9, bsz=430, num_updates=10500, lr=0.000138013, gnorm=0.29, clip=0, loss_scale=8, train_wall=86, gb_free=13.5, wall=8930
2023-07-09 12:43:45 | INFO | train_inner | epoch 008:    290 / 1474 loss=2.298, trans_loss=3.502, nll_loss=1.664, w2v_ctc_loss=0.64, task_loss=0.474, contrastive_loss=0.139, total=4207.9, n_correct=2496.96, ppl=3.17, accuracy=59.34, wps=14543.1, ups=1.16, wpb=12570.8, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.283, clip=0, loss_scale=8, train_wall=86, gb_free=14.3, wall=9017
2023-07-09 12:45:12 | INFO | train_inner | epoch 008:    390 / 1474 loss=2.314, trans_loss=3.511, nll_loss=1.675, w2v_ctc_loss=0.656, task_loss=0.531, contrastive_loss=0.164, total=4134.6, n_correct=2431.47, ppl=3.19, accuracy=58.808, wps=14059.9, ups=1.14, wpb=12336.1, bsz=444.7, num_updates=10700, lr=0.000136717, gnorm=0.286, clip=0, loss_scale=8, train_wall=87, gb_free=17.4, wall=9104
2023-07-09 12:46:40 | INFO | train_inner | epoch 008:    490 / 1474 loss=2.333, trans_loss=3.511, nll_loss=1.676, w2v_ctc_loss=0.644, task_loss=0.457, contrastive_loss=0.426, total=4196.6, n_correct=2472.08, ppl=3.2, accuracy=58.907, wps=14396.8, ups=1.15, wpb=12551.9, bsz=501.4, num_updates=10800, lr=0.000136083, gnorm=0.292, clip=0, loss_scale=8, train_wall=87, gb_free=13.2, wall=9192
2023-07-09 12:48:07 | INFO | train_inner | epoch 008:    590 / 1474 loss=2.306, trans_loss=3.51, nll_loss=1.677, w2v_ctc_loss=0.651, task_loss=0.548, contrastive_loss=0.096, total=4065.55, n_correct=2393.24, ppl=3.2, accuracy=58.866, wps=13967.7, ups=1.15, wpb=12176.4, bsz=428.3, num_updates=10900, lr=0.000135457, gnorm=0.288, clip=0, loss_scale=8, train_wall=87, gb_free=16.3, wall=9279
2023-07-09 12:49:34 | INFO | train_inner | epoch 008:    690 / 1474 loss=2.307, trans_loss=3.508, nll_loss=1.675, w2v_ctc_loss=0.656, task_loss=0.523, contrastive_loss=0.107, total=4135.41, n_correct=2447.38, ppl=3.19, accuracy=59.181, wps=14183, ups=1.15, wpb=12330.3, bsz=447.2, num_updates=11000, lr=0.00013484, gnorm=0.284, clip=0, loss_scale=8, train_wall=86, gb_free=16.2, wall=9366
2023-07-09 12:51:00 | INFO | train_inner | epoch 008:    790 / 1474 loss=2.307, trans_loss=3.504, nll_loss=1.671, w2v_ctc_loss=0.646, task_loss=0.509, contrastive_loss=0.195, total=4128.86, n_correct=2445.33, ppl=3.18, accuracy=59.225, wps=14282.4, ups=1.16, wpb=12353.8, bsz=452.1, num_updates=11100, lr=0.000134231, gnorm=0.288, clip=0, loss_scale=8, train_wall=86, gb_free=16.6, wall=9452
2023-07-09 12:52:27 | INFO | train_inner | epoch 008:    890 / 1474 loss=2.306, trans_loss=3.507, nll_loss=1.674, w2v_ctc_loss=0.641, task_loss=0.485, contrastive_loss=0.201, total=4166.92, n_correct=2467.34, ppl=3.19, accuracy=59.213, wps=14337.4, ups=1.15, wpb=12450.6, bsz=471.5, num_updates=11200, lr=0.000133631, gnorm=0.286, clip=0, loss_scale=8, train_wall=86, gb_free=14.7, wall=9539
2023-07-09 12:53:53 | INFO | train_inner | epoch 008:    990 / 1474 loss=2.292, trans_loss=3.502, nll_loss=1.668, w2v_ctc_loss=0.638, task_loss=0.486, contrastive_loss=0.103, total=4150.39, n_correct=2463.21, ppl=3.18, accuracy=59.349, wps=14357.8, ups=1.16, wpb=12385.2, bsz=462.8, num_updates=11300, lr=0.000133038, gnorm=0.284, clip=0, loss_scale=8, train_wall=86, gb_free=17.4, wall=9625
2023-07-09 12:55:21 | INFO | train_inner | epoch 008:   1090 / 1474 loss=2.314, trans_loss=3.508, nll_loss=1.676, w2v_ctc_loss=0.643, task_loss=0.502, contrastive_loss=0.329, total=4197.39, n_correct=2476.56, ppl=3.2, accuracy=59.002, wps=14269.5, ups=1.14, wpb=12518.1, bsz=466.4, num_updates=11400, lr=0.000132453, gnorm=0.282, clip=0, loss_scale=8, train_wall=87, gb_free=16.9, wall=9713
2023-07-09 12:56:48 | INFO | train_inner | epoch 008:   1190 / 1474 loss=2.301, trans_loss=3.507, nll_loss=1.676, w2v_ctc_loss=0.644, task_loss=0.476, contrastive_loss=0.113, total=4180.55, n_correct=2477.53, ppl=3.2, accuracy=59.263, wps=14425.3, ups=1.16, wpb=12486.6, bsz=472.7, num_updates=11500, lr=0.000131876, gnorm=0.283, clip=0, loss_scale=8, train_wall=86, gb_free=17.4, wall=9800
2023-07-09 12:58:14 | INFO | train_inner | epoch 008:   1290 / 1474 loss=2.307, trans_loss=3.509, nll_loss=1.678, w2v_ctc_loss=0.649, task_loss=0.527, contrastive_loss=0.134, total=4062.6, n_correct=2395.94, ppl=3.2, accuracy=58.976, wps=14056, ups=1.16, wpb=12134.6, bsz=437.8, num_updates=11600, lr=0.000131306, gnorm=0.289, clip=0, loss_scale=8, train_wall=86, gb_free=13.3, wall=9886
2023-07-09 12:59:40 | INFO | train_inner | epoch 008:   1390 / 1474 loss=2.31, trans_loss=3.509, nll_loss=1.68, w2v_ctc_loss=0.646, task_loss=0.49, contrastive_loss=0.204, total=4159.11, n_correct=2465.27, ppl=3.2, accuracy=59.274, wps=14363.5, ups=1.16, wpb=12403.4, bsz=468.7, num_updates=11700, lr=0.000130744, gnorm=0.284, clip=0, loss_scale=8, train_wall=86, gb_free=13.5, wall=9972
2023-07-09 13:00:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 13:01:18 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 2.447 | trans_loss 5.675 | nll_loss 2.984 | w2v_ctc_loss 0.687 | task_loss 2.365 | contrastive_loss 0.263 | total 4003.4 | n_correct 2404.9 | ppl 7.91 | accuracy 60.071 | uer 18.366 | wer 20.063 | raw_wer 20.063 | bleu 18.85 | wps 2106.6 | wpb 4003.4 | bsz 141.8 | num_updates 11784 | best_bleu 18.85
2023-07-09 13:01:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11784 updates
2023-07-09 13:01:18 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 13:01:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 13:01:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt (epoch 8 @ 11784 updates, score 18.85) (writing took 8.296092710021185 seconds)
2023-07-09 13:01:27 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-07-09 13:01:27 | INFO | train | epoch 008 | loss 2.308 | trans_loss 3.508 | nll_loss 1.674 | w2v_ctc_loss 0.646 | task_loss 0.505 | contrastive_loss 0.182 | total 4138.65 | n_correct 2446.08 | ppl 3.19 | accuracy 59.103 | wps 13790.5 | ups 1.12 | wpb 12355.8 | bsz 458.5 | num_updates 11784 | lr 0.000130277 | gnorm 0.286 | clip 0 | loss_scale 8 | train_wall 1273 | gb_free 17.1 | wall 10079
2023-07-09 13:01:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 13:01:27 | INFO | fairseq.trainer | begin training epoch 9
2023-07-09 13:01:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 13:01:49 | INFO | train_inner | epoch 009:     16 / 1474 loss=2.303, trans_loss=3.502, nll_loss=1.669, w2v_ctc_loss=0.633, task_loss=0.495, contrastive_loss=0.297, total=4121.25, n_correct=2451.05, ppl=3.18, accuracy=59.473, wps=9543, ups=0.78, wpb=12280.4, bsz=466, num_updates=11800, lr=0.000130189, gnorm=0.283, clip=0, loss_scale=8, train_wall=86, gb_free=17.8, wall=10101
2023-07-09 13:03:16 | INFO | train_inner | epoch 009:    116 / 1474 loss=2.263, trans_loss=3.474, nll_loss=1.632, w2v_ctc_loss=0.612, task_loss=0.474, contrastive_loss=0.133, total=4191.82, n_correct=2527.26, ppl=3.1, accuracy=60.29, wps=14372.4, ups=1.15, wpb=12521.5, bsz=479.9, num_updates=11900, lr=0.000129641, gnorm=0.281, clip=0, loss_scale=8, train_wall=87, gb_free=16.1, wall=10188
2023-07-09 13:04:43 | INFO | train_inner | epoch 009:    216 / 1474 loss=2.267, trans_loss=3.485, nll_loss=1.644, w2v_ctc_loss=0.617, task_loss=0.543, contrastive_loss=0.09, total=4061.27, n_correct=2438.84, ppl=3.13, accuracy=60.051, wps=13912.9, ups=1.15, wpb=12136, bsz=431.4, num_updates=12000, lr=0.000129099, gnorm=0.285, clip=0, loss_scale=8, train_wall=87, gb_free=17.7, wall=10275
2023-07-09 13:04:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 13:05:09 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 2.442 | trans_loss 5.687 | nll_loss 3 | w2v_ctc_loss 0.663 | task_loss 2.365 | contrastive_loss 0.259 | total 4003.4 | n_correct 2398.9 | ppl 8 | accuracy 59.922 | uer 18.215 | wer 20.059 | raw_wer 20.059 | bleu 18.35 | wps 2119.1 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 18.85
2023-07-09 13:05:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-07-09 13:05:09 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_9_12000.pt
2023-07-09 13:05:12 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_9_12000.pt
2023-07-09 13:05:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.35) (writing took 6.269021428015549 seconds)
2023-07-09 13:06:42 | INFO | train_inner | epoch 009:    316 / 1474 loss=2.263, trans_loss=3.473, nll_loss=1.631, w2v_ctc_loss=0.609, task_loss=0.476, contrastive_loss=0.139, total=4146.43, n_correct=2507.11, ppl=3.1, accuracy=60.464, wps=10450.1, ups=0.84, wpb=12407.6, bsz=474.6, num_updates=12100, lr=0.000128565, gnorm=0.281, clip=0, loss_scale=16, train_wall=85, gb_free=16.8, wall=10394
2023-07-09 13:08:09 | INFO | train_inner | epoch 009:    416 / 1474 loss=2.266, trans_loss=3.48, nll_loss=1.641, w2v_ctc_loss=0.618, task_loss=0.496, contrastive_loss=0.107, total=4194.84, n_correct=2517.46, ppl=3.12, accuracy=60.013, wps=14319, ups=1.14, wpb=12516.2, bsz=466.7, num_updates=12200, lr=0.000128037, gnorm=0.283, clip=0, loss_scale=16, train_wall=87, gb_free=16.3, wall=10481
2023-07-09 13:09:36 | INFO | train_inner | epoch 009:    516 / 1474 loss=2.284, trans_loss=3.49, nll_loss=1.654, w2v_ctc_loss=0.631, task_loss=0.526, contrastive_loss=0.158, total=4124.3, n_correct=2464.83, ppl=3.15, accuracy=59.764, wps=14263.8, ups=1.16, wpb=12292.8, bsz=439.5, num_updates=12300, lr=0.000127515, gnorm=0.29, clip=0, loss_scale=16, train_wall=86, gb_free=12, wall=10568
2023-07-09 13:11:03 | INFO | train_inner | epoch 009:    616 / 1474 loss=2.267, trans_loss=3.48, nll_loss=1.642, w2v_ctc_loss=0.615, task_loss=0.516, contrastive_loss=0.118, total=4120.96, n_correct=2477.85, ppl=3.12, accuracy=60.128, wps=14174.9, ups=1.15, wpb=12325.2, bsz=453.4, num_updates=12400, lr=0.000127, gnorm=0.284, clip=0, loss_scale=16, train_wall=87, gb_free=16.3, wall=10655
2023-07-09 13:12:29 | INFO | train_inner | epoch 009:    716 / 1474 loss=2.285, trans_loss=3.489, nll_loss=1.652, w2v_ctc_loss=0.626, task_loss=0.515, contrastive_loss=0.199, total=4088.53, n_correct=2442.38, ppl=3.14, accuracy=59.737, wps=14200, ups=1.16, wpb=12225.7, bsz=451.4, num_updates=12500, lr=0.000126491, gnorm=0.287, clip=0, loss_scale=16, train_wall=86, gb_free=17.1, wall=10741
2023-07-09 13:13:57 | INFO | train_inner | epoch 009:    816 / 1474 loss=2.295, trans_loss=3.477, nll_loss=1.642, w2v_ctc_loss=0.626, task_loss=0.456, contrastive_loss=0.348, total=4220.43, n_correct=2528.84, ppl=3.12, accuracy=59.919, wps=14326.3, ups=1.14, wpb=12596.8, bsz=501.1, num_updates=12600, lr=0.000125988, gnorm=0.291, clip=0, loss_scale=16, train_wall=88, gb_free=14.6, wall=10829
2023-07-09 13:15:24 | INFO | train_inner | epoch 009:    916 / 1474 loss=2.286, trans_loss=3.488, nll_loss=1.651, w2v_ctc_loss=0.621, task_loss=0.52, contrastive_loss=0.326, total=4146.05, n_correct=2483.56, ppl=3.14, accuracy=59.902, wps=14072.8, ups=1.14, wpb=12355.9, bsz=450.3, num_updates=12700, lr=0.000125491, gnorm=0.284, clip=0, loss_scale=16, train_wall=87, gb_free=17.9, wall=10916
2023-07-09 13:16:52 | INFO | train_inner | epoch 009:   1016 / 1474 loss=2.276, trans_loss=3.496, nll_loss=1.659, w2v_ctc_loss=0.624, task_loss=0.566, contrastive_loss=0.105, total=4101.48, n_correct=2447.52, ppl=3.16, accuracy=59.674, wps=14032, ups=1.15, wpb=12243.2, bsz=424.4, num_updates=12800, lr=0.000125, gnorm=0.284, clip=0, loss_scale=16, train_wall=87, gb_free=16.1, wall=11004
2023-07-09 13:18:18 | INFO | train_inner | epoch 009:   1116 / 1474 loss=2.274, trans_loss=3.488, nll_loss=1.65, w2v_ctc_loss=0.624, task_loss=0.476, contrastive_loss=0.129, total=4179.09, n_correct=2510.13, ppl=3.14, accuracy=60.064, wps=14454.1, ups=1.16, wpb=12439.9, bsz=474.7, num_updates=12900, lr=0.000124515, gnorm=0.286, clip=0, loss_scale=16, train_wall=86, gb_free=15.4, wall=11090
2023-07-09 13:19:45 | INFO | train_inner | epoch 009:   1216 / 1474 loss=2.277, trans_loss=3.496, nll_loss=1.657, w2v_ctc_loss=0.624, task_loss=0.533, contrastive_loss=0.111, total=4140.66, n_correct=2480.1, ppl=3.15, accuracy=59.896, wps=14181.9, ups=1.14, wpb=12405, bsz=448.1, num_updates=13000, lr=0.000124035, gnorm=0.283, clip=0, loss_scale=16, train_wall=87, gb_free=17.2, wall=11177
2023-07-09 13:21:12 | INFO | train_inner | epoch 009:   1316 / 1474 loss=2.276, trans_loss=3.48, nll_loss=1.641, w2v_ctc_loss=0.609, task_loss=0.458, contrastive_loss=0.302, total=4204.43, n_correct=2535.99, ppl=3.12, accuracy=60.317, wps=14531.1, ups=1.16, wpb=12539.3, bsz=492.5, num_updates=13100, lr=0.00012356, gnorm=0.284, clip=0, loss_scale=16, train_wall=86, gb_free=17.8, wall=11264
2023-07-09 13:22:38 | INFO | train_inner | epoch 009:   1416 / 1474 loss=2.277, trans_loss=3.499, nll_loss=1.663, w2v_ctc_loss=0.627, task_loss=0.549, contrastive_loss=0.089, total=4069.19, n_correct=2432.61, ppl=3.17, accuracy=59.781, wps=14119.7, ups=1.16, wpb=12152.5, bsz=427.7, num_updates=13200, lr=0.000123091, gnorm=0.288, clip=0, loss_scale=16, train_wall=86, gb_free=16.8, wall=11350
2023-07-09 13:23:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 13:23:54 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 2.424 | trans_loss 5.651 | nll_loss 2.963 | w2v_ctc_loss 0.665 | task_loss 2.365 | contrastive_loss 0.264 | total 4003.4 | n_correct 2413.8 | ppl 7.8 | accuracy 60.294 | uer 17.801 | wer 19.589 | raw_wer 19.589 | bleu 19 | wps 2002.5 | wpb 4003.4 | bsz 141.8 | num_updates 13258 | best_bleu 19
2023-07-09 13:23:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13258 updates
2023-07-09 13:23:54 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 13:23:58 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 13:24:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt (epoch 9 @ 13258 updates, score 19.0) (writing took 8.27731273000245 seconds)
2023-07-09 13:24:03 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-07-09 13:24:03 | INFO | train | epoch 009 | loss 2.276 | trans_loss 3.485 | nll_loss 1.647 | w2v_ctc_loss 0.62 | task_loss 0.505 | contrastive_loss 0.174 | total 4138.65 | n_correct 2483.67 | ppl 3.13 | accuracy 60.012 | wps 13431.4 | ups 1.09 | wpb 12355.8 | bsz 458.5 | num_updates 13258 | lr 0.000122822 | gnorm 0.285 | clip 0 | loss_scale 16 | train_wall 1273 | gb_free 12 | wall 11435
2023-07-09 13:24:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 13:24:03 | INFO | fairseq.trainer | begin training epoch 10
2023-07-09 13:24:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 13:24:47 | INFO | train_inner | epoch 010:     42 / 1474 loss=2.266, trans_loss=3.477, nll_loss=1.637, w2v_ctc_loss=0.611, task_loss=0.481, contrastive_loss=0.187, total=4100.8, n_correct=2479.08, ppl=3.11, accuracy=60.454, wps=9445.2, ups=0.77, wpb=12243.3, bsz=469.4, num_updates=13300, lr=0.000122628, gnorm=0.288, clip=0, loss_scale=16, train_wall=85, gb_free=16.4, wall=11479
2023-07-09 13:26:14 | INFO | train_inner | epoch 010:    142 / 1474 loss=2.234, trans_loss=3.459, nll_loss=1.61, w2v_ctc_loss=0.59, task_loss=0.478, contrastive_loss=0.109, total=4247.35, n_correct=2592.25, ppl=3.05, accuracy=61.032, wps=14592.6, ups=1.15, wpb=12717.5, bsz=479.6, num_updates=13400, lr=0.000122169, gnorm=0.277, clip=0, loss_scale=16, train_wall=87, gb_free=12.1, wall=11566
2023-07-09 13:27:41 | INFO | train_inner | epoch 010:    242 / 1474 loss=2.247, trans_loss=3.453, nll_loss=1.607, w2v_ctc_loss=0.596, task_loss=0.499, contrastive_loss=0.232, total=4122.82, n_correct=2518.53, ppl=3.05, accuracy=61.088, wps=14252.5, ups=1.16, wpb=12279.5, bsz=461.4, num_updates=13500, lr=0.000121716, gnorm=0.284, clip=0, loss_scale=16, train_wall=86, gb_free=16.4, wall=11653
2023-07-09 13:29:08 | INFO | train_inner | epoch 010:    342 / 1474 loss=2.242, trans_loss=3.457, nll_loss=1.614, w2v_ctc_loss=0.596, task_loss=0.509, contrastive_loss=0.145, total=4138.27, n_correct=2522.09, ppl=3.06, accuracy=60.946, wps=14156, ups=1.14, wpb=12378.7, bsz=453.8, num_updates=13600, lr=0.000121268, gnorm=0.283, clip=0, loss_scale=16, train_wall=87, gb_free=16.6, wall=11740
2023-07-09 13:30:36 | INFO | train_inner | epoch 010:    442 / 1474 loss=2.248, trans_loss=3.459, nll_loss=1.615, w2v_ctc_loss=0.585, task_loss=0.485, contrastive_loss=0.318, total=4196.37, n_correct=2554.42, ppl=3.06, accuracy=60.872, wps=14171.1, ups=1.13, wpb=12523.5, bsz=481.1, num_updates=13700, lr=0.000120824, gnorm=0.28, clip=0, loss_scale=16, train_wall=88, gb_free=16.6, wall=11828
2023-07-09 13:32:03 | INFO | train_inner | epoch 010:    542 / 1474 loss=2.251, trans_loss=3.471, nll_loss=1.627, w2v_ctc_loss=0.607, task_loss=0.545, contrastive_loss=0.098, total=4102.8, n_correct=2490.16, ppl=3.09, accuracy=60.694, wps=14117, ups=1.15, wpb=12224.8, bsz=437.8, num_updates=13800, lr=0.000120386, gnorm=0.283, clip=0, loss_scale=16, train_wall=86, gb_free=17.1, wall=11915
2023-07-09 13:33:30 | INFO | train_inner | epoch 010:    642 / 1474 loss=2.259, trans_loss=3.47, nll_loss=1.628, w2v_ctc_loss=0.604, task_loss=0.478, contrastive_loss=0.214, total=4176.56, n_correct=2537.89, ppl=3.09, accuracy=60.765, wps=14395.7, ups=1.15, wpb=12467.5, bsz=477.2, num_updates=13900, lr=0.000119952, gnorm=0.285, clip=0, loss_scale=16, train_wall=86, gb_free=16.4, wall=12002
2023-07-09 13:34:56 | INFO | train_inner | epoch 010:    742 / 1474 loss=2.254, trans_loss=3.471, nll_loss=1.629, w2v_ctc_loss=0.613, task_loss=0.505, contrastive_loss=0.096, total=4125.87, n_correct=2499.39, ppl=3.09, accuracy=60.578, wps=14314.9, ups=1.16, wpb=12315.5, bsz=454.4, num_updates=14000, lr=0.000119523, gnorm=0.289, clip=0, loss_scale=16, train_wall=86, gb_free=14.7, wall=12088
2023-07-09 13:34:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 13:35:23 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 2.422 | trans_loss 5.654 | nll_loss 2.962 | w2v_ctc_loss 0.668 | task_loss 2.365 | contrastive_loss 0.259 | total 4003.4 | n_correct 2419 | ppl 7.79 | accuracy 60.424 | uer 17.968 | wer 19.85 | raw_wer 19.85 | bleu 18.98 | wps 2057.4 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 19
2023-07-09 13:35:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-07-09 13:35:23 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_10_14000.pt
2023-07-09 13:35:25 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_10_14000.pt
2023-07-09 13:35:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 18.98) (writing took 6.063411787006771 seconds)
2023-07-09 13:36:56 | INFO | train_inner | epoch 010:    842 / 1474 loss=2.242, trans_loss=3.468, nll_loss=1.625, w2v_ctc_loss=0.596, task_loss=0.498, contrastive_loss=0.098, total=4128.44, n_correct=2508.15, ppl=3.08, accuracy=60.753, wps=10281.4, ups=0.83, wpb=12345, bsz=456.3, num_updates=14100, lr=0.000119098, gnorm=0.281, clip=0, loss_scale=32, train_wall=86, gb_free=14.9, wall=12208
2023-07-09 13:38:21 | INFO | train_inner | epoch 010:    942 / 1474 loss=2.251, trans_loss=3.465, nll_loss=1.624, w2v_ctc_loss=0.606, task_loss=0.488, contrastive_loss=0.137, total=4160.94, n_correct=2526.98, ppl=3.08, accuracy=60.731, wps=14477.5, ups=1.17, wpb=12380.2, bsz=468.1, num_updates=14200, lr=0.000118678, gnorm=0.287, clip=0, loss_scale=32, train_wall=85, gb_free=15.6, wall=12293
2023-07-09 13:39:49 | INFO | train_inner | epoch 010:   1042 / 1474 loss=2.251, trans_loss=3.471, nll_loss=1.631, w2v_ctc_loss=0.605, task_loss=0.548, contrastive_loss=0.111, total=4067.53, n_correct=2462.8, ppl=3.1, accuracy=60.548, wps=13876.1, ups=1.14, wpb=12142, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.287, clip=0, loss_scale=32, train_wall=87, gb_free=17, wall=12381
2023-07-09 13:41:15 | INFO | train_inner | epoch 010:   1142 / 1474 loss=2.251, trans_loss=3.475, nll_loss=1.635, w2v_ctc_loss=0.607, task_loss=0.563, contrastive_loss=0.092, total=4044.03, n_correct=2442.56, ppl=3.11, accuracy=60.399, wps=14048.9, ups=1.16, wpb=12072.9, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.286, clip=0, loss_scale=32, train_wall=86, gb_free=17.4, wall=12467
2023-07-09 13:42:41 | INFO | train_inner | epoch 010:   1242 / 1474 loss=2.246, trans_loss=3.468, nll_loss=1.631, w2v_ctc_loss=0.605, task_loss=0.516, contrastive_loss=0.087, total=4110.41, n_correct=2495.18, ppl=3.1, accuracy=60.704, wps=14232.9, ups=1.16, wpb=12302.3, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.285, clip=0, loss_scale=32, train_wall=86, gb_free=16.6, wall=12553
2023-07-09 13:44:08 | INFO | train_inner | epoch 010:   1342 / 1474 loss=2.243, trans_loss=3.467, nll_loss=1.626, w2v_ctc_loss=0.6, task_loss=0.514, contrastive_loss=0.099, total=4121.38, n_correct=2504.41, ppl=3.09, accuracy=60.766, wps=14222.6, ups=1.15, wpb=12315.5, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.286, clip=0, loss_scale=32, train_wall=86, gb_free=14.3, wall=12640
2023-07-09 13:45:35 | INFO | train_inner | epoch 010:   1442 / 1474 loss=2.268, trans_loss=3.473, nll_loss=1.636, w2v_ctc_loss=0.595, task_loss=0.476, contrastive_loss=0.354, total=4192.39, n_correct=2538.78, ppl=3.11, accuracy=60.557, wps=14336.2, ups=1.15, wpb=12477.9, bsz=482, num_updates=14700, lr=0.000116642, gnorm=0.287, clip=0, loss_scale=32, train_wall=87, gb_free=17.1, wall=12727
2023-07-09 13:46:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 13:46:30 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 2.411 | trans_loss 5.633 | nll_loss 2.935 | w2v_ctc_loss 0.667 | task_loss 2.365 | contrastive_loss 0.26 | total 4003.4 | n_correct 2428.9 | ppl 7.65 | accuracy 60.671 | uer 17.54 | wer 19.298 | raw_wer 19.298 | bleu 19.01 | wps 1944.8 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 19.01
2023-07-09 13:46:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-07-09 13:46:30 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 13:46:34 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 13:46:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt (epoch 10 @ 14732 updates, score 19.01) (writing took 8.218324541987386 seconds)
2023-07-09 13:46:38 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-07-09 13:46:38 | INFO | train | epoch 010 | loss 2.249 | trans_loss 3.466 | nll_loss 1.624 | w2v_ctc_loss 0.6 | task_loss 0.505 | contrastive_loss 0.167 | total 4138.65 | n_correct 2514.2 | ppl 3.08 | accuracy 60.749 | wps 13433.3 | ups 1.09 | wpb 12355.8 | bsz 458.5 | num_updates 14732 | lr 0.000116516 | gnorm 0.284 | clip 0 | loss_scale 32 | train_wall 1272 | gb_free 17.4 | wall 12790
2023-07-09 13:46:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 13:46:39 | INFO | fairseq.trainer | begin training epoch 11
2023-07-09 13:46:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 13:47:44 | INFO | train_inner | epoch 011:     68 / 1474 loss=2.226, trans_loss=3.447, nll_loss=1.599, w2v_ctc_loss=0.581, task_loss=0.466, contrastive_loss=0.174, total=4175.24, n_correct=2569.5, ppl=3.03, accuracy=61.541, wps=9619.1, ups=0.77, wpb=12460.8, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.276, clip=0, loss_scale=32, train_wall=85, gb_free=16.9, wall=12856
2023-07-09 13:49:11 | INFO | train_inner | epoch 011:    168 / 1474 loss=2.22, trans_loss=3.446, nll_loss=1.599, w2v_ctc_loss=0.583, task_loss=0.521, contrastive_loss=0.094, total=4087.78, n_correct=2510.75, ppl=3.03, accuracy=61.421, wps=14023, ups=1.15, wpb=12225.8, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.285, clip=0, loss_scale=32, train_wall=87, gb_free=16.7, wall=12943
2023-07-09 13:50:38 | INFO | train_inner | epoch 011:    268 / 1474 loss=2.217, trans_loss=3.446, nll_loss=1.6, w2v_ctc_loss=0.579, task_loss=0.52, contrastive_loss=0.091, total=4118.77, n_correct=2525.97, ppl=3.03, accuracy=61.328, wps=14208.4, ups=1.16, wpb=12285.5, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.284, clip=0, loss_scale=32, train_wall=86, gb_free=12.7, wall=13030
tensor(0.2389, device='cuda:0')
tensor(0.1256, device='cuda:0')
2023-07-09 13:52:04 | INFO | train_inner | epoch 011:    368 / 1474 loss=2.215, trans_loss=3.444, nll_loss=1.595, w2v_ctc_loss=0.576, task_loss=0.521, contrastive_loss=0.094, total=4097.83, n_correct=2523.87, ppl=3.02, accuracy=61.59, wps=14182.2, ups=1.16, wpb=12202.1, bsz=444.2, num_updates=15100, lr=0.000115087, gnorm=0.218, clip=0, loss_scale=32, train_wall=86, gb_free=16.4, wall=13116
2023-07-09 13:53:31 | INFO | train_inner | epoch 011:    468 / 1474 loss=2.239, trans_loss=3.46, nll_loss=1.613, w2v_ctc_loss=0.581, task_loss=0.531, contrastive_loss=0.253, total=4110.64, n_correct=2513.1, ppl=3.06, accuracy=61.136, wps=14069.5, ups=1.15, wpb=12265.6, bsz=450.5, num_updates=15200, lr=0.000114708, gnorm=0.22, clip=0, loss_scale=32, train_wall=87, gb_free=16.5, wall=13203
2023-07-09 13:54:58 | INFO | train_inner | epoch 011:    568 / 1474 loss=2.243, trans_loss=3.456, nll_loss=1.614, w2v_ctc_loss=0.591, task_loss=0.538, contrastive_loss=0.251, total=4071.69, n_correct=2491.28, ppl=3.06, accuracy=61.185, wps=13955.5, ups=1.15, wpb=12176.5, bsz=440.6, num_updates=15300, lr=0.000114332, gnorm=0.221, clip=0, loss_scale=32, train_wall=87, gb_free=16.5, wall=13290
2023-07-09 13:56:25 | INFO | train_inner | epoch 011:    668 / 1474 loss=2.242, trans_loss=3.452, nll_loss=1.606, w2v_ctc_loss=0.584, task_loss=0.498, contrastive_loss=0.33, total=4157.2, n_correct=2546.23, ppl=3.04, accuracy=61.249, wps=14291.6, ups=1.15, wpb=12400.2, bsz=464.4, num_updates=15400, lr=0.000113961, gnorm=0.22, clip=0, loss_scale=32, train_wall=86, gb_free=16.9, wall=13377
2023-07-09 13:57:52 | INFO | train_inner | epoch 011:    768 / 1474 loss=2.229, trans_loss=3.456, nll_loss=1.611, w2v_ctc_loss=0.591, task_loss=0.506, contrastive_loss=0.097, total=4174.91, n_correct=2560.09, ppl=3.06, accuracy=61.321, wps=14333.9, ups=1.15, wpb=12472.8, bsz=460.4, num_updates=15500, lr=0.000113592, gnorm=0.218, clip=0, loss_scale=32, train_wall=87, gb_free=17.1, wall=13464
2023-07-09 13:59:18 | INFO | train_inner | epoch 011:    868 / 1474 loss=2.226, trans_loss=3.454, nll_loss=1.612, w2v_ctc_loss=0.59, task_loss=0.527, contrastive_loss=0.081, total=4118.44, n_correct=2513.49, ppl=3.06, accuracy=61.03, wps=14247.4, ups=1.16, wpb=12290.5, bsz=440.6, num_updates=15600, lr=0.000113228, gnorm=0.219, clip=0, loss_scale=32, train_wall=86, gb_free=11.2, wall=13550
2023-07-09 14:00:45 | INFO | train_inner | epoch 011:    968 / 1474 loss=2.228, trans_loss=3.455, nll_loss=1.612, w2v_ctc_loss=0.589, task_loss=0.514, contrastive_loss=0.098, total=4140.92, n_correct=2537.35, ppl=3.06, accuracy=61.275, wps=14258.5, ups=1.15, wpb=12353.7, bsz=452.9, num_updates=15700, lr=0.000112867, gnorm=0.218, clip=0, loss_scale=32, train_wall=86, gb_free=15.8, wall=13637
2023-07-09 14:02:12 | INFO | train_inner | epoch 011:   1068 / 1474 loss=2.232, trans_loss=3.453, nll_loss=1.611, w2v_ctc_loss=0.591, task_loss=0.495, contrastive_loss=0.121, total=4136.99, n_correct=2538.36, ppl=3.05, accuracy=61.358, wps=14302.2, ups=1.16, wpb=12367, bsz=463.2, num_updates=15800, lr=0.000112509, gnorm=0.218, clip=0, loss_scale=32, train_wall=86, gb_free=17.7, wall=13724
2023-07-09 14:03:38 | INFO | train_inner | epoch 011:   1168 / 1474 loss=2.229, trans_loss=3.455, nll_loss=1.617, w2v_ctc_loss=0.592, task_loss=0.501, contrastive_loss=0.104, total=4185.65, n_correct=2559.93, ppl=3.07, accuracy=61.16, wps=14367.4, ups=1.15, wpb=12477.8, bsz=464.7, num_updates=15900, lr=0.000112154, gnorm=0.218, clip=0, loss_scale=32, train_wall=86, gb_free=14.3, wall=13810
2023-07-09 14:05:06 | INFO | train_inner | epoch 011:   1268 / 1474 loss=2.244, trans_loss=3.456, nll_loss=1.615, w2v_ctc_loss=0.598, task_loss=0.486, contrastive_loss=0.195, total=4171.89, n_correct=2554.82, ppl=3.06, accuracy=61.239, wps=14216.7, ups=1.14, wpb=12466.6, bsz=471.1, num_updates=16000, lr=0.000111803, gnorm=0.22, clip=0, loss_scale=32, train_wall=87, gb_free=16.1, wall=13898
2023-07-09 14:05:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.2389, device='cuda:1')
tensor(0.1256, device='cuda:1')
tensor(0.2389, device='cuda:6')
tensor(0.1256, device='cuda:6')
tensor(0.2389, device='cuda:7')
tensor(0.1256, device='cuda:7')
tensor(0.2389, device='cuda:5')
tensor(0.1256, device='cuda:5')
tensor(0.2389, device='cuda:3')
tensor(0.1256, device='cuda:3')
tensor(0.2389, device='cuda:4')
tensor(0.1256, device='cuda:4')
tensor(0.2389, device='cuda:2')
tensor(0.1256, device='cuda:2')
2023-07-09 14:05:32 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 2.412 | trans_loss 5.633 | nll_loss 2.934 | w2v_ctc_loss 0.697 | task_loss 2.365 | contrastive_loss 0.259 | total 4003.4 | n_correct 2431.5 | ppl 7.64 | accuracy 60.736 | uer 17.681 | wer 19.44 | raw_wer 19.44 | bleu 19.15 | wps 2073.1 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.15
2023-07-09 14:05:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-07-09 14:05:32 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_11_16000.pt
2023-07-09 14:05:34 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_11_16000.pt
2023-07-09 14:05:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 19.15) (writing took 8.871995707973838 seconds)
2023-07-09 14:07:08 | INFO | train_inner | epoch 011:   1368 / 1474 loss=2.25, trans_loss=3.454, nll_loss=1.612, w2v_ctc_loss=0.584, task_loss=0.465, contrastive_loss=0.41, total=4190.34, n_correct=2561.56, ppl=3.06, accuracy=61.13, wps=10227.1, ups=0.82, wpb=12512.8, bsz=491.8, num_updates=16100, lr=0.000111456, gnorm=0.219, clip=0, loss_scale=32, train_wall=87, gb_free=17.1, wall=14021
2023-07-09 14:08:35 | INFO | train_inner | epoch 011:   1468 / 1474 loss=2.225, trans_loss=3.455, nll_loss=1.614, w2v_ctc_loss=0.586, task_loss=0.489, contrastive_loss=0.107, total=4158.39, n_correct=2547.9, ppl=3.06, accuracy=61.271, wps=14333.5, ups=1.15, wpb=12421.8, bsz=468, num_updates=16200, lr=0.000111111, gnorm=0.217, clip=0, loss_scale=64, train_wall=86, gb_free=17.1, wall=14107
2023-07-09 14:08:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 14:09:07 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 2.398 | trans_loss 5.613 | nll_loss 2.912 | w2v_ctc_loss 0.678 | task_loss 2.365 | contrastive_loss 0.261 | total 4003.4 | n_correct 2437.9 | ppl 7.53 | accuracy 60.896 | uer 17.466 | wer 19.246 | raw_wer 19.246 | bleu 19.31 | wps 2004.8 | wpb 4003.4 | bsz 141.8 | num_updates 16206 | best_bleu 19.31
2023-07-09 14:09:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16206 updates
2023-07-09 14:09:07 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 14:09:12 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 14:09:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt (epoch 11 @ 16206 updates, score 19.31) (writing took 8.275623014982557 seconds)
2023-07-09 14:09:16 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-07-09 14:09:16 | INFO | train | epoch 011 | loss 2.23 | trans_loss 3.452 | nll_loss 1.608 | w2v_ctc_loss 0.586 | task_loss 0.505 | contrastive_loss 0.164 | total 4138.65 | n_correct 2536.64 | ppl 3.05 | accuracy 61.291 | wps 13416.8 | ups 1.09 | wpb 12355.8 | bsz 458.5 | num_updates 16206 | lr 0.000111091 | gnorm 0.23 | clip 0 | loss_scale 64 | train_wall 1273 | gb_free 17.3 | wall 14148
2023-07-09 14:09:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 14:09:16 | INFO | fairseq.trainer | begin training epoch 12
2023-07-09 14:09:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 14:10:45 | INFO | train_inner | epoch 012:     94 / 1474 loss=2.208, trans_loss=3.429, nll_loss=1.579, w2v_ctc_loss=0.573, task_loss=0.484, contrastive_loss=0.149, total=4146.82, n_correct=2580.37, ppl=2.99, accuracy=62.225, wps=9502.8, ups=0.77, wpb=12379.4, bsz=470.8, num_updates=16300, lr=0.00011077, gnorm=0.217, clip=0, loss_scale=64, train_wall=86, gb_free=15.9, wall=14237
2023-07-09 14:12:12 | INFO | train_inner | epoch 012:    194 / 1474 loss=2.204, trans_loss=3.431, nll_loss=1.582, w2v_ctc_loss=0.574, task_loss=0.52, contrastive_loss=0.084, total=4120.68, n_correct=2558.94, ppl=2.99, accuracy=62.1, wps=14221.4, ups=1.15, wpb=12345.4, bsz=442.1, num_updates=16400, lr=0.000110432, gnorm=0.218, clip=0, loss_scale=64, train_wall=86, gb_free=15.8, wall=14324
2023-07-09 14:13:39 | INFO | train_inner | epoch 012:    294 / 1474 loss=2.203, trans_loss=3.431, nll_loss=1.584, w2v_ctc_loss=0.567, task_loss=0.475, contrastive_loss=0.125, total=4199.46, n_correct=2614.57, ppl=3, accuracy=62.26, wps=14467.4, ups=1.15, wpb=12539.6, bsz=480.4, num_updates=16500, lr=0.000110096, gnorm=0.216, clip=0, loss_scale=64, train_wall=86, gb_free=16.7, wall=14411
2023-07-09 14:15:07 | INFO | train_inner | epoch 012:    394 / 1474 loss=2.204, trans_loss=3.435, nll_loss=1.589, w2v_ctc_loss=0.571, task_loss=0.495, contrastive_loss=0.103, total=4151.14, n_correct=2575.66, ppl=3.01, accuracy=62.047, wps=14140.9, ups=1.14, wpb=12410, bsz=461.6, num_updates=16600, lr=0.000109764, gnorm=0.216, clip=0, loss_scale=64, train_wall=87, gb_free=17.2, wall=14499
2023-07-09 14:16:33 | INFO | train_inner | epoch 012:    494 / 1474 loss=2.221, trans_loss=3.448, nll_loss=1.603, w2v_ctc_loss=0.585, task_loss=0.51, contrastive_loss=0.114, total=4110.49, n_correct=2536.98, ppl=3.04, accuracy=61.72, wps=14103, ups=1.15, wpb=12226.9, bsz=453.3, num_updates=16700, lr=0.000109435, gnorm=0.22, clip=0, loss_scale=64, train_wall=86, gb_free=14.1, wall=14585
2023-07-09 14:18:01 | INFO | train_inner | epoch 012:    594 / 1474 loss=2.218, trans_loss=3.436, nll_loss=1.593, w2v_ctc_loss=0.577, task_loss=0.483, contrastive_loss=0.198, total=4189.92, n_correct=2591.92, ppl=3.02, accuracy=61.861, wps=14257.4, ups=1.14, wpb=12531.1, bsz=472.7, num_updates=16800, lr=0.000109109, gnorm=0.216, clip=0, loss_scale=64, train_wall=87, gb_free=15.1, wall=14673
2023-07-09 14:19:28 | INFO | train_inner | epoch 012:    694 / 1474 loss=2.216, trans_loss=3.434, nll_loss=1.589, w2v_ctc_loss=0.567, task_loss=0.464, contrastive_loss=0.317, total=4206.3, n_correct=2609.58, ppl=3.01, accuracy=62.04, wps=14493.8, ups=1.16, wpb=12501.9, bsz=488.5, num_updates=16900, lr=0.000108786, gnorm=0.218, clip=0, loss_scale=64, train_wall=86, gb_free=16.4, wall=14760
2023-07-09 14:20:54 | INFO | train_inner | epoch 012:    794 / 1474 loss=2.214, trans_loss=3.441, nll_loss=1.594, w2v_ctc_loss=0.581, task_loss=0.516, contrastive_loss=0.099, total=4085.96, n_correct=2529.57, ppl=3.02, accuracy=61.909, wps=14101, ups=1.15, wpb=12212.6, bsz=445.7, num_updates=17000, lr=0.000108465, gnorm=0.222, clip=0, loss_scale=64, train_wall=86, gb_free=16.6, wall=14846
2023-07-09 14:22:21 | INFO | train_inner | epoch 012:    894 / 1474 loss=2.213, trans_loss=3.437, nll_loss=1.594, w2v_ctc_loss=0.573, task_loss=0.515, contrastive_loss=0.165, total=4169.74, n_correct=2584.08, ppl=3.02, accuracy=61.972, wps=14300.8, ups=1.15, wpb=12453, bsz=459.6, num_updates=17100, lr=0.000108148, gnorm=0.217, clip=0, loss_scale=64, train_wall=87, gb_free=16.2, wall=14933
2023-07-09 14:23:48 | INFO | train_inner | epoch 012:    994 / 1474 loss=2.219, trans_loss=3.444, nll_loss=1.601, w2v_ctc_loss=0.581, task_loss=0.515, contrastive_loss=0.181, total=4117.67, n_correct=2542.97, ppl=3.03, accuracy=61.757, wps=14145.3, ups=1.15, wpb=12288, bsz=452.1, num_updates=17200, lr=0.000107833, gnorm=0.219, clip=0, loss_scale=64, train_wall=86, gb_free=17.7, wall=15020
2023-07-09 14:25:14 | INFO | train_inner | epoch 012:   1094 / 1474 loss=2.232, trans_loss=3.449, nll_loss=1.607, w2v_ctc_loss=0.585, task_loss=0.531, contrastive_loss=0.239, total=4047.61, n_correct=2494.64, ppl=3.05, accuracy=61.632, wps=14030.4, ups=1.16, wpb=12086.1, bsz=435.6, num_updates=17300, lr=0.000107521, gnorm=0.222, clip=0, loss_scale=64, train_wall=86, gb_free=16.9, wall=15106
2023-07-09 14:26:41 | INFO | train_inner | epoch 012:   1194 / 1474 loss=2.231, trans_loss=3.448, nll_loss=1.609, w2v_ctc_loss=0.593, task_loss=0.497, contrastive_loss=0.178, total=4184.55, n_correct=2567.01, ppl=3.05, accuracy=61.345, wps=14350.1, ups=1.15, wpb=12497.1, bsz=471.4, num_updates=17400, lr=0.000107211, gnorm=0.22, clip=0, loss_scale=64, train_wall=87, gb_free=16.9, wall=15193
2023-07-09 14:28:08 | INFO | train_inner | epoch 012:   1294 / 1474 loss=2.223, trans_loss=3.45, nll_loss=1.613, w2v_ctc_loss=0.589, task_loss=0.549, contrastive_loss=0.104, total=4086.33, n_correct=2516.08, ppl=3.06, accuracy=61.573, wps=14025.4, ups=1.15, wpb=12210.8, bsz=437.2, num_updates=17500, lr=0.000106904, gnorm=0.22, clip=0, loss_scale=64, train_wall=87, gb_free=17, wall=15280
2023-07-09 14:29:35 | INFO | train_inner | epoch 012:   1394 / 1474 loss=2.218, trans_loss=3.444, nll_loss=1.602, w2v_ctc_loss=0.572, task_loss=0.513, contrastive_loss=0.22, total=4134.89, n_correct=2554.51, ppl=3.04, accuracy=61.779, wps=14187.4, ups=1.15, wpb=12323.9, bsz=456.6, num_updates=17600, lr=0.0001066, gnorm=0.22, clip=0, loss_scale=64, train_wall=86, gb_free=17.4, wall=15367
2023-07-09 14:30:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 14:31:12 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 2.386 | trans_loss 5.607 | nll_loss 2.91 | w2v_ctc_loss 0.673 | task_loss 2.365 | contrastive_loss 0.253 | total 4003.4 | n_correct 2445.8 | ppl 7.52 | accuracy 61.093 | uer 17.532 | wer 19.309 | raw_wer 19.309 | bleu 19.37 | wps 2041.1 | wpb 4003.4 | bsz 141.8 | num_updates 17680 | best_bleu 19.37
2023-07-09 14:31:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17680 updates
2023-07-09 14:31:12 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 14:31:16 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 14:31:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt (epoch 12 @ 17680 updates, score 19.37) (writing took 8.08307228400372 seconds)
2023-07-09 14:31:20 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-07-09 14:31:20 | INFO | train | epoch 012 | loss 2.216 | trans_loss 3.44 | nll_loss 1.596 | w2v_ctc_loss 0.578 | task_loss 0.505 | contrastive_loss 0.16 | total 4138.65 | n_correct 2560.27 | ppl 3.02 | accuracy 61.862 | wps 13755.6 | ups 1.11 | wpb 12355.8 | bsz 458.5 | num_updates 17680 | lr 0.000106359 | gnorm 0.219 | clip 0 | loss_scale 64 | train_wall 1274 | gb_free 13.2 | wall 15472
2023-07-09 14:31:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 14:31:20 | INFO | fairseq.trainer | begin training epoch 13
2023-07-09 14:31:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 14:31:45 | INFO | train_inner | epoch 013:     20 / 1474 loss=2.216, trans_loss=3.444, nll_loss=1.603, w2v_ctc_loss=0.586, task_loss=0.523, contrastive_loss=0.093, total=4104.86, n_correct=2530.6, ppl=3.04, accuracy=61.649, wps=9448.1, ups=0.77, wpb=12264.8, bsz=445.3, num_updates=17700, lr=0.000106299, gnorm=0.219, clip=0, loss_scale=64, train_wall=86, gb_free=15, wall=15497
2023-07-09 14:33:12 | INFO | train_inner | epoch 013:    120 / 1474 loss=2.186, trans_loss=3.418, nll_loss=1.569, w2v_ctc_loss=0.559, task_loss=0.507, contrastive_loss=0.107, total=4161.2, n_correct=2606.84, ppl=2.97, accuracy=62.646, wps=14278.4, ups=1.15, wpb=12419, bsz=454.4, num_updates=17800, lr=0.000106, gnorm=0.214, clip=0, loss_scale=64, train_wall=87, gb_free=16.3, wall=15584
2023-07-09 14:34:40 | INFO | train_inner | epoch 013:    220 / 1474 loss=2.217, trans_loss=3.422, nll_loss=1.578, w2v_ctc_loss=0.565, task_loss=0.47, contrastive_loss=0.393, total=4202.62, n_correct=2629.46, ppl=2.98, accuracy=62.567, wps=14210.6, ups=1.14, wpb=12504.4, bsz=492.4, num_updates=17900, lr=0.000105703, gnorm=0.217, clip=0, loss_scale=64, train_wall=88, gb_free=17.3, wall=15672
2023-07-09 14:36:07 | INFO | train_inner | epoch 013:    320 / 1474 loss=2.19, trans_loss=3.424, nll_loss=1.575, w2v_ctc_loss=0.562, task_loss=0.521, contrastive_loss=0.089, total=4112.8, n_correct=2575.67, ppl=2.98, accuracy=62.626, wps=14174.2, ups=1.16, wpb=12262.5, bsz=444, num_updates=18000, lr=0.000105409, gnorm=0.22, clip=0, loss_scale=64, train_wall=86, gb_free=17.9, wall=15759
2023-07-09 14:36:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 14:36:34 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 2.383 | trans_loss 5.61 | nll_loss 2.904 | w2v_ctc_loss 0.669 | task_loss 2.365 | contrastive_loss 0.245 | total 4003.4 | n_correct 2448.7 | ppl 7.49 | accuracy 61.166 | uer 17.376 | wer 19.227 | raw_wer 19.227 | bleu 19.8 | wps 2014.2 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.8
2023-07-09 14:36:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-07-09 14:36:34 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_13_18000.pt
2023-07-09 14:36:36 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_13_18000.pt
2023-07-09 14:36:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.8) (writing took 10.021447812003316 seconds)
2023-07-09 14:38:10 | INFO | train_inner | epoch 013:    420 / 1474 loss=2.202, trans_loss=3.429, nll_loss=1.582, w2v_ctc_loss=0.567, task_loss=0.478, contrastive_loss=0.15, total=4176.06, n_correct=2614.47, ppl=2.99, accuracy=62.606, wps=10091, ups=0.81, wpb=12453.9, bsz=476.2, num_updates=18100, lr=0.000105118, gnorm=0.217, clip=0, loss_scale=64, train_wall=85, gb_free=16.6, wall=15882
2023-07-09 14:39:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-09 14:39:38 | INFO | train_inner | epoch 013:    521 / 1474 loss=2.205, trans_loss=3.43, nll_loss=1.585, w2v_ctc_loss=0.57, task_loss=0.497, contrastive_loss=0.198, total=4188.16, n_correct=2606.46, ppl=3, accuracy=62.234, wps=14168.7, ups=1.13, wpb=12499.7, bsz=473.6, num_updates=18200, lr=0.000104828, gnorm=0.217, clip=0, loss_scale=32, train_wall=88, gb_free=13.2, wall=15970
2023-07-09 14:41:05 | INFO | train_inner | epoch 013:    621 / 1474 loss=2.189, trans_loss=3.423, nll_loss=1.576, w2v_ctc_loss=0.563, task_loss=0.489, contrastive_loss=0.083, total=4161.98, n_correct=2608.12, ppl=2.98, accuracy=62.665, wps=14346.8, ups=1.15, wpb=12435.5, bsz=462.4, num_updates=18300, lr=0.000104542, gnorm=0.216, clip=0, loss_scale=32, train_wall=86, gb_free=16, wall=16057
2023-07-09 14:42:31 | INFO | train_inner | epoch 013:    721 / 1474 loss=2.204, trans_loss=3.431, nll_loss=1.585, w2v_ctc_loss=0.582, task_loss=0.56, contrastive_loss=0.082, total=4096.76, n_correct=2550.48, ppl=3, accuracy=62.256, wps=14127.9, ups=1.16, wpb=12226.1, bsz=426.8, num_updates=18400, lr=0.000104257, gnorm=0.219, clip=0, loss_scale=32, train_wall=86, gb_free=16.8, wall=16143
2023-07-09 14:43:59 | INFO | train_inner | epoch 013:    821 / 1474 loss=2.199, trans_loss=3.429, nll_loss=1.584, w2v_ctc_loss=0.567, task_loss=0.511, contrastive_loss=0.142, total=4121.73, n_correct=2565.39, ppl=3, accuracy=62.241, wps=14069.9, ups=1.14, wpb=12319.8, bsz=460, num_updates=18500, lr=0.000103975, gnorm=0.221, clip=0, loss_scale=32, train_wall=87, gb_free=15, wall=16231
2023-07-09 14:45:25 | INFO | train_inner | epoch 013:    921 / 1474 loss=2.197, trans_loss=3.432, nll_loss=1.588, w2v_ctc_loss=0.568, task_loss=0.514, contrastive_loss=0.095, total=4107.01, n_correct=2560.45, ppl=3.01, accuracy=62.343, wps=14217.3, ups=1.16, wpb=12264.1, bsz=444.7, num_updates=18600, lr=0.000103695, gnorm=0.223, clip=0, loss_scale=32, train_wall=86, gb_free=16.1, wall=16317
2023-07-09 14:46:51 | INFO | train_inner | epoch 013:   1021 / 1474 loss=2.207, trans_loss=3.429, nll_loss=1.588, w2v_ctc_loss=0.575, task_loss=0.533, contrastive_loss=0.161, total=4081.02, n_correct=2536.11, ppl=3.01, accuracy=62.144, wps=14164.3, ups=1.16, wpb=12208.8, bsz=440.1, num_updates=18700, lr=0.000103418, gnorm=0.219, clip=0, loss_scale=32, train_wall=86, gb_free=16.4, wall=16404
2023-07-09 14:48:18 | INFO | train_inner | epoch 013:   1121 / 1474 loss=2.199, trans_loss=3.428, nll_loss=1.583, w2v_ctc_loss=0.565, task_loss=0.497, contrastive_loss=0.138, total=4105.62, n_correct=2566.96, ppl=3, accuracy=62.523, wps=14255.2, ups=1.16, wpb=12265.4, bsz=458.9, num_updates=18800, lr=0.000103142, gnorm=0.219, clip=0, loss_scale=32, train_wall=86, gb_free=16.9, wall=16490
2023-07-09 14:49:45 | INFO | train_inner | epoch 013:   1221 / 1474 loss=2.207, trans_loss=3.439, nll_loss=1.596, w2v_ctc_loss=0.578, task_loss=0.538, contrastive_loss=0.086, total=4110.35, n_correct=2555.66, ppl=3.02, accuracy=62.176, wps=14036.7, ups=1.14, wpb=12287.7, bsz=442.6, num_updates=18900, lr=0.000102869, gnorm=0.222, clip=0, loss_scale=32, train_wall=87, gb_free=15.1, wall=16577
2023-07-09 14:51:12 | INFO | train_inner | epoch 013:   1321 / 1474 loss=2.203, trans_loss=3.428, nll_loss=1.586, w2v_ctc_loss=0.565, task_loss=0.493, contrastive_loss=0.216, total=4112.2, n_correct=2570.32, ppl=3, accuracy=62.505, wps=14150, ups=1.15, wpb=12280.4, bsz=462.3, num_updates=19000, lr=0.000102598, gnorm=0.218, clip=0, loss_scale=32, train_wall=86, gb_free=17.7, wall=16664
2023-07-09 14:52:39 | INFO | train_inner | epoch 013:   1421 / 1474 loss=2.21, trans_loss=3.439, nll_loss=1.596, w2v_ctc_loss=0.566, task_loss=0.496, contrastive_loss=0.23, total=4180.88, n_correct=2598.45, ppl=3.02, accuracy=62.151, wps=14267.9, ups=1.14, wpb=12470.5, bsz=468.3, num_updates=19100, lr=0.000102329, gnorm=0.218, clip=0, loss_scale=32, train_wall=87, gb_free=15.5, wall=16751
2023-07-09 14:53:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 14:53:52 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 2.371 | trans_loss 5.591 | nll_loss 2.891 | w2v_ctc_loss 0.67 | task_loss 2.365 | contrastive_loss 0.244 | total 4003.4 | n_correct 2449.6 | ppl 7.42 | accuracy 61.188 | uer 17.089 | wer 18.963 | raw_wer 18.963 | bleu 19.65 | wps 1927.4 | wpb 4003.4 | bsz 141.8 | num_updates 19153 | best_bleu 19.8
2023-07-09 14:53:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19153 updates
2023-07-09 14:53:52 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.6501.pt
2023-07-09 14:53:54 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.6501.pt
2023-07-09 14:53:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.6501.pt (epoch 13 @ 19153 updates, score 19.65) (writing took 5.287382651993539 seconds)
2023-07-09 14:53:57 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-07-09 14:53:57 | INFO | train | epoch 013 | loss 2.201 | trans_loss 3.428 | nll_loss 1.583 | w2v_ctc_loss 0.568 | task_loss 0.505 | contrastive_loss 0.155 | total 4138.06 | n_correct 2582.66 | ppl 3 | accuracy 62.412 | wps 13405.1 | ups 1.09 | wpb 12354.1 | bsz 458.2 | num_updates 19153 | lr 0.000102187 | gnorm 0.218 | clip 0 | loss_scale 32 | train_wall 1273 | gb_free 17.7 | wall 16829
2023-07-09 14:53:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 14:53:58 | INFO | fairseq.trainer | begin training epoch 14
2023-07-09 14:53:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 14:54:47 | INFO | train_inner | epoch 014:     47 / 1474 loss=2.178, trans_loss=3.408, nll_loss=1.56, w2v_ctc_loss=0.557, task_loss=0.459, contrastive_loss=0.101, total=4176.2, n_correct=2636.38, ppl=2.95, accuracy=63.129, wps=9788.5, ups=0.78, wpb=12486.4, bsz=483.4, num_updates=19200, lr=0.000102062, gnorm=0.216, clip=0, loss_scale=32, train_wall=86, gb_free=11.2, wall=16879
2023-07-09 14:56:14 | INFO | train_inner | epoch 014:    147 / 1474 loss=2.176, trans_loss=3.409, nll_loss=1.555, w2v_ctc_loss=0.554, task_loss=0.511, contrastive_loss=0.079, total=4080.86, n_correct=2585.55, ppl=2.94, accuracy=63.358, wps=14058.8, ups=1.15, wpb=12203.2, bsz=449.3, num_updates=19300, lr=0.000101797, gnorm=0.216, clip=0, loss_scale=32, train_wall=86, gb_free=17, wall=16966
2023-07-09 14:57:40 | INFO | train_inner | epoch 014:    247 / 1474 loss=2.188, trans_loss=3.419, nll_loss=1.57, w2v_ctc_loss=0.553, task_loss=0.534, contrastive_loss=0.215, total=4106.97, n_correct=2588.51, ppl=2.97, accuracy=63.027, wps=14137.3, ups=1.16, wpb=12224.4, bsz=440, num_updates=19400, lr=0.000101535, gnorm=0.216, clip=0, loss_scale=32, train_wall=86, gb_free=12.7, wall=17052
2023-07-09 14:59:07 | INFO | train_inner | epoch 014:    347 / 1474 loss=2.174, trans_loss=3.402, nll_loss=1.557, w2v_ctc_loss=0.554, task_loss=0.462, contrastive_loss=0.125, total=4179.8, n_correct=2635.32, ppl=2.94, accuracy=63.049, wps=14367.9, ups=1.15, wpb=12454.9, bsz=483.8, num_updates=19500, lr=0.000101274, gnorm=0.217, clip=0, loss_scale=32, train_wall=86, gb_free=17.4, wall=17139
2023-07-09 15:00:33 | INFO | train_inner | epoch 014:    447 / 1474 loss=2.177, trans_loss=3.417, nll_loss=1.57, w2v_ctc_loss=0.555, task_loss=0.522, contrastive_loss=0.075, total=4120.38, n_correct=2592.01, ppl=2.97, accuracy=62.907, wps=14226.9, ups=1.16, wpb=12283.1, bsz=444.5, num_updates=19600, lr=0.000101015, gnorm=0.218, clip=0, loss_scale=32, train_wall=86, gb_free=17.2, wall=17225
2023-07-09 15:02:01 | INFO | train_inner | epoch 014:    547 / 1474 loss=2.194, trans_loss=3.425, nll_loss=1.58, w2v_ctc_loss=0.566, task_loss=0.534, contrastive_loss=0.117, total=4089.86, n_correct=2562.69, ppl=2.99, accuracy=62.66, wps=14036.5, ups=1.14, wpb=12262.9, bsz=443.3, num_updates=19700, lr=0.000100759, gnorm=0.22, clip=0, loss_scale=32, train_wall=87, gb_free=12.4, wall=17313
2023-07-09 15:03:28 | INFO | train_inner | epoch 014:    647 / 1474 loss=2.188, trans_loss=3.421, nll_loss=1.575, w2v_ctc_loss=0.556, task_loss=0.503, contrastive_loss=0.178, total=4158.94, n_correct=2613.23, ppl=2.98, accuracy=62.834, wps=14222.3, ups=1.15, wpb=12415.4, bsz=460, num_updates=19800, lr=0.000100504, gnorm=0.221, clip=0, loss_scale=32, train_wall=87, gb_free=16.4, wall=17400
2023-07-09 15:04:55 | INFO | train_inner | epoch 014:    747 / 1474 loss=2.18, trans_loss=3.414, nll_loss=1.566, w2v_ctc_loss=0.557, task_loss=0.489, contrastive_loss=0.089, total=4150.03, n_correct=2616.99, ppl=2.96, accuracy=63.06, wps=14294.7, ups=1.15, wpb=12407.3, bsz=465.5, num_updates=19900, lr=0.000100251, gnorm=0.218, clip=0, loss_scale=32, train_wall=86, gb_free=15.7, wall=17487
2023-07-09 15:06:21 | INFO | train_inner | epoch 014:    847 / 1474 loss=2.187, trans_loss=3.41, nll_loss=1.564, w2v_ctc_loss=0.552, task_loss=0.48, contrastive_loss=0.234, total=4162.8, n_correct=2620.43, ppl=2.96, accuracy=62.949, wps=14363.7, ups=1.16, wpb=12422.9, bsz=475.8, num_updates=20000, lr=0.0001, gnorm=0.219, clip=0, loss_scale=32, train_wall=86, gb_free=17.2, wall=17573
2023-07-09 15:06:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 15:06:46 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 2.362 | trans_loss 5.579 | nll_loss 2.873 | w2v_ctc_loss 0.668 | task_loss 2.365 | contrastive_loss 0.242 | total 4003.4 | n_correct 2458.3 | ppl 7.33 | accuracy 61.405 | uer 16.933 | wer 18.892 | raw_wer 18.892 | bleu 19.73 | wps 2085 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.8
2023-07-09 15:06:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-07-09 15:06:46 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_14_20000.pt
2023-07-09 15:06:48 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_14_20000.pt
2023-07-09 15:06:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.73) (writing took 6.077659258997301 seconds)
tensor(0.0221, device='cuda:0')
tensor(0.0008, device='cuda:0')
2023-07-09 15:07:54 | INFO | train_inner | epoch 014:    947 / 1474 loss=1.55, trans_loss=5.356, nll_loss=2.723, w2v_ctc_loss=0.473, task_loss=1.486, contrastive_loss=0.137, total=4159.46, n_correct=2603.69, ppl=6.6, accuracy=62.597, wps=4573, ups=1.08, wpb=4251.9, bsz=158.1, num_updates=20100, lr=9.97509e-05, gnorm=0.346, clip=0, loss_scale=32, train_wall=61, gb_free=15.6, wall=17666
2023-07-09 15:08:55 | INFO | train_inner | epoch 014:   1047 / 1474 loss=1.543, trans_loss=5.426, nll_loss=2.77, w2v_ctc_loss=0.468, task_loss=1.517, contrastive_loss=0.278, total=4155.93, n_correct=2597.74, ppl=6.82, accuracy=62.507, wps=6803.3, ups=1.64, wpb=4155.9, bsz=153, num_updates=20200, lr=9.95037e-05, gnorm=0.348, clip=0, loss_scale=32, train_wall=61, gb_free=16.7, wall=17727
2023-07-09 15:09:56 | INFO | train_inner | epoch 014:   1147 / 1474 loss=1.556, trans_loss=5.433, nll_loss=2.78, w2v_ctc_loss=0.478, task_loss=1.432, contrastive_loss=0.722, total=4228.09, n_correct=2638.16, ppl=6.87, accuracy=62.396, wps=6911.3, ups=1.63, wpb=4228.1, bsz=163.2, num_updates=20300, lr=9.92583e-05, gnorm=0.348, clip=0, loss_scale=64, train_wall=61, gb_free=17.7, wall=17788
2023-07-09 15:10:57 | INFO | train_inner | epoch 014:   1247 / 1474 loss=1.547, trans_loss=5.444, nll_loss=2.793, w2v_ctc_loss=0.479, task_loss=1.77, contrastive_loss=0.106, total=4027.71, n_correct=2502.82, ppl=6.93, accuracy=62.14, wps=6676.9, ups=1.66, wpb=4027.7, bsz=136.8, num_updates=20400, lr=9.90148e-05, gnorm=0.354, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=17849
2023-07-09 15:11:57 | INFO | train_inner | epoch 014:   1347 / 1474 loss=1.536, trans_loss=5.421, nll_loss=2.765, w2v_ctc_loss=0.468, task_loss=1.448, contrastive_loss=0.136, total=4198.71, n_correct=2629.49, ppl=6.8, accuracy=62.626, wps=6918.5, ups=1.65, wpb=4198.7, bsz=157.7, num_updates=20500, lr=9.8773e-05, gnorm=0.349, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=17909
2023-07-09 15:12:58 | INFO | train_inner | epoch 014:   1447 / 1474 loss=1.541, trans_loss=5.43, nll_loss=2.777, w2v_ctc_loss=0.471, task_loss=1.494, contrastive_loss=0.213, total=4140.5, n_correct=2587.7, ppl=6.85, accuracy=62.497, wps=6837.3, ups=1.65, wpb=4140.5, bsz=153.5, num_updates=20600, lr=9.85329e-05, gnorm=0.349, clip=0, loss_scale=64, train_wall=60, gb_free=17.7, wall=17970
2023-07-09 15:13:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0221, device='cuda:5')
tensor(0.0008, device='cuda:5')
tensor(0.0221, device='cuda:4')
tensor(0.0008, device='cuda:4')
tensor(0.0221, device='cuda:3')
tensor(0.0008, device='cuda:3')
tensor(0.0221, device='cuda:2')
tensor(0.0008, device='cuda:2')
tensor(0.0221, device='cuda:7')
tensor(0.0008, device='cuda:7')
tensor(0.0221, device='cuda:1')
tensor(0.0008, device='cuda:1')
tensor(0.0221, device='cuda:6')
tensor(0.0008, device='cuda:6')
2023-07-09 15:13:41 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 2.36 | trans_loss 5.578 | nll_loss 2.879 | w2v_ctc_loss 0.678 | task_loss 2.365 | contrastive_loss 0.244 | total 4003.4 | n_correct 2461.7 | ppl 7.36 | accuracy 61.49 | uer 17.272 | wer 19.104 | raw_wer 19.104 | bleu 19.43 | wps 1954.9 | wpb 4003.4 | bsz 141.8 | num_updates 20627 | best_bleu 19.8
2023-07-09 15:13:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20627 updates
2023-07-09 15:13:41 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.4305.pt
2023-07-09 15:13:43 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.4305.pt
2023-07-09 15:13:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.4305.pt (epoch 14 @ 20627 updates, score 19.43) (writing took 5.212430490006227 seconds)
2023-07-09 15:13:47 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-07-09 15:13:47 | INFO | train | epoch 014 | loss 1.985 | trans_loss 3.814 | nll_loss 1.806 | w2v_ctc_loss 0.53 | task_loss 0.703 | contrastive_loss 0.162 | total 4138.65 | n_correct 2597.9 | ppl 3.5 | accuracy 62.772 | wps 10985.6 | ups 1.24 | wpb 8862.4 | bsz 329.2 | num_updates 20627 | lr 9.84684e-05 | gnorm 0.274 | clip 0 | loss_scale 64 | train_wall 1109 | gb_free 16.6 | wall 18019
2023-07-09 15:13:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 15:13:47 | INFO | fairseq.trainer | begin training epoch 15
2023-07-09 15:13:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 15:14:39 | INFO | train_inner | epoch 015:     73 / 1474 loss=1.532, trans_loss=5.394, nll_loss=2.73, w2v_ctc_loss=0.459, task_loss=1.519, contrastive_loss=0.313, total=4083.93, n_correct=2575.37, ppl=6.63, accuracy=63.061, wps=4050.8, ups=0.99, wpb=4083.9, bsz=150, num_updates=20700, lr=9.82946e-05, gnorm=0.347, clip=0, loss_scale=64, train_wall=59, gb_free=15.8, wall=18071
2023-07-09 15:15:39 | INFO | train_inner | epoch 015:    173 / 1474 loss=1.527, trans_loss=5.384, nll_loss=2.716, w2v_ctc_loss=0.467, task_loss=1.572, contrastive_loss=0.128, total=4122.67, n_correct=2605.1, ppl=6.57, accuracy=63.19, wps=6846.6, ups=1.66, wpb=4122.7, bsz=149.6, num_updates=20800, lr=9.80581e-05, gnorm=0.344, clip=0, loss_scale=64, train_wall=60, gb_free=17.3, wall=18131
2023-07-09 15:16:39 | INFO | train_inner | epoch 015:    273 / 1474 loss=1.52, trans_loss=5.376, nll_loss=2.706, w2v_ctc_loss=0.46, task_loss=1.452, contrastive_loss=0.112, total=4190.11, n_correct=2653.12, ppl=6.53, accuracy=63.319, wps=6980.3, ups=1.67, wpb=4190.1, bsz=156.3, num_updates=20900, lr=9.78232e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=60, gb_free=17.3, wall=18191
2023-07-09 15:17:39 | INFO | train_inner | epoch 015:    373 / 1474 loss=1.525, trans_loss=5.378, nll_loss=2.709, w2v_ctc_loss=0.461, task_loss=1.565, contrastive_loss=0.155, total=4150.33, n_correct=2624.66, ppl=6.54, accuracy=63.24, wps=6877, ups=1.66, wpb=4150.3, bsz=150.5, num_updates=21000, lr=9.759e-05, gnorm=0.347, clip=0, loss_scale=64, train_wall=60, gb_free=15.7, wall=18251
2023-07-09 15:18:40 | INFO | train_inner | epoch 015:    473 / 1474 loss=1.532, trans_loss=5.394, nll_loss=2.73, w2v_ctc_loss=0.462, task_loss=1.555, contrastive_loss=0.343, total=4082.7, n_correct=2573.55, ppl=6.64, accuracy=63.035, wps=6759.4, ups=1.66, wpb=4082.7, bsz=149.2, num_updates=21100, lr=9.73585e-05, gnorm=0.351, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=18312
2023-07-09 15:19:40 | INFO | train_inner | epoch 015:    573 / 1474 loss=1.528, trans_loss=5.396, nll_loss=2.734, w2v_ctc_loss=0.473, task_loss=1.604, contrastive_loss=0.121, total=4130.96, n_correct=2596.7, ppl=6.65, accuracy=62.859, wps=6857.8, ups=1.66, wpb=4131, bsz=146.7, num_updates=21200, lr=9.71286e-05, gnorm=0.35, clip=0, loss_scale=64, train_wall=60, gb_free=17.4, wall=18372
2023-07-09 15:20:40 | INFO | train_inner | epoch 015:    673 / 1474 loss=1.528, trans_loss=5.391, nll_loss=2.728, w2v_ctc_loss=0.466, task_loss=1.501, contrastive_loss=0.264, total=4138.41, n_correct=2611.66, ppl=6.62, accuracy=63.108, wps=6877.4, ups=1.66, wpb=4138.4, bsz=154.7, num_updates=21300, lr=9.69003e-05, gnorm=0.353, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=18432
2023-07-09 15:21:41 | INFO | train_inner | epoch 015:    773 / 1474 loss=1.531, trans_loss=5.403, nll_loss=2.744, w2v_ctc_loss=0.471, task_loss=1.523, contrastive_loss=0.163, total=4186.48, n_correct=2628.65, ppl=6.7, accuracy=62.789, wps=6900.4, ups=1.65, wpb=4186.5, bsz=153.9, num_updates=21400, lr=9.66736e-05, gnorm=0.349, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=18493
2023-07-09 15:22:40 | INFO | train_inner | epoch 015:    873 / 1474 loss=1.528, trans_loss=5.406, nll_loss=2.749, w2v_ctc_loss=0.468, task_loss=1.645, contrastive_loss=0.121, total=4054.09, n_correct=2542.8, ppl=6.72, accuracy=62.722, wps=6812.3, ups=1.68, wpb=4054.1, bsz=143.1, num_updates=21500, lr=9.64486e-05, gnorm=0.356, clip=0, loss_scale=64, train_wall=59, gb_free=16, wall=18552
2023-07-09 15:23:41 | INFO | train_inner | epoch 015:    973 / 1474 loss=1.531, trans_loss=5.391, nll_loss=2.73, w2v_ctc_loss=0.465, task_loss=1.511, contrastive_loss=0.293, total=4126.63, n_correct=2604.03, ppl=6.64, accuracy=63.103, wps=6860.5, ups=1.66, wpb=4126.6, bsz=151.5, num_updates=21600, lr=9.6225e-05, gnorm=0.347, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=18613
2023-07-09 15:24:43 | INFO | train_inner | epoch 015:   1073 / 1474 loss=1.536, trans_loss=5.4, nll_loss=2.743, w2v_ctc_loss=0.464, task_loss=1.404, contrastive_loss=0.604, total=4199.33, n_correct=2638.82, ppl=6.69, accuracy=62.839, wps=6774.3, ups=1.61, wpb=4199.3, bsz=163.6, num_updates=21700, lr=9.60031e-05, gnorm=0.347, clip=0, loss_scale=64, train_wall=62, gb_free=11.9, wall=18675
2023-07-09 15:25:42 | INFO | train_inner | epoch 015:   1173 / 1474 loss=1.522, trans_loss=5.385, nll_loss=2.724, w2v_ctc_loss=0.458, task_loss=1.371, contrastive_loss=0.217, total=4172.81, n_correct=2638.88, ppl=6.61, accuracy=63.24, wps=6958.9, ups=1.67, wpb=4172.8, bsz=163.2, num_updates=21800, lr=9.57826e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=59, gb_free=13.2, wall=18735
2023-07-09 15:26:43 | INFO | train_inner | epoch 015:   1273 / 1474 loss=1.525, trans_loss=5.395, nll_loss=2.736, w2v_ctc_loss=0.473, task_loss=1.539, contrastive_loss=0.129, total=4152.76, n_correct=2616.05, ppl=6.66, accuracy=62.995, wps=6865.2, ups=1.65, wpb=4152.8, bsz=152.3, num_updates=21900, lr=9.55637e-05, gnorm=0.347, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=18795
2023-07-09 15:27:43 | INFO | train_inner | epoch 015:   1373 / 1474 loss=1.524, trans_loss=5.393, nll_loss=2.733, w2v_ctc_loss=0.468, task_loss=1.57, contrastive_loss=0.101, total=4107.77, n_correct=2586.42, ppl=6.65, accuracy=62.964, wps=6815.6, ups=1.66, wpb=4107.8, bsz=147, num_updates=22000, lr=9.53463e-05, gnorm=0.347, clip=0, loss_scale=64, train_wall=60, gb_free=15.5, wall=18855
2023-07-09 15:27:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 15:28:10 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 2.344 | trans_loss 5.568 | nll_loss 2.864 | w2v_ctc_loss 0.662 | task_loss 2.367 | contrastive_loss 0.248 | total 4003.4 | n_correct 2473.9 | ppl 7.28 | accuracy 61.795 | uer 17.079 | wer 18.985 | raw_wer 18.985 | bleu 19.98 | wps 1901.6 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 19.98
2023-07-09 15:28:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-07-09 15:28:10 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_15_22000.pt
2023-07-09 15:28:12 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_15_22000.pt
2023-07-09 15:28:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.98) (writing took 9.225421976007055 seconds)
2023-07-09 15:29:21 | INFO | train_inner | epoch 015:   1473 / 1474 loss=1.527, trans_loss=5.404, nll_loss=2.75, w2v_ctc_loss=0.467, task_loss=1.474, contrastive_loss=0.276, total=4157.38, n_correct=2614.84, ppl=6.73, accuracy=62.896, wps=4250.3, ups=1.02, wpb=4157.4, bsz=157.4, num_updates=22100, lr=9.51303e-05, gnorm=0.347, clip=0, loss_scale=64, train_wall=61, gb_free=17.4, wall=18953
2023-07-09 15:29:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 15:29:47 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 2.351 | trans_loss 5.566 | nll_loss 2.868 | w2v_ctc_loss 0.689 | task_loss 2.366 | contrastive_loss 0.254 | total 4003.4 | n_correct 2469.1 | ppl 7.3 | accuracy 61.675 | uer 17.1 | wer 18.985 | raw_wer 18.985 | bleu 19.86 | wps 2149.6 | wpb 4003.4 | bsz 141.8 | num_updates 22101 | best_bleu 19.98
2023-07-09 15:29:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22101 updates
2023-07-09 15:29:47 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.8604.pt
2023-07-09 15:29:49 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.8604.pt
2023-07-09 15:29:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.8604.pt (epoch 15 @ 22101 updates, score 19.86) (writing took 5.136642605997622 seconds)
2023-07-09 15:29:52 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-07-09 15:29:52 | INFO | train | epoch 015 | loss 1.527 | trans_loss 5.392 | nll_loss 2.73 | w2v_ctc_loss 0.465 | task_loss 1.515 | contrastive_loss 0.227 | total 4138.65 | n_correct 2609.08 | ppl 6.63 | accuracy 63.042 | wps 6316.8 | ups 1.53 | wpb 4138.6 | bsz 152.8 | num_updates 22101 | lr 9.51281e-05 | gnorm 0.348 | clip 0 | loss_scale 64 | train_wall 883 | gb_free 17.2 | wall 18984
2023-07-09 15:29:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 15:29:53 | INFO | fairseq.trainer | begin training epoch 16
2023-07-09 15:29:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 15:31:01 | INFO | train_inner | epoch 016:     99 / 1474 loss=1.507, trans_loss=5.341, nll_loss=2.666, w2v_ctc_loss=0.454, task_loss=1.433, contrastive_loss=0.156, total=4113.74, n_correct=2629.66, ppl=6.35, accuracy=63.924, wps=4128.3, ups=1, wpb=4113.7, bsz=158, num_updates=22200, lr=9.49158e-05, gnorm=0.348, clip=0, loss_scale=64, train_wall=60, gb_free=17.6, wall=19053
2023-07-09 15:32:01 | INFO | train_inner | epoch 016:    199 / 1474 loss=1.503, trans_loss=5.345, nll_loss=2.67, w2v_ctc_loss=0.448, task_loss=1.563, contrastive_loss=0.11, total=4091.27, n_correct=2611.59, ppl=6.36, accuracy=63.833, wps=6784, ups=1.66, wpb=4091.3, bsz=147.2, num_updates=22300, lr=9.47027e-05, gnorm=0.342, clip=0, loss_scale=128, train_wall=60, gb_free=15, wall=19113
2023-07-09 15:32:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-09 15:33:02 | INFO | train_inner | epoch 016:    300 / 1474 loss=1.519, trans_loss=5.365, nll_loss=2.699, w2v_ctc_loss=0.468, task_loss=1.518, contrastive_loss=0.124, total=4158.96, n_correct=2639.93, ppl=6.49, accuracy=63.476, wps=6796.5, ups=1.63, wpb=4159, bsz=152.8, num_updates=22400, lr=9.44911e-05, gnorm=0.349, clip=0, loss_scale=64, train_wall=61, gb_free=17.3, wall=19174
2023-07-09 15:34:02 | INFO | train_inner | epoch 016:    400 / 1474 loss=1.52, trans_loss=5.374, nll_loss=2.709, w2v_ctc_loss=0.466, task_loss=1.615, contrastive_loss=0.284, total=4073.3, n_correct=2577.34, ppl=6.54, accuracy=63.274, wps=6820.5, ups=1.67, wpb=4073.3, bsz=144, num_updates=22500, lr=9.42809e-05, gnorm=0.352, clip=0, loss_scale=64, train_wall=59, gb_free=17.2, wall=19234
2023-07-09 15:35:03 | INFO | train_inner | epoch 016:    500 / 1474 loss=1.514, trans_loss=5.361, nll_loss=2.694, w2v_ctc_loss=0.461, task_loss=1.458, contrastive_loss=0.175, total=4174.67, n_correct=2656, ppl=6.47, accuracy=63.622, wps=6867.9, ups=1.65, wpb=4174.7, bsz=159.5, num_updates=22600, lr=9.40721e-05, gnorm=0.348, clip=0, loss_scale=64, train_wall=60, gb_free=16.1, wall=19295
2023-07-09 15:36:02 | INFO | train_inner | epoch 016:    600 / 1474 loss=1.51, trans_loss=5.359, nll_loss=2.689, w2v_ctc_loss=0.456, task_loss=1.538, contrastive_loss=0.1, total=4124.65, n_correct=2624.1, ppl=6.45, accuracy=63.62, wps=6906.1, ups=1.67, wpb=4124.6, bsz=148.8, num_updates=22700, lr=9.38647e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=59, gb_free=16.4, wall=19354
2023-07-09 15:37:03 | INFO | train_inner | epoch 016:    700 / 1474 loss=1.515, trans_loss=5.37, nll_loss=2.705, w2v_ctc_loss=0.464, task_loss=1.561, contrastive_loss=0.108, total=4095.49, n_correct=2595.3, ppl=6.52, accuracy=63.37, wps=6792.4, ups=1.66, wpb=4095.5, bsz=148.2, num_updates=22800, lr=9.36586e-05, gnorm=0.349, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=19415
2023-07-09 15:38:03 | INFO | train_inner | epoch 016:    800 / 1474 loss=1.516, trans_loss=5.376, nll_loss=2.714, w2v_ctc_loss=0.456, task_loss=2.247, contrastive_loss=0.246, total=4174.94, n_correct=2637.46, ppl=6.56, accuracy=63.174, wps=6941.8, ups=1.66, wpb=4174.9, bsz=155.4, num_updates=22900, lr=9.34539e-05, gnorm=0.35, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=19475
2023-07-09 15:39:03 | INFO | train_inner | epoch 016:    900 / 1474 loss=1.514, trans_loss=5.366, nll_loss=2.702, w2v_ctc_loss=0.456, task_loss=2.031, contrastive_loss=0.232, total=4163.19, n_correct=2640.67, ppl=6.51, accuracy=63.429, wps=6918.3, ups=1.66, wpb=4163.2, bsz=155.3, num_updates=23000, lr=9.32505e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=19535
2023-07-09 15:40:04 | INFO | train_inner | epoch 016:   1000 / 1474 loss=1.52, trans_loss=5.384, nll_loss=2.723, w2v_ctc_loss=0.467, task_loss=2.181, contrastive_loss=0.219, total=4103.45, n_correct=2590.58, ppl=6.6, accuracy=63.132, wps=6770.7, ups=1.65, wpb=4103.4, bsz=149, num_updates=23100, lr=9.30484e-05, gnorm=0.348, clip=0, loss_scale=64, train_wall=60, gb_free=15.1, wall=19596
2023-07-09 15:41:04 | INFO | train_inner | epoch 016:   1100 / 1474 loss=1.518, trans_loss=5.388, nll_loss=2.729, w2v_ctc_loss=0.468, task_loss=2.237, contrastive_loss=0.166, total=4119.27, n_correct=2596.39, ppl=6.63, accuracy=63.03, wps=6782.7, ups=1.65, wpb=4119.3, bsz=147.7, num_updates=23200, lr=9.28477e-05, gnorm=0.349, clip=0, loss_scale=64, train_wall=60, gb_free=17.9, wall=19656
2023-07-09 15:42:06 | INFO | train_inner | epoch 016:   1200 / 1474 loss=1.519, trans_loss=5.381, nll_loss=2.721, w2v_ctc_loss=0.458, task_loss=2.111, contrastive_loss=0.357, total=4165.11, n_correct=2628.81, ppl=6.59, accuracy=63.115, wps=6817.3, ups=1.64, wpb=4165.1, bsz=154.3, num_updates=23300, lr=9.26482e-05, gnorm=0.35, clip=0, loss_scale=64, train_wall=61, gb_free=17, wall=19718
2023-07-09 15:43:07 | INFO | train_inner | epoch 016:   1300 / 1474 loss=1.523, trans_loss=5.387, nll_loss=2.729, w2v_ctc_loss=0.469, task_loss=2.055, contrastive_loss=0.322, total=4134.61, n_correct=2611.88, ppl=6.63, accuracy=63.171, wps=6776.7, ups=1.64, wpb=4134.6, bsz=155.4, num_updates=23400, lr=9.245e-05, gnorm=0.351, clip=0, loss_scale=64, train_wall=61, gb_free=16.9, wall=19779
2023-07-09 15:44:07 | INFO | train_inner | epoch 016:   1400 / 1474 loss=1.516, trans_loss=5.377, nll_loss=2.716, w2v_ctc_loss=0.465, task_loss=1.988, contrastive_loss=0.176, total=4206.33, n_correct=2661.43, ppl=6.57, accuracy=63.272, wps=6918.5, ups=1.64, wpb=4206.3, bsz=161.1, num_updates=23500, lr=9.22531e-05, gnorm=0.347, clip=0, loss_scale=64, train_wall=60, gb_free=15.7, wall=19839
2023-07-09 15:44:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 15:45:20 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 2.341 | trans_loss 5.561 | nll_loss 2.859 | w2v_ctc_loss 0.688 | task_loss 2.365 | contrastive_loss 0.247 | total 4003.4 | n_correct 2469.9 | ppl 7.25 | accuracy 61.695 | uer 17.129 | wer 18.944 | raw_wer 18.944 | bleu 19.76 | wps 1963.9 | wpb 4003.4 | bsz 141.8 | num_updates 23574 | best_bleu 19.98
2023-07-09 15:45:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23574 updates
2023-07-09 15:45:20 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.7605.pt
2023-07-09 15:45:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.7605.pt
2023-07-09 15:45:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.7605.pt (epoch 16 @ 23574 updates, score 19.76) (writing took 5.09353409500909 seconds)
2023-07-09 15:45:25 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-07-09 15:45:25 | INFO | train | epoch 016 | loss 1.516 | trans_loss 5.37 | nll_loss 2.706 | w2v_ctc_loss 0.461 | task_loss 1.838 | contrastive_loss 0.217 | total 4137.91 | n_correct 2622.34 | ppl 6.52 | accuracy 63.374 | wps 6536 | ups 1.58 | wpb 4137.9 | bsz 152.7 | num_updates 23574 | lr 9.21082e-05 | gnorm 0.348 | clip 0 | loss_scale 64 | train_wall 884 | gb_free 15.6 | wall 19917
2023-07-09 15:45:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 15:45:25 | INFO | fairseq.trainer | begin training epoch 17
2023-07-09 15:45:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 15:45:49 | INFO | train_inner | epoch 017:     26 / 1474 loss=1.517, trans_loss=5.363, nll_loss=2.697, w2v_ctc_loss=0.459, task_loss=2.113, contrastive_loss=0.447, total=4152.31, n_correct=2636.16, ppl=6.49, accuracy=63.487, wps=4070.9, ups=0.98, wpb=4152.3, bsz=152.3, num_updates=23600, lr=9.20575e-05, gnorm=0.35, clip=0, loss_scale=64, train_wall=60, gb_free=14.1, wall=19941
2023-07-09 15:46:50 | INFO | train_inner | epoch 017:    126 / 1474 loss=1.504, trans_loss=5.335, nll_loss=2.661, w2v_ctc_loss=0.46, task_loss=2.167, contrastive_loss=0.119, total=4118.91, n_correct=2628.79, ppl=6.32, accuracy=63.822, wps=6783.8, ups=1.65, wpb=4118.9, bsz=147.9, num_updates=23700, lr=9.1863e-05, gnorm=0.344, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=20002
2023-07-09 15:47:50 | INFO | train_inner | epoch 017:    226 / 1474 loss=1.51, trans_loss=5.338, nll_loss=2.666, w2v_ctc_loss=0.453, task_loss=1.994, contrastive_loss=0.454, total=4145.15, n_correct=2647.83, ppl=6.35, accuracy=63.878, wps=6895.5, ups=1.66, wpb=4145.1, bsz=157.5, num_updates=23800, lr=9.16698e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=60, gb_free=15.8, wall=20062
2023-07-09 15:48:51 | INFO | train_inner | epoch 017:    326 / 1474 loss=1.509, trans_loss=5.338, nll_loss=2.666, w2v_ctc_loss=0.454, task_loss=2.062, contrastive_loss=0.459, total=4169.51, n_correct=2660.04, ppl=6.35, accuracy=63.797, wps=6888.5, ups=1.65, wpb=4169.5, bsz=154.1, num_updates=23900, lr=9.14779e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=20123
2023-07-09 15:49:52 | INFO | train_inner | epoch 017:    426 / 1474 loss=1.501, trans_loss=5.346, nll_loss=2.676, w2v_ctc_loss=0.458, task_loss=2.077, contrastive_loss=0.12, total=4140.49, n_correct=2643.73, ppl=6.39, accuracy=63.851, wps=6810.8, ups=1.64, wpb=4140.5, bsz=153.4, num_updates=24000, lr=9.12871e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=20184
2023-07-09 15:49:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 15:50:18 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 2.336 | trans_loss 5.561 | nll_loss 2.858 | w2v_ctc_loss 0.676 | task_loss 2.365 | contrastive_loss 0.251 | total 4003.4 | n_correct 2464.8 | ppl 7.25 | accuracy 61.568 | uer 17.105 | wer 18.899 | raw_wer 18.899 | bleu 19.55 | wps 1971 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 19.98
2023-07-09 15:50:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-07-09 15:50:18 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_17_24000.pt
2023-07-09 15:50:20 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_17_24000.pt
2023-07-09 15:50:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.55) (writing took 6.251774688018486 seconds)
2023-07-09 15:51:26 | INFO | train_inner | epoch 017:    526 / 1474 loss=1.509, trans_loss=5.351, nll_loss=2.684, w2v_ctc_loss=0.463, task_loss=2.194, contrastive_loss=0.211, total=4184.16, n_correct=2663.78, ppl=6.42, accuracy=63.663, wps=4433.9, ups=1.06, wpb=4184.2, bsz=153.5, num_updates=24100, lr=9.10975e-05, gnorm=0.347, clip=0, loss_scale=64, train_wall=61, gb_free=17.4, wall=20278
2023-07-09 15:52:27 | INFO | train_inner | epoch 017:    626 / 1474 loss=1.503, trans_loss=5.347, nll_loss=2.678, w2v_ctc_loss=0.456, task_loss=2.088, contrastive_loss=0.112, total=4166.61, n_correct=2654.51, ppl=6.4, accuracy=63.709, wps=6846, ups=1.64, wpb=4166.6, bsz=151.7, num_updates=24200, lr=9.09091e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=20339
2023-07-09 15:53:27 | INFO | train_inner | epoch 017:    726 / 1474 loss=1.512, trans_loss=5.364, nll_loss=2.7, w2v_ctc_loss=0.467, task_loss=2.076, contrastive_loss=0.208, total=4167.85, n_correct=2650.01, ppl=6.5, accuracy=63.582, wps=6888, ups=1.65, wpb=4167.9, bsz=154.2, num_updates=24300, lr=9.07218e-05, gnorm=0.351, clip=0, loss_scale=64, train_wall=60, gb_free=15.4, wall=20399
2023-07-09 15:54:27 | INFO | train_inner | epoch 017:    826 / 1474 loss=1.506, trans_loss=5.354, nll_loss=2.687, w2v_ctc_loss=0.461, task_loss=2.105, contrastive_loss=0.134, total=4093.22, n_correct=2602.19, ppl=6.44, accuracy=63.573, wps=6866.7, ups=1.68, wpb=4093.2, bsz=148.2, num_updates=24400, lr=9.05357e-05, gnorm=0.347, clip=0, loss_scale=64, train_wall=59, gb_free=16.5, wall=20459
2023-07-09 15:55:27 | INFO | train_inner | epoch 017:    926 / 1474 loss=1.503, trans_loss=5.347, nll_loss=2.678, w2v_ctc_loss=0.454, task_loss=2.086, contrastive_loss=0.128, total=4099.33, n_correct=2615.01, ppl=6.4, accuracy=63.791, wps=6822.9, ups=1.66, wpb=4099.3, bsz=150.9, num_updates=24500, lr=9.03508e-05, gnorm=0.352, clip=0, loss_scale=128, train_wall=60, gb_free=16.5, wall=20519
2023-07-09 15:56:27 | INFO | train_inner | epoch 017:   1026 / 1474 loss=1.503, trans_loss=5.344, nll_loss=2.675, w2v_ctc_loss=0.458, task_loss=2.044, contrastive_loss=0.141, total=4123.22, n_correct=2631.37, ppl=6.39, accuracy=63.818, wps=6861.3, ups=1.66, wpb=4123.2, bsz=153.8, num_updates=24600, lr=9.0167e-05, gnorm=0.347, clip=0, loss_scale=128, train_wall=60, gb_free=17.2, wall=20579
2023-07-09 15:57:27 | INFO | train_inner | epoch 017:   1126 / 1474 loss=1.5, trans_loss=5.346, nll_loss=2.677, w2v_ctc_loss=0.451, task_loss=2.17, contrastive_loss=0.114, total=4068.18, n_correct=2591.36, ppl=6.39, accuracy=63.698, wps=6830, ups=1.68, wpb=4068.2, bsz=146.7, num_updates=24700, lr=8.99843e-05, gnorm=0.349, clip=0, loss_scale=128, train_wall=59, gb_free=10.8, wall=20639
2023-07-09 15:57:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-09 15:58:29 | INFO | train_inner | epoch 017:   1227 / 1474 loss=1.516, trans_loss=5.375, nll_loss=2.716, w2v_ctc_loss=0.461, task_loss=2.093, contrastive_loss=0.498, total=4155.29, n_correct=2626.11, ppl=6.57, accuracy=63.199, wps=6717.8, ups=1.62, wpb=4155.3, bsz=157.8, num_updates=24800, lr=8.98027e-05, gnorm=0.355, clip=0, loss_scale=64, train_wall=61, gb_free=16.2, wall=20701
2023-07-09 15:59:29 | INFO | train_inner | epoch 017:   1327 / 1474 loss=1.508, trans_loss=5.358, nll_loss=2.695, w2v_ctc_loss=0.455, task_loss=2.075, contrastive_loss=0.274, total=4156.28, n_correct=2642.92, ppl=6.47, accuracy=63.589, wps=6865, ups=1.65, wpb=4156.3, bsz=154, num_updates=24900, lr=8.96221e-05, gnorm=0.352, clip=0, loss_scale=64, train_wall=60, gb_free=17.9, wall=20761
2023-07-09 16:00:29 | INFO | train_inner | epoch 017:   1427 / 1474 loss=1.498, trans_loss=5.354, nll_loss=2.689, w2v_ctc_loss=0.455, task_loss=2.109, contrastive_loss=0.12, total=4112.95, n_correct=2616.53, ppl=6.45, accuracy=63.617, wps=6808.8, ups=1.66, wpb=4112.9, bsz=151.6, num_updates=25000, lr=8.94427e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=20821
tensor(0.0221, device='cuda:0')
tensor(0.0008, device='cuda:0')
2023-07-09 16:00:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0221, device='cuda:6')
tensor(0.0008, device='cuda:6')
tensor(0.0221, device='cuda:7')
tensor(0.0008, device='cuda:7')
tensor(0.0221, device='cuda:5')
tensor(0.0008, device='cuda:5')
tensor(0.0221, device='cuda:4')
tensor(0.0008, device='cuda:4')
tensor(0.0221, device='cuda:1')
tensor(0.0008, device='cuda:1')
tensor(0.0221, device='cuda:3')
tensor(0.0008, device='cuda:3')
tensor(0.0221, device='cuda:2')
tensor(0.0008, device='cuda:2')
2023-07-09 16:01:27 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 2.328 | trans_loss 5.558 | nll_loss 2.858 | w2v_ctc_loss 0.667 | task_loss 2.365 | contrastive_loss 0.251 | total 4003.4 | n_correct 2468.8 | ppl 7.25 | accuracy 61.668 | uer 16.975 | wer 18.709 | raw_wer 18.709 | bleu 19.85 | wps 1864.1 | wpb 4003.4 | bsz 141.8 | num_updates 25047 | best_bleu 19.98
2023-07-09 16:01:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25047 updates
2023-07-09 16:01:27 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.8508.pt
2023-07-09 16:01:29 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.8508.pt
2023-07-09 16:01:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.8508.pt (epoch 17 @ 25047 updates, score 19.85) (writing took 5.278705098986393 seconds)
2023-07-09 16:01:32 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-07-09 16:01:32 | INFO | train | epoch 017 | loss 1.505 | trans_loss 5.349 | nll_loss 2.681 | w2v_ctc_loss 0.457 | task_loss 2.096 | contrastive_loss 0.218 | total 4136.92 | n_correct 2634.96 | ppl 6.41 | accuracy 63.694 | wps 6299.9 | ups 1.52 | wpb 4136.9 | bsz 152.6 | num_updates 25047 | lr 8.93588e-05 | gnorm 0.348 | clip 0 | loss_scale 64 | train_wall 885 | gb_free 16.6 | wall 20884
2023-07-09 16:01:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 16:01:32 | INFO | fairseq.trainer | begin training epoch 18
2023-07-09 16:01:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 16:02:13 | INFO | train_inner | epoch 018:     53 / 1474 loss=1.498, trans_loss=5.336, nll_loss=2.666, w2v_ctc_loss=0.458, task_loss=2.135, contrastive_loss=0.141, total=4139.04, n_correct=2641.87, ppl=6.35, accuracy=63.828, wps=3979.5, ups=0.96, wpb=4139, bsz=151.7, num_updates=25100, lr=8.92644e-05, gnorm=0.347, clip=0, loss_scale=64, train_wall=61, gb_free=17.3, wall=20925
2023-07-09 16:03:14 | INFO | train_inner | epoch 018:    153 / 1474 loss=1.493, trans_loss=5.308, nll_loss=2.627, w2v_ctc_loss=0.44, task_loss=1.994, contrastive_loss=0.387, total=4154.85, n_correct=2672.64, ppl=6.18, accuracy=64.326, wps=6892.1, ups=1.66, wpb=4154.9, bsz=156.4, num_updates=25200, lr=8.90871e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=20986
2023-07-09 16:04:15 | INFO | train_inner | epoch 018:    253 / 1474 loss=1.49, trans_loss=5.307, nll_loss=2.628, w2v_ctc_loss=0.449, task_loss=2.029, contrastive_loss=0.123, total=4162.72, n_correct=2684.29, ppl=6.18, accuracy=64.484, wps=6807.6, ups=1.64, wpb=4162.7, bsz=156.5, num_updates=25300, lr=8.89108e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=61, gb_free=16.4, wall=21047
2023-07-09 16:05:16 | INFO | train_inner | epoch 018:    353 / 1474 loss=1.493, trans_loss=5.322, nll_loss=2.647, w2v_ctc_loss=0.451, task_loss=2.131, contrastive_loss=0.15, total=4161.22, n_correct=2665.04, ppl=6.26, accuracy=64.045, wps=6852.6, ups=1.65, wpb=4161.2, bsz=150.7, num_updates=25400, lr=8.87357e-05, gnorm=0.344, clip=0, loss_scale=64, train_wall=60, gb_free=14.7, wall=21108
2023-07-09 16:06:17 | INFO | train_inner | epoch 018:    453 / 1474 loss=1.499, trans_loss=5.334, nll_loss=2.662, w2v_ctc_loss=0.452, task_loss=2.228, contrastive_loss=0.334, total=4092.36, n_correct=2619.06, ppl=6.33, accuracy=63.999, wps=6709.6, ups=1.64, wpb=4092.4, bsz=147.7, num_updates=25500, lr=8.85615e-05, gnorm=0.349, clip=0, loss_scale=64, train_wall=61, gb_free=16.9, wall=21169
2023-07-09 16:07:18 | INFO | train_inner | epoch 018:    553 / 1474 loss=1.486, trans_loss=5.309, nll_loss=2.632, w2v_ctc_loss=0.447, task_loss=1.876, contrastive_loss=0.148, total=4206.45, n_correct=2708.03, ppl=6.2, accuracy=64.378, wps=6907.8, ups=1.64, wpb=4206.4, bsz=164.5, num_updates=25600, lr=8.83883e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=60, gb_free=17.9, wall=21230
2023-07-09 16:08:18 | INFO | train_inner | epoch 018:    653 / 1474 loss=1.502, trans_loss=5.344, nll_loss=2.676, w2v_ctc_loss=0.453, task_loss=2.162, contrastive_loss=0.286, total=4097.96, n_correct=2613.56, ppl=6.39, accuracy=63.777, wps=6819.9, ups=1.66, wpb=4098, bsz=149.3, num_updates=25700, lr=8.82162e-05, gnorm=0.352, clip=0, loss_scale=64, train_wall=60, gb_free=12.7, wall=21290
2023-07-09 16:09:18 | INFO | train_inner | epoch 018:    753 / 1474 loss=1.504, trans_loss=5.339, nll_loss=2.671, w2v_ctc_loss=0.46, task_loss=1.996, contrastive_loss=0.475, total=4208.5, n_correct=2687.56, ppl=6.37, accuracy=63.86, wps=6962.7, ups=1.65, wpb=4208.5, bsz=161.3, num_updates=25800, lr=8.80451e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=21350
2023-07-09 16:10:18 | INFO | train_inner | epoch 018:    853 / 1474 loss=1.491, trans_loss=5.331, nll_loss=2.659, w2v_ctc_loss=0.452, task_loss=2.107, contrastive_loss=0.106, total=4166.07, n_correct=2668.56, ppl=6.32, accuracy=64.055, wps=6916.5, ups=1.66, wpb=4166.1, bsz=151.2, num_updates=25900, lr=8.7875e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=21410
2023-07-09 16:11:18 | INFO | train_inner | epoch 018:    953 / 1474 loss=1.495, trans_loss=5.326, nll_loss=2.654, w2v_ctc_loss=0.451, task_loss=1.94, contrastive_loss=0.15, total=4141.27, n_correct=2650.64, ppl=6.29, accuracy=64.005, wps=6934.4, ups=1.67, wpb=4141.3, bsz=158, num_updates=26000, lr=8.77058e-05, gnorm=0.352, clip=0, loss_scale=64, train_wall=59, gb_free=16.2, wall=21470
2023-07-09 16:11:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 16:11:43 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 2.329 | trans_loss 5.555 | nll_loss 2.853 | w2v_ctc_loss 0.687 | task_loss 2.365 | contrastive_loss 0.245 | total 4003.4 | n_correct 2476.9 | ppl 7.22 | accuracy 61.87 | uer 16.983 | wer 18.929 | raw_wer 18.929 | bleu 19.52 | wps 2201.7 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 19.98
2023-07-09 16:11:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-07-09 16:11:43 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_18_26000.pt
2023-07-09 16:11:45 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_18_26000.pt
2023-07-09 16:11:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 19.52) (writing took 6.140076951007359 seconds)
2023-07-09 16:12:50 | INFO | train_inner | epoch 018:   1053 / 1474 loss=1.494, trans_loss=5.337, nll_loss=2.667, w2v_ctc_loss=0.45, task_loss=2.173, contrastive_loss=0.128, total=4134.55, n_correct=2639.26, ppl=6.35, accuracy=63.834, wps=4501.4, ups=1.09, wpb=4134.6, bsz=150.4, num_updates=26100, lr=8.75376e-05, gnorm=0.349, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=21562
2023-07-09 16:13:50 | INFO | train_inner | epoch 018:   1153 / 1474 loss=1.496, trans_loss=5.327, nll_loss=2.655, w2v_ctc_loss=0.451, task_loss=1.998, contrastive_loss=0.337, total=4157.63, n_correct=2660.96, ppl=6.3, accuracy=64.002, wps=6869.5, ups=1.65, wpb=4157.6, bsz=157, num_updates=26200, lr=8.73704e-05, gnorm=0.344, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=21622
2023-07-09 16:14:51 | INFO | train_inner | epoch 018:   1253 / 1474 loss=1.498, trans_loss=5.347, nll_loss=2.682, w2v_ctc_loss=0.454, task_loss=2.259, contrastive_loss=0.118, total=4085.66, n_correct=2601.16, ppl=6.42, accuracy=63.666, wps=6761.3, ups=1.65, wpb=4085.7, bsz=143.3, num_updates=26300, lr=8.72041e-05, gnorm=0.348, clip=0, loss_scale=64, train_wall=60, gb_free=17.6, wall=21683
2023-07-09 16:15:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-09 16:15:51 | INFO | train_inner | epoch 018:   1354 / 1474 loss=1.504, trans_loss=5.355, nll_loss=2.693, w2v_ctc_loss=0.467, task_loss=2.226, contrastive_loss=0.165, total=4068.69, n_correct=2584.64, ppl=6.47, accuracy=63.525, wps=6727.5, ups=1.65, wpb=4068.7, bsz=146.1, num_updates=26400, lr=8.70388e-05, gnorm=0.355, clip=0, loss_scale=32, train_wall=60, gb_free=17.5, wall=21743
2023-07-09 16:16:52 | INFO | train_inner | epoch 018:   1454 / 1474 loss=1.494, trans_loss=5.343, nll_loss=2.677, w2v_ctc_loss=0.456, task_loss=2.21, contrastive_loss=0.137, total=4113.2, n_correct=2622.86, ppl=6.39, accuracy=63.767, wps=6814, ups=1.66, wpb=4113.2, bsz=148.8, num_updates=26500, lr=8.68744e-05, gnorm=0.349, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=21804
2023-07-09 16:17:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 16:17:30 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 2.334 | trans_loss 5.555 | nll_loss 2.855 | w2v_ctc_loss 0.707 | task_loss 2.365 | contrastive_loss 0.252 | total 4003.4 | n_correct 2466.4 | ppl 7.23 | accuracy 61.608 | uer 17.049 | wer 19.116 | raw_wer 19.116 | bleu 19.71 | wps 1967.9 | wpb 4003.4 | bsz 141.8 | num_updates 26520 | best_bleu 19.98
2023-07-09 16:17:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26520 updates
2023-07-09 16:17:30 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.7106.pt
2023-07-09 16:17:32 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.7106.pt
2023-07-09 16:17:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.7106.pt (epoch 18 @ 26520 updates, score 19.71) (writing took 5.188179378019413 seconds)
2023-07-09 16:17:35 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-07-09 16:17:35 | INFO | train | epoch 018 | loss 1.496 | trans_loss 5.33 | nll_loss 2.659 | w2v_ctc_loss 0.452 | task_loss 2.092 | contrastive_loss 0.224 | total 4138.58 | n_correct 2647.92 | ppl 6.32 | accuracy 63.981 | wps 6328.2 | ups 1.53 | wpb 4138.6 | bsz 152.8 | num_updates 26520 | lr 8.68417e-05 | gnorm 0.348 | clip 0 | loss_scale 32 | train_wall 885 | gb_free 16.1 | wall 21847
2023-07-09 16:17:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 16:17:36 | INFO | fairseq.trainer | begin training epoch 19
2023-07-09 16:17:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 16:18:32 | INFO | train_inner | epoch 019:     80 / 1474 loss=1.49, trans_loss=5.304, nll_loss=2.625, w2v_ctc_loss=0.444, task_loss=2.099, contrastive_loss=0.239, total=4102.06, n_correct=2641.65, ppl=6.17, accuracy=64.398, wps=4087.1, ups=1, wpb=4102.1, bsz=148.5, num_updates=26600, lr=8.6711e-05, gnorm=0.351, clip=0, loss_scale=32, train_wall=59, gb_free=17.6, wall=21904
2023-07-09 16:19:33 | INFO | train_inner | epoch 019:    180 / 1474 loss=1.483, trans_loss=5.295, nll_loss=2.614, w2v_ctc_loss=0.452, task_loss=1.944, contrastive_loss=0.221, total=4227.7, n_correct=2731.45, ppl=6.12, accuracy=64.608, wps=6929, ups=1.64, wpb=4227.7, bsz=162.4, num_updates=26700, lr=8.65485e-05, gnorm=0.346, clip=0, loss_scale=32, train_wall=61, gb_free=17.2, wall=21965
2023-07-09 16:20:33 | INFO | train_inner | epoch 019:    280 / 1474 loss=1.478, trans_loss=5.29, nll_loss=2.607, w2v_ctc_loss=0.445, task_loss=2.065, contrastive_loss=0.11, total=4187.34, n_correct=2707.1, ppl=6.09, accuracy=64.65, wps=6945.5, ups=1.66, wpb=4187.3, bsz=153.2, num_updates=26800, lr=8.63868e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=22025
2023-07-09 16:21:34 | INFO | train_inner | epoch 019:    380 / 1474 loss=1.487, trans_loss=5.301, nll_loss=2.621, w2v_ctc_loss=0.443, task_loss=2.066, contrastive_loss=0.323, total=4170.52, n_correct=2687.5, ppl=6.15, accuracy=64.44, wps=6895, ups=1.65, wpb=4170.5, bsz=155.5, num_updates=26900, lr=8.62261e-05, gnorm=0.346, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=22086
2023-07-09 16:22:34 | INFO | train_inner | epoch 019:    480 / 1474 loss=1.486, trans_loss=5.313, nll_loss=2.637, w2v_ctc_loss=0.451, task_loss=2.14, contrastive_loss=0.139, total=4113.89, n_correct=2645.95, ppl=6.22, accuracy=64.317, wps=6888.8, ups=1.67, wpb=4113.9, bsz=150.8, num_updates=27000, lr=8.60663e-05, gnorm=0.348, clip=0, loss_scale=32, train_wall=59, gb_free=17.3, wall=22146
2023-07-09 16:23:33 | INFO | train_inner | epoch 019:    580 / 1474 loss=1.487, trans_loss=5.307, nll_loss=2.63, w2v_ctc_loss=0.445, task_loss=2.04, contrastive_loss=0.27, total=4128.58, n_correct=2656.24, ppl=6.19, accuracy=64.338, wps=6905.5, ups=1.67, wpb=4128.6, bsz=153.1, num_updates=27100, lr=8.59074e-05, gnorm=0.35, clip=0, loss_scale=32, train_wall=59, gb_free=16.7, wall=22205
2023-07-09 16:24:34 | INFO | train_inner | epoch 019:    680 / 1474 loss=1.481, trans_loss=5.305, nll_loss=2.628, w2v_ctc_loss=0.441, task_loss=1.903, contrastive_loss=0.124, total=4201.56, n_correct=2708.27, ppl=6.18, accuracy=64.459, wps=6986.4, ups=1.66, wpb=4201.6, bsz=160.7, num_updates=27200, lr=8.57493e-05, gnorm=0.348, clip=0, loss_scale=32, train_wall=60, gb_free=17.9, wall=22266
2023-07-09 16:25:34 | INFO | train_inner | epoch 019:    780 / 1474 loss=1.483, trans_loss=5.312, nll_loss=2.636, w2v_ctc_loss=0.452, task_loss=2.158, contrastive_loss=0.134, total=4124.03, n_correct=2650.83, ppl=6.22, accuracy=64.278, wps=6825.8, ups=1.66, wpb=4124, bsz=149.5, num_updates=27300, lr=8.55921e-05, gnorm=0.349, clip=0, loss_scale=32, train_wall=60, gb_free=17.6, wall=22326
2023-07-09 16:26:35 | INFO | train_inner | epoch 019:    880 / 1474 loss=1.488, trans_loss=5.322, nll_loss=2.649, w2v_ctc_loss=0.454, task_loss=2.085, contrastive_loss=0.128, total=4177.8, n_correct=2675.75, ppl=6.27, accuracy=64.047, wps=6890.1, ups=1.65, wpb=4177.8, bsz=154.8, num_updates=27400, lr=8.54358e-05, gnorm=0.348, clip=0, loss_scale=32, train_wall=60, gb_free=15.1, wall=22387
2023-07-09 16:27:36 | INFO | train_inner | epoch 019:    980 / 1474 loss=1.504, trans_loss=5.342, nll_loss=2.676, w2v_ctc_loss=0.453, task_loss=2.127, contrastive_loss=0.588, total=4084.26, n_correct=2605.99, ppl=6.39, accuracy=63.806, wps=6692.6, ups=1.64, wpb=4084.3, bsz=152.9, num_updates=27500, lr=8.52803e-05, gnorm=0.357, clip=0, loss_scale=32, train_wall=61, gb_free=16.4, wall=22448
2023-07-09 16:28:36 | INFO | train_inner | epoch 019:   1080 / 1474 loss=1.491, trans_loss=5.336, nll_loss=2.669, w2v_ctc_loss=0.45, task_loss=2.199, contrastive_loss=0.203, total=4042.73, n_correct=2582.55, ppl=6.36, accuracy=63.881, wps=6743.5, ups=1.67, wpb=4042.7, bsz=147, num_updates=27600, lr=8.51257e-05, gnorm=0.353, clip=0, loss_scale=32, train_wall=60, gb_free=17.4, wall=22508
2023-07-09 16:29:37 | INFO | train_inner | epoch 019:   1180 / 1474 loss=1.5, trans_loss=5.337, nll_loss=2.669, w2v_ctc_loss=0.455, task_loss=2.122, contrastive_loss=0.368, total=4140.95, n_correct=2640.74, ppl=6.36, accuracy=63.771, wps=6771.5, ups=1.64, wpb=4140.9, bsz=154, num_updates=27700, lr=8.49719e-05, gnorm=0.353, clip=0, loss_scale=32, train_wall=61, gb_free=13.1, wall=22569
2023-07-09 16:30:37 | INFO | train_inner | epoch 019:   1280 / 1474 loss=1.492, trans_loss=5.334, nll_loss=2.666, w2v_ctc_loss=0.45, task_loss=2.133, contrastive_loss=0.163, total=4135.79, n_correct=2642.65, ppl=6.35, accuracy=63.897, wps=6908, ups=1.67, wpb=4135.8, bsz=149.8, num_updates=27800, lr=8.48189e-05, gnorm=0.351, clip=0, loss_scale=32, train_wall=59, gb_free=17.9, wall=22629
2023-07-09 16:31:37 | INFO | train_inner | epoch 019:   1380 / 1474 loss=1.487, trans_loss=5.32, nll_loss=2.648, w2v_ctc_loss=0.451, task_loss=2.138, contrastive_loss=0.135, total=4138.67, n_correct=2653.72, ppl=6.27, accuracy=64.12, wps=6870.6, ups=1.66, wpb=4138.7, bsz=150.8, num_updates=27900, lr=8.46668e-05, gnorm=0.348, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=22689
2023-07-09 16:32:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 16:33:00 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 2.327 | trans_loss 5.556 | nll_loss 2.861 | w2v_ctc_loss 0.7 | task_loss 2.365 | contrastive_loss 0.251 | total 4003.4 | n_correct 2475.4 | ppl 7.26 | accuracy 61.832 | uer 17.198 | wer 19.097 | raw_wer 19.097 | bleu 19.69 | wps 1926.4 | wpb 4003.4 | bsz 141.8 | num_updates 27994 | best_bleu 19.98
2023-07-09 16:33:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27994 updates
2023-07-09 16:33:00 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.6904.pt
2023-07-09 16:33:03 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.6904.pt
2023-07-09 16:33:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.6904.pt (epoch 19 @ 27994 updates, score 19.69) (writing took 5.211687671981053 seconds)
2023-07-09 16:33:06 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-07-09 16:33:06 | INFO | train | epoch 019 | loss 1.488 | trans_loss 5.315 | nll_loss 2.641 | w2v_ctc_loss 0.449 | task_loss 2.092 | contrastive_loss 0.223 | total 4138.65 | n_correct 2657.81 | ppl 6.24 | accuracy 64.219 | wps 6557.7 | ups 1.58 | wpb 4138.6 | bsz 152.8 | num_updates 27994 | lr 8.45245e-05 | gnorm 0.349 | clip 0 | loss_scale 32 | train_wall 883 | gb_free 17.5 | wall 22778
2023-07-09 16:33:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 16:33:06 | INFO | fairseq.trainer | begin training epoch 20
2023-07-09 16:33:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 16:33:18 | INFO | train_inner | epoch 020:      6 / 1474 loss=1.488, trans_loss=5.317, nll_loss=2.644, w2v_ctc_loss=0.448, task_loss=2.124, contrastive_loss=0.303, total=4117.61, n_correct=2641.53, ppl=6.25, accuracy=64.152, wps=4072.5, ups=0.99, wpb=4117.6, bsz=151.5, num_updates=28000, lr=8.45154e-05, gnorm=0.349, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=22790
2023-07-09 16:33:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 16:33:45 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 2.324 | trans_loss 5.553 | nll_loss 2.854 | w2v_ctc_loss 0.695 | task_loss 2.365 | contrastive_loss 0.249 | total 4003.4 | n_correct 2481.7 | ppl 7.23 | accuracy 61.99 | uer 17.246 | wer 19.116 | raw_wer 19.116 | bleu 19.96 | wps 1873.4 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 19.98
2023-07-09 16:33:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-07-09 16:33:45 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_20_28000.pt
2023-07-09 16:33:47 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_20_28000.pt
2023-07-09 16:33:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 19.96) (writing took 6.301226048992248 seconds)
2023-07-09 16:34:53 | INFO | train_inner | epoch 020:    106 / 1474 loss=1.472, trans_loss=5.274, nll_loss=2.588, w2v_ctc_loss=0.44, task_loss=2.018, contrastive_loss=0.147, total=4192.82, n_correct=2719.16, ppl=6.01, accuracy=64.853, wps=4400.4, ups=1.05, wpb=4192.8, bsz=156.4, num_updates=28100, lr=8.43649e-05, gnorm=0.343, clip=0, loss_scale=32, train_wall=61, gb_free=16.5, wall=22885
2023-07-09 16:35:54 | INFO | train_inner | epoch 020:    206 / 1474 loss=1.475, trans_loss=5.282, nll_loss=2.598, w2v_ctc_loss=0.44, task_loss=2.166, contrastive_loss=0.254, total=4155.9, n_correct=2690.75, ppl=6.05, accuracy=64.745, wps=6834.2, ups=1.64, wpb=4155.9, bsz=151.1, num_updates=28200, lr=8.42152e-05, gnorm=0.352, clip=0, loss_scale=32, train_wall=60, gb_free=12.2, wall=22946
2023-07-09 16:36:55 | INFO | train_inner | epoch 020:    306 / 1474 loss=1.473, trans_loss=5.275, nll_loss=2.59, w2v_ctc_loss=0.439, task_loss=1.874, contrastive_loss=0.131, total=4192.69, n_correct=2720.37, ppl=6.02, accuracy=64.884, wps=6906.3, ups=1.65, wpb=4192.7, bsz=163.8, num_updates=28300, lr=8.40663e-05, gnorm=0.348, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=23007
2023-07-09 16:37:55 | INFO | train_inner | epoch 020:    406 / 1474 loss=1.47, trans_loss=5.281, nll_loss=2.597, w2v_ctc_loss=0.436, task_loss=2.132, contrastive_loss=0.127, total=4116.96, n_correct=2668.2, ppl=6.05, accuracy=64.81, wps=6852, ups=1.66, wpb=4117, bsz=148.4, num_updates=28400, lr=8.39181e-05, gnorm=0.348, clip=0, loss_scale=32, train_wall=60, gb_free=13, wall=23067
2023-07-09 16:38:55 | INFO | train_inner | epoch 020:    506 / 1474 loss=1.486, trans_loss=5.306, nll_loss=2.63, w2v_ctc_loss=0.443, task_loss=2.162, contrastive_loss=0.308, total=4100.73, n_correct=2642.31, ppl=6.19, accuracy=64.435, wps=6785.8, ups=1.65, wpb=4100.7, bsz=149.2, num_updates=28500, lr=8.37708e-05, gnorm=0.355, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=23127
2023-07-09 16:39:55 | INFO | train_inner | epoch 020:    606 / 1474 loss=1.482, trans_loss=5.301, nll_loss=2.622, w2v_ctc_loss=0.442, task_loss=2.174, contrastive_loss=0.305, total=4101.99, n_correct=2643.46, ppl=6.16, accuracy=64.443, wps=6842.2, ups=1.67, wpb=4102, bsz=149.2, num_updates=28600, lr=8.36242e-05, gnorm=0.35, clip=0, loss_scale=64, train_wall=60, gb_free=13.8, wall=23187
2023-07-09 16:40:55 | INFO | train_inner | epoch 020:    706 / 1474 loss=1.483, trans_loss=5.305, nll_loss=2.628, w2v_ctc_loss=0.448, task_loss=2.119, contrastive_loss=0.112, total=4124.25, n_correct=2654.58, ppl=6.18, accuracy=64.365, wps=6862.1, ups=1.66, wpb=4124.2, bsz=148.6, num_updates=28700, lr=8.34784e-05, gnorm=0.349, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=23247
2023-07-09 16:41:55 | INFO | train_inner | epoch 020:    806 / 1474 loss=1.474, trans_loss=5.293, nll_loss=2.614, w2v_ctc_loss=0.443, task_loss=2.047, contrastive_loss=0.125, total=4153.23, n_correct=2683.84, ppl=6.12, accuracy=64.621, wps=6951.6, ups=1.67, wpb=4153.2, bsz=154.3, num_updates=28800, lr=8.33333e-05, gnorm=0.349, clip=0, loss_scale=64, train_wall=59, gb_free=17.8, wall=23307
2023-07-09 16:42:57 | INFO | train_inner | epoch 020:    906 / 1474 loss=1.5, trans_loss=5.318, nll_loss=2.646, w2v_ctc_loss=0.445, task_loss=2.011, contrastive_loss=0.706, total=4153.72, n_correct=2665.5, ppl=6.26, accuracy=64.171, wps=6737.4, ups=1.62, wpb=4153.7, bsz=160.3, num_updates=28900, lr=8.3189e-05, gnorm=0.354, clip=0, loss_scale=64, train_wall=61, gb_free=16.3, wall=23369
2023-07-09 16:43:57 | INFO | train_inner | epoch 020:   1006 / 1474 loss=1.477, trans_loss=5.299, nll_loss=2.622, w2v_ctc_loss=0.44, task_loss=2.108, contrastive_loss=0.134, total=4156.05, n_correct=2679.83, ppl=6.16, accuracy=64.48, wps=6847.6, ups=1.65, wpb=4156.1, bsz=152.6, num_updates=29000, lr=8.30455e-05, gnorm=0.349, clip=0, loss_scale=64, train_wall=60, gb_free=15.2, wall=23429
2023-07-09 16:44:58 | INFO | train_inner | epoch 020:   1106 / 1474 loss=1.487, trans_loss=5.306, nll_loss=2.631, w2v_ctc_loss=0.443, task_loss=1.97, contrastive_loss=0.407, total=4181.53, n_correct=2692.7, ppl=6.19, accuracy=64.395, wps=6942.6, ups=1.66, wpb=4181.5, bsz=160.1, num_updates=29100, lr=8.29027e-05, gnorm=0.353, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=23490
2023-07-09 16:45:58 | INFO | train_inner | epoch 020:   1206 / 1474 loss=1.479, trans_loss=5.304, nll_loss=2.628, w2v_ctc_loss=0.452, task_loss=2.309, contrastive_loss=0.104, total=4029.26, n_correct=2593.42, ppl=6.18, accuracy=64.365, wps=6692.5, ups=1.66, wpb=4029.3, bsz=141.2, num_updates=29200, lr=8.27606e-05, gnorm=0.354, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=23550
2023-07-09 16:46:59 | INFO | train_inner | epoch 020:   1306 / 1474 loss=1.477, trans_loss=5.311, nll_loss=2.639, w2v_ctc_loss=0.445, task_loss=2.181, contrastive_loss=0.13, total=4127.21, n_correct=2651.85, ppl=6.23, accuracy=64.253, wps=6765.1, ups=1.64, wpb=4127.2, bsz=150, num_updates=29300, lr=8.26192e-05, gnorm=0.354, clip=0, loss_scale=64, train_wall=61, gb_free=15, wall=23611
2023-07-09 16:47:59 | INFO | train_inner | epoch 020:   1406 / 1474 loss=1.481, trans_loss=5.318, nll_loss=2.646, w2v_ctc_loss=0.449, task_loss=2.253, contrastive_loss=0.118, total=4110.89, n_correct=2634.44, ppl=6.26, accuracy=64.084, wps=6804, ups=1.66, wpb=4110.9, bsz=145.8, num_updates=29400, lr=8.24786e-05, gnorm=0.354, clip=0, loss_scale=64, train_wall=60, gb_free=13.6, wall=23671
2023-07-09 16:48:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 16:49:06 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 2.304 | trans_loss 5.542 | nll_loss 2.842 | w2v_ctc_loss 0.657 | task_loss 2.365 | contrastive_loss 0.239 | total 4003.4 | n_correct 2478.4 | ppl 7.17 | accuracy 61.907 | uer 16.861 | wer 18.642 | raw_wer 18.642 | bleu 19.84 | wps 2084.5 | wpb 4003.4 | bsz 141.8 | num_updates 29468 | best_bleu 19.98
2023-07-09 16:49:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29468 updates
2023-07-09 16:49:06 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.8401.pt
2023-07-09 16:49:08 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.8401.pt
2023-07-09 16:49:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.8401.pt (epoch 20 @ 29468 updates, score 19.84) (writing took 5.121460082998965 seconds)
2023-07-09 16:49:11 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-07-09 16:49:11 | INFO | train | epoch 020 | loss 1.48 | trans_loss 5.299 | nll_loss 2.621 | w2v_ctc_loss 0.443 | task_loss 2.092 | contrastive_loss 0.224 | total 4138.65 | n_correct 2668.95 | ppl 6.15 | accuracy 64.488 | wps 6319.4 | ups 1.53 | wpb 4138.6 | bsz 152.8 | num_updates 29468 | lr 8.23834e-05 | gnorm 0.351 | clip 0 | loss_scale 64 | train_wall 886 | gb_free 16.8 | wall 23743
2023-07-09 16:49:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 16:49:11 | INFO | fairseq.trainer | begin training epoch 21
2023-07-09 16:49:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 16:49:39 | INFO | train_inner | epoch 021:     32 / 1474 loss=1.481, trans_loss=5.304, nll_loss=2.628, w2v_ctc_loss=0.444, task_loss=1.968, contrastive_loss=0.358, total=4166.35, n_correct=2686.91, ppl=6.18, accuracy=64.491, wps=4178.1, ups=1, wpb=4166.4, bsz=159.7, num_updates=29500, lr=8.23387e-05, gnorm=0.352, clip=0, loss_scale=64, train_wall=60, gb_free=11.6, wall=23771
2023-07-09 16:50:39 | INFO | train_inner | epoch 021:    132 / 1474 loss=1.467, trans_loss=5.259, nll_loss=2.569, w2v_ctc_loss=0.431, task_loss=1.968, contrastive_loss=0.343, total=4181.45, n_correct=2719.02, ppl=5.94, accuracy=65.026, wps=6925, ups=1.66, wpb=4181.4, bsz=158.8, num_updates=29600, lr=8.21995e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=60, gb_free=15.3, wall=23831
2023-07-09 16:51:40 | INFO | train_inner | epoch 021:    232 / 1474 loss=1.467, trans_loss=5.264, nll_loss=2.577, w2v_ctc_loss=0.431, task_loss=1.97, contrastive_loss=0.252, total=4167.12, n_correct=2710.28, ppl=5.97, accuracy=65.04, wps=6922.4, ups=1.66, wpb=4167.1, bsz=157.6, num_updates=29700, lr=8.2061e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=60, gb_free=12.2, wall=23892
2023-07-09 16:52:41 | INFO | train_inner | epoch 021:    332 / 1474 loss=1.471, trans_loss=5.274, nll_loss=2.589, w2v_ctc_loss=0.441, task_loss=2.141, contrastive_loss=0.253, total=4130.24, n_correct=2676.18, ppl=6.02, accuracy=64.795, wps=6737.9, ups=1.63, wpb=4130.2, bsz=151.8, num_updates=29800, lr=8.19232e-05, gnorm=0.349, clip=0, loss_scale=64, train_wall=61, gb_free=17.4, wall=23953
2023-07-09 16:53:41 | INFO | train_inner | epoch 021:    432 / 1474 loss=1.464, trans_loss=5.266, nll_loss=2.578, w2v_ctc_loss=0.433, task_loss=2.009, contrastive_loss=0.117, total=4186.28, n_correct=2723.02, ppl=5.97, accuracy=65.046, wps=6916.3, ups=1.65, wpb=4186.3, bsz=155.1, num_updates=29900, lr=8.17861e-05, gnorm=0.347, clip=0, loss_scale=64, train_wall=60, gb_free=17.4, wall=24013
2023-07-09 16:54:41 | INFO | train_inner | epoch 021:    532 / 1474 loss=1.466, trans_loss=5.271, nll_loss=2.585, w2v_ctc_loss=0.44, task_loss=2.133, contrastive_loss=0.109, total=4096.33, n_correct=2659.87, ppl=6, accuracy=64.933, wps=6824.4, ups=1.67, wpb=4096.3, bsz=149, num_updates=30000, lr=8.16497e-05, gnorm=0.349, clip=0, loss_scale=64, train_wall=60, gb_free=17.3, wall=24073
2023-07-09 16:54:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 16:55:07 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 2.317 | trans_loss 5.555 | nll_loss 2.857 | w2v_ctc_loss 0.685 | task_loss 2.365 | contrastive_loss 0.254 | total 4003.4 | n_correct 2483.5 | ppl 7.25 | accuracy 62.035 | uer 16.757 | wer 18.568 | raw_wer 18.568 | bleu 20.08 | wps 2135.6 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.08
2023-07-09 16:55:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-07-09 16:55:07 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_21_30000.pt
2023-07-09 16:55:09 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_21_30000.pt
2023-07-09 16:55:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 20.08) (writing took 8.93117866499233 seconds)
tensor(0.0221, device='cuda:0')
tensor(0.0008, device='cuda:0')
2023-07-09 16:56:17 | INFO | train_inner | epoch 021:    632 / 1474 loss=1.475, trans_loss=5.279, nll_loss=2.597, w2v_ctc_loss=0.435, task_loss=2.071, contrastive_loss=0.448, total=4215.02, n_correct=2732.77, ppl=6.05, accuracy=64.834, wps=4407.7, ups=1.05, wpb=4215, bsz=157.3, num_updates=30100, lr=8.15139e-05, gnorm=0.347, clip=0, loss_scale=64, train_wall=61, gb_free=16.7, wall=24169
2023-07-09 16:57:18 | INFO | train_inner | epoch 021:    732 / 1474 loss=1.469, trans_loss=5.284, nll_loss=2.603, w2v_ctc_loss=0.437, task_loss=2.098, contrastive_loss=0.174, total=4147.25, n_correct=2686.16, ppl=6.08, accuracy=64.77, wps=6869, ups=1.66, wpb=4147.2, bsz=154.3, num_updates=30200, lr=8.13788e-05, gnorm=0.354, clip=0, loss_scale=64, train_wall=60, gb_free=17.9, wall=24230
2023-07-09 16:58:18 | INFO | train_inner | epoch 021:    832 / 1474 loss=1.474, trans_loss=5.297, nll_loss=2.62, w2v_ctc_loss=0.44, task_loss=2.222, contrastive_loss=0.202, total=4071.46, n_correct=2625.67, ppl=6.15, accuracy=64.49, wps=6723.1, ups=1.65, wpb=4071.5, bsz=147.1, num_updates=30300, lr=8.12444e-05, gnorm=0.355, clip=0, loss_scale=64, train_wall=60, gb_free=17.4, wall=24290
2023-07-09 16:59:18 | INFO | train_inner | epoch 021:    932 / 1474 loss=1.472, trans_loss=5.281, nll_loss=2.6, w2v_ctc_loss=0.44, task_loss=2.079, contrastive_loss=0.148, total=4098.4, n_correct=2651.59, ppl=6.06, accuracy=64.698, wps=6798.5, ups=1.66, wpb=4098.4, bsz=150.7, num_updates=30400, lr=8.11107e-05, gnorm=0.353, clip=0, loss_scale=64, train_wall=60, gb_free=16, wall=24350
2023-07-09 17:00:18 | INFO | train_inner | epoch 021:   1032 / 1474 loss=1.481, trans_loss=5.308, nll_loss=2.634, w2v_ctc_loss=0.447, task_loss=2.134, contrastive_loss=0.143, total=4099.06, n_correct=2633.7, ppl=6.21, accuracy=64.251, wps=6826.5, ups=1.67, wpb=4099.1, bsz=148.8, num_updates=30500, lr=8.09776e-05, gnorm=0.356, clip=0, loss_scale=128, train_wall=60, gb_free=16.6, wall=24410
2023-07-09 17:01:19 | INFO | train_inner | epoch 021:   1132 / 1474 loss=1.473, trans_loss=5.294, nll_loss=2.615, w2v_ctc_loss=0.442, task_loss=2.237, contrastive_loss=0.15, total=4127.16, n_correct=2664.37, ppl=6.13, accuracy=64.557, wps=6853.1, ups=1.66, wpb=4127.2, bsz=147.8, num_updates=30600, lr=8.08452e-05, gnorm=0.357, clip=0, loss_scale=128, train_wall=60, gb_free=15.8, wall=24471
2023-07-09 17:01:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-09 17:02:19 | INFO | train_inner | epoch 021:   1233 / 1474 loss=1.473, trans_loss=5.287, nll_loss=2.608, w2v_ctc_loss=0.439, task_loss=2.04, contrastive_loss=0.204, total=4136.87, n_correct=2671.81, ppl=6.1, accuracy=64.585, wps=6837, ups=1.65, wpb=4136.9, bsz=152.6, num_updates=30700, lr=8.07134e-05, gnorm=0.349, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=24531
2023-07-09 17:03:19 | INFO | train_inner | epoch 021:   1333 / 1474 loss=1.469, trans_loss=5.29, nll_loss=2.612, w2v_ctc_loss=0.436, task_loss=2.021, contrastive_loss=0.174, total=4141.76, n_correct=2677.72, ppl=6.11, accuracy=64.652, wps=6885.6, ups=1.66, wpb=4141.8, bsz=155.8, num_updates=30800, lr=8.05823e-05, gnorm=0.351, clip=0, loss_scale=64, train_wall=60, gb_free=17.5, wall=24591
2023-07-09 17:04:20 | INFO | train_inner | epoch 021:   1433 / 1474 loss=1.483, trans_loss=5.311, nll_loss=2.639, w2v_ctc_loss=0.45, task_loss=2.21, contrastive_loss=0.271, total=4127.02, n_correct=2651.03, ppl=6.23, accuracy=64.236, wps=6760.8, ups=1.64, wpb=4127, bsz=151.1, num_updates=30900, lr=8.04518e-05, gnorm=0.353, clip=0, loss_scale=64, train_wall=61, gb_free=16.7, wall=24652
2023-07-09 17:04:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0221, device='cuda:5')
tensor(0.0008, device='cuda:5')
tensor(0.0221, device='cuda:6')
tensor(0.0008, device='cuda:6')
tensor(0.0221, device='cuda:4')
tensor(0.0008, device='cuda:4')
tensor(0.0221, device='cuda:7')
tensor(0.0008, device='cuda:7')
tensor(0.0221, device='cuda:2')
tensor(0.0008, device='cuda:2')
tensor(0.0221, device='cuda:1')
tensor(0.0008, device='cuda:1')
tensor(0.0221, device='cuda:3')
tensor(0.0008, device='cuda:3')
2023-07-09 17:05:12 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 2.308 | trans_loss 5.549 | nll_loss 2.851 | w2v_ctc_loss 0.673 | task_loss 2.365 | contrastive_loss 0.251 | total 4003.4 | n_correct 2486 | ppl 7.21 | accuracy 62.097 | uer 16.917 | wer 18.84 | raw_wer 18.84 | bleu 20.2 | wps 1898.7 | wpb 4003.4 | bsz 141.8 | num_updates 30941 | best_bleu 20.2
2023-07-09 17:05:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30941 updates
2023-07-09 17:05:12 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 17:05:16 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 17:05:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt (epoch 21 @ 30941 updates, score 20.2) (writing took 8.30244833600591 seconds)
2023-07-09 17:05:21 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-07-09 17:05:21 | INFO | train | epoch 021 | loss 1.472 | trans_loss 5.283 | nll_loss 2.602 | w2v_ctc_loss 0.438 | task_loss 2.095 | contrastive_loss 0.222 | total 4137.43 | n_correct 2677.38 | ppl 6.07 | accuracy 64.711 | wps 6285 | ups 1.52 | wpb 4137.4 | bsz 152.6 | num_updates 30941 | lr 8.03985e-05 | gnorm 0.351 | clip 0 | loss_scale 64 | train_wall 885 | gb_free 15.6 | wall 24713
2023-07-09 17:05:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 17:05:21 | INFO | fairseq.trainer | begin training epoch 22
2023-07-09 17:05:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 17:06:05 | INFO | train_inner | epoch 022:     59 / 1474 loss=1.464, trans_loss=5.267, nll_loss=2.582, w2v_ctc_loss=0.439, task_loss=2.101, contrastive_loss=0.114, total=4140.16, n_correct=2692.2, ppl=5.99, accuracy=65.026, wps=3957.9, ups=0.96, wpb=4140.2, bsz=150.1, num_updates=31000, lr=8.03219e-05, gnorm=0.351, clip=0, loss_scale=64, train_wall=60, gb_free=17.8, wall=24757
2023-07-09 17:07:05 | INFO | train_inner | epoch 022:    159 / 1474 loss=1.464, trans_loss=5.251, nll_loss=2.561, w2v_ctc_loss=0.435, task_loss=2.116, contrastive_loss=0.275, total=4115.86, n_correct=2686.93, ppl=5.9, accuracy=65.282, wps=6809.8, ups=1.65, wpb=4115.9, bsz=154.7, num_updates=31100, lr=8.01927e-05, gnorm=0.352, clip=0, loss_scale=64, train_wall=60, gb_free=17.5, wall=24817
2023-07-09 17:08:06 | INFO | train_inner | epoch 022:    259 / 1474 loss=1.452, trans_loss=5.242, nll_loss=2.549, w2v_ctc_loss=0.424, task_loss=1.895, contrastive_loss=0.137, total=4247.73, n_correct=2776.48, ppl=5.85, accuracy=65.364, wps=6997.8, ups=1.65, wpb=4247.7, bsz=161.6, num_updates=31200, lr=8.00641e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=60, gb_free=14.2, wall=24878
2023-07-09 17:09:08 | INFO | train_inner | epoch 022:    359 / 1474 loss=1.47, trans_loss=5.269, nll_loss=2.584, w2v_ctc_loss=0.432, task_loss=2.068, contrastive_loss=0.48, total=4212.22, n_correct=2737.33, ppl=6, accuracy=64.985, wps=6808.5, ups=1.62, wpb=4212.2, bsz=159, num_updates=31300, lr=7.99361e-05, gnorm=0.352, clip=0, loss_scale=64, train_wall=61, gb_free=15.8, wall=24940
2023-07-09 17:10:09 | INFO | train_inner | epoch 022:    459 / 1474 loss=1.472, trans_loss=5.28, nll_loss=2.597, w2v_ctc_loss=0.438, task_loss=2.199, contrastive_loss=0.234, total=4131.12, n_correct=2677.77, ppl=6.05, accuracy=64.819, wps=6790.9, ups=1.64, wpb=4131.1, bsz=148.6, num_updates=31400, lr=7.98087e-05, gnorm=0.352, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=25001
2023-07-09 17:11:10 | INFO | train_inner | epoch 022:    559 / 1474 loss=1.461, trans_loss=5.264, nll_loss=2.577, w2v_ctc_loss=0.436, task_loss=2.122, contrastive_loss=0.134, total=4153.54, n_correct=2702.51, ppl=5.97, accuracy=65.065, wps=6790.6, ups=1.63, wpb=4153.5, bsz=153.6, num_updates=31500, lr=7.96819e-05, gnorm=0.351, clip=0, loss_scale=64, train_wall=61, gb_free=15.1, wall=25062
2023-07-09 17:12:10 | INFO | train_inner | epoch 022:    659 / 1474 loss=1.46, trans_loss=5.254, nll_loss=2.565, w2v_ctc_loss=0.423, task_loss=1.97, contrastive_loss=0.301, total=4143.91, n_correct=2700.5, ppl=5.92, accuracy=65.168, wps=6910.6, ups=1.67, wpb=4143.9, bsz=156.6, num_updates=31600, lr=7.95557e-05, gnorm=0.35, clip=0, loss_scale=64, train_wall=60, gb_free=16, wall=25122
2023-07-09 17:13:10 | INFO | train_inner | epoch 022:    759 / 1474 loss=1.463, trans_loss=5.267, nll_loss=2.581, w2v_ctc_loss=0.437, task_loss=2.148, contrastive_loss=0.139, total=4168.91, n_correct=2707.84, ppl=5.98, accuracy=64.953, wps=6904.7, ups=1.66, wpb=4168.9, bsz=151.8, num_updates=31700, lr=7.94301e-05, gnorm=0.349, clip=0, loss_scale=64, train_wall=60, gb_free=17.6, wall=25182
2023-07-09 17:13:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-09 17:14:12 | INFO | train_inner | epoch 022:    860 / 1474 loss=1.462, trans_loss=5.279, nll_loss=2.597, w2v_ctc_loss=0.437, task_loss=2.278, contrastive_loss=0.113, total=4074.76, n_correct=2638.25, ppl=6.05, accuracy=64.746, wps=6615.4, ups=1.62, wpb=4074.8, bsz=144.4, num_updates=31800, lr=7.93052e-05, gnorm=0.359, clip=0, loss_scale=32, train_wall=61, gb_free=17.6, wall=25244
2023-07-09 17:15:13 | INFO | train_inner | epoch 022:    960 / 1474 loss=1.462, trans_loss=5.269, nll_loss=2.585, w2v_ctc_loss=0.432, task_loss=2.101, contrastive_loss=0.117, total=4136.34, n_correct=2687.74, ppl=6, accuracy=64.979, wps=6821, ups=1.65, wpb=4136.3, bsz=151.8, num_updates=31900, lr=7.91808e-05, gnorm=0.354, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=25305
2023-07-09 17:16:12 | INFO | train_inner | epoch 022:   1060 / 1474 loss=1.468, trans_loss=5.266, nll_loss=2.581, w2v_ctc_loss=0.43, task_loss=1.985, contrastive_loss=0.459, total=4157.21, n_correct=2705.93, ppl=5.99, accuracy=65.09, wps=6949.1, ups=1.67, wpb=4157.2, bsz=157.7, num_updates=32000, lr=7.90569e-05, gnorm=0.352, clip=0, loss_scale=32, train_wall=59, gb_free=12.5, wall=25364
2023-07-09 17:16:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 17:16:38 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 2.307 | trans_loss 5.543 | nll_loss 2.842 | w2v_ctc_loss 0.684 | task_loss 2.365 | contrastive_loss 0.251 | total 4003.4 | n_correct 2480 | ppl 7.17 | accuracy 61.947 | uer 16.755 | wer 18.452 | raw_wer 18.452 | bleu 20.03 | wps 2120.2 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.2
2023-07-09 17:16:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-07-09 17:16:38 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_22_32000.pt
2023-07-09 17:16:40 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_22_32000.pt
2023-07-09 17:16:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 20.03) (writing took 6.101830555009656 seconds)
2023-07-09 17:17:44 | INFO | train_inner | epoch 022:   1160 / 1474 loss=1.475, trans_loss=5.297, nll_loss=2.621, w2v_ctc_loss=0.439, task_loss=2.169, contrastive_loss=0.217, total=4092.91, n_correct=2638.35, ppl=6.15, accuracy=64.461, wps=4469.3, ups=1.09, wpb=4092.9, bsz=147.2, num_updates=32100, lr=7.89337e-05, gnorm=0.356, clip=0, loss_scale=32, train_wall=59, gb_free=16.2, wall=25456
2023-07-09 17:18:45 | INFO | train_inner | epoch 022:   1260 / 1474 loss=1.467, trans_loss=5.283, nll_loss=2.603, w2v_ctc_loss=0.436, task_loss=1.931, contrastive_loss=0.208, total=4182.65, n_correct=2706.72, ppl=6.08, accuracy=64.713, wps=6899.3, ups=1.65, wpb=4182.6, bsz=161.8, num_updates=32200, lr=7.8811e-05, gnorm=0.346, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=25517
2023-07-09 17:19:45 | INFO | train_inner | epoch 022:   1360 / 1474 loss=1.464, trans_loss=5.271, nll_loss=2.588, w2v_ctc_loss=0.429, task_loss=2.072, contrastive_loss=0.254, total=4071.58, n_correct=2642.2, ppl=6.01, accuracy=64.894, wps=6771.2, ups=1.66, wpb=4071.6, bsz=150.3, num_updates=32300, lr=7.86889e-05, gnorm=0.352, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=25577
2023-07-09 17:20:45 | INFO | train_inner | epoch 022:   1460 / 1474 loss=1.47, trans_loss=5.291, nll_loss=2.613, w2v_ctc_loss=0.441, task_loss=2.228, contrastive_loss=0.146, total=4077.83, n_correct=2632.45, ppl=6.12, accuracy=64.555, wps=6783.2, ups=1.66, wpb=4077.8, bsz=144, num_updates=32400, lr=7.85674e-05, gnorm=0.355, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=25637
2023-07-09 17:20:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 17:21:21 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 2.298 | trans_loss 5.543 | nll_loss 2.842 | w2v_ctc_loss 0.658 | task_loss 2.365 | contrastive_loss 0.25 | total 4003.4 | n_correct 2486.6 | ppl 7.17 | accuracy 62.112 | uer 16.946 | wer 18.821 | raw_wer 18.821 | bleu 19.77 | wps 1838 | wpb 4003.4 | bsz 141.8 | num_updates 32414 | best_bleu 20.2
2023-07-09 17:21:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32414 updates
2023-07-09 17:21:21 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.7700.pt
2023-07-09 17:21:23 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.7700.pt
2023-07-09 17:21:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.7700.pt (epoch 22 @ 32414 updates, score 19.77) (writing took 5.319625069008907 seconds)
2023-07-09 17:21:27 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-07-09 17:21:27 | INFO | train | epoch 022 | loss 1.465 | trans_loss 5.269 | nll_loss 2.585 | w2v_ctc_loss 0.434 | task_loss 2.091 | contrastive_loss 0.226 | total 4138.9 | n_correct 2688.05 | ppl 6 | accuracy 64.946 | wps 6312.6 | ups 1.53 | wpb 4138.9 | bsz 152.9 | num_updates 32414 | lr 7.85505e-05 | gnorm 0.352 | clip 0 | loss_scale 32 | train_wall 886 | gb_free 12.2 | wall 25679
2023-07-09 17:21:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 17:21:27 | INFO | fairseq.trainer | begin training epoch 23
2023-07-09 17:21:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 17:22:28 | INFO | train_inner | epoch 023:     86 / 1474 loss=1.454, trans_loss=5.244, nll_loss=2.551, w2v_ctc_loss=0.433, task_loss=2.162, contrastive_loss=0.131, total=4089.8, n_correct=2672.77, ppl=5.86, accuracy=65.352, wps=3980.5, ups=0.97, wpb=4089.8, bsz=149.7, num_updates=32500, lr=7.84465e-05, gnorm=0.353, clip=0, loss_scale=32, train_wall=61, gb_free=16.8, wall=25740
2023-07-09 17:23:28 | INFO | train_inner | epoch 023:    186 / 1474 loss=1.454, trans_loss=5.241, nll_loss=2.548, w2v_ctc_loss=0.43, task_loss=2.208, contrastive_loss=0.124, total=4117.76, n_correct=2692.04, ppl=5.85, accuracy=65.376, wps=6793.5, ups=1.65, wpb=4117.8, bsz=148, num_updates=32600, lr=7.8326e-05, gnorm=0.36, clip=0, loss_scale=32, train_wall=60, gb_free=15.7, wall=25800
2023-07-09 17:24:29 | INFO | train_inner | epoch 023:    286 / 1474 loss=1.458, trans_loss=5.249, nll_loss=2.559, w2v_ctc_loss=0.425, task_loss=2.122, contrastive_loss=0.282, total=4144.73, n_correct=2705.37, ppl=5.89, accuracy=65.273, wps=6770.2, ups=1.63, wpb=4144.7, bsz=152, num_updates=32700, lr=7.82062e-05, gnorm=0.35, clip=0, loss_scale=32, train_wall=61, gb_free=17.6, wall=25861
2023-07-09 17:25:30 | INFO | train_inner | epoch 023:    386 / 1474 loss=1.452, trans_loss=5.245, nll_loss=2.554, w2v_ctc_loss=0.426, task_loss=2.149, contrastive_loss=0.112, total=4126.79, n_correct=2695.95, ppl=5.87, accuracy=65.328, wps=6849.1, ups=1.66, wpb=4126.8, bsz=148.2, num_updates=32800, lr=7.80869e-05, gnorm=0.349, clip=0, loss_scale=32, train_wall=60, gb_free=17.3, wall=25922
2023-07-09 17:26:30 | INFO | train_inner | epoch 023:    486 / 1474 loss=1.457, trans_loss=5.25, nll_loss=2.559, w2v_ctc_loss=0.427, task_loss=2.043, contrastive_loss=0.225, total=4150.15, n_correct=2706.67, ppl=5.89, accuracy=65.219, wps=6915, ups=1.67, wpb=4150.1, bsz=156, num_updates=32900, lr=7.79681e-05, gnorm=0.351, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=25982
2023-07-09 17:27:30 | INFO | train_inner | epoch 023:    586 / 1474 loss=1.449, trans_loss=5.236, nll_loss=2.543, w2v_ctc_loss=0.424, task_loss=1.968, contrastive_loss=0.124, total=4174.6, n_correct=2734.58, ppl=5.83, accuracy=65.505, wps=6925.9, ups=1.66, wpb=4174.6, bsz=158.2, num_updates=33000, lr=7.78499e-05, gnorm=0.349, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=26042
2023-07-09 17:28:31 | INFO | train_inner | epoch 023:    686 / 1474 loss=1.455, trans_loss=5.247, nll_loss=2.556, w2v_ctc_loss=0.429, task_loss=2.109, contrastive_loss=0.198, total=4136.6, n_correct=2699.91, ppl=5.88, accuracy=65.269, wps=6836.2, ups=1.65, wpb=4136.6, bsz=150.6, num_updates=33100, lr=7.77322e-05, gnorm=0.351, clip=0, loss_scale=32, train_wall=60, gb_free=17.8, wall=26103
2023-07-09 17:29:30 | INFO | train_inner | epoch 023:    786 / 1474 loss=1.462, trans_loss=5.265, nll_loss=2.58, w2v_ctc_loss=0.436, task_loss=2.104, contrastive_loss=0.162, total=4147.22, n_correct=2699.1, ppl=5.98, accuracy=65.082, wps=6930.8, ups=1.67, wpb=4147.2, bsz=152.6, num_updates=33200, lr=7.76151e-05, gnorm=0.356, clip=0, loss_scale=32, train_wall=59, gb_free=17.4, wall=26162
2023-07-09 17:30:30 | INFO | train_inner | epoch 023:    886 / 1474 loss=1.459, trans_loss=5.25, nll_loss=2.561, w2v_ctc_loss=0.428, task_loss=1.894, contrastive_loss=0.316, total=4193.16, n_correct=2738.63, ppl=5.9, accuracy=65.312, wps=7010.3, ups=1.67, wpb=4193.2, bsz=163.6, num_updates=33300, lr=7.74984e-05, gnorm=0.352, clip=0, loss_scale=32, train_wall=59, gb_free=16.2, wall=26222
2023-07-09 17:31:31 | INFO | train_inner | epoch 023:    986 / 1474 loss=1.472, trans_loss=5.266, nll_loss=2.582, w2v_ctc_loss=0.432, task_loss=2.086, contrastive_loss=0.628, total=4164.33, n_correct=2702.75, ppl=5.99, accuracy=64.902, wps=6879.4, ups=1.65, wpb=4164.3, bsz=155.1, num_updates=33400, lr=7.73823e-05, gnorm=0.357, clip=0, loss_scale=32, train_wall=60, gb_free=17.8, wall=26283
2023-07-09 17:32:31 | INFO | train_inner | epoch 023:   1086 / 1474 loss=1.461, trans_loss=5.266, nll_loss=2.582, w2v_ctc_loss=0.439, task_loss=2.248, contrastive_loss=0.14, total=4088.37, n_correct=2655.01, ppl=5.99, accuracy=64.941, wps=6745.7, ups=1.65, wpb=4088.4, bsz=144.8, num_updates=33500, lr=7.72667e-05, gnorm=0.353, clip=0, loss_scale=32, train_wall=60, gb_free=15.8, wall=26343
2023-07-09 17:33:32 | INFO | train_inner | epoch 023:   1186 / 1474 loss=1.454, trans_loss=5.259, nll_loss=2.572, w2v_ctc_loss=0.43, task_loss=2.082, contrastive_loss=0.126, total=4162.3, n_correct=2709.37, ppl=5.95, accuracy=65.093, wps=6850.1, ups=1.65, wpb=4162.3, bsz=154.5, num_updates=33600, lr=7.71517e-05, gnorm=0.35, clip=0, loss_scale=32, train_wall=60, gb_free=15.8, wall=26404
2023-07-09 17:34:33 | INFO | train_inner | epoch 023:   1286 / 1474 loss=1.457, trans_loss=5.259, nll_loss=2.574, w2v_ctc_loss=0.428, task_loss=2.038, contrastive_loss=0.146, total=4131.74, n_correct=2691.95, ppl=5.95, accuracy=65.153, wps=6807.8, ups=1.65, wpb=4131.7, bsz=154.4, num_updates=33700, lr=7.70371e-05, gnorm=0.349, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=26465
2023-07-09 17:35:33 | INFO | train_inner | epoch 023:   1386 / 1474 loss=1.469, trans_loss=5.289, nll_loss=2.612, w2v_ctc_loss=0.438, task_loss=2.109, contrastive_loss=0.259, total=4141.25, n_correct=2675.94, ppl=6.11, accuracy=64.617, wps=6854.3, ups=1.66, wpb=4141.2, bsz=152.4, num_updates=33800, lr=7.69231e-05, gnorm=0.354, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=26525
2023-07-09 17:36:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 17:36:51 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 2.302 | trans_loss 5.532 | nll_loss 2.83 | w2v_ctc_loss 0.693 | task_loss 2.365 | contrastive_loss 0.253 | total 4003.4 | n_correct 2492.6 | ppl 7.11 | accuracy 62.262 | uer 16.76 | wer 18.541 | raw_wer 18.541 | bleu 19.92 | wps 2177.5 | wpb 4003.4 | bsz 141.8 | num_updates 33888 | best_bleu 20.2
2023-07-09 17:36:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33888 updates
2023-07-09 17:36:51 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.9206.pt
2023-07-09 17:36:54 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.9206.pt
2023-07-09 17:36:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_19.9206.pt (epoch 23 @ 33888 updates, score 19.92) (writing took 5.276165810006205 seconds)
2023-07-09 17:36:57 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-07-09 17:36:57 | INFO | train | epoch 023 | loss 1.459 | trans_loss 5.256 | nll_loss 2.569 | w2v_ctc_loss 0.43 | task_loss 2.092 | contrastive_loss 0.228 | total 4138.65 | n_correct 2696.24 | ppl 5.93 | accuracy 65.148 | wps 6557.6 | ups 1.58 | wpb 4138.6 | bsz 152.8 | num_updates 33888 | lr 7.68231e-05 | gnorm 0.353 | clip 0 | loss_scale 64 | train_wall 885 | gb_free 14.1 | wall 26609
2023-07-09 17:36:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 17:36:57 | INFO | fairseq.trainer | begin training epoch 24
2023-07-09 17:36:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 17:37:13 | INFO | train_inner | epoch 024:     12 / 1474 loss=1.467, trans_loss=5.281, nll_loss=2.603, w2v_ctc_loss=0.429, task_loss=2.08, contrastive_loss=0.41, total=4095.53, n_correct=2651.53, ppl=6.07, accuracy=64.742, wps=4120.7, ups=1.01, wpb=4095.5, bsz=153.1, num_updates=33900, lr=7.68095e-05, gnorm=0.36, clip=0, loss_scale=64, train_wall=60, gb_free=17.5, wall=26625
2023-07-09 17:38:13 | INFO | train_inner | epoch 024:    112 / 1474 loss=1.457, trans_loss=5.229, nll_loss=2.534, w2v_ctc_loss=0.425, task_loss=1.943, contrastive_loss=0.46, total=4167.42, n_correct=2735.26, ppl=5.79, accuracy=65.634, wps=6897.8, ups=1.66, wpb=4167.4, bsz=161.5, num_updates=34000, lr=7.66965e-05, gnorm=0.352, clip=0, loss_scale=64, train_wall=60, gb_free=17.8, wall=26685
2023-07-09 17:38:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 17:38:37 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 2.298 | trans_loss 5.54 | nll_loss 2.837 | w2v_ctc_loss 0.672 | task_loss 2.365 | contrastive_loss 0.259 | total 4003.4 | n_correct 2494.9 | ppl 7.14 | accuracy 62.32 | uer 16.68 | wer 18.467 | raw_wer 18.467 | bleu 20 | wps 2224.5 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.2
2023-07-09 17:38:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-07-09 17:38:37 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_24_34000.pt
2023-07-09 17:38:39 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_24_34000.pt
2023-07-09 17:38:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 20.0) (writing took 6.305196631001309 seconds)
2023-07-09 17:39:45 | INFO | train_inner | epoch 024:    212 / 1474 loss=1.455, trans_loss=5.23, nll_loss=2.536, w2v_ctc_loss=0.417, task_loss=1.829, contrastive_loss=0.557, total=4247.08, n_correct=2785.6, ppl=5.8, accuracy=65.589, wps=4637.2, ups=1.09, wpb=4247.1, bsz=169.8, num_updates=34100, lr=7.6584e-05, gnorm=0.347, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=26777
2023-07-09 17:40:45 | INFO | train_inner | epoch 024:    312 / 1474 loss=1.444, trans_loss=5.224, nll_loss=2.527, w2v_ctc_loss=0.423, task_loss=2.024, contrastive_loss=0.12, total=4139.31, n_correct=2721.7, ppl=5.77, accuracy=65.753, wps=6887.8, ups=1.66, wpb=4139.3, bsz=154.2, num_updates=34200, lr=7.64719e-05, gnorm=0.348, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=26837
2023-07-09 17:40:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-09 17:41:47 | INFO | train_inner | epoch 024:    413 / 1474 loss=1.454, trans_loss=5.247, nll_loss=2.557, w2v_ctc_loss=0.434, task_loss=2.281, contrastive_loss=0.175, total=4127.95, n_correct=2697.68, ppl=5.88, accuracy=65.352, wps=6648.7, ups=1.61, wpb=4127.9, bsz=145.2, num_updates=34300, lr=7.63604e-05, gnorm=0.357, clip=0, loss_scale=32, train_wall=62, gb_free=16.8, wall=26899
2023-07-09 17:42:47 | INFO | train_inner | epoch 024:    513 / 1474 loss=1.455, trans_loss=5.245, nll_loss=2.554, w2v_ctc_loss=0.429, task_loss=2.115, contrastive_loss=0.258, total=4144.91, n_correct=2708.69, ppl=5.87, accuracy=65.35, wps=6864.9, ups=1.66, wpb=4144.9, bsz=151.6, num_updates=34400, lr=7.62493e-05, gnorm=0.357, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=26959
2023-07-09 17:43:48 | INFO | train_inner | epoch 024:    613 / 1474 loss=1.448, trans_loss=5.233, nll_loss=2.54, w2v_ctc_loss=0.422, task_loss=2.108, contrastive_loss=0.182, total=4165.3, n_correct=2728.26, ppl=5.82, accuracy=65.5, wps=6896.2, ups=1.66, wpb=4165.3, bsz=153.8, num_updates=34500, lr=7.61387e-05, gnorm=0.352, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=27020
2023-07-09 17:44:48 | INFO | train_inner | epoch 024:    713 / 1474 loss=1.456, trans_loss=5.252, nll_loss=2.563, w2v_ctc_loss=0.432, task_loss=2.165, contrastive_loss=0.207, total=4102.21, n_correct=2674.59, ppl=5.91, accuracy=65.199, wps=6742.1, ups=1.64, wpb=4102.2, bsz=147.5, num_updates=34600, lr=7.60286e-05, gnorm=0.353, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=27080
2023-07-09 17:45:49 | INFO | train_inner | epoch 024:    813 / 1474 loss=1.451, trans_loss=5.242, nll_loss=2.552, w2v_ctc_loss=0.423, task_loss=2.112, contrastive_loss=0.162, total=4110.6, n_correct=2684.31, ppl=5.86, accuracy=65.302, wps=6799.7, ups=1.65, wpb=4110.6, bsz=152.7, num_updates=34700, lr=7.5919e-05, gnorm=0.353, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=27141
2023-07-09 17:46:49 | INFO | train_inner | epoch 024:    913 / 1474 loss=1.454, trans_loss=5.255, nll_loss=2.566, w2v_ctc_loss=0.431, task_loss=2.31, contrastive_loss=0.114, total=4043.03, n_correct=2630.51, ppl=5.92, accuracy=65.063, wps=6717.8, ups=1.66, wpb=4043, bsz=140.5, num_updates=34800, lr=7.58098e-05, gnorm=0.354, clip=0, loss_scale=32, train_wall=60, gb_free=11.7, wall=27201
2023-07-09 17:47:50 | INFO | train_inner | epoch 024:   1013 / 1474 loss=1.448, trans_loss=5.252, nll_loss=2.564, w2v_ctc_loss=0.423, task_loss=2.161, contrastive_loss=0.122, total=4136.81, n_correct=2699.68, ppl=5.91, accuracy=65.26, wps=6827.4, ups=1.65, wpb=4136.8, bsz=149.2, num_updates=34900, lr=7.57011e-05, gnorm=0.354, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=27262
2023-07-09 17:48:50 | INFO | train_inner | epoch 024:   1113 / 1474 loss=1.447, trans_loss=5.234, nll_loss=2.541, w2v_ctc_loss=0.426, task_loss=2.033, contrastive_loss=0.21, total=4135.73, n_correct=2708.58, ppl=5.82, accuracy=65.492, wps=6878.8, ups=1.66, wpb=4135.7, bsz=154.4, num_updates=35000, lr=7.55929e-05, gnorm=0.355, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=27322
tensor(0.0221, device='cuda:0')
tensor(0.0008, device='cuda:0')
2023-07-09 17:49:50 | INFO | train_inner | epoch 024:   1213 / 1474 loss=1.453, trans_loss=5.256, nll_loss=2.57, w2v_ctc_loss=0.425, task_loss=2.073, contrastive_loss=0.187, total=4148.3, n_correct=2704.27, ppl=5.94, accuracy=65.19, wps=6850.4, ups=1.65, wpb=4148.3, bsz=155.4, num_updates=35100, lr=7.54851e-05, gnorm=0.355, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=27382
2023-07-09 17:50:51 | INFO | train_inner | epoch 024:   1313 / 1474 loss=1.459, trans_loss=5.261, nll_loss=2.576, w2v_ctc_loss=0.433, task_loss=2.223, contrastive_loss=0.132, total=4110.05, n_correct=2675.19, ppl=5.96, accuracy=65.089, wps=6784, ups=1.65, wpb=4110.1, bsz=147.1, num_updates=35200, lr=7.53778e-05, gnorm=0.355, clip=0, loss_scale=32, train_wall=60, gb_free=17.4, wall=27443
2023-07-09 17:51:51 | INFO | train_inner | epoch 024:   1413 / 1474 loss=1.458, trans_loss=5.262, nll_loss=2.579, w2v_ctc_loss=0.437, task_loss=2.188, contrastive_loss=0.129, total=4090.91, n_correct=2660.1, ppl=5.97, accuracy=65.025, wps=6813, ups=1.67, wpb=4090.9, bsz=146.4, num_updates=35300, lr=7.5271e-05, gnorm=0.353, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=27503
2023-07-09 17:52:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0221, device='cuda:5')
tensor(0.0008, device='cuda:5')
tensor(0.0221, device='cuda:4')
tensor(0.0008, device='cuda:4')
tensor(0.0221, device='cuda:6')
tensor(0.0008, device='cuda:6')
tensor(0.0221, device='cuda:1')
tensor(0.0008, device='cuda:1')
tensor(0.0221, device='cuda:2')
tensor(0.0008, device='cuda:2')
tensor(0.0221, device='cuda:7')
tensor(0.0008, device='cuda:7')
tensor(0.0221, device='cuda:3')
tensor(0.0008, device='cuda:3')
2023-07-09 17:52:54 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 2.3 | trans_loss 5.538 | nll_loss 2.838 | w2v_ctc_loss 0.689 | task_loss 2.365 | contrastive_loss 0.264 | total 4003.4 | n_correct 2489.9 | ppl 7.15 | accuracy 62.195 | uer 16.654 | wer 18.564 | raw_wer 18.564 | bleu 20.2 | wps 1994.6 | wpb 4003.4 | bsz 141.8 | num_updates 35361 | best_bleu 20.2
2023-07-09 17:52:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35361 updates
2023-07-09 17:52:54 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 17:52:58 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 17:53:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt (epoch 24 @ 35361 updates, score 20.2) (writing took 8.237670999020338 seconds)
2023-07-09 17:53:02 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-07-09 17:53:02 | INFO | train | epoch 024 | loss 1.452 | trans_loss 5.244 | nll_loss 2.554 | w2v_ctc_loss 0.427 | task_loss 2.096 | contrastive_loss 0.217 | total 4137.03 | n_correct 2703.48 | ppl 5.87 | accuracy 65.348 | wps 6312.1 | ups 1.53 | wpb 4137 | bsz 152.6 | num_updates 35361 | lr 7.5206e-05 | gnorm 0.353 | clip 0 | loss_scale 32 | train_wall 885 | gb_free 16.3 | wall 27574
2023-07-09 17:53:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 17:53:03 | INFO | fairseq.trainer | begin training epoch 25
2023-07-09 17:53:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 17:53:34 | INFO | train_inner | epoch 025:     39 / 1474 loss=1.443, trans_loss=5.228, nll_loss=2.534, w2v_ctc_loss=0.422, task_loss=1.995, contrastive_loss=0.146, total=4166.95, n_correct=2735.3, ppl=5.79, accuracy=65.643, wps=4051.5, ups=0.97, wpb=4166.9, bsz=156, num_updates=35400, lr=7.51646e-05, gnorm=0.349, clip=0, loss_scale=32, train_wall=59, gb_free=16.6, wall=27606
2023-07-09 17:54:34 | INFO | train_inner | epoch 025:    139 / 1474 loss=1.441, trans_loss=5.213, nll_loss=2.515, w2v_ctc_loss=0.419, task_loss=2.049, contrastive_loss=0.14, total=4133.64, n_correct=2724.01, ppl=5.71, accuracy=65.899, wps=6834.7, ups=1.65, wpb=4133.6, bsz=153.9, num_updates=35500, lr=7.50587e-05, gnorm=0.351, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=27666
2023-07-09 17:55:35 | INFO | train_inner | epoch 025:    239 / 1474 loss=1.439, trans_loss=5.214, nll_loss=2.514, w2v_ctc_loss=0.423, task_loss=2.149, contrastive_loss=0.15, total=4114.53, n_correct=2707.43, ppl=5.71, accuracy=65.802, wps=6764.9, ups=1.64, wpb=4114.5, bsz=151.4, num_updates=35600, lr=7.49532e-05, gnorm=0.353, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=27727
2023-07-09 17:56:36 | INFO | train_inner | epoch 025:    339 / 1474 loss=1.444, trans_loss=5.224, nll_loss=2.526, w2v_ctc_loss=0.42, task_loss=2.23, contrastive_loss=0.206, total=4148.7, n_correct=2722.58, ppl=5.76, accuracy=65.625, wps=6779.2, ups=1.63, wpb=4148.7, bsz=147.6, num_updates=35700, lr=7.48481e-05, gnorm=0.355, clip=0, loss_scale=32, train_wall=61, gb_free=16.8, wall=27788
2023-07-09 17:57:37 | INFO | train_inner | epoch 025:    439 / 1474 loss=1.458, trans_loss=5.237, nll_loss=2.544, w2v_ctc_loss=0.431, task_loss=2.179, contrastive_loss=0.36, total=4167.03, n_correct=2727.31, ppl=5.83, accuracy=65.45, wps=6841.8, ups=1.64, wpb=4167, bsz=149.2, num_updates=35800, lr=7.47435e-05, gnorm=0.357, clip=0, loss_scale=32, train_wall=60, gb_free=12.7, wall=27849
2023-07-09 17:58:38 | INFO | train_inner | epoch 025:    539 / 1474 loss=1.447, trans_loss=5.239, nll_loss=2.549, w2v_ctc_loss=0.427, task_loss=2.049, contrastive_loss=0.151, total=4156.93, n_correct=2723.33, ppl=5.85, accuracy=65.513, wps=6898.2, ups=1.66, wpb=4156.9, bsz=156.4, num_updates=35900, lr=7.46393e-05, gnorm=0.353, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=27910
2023-07-09 17:59:38 | INFO | train_inner | epoch 025:    639 / 1474 loss=1.446, trans_loss=5.228, nll_loss=2.534, w2v_ctc_loss=0.422, task_loss=2.083, contrastive_loss=0.283, total=4153.23, n_correct=2726.54, ppl=5.79, accuracy=65.649, wps=6897.7, ups=1.66, wpb=4153.2, bsz=154.8, num_updates=36000, lr=7.45356e-05, gnorm=0.355, clip=0, loss_scale=32, train_wall=60, gb_free=15.1, wall=27970
2023-07-09 17:59:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 18:00:03 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 2.295 | trans_loss 5.536 | nll_loss 2.834 | w2v_ctc_loss 0.681 | task_loss 2.365 | contrastive_loss 0.264 | total 4003.4 | n_correct 2494.9 | ppl 7.13 | accuracy 62.32 | uer 16.662 | wer 18.664 | raw_wer 18.664 | bleu 20.15 | wps 2037.3 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.2
2023-07-09 18:00:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-07-09 18:00:03 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_25_36000.pt
2023-07-09 18:00:05 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_25_36000.pt
2023-07-09 18:00:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 20.15) (writing took 6.193729177000932 seconds)
2023-07-09 18:01:10 | INFO | train_inner | epoch 025:    739 / 1474 loss=1.449, trans_loss=5.236, nll_loss=2.543, w2v_ctc_loss=0.425, task_loss=2.117, contrastive_loss=0.276, total=4123.21, n_correct=2701.11, ppl=5.83, accuracy=65.51, wps=4469.3, ups=1.08, wpb=4123.2, bsz=150.4, num_updates=36100, lr=7.44323e-05, gnorm=0.361, clip=0, loss_scale=32, train_wall=60, gb_free=15, wall=28062
2023-07-09 18:02:10 | INFO | train_inner | epoch 025:    839 / 1474 loss=1.445, trans_loss=5.23, nll_loss=2.537, w2v_ctc_loss=0.42, task_loss=1.909, contrastive_loss=0.172, total=4197.27, n_correct=2756.63, ppl=5.8, accuracy=65.677, wps=6981.2, ups=1.66, wpb=4197.3, bsz=164.1, num_updates=36200, lr=7.43294e-05, gnorm=0.352, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=28122
2023-07-09 18:03:11 | INFO | train_inner | epoch 025:    939 / 1474 loss=1.449, trans_loss=5.233, nll_loss=2.542, w2v_ctc_loss=0.424, task_loss=2.014, contrastive_loss=0.282, total=4137.23, n_correct=2711.71, ppl=5.82, accuracy=65.544, wps=6828.6, ups=1.65, wpb=4137.2, bsz=156.7, num_updates=36300, lr=7.4227e-05, gnorm=0.351, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=28183
2023-07-09 18:04:12 | INFO | train_inner | epoch 025:   1039 / 1474 loss=1.455, trans_loss=5.25, nll_loss=2.561, w2v_ctc_loss=0.418, task_loss=2.071, contrastive_loss=0.504, total=4183.45, n_correct=2727.24, ppl=5.9, accuracy=65.191, wps=6846.5, ups=1.64, wpb=4183.4, bsz=155.5, num_updates=36400, lr=7.41249e-05, gnorm=0.354, clip=0, loss_scale=64, train_wall=61, gb_free=16.9, wall=28244
2023-07-09 18:05:12 | INFO | train_inner | epoch 025:   1139 / 1474 loss=1.446, trans_loss=5.241, nll_loss=2.55, w2v_ctc_loss=0.421, task_loss=2.244, contrastive_loss=0.121, total=4045.24, n_correct=2645.55, ppl=5.86, accuracy=65.399, wps=6732.2, ups=1.66, wpb=4045.2, bsz=143.5, num_updates=36500, lr=7.40233e-05, gnorm=0.359, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=28304
2023-07-09 18:06:11 | INFO | train_inner | epoch 025:   1239 / 1474 loss=1.449, trans_loss=5.246, nll_loss=2.556, w2v_ctc_loss=0.424, task_loss=2.144, contrastive_loss=0.128, total=4079.17, n_correct=2664.7, ppl=5.88, accuracy=65.325, wps=6872.5, ups=1.68, wpb=4079.2, bsz=146.2, num_updates=36600, lr=7.39221e-05, gnorm=0.361, clip=0, loss_scale=64, train_wall=59, gb_free=17.2, wall=28363
2023-07-09 18:07:12 | INFO | train_inner | epoch 025:   1339 / 1474 loss=1.452, trans_loss=5.239, nll_loss=2.549, w2v_ctc_loss=0.422, task_loss=2.014, contrastive_loss=0.331, total=4173.55, n_correct=2731.15, ppl=5.85, accuracy=65.439, wps=6890.2, ups=1.65, wpb=4173.6, bsz=156.3, num_updates=36700, lr=7.38213e-05, gnorm=0.353, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=28424
2023-07-09 18:08:13 | INFO | train_inner | epoch 025:   1439 / 1474 loss=1.453, trans_loss=5.262, nll_loss=2.578, w2v_ctc_loss=0.427, task_loss=2.18, contrastive_loss=0.225, total=4102.27, n_correct=2670.35, ppl=5.97, accuracy=65.094, wps=6722.3, ups=1.64, wpb=4102.3, bsz=149.9, num_updates=36800, lr=7.3721e-05, gnorm=0.354, clip=0, loss_scale=64, train_wall=61, gb_free=16.2, wall=28485
2023-07-09 18:08:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 18:08:59 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 2.289 | trans_loss 5.531 | nll_loss 2.829 | w2v_ctc_loss 0.672 | task_loss 2.365 | contrastive_loss 0.267 | total 4003.4 | n_correct 2491.2 | ppl 7.1 | accuracy 62.227 | uer 16.715 | wer 18.735 | raw_wer 18.735 | bleu 20.16 | wps 2100.5 | wpb 4003.4 | bsz 141.8 | num_updates 36835 | best_bleu 20.2
2023-07-09 18:08:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36835 updates
2023-07-09 18:08:59 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.1603.pt
2023-07-09 18:09:02 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.1603.pt
2023-07-09 18:09:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.1603.pt (epoch 25 @ 36835 updates, score 20.16) (writing took 5.269579422019888 seconds)
2023-07-09 18:09:05 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-07-09 18:09:05 | INFO | train | epoch 025 | loss 1.448 | trans_loss 5.235 | nll_loss 2.542 | w2v_ctc_loss 0.423 | task_loss 2.092 | contrastive_loss 0.236 | total 4138.65 | n_correct 2711.33 | ppl 5.83 | accuracy 65.512 | wps 6337.3 | ups 1.53 | wpb 4138.6 | bsz 152.8 | num_updates 36835 | lr 7.36859e-05 | gnorm 0.355 | clip 0 | loss_scale 64 | train_wall 885 | gb_free 14.6 | wall 28537
2023-07-09 18:09:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 18:09:05 | INFO | fairseq.trainer | begin training epoch 26
2023-07-09 18:09:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 18:09:52 | INFO | train_inner | epoch 026:     65 / 1474 loss=1.433, trans_loss=5.206, nll_loss=2.505, w2v_ctc_loss=0.414, task_loss=1.973, contrastive_loss=0.198, total=4178.19, n_correct=2756.58, ppl=5.68, accuracy=65.975, wps=4194.7, ups=1, wpb=4178.2, bsz=158.7, num_updates=36900, lr=7.3621e-05, gnorm=0.35, clip=0, loss_scale=64, train_wall=60, gb_free=14.5, wall=28584
2023-07-09 18:10:53 | INFO | train_inner | epoch 026:    165 / 1474 loss=1.441, trans_loss=5.197, nll_loss=2.495, w2v_ctc_loss=0.405, task_loss=1.822, contrastive_loss=0.562, total=4269.55, n_correct=2823.42, ppl=5.64, accuracy=66.129, wps=7014.4, ups=1.64, wpb=4269.6, bsz=170.7, num_updates=37000, lr=7.35215e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=60, gb_free=15.6, wall=28645
2023-07-09 18:11:54 | INFO | train_inner | epoch 026:    265 / 1474 loss=1.446, trans_loss=5.215, nll_loss=2.516, w2v_ctc_loss=0.423, task_loss=2.071, contrastive_loss=0.319, total=4128.39, n_correct=2714.69, ppl=5.72, accuracy=65.757, wps=6791.8, ups=1.65, wpb=4128.4, bsz=153.4, num_updates=37100, lr=7.34223e-05, gnorm=0.36, clip=0, loss_scale=64, train_wall=60, gb_free=10.6, wall=28706
2023-07-09 18:12:54 | INFO | train_inner | epoch 026:    365 / 1474 loss=1.439, trans_loss=5.209, nll_loss=2.51, w2v_ctc_loss=0.416, task_loss=2.005, contrastive_loss=0.234, total=4166.22, n_correct=2746.54, ppl=5.7, accuracy=65.924, wps=6913.2, ups=1.66, wpb=4166.2, bsz=157.5, num_updates=37200, lr=7.33236e-05, gnorm=0.352, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=28766
2023-07-09 18:13:55 | INFO | train_inner | epoch 026:    465 / 1474 loss=1.441, trans_loss=5.201, nll_loss=2.499, w2v_ctc_loss=0.417, task_loss=1.985, contrastive_loss=0.322, total=4171.18, n_correct=2759.47, ppl=5.65, accuracy=66.156, wps=6938.6, ups=1.66, wpb=4171.2, bsz=157.7, num_updates=37300, lr=7.32252e-05, gnorm=0.35, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=28827
2023-07-09 18:14:55 | INFO | train_inner | epoch 026:    565 / 1474 loss=1.44, trans_loss=5.224, nll_loss=2.528, w2v_ctc_loss=0.427, task_loss=2.129, contrastive_loss=0.161, total=4139.82, n_correct=2720.15, ppl=5.77, accuracy=65.707, wps=6843, ups=1.65, wpb=4139.8, bsz=150, num_updates=37400, lr=7.31272e-05, gnorm=0.356, clip=0, loss_scale=64, train_wall=60, gb_free=15.3, wall=28887
2023-07-09 18:15:56 | INFO | train_inner | epoch 026:    665 / 1474 loss=1.435, trans_loss=5.212, nll_loss=2.513, w2v_ctc_loss=0.411, task_loss=2.112, contrastive_loss=0.14, total=4146.72, n_correct=2729.82, ppl=5.71, accuracy=65.831, wps=6834.1, ups=1.65, wpb=4146.7, bsz=151.4, num_updates=37500, lr=7.30297e-05, gnorm=0.354, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=28948
2023-07-09 18:16:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-09 18:16:56 | INFO | train_inner | epoch 026:    766 / 1474 loss=1.448, trans_loss=5.227, nll_loss=2.533, w2v_ctc_loss=0.418, task_loss=2.12, contrastive_loss=0.357, total=4085.95, n_correct=2680.08, ppl=5.79, accuracy=65.593, wps=6761.1, ups=1.65, wpb=4086, bsz=149.2, num_updates=37600, lr=7.29325e-05, gnorm=0.358, clip=0, loss_scale=32, train_wall=60, gb_free=15.3, wall=29008
2023-07-09 18:17:57 | INFO | train_inner | epoch 026:    866 / 1474 loss=1.445, trans_loss=5.223, nll_loss=2.527, w2v_ctc_loss=0.422, task_loss=2.067, contrastive_loss=0.168, total=4183.26, n_correct=2748.21, ppl=5.76, accuracy=65.695, wps=6914.3, ups=1.65, wpb=4183.3, bsz=154.1, num_updates=37700, lr=7.28357e-05, gnorm=0.359, clip=0, loss_scale=32, train_wall=60, gb_free=17.4, wall=29069
2023-07-09 18:18:57 | INFO | train_inner | epoch 026:    966 / 1474 loss=1.445, trans_loss=5.235, nll_loss=2.543, w2v_ctc_loss=0.416, task_loss=2.157, contrastive_loss=0.273, total=4137.96, n_correct=2709.08, ppl=5.83, accuracy=65.469, wps=6829.6, ups=1.65, wpb=4138, bsz=149.5, num_updates=37800, lr=7.27393e-05, gnorm=0.354, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=29129
2023-07-09 18:19:58 | INFO | train_inner | epoch 026:   1066 / 1474 loss=1.441, trans_loss=5.232, nll_loss=2.54, w2v_ctc_loss=0.422, task_loss=2.201, contrastive_loss=0.136, total=4120.53, n_correct=2702.43, ppl=5.81, accuracy=65.585, wps=6826.9, ups=1.66, wpb=4120.5, bsz=147.1, num_updates=37900, lr=7.26433e-05, gnorm=0.355, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=29190
2023-07-09 18:20:58 | INFO | train_inner | epoch 026:   1166 / 1474 loss=1.448, trans_loss=5.241, nll_loss=2.551, w2v_ctc_loss=0.424, task_loss=2.196, contrastive_loss=0.219, total=4113.86, n_correct=2689.5, ppl=5.86, accuracy=65.377, wps=6756.3, ups=1.64, wpb=4113.9, bsz=149.2, num_updates=38000, lr=7.25476e-05, gnorm=0.358, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=29251
2023-07-09 18:20:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 18:21:24 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 2.297 | trans_loss 5.538 | nll_loss 2.838 | w2v_ctc_loss 0.697 | task_loss 2.365 | contrastive_loss 0.268 | total 4003.4 | n_correct 2486 | ppl 7.15 | accuracy 62.097 | uer 16.718 | wer 18.534 | raw_wer 18.534 | bleu 20.1 | wps 2079.2 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.2
2023-07-09 18:21:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-07-09 18:21:24 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_26_38000.pt
2023-07-09 18:21:26 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_26_38000.pt
2023-07-09 18:21:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 20.1) (writing took 6.272860356984893 seconds)
2023-07-09 18:22:31 | INFO | train_inner | epoch 026:   1266 / 1474 loss=1.451, trans_loss=5.256, nll_loss=2.57, w2v_ctc_loss=0.431, task_loss=2.341, contrastive_loss=0.143, total=3996.19, n_correct=2601.78, ppl=5.94, accuracy=65.107, wps=4310.7, ups=1.08, wpb=3996.2, bsz=139.6, num_updates=38100, lr=7.24524e-05, gnorm=0.367, clip=0, loss_scale=32, train_wall=60, gb_free=17.8, wall=29343
2023-07-09 18:23:33 | INFO | train_inner | epoch 026:   1366 / 1474 loss=1.444, trans_loss=5.24, nll_loss=2.55, w2v_ctc_loss=0.42, task_loss=2.095, contrastive_loss=0.172, total=4159.74, n_correct=2725.5, ppl=5.86, accuracy=65.521, wps=6763.3, ups=1.63, wpb=4159.7, bsz=155.7, num_updates=38200, lr=7.23575e-05, gnorm=0.354, clip=0, loss_scale=32, train_wall=61, gb_free=17.4, wall=29405
2023-07-09 18:24:33 | INFO | train_inner | epoch 026:   1466 / 1474 loss=1.439, trans_loss=5.23, nll_loss=2.537, w2v_ctc_loss=0.415, task_loss=1.986, contrastive_loss=0.162, total=4165.66, n_correct=2735.2, ppl=5.8, accuracy=65.661, wps=6941.4, ups=1.67, wpb=4165.7, bsz=158.7, num_updates=38300, lr=7.22629e-05, gnorm=0.351, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=29465
2023-07-09 18:24:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 18:25:04 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 2.294 | trans_loss 5.534 | nll_loss 2.833 | w2v_ctc_loss 0.692 | task_loss 2.365 | contrastive_loss 0.259 | total 4003.4 | n_correct 2493.3 | ppl 7.13 | accuracy 62.28 | uer 16.696 | wer 18.508 | raw_wer 18.508 | bleu 19.65 | wps 1939.1 | wpb 4003.4 | bsz 141.8 | num_updates 38308 | best_bleu 20.2
2023-07-09 18:25:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38308 updates
2023-07-09 18:25:04 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_last.pt
2023-07-09 18:25:08 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_last.pt
2023-07-09 18:25:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_last.pt (epoch 26 @ 38308 updates, score 19.65) (writing took 4.208744412026135 seconds)
2023-07-09 18:25:08 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-07-09 18:25:08 | INFO | train | epoch 026 | loss 1.442 | trans_loss 5.222 | nll_loss 2.527 | w2v_ctc_loss 0.419 | task_loss 2.091 | contrastive_loss 0.24 | total 4138.66 | n_correct 2719.57 | ppl 5.76 | accuracy 65.711 | wps 6327.9 | ups 1.53 | wpb 4138.7 | bsz 152.9 | num_updates 38308 | lr 7.22554e-05 | gnorm 0.355 | clip 0 | loss_scale 32 | train_wall 886 | gb_free 16.2 | wall 29500
2023-07-09 18:25:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 18:25:09 | INFO | fairseq.trainer | begin training epoch 27
2023-07-09 18:25:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 18:26:12 | INFO | train_inner | epoch 027:     92 / 1474 loss=1.428, trans_loss=5.179, nll_loss=2.47, w2v_ctc_loss=0.41, task_loss=2.261, contrastive_loss=0.117, total=4054.57, n_correct=2694, ppl=5.54, accuracy=66.444, wps=4092.9, ups=1.01, wpb=4054.6, bsz=141.2, num_updates=38400, lr=7.21688e-05, gnorm=0.358, clip=0, loss_scale=32, train_wall=59, gb_free=16.5, wall=29564
2023-07-09 18:27:12 | INFO | train_inner | epoch 027:    192 / 1474 loss=1.428, trans_loss=5.183, nll_loss=2.475, w2v_ctc_loss=0.412, task_loss=1.972, contrastive_loss=0.176, total=4195.2, n_correct=2781.92, ppl=5.56, accuracy=66.312, wps=6920.6, ups=1.65, wpb=4195.2, bsz=161.6, num_updates=38500, lr=7.2075e-05, gnorm=0.349, clip=0, loss_scale=32, train_wall=60, gb_free=17.3, wall=29624
2023-07-09 18:28:14 | INFO | train_inner | epoch 027:    292 / 1474 loss=1.43, trans_loss=5.198, nll_loss=2.495, w2v_ctc_loss=0.414, task_loss=2.098, contrastive_loss=0.142, total=4162.23, n_correct=2752.45, ppl=5.64, accuracy=66.129, wps=6795.1, ups=1.63, wpb=4162.2, bsz=152.7, num_updates=38600, lr=7.19816e-05, gnorm=0.35, clip=0, loss_scale=32, train_wall=61, gb_free=17.3, wall=29686
2023-07-09 18:29:15 | INFO | train_inner | epoch 027:    392 / 1474 loss=1.446, trans_loss=5.219, nll_loss=2.523, w2v_ctc_loss=0.416, task_loss=2.195, contrastive_loss=0.511, total=4079.05, n_correct=2683.78, ppl=5.75, accuracy=65.794, wps=6606.5, ups=1.62, wpb=4079.1, bsz=148.6, num_updates=38700, lr=7.18885e-05, gnorm=0.355, clip=0, loss_scale=32, train_wall=61, gb_free=17.1, wall=29747
2023-07-09 18:30:16 | INFO | train_inner | epoch 027:    492 / 1474 loss=1.44, trans_loss=5.216, nll_loss=2.519, w2v_ctc_loss=0.414, task_loss=1.913, contrastive_loss=0.376, total=4243.25, n_correct=2791.37, ppl=5.73, accuracy=65.784, wps=6956.4, ups=1.64, wpb=4243.2, bsz=165.5, num_updates=38800, lr=7.17958e-05, gnorm=0.351, clip=0, loss_scale=32, train_wall=61, gb_free=15.9, wall=29808
2023-07-09 18:31:17 | INFO | train_inner | epoch 027:    592 / 1474 loss=1.438, trans_loss=5.212, nll_loss=2.514, w2v_ctc_loss=0.416, task_loss=2.047, contrastive_loss=0.262, total=4137.92, n_correct=2724.74, ppl=5.71, accuracy=65.848, wps=6882.7, ups=1.66, wpb=4137.9, bsz=156.7, num_updates=38900, lr=7.17035e-05, gnorm=0.356, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=29869
2023-07-09 18:32:17 | INFO | train_inner | epoch 027:    692 / 1474 loss=1.442, trans_loss=5.223, nll_loss=2.528, w2v_ctc_loss=0.421, task_loss=2.102, contrastive_loss=0.217, total=4158.48, n_correct=2732.15, ppl=5.77, accuracy=65.701, wps=6868.5, ups=1.65, wpb=4158.5, bsz=152, num_updates=39000, lr=7.16115e-05, gnorm=0.358, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=29929
2023-07-09 18:33:17 | INFO | train_inner | epoch 027:    792 / 1474 loss=1.44, trans_loss=5.221, nll_loss=2.525, w2v_ctc_loss=0.421, task_loss=2.211, contrastive_loss=0.141, total=4100.88, n_correct=2692.17, ppl=5.76, accuracy=65.649, wps=6820, ups=1.66, wpb=4100.9, bsz=146.1, num_updates=39100, lr=7.15199e-05, gnorm=0.361, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=29989
2023-07-09 18:34:17 | INFO | train_inner | epoch 027:    892 / 1474 loss=1.437, trans_loss=5.216, nll_loss=2.519, w2v_ctc_loss=0.413, task_loss=2.157, contrastive_loss=0.13, total=4111.94, n_correct=2706.93, ppl=5.73, accuracy=65.831, wps=6860.7, ups=1.67, wpb=4111.9, bsz=147.4, num_updates=39200, lr=7.14286e-05, gnorm=0.357, clip=0, loss_scale=32, train_wall=59, gb_free=16.5, wall=30049
2023-07-09 18:35:19 | INFO | train_inner | epoch 027:    992 / 1474 loss=1.443, trans_loss=5.223, nll_loss=2.528, w2v_ctc_loss=0.419, task_loss=2.033, contrastive_loss=0.507, total=4189.27, n_correct=2752.54, ppl=5.77, accuracy=65.705, wps=6779.5, ups=1.62, wpb=4189.3, bsz=157.5, num_updates=39300, lr=7.13376e-05, gnorm=0.355, clip=0, loss_scale=32, train_wall=61, gb_free=14.6, wall=30111
2023-07-09 18:36:19 | INFO | train_inner | epoch 027:   1092 / 1474 loss=1.434, trans_loss=5.214, nll_loss=2.517, w2v_ctc_loss=0.415, task_loss=2.089, contrastive_loss=0.167, total=4160.42, n_correct=2735.58, ppl=5.72, accuracy=65.752, wps=6877.6, ups=1.65, wpb=4160.4, bsz=153.7, num_updates=39400, lr=7.1247e-05, gnorm=0.353, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=30171
2023-07-09 18:37:20 | INFO | train_inner | epoch 027:   1192 / 1474 loss=1.439, trans_loss=5.223, nll_loss=2.529, w2v_ctc_loss=0.419, task_loss=2.193, contrastive_loss=0.176, total=4103.72, n_correct=2695.02, ppl=5.77, accuracy=65.673, wps=6740.6, ups=1.64, wpb=4103.7, bsz=148.6, num_updates=39500, lr=7.11568e-05, gnorm=0.356, clip=0, loss_scale=32, train_wall=60, gb_free=17.7, wall=30232
2023-07-09 18:38:21 | INFO | train_inner | epoch 027:   1292 / 1474 loss=1.442, trans_loss=5.232, nll_loss=2.54, w2v_ctc_loss=0.415, task_loss=2.236, contrastive_loss=0.279, total=4065.94, n_correct=2662.81, ppl=5.82, accuracy=65.491, wps=6758.1, ups=1.66, wpb=4065.9, bsz=146.2, num_updates=39600, lr=7.10669e-05, gnorm=0.361, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=30293
2023-07-09 18:39:20 | INFO | train_inner | epoch 027:   1392 / 1474 loss=1.442, trans_loss=5.226, nll_loss=2.534, w2v_ctc_loss=0.418, task_loss=1.978, contrastive_loss=0.248, total=4149.21, n_correct=2719.64, ppl=5.79, accuracy=65.546, wps=6945, ups=1.67, wpb=4149.2, bsz=156.3, num_updates=39700, lr=7.09773e-05, gnorm=0.357, clip=0, loss_scale=64, train_wall=59, gb_free=17.1, wall=30352
2023-07-09 18:40:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 18:40:35 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 2.291 | trans_loss 5.535 | nll_loss 2.835 | w2v_ctc_loss 0.691 | task_loss 2.365 | contrastive_loss 0.262 | total 4003.4 | n_correct 2495.6 | ppl 7.14 | accuracy 62.337 | uer 16.914 | wer 18.802 | raw_wer 18.802 | bleu 20.08 | wps 2046.9 | wpb 4003.4 | bsz 141.8 | num_updates 39782 | best_bleu 20.2
2023-07-09 18:40:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39782 updates
2023-07-09 18:40:35 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.0800.pt
2023-07-09 18:40:38 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.0800.pt
2023-07-09 18:40:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.0800.pt (epoch 27 @ 39782 updates, score 20.08) (writing took 5.348573436000152 seconds)
2023-07-09 18:40:41 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-07-09 18:40:41 | INFO | train | epoch 027 | loss 1.438 | trans_loss 5.213 | nll_loss 2.515 | w2v_ctc_loss 0.416 | task_loss 2.092 | contrastive_loss 0.244 | total 4138.65 | n_correct 2724.87 | ppl 5.72 | accuracy 65.84 | wps 6541 | ups 1.58 | wpb 4138.6 | bsz 152.8 | num_updates 39782 | lr 7.09042e-05 | gnorm 0.356 | clip 0 | loss_scale 64 | train_wall 886 | gb_free 17.9 | wall 30433
2023-07-09 18:40:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 18:40:41 | INFO | fairseq.trainer | begin training epoch 28
2023-07-09 18:40:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 18:41:00 | INFO | train_inner | epoch 028:     18 / 1474 loss=1.433, trans_loss=5.203, nll_loss=2.502, w2v_ctc_loss=0.41, task_loss=2.02, contrastive_loss=0.148, total=4106.72, n_correct=2710.3, ppl=5.67, accuracy=65.997, wps=4127.9, ups=1.01, wpb=4106.7, bsz=152.5, num_updates=39800, lr=7.08881e-05, gnorm=0.357, clip=0, loss_scale=64, train_wall=59, gb_free=16.4, wall=30452
2023-07-09 18:42:00 | INFO | train_inner | epoch 028:    118 / 1474 loss=1.43, trans_loss=5.185, nll_loss=2.479, w2v_ctc_loss=0.415, task_loss=2.208, contrastive_loss=0.142, total=4103.42, n_correct=2721.88, ppl=5.57, accuracy=66.332, wps=6806.8, ups=1.66, wpb=4103.4, bsz=146, num_updates=39900, lr=7.07992e-05, gnorm=0.361, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=30512
2023-07-09 18:43:00 | INFO | train_inner | epoch 028:    218 / 1474 loss=1.423, trans_loss=5.179, nll_loss=2.47, w2v_ctc_loss=0.406, task_loss=1.956, contrastive_loss=0.157, total=4200.12, n_correct=2790.01, ppl=5.54, accuracy=66.427, wps=6972.2, ups=1.66, wpb=4200.1, bsz=158.9, num_updates=40000, lr=7.07107e-05, gnorm=0.353, clip=0, loss_scale=64, train_wall=60, gb_free=11.5, wall=30572
2023-07-09 18:43:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 18:43:27 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 2.285 | trans_loss 5.538 | nll_loss 2.838 | w2v_ctc_loss 0.666 | task_loss 2.365 | contrastive_loss 0.27 | total 4003.4 | n_correct 2495.5 | ppl 7.15 | accuracy 62.335 | uer 16.781 | wer 18.59 | raw_wer 18.59 | bleu 20.26 | wps 1917.3 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.26
2023-07-09 18:43:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-07-09 18:43:27 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_28_40000.pt
2023-07-09 18:43:29 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_28_40000.pt
2023-07-09 18:43:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 20.26) (writing took 9.052252369001508 seconds)
tensor(0.0221, device='cuda:0')
tensor(0.0008, device='cuda:0')
2023-07-09 18:44:37 | INFO | train_inner | epoch 028:    318 / 1474 loss=1.447, trans_loss=5.204, nll_loss=2.504, w2v_ctc_loss=0.406, task_loss=2.082, contrastive_loss=0.82, total=4147.36, n_correct=2736.19, ppl=5.67, accuracy=65.974, wps=4277, ups=1.03, wpb=4147.4, bsz=157.7, num_updates=40100, lr=7.06225e-05, gnorm=0.362, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=30669
2023-07-09 18:45:37 | INFO | train_inner | epoch 028:    418 / 1474 loss=1.431, trans_loss=5.198, nll_loss=2.496, w2v_ctc_loss=0.415, task_loss=2.162, contrastive_loss=0.135, total=4087.34, n_correct=2703.09, ppl=5.64, accuracy=66.133, wps=6836.9, ups=1.67, wpb=4087.3, bsz=147.6, num_updates=40200, lr=7.05346e-05, gnorm=0.359, clip=0, loss_scale=64, train_wall=59, gb_free=17, wall=30729
2023-07-09 18:46:37 | INFO | train_inner | epoch 028:    518 / 1474 loss=1.429, trans_loss=5.193, nll_loss=2.489, w2v_ctc_loss=0.409, task_loss=2.171, contrastive_loss=0.159, total=4099.71, n_correct=2711.76, ppl=5.62, accuracy=66.145, wps=6807.1, ups=1.66, wpb=4099.7, bsz=148.1, num_updates=40300, lr=7.0447e-05, gnorm=0.355, clip=0, loss_scale=64, train_wall=60, gb_free=15.5, wall=30789
2023-07-09 18:47:38 | INFO | train_inner | epoch 028:    618 / 1474 loss=1.431, trans_loss=5.208, nll_loss=2.508, w2v_ctc_loss=0.413, task_loss=2.122, contrastive_loss=0.157, total=4177.06, n_correct=2754.43, ppl=5.69, accuracy=65.942, wps=6927.7, ups=1.66, wpb=4177.1, bsz=152, num_updates=40400, lr=7.03598e-05, gnorm=0.357, clip=0, loss_scale=64, train_wall=60, gb_free=17.4, wall=30850
2023-07-09 18:48:38 | INFO | train_inner | epoch 028:    718 / 1474 loss=1.436, trans_loss=5.203, nll_loss=2.504, w2v_ctc_loss=0.409, task_loss=1.877, contrastive_loss=0.377, total=4190.74, n_correct=2767.47, ppl=5.67, accuracy=66.038, wps=6917.8, ups=1.65, wpb=4190.7, bsz=164.2, num_updates=40500, lr=7.02728e-05, gnorm=0.353, clip=0, loss_scale=64, train_wall=60, gb_free=15.7, wall=30910
2023-07-09 18:49:38 | INFO | train_inner | epoch 028:    818 / 1474 loss=1.429, trans_loss=5.197, nll_loss=2.495, w2v_ctc_loss=0.408, task_loss=2.06, contrastive_loss=0.145, total=4091.75, n_correct=2708.49, ppl=5.64, accuracy=66.194, wps=6821.1, ups=1.67, wpb=4091.8, bsz=153, num_updates=40600, lr=7.01862e-05, gnorm=0.356, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=30970
2023-07-09 18:50:39 | INFO | train_inner | epoch 028:    918 / 1474 loss=1.434, trans_loss=5.214, nll_loss=2.517, w2v_ctc_loss=0.414, task_loss=2.152, contrastive_loss=0.267, total=4123.89, n_correct=2716.56, ppl=5.72, accuracy=65.874, wps=6729.8, ups=1.63, wpb=4123.9, bsz=150.5, num_updates=40700, lr=7.01e-05, gnorm=0.356, clip=0, loss_scale=64, train_wall=61, gb_free=17.3, wall=31031
2023-07-09 18:51:40 | INFO | train_inner | epoch 028:   1018 / 1474 loss=1.439, trans_loss=5.216, nll_loss=2.52, w2v_ctc_loss=0.416, task_loss=2.042, contrastive_loss=0.37, total=4176.06, n_correct=2747.05, ppl=5.74, accuracy=65.781, wps=6930.2, ups=1.66, wpb=4176.1, bsz=155.7, num_updates=40800, lr=7.0014e-05, gnorm=0.362, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=31092
2023-07-09 18:52:40 | INFO | train_inner | epoch 028:   1118 / 1474 loss=1.43, trans_loss=5.2, nll_loss=2.5, w2v_ctc_loss=0.412, task_loss=2.037, contrastive_loss=0.189, total=4206.08, n_correct=2776.76, ppl=5.66, accuracy=66.018, wps=6950.4, ups=1.65, wpb=4206.1, bsz=158.7, num_updates=40900, lr=6.99284e-05, gnorm=0.354, clip=0, loss_scale=64, train_wall=60, gb_free=17.3, wall=31152
2023-07-09 18:53:40 | INFO | train_inner | epoch 028:   1218 / 1474 loss=1.43, trans_loss=5.205, nll_loss=2.506, w2v_ctc_loss=0.41, task_loss=2.06, contrastive_loss=0.162, total=4109.72, n_correct=2711.81, ppl=5.68, accuracy=65.985, wps=6840.2, ups=1.66, wpb=4109.7, bsz=153.5, num_updates=41000, lr=6.9843e-05, gnorm=0.359, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=31212
2023-07-09 18:54:41 | INFO | train_inner | epoch 028:   1318 / 1474 loss=1.438, trans_loss=5.223, nll_loss=2.528, w2v_ctc_loss=0.422, task_loss=2.285, contrastive_loss=0.19, total=4085.44, n_correct=2681.59, ppl=5.77, accuracy=65.638, wps=6707.3, ups=1.64, wpb=4085.4, bsz=142.8, num_updates=41100, lr=6.9758e-05, gnorm=0.358, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=31273
2023-07-09 18:55:42 | INFO | train_inner | epoch 028:   1418 / 1474 loss=1.436, trans_loss=5.219, nll_loss=2.524, w2v_ctc_loss=0.416, task_loss=2.229, contrastive_loss=0.232, total=4137.47, n_correct=2717.33, ppl=5.75, accuracy=65.676, wps=6831.6, ups=1.65, wpb=4137.5, bsz=147.4, num_updates=41200, lr=6.96733e-05, gnorm=0.36, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=31334
2023-07-09 18:56:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0221, device='cuda:6')
tensor(0.0008, device='cuda:6')
tensor(0.0221, device='cuda:5')
tensor(0.0008, device='cuda:5')
tensor(0.0221, device='cuda:4')
tensor(0.0008, device='cuda:4')
tensor(0.0221, device='cuda:2')
tensor(0.0008, device='cuda:2')
tensor(0.0221, device='cuda:7')
tensor(0.0008, device='cuda:7')
tensor(0.0221, device='cuda:3')
tensor(0.0008, device='cuda:3')
tensor(0.0221, device='cuda:1')
tensor(0.0008, device='cuda:1')
2023-07-09 18:56:41 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 2.284 | trans_loss 5.53 | nll_loss 2.827 | w2v_ctc_loss 0.678 | task_loss 2.365 | contrastive_loss 0.272 | total 4003.4 | n_correct 2497.4 | ppl 7.1 | accuracy 62.382 | uer 16.625 | wer 18.523 | raw_wer 18.523 | bleu 20.02 | wps 2075 | wpb 4003.4 | bsz 141.8 | num_updates 41256 | best_bleu 20.26
2023-07-09 18:56:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41256 updates
2023-07-09 18:56:41 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.0203.pt
2023-07-09 18:56:43 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.0203.pt
2023-07-09 18:56:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.0203.pt (epoch 28 @ 41256 updates, score 20.02) (writing took 5.314066826977069 seconds)
2023-07-09 18:56:46 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-07-09 18:56:46 | INFO | train | epoch 028 | loss 1.433 | trans_loss 5.203 | nll_loss 2.502 | w2v_ctc_loss 0.412 | task_loss 2.092 | contrastive_loss 0.249 | total 4138.65 | n_correct 2732.54 | ppl 5.67 | accuracy 66.025 | wps 6318.8 | ups 1.53 | wpb 4138.6 | bsz 152.8 | num_updates 41256 | lr 6.9626e-05 | gnorm 0.357 | clip 0 | loss_scale 64 | train_wall 883 | gb_free 16.7 | wall 31398
2023-07-09 18:56:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 18:56:47 | INFO | fairseq.trainer | begin training epoch 29
2023-07-09 18:56:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 18:57:22 | INFO | train_inner | epoch 029:     44 / 1474 loss=1.426, trans_loss=5.184, nll_loss=2.479, w2v_ctc_loss=0.412, task_loss=2.004, contrastive_loss=0.176, total=4168.25, n_correct=2767.42, ppl=5.58, accuracy=66.393, wps=4174.8, ups=1, wpb=4168.2, bsz=157.9, num_updates=41300, lr=6.95889e-05, gnorm=0.358, clip=0, loss_scale=64, train_wall=60, gb_free=17.8, wall=31434
2023-07-09 18:58:22 | INFO | train_inner | epoch 029:    144 / 1474 loss=1.425, trans_loss=5.178, nll_loss=2.47, w2v_ctc_loss=0.405, task_loss=2.056, contrastive_loss=0.236, total=4117.66, n_correct=2738, ppl=5.54, accuracy=66.494, wps=6817.1, ups=1.66, wpb=4117.7, bsz=154.2, num_updates=41400, lr=6.95048e-05, gnorm=0.357, clip=0, loss_scale=64, train_wall=60, gb_free=17.4, wall=31494
2023-07-09 18:59:23 | INFO | train_inner | epoch 029:    244 / 1474 loss=1.426, trans_loss=5.177, nll_loss=2.469, w2v_ctc_loss=0.402, task_loss=1.912, contrastive_loss=0.387, total=4198.99, n_correct=2789.38, ppl=5.54, accuracy=66.43, wps=6888.9, ups=1.64, wpb=4199, bsz=165.4, num_updates=41500, lr=6.9421e-05, gnorm=0.358, clip=0, loss_scale=64, train_wall=61, gb_free=15.5, wall=31555
2023-07-09 19:00:24 | INFO | train_inner | epoch 029:    344 / 1474 loss=1.43, trans_loss=5.2, nll_loss=2.499, w2v_ctc_loss=0.417, task_loss=2.25, contrastive_loss=0.151, total=4091.28, n_correct=2705.94, ppl=5.65, accuracy=66.139, wps=6731.4, ups=1.65, wpb=4091.3, bsz=145.2, num_updates=41600, lr=6.93375e-05, gnorm=0.362, clip=0, loss_scale=64, train_wall=60, gb_free=17.4, wall=31616
2023-07-09 19:01:24 | INFO | train_inner | epoch 029:    444 / 1474 loss=1.418, trans_loss=5.164, nll_loss=2.451, w2v_ctc_loss=0.404, task_loss=2.024, contrastive_loss=0.138, total=4158.09, n_correct=2772.94, ppl=5.47, accuracy=66.688, wps=6862.9, ups=1.65, wpb=4158.1, bsz=153.6, num_updates=41700, lr=6.92543e-05, gnorm=0.357, clip=0, loss_scale=128, train_wall=60, gb_free=16.1, wall=31676
2023-07-09 19:01:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-09 19:02:26 | INFO | train_inner | epoch 029:    545 / 1474 loss=1.434, trans_loss=5.203, nll_loss=2.502, w2v_ctc_loss=0.414, task_loss=2.242, contrastive_loss=0.212, total=4148.7, n_correct=2739.13, ppl=5.67, accuracy=66.024, wps=6753.2, ups=1.63, wpb=4148.7, bsz=145.8, num_updates=41800, lr=6.91714e-05, gnorm=0.358, clip=0, loss_scale=64, train_wall=61, gb_free=16.8, wall=31738
2023-07-09 19:03:26 | INFO | train_inner | epoch 029:    645 / 1474 loss=1.433, trans_loss=5.192, nll_loss=2.49, w2v_ctc_loss=0.41, task_loss=1.963, contrastive_loss=0.473, total=4143.76, n_correct=2743.5, ppl=5.62, accuracy=66.208, wps=6897.8, ups=1.66, wpb=4143.8, bsz=159.4, num_updates=41900, lr=6.90889e-05, gnorm=0.36, clip=0, loss_scale=64, train_wall=60, gb_free=17.4, wall=31798
2023-07-09 19:04:27 | INFO | train_inner | epoch 029:    745 / 1474 loss=1.424, trans_loss=5.183, nll_loss=2.477, w2v_ctc_loss=0.405, task_loss=1.943, contrastive_loss=0.314, total=4234.8, n_correct=2813.06, ppl=5.57, accuracy=66.427, wps=6897.8, ups=1.63, wpb=4234.8, bsz=164.1, num_updates=42000, lr=6.90066e-05, gnorm=0.351, clip=0, loss_scale=64, train_wall=61, gb_free=17, wall=31859
2023-07-09 19:04:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 19:04:52 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 2.288 | trans_loss 5.534 | nll_loss 2.834 | w2v_ctc_loss 0.69 | task_loss 2.365 | contrastive_loss 0.275 | total 4003.4 | n_correct 2494.2 | ppl 7.13 | accuracy 62.302 | uer 16.691 | wer 18.486 | raw_wer 18.486 | bleu 20.01 | wps 2218.1 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.26
2023-07-09 19:04:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-07-09 19:04:52 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_29_42000.pt
2023-07-09 19:04:54 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_29_42000.pt
2023-07-09 19:04:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 20.01) (writing took 5.120313182997052 seconds)
2023-07-09 19:05:57 | INFO | train_inner | epoch 029:    845 / 1474 loss=1.434, trans_loss=5.215, nll_loss=2.519, w2v_ctc_loss=0.413, task_loss=2.316, contrastive_loss=0.143, total=4033.21, n_correct=2654.43, ppl=5.73, accuracy=65.814, wps=4498.3, ups=1.12, wpb=4033.2, bsz=140.8, num_updates=42100, lr=6.89246e-05, gnorm=0.365, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=31949
2023-07-09 19:06:57 | INFO | train_inner | epoch 029:    945 / 1474 loss=1.428, trans_loss=5.203, nll_loss=2.502, w2v_ctc_loss=0.411, task_loss=2.13, contrastive_loss=0.159, total=4085.97, n_correct=2697.62, ppl=5.67, accuracy=66.022, wps=6753.5, ups=1.65, wpb=4086, bsz=148.4, num_updates=42200, lr=6.88428e-05, gnorm=0.358, clip=0, loss_scale=64, train_wall=60, gb_free=17.3, wall=32009
2023-07-09 19:07:57 | INFO | train_inner | epoch 029:   1045 / 1474 loss=1.427, trans_loss=5.193, nll_loss=2.49, w2v_ctc_loss=0.406, task_loss=2.101, contrastive_loss=0.311, total=4140.84, n_correct=2739.56, ppl=5.62, accuracy=66.16, wps=6893.6, ups=1.66, wpb=4140.8, bsz=153.4, num_updates=42300, lr=6.87614e-05, gnorm=0.356, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=32070
2023-07-09 19:08:58 | INFO | train_inner | epoch 029:   1145 / 1474 loss=1.43, trans_loss=5.208, nll_loss=2.509, w2v_ctc_loss=0.415, task_loss=2.269, contrastive_loss=0.133, total=4068.4, n_correct=2680.37, ppl=5.69, accuracy=65.883, wps=6763.6, ups=1.66, wpb=4068.4, bsz=142.1, num_updates=42400, lr=6.86803e-05, gnorm=0.358, clip=0, loss_scale=64, train_wall=60, gb_free=17.6, wall=32130
2023-07-09 19:09:58 | INFO | train_inner | epoch 029:   1245 / 1474 loss=1.432, trans_loss=5.214, nll_loss=2.517, w2v_ctc_loss=0.414, task_loss=2.138, contrastive_loss=0.151, total=4154.79, n_correct=2736.57, ppl=5.73, accuracy=65.865, wps=6864.5, ups=1.65, wpb=4154.8, bsz=149.8, num_updates=42500, lr=6.85994e-05, gnorm=0.356, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=32190
2023-07-09 19:10:59 | INFO | train_inner | epoch 029:   1345 / 1474 loss=1.43, trans_loss=5.193, nll_loss=2.491, w2v_ctc_loss=0.407, task_loss=2.053, contrastive_loss=0.283, total=4166.4, n_correct=2757.17, ppl=5.62, accuracy=66.176, wps=6863.3, ups=1.65, wpb=4166.4, bsz=155.8, num_updates=42600, lr=6.85189e-05, gnorm=0.358, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=32251
2023-07-09 19:11:59 | INFO | train_inner | epoch 029:   1445 / 1474 loss=1.431, trans_loss=5.198, nll_loss=2.499, w2v_ctc_loss=0.406, task_loss=2.055, contrastive_loss=0.343, total=4169.4, n_correct=2749.29, ppl=5.65, accuracy=65.94, wps=6956.9, ups=1.67, wpb=4169.4, bsz=156, num_updates=42700, lr=6.84386e-05, gnorm=0.355, clip=0, loss_scale=64, train_wall=60, gb_free=16.1, wall=32311
2023-07-09 19:12:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 19:12:41 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 2.285 | trans_loss 5.532 | nll_loss 2.827 | w2v_ctc_loss 0.687 | task_loss 2.365 | contrastive_loss 0.27 | total 4003.4 | n_correct 2500.2 | ppl 7.1 | accuracy 62.452 | uer 16.58 | wer 18.467 | raw_wer 18.467 | bleu 20.09 | wps 2132.6 | wpb 4003.4 | bsz 141.8 | num_updates 42729 | best_bleu 20.26
2023-07-09 19:12:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42729 updates
2023-07-09 19:12:41 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.0905.pt
2023-07-09 19:12:44 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.0905.pt
2023-07-09 19:12:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.0905.pt (epoch 29 @ 42729 updates, score 20.09) (writing took 5.4792183760146145 seconds)
2023-07-09 19:12:47 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-07-09 19:12:47 | INFO | train | epoch 029 | loss 1.429 | trans_loss 5.193 | nll_loss 2.491 | w2v_ctc_loss 0.409 | task_loss 2.094 | contrastive_loss 0.245 | total 4137.69 | n_correct 2738.1 | ppl 5.62 | accuracy 66.175 | wps 6345.7 | ups 1.53 | wpb 4137.7 | bsz 152.7 | num_updates 42729 | lr 6.84154e-05 | gnorm 0.358 | clip 0 | loss_scale 64 | train_wall 885 | gb_free 16.4 | wall 32359
2023-07-09 19:12:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 19:12:47 | INFO | fairseq.trainer | begin training epoch 30
2023-07-09 19:12:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 19:13:39 | INFO | train_inner | epoch 030:     71 / 1474 loss=1.425, trans_loss=5.177, nll_loss=2.47, w2v_ctc_loss=0.4, task_loss=1.991, contrastive_loss=0.377, total=4176.73, n_correct=2771.82, ppl=5.54, accuracy=66.363, wps=4186.8, ups=1, wpb=4176.7, bsz=159.5, num_updates=42800, lr=6.83586e-05, gnorm=0.36, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=32411
2023-07-09 19:14:39 | INFO | train_inner | epoch 030:    171 / 1474 loss=1.417, trans_loss=5.156, nll_loss=2.443, w2v_ctc_loss=0.404, task_loss=1.956, contrastive_loss=0.238, total=4202.84, n_correct=2810.21, ppl=5.44, accuracy=66.865, wps=7009.4, ups=1.67, wpb=4202.8, bsz=159.3, num_updates=42900, lr=6.82789e-05, gnorm=0.357, clip=0, loss_scale=64, train_wall=60, gb_free=13, wall=32471
2023-07-09 19:15:39 | INFO | train_inner | epoch 030:    271 / 1474 loss=1.421, trans_loss=5.171, nll_loss=2.46, w2v_ctc_loss=0.411, task_loss=2.148, contrastive_loss=0.146, total=4120.08, n_correct=2742.7, ppl=5.5, accuracy=66.569, wps=6847.3, ups=1.66, wpb=4120.1, bsz=148.2, num_updates=43000, lr=6.81994e-05, gnorm=0.356, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=32531
2023-07-09 19:16:40 | INFO | train_inner | epoch 030:    371 / 1474 loss=1.416, trans_loss=5.164, nll_loss=2.452, w2v_ctc_loss=0.401, task_loss=2.104, contrastive_loss=0.156, total=4175.82, n_correct=2787, ppl=5.47, accuracy=66.741, wps=6862.6, ups=1.64, wpb=4175.8, bsz=153.1, num_updates=43100, lr=6.81203e-05, gnorm=0.354, clip=0, loss_scale=64, train_wall=60, gb_free=15.8, wall=32592
2023-07-09 19:17:40 | INFO | train_inner | epoch 030:    471 / 1474 loss=1.422, trans_loss=5.174, nll_loss=2.466, w2v_ctc_loss=0.403, task_loss=2.004, contrastive_loss=0.281, total=4128.9, n_correct=2746.61, ppl=5.52, accuracy=66.522, wps=6878.8, ups=1.67, wpb=4128.9, bsz=156.2, num_updates=43200, lr=6.80414e-05, gnorm=0.36, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=32652
2023-07-09 19:18:40 | INFO | train_inner | epoch 030:    571 / 1474 loss=1.419, trans_loss=5.178, nll_loss=2.471, w2v_ctc_loss=0.399, task_loss=2.045, contrastive_loss=0.211, total=4162.83, n_correct=2768.33, ppl=5.54, accuracy=66.501, wps=6936.1, ups=1.67, wpb=4162.8, bsz=155.7, num_updates=43300, lr=6.79628e-05, gnorm=0.359, clip=0, loss_scale=64, train_wall=60, gb_free=15.3, wall=32712
2023-07-09 19:19:41 | INFO | train_inner | epoch 030:    671 / 1474 loss=1.421, trans_loss=5.177, nll_loss=2.47, w2v_ctc_loss=0.405, task_loss=2.035, contrastive_loss=0.238, total=4197.56, n_correct=2787.51, ppl=5.54, accuracy=66.408, wps=6856.3, ups=1.63, wpb=4197.6, bsz=158.8, num_updates=43400, lr=6.78844e-05, gnorm=0.358, clip=0, loss_scale=64, train_wall=61, gb_free=16.7, wall=32773
2023-07-09 19:20:41 | INFO | train_inner | epoch 030:    771 / 1474 loss=1.438, trans_loss=5.206, nll_loss=2.507, w2v_ctc_loss=0.413, task_loss=2.149, contrastive_loss=0.398, total=4097.27, n_correct=2704.88, ppl=5.69, accuracy=66.017, wps=6763.2, ups=1.65, wpb=4097.3, bsz=150.6, num_updates=43500, lr=6.78064e-05, gnorm=0.363, clip=0, loss_scale=64, train_wall=60, gb_free=15.1, wall=32833
2023-07-09 19:21:42 | INFO | train_inner | epoch 030:    871 / 1474 loss=1.425, trans_loss=5.192, nll_loss=2.489, w2v_ctc_loss=0.408, task_loss=2.183, contrastive_loss=0.159, total=4097.18, n_correct=2712.37, ppl=5.61, accuracy=66.201, wps=6799.6, ups=1.66, wpb=4097.2, bsz=146.1, num_updates=43600, lr=6.77285e-05, gnorm=0.357, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=32894
2023-07-09 19:22:42 | INFO | train_inner | epoch 030:    971 / 1474 loss=1.428, trans_loss=5.193, nll_loss=2.491, w2v_ctc_loss=0.411, task_loss=2.112, contrastive_loss=0.201, total=4140.12, n_correct=2737.19, ppl=5.62, accuracy=66.114, wps=6825.5, ups=1.65, wpb=4140.1, bsz=152.3, num_updates=43700, lr=6.7651e-05, gnorm=0.36, clip=0, loss_scale=64, train_wall=60, gb_free=15.5, wall=32954
2023-07-09 19:23:43 | INFO | train_inner | epoch 030:   1071 / 1474 loss=1.434, trans_loss=5.209, nll_loss=2.511, w2v_ctc_loss=0.41, task_loss=2.358, contrastive_loss=0.33, total=4099.61, n_correct=2702.3, ppl=5.7, accuracy=65.916, wps=6708.1, ups=1.64, wpb=4099.6, bsz=140.7, num_updates=43800, lr=6.75737e-05, gnorm=0.361, clip=0, loss_scale=128, train_wall=61, gb_free=17.5, wall=33015
2023-07-09 19:24:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-09 19:24:44 | INFO | train_inner | epoch 030:   1172 / 1474 loss=1.42, trans_loss=5.187, nll_loss=2.483, w2v_ctc_loss=0.403, task_loss=2.035, contrastive_loss=0.171, total=4150.45, n_correct=2751.56, ppl=5.59, accuracy=66.295, wps=6821.3, ups=1.64, wpb=4150.4, bsz=154.9, num_updates=43900, lr=6.74967e-05, gnorm=0.357, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=33076
2023-07-09 19:25:45 | INFO | train_inner | epoch 030:   1272 / 1474 loss=1.428, trans_loss=5.206, nll_loss=2.507, w2v_ctc_loss=0.412, task_loss=2.352, contrastive_loss=0.163, total=4032.74, n_correct=2658.75, ppl=5.68, accuracy=65.929, wps=6629.7, ups=1.64, wpb=4032.7, bsz=140.9, num_updates=44000, lr=6.742e-05, gnorm=0.369, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=33137
2023-07-09 19:25:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 19:26:11 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 2.283 | trans_loss 5.534 | nll_loss 2.832 | w2v_ctc_loss 0.683 | task_loss 2.365 | contrastive_loss 0.277 | total 4003.4 | n_correct 2496.7 | ppl 7.12 | accuracy 62.364 | uer 16.638 | wer 18.377 | raw_wer 18.377 | bleu 20.24 | wps 2007.2 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.26
2023-07-09 19:26:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-07-09 19:26:11 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_30_44000.pt
2023-07-09 19:26:13 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_30_44000.pt
2023-07-09 19:26:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 20.24) (writing took 6.126777950004907 seconds)
2023-07-09 19:27:18 | INFO | train_inner | epoch 030:   1372 / 1474 loss=1.42, trans_loss=5.186, nll_loss=2.483, w2v_ctc_loss=0.403, task_loss=1.957, contrastive_loss=0.191, total=4166.96, n_correct=2762.81, ppl=5.59, accuracy=66.303, wps=4501.9, ups=1.08, wpb=4167, bsz=161.1, num_updates=44100, lr=6.73435e-05, gnorm=0.358, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=33230
2023-07-09 19:28:18 | INFO | train_inner | epoch 030:   1472 / 1474 loss=1.431, trans_loss=5.191, nll_loss=2.489, w2v_ctc_loss=0.401, task_loss=2, contrastive_loss=0.479, total=4125.17, n_correct=2730.56, ppl=5.61, accuracy=66.193, wps=6852.3, ups=1.66, wpb=4125.2, bsz=155, num_updates=44200, lr=6.72673e-05, gnorm=0.361, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=33290
2023-07-09 19:28:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 19:28:44 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 2.284 | trans_loss 5.534 | nll_loss 2.834 | w2v_ctc_loss 0.684 | task_loss 2.365 | contrastive_loss 0.285 | total 4003.4 | n_correct 2495.5 | ppl 7.13 | accuracy 62.335 | uer 16.845 | wer 18.657 | raw_wer 18.657 | bleu 20.35 | wps 2168.9 | wpb 4003.4 | bsz 141.8 | num_updates 44202 | best_bleu 20.35
2023-07-09 19:28:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44202 updates
2023-07-09 19:28:44 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 19:28:48 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 19:28:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt (epoch 30 @ 44202 updates, score 20.35) (writing took 8.313713691022713 seconds)
2023-07-09 19:28:52 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-07-09 19:28:52 | INFO | train | epoch 030 | loss 1.424 | trans_loss 5.184 | nll_loss 2.479 | w2v_ctc_loss 0.405 | task_loss 2.094 | contrastive_loss 0.251 | total 4137.63 | n_correct 2744.84 | ppl 5.58 | accuracy 66.339 | wps 6311.7 | ups 1.53 | wpb 4137.6 | bsz 152.7 | num_updates 44202 | lr 6.72658e-05 | gnorm 0.359 | clip 0 | loss_scale 64 | train_wall 885 | gb_free 17.2 | wall 33324
2023-07-09 19:28:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 19:28:53 | INFO | fairseq.trainer | begin training epoch 31
2023-07-09 19:28:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 19:30:00 | INFO | train_inner | epoch 031:     98 / 1474 loss=1.417, trans_loss=5.167, nll_loss=2.456, w2v_ctc_loss=0.407, task_loss=2.166, contrastive_loss=0.167, total=4081.34, n_correct=2719.5, ppl=5.49, accuracy=66.633, wps=3992.8, ups=0.98, wpb=4081.3, bsz=147.3, num_updates=44300, lr=6.71913e-05, gnorm=0.369, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=33392
2023-07-09 19:31:01 | INFO | train_inner | epoch 031:    198 / 1474 loss=1.418, trans_loss=5.167, nll_loss=2.457, w2v_ctc_loss=0.403, task_loss=2.139, contrastive_loss=0.213, total=4146.03, n_correct=2761.19, ppl=5.49, accuracy=66.598, wps=6836.3, ups=1.65, wpb=4146, bsz=151.1, num_updates=44400, lr=6.71156e-05, gnorm=0.358, clip=0, loss_scale=64, train_wall=60, gb_free=13.7, wall=33453
2023-07-09 19:32:02 | INFO | train_inner | epoch 031:    298 / 1474 loss=1.421, trans_loss=5.171, nll_loss=2.461, w2v_ctc_loss=0.403, task_loss=2.155, contrastive_loss=0.291, total=4146.75, n_correct=2760.23, ppl=5.51, accuracy=66.564, wps=6730.5, ups=1.62, wpb=4146.8, bsz=150.4, num_updates=44500, lr=6.70402e-05, gnorm=0.362, clip=0, loss_scale=64, train_wall=61, gb_free=17.7, wall=33514
2023-07-09 19:33:04 | INFO | train_inner | epoch 031:    398 / 1474 loss=1.419, trans_loss=5.172, nll_loss=2.462, w2v_ctc_loss=0.402, task_loss=2.292, contrastive_loss=0.164, total=4089.43, n_correct=2718.32, ppl=5.51, accuracy=66.472, wps=6687.9, ups=1.64, wpb=4089.4, bsz=142.8, num_updates=44600, lr=6.6965e-05, gnorm=0.359, clip=0, loss_scale=64, train_wall=61, gb_free=16.3, wall=33576
2023-07-09 19:34:05 | INFO | train_inner | epoch 031:    498 / 1474 loss=1.416, trans_loss=5.164, nll_loss=2.452, w2v_ctc_loss=0.403, task_loss=2.177, contrastive_loss=0.181, total=4114.41, n_correct=2741.1, ppl=5.47, accuracy=66.622, wps=6724.6, ups=1.63, wpb=4114.4, bsz=150.4, num_updates=44700, lr=6.689e-05, gnorm=0.358, clip=0, loss_scale=64, train_wall=61, gb_free=16.3, wall=33637
2023-07-09 19:35:05 | INFO | train_inner | epoch 031:    598 / 1474 loss=1.421, trans_loss=5.178, nll_loss=2.472, w2v_ctc_loss=0.405, task_loss=2.18, contrastive_loss=0.166, total=4084.36, n_correct=2711.09, ppl=5.55, accuracy=66.377, wps=6768.2, ups=1.66, wpb=4084.4, bsz=147.5, num_updates=44800, lr=6.68153e-05, gnorm=0.364, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=33697
2023-07-09 19:36:06 | INFO | train_inner | epoch 031:    698 / 1474 loss=1.413, trans_loss=5.165, nll_loss=2.454, w2v_ctc_loss=0.398, task_loss=1.998, contrastive_loss=0.169, total=4210.09, n_correct=2801.87, ppl=5.48, accuracy=66.551, wps=6941.3, ups=1.65, wpb=4210.1, bsz=157.4, num_updates=44900, lr=6.67409e-05, gnorm=0.355, clip=0, loss_scale=64, train_wall=60, gb_free=15, wall=33758
2023-07-09 19:37:06 | INFO | train_inner | epoch 031:    798 / 1474 loss=1.421, trans_loss=5.186, nll_loss=2.482, w2v_ctc_loss=0.401, task_loss=2.191, contrastive_loss=0.306, total=4098.1, n_correct=2713.34, ppl=5.59, accuracy=66.21, wps=6754.8, ups=1.65, wpb=4098.1, bsz=147.8, num_updates=45000, lr=6.66667e-05, gnorm=0.362, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=33818
tensor(0.0221, device='cuda:0')
tensor(0.0008, device='cuda:0')
2023-07-09 19:38:07 | INFO | train_inner | epoch 031:    898 / 1474 loss=1.419, trans_loss=5.174, nll_loss=2.466, w2v_ctc_loss=0.402, task_loss=2.177, contrastive_loss=0.198, total=4101.05, n_correct=2723.75, ppl=5.52, accuracy=66.416, wps=6756.6, ups=1.65, wpb=4101.1, bsz=148.4, num_updates=45100, lr=6.65927e-05, gnorm=0.364, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=33879
2023-07-09 19:39:08 | INFO | train_inner | epoch 031:    998 / 1474 loss=1.426, trans_loss=5.182, nll_loss=2.477, w2v_ctc_loss=0.4, task_loss=1.971, contrastive_loss=0.37, total=4186.3, n_correct=2782.12, ppl=5.57, accuracy=66.458, wps=6916.8, ups=1.65, wpb=4186.3, bsz=159.3, num_updates=45200, lr=6.6519e-05, gnorm=0.359, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=33940
2023-07-09 19:40:08 | INFO | train_inner | epoch 031:   1098 / 1474 loss=1.423, trans_loss=5.187, nll_loss=2.484, w2v_ctc_loss=0.403, task_loss=2.065, contrastive_loss=0.267, total=4147.34, n_correct=2747.42, ppl=5.59, accuracy=66.245, wps=6837, ups=1.65, wpb=4147.3, bsz=157.3, num_updates=45300, lr=6.64455e-05, gnorm=0.364, clip=0, loss_scale=64, train_wall=60, gb_free=17.3, wall=34000
2023-07-09 19:41:08 | INFO | train_inner | epoch 031:   1198 / 1474 loss=1.432, trans_loss=5.192, nll_loss=2.491, w2v_ctc_loss=0.405, task_loss=1.944, contrastive_loss=0.495, total=4185.34, n_correct=2769.64, ppl=5.62, accuracy=66.175, wps=6983.6, ups=1.67, wpb=4185.3, bsz=160.8, num_updates=45400, lr=6.63723e-05, gnorm=0.359, clip=0, loss_scale=64, train_wall=59, gb_free=17.2, wall=34060
2023-07-09 19:42:09 | INFO | train_inner | epoch 031:   1298 / 1474 loss=1.419, trans_loss=5.18, nll_loss=2.476, w2v_ctc_loss=0.402, task_loss=1.88, contrastive_loss=0.185, total=4223.54, n_correct=2804.41, ppl=5.56, accuracy=66.4, wps=6984.5, ups=1.65, wpb=4223.5, bsz=162.5, num_updates=45500, lr=6.62994e-05, gnorm=0.358, clip=0, loss_scale=64, train_wall=60, gb_free=13.9, wall=34121
2023-07-09 19:43:10 | INFO | train_inner | epoch 031:   1398 / 1474 loss=1.43, trans_loss=5.189, nll_loss=2.487, w2v_ctc_loss=0.402, task_loss=1.903, contrastive_loss=0.587, total=4195.76, n_correct=2784.07, ppl=5.6, accuracy=66.354, wps=6875.7, ups=1.64, wpb=4195.8, bsz=164.1, num_updates=45600, lr=6.62266e-05, gnorm=0.359, clip=0, loss_scale=64, train_wall=61, gb_free=16.8, wall=34182
2023-07-09 19:43:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0221, device='cuda:6')
tensor(0.0008, device='cuda:6')
tensor(0.0221, device='cuda:4')
tensor(0.0008, device='cuda:4')
tensor(0.0221, device='cuda:1')
tensor(0.0008, device='cuda:1')
tensor(0.0221, device='cuda:5')
tensor(0.0008, device='cuda:5')
tensor(0.0221, device='cuda:2')
tensor(0.0008, device='cuda:2')
tensor(0.0221, device='cuda:3')
tensor(0.0008, device='cuda:3')
tensor(0.0221, device='cuda:7')
tensor(0.0008, device='cuda:7')
2023-07-09 19:44:22 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 2.279 | trans_loss 5.532 | nll_loss 2.832 | w2v_ctc_loss 0.679 | task_loss 2.365 | contrastive_loss 0.282 | total 4003.4 | n_correct 2499.7 | ppl 7.12 | accuracy 62.439 | uer 16.449 | wer 18.239 | raw_wer 18.239 | bleu 20.44 | wps 2192.6 | wpb 4003.4 | bsz 141.8 | num_updates 45676 | best_bleu 20.44
2023-07-09 19:44:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45676 updates
2023-07-09 19:44:22 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 19:44:26 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt
2023-07-09 19:44:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_best.pt (epoch 31 @ 45676 updates, score 20.44) (writing took 8.179021263000323 seconds)
2023-07-09 19:44:30 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-07-09 19:44:30 | INFO | train | epoch 031 | loss 1.421 | trans_loss 5.177 | nll_loss 2.47 | w2v_ctc_loss 0.403 | task_loss 2.092 | contrastive_loss 0.266 | total 4138.65 | n_correct 2749.09 | ppl 5.54 | accuracy 66.425 | wps 6504.8 | ups 1.57 | wpb 4138.6 | bsz 152.8 | num_updates 45676 | lr 6.61715e-05 | gnorm 0.361 | clip 0 | loss_scale 64 | train_wall 888 | gb_free 12.5 | wall 34262
2023-07-09 19:44:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 19:44:31 | INFO | fairseq.trainer | begin training epoch 32
2023-07-09 19:44:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 19:44:53 | INFO | train_inner | epoch 032:     24 / 1474 loss=1.417, trans_loss=5.174, nll_loss=2.467, w2v_ctc_loss=0.401, task_loss=2.223, contrastive_loss=0.158, total=4039.04, n_correct=2685.65, ppl=5.53, accuracy=66.492, wps=3919.2, ups=0.97, wpb=4039, bsz=143.6, num_updates=45700, lr=6.61541e-05, gnorm=0.365, clip=0, loss_scale=64, train_wall=60, gb_free=17.9, wall=34285
2023-07-09 19:45:54 | INFO | train_inner | epoch 032:    124 / 1474 loss=1.401, trans_loss=5.131, nll_loss=2.411, w2v_ctc_loss=0.386, task_loss=1.942, contrastive_loss=0.189, total=4224.84, n_correct=2841.43, ppl=5.32, accuracy=67.255, wps=6903.7, ups=1.63, wpb=4224.8, bsz=161.2, num_updates=45800, lr=6.60819e-05, gnorm=0.354, clip=0, loss_scale=64, train_wall=61, gb_free=16.7, wall=34346
2023-07-09 19:46:55 | INFO | train_inner | epoch 032:    224 / 1474 loss=1.408, trans_loss=5.154, nll_loss=2.44, w2v_ctc_loss=0.396, task_loss=1.983, contrastive_loss=0.211, total=4163.01, n_correct=2779.86, ppl=5.43, accuracy=66.775, wps=6844.1, ups=1.64, wpb=4163, bsz=161.1, num_updates=45900, lr=6.60098e-05, gnorm=0.361, clip=0, loss_scale=128, train_wall=60, gb_free=17.3, wall=34407
2023-07-09 19:47:55 | INFO | train_inner | epoch 032:    324 / 1474 loss=1.408, trans_loss=5.14, nll_loss=2.422, w2v_ctc_loss=0.393, task_loss=1.973, contrastive_loss=0.197, total=4185.21, n_correct=2807.02, ppl=5.36, accuracy=67.07, wps=6971.6, ups=1.67, wpb=4185.2, bsz=157.5, num_updates=46000, lr=6.5938e-05, gnorm=0.356, clip=0, loss_scale=128, train_wall=60, gb_free=16.6, wall=34467
2023-07-09 19:47:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 19:48:20 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 2.284 | trans_loss 5.539 | nll_loss 2.84 | w2v_ctc_loss 0.686 | task_loss 2.365 | contrastive_loss 0.289 | total 4003.4 | n_correct 2490.8 | ppl 7.16 | accuracy 62.217 | uer 16.468 | wer 18.172 | raw_wer 18.172 | bleu 20.03 | wps 2163.8 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.44
2023-07-09 19:48:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-07-09 19:48:20 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_32_46000.pt
2023-07-09 19:48:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_32_46000.pt
2023-07-09 19:48:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 20.03) (writing took 5.09472750799614 seconds)
2023-07-09 19:49:26 | INFO | train_inner | epoch 032:    424 / 1474 loss=1.41, trans_loss=5.151, nll_loss=2.437, w2v_ctc_loss=0.395, task_loss=2.083, contrastive_loss=0.187, total=4156.71, n_correct=2779.65, ppl=5.41, accuracy=66.871, wps=4569.6, ups=1.1, wpb=4156.7, bsz=152.8, num_updates=46100, lr=6.58665e-05, gnorm=0.362, clip=0, loss_scale=128, train_wall=60, gb_free=11.3, wall=34558
2023-07-09 19:50:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-09 19:50:28 | INFO | train_inner | epoch 032:    525 / 1474 loss=1.414, trans_loss=5.16, nll_loss=2.448, w2v_ctc_loss=0.4, task_loss=2.076, contrastive_loss=0.228, total=4176.43, n_correct=2785.61, ppl=5.46, accuracy=66.698, wps=6749.3, ups=1.62, wpb=4176.4, bsz=155.4, num_updates=46200, lr=6.57952e-05, gnorm=0.359, clip=0, loss_scale=64, train_wall=61, gb_free=17.4, wall=34620
2023-07-09 19:51:29 | INFO | train_inner | epoch 032:    625 / 1474 loss=1.418, trans_loss=5.174, nll_loss=2.466, w2v_ctc_loss=0.404, task_loss=2.157, contrastive_loss=0.208, total=4142.69, n_correct=2753.41, ppl=5.52, accuracy=66.464, wps=6771.7, ups=1.63, wpb=4142.7, bsz=150.8, num_updates=46300, lr=6.57241e-05, gnorm=0.363, clip=0, loss_scale=64, train_wall=61, gb_free=17.5, wall=34681
2023-07-09 19:52:30 | INFO | train_inner | epoch 032:    725 / 1474 loss=1.42, trans_loss=5.174, nll_loss=2.466, w2v_ctc_loss=0.407, task_loss=2.138, contrastive_loss=0.172, total=4154.59, n_correct=2764.72, ppl=5.53, accuracy=66.546, wps=6825.4, ups=1.64, wpb=4154.6, bsz=150.9, num_updates=46400, lr=6.56532e-05, gnorm=0.362, clip=0, loss_scale=64, train_wall=60, gb_free=16.2, wall=34742
2023-07-09 19:53:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-09 19:53:30 | INFO | train_inner | epoch 032:    826 / 1474 loss=1.412, trans_loss=5.165, nll_loss=2.455, w2v_ctc_loss=0.397, task_loss=2.177, contrastive_loss=0.165, total=4111.84, n_correct=2738.84, ppl=5.48, accuracy=66.609, wps=6794.7, ups=1.65, wpb=4111.8, bsz=146.7, num_updates=46500, lr=6.55826e-05, gnorm=0.36, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=34802
2023-07-09 19:54:31 | INFO | train_inner | epoch 032:    926 / 1474 loss=1.416, trans_loss=5.17, nll_loss=2.461, w2v_ctc_loss=0.398, task_loss=2.168, contrastive_loss=0.167, total=4139.37, n_correct=2756.17, ppl=5.51, accuracy=66.584, wps=6827.6, ups=1.65, wpb=4139.4, bsz=149.3, num_updates=46600, lr=6.55122e-05, gnorm=0.359, clip=0, loss_scale=32, train_wall=60, gb_free=13.2, wall=34863
2023-07-09 19:55:32 | INFO | train_inner | epoch 032:   1026 / 1474 loss=1.416, trans_loss=5.172, nll_loss=2.464, w2v_ctc_loss=0.395, task_loss=2.052, contrastive_loss=0.346, total=4121.85, n_correct=2745.04, ppl=5.52, accuracy=66.597, wps=6774.6, ups=1.64, wpb=4121.9, bsz=153, num_updates=46700, lr=6.5442e-05, gnorm=0.357, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=34924
2023-07-09 19:56:32 | INFO | train_inner | epoch 032:   1126 / 1474 loss=1.424, trans_loss=5.189, nll_loss=2.485, w2v_ctc_loss=0.404, task_loss=2.493, contrastive_loss=0.234, total=4015.59, n_correct=2656.31, ppl=5.6, accuracy=66.15, wps=6633.2, ups=1.65, wpb=4015.6, bsz=135.1, num_updates=46800, lr=6.5372e-05, gnorm=0.369, clip=0, loss_scale=32, train_wall=60, gb_free=17.4, wall=34984
2023-07-09 19:57:33 | INFO | train_inner | epoch 032:   1226 / 1474 loss=1.43, trans_loss=5.192, nll_loss=2.491, w2v_ctc_loss=0.401, task_loss=2.052, contrastive_loss=0.45, total=4153.44, n_correct=2749.85, ppl=5.62, accuracy=66.207, wps=6851.4, ups=1.65, wpb=4153.4, bsz=155.4, num_updates=46900, lr=6.53023e-05, gnorm=0.368, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=35045
2023-07-09 19:58:33 | INFO | train_inner | epoch 032:   1326 / 1474 loss=1.421, trans_loss=5.183, nll_loss=2.478, w2v_ctc_loss=0.405, task_loss=2.156, contrastive_loss=0.168, total=4075.86, n_correct=2705.47, ppl=5.57, accuracy=66.378, wps=6756.6, ups=1.66, wpb=4075.9, bsz=147.7, num_updates=47000, lr=6.52328e-05, gnorm=0.365, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=35105
2023-07-09 19:59:34 | INFO | train_inner | epoch 032:   1426 / 1474 loss=1.433, trans_loss=5.191, nll_loss=2.489, w2v_ctc_loss=0.407, task_loss=2.089, contrastive_loss=0.628, total=4116.4, n_correct=2727.54, ppl=5.61, accuracy=66.26, wps=6813.7, ups=1.66, wpb=4116.4, bsz=153.8, num_updates=47100, lr=6.51635e-05, gnorm=0.364, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=35166
2023-07-09 20:00:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 20:00:27 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 2.286 | trans_loss 5.536 | nll_loss 2.836 | w2v_ctc_loss 0.7 | task_loss 2.365 | contrastive_loss 0.292 | total 4003.4 | n_correct 2495.2 | ppl 7.14 | accuracy 62.327 | uer 16.81 | wer 18.843 | raw_wer 18.843 | bleu 20.12 | wps 2106.2 | wpb 4003.4 | bsz 141.8 | num_updates 47148 | best_bleu 20.44
2023-07-09 20:00:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47148 updates
2023-07-09 20:00:27 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.1208.pt
2023-07-09 20:00:30 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.1208.pt
2023-07-09 20:00:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.1208.pt (epoch 32 @ 47148 updates, score 20.12) (writing took 5.220241511997301 seconds)
2023-07-09 20:00:33 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-07-09 20:00:33 | INFO | train | epoch 032 | loss 1.417 | trans_loss 5.168 | nll_loss 2.458 | w2v_ctc_loss 0.399 | task_loss 2.095 | contrastive_loss 0.264 | total 4137.33 | n_correct 2755.85 | ppl 5.49 | accuracy 66.61 | wps 6326.4 | ups 1.53 | wpb 4137.3 | bsz 152.6 | num_updates 47148 | lr 6.51303e-05 | gnorm 0.362 | clip 0 | loss_scale 32 | train_wall 887 | gb_free 16.8 | wall 35225
2023-07-09 20:00:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 20:00:33 | INFO | fairseq.trainer | begin training epoch 33
2023-07-09 20:00:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 20:01:13 | INFO | train_inner | epoch 033:     52 / 1474 loss=1.419, trans_loss=5.165, nll_loss=2.456, w2v_ctc_loss=0.398, task_loss=1.967, contrastive_loss=0.375, total=4149.21, n_correct=2767.21, ppl=5.49, accuracy=66.692, wps=4173.4, ups=1.01, wpb=4149.2, bsz=160.3, num_updates=47200, lr=6.50945e-05, gnorm=0.362, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=35265
2023-07-09 20:02:14 | INFO | train_inner | epoch 033:    152 / 1474 loss=1.401, trans_loss=5.139, nll_loss=2.421, w2v_ctc_loss=0.386, task_loss=2.252, contrastive_loss=0.142, total=4073.9, n_correct=2734.04, ppl=5.35, accuracy=67.111, wps=6673.3, ups=1.64, wpb=4073.9, bsz=142.4, num_updates=47300, lr=6.50256e-05, gnorm=0.357, clip=0, loss_scale=32, train_wall=61, gb_free=15.5, wall=35326
2023-07-09 20:03:15 | INFO | train_inner | epoch 033:    252 / 1474 loss=1.412, trans_loss=5.144, nll_loss=2.43, w2v_ctc_loss=0.391, task_loss=1.779, contrastive_loss=0.504, total=4280.14, n_correct=2871.65, ppl=5.39, accuracy=67.092, wps=7035.4, ups=1.64, wpb=4280.1, bsz=173.2, num_updates=47400, lr=6.4957e-05, gnorm=0.358, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=35387
2023-07-09 20:04:16 | INFO | train_inner | epoch 033:    352 / 1474 loss=1.416, trans_loss=5.156, nll_loss=2.443, w2v_ctc_loss=0.4, task_loss=2.144, contrastive_loss=0.213, total=4120.27, n_correct=2753.83, ppl=5.44, accuracy=66.836, wps=6786.9, ups=1.65, wpb=4120.3, bsz=150.3, num_updates=47500, lr=6.48886e-05, gnorm=0.363, clip=0, loss_scale=32, train_wall=60, gb_free=17.4, wall=35448
2023-07-09 20:05:16 | INFO | train_inner | epoch 033:    452 / 1474 loss=1.404, trans_loss=5.134, nll_loss=2.414, w2v_ctc_loss=0.391, task_loss=1.976, contrastive_loss=0.167, total=4141.22, n_correct=2779.52, ppl=5.33, accuracy=67.118, wps=6912.4, ups=1.67, wpb=4141.2, bsz=155.4, num_updates=47600, lr=6.48204e-05, gnorm=0.362, clip=0, loss_scale=32, train_wall=59, gb_free=16.6, wall=35508
2023-07-09 20:06:16 | INFO | train_inner | epoch 033:    552 / 1474 loss=1.417, trans_loss=5.163, nll_loss=2.452, w2v_ctc_loss=0.398, task_loss=2.174, contrastive_loss=0.21, total=4133.59, n_correct=2753, ppl=5.47, accuracy=66.601, wps=6807.1, ups=1.65, wpb=4133.6, bsz=147, num_updates=47700, lr=6.47524e-05, gnorm=0.364, clip=0, loss_scale=32, train_wall=60, gb_free=15.5, wall=35568
2023-07-09 20:07:17 | INFO | train_inner | epoch 033:    652 / 1474 loss=1.417, trans_loss=5.173, nll_loss=2.465, w2v_ctc_loss=0.398, task_loss=2.145, contrastive_loss=0.275, total=4157.63, n_correct=2762.82, ppl=5.52, accuracy=66.452, wps=6885.7, ups=1.66, wpb=4157.6, bsz=150.8, num_updates=47800, lr=6.46846e-05, gnorm=0.362, clip=0, loss_scale=32, train_wall=60, gb_free=17.8, wall=35629
2023-07-09 20:08:17 | INFO | train_inner | epoch 033:    752 / 1474 loss=1.421, trans_loss=5.178, nll_loss=2.471, w2v_ctc_loss=0.408, task_loss=2.27, contrastive_loss=0.17, total=4070.75, n_correct=2700.83, ppl=5.54, accuracy=66.347, wps=6705.6, ups=1.65, wpb=4070.8, bsz=143.6, num_updates=47900, lr=6.46171e-05, gnorm=0.37, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=35689
2023-07-09 20:09:18 | INFO | train_inner | epoch 033:    852 / 1474 loss=1.41, trans_loss=5.158, nll_loss=2.447, w2v_ctc_loss=0.392, task_loss=1.997, contrastive_loss=0.316, total=4130.24, n_correct=2760.48, ppl=5.45, accuracy=66.836, wps=6863.2, ups=1.66, wpb=4130.2, bsz=158.2, num_updates=48000, lr=6.45497e-05, gnorm=0.361, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=35750
2023-07-09 20:09:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 20:09:42 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 2.282 | trans_loss 5.539 | nll_loss 2.838 | w2v_ctc_loss 0.688 | task_loss 2.365 | contrastive_loss 0.294 | total 4003.4 | n_correct 2488.1 | ppl 7.15 | accuracy 62.15 | uer 16.755 | wer 18.463 | raw_wer 18.463 | bleu 19.74 | wps 2202.1 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.44
2023-07-09 20:09:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-07-09 20:09:42 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_33_48000.pt
2023-07-09 20:09:44 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_33_48000.pt
2023-07-09 20:09:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 19.74) (writing took 5.045488829986425 seconds)
2023-07-09 20:10:48 | INFO | train_inner | epoch 033:    952 / 1474 loss=1.413, trans_loss=5.166, nll_loss=2.457, w2v_ctc_loss=0.401, task_loss=2.092, contrastive_loss=0.201, total=4151.18, n_correct=2768.46, ppl=5.49, accuracy=66.691, wps=4595.3, ups=1.11, wpb=4151.2, bsz=154.1, num_updates=48100, lr=6.44826e-05, gnorm=0.363, clip=0, loss_scale=32, train_wall=60, gb_free=11.6, wall=35840
2023-07-09 20:11:50 | INFO | train_inner | epoch 033:   1052 / 1474 loss=1.42, trans_loss=5.166, nll_loss=2.457, w2v_ctc_loss=0.401, task_loss=2.104, contrastive_loss=0.4, total=4140.1, n_correct=2757.57, ppl=5.49, accuracy=66.606, wps=6727, ups=1.62, wpb=4140.1, bsz=153.8, num_updates=48200, lr=6.44157e-05, gnorm=0.361, clip=0, loss_scale=32, train_wall=61, gb_free=12.1, wall=35902
2023-07-09 20:12:50 | INFO | train_inner | epoch 033:   1152 / 1474 loss=1.418, trans_loss=5.171, nll_loss=2.462, w2v_ctc_loss=0.393, task_loss=2.09, contrastive_loss=0.383, total=4182.67, n_correct=2780.81, ppl=5.51, accuracy=66.484, wps=6894.1, ups=1.65, wpb=4182.7, bsz=154.7, num_updates=48300, lr=6.43489e-05, gnorm=0.362, clip=0, loss_scale=32, train_wall=60, gb_free=17.7, wall=35962
2023-07-09 20:13:51 | INFO | train_inner | epoch 033:   1252 / 1474 loss=1.415, trans_loss=5.173, nll_loss=2.465, w2v_ctc_loss=0.404, task_loss=2.207, contrastive_loss=0.184, total=4110.02, n_correct=2732.78, ppl=5.52, accuracy=66.491, wps=6774.7, ups=1.65, wpb=4110, bsz=147.2, num_updates=48400, lr=6.42824e-05, gnorm=0.369, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=36023
2023-07-09 20:14:52 | INFO | train_inner | epoch 033:   1352 / 1474 loss=1.41, trans_loss=5.165, nll_loss=2.457, w2v_ctc_loss=0.398, task_loss=2.045, contrastive_loss=0.226, total=4128.82, n_correct=2752.32, ppl=5.49, accuracy=66.661, wps=6749.5, ups=1.63, wpb=4128.8, bsz=156.2, num_updates=48500, lr=6.42161e-05, gnorm=0.36, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=36084
2023-07-09 20:15:53 | INFO | train_inner | epoch 033:   1452 / 1474 loss=1.422, trans_loss=5.172, nll_loss=2.465, w2v_ctc_loss=0.395, task_loss=2.072, contrastive_loss=0.518, total=4123.47, n_correct=2745.95, ppl=5.52, accuracy=66.593, wps=6760.3, ups=1.64, wpb=4123.5, bsz=154.4, num_updates=48600, lr=6.415e-05, gnorm=0.366, clip=0, loss_scale=64, train_wall=61, gb_free=16.7, wall=36145
2023-07-09 20:16:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 20:16:32 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 2.285 | trans_loss 5.541 | nll_loss 2.842 | w2v_ctc_loss 0.695 | task_loss 2.365 | contrastive_loss 0.293 | total 4003.4 | n_correct 2487.5 | ppl 7.17 | accuracy 62.135 | uer 16.736 | wer 18.623 | raw_wer 18.623 | bleu 19.85 | wps 2065.1 | wpb 4003.4 | bsz 141.8 | num_updates 48622 | best_bleu 20.44
2023-07-09 20:16:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48622 updates
2023-07-09 20:16:32 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_last.pt
2023-07-09 20:16:36 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_last.pt
2023-07-09 20:16:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_last.pt (epoch 33 @ 48622 updates, score 19.85) (writing took 4.212205934978556 seconds)
2023-07-09 20:16:36 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-07-09 20:16:36 | INFO | train | epoch 033 | loss 1.414 | trans_loss 5.161 | nll_loss 2.45 | w2v_ctc_loss 0.397 | task_loss 2.092 | contrastive_loss 0.277 | total 4138.65 | n_correct 2761.13 | ppl 5.46 | accuracy 66.716 | wps 6333.7 | ups 1.53 | wpb 4138.6 | bsz 152.8 | num_updates 48622 | lr 6.41355e-05 | gnorm 0.362 | clip 0 | loss_scale 64 | train_wall 888 | gb_free 17.9 | wall 36188
2023-07-09 20:16:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 20:16:36 | INFO | fairseq.trainer | begin training epoch 34
2023-07-09 20:16:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 20:17:32 | INFO | train_inner | epoch 034:     78 / 1474 loss=1.406, trans_loss=5.141, nll_loss=2.424, w2v_ctc_loss=0.394, task_loss=2.068, contrastive_loss=0.187, total=4128.94, n_correct=2766.9, ppl=5.37, accuracy=67.012, wps=4163.3, ups=1.01, wpb=4128.9, bsz=151.1, num_updates=48700, lr=6.40841e-05, gnorm=0.359, clip=0, loss_scale=64, train_wall=60, gb_free=15.4, wall=36244
2023-07-09 20:18:33 | INFO | train_inner | epoch 034:    178 / 1474 loss=1.407, trans_loss=5.142, nll_loss=2.424, w2v_ctc_loss=0.398, task_loss=2.185, contrastive_loss=0.192, total=4071.22, n_correct=2727.03, ppl=5.37, accuracy=66.983, wps=6680.4, ups=1.64, wpb=4071.2, bsz=147.6, num_updates=48800, lr=6.40184e-05, gnorm=0.364, clip=0, loss_scale=64, train_wall=61, gb_free=15.8, wall=36305
2023-07-09 20:18:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-09 20:19:35 | INFO | train_inner | epoch 034:    279 / 1474 loss=1.414, trans_loss=5.152, nll_loss=2.439, w2v_ctc_loss=0.393, task_loss=2.008, contrastive_loss=0.409, total=4222.46, n_correct=2824.91, ppl=5.42, accuracy=66.902, wps=6826.2, ups=1.62, wpb=4222.5, bsz=160.3, num_updates=48900, lr=6.39529e-05, gnorm=0.36, clip=0, loss_scale=32, train_wall=61, gb_free=17.9, wall=36367
2023-07-09 20:20:36 | INFO | train_inner | epoch 034:    379 / 1474 loss=1.409, trans_loss=5.138, nll_loss=2.42, w2v_ctc_loss=0.391, task_loss=1.987, contrastive_loss=0.385, total=4156.17, n_correct=2793.78, ppl=5.35, accuracy=67.22, wps=6847.8, ups=1.65, wpb=4156.2, bsz=158.4, num_updates=49000, lr=6.38877e-05, gnorm=0.362, clip=0, loss_scale=32, train_wall=60, gb_free=17.8, wall=36428
2023-07-09 20:21:37 | INFO | train_inner | epoch 034:    479 / 1474 loss=1.412, trans_loss=5.156, nll_loss=2.442, w2v_ctc_loss=0.401, task_loss=2.296, contrastive_loss=0.179, total=4070.55, n_correct=2716.97, ppl=5.43, accuracy=66.747, wps=6693, ups=1.64, wpb=4070.6, bsz=142.3, num_updates=49100, lr=6.38226e-05, gnorm=0.367, clip=0, loss_scale=32, train_wall=60, gb_free=17.6, wall=36489
2023-07-09 20:22:36 | INFO | train_inner | epoch 034:    579 / 1474 loss=1.406, trans_loss=5.138, nll_loss=2.42, w2v_ctc_loss=0.393, task_loss=2.127, contrastive_loss=0.187, total=4119.38, n_correct=2764.04, ppl=5.35, accuracy=67.098, wps=6887.8, ups=1.67, wpb=4119.4, bsz=150.1, num_updates=49200, lr=6.37577e-05, gnorm=0.367, clip=0, loss_scale=32, train_wall=59, gb_free=13.5, wall=36548
2023-07-09 20:23:37 | INFO | train_inner | epoch 034:    679 / 1474 loss=1.405, trans_loss=5.142, nll_loss=2.426, w2v_ctc_loss=0.391, task_loss=2.124, contrastive_loss=0.174, total=4124.83, n_correct=2765.07, ppl=5.37, accuracy=67.035, wps=6852.6, ups=1.66, wpb=4124.8, bsz=150.1, num_updates=49300, lr=6.3693e-05, gnorm=0.361, clip=0, loss_scale=32, train_wall=60, gb_free=14.6, wall=36609
2023-07-09 20:24:37 | INFO | train_inner | epoch 034:    779 / 1474 loss=1.416, trans_loss=5.171, nll_loss=2.463, w2v_ctc_loss=0.392, task_loss=2.198, contrastive_loss=0.32, total=4082.07, n_correct=2716.13, ppl=5.51, accuracy=66.538, wps=6747.1, ups=1.65, wpb=4082.1, bsz=147.5, num_updates=49400, lr=6.36285e-05, gnorm=0.369, clip=0, loss_scale=32, train_wall=60, gb_free=15.8, wall=36669
2023-07-09 20:25:38 | INFO | train_inner | epoch 034:    879 / 1474 loss=1.414, trans_loss=5.166, nll_loss=2.457, w2v_ctc_loss=0.396, task_loss=2.204, contrastive_loss=0.232, total=4100.9, n_correct=2732.66, ppl=5.49, accuracy=66.636, wps=6725.6, ups=1.64, wpb=4100.9, bsz=148.3, num_updates=49500, lr=6.35642e-05, gnorm=0.37, clip=0, loss_scale=32, train_wall=61, gb_free=12.6, wall=36730
2023-07-09 20:26:39 | INFO | train_inner | epoch 034:    979 / 1474 loss=1.409, trans_loss=5.158, nll_loss=2.447, w2v_ctc_loss=0.394, task_loss=2.047, contrastive_loss=0.228, total=4168.39, n_correct=2780.55, ppl=5.45, accuracy=66.706, wps=6820.3, ups=1.64, wpb=4168.4, bsz=156, num_updates=49600, lr=6.35001e-05, gnorm=0.358, clip=0, loss_scale=32, train_wall=61, gb_free=16.1, wall=36791
2023-07-09 20:27:39 | INFO | train_inner | epoch 034:   1079 / 1474 loss=1.414, trans_loss=5.163, nll_loss=2.453, w2v_ctc_loss=0.399, task_loss=2.024, contrastive_loss=0.189, total=4150.57, n_correct=2765.64, ppl=5.48, accuracy=66.633, wps=6917.3, ups=1.67, wpb=4150.6, bsz=154.2, num_updates=49700, lr=6.34361e-05, gnorm=0.367, clip=0, loss_scale=32, train_wall=60, gb_free=17, wall=36851
2023-07-09 20:28:40 | INFO | train_inner | epoch 034:   1179 / 1474 loss=1.411, trans_loss=5.157, nll_loss=2.446, w2v_ctc_loss=0.394, task_loss=2.152, contrastive_loss=0.211, total=4098.77, n_correct=2732.99, ppl=5.45, accuracy=66.678, wps=6775.2, ups=1.65, wpb=4098.8, bsz=148.6, num_updates=49800, lr=6.33724e-05, gnorm=0.365, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=36912
2023-07-09 20:29:40 | INFO | train_inner | epoch 034:   1279 / 1474 loss=1.404, trans_loss=5.153, nll_loss=2.44, w2v_ctc_loss=0.39, task_loss=2.114, contrastive_loss=0.178, total=4150.54, n_correct=2771.61, ppl=5.43, accuracy=66.777, wps=6904.6, ups=1.66, wpb=4150.5, bsz=150.5, num_updates=49900, lr=6.33089e-05, gnorm=0.363, clip=0, loss_scale=32, train_wall=60, gb_free=17.3, wall=36972
2023-07-09 20:30:41 | INFO | train_inner | epoch 034:   1379 / 1474 loss=1.413, trans_loss=5.164, nll_loss=2.455, w2v_ctc_loss=0.397, task_loss=1.992, contrastive_loss=0.319, total=4196.91, n_correct=2796.73, ppl=5.48, accuracy=66.638, wps=6863.6, ups=1.64, wpb=4196.9, bsz=160.7, num_updates=50000, lr=6.32456e-05, gnorm=0.364, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=37033
2023-07-09 20:30:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 20:31:06 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 2.278 | trans_loss 5.531 | nll_loss 2.829 | w2v_ctc_loss 0.689 | task_loss 2.365 | contrastive_loss 0.298 | total 4003.4 | n_correct 2503 | ppl 7.11 | accuracy 62.522 | uer 16.418 | wer 18.165 | raw_wer 18.165 | bleu 20.1 | wps 2185.4 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.44
2023-07-09 20:31:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-07-09 20:31:06 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_34_50000.pt
2023-07-09 20:31:08 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_34_50000.pt
2023-07-09 20:31:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 20.1) (writing took 6.218870123993838 seconds)
tensor(0.0221, device='cuda:0')
tensor(0.0008, device='cuda:0')
2023-07-09 20:32:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0221, device='cuda:5')
tensor(0.0008, device='cuda:5')
tensor(0.0221, device='cuda:6')
tensor(0.0008, device='cuda:6')
tensor(0.0221, device='cuda:7')
tensor(0.0008, device='cuda:7')
tensor(0.0221, device='cuda:4')
tensor(0.0008, device='cuda:4')
tensor(0.0221, device='cuda:1')
tensor(0.0008, device='cuda:1')
tensor(0.0221, device='cuda:2')
tensor(0.0008, device='cuda:2')
tensor(0.0221, device='cuda:3')
tensor(0.0008, device='cuda:3')
2023-07-09 20:32:33 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 2.278 | trans_loss 5.536 | nll_loss 2.836 | w2v_ctc_loss 0.685 | task_loss 2.365 | contrastive_loss 0.293 | total 4003.4 | n_correct 2498.4 | ppl 7.14 | accuracy 62.407 | uer 16.338 | wer 18.101 | raw_wer 18.101 | bleu 20.21 | wps 2259.3 | wpb 4003.4 | bsz 141.8 | num_updates 50095 | best_bleu 20.44
2023-07-09 20:32:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50095 updates
2023-07-09 20:32:33 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.2100.pt
2023-07-09 20:32:36 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.2100.pt
2023-07-09 20:32:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.2100.pt (epoch 34 @ 50095 updates, score 20.21) (writing took 5.232340018992545 seconds)
2023-07-09 20:32:39 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-07-09 20:32:39 | INFO | train | epoch 034 | loss 1.411 | trans_loss 5.154 | nll_loss 2.441 | w2v_ctc_loss 0.394 | task_loss 2.095 | contrastive_loss 0.271 | total 4137.27 | n_correct 2764.5 | ppl 5.43 | accuracy 66.819 | wps 6329.5 | ups 1.53 | wpb 4137.3 | bsz 152.6 | num_updates 50095 | lr 6.31856e-05 | gnorm 0.364 | clip 0 | loss_scale 32 | train_wall 887 | gb_free 17.5 | wall 37151
2023-07-09 20:32:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 20:32:39 | INFO | fairseq.trainer | begin training epoch 35
2023-07-09 20:32:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 20:32:50 | INFO | train_inner | epoch 035:      5 / 1474 loss=1.42, trans_loss=5.164, nll_loss=2.455, w2v_ctc_loss=0.392, task_loss=1.921, contrastive_loss=0.595, total=4213.19, n_correct=2808.48, ppl=5.48, accuracy=66.659, wps=3254.2, ups=0.77, wpb=4213.2, bsz=163.1, num_updates=50100, lr=6.31824e-05, gnorm=0.362, clip=0, loss_scale=32, train_wall=60, gb_free=17.5, wall=37162
2023-07-09 20:33:51 | INFO | train_inner | epoch 035:    105 / 1474 loss=1.406, trans_loss=5.132, nll_loss=2.413, w2v_ctc_loss=0.385, task_loss=2.013, contrastive_loss=0.478, total=4166.04, n_correct=2797.51, ppl=5.32, accuracy=67.15, wps=6849.5, ups=1.64, wpb=4166, bsz=156.6, num_updates=50200, lr=6.31194e-05, gnorm=0.365, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=37223
2023-07-09 20:34:52 | INFO | train_inner | epoch 035:    205 / 1474 loss=1.398, trans_loss=5.124, nll_loss=2.401, w2v_ctc_loss=0.384, task_loss=1.964, contrastive_loss=0.198, total=4171.82, n_correct=2810.96, ppl=5.28, accuracy=67.38, wps=6917, ups=1.66, wpb=4171.8, bsz=158.3, num_updates=50300, lr=6.30567e-05, gnorm=0.36, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=37284
2023-07-09 20:35:53 | INFO | train_inner | epoch 035:    305 / 1474 loss=1.407, trans_loss=5.133, nll_loss=2.413, w2v_ctc_loss=0.387, task_loss=2.175, contrastive_loss=0.519, total=4111.19, n_correct=2761.38, ppl=5.33, accuracy=67.167, wps=6731.7, ups=1.64, wpb=4111.2, bsz=150, num_updates=50400, lr=6.29941e-05, gnorm=0.362, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=37345
2023-07-09 20:36:53 | INFO | train_inner | epoch 035:    405 / 1474 loss=1.41, trans_loss=5.142, nll_loss=2.425, w2v_ctc_loss=0.396, task_loss=2.332, contrastive_loss=0.192, total=4070.26, n_correct=2725.45, ppl=5.37, accuracy=66.96, wps=6703.4, ups=1.65, wpb=4070.3, bsz=141.3, num_updates=50500, lr=6.29317e-05, gnorm=0.371, clip=0, loss_scale=32, train_wall=60, gb_free=17, wall=37405
2023-07-09 20:37:54 | INFO | train_inner | epoch 035:    505 / 1474 loss=1.411, trans_loss=5.144, nll_loss=2.428, w2v_ctc_loss=0.39, task_loss=2.125, contrastive_loss=0.344, total=4154.8, n_correct=2784.25, ppl=5.38, accuracy=67.013, wps=6810.5, ups=1.64, wpb=4154.8, bsz=152.4, num_updates=50600, lr=6.28695e-05, gnorm=0.364, clip=0, loss_scale=32, train_wall=61, gb_free=14, wall=37466
2023-07-09 20:38:55 | INFO | train_inner | epoch 035:    605 / 1474 loss=1.406, trans_loss=5.14, nll_loss=2.423, w2v_ctc_loss=0.388, task_loss=2.069, contrastive_loss=0.361, total=4170.95, n_correct=2796.08, ppl=5.36, accuracy=67.037, wps=6911.6, ups=1.66, wpb=4170.9, bsz=155, num_updates=50700, lr=6.28074e-05, gnorm=0.367, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=37527
2023-07-09 20:39:56 | INFO | train_inner | epoch 035:    705 / 1474 loss=1.409, trans_loss=5.147, nll_loss=2.431, w2v_ctc_loss=0.398, task_loss=2.189, contrastive_loss=0.218, total=4081.06, n_correct=2735.72, ppl=5.39, accuracy=67.035, wps=6677.6, ups=1.64, wpb=4081.1, bsz=147.4, num_updates=50800, lr=6.27456e-05, gnorm=0.366, clip=0, loss_scale=32, train_wall=61, gb_free=17.2, wall=37588
2023-07-09 20:40:56 | INFO | train_inner | epoch 035:    805 / 1474 loss=1.408, trans_loss=5.149, nll_loss=2.436, w2v_ctc_loss=0.396, task_loss=2.07, contrastive_loss=0.241, total=4151.95, n_correct=2778.52, ppl=5.41, accuracy=66.921, wps=6844.9, ups=1.65, wpb=4151.9, bsz=155.1, num_updates=50900, lr=6.26839e-05, gnorm=0.364, clip=0, loss_scale=64, train_wall=60, gb_free=15.8, wall=37648
2023-07-09 20:41:57 | INFO | train_inner | epoch 035:    905 / 1474 loss=1.411, trans_loss=5.153, nll_loss=2.439, w2v_ctc_loss=0.398, task_loss=2.204, contrastive_loss=0.195, total=4096.04, n_correct=2734.29, ppl=5.42, accuracy=66.754, wps=6729.7, ups=1.64, wpb=4096, bsz=146.9, num_updates=51000, lr=6.26224e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=60, gb_free=11.6, wall=37709
2023-07-09 20:42:58 | INFO | train_inner | epoch 035:   1005 / 1474 loss=1.415, trans_loss=5.157, nll_loss=2.446, w2v_ctc_loss=0.39, task_loss=2.114, contrastive_loss=0.449, total=4144.92, n_correct=2767.14, ppl=5.45, accuracy=66.76, wps=6828.6, ups=1.65, wpb=4144.9, bsz=153.5, num_updates=51100, lr=6.25611e-05, gnorm=0.366, clip=0, loss_scale=64, train_wall=60, gb_free=15, wall=37770
2023-07-09 20:43:59 | INFO | train_inner | epoch 035:   1105 / 1474 loss=1.408, trans_loss=5.151, nll_loss=2.438, w2v_ctc_loss=0.394, task_loss=1.994, contrastive_loss=0.214, total=4180.8, n_correct=2795.9, ppl=5.42, accuracy=66.875, wps=6898.3, ups=1.65, wpb=4180.8, bsz=155.7, num_updates=51200, lr=6.25e-05, gnorm=0.364, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=37831
2023-07-09 20:44:59 | INFO | train_inner | epoch 035:   1205 / 1474 loss=1.411, trans_loss=5.152, nll_loss=2.439, w2v_ctc_loss=0.391, task_loss=1.938, contrastive_loss=0.317, total=4214.15, n_correct=2819.24, ppl=5.42, accuracy=66.899, wps=6980.3, ups=1.66, wpb=4214.1, bsz=160.4, num_updates=51300, lr=6.24391e-05, gnorm=0.365, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=37891
2023-07-09 20:46:00 | INFO | train_inner | epoch 035:   1305 / 1474 loss=1.405, trans_loss=5.153, nll_loss=2.441, w2v_ctc_loss=0.391, task_loss=2.016, contrastive_loss=0.224, total=4140.13, n_correct=2768.16, ppl=5.43, accuracy=66.862, wps=6799.5, ups=1.64, wpb=4140.1, bsz=156.5, num_updates=51400, lr=6.23783e-05, gnorm=0.362, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=37952
2023-07-09 20:47:00 | INFO | train_inner | epoch 035:   1405 / 1474 loss=1.412, trans_loss=5.168, nll_loss=2.46, w2v_ctc_loss=0.396, task_loss=2.279, contrastive_loss=0.196, total=4056.79, n_correct=2698.28, ppl=5.5, accuracy=66.513, wps=6726.9, ups=1.66, wpb=4056.8, bsz=143.1, num_updates=51500, lr=6.23177e-05, gnorm=0.374, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=38012
2023-07-09 20:47:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 20:48:06 | INFO | dev_st | epoch 035 | valid on 'dev_st' subset | loss 2.278 | trans_loss 5.539 | nll_loss 2.84 | w2v_ctc_loss 0.682 | task_loss 2.365 | contrastive_loss 0.316 | total 4003.4 | n_correct 2493.7 | ppl 7.16 | accuracy 62.29 | uer 16.54 | wer 18.362 | raw_wer 18.362 | bleu 19.95 | wps 2309.8 | wpb 4003.4 | bsz 141.8 | num_updates 51569 | best_bleu 20.44
2023-07-09 20:48:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 51569 updates
2023-07-09 20:48:06 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_last.pt
2023-07-09 20:48:10 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_last.pt
2023-07-09 20:48:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_last.pt (epoch 35 @ 51569 updates, score 19.95) (writing took 4.425720483006444 seconds)
2023-07-09 20:48:10 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-07-09 20:48:10 | INFO | train | epoch 035 | loss 1.408 | trans_loss 5.146 | nll_loss 2.431 | w2v_ctc_loss 0.391 | task_loss 2.092 | contrastive_loss 0.298 | total 4138.65 | n_correct 2770.75 | ppl 5.39 | accuracy 66.948 | wps 6549.4 | ups 1.58 | wpb 4138.6 | bsz 152.8 | num_updates 51569 | lr 6.2276e-05 | gnorm 0.366 | clip 0 | loss_scale 64 | train_wall 889 | gb_free 17.4 | wall 38082
2023-07-09 20:48:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 20:48:11 | INFO | fairseq.trainer | begin training epoch 36
2023-07-09 20:48:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 20:48:37 | INFO | train_inner | epoch 036:     31 / 1474 loss=1.405, trans_loss=5.14, nll_loss=2.423, w2v_ctc_loss=0.389, task_loss=2.037, contrastive_loss=0.282, total=4123.87, n_correct=2763.96, ppl=5.36, accuracy=67.023, wps=4252.6, ups=1.03, wpb=4123.9, bsz=154.3, num_updates=51600, lr=6.22573e-05, gnorm=0.364, clip=0, loss_scale=64, train_wall=60, gb_free=17.5, wall=38109
2023-07-09 20:49:38 | INFO | train_inner | epoch 036:    131 / 1474 loss=1.403, trans_loss=5.13, nll_loss=2.409, w2v_ctc_loss=0.391, task_loss=2.173, contrastive_loss=0.219, total=4105.22, n_correct=2758.65, ppl=5.31, accuracy=67.199, wps=6784.5, ups=1.65, wpb=4105.2, bsz=149.6, num_updates=51700, lr=6.2197e-05, gnorm=0.364, clip=0, loss_scale=64, train_wall=60, gb_free=15.7, wall=38170
2023-07-09 20:50:39 | INFO | train_inner | epoch 036:    231 / 1474 loss=1.401, trans_loss=5.125, nll_loss=2.404, w2v_ctc_loss=0.387, task_loss=2.131, contrastive_loss=0.238, total=4152.4, n_correct=2794.68, ppl=5.29, accuracy=67.303, wps=6768.1, ups=1.63, wpb=4152.4, bsz=151.5, num_updates=51800, lr=6.2137e-05, gnorm=0.364, clip=0, loss_scale=64, train_wall=61, gb_free=16.2, wall=38231
2023-07-09 20:51:39 | INFO | train_inner | epoch 036:    331 / 1474 loss=1.398, trans_loss=5.13, nll_loss=2.41, w2v_ctc_loss=0.381, task_loss=1.982, contrastive_loss=0.194, total=4161.71, n_correct=2798.05, ppl=5.31, accuracy=67.233, wps=6908, ups=1.66, wpb=4161.7, bsz=155.1, num_updates=51900, lr=6.20771e-05, gnorm=0.362, clip=0, loss_scale=64, train_wall=60, gb_free=13.9, wall=38291
2023-07-09 20:52:40 | INFO | train_inner | epoch 036:    431 / 1474 loss=1.406, trans_loss=5.125, nll_loss=2.405, w2v_ctc_loss=0.385, task_loss=1.825, contrastive_loss=0.436, total=4234.57, n_correct=2855.38, ppl=5.29, accuracy=67.43, wps=7003, ups=1.65, wpb=4234.6, bsz=166.8, num_updates=52000, lr=6.20174e-05, gnorm=0.361, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=38352
2023-07-09 20:52:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 20:53:06 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 2.289 | trans_loss 5.542 | nll_loss 2.844 | w2v_ctc_loss 0.716 | task_loss 2.365 | contrastive_loss 0.315 | total 4003.4 | n_correct 2494.4 | ppl 7.18 | accuracy 62.307 | uer 16.712 | wer 18.53 | raw_wer 18.53 | bleu 20.19 | wps 2164.8 | wpb 4003.4 | bsz 141.8 | num_updates 52000 | best_bleu 20.44
2023-07-09 20:53:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 52000 updates
2023-07-09 20:53:06 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_36_52000.pt
2023-07-09 20:53:08 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_36_52000.pt
2023-07-09 20:53:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_36_52000.pt (epoch 36 @ 52000 updates, score 20.19) (writing took 6.120277871988947 seconds)
2023-07-09 20:54:14 | INFO | train_inner | epoch 036:    531 / 1474 loss=1.414, trans_loss=5.15, nll_loss=2.437, w2v_ctc_loss=0.384, task_loss=2.109, contrastive_loss=0.704, total=4145.92, n_correct=2773.25, ppl=5.42, accuracy=66.891, wps=4398.5, ups=1.06, wpb=4145.9, bsz=155.5, num_updates=52100, lr=6.19578e-05, gnorm=0.366, clip=0, loss_scale=64, train_wall=61, gb_free=16.6, wall=38446
2023-07-09 20:55:15 | INFO | train_inner | epoch 036:    631 / 1474 loss=1.402, trans_loss=5.126, nll_loss=2.404, w2v_ctc_loss=0.388, task_loss=2.016, contrastive_loss=0.362, total=4180.58, n_correct=2811.62, ppl=5.29, accuracy=67.254, wps=6892.2, ups=1.65, wpb=4180.6, bsz=158.3, num_updates=52200, lr=6.18984e-05, gnorm=0.362, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=38507
2023-07-09 20:56:16 | INFO | train_inner | epoch 036:    731 / 1474 loss=1.407, trans_loss=5.148, nll_loss=2.434, w2v_ctc_loss=0.393, task_loss=2.013, contrastive_loss=0.231, total=4185.09, n_correct=2802.83, ppl=5.4, accuracy=66.972, wps=6881.1, ups=1.64, wpb=4185.1, bsz=158.6, num_updates=52300, lr=6.18392e-05, gnorm=0.364, clip=0, loss_scale=64, train_wall=60, gb_free=17.3, wall=38568
2023-07-09 20:57:16 | INFO | train_inner | epoch 036:    831 / 1474 loss=1.42, trans_loss=5.16, nll_loss=2.449, w2v_ctc_loss=0.39, task_loss=1.979, contrastive_loss=0.553, total=4167.92, n_correct=2780.94, ppl=5.46, accuracy=66.722, wps=6861.2, ups=1.65, wpb=4167.9, bsz=159.5, num_updates=52400, lr=6.17802e-05, gnorm=0.367, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=38628
2023-07-09 20:58:18 | INFO | train_inner | epoch 036:    931 / 1474 loss=1.399, trans_loss=5.135, nll_loss=2.418, w2v_ctc_loss=0.388, task_loss=2.097, contrastive_loss=0.207, total=4180.47, n_correct=2802.12, ppl=5.34, accuracy=67.029, wps=6811.6, ups=1.63, wpb=4180.5, bsz=153.8, num_updates=52500, lr=6.17213e-05, gnorm=0.362, clip=0, loss_scale=64, train_wall=61, gb_free=13.1, wall=38690
2023-07-09 20:59:19 | INFO | train_inner | epoch 036:   1031 / 1474 loss=1.402, trans_loss=5.144, nll_loss=2.428, w2v_ctc_loss=0.389, task_loss=2.174, contrastive_loss=0.193, total=4175.32, n_correct=2796.23, ppl=5.38, accuracy=66.97, wps=6845.5, ups=1.64, wpb=4175.3, bsz=150.4, num_updates=52600, lr=6.16626e-05, gnorm=0.363, clip=0, loss_scale=64, train_wall=61, gb_free=13.6, wall=38751
2023-07-09 21:00:19 | INFO | train_inner | epoch 036:   1131 / 1474 loss=1.402, trans_loss=5.137, nll_loss=2.42, w2v_ctc_loss=0.392, task_loss=2.08, contrastive_loss=0.23, total=4140.45, n_correct=2777.07, ppl=5.35, accuracy=67.072, wps=6841.9, ups=1.65, wpb=4140.4, bsz=154.1, num_updates=52700, lr=6.16041e-05, gnorm=0.367, clip=0, loss_scale=64, train_wall=60, gb_free=16, wall=38811
2023-07-09 21:01:20 | INFO | train_inner | epoch 036:   1231 / 1474 loss=1.404, trans_loss=5.145, nll_loss=2.429, w2v_ctc_loss=0.393, task_loss=2.329, contrastive_loss=0.185, total=4044.64, n_correct=2706.88, ppl=5.38, accuracy=66.925, wps=6705.1, ups=1.66, wpb=4044.6, bsz=139.5, num_updates=52800, lr=6.15457e-05, gnorm=0.371, clip=0, loss_scale=64, train_wall=60, gb_free=13.7, wall=38872
2023-07-09 21:02:20 | INFO | train_inner | epoch 036:   1331 / 1474 loss=1.405, trans_loss=5.144, nll_loss=2.429, w2v_ctc_loss=0.391, task_loss=2.088, contrastive_loss=0.215, total=4106.95, n_correct=2747.6, ppl=5.39, accuracy=66.901, wps=6839.8, ups=1.67, wpb=4106.9, bsz=152.7, num_updates=52900, lr=6.14875e-05, gnorm=0.369, clip=0, loss_scale=64, train_wall=60, gb_free=17.6, wall=38932
2023-07-09 21:03:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-09 21:03:21 | INFO | train_inner | epoch 036:   1432 / 1474 loss=1.411, trans_loss=5.163, nll_loss=2.453, w2v_ctc_loss=0.395, task_loss=2.408, contrastive_loss=0.182, total=4032.05, n_correct=2685.83, ppl=5.47, accuracy=66.612, wps=6577.4, ups=1.63, wpb=4032.1, bsz=136.5, num_updates=53000, lr=6.14295e-05, gnorm=0.374, clip=0, loss_scale=64, train_wall=61, gb_free=11.3, wall=38993
2023-07-09 21:03:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 21:04:12 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 2.286 | trans_loss 5.528 | nll_loss 2.825 | w2v_ctc_loss 0.724 | task_loss 2.365 | contrastive_loss 0.317 | total 4003.4 | n_correct 2506.1 | ppl 7.08 | accuracy 62.599 | uer 16.71 | wer 18.258 | raw_wer 18.258 | bleu 20.3 | wps 2050.6 | wpb 4003.4 | bsz 141.8 | num_updates 53042 | best_bleu 20.44
2023-07-09 21:04:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 53042 updates
2023-07-09 21:04:12 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.3000.pt
2023-07-09 21:04:15 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.3000.pt
2023-07-09 21:04:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.3000.pt (epoch 36 @ 53042 updates, score 20.3) (writing took 5.353554047993384 seconds)
2023-07-09 21:04:18 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-07-09 21:04:18 | INFO | train | epoch 036 | loss 1.405 | trans_loss 5.14 | nll_loss 2.423 | w2v_ctc_loss 0.389 | task_loss 2.094 | contrastive_loss 0.295 | total 4137.6 | n_correct 2774.1 | ppl 5.36 | accuracy 67.046 | wps 6300.1 | ups 1.52 | wpb 4137.6 | bsz 152.7 | num_updates 53042 | lr 6.14052e-05 | gnorm 0.366 | clip 0 | loss_scale 64 | train_wall 887 | gb_free 17 | wall 39050
2023-07-09 21:04:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 21:04:18 | INFO | fairseq.trainer | begin training epoch 37
2023-07-09 21:04:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 21:05:02 | INFO | train_inner | epoch 037:     58 / 1474 loss=1.399, trans_loss=5.126, nll_loss=2.406, w2v_ctc_loss=0.385, task_loss=2.097, contrastive_loss=0.218, total=4092.98, n_correct=2754.4, ppl=5.3, accuracy=67.296, wps=4045.5, ups=0.99, wpb=4093, bsz=150, num_updates=53100, lr=6.13716e-05, gnorm=0.367, clip=0, loss_scale=64, train_wall=60, gb_free=15.5, wall=39094
2023-07-09 21:06:03 | INFO | train_inner | epoch 037:    158 / 1474 loss=1.402, trans_loss=5.124, nll_loss=2.402, w2v_ctc_loss=0.384, task_loss=2.128, contrastive_loss=0.336, total=4124.56, n_correct=2777.86, ppl=5.28, accuracy=67.349, wps=6819.4, ups=1.65, wpb=4124.6, bsz=153.4, num_updates=53200, lr=6.13139e-05, gnorm=0.37, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=39155
2023-07-09 21:07:03 | INFO | train_inner | epoch 037:    258 / 1474 loss=1.39, trans_loss=5.105, nll_loss=2.377, w2v_ctc_loss=0.374, task_loss=1.956, contrastive_loss=0.216, total=4188.93, n_correct=2833.78, ppl=5.2, accuracy=67.649, wps=6944.4, ups=1.66, wpb=4188.9, bsz=159.7, num_updates=53300, lr=6.12564e-05, gnorm=0.361, clip=0, loss_scale=64, train_wall=60, gb_free=15.1, wall=39215
2023-07-09 21:08:03 | INFO | train_inner | epoch 037:    358 / 1474 loss=1.402, trans_loss=5.124, nll_loss=2.402, w2v_ctc_loss=0.389, task_loss=2.113, contrastive_loss=0.233, total=4171.05, n_correct=2812.03, ppl=5.28, accuracy=67.418, wps=6926.1, ups=1.66, wpb=4171.1, bsz=152.9, num_updates=53400, lr=6.1199e-05, gnorm=0.366, clip=0, loss_scale=64, train_wall=60, gb_free=16.1, wall=39275
2023-07-09 21:08:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-09 21:09:05 | INFO | train_inner | epoch 037:    459 / 1474 loss=1.413, trans_loss=5.145, nll_loss=2.43, w2v_ctc_loss=0.386, task_loss=2.073, contrastive_loss=0.521, total=4154.31, n_correct=2782.28, ppl=5.39, accuracy=66.973, wps=6675.4, ups=1.61, wpb=4154.3, bsz=154.7, num_updates=53500, lr=6.11418e-05, gnorm=0.371, clip=0, loss_scale=32, train_wall=62, gb_free=14.1, wall=39337
2023-07-09 21:10:06 | INFO | train_inner | epoch 037:    559 / 1474 loss=1.398, trans_loss=5.126, nll_loss=2.405, w2v_ctc_loss=0.389, task_loss=2.164, contrastive_loss=0.21, total=4092.13, n_correct=2751.76, ppl=5.3, accuracy=67.245, wps=6736, ups=1.65, wpb=4092.1, bsz=149.9, num_updates=53600, lr=6.10847e-05, gnorm=0.365, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=39398
2023-07-09 21:11:07 | INFO | train_inner | epoch 037:    659 / 1474 loss=1.403, trans_loss=5.138, nll_loss=2.421, w2v_ctc_loss=0.394, task_loss=2.194, contrastive_loss=0.223, total=4102.49, n_correct=2751.11, ppl=5.36, accuracy=67.06, wps=6756.3, ups=1.65, wpb=4102.5, bsz=146, num_updates=53700, lr=6.10278e-05, gnorm=0.371, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=39459
2023-07-09 21:12:07 | INFO | train_inner | epoch 037:    759 / 1474 loss=1.398, trans_loss=5.13, nll_loss=2.41, w2v_ctc_loss=0.381, task_loss=2.09, contrastive_loss=0.337, total=4123.95, n_correct=2772.03, ppl=5.32, accuracy=67.218, wps=6844.9, ups=1.66, wpb=4123.9, bsz=152.4, num_updates=53800, lr=6.09711e-05, gnorm=0.368, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=39519
2023-07-09 21:13:07 | INFO | train_inner | epoch 037:    859 / 1474 loss=1.399, trans_loss=5.126, nll_loss=2.405, w2v_ctc_loss=0.381, task_loss=1.962, contrastive_loss=0.212, total=4159.03, n_correct=2800.7, ppl=5.3, accuracy=67.34, wps=6892.4, ups=1.66, wpb=4159, bsz=157.9, num_updates=53900, lr=6.09145e-05, gnorm=0.368, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=39579
2023-07-09 21:14:08 | INFO | train_inner | epoch 037:    959 / 1474 loss=1.406, trans_loss=5.149, nll_loss=2.434, w2v_ctc_loss=0.394, task_loss=2.234, contrastive_loss=0.222, total=4097.89, n_correct=2746.23, ppl=5.4, accuracy=67.016, wps=6771.8, ups=1.65, wpb=4097.9, bsz=146.2, num_updates=54000, lr=6.08581e-05, gnorm=0.371, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=39640
2023-07-09 21:14:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 21:14:33 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 2.278 | trans_loss 5.532 | nll_loss 2.831 | w2v_ctc_loss 0.694 | task_loss 2.365 | contrastive_loss 0.322 | total 4003.4 | n_correct 2503 | ppl 7.11 | accuracy 62.522 | uer 16.46 | wer 18.221 | raw_wer 18.221 | bleu 20.04 | wps 2102.6 | wpb 4003.4 | bsz 141.8 | num_updates 54000 | best_bleu 20.44
2023-07-09 21:14:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54000 updates
2023-07-09 21:14:33 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_37_54000.pt
2023-07-09 21:14:35 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_37_54000.pt
2023-07-09 21:14:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_37_54000.pt (epoch 37 @ 54000 updates, score 20.04) (writing took 5.0588078100117855 seconds)
2023-07-09 21:15:39 | INFO | train_inner | epoch 037:   1059 / 1474 loss=1.402, trans_loss=5.13, nll_loss=2.411, w2v_ctc_loss=0.381, task_loss=1.96, contrastive_loss=0.477, total=4162.64, n_correct=2797.68, ppl=5.32, accuracy=67.209, wps=4555.9, ups=1.09, wpb=4162.6, bsz=159.9, num_updates=54100, lr=6.08018e-05, gnorm=0.368, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=39731
2023-07-09 21:16:40 | INFO | train_inner | epoch 037:   1159 / 1474 loss=1.408, trans_loss=5.147, nll_loss=2.434, w2v_ctc_loss=0.385, task_loss=2.029, contrastive_loss=0.527, total=4176.35, n_correct=2797.16, ppl=5.4, accuracy=66.976, wps=6883.8, ups=1.65, wpb=4176.4, bsz=156.1, num_updates=54200, lr=6.07457e-05, gnorm=0.363, clip=0, loss_scale=32, train_wall=60, gb_free=16.2, wall=39792
2023-07-09 21:17:41 | INFO | train_inner | epoch 037:   1259 / 1474 loss=1.401, trans_loss=5.141, nll_loss=2.426, w2v_ctc_loss=0.384, task_loss=2.028, contrastive_loss=0.228, total=4167.2, n_correct=2792.82, ppl=5.37, accuracy=67.019, wps=6875.3, ups=1.65, wpb=4167.2, bsz=155.9, num_updates=54300, lr=6.06897e-05, gnorm=0.364, clip=0, loss_scale=32, train_wall=60, gb_free=16.2, wall=39853
2023-07-09 21:18:41 | INFO | train_inner | epoch 037:   1359 / 1474 loss=1.413, trans_loss=5.157, nll_loss=2.446, w2v_ctc_loss=0.404, task_loss=2.296, contrastive_loss=0.205, total=4072.63, n_correct=2716.45, ppl=5.45, accuracy=66.7, wps=6718.4, ups=1.65, wpb=4072.6, bsz=143, num_updates=54400, lr=6.06339e-05, gnorm=0.379, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=39913
2023-07-09 21:19:41 | INFO | train_inner | epoch 037:   1459 / 1474 loss=1.404, trans_loss=5.148, nll_loss=2.435, w2v_ctc_loss=0.387, task_loss=2.076, contrastive_loss=0.273, total=4155.97, n_correct=2779.35, ppl=5.41, accuracy=66.876, wps=6950.3, ups=1.67, wpb=4156, bsz=152.6, num_updates=54500, lr=6.05783e-05, gnorm=0.369, clip=0, loss_scale=32, train_wall=59, gb_free=16.3, wall=39973
2023-07-09 21:19:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 21:20:15 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 2.279 | trans_loss 5.534 | nll_loss 2.831 | w2v_ctc_loss 0.698 | task_loss 2.365 | contrastive_loss 0.32 | total 4003.4 | n_correct 2501.5 | ppl 7.12 | accuracy 62.484 | uer 16.723 | wer 18.504 | raw_wer 18.504 | bleu 20.22 | wps 2158.5 | wpb 4003.4 | bsz 141.8 | num_updates 54515 | best_bleu 20.44
2023-07-09 21:20:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54515 updates
2023-07-09 21:20:15 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.2207.pt
2023-07-09 21:20:17 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.2207.pt
2023-07-09 21:20:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint.best_bleu_20.2207.pt (epoch 37 @ 54515 updates, score 20.22) (writing took 5.239056293998146 seconds)
2023-07-09 21:20:20 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-07-09 21:20:20 | INFO | train | epoch 037 | loss 1.403 | trans_loss 5.134 | nll_loss 2.416 | w2v_ctc_loss 0.387 | task_loss 2.096 | contrastive_loss 0.299 | total 4136.85 | n_correct 2778.01 | ppl 5.34 | accuracy 67.153 | wps 6332.5 | ups 1.53 | wpb 4136.9 | bsz 152.5 | num_updates 54515 | lr 6.05699e-05 | gnorm 0.368 | clip 0 | loss_scale 32 | train_wall 886 | gb_free 13.2 | wall 40012
2023-07-09 21:20:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 21:20:20 | INFO | fairseq.trainer | begin training epoch 38
2023-07-09 21:20:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 21:21:20 | INFO | train_inner | epoch 038:     85 / 1474 loss=1.394, trans_loss=5.112, nll_loss=2.386, w2v_ctc_loss=0.382, task_loss=2.184, contrastive_loss=0.2, total=4085.19, n_correct=2760.21, ppl=5.23, accuracy=67.566, wps=4136.5, ups=1.01, wpb=4085.2, bsz=146.8, num_updates=54600, lr=6.05228e-05, gnorm=0.368, clip=0, loss_scale=32, train_wall=59, gb_free=17.1, wall=40072
2023-07-09 21:22:21 | INFO | train_inner | epoch 038:    185 / 1474 loss=1.394, trans_loss=5.117, nll_loss=2.393, w2v_ctc_loss=0.382, task_loss=2.193, contrastive_loss=0.208, total=4081.12, n_correct=2753.76, ppl=5.25, accuracy=67.476, wps=6678.7, ups=1.64, wpb=4081.1, bsz=146.3, num_updates=54700, lr=6.04674e-05, gnorm=0.37, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=40133
2023-07-09 21:23:21 | INFO | train_inner | epoch 038:    285 / 1474 loss=1.397, trans_loss=5.119, nll_loss=2.396, w2v_ctc_loss=0.383, task_loss=2.185, contrastive_loss=0.248, total=4073.75, n_correct=2747.16, ppl=5.26, accuracy=67.436, wps=6767, ups=1.66, wpb=4073.8, bsz=147.9, num_updates=54800, lr=6.04122e-05, gnorm=0.369, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=40193
2023-07-09 21:24:22 | INFO | train_inner | epoch 038:    385 / 1474 loss=1.397, trans_loss=5.122, nll_loss=2.401, w2v_ctc_loss=0.387, task_loss=2.073, contrastive_loss=0.254, total=4173.43, n_correct=2809.84, ppl=5.28, accuracy=67.327, wps=6905.6, ups=1.65, wpb=4173.4, bsz=154.1, num_updates=54900, lr=6.03572e-05, gnorm=0.372, clip=0, loss_scale=32, train_wall=60, gb_free=14.1, wall=40254
2023-07-09 21:25:22 | INFO | train_inner | epoch 038:    485 / 1474 loss=1.394, trans_loss=5.113, nll_loss=2.389, w2v_ctc_loss=0.38, task_loss=2.017, contrastive_loss=0.246, total=4192.03, n_correct=2830.17, ppl=5.24, accuracy=67.513, wps=6969.8, ups=1.66, wpb=4192, bsz=156, num_updates=55000, lr=6.03023e-05, gnorm=0.366, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=40314
tensor(0.0221, device='cuda:0')
tensor(0.0008, device='cuda:0')
2023-07-09 21:26:23 | INFO | train_inner | epoch 038:    585 / 1474 loss=1.411, trans_loss=5.141, nll_loss=2.425, w2v_ctc_loss=0.385, task_loss=2.09, contrastive_loss=0.579, total=4172.44, n_correct=2795.05, ppl=5.37, accuracy=66.988, wps=6804.3, ups=1.63, wpb=4172.4, bsz=154.4, num_updates=55100, lr=6.02475e-05, gnorm=0.372, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=40375
2023-07-09 21:27:24 | INFO | train_inner | epoch 038:    685 / 1474 loss=1.4, trans_loss=5.121, nll_loss=2.4, w2v_ctc_loss=0.379, task_loss=1.982, contrastive_loss=0.551, total=4179.22, n_correct=2813.29, ppl=5.28, accuracy=67.316, wps=6904.6, ups=1.65, wpb=4179.2, bsz=161.2, num_updates=55200, lr=6.01929e-05, gnorm=0.366, clip=0, loss_scale=32, train_wall=60, gb_free=13.4, wall=40436
2023-07-09 21:28:24 | INFO | train_inner | epoch 038:    785 / 1474 loss=1.396, trans_loss=5.114, nll_loss=2.39, w2v_ctc_loss=0.376, task_loss=1.922, contrastive_loss=0.403, total=4180.46, n_correct=2824.71, ppl=5.24, accuracy=67.569, wps=6920.5, ups=1.66, wpb=4180.5, bsz=162.9, num_updates=55300, lr=6.01385e-05, gnorm=0.365, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=40496
2023-07-09 21:29:24 | INFO | train_inner | epoch 038:    885 / 1474 loss=1.393, trans_loss=5.117, nll_loss=2.395, w2v_ctc_loss=0.381, task_loss=1.974, contrastive_loss=0.219, total=4122.77, n_correct=2778.55, ppl=5.26, accuracy=67.395, wps=6823.8, ups=1.66, wpb=4122.8, bsz=155.9, num_updates=55400, lr=6.00842e-05, gnorm=0.365, clip=0, loss_scale=32, train_wall=60, gb_free=15.7, wall=40556
2023-07-09 21:30:24 | INFO | train_inner | epoch 038:    985 / 1474 loss=1.399, trans_loss=5.143, nll_loss=2.428, w2v_ctc_loss=0.387, task_loss=2.097, contrastive_loss=0.28, total=4116.2, n_correct=2761.79, ppl=5.38, accuracy=67.096, wps=6862.9, ups=1.67, wpb=4116.2, bsz=150.8, num_updates=55500, lr=6.003e-05, gnorm=0.365, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=40616
2023-07-09 21:31:25 | INFO | train_inner | epoch 038:   1085 / 1474 loss=1.404, trans_loss=5.132, nll_loss=2.415, w2v_ctc_loss=0.385, task_loss=1.906, contrastive_loss=0.36, total=4248.59, n_correct=2854.84, ppl=5.33, accuracy=67.195, wps=7029.2, ups=1.65, wpb=4248.6, bsz=164.4, num_updates=55600, lr=5.9976e-05, gnorm=0.369, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=40677
2023-07-09 21:32:26 | INFO | train_inner | epoch 038:   1185 / 1474 loss=1.405, trans_loss=5.149, nll_loss=2.436, w2v_ctc_loss=0.393, task_loss=2.3, contrastive_loss=0.228, total=4077.59, n_correct=2724.93, ppl=5.41, accuracy=66.827, wps=6694.1, ups=1.64, wpb=4077.6, bsz=143.7, num_updates=55700, lr=5.99222e-05, gnorm=0.372, clip=0, loss_scale=64, train_wall=60, gb_free=14.3, wall=40738
2023-07-09 21:33:26 | INFO | train_inner | epoch 038:   1285 / 1474 loss=1.406, trans_loss=5.149, nll_loss=2.435, w2v_ctc_loss=0.388, task_loss=2.232, contrastive_loss=0.223, total=4146.3, n_correct=2773.67, ppl=5.41, accuracy=66.895, wps=6830.1, ups=1.65, wpb=4146.3, bsz=147.8, num_updates=55800, lr=5.98684e-05, gnorm=0.368, clip=0, loss_scale=64, train_wall=60, gb_free=17.7, wall=40798
2023-07-09 21:34:27 | INFO | train_inner | epoch 038:   1385 / 1474 loss=1.409, trans_loss=5.144, nll_loss=2.43, w2v_ctc_loss=0.389, task_loss=2.063, contrastive_loss=0.328, total=4156.39, n_correct=2785.3, ppl=5.39, accuracy=67.012, wps=6867.6, ups=1.65, wpb=4156.4, bsz=155.3, num_updates=55900, lr=5.98149e-05, gnorm=0.374, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=40859
2023-07-09 21:35:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0221, device='cuda:6')
tensor(0.0008, device='cuda:6')
tensor(0.0221, device='cuda:4')
tensor(0.0008, device='cuda:4')
tensor(0.0221, device='cuda:7')
tensor(0.0008, device='cuda:7')
tensor(0.0221, device='cuda:5')
tensor(0.0008, device='cuda:5')
tensor(0.0221, device='cuda:1')
tensor(0.0008, device='cuda:1')
tensor(0.0221, device='cuda:2')
tensor(0.0008, device='cuda:2')
tensor(0.0221, device='cuda:3')
tensor(0.0008, device='cuda:3')
2023-07-09 21:35:45 | INFO | dev_st | epoch 038 | valid on 'dev_st' subset | loss 2.278 | trans_loss 5.533 | nll_loss 2.832 | w2v_ctc_loss 0.698 | task_loss 2.365 | contrastive_loss 0.327 | total 4003.4 | n_correct 2501.3 | ppl 7.12 | accuracy 62.479 | uer 16.463 | wer 18.251 | raw_wer 18.251 | bleu 20.16 | wps 2231.4 | wpb 4003.4 | bsz 141.8 | num_updates 55989 | best_bleu 20.44
2023-07-09 21:35:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 55989 updates
2023-07-09 21:35:45 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_last.pt
2023-07-09 21:35:49 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_last.pt
2023-07-09 21:35:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_last.pt (epoch 38 @ 55989 updates, score 20.16) (writing took 4.284994707006263 seconds)
2023-07-09 21:35:50 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-07-09 21:35:50 | INFO | train | epoch 038 | loss 1.4 | trans_loss 5.129 | nll_loss 2.409 | w2v_ctc_loss 0.384 | task_loss 2.092 | contrastive_loss 0.315 | total 4138.65 | n_correct 2783.03 | ppl 5.31 | accuracy 67.245 | wps 6562.8 | ups 1.59 | wpb 4138.6 | bsz 152.8 | num_updates 55989 | lr 5.97673e-05 | gnorm 0.369 | clip 0 | loss_scale 64 | train_wall 885 | gb_free 16.8 | wall 40942
2023-07-09 21:35:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 21:35:50 | INFO | fairseq.trainer | begin training epoch 39
2023-07-09 21:35:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 21:36:04 | INFO | train_inner | epoch 039:     11 / 1474 loss=1.405, trans_loss=5.141, nll_loss=2.424, w2v_ctc_loss=0.388, task_loss=2.248, contrastive_loss=0.34, total=4033.2, n_correct=2702.68, ppl=5.37, accuracy=67.011, wps=4136.1, ups=1.03, wpb=4033.2, bsz=142.9, num_updates=56000, lr=5.97614e-05, gnorm=0.371, clip=0, loss_scale=64, train_wall=60, gb_free=17.5, wall=40956
2023-07-09 21:36:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 21:36:29 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 2.277 | trans_loss 5.531 | nll_loss 2.827 | w2v_ctc_loss 0.698 | task_loss 2.365 | contrastive_loss 0.327 | total 4003.4 | n_correct 2504.8 | ppl 7.1 | accuracy 62.567 | uer 16.396 | wer 18.21 | raw_wer 18.21 | bleu 20.3 | wps 2253.3 | wpb 4003.4 | bsz 141.8 | num_updates 56000 | best_bleu 20.44
2023-07-09 21:36:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 56000 updates
2023-07-09 21:36:29 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_39_56000.pt
2023-07-09 21:36:31 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_39_56000.pt
2023-07-09 21:36:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_39_56000.pt (epoch 39 @ 56000 updates, score 20.3) (writing took 6.217030366999097 seconds)
2023-07-09 21:37:35 | INFO | train_inner | epoch 039:    111 / 1474 loss=1.392, trans_loss=5.101, nll_loss=2.372, w2v_ctc_loss=0.384, task_loss=2.228, contrastive_loss=0.21, total=4057.77, n_correct=2746.85, ppl=5.17, accuracy=67.694, wps=4503.7, ups=1.11, wpb=4057.8, bsz=143.2, num_updates=56100, lr=5.97081e-05, gnorm=0.371, clip=0, loss_scale=64, train_wall=59, gb_free=17.5, wall=41047
2023-07-09 21:38:35 | INFO | train_inner | epoch 039:    211 / 1474 loss=1.389, trans_loss=5.095, nll_loss=2.364, w2v_ctc_loss=0.379, task_loss=2.129, contrastive_loss=0.21, total=4134.99, n_correct=2801.83, ppl=5.15, accuracy=67.759, wps=6880.5, ups=1.66, wpb=4135, bsz=150.2, num_updates=56200, lr=5.9655e-05, gnorm=0.366, clip=0, loss_scale=64, train_wall=60, gb_free=15.9, wall=41107
2023-07-09 21:39:35 | INFO | train_inner | epoch 039:    311 / 1474 loss=1.388, trans_loss=5.101, nll_loss=2.374, w2v_ctc_loss=0.38, task_loss=2.131, contrastive_loss=0.221, total=4135.88, n_correct=2802.72, ppl=5.18, accuracy=67.766, wps=6873.6, ups=1.66, wpb=4135.9, bsz=149.8, num_updates=56300, lr=5.9602e-05, gnorm=0.369, clip=0, loss_scale=64, train_wall=60, gb_free=13.4, wall=41167
2023-07-09 21:40:36 | INFO | train_inner | epoch 039:    411 / 1474 loss=1.397, trans_loss=5.11, nll_loss=2.385, w2v_ctc_loss=0.378, task_loss=2.073, contrastive_loss=0.522, total=4128.52, n_correct=2792.92, ppl=5.22, accuracy=67.649, wps=6767.2, ups=1.64, wpb=4128.5, bsz=156.1, num_updates=56400, lr=5.95491e-05, gnorm=0.365, clip=0, loss_scale=64, train_wall=61, gb_free=13, wall=41228
2023-07-09 21:41:37 | INFO | train_inner | epoch 039:    511 / 1474 loss=1.399, trans_loss=5.122, nll_loss=2.401, w2v_ctc_loss=0.38, task_loss=2.063, contrastive_loss=0.542, total=4143.39, n_correct=2789.95, ppl=5.28, accuracy=67.335, wps=6755.4, ups=1.63, wpb=4143.4, bsz=155.8, num_updates=56500, lr=5.94964e-05, gnorm=0.366, clip=0, loss_scale=64, train_wall=61, gb_free=17, wall=41289
2023-07-09 21:42:38 | INFO | train_inner | epoch 039:    611 / 1474 loss=1.399, trans_loss=5.123, nll_loss=2.402, w2v_ctc_loss=0.383, task_loss=2.122, contrastive_loss=0.33, total=4131.41, n_correct=2781.28, ppl=5.29, accuracy=67.32, wps=6800.9, ups=1.65, wpb=4131.4, bsz=151.4, num_updates=56600, lr=5.94438e-05, gnorm=0.369, clip=0, loss_scale=64, train_wall=60, gb_free=16, wall=41350
2023-07-09 21:43:37 | INFO | train_inner | epoch 039:    711 / 1474 loss=1.4, trans_loss=5.127, nll_loss=2.407, w2v_ctc_loss=0.38, task_loss=2.034, contrastive_loss=0.31, total=4133.78, n_correct=2782.27, ppl=5.3, accuracy=67.306, wps=6975.6, ups=1.69, wpb=4133.8, bsz=152.9, num_updates=56700, lr=5.93914e-05, gnorm=0.371, clip=0, loss_scale=64, train_wall=59, gb_free=16.2, wall=41409
2023-07-09 21:44:38 | INFO | train_inner | epoch 039:    811 / 1474 loss=1.397, trans_loss=5.123, nll_loss=2.402, w2v_ctc_loss=0.386, task_loss=2.098, contrastive_loss=0.246, total=4178.43, n_correct=2811.83, ppl=5.29, accuracy=67.294, wps=6836.1, ups=1.64, wpb=4178.4, bsz=154.9, num_updates=56800, lr=5.93391e-05, gnorm=0.367, clip=0, loss_scale=64, train_wall=61, gb_free=17.1, wall=41470
2023-07-09 21:45:38 | INFO | train_inner | epoch 039:    911 / 1474 loss=1.396, trans_loss=5.124, nll_loss=2.403, w2v_ctc_loss=0.382, task_loss=2.163, contrastive_loss=0.247, total=4125.39, n_correct=2776.22, ppl=5.29, accuracy=67.296, wps=6869.7, ups=1.67, wpb=4125.4, bsz=149.5, num_updates=56900, lr=5.92869e-05, gnorm=0.368, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=41530
2023-07-09 21:46:39 | INFO | train_inner | epoch 039:   1011 / 1474 loss=1.406, trans_loss=5.136, nll_loss=2.419, w2v_ctc_loss=0.383, task_loss=2.043, contrastive_loss=0.479, total=4198.7, n_correct=2820.27, ppl=5.35, accuracy=67.17, wps=6887, ups=1.64, wpb=4198.7, bsz=159.7, num_updates=57000, lr=5.92349e-05, gnorm=0.374, clip=0, loss_scale=64, train_wall=61, gb_free=16.2, wall=41591
2023-07-09 21:47:40 | INFO | train_inner | epoch 039:   1111 / 1474 loss=1.399, trans_loss=5.118, nll_loss=2.396, w2v_ctc_loss=0.379, task_loss=1.961, contrastive_loss=0.42, total=4194.7, n_correct=2827.22, ppl=5.26, accuracy=67.4, wps=6876.4, ups=1.64, wpb=4194.7, bsz=160.9, num_updates=57100, lr=5.9183e-05, gnorm=0.364, clip=0, loss_scale=64, train_wall=61, gb_free=15.7, wall=41652
2023-07-09 21:48:41 | INFO | train_inner | epoch 039:   1211 / 1474 loss=1.4, trans_loss=5.132, nll_loss=2.415, w2v_ctc_loss=0.382, task_loss=2.095, contrastive_loss=0.312, total=4123.07, n_correct=2768.33, ppl=5.33, accuracy=67.142, wps=6792.8, ups=1.65, wpb=4123.1, bsz=153.6, num_updates=57200, lr=5.91312e-05, gnorm=0.372, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=41713
2023-07-09 21:49:41 | INFO | train_inner | epoch 039:   1311 / 1474 loss=1.398, trans_loss=5.125, nll_loss=2.405, w2v_ctc_loss=0.383, task_loss=1.986, contrastive_loss=0.286, total=4183.27, n_correct=2815.06, ppl=5.29, accuracy=67.293, wps=6934.4, ups=1.66, wpb=4183.3, bsz=158.8, num_updates=57300, lr=5.90796e-05, gnorm=0.368, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=41773
2023-07-09 21:50:42 | INFO | train_inner | epoch 039:   1411 / 1474 loss=1.399, trans_loss=5.132, nll_loss=2.413, w2v_ctc_loss=0.384, task_loss=2.292, contrastive_loss=0.2, total=4052.15, n_correct=2720.94, ppl=5.32, accuracy=67.148, wps=6725.1, ups=1.66, wpb=4052.2, bsz=139.3, num_updates=57400, lr=5.90281e-05, gnorm=0.374, clip=0, loss_scale=64, train_wall=60, gb_free=13.3, wall=41834
2023-07-09 21:51:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 21:51:45 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 2.281 | trans_loss 5.527 | nll_loss 2.821 | w2v_ctc_loss 0.716 | task_loss 2.365 | contrastive_loss 0.337 | total 4003.4 | n_correct 2509.1 | ppl 7.07 | accuracy 62.674 | uer 16.537 | wer 18.34 | raw_wer 18.34 | bleu 20.04 | wps 2154.2 | wpb 4003.4 | bsz 141.8 | num_updates 57463 | best_bleu 20.44
2023-07-09 21:51:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 57463 updates
2023-07-09 21:51:45 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_last.pt
2023-07-09 21:51:49 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_last.pt
2023-07-09 21:51:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_last.pt (epoch 39 @ 57463 updates, score 20.04) (writing took 4.2289099839981645 seconds)
2023-07-09 21:51:49 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-07-09 21:51:49 | INFO | train | epoch 039 | loss 1.397 | trans_loss 5.12 | nll_loss 2.397 | w2v_ctc_loss 0.381 | task_loss 2.092 | contrastive_loss 0.323 | total 4138.65 | n_correct 2789.09 | ppl 5.27 | accuracy 67.391 | wps 6360 | ups 1.54 | wpb 4138.6 | bsz 152.8 | num_updates 57463 | lr 5.89958e-05 | gnorm 0.369 | clip 0 | loss_scale 64 | train_wall 884 | gb_free 15.7 | wall 41901
2023-07-09 21:51:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 21:51:49 | INFO | fairseq.trainer | begin training epoch 40
2023-07-09 21:51:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 21:52:20 | INFO | train_inner | epoch 040:     37 / 1474 loss=1.392, trans_loss=5.121, nll_loss=2.399, w2v_ctc_loss=0.373, task_loss=2.015, contrastive_loss=0.258, total=4171.45, n_correct=2808.64, ppl=5.28, accuracy=67.33, wps=4255.3, ups=1.02, wpb=4171.4, bsz=156.1, num_updates=57500, lr=5.89768e-05, gnorm=0.37, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=41932
2023-07-09 21:53:20 | INFO | train_inner | epoch 040:    137 / 1474 loss=1.388, trans_loss=5.086, nll_loss=2.353, w2v_ctc_loss=0.378, task_loss=2.1, contrastive_loss=0.249, total=4150.33, n_correct=2819.62, ppl=5.11, accuracy=67.937, wps=6836.6, ups=1.65, wpb=4150.3, bsz=152.4, num_updates=57600, lr=5.89256e-05, gnorm=0.364, clip=0, loss_scale=128, train_wall=60, gb_free=16.2, wall=41992
2023-07-09 21:54:20 | INFO | train_inner | epoch 040:    237 / 1474 loss=1.391, trans_loss=5.1, nll_loss=2.372, w2v_ctc_loss=0.384, task_loss=2.131, contrastive_loss=0.244, total=4101.56, n_correct=2778.4, ppl=5.18, accuracy=67.74, wps=6861.6, ups=1.67, wpb=4101.6, bsz=150.4, num_updates=57700, lr=5.88745e-05, gnorm=0.373, clip=0, loss_scale=128, train_wall=59, gb_free=12.9, wall=42052
2023-07-09 21:55:21 | INFO | train_inner | epoch 040:    337 / 1474 loss=1.389, trans_loss=5.1, nll_loss=2.373, w2v_ctc_loss=0.373, task_loss=1.949, contrastive_loss=0.275, total=4153.24, n_correct=2814.41, ppl=5.18, accuracy=67.764, wps=6846.9, ups=1.65, wpb=4153.2, bsz=159.4, num_updates=57800, lr=5.88235e-05, gnorm=0.37, clip=0, loss_scale=128, train_wall=60, gb_free=17, wall=42113
2023-07-09 21:56:21 | INFO | train_inner | epoch 040:    437 / 1474 loss=1.397, trans_loss=5.111, nll_loss=2.388, w2v_ctc_loss=0.38, task_loss=2.101, contrastive_loss=0.419, total=4138.54, n_correct=2794.81, ppl=5.23, accuracy=67.531, wps=6827.5, ups=1.65, wpb=4138.5, bsz=154.4, num_updates=57900, lr=5.87727e-05, gnorm=0.372, clip=0, loss_scale=128, train_wall=60, gb_free=15.9, wall=42173
2023-07-09 21:57:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-09 21:57:23 | INFO | train_inner | epoch 040:    538 / 1474 loss=1.386, trans_loss=5.097, nll_loss=2.368, w2v_ctc_loss=0.375, task_loss=2.071, contrastive_loss=0.255, total=4144.53, n_correct=2809.88, ppl=5.16, accuracy=67.797, wps=6781.3, ups=1.64, wpb=4144.5, bsz=154.7, num_updates=58000, lr=5.8722e-05, gnorm=0.366, clip=0, loss_scale=64, train_wall=61, gb_free=16.3, wall=42235
2023-07-09 21:57:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 21:57:47 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 2.281 | trans_loss 5.538 | nll_loss 2.839 | w2v_ctc_loss 0.703 | task_loss 2.365 | contrastive_loss 0.337 | total 4003.4 | n_correct 2498.9 | ppl 7.16 | accuracy 62.419 | uer 16.532 | wer 18.389 | raw_wer 18.389 | bleu 19.98 | wps 2281.9 | wpb 4003.4 | bsz 141.8 | num_updates 58000 | best_bleu 20.44
2023-07-09 21:57:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58000 updates
2023-07-09 21:57:47 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_40_58000.pt
2023-07-09 21:57:49 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_40_58000.pt
2023-07-09 21:57:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_40_58000.pt (epoch 40 @ 58000 updates, score 19.98) (writing took 5.192486754996935 seconds)
2023-07-09 21:58:53 | INFO | train_inner | epoch 040:    638 / 1474 loss=1.398, trans_loss=5.126, nll_loss=2.406, w2v_ctc_loss=0.391, task_loss=2.172, contrastive_loss=0.275, total=4118.6, n_correct=2769.48, ppl=5.3, accuracy=67.243, wps=4572.6, ups=1.11, wpb=4118.6, bsz=149.2, num_updates=58100, lr=5.86715e-05, gnorm=0.376, clip=0, loss_scale=64, train_wall=60, gb_free=12.7, wall=42325
2023-07-09 21:59:53 | INFO | train_inner | epoch 040:    738 / 1474 loss=1.392, trans_loss=5.112, nll_loss=2.387, w2v_ctc_loss=0.378, task_loss=2.025, contrastive_loss=0.23, total=4137.91, n_correct=2795.29, ppl=5.23, accuracy=67.553, wps=6877.8, ups=1.66, wpb=4137.9, bsz=154.2, num_updates=58200, lr=5.8621e-05, gnorm=0.37, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=42385
2023-07-09 22:00:54 | INFO | train_inner | epoch 040:    838 / 1474 loss=1.404, trans_loss=5.124, nll_loss=2.404, w2v_ctc_loss=0.376, task_loss=1.892, contrastive_loss=0.647, total=4214.92, n_correct=2836.24, ppl=5.29, accuracy=67.29, wps=6899.7, ups=1.64, wpb=4214.9, bsz=164.6, num_updates=58300, lr=5.85707e-05, gnorm=0.369, clip=0, loss_scale=64, train_wall=61, gb_free=16.8, wall=42446
2023-07-09 22:01:55 | INFO | train_inner | epoch 040:    938 / 1474 loss=1.395, trans_loss=5.123, nll_loss=2.402, w2v_ctc_loss=0.383, task_loss=2.205, contrastive_loss=0.277, total=4092.24, n_correct=2752.55, ppl=5.28, accuracy=67.263, wps=6732.3, ups=1.65, wpb=4092.2, bsz=146.8, num_updates=58400, lr=5.85206e-05, gnorm=0.372, clip=0, loss_scale=64, train_wall=60, gb_free=15.2, wall=42507
2023-07-09 22:02:55 | INFO | train_inner | epoch 040:   1038 / 1474 loss=1.403, trans_loss=5.14, nll_loss=2.423, w2v_ctc_loss=0.384, task_loss=2.271, contrastive_loss=0.315, total=4119.93, n_correct=2762.79, ppl=5.36, accuracy=67.059, wps=6833.4, ups=1.66, wpb=4119.9, bsz=143.8, num_updates=58500, lr=5.84705e-05, gnorm=0.375, clip=0, loss_scale=64, train_wall=60, gb_free=16, wall=42567
2023-07-09 22:03:56 | INFO | train_inner | epoch 040:   1138 / 1474 loss=1.397, trans_loss=5.128, nll_loss=2.408, w2v_ctc_loss=0.385, task_loss=2.18, contrastive_loss=0.258, total=4124.74, n_correct=2774.11, ppl=5.31, accuracy=67.255, wps=6733.6, ups=1.63, wpb=4124.7, bsz=149.2, num_updates=58600, lr=5.84206e-05, gnorm=0.375, clip=0, loss_scale=64, train_wall=61, gb_free=16.9, wall=42628
2023-07-09 22:04:57 | INFO | train_inner | epoch 040:   1238 / 1474 loss=1.397, trans_loss=5.119, nll_loss=2.397, w2v_ctc_loss=0.378, task_loss=2.057, contrastive_loss=0.375, total=4198.52, n_correct=2832.26, ppl=5.27, accuracy=67.459, wps=6916.3, ups=1.65, wpb=4198.5, bsz=155.4, num_updates=58700, lr=5.83708e-05, gnorm=0.373, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=42689
2023-07-09 22:05:57 | INFO | train_inner | epoch 040:   1338 / 1474 loss=1.396, trans_loss=5.121, nll_loss=2.4, w2v_ctc_loss=0.374, task_loss=2.106, contrastive_loss=0.384, total=4124.38, n_correct=2777.49, ppl=5.28, accuracy=67.343, wps=6858.9, ups=1.66, wpb=4124.4, bsz=153, num_updates=58800, lr=5.83212e-05, gnorm=0.374, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=42749
2023-07-09 22:06:57 | INFO | train_inner | epoch 040:   1438 / 1474 loss=1.403, trans_loss=5.135, nll_loss=2.417, w2v_ctc_loss=0.385, task_loss=2.095, contrastive_loss=0.317, total=4121.8, n_correct=2767.03, ppl=5.34, accuracy=67.132, wps=6827.7, ups=1.66, wpb=4121.8, bsz=152.2, num_updates=58900, lr=5.82717e-05, gnorm=0.371, clip=0, loss_scale=64, train_wall=60, gb_free=15.8, wall=42809
2023-07-09 22:07:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 22:07:44 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 2.283 | trans_loss 5.534 | nll_loss 2.832 | w2v_ctc_loss 0.714 | task_loss 2.365 | contrastive_loss 0.344 | total 4003.4 | n_correct 2504 | ppl 7.12 | accuracy 62.547 | uer 16.465 | wer 18.169 | raw_wer 18.169 | bleu 19.91 | wps 2204.3 | wpb 4003.4 | bsz 141.8 | num_updates 58936 | best_bleu 20.44
2023-07-09 22:07:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58936 updates
2023-07-09 22:07:44 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_last.pt
2023-07-09 22:07:48 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_last.pt
2023-07-09 22:07:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_last.pt (epoch 40 @ 58936 updates, score 19.91) (writing took 4.344485442998121 seconds)
2023-07-09 22:07:48 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-07-09 22:07:48 | INFO | train | epoch 040 | loss 1.395 | trans_loss 5.116 | nll_loss 2.392 | w2v_ctc_loss 0.38 | task_loss 2.096 | contrastive_loss 0.32 | total 4136.58 | n_correct 2790.43 | ppl 5.25 | accuracy 67.457 | wps 6352.5 | ups 1.54 | wpb 4136.6 | bsz 152.5 | num_updates 58936 | lr 5.82539e-05 | gnorm 0.371 | clip 0 | loss_scale 64 | train_wall 885 | gb_free 16 | wall 42860
2023-07-09 22:07:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-09 22:07:48 | INFO | fairseq.trainer | begin training epoch 41
2023-07-09 22:07:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-09 22:08:35 | INFO | train_inner | epoch 041:     64 / 1474 loss=1.394, trans_loss=5.105, nll_loss=2.378, w2v_ctc_loss=0.376, task_loss=2.163, contrastive_loss=0.261, total=4088.95, n_correct=2763.35, ppl=5.2, accuracy=67.581, wps=4189.8, ups=1.02, wpb=4089, bsz=147.8, num_updates=59000, lr=5.82223e-05, gnorm=0.371, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=42907
2023-07-09 22:09:35 | INFO | train_inner | epoch 041:    164 / 1474 loss=1.386, trans_loss=5.085, nll_loss=2.353, w2v_ctc_loss=0.373, task_loss=2.03, contrastive_loss=0.366, total=4141.51, n_correct=2816, ppl=5.11, accuracy=67.995, wps=6861.6, ups=1.66, wpb=4141.5, bsz=155.7, num_updates=59100, lr=5.8173e-05, gnorm=0.371, clip=0, loss_scale=64, train_wall=60, gb_free=16, wall=42967
2023-07-09 22:10:36 | INFO | train_inner | epoch 041:    264 / 1474 loss=1.389, trans_loss=5.094, nll_loss=2.365, w2v_ctc_loss=0.371, task_loss=1.941, contrastive_loss=0.356, total=4181.72, n_correct=2837.49, ppl=5.15, accuracy=67.855, wps=6956.4, ups=1.66, wpb=4181.7, bsz=159.6, num_updates=59200, lr=5.81238e-05, gnorm=0.369, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=43028
2023-07-09 22:11:36 | INFO | train_inner | epoch 041:    364 / 1474 loss=1.388, trans_loss=5.099, nll_loss=2.371, w2v_ctc_loss=0.377, task_loss=2.088, contrastive_loss=0.272, total=4147.02, n_correct=2810.05, ppl=5.17, accuracy=67.761, wps=6853.2, ups=1.65, wpb=4147, bsz=152.5, num_updates=59300, lr=5.80748e-05, gnorm=0.371, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=43088
2023-07-09 22:12:36 | INFO | train_inner | epoch 041:    464 / 1474 loss=1.387, trans_loss=5.1, nll_loss=2.372, w2v_ctc_loss=0.375, task_loss=2.102, contrastive_loss=0.237, total=4144.36, n_correct=2805.23, ppl=5.18, accuracy=67.688, wps=6855.1, ups=1.65, wpb=4144.4, bsz=151.4, num_updates=59400, lr=5.80259e-05, gnorm=0.373, clip=0, loss_scale=64, train_wall=60, gb_free=16, wall=43148
2023-07-09 22:13:37 | INFO | train_inner | epoch 041:    564 / 1474 loss=1.389, trans_loss=5.103, nll_loss=2.375, w2v_ctc_loss=0.378, task_loss=2.094, contrastive_loss=0.281, total=4145.19, n_correct=2806.11, ppl=5.19, accuracy=67.696, wps=6842.6, ups=1.65, wpb=4145.2, bsz=153.6, num_updates=59500, lr=5.79771e-05, gnorm=0.37, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=43209
2023-07-09 22:14:37 | INFO | train_inner | epoch 041:    664 / 1474 loss=1.387, trans_loss=5.095, nll_loss=2.365, w2v_ctc_loss=0.372, task_loss=1.968, contrastive_loss=0.252, total=4189.74, n_correct=2841.83, ppl=5.15, accuracy=67.828, wps=6949.4, ups=1.66, wpb=4189.7, bsz=159, num_updates=59600, lr=5.79284e-05, gnorm=0.372, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=43269
2023-07-09 22:15:38 | INFO | train_inner | epoch 041:    764 / 1474 loss=1.391, trans_loss=5.106, nll_loss=2.38, w2v_ctc_loss=0.376, task_loss=2.114, contrastive_loss=0.24, total=4150.75, n_correct=2806.5, ppl=5.21, accuracy=67.614, wps=6887.1, ups=1.66, wpb=4150.8, bsz=150.4, num_updates=59700, lr=5.78799e-05, gnorm=0.372, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=43330
2023-07-09 22:16:38 | INFO | train_inner | epoch 041:    864 / 1474 loss=1.39, trans_loss=5.101, nll_loss=2.374, w2v_ctc_loss=0.374, task_loss=2.17, contrastive_loss=0.24, total=4108.1, n_correct=2780.82, ppl=5.18, accuracy=67.691, wps=6850.8, ups=1.67, wpb=4108.1, bsz=147.9, num_updates=59800, lr=5.78315e-05, gnorm=0.373, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=43390
2023-07-09 22:17:39 | INFO | train_inner | epoch 041:    964 / 1474 loss=1.401, trans_loss=5.123, nll_loss=2.402, w2v_ctc_loss=0.384, task_loss=2.177, contrastive_loss=0.427, total=4122.2, n_correct=2774.34, ppl=5.29, accuracy=67.302, wps=6759.4, ups=1.64, wpb=4122.2, bsz=149.6, num_updates=59900, lr=5.77832e-05, gnorm=0.375, clip=0, loss_scale=64, train_wall=61, gb_free=15.2, wall=43451
2023-07-09 22:18:38 | INFO | train_inner | epoch 041:   1064 / 1474 loss=1.394, trans_loss=5.125, nll_loss=2.405, w2v_ctc_loss=0.379, task_loss=2.08, contrastive_loss=0.257, total=4133.83, n_correct=2780.35, ppl=5.3, accuracy=67.258, wps=6902.4, ups=1.67, wpb=4133.8, bsz=152, num_updates=60000, lr=5.7735e-05, gnorm=0.373, clip=0, loss_scale=64, train_wall=59, gb_free=12.8, wall=43510
2023-07-09 22:18:38 | INFO | fairseq_cli.train | Stopping training due to num_updates: 60000 >= max_update: 60000
2023-07-09 22:18:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-09 22:19:03 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 2.28 | trans_loss 5.529 | nll_loss 2.829 | w2v_ctc_loss 0.714 | task_loss 2.365 | contrastive_loss 0.355 | total 4003.4 | n_correct 2503.9 | ppl 7.11 | accuracy 62.544 | uer 16.434 | wer 18.314 | raw_wer 18.314 | bleu 20.33 | wps 2141.8 | wpb 4003.4 | bsz 141.8 | num_updates 60000 | best_bleu 20.44
2023-07-09 22:19:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 60000 updates
2023-07-09 22:19:03 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_41_60000.pt
2023-07-09 22:19:05 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_41_60000.pt
2023-07-09 22:19:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_l2norm_proj_st/checkpoint_41_60000.pt (epoch 41 @ 60000 updates, score 20.33) (writing took 6.053255594015354 seconds)
2023-07-09 22:19:10 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-07-09 22:19:10 | INFO | train | epoch 041 | loss 1.39 | trans_loss 5.103 | nll_loss 2.375 | w2v_ctc_loss 0.376 | task_loss 2.079 | contrastive_loss 0.292 | total 4144.26 | n_correct 2804.54 | ppl 5.19 | accuracy 67.673 | wps 6466.9 | ups 1.56 | wpb 4144.3 | bsz 153 | num_updates 60000 | lr 5.7735e-05 | gnorm 0.372 | clip 0 | loss_scale 64 | train_wall 638 | gb_free 12.8 | wall 43542
2023-07-09 22:19:10 | INFO | fairseq_cli.train | done training in 43472.5 seconds
/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1776 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
