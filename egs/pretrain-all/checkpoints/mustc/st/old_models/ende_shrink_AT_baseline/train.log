2023-07-04 03:53:29 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:17988
2023-07-04 03:53:29 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:17988
2023-07-04 03:53:29 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:17988
2023-07-04 03:53:29 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:17988
2023-07-04 03:53:29 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:17988
2023-07-04 03:53:29 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:17988
2023-07-04 03:53:29 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:17988
2023-07-04 03:53:29 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:17988
2023-07-04 03:53:29 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-04 03:53:30 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-04 03:53:30 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-04 03:53:30 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-04 03:53:30 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-04 03:53:30 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-04 03:53:30 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-04 03:53:30 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-04 03:53:30 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-04 03:53:30 | INFO | fairseq.distributed.utils | initialized host capios as rank 5
2023-07-04 03:53:30 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-04 03:53:30 | INFO | fairseq.distributed.utils | initialized host capios as rank 1
2023-07-04 03:53:30 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-04 03:53:30 | INFO | fairseq.distributed.utils | initialized host capios as rank 6
2023-07-04 03:53:30 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-04 03:53:30 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-04 03:53:30 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-04 03:53:30 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-04 03:53:30 | INFO | fairseq.distributed.utils | initialized host capios as rank 4
2023-07-04 03:53:30 | INFO | fairseq.distributed.utils | initialized host capios as rank 3
2023-07-04 03:53:30 | INFO | fairseq.distributed.utils | initialized host capios as rank 7
2023-07-04 03:53:30 | INFO | fairseq.distributed.utils | initialized host capios as rank 2
2023-07-04 03:53:30 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-04 03:53:30 | INFO | fairseq.distributed.utils | initialized host capios as rank 0
2023-07-04 03:53:33 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_baseline', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:17988', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_baseline', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_baseline', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_baseline', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_baseline', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_baseline', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_baseline', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_baseline', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-04 03:53:33 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-04 03:53:33 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-04 03:53:33 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-04 03:53:33 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-04 03:53:33 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-04 03:53:37 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-04 03:53:37 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-04 03:53:37 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-04 03:53:39 | INFO | root | load pretrained hubert
2023-07-04 03:53:42 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-04 03:53:43 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-04 03:53:45 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-04 03:53:45 | INFO | root | share the sematic adapter and textual encoder
2023-07-04 03:53:45 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-04 03:53:45 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-04 03:53:45 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-04 03:53:45 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-04 03:53:45 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-04 03:53:45 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-04 03:53:45 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-04 03:53:45 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-04 03:53:46 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-04 03:53:46 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-04 03:53:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-04 03:53:53 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-04 03:53:53 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-04 03:53:54 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-04 03:53:54 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-04 03:53:54 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-04 03:53:54 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-04 03:53:54 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-04 03:53:54 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-04 03:53:54 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-04 03:53:54 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-04 03:53:54 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-04 03:53:54 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-04 03:53:54 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-04 03:53:54 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-04 03:53:54 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_last.pt
2023-07-04 03:53:54 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_last.pt
2023-07-04 03:53:54 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-04 03:53:54 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-04 03:53:54 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-04 03:53:54 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-04 03:53:55 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-04 03:53:57 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-04 03:53:59 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-04 03:55:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 03:55:04 | INFO | fairseq.trainer | begin training epoch 1
2023-07-04 03:55:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 03:55:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-04 03:55:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-04 03:56:03 | INFO | train_inner | epoch 001:    102 / 1474 loss=21.301, trans_loss=5.638, nll_loss=4.212, w2v_ctc_loss=23.087, task_loss=0, contrastive_loss=3.3, total=4189.76, n_correct=211.26, ppl=18.54, accuracy=5.042, wps=25569.1, ups=2.04, wpb=12515.9, bsz=463.7, num_updates=100, lr=4.098e-06, gnorm=0.956, clip=0, loss_scale=32, train_wall=51, gb_free=19, wall=129
2023-07-04 03:56:50 | INFO | train_inner | epoch 001:    202 / 1474 loss=19.03, trans_loss=5.468, nll_loss=4.06, w2v_ctc_loss=19.841, task_loss=0, contrastive_loss=3.286, total=4125.46, n_correct=243.52, ppl=16.68, accuracy=5.903, wps=26087.5, ups=2.12, wpb=12321.8, bsz=461.7, num_updates=200, lr=8.096e-06, gnorm=3.709, clip=0, loss_scale=32, train_wall=47, gb_free=19, wall=176
2023-07-04 03:57:36 | INFO | train_inner | epoch 001:    302 / 1474 loss=11.935, trans_loss=5.468, nll_loss=4.116, w2v_ctc_loss=9.009, task_loss=0, contrastive_loss=3.198, total=4077.62, n_correct=228.96, ppl=17.34, accuracy=5.615, wps=26354.3, ups=2.16, wpb=12184.2, bsz=437.4, num_updates=300, lr=1.2094e-05, gnorm=4.76, clip=0, loss_scale=32, train_wall=46, gb_free=19.5, wall=223
2023-07-04 03:58:23 | INFO | train_inner | epoch 001:    402 / 1474 loss=10.664, trans_loss=5.491, nll_loss=4.165, w2v_ctc_loss=6.993, task_loss=0, contrastive_loss=3.237, total=4177.45, n_correct=214.58, ppl=17.94, accuracy=5.137, wps=26619.4, ups=2.13, wpb=12472.6, bsz=462.8, num_updates=400, lr=1.6092e-05, gnorm=3.081, clip=0, loss_scale=32, train_wall=46, gb_free=19, wall=269
2023-07-04 03:59:10 | INFO | train_inner | epoch 001:    502 / 1474 loss=10.196, trans_loss=5.466, nll_loss=4.144, w2v_ctc_loss=6.292, task_loss=0, contrastive_loss=3.306, total=4202.06, n_correct=215.19, ppl=17.68, accuracy=5.121, wps=26882.2, ups=2.14, wpb=12582.1, bsz=490.7, num_updates=500, lr=2.009e-05, gnorm=1.478, clip=0, loss_scale=32, train_wall=46, gb_free=16.9, wall=316
2023-07-04 03:59:56 | INFO | train_inner | epoch 001:    602 / 1474 loss=9.961, trans_loss=5.5, nll_loss=4.189, w2v_ctc_loss=5.987, task_loss=0, contrastive_loss=3.204, total=4124.52, n_correct=198.79, ppl=18.24, accuracy=4.82, wps=26609.2, ups=2.16, wpb=12305.7, bsz=471, num_updates=600, lr=2.4088e-05, gnorm=0.749, clip=0, loss_scale=32, train_wall=46, gb_free=19.1, wall=363
2023-07-04 04:00:43 | INFO | train_inner | epoch 001:    702 / 1474 loss=9.784, trans_loss=5.486, nll_loss=4.181, w2v_ctc_loss=5.841, task_loss=0, contrastive_loss=3.03, total=4147.01, n_correct=217.9, ppl=18.14, accuracy=5.254, wps=26727.9, ups=2.16, wpb=12358.1, bsz=455.2, num_updates=700, lr=2.8086e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=46, gb_free=19.4, wall=409
2023-07-04 04:01:29 | INFO | train_inner | epoch 001:    802 / 1474 loss=9.498, trans_loss=5.439, nll_loss=4.126, w2v_ctc_loss=5.602, task_loss=0, contrastive_loss=2.931, total=4121.11, n_correct=250.25, ppl=17.45, accuracy=6.072, wps=26776.3, ups=2.18, wpb=12306.8, bsz=463.4, num_updates=800, lr=3.2084e-05, gnorm=0.843, clip=0, loss_scale=32, train_wall=46, gb_free=19.3, wall=455
2023-07-04 04:02:15 | INFO | train_inner | epoch 001:    902 / 1474 loss=9.242, trans_loss=5.416, nll_loss=4.112, w2v_ctc_loss=5.421, task_loss=0, contrastive_loss=2.684, total=4167.98, n_correct=269.85, ppl=17.29, accuracy=6.474, wps=26919.9, ups=2.17, wpb=12422.1, bsz=457.5, num_updates=900, lr=3.6082e-05, gnorm=1.395, clip=0, loss_scale=32, train_wall=46, gb_free=19.2, wall=501
2023-07-04 04:03:01 | INFO | train_inner | epoch 001:   1002 / 1474 loss=8.964, trans_loss=5.394, nll_loss=4.089, w2v_ctc_loss=5.188, task_loss=0, contrastive_loss=2.542, total=4136.38, n_correct=294.37, ppl=17.02, accuracy=7.117, wps=26644.9, ups=2.16, wpb=12363.4, bsz=458.8, num_updates=1000, lr=4.008e-05, gnorm=1.438, clip=0, loss_scale=32, train_wall=46, gb_free=19.5, wall=547
2023-07-04 04:03:48 | INFO | train_inner | epoch 001:   1102 / 1474 loss=8.706, trans_loss=5.386, nll_loss=4.083, w2v_ctc_loss=4.997, task_loss=0, contrastive_loss=2.308, total=4148.31, n_correct=311.95, ppl=16.95, accuracy=7.52, wps=26456.6, ups=2.14, wpb=12363.5, bsz=453.4, num_updates=1100, lr=4.4078e-05, gnorm=1.752, clip=0, loss_scale=32, train_wall=46, gb_free=18.9, wall=594
2023-07-04 04:04:34 | INFO | train_inner | epoch 001:   1202 / 1474 loss=8.462, trans_loss=5.365, nll_loss=4.063, w2v_ctc_loss=4.809, task_loss=0, contrastive_loss=2.104, total=4134.43, n_correct=322.18, ppl=16.72, accuracy=7.793, wps=26730.6, ups=2.16, wpb=12370.3, bsz=438.4, num_updates=1200, lr=4.8076e-05, gnorm=1.801, clip=0, loss_scale=32, train_wall=46, gb_free=19.6, wall=640
2023-07-04 04:05:20 | INFO | train_inner | epoch 001:   1302 / 1474 loss=8.25, trans_loss=5.361, nll_loss=4.061, w2v_ctc_loss=4.617, task_loss=0, contrastive_loss=1.935, total=4055.44, n_correct=319.18, ppl=16.7, accuracy=7.87, wps=26335.5, ups=2.17, wpb=12117.4, bsz=442.9, num_updates=1300, lr=5.2074e-05, gnorm=1.83, clip=0, loss_scale=32, train_wall=46, gb_free=19.3, wall=686
2023-07-04 04:06:07 | INFO | train_inner | epoch 001:   1402 / 1474 loss=8.062, trans_loss=5.358, nll_loss=4.07, w2v_ctc_loss=4.437, task_loss=0, contrastive_loss=1.995, total=4125.61, n_correct=328.49, ppl=16.8, accuracy=7.962, wps=26511.6, ups=2.16, wpb=12282.5, bsz=452, num_updates=1400, lr=5.6072e-05, gnorm=1.74, clip=0, loss_scale=32, train_wall=46, gb_free=18.8, wall=733
2023-07-04 04:06:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-07-04 04:07:13 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.906 | trans_loss 10.928 | nll_loss 9.904 | w2v_ctc_loss 5.798 | task_loss 0 | contrastive_loss 2.345 | total 4003.4 | n_correct 379.7 | ppl 958.19 | accuracy 9.484 | uer 71.611 | wer 69.509 | raw_wer 69.509 | bleu 0.02 | wps 1487 | wpb 4003.4 | bsz 141.8 | num_updates 1472
2023-07-04 04:07:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1472 updates
2023-07-04 04:07:13 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 04:07:16 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 04:07:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt (epoch 1 @ 1472 updates, score 0.02) (writing took 4.99380560638383 seconds)
2023-07-04 04:07:18 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-07-04 04:07:18 | INFO | train | epoch 001 | loss 10.862 | trans_loss 5.441 | nll_loss 4.116 | w2v_ctc_loss 7.839 | task_loss 0 | contrastive_loss 2.75 | total 4137.53 | n_correct 262.702 | ppl 17.34 | accuracy 6.349 | wps 25117.2 | ups 2.03 | wpb 12352.4 | bsz 458 | num_updates 1472 | lr 5.89506e-05 | gnorm 1.859 | clip 0 | loss_scale 32 | train_wall 682 | gb_free 19.2 | wall 804
2023-07-04 04:07:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 04:07:18 | INFO | fairseq.trainer | begin training epoch 2
2023-07-04 04:07:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 04:07:39 | INFO | train_inner | epoch 002:     28 / 1474 loss=7.866, trans_loss=5.351, nll_loss=4.049, w2v_ctc_loss=4.228, task_loss=0, contrastive_loss=1.846, total=4164.65, n_correct=336.41, ppl=16.55, accuracy=8.078, wps=13360.8, ups=1.08, wpb=12416.9, bsz=471.6, num_updates=1500, lr=6.007e-05, gnorm=1.727, clip=0, loss_scale=32, train_wall=46, gb_free=18.9, wall=826
2023-07-04 04:08:26 | INFO | train_inner | epoch 002:    128 / 1474 loss=7.695, trans_loss=5.352, nll_loss=4.051, w2v_ctc_loss=4.101, task_loss=0, contrastive_loss=1.644, total=4153.14, n_correct=338.51, ppl=16.57, accuracy=8.151, wps=26669.7, ups=2.15, wpb=12382.5, bsz=450.6, num_updates=1600, lr=6.4068e-05, gnorm=1.728, clip=0, loss_scale=32, train_wall=46, gb_free=19.8, wall=872
2023-07-04 04:09:12 | INFO | train_inner | epoch 002:    228 / 1474 loss=7.531, trans_loss=5.324, nll_loss=4.019, w2v_ctc_loss=3.904, task_loss=0, contrastive_loss=1.678, total=4192.9, n_correct=349.69, ppl=16.21, accuracy=8.34, wps=27187.4, ups=2.17, wpb=12524.1, bsz=493, num_updates=1700, lr=6.8066e-05, gnorm=1.522, clip=0, loss_scale=32, train_wall=46, gb_free=19.2, wall=918
2023-07-04 04:09:58 | INFO | train_inner | epoch 002:    328 / 1474 loss=7.359, trans_loss=5.329, nll_loss=4.022, w2v_ctc_loss=3.807, task_loss=0, contrastive_loss=1.376, total=4132.45, n_correct=347.04, ppl=16.24, accuracy=8.398, wps=26613.4, ups=2.16, wpb=12344.7, bsz=443.2, num_updates=1800, lr=7.2064e-05, gnorm=1.517, clip=0, loss_scale=32, train_wall=46, gb_free=19.4, wall=964
2023-07-04 04:10:44 | INFO | train_inner | epoch 002:    428 / 1474 loss=7.211, trans_loss=5.318, nll_loss=4.012, w2v_ctc_loss=3.703, task_loss=0, contrastive_loss=1.205, total=4037.61, n_correct=340.1, ppl=16.14, accuracy=8.423, wps=26317.4, ups=2.18, wpb=12077.3, bsz=415.8, num_updates=1900, lr=7.6062e-05, gnorm=1.464, clip=0, loss_scale=32, train_wall=46, gb_free=19.9, wall=1010
2023-07-04 04:11:30 | INFO | train_inner | epoch 002:    528 / 1474 loss=7.118, trans_loss=5.313, nll_loss=4.002, w2v_ctc_loss=3.542, task_loss=0, contrastive_loss=1.313, total=4183.4, n_correct=362.96, ppl=16.02, accuracy=8.676, wps=27121.2, ups=2.17, wpb=12489.2, bsz=470.3, num_updates=2000, lr=8.006e-05, gnorm=1.379, clip=0, loss_scale=32, train_wall=46, gb_free=19, wall=1056
2023-07-04 04:11:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 04:12:04 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 9.283 | trans_loss 10.778 | nll_loss 9.701 | w2v_ctc_loss 4.685 | task_loss 0 | contrastive_loss 1.626 | total 4003.4 | n_correct 405.5 | ppl 832.56 | accuracy 10.129 | uer 61.824 | wer 59.61 | raw_wer 59.61 | bleu 0.06 | wps 1504.7 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.06
2023-07-04 04:12:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-07-04 04:12:04 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_2_2000.pt
2023-07-04 04:12:06 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_2_2000.pt
2023-07-04 04:12:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.06) (writing took 10.869000603910536 seconds)
2023-07-04 04:13:00 | INFO | train_inner | epoch 002:    628 / 1474 loss=6.981, trans_loss=5.299, nll_loss=3.988, w2v_ctc_loss=3.44, task_loss=0, contrastive_loss=1.107, total=4126.46, n_correct=362.96, ppl=15.87, accuracy=8.796, wps=13689.3, ups=1.11, wpb=12304.9, bsz=446.7, num_updates=2100, lr=8.4058e-05, gnorm=1.181, clip=0, loss_scale=64, train_wall=45, gb_free=19.3, wall=1146
2023-07-04 04:13:46 | INFO | train_inner | epoch 002:    728 / 1474 loss=6.903, trans_loss=5.283, nll_loss=3.971, w2v_ctc_loss=3.355, task_loss=0, contrastive_loss=1.196, total=4148.66, n_correct=376.42, ppl=15.69, accuracy=9.073, wps=26928, ups=2.18, wpb=12368.2, bsz=462.9, num_updates=2200, lr=8.8056e-05, gnorm=1.133, clip=0, loss_scale=64, train_wall=46, gb_free=19.7, wall=1192
2023-07-04 04:14:32 | INFO | train_inner | epoch 002:    828 / 1474 loss=6.817, trans_loss=5.278, nll_loss=3.964, w2v_ctc_loss=3.275, task_loss=0, contrastive_loss=1.151, total=4164.61, n_correct=376.82, ppl=15.6, accuracy=9.048, wps=26993.4, ups=2.17, wpb=12446.9, bsz=459.2, num_updates=2300, lr=9.2054e-05, gnorm=1.073, clip=0, loss_scale=64, train_wall=46, gb_free=19.5, wall=1238
2023-07-04 04:15:18 | INFO | train_inner | epoch 002:    928 / 1474 loss=6.723, trans_loss=5.266, nll_loss=3.95, w2v_ctc_loss=3.179, task_loss=0, contrastive_loss=1.131, total=4109.63, n_correct=373.77, ppl=15.45, accuracy=9.095, wps=26710, ups=2.18, wpb=12261.8, bsz=447.9, num_updates=2400, lr=9.6052e-05, gnorm=1.053, clip=0, loss_scale=64, train_wall=46, gb_free=18.9, wall=1284
2023-07-04 04:16:04 | INFO | train_inner | epoch 002:   1028 / 1474 loss=6.634, trans_loss=5.258, nll_loss=3.938, w2v_ctc_loss=3.104, task_loss=0, contrastive_loss=0.988, total=4101.19, n_correct=379.97, ppl=15.32, accuracy=9.265, wps=26752.2, ups=2.18, wpb=12262.4, bsz=454.5, num_updates=2500, lr=0.00010005, gnorm=0.943, clip=0, loss_scale=64, train_wall=45, gb_free=19, wall=1330
2023-07-04 04:16:50 | INFO | train_inner | epoch 002:   1128 / 1474 loss=6.606, trans_loss=5.245, nll_loss=3.924, w2v_ctc_loss=3.025, task_loss=0, contrastive_loss=1.202, total=4192.73, n_correct=395.47, ppl=15.18, accuracy=9.432, wps=26984.9, ups=2.16, wpb=12503.4, bsz=488.9, num_updates=2600, lr=0.000104048, gnorm=0.927, clip=0, loss_scale=64, train_wall=46, gb_free=18.9, wall=1376
2023-07-04 04:17:37 | INFO | train_inner | epoch 002:   1228 / 1474 loss=6.539, trans_loss=5.232, nll_loss=3.908, w2v_ctc_loss=2.978, task_loss=0, contrastive_loss=1.121, total=4219.96, n_correct=408.92, ppl=15.01, accuracy=9.69, wps=27114.9, ups=2.15, wpb=12583.5, bsz=491.8, num_updates=2700, lr=0.000108046, gnorm=0.818, clip=0, loss_scale=64, train_wall=46, gb_free=18.9, wall=1423
2023-07-04 04:18:23 | INFO | train_inner | epoch 002:   1328 / 1474 loss=6.43, trans_loss=5.215, nll_loss=3.892, w2v_ctc_loss=2.931, task_loss=0, contrastive_loss=0.833, total=4163.26, n_correct=409.41, ppl=14.84, accuracy=9.834, wps=27082.7, ups=2.18, wpb=12439.7, bsz=463, num_updates=2800, lr=0.000112044, gnorm=0.795, clip=0, loss_scale=64, train_wall=46, gb_free=19, wall=1469
2023-07-04 04:19:09 | INFO | train_inner | epoch 002:   1428 / 1474 loss=6.391, trans_loss=5.216, nll_loss=3.887, w2v_ctc_loss=2.888, task_loss=0, contrastive_loss=0.921, total=4049.42, n_correct=395.98, ppl=14.8, accuracy=9.779, wps=26006, ups=2.15, wpb=12112.8, bsz=437.6, num_updates=2900, lr=0.000116042, gnorm=0.765, clip=0, loss_scale=64, train_wall=46, gb_free=19.2, wall=1515
2023-07-04 04:19:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 04:20:04 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.502 | trans_loss 10.282 | nll_loss 9.096 | w2v_ctc_loss 3.731 | task_loss 0 | contrastive_loss 1.002 | total 4003.4 | n_correct 494.4 | ppl 547.12 | accuracy 12.35 | uer 51.613 | wer 50.371 | raw_wer 50.371 | bleu 0.13 | wps 1501.5 | wpb 4003.4 | bsz 141.8 | num_updates 2946 | best_bleu 0.13
2023-07-04 04:20:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2946 updates
2023-07-04 04:20:04 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 04:20:08 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 04:20:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt (epoch 2 @ 2946 updates, score 0.13) (writing took 8.543512023054063 seconds)
2023-07-04 04:20:12 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-07-04 04:20:12 | INFO | train | epoch 002 | loss 6.924 | trans_loss 5.28 | nll_loss 3.965 | w2v_ctc_loss 3.373 | task_loss 0 | contrastive_loss 1.208 | total 4138.65 | n_correct 372.995 | ppl 15.62 | accuracy 9.012 | wps 23527.6 | ups 1.9 | wpb 12355.8 | bsz 458.5 | num_updates 2946 | lr 0.000117881 | gnorm 1.162 | clip 0 | loss_scale 64 | train_wall 675 | gb_free 19.3 | wall 1578
2023-07-04 04:20:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 04:20:12 | INFO | fairseq.trainer | begin training epoch 3
2023-07-04 04:20:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 04:20:45 | INFO | train_inner | epoch 003:     54 / 1474 loss=6.316, trans_loss=5.202, nll_loss=3.872, w2v_ctc_loss=2.827, task_loss=0, contrastive_loss=0.822, total=4067, n_correct=411.39, ppl=14.64, accuracy=10.115, wps=12724.2, ups=1.05, wpb=12138.5, bsz=441.4, num_updates=3000, lr=0.00012004, gnorm=0.739, clip=0, loss_scale=64, train_wall=46, gb_free=19.2, wall=1611
2023-07-04 04:20:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-04 04:20:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-04 04:20:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-04 04:20:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-07-04 04:21:50 | INFO | train_inner | epoch 003:    158 / 1474 loss=5.515, trans_loss=4.469, nll_loss=2.915, w2v_ctc_loss=2.462, task_loss=0, contrastive_loss=0.686, total=4144.18, n_correct=1071.08, ppl=7.54, accuracy=25.845, wps=18913.9, ups=1.53, wpb=12381.7, bsz=458.6, num_updates=3100, lr=0.000124038, gnorm=1.738, clip=1, loss_scale=4, train_wall=65, gb_free=16.7, wall=1676
2023-07-04 04:22:54 | INFO | train_inner | epoch 003:    258 / 1474 loss=5.079, trans_loss=4.186, nll_loss=2.542, w2v_ctc_loss=2.194, task_loss=0, contrastive_loss=0.6, total=4161.13, n_correct=1385.08, ppl=5.83, accuracy=33.286, wps=19435.1, ups=1.56, wpb=12444.3, bsz=467, num_updates=3200, lr=0.000128036, gnorm=1.209, clip=0, loss_scale=4, train_wall=64, gb_free=17.3, wall=1740
2023-07-04 04:23:58 | INFO | train_inner | epoch 003:    358 / 1474 loss=4.937, trans_loss=4.098, nll_loss=2.425, w2v_ctc_loss=2.088, task_loss=0, contrastive_loss=0.636, total=4150.02, n_correct=1506.86, ppl=5.37, accuracy=36.31, wps=19546.6, ups=1.58, wpb=12369, bsz=461.6, num_updates=3300, lr=0.000132034, gnorm=1.159, clip=0, loss_scale=4, train_wall=63, gb_free=17.3, wall=1804
2023-07-04 04:25:01 | INFO | train_inner | epoch 003:    458 / 1474 loss=4.788, trans_loss=4.02, nll_loss=2.324, w2v_ctc_loss=2.001, task_loss=0, contrastive_loss=0.491, total=4209.57, n_correct=1637.36, ppl=5.01, accuracy=38.896, wps=19774.4, ups=1.58, wpb=12537.6, bsz=476.8, num_updates=3400, lr=0.000136032, gnorm=1.084, clip=0, loss_scale=4, train_wall=63, gb_free=16.2, wall=1867
2023-07-04 04:26:04 | INFO | train_inner | epoch 003:    558 / 1474 loss=4.682, trans_loss=3.98, nll_loss=2.267, w2v_ctc_loss=1.909, task_loss=0, contrastive_loss=0.461, total=4088.48, n_correct=1656.23, ppl=4.81, accuracy=40.51, wps=19375.2, ups=1.58, wpb=12237.1, bsz=439.7, num_updates=3500, lr=0.00014003, gnorm=1.02, clip=0, loss_scale=4, train_wall=63, gb_free=17.8, wall=1930
2023-07-04 04:27:08 | INFO | train_inner | epoch 003:    658 / 1474 loss=4.619, trans_loss=3.933, nll_loss=2.208, w2v_ctc_loss=1.846, task_loss=0, contrastive_loss=0.571, total=4221.58, n_correct=1788.27, ppl=4.62, accuracy=42.36, wps=19552.9, ups=1.56, wpb=12558.6, bsz=481.9, num_updates=3600, lr=0.000144028, gnorm=0.982, clip=0, loss_scale=4, train_wall=64, gb_free=16.5, wall=1994
2023-07-04 04:28:11 | INFO | train_inner | epoch 003:    758 / 1474 loss=4.538, trans_loss=3.9, nll_loss=2.164, w2v_ctc_loss=1.808, task_loss=0, contrastive_loss=0.338, total=4167.41, n_correct=1813.41, ppl=4.48, accuracy=43.514, wps=19791.8, ups=1.59, wpb=12462.8, bsz=472.6, num_updates=3700, lr=0.000148026, gnorm=0.975, clip=0, loss_scale=4, train_wall=63, gb_free=16.5, wall=2057
2023-07-04 04:29:14 | INFO | train_inner | epoch 003:    858 / 1474 loss=4.48, trans_loss=3.882, nll_loss=2.14, w2v_ctc_loss=1.761, task_loss=0, contrastive_loss=0.301, total=4165.53, n_correct=1840.22, ppl=4.41, accuracy=44.177, wps=19695.5, ups=1.58, wpb=12445.3, bsz=456.1, num_updates=3800, lr=0.000152024, gnorm=0.934, clip=0, loss_scale=4, train_wall=63, gb_free=17.2, wall=2121
2023-07-04 04:30:18 | INFO | train_inner | epoch 003:    958 / 1474 loss=4.451, trans_loss=3.857, nll_loss=2.108, w2v_ctc_loss=1.741, task_loss=0, contrastive_loss=0.333, total=4162.3, n_correct=1882.01, ppl=4.31, accuracy=45.216, wps=19611.8, ups=1.58, wpb=12408.5, bsz=469.2, num_updates=3900, lr=0.000156022, gnorm=0.95, clip=0, loss_scale=4, train_wall=63, gb_free=16.9, wall=2184
2023-07-04 04:31:21 | INFO | train_inner | epoch 003:   1058 / 1474 loss=4.417, trans_loss=3.846, nll_loss=2.093, w2v_ctc_loss=1.722, task_loss=0, contrastive_loss=0.289, total=4069.95, n_correct=1862.33, ppl=4.27, accuracy=45.758, wps=19363.3, ups=1.59, wpb=12168.2, bsz=443.6, num_updates=4000, lr=0.00016002, gnorm=0.939, clip=0, loss_scale=4, train_wall=62, gb_free=16.5, wall=2247
2023-07-04 04:31:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 04:31:52 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.179 | trans_loss 6.438 | nll_loss 3.989 | w2v_ctc_loss 2.035 | task_loss 0 | contrastive_loss 0.397 | total 4003.4 | n_correct 1944.9 | ppl 15.88 | accuracy 48.581 | uer 29.132 | wer 29.932 | raw_wer 29.932 | bleu 6.77 | wps 1606.4 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 6.77
2023-07-04 04:31:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-07-04 04:31:52 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_3_4000.pt
2023-07-04 04:31:54 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_3_4000.pt
2023-07-04 04:32:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 6.77) (writing took 9.720850515644997 seconds)
2023-07-04 04:33:05 | INFO | train_inner | epoch 003:   1158 / 1474 loss=4.379, trans_loss=3.835, nll_loss=2.078, w2v_ctc_loss=1.682, task_loss=0, contrastive_loss=0.268, total=4038.49, n_correct=1866.98, ppl=4.22, accuracy=46.23, wps=11596.6, ups=0.96, wpb=12064, bsz=432.5, num_updates=4100, lr=0.000164018, gnorm=0.932, clip=0, loss_scale=4, train_wall=62, gb_free=16.6, wall=2351
2023-07-04 04:34:08 | INFO | train_inner | epoch 003:   1258 / 1474 loss=4.344, trans_loss=3.819, nll_loss=2.057, w2v_ctc_loss=1.65, task_loss=0, contrastive_loss=0.254, total=4064.31, n_correct=1913.85, ppl=4.16, accuracy=47.089, wps=19291, ups=1.59, wpb=12147.9, bsz=433.9, num_updates=4200, lr=0.000168016, gnorm=0.908, clip=0, loss_scale=4, train_wall=63, gb_free=17.5, wall=2414
2023-07-04 04:35:12 | INFO | train_inner | epoch 003:   1358 / 1474 loss=4.325, trans_loss=3.797, nll_loss=2.033, w2v_ctc_loss=1.623, task_loss=0, contrastive_loss=0.366, total=4134.58, n_correct=1969.17, ppl=4.09, accuracy=47.627, wps=19155.4, ups=1.55, wpb=12326.9, bsz=460.7, num_updates=4300, lr=0.000172014, gnorm=0.927, clip=0, loss_scale=4, train_wall=64, gb_free=17.9, wall=2478
2023-07-04 04:36:16 | INFO | train_inner | epoch 003:   1458 / 1474 loss=4.302, trans_loss=3.782, nll_loss=2.013, w2v_ctc_loss=1.601, task_loss=0, contrastive_loss=0.345, total=4209.94, n_correct=2035.78, ppl=4.04, accuracy=48.357, wps=19736, ups=1.57, wpb=12573.7, bsz=477.4, num_updates=4400, lr=0.000176012, gnorm=0.896, clip=0, loss_scale=4, train_wall=63, gb_free=17.2, wall=2542
2023-07-04 04:36:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 04:36:57 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.044 | trans_loss 6.327 | nll_loss 3.843 | w2v_ctc_loss 1.856 | task_loss 0 | contrastive_loss 0.385 | total 4003.4 | n_correct 2012.7 | ppl 14.35 | accuracy 50.275 | uer 27.996 | wer 28.806 | raw_wer 28.806 | bleu 7.82 | wps 1621.5 | wpb 4003.4 | bsz 141.8 | num_updates 4416 | best_bleu 7.82
2023-07-04 04:36:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4416 updates
2023-07-04 04:36:57 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 04:37:01 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 04:37:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt (epoch 3 @ 4416 updates, score 7.82) (writing took 8.333175567910075 seconds)
2023-07-04 04:37:05 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-07-04 04:37:05 | INFO | train | epoch 003 | loss 4.691 | trans_loss 4.001 | nll_loss 2.298 | w2v_ctc_loss 1.896 | task_loss 0 | contrastive_loss 0.441 | total 4139.73 | n_correct 1684.56 | ppl 4.92 | accuracy 40.692 | wps 17931.9 | ups 1.45 | wpb 12359.3 | bsz 458.9 | num_updates 4416 | lr 0.000176652 | gnorm 1.033 | clip 0.1 | loss_scale 4 | train_wall 919 | gb_free 16.8 | wall 2591
2023-07-04 04:37:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 04:37:05 | INFO | fairseq.trainer | begin training epoch 4
2023-07-04 04:37:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 04:38:06 | INFO | train_inner | epoch 004:     84 / 1474 loss=4.212, trans_loss=3.756, nll_loss=1.978, w2v_ctc_loss=1.551, task_loss=0, contrastive_loss=0.2, total=4099.41, n_correct=2010.36, ppl=3.94, accuracy=49.04, wps=11112.7, ups=0.91, wpb=12215.8, bsz=439.5, num_updates=4500, lr=0.00018001, gnorm=0.859, clip=0, loss_scale=4, train_wall=62, gb_free=16.6, wall=2652
2023-07-04 04:39:08 | INFO | train_inner | epoch 004:    184 / 1474 loss=4.199, trans_loss=3.739, nll_loss=1.954, w2v_ctc_loss=1.535, task_loss=0, contrastive_loss=0.227, total=4175.15, n_correct=2077.93, ppl=3.88, accuracy=49.769, wps=19834.6, ups=1.59, wpb=12466.1, bsz=468.3, num_updates=4600, lr=0.000184008, gnorm=0.867, clip=0, loss_scale=4, train_wall=62, gb_free=16.8, wall=2715
2023-07-04 04:40:12 | INFO | train_inner | epoch 004:    284 / 1474 loss=4.216, trans_loss=3.74, nll_loss=1.958, w2v_ctc_loss=1.534, task_loss=0, contrastive_loss=0.351, total=4145.23, n_correct=2061.25, ppl=3.88, accuracy=49.726, wps=19554.1, ups=1.58, wpb=12387.3, bsz=463, num_updates=4700, lr=0.000188006, gnorm=0.882, clip=0, loss_scale=4, train_wall=63, gb_free=16.1, wall=2778
2023-07-04 04:41:15 | INFO | train_inner | epoch 004:    384 / 1474 loss=4.178, trans_loss=3.738, nll_loss=1.954, w2v_ctc_loss=1.517, task_loss=0, contrastive_loss=0.198, total=4127.66, n_correct=2061.86, ppl=3.87, accuracy=49.952, wps=19593.1, ups=1.59, wpb=12298.8, bsz=443.5, num_updates=4800, lr=0.000192004, gnorm=0.852, clip=0, loss_scale=4, train_wall=62, gb_free=17.5, wall=2841
2023-07-04 04:42:18 | INFO | train_inner | epoch 004:    484 / 1474 loss=4.207, trans_loss=3.721, nll_loss=1.935, w2v_ctc_loss=1.484, task_loss=0, contrastive_loss=0.599, total=4218.78, n_correct=2133.86, ppl=3.82, accuracy=50.58, wps=19781.4, ups=1.57, wpb=12578.2, bsz=497.8, num_updates=4900, lr=0.000196002, gnorm=0.854, clip=0, loss_scale=4, train_wall=63, gb_free=16.7, wall=2904
2023-07-04 04:43:22 | INFO | train_inner | epoch 004:    584 / 1474 loss=4.169, trans_loss=3.716, nll_loss=1.928, w2v_ctc_loss=1.505, task_loss=0, contrastive_loss=0.272, total=4217.52, n_correct=2142.16, ppl=3.81, accuracy=50.792, wps=19856.1, ups=1.58, wpb=12583.6, bsz=485.9, num_updates=5000, lr=0.0002, gnorm=0.857, clip=0, loss_scale=4, train_wall=63, gb_free=16.3, wall=2968
tensor(0.8621, device='cuda:0')
tensor(0.8385, device='cuda:0')
2023-07-04 04:44:26 | INFO | train_inner | epoch 004:    684 / 1474 loss=4.15, trans_loss=3.72, nll_loss=1.928, w2v_ctc_loss=1.473, task_loss=0, contrastive_loss=0.317, total=4176.39, n_correct=2126.87, ppl=3.81, accuracy=50.926, wps=19379.1, ups=1.56, wpb=12440.1, bsz=455.8, num_updates=5100, lr=0.00019803, gnorm=0.734, clip=0, loss_scale=8, train_wall=64, gb_free=17.2, wall=3032
2023-07-04 04:45:29 | INFO | train_inner | epoch 004:    784 / 1474 loss=4.129, trans_loss=3.714, nll_loss=1.922, w2v_ctc_loss=1.479, task_loss=0, contrastive_loss=0.187, total=4026.63, n_correct=2059.26, ppl=3.79, accuracy=51.141, wps=19098.5, ups=1.58, wpb=12049.9, bsz=420.6, num_updates=5200, lr=0.000196116, gnorm=0.748, clip=0, loss_scale=8, train_wall=63, gb_free=13.5, wall=3095
2023-07-04 04:46:32 | INFO | train_inner | epoch 004:    884 / 1474 loss=4.144, trans_loss=3.7, nll_loss=1.909, w2v_ctc_loss=1.47, task_loss=0, contrastive_loss=0.364, total=4186.04, n_correct=2157.25, ppl=3.76, accuracy=51.534, wps=19646.2, ups=1.57, wpb=12493.4, bsz=466.3, num_updates=5300, lr=0.000194257, gnorm=0.737, clip=0, loss_scale=8, train_wall=63, gb_free=17.8, wall=3159
2023-07-04 04:47:36 | INFO | train_inner | epoch 004:    984 / 1474 loss=4.099, trans_loss=3.691, nll_loss=1.897, w2v_ctc_loss=1.447, task_loss=0, contrastive_loss=0.231, total=4125.02, n_correct=2143.48, ppl=3.72, accuracy=51.963, wps=19384.9, ups=1.57, wpb=12319.9, bsz=457.1, num_updates=5400, lr=0.00019245, gnorm=0.722, clip=0, loss_scale=8, train_wall=63, gb_free=13.1, wall=3222
2023-07-04 04:48:40 | INFO | train_inner | epoch 004:   1084 / 1474 loss=4.102, trans_loss=3.7, nll_loss=1.905, w2v_ctc_loss=1.451, task_loss=0, contrastive_loss=0.208, total=4075.6, n_correct=2110.56, ppl=3.75, accuracy=51.785, wps=19031.5, ups=1.56, wpb=12166.1, bsz=435.7, num_updates=5500, lr=0.000190693, gnorm=0.729, clip=0, loss_scale=8, train_wall=64, gb_free=16.2, wall=3286
2023-07-04 04:49:44 | INFO | train_inner | epoch 004:   1184 / 1474 loss=4.117, trans_loss=3.69, nll_loss=1.895, w2v_ctc_loss=1.441, task_loss=0, contrastive_loss=0.319, total=4161.18, n_correct=2174.3, ppl=3.72, accuracy=52.252, wps=19534.5, ups=1.57, wpb=12451.8, bsz=483.4, num_updates=5600, lr=0.000188982, gnorm=0.723, clip=0, loss_scale=8, train_wall=63, gb_free=16.9, wall=3350
2023-07-04 04:50:47 | INFO | train_inner | epoch 004:   1284 / 1474 loss=4.09, trans_loss=3.684, nll_loss=1.886, w2v_ctc_loss=1.42, task_loss=0, contrastive_loss=0.279, total=4156.53, n_correct=2191.13, ppl=3.7, accuracy=52.715, wps=19635.8, ups=1.58, wpb=12424.6, bsz=472.7, num_updates=5700, lr=0.000187317, gnorm=0.716, clip=0, loss_scale=8, train_wall=63, gb_free=16.2, wall=3413
2023-07-04 04:51:49 | INFO | train_inner | epoch 004:   1384 / 1474 loss=4.06, trans_loss=3.679, nll_loss=1.88, w2v_ctc_loss=1.417, task_loss=0, contrastive_loss=0.16, total=4101.23, n_correct=2161.22, ppl=3.68, accuracy=52.697, wps=19632.2, ups=1.6, wpb=12255, bsz=437.6, num_updates=5800, lr=0.000185695, gnorm=0.712, clip=0, loss_scale=8, train_wall=62, gb_free=15.8, wall=3476
2023-07-04 04:52:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.8621, device='cuda:6')
tensor(0.8385, device='cuda:6')
tensor(0.8621, device='cuda:7')
tensor(0.8385, device='cuda:7')
tensor(0.8621, device='cuda:2')
tensor(0.8385, device='cuda:2')
tensor(0.8621, device='cuda:5')
tensor(0.8385, device='cuda:5')
tensor(0.8621, device='cuda:4')
tensor(0.8385, device='cuda:4')
tensor(0.8621, device='cuda:1')
tensor(0.8385, device='cuda:1')
tensor(0.8621, device='cuda:3')
tensor(0.8385, device='cuda:3')
2023-07-04 04:53:14 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.678 | trans_loss 5.954 | nll_loss 3.348 | w2v_ctc_loss 1.556 | task_loss 0 | contrastive_loss 0.3 | total 4003.4 | n_correct 2235.1 | ppl 10.18 | accuracy 55.83 | uer 22.719 | wer 24.212 | raw_wer 24.212 | bleu 14.52 | wps 1826.3 | wpb 4003.4 | bsz 141.8 | num_updates 5890 | best_bleu 14.52
2023-07-04 04:53:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5890 updates
2023-07-04 04:53:14 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 04:53:18 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 04:53:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt (epoch 4 @ 5890 updates, score 14.52) (writing took 8.27273875195533 seconds)
2023-07-04 04:53:23 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-07-04 04:53:23 | INFO | train | epoch 004 | loss 4.141 | trans_loss 3.711 | nll_loss 1.92 | w2v_ctc_loss 1.474 | task_loss 0 | contrastive_loss 0.278 | total 4138.65 | n_correct 2118.72 | ppl 3.78 | accuracy 51.194 | wps 18635.4 | ups 1.51 | wpb 12355.8 | bsz 458.5 | num_updates 5890 | lr 0.000184271 | gnorm 0.78 | clip 0 | loss_scale 8 | train_wall 927 | gb_free 15 | wall 3569
2023-07-04 04:53:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 04:53:23 | INFO | fairseq.trainer | begin training epoch 5
2023-07-04 04:53:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 04:53:37 | INFO | train_inner | epoch 005:     10 / 1474 loss=4.038, trans_loss=3.673, nll_loss=1.873, w2v_ctc_loss=1.391, task_loss=0, contrastive_loss=0.18, total=4037.7, n_correct=2137.76, ppl=3.66, accuracy=52.945, wps=11235.4, ups=0.93, wpb=12062.8, bsz=439.3, num_updates=5900, lr=0.000184115, gnorm=0.71, clip=0, loss_scale=8, train_wall=62, gb_free=17, wall=3583
2023-07-04 04:54:40 | INFO | train_inner | epoch 005:    110 / 1474 loss=3.95, trans_loss=3.623, nll_loss=1.809, w2v_ctc_loss=1.315, task_loss=0, contrastive_loss=0.188, total=4247.37, n_correct=2314.24, ppl=3.5, accuracy=54.486, wps=19984, ups=1.58, wpb=12683.8, bsz=495.1, num_updates=6000, lr=0.000182574, gnorm=0.685, clip=0, loss_scale=8, train_wall=63, gb_free=16.9, wall=3646
2023-07-04 04:54:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 04:55:07 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.684 | trans_loss 5.955 | nll_loss 3.347 | w2v_ctc_loss 1.567 | task_loss 0 | contrastive_loss 0.313 | total 4003.4 | n_correct 2236.3 | ppl 10.18 | accuracy 55.86 | uer 22.958 | wer 24.563 | raw_wer 24.563 | bleu 14.41 | wps 2013.9 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 14.52
2023-07-04 04:55:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-07-04 04:55:07 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_5_6000.pt
2023-07-04 04:55:09 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_5_6000.pt
2023-07-04 04:55:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 14.41) (writing took 6.443367986008525 seconds)
2023-07-04 04:56:16 | INFO | train_inner | epoch 005:    210 / 1474 loss=3.998, trans_loss=3.63, nll_loss=1.816, w2v_ctc_loss=1.333, task_loss=0, contrastive_loss=0.41, total=4189.85, n_correct=2271.98, ppl=3.52, accuracy=54.226, wps=13001.4, ups=1.04, wpb=12492.8, bsz=488.2, num_updates=6100, lr=0.000181071, gnorm=0.693, clip=0, loss_scale=8, train_wall=62, gb_free=17.9, wall=3742
2023-07-04 04:57:19 | INFO | train_inner | epoch 005:    310 / 1474 loss=3.982, trans_loss=3.63, nll_loss=1.818, w2v_ctc_loss=1.342, task_loss=0, contrastive_loss=0.255, total=4090.1, n_correct=2210.06, ppl=3.53, accuracy=54.034, wps=19473.5, ups=1.59, wpb=12240, bsz=443.9, num_updates=6200, lr=0.000179605, gnorm=0.698, clip=0, loss_scale=8, train_wall=62, gb_free=16.4, wall=3805
2023-07-04 04:58:23 | INFO | train_inner | epoch 005:    410 / 1474 loss=3.976, trans_loss=3.623, nll_loss=1.813, w2v_ctc_loss=1.318, task_loss=0, contrastive_loss=0.344, total=4147.17, n_correct=2258.19, ppl=3.51, accuracy=54.451, wps=19492.2, ups=1.57, wpb=12381.8, bsz=472.5, num_updates=6300, lr=0.000178174, gnorm=0.714, clip=0, loss_scale=8, train_wall=63, gb_free=15, wall=3869
2023-07-04 04:59:26 | INFO | train_inner | epoch 005:    510 / 1474 loss=3.954, trans_loss=3.637, nll_loss=1.825, w2v_ctc_loss=1.323, task_loss=0, contrastive_loss=0.132, total=4026.81, n_correct=2177.14, ppl=3.54, accuracy=54.066, wps=19154.5, ups=1.59, wpb=12047.2, bsz=416.6, num_updates=6400, lr=0.000176777, gnorm=0.688, clip=0, loss_scale=8, train_wall=62, gb_free=17.5, wall=3932
2023-07-04 05:00:29 | INFO | train_inner | epoch 005:    610 / 1474 loss=3.963, trans_loss=3.631, nll_loss=1.818, w2v_ctc_loss=1.31, task_loss=0, contrastive_loss=0.301, total=4107.75, n_correct=2229.13, ppl=3.53, accuracy=54.266, wps=19311.1, ups=1.58, wpb=12245.3, bsz=451.2, num_updates=6500, lr=0.000175412, gnorm=0.699, clip=0, loss_scale=8, train_wall=63, gb_free=16.3, wall=3995
2023-07-04 05:01:32 | INFO | train_inner | epoch 005:    710 / 1474 loss=3.962, trans_loss=3.621, nll_loss=1.807, w2v_ctc_loss=1.312, task_loss=0, contrastive_loss=0.28, total=4178.85, n_correct=2283.77, ppl=3.5, accuracy=54.651, wps=19709.3, ups=1.58, wpb=12462.3, bsz=480.9, num_updates=6600, lr=0.000174078, gnorm=0.689, clip=0, loss_scale=8, train_wall=63, gb_free=17.8, wall=4058
2023-07-04 05:02:36 | INFO | train_inner | epoch 005:    810 / 1474 loss=3.947, trans_loss=3.628, nll_loss=1.815, w2v_ctc_loss=1.306, task_loss=0, contrastive_loss=0.207, total=4127.73, n_correct=2253.3, ppl=3.52, accuracy=54.589, wps=19205.6, ups=1.56, wpb=12320.4, bsz=449.2, num_updates=6700, lr=0.000172774, gnorm=0.689, clip=0, loss_scale=8, train_wall=64, gb_free=15.4, wall=4123
2023-07-04 05:03:40 | INFO | train_inner | epoch 005:    910 / 1474 loss=3.928, trans_loss=3.621, nll_loss=1.806, w2v_ctc_loss=1.294, task_loss=0, contrastive_loss=0.166, total=4095.48, n_correct=2245.68, ppl=3.5, accuracy=54.833, wps=19351.8, ups=1.58, wpb=12237.9, bsz=445.3, num_updates=6800, lr=0.000171499, gnorm=0.685, clip=0, loss_scale=8, train_wall=63, gb_free=15.8, wall=4186
2023-07-04 05:04:43 | INFO | train_inner | epoch 005:   1010 / 1474 loss=3.943, trans_loss=3.621, nll_loss=1.807, w2v_ctc_loss=1.297, task_loss=0, contrastive_loss=0.25, total=4165.12, n_correct=2292.58, ppl=3.5, accuracy=55.042, wps=19680.6, ups=1.58, wpb=12426.3, bsz=463.5, num_updates=6900, lr=0.000170251, gnorm=0.671, clip=0, loss_scale=8, train_wall=63, gb_free=15.9, wall=4249
2023-07-04 05:05:47 | INFO | train_inner | epoch 005:   1110 / 1474 loss=3.956, trans_loss=3.626, nll_loss=1.811, w2v_ctc_loss=1.305, task_loss=0, contrastive_loss=0.25, total=4176.72, n_correct=2295.88, ppl=3.51, accuracy=54.968, wps=19398.7, ups=1.56, wpb=12467.3, bsz=466.1, num_updates=7000, lr=0.000169031, gnorm=0.689, clip=0, loss_scale=8, train_wall=64, gb_free=16.9, wall=4313
2023-07-04 05:06:51 | INFO | train_inner | epoch 005:   1210 / 1474 loss=3.915, trans_loss=3.621, nll_loss=1.806, w2v_ctc_loss=1.278, task_loss=0, contrastive_loss=0.153, total=4164.13, n_correct=2298.87, ppl=3.5, accuracy=55.206, wps=19542.5, ups=1.57, wpb=12416.1, bsz=453.8, num_updates=7100, lr=0.000167836, gnorm=0.675, clip=0, loss_scale=16, train_wall=63, gb_free=17.1, wall=4377
2023-07-04 05:07:54 | INFO | train_inner | epoch 005:   1310 / 1474 loss=3.903, trans_loss=3.618, nll_loss=1.801, w2v_ctc_loss=1.268, task_loss=0, contrastive_loss=0.125, total=4134.91, n_correct=2282.95, ppl=3.48, accuracy=55.212, wps=19530.1, ups=1.58, wpb=12356.4, bsz=445.6, num_updates=7200, lr=0.000166667, gnorm=0.669, clip=0, loss_scale=16, train_wall=63, gb_free=16.6, wall=4440
2023-07-04 05:08:57 | INFO | train_inner | epoch 005:   1410 / 1474 loss=3.903, trans_loss=3.61, nll_loss=1.796, w2v_ctc_loss=1.268, task_loss=0, contrastive_loss=0.187, total=4134.37, n_correct=2284.37, ppl=3.47, accuracy=55.253, wps=19562.1, ups=1.59, wpb=12339.9, bsz=458.5, num_updates=7300, lr=0.000165521, gnorm=0.679, clip=0, loss_scale=16, train_wall=63, gb_free=17.9, wall=4503
2023-07-04 05:09:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 05:10:07 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.593 | trans_loss 5.878 | nll_loss 3.246 | w2v_ctc_loss 1.442 | task_loss 0 | contrastive_loss 0.315 | total 4003.4 | n_correct 2287.6 | ppl 9.49 | accuracy 57.141 | uer 22.045 | wer 23.843 | raw_wer 23.843 | bleu 15.64 | wps 1764.7 | wpb 4003.4 | bsz 141.8 | num_updates 7364 | best_bleu 15.64
2023-07-04 05:10:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7364 updates
2023-07-04 05:10:07 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 05:10:11 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 05:10:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt (epoch 5 @ 7364 updates, score 15.64) (writing took 8.36463654274121 seconds)
2023-07-04 05:10:15 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-07-04 05:10:15 | INFO | train | epoch 005 | loss 3.948 | trans_loss 3.624 | nll_loss 1.81 | w2v_ctc_loss 1.304 | task_loss 0 | contrastive_loss 0.232 | total 4138.65 | n_correct 2263.66 | ppl 3.51 | accuracy 54.696 | wps 17982.1 | ups 1.46 | wpb 12355.8 | bsz 458.5 | num_updates 7364 | lr 0.0001648 | gnorm 0.688 | clip 0 | loss_scale 16 | train_wall 928 | gb_free 16.4 | wall 4581
2023-07-04 05:10:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 05:10:16 | INFO | fairseq.trainer | begin training epoch 6
2023-07-04 05:10:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 05:10:47 | INFO | train_inner | epoch 006:     36 / 1474 loss=3.89, trans_loss=3.596, nll_loss=1.774, w2v_ctc_loss=1.26, task_loss=0, contrastive_loss=0.184, total=4115.45, n_correct=2298.36, ppl=3.42, accuracy=55.847, wps=11205.7, ups=0.91, wpb=12279.2, bsz=447.9, num_updates=7400, lr=0.000164399, gnorm=0.696, clip=0, loss_scale=16, train_wall=63, gb_free=16.6, wall=4613
2023-07-04 05:11:50 | INFO | train_inner | epoch 006:    136 / 1474 loss=3.84, trans_loss=3.571, nll_loss=1.742, w2v_ctc_loss=1.21, task_loss=0, contrastive_loss=0.229, total=4154.25, n_correct=2343.22, ppl=3.35, accuracy=56.405, wps=19612.2, ups=1.58, wpb=12409.6, bsz=456.1, num_updates=7500, lr=0.000163299, gnorm=0.67, clip=0, loss_scale=16, train_wall=63, gb_free=15.7, wall=4676
2023-07-04 05:12:53 | INFO | train_inner | epoch 006:    236 / 1474 loss=3.849, trans_loss=3.576, nll_loss=1.751, w2v_ctc_loss=1.24, task_loss=0, contrastive_loss=0.135, total=4112.66, n_correct=2306.92, ppl=3.37, accuracy=56.093, wps=19369.1, ups=1.58, wpb=12281.7, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.668, clip=0, loss_scale=16, train_wall=63, gb_free=16.3, wall=4739
2023-07-04 05:13:58 | INFO | train_inner | epoch 006:    336 / 1474 loss=3.864, trans_loss=3.566, nll_loss=1.74, w2v_ctc_loss=1.194, task_loss=0, contrastive_loss=0.439, total=4177.51, n_correct=2368.84, ppl=3.34, accuracy=56.705, wps=19319.9, ups=1.55, wpb=12463.7, bsz=491.3, num_updates=7700, lr=0.000161165, gnorm=0.675, clip=0, loss_scale=16, train_wall=64, gb_free=16.2, wall=4804
2023-07-04 05:15:01 | INFO | train_inner | epoch 006:    436 / 1474 loss=3.822, trans_loss=3.57, nll_loss=1.742, w2v_ctc_loss=1.2, task_loss=0, contrastive_loss=0.151, total=4154.57, n_correct=2356.11, ppl=3.34, accuracy=56.711, wps=19743.1, ups=1.59, wpb=12407.2, bsz=470.2, num_updates=7800, lr=0.000160128, gnorm=0.657, clip=0, loss_scale=16, train_wall=62, gb_free=16.3, wall=4867
2023-07-04 05:16:04 | INFO | train_inner | epoch 006:    536 / 1474 loss=3.834, trans_loss=3.573, nll_loss=1.747, w2v_ctc_loss=1.219, task_loss=0, contrastive_loss=0.139, total=4167.79, n_correct=2359.95, ppl=3.36, accuracy=56.624, wps=19616.5, ups=1.58, wpb=12419.2, bsz=455.2, num_updates=7900, lr=0.000159111, gnorm=0.67, clip=0, loss_scale=16, train_wall=63, gb_free=15.9, wall=4930
2023-07-04 05:17:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-04 05:17:08 | INFO | train_inner | epoch 006:    637 / 1474 loss=3.821, trans_loss=3.575, nll_loss=1.746, w2v_ctc_loss=1.195, task_loss=0, contrastive_loss=0.136, total=4144.56, n_correct=2346.23, ppl=3.35, accuracy=56.61, wps=19415.2, ups=1.57, wpb=12394.7, bsz=469.2, num_updates=8000, lr=0.000158114, gnorm=0.66, clip=0, loss_scale=8, train_wall=63, gb_free=16, wall=4994
2023-07-04 05:17:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 05:17:35 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.551 | trans_loss 5.826 | nll_loss 3.176 | w2v_ctc_loss 1.438 | task_loss 0 | contrastive_loss 0.289 | total 4003.4 | n_correct 2316.3 | ppl 9.04 | accuracy 57.858 | uer 20.776 | wer 22.594 | raw_wer 22.594 | bleu 15.93 | wps 2013.8 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 15.93
2023-07-04 05:17:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-07-04 05:17:35 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_6_8000.pt
2023-07-04 05:17:37 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_6_8000.pt
2023-07-04 05:17:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 15.93) (writing took 9.317055935040116 seconds)
2023-07-04 05:18:48 | INFO | train_inner | epoch 006:    737 / 1474 loss=3.834, trans_loss=3.575, nll_loss=1.749, w2v_ctc_loss=1.214, task_loss=0, contrastive_loss=0.148, total=4151.01, n_correct=2353.89, ppl=3.36, accuracy=56.706, wps=12353.4, ups=1, wpb=12384.3, bsz=454.2, num_updates=8100, lr=0.000157135, gnorm=0.663, clip=0, loss_scale=8, train_wall=63, gb_free=13.2, wall=5094
2023-07-04 05:19:52 | INFO | train_inner | epoch 006:    837 / 1474 loss=3.831, trans_loss=3.581, nll_loss=1.756, w2v_ctc_loss=1.209, task_loss=0, contrastive_loss=0.13, total=4108.83, n_correct=2316.58, ppl=3.38, accuracy=56.381, wps=19351, ups=1.58, wpb=12275.7, bsz=439.4, num_updates=8200, lr=0.000156174, gnorm=0.662, clip=0, loss_scale=8, train_wall=63, gb_free=17.2, wall=5158
2023-07-04 05:20:55 | INFO | train_inner | epoch 006:    937 / 1474 loss=3.848, trans_loss=3.579, nll_loss=1.755, w2v_ctc_loss=1.212, task_loss=0, contrastive_loss=0.228, total=4076.46, n_correct=2302.56, ppl=3.38, accuracy=56.484, wps=19129.4, ups=1.57, wpb=12153.2, bsz=443, num_updates=8300, lr=0.00015523, gnorm=0.672, clip=0, loss_scale=8, train_wall=63, gb_free=12.9, wall=5221
2023-07-04 05:21:59 | INFO | train_inner | epoch 006:   1037 / 1474 loss=3.844, trans_loss=3.57, nll_loss=1.743, w2v_ctc_loss=1.192, task_loss=0, contrastive_loss=0.301, total=4175.9, n_correct=2376.42, ppl=3.35, accuracy=56.908, wps=19642.7, ups=1.58, wpb=12465.4, bsz=480.4, num_updates=8400, lr=0.000154303, gnorm=0.681, clip=0, loss_scale=8, train_wall=63, gb_free=14.4, wall=5285
2023-07-04 05:23:02 | INFO | train_inner | epoch 006:   1137 / 1474 loss=3.825, trans_loss=3.58, nll_loss=1.754, w2v_ctc_loss=1.202, task_loss=0, contrastive_loss=0.135, total=4077.2, n_correct=2306.52, ppl=3.37, accuracy=56.571, wps=19227.9, ups=1.58, wpb=12179.9, bsz=430.6, num_updates=8500, lr=0.000153393, gnorm=0.663, clip=0, loss_scale=8, train_wall=63, gb_free=16.4, wall=5348
2023-07-04 05:24:06 | INFO | train_inner | epoch 006:   1237 / 1474 loss=3.861, trans_loss=3.572, nll_loss=1.747, w2v_ctc_loss=1.19, task_loss=0, contrastive_loss=0.451, total=4133.46, n_correct=2349.3, ppl=3.36, accuracy=56.836, wps=19373.3, ups=1.57, wpb=12360.6, bsz=470.3, num_updates=8600, lr=0.000152499, gnorm=0.669, clip=0, loss_scale=8, train_wall=63, gb_free=12.7, wall=5412
2023-07-04 05:25:08 | INFO | train_inner | epoch 006:   1337 / 1474 loss=3.815, trans_loss=3.577, nll_loss=1.748, w2v_ctc_loss=1.185, task_loss=0, contrastive_loss=0.12, total=4127.77, n_correct=2355.82, ppl=3.36, accuracy=57.072, wps=19716.1, ups=1.6, wpb=12325.7, bsz=454.1, num_updates=8700, lr=0.00015162, gnorm=0.659, clip=0, loss_scale=8, train_wall=62, gb_free=17.1, wall=5474
2023-07-04 05:26:12 | INFO | train_inner | epoch 006:   1437 / 1474 loss=3.805, trans_loss=3.567, nll_loss=1.74, w2v_ctc_loss=1.188, task_loss=0, contrastive_loss=0.126, total=4190.32, n_correct=2394.02, ppl=3.34, accuracy=57.132, wps=19683.7, ups=1.58, wpb=12495.5, bsz=460.5, num_updates=8800, lr=0.000150756, gnorm=0.654, clip=0, loss_scale=8, train_wall=63, gb_free=17, wall=5538
2023-07-04 05:26:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 05:27:01 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.486 | trans_loss 5.764 | nll_loss 3.093 | w2v_ctc_loss 1.372 | task_loss 0 | contrastive_loss 0.285 | total 4003.4 | n_correct 2348.7 | ppl 8.53 | accuracy 58.668 | uer 19.552 | wer 21.394 | raw_wer 21.394 | bleu 17.81 | wps 2120.7 | wpb 4003.4 | bsz 141.8 | num_updates 8837 | best_bleu 17.81
2023-07-04 05:27:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8837 updates
2023-07-04 05:27:01 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 05:27:05 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 05:27:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt (epoch 6 @ 8837 updates, score 17.81) (writing took 8.61446447391063 seconds)
2023-07-04 05:27:10 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-07-04 05:27:10 | INFO | train | epoch 006 | loss 3.834 | trans_loss 3.573 | nll_loss 1.746 | w2v_ctc_loss 1.203 | task_loss 0 | contrastive_loss 0.204 | total 4138.46 | n_correct 2345.59 | ppl 3.36 | accuracy 56.678 | wps 17946.3 | ups 1.45 | wpb 12355.5 | bsz 458.3 | num_updates 8837 | lr 0.00015044 | gnorm 0.666 | clip 0 | loss_scale 8 | train_wall 928 | gb_free 15.3 | wall 5596
2023-07-04 05:27:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 05:27:10 | INFO | fairseq.trainer | begin training epoch 7
2023-07-04 05:27:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 05:27:58 | INFO | train_inner | epoch 007:     63 / 1474 loss=3.767, trans_loss=3.542, nll_loss=1.707, w2v_ctc_loss=1.151, task_loss=0, contrastive_loss=0.142, total=4110.43, n_correct=2373.43, ppl=3.26, accuracy=57.742, wps=11585.1, ups=0.94, wpb=12276.6, bsz=462.8, num_updates=8900, lr=0.000149906, gnorm=0.656, clip=0, loss_scale=8, train_wall=63, gb_free=17.4, wall=5644
2023-07-04 05:29:01 | INFO | train_inner | epoch 007:    163 / 1474 loss=3.76, trans_loss=3.538, nll_loss=1.701, w2v_ctc_loss=1.14, task_loss=0, contrastive_loss=0.212, total=4109.53, n_correct=2377.44, ppl=3.25, accuracy=57.852, wps=19457.1, ups=1.59, wpb=12264.3, bsz=454.1, num_updates=9000, lr=0.000149071, gnorm=0.66, clip=0, loss_scale=8, train_wall=63, gb_free=13.8, wall=5707
2023-07-04 05:30:04 | INFO | train_inner | epoch 007:    263 / 1474 loss=3.75, trans_loss=3.534, nll_loss=1.695, w2v_ctc_loss=1.141, task_loss=0, contrastive_loss=0.123, total=4133.29, n_correct=2400.06, ppl=3.24, accuracy=58.067, wps=19579.6, ups=1.59, wpb=12339.3, bsz=455.5, num_updates=9100, lr=0.00014825, gnorm=0.654, clip=0, loss_scale=8, train_wall=63, gb_free=15.5, wall=5770
2023-07-04 05:31:07 | INFO | train_inner | epoch 007:    363 / 1474 loss=3.788, trans_loss=3.54, nll_loss=1.704, w2v_ctc_loss=1.137, task_loss=0, contrastive_loss=0.384, total=4194.76, n_correct=2424.07, ppl=3.26, accuracy=57.788, wps=19652, ups=1.57, wpb=12509.7, bsz=477.6, num_updates=9200, lr=0.000147442, gnorm=0.658, clip=0, loss_scale=8, train_wall=63, gb_free=13.3, wall=5833
2023-07-04 05:32:11 | INFO | train_inner | epoch 007:    463 / 1474 loss=3.773, trans_loss=3.538, nll_loss=1.706, w2v_ctc_loss=1.132, task_loss=0, contrastive_loss=0.307, total=4153.22, n_correct=2399.39, ppl=3.26, accuracy=57.772, wps=19536.7, ups=1.58, wpb=12386.6, bsz=463, num_updates=9300, lr=0.000146647, gnorm=0.663, clip=0, loss_scale=8, train_wall=63, gb_free=17, wall=5897
2023-07-04 05:33:14 | INFO | train_inner | epoch 007:    563 / 1474 loss=3.748, trans_loss=3.536, nll_loss=1.701, w2v_ctc_loss=1.137, task_loss=0, contrastive_loss=0.129, total=4168.14, n_correct=2419.78, ppl=3.25, accuracy=58.054, wps=19757.5, ups=1.59, wpb=12410.5, bsz=459.8, num_updates=9400, lr=0.000145865, gnorm=0.659, clip=0, loss_scale=8, train_wall=62, gb_free=17, wall=5960
2023-07-04 05:34:17 | INFO | train_inner | epoch 007:    663 / 1474 loss=3.745, trans_loss=3.54, nll_loss=1.702, w2v_ctc_loss=1.126, task_loss=0, contrastive_loss=0.117, total=4157.82, n_correct=2416.25, ppl=3.25, accuracy=58.113, wps=19614.5, ups=1.58, wpb=12417.8, bsz=455.4, num_updates=9500, lr=0.000145095, gnorm=0.651, clip=0, loss_scale=8, train_wall=63, gb_free=15.7, wall=6023
2023-07-04 05:35:21 | INFO | train_inner | epoch 007:    763 / 1474 loss=3.744, trans_loss=3.541, nll_loss=1.705, w2v_ctc_loss=1.129, task_loss=0, contrastive_loss=0.113, total=4122.1, n_correct=2385.77, ppl=3.26, accuracy=57.878, wps=19363.8, ups=1.57, wpb=12321.9, bsz=446.2, num_updates=9600, lr=0.000144338, gnorm=0.65, clip=0, loss_scale=8, train_wall=63, gb_free=15.8, wall=6087
2023-07-04 05:36:24 | INFO | train_inner | epoch 007:    863 / 1474 loss=3.75, trans_loss=3.539, nll_loss=1.702, w2v_ctc_loss=1.13, task_loss=0, contrastive_loss=0.134, total=4147.23, n_correct=2405.94, ppl=3.25, accuracy=58.013, wps=19533.3, ups=1.58, wpb=12392, bsz=460.9, num_updates=9700, lr=0.000143592, gnorm=0.659, clip=0, loss_scale=8, train_wall=63, gb_free=17.6, wall=6150
2023-07-04 05:37:28 | INFO | train_inner | epoch 007:    963 / 1474 loss=3.759, trans_loss=3.537, nll_loss=1.702, w2v_ctc_loss=1.121, task_loss=0, contrastive_loss=0.228, total=4140.14, n_correct=2412.42, ppl=3.25, accuracy=58.269, wps=19306.4, ups=1.56, wpb=12360, bsz=474.6, num_updates=9800, lr=0.000142857, gnorm=0.662, clip=0, loss_scale=8, train_wall=64, gb_free=16.1, wall=6214
2023-07-04 05:38:31 | INFO | train_inner | epoch 007:   1063 / 1474 loss=3.749, trans_loss=3.546, nll_loss=1.711, w2v_ctc_loss=1.133, task_loss=0, contrastive_loss=0.098, total=4103.51, n_correct=2376.67, ppl=3.27, accuracy=57.918, wps=19333.1, ups=1.58, wpb=12263.4, bsz=437.5, num_updates=9900, lr=0.000142134, gnorm=0.654, clip=0, loss_scale=8, train_wall=63, gb_free=17, wall=6278
2023-07-04 05:39:35 | INFO | train_inner | epoch 007:   1163 / 1474 loss=3.777, trans_loss=3.533, nll_loss=1.702, w2v_ctc_loss=1.123, task_loss=0, contrastive_loss=0.368, total=4137.04, n_correct=2402.78, ppl=3.25, accuracy=58.08, wps=19382.4, ups=1.57, wpb=12348.6, bsz=470.9, num_updates=10000, lr=0.000141421, gnorm=0.673, clip=0, loss_scale=8, train_wall=63, gb_free=16.2, wall=6341
2023-07-04 05:39:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 05:40:00 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.461 | trans_loss 5.72 | nll_loss 3.036 | w2v_ctc_loss 1.392 | task_loss 0 | contrastive_loss 0.287 | total 4003.4 | n_correct 2379.8 | ppl 8.2 | accuracy 59.444 | uer 18.846 | wer 20.782 | raw_wer 20.782 | bleu 18.51 | wps 2319.8 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 18.51
2023-07-04 05:40:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-07-04 05:40:00 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_7_10000.pt
2023-07-04 05:40:03 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_7_10000.pt
2023-07-04 05:40:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 18.51) (writing took 9.931506007909775 seconds)
tensor(0.6185, device='cuda:0')
tensor(0.5027, device='cuda:0')
2023-07-04 05:41:13 | INFO | train_inner | epoch 007:   1263 / 1474 loss=3.732, trans_loss=3.533, nll_loss=1.698, w2v_ctc_loss=1.115, task_loss=0, contrastive_loss=0.126, total=4129.52, n_correct=2400.99, ppl=3.24, accuracy=58.142, wps=12567.5, ups=1.02, wpb=12329.2, bsz=450.2, num_updates=10100, lr=0.00014072, gnorm=0.488, clip=0, loss_scale=16, train_wall=63, gb_free=17, wall=6439
2023-07-04 05:42:16 | INFO | train_inner | epoch 007:   1363 / 1474 loss=3.743, trans_loss=3.53, nll_loss=1.694, w2v_ctc_loss=1.123, task_loss=0, contrastive_loss=0.162, total=4172.87, n_correct=2438.46, ppl=3.24, accuracy=58.436, wps=19725.1, ups=1.58, wpb=12453.5, bsz=476.2, num_updates=10200, lr=0.000140028, gnorm=0.486, clip=0, loss_scale=16, train_wall=63, gb_free=17.3, wall=6503
2023-07-04 05:43:21 | INFO | train_inner | epoch 007:   1463 / 1474 loss=3.757, trans_loss=3.541, nll_loss=1.709, w2v_ctc_loss=1.122, task_loss=0, contrastive_loss=0.227, total=4109.42, n_correct=2388.18, ppl=3.27, accuracy=58.115, wps=19141.5, ups=1.56, wpb=12285.7, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.499, clip=0, loss_scale=16, train_wall=64, gb_free=16.6, wall=6567
2023-07-04 05:43:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.6185, device='cuda:6')
tensor(0.5027, device='cuda:6')
tensor(0.6185, device='cuda:7')
tensor(0.5027, device='cuda:7')
tensor(0.6185, device='cuda:1')
tensor(0.5027, device='cuda:1')
tensor(0.6185, device='cuda:3')
tensor(0.5027, device='cuda:3')
tensor(0.6185, device='cuda:4')
tensor(0.5027, device='cuda:4')
tensor(0.6185, device='cuda:5')
tensor(0.5027, device='cuda:5')
tensor(0.6185, device='cuda:2')
tensor(0.5027, device='cuda:2')
2023-07-04 05:43:56 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.465 | trans_loss 5.737 | nll_loss 3.059 | w2v_ctc_loss 1.367 | task_loss 0 | contrastive_loss 0.279 | total 4003.4 | n_correct 2365.5 | ppl 8.33 | accuracy 59.087 | uer 18.934 | wer 20.778 | raw_wer 20.778 | bleu 17.14 | wps 1803.1 | wpb 4003.4 | bsz 141.8 | num_updates 10311 | best_bleu 18.51
2023-07-04 05:43:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10311 updates
2023-07-04 05:43:56 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_17.1401.pt
2023-07-04 05:43:59 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_17.1401.pt
2023-07-04 05:44:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_17.1401.pt (epoch 7 @ 10311 updates, score 17.14) (writing took 5.534858358092606 seconds)
2023-07-04 05:44:02 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-07-04 05:44:02 | INFO | train | epoch 007 | loss 3.755 | trans_loss 3.537 | nll_loss 1.702 | w2v_ctc_loss 1.129 | task_loss 0 | contrastive_loss 0.193 | total 4138.65 | n_correct 2401.75 | ppl 3.25 | accuracy 58.032 | wps 17984 | ups 1.46 | wpb 12355.8 | bsz 458.5 | num_updates 10311 | lr 0.000139272 | gnorm 0.623 | clip 0 | loss_scale 16 | train_wall 929 | gb_free 13.5 | wall 6608
2023-07-04 05:44:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 05:44:02 | INFO | fairseq.trainer | begin training epoch 8
2023-07-04 05:44:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 05:45:07 | INFO | train_inner | epoch 008:     89 / 1474 loss=3.69, trans_loss=3.513, nll_loss=1.667, w2v_ctc_loss=1.081, task_loss=0, contrastive_loss=0.121, total=4116.25, n_correct=2424.49, ppl=3.18, accuracy=58.9, wps=11558.4, ups=0.94, wpb=12265.9, bsz=443.3, num_updates=10400, lr=0.000138675, gnorm=0.489, clip=0, loss_scale=16, train_wall=63, gb_free=17.1, wall=6673
2023-07-04 05:46:10 | INFO | train_inner | epoch 008:    189 / 1474 loss=3.691, trans_loss=3.513, nll_loss=1.667, w2v_ctc_loss=1.076, task_loss=0, contrastive_loss=0.142, total=4037.23, n_correct=2382.4, ppl=3.18, accuracy=59.011, wps=19066.3, ups=1.58, wpb=12033.3, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.494, clip=0, loss_scale=16, train_wall=63, gb_free=13.1, wall=6736
2023-07-04 05:47:13 | INFO | train_inner | epoch 008:    289 / 1474 loss=3.688, trans_loss=3.506, nll_loss=1.659, w2v_ctc_loss=1.077, task_loss=0, contrastive_loss=0.14, total=4207.78, n_correct=2491.79, ppl=3.16, accuracy=59.219, wps=19940.1, ups=1.59, wpb=12570.1, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.491, clip=0, loss_scale=16, train_wall=63, gb_free=13.3, wall=6799
2023-07-04 05:48:17 | INFO | train_inner | epoch 008:    389 / 1474 loss=3.706, trans_loss=3.513, nll_loss=1.668, w2v_ctc_loss=1.094, task_loss=0, contrastive_loss=0.164, total=4127.24, n_correct=2428.09, ppl=3.18, accuracy=58.831, wps=19163.5, ups=1.56, wpb=12318.5, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=0.493, clip=0, loss_scale=16, train_wall=64, gb_free=12.1, wall=6863
2023-07-04 05:49:21 | INFO | train_inner | epoch 008:    489 / 1474 loss=3.737, trans_loss=3.51, nll_loss=1.666, w2v_ctc_loss=1.07, task_loss=0, contrastive_loss=0.424, total=4203.76, n_correct=2483.24, ppl=3.17, accuracy=59.072, wps=19707.5, ups=1.57, wpb=12567.7, bsz=504.5, num_updates=10800, lr=0.000136083, gnorm=0.5, clip=0, loss_scale=16, train_wall=63, gb_free=14.7, wall=6927
2023-07-04 05:50:24 | INFO | train_inner | epoch 008:    589 / 1474 loss=3.692, trans_loss=3.513, nll_loss=1.671, w2v_ctc_loss=1.092, task_loss=0, contrastive_loss=0.096, total=4062.5, n_correct=2388.37, ppl=3.18, accuracy=58.791, wps=19192.2, ups=1.58, wpb=12171.9, bsz=427.9, num_updates=10900, lr=0.000135457, gnorm=0.493, clip=0, loss_scale=16, train_wall=63, gb_free=11.7, wall=6991
2023-07-04 05:51:28 | INFO | train_inner | epoch 008:    689 / 1474 loss=3.687, trans_loss=3.507, nll_loss=1.663, w2v_ctc_loss=1.086, task_loss=0, contrastive_loss=0.107, total=4142.78, n_correct=2452.85, ppl=3.17, accuracy=59.208, wps=19425.9, ups=1.57, wpb=12347.9, bsz=448.6, num_updates=11000, lr=0.00013484, gnorm=0.49, clip=0, loss_scale=16, train_wall=63, gb_free=16, wall=7054
2023-07-04 05:52:32 | INFO | train_inner | epoch 008:    789 / 1474 loss=3.695, trans_loss=3.505, nll_loss=1.662, w2v_ctc_loss=1.078, task_loss=0, contrastive_loss=0.193, total=4118.9, n_correct=2437.42, ppl=3.16, accuracy=59.176, wps=19409, ups=1.57, wpb=12327.8, bsz=447.8, num_updates=11100, lr=0.000134231, gnorm=0.492, clip=0, loss_scale=16, train_wall=63, gb_free=15.3, wall=7118
2023-07-04 05:53:35 | INFO | train_inner | epoch 008:    889 / 1474 loss=3.695, trans_loss=3.507, nll_loss=1.666, w2v_ctc_loss=1.068, task_loss=0, contrastive_loss=0.2, total=4169.01, n_correct=2469.52, ppl=3.17, accuracy=59.235, wps=19621.8, ups=1.58, wpb=12455.3, bsz=473.7, num_updates=11200, lr=0.000133631, gnorm=0.487, clip=0, loss_scale=16, train_wall=63, gb_free=16.3, wall=7181
2023-07-04 05:54:38 | INFO | train_inner | epoch 008:    989 / 1474 loss=3.672, trans_loss=3.504, nll_loss=1.661, w2v_ctc_loss=1.067, task_loss=0, contrastive_loss=0.104, total=4154.69, n_correct=2460.53, ppl=3.16, accuracy=59.223, wps=19668.4, ups=1.59, wpb=12398.4, bsz=464.9, num_updates=11300, lr=0.000133038, gnorm=0.485, clip=0, loss_scale=16, train_wall=63, gb_free=17.8, wall=7244
2023-07-04 05:55:42 | INFO | train_inner | epoch 008:   1089 / 1474 loss=3.708, trans_loss=3.507, nll_loss=1.666, w2v_ctc_loss=1.071, task_loss=0, contrastive_loss=0.33, total=4199.1, n_correct=2484.91, ppl=3.17, accuracy=59.177, wps=19555.6, ups=1.56, wpb=12520.7, bsz=465.3, num_updates=11400, lr=0.000132453, gnorm=0.49, clip=0, loss_scale=16, train_wall=64, gb_free=13, wall=7308
2023-07-04 05:56:45 | INFO | train_inner | epoch 008:   1189 / 1474 loss=3.682, trans_loss=3.507, nll_loss=1.666, w2v_ctc_loss=1.07, task_loss=0, contrastive_loss=0.114, total=4177.31, n_correct=2476.66, ppl=3.17, accuracy=59.288, wps=19835.7, ups=1.59, wpb=12476.4, bsz=472.6, num_updates=11500, lr=0.000131876, gnorm=0.489, clip=0, loss_scale=16, train_wall=62, gb_free=15.1, wall=7371
2023-07-04 05:57:48 | INFO | train_inner | epoch 008:   1289 / 1474 loss=3.695, trans_loss=3.51, nll_loss=1.671, w2v_ctc_loss=1.085, task_loss=0, contrastive_loss=0.136, total=4063.85, n_correct=2399.58, ppl=3.18, accuracy=59.047, wps=19339.1, ups=1.59, wpb=12141.2, bsz=438.4, num_updates=11600, lr=0.000131306, gnorm=0.497, clip=0, loss_scale=16, train_wall=62, gb_free=16.9, wall=7434
2023-07-04 05:58:51 | INFO | train_inner | epoch 008:   1389 / 1474 loss=3.694, trans_loss=3.509, nll_loss=1.67, w2v_ctc_loss=1.073, task_loss=0, contrastive_loss=0.187, total=4141.5, n_correct=2452.01, ppl=3.18, accuracy=59.206, wps=19632, ups=1.59, wpb=12351.9, bsz=461.5, num_updates=11700, lr=0.000130744, gnorm=0.485, clip=0, loss_scale=16, train_wall=63, gb_free=16.7, wall=7497
2023-07-04 05:59:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 06:00:10 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.41 | trans_loss 5.682 | nll_loss 2.981 | w2v_ctc_loss 1.327 | task_loss 0 | contrastive_loss 0.255 | total 4003.4 | n_correct 2401 | ppl 7.89 | accuracy 59.974 | uer 18.156 | wer 19.716 | raw_wer 19.716 | bleu 18.83 | wps 2231.3 | wpb 4003.4 | bsz 141.8 | num_updates 11785 | best_bleu 18.83
2023-07-04 06:00:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11785 updates
2023-07-04 06:00:10 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 06:00:14 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 06:00:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt (epoch 8 @ 11785 updates, score 18.83) (writing took 8.571176503784955 seconds)
2023-07-04 06:00:19 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-07-04 06:00:19 | INFO | train | epoch 008 | loss 3.695 | trans_loss 3.509 | nll_loss 1.666 | w2v_ctc_loss 1.077 | task_loss 0 | contrastive_loss 0.183 | total 4138.65 | n_correct 2446.93 | ppl 3.17 | accuracy 59.124 | wps 18651.9 | ups 1.51 | wpb 12355.8 | bsz 458.5 | num_updates 11785 | lr 0.000130272 | gnorm 0.491 | clip 0 | loss_scale 16 | train_wall 928 | gb_free 17.1 | wall 7585
2023-07-04 06:00:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 06:00:19 | INFO | fairseq.trainer | begin training epoch 9
2023-07-04 06:00:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 06:00:36 | INFO | train_inner | epoch 009:     15 / 1474 loss=3.696, trans_loss=3.504, nll_loss=1.661, w2v_ctc_loss=1.057, task_loss=0, contrastive_loss=0.314, total=4139.35, n_correct=2464.16, ppl=3.16, accuracy=59.53, wps=11677.5, ups=0.95, wpb=12332.8, bsz=472.9, num_updates=11800, lr=0.000130189, gnorm=0.492, clip=0, loss_scale=16, train_wall=63, gb_free=16.4, wall=7602
2023-07-04 06:01:40 | INFO | train_inner | epoch 009:    115 / 1474 loss=3.63, trans_loss=3.475, nll_loss=1.623, w2v_ctc_loss=1.025, task_loss=0, contrastive_loss=0.132, total=4181.9, n_correct=2524.6, ppl=3.08, accuracy=60.37, wps=19764.1, ups=1.58, wpb=12493.2, bsz=475.9, num_updates=11900, lr=0.000129641, gnorm=0.482, clip=0, loss_scale=16, train_wall=63, gb_free=16.4, wall=7666
2023-07-04 06:02:43 | INFO | train_inner | epoch 009:    215 / 1474 loss=3.628, trans_loss=3.486, nll_loss=1.636, w2v_ctc_loss=1.027, task_loss=0, contrastive_loss=0.092, total=4062.07, n_correct=2438.23, ppl=3.11, accuracy=60.024, wps=19074.8, ups=1.57, wpb=12136.5, bsz=431.6, num_updates=12000, lr=0.000129099, gnorm=0.488, clip=0, loss_scale=16, train_wall=63, gb_free=15.7, wall=7729
2023-07-04 06:02:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 06:03:08 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.413 | trans_loss 5.691 | nll_loss 2.996 | w2v_ctc_loss 1.312 | task_loss 0 | contrastive_loss 0.262 | total 4003.4 | n_correct 2398.6 | ppl 7.98 | accuracy 59.914 | uer 18.077 | wer 19.958 | raw_wer 19.958 | bleu 18.73 | wps 2370 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 18.83
2023-07-04 06:03:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-07-04 06:03:08 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_9_12000.pt
2023-07-04 06:03:11 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_9_12000.pt
2023-07-04 06:03:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.73) (writing took 7.077690487261862 seconds)
2023-07-04 06:04:19 | INFO | train_inner | epoch 009:    315 / 1474 loss=3.623, trans_loss=3.474, nll_loss=1.622, w2v_ctc_loss=1.014, task_loss=0, contrastive_loss=0.14, total=4152.1, n_correct=2510.1, ppl=3.08, accuracy=60.454, wps=13026.1, ups=1.05, wpb=12422.8, bsz=476.6, num_updates=12100, lr=0.000128565, gnorm=0.482, clip=0, loss_scale=32, train_wall=63, gb_free=16.4, wall=7825
2023-07-04 06:05:23 | INFO | train_inner | epoch 009:    415 / 1474 loss=3.627, trans_loss=3.48, nll_loss=1.63, w2v_ctc_loss=1.026, task_loss=0, contrastive_loss=0.108, total=4203.78, n_correct=2522.78, ppl=3.1, accuracy=60.012, wps=19547.5, ups=1.56, wpb=12545.5, bsz=469.8, num_updates=12200, lr=0.000128037, gnorm=0.48, clip=0, loss_scale=32, train_wall=64, gb_free=17.2, wall=7889
2023-07-04 06:06:26 | INFO | train_inner | epoch 009:    515 / 1474 loss=3.659, trans_loss=3.492, nll_loss=1.645, w2v_ctc_loss=1.053, task_loss=0, contrastive_loss=0.159, total=4112.78, n_correct=2458.05, ppl=3.13, accuracy=59.766, wps=19374.3, ups=1.58, wpb=12260.1, bsz=437.7, num_updates=12300, lr=0.000127515, gnorm=0.494, clip=0, loss_scale=32, train_wall=63, gb_free=16.3, wall=7952
2023-07-04 06:07:29 | INFO | train_inner | epoch 009:    615 / 1474 loss=3.626, trans_loss=3.48, nll_loss=1.632, w2v_ctc_loss=1.019, task_loss=0, contrastive_loss=0.119, total=4131.32, n_correct=2482.62, ppl=3.1, accuracy=60.093, wps=19549.1, ups=1.58, wpb=12355.3, bsz=455, num_updates=12400, lr=0.000127, gnorm=0.483, clip=0, loss_scale=32, train_wall=63, gb_free=17.9, wall=8015
2023-07-04 06:08:33 | INFO | train_inner | epoch 009:    715 / 1474 loss=3.661, trans_loss=3.488, nll_loss=1.64, w2v_ctc_loss=1.046, task_loss=0, contrastive_loss=0.202, total=4082.11, n_correct=2442.97, ppl=3.12, accuracy=59.846, wps=19131.3, ups=1.57, wpb=12206.9, bsz=449.7, num_updates=12500, lr=0.000126491, gnorm=0.495, clip=0, loss_scale=32, train_wall=63, gb_free=17.1, wall=8079
2023-07-04 06:09:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-04 06:09:37 | INFO | train_inner | epoch 009:    816 / 1474 loss=3.661, trans_loss=3.476, nll_loss=1.629, w2v_ctc_loss=1.04, task_loss=0, contrastive_loss=0.268, total=4202.99, n_correct=2527.27, ppl=3.09, accuracy=60.13, wps=19485.4, ups=1.55, wpb=12540.2, bsz=492, num_updates=12600, lr=0.000125988, gnorm=0.494, clip=0, loss_scale=16, train_wall=64, gb_free=14.6, wall=8143
2023-07-04 06:10:42 | INFO | train_inner | epoch 009:    916 / 1474 loss=3.665, trans_loss=3.487, nll_loss=1.639, w2v_ctc_loss=1.036, task_loss=0, contrastive_loss=0.326, total=4146.05, n_correct=2489.6, ppl=3.11, accuracy=60.048, wps=19263.9, ups=1.56, wpb=12355.9, bsz=450.3, num_updates=12700, lr=0.000125491, gnorm=0.488, clip=0, loss_scale=16, train_wall=64, gb_free=17.9, wall=8208
2023-07-04 06:11:45 | INFO | train_inner | epoch 009:   1016 / 1474 loss=3.645, trans_loss=3.498, nll_loss=1.652, w2v_ctc_loss=1.038, task_loss=0, contrastive_loss=0.106, total=4101.48, n_correct=2447.87, ppl=3.14, accuracy=59.683, wps=19286.2, ups=1.58, wpb=12243.2, bsz=424.4, num_updates=12800, lr=0.000125, gnorm=0.488, clip=0, loss_scale=16, train_wall=63, gb_free=16, wall=8271
2023-07-04 06:12:48 | INFO | train_inner | epoch 009:   1116 / 1474 loss=3.641, trans_loss=3.488, nll_loss=1.638, w2v_ctc_loss=1.034, task_loss=0, contrastive_loss=0.129, total=4179.09, n_correct=2510.17, ppl=3.11, accuracy=60.065, wps=19772.8, ups=1.59, wpb=12439.9, bsz=474.7, num_updates=12900, lr=0.000124515, gnorm=0.492, clip=0, loss_scale=16, train_wall=63, gb_free=15.5, wall=8334
2023-07-04 06:13:52 | INFO | train_inner | epoch 009:   1216 / 1474 loss=3.653, trans_loss=3.496, nll_loss=1.647, w2v_ctc_loss=1.042, task_loss=0, contrastive_loss=0.113, total=4140.66, n_correct=2479.48, ppl=3.13, accuracy=59.881, wps=19462.7, ups=1.57, wpb=12405, bsz=448.1, num_updates=13000, lr=0.000124035, gnorm=0.486, clip=0, loss_scale=16, train_wall=63, gb_free=17.2, wall=8398
2023-07-04 06:14:55 | INFO | train_inner | epoch 009:   1316 / 1474 loss=3.664, trans_loss=3.483, nll_loss=1.634, w2v_ctc_loss=1.028, task_loss=0, contrastive_loss=0.301, total=4204.43, n_correct=2536.57, ppl=3.1, accuracy=60.331, wps=19845.6, ups=1.58, wpb=12539.3, bsz=492.5, num_updates=13100, lr=0.00012356, gnorm=0.486, clip=0, loss_scale=16, train_wall=63, gb_free=17.8, wall=8461
2023-07-04 06:15:58 | INFO | train_inner | epoch 009:   1416 / 1474 loss=3.647, trans_loss=3.497, nll_loss=1.65, w2v_ctc_loss=1.042, task_loss=0, contrastive_loss=0.089, total=4069.19, n_correct=2435.62, ppl=3.14, accuracy=59.855, wps=19264.3, ups=1.59, wpb=12152.5, bsz=427.7, num_updates=13200, lr=0.000123091, gnorm=0.489, clip=0, loss_scale=16, train_wall=63, gb_free=16.8, wall=8524
2023-07-04 06:16:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 06:17:00 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.397 | trans_loss 5.664 | nll_loss 2.963 | w2v_ctc_loss 1.325 | task_loss 0 | contrastive_loss 0.261 | total 4003.4 | n_correct 2409.3 | ppl 7.8 | accuracy 60.181 | uer 17.758 | wer 19.593 | raw_wer 19.593 | bleu 18.72 | wps 2213.7 | wpb 4003.4 | bsz 141.8 | num_updates 13258 | best_bleu 18.83
2023-07-04 06:17:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13258 updates
2023-07-04 06:17:00 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_18.7205.pt
2023-07-04 06:17:02 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_18.7205.pt
2023-07-04 06:17:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_18.7205.pt (epoch 9 @ 13258 updates, score 18.72) (writing took 5.330232345033437 seconds)
2023-07-04 06:17:05 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-07-04 06:17:05 | INFO | train | epoch 009 | loss 3.645 | trans_loss 3.486 | nll_loss 1.637 | w2v_ctc_loss 1.034 | task_loss 0 | contrastive_loss 0.169 | total 4137.53 | n_correct 2484.65 | ppl 3.11 | accuracy 60.052 | wps 18073.7 | ups 1.46 | wpb 12352.2 | bsz 457.9 | num_updates 13258 | lr 0.000122822 | gnorm 0.488 | clip 0 | loss_scale 16 | train_wall 929 | gb_free 12 | wall 8591
2023-07-04 06:17:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 06:17:06 | INFO | fairseq.trainer | begin training epoch 10
2023-07-04 06:17:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 06:17:40 | INFO | train_inner | epoch 010:     42 / 1474 loss=3.633, trans_loss=3.476, nll_loss=1.624, w2v_ctc_loss=1.014, task_loss=0, contrastive_loss=0.19, total=4100.8, n_correct=2485.7, ppl=3.08, accuracy=60.615, wps=12014.1, ups=0.98, wpb=12243.3, bsz=469.4, num_updates=13300, lr=0.000122628, gnorm=0.488, clip=0, loss_scale=16, train_wall=62, gb_free=16.4, wall=8626
2023-07-04 06:18:43 | INFO | train_inner | epoch 010:    142 / 1474 loss=3.583, trans_loss=3.459, nll_loss=1.6, w2v_ctc_loss=0.979, task_loss=0, contrastive_loss=0.11, total=4247.35, n_correct=2594.88, ppl=3.03, accuracy=61.094, wps=20043.8, ups=1.58, wpb=12717.5, bsz=479.6, num_updates=13400, lr=0.000122169, gnorm=0.475, clip=0, loss_scale=16, train_wall=63, gb_free=12.1, wall=8689
2023-07-04 06:19:47 | INFO | train_inner | epoch 010:    242 / 1474 loss=3.601, trans_loss=3.456, nll_loss=1.601, w2v_ctc_loss=0.994, task_loss=0, contrastive_loss=0.233, total=4122.82, n_correct=2516.84, ppl=3.03, accuracy=61.047, wps=19427.5, ups=1.58, wpb=12279.5, bsz=461.4, num_updates=13500, lr=0.000121716, gnorm=0.486, clip=0, loss_scale=16, train_wall=63, gb_free=16.4, wall=8753
2023-07-04 06:20:50 | INFO | train_inner | epoch 010:    342 / 1474 loss=3.588, trans_loss=3.455, nll_loss=1.6, w2v_ctc_loss=0.987, task_loss=0, contrastive_loss=0.146, total=4138.27, n_correct=2525.25, ppl=3.03, accuracy=61.022, wps=19450.3, ups=1.57, wpb=12378.7, bsz=453.8, num_updates=13600, lr=0.000121268, gnorm=0.485, clip=0, loss_scale=16, train_wall=63, gb_free=16.6, wall=8816
2023-07-04 06:21:55 | INFO | train_inner | epoch 010:    442 / 1474 loss=3.605, trans_loss=3.458, nll_loss=1.603, w2v_ctc_loss=0.977, task_loss=0, contrastive_loss=0.32, total=4196.37, n_correct=2558.35, ppl=3.04, accuracy=60.966, wps=19414.9, ups=1.55, wpb=12523.5, bsz=481.1, num_updates=13700, lr=0.000120824, gnorm=0.481, clip=0, loss_scale=16, train_wall=64, gb_free=16.6, wall=8881
2023-07-04 06:22:58 | INFO | train_inner | epoch 010:    542 / 1474 loss=3.61, trans_loss=3.473, nll_loss=1.618, w2v_ctc_loss=1.014, task_loss=0, contrastive_loss=0.099, total=4102.8, n_correct=2488.7, ppl=3.07, accuracy=60.659, wps=19263.5, ups=1.58, wpb=12224.8, bsz=437.8, num_updates=13800, lr=0.000120386, gnorm=0.487, clip=0, loss_scale=16, train_wall=63, gb_free=17.1, wall=8944
2023-07-04 06:24:02 | INFO | train_inner | epoch 010:    642 / 1474 loss=3.619, trans_loss=3.469, nll_loss=1.616, w2v_ctc_loss=1, task_loss=0, contrastive_loss=0.215, total=4176.56, n_correct=2539.92, ppl=3.06, accuracy=60.814, wps=19534.3, ups=1.57, wpb=12467.5, bsz=477.2, num_updates=13900, lr=0.000119952, gnorm=0.49, clip=0, loss_scale=16, train_wall=63, gb_free=16.4, wall=9008
2023-07-04 06:25:05 | INFO | train_inner | epoch 010:    742 / 1474 loss=3.609, trans_loss=3.468, nll_loss=1.614, w2v_ctc_loss=1.016, task_loss=0, contrastive_loss=0.097, total=4125.87, n_correct=2507.11, ppl=3.06, accuracy=60.766, wps=19553.3, ups=1.59, wpb=12315.5, bsz=454.4, num_updates=14000, lr=0.000119523, gnorm=0.492, clip=0, loss_scale=16, train_wall=63, gb_free=14.7, wall=9071
2023-07-04 06:25:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 06:25:33 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.417 | trans_loss 5.669 | nll_loss 2.971 | w2v_ctc_loss 1.377 | task_loss 0 | contrastive_loss 0.263 | total 4003.4 | n_correct 2407.9 | ppl 7.84 | accuracy 60.146 | uer 18.201 | wer 20.066 | raw_wer 20.066 | bleu 18.51 | wps 1867.5 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 18.83
2023-07-04 06:25:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-07-04 06:25:33 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_10_14000.pt
2023-07-04 06:25:36 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_10_14000.pt
2023-07-04 06:25:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 18.51) (writing took 6.738882584962994 seconds)
2023-07-04 06:26:44 | INFO | train_inner | epoch 010:    842 / 1474 loss=3.593, trans_loss=3.466, nll_loss=1.612, w2v_ctc_loss=0.99, task_loss=0, contrastive_loss=0.099, total=4128.44, n_correct=2513.9, ppl=3.06, accuracy=60.892, wps=12478.7, ups=1.01, wpb=12345, bsz=456.3, num_updates=14100, lr=0.000119098, gnorm=0.481, clip=0, loss_scale=16, train_wall=63, gb_free=14.9, wall=9170
2023-07-04 06:27:47 | INFO | train_inner | epoch 010:    942 / 1474 loss=3.602, trans_loss=3.464, nll_loss=1.611, w2v_ctc_loss=1.002, task_loss=0, contrastive_loss=0.138, total=4160.94, n_correct=2530.47, ppl=3.05, accuracy=60.815, wps=19663, ups=1.59, wpb=12380.2, bsz=468.1, num_updates=14200, lr=0.000118678, gnorm=0.487, clip=0, loss_scale=16, train_wall=63, gb_free=15.6, wall=9233
2023-07-04 06:28:50 | INFO | train_inner | epoch 010:   1042 / 1474 loss=3.602, trans_loss=3.47, nll_loss=1.618, w2v_ctc_loss=1.003, task_loss=0, contrastive_loss=0.112, total=4067.53, n_correct=2464.82, ppl=3.07, accuracy=60.597, wps=19117.3, ups=1.57, wpb=12142, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.493, clip=0, loss_scale=16, train_wall=63, gb_free=17, wall=9296
2023-07-04 06:29:53 | INFO | train_inner | epoch 010:   1142 / 1474 loss=3.615, trans_loss=3.476, nll_loss=1.625, w2v_ctc_loss=1.018, task_loss=0, contrastive_loss=0.094, total=4044.03, n_correct=2443.62, ppl=3.08, accuracy=60.425, wps=19226.9, ups=1.59, wpb=12072.9, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.494, clip=0, loss_scale=16, train_wall=62, gb_free=17.4, wall=9359
2023-07-04 06:30:56 | INFO | train_inner | epoch 010:   1242 / 1474 loss=3.604, trans_loss=3.468, nll_loss=1.619, w2v_ctc_loss=1.011, task_loss=0, contrastive_loss=0.091, total=4110.41, n_correct=2491.18, ppl=3.07, accuracy=60.607, wps=19438.5, ups=1.58, wpb=12302.3, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.496, clip=0, loss_scale=16, train_wall=63, gb_free=16.6, wall=9423
2023-07-04 06:32:00 | INFO | train_inner | epoch 010:   1342 / 1474 loss=3.603, trans_loss=3.469, nll_loss=1.617, w2v_ctc_loss=1.004, task_loss=0, contrastive_loss=0.101, total=4121.38, n_correct=2501.13, ppl=3.07, accuracy=60.687, wps=19447, ups=1.58, wpb=12315.5, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.49, clip=0, loss_scale=32, train_wall=63, gb_free=14.3, wall=9486
2023-07-04 06:33:04 | INFO | train_inner | epoch 010:   1442 / 1474 loss=3.644, trans_loss=3.473, nll_loss=1.624, w2v_ctc_loss=0.995, task_loss=0, contrastive_loss=0.352, total=4192.39, n_correct=2539.61, ppl=3.08, accuracy=60.577, wps=19559.7, ups=1.57, wpb=12477.9, bsz=482, num_updates=14700, lr=0.000116642, gnorm=0.497, clip=0, loss_scale=32, train_wall=63, gb_free=17.1, wall=9550
2023-07-04 06:33:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 06:33:49 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.393 | trans_loss 5.64 | nll_loss 2.929 | w2v_ctc_loss 1.366 | task_loss 0 | contrastive_loss 0.261 | total 4003.4 | n_correct 2435.3 | ppl 7.62 | accuracy 60.831 | uer 17.445 | wer 19.529 | raw_wer 19.529 | bleu 19.47 | wps 2195.4 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 19.47
2023-07-04 06:33:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-07-04 06:33:49 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 06:33:53 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 06:33:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt (epoch 10 @ 14732 updates, score 19.47) (writing took 8.137641017325222 seconds)
2023-07-04 06:33:57 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-07-04 06:33:57 | INFO | train | epoch 010 | loss 3.606 | trans_loss 3.466 | nll_loss 1.612 | w2v_ctc_loss 0.998 | task_loss 0 | contrastive_loss 0.169 | total 4138.65 | n_correct 2516.19 | ppl 3.06 | accuracy 60.797 | wps 17995.6 | ups 1.46 | wpb 12355.8 | bsz 458.5 | num_updates 14732 | lr 0.000116516 | gnorm 0.488 | clip 0 | loss_scale 32 | train_wall 928 | gb_free 17.4 | wall 9604
2023-07-04 06:33:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 06:33:58 | INFO | fairseq.trainer | begin training epoch 11
2023-07-04 06:33:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 06:34:48 | INFO | train_inner | epoch 011:     68 / 1474 loss=3.573, trans_loss=3.448, nll_loss=1.59, w2v_ctc_loss=0.97, task_loss=0, contrastive_loss=0.176, total=4175.24, n_correct=2564.11, ppl=3.01, accuracy=61.412, wps=11919.1, ups=0.96, wpb=12460.8, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.484, clip=0, loss_scale=32, train_wall=62, gb_free=16.9, wall=9654
2023-07-04 06:35:52 | INFO | train_inner | epoch 011:    168 / 1474 loss=3.559, trans_loss=3.445, nll_loss=1.586, w2v_ctc_loss=0.969, task_loss=0, contrastive_loss=0.096, total=4087.78, n_correct=2512.28, ppl=3, accuracy=61.458, wps=19293.1, ups=1.58, wpb=12225.8, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.485, clip=0, loss_scale=32, train_wall=63, gb_free=16.7, wall=9718
2023-07-04 06:36:55 | INFO | train_inner | epoch 011:    268 / 1474 loss=3.55, trans_loss=3.442, nll_loss=1.583, w2v_ctc_loss=0.962, task_loss=0, contrastive_loss=0.091, total=4118.77, n_correct=2538.99, ppl=3, accuracy=61.644, wps=19441.2, ups=1.58, wpb=12285.5, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.484, clip=0, loss_scale=32, train_wall=63, gb_free=12.7, wall=9781
tensor(0.2697, device='cuda:0')
tensor(0.1564, device='cuda:0')
2023-07-04 06:37:58 | INFO | train_inner | epoch 011:    368 / 1474 loss=3.553, trans_loss=3.445, nll_loss=1.586, w2v_ctc_loss=0.959, task_loss=0, contrastive_loss=0.096, total=4097.83, n_correct=2523.55, ppl=3, accuracy=61.583, wps=19409.7, ups=1.59, wpb=12202.1, bsz=444.2, num_updates=15100, lr=0.000115087, gnorm=0.367, clip=0, loss_scale=32, train_wall=62, gb_free=16.3, wall=9844
2023-07-04 06:39:02 | INFO | train_inner | epoch 011:    468 / 1474 loss=3.59, trans_loss=3.458, nll_loss=1.598, w2v_ctc_loss=0.964, task_loss=0, contrastive_loss=0.254, total=4110.64, n_correct=2513.6, ppl=3.03, accuracy=61.149, wps=19156.3, ups=1.56, wpb=12265.6, bsz=450.5, num_updates=15200, lr=0.000114708, gnorm=0.372, clip=0, loss_scale=32, train_wall=64, gb_free=16.5, wall=9908
2023-07-04 06:40:06 | INFO | train_inner | epoch 011:    568 / 1474 loss=3.593, trans_loss=3.453, nll_loss=1.598, w2v_ctc_loss=0.975, task_loss=0, contrastive_loss=0.251, total=4071.69, n_correct=2498.1, ppl=3.03, accuracy=61.353, wps=19058.9, ups=1.57, wpb=12176.5, bsz=440.6, num_updates=15300, lr=0.000114332, gnorm=0.373, clip=0, loss_scale=32, train_wall=63, gb_free=16.5, wall=9972
2023-07-04 06:41:09 | INFO | train_inner | epoch 011:    668 / 1474 loss=3.597, trans_loss=3.45, nll_loss=1.592, w2v_ctc_loss=0.969, task_loss=0, contrastive_loss=0.33, total=4157.2, n_correct=2550.68, ppl=3.01, accuracy=61.356, wps=19663.1, ups=1.59, wpb=12400.2, bsz=464.4, num_updates=15400, lr=0.000113961, gnorm=0.369, clip=0, loss_scale=32, train_wall=63, gb_free=16.9, wall=10035
2023-07-04 06:42:12 | INFO | train_inner | epoch 011:    768 / 1474 loss=3.579, trans_loss=3.455, nll_loss=1.597, w2v_ctc_loss=0.984, task_loss=0, contrastive_loss=0.096, total=4174.91, n_correct=2562, ppl=3.03, accuracy=61.367, wps=19605, ups=1.57, wpb=12472.8, bsz=460.4, num_updates=15500, lr=0.000113592, gnorm=0.368, clip=0, loss_scale=32, train_wall=63, gb_free=17.1, wall=10098
2023-07-04 06:43:16 | INFO | train_inner | epoch 011:    868 / 1474 loss=3.57, trans_loss=3.452, nll_loss=1.597, w2v_ctc_loss=0.98, task_loss=0, contrastive_loss=0.082, total=4118.44, n_correct=2519.92, ppl=3.03, accuracy=61.186, wps=19379.5, ups=1.58, wpb=12290.5, bsz=440.6, num_updates=15600, lr=0.000113228, gnorm=0.368, clip=0, loss_scale=32, train_wall=63, gb_free=11.2, wall=10162
2023-07-04 06:44:19 | INFO | train_inner | epoch 011:    968 / 1474 loss=3.573, trans_loss=3.454, nll_loss=1.598, w2v_ctc_loss=0.978, task_loss=0, contrastive_loss=0.098, total=4140.92, n_correct=2537.15, ppl=3.03, accuracy=61.27, wps=19551.4, ups=1.58, wpb=12353.7, bsz=452.9, num_updates=15700, lr=0.000112867, gnorm=0.369, clip=0, loss_scale=32, train_wall=63, gb_free=15.8, wall=10225
2023-07-04 06:45:22 | INFO | train_inner | epoch 011:   1068 / 1474 loss=3.58, trans_loss=3.452, nll_loss=1.597, w2v_ctc_loss=0.983, task_loss=0, contrastive_loss=0.121, total=4136.99, n_correct=2539.96, ppl=3.02, accuracy=61.396, wps=19632.7, ups=1.59, wpb=12367, bsz=463.2, num_updates=15800, lr=0.000112509, gnorm=0.369, clip=0, loss_scale=32, train_wall=63, gb_free=17.7, wall=10288
2023-07-04 06:46:25 | INFO | train_inner | epoch 011:   1168 / 1474 loss=3.575, trans_loss=3.453, nll_loss=1.601, w2v_ctc_loss=0.982, task_loss=0, contrastive_loss=0.103, total=4185.65, n_correct=2565.07, ppl=3.03, accuracy=61.282, wps=19693.3, ups=1.58, wpb=12477.8, bsz=464.7, num_updates=15900, lr=0.000112154, gnorm=0.365, clip=0, loss_scale=32, train_wall=63, gb_free=14.3, wall=10351
2023-07-04 06:47:29 | INFO | train_inner | epoch 011:   1268 / 1474 loss=3.594, trans_loss=3.454, nll_loss=1.598, w2v_ctc_loss=0.981, task_loss=0, contrastive_loss=0.194, total=4171.89, n_correct=2558.3, ppl=3.03, accuracy=61.322, wps=19666.6, ups=1.58, wpb=12466.6, bsz=471.1, num_updates=16000, lr=0.000111803, gnorm=0.368, clip=0, loss_scale=32, train_wall=63, gb_free=16.1, wall=10415
2023-07-04 06:47:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.2697, device='cuda:5')
tensor(0.1564, device='cuda:5')
tensor(0.2697, device='cuda:1')
tensor(0.1564, device='cuda:1')
tensor(0.2697, device='cuda:6')
tensor(0.1564, device='cuda:6')
tensor(0.2697, device='cuda:4')
tensor(0.1564, device='cuda:4')
tensor(0.2697, device='cuda:2')
tensor(0.1564, device='cuda:2')
tensor(0.2697, device='cuda:7')
tensor(0.1564, device='cuda:7')
tensor(0.2697, device='cuda:3')
tensor(0.1564, device='cuda:3')
2023-07-04 06:47:55 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.417 | trans_loss 5.644 | nll_loss 2.938 | w2v_ctc_loss 1.438 | task_loss 0 | contrastive_loss 0.261 | total 4003.4 | n_correct 2432 | ppl 7.66 | accuracy 60.748 | uer 17.787 | wer 19.38 | raw_wer 19.38 | bleu 19.56 | wps 2151.4 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.56
2023-07-04 06:47:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-07-04 06:47:55 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_11_16000.pt
2023-07-04 06:47:57 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_11_16000.pt
2023-07-04 06:48:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 19.56) (writing took 9.356492745224386 seconds)
2023-07-04 06:49:08 | INFO | train_inner | epoch 011:   1368 / 1474 loss=3.617, trans_loss=3.452, nll_loss=1.596, w2v_ctc_loss=0.972, task_loss=0, contrastive_loss=0.41, total=4190.34, n_correct=2567.36, ppl=3.02, accuracy=61.269, wps=12533, ups=1, wpb=12512.8, bsz=491.8, num_updates=16100, lr=0.000111456, gnorm=0.368, clip=0, loss_scale=32, train_wall=63, gb_free=17.1, wall=10515
2023-07-04 06:50:12 | INFO | train_inner | epoch 011:   1468 / 1474 loss=3.576, trans_loss=3.454, nll_loss=1.599, w2v_ctc_loss=0.978, task_loss=0, contrastive_loss=0.109, total=4158.39, n_correct=2549.49, ppl=3.03, accuracy=61.31, wps=19555.7, ups=1.57, wpb=12421.8, bsz=468, num_updates=16200, lr=0.000111111, gnorm=0.366, clip=0, loss_scale=32, train_wall=63, gb_free=17.1, wall=10578
2023-07-04 06:50:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 06:50:44 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.382 | trans_loss 5.629 | nll_loss 2.919 | w2v_ctc_loss 1.358 | task_loss 0 | contrastive_loss 0.256 | total 4003.4 | n_correct 2429.9 | ppl 7.56 | accuracy 60.696 | uer 17.53 | wer 19.38 | raw_wer 19.38 | bleu 19.43 | wps 1876.2 | wpb 4003.4 | bsz 141.8 | num_updates 16206 | best_bleu 19.56
2023-07-04 06:50:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16206 updates
2023-07-04 06:50:44 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_19.4303.pt
2023-07-04 06:50:46 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_19.4303.pt
2023-07-04 06:50:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_19.4303.pt (epoch 11 @ 16206 updates, score 19.43) (writing took 5.5960846287198365 seconds)
2023-07-04 06:50:50 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-07-04 06:50:50 | INFO | train | epoch 011 | loss 3.578 | trans_loss 3.451 | nll_loss 1.594 | w2v_ctc_loss 0.974 | task_loss 0 | contrastive_loss 0.164 | total 4138.65 | n_correct 2539.63 | ppl 3.02 | accuracy 61.364 | wps 17990.7 | ups 1.46 | wpb 12355.8 | bsz 458.5 | num_updates 16206 | lr 0.000111091 | gnorm 0.389 | clip 0 | loss_scale 32 | train_wall 927 | gb_free 17.3 | wall 10616
2023-07-04 06:50:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 06:50:50 | INFO | fairseq.trainer | begin training epoch 12
2023-07-04 06:50:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 06:51:57 | INFO | train_inner | epoch 012:     94 / 1474 loss=3.538, trans_loss=3.427, nll_loss=1.562, w2v_ctc_loss=0.944, task_loss=0, contrastive_loss=0.151, total=4146.82, n_correct=2583.69, ppl=2.95, accuracy=62.305, wps=11776, ups=0.95, wpb=12379.4, bsz=470.8, num_updates=16300, lr=0.00011077, gnorm=0.365, clip=0, loss_scale=32, train_wall=63, gb_free=15.9, wall=10683
2023-07-04 06:53:00 | INFO | train_inner | epoch 012:    194 / 1474 loss=3.536, trans_loss=3.43, nll_loss=1.568, w2v_ctc_loss=0.954, task_loss=0, contrastive_loss=0.085, total=4120.68, n_correct=2558.69, ppl=2.96, accuracy=62.094, wps=19546.3, ups=1.58, wpb=12345.4, bsz=442.1, num_updates=16400, lr=0.000110432, gnorm=0.368, clip=0, loss_scale=32, train_wall=63, gb_free=15.8, wall=10746
2023-07-04 06:54:04 | INFO | train_inner | epoch 012:    294 / 1474 loss=3.535, trans_loss=3.43, nll_loss=1.569, w2v_ctc_loss=0.938, task_loss=0, contrastive_loss=0.126, total=4199.46, n_correct=2611.77, ppl=2.97, accuracy=62.193, wps=19629.9, ups=1.57, wpb=12539.6, bsz=480.4, num_updates=16500, lr=0.000110096, gnorm=0.363, clip=0, loss_scale=32, train_wall=63, gb_free=16.7, wall=10810
2023-07-04 06:55:08 | INFO | train_inner | epoch 012:    394 / 1474 loss=3.536, trans_loss=3.433, nll_loss=1.571, w2v_ctc_loss=0.947, task_loss=0, contrastive_loss=0.104, total=4151.14, n_correct=2578.05, ppl=2.97, accuracy=62.105, wps=19404.8, ups=1.56, wpb=12410, bsz=461.6, num_updates=16600, lr=0.000109764, gnorm=0.363, clip=0, loss_scale=32, train_wall=64, gb_free=17.2, wall=10874
2023-07-04 06:56:11 | INFO | train_inner | epoch 012:    494 / 1474 loss=3.561, trans_loss=3.446, nll_loss=1.585, w2v_ctc_loss=0.966, task_loss=0, contrastive_loss=0.115, total=4110.49, n_correct=2540.6, ppl=3, accuracy=61.808, wps=19311.1, ups=1.58, wpb=12226.9, bsz=453.3, num_updates=16700, lr=0.000109435, gnorm=0.369, clip=0, loss_scale=64, train_wall=63, gb_free=14.1, wall=10938
2023-07-04 06:57:16 | INFO | train_inner | epoch 012:    594 / 1474 loss=3.558, trans_loss=3.435, nll_loss=1.576, w2v_ctc_loss=0.956, task_loss=0, contrastive_loss=0.197, total=4189.92, n_correct=2596.81, ppl=2.98, accuracy=61.978, wps=19477.2, ups=1.55, wpb=12531.1, bsz=472.7, num_updates=16800, lr=0.000109109, gnorm=0.369, clip=0, loss_scale=64, train_wall=64, gb_free=15.1, wall=11002
2023-07-04 06:58:19 | INFO | train_inner | epoch 012:    694 / 1474 loss=3.558, trans_loss=3.43, nll_loss=1.57, w2v_ctc_loss=0.938, task_loss=0, contrastive_loss=0.317, total=4206.3, n_correct=2612.95, ppl=2.97, accuracy=62.12, wps=19814.3, ups=1.58, wpb=12501.9, bsz=488.5, num_updates=16900, lr=0.000108786, gnorm=0.364, clip=0, loss_scale=64, train_wall=63, gb_free=16.4, wall=11065
2023-07-04 06:59:23 | INFO | train_inner | epoch 012:    794 / 1474 loss=3.552, trans_loss=3.439, nll_loss=1.577, w2v_ctc_loss=0.959, task_loss=0, contrastive_loss=0.1, total=4085.96, n_correct=2537.31, ppl=2.98, accuracy=62.098, wps=19178.4, ups=1.57, wpb=12212.6, bsz=445.7, num_updates=17000, lr=0.000108465, gnorm=0.368, clip=0, loss_scale=64, train_wall=63, gb_free=16.6, wall=11129
2023-07-04 07:00:26 | INFO | train_inner | epoch 012:    894 / 1474 loss=3.558, trans_loss=3.436, nll_loss=1.577, w2v_ctc_loss=0.958, task_loss=0, contrastive_loss=0.168, total=4169.74, n_correct=2588.62, ppl=2.98, accuracy=62.081, wps=19477.4, ups=1.56, wpb=12453, bsz=459.6, num_updates=17100, lr=0.000108148, gnorm=0.369, clip=0, loss_scale=64, train_wall=64, gb_free=16.2, wall=11193
2023-07-04 07:01:30 | INFO | train_inner | epoch 012:    994 / 1474 loss=3.56, trans_loss=3.441, nll_loss=1.581, w2v_ctc_loss=0.961, task_loss=0, contrastive_loss=0.179, total=4117.67, n_correct=2548.34, ppl=2.99, accuracy=61.888, wps=19441.4, ups=1.58, wpb=12288, bsz=452.1, num_updates=17200, lr=0.000107833, gnorm=0.369, clip=0, loss_scale=64, train_wall=63, gb_free=17.7, wall=11256
2023-07-04 07:02:33 | INFO | train_inner | epoch 012:   1094 / 1474 loss=3.579, trans_loss=3.445, nll_loss=1.587, w2v_ctc_loss=0.967, task_loss=0, contrastive_loss=0.241, total=4047.61, n_correct=2499.24, ppl=3, accuracy=61.746, wps=19171.6, ups=1.59, wpb=12086.1, bsz=435.6, num_updates=17300, lr=0.000107521, gnorm=0.377, clip=0, loss_scale=64, train_wall=63, gb_free=16.9, wall=11319
2023-07-04 07:03:36 | INFO | train_inner | epoch 012:   1194 / 1474 loss=3.581, trans_loss=3.444, nll_loss=1.588, w2v_ctc_loss=0.98, task_loss=0, contrastive_loss=0.176, total=4184.55, n_correct=2578.13, ppl=3.01, accuracy=61.611, wps=19730.9, ups=1.58, wpb=12497.1, bsz=471.4, num_updates=17400, lr=0.000107211, gnorm=0.368, clip=0, loss_scale=64, train_wall=63, gb_free=16.9, wall=11382
2023-07-04 07:04:40 | INFO | train_inner | epoch 012:   1294 / 1474 loss=3.569, trans_loss=3.448, nll_loss=1.594, w2v_ctc_loss=0.977, task_loss=0, contrastive_loss=0.107, total=4086.33, n_correct=2522.41, ppl=3.02, accuracy=61.728, wps=19178.6, ups=1.57, wpb=12210.8, bsz=437.2, num_updates=17500, lr=0.000106904, gnorm=0.376, clip=0, loss_scale=64, train_wall=63, gb_free=17, wall=11446
2023-07-04 07:05:43 | INFO | train_inner | epoch 012:   1394 / 1474 loss=3.565, trans_loss=3.442, nll_loss=1.585, w2v_ctc_loss=0.955, task_loss=0, contrastive_loss=0.22, total=4134.89, n_correct=2556.68, ppl=3, accuracy=61.832, wps=19518.5, ups=1.58, wpb=12323.9, bsz=456.6, num_updates=17600, lr=0.0001066, gnorm=0.365, clip=0, loss_scale=64, train_wall=63, gb_free=17.4, wall=11509
2023-07-04 07:06:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 07:06:59 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.379 | trans_loss 5.62 | nll_loss 2.906 | w2v_ctc_loss 1.364 | task_loss 0 | contrastive_loss 0.265 | total 4003.4 | n_correct 2443.8 | ppl 7.5 | accuracy 61.043 | uer 17.774 | wer 19.604 | raw_wer 19.604 | bleu 19.56 | wps 2199.8 | wpb 4003.4 | bsz 141.8 | num_updates 17680 | best_bleu 19.56
2023-07-04 07:06:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17680 updates
2023-07-04 07:06:59 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 07:07:03 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 07:07:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt (epoch 12 @ 17680 updates, score 19.56) (writing took 8.559808219317347 seconds)
2023-07-04 07:07:08 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-07-04 07:07:08 | INFO | train | epoch 012 | loss 3.556 | trans_loss 3.438 | nll_loss 1.578 | w2v_ctc_loss 0.958 | task_loss 0 | contrastive_loss 0.16 | total 4138.65 | n_correct 2564.51 | ppl 2.99 | accuracy 61.965 | wps 18624.9 | ups 1.51 | wpb 12355.8 | bsz 458.5 | num_updates 17680 | lr 0.000106359 | gnorm 0.368 | clip 0 | loss_scale 64 | train_wall 930 | gb_free 13.2 | wall 11594
2023-07-04 07:07:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 07:07:08 | INFO | fairseq.trainer | begin training epoch 13
2023-07-04 07:07:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 07:07:29 | INFO | train_inner | epoch 013:     20 / 1474 loss=3.556, trans_loss=3.439, nll_loss=1.581, w2v_ctc_loss=0.971, task_loss=0, contrastive_loss=0.093, total=4104.86, n_correct=2541.3, ppl=2.99, accuracy=61.91, wps=11613.2, ups=0.95, wpb=12264.8, bsz=445.3, num_updates=17700, lr=0.000106299, gnorm=0.368, clip=0, loss_scale=64, train_wall=63, gb_free=15, wall=11615
2023-07-04 07:08:32 | INFO | train_inner | epoch 013:    120 / 1474 loss=3.517, trans_loss=3.417, nll_loss=1.551, w2v_ctc_loss=0.933, task_loss=0, contrastive_loss=0.107, total=4161.2, n_correct=2610.45, ppl=2.93, accuracy=62.733, wps=19459.4, ups=1.57, wpb=12419, bsz=454.4, num_updates=17800, lr=0.000106, gnorm=0.358, clip=0, loss_scale=64, train_wall=63, gb_free=16.3, wall=11678
2023-07-04 07:09:36 | INFO | train_inner | epoch 013:    220 / 1474 loss=3.567, trans_loss=3.422, nll_loss=1.562, w2v_ctc_loss=0.942, task_loss=0, contrastive_loss=0.396, total=4202.62, n_correct=2622.21, ppl=2.95, accuracy=62.395, wps=19548.4, ups=1.56, wpb=12504.4, bsz=492.4, num_updates=17900, lr=0.000105703, gnorm=0.366, clip=0, loss_scale=64, train_wall=64, gb_free=17.3, wall=11742
2023-07-04 07:10:40 | INFO | train_inner | epoch 013:    320 / 1474 loss=3.515, trans_loss=3.422, nll_loss=1.556, w2v_ctc_loss=0.929, task_loss=0, contrastive_loss=0.089, total=4112.8, n_correct=2580.61, ppl=2.94, accuracy=62.746, wps=19314, ups=1.58, wpb=12262.5, bsz=444, num_updates=18000, lr=0.000105409, gnorm=0.37, clip=0, loss_scale=64, train_wall=63, gb_free=17.9, wall=11806
2023-07-04 07:10:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 07:11:09 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.385 | trans_loss 5.628 | nll_loss 2.913 | w2v_ctc_loss 1.367 | task_loss 0 | contrastive_loss 0.264 | total 4003.4 | n_correct 2438.7 | ppl 7.53 | accuracy 60.916 | uer 17.641 | wer 19.526 | raw_wer 19.526 | bleu 19.13 | wps 1798 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.56
2023-07-04 07:11:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-07-04 07:11:09 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_13_18000.pt
2023-07-04 07:11:11 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_13_18000.pt
2023-07-04 07:11:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.13) (writing took 6.42552395304665 seconds)
2023-07-04 07:12:19 | INFO | train_inner | epoch 013:    420 / 1474 loss=3.533, trans_loss=3.426, nll_loss=1.562, w2v_ctc_loss=0.933, task_loss=0, contrastive_loss=0.153, total=4176.06, n_correct=2622.12, ppl=2.95, accuracy=62.789, wps=12523.7, ups=1.01, wpb=12453.9, bsz=476.2, num_updates=18100, lr=0.000105118, gnorm=0.362, clip=0, loss_scale=64, train_wall=63, gb_free=16.6, wall=11905
2023-07-04 07:13:23 | INFO | train_inner | epoch 013:    520 / 1474 loss=3.542, trans_loss=3.426, nll_loss=1.563, w2v_ctc_loss=0.94, task_loss=0, contrastive_loss=0.2, total=4197.57, n_correct=2617.88, ppl=2.95, accuracy=62.367, wps=19615.7, ups=1.57, wpb=12523.8, bsz=477.2, num_updates=18200, lr=0.000104828, gnorm=0.362, clip=0, loss_scale=64, train_wall=63, gb_free=15.5, wall=11969
2023-07-04 07:14:26 | INFO | train_inner | epoch 013:    620 / 1474 loss=3.515, trans_loss=3.421, nll_loss=1.557, w2v_ctc_loss=0.93, task_loss=0, contrastive_loss=0.084, total=4160.12, n_correct=2607.31, ppl=2.94, accuracy=62.674, wps=19685.9, ups=1.58, wpb=12433.1, bsz=463, num_updates=18300, lr=0.000104542, gnorm=0.364, clip=0, loss_scale=64, train_wall=63, gb_free=16.5, wall=12032
2023-07-04 07:15:30 | INFO | train_inner | epoch 013:    720 / 1474 loss=3.539, trans_loss=3.43, nll_loss=1.568, w2v_ctc_loss=0.963, task_loss=0, contrastive_loss=0.084, total=4101.54, n_correct=2553.06, ppl=2.96, accuracy=62.246, wps=19272.2, ups=1.57, wpb=12238, bsz=428.5, num_updates=18400, lr=0.000104257, gnorm=0.372, clip=0, loss_scale=64, train_wall=63, gb_free=15.9, wall=12096
2023-07-04 07:16:34 | INFO | train_inner | epoch 013:    820 / 1474 loss=3.536, trans_loss=3.427, nll_loss=1.564, w2v_ctc_loss=0.94, task_loss=0, contrastive_loss=0.144, total=4126.37, n_correct=2571.62, ppl=2.96, accuracy=62.322, wps=19269.5, ups=1.56, wpb=12333.7, bsz=460.5, num_updates=18500, lr=0.000103975, gnorm=0.37, clip=0, loss_scale=64, train_wall=64, gb_free=17.7, wall=12160
2023-07-04 07:17:37 | INFO | train_inner | epoch 013:    920 / 1474 loss=3.524, trans_loss=3.427, nll_loss=1.565, w2v_ctc_loss=0.935, task_loss=0, contrastive_loss=0.096, total=4102.78, n_correct=2561.94, ppl=2.96, accuracy=62.444, wps=19396.1, ups=1.58, wpb=12250.4, bsz=443.9, num_updates=18600, lr=0.000103695, gnorm=0.37, clip=0, loss_scale=64, train_wall=63, gb_free=16.7, wall=12223
2023-07-04 07:18:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-04 07:18:41 | INFO | train_inner | epoch 013:   1021 / 1474 loss=3.532, trans_loss=3.425, nll_loss=1.565, w2v_ctc_loss=0.958, task_loss=0, contrastive_loss=0.075, total=4053.83, n_correct=2525.39, ppl=2.96, accuracy=62.296, wps=19089.4, ups=1.57, wpb=12133, bsz=426.3, num_updates=18700, lr=0.000103418, gnorm=0.372, clip=0, loss_scale=64, train_wall=63, gb_free=16.4, wall=12287
2023-07-04 07:19:44 | INFO | train_inner | epoch 013:   1121 / 1474 loss=3.533, trans_loss=3.425, nll_loss=1.561, w2v_ctc_loss=0.938, task_loss=0, contrastive_loss=0.139, total=4105.62, n_correct=2573.89, ppl=2.95, accuracy=62.692, wps=19468, ups=1.59, wpb=12265.4, bsz=458.9, num_updates=18800, lr=0.000103142, gnorm=0.367, clip=0, loss_scale=64, train_wall=63, gb_free=16.9, wall=12350
2023-07-04 07:20:47 | INFO | train_inner | epoch 013:   1221 / 1474 loss=3.54, trans_loss=3.435, nll_loss=1.574, w2v_ctc_loss=0.95, task_loss=0, contrastive_loss=0.085, total=4110.35, n_correct=2564.56, ppl=2.98, accuracy=62.393, wps=19333.8, ups=1.57, wpb=12287.7, bsz=442.6, num_updates=18900, lr=0.000102869, gnorm=0.372, clip=0, loss_scale=64, train_wall=63, gb_free=15.1, wall=12413
2023-07-04 07:21:51 | INFO | train_inner | epoch 013:   1321 / 1474 loss=3.538, trans_loss=3.424, nll_loss=1.564, w2v_ctc_loss=0.936, task_loss=0, contrastive_loss=0.216, total=4112.2, n_correct=2575.31, ppl=2.96, accuracy=62.626, wps=19288.8, ups=1.57, wpb=12280.4, bsz=462.3, num_updates=19000, lr=0.000102598, gnorm=0.371, clip=0, loss_scale=64, train_wall=63, gb_free=17.7, wall=12477
2023-07-04 07:22:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-04 07:22:55 | INFO | train_inner | epoch 013:   1422 / 1474 loss=3.527, trans_loss=3.432, nll_loss=1.569, w2v_ctc_loss=0.936, task_loss=0, contrastive_loss=0.079, total=4156.59, n_correct=2595.21, ppl=2.97, accuracy=62.436, wps=19389.8, ups=1.56, wpb=12408.2, bsz=455, num_updates=19100, lr=0.000102329, gnorm=0.366, clip=0, loss_scale=32, train_wall=64, gb_free=16.2, wall=12541
2023-07-04 07:23:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 07:23:55 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.381 | trans_loss 5.618 | nll_loss 2.907 | w2v_ctc_loss 1.378 | task_loss 0 | contrastive_loss 0.262 | total 4003.4 | n_correct 2444.6 | ppl 7.5 | accuracy 61.063 | uer 17.58 | wer 19.403 | raw_wer 19.403 | bleu 19.77 | wps 2042.1 | wpb 4003.4 | bsz 141.8 | num_updates 19152 | best_bleu 19.77
2023-07-04 07:23:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19152 updates
2023-07-04 07:23:55 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 07:23:59 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 07:24:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt (epoch 13 @ 19152 updates, score 19.77) (writing took 8.48252911074087 seconds)
2023-07-04 07:24:03 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-07-04 07:24:03 | INFO | train | epoch 013 | loss 3.532 | trans_loss 3.425 | nll_loss 1.563 | w2v_ctc_loss 0.94 | task_loss 0 | contrastive_loss 0.14 | total 4135.66 | n_correct 2585.7 | ppl 2.95 | accuracy 62.522 | wps 17894.7 | ups 1.45 | wpb 12347.6 | bsz 456.9 | num_updates 19152 | lr 0.00010219 | gnorm 0.367 | clip 0 | loss_scale 32 | train_wall 929 | gb_free 17.7 | wall 12609
2023-07-04 07:24:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 07:24:04 | INFO | fairseq.trainer | begin training epoch 14
2023-07-04 07:24:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 07:24:42 | INFO | train_inner | epoch 014:     48 / 1474 loss=3.503, trans_loss=3.407, nll_loss=1.541, w2v_ctc_loss=0.926, task_loss=0, contrastive_loss=0.102, total=4179.66, n_correct=2639.91, ppl=2.91, accuracy=63.161, wps=11691.3, ups=0.94, wpb=12495.5, bsz=483, num_updates=19200, lr=0.000102062, gnorm=0.366, clip=0, loss_scale=32, train_wall=63, gb_free=11, wall=12648
2023-07-04 07:25:45 | INFO | train_inner | epoch 014:    148 / 1474 loss=3.492, trans_loss=3.407, nll_loss=1.536, w2v_ctc_loss=0.916, task_loss=0, contrastive_loss=0.08, total=4081.01, n_correct=2587.85, ppl=2.9, accuracy=63.412, wps=19387.1, ups=1.59, wpb=12201.4, bsz=450.9, num_updates=19300, lr=0.000101797, gnorm=0.367, clip=0, loss_scale=32, train_wall=63, gb_free=16.1, wall=12711
2023-07-04 07:26:48 | INFO | train_inner | epoch 014:    248 / 1474 loss=3.515, trans_loss=3.417, nll_loss=1.551, w2v_ctc_loss=0.915, task_loss=0, contrastive_loss=0.216, total=4109.83, n_correct=2593.79, ppl=2.93, accuracy=63.112, wps=19238.6, ups=1.57, wpb=12237.8, bsz=442.7, num_updates=19400, lr=0.000101535, gnorm=0.369, clip=0, loss_scale=32, train_wall=63, gb_free=15.9, wall=12774
2023-07-04 07:27:51 | INFO | train_inner | epoch 014:    348 / 1474 loss=3.49, trans_loss=3.399, nll_loss=1.536, w2v_ctc_loss=0.911, task_loss=0, contrastive_loss=0.126, total=4171.83, n_correct=2641.67, ppl=2.9, accuracy=63.322, wps=19643.6, ups=1.58, wpb=12430.7, bsz=479.5, num_updates=19500, lr=0.000101274, gnorm=0.363, clip=0, loss_scale=32, train_wall=63, gb_free=16.8, wall=12838
2023-07-04 07:28:55 | INFO | train_inner | epoch 014:    448 / 1474 loss=3.498, trans_loss=3.411, nll_loss=1.545, w2v_ctc_loss=0.917, task_loss=0, contrastive_loss=0.092, total=4142.75, n_correct=2613.14, ppl=2.92, accuracy=63.077, wps=19441.2, ups=1.58, wpb=12340.5, bsz=453.3, num_updates=19600, lr=0.000101015, gnorm=0.368, clip=0, loss_scale=32, train_wall=63, gb_free=16.8, wall=12901
2023-07-04 07:29:59 | INFO | train_inner | epoch 014:    548 / 1474 loss=3.523, trans_loss=3.42, nll_loss=1.555, w2v_ctc_loss=0.936, task_loss=0, contrastive_loss=0.103, total=4073.76, n_correct=2557.54, ppl=2.94, accuracy=62.781, wps=19218.3, ups=1.57, wpb=12222.1, bsz=436.3, num_updates=19700, lr=0.000100759, gnorm=0.372, clip=0, loss_scale=32, train_wall=63, gb_free=15.6, wall=12965
2023-07-04 07:31:02 | INFO | train_inner | epoch 014:    648 / 1474 loss=3.52, trans_loss=3.418, nll_loss=1.554, w2v_ctc_loss=0.922, task_loss=0, contrastive_loss=0.18, total=4158.79, n_correct=2612.41, ppl=2.94, accuracy=62.817, wps=19624.8, ups=1.58, wpb=12412.4, bsz=460.2, num_updates=19800, lr=0.000100504, gnorm=0.37, clip=0, loss_scale=32, train_wall=63, gb_free=17.3, wall=13028
2023-07-04 07:32:05 | INFO | train_inner | epoch 014:    748 / 1474 loss=3.501, trans_loss=3.412, nll_loss=1.546, w2v_ctc_loss=0.92, task_loss=0, contrastive_loss=0.09, total=4145.47, n_correct=2617.51, ppl=2.92, accuracy=63.141, wps=19573.3, ups=1.58, wpb=12397.1, bsz=464.3, num_updates=19900, lr=0.000100251, gnorm=0.367, clip=0, loss_scale=32, train_wall=63, gb_free=16.4, wall=13091
2023-07-04 07:33:08 | INFO | train_inner | epoch 014:    848 / 1474 loss=3.518, trans_loss=3.407, nll_loss=1.543, w2v_ctc_loss=0.915, task_loss=0, contrastive_loss=0.237, total=4171.1, n_correct=2631, ppl=2.91, accuracy=63.077, wps=19724, ups=1.58, wpb=12447.1, bsz=479.5, num_updates=20000, lr=0.0001, gnorm=0.371, clip=0, loss_scale=32, train_wall=63, gb_free=16.9, wall=13154
2023-07-04 07:33:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 07:33:35 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.384 | trans_loss 5.607 | nll_loss 2.889 | w2v_ctc_loss 1.416 | task_loss 0 | contrastive_loss 0.252 | total 4003.4 | n_correct 2456.6 | ppl 7.41 | accuracy 61.363 | uer 17.495 | wer 19.302 | raw_wer 19.302 | bleu 19.6 | wps 2017.5 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.77
2023-07-04 07:33:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-07-04 07:33:35 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_14_20000.pt
2023-07-04 07:33:37 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_14_20000.pt
2023-07-04 07:33:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.6) (writing took 6.397018933668733 seconds)
tensor(0.0295, device='cuda:0')
tensor(0.0009, device='cuda:0')
2023-07-04 07:34:20 | INFO | train_inner | epoch 014:    948 / 1474 loss=4.236, trans_loss=5.367, nll_loss=2.713, w2v_ctc_loss=1.394, task_loss=0, contrastive_loss=0.228, total=4167.75, n_correct=2606.28, ppl=6.55, accuracy=62.534, wps=5979.7, ups=1.4, wpb=4260.9, bsz=157.9, num_updates=20100, lr=9.97509e-05, gnorm=1.037, clip=0, loss_scale=32, train_wall=37, gb_free=17, wall=13226
2023-07-04 07:34:57 | INFO | train_inner | epoch 014:   1048 / 1474 loss=4.245, trans_loss=5.428, nll_loss=2.748, w2v_ctc_loss=1.392, task_loss=0, contrastive_loss=0.181, total=4143.92, n_correct=2596.73, ppl=6.72, accuracy=62.664, wps=11102.8, ups=2.68, wpb=4143.9, bsz=150.4, num_updates=20200, lr=9.95037e-05, gnorm=1.035, clip=0, loss_scale=32, train_wall=37, gb_free=16.4, wall=13263
2023-07-04 07:35:34 | INFO | train_inner | epoch 014:   1148 / 1474 loss=4.287, trans_loss=5.431, nll_loss=2.752, w2v_ctc_loss=1.406, task_loss=0, contrastive_loss=0.723, total=4228.69, n_correct=2650.33, ppl=6.74, accuracy=62.675, wps=11359.8, ups=2.69, wpb=4228.7, bsz=163.6, num_updates=20300, lr=9.92583e-05, gnorm=1.028, clip=0, loss_scale=32, train_wall=37, gb_free=16.2, wall=13300
2023-07-04 07:36:11 | INFO | train_inner | epoch 014:   1248 / 1474 loss=4.265, trans_loss=5.45, nll_loss=2.774, w2v_ctc_loss=1.435, task_loss=0, contrastive_loss=0.105, total=4021.19, n_correct=2508.18, ppl=6.84, accuracy=62.374, wps=10999, ups=2.74, wpb=4021.2, bsz=135.8, num_updates=20400, lr=9.90148e-05, gnorm=1.06, clip=0, loss_scale=32, train_wall=36, gb_free=16.7, wall=13337
2023-07-04 07:36:47 | INFO | train_inner | epoch 014:   1348 / 1474 loss=4.238, trans_loss=5.426, nll_loss=2.745, w2v_ctc_loss=1.385, task_loss=0, contrastive_loss=0.135, total=4213.9, n_correct=2644.85, ppl=6.7, accuracy=62.765, wps=11501.8, ups=2.73, wpb=4213.9, bsz=159.7, num_updates=20500, lr=9.8773e-05, gnorm=1.013, clip=0, loss_scale=32, train_wall=36, gb_free=16.5, wall=13373
2023-07-04 07:37:24 | INFO | train_inner | epoch 014:   1448 / 1474 loss=4.255, trans_loss=5.434, nll_loss=2.757, w2v_ctc_loss=1.403, task_loss=0, contrastive_loss=0.216, total=4130.28, n_correct=2588.98, ppl=6.76, accuracy=62.683, wps=11239.5, ups=2.72, wpb=4130.3, bsz=152, num_updates=20600, lr=9.85329e-05, gnorm=1.033, clip=0, loss_scale=32, train_wall=36, gb_free=15.8, wall=13410
2023-07-04 07:37:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0295, device='cuda:2')
tensor(0.0009, device='cuda:2')
tensor(0.0295, device='cuda:4')
tensor(0.0009, device='cuda:4')
tensor(0.0295, device='cuda:6')
tensor(0.0009, device='cuda:6')
tensor(0.0295, device='cuda:5')
tensor(0.0009, device='cuda:5')
tensor(0.0295, device='cuda:7')
tensor(0.0009, device='cuda:7')
tensor(0.0295, device='cuda:3')
tensor(0.0009, device='cuda:3')
tensor(0.0295, device='cuda:1')
tensor(0.0009, device='cuda:1')
2023-07-04 07:38:02 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.353 | trans_loss 5.593 | nll_loss 2.876 | w2v_ctc_loss 1.343 | task_loss 0 | contrastive_loss 0.258 | total 4003.4 | n_correct 2459.1 | ppl 7.34 | accuracy 61.425 | uer 17.227 | wer 19.257 | raw_wer 19.257 | bleu 19.93 | wps 1863.8 | wpb 4003.4 | bsz 141.8 | num_updates 20626 | best_bleu 19.93
2023-07-04 07:38:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20626 updates
2023-07-04 07:38:02 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 07:38:06 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 07:38:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt (epoch 14 @ 20626 updates, score 19.93) (writing took 8.308474232442677 seconds)
2023-07-04 07:38:11 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-07-04 07:38:11 | INFO | train | epoch 014 | loss 3.655 | trans_loss 3.811 | nll_loss 1.785 | w2v_ctc_loss 1.016 | task_loss 0 | contrastive_loss 0.163 | total 4138.65 | n_correct 2603.07 | ppl 3.45 | accuracy 62.897 | wps 15423.3 | ups 1.74 | wpb 8868.8 | bsz 329.4 | num_updates 20626 | lr 9.84708e-05 | gnorm 0.652 | clip 0 | loss_scale 32 | train_wall 763 | gb_free 16.8 | wall 13457
2023-07-04 07:38:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 07:38:11 | INFO | fairseq.trainer | begin training epoch 15
2023-07-04 07:38:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 07:38:46 | INFO | train_inner | epoch 015:     74 / 1474 loss=4.22, trans_loss=5.393, nll_loss=2.702, w2v_ctc_loss=1.366, task_loss=0, contrastive_loss=0.316, total=4083.88, n_correct=2581.29, ppl=6.51, accuracy=63.207, wps=4991, ups=1.22, wpb=4083.9, bsz=150.1, num_updates=20700, lr=9.82946e-05, gnorm=1.041, clip=0, loss_scale=32, train_wall=36, gb_free=16.6, wall=13492
2023-07-04 07:39:23 | INFO | train_inner | epoch 015:    174 / 1474 loss=4.215, trans_loss=5.392, nll_loss=2.699, w2v_ctc_loss=1.393, task_loss=0, contrastive_loss=0.131, total=4115.73, n_correct=2606.85, ppl=6.49, accuracy=63.339, wps=11175.6, ups=2.72, wpb=4115.7, bsz=148.9, num_updates=20800, lr=9.80581e-05, gnorm=1.034, clip=0, loss_scale=32, train_wall=36, gb_free=17.2, wall=13529
2023-07-04 07:40:00 | INFO | train_inner | epoch 015:    274 / 1474 loss=4.202, trans_loss=5.384, nll_loss=2.69, w2v_ctc_loss=1.37, task_loss=0, contrastive_loss=0.116, total=4193.15, n_correct=2662.32, ppl=6.45, accuracy=63.492, wps=11383.4, ups=2.71, wpb=4193.1, bsz=156.3, num_updates=20900, lr=9.78232e-05, gnorm=1.019, clip=0, loss_scale=32, train_wall=36, gb_free=13.4, wall=13566
2023-07-04 07:40:37 | INFO | train_inner | epoch 015:    374 / 1474 loss=4.204, trans_loss=5.381, nll_loss=2.685, w2v_ctc_loss=1.371, task_loss=0, contrastive_loss=0.164, total=4167.66, n_correct=2643.35, ppl=6.43, accuracy=63.425, wps=11238.4, ups=2.7, wpb=4167.7, bsz=153, num_updates=21000, lr=9.759e-05, gnorm=1.025, clip=0, loss_scale=32, train_wall=37, gb_free=16.5, wall=13603
2023-07-04 07:41:14 | INFO | train_inner | epoch 015:    474 / 1474 loss=4.224, trans_loss=5.395, nll_loss=2.703, w2v_ctc_loss=1.366, task_loss=0, contrastive_loss=0.342, total=4074.53, n_correct=2573.38, ppl=6.51, accuracy=63.158, wps=11040.3, ups=2.71, wpb=4074.5, bsz=147.1, num_updates=21100, lr=9.73585e-05, gnorm=1.038, clip=0, loss_scale=32, train_wall=36, gb_free=16.2, wall=13640
2023-07-04 07:41:50 | INFO | train_inner | epoch 015:    574 / 1474 loss=4.214, trans_loss=5.389, nll_loss=2.698, w2v_ctc_loss=1.395, task_loss=0, contrastive_loss=0.129, total=4140.59, n_correct=2620.94, ppl=6.49, accuracy=63.299, wps=11311.9, ups=2.73, wpb=4140.6, bsz=149.4, num_updates=21200, lr=9.71286e-05, gnorm=1.031, clip=0, loss_scale=64, train_wall=36, gb_free=12.8, wall=13676
2023-07-04 07:42:27 | INFO | train_inner | epoch 015:    674 / 1474 loss=4.233, trans_loss=5.398, nll_loss=2.708, w2v_ctc_loss=1.394, task_loss=0, contrastive_loss=0.29, total=4134.99, n_correct=2614.4, ppl=6.54, accuracy=63.226, wps=11166.2, ups=2.7, wpb=4135, bsz=153.5, num_updates=21300, lr=9.69003e-05, gnorm=1.039, clip=0, loss_scale=64, train_wall=37, gb_free=11.3, wall=13713
2023-07-04 07:43:04 | INFO | train_inner | epoch 015:    774 / 1474 loss=4.217, trans_loss=5.397, nll_loss=2.708, w2v_ctc_loss=1.384, task_loss=0, contrastive_loss=0.135, total=4173.66, n_correct=2638.04, ppl=6.53, accuracy=63.207, wps=11298.3, ups=2.71, wpb=4173.7, bsz=152.5, num_updates=21400, lr=9.66736e-05, gnorm=1.023, clip=0, loss_scale=64, train_wall=37, gb_free=17.1, wall=13750
2023-07-04 07:43:41 | INFO | train_inner | epoch 015:    874 / 1474 loss=4.226, trans_loss=5.406, nll_loss=2.719, w2v_ctc_loss=1.4, task_loss=0, contrastive_loss=0.126, total=4059.35, n_correct=2560.96, ppl=6.59, accuracy=63.088, wps=11106.6, ups=2.74, wpb=4059.3, bsz=144.1, num_updates=21500, lr=9.64486e-05, gnorm=1.047, clip=0, loss_scale=64, train_wall=36, gb_free=16, wall=13787
2023-07-04 07:44:17 | INFO | train_inner | epoch 015:    974 / 1474 loss=4.223, trans_loss=5.397, nll_loss=2.707, w2v_ctc_loss=1.377, task_loss=0, contrastive_loss=0.292, total=4122.87, n_correct=2602.29, ppl=6.53, accuracy=63.118, wps=11271, ups=2.73, wpb=4122.9, bsz=150.8, num_updates=21600, lr=9.6225e-05, gnorm=1.022, clip=0, loss_scale=64, train_wall=36, gb_free=17.9, wall=13823
2023-07-04 07:44:55 | INFO | train_inner | epoch 015:   1074 / 1474 loss=4.258, trans_loss=5.409, nll_loss=2.725, w2v_ctc_loss=1.384, task_loss=0, contrastive_loss=0.612, total=4192.24, n_correct=2639.8, ppl=6.61, accuracy=62.969, wps=11253.8, ups=2.68, wpb=4192.2, bsz=162.6, num_updates=21700, lr=9.60031e-05, gnorm=1.033, clip=0, loss_scale=64, train_wall=37, gb_free=17.5, wall=13861
2023-07-04 07:45:31 | INFO | train_inner | epoch 015:   1174 / 1474 loss=4.201, trans_loss=5.379, nll_loss=2.688, w2v_ctc_loss=1.347, task_loss=0, contrastive_loss=0.222, total=4185, n_correct=2659.72, ppl=6.44, accuracy=63.554, wps=11450.3, ups=2.74, wpb=4185, bsz=164.6, num_updates=21800, lr=9.57826e-05, gnorm=1.02, clip=0, loss_scale=64, train_wall=36, gb_free=16.6, wall=13897
2023-07-04 07:46:08 | INFO | train_inner | epoch 015:   1274 / 1474 loss=4.227, trans_loss=5.401, nll_loss=2.715, w2v_ctc_loss=1.408, task_loss=0, contrastive_loss=0.133, total=4152.04, n_correct=2619.45, ppl=6.56, accuracy=63.088, wps=11263.5, ups=2.71, wpb=4152, bsz=151.8, num_updates=21900, lr=9.55637e-05, gnorm=1.022, clip=0, loss_scale=64, train_wall=36, gb_free=17, wall=13934
2023-07-04 07:46:45 | INFO | train_inner | epoch 015:   1374 / 1474 loss=4.219, trans_loss=5.4, nll_loss=2.712, w2v_ctc_loss=1.395, task_loss=0, contrastive_loss=0.107, total=4100.21, n_correct=2590.23, ppl=6.55, accuracy=63.173, wps=11020.4, ups=2.69, wpb=4100.2, bsz=146.8, num_updates=22000, lr=9.53463e-05, gnorm=1.032, clip=0, loss_scale=64, train_wall=37, gb_free=17.9, wall=13971
2023-07-04 07:46:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 07:47:11 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.359 | trans_loss 5.594 | nll_loss 2.873 | w2v_ctc_loss 1.364 | task_loss 0 | contrastive_loss 0.257 | total 4003.4 | n_correct 2462.5 | ppl 7.33 | accuracy 61.51 | uer 17.195 | wer 19.153 | raw_wer 19.153 | bleu 20.03 | wps 2051.9 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 20.03
2023-07-04 07:47:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-07-04 07:47:11 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_15_22000.pt
2023-07-04 07:47:13 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_15_22000.pt
2023-07-04 07:47:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 20.03) (writing took 9.348276490345597 seconds)
2023-07-04 07:47:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-04 07:47:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 07:48:24 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.347 | trans_loss 5.589 | nll_loss 2.869 | w2v_ctc_loss 1.339 | task_loss 0 | contrastive_loss 0.253 | total 4003.4 | n_correct 2460.1 | ppl 7.31 | accuracy 61.45 | uer 17.315 | wer 19.097 | raw_wer 19.097 | bleu 20.03 | wps 2104.4 | wpb 4003.4 | bsz 141.8 | num_updates 22099 | best_bleu 20.03
2023-07-04 07:48:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22099 updates
2023-07-04 07:48:24 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 07:48:28 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 07:48:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt (epoch 15 @ 22099 updates, score 20.03) (writing took 8.183177451137453 seconds)
2023-07-04 07:48:33 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-07-04 07:48:33 | INFO | train | epoch 015 | loss 4.22 | trans_loss 5.394 | nll_loss 2.703 | w2v_ctc_loss 1.381 | task_loss 0 | contrastive_loss 0.222 | total 4138.19 | n_correct 2617.63 | ppl 6.51 | accuracy 63.255 | wps 9802.2 | ups 2.37 | wpb 4138.2 | bsz 152.7 | num_updates 22099 | lr 9.51325e-05 | gnorm 1.029 | clip 0 | loss_scale 32 | train_wall 537 | gb_free 17.4 | wall 14079
2023-07-04 07:48:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 07:48:33 | INFO | fairseq.trainer | begin training epoch 16
2023-07-04 07:48:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 07:48:41 | INFO | train_inner | epoch 016:      1 / 1474 loss=4.221, trans_loss=5.398, nll_loss=2.711, w2v_ctc_loss=1.385, task_loss=0, contrastive_loss=0.163, total=4136.79, n_correct=2616.03, ppl=6.55, accuracy=63.238, wps=3567.1, ups=0.86, wpb=4136.8, bsz=155.2, num_updates=22100, lr=9.51303e-05, gnorm=1.024, clip=0, loss_scale=32, train_wall=37, gb_free=17.8, wall=14087
2023-07-04 07:49:18 | INFO | train_inner | epoch 016:    101 / 1474 loss=4.169, trans_loss=5.344, nll_loss=2.639, w2v_ctc_loss=1.339, task_loss=0, contrastive_loss=0.167, total=4118.73, n_correct=2636.19, ppl=6.23, accuracy=64.005, wps=11268.4, ups=2.74, wpb=4118.7, bsz=157, num_updates=22200, lr=9.49158e-05, gnorm=1.023, clip=0, loss_scale=32, train_wall=36, gb_free=16.6, wall=14124
2023-07-04 07:49:55 | INFO | train_inner | epoch 016:    201 / 1474 loss=4.165, trans_loss=5.346, nll_loss=2.641, w2v_ctc_loss=1.336, task_loss=0, contrastive_loss=0.12, total=4106.45, n_correct=2631.17, ppl=6.24, accuracy=64.074, wps=10994.9, ups=2.68, wpb=4106.4, bsz=148.7, num_updates=22300, lr=9.47027e-05, gnorm=1.02, clip=0, loss_scale=32, train_wall=37, gb_free=16.8, wall=14161
2023-07-04 07:50:32 | INFO | train_inner | epoch 016:    301 / 1474 loss=4.201, trans_loss=5.366, nll_loss=2.669, w2v_ctc_loss=1.372, task_loss=0, contrastive_loss=0.264, total=4169.65, n_correct=2658.83, ppl=6.36, accuracy=63.766, wps=11372.4, ups=2.73, wpb=4169.6, bsz=154.9, num_updates=22400, lr=9.44911e-05, gnorm=1.036, clip=0, loss_scale=32, train_wall=36, gb_free=11.4, wall=14198
2023-07-04 07:51:08 | INFO | train_inner | epoch 016:    401 / 1474 loss=4.198, trans_loss=5.369, nll_loss=2.67, w2v_ctc_loss=1.362, task_loss=0, contrastive_loss=0.291, total=4063.79, n_correct=2587.58, ppl=6.37, accuracy=63.674, wps=11132.6, ups=2.74, wpb=4063.8, bsz=143.2, num_updates=22500, lr=9.42809e-05, gnorm=1.042, clip=0, loss_scale=32, train_wall=36, gb_free=13.3, wall=14234
2023-07-04 07:51:45 | INFO | train_inner | epoch 016:    501 / 1474 loss=4.186, trans_loss=5.356, nll_loss=2.656, w2v_ctc_loss=1.364, task_loss=0, contrastive_loss=0.178, total=4179.53, n_correct=2675.04, ppl=6.3, accuracy=64.003, wps=11340.8, ups=2.71, wpb=4179.5, bsz=159.8, num_updates=22600, lr=9.40721e-05, gnorm=1.021, clip=0, loss_scale=32, train_wall=36, gb_free=18.1, wall=14271
2023-07-04 07:52:22 | INFO | train_inner | epoch 016:    601 / 1474 loss=4.182, trans_loss=5.363, nll_loss=2.665, w2v_ctc_loss=1.355, task_loss=0, contrastive_loss=0.108, total=4121.37, n_correct=2628.57, ppl=6.34, accuracy=63.779, wps=11219.1, ups=2.72, wpb=4121.4, bsz=148.7, num_updates=22700, lr=9.38647e-05, gnorm=1.031, clip=0, loss_scale=32, train_wall=36, gb_free=18.2, wall=14308
2023-07-04 07:52:58 | INFO | train_inner | epoch 016:    701 / 1474 loss=4.199, trans_loss=5.374, nll_loss=2.679, w2v_ctc_loss=1.387, task_loss=0, contrastive_loss=0.114, total=4099.17, n_correct=2603.32, ppl=6.4, accuracy=63.508, wps=11232.7, ups=2.74, wpb=4099.2, bsz=148.7, num_updates=22800, lr=9.36586e-05, gnorm=1.039, clip=0, loss_scale=32, train_wall=36, gb_free=17.2, wall=14344
2023-07-04 07:53:35 | INFO | train_inner | epoch 016:    801 / 1474 loss=4.194, trans_loss=5.369, nll_loss=2.673, w2v_ctc_loss=1.346, task_loss=0, contrastive_loss=0.236, total=4184.53, n_correct=2661.95, ppl=6.38, accuracy=63.614, wps=11448.7, ups=2.74, wpb=4184.5, bsz=156.5, num_updates=22900, lr=9.34539e-05, gnorm=1.011, clip=0, loss_scale=32, train_wall=36, gb_free=13.9, wall=14381
2023-07-04 07:54:11 | INFO | train_inner | epoch 016:    901 / 1474 loss=4.199, trans_loss=5.369, nll_loss=2.675, w2v_ctc_loss=1.37, task_loss=0, contrastive_loss=0.218, total=4151.84, n_correct=2643.93, ppl=6.38, accuracy=63.681, wps=11352.3, ups=2.73, wpb=4151.8, bsz=153.5, num_updates=23000, lr=9.32505e-05, gnorm=1.026, clip=0, loss_scale=32, train_wall=36, gb_free=17.2, wall=14418
2023-07-04 07:54:48 | INFO | train_inner | epoch 016:   1001 / 1474 loss=4.215, trans_loss=5.383, nll_loss=2.691, w2v_ctc_loss=1.39, task_loss=0, contrastive_loss=0.217, total=4112.79, n_correct=2606.84, ppl=6.46, accuracy=63.384, wps=11185.7, ups=2.72, wpb=4112.8, bsz=149.8, num_updates=23100, lr=9.30484e-05, gnorm=1.035, clip=0, loss_scale=32, train_wall=36, gb_free=15.4, wall=14454
2023-07-04 07:55:25 | INFO | train_inner | epoch 016:   1101 / 1474 loss=4.209, trans_loss=5.385, nll_loss=2.695, w2v_ctc_loss=1.378, task_loss=0, contrastive_loss=0.166, total=4111.6, n_correct=2605.39, ppl=6.47, accuracy=63.367, wps=11135.2, ups=2.71, wpb=4111.6, bsz=147.8, num_updates=23200, lr=9.28477e-05, gnorm=1.03, clip=0, loss_scale=32, train_wall=37, gb_free=15.1, wall=14491
2023-07-04 07:56:02 | INFO | train_inner | epoch 016:   1201 / 1474 loss=4.218, trans_loss=5.385, nll_loss=2.695, w2v_ctc_loss=1.364, task_loss=0, contrastive_loss=0.359, total=4157.51, n_correct=2634.59, ppl=6.47, accuracy=63.369, wps=11145.8, ups=2.68, wpb=4157.5, bsz=153.3, num_updates=23300, lr=9.26482e-05, gnorm=1.035, clip=0, loss_scale=32, train_wall=37, gb_free=15.4, wall=14529
2023-07-04 07:56:40 | INFO | train_inner | epoch 016:   1301 / 1474 loss=4.225, trans_loss=5.386, nll_loss=2.696, w2v_ctc_loss=1.395, task_loss=0, contrastive_loss=0.317, total=4151.03, n_correct=2630.92, ppl=6.48, accuracy=63.38, wps=11176.5, ups=2.69, wpb=4151, bsz=157.2, num_updates=23400, lr=9.245e-05, gnorm=1.037, clip=0, loss_scale=32, train_wall=37, gb_free=17, wall=14566
2023-07-04 07:57:17 | INFO | train_inner | epoch 016:   1401 / 1474 loss=4.21, trans_loss=5.381, nll_loss=2.691, w2v_ctc_loss=1.384, task_loss=0, contrastive_loss=0.174, total=4201.47, n_correct=2666.1, ppl=6.46, accuracy=63.456, wps=11331.3, ups=2.7, wpb=4201.5, bsz=160.4, num_updates=23500, lr=9.22531e-05, gnorm=1.023, clip=0, loss_scale=32, train_wall=37, gb_free=16.4, wall=14603
2023-07-04 07:57:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 07:58:10 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.336 | trans_loss 5.575 | nll_loss 2.858 | w2v_ctc_loss 1.332 | task_loss 0 | contrastive_loss 0.25 | total 4003.4 | n_correct 2470.2 | ppl 7.25 | accuracy 61.703 | uer 17.177 | wer 19.037 | raw_wer 19.037 | bleu 20 | wps 2054.2 | wpb 4003.4 | bsz 141.8 | num_updates 23573 | best_bleu 20.03
2023-07-04 07:58:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23573 updates
2023-07-04 07:58:10 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.0002.pt
2023-07-04 07:58:13 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.0002.pt
2023-07-04 07:58:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.0002.pt (epoch 16 @ 23573 updates, score 20.0) (writing took 5.386410078033805 seconds)
2023-07-04 07:58:16 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-07-04 07:58:16 | INFO | train | epoch 016 | loss 4.199 | trans_loss 5.37 | nll_loss 2.675 | w2v_ctc_loss 1.367 | task_loss 0 | contrastive_loss 0.227 | total 4138.65 | n_correct 2633.86 | ppl 6.38 | accuracy 63.641 | wps 10462.4 | ups 2.53 | wpb 4138.6 | bsz 152.8 | num_updates 23573 | lr 9.21102e-05 | gnorm 1.029 | clip 0 | loss_scale 32 | train_wall 537 | gb_free 15.9 | wall 14662
2023-07-04 07:58:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 07:58:16 | INFO | fairseq.trainer | begin training epoch 17
2023-07-04 07:58:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 07:58:34 | INFO | train_inner | epoch 017:     27 / 1474 loss=4.201, trans_loss=5.36, nll_loss=2.662, w2v_ctc_loss=1.359, task_loss=0, contrastive_loss=0.449, total=4145.04, n_correct=2645.09, ppl=6.33, accuracy=63.813, wps=5349.2, ups=1.29, wpb=4145, bsz=151.2, num_updates=23600, lr=9.20575e-05, gnorm=1.027, clip=0, loss_scale=32, train_wall=37, gb_free=16, wall=14680
2023-07-04 07:59:11 | INFO | train_inner | epoch 017:    127 / 1474 loss=4.163, trans_loss=5.333, nll_loss=2.625, w2v_ctc_loss=1.361, task_loss=0, contrastive_loss=0.119, total=4117.27, n_correct=2645.66, ppl=6.17, accuracy=64.258, wps=11101.1, ups=2.7, wpb=4117.3, bsz=148.1, num_updates=23700, lr=9.1863e-05, gnorm=1.033, clip=0, loss_scale=32, train_wall=37, gb_free=18.1, wall=14717
2023-07-04 07:59:48 | INFO | train_inner | epoch 017:    227 / 1474 loss=4.188, trans_loss=5.341, nll_loss=2.638, w2v_ctc_loss=1.34, task_loss=0, contrastive_loss=0.449, total=4159.6, n_correct=2668.33, ppl=6.22, accuracy=64.149, wps=11238.9, ups=2.7, wpb=4159.6, bsz=158.8, num_updates=23800, lr=9.16698e-05, gnorm=1.033, clip=0, loss_scale=32, train_wall=37, gb_free=17.4, wall=14754
2023-07-04 08:00:25 | INFO | train_inner | epoch 017:    327 / 1474 loss=4.185, trans_loss=5.342, nll_loss=2.638, w2v_ctc_loss=1.347, task_loss=0, contrastive_loss=0.458, total=4156.91, n_correct=2666.31, ppl=6.23, accuracy=64.142, wps=11329.7, ups=2.73, wpb=4156.9, bsz=152.9, num_updates=23900, lr=9.14779e-05, gnorm=1.034, clip=0, loss_scale=32, train_wall=36, gb_free=17.9, wall=14791
2023-07-04 08:01:02 | INFO | train_inner | epoch 017:    427 / 1474 loss=4.163, trans_loss=5.336, nll_loss=2.63, w2v_ctc_loss=1.351, task_loss=0, contrastive_loss=0.118, total=4146.43, n_correct=2669.36, ppl=6.19, accuracy=64.377, wps=11102.6, ups=2.68, wpb=4146.4, bsz=154, num_updates=24000, lr=9.12871e-05, gnorm=1.023, clip=0, loss_scale=32, train_wall=37, gb_free=16.9, wall=14828
2023-07-04 08:01:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 08:01:28 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.368 | trans_loss 5.586 | nll_loss 2.86 | w2v_ctc_loss 1.412 | task_loss 0 | contrastive_loss 0.254 | total 4003.4 | n_correct 2467.8 | ppl 7.26 | accuracy 61.643 | uer 17.378 | wer 19.097 | raw_wer 19.097 | bleu 19.87 | wps 2076.6 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 20.03
2023-07-04 08:01:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-07-04 08:01:28 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_17_24000.pt
2023-07-04 08:01:30 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_17_24000.pt
2023-07-04 08:01:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.87) (writing took 6.5073717618361115 seconds)
2023-07-04 08:02:12 | INFO | train_inner | epoch 017:    527 / 1474 loss=4.18, trans_loss=5.347, nll_loss=2.645, w2v_ctc_loss=1.363, task_loss=0, contrastive_loss=0.21, total=4182.1, n_correct=2673.91, ppl=6.25, accuracy=63.937, wps=5962.8, ups=1.43, wpb=4182.1, bsz=153.9, num_updates=24100, lr=9.10975e-05, gnorm=1.025, clip=0, loss_scale=32, train_wall=37, gb_free=17.2, wall=14899
2023-07-04 08:02:49 | INFO | train_inner | epoch 017:    627 / 1474 loss=4.167, trans_loss=5.344, nll_loss=2.641, w2v_ctc_loss=1.351, task_loss=0, contrastive_loss=0.109, total=4167.27, n_correct=2669.62, ppl=6.24, accuracy=64.062, wps=11340, ups=2.72, wpb=4167.3, bsz=151.1, num_updates=24200, lr=9.09091e-05, gnorm=1.022, clip=0, loss_scale=64, train_wall=36, gb_free=11.6, wall=14935
2023-07-04 08:03:26 | INFO | train_inner | epoch 017:    727 / 1474 loss=4.194, trans_loss=5.358, nll_loss=2.66, w2v_ctc_loss=1.381, task_loss=0, contrastive_loss=0.2, total=4166.12, n_correct=2659.64, ppl=6.32, accuracy=63.84, wps=11381.6, ups=2.73, wpb=4166.1, bsz=154.1, num_updates=24300, lr=9.07218e-05, gnorm=1.028, clip=0, loss_scale=64, train_wall=36, gb_free=16.7, wall=14972
2023-07-04 08:04:02 | INFO | train_inner | epoch 017:    827 / 1474 loss=4.174, trans_loss=5.348, nll_loss=2.646, w2v_ctc_loss=1.36, task_loss=0, contrastive_loss=0.132, total=4091.64, n_correct=2615.1, ppl=6.26, accuracy=63.913, wps=11253.5, ups=2.75, wpb=4091.6, bsz=147.7, num_updates=24400, lr=9.05357e-05, gnorm=1.027, clip=0, loss_scale=64, train_wall=36, gb_free=17.7, wall=15008
2023-07-04 08:04:38 | INFO | train_inner | epoch 017:    927 / 1474 loss=4.173, trans_loss=5.35, nll_loss=2.65, w2v_ctc_loss=1.349, task_loss=0, contrastive_loss=0.13, total=4106.83, n_correct=2624.67, ppl=6.28, accuracy=63.91, wps=11364.2, ups=2.77, wpb=4106.8, bsz=152.3, num_updates=24500, lr=9.03508e-05, gnorm=1.035, clip=0, loss_scale=64, train_wall=36, gb_free=16.2, wall=15044
2023-07-04 08:05:15 | INFO | train_inner | epoch 017:   1027 / 1474 loss=4.177, trans_loss=5.349, nll_loss=2.649, w2v_ctc_loss=1.364, task_loss=0, contrastive_loss=0.136, total=4115.49, n_correct=2634.59, ppl=6.27, accuracy=64.016, wps=11271, ups=2.74, wpb=4115.5, bsz=152.9, num_updates=24600, lr=9.0167e-05, gnorm=1.029, clip=0, loss_scale=64, train_wall=36, gb_free=17, wall=15081
2023-07-04 08:05:52 | INFO | train_inner | epoch 017:   1127 / 1474 loss=4.167, trans_loss=5.349, nll_loss=2.649, w2v_ctc_loss=1.34, task_loss=0, contrastive_loss=0.112, total=4078.39, n_correct=2607.76, ppl=6.27, accuracy=63.941, wps=11032.5, ups=2.71, wpb=4078.4, bsz=146.9, num_updates=24700, lr=8.99843e-05, gnorm=1.034, clip=0, loss_scale=64, train_wall=37, gb_free=16, wall=15118
2023-07-04 08:06:29 | INFO | train_inner | epoch 017:   1227 / 1474 loss=4.224, trans_loss=5.373, nll_loss=2.681, w2v_ctc_loss=1.356, task_loss=0, contrastive_loss=0.6, total=4173.49, n_correct=2655.3, ppl=6.41, accuracy=63.623, wps=11163.6, ups=2.67, wpb=4173.5, bsz=161.9, num_updates=24800, lr=8.98027e-05, gnorm=1.029, clip=0, loss_scale=64, train_wall=37, gb_free=16.5, wall=15155
2023-07-04 08:07:06 | INFO | train_inner | epoch 017:   1327 / 1474 loss=4.184, trans_loss=5.354, nll_loss=2.656, w2v_ctc_loss=1.341, task_loss=0, contrastive_loss=0.274, total=4156.28, n_correct=2651.73, ppl=6.3, accuracy=63.801, wps=11184.3, ups=2.69, wpb=4156.3, bsz=154, num_updates=24900, lr=8.96221e-05, gnorm=1.025, clip=0, loss_scale=64, train_wall=37, gb_free=18.1, wall=15193
2023-07-04 08:07:43 | INFO | train_inner | epoch 017:   1427 / 1474 loss=4.179, trans_loss=5.357, nll_loss=2.66, w2v_ctc_loss=1.355, task_loss=0, contrastive_loss=0.123, total=4112.95, n_correct=2623.75, ppl=6.32, accuracy=63.792, wps=11117, ups=2.7, wpb=4112.9, bsz=151.6, num_updates=25000, lr=8.94427e-05, gnorm=1.031, clip=0, loss_scale=64, train_wall=37, gb_free=17.2, wall=15230
tensor(0.0295, device='cuda:0')
tensor(0.0009, device='cuda:0')
2023-07-04 08:08:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0295, device='cuda:4')
tensor(0.0009, device='cuda:4')
tensor(0.0295, device='cuda:5')
tensor(0.0009, device='cuda:5')
tensor(0.0295, device='cuda:6')
tensor(0.0009, device='cuda:6')
tensor(0.0295, device='cuda:1')
tensor(0.0009, device='cuda:1')
tensor(0.0295, device='cuda:2')
tensor(0.0009, device='cuda:2')
tensor(0.0295, device='cuda:7')
tensor(0.0009, device='cuda:7')
tensor(0.0295, device='cuda:3')
tensor(0.0009, device='cuda:3')
2023-07-04 08:08:25 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.335 | trans_loss 5.568 | nll_loss 2.842 | w2v_ctc_loss 1.347 | task_loss 0 | contrastive_loss 0.251 | total 4003.4 | n_correct 2471.2 | ppl 7.17 | accuracy 61.728 | uer 16.792 | wer 18.605 | raw_wer 18.605 | bleu 20.21 | wps 2252.7 | wpb 4003.4 | bsz 141.8 | num_updates 25047 | best_bleu 20.21
2023-07-04 08:08:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25047 updates
2023-07-04 08:08:25 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 08:08:29 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 08:08:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt (epoch 17 @ 25047 updates, score 20.21) (writing took 8.87206152221188 seconds)
2023-07-04 08:08:34 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-07-04 08:08:34 | INFO | train | epoch 017 | loss 4.179 | trans_loss 5.348 | nll_loss 2.647 | w2v_ctc_loss 1.355 | task_loss 0 | contrastive_loss 0.224 | total 4138.65 | n_correct 2648.41 | ppl 6.26 | accuracy 63.992 | wps 9869.4 | ups 2.38 | wpb 4138.6 | bsz 152.8 | num_updates 25047 | lr 8.93588e-05 | gnorm 1.029 | clip 0 | loss_scale 64 | train_wall 538 | gb_free 16.8 | wall 15280
2023-07-04 08:08:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 08:08:34 | INFO | fairseq.trainer | begin training epoch 18
2023-07-04 08:08:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 08:09:02 | INFO | train_inner | epoch 018:     53 / 1474 loss=4.175, trans_loss=5.342, nll_loss=2.639, w2v_ctc_loss=1.371, task_loss=0, contrastive_loss=0.14, total=4139.04, n_correct=2653.42, ppl=6.23, accuracy=64.107, wps=5249.4, ups=1.27, wpb=4139, bsz=151.7, num_updates=25100, lr=8.92644e-05, gnorm=1.04, clip=0, loss_scale=64, train_wall=37, gb_free=17.5, wall=15308
2023-07-04 08:09:39 | INFO | train_inner | epoch 018:    153 / 1474 loss=4.156, trans_loss=5.313, nll_loss=2.6, w2v_ctc_loss=1.317, task_loss=0, contrastive_loss=0.387, total=4154.85, n_correct=2680.3, ppl=6.06, accuracy=64.51, wps=11326.1, ups=2.73, wpb=4154.9, bsz=156.4, num_updates=25200, lr=8.90871e-05, gnorm=1.027, clip=0, loss_scale=64, train_wall=36, gb_free=17.1, wall=15345
2023-07-04 08:10:16 | INFO | train_inner | epoch 018:    253 / 1474 loss=4.139, trans_loss=5.309, nll_loss=2.597, w2v_ctc_loss=1.331, task_loss=0, contrastive_loss=0.121, total=4162.72, n_correct=2695.11, ppl=6.05, accuracy=64.744, wps=11257.4, ups=2.7, wpb=4162.7, bsz=156.5, num_updates=25300, lr=8.89108e-05, gnorm=1.018, clip=0, loss_scale=64, train_wall=37, gb_free=16.7, wall=15382
2023-07-04 08:10:53 | INFO | train_inner | epoch 018:    353 / 1474 loss=4.138, trans_loss=5.313, nll_loss=2.6, w2v_ctc_loss=1.319, task_loss=0, contrastive_loss=0.145, total=4161.22, n_correct=2686.09, ppl=6.06, accuracy=64.551, wps=11316.7, ups=2.72, wpb=4161.2, bsz=150.7, num_updates=25400, lr=8.87357e-05, gnorm=1.026, clip=0, loss_scale=64, train_wall=36, gb_free=14.9, wall=15419
2023-07-04 08:11:30 | INFO | train_inner | epoch 018:    453 / 1474 loss=4.167, trans_loss=5.331, nll_loss=2.625, w2v_ctc_loss=1.336, task_loss=0, contrastive_loss=0.331, total=4092.36, n_correct=2631.32, ppl=6.17, accuracy=64.298, wps=10897.7, ups=2.66, wpb=4092.4, bsz=147.7, num_updates=25500, lr=8.85615e-05, gnorm=1.036, clip=0, loss_scale=64, train_wall=37, gb_free=17.1, wall=15456
2023-07-04 08:12:07 | INFO | train_inner | epoch 018:    553 / 1474 loss=4.133, trans_loss=5.304, nll_loss=2.591, w2v_ctc_loss=1.317, task_loss=0, contrastive_loss=0.149, total=4206.45, n_correct=2723.24, ppl=6.03, accuracy=64.74, wps=11451.6, ups=2.72, wpb=4206.4, bsz=164.5, num_updates=25600, lr=8.83883e-05, gnorm=1.016, clip=0, loss_scale=64, train_wall=36, gb_free=18.1, wall=15493
2023-07-04 08:12:43 | INFO | train_inner | epoch 018:    653 / 1474 loss=4.179, trans_loss=5.343, nll_loss=2.641, w2v_ctc_loss=1.356, task_loss=0, contrastive_loss=0.287, total=4097.96, n_correct=2627.38, ppl=6.24, accuracy=64.114, wps=11245, ups=2.74, wpb=4098, bsz=149.3, num_updates=25700, lr=8.82162e-05, gnorm=1.036, clip=0, loss_scale=64, train_wall=36, gb_free=12.9, wall=15530
2023-07-04 08:13:20 | INFO | train_inner | epoch 018:    753 / 1474 loss=4.191, trans_loss=5.341, nll_loss=2.639, w2v_ctc_loss=1.36, task_loss=0, contrastive_loss=0.463, total=4208.5, n_correct=2697.98, ppl=6.23, accuracy=64.108, wps=11455.2, ups=2.72, wpb=4208.5, bsz=161.3, num_updates=25800, lr=8.80451e-05, gnorm=1.026, clip=0, loss_scale=64, train_wall=36, gb_free=16.6, wall=15566
2023-07-04 08:13:57 | INFO | train_inner | epoch 018:    853 / 1474 loss=4.153, trans_loss=5.329, nll_loss=2.622, w2v_ctc_loss=1.339, task_loss=0, contrastive_loss=0.105, total=4166.07, n_correct=2676.8, ppl=6.16, accuracy=64.252, wps=11350.7, ups=2.72, wpb=4166.1, bsz=151.2, num_updates=25900, lr=8.7875e-05, gnorm=1.027, clip=0, loss_scale=64, train_wall=36, gb_free=16.7, wall=15603
2023-07-04 08:14:33 | INFO | train_inner | epoch 018:    953 / 1474 loss=4.144, trans_loss=5.319, nll_loss=2.611, w2v_ctc_loss=1.319, task_loss=0, contrastive_loss=0.145, total=4141.27, n_correct=2667.49, ppl=6.11, accuracy=64.412, wps=11404.9, ups=2.75, wpb=4141.3, bsz=158, num_updates=26000, lr=8.77058e-05, gnorm=1.016, clip=0, loss_scale=64, train_wall=36, gb_free=16.5, wall=15639
2023-07-04 08:14:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 08:14:59 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.389 | trans_loss 5.588 | nll_loss 2.867 | w2v_ctc_loss 1.475 | task_loss 0 | contrastive_loss 0.26 | total 4003.4 | n_correct 2463.8 | ppl 7.29 | accuracy 61.543 | uer 17.758 | wer 19.72 | raw_wer 19.72 | bleu 19.71 | wps 2118 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 20.21
2023-07-04 08:14:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-07-04 08:14:59 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_18_26000.pt
2023-07-04 08:15:01 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_18_26000.pt
2023-07-04 08:15:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 19.71) (writing took 6.236509072128683 seconds)
2023-07-04 08:15:43 | INFO | train_inner | epoch 018:   1053 / 1474 loss=4.15, trans_loss=5.328, nll_loss=2.622, w2v_ctc_loss=1.328, task_loss=0, contrastive_loss=0.127, total=4134.55, n_correct=2660.65, ppl=6.16, accuracy=64.352, wps=5900.1, ups=1.43, wpb=4134.6, bsz=150.4, num_updates=26100, lr=8.75376e-05, gnorm=1.027, clip=0, loss_scale=64, train_wall=37, gb_free=16.9, wall=15709
2023-07-04 08:16:20 | INFO | train_inner | epoch 018:   1153 / 1474 loss=4.167, trans_loss=5.321, nll_loss=2.615, w2v_ctc_loss=1.342, task_loss=0, contrastive_loss=0.344, total=4157.63, n_correct=2678.03, ppl=6.12, accuracy=64.412, wps=11285.9, ups=2.71, wpb=4157.6, bsz=157, num_updates=26200, lr=8.73704e-05, gnorm=1.021, clip=0, loss_scale=128, train_wall=36, gb_free=17.4, wall=15746
2023-07-04 08:16:57 | INFO | train_inner | epoch 018:   1253 / 1474 loss=4.156, trans_loss=5.336, nll_loss=2.633, w2v_ctc_loss=1.333, task_loss=0, contrastive_loss=0.115, total=4085.66, n_correct=2619.2, ppl=6.2, accuracy=64.107, wps=11097.1, ups=2.72, wpb=4085.7, bsz=143.3, num_updates=26300, lr=8.72041e-05, gnorm=1.033, clip=0, loss_scale=128, train_wall=36, gb_free=17.8, wall=15783
2023-07-04 08:17:34 | INFO | train_inner | epoch 018:   1353 / 1474 loss=4.186, trans_loss=5.352, nll_loss=2.654, w2v_ctc_loss=1.378, task_loss=0, contrastive_loss=0.166, total=4065.6, n_correct=2598.75, ppl=6.29, accuracy=63.92, wps=11076.6, ups=2.72, wpb=4065.6, bsz=145.6, num_updates=26400, lr=8.70388e-05, gnorm=1.052, clip=0, loss_scale=128, train_wall=36, gb_free=13.7, wall=15820
2023-07-04 08:18:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-04 08:18:11 | INFO | train_inner | epoch 018:   1454 / 1474 loss=4.167, trans_loss=5.339, nll_loss=2.637, w2v_ctc_loss=1.356, task_loss=0, contrastive_loss=0.126, total=4110.91, n_correct=2639.14, ppl=6.22, accuracy=64.198, wps=11010.2, ups=2.68, wpb=4110.9, bsz=148.1, num_updates=26500, lr=8.68744e-05, gnorm=1.027, clip=0, loss_scale=64, train_wall=37, gb_free=16.8, wall=15857
2023-07-04 08:18:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 08:18:43 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.346 | trans_loss 5.565 | nll_loss 2.841 | w2v_ctc_loss 1.386 | task_loss 0 | contrastive_loss 0.26 | total 4003.4 | n_correct 2473.4 | ppl 7.16 | accuracy 61.782 | uer 16.956 | wer 18.81 | raw_wer 18.81 | bleu 19.87 | wps 2277.5 | wpb 4003.4 | bsz 141.8 | num_updates 26520 | best_bleu 20.21
2023-07-04 08:18:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26520 updates
2023-07-04 08:18:43 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_19.8707.pt
2023-07-04 08:18:45 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_19.8707.pt
2023-07-04 08:18:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_19.8707.pt (epoch 18 @ 26520 updates, score 19.87) (writing took 5.54550238372758 seconds)
2023-07-04 08:18:48 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-07-04 08:18:48 | INFO | train | epoch 018 | loss 4.16 | trans_loss 5.327 | nll_loss 2.621 | w2v_ctc_loss 1.338 | task_loss 0 | contrastive_loss 0.221 | total 4138.22 | n_correct 2662.17 | ppl 6.15 | accuracy 64.331 | wps 9919.9 | ups 2.4 | wpb 4138.2 | bsz 152.8 | num_updates 26520 | lr 8.68417e-05 | gnorm 1.028 | clip 0 | loss_scale 64 | train_wall 537 | gb_free 16.3 | wall 15895
2023-07-04 08:18:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 08:18:49 | INFO | fairseq.trainer | begin training epoch 19
2023-07-04 08:18:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 08:19:26 | INFO | train_inner | epoch 019:     80 / 1474 loss=4.136, trans_loss=5.301, nll_loss=2.586, w2v_ctc_loss=1.32, task_loss=0, contrastive_loss=0.236, total=4102.06, n_correct=2652.13, ppl=6, accuracy=64.654, wps=5468.5, ups=1.33, wpb=4102.1, bsz=148.5, num_updates=26600, lr=8.6711e-05, gnorm=1.035, clip=0, loss_scale=64, train_wall=36, gb_free=17.8, wall=15932
2023-07-04 08:20:03 | INFO | train_inner | epoch 019:    180 / 1474 loss=4.134, trans_loss=5.29, nll_loss=2.572, w2v_ctc_loss=1.333, task_loss=0, contrastive_loss=0.218, total=4227.7, n_correct=2745.93, ppl=5.95, accuracy=64.951, wps=11415.9, ups=2.7, wpb=4227.7, bsz=162.4, num_updates=26700, lr=8.65485e-05, gnorm=1.016, clip=0, loss_scale=64, train_wall=37, gb_free=17.4, wall=15969
2023-07-04 08:20:40 | INFO | train_inner | epoch 019:    280 / 1474 loss=4.116, trans_loss=5.284, nll_loss=2.564, w2v_ctc_loss=1.322, task_loss=0, contrastive_loss=0.109, total=4187.34, n_correct=2722.74, ppl=5.91, accuracy=65.023, wps=11360, ups=2.71, wpb=4187.3, bsz=153.2, num_updates=26800, lr=8.63868e-05, gnorm=1.024, clip=0, loss_scale=64, train_wall=36, gb_free=16.3, wall=16006
2023-07-04 08:21:17 | INFO | train_inner | epoch 019:    380 / 1474 loss=4.137, trans_loss=5.297, nll_loss=2.583, w2v_ctc_loss=1.304, task_loss=0, contrastive_loss=0.328, total=4170.52, n_correct=2699.9, ppl=5.99, accuracy=64.738, wps=11288, ups=2.71, wpb=4170.5, bsz=155.5, num_updates=26900, lr=8.62261e-05, gnorm=1.025, clip=0, loss_scale=64, train_wall=37, gb_free=16.7, wall=16043
2023-07-04 08:21:53 | INFO | train_inner | epoch 019:    480 / 1474 loss=4.136, trans_loss=5.306, nll_loss=2.593, w2v_ctc_loss=1.33, task_loss=0, contrastive_loss=0.137, total=4113.89, n_correct=2662.59, ppl=6.03, accuracy=64.722, wps=11261.8, ups=2.74, wpb=4113.9, bsz=150.8, num_updates=27000, lr=8.60663e-05, gnorm=1.041, clip=0, loss_scale=64, train_wall=36, gb_free=17.5, wall=16080
2023-07-04 08:22:30 | INFO | train_inner | epoch 019:    580 / 1474 loss=4.134, trans_loss=5.3, nll_loss=2.586, w2v_ctc_loss=1.312, task_loss=0, contrastive_loss=0.265, total=4128.58, n_correct=2674.53, ppl=6, accuracy=64.781, wps=11302.2, ups=2.74, wpb=4128.6, bsz=153.1, num_updates=27100, lr=8.59074e-05, gnorm=1.029, clip=0, loss_scale=64, train_wall=36, gb_free=17, wall=16116
2023-07-04 08:23:07 | INFO | train_inner | epoch 019:    680 / 1474 loss=4.118, trans_loss=5.297, nll_loss=2.583, w2v_ctc_loss=1.291, task_loss=0, contrastive_loss=0.121, total=4201.56, n_correct=2723.78, ppl=5.99, accuracy=64.828, wps=11468.1, ups=2.73, wpb=4201.6, bsz=160.7, num_updates=27200, lr=8.57493e-05, gnorm=1.016, clip=0, loss_scale=64, train_wall=36, gb_free=18.1, wall=16153
2023-07-04 08:23:44 | INFO | train_inner | epoch 019:    780 / 1474 loss=4.13, trans_loss=5.3, nll_loss=2.586, w2v_ctc_loss=1.324, task_loss=0, contrastive_loss=0.131, total=4124.03, n_correct=2669.73, ppl=6, accuracy=64.736, wps=11177.1, ups=2.71, wpb=4124, bsz=149.5, num_updates=27300, lr=8.55921e-05, gnorm=1.022, clip=0, loss_scale=64, train_wall=37, gb_free=17.8, wall=16190
2023-07-04 08:24:20 | INFO | train_inner | epoch 019:    880 / 1474 loss=4.142, trans_loss=5.314, nll_loss=2.604, w2v_ctc_loss=1.332, task_loss=0, contrastive_loss=0.129, total=4177.8, n_correct=2695.46, ppl=6.08, accuracy=64.519, wps=11364.2, ups=2.72, wpb=4177.8, bsz=154.8, num_updates=27400, lr=8.54358e-05, gnorm=1.027, clip=0, loss_scale=64, train_wall=36, gb_free=15.3, wall=16226
2023-07-04 08:24:58 | INFO | train_inner | epoch 019:    980 / 1474 loss=4.182, trans_loss=5.331, nll_loss=2.627, w2v_ctc_loss=1.329, task_loss=0, contrastive_loss=0.59, total=4084.26, n_correct=2624.62, ppl=6.18, accuracy=64.262, wps=10815.7, ups=2.65, wpb=4084.3, bsz=152.9, num_updates=27500, lr=8.52803e-05, gnorm=1.052, clip=0, loss_scale=64, train_wall=37, gb_free=16.6, wall=16264
2023-07-04 08:25:35 | INFO | train_inner | epoch 019:   1080 / 1474 loss=4.157, trans_loss=5.328, nll_loss=2.623, w2v_ctc_loss=1.33, task_loss=0, contrastive_loss=0.203, total=4042.73, n_correct=2598.2, ppl=6.16, accuracy=64.268, wps=11060.2, ups=2.74, wpb=4042.7, bsz=147, num_updates=27600, lr=8.51257e-05, gnorm=1.041, clip=0, loss_scale=64, train_wall=36, gb_free=17.6, wall=16301
2023-07-04 08:26:12 | INFO | train_inner | epoch 019:   1180 / 1474 loss=4.168, trans_loss=5.328, nll_loss=2.624, w2v_ctc_loss=1.324, task_loss=0, contrastive_loss=0.368, total=4140.95, n_correct=2659.76, ppl=6.16, accuracy=64.231, wps=11000, ups=2.66, wpb=4140.9, bsz=154, num_updates=27700, lr=8.49719e-05, gnorm=1.027, clip=0, loss_scale=64, train_wall=37, gb_free=13.3, wall=16338
2023-07-04 08:26:49 | INFO | train_inner | epoch 019:   1280 / 1474 loss=4.149, trans_loss=5.325, nll_loss=2.62, w2v_ctc_loss=1.32, task_loss=0, contrastive_loss=0.163, total=4135.79, n_correct=2661.6, ppl=6.15, accuracy=64.355, wps=11169.3, ups=2.7, wpb=4135.8, bsz=149.8, num_updates=27800, lr=8.48189e-05, gnorm=1.03, clip=0, loss_scale=64, train_wall=37, gb_free=18.1, wall=16375
2023-07-04 08:27:26 | INFO | train_inner | epoch 019:   1380 / 1474 loss=4.146, trans_loss=5.317, nll_loss=2.61, w2v_ctc_loss=1.336, task_loss=0, contrastive_loss=0.134, total=4138.67, n_correct=2667.84, ppl=6.1, accuracy=64.461, wps=11335.5, ups=2.74, wpb=4138.7, bsz=150.8, num_updates=27900, lr=8.46668e-05, gnorm=1.039, clip=0, loss_scale=64, train_wall=36, gb_free=16.9, wall=16412
2023-07-04 08:28:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 08:28:25 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.361 | trans_loss 5.575 | nll_loss 2.854 | w2v_ctc_loss 1.416 | task_loss 0 | contrastive_loss 0.253 | total 4003.4 | n_correct 2465.5 | ppl 7.23 | accuracy 61.585 | uer 17.264 | wer 19.015 | raw_wer 19.015 | bleu 20.32 | wps 2158.5 | wpb 4003.4 | bsz 141.8 | num_updates 27994 | best_bleu 20.32
2023-07-04 08:28:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27994 updates
2023-07-04 08:28:25 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 08:28:29 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 08:28:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt (epoch 19 @ 27994 updates, score 20.32) (writing took 8.572565623093396 seconds)
2023-07-04 08:28:34 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-07-04 08:28:34 | INFO | train | epoch 019 | loss 4.142 | trans_loss 5.308 | nll_loss 2.597 | w2v_ctc_loss 1.323 | task_loss 0 | contrastive_loss 0.222 | total 4138.65 | n_correct 2674.21 | ppl 6.05 | accuracy 64.615 | wps 10419 | ups 2.52 | wpb 4138.6 | bsz 152.8 | num_updates 27994 | lr 8.45245e-05 | gnorm 1.031 | clip 0 | loss_scale 64 | train_wall 538 | gb_free 17.7 | wall 16480
2023-07-04 08:28:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 08:28:34 | INFO | fairseq.trainer | begin training epoch 20
2023-07-04 08:28:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 08:28:45 | INFO | train_inner | epoch 020:      6 / 1474 loss=4.148, trans_loss=5.31, nll_loss=2.601, w2v_ctc_loss=1.324, task_loss=0, contrastive_loss=0.3, total=4117.61, n_correct=2659.18, ppl=6.07, accuracy=64.581, wps=5230.3, ups=1.27, wpb=4117.6, bsz=151.5, num_updates=28000, lr=8.45154e-05, gnorm=1.038, clip=0, loss_scale=64, train_wall=36, gb_free=16.8, wall=16491
2023-07-04 08:28:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 08:29:10 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.357 | trans_loss 5.574 | nll_loss 2.849 | w2v_ctc_loss 1.406 | task_loss 0 | contrastive_loss 0.252 | total 4003.4 | n_correct 2471.1 | ppl 7.21 | accuracy 61.725 | uer 17.137 | wer 19.007 | raw_wer 19.007 | bleu 20.52 | wps 2151 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.52
2023-07-04 08:29:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-07-04 08:29:10 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_20_28000.pt
2023-07-04 08:29:12 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_20_28000.pt
2023-07-04 08:29:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 20.52) (writing took 9.46090151462704 seconds)
2023-07-04 08:29:56 | INFO | train_inner | epoch 020:    106 / 1474 loss=4.1, trans_loss=5.268, nll_loss=2.544, w2v_ctc_loss=1.294, task_loss=0, contrastive_loss=0.146, total=4192.82, n_correct=2740.36, ppl=5.83, accuracy=65.358, wps=5841.8, ups=1.39, wpb=4192.8, bsz=156.4, num_updates=28100, lr=8.43649e-05, gnorm=1.017, clip=0, loss_scale=64, train_wall=36, gb_free=16.7, wall=16562
2023-07-04 08:30:33 | INFO | train_inner | epoch 020:    206 / 1474 loss=4.107, trans_loss=5.275, nll_loss=2.553, w2v_ctc_loss=1.287, task_loss=0, contrastive_loss=0.252, total=4155.9, n_correct=2707.74, ppl=5.87, accuracy=65.154, wps=11201.6, ups=2.7, wpb=4155.9, bsz=151.1, num_updates=28200, lr=8.42152e-05, gnorm=1.005, clip=0, loss_scale=64, train_wall=37, gb_free=12.4, wall=16600
2023-07-04 08:31:10 | INFO | train_inner | epoch 020:    306 / 1474 loss=4.101, trans_loss=5.268, nll_loss=2.545, w2v_ctc_loss=1.299, task_loss=0, contrastive_loss=0.129, total=4192.69, n_correct=2737.68, ppl=5.83, accuracy=65.297, wps=11356.4, ups=2.71, wpb=4192.7, bsz=163.8, num_updates=28300, lr=8.40663e-05, gnorm=1.017, clip=0, loss_scale=64, train_wall=37, gb_free=17.3, wall=16636
2023-07-04 08:31:47 | INFO | train_inner | epoch 020:    406 / 1474 loss=4.101, trans_loss=5.274, nll_loss=2.552, w2v_ctc_loss=1.291, task_loss=0, contrastive_loss=0.123, total=4116.96, n_correct=2685.44, ppl=5.87, accuracy=65.229, wps=11248.2, ups=2.73, wpb=4117, bsz=148.4, num_updates=28400, lr=8.39181e-05, gnorm=1.016, clip=0, loss_scale=64, train_wall=36, gb_free=13.2, wall=16673
2023-07-04 08:32:24 | INFO | train_inner | epoch 020:    506 / 1474 loss=4.129, trans_loss=5.296, nll_loss=2.58, w2v_ctc_loss=1.296, task_loss=0, contrastive_loss=0.302, total=4100.73, n_correct=2657.89, ppl=5.98, accuracy=64.815, wps=11110.2, ups=2.71, wpb=4100.7, bsz=149.2, num_updates=28500, lr=8.37708e-05, gnorm=1.037, clip=0, loss_scale=64, train_wall=37, gb_free=16.7, wall=16710
2023-07-04 08:32:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-04 08:33:01 | INFO | train_inner | epoch 020:    607 / 1474 loss=4.13, trans_loss=5.296, nll_loss=2.581, w2v_ctc_loss=1.312, task_loss=0, contrastive_loss=0.224, total=4076.03, n_correct=2640.01, ppl=5.98, accuracy=64.769, wps=11085.3, ups=2.72, wpb=4076, bsz=145.2, num_updates=28600, lr=8.36242e-05, gnorm=1.037, clip=0, loss_scale=64, train_wall=36, gb_free=12.6, wall=16747
2023-07-04 08:33:37 | INFO | train_inner | epoch 020:    707 / 1474 loss=4.124, trans_loss=5.295, nll_loss=2.579, w2v_ctc_loss=1.322, task_loss=0, contrastive_loss=0.112, total=4140.23, n_correct=2683.62, ppl=5.98, accuracy=64.818, wps=11324.6, ups=2.74, wpb=4140.2, bsz=150.3, num_updates=28700, lr=8.34784e-05, gnorm=1.028, clip=0, loss_scale=64, train_wall=36, gb_free=16.7, wall=16783
2023-07-04 08:34:14 | INFO | train_inner | epoch 020:    807 / 1474 loss=4.118, trans_loss=5.288, nll_loss=2.571, w2v_ctc_loss=1.314, task_loss=0, contrastive_loss=0.119, total=4140.66, n_correct=2691.94, ppl=5.94, accuracy=65.012, wps=11295.2, ups=2.73, wpb=4140.7, bsz=152.8, num_updates=28800, lr=8.33333e-05, gnorm=1.027, clip=0, loss_scale=64, train_wall=36, gb_free=17.9, wall=16820
2023-07-04 08:34:51 | INFO | train_inner | epoch 020:    907 / 1474 loss=4.166, trans_loss=5.304, nll_loss=2.594, w2v_ctc_loss=1.3, task_loss=0, contrastive_loss=0.702, total=4157.15, n_correct=2688.86, ppl=6.04, accuracy=64.68, wps=11102.6, ups=2.67, wpb=4157.1, bsz=161.3, num_updates=28900, lr=8.3189e-05, gnorm=1.023, clip=0, loss_scale=64, train_wall=37, gb_free=18.1, wall=16857
2023-07-04 08:35:28 | INFO | train_inner | epoch 020:   1007 / 1474 loss=4.112, trans_loss=5.286, nll_loss=2.569, w2v_ctc_loss=1.295, task_loss=0, contrastive_loss=0.129, total=4171.86, n_correct=2708.25, ppl=5.94, accuracy=64.917, wps=11283.6, ups=2.7, wpb=4171.9, bsz=154.3, num_updates=29000, lr=8.30455e-05, gnorm=1.01, clip=0, loss_scale=64, train_wall=37, gb_free=16.4, wall=16894
2023-07-04 08:36:06 | INFO | train_inner | epoch 020:   1107 / 1474 loss=4.149, trans_loss=5.304, nll_loss=2.594, w2v_ctc_loss=1.308, task_loss=0, contrastive_loss=0.405, total=4162.96, n_correct=2695.16, ppl=6.04, accuracy=64.741, wps=11154.5, ups=2.68, wpb=4163, bsz=157.5, num_updates=29100, lr=8.29027e-05, gnorm=1.033, clip=0, loss_scale=64, train_wall=37, gb_free=17.4, wall=16932
2023-07-04 08:36:42 | INFO | train_inner | epoch 020:   1207 / 1474 loss=4.127, trans_loss=5.294, nll_loss=2.58, w2v_ctc_loss=1.334, task_loss=0, contrastive_loss=0.107, total=4033.74, n_correct=2613.91, ppl=5.98, accuracy=64.801, wps=11032, ups=2.73, wpb=4033.7, bsz=142.6, num_updates=29200, lr=8.27606e-05, gnorm=1.042, clip=0, loss_scale=64, train_wall=36, gb_free=17.6, wall=16968
2023-07-04 08:37:19 | INFO | train_inner | epoch 020:   1307 / 1474 loss=4.123, trans_loss=5.299, nll_loss=2.587, w2v_ctc_loss=1.309, task_loss=0, contrastive_loss=0.114, total=4124.42, n_correct=2670.07, ppl=6.01, accuracy=64.738, wps=11123.5, ups=2.7, wpb=4124.4, bsz=148.5, num_updates=29300, lr=8.26192e-05, gnorm=1.015, clip=0, loss_scale=64, train_wall=37, gb_free=16.5, wall=17005
2023-07-04 08:37:56 | INFO | train_inner | epoch 020:   1407 / 1474 loss=4.126, trans_loss=5.301, nll_loss=2.589, w2v_ctc_loss=1.313, task_loss=0, contrastive_loss=0.117, total=4114.1, n_correct=2664.12, ppl=6.02, accuracy=64.756, wps=11213.8, ups=2.73, wpb=4114.1, bsz=146.8, num_updates=29400, lr=8.24786e-05, gnorm=1.037, clip=0, loss_scale=64, train_wall=36, gb_free=14.9, wall=17042
2023-07-04 08:38:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 08:38:48 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.354 | trans_loss 5.567 | nll_loss 2.847 | w2v_ctc_loss 1.408 | task_loss 0 | contrastive_loss 0.262 | total 4003.4 | n_correct 2474.3 | ppl 7.2 | accuracy 61.805 | uer 17.267 | wer 19.022 | raw_wer 19.022 | bleu 20.26 | wps 1817 | wpb 4003.4 | bsz 141.8 | num_updates 29467 | best_bleu 20.52
2023-07-04 08:38:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29467 updates
2023-07-04 08:38:48 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.2601.pt
2023-07-04 08:38:50 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.2601.pt
2023-07-04 08:38:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.2601.pt (epoch 20 @ 29467 updates, score 20.26) (writing took 5.312804443761706 seconds)
2023-07-04 08:38:54 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-07-04 08:38:54 | INFO | train | epoch 020 | loss 4.123 | trans_loss 5.29 | nll_loss 2.574 | w2v_ctc_loss 1.305 | task_loss 0 | contrastive_loss 0.215 | total 4137.26 | n_correct 2686.19 | ppl 5.95 | accuracy 64.927 | wps 9836.2 | ups 2.38 | wpb 4137.3 | bsz 152.6 | num_updates 29467 | lr 8.23848e-05 | gnorm 1.024 | clip 0 | loss_scale 64 | train_wall 537 | gb_free 17 | wall 17100
2023-07-04 08:38:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 08:38:54 | INFO | fairseq.trainer | begin training epoch 21
2023-07-04 08:38:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 08:39:14 | INFO | train_inner | epoch 021:     33 / 1474 loss=4.137, trans_loss=5.296, nll_loss=2.583, w2v_ctc_loss=1.301, task_loss=0, contrastive_loss=0.351, total=4155.01, n_correct=2694.84, ppl=5.99, accuracy=64.858, wps=5334.2, ups=1.28, wpb=4155, bsz=158.8, num_updates=29500, lr=8.23387e-05, gnorm=1.025, clip=0, loss_scale=64, train_wall=36, gb_free=16.7, wall=17120
2023-07-04 08:39:51 | INFO | train_inner | epoch 021:    133 / 1474 loss=4.099, trans_loss=5.254, nll_loss=2.528, w2v_ctc_loss=1.275, task_loss=0, contrastive_loss=0.338, total=4186.67, n_correct=2739.29, ppl=5.77, accuracy=65.429, wps=11379.9, ups=2.72, wpb=4186.7, bsz=158.7, num_updates=29600, lr=8.21995e-05, gnorm=1.014, clip=0, loss_scale=64, train_wall=36, gb_free=13.6, wall=17157
2023-07-04 08:40:27 | INFO | train_inner | epoch 021:    233 / 1474 loss=4.093, trans_loss=5.26, nll_loss=2.535, w2v_ctc_loss=1.273, task_loss=0, contrastive_loss=0.247, total=4166.37, n_correct=2726.14, ppl=5.79, accuracy=65.432, wps=11318.3, ups=2.72, wpb=4166.4, bsz=157.6, num_updates=29700, lr=8.2061e-05, gnorm=1.03, clip=0, loss_scale=64, train_wall=36, gb_free=14.5, wall=17194
2023-07-04 08:41:04 | INFO | train_inner | epoch 021:    333 / 1474 loss=4.106, trans_loss=5.266, nll_loss=2.542, w2v_ctc_loss=1.296, task_loss=0, contrastive_loss=0.249, total=4132.25, n_correct=2696.3, ppl=5.82, accuracy=65.25, wps=11215.4, ups=2.71, wpb=4132.2, bsz=152.5, num_updates=29800, lr=8.19232e-05, gnorm=1.022, clip=0, loss_scale=64, train_wall=36, gb_free=17, wall=17230
2023-07-04 08:41:41 | INFO | train_inner | epoch 021:    433 / 1474 loss=4.083, trans_loss=5.257, nll_loss=2.531, w2v_ctc_loss=1.272, task_loss=0, contrastive_loss=0.114, total=4195.53, n_correct=2746.83, ppl=5.78, accuracy=65.47, wps=11551.3, ups=2.75, wpb=4195.5, bsz=155.8, num_updates=29900, lr=8.17861e-05, gnorm=1.026, clip=0, loss_scale=64, train_wall=36, gb_free=16.9, wall=17267
2023-07-04 08:42:17 | INFO | train_inner | epoch 021:    533 / 1474 loss=4.094, trans_loss=5.264, nll_loss=2.54, w2v_ctc_loss=1.297, task_loss=0, contrastive_loss=0.103, total=4085.05, n_correct=2668.99, ppl=5.81, accuracy=65.336, wps=11127.7, ups=2.72, wpb=4085.1, bsz=148, num_updates=30000, lr=8.16497e-05, gnorm=1.04, clip=0, loss_scale=64, train_wall=36, gb_free=16.6, wall=17303
2023-07-04 08:42:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 08:42:44 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.335 | trans_loss 5.576 | nll_loss 2.857 | w2v_ctc_loss 1.329 | task_loss 0 | contrastive_loss 0.253 | total 4003.4 | n_correct 2475.1 | ppl 7.25 | accuracy 61.825 | uer 16.818 | wer 18.623 | raw_wer 18.623 | bleu 19.87 | wps 1967.1 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.52
2023-07-04 08:42:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-07-04 08:42:44 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_21_30000.pt
2023-07-04 08:42:46 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_21_30000.pt
2023-07-04 08:42:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 19.87) (writing took 8.225698109716177 seconds)
tensor(0.0295, device='cuda:0')
tensor(0.0009, device='cuda:0')
2023-07-04 08:43:29 | INFO | train_inner | epoch 021:    633 / 1474 loss=4.118, trans_loss=5.274, nll_loss=2.555, w2v_ctc_loss=1.282, task_loss=0, contrastive_loss=0.441, total=4220.3, n_correct=2750.65, ppl=5.87, accuracy=65.177, wps=5860.5, ups=1.39, wpb=4220.3, bsz=157.9, num_updates=30100, lr=8.15139e-05, gnorm=1.027, clip=0, loss_scale=64, train_wall=37, gb_free=16.1, wall=17375
2023-07-04 08:44:06 | INFO | train_inner | epoch 021:    733 / 1474 loss=4.114, trans_loss=5.285, nll_loss=2.568, w2v_ctc_loss=1.294, task_loss=0, contrastive_loss=0.166, total=4148.18, n_correct=2695.18, ppl=5.93, accuracy=64.973, wps=11180.4, ups=2.7, wpb=4148.2, bsz=154.2, num_updates=30200, lr=8.13788e-05, gnorm=1.04, clip=0, loss_scale=64, train_wall=37, gb_free=12.5, wall=17413
2023-07-04 08:44:43 | INFO | train_inner | epoch 021:    833 / 1474 loss=4.124, trans_loss=5.292, nll_loss=2.576, w2v_ctc_loss=1.306, task_loss=0, contrastive_loss=0.196, total=4062.56, n_correct=2637.9, ppl=5.96, accuracy=64.932, wps=11010, ups=2.71, wpb=4062.6, bsz=146.5, num_updates=30300, lr=8.12444e-05, gnorm=1.05, clip=0, loss_scale=64, train_wall=36, gb_free=16.7, wall=17449
2023-07-04 08:45:20 | INFO | train_inner | epoch 021:    933 / 1474 loss=4.101, trans_loss=5.272, nll_loss=2.552, w2v_ctc_loss=1.291, task_loss=0, contrastive_loss=0.138, total=4103.66, n_correct=2672.74, ppl=5.86, accuracy=65.131, wps=11283.8, ups=2.75, wpb=4103.7, bsz=150.7, num_updates=30400, lr=8.11107e-05, gnorm=1.029, clip=0, loss_scale=64, train_wall=36, gb_free=17.5, wall=17486
2023-07-04 08:45:57 | INFO | train_inner | epoch 021:   1033 / 1474 loss=4.127, trans_loss=5.299, nll_loss=2.587, w2v_ctc_loss=1.316, task_loss=0, contrastive_loss=0.134, total=4100.54, n_correct=2654.76, ppl=6.01, accuracy=64.742, wps=11078.4, ups=2.7, wpb=4100.5, bsz=149.1, num_updates=30500, lr=8.09776e-05, gnorm=1.033, clip=0, loss_scale=64, train_wall=37, gb_free=18.2, wall=17523
2023-07-04 08:46:33 | INFO | train_inner | epoch 021:   1133 / 1474 loss=4.115, trans_loss=5.286, nll_loss=2.569, w2v_ctc_loss=1.306, task_loss=0, contrastive_loss=0.14, total=4119.98, n_correct=2675.27, ppl=5.94, accuracy=64.934, wps=11296.7, ups=2.74, wpb=4120, bsz=147, num_updates=30600, lr=8.08452e-05, gnorm=1.045, clip=0, loss_scale=64, train_wall=36, gb_free=18.2, wall=17559
2023-07-04 08:46:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-04 08:47:10 | INFO | train_inner | epoch 021:   1234 / 1474 loss=4.112, trans_loss=5.278, nll_loss=2.56, w2v_ctc_loss=1.296, task_loss=0, contrastive_loss=0.202, total=4138.58, n_correct=2691.34, ppl=5.9, accuracy=65.031, wps=11209, ups=2.71, wpb=4138.6, bsz=152.7, num_updates=30700, lr=8.07134e-05, gnorm=1.021, clip=0, loss_scale=64, train_wall=37, gb_free=13.2, wall=17596
2023-07-04 08:47:47 | INFO | train_inner | epoch 021:   1334 / 1474 loss=4.113, trans_loss=5.283, nll_loss=2.567, w2v_ctc_loss=1.295, task_loss=0, contrastive_loss=0.168, total=4147.17, n_correct=2700.32, ppl=5.92, accuracy=65.112, wps=11387.8, ups=2.75, wpb=4147.2, bsz=155.9, num_updates=30800, lr=8.05823e-05, gnorm=1.028, clip=0, loss_scale=64, train_wall=36, gb_free=16.7, wall=17633
2023-07-04 08:48:23 | INFO | train_inner | epoch 021:   1434 / 1474 loss=4.143, trans_loss=5.3, nll_loss=2.588, w2v_ctc_loss=1.331, task_loss=0, contrastive_loss=0.264, total=4133.93, n_correct=2677.11, ppl=6.01, accuracy=64.759, wps=11223.6, ups=2.71, wpb=4133.9, bsz=152.2, num_updates=30900, lr=8.04518e-05, gnorm=1.041, clip=0, loss_scale=64, train_wall=36, gb_free=15.9, wall=17670
2023-07-04 08:48:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0295, device='cuda:7')
tensor(0.0009, device='cuda:7')
tensor(0.0295, device='cuda:5')
tensor(0.0009, device='cuda:5')
tensor(0.0295, device='cuda:3')
tensor(0.0009, device='cuda:3')
tensor(0.0295, device='cuda:4')
tensor(0.0009, device='cuda:4')
tensor(0.0295, device='cuda:2')
tensor(0.0009, device='cuda:2')
tensor(0.0295, device='cuda:6')
tensor(0.0009, device='cuda:6')
tensor(0.0295, device='cuda:1')
tensor(0.0009, device='cuda:1')
2023-07-04 08:49:02 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.347 | trans_loss 5.567 | nll_loss 2.845 | w2v_ctc_loss 1.386 | task_loss 0 | contrastive_loss 0.259 | total 4003.4 | n_correct 2478.6 | ppl 7.18 | accuracy 61.912 | uer 17.288 | wer 19.224 | raw_wer 19.224 | bleu 19.95 | wps 2236.4 | wpb 4003.4 | bsz 141.8 | num_updates 30940 | best_bleu 20.52
2023-07-04 08:49:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30940 updates
2023-07-04 08:49:02 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_19.9509.pt
2023-07-04 08:49:05 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_19.9509.pt
2023-07-04 08:49:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_19.9509.pt (epoch 21 @ 30940 updates, score 19.95) (writing took 5.4606617032550275 seconds)
2023-07-04 08:49:08 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-07-04 08:49:08 | INFO | train | epoch 021 | loss 4.11 | trans_loss 5.276 | nll_loss 2.557 | w2v_ctc_loss 1.294 | task_loss 0 | contrastive_loss 0.216 | total 4137.43 | n_correct 2694.56 | ppl 5.88 | accuracy 65.127 | wps 9917 | ups 2.4 | wpb 4137.4 | bsz 152.6 | num_updates 30940 | lr 8.03998e-05 | gnorm 1.032 | clip 0 | loss_scale 64 | train_wall 536 | gb_free 15.8 | wall 17714
2023-07-04 08:49:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 08:49:08 | INFO | fairseq.trainer | begin training epoch 22
2023-07-04 08:49:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 08:49:39 | INFO | train_inner | epoch 022:     60 / 1474 loss=4.09, trans_loss=5.258, nll_loss=2.533, w2v_ctc_loss=1.297, task_loss=0, contrastive_loss=0.104, total=4128.84, n_correct=2703.94, ppl=5.79, accuracy=65.489, wps=5494.8, ups=1.33, wpb=4128.8, bsz=148.8, num_updates=31000, lr=8.03219e-05, gnorm=1.034, clip=0, loss_scale=64, train_wall=36, gb_free=14.7, wall=17745
2023-07-04 08:50:16 | INFO | train_inner | epoch 022:    160 / 1474 loss=4.092, trans_loss=5.249, nll_loss=2.522, w2v_ctc_loss=1.284, task_loss=0, contrastive_loss=0.267, total=4123.35, n_correct=2705.39, ppl=5.74, accuracy=65.611, wps=11028, ups=2.67, wpb=4123.4, bsz=155.1, num_updates=31100, lr=8.01927e-05, gnorm=1.03, clip=0, loss_scale=64, train_wall=37, gb_free=15.2, wall=17782
2023-07-04 08:50:53 | INFO | train_inner | epoch 022:    260 / 1474 loss=4.068, trans_loss=5.236, nll_loss=2.505, w2v_ctc_loss=1.258, task_loss=0, contrastive_loss=0.148, total=4267.16, n_correct=2808.64, ppl=5.68, accuracy=65.82, wps=11625, ups=2.72, wpb=4267.2, bsz=165, num_updates=31200, lr=8.00641e-05, gnorm=1.009, clip=0, loss_scale=64, train_wall=36, gb_free=17.3, wall=17819
2023-07-04 08:51:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-04 08:51:31 | INFO | train_inner | epoch 022:    361 / 1474 loss=4.111, trans_loss=5.265, nll_loss=2.541, w2v_ctc_loss=1.292, task_loss=0, contrastive_loss=0.345, total=4163.56, n_correct=2718.1, ppl=5.82, accuracy=65.283, wps=11003.6, ups=2.64, wpb=4163.6, bsz=152, num_updates=31300, lr=7.99361e-05, gnorm=1.045, clip=0, loss_scale=32, train_wall=37, gb_free=16.5, wall=17857
2023-07-04 08:52:07 | INFO | train_inner | epoch 022:    461 / 1474 loss=4.107, trans_loss=5.268, nll_loss=2.546, w2v_ctc_loss=1.294, task_loss=0, contrastive_loss=0.228, total=4132.96, n_correct=2698.92, ppl=5.84, accuracy=65.302, wps=11236.6, ups=2.72, wpb=4133, bsz=148.8, num_updates=31400, lr=7.98087e-05, gnorm=1.032, clip=0, loss_scale=32, train_wall=36, gb_free=17.3, wall=17893
2023-07-04 08:52:45 | INFO | train_inner | epoch 022:    561 / 1474 loss=4.085, trans_loss=5.253, nll_loss=2.526, w2v_ctc_loss=1.286, task_loss=0, contrastive_loss=0.124, total=4158.17, n_correct=2724.27, ppl=5.76, accuracy=65.516, wps=11158.6, ups=2.68, wpb=4158.2, bsz=153.9, num_updates=31500, lr=7.96819e-05, gnorm=1.022, clip=0, loss_scale=32, train_wall=37, gb_free=17.3, wall=17931
2023-07-04 08:53:21 | INFO | train_inner | epoch 022:    661 / 1474 loss=4.09, trans_loss=5.251, nll_loss=2.525, w2v_ctc_loss=1.27, task_loss=0, contrastive_loss=0.295, total=4139.66, n_correct=2712.15, ppl=5.76, accuracy=65.516, wps=11280, ups=2.72, wpb=4139.7, bsz=155.5, num_updates=31600, lr=7.95557e-05, gnorm=1.023, clip=0, loss_scale=32, train_wall=36, gb_free=16.6, wall=17967
2023-07-04 08:53:58 | INFO | train_inner | epoch 022:    761 / 1474 loss=4.092, trans_loss=5.259, nll_loss=2.533, w2v_ctc_loss=1.292, task_loss=0, contrastive_loss=0.132, total=4167.89, n_correct=2725.8, ppl=5.79, accuracy=65.4, wps=11375.6, ups=2.73, wpb=4167.9, bsz=152, num_updates=31700, lr=7.94301e-05, gnorm=1.035, clip=0, loss_scale=32, train_wall=36, gb_free=13.4, wall=18004
2023-07-04 08:54:35 | INFO | train_inner | epoch 022:    861 / 1474 loss=4.104, trans_loss=5.272, nll_loss=2.552, w2v_ctc_loss=1.307, task_loss=0, contrastive_loss=0.107, total=4075.79, n_correct=2656.52, ppl=5.86, accuracy=65.178, wps=11062.1, ups=2.71, wpb=4075.8, bsz=144.5, num_updates=31800, lr=7.93052e-05, gnorm=1.052, clip=0, loss_scale=32, train_wall=36, gb_free=16.6, wall=18041
2023-07-04 08:55:12 | INFO | train_inner | epoch 022:    961 / 1474 loss=4.083, trans_loss=5.258, nll_loss=2.534, w2v_ctc_loss=1.27, task_loss=0, contrastive_loss=0.109, total=4134.72, n_correct=2706.94, ppl=5.79, accuracy=65.469, wps=11092.8, ups=2.68, wpb=4134.7, bsz=151.6, num_updates=31900, lr=7.91808e-05, gnorm=1.033, clip=0, loss_scale=32, train_wall=37, gb_free=14.7, wall=18078
2023-07-04 08:55:49 | INFO | train_inner | epoch 022:   1061 / 1474 loss=4.099, trans_loss=5.256, nll_loss=2.532, w2v_ctc_loss=1.258, task_loss=0, contrastive_loss=0.445, total=4160.57, n_correct=2723.07, ppl=5.78, accuracy=65.449, wps=11159.3, ups=2.68, wpb=4160.6, bsz=157.8, num_updates=32000, lr=7.90569e-05, gnorm=1.027, clip=0, loss_scale=32, train_wall=37, gb_free=17.6, wall=18115
2023-07-04 08:55:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 08:56:16 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.345 | trans_loss 5.569 | nll_loss 2.848 | w2v_ctc_loss 1.377 | task_loss 0 | contrastive_loss 0.246 | total 4003.4 | n_correct 2476 | ppl 7.2 | accuracy 61.847 | uer 17.052 | wer 19.015 | raw_wer 19.015 | bleu 19.81 | wps 2017 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.52
2023-07-04 08:56:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-07-04 08:56:16 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_22_32000.pt
2023-07-04 08:56:19 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_22_32000.pt
2023-07-04 08:56:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 19.81) (writing took 5.322095944080502 seconds)
2023-07-04 08:56:59 | INFO | train_inner | epoch 022:   1161 / 1474 loss=4.12, trans_loss=5.285, nll_loss=2.569, w2v_ctc_loss=1.305, task_loss=0, contrastive_loss=0.21, total=4099.59, n_correct=2664.33, ppl=5.94, accuracy=64.99, wps=5912.4, ups=1.44, wpb=4099.6, bsz=148.1, num_updates=32100, lr=7.89337e-05, gnorm=1.047, clip=0, loss_scale=32, train_wall=36, gb_free=15.4, wall=18185
2023-07-04 08:57:36 | INFO | train_inner | epoch 022:   1261 / 1474 loss=4.111, trans_loss=5.275, nll_loss=2.558, w2v_ctc_loss=1.293, task_loss=0, contrastive_loss=0.2, total=4182.05, n_correct=2726.23, ppl=5.89, accuracy=65.189, wps=11342, ups=2.71, wpb=4182.1, bsz=161.5, num_updates=32200, lr=7.8811e-05, gnorm=1.034, clip=0, loss_scale=32, train_wall=36, gb_free=16, wall=18222
2023-07-04 08:58:12 | INFO | train_inner | epoch 022:   1361 / 1474 loss=4.091, trans_loss=5.263, nll_loss=2.54, w2v_ctc_loss=1.264, task_loss=0, contrastive_loss=0.241, total=4062.31, n_correct=2652.8, ppl=5.82, accuracy=65.303, wps=11144.8, ups=2.74, wpb=4062.3, bsz=149.5, num_updates=32300, lr=7.86889e-05, gnorm=1.034, clip=0, loss_scale=32, train_wall=36, gb_free=15.5, wall=18258
2023-07-04 08:58:49 | INFO | train_inner | epoch 022:   1461 / 1474 loss=4.119, trans_loss=5.286, nll_loss=2.571, w2v_ctc_loss=1.316, task_loss=0, contrastive_loss=0.141, total=4081.88, n_correct=2647.97, ppl=5.94, accuracy=64.871, wps=11121.4, ups=2.72, wpb=4081.9, bsz=144.5, num_updates=32400, lr=7.85674e-05, gnorm=1.035, clip=0, loss_scale=32, train_wall=36, gb_free=17.6, wall=18295
2023-07-04 08:58:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 08:59:20 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.337 | trans_loss 5.566 | nll_loss 2.839 | w2v_ctc_loss 1.356 | task_loss 0 | contrastive_loss 0.253 | total 4003.4 | n_correct 2480.7 | ppl 7.15 | accuracy 61.965 | uer 17.002 | wer 18.836 | raw_wer 18.836 | bleu 20.02 | wps 2248.7 | wpb 4003.4 | bsz 141.8 | num_updates 32413 | best_bleu 20.52
2023-07-04 08:59:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32413 updates
2023-07-04 08:59:20 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.0208.pt
2023-07-04 08:59:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.0208.pt
2023-07-04 08:59:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.0208.pt (epoch 22 @ 32413 updates, score 20.02) (writing took 5.488164857029915 seconds)
2023-07-04 08:59:25 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-07-04 08:59:25 | INFO | train | epoch 022 | loss 4.097 | trans_loss 5.262 | nll_loss 2.539 | w2v_ctc_loss 1.286 | task_loss 0 | contrastive_loss 0.21 | total 4137.49 | n_correct 2704.46 | ppl 5.81 | accuracy 65.365 | wps 9874.9 | ups 2.39 | wpb 4137.5 | bsz 152.6 | num_updates 32413 | lr 7.85517e-05 | gnorm 1.033 | clip 0 | loss_scale 32 | train_wall 538 | gb_free 12.4 | wall 18331
2023-07-04 08:59:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 08:59:26 | INFO | fairseq.trainer | begin training epoch 23
2023-07-04 08:59:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 09:00:06 | INFO | train_inner | epoch 023:     87 / 1474 loss=4.077, trans_loss=5.24, nll_loss=2.51, w2v_ctc_loss=1.29, task_loss=0, contrastive_loss=0.121, total=4096.09, n_correct=2694.08, ppl=5.69, accuracy=65.772, wps=5304, ups=1.29, wpb=4096.1, bsz=150.6, num_updates=32500, lr=7.84465e-05, gnorm=1.043, clip=0, loss_scale=32, train_wall=37, gb_free=16.8, wall=18372
2023-07-04 09:00:43 | INFO | train_inner | epoch 023:    187 / 1474 loss=4.064, trans_loss=5.233, nll_loss=2.501, w2v_ctc_loss=1.265, task_loss=0, contrastive_loss=0.113, total=4107.77, n_correct=2705.17, ppl=5.66, accuracy=65.855, wps=11167.6, ups=2.72, wpb=4107.8, bsz=146.7, num_updates=32600, lr=7.8326e-05, gnorm=1.024, clip=0, loss_scale=32, train_wall=36, gb_free=16.8, wall=18409
2023-07-04 09:01:20 | INFO | train_inner | epoch 023:    287 / 1474 loss=4.068, trans_loss=5.232, nll_loss=2.5, w2v_ctc_loss=1.242, task_loss=0, contrastive_loss=0.27, total=4153.12, n_correct=2735.32, ppl=5.66, accuracy=65.862, wps=11207.8, ups=2.7, wpb=4153.1, bsz=153.2, num_updates=32700, lr=7.82062e-05, gnorm=1.022, clip=0, loss_scale=32, train_wall=37, gb_free=17.4, wall=18446
2023-07-04 09:01:57 | INFO | train_inner | epoch 023:    387 / 1474 loss=4.063, trans_loss=5.236, nll_loss=2.505, w2v_ctc_loss=1.258, task_loss=0, contrastive_loss=0.102, total=4116.7, n_correct=2709.45, ppl=5.67, accuracy=65.816, wps=11227.3, ups=2.73, wpb=4116.7, bsz=147, num_updates=32800, lr=7.80869e-05, gnorm=1.037, clip=0, loss_scale=32, train_wall=36, gb_free=15.7, wall=18483
2023-07-04 09:02:34 | INFO | train_inner | epoch 023:    487 / 1474 loss=4.076, trans_loss=5.241, nll_loss=2.511, w2v_ctc_loss=1.259, task_loss=0, contrastive_loss=0.216, total=4157.6, n_correct=2729.66, ppl=5.7, accuracy=65.655, wps=11217.5, ups=2.7, wpb=4157.6, bsz=156.8, num_updates=32900, lr=7.79681e-05, gnorm=1.035, clip=0, loss_scale=32, train_wall=37, gb_free=17.6, wall=18520
2023-07-04 09:03:10 | INFO | train_inner | epoch 023:    587 / 1474 loss=4.054, trans_loss=5.225, nll_loss=2.491, w2v_ctc_loss=1.248, task_loss=0, contrastive_loss=0.11, total=4173.42, n_correct=2755.19, ppl=5.62, accuracy=66.018, wps=11411.8, ups=2.73, wpb=4173.4, bsz=158, num_updates=33000, lr=7.78499e-05, gnorm=1.024, clip=0, loss_scale=32, train_wall=36, gb_free=13.3, wall=18556
2023-07-04 09:03:47 | INFO | train_inner | epoch 023:    687 / 1474 loss=4.079, trans_loss=5.243, nll_loss=2.513, w2v_ctc_loss=1.273, task_loss=0, contrastive_loss=0.189, total=4137.82, n_correct=2717.49, ppl=5.71, accuracy=65.674, wps=11287.3, ups=2.73, wpb=4137.8, bsz=151.2, num_updates=33100, lr=7.77322e-05, gnorm=1.024, clip=0, loss_scale=32, train_wall=36, gb_free=17.5, wall=18593
2023-07-04 09:04:24 | INFO | train_inner | epoch 023:    787 / 1474 loss=4.088, trans_loss=5.254, nll_loss=2.529, w2v_ctc_loss=1.285, task_loss=0, contrastive_loss=0.149, total=4150.99, n_correct=2721.99, ppl=5.77, accuracy=65.574, wps=11314.7, ups=2.73, wpb=4151, bsz=152.7, num_updates=33200, lr=7.76151e-05, gnorm=1.044, clip=0, loss_scale=32, train_wall=36, gb_free=16.9, wall=18630
2023-07-04 09:05:00 | INFO | train_inner | epoch 023:    887 / 1474 loss=4.081, trans_loss=5.238, nll_loss=2.509, w2v_ctc_loss=1.261, task_loss=0, contrastive_loss=0.305, total=4181.99, n_correct=2750.86, ppl=5.69, accuracy=65.779, wps=11356.7, ups=2.72, wpb=4182, bsz=162.3, num_updates=33300, lr=7.74984e-05, gnorm=1.025, clip=0, loss_scale=32, train_wall=36, gb_free=16.9, wall=18666
2023-07-04 09:05:37 | INFO | train_inner | epoch 023:    987 / 1474 loss=4.113, trans_loss=5.255, nll_loss=2.53, w2v_ctc_loss=1.271, task_loss=0, contrastive_loss=0.622, total=4168.73, n_correct=2727.53, ppl=5.78, accuracy=65.428, wps=11338.7, ups=2.72, wpb=4168.7, bsz=155.2, num_updates=33400, lr=7.73823e-05, gnorm=1.032, clip=0, loss_scale=64, train_wall=36, gb_free=11.7, wall=18703
2023-07-04 09:06:14 | INFO | train_inner | epoch 023:   1087 / 1474 loss=4.089, trans_loss=5.255, nll_loss=2.529, w2v_ctc_loss=1.292, task_loss=0, contrastive_loss=0.127, total=4088.49, n_correct=2676.75, ppl=5.77, accuracy=65.47, wps=11056.4, ups=2.7, wpb=4088.5, bsz=145, num_updates=33500, lr=7.72667e-05, gnorm=1.039, clip=0, loss_scale=64, train_wall=37, gb_free=16.3, wall=18740
2023-07-04 09:06:51 | INFO | train_inner | epoch 023:   1187 / 1474 loss=4.081, trans_loss=5.252, nll_loss=2.526, w2v_ctc_loss=1.276, task_loss=0, contrastive_loss=0.113, total=4162.7, n_correct=2724.34, ppl=5.76, accuracy=65.446, wps=11188.8, ups=2.69, wpb=4162.7, bsz=154.7, num_updates=33600, lr=7.71517e-05, gnorm=1.031, clip=0, loss_scale=64, train_wall=37, gb_free=16.6, wall=18777
2023-07-04 09:07:28 | INFO | train_inner | epoch 023:   1287 / 1474 loss=4.073, trans_loss=5.245, nll_loss=2.518, w2v_ctc_loss=1.257, task_loss=0, contrastive_loss=0.134, total=4135.53, n_correct=2715.99, ppl=5.73, accuracy=65.675, wps=11296, ups=2.73, wpb=4135.5, bsz=154.5, num_updates=33700, lr=7.70371e-05, gnorm=1.021, clip=0, loss_scale=64, train_wall=36, gb_free=17.2, wall=18814
2023-07-04 09:08:05 | INFO | train_inner | epoch 023:   1387 / 1474 loss=4.11, trans_loss=5.275, nll_loss=2.557, w2v_ctc_loss=1.283, task_loss=0, contrastive_loss=0.25, total=4143.98, n_correct=2699.83, ppl=5.88, accuracy=65.151, wps=11234.5, ups=2.71, wpb=4144, bsz=152.6, num_updates=33800, lr=7.69231e-05, gnorm=1.032, clip=0, loss_scale=64, train_wall=36, gb_free=16.4, wall=18851
2023-07-04 09:08:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 09:09:02 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.344 | trans_loss 5.554 | nll_loss 2.829 | w2v_ctc_loss 1.407 | task_loss 0 | contrastive_loss 0.252 | total 4003.4 | n_correct 2486.6 | ppl 7.1 | accuracy 62.112 | uer 16.739 | wer 18.59 | raw_wer 18.59 | bleu 20.28 | wps 2191.6 | wpb 4003.4 | bsz 141.8 | num_updates 33887 | best_bleu 20.52
2023-07-04 09:09:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33887 updates
2023-07-04 09:09:02 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.2808.pt
2023-07-04 09:09:04 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.2808.pt
2023-07-04 09:09:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.2808.pt (epoch 23 @ 33887 updates, score 20.28) (writing took 5.387436481192708 seconds)
2023-07-04 09:09:07 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-07-04 09:09:07 | INFO | train | epoch 023 | loss 4.082 | trans_loss 5.246 | nll_loss 2.519 | w2v_ctc_loss 1.269 | task_loss 0 | contrastive_loss 0.218 | total 4138.65 | n_correct 2715.95 | ppl 5.73 | accuracy 65.624 | wps 10478 | ups 2.53 | wpb 4138.6 | bsz 152.8 | num_updates 33887 | lr 7.68243e-05 | gnorm 1.031 | clip 0 | loss_scale 64 | train_wall 537 | gb_free 14.3 | wall 18914
2023-07-04 09:09:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 09:09:08 | INFO | fairseq.trainer | begin training epoch 24
2023-07-04 09:09:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 09:09:20 | INFO | train_inner | epoch 024:     13 / 1474 loss=4.114, trans_loss=5.268, nll_loss=2.55, w2v_ctc_loss=1.272, task_loss=0, contrastive_loss=0.407, total=4085.11, n_correct=2663.92, ppl=5.85, accuracy=65.21, wps=5401, ups=1.32, wpb=4085.1, bsz=152.1, num_updates=33900, lr=7.68095e-05, gnorm=1.042, clip=0, loss_scale=64, train_wall=36, gb_free=13.2, wall=18927
2023-07-04 09:09:57 | INFO | train_inner | epoch 024:    113 / 1474 loss=4.069, trans_loss=5.213, nll_loss=2.475, w2v_ctc_loss=1.247, task_loss=0, contrastive_loss=0.439, total=4171.44, n_correct=2760.83, ppl=5.56, accuracy=66.184, wps=11332.8, ups=2.72, wpb=4171.4, bsz=162.3, num_updates=34000, lr=7.66965e-05, gnorm=1.017, clip=0, loss_scale=64, train_wall=36, gb_free=16.8, wall=18963
2023-07-04 09:09:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 09:10:22 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.341 | trans_loss 5.564 | nll_loss 2.834 | w2v_ctc_loss 1.374 | task_loss 0 | contrastive_loss 0.254 | total 4003.4 | n_correct 2484.3 | ppl 7.13 | accuracy 62.055 | uer 16.834 | wer 18.769 | raw_wer 18.769 | bleu 20.18 | wps 2246.9 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.52
2023-07-04 09:10:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-07-04 09:10:22 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_24_34000.pt
2023-07-04 09:10:24 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_24_34000.pt
2023-07-04 09:10:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 20.18) (writing took 6.472044836729765 seconds)
2023-07-04 09:11:06 | INFO | train_inner | epoch 024:    213 / 1474 loss=4.071, trans_loss=5.217, nll_loss=2.481, w2v_ctc_loss=1.22, task_loss=0, contrastive_loss=0.545, total=4251.29, n_correct=2814.47, ppl=5.58, accuracy=66.203, wps=6220.1, ups=1.46, wpb=4251.3, bsz=170.4, num_updates=34100, lr=7.6584e-05, gnorm=1.017, clip=0, loss_scale=64, train_wall=37, gb_free=17.2, wall=19032
2023-07-04 09:11:43 | INFO | train_inner | epoch 024:    313 / 1474 loss=4.045, trans_loss=5.216, nll_loss=2.479, w2v_ctc_loss=1.244, task_loss=0, contrastive_loss=0.105, total=4128.18, n_correct=2729.83, ppl=5.57, accuracy=66.127, wps=11166.8, ups=2.71, wpb=4128.2, bsz=152.8, num_updates=34200, lr=7.64719e-05, gnorm=1.02, clip=0, loss_scale=64, train_wall=37, gb_free=16.6, wall=19069
2023-07-04 09:12:20 | INFO | train_inner | epoch 024:    413 / 1474 loss=4.09, trans_loss=5.24, nll_loss=2.51, w2v_ctc_loss=1.271, task_loss=0, contrastive_loss=0.386, total=4158.92, n_correct=2733.08, ppl=5.7, accuracy=65.716, wps=11155.8, ups=2.68, wpb=4158.9, bsz=149.9, num_updates=34300, lr=7.63604e-05, gnorm=1.031, clip=0, loss_scale=64, train_wall=37, gb_free=17, wall=19106
2023-07-04 09:12:57 | INFO | train_inner | epoch 024:    513 / 1474 loss=4.069, trans_loss=5.23, nll_loss=2.497, w2v_ctc_loss=1.261, task_loss=0, contrastive_loss=0.243, total=4144.91, n_correct=2732.12, ppl=5.65, accuracy=65.915, wps=11240.8, ups=2.71, wpb=4144.9, bsz=151.6, num_updates=34400, lr=7.62493e-05, gnorm=1.026, clip=0, loss_scale=64, train_wall=36, gb_free=17.3, wall=19143
2023-07-04 09:13:34 | INFO | train_inner | epoch 024:    613 / 1474 loss=4.059, trans_loss=5.226, nll_loss=2.493, w2v_ctc_loss=1.248, task_loss=0, contrastive_loss=0.17, total=4165.3, n_correct=2746.75, ppl=5.63, accuracy=65.944, wps=11275.6, ups=2.71, wpb=4165.3, bsz=153.8, num_updates=34500, lr=7.61387e-05, gnorm=1.031, clip=0, loss_scale=64, train_wall=36, gb_free=16.2, wall=19180
2023-07-04 09:14:11 | INFO | train_inner | epoch 024:    713 / 1474 loss=4.068, trans_loss=5.234, nll_loss=2.503, w2v_ctc_loss=1.254, task_loss=0, contrastive_loss=0.192, total=4102.21, n_correct=2699.41, ppl=5.67, accuracy=65.804, wps=11092.8, ups=2.7, wpb=4102.2, bsz=147.5, num_updates=34600, lr=7.60286e-05, gnorm=1.035, clip=0, loss_scale=64, train_wall=37, gb_free=17.4, wall=19217
2023-07-04 09:14:48 | INFO | train_inner | epoch 024:    813 / 1474 loss=4.061, trans_loss=5.233, nll_loss=2.502, w2v_ctc_loss=1.247, task_loss=0, contrastive_loss=0.147, total=4110.6, n_correct=2707.36, ppl=5.67, accuracy=65.863, wps=10960.4, ups=2.67, wpb=4110.6, bsz=152.7, num_updates=34700, lr=7.5919e-05, gnorm=1.03, clip=0, loss_scale=64, train_wall=37, gb_free=17.1, wall=19254
2023-07-04 09:15:25 | INFO | train_inner | epoch 024:    913 / 1474 loss=4.08, trans_loss=5.251, nll_loss=2.523, w2v_ctc_loss=1.28, task_loss=0, contrastive_loss=0.1, total=4043.03, n_correct=2646.03, ppl=5.75, accuracy=65.447, wps=10939.2, ups=2.71, wpb=4043, bsz=140.5, num_updates=34800, lr=7.58098e-05, gnorm=1.047, clip=0, loss_scale=64, train_wall=37, gb_free=11.9, wall=19291
2023-07-04 09:16:02 | INFO | train_inner | epoch 024:   1013 / 1474 loss=4.064, trans_loss=5.24, nll_loss=2.511, w2v_ctc_loss=1.248, task_loss=0, contrastive_loss=0.108, total=4136.81, n_correct=2717.62, ppl=5.7, accuracy=65.694, wps=11198.4, ups=2.71, wpb=4136.8, bsz=149.2, num_updates=34900, lr=7.57011e-05, gnorm=1.033, clip=0, loss_scale=64, train_wall=36, gb_free=17.3, wall=19328
2023-07-04 09:16:39 | INFO | train_inner | epoch 024:   1113 / 1474 loss=4.064, trans_loss=5.226, nll_loss=2.493, w2v_ctc_loss=1.257, task_loss=0, contrastive_loss=0.193, total=4135.73, n_correct=2726.47, ppl=5.63, accuracy=65.925, wps=11199.5, ups=2.71, wpb=4135.7, bsz=154.4, num_updates=35000, lr=7.55929e-05, gnorm=1.032, clip=0, loss_scale=64, train_wall=36, gb_free=17.5, wall=19365
tensor(0.0295, device='cuda:0')
tensor(0.0009, device='cuda:0')
2023-07-04 09:17:16 | INFO | train_inner | epoch 024:   1213 / 1474 loss=4.072, trans_loss=5.241, nll_loss=2.513, w2v_ctc_loss=1.254, task_loss=0, contrastive_loss=0.17, total=4148.3, n_correct=2726.77, ppl=5.71, accuracy=65.732, wps=11164.1, ups=2.69, wpb=4148.3, bsz=155.4, num_updates=35100, lr=7.54851e-05, gnorm=1.041, clip=0, loss_scale=64, train_wall=37, gb_free=17, wall=19402
2023-07-04 09:17:53 | INFO | train_inner | epoch 024:   1313 / 1474 loss=4.085, trans_loss=5.252, nll_loss=2.526, w2v_ctc_loss=1.288, task_loss=0, contrastive_loss=0.117, total=4110.05, n_correct=2692.37, ppl=5.76, accuracy=65.507, wps=11143.9, ups=2.71, wpb=4110.1, bsz=147.1, num_updates=35200, lr=7.53778e-05, gnorm=1.041, clip=0, loss_scale=64, train_wall=36, gb_free=17.6, wall=19439
2023-07-04 09:18:30 | INFO | train_inner | epoch 024:   1413 / 1474 loss=4.079, trans_loss=5.246, nll_loss=2.52, w2v_ctc_loss=1.283, task_loss=0, contrastive_loss=0.115, total=4090.91, n_correct=2682.64, ppl=5.74, accuracy=65.576, wps=11207, ups=2.74, wpb=4090.9, bsz=146.4, num_updates=35300, lr=7.5271e-05, gnorm=1.033, clip=0, loss_scale=64, train_wall=36, gb_free=16.8, wall=19476
2023-07-04 09:18:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0295, device='cuda:6')
tensor(0.0009, device='cuda:6')
tensor(0.0295, device='cuda:4')
tensor(0.0009, device='cuda:4')
tensor(0.0295, device='cuda:2')
tensor(0.0009, device='cuda:2')
tensor(0.0295, device='cuda:1')
tensor(0.0009, device='cuda:1')
tensor(0.0295, device='cuda:5')
tensor(0.0009, device='cuda:5')
tensor(0.0295, device='cuda:7')
tensor(0.0009, device='cuda:7')
tensor(0.0295, device='cuda:3')
tensor(0.0009, device='cuda:3')
2023-07-04 09:19:15 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.345 | trans_loss 5.555 | nll_loss 2.828 | w2v_ctc_loss 1.405 | task_loss 0 | contrastive_loss 0.255 | total 4003.4 | n_correct 2484.3 | ppl 7.1 | accuracy 62.055 | uer 16.765 | wer 18.676 | raw_wer 18.676 | bleu 20.24 | wps 2473.9 | wpb 4003.4 | bsz 141.8 | num_updates 35361 | best_bleu 20.52
2023-07-04 09:19:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35361 updates
2023-07-04 09:19:15 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.2400.pt
2023-07-04 09:19:18 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.2400.pt
2023-07-04 09:19:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.2400.pt (epoch 24 @ 35361 updates, score 20.24) (writing took 5.533407506067306 seconds)
2023-07-04 09:19:21 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-07-04 09:19:21 | INFO | train | epoch 024 | loss 4.069 | trans_loss 5.233 | nll_loss 2.502 | w2v_ctc_loss 1.256 | task_loss 0 | contrastive_loss 0.217 | total 4138.65 | n_correct 2724.65 | ppl 5.66 | accuracy 65.834 | wps 9945.1 | ups 2.4 | wpb 4138.6 | bsz 152.8 | num_updates 35361 | lr 7.5206e-05 | gnorm 1.03 | clip 0 | loss_scale 128 | train_wall 539 | gb_free 16.5 | wall 19527
2023-07-04 09:19:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 09:19:21 | INFO | fairseq.trainer | begin training epoch 25
2023-07-04 09:19:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 09:19:44 | INFO | train_inner | epoch 025:     39 / 1474 loss=4.049, trans_loss=5.217, nll_loss=2.482, w2v_ctc_loss=1.244, task_loss=0, contrastive_loss=0.129, total=4166.95, n_correct=2753.06, ppl=5.59, accuracy=66.069, wps=5593.5, ups=1.34, wpb=4166.9, bsz=156, num_updates=35400, lr=7.51646e-05, gnorm=1.025, clip=0, loss_scale=128, train_wall=36, gb_free=16.8, wall=19550
2023-07-04 09:20:21 | INFO | train_inner | epoch 025:    139 / 1474 loss=4.027, trans_loss=5.197, nll_loss=2.455, w2v_ctc_loss=1.22, task_loss=0, contrastive_loss=0.124, total=4133.64, n_correct=2748.11, ppl=5.48, accuracy=66.482, wps=11252.6, ups=2.72, wpb=4133.6, bsz=153.9, num_updates=35500, lr=7.50587e-05, gnorm=1.018, clip=0, loss_scale=128, train_wall=36, gb_free=16.2, wall=19587
2023-07-04 09:20:58 | INFO | train_inner | epoch 025:    239 / 1474 loss=4.04, trans_loss=5.204, nll_loss=2.463, w2v_ctc_loss=1.247, task_loss=0, contrastive_loss=0.134, total=4114.53, n_correct=2726.92, ppl=5.52, accuracy=66.275, wps=11136.4, ups=2.71, wpb=4114.5, bsz=151.4, num_updates=35600, lr=7.49532e-05, gnorm=1.029, clip=0, loss_scale=128, train_wall=37, gb_free=17.4, wall=19624
2023-07-04 09:21:35 | INFO | train_inner | epoch 025:    339 / 1474 loss=4.052, trans_loss=5.215, nll_loss=2.477, w2v_ctc_loss=1.248, task_loss=0, contrastive_loss=0.191, total=4148.7, n_correct=2738.26, ppl=5.57, accuracy=66.003, wps=11048.3, ups=2.66, wpb=4148.7, bsz=147.6, num_updates=35700, lr=7.48481e-05, gnorm=1.026, clip=0, loss_scale=128, train_wall=37, gb_free=17, wall=19661
2023-07-04 09:21:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-04 09:22:13 | INFO | train_inner | epoch 025:    440 / 1474 loss=4.054, trans_loss=5.218, nll_loss=2.481, w2v_ctc_loss=1.271, task_loss=0, contrastive_loss=0.108, total=4142.33, n_correct=2737.5, ppl=5.58, accuracy=66.086, wps=11083.7, ups=2.68, wpb=4142.3, bsz=144.7, num_updates=35800, lr=7.47435e-05, gnorm=1.036, clip=0, loss_scale=64, train_wall=37, gb_free=16.3, wall=19699
2023-07-04 09:22:50 | INFO | train_inner | epoch 025:    540 / 1474 loss=4.057, trans_loss=5.224, nll_loss=2.49, w2v_ctc_loss=1.253, task_loss=0, contrastive_loss=0.13, total=4160.61, n_correct=2745.17, ppl=5.62, accuracy=65.98, wps=11272.7, ups=2.71, wpb=4160.6, bsz=157, num_updates=35900, lr=7.46393e-05, gnorm=1.031, clip=0, loss_scale=64, train_wall=36, gb_free=17.9, wall=19736
2023-07-04 09:23:27 | INFO | train_inner | epoch 025:    640 / 1474 loss=4.053, trans_loss=5.212, nll_loss=2.475, w2v_ctc_loss=1.243, task_loss=0, contrastive_loss=0.265, total=4153.68, n_correct=2747.16, ppl=5.56, accuracy=66.138, wps=11247.5, ups=2.71, wpb=4153.7, bsz=154.8, num_updates=36000, lr=7.45356e-05, gnorm=1.023, clip=0, loss_scale=64, train_wall=37, gb_free=16.8, wall=19773
2023-07-04 09:23:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 09:23:51 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.334 | trans_loss 5.557 | nll_loss 2.828 | w2v_ctc_loss 1.363 | task_loss 0 | contrastive_loss 0.258 | total 4003.4 | n_correct 2490.1 | ppl 7.1 | accuracy 62.2 | uer 16.699 | wer 18.459 | raw_wer 18.459 | bleu 20.08 | wps 2207.1 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.52
2023-07-04 09:23:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-07-04 09:23:51 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_25_36000.pt
2023-07-04 09:23:54 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_25_36000.pt
2023-07-04 09:23:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 20.08) (writing took 6.5669630146585405 seconds)
2023-07-04 09:24:36 | INFO | train_inner | epoch 025:    740 / 1474 loss=4.063, trans_loss=5.222, nll_loss=2.488, w2v_ctc_loss=1.248, task_loss=0, contrastive_loss=0.259, total=4128.34, n_correct=2724.78, ppl=5.61, accuracy=66.002, wps=5989.3, ups=1.45, wpb=4128.3, bsz=150.6, num_updates=36100, lr=7.44323e-05, gnorm=1.037, clip=0, loss_scale=64, train_wall=37, gb_free=17.4, wall=19842
2023-07-04 09:25:12 | INFO | train_inner | epoch 025:    840 / 1474 loss=4.055, trans_loss=5.222, nll_loss=2.488, w2v_ctc_loss=1.246, task_loss=0, contrastive_loss=0.151, total=4182.4, n_correct=2762.07, ppl=5.61, accuracy=66.04, wps=11364.3, ups=2.72, wpb=4182.4, bsz=163, num_updates=36200, lr=7.43294e-05, gnorm=1.029, clip=0, loss_scale=64, train_wall=36, gb_free=18, wall=19878
2023-07-04 09:25:49 | INFO | train_inner | epoch 025:    940 / 1474 loss=4.061, trans_loss=5.219, nll_loss=2.485, w2v_ctc_loss=1.245, task_loss=0, contrastive_loss=0.266, total=4155.21, n_correct=2744.39, ppl=5.6, accuracy=66.047, wps=11220.3, ups=2.7, wpb=4155.2, bsz=158.5, num_updates=36300, lr=7.4227e-05, gnorm=1.032, clip=0, loss_scale=64, train_wall=37, gb_free=14.6, wall=19915
2023-07-04 09:26:26 | INFO | train_inner | epoch 025:   1040 / 1474 loss=4.09, trans_loss=5.243, nll_loss=2.516, w2v_ctc_loss=1.249, task_loss=0, contrastive_loss=0.483, total=4177.7, n_correct=2745.16, ppl=5.72, accuracy=65.71, wps=11320.8, ups=2.71, wpb=4177.7, bsz=154.9, num_updates=36400, lr=7.41249e-05, gnorm=1.046, clip=0, loss_scale=64, train_wall=36, gb_free=16.1, wall=19952
2023-07-04 09:27:03 | INFO | train_inner | epoch 025:   1140 / 1474 loss=4.057, trans_loss=5.23, nll_loss=2.499, w2v_ctc_loss=1.252, task_loss=0, contrastive_loss=0.1, total=4039.24, n_correct=2662.17, ppl=5.65, accuracy=65.908, wps=11051.6, ups=2.74, wpb=4039.2, bsz=142.6, num_updates=36500, lr=7.40233e-05, gnorm=1.048, clip=0, loss_scale=64, train_wall=36, gb_free=16.8, wall=19989
2023-07-04 09:27:39 | INFO | train_inner | epoch 025:   1240 / 1474 loss=4.056, trans_loss=5.231, nll_loss=2.499, w2v_ctc_loss=1.242, task_loss=0, contrastive_loss=0.117, total=4090.59, n_correct=2692.12, ppl=5.65, accuracy=65.813, wps=11280.4, ups=2.76, wpb=4090.6, bsz=147.8, num_updates=36600, lr=7.39221e-05, gnorm=1.031, clip=0, loss_scale=64, train_wall=36, gb_free=17.6, wall=20025
2023-07-04 09:28:16 | INFO | train_inner | epoch 025:   1340 / 1474 loss=4.073, trans_loss=5.229, nll_loss=2.497, w2v_ctc_loss=1.259, task_loss=0, contrastive_loss=0.31, total=4164.34, n_correct=2745.46, ppl=5.65, accuracy=65.928, wps=11258.9, ups=2.7, wpb=4164.3, bsz=155.1, num_updates=36700, lr=7.38213e-05, gnorm=1.041, clip=0, loss_scale=64, train_wall=37, gb_free=17.3, wall=20062
2023-07-04 09:28:53 | INFO | train_inner | epoch 025:   1440 / 1474 loss=4.077, trans_loss=5.246, nll_loss=2.519, w2v_ctc_loss=1.252, task_loss=0, contrastive_loss=0.208, total=4099.11, n_correct=2690.21, ppl=5.73, accuracy=65.629, wps=11054.1, ups=2.7, wpb=4099.1, bsz=149.7, num_updates=36800, lr=7.3721e-05, gnorm=1.041, clip=0, loss_scale=64, train_wall=37, gb_free=12.9, wall=20099
2023-07-04 09:29:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 09:29:31 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.348 | trans_loss 5.559 | nll_loss 2.834 | w2v_ctc_loss 1.407 | task_loss 0 | contrastive_loss 0.259 | total 4003.4 | n_correct 2485.2 | ppl 7.13 | accuracy 62.077 | uer 16.988 | wer 18.933 | raw_wer 18.933 | bleu 20.14 | wps 2114.6 | wpb 4003.4 | bsz 141.8 | num_updates 36834 | best_bleu 20.52
2023-07-04 09:29:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36834 updates
2023-07-04 09:29:31 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.1402.pt
2023-07-04 09:29:33 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.1402.pt
2023-07-04 09:29:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.1402.pt (epoch 25 @ 36834 updates, score 20.14) (writing took 5.402251484803855 seconds)
2023-07-04 09:29:36 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-07-04 09:29:36 | INFO | train | epoch 025 | loss 4.058 | trans_loss 5.222 | nll_loss 2.487 | w2v_ctc_loss 1.248 | task_loss 0 | contrastive_loss 0.202 | total 4137.25 | n_correct 2731 | ppl 5.61 | accuracy 66.01 | wps 9901.9 | ups 2.39 | wpb 4137.2 | bsz 152.6 | num_updates 36834 | lr 7.36869e-05 | gnorm 1.033 | clip 0 | loss_scale 64 | train_wall 538 | gb_free 14.8 | wall 20142
2023-07-04 09:29:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 09:29:37 | INFO | fairseq.trainer | begin training epoch 26
2023-07-04 09:29:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 09:30:09 | INFO | train_inner | epoch 026:     66 / 1474 loss=4.028, trans_loss=5.191, nll_loss=2.449, w2v_ctc_loss=1.222, task_loss=0, contrastive_loss=0.175, total=4180.21, n_correct=2778.26, ppl=5.46, accuracy=66.462, wps=5540.6, ups=1.33, wpb=4180.2, bsz=159.2, num_updates=36900, lr=7.3621e-05, gnorm=1.024, clip=0, loss_scale=64, train_wall=36, gb_free=17.4, wall=20175
2023-07-04 09:30:46 | INFO | train_inner | epoch 026:    166 / 1474 loss=4.051, trans_loss=5.192, nll_loss=2.45, w2v_ctc_loss=1.209, task_loss=0, contrastive_loss=0.549, total=4270.78, n_correct=2847.42, ppl=5.47, accuracy=66.672, wps=11497.4, ups=2.69, wpb=4270.8, bsz=170.2, num_updates=37000, lr=7.35215e-05, gnorm=1.018, clip=0, loss_scale=64, train_wall=37, gb_free=15.7, wall=20212
2023-07-04 09:31:23 | INFO | train_inner | epoch 026:    266 / 1474 loss=4.04, trans_loss=5.195, nll_loss=2.453, w2v_ctc_loss=1.232, task_loss=0, contrastive_loss=0.291, total=4125.04, n_correct=2739.39, ppl=5.47, accuracy=66.409, wps=11107.9, ups=2.69, wpb=4125, bsz=153.6, num_updates=37100, lr=7.34223e-05, gnorm=1.034, clip=0, loss_scale=64, train_wall=37, gb_free=15.7, wall=20249
2023-07-04 09:32:00 | INFO | train_inner | epoch 026:    366 / 1474 loss=4.04, trans_loss=5.2, nll_loss=2.459, w2v_ctc_loss=1.233, task_loss=0, contrastive_loss=0.209, total=4165.74, n_correct=2763.13, ppl=5.5, accuracy=66.33, wps=11339.3, ups=2.72, wpb=4165.7, bsz=157.3, num_updates=37200, lr=7.33236e-05, gnorm=1.033, clip=0, loss_scale=64, train_wall=36, gb_free=17.2, wall=20286
2023-07-04 09:32:36 | INFO | train_inner | epoch 026:    466 / 1474 loss=4.043, trans_loss=5.197, nll_loss=2.456, w2v_ctc_loss=1.235, task_loss=0, contrastive_loss=0.304, total=4170.23, n_correct=2774.03, ppl=5.49, accuracy=66.52, wps=11332.4, ups=2.72, wpb=4170.2, bsz=157.7, num_updates=37300, lr=7.32252e-05, gnorm=1.031, clip=0, loss_scale=64, train_wall=36, gb_free=18.1, wall=20323
2023-07-04 09:33:14 | INFO | train_inner | epoch 026:    566 / 1474 loss=4.044, trans_loss=5.205, nll_loss=2.465, w2v_ctc_loss=1.253, task_loss=0, contrastive_loss=0.141, total=4155.02, n_correct=2752.16, ppl=5.52, accuracy=66.237, wps=11177.8, ups=2.69, wpb=4155, bsz=151.9, num_updates=37400, lr=7.31272e-05, gnorm=1.035, clip=0, loss_scale=64, train_wall=37, gb_free=18.1, wall=20360
2023-07-04 09:33:51 | INFO | train_inner | epoch 026:    666 / 1474 loss=4.028, trans_loss=5.2, nll_loss=2.459, w2v_ctc_loss=1.219, task_loss=0, contrastive_loss=0.115, total=4136.96, n_correct=2743.27, ppl=5.5, accuracy=66.311, wps=11165.4, ups=2.7, wpb=4137, bsz=149.6, num_updates=37500, lr=7.30297e-05, gnorm=1.036, clip=0, loss_scale=64, train_wall=37, gb_free=15.8, wall=20397
2023-07-04 09:34:27 | INFO | train_inner | epoch 026:    766 / 1474 loss=4.057, trans_loss=5.214, nll_loss=2.476, w2v_ctc_loss=1.229, task_loss=0, contrastive_loss=0.339, total=4086.28, n_correct=2701.41, ppl=5.57, accuracy=66.109, wps=11159.1, ups=2.73, wpb=4086.3, bsz=149.2, num_updates=37600, lr=7.29325e-05, gnorm=1.043, clip=0, loss_scale=64, train_wall=36, gb_free=15.5, wall=20433
2023-07-04 09:35:04 | INFO | train_inner | epoch 026:    866 / 1474 loss=4.041, trans_loss=5.207, nll_loss=2.468, w2v_ctc_loss=1.236, task_loss=0, contrastive_loss=0.142, total=4183.26, n_correct=2770.78, ppl=5.53, accuracy=66.235, wps=11337.4, ups=2.71, wpb=4183.3, bsz=154.1, num_updates=37700, lr=7.28357e-05, gnorm=1.035, clip=0, loss_scale=64, train_wall=36, gb_free=17.7, wall=20470
2023-07-04 09:35:41 | INFO | train_inner | epoch 026:    966 / 1474 loss=4.055, trans_loss=5.221, nll_loss=2.487, w2v_ctc_loss=1.23, task_loss=0, contrastive_loss=0.25, total=4137.96, n_correct=2730, ppl=5.61, accuracy=65.975, wps=11261.9, ups=2.72, wpb=4138, bsz=149.5, num_updates=37800, lr=7.27393e-05, gnorm=1.038, clip=0, loss_scale=64, train_wall=36, gb_free=17.3, wall=20507
2023-07-04 09:36:18 | INFO | train_inner | epoch 026:   1066 / 1474 loss=4.041, trans_loss=5.212, nll_loss=2.475, w2v_ctc_loss=1.236, task_loss=0, contrastive_loss=0.113, total=4120.53, n_correct=2726.35, ppl=5.56, accuracy=66.165, wps=11256.9, ups=2.73, wpb=4120.5, bsz=147.1, num_updates=37900, lr=7.26433e-05, gnorm=1.025, clip=0, loss_scale=128, train_wall=36, gb_free=17, wall=20544
2023-07-04 09:36:55 | INFO | train_inner | epoch 026:   1166 / 1474 loss=4.057, trans_loss=5.222, nll_loss=2.487, w2v_ctc_loss=1.245, task_loss=0, contrastive_loss=0.193, total=4113.86, n_correct=2715.02, ppl=5.61, accuracy=65.997, wps=11038.3, ups=2.68, wpb=4113.9, bsz=149.2, num_updates=38000, lr=7.25476e-05, gnorm=1.026, clip=0, loss_scale=128, train_wall=37, gb_free=17, wall=20581
2023-07-04 09:36:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 09:37:20 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.354 | trans_loss 5.558 | nll_loss 2.83 | w2v_ctc_loss 1.432 | task_loss 0 | contrastive_loss 0.254 | total 4003.4 | n_correct 2487.4 | ppl 7.11 | accuracy 62.132 | uer 16.84 | wer 18.676 | raw_wer 18.676 | bleu 20.05 | wps 2113.1 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.52
2023-07-04 09:37:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-07-04 09:37:20 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_26_38000.pt
2023-07-04 09:37:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_26_38000.pt
2023-07-04 09:37:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 20.05) (writing took 6.44309900701046 seconds)
2023-07-04 09:38:04 | INFO | train_inner | epoch 026:   1266 / 1474 loss=4.068, trans_loss=5.236, nll_loss=2.506, w2v_ctc_loss=1.269, task_loss=0, contrastive_loss=0.119, total=3996.19, n_correct=2624.85, ppl=5.68, accuracy=65.684, wps=5776.5, ups=1.45, wpb=3996.2, bsz=139.6, num_updates=38100, lr=7.24524e-05, gnorm=1.054, clip=0, loss_scale=128, train_wall=36, gb_free=18.1, wall=20650
2023-07-04 09:38:41 | INFO | train_inner | epoch 026:   1366 / 1474 loss=4.052, trans_loss=5.222, nll_loss=2.489, w2v_ctc_loss=1.239, task_loss=0, contrastive_loss=0.144, total=4159.74, n_correct=2750.47, ppl=5.61, accuracy=66.121, wps=11182.1, ups=2.69, wpb=4159.7, bsz=155.7, num_updates=38200, lr=7.23575e-05, gnorm=1.035, clip=0, loss_scale=128, train_wall=37, gb_free=17.6, wall=20687
2023-07-04 09:39:18 | INFO | train_inner | epoch 026:   1466 / 1474 loss=4.042, trans_loss=5.214, nll_loss=2.48, w2v_ctc_loss=1.226, task_loss=0, contrastive_loss=0.132, total=4165.66, n_correct=2757.96, ppl=5.58, accuracy=66.207, wps=11352, ups=2.73, wpb=4165.7, bsz=158.7, num_updates=38300, lr=7.22629e-05, gnorm=1.017, clip=0, loss_scale=128, train_wall=36, gb_free=16.9, wall=20724
2023-07-04 09:39:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 09:39:46 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.326 | trans_loss 5.556 | nll_loss 2.83 | w2v_ctc_loss 1.343 | task_loss 0 | contrastive_loss 0.251 | total 4003.4 | n_correct 2487.9 | ppl 7.11 | accuracy 62.145 | uer 16.667 | wer 18.445 | raw_wer 18.445 | bleu 20.62 | wps 2213.5 | wpb 4003.4 | bsz 141.8 | num_updates 38308 | best_bleu 20.62
2023-07-04 09:39:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38308 updates
2023-07-04 09:39:46 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 09:39:50 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 09:39:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt (epoch 26 @ 38308 updates, score 20.62) (writing took 8.458489014301449 seconds)
2023-07-04 09:39:54 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-07-04 09:39:54 | INFO | train | epoch 026 | loss 4.045 | trans_loss 5.208 | nll_loss 2.47 | w2v_ctc_loss 1.234 | task_loss 0 | contrastive_loss 0.217 | total 4138.65 | n_correct 2741.53 | ppl 5.54 | accuracy 66.242 | wps 9872.2 | ups 2.39 | wpb 4138.6 | bsz 152.8 | num_updates 38308 | lr 7.22554e-05 | gnorm 1.033 | clip 0 | loss_scale 128 | train_wall 538 | gb_free 16.5 | wall 20760
2023-07-04 09:39:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 09:39:55 | INFO | fairseq.trainer | begin training epoch 27
2023-07-04 09:39:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 09:40:36 | INFO | train_inner | epoch 027:     92 / 1474 loss=4.002, trans_loss=5.172, nll_loss=2.422, w2v_ctc_loss=1.208, task_loss=0, contrastive_loss=0.094, total=4054.57, n_correct=2710.27, ppl=5.36, accuracy=66.845, wps=5195.4, ups=1.28, wpb=4054.6, bsz=141.2, num_updates=38400, lr=7.21688e-05, gnorm=1.042, clip=0, loss_scale=128, train_wall=36, gb_free=16.8, wall=20802
2023-07-04 09:41:13 | INFO | train_inner | epoch 027:    192 / 1474 loss=4.009, trans_loss=5.17, nll_loss=2.421, w2v_ctc_loss=1.214, task_loss=0, contrastive_loss=0.15, total=4195.2, n_correct=2805.46, ppl=5.36, accuracy=66.873, wps=11257.4, ups=2.68, wpb=4195.2, bsz=161.6, num_updates=38500, lr=7.2075e-05, gnorm=1.032, clip=0, loss_scale=128, train_wall=37, gb_free=17.5, wall=20839
2023-07-04 09:41:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-04 09:41:51 | INFO | train_inner | epoch 027:    293 / 1474 loss=4.018, trans_loss=5.184, nll_loss=2.438, w2v_ctc_loss=1.222, task_loss=0, contrastive_loss=0.109, total=4157.22, n_correct=2772.09, ppl=5.42, accuracy=66.681, wps=11136.7, ups=2.68, wpb=4157.2, bsz=151.9, num_updates=38600, lr=7.19816e-05, gnorm=1.028, clip=0, loss_scale=64, train_wall=37, gb_free=17.3, wall=20877
2023-07-04 09:42:28 | INFO | train_inner | epoch 027:    393 / 1474 loss=4.059, trans_loss=5.204, nll_loss=2.464, w2v_ctc_loss=1.233, task_loss=0, contrastive_loss=0.482, total=4075.21, n_correct=2704.16, ppl=5.52, accuracy=66.356, wps=10843.6, ups=2.66, wpb=4075.2, bsz=148, num_updates=38700, lr=7.18885e-05, gnorm=1.033, clip=0, loss_scale=64, train_wall=37, gb_free=18, wall=20914
2023-07-04 09:43:05 | INFO | train_inner | epoch 027:    493 / 1474 loss=4.052, trans_loss=5.203, nll_loss=2.464, w2v_ctc_loss=1.229, task_loss=0, contrastive_loss=0.354, total=4249.35, n_correct=2815.37, ppl=5.52, accuracy=66.254, wps=11420.3, ups=2.69, wpb=4249.4, bsz=166, num_updates=38800, lr=7.17958e-05, gnorm=1.025, clip=0, loss_scale=64, train_wall=37, gb_free=12.6, wall=20952
2023-07-04 09:43:42 | INFO | train_inner | epoch 027:    593 / 1474 loss=4.034, trans_loss=5.194, nll_loss=2.453, w2v_ctc_loss=1.219, task_loss=0, contrastive_loss=0.233, total=4133.39, n_correct=2748.43, ppl=5.47, accuracy=66.493, wps=11211.1, ups=2.71, wpb=4133.4, bsz=156, num_updates=38900, lr=7.17035e-05, gnorm=1.047, clip=0, loss_scale=64, train_wall=36, gb_free=12.7, wall=20988
2023-07-04 09:44:19 | INFO | train_inner | epoch 027:    693 / 1474 loss=4.043, trans_loss=5.205, nll_loss=2.466, w2v_ctc_loss=1.237, task_loss=0, contrastive_loss=0.19, total=4162.71, n_correct=2763.26, ppl=5.52, accuracy=66.381, wps=11319.8, ups=2.72, wpb=4162.7, bsz=152.7, num_updates=39000, lr=7.16115e-05, gnorm=1.03, clip=0, loss_scale=64, train_wall=36, gb_free=16.7, wall=21025
2023-07-04 09:44:56 | INFO | train_inner | epoch 027:    793 / 1474 loss=4.033, trans_loss=5.199, nll_loss=2.459, w2v_ctc_loss=1.236, task_loss=0, contrastive_loss=0.12, total=4103.81, n_correct=2726.88, ppl=5.5, accuracy=66.448, wps=11229.7, ups=2.74, wpb=4103.8, bsz=147.1, num_updates=39100, lr=7.15199e-05, gnorm=1.039, clip=0, loss_scale=64, train_wall=36, gb_free=16.9, wall=21062
2023-07-04 09:45:33 | INFO | train_inner | epoch 027:    893 / 1474 loss=4.023, trans_loss=5.199, nll_loss=2.458, w2v_ctc_loss=1.209, task_loss=0, contrastive_loss=0.102, total=4101.56, n_correct=2723.94, ppl=5.49, accuracy=66.412, wps=11050.4, ups=2.69, wpb=4101.6, bsz=146.1, num_updates=39200, lr=7.14286e-05, gnorm=1.05, clip=0, loss_scale=64, train_wall=37, gb_free=18, wall=21099
2023-07-04 09:46:10 | INFO | train_inner | epoch 027:    993 / 1474 loss=4.061, trans_loss=5.208, nll_loss=2.471, w2v_ctc_loss=1.23, task_loss=0, contrastive_loss=0.474, total=4199.56, n_correct=2784.55, ppl=5.55, accuracy=66.306, wps=11270.4, ups=2.68, wpb=4199.6, bsz=158.4, num_updates=39300, lr=7.13376e-05, gnorm=1.035, clip=0, loss_scale=64, train_wall=37, gb_free=12.3, wall=21136
2023-07-04 09:46:47 | INFO | train_inner | epoch 027:   1093 / 1474 loss=4.03, trans_loss=5.198, nll_loss=2.458, w2v_ctc_loss=1.224, task_loss=0, contrastive_loss=0.141, total=4150.97, n_correct=2753.18, ppl=5.49, accuracy=66.326, wps=11227.9, ups=2.7, wpb=4151, bsz=152.5, num_updates=39400, lr=7.1247e-05, gnorm=1.034, clip=0, loss_scale=64, train_wall=37, gb_free=12.6, wall=21173
2023-07-04 09:47:24 | INFO | train_inner | epoch 027:   1193 / 1474 loss=4.038, trans_loss=5.204, nll_loss=2.465, w2v_ctc_loss=1.232, task_loss=0, contrastive_loss=0.147, total=4103.06, n_correct=2719.6, ppl=5.52, accuracy=66.282, wps=11169.4, ups=2.72, wpb=4103.1, bsz=148.8, num_updates=39500, lr=7.11568e-05, gnorm=1.031, clip=0, loss_scale=64, train_wall=36, gb_free=17, wall=21210
2023-07-04 09:48:01 | INFO | train_inner | epoch 027:   1293 / 1474 loss=4.056, trans_loss=5.218, nll_loss=2.483, w2v_ctc_loss=1.237, task_loss=0, contrastive_loss=0.255, total=4062.52, n_correct=2683.23, ppl=5.59, accuracy=66.048, wps=11032.1, ups=2.72, wpb=4062.5, bsz=146.1, num_updates=39600, lr=7.10669e-05, gnorm=1.056, clip=0, loss_scale=64, train_wall=36, gb_free=16.9, wall=21247
2023-07-04 09:48:37 | INFO | train_inner | epoch 027:   1393 / 1474 loss=4.043, trans_loss=5.208, nll_loss=2.471, w2v_ctc_loss=1.222, task_loss=0, contrastive_loss=0.21, total=4152, n_correct=2749.63, ppl=5.55, accuracy=66.224, wps=11408.3, ups=2.75, wpb=4152, bsz=156.2, num_updates=39700, lr=7.09773e-05, gnorm=1.016, clip=0, loss_scale=64, train_wall=36, gb_free=17, wall=21283
2023-07-04 09:49:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 09:49:31 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.343 | trans_loss 5.558 | nll_loss 2.83 | w2v_ctc_loss 1.393 | task_loss 0 | contrastive_loss 0.253 | total 4003.4 | n_correct 2494.1 | ppl 7.11 | accuracy 62.3 | uer 16.882 | wer 18.784 | raw_wer 18.784 | bleu 20.02 | wps 2330 | wpb 4003.4 | bsz 141.8 | num_updates 39781 | best_bleu 20.62
2023-07-04 09:49:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39781 updates
2023-07-04 09:49:31 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_last.pt
2023-07-04 09:49:35 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_last.pt
2023-07-04 09:49:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_last.pt (epoch 27 @ 39781 updates, score 20.02) (writing took 4.264614062849432 seconds)
2023-07-04 09:49:35 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-07-04 09:49:35 | INFO | train | epoch 027 | loss 4.035 | trans_loss 5.197 | nll_loss 2.456 | w2v_ctc_loss 1.224 | task_loss 0 | contrastive_loss 0.216 | total 4138.14 | n_correct 2749.01 | ppl 5.49 | accuracy 66.431 | wps 10498.7 | ups 2.54 | wpb 4138.1 | bsz 152.7 | num_updates 39781 | lr 7.0905e-05 | gnorm 1.035 | clip 0 | loss_scale 64 | train_wall 538 | gb_free 18.1 | wall 21341
2023-07-04 09:49:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 09:49:35 | INFO | fairseq.trainer | begin training epoch 28
2023-07-04 09:49:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 09:49:50 | INFO | train_inner | epoch 028:     19 / 1474 loss=4.016, trans_loss=5.187, nll_loss=2.443, w2v_ctc_loss=1.206, task_loss=0, contrastive_loss=0.12, total=4108.43, n_correct=2735.12, ppl=5.44, accuracy=66.573, wps=5624.5, ups=1.37, wpb=4108.4, bsz=152.6, num_updates=39800, lr=7.08881e-05, gnorm=1.028, clip=0, loss_scale=64, train_wall=36, gb_free=16.7, wall=21356
2023-07-04 09:50:27 | INFO | train_inner | epoch 028:    119 / 1474 loss=4.008, trans_loss=5.172, nll_loss=2.422, w2v_ctc_loss=1.22, task_loss=0, contrastive_loss=0.115, total=4113.41, n_correct=2752.3, ppl=5.36, accuracy=66.91, wps=11092.9, ups=2.7, wpb=4113.4, bsz=147, num_updates=39900, lr=7.07992e-05, gnorm=1.038, clip=0, loss_scale=64, train_wall=37, gb_free=17.4, wall=21393
2023-07-04 09:51:04 | INFO | train_inner | epoch 028:    219 / 1474 loss=3.993, trans_loss=5.161, nll_loss=2.409, w2v_ctc_loss=1.188, task_loss=0, contrastive_loss=0.129, total=4191.56, n_correct=2813.98, ppl=5.31, accuracy=67.134, wps=11385, ups=2.72, wpb=4191.6, bsz=157.6, num_updates=40000, lr=7.07107e-05, gnorm=1.021, clip=0, loss_scale=64, train_wall=36, gb_free=15.6, wall=21430
2023-07-04 09:51:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 09:51:28 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.35 | trans_loss 5.566 | nll_loss 2.842 | w2v_ctc_loss 1.397 | task_loss 0 | contrastive_loss 0.255 | total 4003.4 | n_correct 2484.4 | ppl 7.17 | accuracy 62.057 | uer 16.72 | wer 18.452 | raw_wer 18.452 | bleu 20.43 | wps 2271.2 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.62
2023-07-04 09:51:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-07-04 09:51:28 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_28_40000.pt
2023-07-04 09:51:30 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_28_40000.pt
2023-07-04 09:51:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 20.43) (writing took 6.435194455087185 seconds)
tensor(0.0295, device='cuda:0')
tensor(0.0009, device='cuda:0')
2023-07-04 09:52:13 | INFO | train_inner | epoch 028:    319 / 1474 loss=4.06, trans_loss=5.191, nll_loss=2.449, w2v_ctc_loss=1.197, task_loss=0, contrastive_loss=0.789, total=4145.32, n_correct=2755.61, ppl=5.46, accuracy=66.475, wps=6020.9, ups=1.45, wpb=4145.3, bsz=158.1, num_updates=40100, lr=7.06225e-05, gnorm=1.045, clip=0, loss_scale=64, train_wall=37, gb_free=16.2, wall=21499
2023-07-04 09:52:49 | INFO | train_inner | epoch 028:    419 / 1474 loss=4.021, trans_loss=5.186, nll_loss=2.44, w2v_ctc_loss=1.232, task_loss=0, contrastive_loss=0.105, total=4092.14, n_correct=2724.54, ppl=5.43, accuracy=66.58, wps=11209.2, ups=2.74, wpb=4092.1, bsz=147.8, num_updates=40200, lr=7.05346e-05, gnorm=1.059, clip=0, loss_scale=64, train_wall=36, gb_free=16.8, wall=21535
2023-07-04 09:53:26 | INFO | train_inner | epoch 028:    519 / 1474 loss=4.008, trans_loss=5.176, nll_loss=2.429, w2v_ctc_loss=1.205, task_loss=0, contrastive_loss=0.128, total=4096.35, n_correct=2734.77, ppl=5.38, accuracy=66.761, wps=11159.4, ups=2.72, wpb=4096.4, bsz=147.8, num_updates=40300, lr=7.0447e-05, gnorm=1.027, clip=0, loss_scale=64, train_wall=36, gb_free=16.4, wall=21572
2023-07-04 09:54:03 | INFO | train_inner | epoch 028:    619 / 1474 loss=4.021, trans_loss=5.19, nll_loss=2.446, w2v_ctc_loss=1.217, task_loss=0, contrastive_loss=0.127, total=4178.12, n_correct=2780.89, ppl=5.45, accuracy=66.558, wps=11402.4, ups=2.73, wpb=4178.1, bsz=152.7, num_updates=40400, lr=7.03598e-05, gnorm=1.024, clip=0, loss_scale=64, train_wall=36, gb_free=16.3, wall=21609
2023-07-04 09:54:39 | INFO | train_inner | epoch 028:    719 / 1474 loss=4.043, trans_loss=5.195, nll_loss=2.455, w2v_ctc_loss=1.218, task_loss=0, contrastive_loss=0.349, total=4185.82, n_correct=2783.24, ppl=5.48, accuracy=66.492, wps=11427.5, ups=2.73, wpb=4185.8, bsz=163.2, num_updates=40500, lr=7.02728e-05, gnorm=1.04, clip=0, loss_scale=64, train_wall=36, gb_free=16.3, wall=21645
2023-07-04 09:55:16 | INFO | train_inner | epoch 028:    819 / 1474 loss=4.015, trans_loss=5.184, nll_loss=2.439, w2v_ctc_loss=1.211, task_loss=0, contrastive_loss=0.115, total=4096.2, n_correct=2732.55, ppl=5.42, accuracy=66.709, wps=11222.1, ups=2.74, wpb=4096.2, bsz=153.5, num_updates=40600, lr=7.01862e-05, gnorm=1.049, clip=0, loss_scale=64, train_wall=36, gb_free=16.2, wall=21682
2023-07-04 09:55:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-04 09:55:54 | INFO | train_inner | epoch 028:    920 / 1474 loss=4.037, trans_loss=5.198, nll_loss=2.457, w2v_ctc_loss=1.223, task_loss=0, contrastive_loss=0.235, total=4108.24, n_correct=2729.27, ppl=5.49, accuracy=66.434, wps=10852.9, ups=2.64, wpb=4108.2, bsz=148.8, num_updates=40700, lr=7.01e-05, gnorm=1.038, clip=0, loss_scale=64, train_wall=37, gb_free=15.8, wall=21720
2023-07-04 09:56:31 | INFO | train_inner | epoch 028:   1020 / 1474 loss=4.049, trans_loss=5.199, nll_loss=2.46, w2v_ctc_loss=1.23, task_loss=0, contrastive_loss=0.339, total=4182.85, n_correct=2776.39, ppl=5.5, accuracy=66.376, wps=11320.5, ups=2.71, wpb=4182.9, bsz=156, num_updates=40800, lr=7.0014e-05, gnorm=1.039, clip=0, loss_scale=64, train_wall=37, gb_free=16.9, wall=21757
2023-07-04 09:57:08 | INFO | train_inner | epoch 028:   1120 / 1474 loss=4.016, trans_loss=5.181, nll_loss=2.436, w2v_ctc_loss=1.208, task_loss=0, contrastive_loss=0.154, total=4220.16, n_correct=2813.89, ppl=5.41, accuracy=66.677, wps=11389.5, ups=2.7, wpb=4220.2, bsz=160.5, num_updates=40900, lr=6.99284e-05, gnorm=1.021, clip=0, loss_scale=64, train_wall=37, gb_free=16.6, wall=21794
2023-07-04 09:57:44 | INFO | train_inner | epoch 028:   1220 / 1474 loss=4.02, trans_loss=5.192, nll_loss=2.45, w2v_ctc_loss=1.205, task_loss=0, contrastive_loss=0.127, total=4092.46, n_correct=2722.33, ppl=5.46, accuracy=66.521, wps=11191.3, ups=2.73, wpb=4092.5, bsz=151.5, num_updates=41000, lr=6.9843e-05, gnorm=1.038, clip=0, loss_scale=64, train_wall=36, gb_free=18, wall=21830
2023-07-04 09:58:21 | INFO | train_inner | epoch 028:   1320 / 1474 loss=4.041, trans_loss=5.205, nll_loss=2.465, w2v_ctc_loss=1.24, task_loss=0, contrastive_loss=0.158, total=4084.55, n_correct=2705.73, ppl=5.52, accuracy=66.243, wps=11056.3, ups=2.71, wpb=4084.6, bsz=142.6, num_updates=41100, lr=6.9758e-05, gnorm=1.048, clip=0, loss_scale=64, train_wall=37, gb_free=16.2, wall=21867
2023-07-04 09:58:58 | INFO | train_inner | epoch 028:   1420 / 1474 loss=4.045, trans_loss=5.206, nll_loss=2.467, w2v_ctc_loss=1.239, task_loss=0, contrastive_loss=0.204, total=4154.09, n_correct=2752.66, ppl=5.53, accuracy=66.264, wps=11222.1, ups=2.7, wpb=4154.1, bsz=149.7, num_updates=41200, lr=6.96733e-05, gnorm=1.039, clip=0, loss_scale=64, train_wall=37, gb_free=16.4, wall=21904
2023-07-04 09:59:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0295, device='cuda:4')
tensor(0.0009, device='cuda:4')
tensor(0.0295, device='cuda:3')
tensor(0.0009, device='cuda:3')
tensor(0.0295, device='cuda:6')
tensor(0.0009, device='cuda:6')
tensor(0.0295, device='cuda:5')
tensor(0.0009, device='cuda:5')
tensor(0.0295, device='cuda:7')
tensor(0.0009, device='cuda:7')
tensor(0.0295, device='cuda:2')
tensor(0.0009, device='cuda:2')
tensor(0.0295, device='cuda:1')
tensor(0.0009, device='cuda:1')
2023-07-04 09:59:42 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.342 | trans_loss 5.559 | nll_loss 2.831 | w2v_ctc_loss 1.383 | task_loss 0 | contrastive_loss 0.258 | total 4003.4 | n_correct 2492.2 | ppl 7.12 | accuracy 62.252 | uer 16.805 | wer 18.646 | raw_wer 18.646 | bleu 20.32 | wps 2325.6 | wpb 4003.4 | bsz 141.8 | num_updates 41254 | best_bleu 20.62
2023-07-04 09:59:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41254 updates
2023-07-04 09:59:42 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.3200.pt
2023-07-04 09:59:45 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.3200.pt
2023-07-04 09:59:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.3200.pt (epoch 28 @ 41254 updates, score 20.32) (writing took 5.36582871992141 seconds)
2023-07-04 09:59:48 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-07-04 09:59:48 | INFO | train | epoch 028 | loss 4.026 | trans_loss 5.187 | nll_loss 2.444 | w2v_ctc_loss 1.217 | task_loss 0 | contrastive_loss 0.218 | total 4138.15 | n_correct 2755.67 | ppl 5.44 | accuracy 66.592 | wps 9944.5 | ups 2.4 | wpb 4138.1 | bsz 152.8 | num_updates 41254 | lr 6.96277e-05 | gnorm 1.037 | clip 0 | loss_scale 64 | train_wall 537 | gb_free 17 | wall 21954
2023-07-04 09:59:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 09:59:48 | INFO | fairseq.trainer | begin training epoch 29
2023-07-04 09:59:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 10:00:13 | INFO | train_inner | epoch 029:     46 / 1474 loss=4.007, trans_loss=5.166, nll_loss=2.416, w2v_ctc_loss=1.214, task_loss=0, contrastive_loss=0.153, total=4169.12, n_correct=2791.55, ppl=5.34, accuracy=66.958, wps=5542.1, ups=1.33, wpb=4169.1, bsz=158.2, num_updates=41300, lr=6.95889e-05, gnorm=1.034, clip=0, loss_scale=64, train_wall=37, gb_free=16.8, wall=21980
2023-07-04 10:00:50 | INFO | train_inner | epoch 029:    146 / 1474 loss=4.01, trans_loss=5.172, nll_loss=2.422, w2v_ctc_loss=1.203, task_loss=0, contrastive_loss=0.185, total=4105.72, n_correct=2744.11, ppl=5.36, accuracy=66.836, wps=11078.3, ups=2.7, wpb=4105.7, bsz=152, num_updates=41400, lr=6.95048e-05, gnorm=1.048, clip=0, loss_scale=64, train_wall=37, gb_free=16.4, wall=22017
2023-07-04 10:01:28 | INFO | train_inner | epoch 029:    246 / 1474 loss=4.007, trans_loss=5.158, nll_loss=2.407, w2v_ctc_loss=1.179, task_loss=0, contrastive_loss=0.355, total=4199.67, n_correct=2818.32, ppl=5.3, accuracy=67.108, wps=11217.7, ups=2.67, wpb=4199.7, bsz=165.3, num_updates=41500, lr=6.9421e-05, gnorm=1.022, clip=0, loss_scale=64, train_wall=37, gb_free=16.1, wall=22054
2023-07-04 10:02:05 | INFO | train_inner | epoch 029:    346 / 1474 loss=4.023, trans_loss=5.186, nll_loss=2.441, w2v_ctc_loss=1.233, task_loss=0, contrastive_loss=0.119, total=4095.17, n_correct=2728.71, ppl=5.43, accuracy=66.632, wps=11133.1, ups=2.72, wpb=4095.2, bsz=145.6, num_updates=41600, lr=6.93375e-05, gnorm=1.044, clip=0, loss_scale=64, train_wall=36, gb_free=17, wall=22091
2023-07-04 10:02:42 | INFO | train_inner | epoch 029:    446 / 1474 loss=3.982, trans_loss=5.15, nll_loss=2.394, w2v_ctc_loss=1.183, task_loss=0, contrastive_loss=0.108, total=4157.44, n_correct=2794.15, ppl=5.26, accuracy=67.208, wps=11263.8, ups=2.71, wpb=4157.4, bsz=153.9, num_updates=41700, lr=6.92543e-05, gnorm=1.029, clip=0, loss_scale=64, train_wall=37, gb_free=16.9, wall=22128
2023-07-04 10:02:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-04 10:03:19 | INFO | train_inner | epoch 029:    547 / 1474 loss=4.027, trans_loss=5.189, nll_loss=2.444, w2v_ctc_loss=1.222, task_loss=0, contrastive_loss=0.186, total=4136.1, n_correct=2751.05, ppl=5.44, accuracy=66.513, wps=11068.5, ups=2.68, wpb=4136.1, bsz=144.6, num_updates=41800, lr=6.91714e-05, gnorm=1.039, clip=0, loss_scale=32, train_wall=37, gb_free=15.8, wall=22165
2023-07-04 10:03:56 | INFO | train_inner | epoch 029:    647 / 1474 loss=4.023, trans_loss=5.172, nll_loss=2.425, w2v_ctc_loss=1.196, task_loss=0, contrastive_loss=0.437, total=4145.39, n_correct=2769.61, ppl=5.37, accuracy=66.812, wps=11309.6, ups=2.73, wpb=4145.4, bsz=159.6, num_updates=41900, lr=6.90889e-05, gnorm=1.045, clip=0, loss_scale=32, train_wall=36, gb_free=17.7, wall=22202
2023-07-04 10:04:33 | INFO | train_inner | epoch 029:    747 / 1474 loss=4.014, trans_loss=5.17, nll_loss=2.422, w2v_ctc_loss=1.193, task_loss=0, contrastive_loss=0.28, total=4242.46, n_correct=2837.01, ppl=5.36, accuracy=66.872, wps=11491.3, ups=2.71, wpb=4242.5, bsz=164.9, num_updates=42000, lr=6.90066e-05, gnorm=1.017, clip=0, loss_scale=32, train_wall=37, gb_free=17, wall=22239
2023-07-04 10:04:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 10:04:59 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.368 | trans_loss 5.564 | nll_loss 2.842 | w2v_ctc_loss 1.457 | task_loss 0 | contrastive_loss 0.264 | total 4003.4 | n_correct 2481.5 | ppl 7.17 | accuracy 61.985 | uer 17.055 | wer 18.918 | raw_wer 18.918 | bleu 20.22 | wps 1997.2 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.62
2023-07-04 10:04:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-07-04 10:04:59 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_29_42000.pt
2023-07-04 10:05:01 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_29_42000.pt
2023-07-04 10:05:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 20.22) (writing took 6.28624918917194 seconds)
2023-07-04 10:05:42 | INFO | train_inner | epoch 029:    847 / 1474 loss=4.024, trans_loss=5.196, nll_loss=2.454, w2v_ctc_loss=1.216, task_loss=0, contrastive_loss=0.108, total=4027.03, n_correct=2673.12, ppl=5.48, accuracy=66.379, wps=5815, ups=1.44, wpb=4027, bsz=140.2, num_updates=42100, lr=6.89246e-05, gnorm=1.057, clip=0, loss_scale=32, train_wall=36, gb_free=17.7, wall=22308
2023-07-04 10:06:19 | INFO | train_inner | epoch 029:    947 / 1474 loss=4.022, trans_loss=5.19, nll_loss=2.448, w2v_ctc_loss=1.216, task_loss=0, contrastive_loss=0.127, total=4086.72, n_correct=2717.53, ppl=5.45, accuracy=66.497, wps=11127.3, ups=2.72, wpb=4086.7, bsz=148.2, num_updates=42200, lr=6.88428e-05, gnorm=1.049, clip=0, loss_scale=32, train_wall=36, gb_free=15.8, wall=22345
2023-07-04 10:06:55 | INFO | train_inner | epoch 029:   1047 / 1474 loss=4.011, trans_loss=5.172, nll_loss=2.425, w2v_ctc_loss=1.191, task_loss=0, contrastive_loss=0.277, total=4139.4, n_correct=2768.48, ppl=5.37, accuracy=66.881, wps=11350.6, ups=2.74, wpb=4139.4, bsz=153.7, num_updates=42300, lr=6.87614e-05, gnorm=1.048, clip=0, loss_scale=32, train_wall=36, gb_free=16, wall=22381
2023-07-04 10:07:32 | INFO | train_inner | epoch 029:   1147 / 1474 loss=4.021, trans_loss=5.189, nll_loss=2.446, w2v_ctc_loss=1.222, task_loss=0, contrastive_loss=0.1, total=4072.33, n_correct=2708.76, ppl=5.45, accuracy=66.516, wps=11073.3, ups=2.72, wpb=4072.3, bsz=142, num_updates=42400, lr=6.86803e-05, gnorm=1.043, clip=0, loss_scale=32, train_wall=36, gb_free=17.3, wall=22418
2023-07-04 10:08:09 | INFO | train_inner | epoch 029:   1247 / 1474 loss=4.019, trans_loss=5.188, nll_loss=2.444, w2v_ctc_loss=1.215, task_loss=0, contrastive_loss=0.115, total=4160.52, n_correct=2767.3, ppl=5.44, accuracy=66.513, wps=11332.6, ups=2.72, wpb=4160.5, bsz=150.8, num_updates=42500, lr=6.85994e-05, gnorm=1.031, clip=0, loss_scale=32, train_wall=36, gb_free=16, wall=22455
2023-07-04 10:08:46 | INFO | train_inner | epoch 029:   1347 / 1474 loss=4.018, trans_loss=5.18, nll_loss=2.434, w2v_ctc_loss=1.197, task_loss=0, contrastive_loss=0.241, total=4168.02, n_correct=2782.7, ppl=5.41, accuracy=66.763, wps=11231.2, ups=2.69, wpb=4168, bsz=155.1, num_updates=42600, lr=6.85189e-05, gnorm=1.033, clip=0, loss_scale=32, train_wall=37, gb_free=16.9, wall=22492
2023-07-04 10:09:22 | INFO | train_inner | epoch 029:   1447 / 1474 loss=4.026, trans_loss=5.181, nll_loss=2.438, w2v_ctc_loss=1.21, task_loss=0, contrastive_loss=0.302, total=4166.06, n_correct=2776.99, ppl=5.42, accuracy=66.657, wps=11390.3, ups=2.73, wpb=4166.1, bsz=156.6, num_updates=42700, lr=6.84386e-05, gnorm=1.03, clip=0, loss_scale=32, train_wall=36, gb_free=17.3, wall=22528
2023-07-04 10:09:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 10:09:56 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.351 | trans_loss 5.555 | nll_loss 2.827 | w2v_ctc_loss 1.42 | task_loss 0 | contrastive_loss 0.263 | total 4003.4 | n_correct 2490 | ppl 7.1 | accuracy 62.197 | uer 16.707 | wer 18.482 | raw_wer 18.482 | bleu 20.67 | wps 2276.1 | wpb 4003.4 | bsz 141.8 | num_updates 42727 | best_bleu 20.67
2023-07-04 10:09:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42727 updates
2023-07-04 10:09:56 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 10:10:01 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt
2023-07-04 10:10:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_best.pt (epoch 29 @ 42727 updates, score 20.67) (writing took 8.748526235111058 seconds)
2023-07-04 10:10:05 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-07-04 10:10:05 | INFO | train | epoch 029 | loss 4.015 | trans_loss 5.177 | nll_loss 2.43 | w2v_ctc_loss 1.205 | task_loss 0 | contrastive_loss 0.211 | total 4137.69 | n_correct 2761.65 | ppl 5.39 | accuracy 66.744 | wps 9868.7 | ups 2.39 | wpb 4137.7 | bsz 152.7 | num_updates 42727 | lr 6.8417e-05 | gnorm 1.038 | clip 0 | loss_scale 32 | train_wall 537 | gb_free 16.7 | wall 22572
2023-07-04 10:10:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 10:10:06 | INFO | fairseq.trainer | begin training epoch 30
2023-07-04 10:10:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 10:10:41 | INFO | train_inner | epoch 030:     73 / 1474 loss=3.998, trans_loss=5.155, nll_loss=2.401, w2v_ctc_loss=1.172, task_loss=0, contrastive_loss=0.333, total=4175.11, n_correct=2801.45, ppl=5.28, accuracy=67.099, wps=5327.2, ups=1.28, wpb=4175.1, bsz=159.3, num_updates=42800, lr=6.83586e-05, gnorm=1.041, clip=0, loss_scale=32, train_wall=36, gb_free=17.5, wall=22607
2023-07-04 10:11:18 | INFO | train_inner | epoch 030:    173 / 1474 loss=3.984, trans_loss=5.141, nll_loss=2.383, w2v_ctc_loss=1.184, task_loss=0, contrastive_loss=0.196, total=4202.64, n_correct=2837.02, ppl=5.22, accuracy=67.506, wps=11295.9, ups=2.69, wpb=4202.6, bsz=159.2, num_updates=42900, lr=6.82789e-05, gnorm=1.019, clip=0, loss_scale=32, train_wall=37, gb_free=17.1, wall=22644
2023-07-04 10:11:55 | INFO | train_inner | epoch 030:    273 / 1474 loss=3.995, trans_loss=5.158, nll_loss=2.404, w2v_ctc_loss=1.208, task_loss=0, contrastive_loss=0.106, total=4120.21, n_correct=2766.86, ppl=5.29, accuracy=67.153, wps=11233.6, ups=2.73, wpb=4120.2, bsz=147.5, num_updates=43000, lr=6.81994e-05, gnorm=1.049, clip=0, loss_scale=32, train_wall=36, gb_free=15.8, wall=22681
2023-07-04 10:12:32 | INFO | train_inner | epoch 030:    373 / 1474 loss=3.977, trans_loss=5.143, nll_loss=2.384, w2v_ctc_loss=1.179, task_loss=0, contrastive_loss=0.115, total=4178.23, n_correct=2814.56, ppl=5.22, accuracy=67.362, wps=11256.8, ups=2.69, wpb=4178.2, bsz=153.8, num_updates=43100, lr=6.81203e-05, gnorm=1.023, clip=0, loss_scale=32, train_wall=37, gb_free=10.8, wall=22718
2023-07-04 10:13:08 | INFO | train_inner | epoch 030:    473 / 1474 loss=3.999, trans_loss=5.157, nll_loss=2.404, w2v_ctc_loss=1.187, task_loss=0, contrastive_loss=0.243, total=4124.47, n_correct=2767.08, ppl=5.29, accuracy=67.089, wps=11333.7, ups=2.75, wpb=4124.5, bsz=156.3, num_updates=43200, lr=6.80414e-05, gnorm=1.042, clip=0, loss_scale=32, train_wall=36, gb_free=17.9, wall=22754
2023-07-04 10:13:45 | INFO | train_inner | epoch 030:    573 / 1474 loss=3.999, trans_loss=5.164, nll_loss=2.414, w2v_ctc_loss=1.189, task_loss=0, contrastive_loss=0.164, total=4168.41, n_correct=2794.3, ppl=5.33, accuracy=67.035, wps=11391.4, ups=2.73, wpb=4168.4, bsz=156.2, num_updates=43300, lr=6.79628e-05, gnorm=1.027, clip=0, loss_scale=32, train_wall=36, gb_free=17.6, wall=22791
2023-07-04 10:14:21 | INFO | train_inner | epoch 030:    673 / 1474 loss=4.008, trans_loss=5.168, nll_loss=2.419, w2v_ctc_loss=1.203, task_loss=0, contrastive_loss=0.19, total=4187.95, n_correct=2801.04, ppl=5.35, accuracy=66.883, wps=11397.5, ups=2.72, wpb=4187.9, bsz=157.5, num_updates=43400, lr=6.78844e-05, gnorm=1.041, clip=0, loss_scale=32, train_wall=36, gb_free=16.3, wall=22827
2023-07-04 10:14:59 | INFO | train_inner | epoch 030:    773 / 1474 loss=4.032, trans_loss=5.184, nll_loss=2.439, w2v_ctc_loss=1.209, task_loss=0, contrastive_loss=0.35, total=4105.32, n_correct=2733.71, ppl=5.42, accuracy=66.589, wps=11020.5, ups=2.68, wpb=4105.3, bsz=151.3, num_updates=43500, lr=6.78064e-05, gnorm=1.057, clip=0, loss_scale=32, train_wall=37, gb_free=13.6, wall=22865
2023-07-04 10:15:35 | INFO | train_inner | epoch 030:    873 / 1474 loss=4.007, trans_loss=5.174, nll_loss=2.426, w2v_ctc_loss=1.201, task_loss=0, contrastive_loss=0.139, total=4102.11, n_correct=2740.1, ppl=5.38, accuracy=66.797, wps=11178.1, ups=2.72, wpb=4102.1, bsz=147.8, num_updates=43600, lr=6.77285e-05, gnorm=1.052, clip=0, loss_scale=32, train_wall=36, gb_free=17.8, wall=22901
2023-07-04 10:16:12 | INFO | train_inner | epoch 030:    973 / 1474 loss=4.013, trans_loss=5.179, nll_loss=2.432, w2v_ctc_loss=1.209, task_loss=0, contrastive_loss=0.141, total=4129.98, n_correct=2753.64, ppl=5.4, accuracy=66.674, wps=11266.6, ups=2.73, wpb=4130, bsz=150.2, num_updates=43700, lr=6.7651e-05, gnorm=1.037, clip=0, loss_scale=32, train_wall=36, gb_free=17.1, wall=22938
2023-07-04 10:16:49 | INFO | train_inner | epoch 030:   1073 / 1474 loss=4.026, trans_loss=5.189, nll_loss=2.445, w2v_ctc_loss=1.204, task_loss=0, contrastive_loss=0.294, total=4101.17, n_correct=2728.41, ppl=5.45, accuracy=66.528, wps=10970.3, ups=2.67, wpb=4101.2, bsz=141.2, num_updates=43800, lr=6.75737e-05, gnorm=1.048, clip=0, loss_scale=64, train_wall=37, gb_free=16.1, wall=22975
2023-07-04 10:17:26 | INFO | train_inner | epoch 030:   1173 / 1474 loss=4.008, trans_loss=5.17, nll_loss=2.423, w2v_ctc_loss=1.185, task_loss=0, contrastive_loss=0.256, total=4168.36, n_correct=2784.91, ppl=5.36, accuracy=66.811, wps=11238.7, ups=2.7, wpb=4168.4, bsz=157, num_updates=43900, lr=6.74967e-05, gnorm=1.037, clip=0, loss_scale=64, train_wall=37, gb_free=16.4, wall=23013
2023-07-04 10:18:04 | INFO | train_inner | epoch 030:   1273 / 1474 loss=4.02, trans_loss=5.186, nll_loss=2.442, w2v_ctc_loss=1.221, task_loss=0, contrastive_loss=0.126, total=4036.17, n_correct=2687.16, ppl=5.43, accuracy=66.577, wps=10852, ups=2.69, wpb=4036.2, bsz=142.1, num_updates=44000, lr=6.742e-05, gnorm=1.058, clip=0, loss_scale=64, train_wall=37, gb_free=16.2, wall=23050
2023-07-04 10:18:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 10:18:29 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.347 | trans_loss 5.554 | nll_loss 2.826 | w2v_ctc_loss 1.413 | task_loss 0 | contrastive_loss 0.258 | total 4003.4 | n_correct 2490.6 | ppl 7.09 | accuracy 62.212 | uer 16.606 | wer 18.277 | raw_wer 18.277 | bleu 20.41 | wps 2096.4 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.67
2023-07-04 10:18:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-07-04 10:18:29 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_30_44000.pt
2023-07-04 10:18:32 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_30_44000.pt
2023-07-04 10:18:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 20.41) (writing took 6.339507263153791 seconds)
2023-07-04 10:19:13 | INFO | train_inner | epoch 030:   1373 / 1474 loss=3.994, trans_loss=5.16, nll_loss=2.41, w2v_ctc_loss=1.184, task_loss=0, contrastive_loss=0.145, total=4165.07, n_correct=2791.76, ppl=5.32, accuracy=67.028, wps=6008.3, ups=1.44, wpb=4165.1, bsz=160.8, num_updates=44100, lr=6.73435e-05, gnorm=1.029, clip=0, loss_scale=64, train_wall=36, gb_free=17.1, wall=23119
2023-07-04 10:19:49 | INFO | train_inner | epoch 030:   1473 / 1474 loss=4.023, trans_loss=5.176, nll_loss=2.431, w2v_ctc_loss=1.186, task_loss=0, contrastive_loss=0.439, total=4141.76, n_correct=2763.92, ppl=5.39, accuracy=66.733, wps=11388.8, ups=2.75, wpb=4141.8, bsz=157.2, num_updates=44200, lr=6.72673e-05, gnorm=1.039, clip=0, loss_scale=64, train_wall=36, gb_free=16.8, wall=23155
2023-07-04 10:19:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 10:20:14 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.346 | trans_loss 5.556 | nll_loss 2.828 | w2v_ctc_loss 1.405 | task_loss 0 | contrastive_loss 0.261 | total 4003.4 | n_correct 2491.2 | ppl 7.1 | accuracy 62.227 | uer 16.792 | wer 18.705 | raw_wer 18.705 | bleu 20.26 | wps 2292.2 | wpb 4003.4 | bsz 141.8 | num_updates 44201 | best_bleu 20.67
2023-07-04 10:20:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44201 updates
2023-07-04 10:20:14 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.2603.pt
2023-07-04 10:20:16 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.2603.pt
2023-07-04 10:20:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.2603.pt (epoch 30 @ 44201 updates, score 20.26) (writing took 5.367819897830486 seconds)
2023-07-04 10:20:19 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-07-04 10:20:19 | INFO | train | epoch 030 | loss 4.005 | trans_loss 5.167 | nll_loss 2.417 | w2v_ctc_loss 1.194 | task_loss 0 | contrastive_loss 0.218 | total 4138.65 | n_correct 2769.99 | ppl 5.34 | accuracy 66.93 | wps 9934.7 | ups 2.4 | wpb 4138.6 | bsz 152.8 | num_updates 44201 | lr 6.72665e-05 | gnorm 1.04 | clip 0 | loss_scale 64 | train_wall 537 | gb_free 17.5 | wall 23186
2023-07-04 10:20:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 10:20:20 | INFO | fairseq.trainer | begin training epoch 31
2023-07-04 10:20:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 10:21:05 | INFO | train_inner | epoch 031:     99 / 1474 loss=3.991, trans_loss=5.151, nll_loss=2.396, w2v_ctc_loss=1.208, task_loss=0, contrastive_loss=0.114, total=4054.44, n_correct=2728.03, ppl=5.26, accuracy=67.285, wps=5395.1, ups=1.33, wpb=4054.4, bsz=144.1, num_updates=44300, lr=6.71913e-05, gnorm=1.05, clip=0, loss_scale=64, train_wall=36, gb_free=16.9, wall=23231
2023-07-04 10:21:42 | INFO | train_inner | epoch 031:    199 / 1474 loss=3.99, trans_loss=5.15, nll_loss=2.395, w2v_ctc_loss=1.192, task_loss=0, contrastive_loss=0.172, total=4147.4, n_correct=2785.95, ppl=5.26, accuracy=67.173, wps=11193.6, ups=2.7, wpb=4147.4, bsz=151.1, num_updates=44400, lr=6.71156e-05, gnorm=1.04, clip=0, loss_scale=64, train_wall=37, gb_free=17.1, wall=23268
2023-07-04 10:22:19 | INFO | train_inner | epoch 031:    299 / 1474 loss=3.994, trans_loss=5.151, nll_loss=2.396, w2v_ctc_loss=1.186, task_loss=0, contrastive_loss=0.248, total=4149.21, n_correct=2789.84, ppl=5.26, accuracy=67.238, wps=11183.3, ups=2.7, wpb=4149.2, bsz=150.8, num_updates=44500, lr=6.70402e-05, gnorm=1.034, clip=0, loss_scale=64, train_wall=37, gb_free=16.6, wall=23305
2023-07-04 10:22:55 | INFO | train_inner | epoch 031:    399 / 1474 loss=3.988, trans_loss=5.157, nll_loss=2.404, w2v_ctc_loss=1.184, task_loss=0, contrastive_loss=0.12, total=4092.62, n_correct=2744.75, ppl=5.29, accuracy=67.066, wps=11156.9, ups=2.73, wpb=4092.6, bsz=142.8, num_updates=44600, lr=6.6965e-05, gnorm=1.05, clip=0, loss_scale=64, train_wall=36, gb_free=17.5, wall=23341
2023-07-04 10:23:32 | INFO | train_inner | epoch 031:    499 / 1474 loss=3.986, trans_loss=5.148, nll_loss=2.393, w2v_ctc_loss=1.193, task_loss=0, contrastive_loss=0.137, total=4111.85, n_correct=2763.61, ppl=5.25, accuracy=67.211, wps=11176.5, ups=2.72, wpb=4111.9, bsz=150.1, num_updates=44700, lr=6.689e-05, gnorm=1.031, clip=0, loss_scale=64, train_wall=36, gb_free=11.7, wall=23378
2023-07-04 10:24:09 | INFO | train_inner | epoch 031:    599 / 1474 loss=3.991, trans_loss=5.156, nll_loss=2.403, w2v_ctc_loss=1.192, task_loss=0, contrastive_loss=0.122, total=4083.44, n_correct=2742.21, ppl=5.29, accuracy=67.154, wps=11154.5, ups=2.73, wpb=4083.4, bsz=147.3, num_updates=44800, lr=6.68153e-05, gnorm=1.046, clip=0, loss_scale=64, train_wall=36, gb_free=17.1, wall=23415
2023-07-04 10:24:46 | INFO | train_inner | epoch 031:    699 / 1474 loss=3.976, trans_loss=5.145, nll_loss=2.388, w2v_ctc_loss=1.168, task_loss=0, contrastive_loss=0.122, total=4213.98, n_correct=2833.64, ppl=5.24, accuracy=67.244, wps=11274.1, ups=2.68, wpb=4214, bsz=157.8, num_updates=44900, lr=6.67409e-05, gnorm=1.03, clip=0, loss_scale=64, train_wall=37, gb_free=16.8, wall=23452
2023-07-04 10:25:23 | INFO | train_inner | epoch 031:    799 / 1474 loss=4.006, trans_loss=5.167, nll_loss=2.417, w2v_ctc_loss=1.184, task_loss=0, contrastive_loss=0.261, total=4097.37, n_correct=2740.75, ppl=5.34, accuracy=66.89, wps=11110.6, ups=2.71, wpb=4097.4, bsz=147.9, num_updates=45000, lr=6.66667e-05, gnorm=1.053, clip=0, loss_scale=64, train_wall=36, gb_free=13.5, wall=23489
tensor(0.0295, device='cuda:0')
tensor(0.0009, device='cuda:0')
2023-07-04 10:26:00 | INFO | train_inner | epoch 031:    899 / 1474 loss=3.991, trans_loss=5.154, nll_loss=2.4, w2v_ctc_loss=1.192, task_loss=0, contrastive_loss=0.149, total=4096.72, n_correct=2749.05, ppl=5.28, accuracy=67.104, wps=11101.4, ups=2.71, wpb=4096.7, bsz=148, num_updates=45100, lr=6.65927e-05, gnorm=1.064, clip=0, loss_scale=64, train_wall=37, gb_free=17.6, wall=23526
2023-07-04 10:26:37 | INFO | train_inner | epoch 031:    999 / 1474 loss=4.008, trans_loss=5.165, nll_loss=2.416, w2v_ctc_loss=1.183, task_loss=0, contrastive_loss=0.318, total=4187.84, n_correct=2808.1, ppl=5.34, accuracy=67.054, wps=11448.9, ups=2.73, wpb=4187.8, bsz=159.7, num_updates=45200, lr=6.6519e-05, gnorm=1.033, clip=0, loss_scale=64, train_wall=36, gb_free=17.6, wall=23563
2023-07-04 10:27:13 | INFO | train_inner | epoch 031:   1099 / 1474 loss=3.999, trans_loss=5.16, nll_loss=2.41, w2v_ctc_loss=1.184, task_loss=0, contrastive_loss=0.213, total=4149.44, n_correct=2782.13, ppl=5.31, accuracy=67.048, wps=11393.8, ups=2.75, wpb=4149.4, bsz=157.5, num_updates=45300, lr=6.64455e-05, gnorm=1.049, clip=0, loss_scale=64, train_wall=36, gb_free=17.9, wall=23599
2023-07-04 10:27:50 | INFO | train_inner | epoch 031:   1199 / 1474 loss=4.022, trans_loss=5.17, nll_loss=2.423, w2v_ctc_loss=1.193, task_loss=0, contrastive_loss=0.446, total=4189.76, n_correct=2801.1, ppl=5.36, accuracy=66.856, wps=11426.7, ups=2.73, wpb=4189.8, bsz=160.6, num_updates=45400, lr=6.63723e-05, gnorm=1.031, clip=0, loss_scale=64, train_wall=36, gb_free=13.8, wall=23636
2023-07-04 10:28:26 | INFO | train_inner | epoch 031:   1299 / 1474 loss=3.996, trans_loss=5.161, nll_loss=2.412, w2v_ctc_loss=1.189, task_loss=0, contrastive_loss=0.137, total=4227.44, n_correct=2834.73, ppl=5.32, accuracy=67.055, wps=11580.2, ups=2.74, wpb=4227.4, bsz=163.2, num_updates=45500, lr=6.62994e-05, gnorm=1.025, clip=0, loss_scale=64, train_wall=36, gb_free=16.9, wall=23672
2023-07-04 10:28:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-04 10:29:03 | INFO | train_inner | epoch 031:   1400 / 1474 loss=4.007, trans_loss=5.161, nll_loss=2.412, w2v_ctc_loss=1.182, task_loss=0, contrastive_loss=0.333, total=4162.83, n_correct=2792.59, ppl=5.32, accuracy=67.084, wps=11152, ups=2.68, wpb=4162.8, bsz=159.5, num_updates=45600, lr=6.62266e-05, gnorm=1.035, clip=0, loss_scale=32, train_wall=37, gb_free=16.9, wall=23710
2023-07-04 10:29:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0295, device='cuda:7')
tensor(0.0009, device='cuda:7')
tensor(0.0295, device='cuda:4')
tensor(0.0009, device='cuda:4')
tensor(0.0295, device='cuda:3')
tensor(0.0009, device='cuda:3')
tensor(0.0295, device='cuda:6')
tensor(0.0009, device='cuda:6')
tensor(0.0295, device='cuda:5')
tensor(0.0009, device='cuda:5')
tensor(0.0295, device='cuda:2')
tensor(0.0009, device='cuda:2')
tensor(0.0295, device='cuda:1')
tensor(0.0009, device='cuda:1')
2023-07-04 10:29:56 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.349 | trans_loss 5.554 | nll_loss 2.827 | w2v_ctc_loss 1.415 | task_loss 0 | contrastive_loss 0.259 | total 4003.4 | n_correct 2494 | ppl 7.1 | accuracy 62.297 | uer 16.986 | wer 18.806 | raw_wer 18.806 | bleu 20.21 | wps 2238.6 | wpb 4003.4 | bsz 141.8 | num_updates 45674 | best_bleu 20.67
2023-07-04 10:29:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45674 updates
2023-07-04 10:29:56 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_last.pt
2023-07-04 10:30:00 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_last.pt
2023-07-04 10:30:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_last.pt (epoch 31 @ 45674 updates, score 20.21) (writing took 4.346194431185722 seconds)
2023-07-04 10:30:00 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-07-04 10:30:00 | INFO | train | epoch 031 | loss 3.996 | trans_loss 5.157 | nll_loss 2.405 | w2v_ctc_loss 1.188 | task_loss 0 | contrastive_loss 0.204 | total 4136.77 | n_correct 2775.66 | ppl 5.3 | accuracy 67.097 | wps 10498.3 | ups 2.54 | wpb 4136.8 | bsz 152.6 | num_updates 45674 | lr 6.61729e-05 | gnorm 1.042 | clip 0 | loss_scale 32 | train_wall 537 | gb_free 12.7 | wall 23766
2023-07-04 10:30:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 10:30:00 | INFO | fairseq.trainer | begin training epoch 32
2023-07-04 10:30:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 10:30:18 | INFO | train_inner | epoch 032:     26 / 1474 loss=3.981, trans_loss=5.15, nll_loss=2.396, w2v_ctc_loss=1.177, task_loss=0, contrastive_loss=0.112, total=4040.88, n_correct=2714.02, ppl=5.26, accuracy=67.164, wps=5438.1, ups=1.35, wpb=4040.9, bsz=144.4, num_updates=45700, lr=6.61541e-05, gnorm=1.057, clip=0, loss_scale=32, train_wall=36, gb_free=16, wall=23784
2023-07-04 10:30:55 | INFO | train_inner | epoch 032:    126 / 1474 loss=3.942, trans_loss=5.108, nll_loss=2.341, w2v_ctc_loss=1.134, task_loss=0, contrastive_loss=0.133, total=4222.14, n_correct=2864.82, ppl=5.07, accuracy=67.852, wps=11476.4, ups=2.72, wpb=4222.1, bsz=161.3, num_updates=45800, lr=6.60819e-05, gnorm=1.023, clip=0, loss_scale=32, train_wall=36, gb_free=16, wall=23821
2023-07-04 10:31:32 | INFO | train_inner | epoch 032:    226 / 1474 loss=3.973, trans_loss=5.134, nll_loss=2.375, w2v_ctc_loss=1.171, task_loss=0, contrastive_loss=0.155, total=4159.77, n_correct=2807.27, ppl=5.19, accuracy=67.486, wps=11233.5, ups=2.7, wpb=4159.8, bsz=160.4, num_updates=45900, lr=6.60098e-05, gnorm=1.044, clip=0, loss_scale=32, train_wall=37, gb_free=16.7, wall=23858
2023-07-04 10:32:08 | INFO | train_inner | epoch 032:    326 / 1474 loss=3.955, trans_loss=5.122, nll_loss=2.358, w2v_ctc_loss=1.147, task_loss=0, contrastive_loss=0.14, total=4179.65, n_correct=2829.94, ppl=5.13, accuracy=67.708, wps=11413.7, ups=2.73, wpb=4179.6, bsz=156.9, num_updates=46000, lr=6.5938e-05, gnorm=1.038, clip=0, loss_scale=32, train_wall=36, gb_free=16.7, wall=23894
2023-07-04 10:32:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 10:32:34 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.369 | trans_loss 5.561 | nll_loss 2.835 | w2v_ctc_loss 1.463 | task_loss 0 | contrastive_loss 0.263 | total 4003.4 | n_correct 2492.8 | ppl 7.14 | accuracy 62.267 | uer 16.893 | wer 18.65 | raw_wer 18.65 | bleu 20.21 | wps 2065.9 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.67
2023-07-04 10:32:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-07-04 10:32:34 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_32_46000.pt
2023-07-04 10:32:36 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_32_46000.pt
2023-07-04 10:32:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 20.21) (writing took 5.367680388968438 seconds)
2023-07-04 10:33:16 | INFO | train_inner | epoch 032:    426 / 1474 loss=3.975, trans_loss=5.135, nll_loss=2.376, w2v_ctc_loss=1.182, task_loss=0, contrastive_loss=0.14, total=4172.34, n_correct=2818.59, ppl=5.19, accuracy=67.554, wps=6123.9, ups=1.47, wpb=4172.3, bsz=155, num_updates=46100, lr=6.58665e-05, gnorm=1.035, clip=0, loss_scale=32, train_wall=36, gb_free=17.5, wall=23962
2023-07-04 10:33:53 | INFO | train_inner | epoch 032:    526 / 1474 loss=4, trans_loss=5.151, nll_loss=2.397, w2v_ctc_loss=1.19, task_loss=0, contrastive_loss=0.294, total=4191.15, n_correct=2818.96, ppl=5.27, accuracy=67.26, wps=11307.2, ups=2.7, wpb=4191.1, bsz=157.5, num_updates=46200, lr=6.57952e-05, gnorm=1.035, clip=0, loss_scale=32, train_wall=37, gb_free=15.6, wall=24000
2023-07-04 10:34:31 | INFO | train_inner | epoch 032:    626 / 1474 loss=3.997, trans_loss=5.158, nll_loss=2.406, w2v_ctc_loss=1.201, task_loss=0, contrastive_loss=0.15, total=4138.05, n_correct=2775.43, ppl=5.3, accuracy=67.071, wps=11117.6, ups=2.69, wpb=4138.1, bsz=149.8, num_updates=46300, lr=6.57241e-05, gnorm=1.043, clip=0, loss_scale=32, train_wall=37, gb_free=13.9, wall=24037
2023-07-04 10:35:08 | INFO | train_inner | epoch 032:    726 / 1474 loss=3.987, trans_loss=5.149, nll_loss=2.394, w2v_ctc_loss=1.193, task_loss=0, contrastive_loss=0.12, total=4156.23, n_correct=2795.28, ppl=5.26, accuracy=67.255, wps=11194.1, ups=2.69, wpb=4156.2, bsz=151.5, num_updates=46400, lr=6.56532e-05, gnorm=1.033, clip=0, loss_scale=32, train_wall=37, gb_free=17, wall=24074
2023-07-04 10:35:45 | INFO | train_inner | epoch 032:    826 / 1474 loss=3.98, trans_loss=5.15, nll_loss=2.395, w2v_ctc_loss=1.174, task_loss=0, contrastive_loss=0.113, total=4112.3, n_correct=2761.68, ppl=5.26, accuracy=67.157, wps=11172.4, ups=2.72, wpb=4112.3, bsz=147, num_updates=46500, lr=6.55826e-05, gnorm=1.037, clip=0, loss_scale=32, train_wall=36, gb_free=16.3, wall=24111
2023-07-04 10:36:22 | INFO | train_inner | epoch 032:    926 / 1474 loss=3.98, trans_loss=5.149, nll_loss=2.394, w2v_ctc_loss=1.176, task_loss=0, contrastive_loss=0.113, total=4139.37, n_correct=2780.17, ppl=5.26, accuracy=67.164, wps=11192.6, ups=2.7, wpb=4139.4, bsz=149.3, num_updates=46600, lr=6.55122e-05, gnorm=1.045, clip=0, loss_scale=32, train_wall=37, gb_free=13.4, wall=24148
2023-07-04 10:36:59 | INFO | train_inner | epoch 032:   1026 / 1474 loss=4, trans_loss=5.158, nll_loss=2.405, w2v_ctc_loss=1.179, task_loss=0, contrastive_loss=0.3, total=4121.85, n_correct=2763.48, ppl=5.3, accuracy=67.045, wps=11149.5, ups=2.7, wpb=4121.9, bsz=153, num_updates=46700, lr=6.5442e-05, gnorm=1.041, clip=0, loss_scale=32, train_wall=37, gb_free=17.3, wall=24185
2023-07-04 10:37:36 | INFO | train_inner | epoch 032:   1126 / 1474 loss=4.002, trans_loss=5.169, nll_loss=2.419, w2v_ctc_loss=1.189, task_loss=0, contrastive_loss=0.186, total=4015.59, n_correct=2685.09, ppl=5.35, accuracy=66.867, wps=10856.9, ups=2.7, wpb=4015.6, bsz=135.1, num_updates=46800, lr=6.5372e-05, gnorm=1.051, clip=0, loss_scale=32, train_wall=37, gb_free=17.6, wall=24222
2023-07-04 10:38:12 | INFO | train_inner | epoch 032:   1226 / 1474 loss=4.024, trans_loss=5.174, nll_loss=2.428, w2v_ctc_loss=1.188, task_loss=0, contrastive_loss=0.399, total=4153.44, n_correct=2772.77, ppl=5.38, accuracy=66.758, wps=11297.8, ups=2.72, wpb=4153.4, bsz=155.4, num_updates=46900, lr=6.53023e-05, gnorm=1.052, clip=0, loss_scale=32, train_wall=36, gb_free=16.7, wall=24258
2023-07-04 10:38:49 | INFO | train_inner | epoch 032:   1326 / 1474 loss=3.993, trans_loss=5.159, nll_loss=2.408, w2v_ctc_loss=1.193, task_loss=0, contrastive_loss=0.114, total=4075.86, n_correct=2731.66, ppl=5.31, accuracy=67.02, wps=11129.3, ups=2.73, wpb=4075.9, bsz=147.7, num_updates=47000, lr=6.52328e-05, gnorm=1.06, clip=0, loss_scale=32, train_wall=36, gb_free=17.3, wall=24295
2023-07-04 10:39:26 | INFO | train_inner | epoch 032:   1426 / 1474 loss=4.027, trans_loss=5.167, nll_loss=2.418, w2v_ctc_loss=1.195, task_loss=0, contrastive_loss=0.575, total=4116.4, n_correct=2755.5, ppl=5.35, accuracy=66.94, wps=11213.3, ups=2.72, wpb=4116.4, bsz=153.8, num_updates=47100, lr=6.51635e-05, gnorm=1.047, clip=0, loss_scale=32, train_wall=36, gb_free=17.2, wall=24332
2023-07-04 10:39:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 10:40:09 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.351 | trans_loss 5.555 | nll_loss 2.827 | w2v_ctc_loss 1.42 | task_loss 0 | contrastive_loss 0.265 | total 4003.4 | n_correct 2490.9 | ppl 7.1 | accuracy 62.22 | uer 16.72 | wer 18.471 | raw_wer 18.471 | bleu 20.13 | wps 2114 | wpb 4003.4 | bsz 141.8 | num_updates 47148 | best_bleu 20.67
2023-07-04 10:40:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47148 updates
2023-07-04 10:40:09 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_last.pt
2023-07-04 10:40:13 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_last.pt
2023-07-04 10:40:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_last.pt (epoch 32 @ 47148 updates, score 20.13) (writing took 4.179516025818884 seconds)
2023-07-04 10:40:13 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-07-04 10:40:13 | INFO | train | epoch 032 | loss 3.989 | trans_loss 5.149 | nll_loss 2.394 | w2v_ctc_loss 1.179 | task_loss 0 | contrastive_loss 0.219 | total 4138.65 | n_correct 2782.4 | ppl 5.25 | accuracy 67.23 | wps 9955.3 | ups 2.41 | wpb 4138.6 | bsz 152.8 | num_updates 47148 | lr 6.51303e-05 | gnorm 1.043 | clip 0 | loss_scale 32 | train_wall 538 | gb_free 17 | wall 24379
2023-07-04 10:40:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 10:40:13 | INFO | fairseq.trainer | begin training epoch 33
2023-07-04 10:40:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 10:40:40 | INFO | train_inner | epoch 033:     52 / 1474 loss=3.995, trans_loss=5.145, nll_loss=2.39, w2v_ctc_loss=1.174, task_loss=0, contrastive_loss=0.322, total=4149.21, n_correct=2791.66, ppl=5.24, accuracy=67.282, wps=5578.3, ups=1.34, wpb=4149.2, bsz=160.3, num_updates=47200, lr=6.50945e-05, gnorm=1.05, clip=0, loss_scale=32, train_wall=36, gb_free=17.4, wall=24406
2023-07-04 10:41:17 | INFO | train_inner | epoch 033:    152 / 1474 loss=3.944, trans_loss=5.119, nll_loss=2.354, w2v_ctc_loss=1.131, task_loss=0, contrastive_loss=0.097, total=4073.9, n_correct=2759.25, ppl=5.11, accuracy=67.73, wps=11078.3, ups=2.72, wpb=4073.9, bsz=142.4, num_updates=47300, lr=6.50256e-05, gnorm=1.038, clip=0, loss_scale=32, train_wall=36, gb_free=15.7, wall=24443
2023-07-04 10:41:54 | INFO | train_inner | epoch 033:    252 / 1474 loss=3.985, trans_loss=5.123, nll_loss=2.361, w2v_ctc_loss=1.154, task_loss=0, contrastive_loss=0.446, total=4280.14, n_correct=2899.83, ppl=5.14, accuracy=67.751, wps=11511.5, ups=2.69, wpb=4280.1, bsz=173.2, num_updates=47400, lr=6.4957e-05, gnorm=1.033, clip=0, loss_scale=32, train_wall=37, gb_free=16.8, wall=24480
2023-07-04 10:42:31 | INFO | train_inner | epoch 033:    352 / 1474 loss=3.976, trans_loss=5.137, nll_loss=2.379, w2v_ctc_loss=1.176, task_loss=0, contrastive_loss=0.158, total=4120.27, n_correct=2776.34, ppl=5.2, accuracy=67.382, wps=11240.2, ups=2.73, wpb=4120.3, bsz=150.3, num_updates=47500, lr=6.48886e-05, gnorm=1.05, clip=0, loss_scale=32, train_wall=36, gb_free=17.6, wall=24517
2023-07-04 10:43:07 | INFO | train_inner | epoch 033:    452 / 1474 loss=3.944, trans_loss=5.11, nll_loss=2.342, w2v_ctc_loss=1.143, task_loss=0, contrastive_loss=0.115, total=4141.22, n_correct=2807.85, ppl=5.07, accuracy=67.802, wps=11323.9, ups=2.73, wpb=4141.2, bsz=155.4, num_updates=47600, lr=6.48204e-05, gnorm=1.042, clip=0, loss_scale=32, train_wall=36, gb_free=16.8, wall=24553
2023-07-04 10:43:44 | INFO | train_inner | epoch 033:    552 / 1474 loss=3.982, trans_loss=5.144, nll_loss=2.386, w2v_ctc_loss=1.182, task_loss=0, contrastive_loss=0.154, total=4133.59, n_correct=2783.82, ppl=5.23, accuracy=67.346, wps=11167.2, ups=2.7, wpb=4133.6, bsz=147, num_updates=47700, lr=6.47524e-05, gnorm=1.048, clip=0, loss_scale=64, train_wall=37, gb_free=15.7, wall=24590
2023-07-04 10:43:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-04 10:44:22 | INFO | train_inner | epoch 033:    653 / 1474 loss=3.988, trans_loss=5.148, nll_loss=2.393, w2v_ctc_loss=1.173, task_loss=0, contrastive_loss=0.222, total=4156.46, n_correct=2795.59, ppl=5.25, accuracy=67.259, wps=11171.7, ups=2.69, wpb=4156.5, bsz=150.8, num_updates=47800, lr=6.46846e-05, gnorm=1.034, clip=0, loss_scale=32, train_wall=37, gb_free=16.5, wall=24628
2023-07-04 10:44:58 | INFO | train_inner | epoch 033:    753 / 1474 loss=3.995, trans_loss=5.156, nll_loss=2.403, w2v_ctc_loss=1.205, task_loss=0, contrastive_loss=0.119, total=4074.99, n_correct=2735.54, ppl=5.29, accuracy=67.13, wps=11032.4, ups=2.71, wpb=4075, bsz=144.1, num_updates=47900, lr=6.46171e-05, gnorm=1.052, clip=0, loss_scale=32, train_wall=37, gb_free=16.7, wall=24665
2023-07-04 10:45:35 | INFO | train_inner | epoch 033:    853 / 1474 loss=3.967, trans_loss=5.129, nll_loss=2.369, w2v_ctc_loss=1.148, task_loss=0, contrastive_loss=0.253, total=4127.6, n_correct=2790.48, ppl=5.17, accuracy=67.605, wps=11345.1, ups=2.75, wpb=4127.6, bsz=157.7, num_updates=48000, lr=6.45497e-05, gnorm=1.04, clip=0, loss_scale=32, train_wall=36, gb_free=16.6, wall=24701
2023-07-04 10:45:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 10:45:59 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.351 | trans_loss 5.557 | nll_loss 2.828 | w2v_ctc_loss 1.416 | task_loss 0 | contrastive_loss 0.26 | total 4003.4 | n_correct 2491.1 | ppl 7.1 | accuracy 62.225 | uer 16.691 | wer 18.299 | raw_wer 18.299 | bleu 20.34 | wps 2228.8 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.67
2023-07-04 10:45:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-07-04 10:45:59 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_33_48000.pt
2023-07-04 10:46:01 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_33_48000.pt
2023-07-04 10:46:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 20.34) (writing took 6.2800347045995295 seconds)
2023-07-04 10:46:43 | INFO | train_inner | epoch 033:    953 / 1474 loss=3.981, trans_loss=5.14, nll_loss=2.383, w2v_ctc_loss=1.187, task_loss=0, contrastive_loss=0.142, total=4157.37, n_correct=2800.22, ppl=5.22, accuracy=67.356, wps=6132.6, ups=1.48, wpb=4157.4, bsz=155, num_updates=48100, lr=6.44826e-05, gnorm=1.04, clip=0, loss_scale=32, train_wall=36, gb_free=17.7, wall=24769
2023-07-04 10:47:20 | INFO | train_inner | epoch 033:   1053 / 1474 loss=3.994, trans_loss=5.146, nll_loss=2.391, w2v_ctc_loss=1.17, task_loss=0, contrastive_loss=0.346, total=4134.8, n_correct=2783.12, ppl=5.24, accuracy=67.31, wps=11172.6, ups=2.7, wpb=4134.8, bsz=153, num_updates=48200, lr=6.44157e-05, gnorm=1.043, clip=0, loss_scale=32, train_wall=37, gb_free=16.1, wall=24806
2023-07-04 10:47:57 | INFO | train_inner | epoch 033:   1153 / 1474 loss=3.996, trans_loss=5.154, nll_loss=2.402, w2v_ctc_loss=1.169, task_loss=0, contrastive_loss=0.32, total=4181.58, n_correct=2807.25, ppl=5.28, accuracy=67.134, wps=11179.9, ups=2.67, wpb=4181.6, bsz=155, num_updates=48300, lr=6.43489e-05, gnorm=1.049, clip=0, loss_scale=32, train_wall=37, gb_free=15.6, wall=24843
2023-07-04 10:48:34 | INFO | train_inner | epoch 033:   1253 / 1474 loss=3.988, trans_loss=5.152, nll_loss=2.398, w2v_ctc_loss=1.19, task_loss=0, contrastive_loss=0.126, total=4115.76, n_correct=2765.07, ppl=5.27, accuracy=67.182, wps=11177.1, ups=2.72, wpb=4115.8, bsz=147.3, num_updates=48400, lr=6.42824e-05, gnorm=1.06, clip=0, loss_scale=32, train_wall=36, gb_free=17.1, wall=24880
2023-07-04 10:49:11 | INFO | train_inner | epoch 033:   1353 / 1474 loss=3.983, trans_loss=5.145, nll_loss=2.39, w2v_ctc_loss=1.176, task_loss=0, contrastive_loss=0.166, total=4120.69, n_correct=2774.1, ppl=5.24, accuracy=67.321, wps=11134.8, ups=2.7, wpb=4120.7, bsz=156, num_updates=48500, lr=6.42161e-05, gnorm=1.037, clip=0, loss_scale=32, train_wall=37, gb_free=17.3, wall=24917
2023-07-04 10:49:48 | INFO | train_inner | epoch 033:   1453 / 1474 loss=4.007, trans_loss=5.154, nll_loss=2.402, w2v_ctc_loss=1.18, task_loss=0, contrastive_loss=0.453, total=4125.28, n_correct=2770.35, ppl=5.28, accuracy=67.155, wps=11125.5, ups=2.7, wpb=4125.3, bsz=154.3, num_updates=48600, lr=6.415e-05, gnorm=1.059, clip=0, loss_scale=32, train_wall=37, gb_free=17.3, wall=24954
2023-07-04 10:49:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 10:50:21 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.356 | trans_loss 5.55 | nll_loss 2.819 | w2v_ctc_loss 1.448 | task_loss 0 | contrastive_loss 0.265 | total 4003.4 | n_correct 2493.9 | ppl 7.05 | accuracy 62.295 | uer 16.672 | wer 18.374 | raw_wer 18.374 | bleu 20.42 | wps 2147.1 | wpb 4003.4 | bsz 141.8 | num_updates 48621 | best_bleu 20.67
2023-07-04 10:50:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48621 updates
2023-07-04 10:50:21 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.4207.pt
2023-07-04 10:50:23 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.4207.pt
2023-07-04 10:50:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.4207.pt (epoch 33 @ 48621 updates, score 20.42) (writing took 5.378681960981339 seconds)
2023-07-04 10:50:26 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-07-04 10:50:26 | INFO | train | epoch 033 | loss 3.98 | trans_loss 5.139 | nll_loss 2.382 | w2v_ctc_loss 1.171 | task_loss 0 | contrastive_loss 0.221 | total 4138.68 | n_correct 2789.25 | ppl 5.21 | accuracy 67.395 | wps 9933.5 | ups 2.4 | wpb 4138.7 | bsz 152.8 | num_updates 48621 | lr 6.41362e-05 | gnorm 1.045 | clip 0 | loss_scale 32 | train_wall 537 | gb_free 18.2 | wall 24993
2023-07-04 10:50:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 10:50:27 | INFO | fairseq.trainer | begin training epoch 34
2023-07-04 10:50:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 10:51:03 | INFO | train_inner | epoch 034:     79 / 1474 loss=3.955, trans_loss=5.118, nll_loss=2.354, w2v_ctc_loss=1.156, task_loss=0, contrastive_loss=0.132, total=4131.47, n_correct=2799.35, ppl=5.11, accuracy=67.757, wps=5472.2, ups=1.32, wpb=4131.5, bsz=150.8, num_updates=48700, lr=6.40841e-05, gnorm=1.052, clip=0, loss_scale=32, train_wall=36, gb_free=17, wall=25030
2023-07-04 10:51:41 | INFO | train_inner | epoch 034:    179 / 1474 loss=3.952, trans_loss=5.114, nll_loss=2.348, w2v_ctc_loss=1.159, task_loss=0, contrastive_loss=0.133, total=4065.88, n_correct=2758.09, ppl=5.09, accuracy=67.835, wps=10970.4, ups=2.7, wpb=4065.9, bsz=147.5, num_updates=48800, lr=6.40184e-05, gnorm=1.054, clip=0, loss_scale=32, train_wall=37, gb_free=16.4, wall=25067
2023-07-04 10:52:18 | INFO | train_inner | epoch 034:    279 / 1474 loss=4.004, trans_loss=5.14, nll_loss=2.384, w2v_ctc_loss=1.163, task_loss=0, contrastive_loss=0.551, total=4246.3, n_correct=2861.08, ppl=5.22, accuracy=67.378, wps=11357.7, ups=2.67, wpb=4246.3, bsz=164.4, num_updates=48900, lr=6.39529e-05, gnorm=1.049, clip=0, loss_scale=32, train_wall=37, gb_free=18.1, wall=25104
2023-07-04 10:52:55 | INFO | train_inner | epoch 034:    379 / 1474 loss=3.963, trans_loss=5.114, nll_loss=2.35, w2v_ctc_loss=1.145, task_loss=0, contrastive_loss=0.329, total=4156.17, n_correct=2822.41, ppl=5.1, accuracy=67.909, wps=11241.7, ups=2.7, wpb=4156.2, bsz=158.4, num_updates=49000, lr=6.38877e-05, gnorm=1.024, clip=0, loss_scale=32, train_wall=37, gb_free=18.1, wall=25141
2023-07-04 10:53:32 | INFO | train_inner | epoch 034:    479 / 1474 loss=3.974, trans_loss=5.136, nll_loss=2.376, w2v_ctc_loss=1.184, task_loss=0, contrastive_loss=0.118, total=4070.55, n_correct=2746.32, ppl=5.19, accuracy=67.468, wps=11086.3, ups=2.72, wpb=4070.6, bsz=142.3, num_updates=49100, lr=6.38226e-05, gnorm=1.062, clip=0, loss_scale=32, train_wall=36, gb_free=17.8, wall=25178
2023-07-04 10:54:08 | INFO | train_inner | epoch 034:    579 / 1474 loss=3.955, trans_loss=5.118, nll_loss=2.354, w2v_ctc_loss=1.155, task_loss=0, contrastive_loss=0.126, total=4119.38, n_correct=2792.21, ppl=5.11, accuracy=67.782, wps=11205.8, ups=2.72, wpb=4119.4, bsz=150.1, num_updates=49200, lr=6.37577e-05, gnorm=1.045, clip=0, loss_scale=32, train_wall=36, gb_free=13.7, wall=25215
2023-07-04 10:54:45 | INFO | train_inner | epoch 034:    679 / 1474 loss=3.945, trans_loss=5.114, nll_loss=2.35, w2v_ctc_loss=1.137, task_loss=0, contrastive_loss=0.112, total=4124.83, n_correct=2794.73, ppl=5.1, accuracy=67.754, wps=11220.4, ups=2.72, wpb=4124.8, bsz=150.1, num_updates=49300, lr=6.3693e-05, gnorm=1.032, clip=0, loss_scale=32, train_wall=36, gb_free=14.8, wall=25251
2023-07-04 10:55:22 | INFO | train_inner | epoch 034:    779 / 1474 loss=3.979, trans_loss=5.145, nll_loss=2.389, w2v_ctc_loss=1.148, task_loss=0, contrastive_loss=0.251, total=4082.07, n_correct=2747.37, ppl=5.24, accuracy=67.303, wps=11114.5, ups=2.72, wpb=4082.1, bsz=147.5, num_updates=49400, lr=6.36285e-05, gnorm=1.054, clip=0, loss_scale=32, train_wall=36, gb_free=16, wall=25288
2023-07-04 10:55:59 | INFO | train_inner | epoch 034:    879 / 1474 loss=3.979, trans_loss=5.143, nll_loss=2.387, w2v_ctc_loss=1.167, task_loss=0, contrastive_loss=0.169, total=4100.9, n_correct=2762.44, ppl=5.23, accuracy=67.362, wps=11088.2, ups=2.7, wpb=4100.9, bsz=148.3, num_updates=49500, lr=6.35642e-05, gnorm=1.069, clip=0, loss_scale=32, train_wall=37, gb_free=12.8, wall=25325
2023-07-04 10:56:36 | INFO | train_inner | epoch 034:    979 / 1474 loss=3.976, trans_loss=5.136, nll_loss=2.379, w2v_ctc_loss=1.173, task_loss=0, contrastive_loss=0.163, total=4168.39, n_correct=2811.94, ppl=5.2, accuracy=67.459, wps=11310, ups=2.71, wpb=4168.4, bsz=156, num_updates=49600, lr=6.35001e-05, gnorm=1.037, clip=0, loss_scale=32, train_wall=36, gb_free=16.4, wall=25362
2023-07-04 10:57:12 | INFO | train_inner | epoch 034:   1079 / 1474 loss=3.976, trans_loss=5.139, nll_loss=2.382, w2v_ctc_loss=1.175, task_loss=0, contrastive_loss=0.128, total=4150.57, n_correct=2797.32, ppl=5.21, accuracy=67.396, wps=11377.9, ups=2.74, wpb=4150.6, bsz=154.2, num_updates=49700, lr=6.34361e-05, gnorm=1.061, clip=0, loss_scale=32, train_wall=36, gb_free=17.2, wall=25398
2023-07-04 10:57:49 | INFO | train_inner | epoch 034:   1179 / 1474 loss=3.975, trans_loss=5.138, nll_loss=2.381, w2v_ctc_loss=1.169, task_loss=0, contrastive_loss=0.15, total=4098.77, n_correct=2763.23, ppl=5.21, accuracy=67.416, wps=11114.1, ups=2.71, wpb=4098.8, bsz=148.6, num_updates=49800, lr=6.33724e-05, gnorm=1.047, clip=0, loss_scale=64, train_wall=36, gb_free=17.3, wall=25435
2023-07-04 10:57:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-04 10:58:26 | INFO | train_inner | epoch 034:   1280 / 1474 loss=3.963, trans_loss=5.131, nll_loss=2.371, w2v_ctc_loss=1.156, task_loss=0, contrastive_loss=0.119, total=4149.64, n_correct=2801.79, ppl=5.17, accuracy=67.519, wps=11193.7, ups=2.7, wpb=4149.6, bsz=150.5, num_updates=49900, lr=6.33089e-05, gnorm=1.042, clip=0, loss_scale=32, train_wall=37, gb_free=17.6, wall=25472
2023-07-04 10:59:03 | INFO | train_inner | epoch 034:   1380 / 1474 loss=3.986, trans_loss=5.14, nll_loss=2.384, w2v_ctc_loss=1.174, task_loss=0, contrastive_loss=0.247, total=4197.99, n_correct=2827.7, ppl=5.22, accuracy=67.358, wps=11308.2, ups=2.69, wpb=4198, bsz=160.6, num_updates=50000, lr=6.32456e-05, gnorm=1.026, clip=0, loss_scale=32, train_wall=37, gb_free=17.6, wall=25509
2023-07-04 10:59:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 10:59:29 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.342 | trans_loss 5.557 | nll_loss 2.829 | w2v_ctc_loss 1.384 | task_loss 0 | contrastive_loss 0.261 | total 4003.4 | n_correct 2489 | ppl 7.1 | accuracy 62.172 | uer 16.513 | wer 18.396 | raw_wer 18.396 | bleu 20.02 | wps 2146.3 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.67
2023-07-04 10:59:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-07-04 10:59:29 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_34_50000.pt
2023-07-04 10:59:31 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_34_50000.pt
2023-07-04 10:59:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 20.02) (writing took 5.2257723324000835 seconds)
tensor(0.0295, device='cuda:0')
tensor(0.0009, device='cuda:0')
2023-07-04 11:00:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0295, device='cuda:5')
tensor(0.0009, device='cuda:5')
tensor(0.0295, device='cuda:4')
tensor(0.0009, device='cuda:4')
tensor(0.0295, device='cuda:6')
tensor(0.0009, device='cuda:6')
tensor(0.0295, device='cuda:7')
tensor(0.0009, device='cuda:7')
tensor(0.0295, device='cuda:1')
tensor(0.0009, device='cuda:1')
tensor(0.0295, device='cuda:3')
tensor(0.0009, device='cuda:3')
tensor(0.0295, device='cuda:2')
tensor(0.0009, device='cuda:2')
2023-07-04 11:00:36 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.347 | trans_loss 5.556 | nll_loss 2.827 | w2v_ctc_loss 1.402 | task_loss 0 | contrastive_loss 0.263 | total 4003.4 | n_correct 2493.6 | ppl 7.1 | accuracy 62.287 | uer 16.42 | wer 18.135 | raw_wer 18.135 | bleu 20.17 | wps 1970.5 | wpb 4003.4 | bsz 141.8 | num_updates 50094 | best_bleu 20.67
2023-07-04 11:00:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50094 updates
2023-07-04 11:00:36 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_last.pt
2023-07-04 11:00:40 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_last.pt
2023-07-04 11:00:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_last.pt (epoch 34 @ 50094 updates, score 20.17) (writing took 4.384763285052031 seconds)
2023-07-04 11:00:41 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-07-04 11:00:41 | INFO | train | epoch 034 | loss 3.972 | trans_loss 5.131 | nll_loss 2.371 | w2v_ctc_loss 1.16 | task_loss 0 | contrastive_loss 0.224 | total 4138.68 | n_correct 2795.21 | ppl 5.17 | accuracy 67.539 | wps 9927 | ups 2.4 | wpb 4138.7 | bsz 152.8 | num_updates 50094 | lr 6.31862e-05 | gnorm 1.046 | clip 0 | loss_scale 32 | train_wall 538 | gb_free 17.7 | wall 25607
2023-07-04 11:00:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 11:00:41 | INFO | fairseq.trainer | begin training epoch 35
2023-07-04 11:00:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 11:00:51 | INFO | train_inner | epoch 035:      6 / 1474 loss=3.993, trans_loss=5.137, nll_loss=2.38, w2v_ctc_loss=1.146, task_loss=0, contrastive_loss=0.529, total=4206.43, n_correct=2834.46, ppl=5.21, accuracy=67.384, wps=3894.1, ups=0.93, wpb=4206.4, bsz=162.4, num_updates=50100, lr=6.31824e-05, gnorm=1.048, clip=0, loss_scale=32, train_wall=37, gb_free=18.1, wall=25617
2023-07-04 11:01:29 | INFO | train_inner | epoch 035:    106 / 1474 loss=3.965, trans_loss=5.113, nll_loss=2.348, w2v_ctc_loss=1.138, task_loss=0, contrastive_loss=0.406, total=4171.34, n_correct=2834.86, ppl=5.09, accuracy=67.96, wps=11171, ups=2.68, wpb=4171.3, bsz=156.8, num_updates=50200, lr=6.31194e-05, gnorm=1.047, clip=0, loss_scale=32, train_wall=37, gb_free=16.2, wall=25655
2023-07-04 11:02:05 | INFO | train_inner | epoch 035:    206 / 1474 loss=3.931, trans_loss=5.096, nll_loss=2.326, w2v_ctc_loss=1.125, task_loss=0, contrastive_loss=0.123, total=4167.37, n_correct=2842.55, ppl=5.01, accuracy=68.21, wps=11332.3, ups=2.72, wpb=4167.4, bsz=158, num_updates=50300, lr=6.30567e-05, gnorm=1.025, clip=0, loss_scale=32, train_wall=36, gb_free=14.2, wall=25692
2023-07-04 11:02:43 | INFO | train_inner | epoch 035:    306 / 1474 loss=3.97, trans_loss=5.118, nll_loss=2.353, w2v_ctc_loss=1.146, task_loss=0, contrastive_loss=0.45, total=4114.35, n_correct=2787.06, ppl=5.11, accuracy=67.74, wps=10943.9, ups=2.66, wpb=4114.4, bsz=150, num_updates=50400, lr=6.29941e-05, gnorm=1.041, clip=0, loss_scale=32, train_wall=37, gb_free=13, wall=25729
2023-07-04 11:03:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-04 11:03:20 | INFO | train_inner | epoch 035:    407 / 1474 loss=3.966, trans_loss=5.126, nll_loss=2.363, w2v_ctc_loss=1.18, task_loss=0, contrastive_loss=0.125, total=4068.08, n_correct=2748.62, ppl=5.14, accuracy=67.566, wps=10904, ups=2.68, wpb=4068.1, bsz=141.3, num_updates=50500, lr=6.29317e-05, gnorm=1.063, clip=0, loss_scale=16, train_wall=37, gb_free=17, wall=25767
2023-07-04 11:03:57 | INFO | train_inner | epoch 035:    507 / 1474 loss=3.966, trans_loss=5.123, nll_loss=2.36, w2v_ctc_loss=1.147, task_loss=0, contrastive_loss=0.269, total=4166.99, n_correct=2820.91, ppl=5.13, accuracy=67.697, wps=11332.1, ups=2.72, wpb=4167, bsz=153.8, num_updates=50600, lr=6.28695e-05, gnorm=1.047, clip=0, loss_scale=16, train_wall=36, gb_free=16.9, wall=25803
2023-07-04 11:04:34 | INFO | train_inner | epoch 035:    607 / 1474 loss=3.951, trans_loss=5.11, nll_loss=2.344, w2v_ctc_loss=1.128, task_loss=0, contrastive_loss=0.287, total=4163.42, n_correct=2825.24, ppl=5.08, accuracy=67.859, wps=11388.6, ups=2.74, wpb=4163.4, bsz=154.2, num_updates=50700, lr=6.28074e-05, gnorm=1.033, clip=0, loss_scale=16, train_wall=36, gb_free=17, wall=25840
2023-07-04 11:05:10 | INFO | train_inner | epoch 035:    707 / 1474 loss=3.97, trans_loss=5.129, nll_loss=2.368, w2v_ctc_loss=1.177, task_loss=0, contrastive_loss=0.148, total=4079.63, n_correct=2758.45, ppl=5.16, accuracy=67.615, wps=11134, ups=2.73, wpb=4079.6, bsz=147, num_updates=50800, lr=6.27456e-05, gnorm=1.076, clip=0, loss_scale=16, train_wall=36, gb_free=16.8, wall=25877
2023-07-04 11:05:47 | INFO | train_inner | epoch 035:    807 / 1474 loss=3.962, trans_loss=5.12, nll_loss=2.358, w2v_ctc_loss=1.165, task_loss=0, contrastive_loss=0.158, total=4152.95, n_correct=2812.24, ppl=5.13, accuracy=67.717, wps=11219.2, ups=2.7, wpb=4152.9, bsz=155.4, num_updates=50900, lr=6.26839e-05, gnorm=1.052, clip=0, loss_scale=16, train_wall=37, gb_free=16.8, wall=25914
2023-07-04 11:06:24 | INFO | train_inner | epoch 035:    907 / 1474 loss=3.964, trans_loss=5.126, nll_loss=2.364, w2v_ctc_loss=1.17, task_loss=0, contrastive_loss=0.121, total=4093.1, n_correct=2764.91, ppl=5.15, accuracy=67.551, wps=11131.7, ups=2.72, wpb=4093.1, bsz=146.2, num_updates=51000, lr=6.26224e-05, gnorm=1.059, clip=0, loss_scale=16, train_wall=36, gb_free=17.3, wall=25950
2023-07-04 11:07:01 | INFO | train_inner | epoch 035:   1007 / 1474 loss=3.985, trans_loss=5.135, nll_loss=2.378, w2v_ctc_loss=1.157, task_loss=0, contrastive_loss=0.367, total=4142.37, n_correct=2794.5, ppl=5.2, accuracy=67.461, wps=11200.6, ups=2.7, wpb=4142.4, bsz=153.2, num_updates=51100, lr=6.25611e-05, gnorm=1.039, clip=0, loss_scale=16, train_wall=37, gb_free=17.9, wall=25987
2023-07-04 11:07:38 | INFO | train_inner | epoch 035:   1107 / 1474 loss=3.966, trans_loss=5.128, nll_loss=2.369, w2v_ctc_loss=1.165, task_loss=0, contrastive_loss=0.135, total=4187.16, n_correct=2833.15, ppl=5.16, accuracy=67.663, wps=11396.5, ups=2.72, wpb=4187.2, bsz=156.2, num_updates=51200, lr=6.25e-05, gnorm=1.042, clip=0, loss_scale=16, train_wall=36, gb_free=17.4, wall=26024
2023-07-04 11:08:15 | INFO | train_inner | epoch 035:   1207 / 1474 loss=3.963, trans_loss=5.121, nll_loss=2.361, w2v_ctc_loss=1.139, task_loss=0, contrastive_loss=0.246, total=4216.84, n_correct=2855.89, ppl=5.14, accuracy=67.726, wps=11430, ups=2.71, wpb=4216.8, bsz=161.4, num_updates=51300, lr=6.24391e-05, gnorm=1.039, clip=0, loss_scale=16, train_wall=36, gb_free=17.4, wall=26061
2023-07-04 11:08:51 | INFO | train_inner | epoch 035:   1307 / 1474 loss=3.962, trans_loss=5.124, nll_loss=2.364, w2v_ctc_loss=1.155, task_loss=0, contrastive_loss=0.144, total=4136.15, n_correct=2796.4, ppl=5.15, accuracy=67.609, wps=11319.6, ups=2.74, wpb=4136.1, bsz=155.8, num_updates=51400, lr=6.23783e-05, gnorm=1.052, clip=0, loss_scale=16, train_wall=36, gb_free=15.6, wall=26097
2023-07-04 11:09:28 | INFO | train_inner | epoch 035:   1407 / 1474 loss=3.975, trans_loss=5.142, nll_loss=2.387, w2v_ctc_loss=1.166, task_loss=0, contrastive_loss=0.125, total=4066.29, n_correct=2738.4, ppl=5.23, accuracy=67.344, wps=11109.4, ups=2.73, wpb=4066.3, bsz=144.4, num_updates=51500, lr=6.23177e-05, gnorm=1.067, clip=0, loss_scale=16, train_wall=36, gb_free=17, wall=26134
2023-07-04 11:09:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 11:10:18 | INFO | dev_st | epoch 035 | valid on 'dev_st' subset | loss 4.36 | trans_loss 5.556 | nll_loss 2.827 | w2v_ctc_loss 1.443 | task_loss 0 | contrastive_loss 0.263 | total 4003.4 | n_correct 2496.2 | ppl 7.09 | accuracy 62.352 | uer 16.752 | wer 18.486 | raw_wer 18.486 | bleu 20.23 | wps 2182.1 | wpb 4003.4 | bsz 141.8 | num_updates 51567 | best_bleu 20.67
2023-07-04 11:10:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 51567 updates
2023-07-04 11:10:18 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_last.pt
2023-07-04 11:10:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_last.pt
2023-07-04 11:10:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_last.pt (epoch 35 @ 51567 updates, score 20.23) (writing took 4.179391052108258 seconds)
2023-07-04 11:10:22 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-07-04 11:10:22 | INFO | train | epoch 035 | loss 3.964 | trans_loss 5.122 | nll_loss 2.36 | w2v_ctc_loss 1.153 | task_loss 0 | contrastive_loss 0.224 | total 4138.75 | n_correct 2801.69 | ppl 5.13 | accuracy 67.694 | wps 10487.6 | ups 2.53 | wpb 4138.8 | bsz 152.8 | num_updates 51567 | lr 6.22772e-05 | gnorm 1.049 | clip 0 | loss_scale 16 | train_wall 537 | gb_free 17.6 | wall 26188
2023-07-04 11:10:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 11:10:22 | INFO | fairseq.trainer | begin training epoch 36
2023-07-04 11:10:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 11:10:42 | INFO | train_inner | epoch 036:     33 / 1474 loss=3.949, trans_loss=5.109, nll_loss=2.342, w2v_ctc_loss=1.136, task_loss=0, contrastive_loss=0.206, total=4116.67, n_correct=2794.59, ppl=5.07, accuracy=67.885, wps=5536.2, ups=1.34, wpb=4116.7, bsz=152.8, num_updates=51600, lr=6.22573e-05, gnorm=1.055, clip=0, loss_scale=16, train_wall=36, gb_free=17.4, wall=26208
2023-07-04 11:11:20 | INFO | train_inner | epoch 036:    133 / 1474 loss=3.939, trans_loss=5.103, nll_loss=2.333, w2v_ctc_loss=1.135, task_loss=0, contrastive_loss=0.138, total=4105.52, n_correct=2792.15, ppl=5.04, accuracy=68.01, wps=11027.7, ups=2.69, wpb=4105.5, bsz=149.6, num_updates=51700, lr=6.2197e-05, gnorm=1.048, clip=0, loss_scale=16, train_wall=37, gb_free=12.8, wall=26246
2023-07-04 11:11:57 | INFO | train_inner | epoch 036:    233 / 1474 loss=3.942, trans_loss=5.102, nll_loss=2.334, w2v_ctc_loss=1.14, task_loss=0, contrastive_loss=0.164, total=4154.98, n_correct=2829.71, ppl=5.04, accuracy=68.104, wps=11029.4, ups=2.65, wpb=4155, bsz=152.7, num_updates=51800, lr=6.2137e-05, gnorm=1.053, clip=0, loss_scale=16, train_wall=37, gb_free=12.4, wall=26283
2023-07-04 11:12:34 | INFO | train_inner | epoch 036:    333 / 1474 loss=3.932, trans_loss=5.101, nll_loss=2.332, w2v_ctc_loss=1.119, task_loss=0, contrastive_loss=0.115, total=4154.45, n_correct=2827.96, ppl=5.04, accuracy=68.071, wps=11286.7, ups=2.72, wpb=4154.4, bsz=154, num_updates=51900, lr=6.20771e-05, gnorm=1.034, clip=0, loss_scale=16, train_wall=36, gb_free=18.1, wall=26320
2023-07-04 11:13:11 | INFO | train_inner | epoch 036:    433 / 1474 loss=3.962, trans_loss=5.109, nll_loss=2.343, w2v_ctc_loss=1.139, task_loss=0, contrastive_loss=0.354, total=4234.63, n_correct=2878.6, ppl=5.07, accuracy=67.978, wps=11556.6, ups=2.73, wpb=4234.6, bsz=166.6, num_updates=52000, lr=6.20174e-05, gnorm=1.062, clip=0, loss_scale=16, train_wall=36, gb_free=16.3, wall=26357
2023-07-04 11:13:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 11:13:35 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 4.349 | trans_loss 5.557 | nll_loss 2.828 | w2v_ctc_loss 1.407 | task_loss 0 | contrastive_loss 0.266 | total 4003.4 | n_correct 2496.4 | ppl 7.1 | accuracy 62.357 | uer 16.641 | wer 18.523 | raw_wer 18.523 | bleu 19.89 | wps 2291.5 | wpb 4003.4 | bsz 141.8 | num_updates 52000 | best_bleu 20.67
2023-07-04 11:13:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 52000 updates
2023-07-04 11:13:35 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_36_52000.pt
2023-07-04 11:13:37 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_36_52000.pt
2023-07-04 11:13:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_36_52000.pt (epoch 36 @ 52000 updates, score 19.89) (writing took 5.157829984091222 seconds)
2023-07-04 11:14:18 | INFO | train_inner | epoch 036:    533 / 1474 loss=3.976, trans_loss=5.116, nll_loss=2.353, w2v_ctc_loss=1.122, task_loss=0, contrastive_loss=0.635, total=4154.95, n_correct=2817.47, ppl=5.11, accuracy=67.81, wps=6183.6, ups=1.49, wpb=4154.9, bsz=157.1, num_updates=52100, lr=6.19578e-05, gnorm=1.057, clip=0, loss_scale=16, train_wall=37, gb_free=15.8, wall=26424
2023-07-04 11:14:55 | INFO | train_inner | epoch 036:    633 / 1474 loss=3.946, trans_loss=5.102, nll_loss=2.333, w2v_ctc_loss=1.131, task_loss=0, contrastive_loss=0.277, total=4178.69, n_correct=2841.58, ppl=5.04, accuracy=68.002, wps=11329.8, ups=2.71, wpb=4178.7, bsz=158.2, num_updates=52200, lr=6.18984e-05, gnorm=1.038, clip=0, loss_scale=16, train_wall=36, gb_free=16.4, wall=26461
2023-07-04 11:15:31 | INFO | train_inner | epoch 036:    733 / 1474 loss=3.961, trans_loss=5.123, nll_loss=2.36, w2v_ctc_loss=1.156, task_loss=0, contrastive_loss=0.145, total=4178, n_correct=2827.12, ppl=5.13, accuracy=67.667, wps=11391, ups=2.73, wpb=4178, bsz=157.6, num_updates=52300, lr=6.18392e-05, gnorm=1.041, clip=0, loss_scale=16, train_wall=36, gb_free=16.9, wall=26498
2023-07-04 11:16:09 | INFO | train_inner | epoch 036:    833 / 1474 loss=3.991, trans_loss=5.132, nll_loss=2.373, w2v_ctc_loss=1.146, task_loss=0, contrastive_loss=0.483, total=4183.16, n_correct=2824.65, ppl=5.18, accuracy=67.524, wps=11244, ups=2.69, wpb=4183.2, bsz=161.7, num_updates=52400, lr=6.17802e-05, gnorm=1.052, clip=0, loss_scale=16, train_wall=37, gb_free=15.4, wall=26535
2023-07-04 11:16:46 | INFO | train_inner | epoch 036:    933 / 1474 loss=3.943, trans_loss=5.108, nll_loss=2.341, w2v_ctc_loss=1.142, task_loss=0, contrastive_loss=0.117, total=4164.3, n_correct=2824.33, ppl=5.07, accuracy=67.822, wps=11305.6, ups=2.71, wpb=4164.3, bsz=151.4, num_updates=52500, lr=6.17213e-05, gnorm=1.028, clip=0, loss_scale=16, train_wall=36, gb_free=17.5, wall=26572
2023-07-04 11:17:22 | INFO | train_inner | epoch 036:   1033 / 1474 loss=3.955, trans_loss=5.12, nll_loss=2.357, w2v_ctc_loss=1.153, task_loss=0, contrastive_loss=0.115, total=4190.15, n_correct=2837.93, ppl=5.12, accuracy=67.729, wps=11370.9, ups=2.71, wpb=4190.1, bsz=151.7, num_updates=52600, lr=6.16626e-05, gnorm=1.05, clip=0, loss_scale=32, train_wall=36, gb_free=13.1, wall=26608
2023-07-04 11:18:00 | INFO | train_inner | epoch 036:   1133 / 1474 loss=3.958, trans_loss=5.117, nll_loss=2.353, w2v_ctc_loss=1.161, task_loss=0, contrastive_loss=0.146, total=4122.99, n_correct=2791.6, ppl=5.11, accuracy=67.708, wps=11105.2, ups=2.69, wpb=4123, bsz=152.4, num_updates=52700, lr=6.16041e-05, gnorm=1.07, clip=0, loss_scale=32, train_wall=37, gb_free=17.1, wall=26646
2023-07-04 11:18:36 | INFO | train_inner | epoch 036:   1233 / 1474 loss=3.958, trans_loss=5.123, nll_loss=2.361, w2v_ctc_loss=1.16, task_loss=0, contrastive_loss=0.106, total=4050.06, n_correct=2739.46, ppl=5.14, accuracy=67.64, wps=11024.4, ups=2.72, wpb=4050.1, bsz=140, num_updates=52800, lr=6.15457e-05, gnorm=1.057, clip=0, loss_scale=32, train_wall=36, gb_free=17.1, wall=26682
2023-07-04 11:19:13 | INFO | train_inner | epoch 036:   1333 / 1474 loss=3.959, trans_loss=5.122, nll_loss=2.36, w2v_ctc_loss=1.156, task_loss=0, contrastive_loss=0.131, total=4110.28, n_correct=2781.14, ppl=5.13, accuracy=67.663, wps=11284.2, ups=2.75, wpb=4110.3, bsz=153.2, num_updates=52900, lr=6.14875e-05, gnorm=1.045, clip=0, loss_scale=32, train_wall=36, gb_free=16.8, wall=26719
2023-07-04 11:19:50 | INFO | train_inner | epoch 036:   1433 / 1474 loss=3.981, trans_loss=5.137, nll_loss=2.379, w2v_ctc_loss=1.174, task_loss=0, contrastive_loss=0.236, total=4043.82, n_correct=2725.03, ppl=5.2, accuracy=67.388, wps=10897.8, ups=2.69, wpb=4043.8, bsz=138.5, num_updates=53000, lr=6.14295e-05, gnorm=1.073, clip=0, loss_scale=32, train_wall=37, gb_free=17.7, wall=26756
2023-07-04 11:20:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 11:20:29 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 4.341 | trans_loss 5.553 | nll_loss 2.824 | w2v_ctc_loss 1.388 | task_loss 0 | contrastive_loss 0.265 | total 4003.4 | n_correct 2493.3 | ppl 7.08 | accuracy 62.28 | uer 16.526 | wer 18.221 | raw_wer 18.221 | bleu 20.32 | wps 2293.3 | wpb 4003.4 | bsz 141.8 | num_updates 53041 | best_bleu 20.67
2023-07-04 11:20:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 53041 updates
2023-07-04 11:20:29 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.3206.pt
2023-07-04 11:20:31 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.3206.pt
2023-07-04 11:20:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.3206.pt (epoch 36 @ 53041 updates, score 20.32) (writing took 5.484769676346332 seconds)
2023-07-04 11:20:34 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-07-04 11:20:34 | INFO | train | epoch 036 | loss 3.956 | trans_loss 5.115 | nll_loss 2.35 | w2v_ctc_loss 1.145 | task_loss 0 | contrastive_loss 0.224 | total 4138.65 | n_correct 2806.35 | ppl 5.1 | accuracy 67.808 | wps 9958.9 | ups 2.41 | wpb 4138.6 | bsz 152.8 | num_updates 53041 | lr 6.14058e-05 | gnorm 1.051 | clip 0 | loss_scale 32 | train_wall 538 | gb_free 17.2 | wall 26800
2023-07-04 11:20:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 11:20:35 | INFO | fairseq.trainer | begin training epoch 37
2023-07-04 11:20:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 11:21:04 | INFO | train_inner | epoch 037:     59 / 1474 loss=3.928, trans_loss=5.092, nll_loss=2.321, w2v_ctc_loss=1.12, task_loss=0, contrastive_loss=0.141, total=4094.27, n_correct=2792.17, ppl=5, accuracy=68.197, wps=5491.9, ups=1.34, wpb=4094.3, bsz=150.1, num_updates=53100, lr=6.13716e-05, gnorm=1.044, clip=0, loss_scale=32, train_wall=36, gb_free=16.2, wall=26830
2023-07-04 11:21:42 | INFO | train_inner | epoch 037:    159 / 1474 loss=3.943, trans_loss=5.099, nll_loss=2.33, w2v_ctc_loss=1.128, task_loss=0, contrastive_loss=0.247, total=4128.52, n_correct=2811.38, ppl=5.03, accuracy=68.097, wps=11043, ups=2.67, wpb=4128.5, bsz=153.7, num_updates=53200, lr=6.13139e-05, gnorm=1.051, clip=0, loss_scale=32, train_wall=37, gb_free=15.8, wall=26868
2023-07-04 11:22:19 | INFO | train_inner | epoch 037:    259 / 1474 loss=3.919, trans_loss=5.083, nll_loss=2.309, w2v_ctc_loss=1.113, task_loss=0, contrastive_loss=0.13, total=4191.64, n_correct=2865.81, ppl=4.96, accuracy=68.37, wps=11315.5, ups=2.7, wpb=4191.6, bsz=160, num_updates=53300, lr=6.12564e-05, gnorm=1.035, clip=0, loss_scale=32, train_wall=37, gb_free=17, wall=26905
2023-07-04 11:22:56 | INFO | train_inner | epoch 037:    359 / 1474 loss=3.939, trans_loss=5.097, nll_loss=2.326, w2v_ctc_loss=1.146, task_loss=0, contrastive_loss=0.143, total=4168.16, n_correct=2841.65, ppl=5.01, accuracy=68.175, wps=11358.4, ups=2.73, wpb=4168.2, bsz=152.7, num_updates=53400, lr=6.1199e-05, gnorm=1.054, clip=0, loss_scale=32, train_wall=36, gb_free=17.3, wall=26942
2023-07-04 11:23:33 | INFO | train_inner | epoch 037:    459 / 1474 loss=3.981, trans_loss=5.119, nll_loss=2.356, w2v_ctc_loss=1.127, task_loss=0, contrastive_loss=0.565, total=4179.15, n_correct=2827.92, ppl=5.12, accuracy=67.667, wps=11014, ups=2.64, wpb=4179.1, bsz=158.9, num_updates=53500, lr=6.11418e-05, gnorm=1.066, clip=0, loss_scale=32, train_wall=38, gb_free=14.3, wall=26980
2023-07-04 11:24:13 | INFO | train_inner | epoch 037:    559 / 1474 loss=3.936, trans_loss=5.097, nll_loss=2.327, w2v_ctc_loss=1.142, task_loss=0, contrastive_loss=0.125, total=4092.13, n_correct=2786.83, ppl=5.02, accuracy=68.102, wps=10285.2, ups=2.51, wpb=4092.1, bsz=149.9, num_updates=53600, lr=6.10847e-05, gnorm=1.044, clip=0, loss_scale=32, train_wall=39, gb_free=17.1, wall=27019
2023-07-04 11:24:54 | INFO | train_inner | epoch 037:    659 / 1474 loss=3.95, trans_loss=5.107, nll_loss=2.339, w2v_ctc_loss=1.162, task_loss=0, contrastive_loss=0.14, total=4102.49, n_correct=2783.15, ppl=5.06, accuracy=67.841, wps=10091.6, ups=2.46, wpb=4102.5, bsz=146, num_updates=53700, lr=6.10278e-05, gnorm=1.064, clip=0, loss_scale=32, train_wall=40, gb_free=17.4, wall=27060
2023-07-04 11:25:35 | INFO | train_inner | epoch 037:    759 / 1474 loss=3.946, trans_loss=5.106, nll_loss=2.339, w2v_ctc_loss=1.13, task_loss=0, contrastive_loss=0.257, total=4123.95, n_correct=2803.47, ppl=5.06, accuracy=67.98, wps=9982.7, ups=2.42, wpb=4123.9, bsz=152.4, num_updates=53800, lr=6.09711e-05, gnorm=1.038, clip=0, loss_scale=32, train_wall=41, gb_free=17.1, wall=27101
2023-07-04 11:26:12 | INFO | train_inner | epoch 037:    859 / 1474 loss=3.933, trans_loss=5.097, nll_loss=2.327, w2v_ctc_loss=1.128, task_loss=0, contrastive_loss=0.13, total=4159.03, n_correct=2831.79, ppl=5.02, accuracy=68.088, wps=11396.4, ups=2.74, wpb=4159, bsz=157.9, num_updates=53900, lr=6.09145e-05, gnorm=1.05, clip=0, loss_scale=32, train_wall=36, gb_free=16.1, wall=27138
2023-07-04 11:26:49 | INFO | train_inner | epoch 037:    959 / 1474 loss=3.963, trans_loss=5.122, nll_loss=2.359, w2v_ctc_loss=1.168, task_loss=0, contrastive_loss=0.139, total=4097.89, n_correct=2776.16, ppl=5.13, accuracy=67.746, wps=11120.8, ups=2.71, wpb=4097.9, bsz=146.2, num_updates=54000, lr=6.08581e-05, gnorm=1.067, clip=0, loss_scale=32, train_wall=36, gb_free=16.3, wall=27175
2023-07-04 11:26:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 11:27:14 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 4.35 | trans_loss 5.553 | nll_loss 2.822 | w2v_ctc_loss 1.414 | task_loss 0 | contrastive_loss 0.27 | total 4003.4 | n_correct 2496.5 | ppl 7.07 | accuracy 62.359 | uer 16.646 | wer 18.482 | raw_wer 18.482 | bleu 20.08 | wps 2108.9 | wpb 4003.4 | bsz 141.8 | num_updates 54000 | best_bleu 20.67
2023-07-04 11:27:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54000 updates
2023-07-04 11:27:14 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_37_54000.pt
2023-07-04 11:27:16 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_37_54000.pt
2023-07-04 11:27:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_37_54000.pt (epoch 37 @ 54000 updates, score 20.08) (writing took 5.337431441992521 seconds)
2023-07-04 11:27:56 | INFO | train_inner | epoch 037:   1059 / 1474 loss=3.948, trans_loss=5.097, nll_loss=2.328, w2v_ctc_loss=1.114, task_loss=0, contrastive_loss=0.391, total=4162.64, n_correct=2837.6, ppl=5.02, accuracy=68.168, wps=6151.4, ups=1.48, wpb=4162.6, bsz=159.9, num_updates=54100, lr=6.08018e-05, gnorm=1.047, clip=0, loss_scale=32, train_wall=36, gb_free=16.9, wall=27242
2023-07-04 11:28:34 | INFO | train_inner | epoch 037:   1159 / 1474 loss=3.968, trans_loss=5.117, nll_loss=2.353, w2v_ctc_loss=1.134, task_loss=0, contrastive_loss=0.449, total=4176.35, n_correct=2833.44, ppl=5.11, accuracy=67.845, wps=11208.7, ups=2.68, wpb=4176.4, bsz=156.1, num_updates=54200, lr=6.07457e-05, gnorm=1.038, clip=0, loss_scale=32, train_wall=37, gb_free=16.4, wall=27280
2023-07-04 11:29:11 | INFO | train_inner | epoch 037:   1259 / 1474 loss=3.951, trans_loss=5.117, nll_loss=2.353, w2v_ctc_loss=1.136, task_loss=0, contrastive_loss=0.146, total=4167.2, n_correct=2825.22, ppl=5.11, accuracy=67.797, wps=11233.3, ups=2.7, wpb=4167.2, bsz=155.9, num_updates=54300, lr=6.06897e-05, gnorm=1.066, clip=0, loss_scale=32, train_wall=37, gb_free=16.4, wall=27317
2023-07-04 11:29:48 | INFO | train_inner | epoch 037:   1359 / 1474 loss=3.961, trans_loss=5.119, nll_loss=2.355, w2v_ctc_loss=1.173, task_loss=0, contrastive_loss=0.126, total=4072.63, n_correct=2754.46, ppl=5.12, accuracy=67.633, wps=10919.3, ups=2.68, wpb=4072.6, bsz=143, num_updates=54400, lr=6.06339e-05, gnorm=1.066, clip=0, loss_scale=32, train_wall=37, gb_free=16.4, wall=27354
2023-07-04 11:30:25 | INFO | train_inner | epoch 037:   1459 / 1474 loss=3.953, trans_loss=5.116, nll_loss=2.352, w2v_ctc_loss=1.134, task_loss=0, contrastive_loss=0.19, total=4155.97, n_correct=2817.03, ppl=5.11, accuracy=67.783, wps=11340.8, ups=2.73, wpb=4156, bsz=152.6, num_updates=54500, lr=6.05783e-05, gnorm=1.06, clip=0, loss_scale=32, train_wall=36, gb_free=16.5, wall=27391
2023-07-04 11:30:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 11:30:54 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 4.35 | trans_loss 5.555 | nll_loss 2.826 | w2v_ctc_loss 1.412 | task_loss 0 | contrastive_loss 0.27 | total 4003.4 | n_correct 2500.5 | ppl 7.09 | accuracy 62.459 | uer 16.651 | wer 18.582 | raw_wer 18.582 | bleu 20.45 | wps 2273.3 | wpb 4003.4 | bsz 141.8 | num_updates 54515 | best_bleu 20.67
2023-07-04 11:30:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54515 updates
2023-07-04 11:30:54 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.4505.pt
2023-07-04 11:30:57 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.4505.pt
2023-07-04 11:31:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.4505.pt (epoch 37 @ 54515 updates, score 20.45) (writing took 5.417543808929622 seconds)
2023-07-04 11:31:00 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-07-04 11:31:00 | INFO | train | epoch 037 | loss 3.948 | trans_loss 5.106 | nll_loss 2.338 | w2v_ctc_loss 1.137 | task_loss 0 | contrastive_loss 0.225 | total 4138.65 | n_correct 2812.86 | ppl 5.06 | accuracy 67.966 | wps 9748.3 | ups 2.36 | wpb 4138.6 | bsz 152.8 | num_updates 54515 | lr 6.05699e-05 | gnorm 1.053 | clip 0 | loss_scale 32 | train_wall 551 | gb_free 13.5 | wall 27426
2023-07-04 11:31:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 11:31:00 | INFO | fairseq.trainer | begin training epoch 38
2023-07-04 11:31:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 11:31:40 | INFO | train_inner | epoch 038:     85 / 1474 loss=3.926, trans_loss=5.089, nll_loss=2.316, w2v_ctc_loss=1.126, task_loss=0, contrastive_loss=0.121, total=4085.19, n_correct=2787.73, ppl=4.98, accuracy=68.24, wps=5432.2, ups=1.33, wpb=4085.2, bsz=146.8, num_updates=54600, lr=6.05228e-05, gnorm=1.06, clip=0, loss_scale=64, train_wall=37, gb_free=17.4, wall=27466
2023-07-04 11:32:17 | INFO | train_inner | epoch 038:    185 / 1474 loss=3.919, trans_loss=5.084, nll_loss=2.309, w2v_ctc_loss=1.118, task_loss=0, contrastive_loss=0.123, total=4081.12, n_correct=2789.45, ppl=4.95, accuracy=68.35, wps=10986.7, ups=2.69, wpb=4081.1, bsz=146.3, num_updates=54700, lr=6.04674e-05, gnorm=1.053, clip=0, loss_scale=64, train_wall=37, gb_free=17.2, wall=27503
2023-07-04 11:32:54 | INFO | train_inner | epoch 038:    285 / 1474 loss=3.931, trans_loss=5.092, nll_loss=2.321, w2v_ctc_loss=1.125, task_loss=0, contrastive_loss=0.162, total=4073.75, n_correct=2780.12, ppl=5, accuracy=68.245, wps=11078.8, ups=2.72, wpb=4073.8, bsz=147.9, num_updates=54800, lr=6.04122e-05, gnorm=1.064, clip=0, loss_scale=64, train_wall=36, gb_free=17.3, wall=27540
2023-07-04 11:33:31 | INFO | train_inner | epoch 038:    385 / 1474 loss=3.928, trans_loss=5.088, nll_loss=2.314, w2v_ctc_loss=1.126, task_loss=0, contrastive_loss=0.161, total=4173.43, n_correct=2851.4, ppl=4.97, accuracy=68.323, wps=11341, ups=2.72, wpb=4173.4, bsz=154.1, num_updates=54900, lr=6.03572e-05, gnorm=1.039, clip=0, loss_scale=64, train_wall=36, gb_free=14.3, wall=27577
2023-07-04 11:34:07 | INFO | train_inner | epoch 038:    485 / 1474 loss=3.926, trans_loss=5.089, nll_loss=2.317, w2v_ctc_loss=1.117, task_loss=0, contrastive_loss=0.156, total=4192.03, n_correct=2859.83, ppl=4.98, accuracy=68.221, wps=11368.9, ups=2.71, wpb=4192, bsz=156, num_updates=55000, lr=6.03023e-05, gnorm=1.055, clip=0, loss_scale=64, train_wall=36, gb_free=16.5, wall=27613
tensor(0.0295, device='cuda:0')
tensor(0.0009, device='cuda:0')
2023-07-04 11:34:45 | INFO | train_inner | epoch 038:    585 / 1474 loss=3.974, trans_loss=5.116, nll_loss=2.351, w2v_ctc_loss=1.133, task_loss=0, contrastive_loss=0.489, total=4172.44, n_correct=2827.13, ppl=5.1, accuracy=67.757, wps=11142.6, ups=2.67, wpb=4172.4, bsz=154.4, num_updates=55100, lr=6.02475e-05, gnorm=1.059, clip=0, loss_scale=64, train_wall=37, gb_free=16.5, wall=27651
2023-07-04 11:35:22 | INFO | train_inner | epoch 038:    685 / 1474 loss=3.946, trans_loss=5.092, nll_loss=2.322, w2v_ctc_loss=1.111, task_loss=0, contrastive_loss=0.457, total=4179.22, n_correct=2847.51, ppl=5, accuracy=68.135, wps=11260.7, ups=2.69, wpb=4179.2, bsz=161.2, num_updates=55200, lr=6.01929e-05, gnorm=1.045, clip=0, loss_scale=64, train_wall=37, gb_free=13.6, wall=27688
2023-07-04 11:35:59 | INFO | train_inner | epoch 038:    785 / 1474 loss=3.933, trans_loss=5.085, nll_loss=2.313, w2v_ctc_loss=1.113, task_loss=0, contrastive_loss=0.305, total=4180.46, n_correct=2856.94, ppl=4.97, accuracy=68.34, wps=11341.1, ups=2.71, wpb=4180.5, bsz=162.9, num_updates=55300, lr=6.01385e-05, gnorm=1.041, clip=0, loss_scale=64, train_wall=36, gb_free=16.2, wall=27725
2023-07-04 11:36:35 | INFO | train_inner | epoch 038:    885 / 1474 loss=3.933, trans_loss=5.092, nll_loss=2.322, w2v_ctc_loss=1.136, task_loss=0, contrastive_loss=0.132, total=4122.77, n_correct=2811.77, ppl=5, accuracy=68.201, wps=11296.1, ups=2.74, wpb=4122.8, bsz=155.9, num_updates=55400, lr=6.00842e-05, gnorm=1.055, clip=0, loss_scale=64, train_wall=36, gb_free=15.9, wall=27761
2023-07-04 11:37:12 | INFO | train_inner | epoch 038:    985 / 1474 loss=3.954, trans_loss=5.113, nll_loss=2.347, w2v_ctc_loss=1.142, task_loss=0, contrastive_loss=0.199, total=4116.2, n_correct=2790.98, ppl=5.09, accuracy=67.805, wps=11112, ups=2.7, wpb=4116.2, bsz=150.8, num_updates=55500, lr=6.003e-05, gnorm=1.044, clip=0, loss_scale=64, train_wall=37, gb_free=16.6, wall=27798
2023-07-04 11:37:49 | INFO | train_inner | epoch 038:   1085 / 1474 loss=3.945, trans_loss=5.096, nll_loss=2.327, w2v_ctc_loss=1.132, task_loss=0, contrastive_loss=0.258, total=4248.59, n_correct=2894.5, ppl=5.02, accuracy=68.128, wps=11554.8, ups=2.72, wpb=4248.6, bsz=164.4, num_updates=55600, lr=5.9976e-05, gnorm=1.04, clip=0, loss_scale=64, train_wall=36, gb_free=16.9, wall=27835
2023-07-04 11:38:27 | INFO | train_inner | epoch 038:   1185 / 1474 loss=3.955, trans_loss=5.116, nll_loss=2.352, w2v_ctc_loss=1.156, task_loss=0, contrastive_loss=0.137, total=4077.59, n_correct=2762.46, ppl=5.11, accuracy=67.747, wps=10880.5, ups=2.67, wpb=4077.6, bsz=143.7, num_updates=55700, lr=5.99222e-05, gnorm=1.049, clip=0, loss_scale=64, train_wall=37, gb_free=14.6, wall=27873
2023-07-04 11:39:04 | INFO | train_inner | epoch 038:   1285 / 1474 loss=3.949, trans_loss=5.115, nll_loss=2.351, w2v_ctc_loss=1.14, task_loss=0, contrastive_loss=0.133, total=4146.3, n_correct=2811.55, ppl=5.1, accuracy=67.809, wps=11210.4, ups=2.7, wpb=4146.3, bsz=147.8, num_updates=55800, lr=5.98684e-05, gnorm=1.049, clip=0, loss_scale=64, train_wall=37, gb_free=17.9, wall=27910
2023-07-04 11:39:40 | INFO | train_inner | epoch 038:   1385 / 1474 loss=3.955, trans_loss=5.113, nll_loss=2.348, w2v_ctc_loss=1.136, task_loss=0, contrastive_loss=0.234, total=4156.39, n_correct=2820.43, ppl=5.09, accuracy=67.858, wps=11304.7, ups=2.72, wpb=4156.4, bsz=155.3, num_updates=55900, lr=5.98149e-05, gnorm=1.055, clip=0, loss_scale=64, train_wall=36, gb_free=16.8, wall=27946
2023-07-04 11:40:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0295, device='cuda:7')
tensor(0.0009, device='cuda:7')
tensor(0.0295, device='cuda:4')
tensor(0.0009, device='cuda:4')
tensor(0.0295, device='cuda:6')
tensor(0.0009, device='cuda:6')
tensor(0.0295, device='cuda:1')
tensor(0.0009, device='cuda:1')
tensor(0.0295, device='cuda:5')
tensor(0.0009, device='cuda:5')
tensor(0.0295, device='cuda:3')
tensor(0.0009, device='cuda:3')
tensor(0.0295, device='cuda:2')
tensor(0.0009, device='cuda:2')
2023-07-04 11:40:38 | INFO | dev_st | epoch 038 | valid on 'dev_st' subset | loss 4.359 | trans_loss 5.559 | nll_loss 2.831 | w2v_ctc_loss 1.428 | task_loss 0 | contrastive_loss 0.273 | total 4003.4 | n_correct 2494.1 | ppl 7.12 | accuracy 62.3 | uer 16.656 | wer 18.433 | raw_wer 18.433 | bleu 20.29 | wps 2149.6 | wpb 4003.4 | bsz 141.8 | num_updates 55989 | best_bleu 20.67
2023-07-04 11:40:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 55989 updates
2023-07-04 11:40:38 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_last.pt
2023-07-04 11:40:42 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_last.pt
2023-07-04 11:40:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_last.pt (epoch 38 @ 55989 updates, score 20.29) (writing took 4.215254643931985 seconds)
2023-07-04 11:40:42 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-07-04 11:40:42 | INFO | train | epoch 038 | loss 3.942 | trans_loss 5.099 | nll_loss 2.33 | w2v_ctc_loss 1.13 | task_loss 0 | contrastive_loss 0.225 | total 4138.65 | n_correct 2817.29 | ppl 5.03 | accuracy 68.073 | wps 10480.4 | ups 2.53 | wpb 4138.6 | bsz 152.8 | num_updates 55989 | lr 5.97673e-05 | gnorm 1.051 | clip 0 | loss_scale 64 | train_wall 539 | gb_free 17 | wall 28008
2023-07-04 11:40:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 11:40:43 | INFO | fairseq.trainer | begin training epoch 39
2023-07-04 11:40:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 11:40:55 | INFO | train_inner | epoch 039:     11 / 1474 loss=3.956, trans_loss=5.114, nll_loss=2.348, w2v_ctc_loss=1.145, task_loss=0, contrastive_loss=0.256, total=4033.2, n_correct=2738.28, ppl=5.09, accuracy=67.893, wps=5415.4, ups=1.34, wpb=4033.2, bsz=142.9, num_updates=56000, lr=5.97614e-05, gnorm=1.069, clip=0, loss_scale=64, train_wall=36, gb_free=17.7, wall=28021
2023-07-04 11:40:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 11:41:19 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 4.361 | trans_loss 5.559 | nll_loss 2.832 | w2v_ctc_loss 1.438 | task_loss 0 | contrastive_loss 0.272 | total 4003.4 | n_correct 2492.4 | ppl 7.12 | accuracy 62.257 | uer 16.781 | wer 18.571 | raw_wer 18.571 | bleu 20.41 | wps 2281.8 | wpb 4003.4 | bsz 141.8 | num_updates 56000 | best_bleu 20.67
2023-07-04 11:41:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 56000 updates
2023-07-04 11:41:19 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_39_56000.pt
2023-07-04 11:41:21 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_39_56000.pt
2023-07-04 11:41:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_39_56000.pt (epoch 39 @ 56000 updates, score 20.41) (writing took 8.33189309714362 seconds)
2023-07-04 11:42:04 | INFO | train_inner | epoch 039:    111 / 1474 loss=3.917, trans_loss=5.075, nll_loss=2.297, w2v_ctc_loss=1.13, task_loss=0, contrastive_loss=0.123, total=4057.77, n_correct=2782.07, ppl=4.91, accuracy=68.562, wps=5877.4, ups=1.45, wpb=4057.8, bsz=143.2, num_updates=56100, lr=5.97081e-05, gnorm=1.064, clip=0, loss_scale=64, train_wall=36, gb_free=17.8, wall=28090
2023-07-04 11:42:41 | INFO | train_inner | epoch 039:    211 / 1474 loss=3.907, trans_loss=5.067, nll_loss=2.287, w2v_ctc_loss=1.115, task_loss=0, contrastive_loss=0.121, total=4134.99, n_correct=2834.12, ppl=4.88, accuracy=68.54, wps=11304.1, ups=2.73, wpb=4135, bsz=150.2, num_updates=56200, lr=5.9655e-05, gnorm=1.059, clip=0, loss_scale=64, train_wall=36, gb_free=16.2, wall=28127
2023-07-04 11:43:17 | INFO | train_inner | epoch 039:    311 / 1474 loss=3.911, trans_loss=5.073, nll_loss=2.295, w2v_ctc_loss=1.112, task_loss=0, contrastive_loss=0.128, total=4135.88, n_correct=2836.61, ppl=4.91, accuracy=68.585, wps=11281.8, ups=2.73, wpb=4135.9, bsz=149.8, num_updates=56300, lr=5.9602e-05, gnorm=1.042, clip=0, loss_scale=64, train_wall=36, gb_free=13.6, wall=28163
2023-07-04 11:43:54 | INFO | train_inner | epoch 039:    411 / 1474 loss=3.948, trans_loss=5.089, nll_loss=2.318, w2v_ctc_loss=1.13, task_loss=0, contrastive_loss=0.424, total=4128.52, n_correct=2817.37, ppl=4.99, accuracy=68.242, wps=11134, ups=2.7, wpb=4128.5, bsz=156.1, num_updates=56400, lr=5.95491e-05, gnorm=1.058, clip=0, loss_scale=64, train_wall=37, gb_free=13.2, wall=28200
2023-07-04 11:44:31 | INFO | train_inner | epoch 039:    511 / 1474 loss=3.938, trans_loss=5.086, nll_loss=2.312, w2v_ctc_loss=1.108, task_loss=0, contrastive_loss=0.441, total=4143.39, n_correct=2826.59, ppl=4.97, accuracy=68.219, wps=11148.7, ups=2.69, wpb=4143.4, bsz=155.8, num_updates=56500, lr=5.94964e-05, gnorm=1.053, clip=0, loss_scale=64, train_wall=37, gb_free=17.2, wall=28238
2023-07-04 11:45:08 | INFO | train_inner | epoch 039:    611 / 1474 loss=3.935, trans_loss=5.094, nll_loss=2.323, w2v_ctc_loss=1.116, task_loss=0, contrastive_loss=0.235, total=4131.41, n_correct=2818.99, ppl=5, accuracy=68.233, wps=11185.8, ups=2.71, wpb=4131.4, bsz=151.4, num_updates=56600, lr=5.94438e-05, gnorm=1.054, clip=0, loss_scale=64, train_wall=37, gb_free=16.2, wall=28274
2023-07-04 11:45:45 | INFO | train_inner | epoch 039:    711 / 1474 loss=3.93, trans_loss=5.091, nll_loss=2.319, w2v_ctc_loss=1.106, task_loss=0, contrastive_loss=0.22, total=4133.78, n_correct=2818.74, ppl=4.99, accuracy=68.188, wps=11402.9, ups=2.76, wpb=4133.8, bsz=152.9, num_updates=56700, lr=5.93914e-05, gnorm=1.043, clip=0, loss_scale=128, train_wall=36, gb_free=16.4, wall=28311
2023-07-04 11:46:22 | INFO | train_inner | epoch 039:    811 / 1474 loss=3.936, trans_loss=5.095, nll_loss=2.325, w2v_ctc_loss=1.138, task_loss=0, contrastive_loss=0.145, total=4178.43, n_correct=2846.07, ppl=5.01, accuracy=68.113, wps=11282.8, ups=2.7, wpb=4178.4, bsz=154.9, num_updates=56800, lr=5.93391e-05, gnorm=1.054, clip=0, loss_scale=128, train_wall=37, gb_free=17.3, wall=28348
2023-07-04 11:46:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-04 11:46:59 | INFO | train_inner | epoch 039:    912 / 1474 loss=3.924, trans_loss=5.088, nll_loss=2.316, w2v_ctc_loss=1.122, task_loss=0, contrastive_loss=0.118, total=4114.56, n_correct=2805.4, ppl=4.98, accuracy=68.182, wps=11130.4, ups=2.71, wpb=4114.6, bsz=148.1, num_updates=56900, lr=5.92869e-05, gnorm=1.04, clip=0, loss_scale=64, train_wall=37, gb_free=12.8, wall=28385
2023-07-04 11:47:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-04 11:47:36 | INFO | train_inner | epoch 039:   1013 / 1474 loss=3.944, trans_loss=5.105, nll_loss=2.338, w2v_ctc_loss=1.137, task_loss=0, contrastive_loss=0.16, total=4173.51, n_correct=2838.78, ppl=5.05, accuracy=68.019, wps=11060.6, ups=2.65, wpb=4173.5, bsz=155.1, num_updates=57000, lr=5.92349e-05, gnorm=1.053, clip=0, loss_scale=32, train_wall=37, gb_free=14.3, wall=28422
2023-07-04 11:48:13 | INFO | train_inner | epoch 039:   1113 / 1474 loss=3.939, trans_loss=5.09, nll_loss=2.32, w2v_ctc_loss=1.118, task_loss=0, contrastive_loss=0.321, total=4196.16, n_correct=2862.31, ppl=4.99, accuracy=68.213, wps=11342.7, ups=2.7, wpb=4196.2, bsz=161.5, num_updates=57100, lr=5.9183e-05, gnorm=1.044, clip=0, loss_scale=32, train_wall=37, gb_free=16.3, wall=28459
2023-07-04 11:48:50 | INFO | train_inner | epoch 039:   1213 / 1474 loss=3.945, trans_loss=5.104, nll_loss=2.337, w2v_ctc_loss=1.128, task_loss=0, contrastive_loss=0.21, total=4129.4, n_correct=2804.18, ppl=5.05, accuracy=67.908, wps=11216.4, ups=2.72, wpb=4129.4, bsz=154.4, num_updates=57200, lr=5.91312e-05, gnorm=1.067, clip=0, loss_scale=32, train_wall=36, gb_free=17.7, wall=28496
2023-07-04 11:49:27 | INFO | train_inner | epoch 039:   1313 / 1474 loss=3.95, trans_loss=5.109, nll_loss=2.343, w2v_ctc_loss=1.141, task_loss=0, contrastive_loss=0.179, total=4169.96, n_correct=2834, ppl=5.07, accuracy=67.962, wps=11303.6, ups=2.71, wpb=4170, bsz=157, num_updates=57300, lr=5.90796e-05, gnorm=1.067, clip=0, loss_scale=32, train_wall=36, gb_free=13, wall=28533
2023-07-04 11:50:04 | INFO | train_inner | epoch 039:   1413 / 1474 loss=3.937, trans_loss=5.103, nll_loss=2.334, w2v_ctc_loss=1.134, task_loss=0, contrastive_loss=0.109, total=4062.74, n_correct=2762.19, ppl=5.04, accuracy=67.988, wps=11075.8, ups=2.73, wpb=4062.7, bsz=140.3, num_updates=57400, lr=5.90281e-05, gnorm=1.059, clip=0, loss_scale=32, train_wall=36, gb_free=16.8, wall=28570
2023-07-04 11:50:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 11:50:52 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 4.365 | trans_loss 5.555 | nll_loss 2.825 | w2v_ctc_loss 1.459 | task_loss 0 | contrastive_loss 0.272 | total 4003.4 | n_correct 2500.7 | ppl 7.08 | accuracy 62.464 | uer 16.479 | wer 18.191 | raw_wer 18.191 | bleu 20.53 | wps 2155.4 | wpb 4003.4 | bsz 141.8 | num_updates 57461 | best_bleu 20.67
2023-07-04 11:50:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 57461 updates
2023-07-04 11:50:52 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.5309.pt
2023-07-04 11:50:54 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.5309.pt
2023-07-04 11:50:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint.best_bleu_20.5309.pt (epoch 39 @ 57461 updates, score 20.53) (writing took 5.619727172888815 seconds)
2023-07-04 11:50:58 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-07-04 11:50:58 | INFO | train | epoch 039 | loss 3.933 | trans_loss 5.091 | nll_loss 2.32 | w2v_ctc_loss 1.123 | task_loss 0 | contrastive_loss 0.209 | total 4136.28 | n_correct 2821.08 | ppl 4.99 | accuracy 68.203 | wps 9894.3 | ups 2.39 | wpb 4136.3 | bsz 152.5 | num_updates 57461 | lr 5.89968e-05 | gnorm 1.054 | clip 0 | loss_scale 32 | train_wall 537 | gb_free 15.9 | wall 28624
2023-07-04 11:50:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 11:50:58 | INFO | fairseq.trainer | begin training epoch 40
2023-07-04 11:50:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 11:51:20 | INFO | train_inner | epoch 040:     39 / 1474 loss=3.926, trans_loss=5.093, nll_loss=2.324, w2v_ctc_loss=1.106, task_loss=0, contrastive_loss=0.154, total=4157.73, n_correct=2836.16, ppl=5.01, accuracy=68.214, wps=5434.8, ups=1.31, wpb=4157.7, bsz=155, num_updates=57500, lr=5.89768e-05, gnorm=1.047, clip=0, loss_scale=32, train_wall=37, gb_free=15.8, wall=28646
2023-07-04 11:51:57 | INFO | train_inner | epoch 040:    139 / 1474 loss=3.899, trans_loss=5.056, nll_loss=2.273, w2v_ctc_loss=1.107, task_loss=0, contrastive_loss=0.14, total=4158.81, n_correct=2863.88, ppl=4.83, accuracy=68.863, wps=11319.4, ups=2.72, wpb=4158.8, bsz=153.3, num_updates=57600, lr=5.89256e-05, gnorm=1.049, clip=0, loss_scale=32, train_wall=36, gb_free=16.5, wall=28683
2023-07-04 11:52:34 | INFO | train_inner | epoch 040:    239 / 1474 loss=3.913, trans_loss=5.071, nll_loss=2.293, w2v_ctc_loss=1.119, task_loss=0, contrastive_loss=0.137, total=4104.08, n_correct=2810.79, ppl=4.9, accuracy=68.488, wps=11218.5, ups=2.73, wpb=4104.1, bsz=150, num_updates=57700, lr=5.88745e-05, gnorm=1.057, clip=0, loss_scale=32, train_wall=36, gb_free=17.9, wall=28720
2023-07-04 11:53:10 | INFO | train_inner | epoch 040:    339 / 1474 loss=3.908, trans_loss=5.07, nll_loss=2.293, w2v_ctc_loss=1.098, task_loss=0, contrastive_loss=0.157, total=4149.88, n_correct=2850.44, ppl=4.9, accuracy=68.687, wps=11265.6, ups=2.71, wpb=4149.9, bsz=159.5, num_updates=57800, lr=5.88235e-05, gnorm=1.044, clip=0, loss_scale=32, train_wall=36, gb_free=14.4, wall=28757
2023-07-04 11:53:48 | INFO | train_inner | epoch 040:    439 / 1474 loss=3.926, trans_loss=5.078, nll_loss=2.303, w2v_ctc_loss=1.109, task_loss=0, contrastive_loss=0.31, total=4147.99, n_correct=2836.6, ppl=4.93, accuracy=68.385, wps=11150.9, ups=2.69, wpb=4148, bsz=156.2, num_updates=57900, lr=5.87727e-05, gnorm=1.048, clip=0, loss_scale=32, train_wall=37, gb_free=17.1, wall=28794
2023-07-04 11:54:25 | INFO | train_inner | epoch 040:    539 / 1474 loss=3.927, trans_loss=5.075, nll_loss=2.3, w2v_ctc_loss=1.099, task_loss=0, contrastive_loss=0.36, total=4166.35, n_correct=2853.1, ppl=4.92, accuracy=68.48, wps=11225.9, ups=2.69, wpb=4166.4, bsz=157.8, num_updates=58000, lr=5.8722e-05, gnorm=1.053, clip=0, loss_scale=32, train_wall=37, gb_free=17.9, wall=28831
2023-07-04 11:54:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 11:54:49 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 4.378 | trans_loss 5.563 | nll_loss 2.836 | w2v_ctc_loss 1.48 | task_loss 0 | contrastive_loss 0.276 | total 4003.4 | n_correct 2494.4 | ppl 7.14 | accuracy 62.307 | uer 16.595 | wer 18.262 | raw_wer 18.262 | bleu 20.5 | wps 2188.4 | wpb 4003.4 | bsz 141.8 | num_updates 58000 | best_bleu 20.67
2023-07-04 11:54:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58000 updates
2023-07-04 11:54:49 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_40_58000.pt
2023-07-04 11:54:52 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_40_58000.pt
2023-07-04 11:54:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_40_58000.pt (epoch 40 @ 58000 updates, score 20.5) (writing took 6.441067900042981 seconds)
2023-07-04 11:55:34 | INFO | train_inner | epoch 040:    639 / 1474 loss=3.94, trans_loss=5.096, nll_loss=2.326, w2v_ctc_loss=1.141, task_loss=0, contrastive_loss=0.162, total=4121.6, n_correct=2806.36, ppl=5.01, accuracy=68.089, wps=5973, ups=1.45, wpb=4121.6, bsz=148.6, num_updates=58100, lr=5.86715e-05, gnorm=1.067, clip=0, loss_scale=32, train_wall=37, gb_free=13.3, wall=28900
2023-07-04 11:56:10 | INFO | train_inner | epoch 040:    739 / 1474 loss=3.913, trans_loss=5.077, nll_loss=2.302, w2v_ctc_loss=1.105, task_loss=0, contrastive_loss=0.126, total=4135.27, n_correct=2832.97, ppl=4.93, accuracy=68.507, wps=11361.1, ups=2.75, wpb=4135.3, bsz=154.8, num_updates=58200, lr=5.8621e-05, gnorm=1.049, clip=0, loss_scale=32, train_wall=36, gb_free=17.9, wall=28936
2023-07-04 11:56:47 | INFO | train_inner | epoch 040:    839 / 1474 loss=3.954, trans_loss=5.094, nll_loss=2.324, w2v_ctc_loss=1.105, task_loss=0, contrastive_loss=0.548, total=4211.77, n_correct=2874.39, ppl=5.01, accuracy=68.247, wps=11300.6, ups=2.68, wpb=4211.8, bsz=164.1, num_updates=58300, lr=5.85707e-05, gnorm=1.057, clip=0, loss_scale=32, train_wall=37, gb_free=15.9, wall=28974
2023-07-04 11:57:24 | INFO | train_inner | epoch 040:    939 / 1474 loss=3.936, trans_loss=5.094, nll_loss=2.323, w2v_ctc_loss=1.131, task_loss=0, contrastive_loss=0.179, total=4091.87, n_correct=2786.76, ppl=5.01, accuracy=68.105, wps=11162.7, ups=2.73, wpb=4091.9, bsz=147.1, num_updates=58400, lr=5.85206e-05, gnorm=1.069, clip=0, loss_scale=32, train_wall=36, gb_free=18.1, wall=29010
2023-07-04 11:58:01 | INFO | train_inner | epoch 040:   1039 / 1474 loss=3.95, trans_loss=5.111, nll_loss=2.344, w2v_ctc_loss=1.13, task_loss=0, contrastive_loss=0.218, total=4124.03, n_correct=2798.77, ppl=5.08, accuracy=67.865, wps=11237.8, ups=2.72, wpb=4124, bsz=143.8, num_updates=58500, lr=5.84705e-05, gnorm=1.065, clip=0, loss_scale=32, train_wall=36, gb_free=17.3, wall=29047
2023-07-04 11:58:38 | INFO | train_inner | epoch 040:   1139 / 1474 loss=3.938, trans_loss=5.1, nll_loss=2.331, w2v_ctc_loss=1.133, task_loss=0, contrastive_loss=0.145, total=4131.03, n_correct=2810.52, ppl=5.03, accuracy=68.034, wps=11150.5, ups=2.7, wpb=4131, bsz=149.6, num_updates=58600, lr=5.84206e-05, gnorm=1.049, clip=0, loss_scale=32, train_wall=37, gb_free=15.5, wall=29084
2023-07-04 11:59:15 | INFO | train_inner | epoch 040:   1239 / 1474 loss=3.927, trans_loss=5.082, nll_loss=2.309, w2v_ctc_loss=1.106, task_loss=0, contrastive_loss=0.271, total=4191.39, n_correct=2863.6, ppl=4.95, accuracy=68.321, wps=11412.5, ups=2.72, wpb=4191.4, bsz=154.6, num_updates=58700, lr=5.83708e-05, gnorm=1.05, clip=0, loss_scale=32, train_wall=36, gb_free=16.8, wall=29121
2023-07-04 11:59:51 | INFO | train_inner | epoch 040:   1339 / 1474 loss=3.936, trans_loss=5.096, nll_loss=2.327, w2v_ctc_loss=1.105, task_loss=0, contrastive_loss=0.279, total=4119.9, n_correct=2806.04, ppl=5.02, accuracy=68.109, wps=11234.2, ups=2.73, wpb=4119.9, bsz=152.7, num_updates=58800, lr=5.83212e-05, gnorm=1.059, clip=0, loss_scale=32, train_wall=36, gb_free=15.6, wall=29157
2023-07-04 12:00:30 | INFO | train_inner | epoch 040:   1439 / 1474 loss=3.941, trans_loss=5.097, nll_loss=2.327, w2v_ctc_loss=1.132, task_loss=0, contrastive_loss=0.21, total=4125.85, n_correct=2810.32, ppl=5.02, accuracy=68.115, wps=10755.7, ups=2.61, wpb=4125.9, bsz=152.7, num_updates=58900, lr=5.82717e-05, gnorm=1.061, clip=0, loss_scale=32, train_wall=38, gb_free=18.2, wall=29196
2023-07-04 12:00:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 12:01:10 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 4.38 | trans_loss 5.565 | nll_loss 2.839 | w2v_ctc_loss 1.483 | task_loss 0 | contrastive_loss 0.268 | total 4003.4 | n_correct 2482.2 | ppl 7.16 | accuracy 62.002 | uer 16.816 | wer 18.668 | raw_wer 18.668 | bleu 20.03 | wps 2120 | wpb 4003.4 | bsz 141.8 | num_updates 58935 | best_bleu 20.67
2023-07-04 12:01:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58935 updates
2023-07-04 12:01:10 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_last.pt
2023-07-04 12:01:14 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_last.pt
2023-07-04 12:01:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_last.pt (epoch 40 @ 58935 updates, score 20.03) (writing took 4.383246380835772 seconds)
2023-07-04 12:01:14 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-07-04 12:01:14 | INFO | train | epoch 040 | loss 3.928 | trans_loss 5.085 | nll_loss 2.312 | w2v_ctc_loss 1.114 | task_loss 0 | contrastive_loss 0.229 | total 4138.65 | n_correct 2827.19 | ppl 4.97 | accuracy 68.312 | wps 9893.3 | ups 2.39 | wpb 4138.6 | bsz 152.8 | num_updates 58935 | lr 5.82543e-05 | gnorm 1.055 | clip 0 | loss_scale 32 | train_wall 540 | gb_free 16.2 | wall 29240
2023-07-04 12:01:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 12:01:15 | INFO | fairseq.trainer | begin training epoch 41
2023-07-04 12:01:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 12:01:51 | INFO | train_inner | epoch 041:     65 / 1474 loss=3.911, trans_loss=5.073, nll_loss=2.297, w2v_ctc_loss=1.101, task_loss=0, contrastive_loss=0.154, total=4098.68, n_correct=2806.43, ppl=4.91, accuracy=68.472, wps=5062.4, ups=1.24, wpb=4098.7, bsz=149.7, num_updates=59000, lr=5.82223e-05, gnorm=1.055, clip=0, loss_scale=64, train_wall=41, gb_free=16.8, wall=29277
2023-07-04 12:02:29 | INFO | train_inner | epoch 041:    165 / 1474 loss=3.9, trans_loss=5.053, nll_loss=2.27, w2v_ctc_loss=1.092, task_loss=0, contrastive_loss=0.258, total=4132.72, n_correct=2844.81, ppl=4.82, accuracy=68.836, wps=10759.2, ups=2.6, wpb=4132.7, bsz=153.5, num_updates=59100, lr=5.8173e-05, gnorm=1.048, clip=0, loss_scale=64, train_wall=38, gb_free=11.8, wall=29315
2023-07-04 12:03:06 | INFO | train_inner | epoch 041:    265 / 1474 loss=3.91, trans_loss=5.065, nll_loss=2.286, w2v_ctc_loss=1.09, task_loss=0, contrastive_loss=0.245, total=4180.79, n_correct=2873.73, ppl=4.88, accuracy=68.737, wps=11403.3, ups=2.73, wpb=4180.8, bsz=159.4, num_updates=59200, lr=5.81238e-05, gnorm=1.051, clip=0, loss_scale=64, train_wall=36, gb_free=17.2, wall=29352
2023-07-04 12:03:43 | INFO | train_inner | epoch 041:    365 / 1474 loss=3.914, trans_loss=5.071, nll_loss=2.293, w2v_ctc_loss=1.113, task_loss=0, contrastive_loss=0.162, total=4152.45, n_correct=2848.9, ppl=4.9, accuracy=68.608, wps=11254.1, ups=2.71, wpb=4152.4, bsz=153.2, num_updates=59300, lr=5.80748e-05, gnorm=1.06, clip=0, loss_scale=64, train_wall=36, gb_free=15.3, wall=29389
2023-07-04 12:04:19 | INFO | train_inner | epoch 041:    465 / 1474 loss=3.908, trans_loss=5.069, nll_loss=2.29, w2v_ctc_loss=1.107, task_loss=0, contrastive_loss=0.132, total=4144.35, n_correct=2842, ppl=4.89, accuracy=68.575, wps=11305.7, ups=2.73, wpb=4144.4, bsz=151.8, num_updates=59400, lr=5.80259e-05, gnorm=1.064, clip=0, loss_scale=64, train_wall=36, gb_free=15.6, wall=29425
2023-07-04 12:04:56 | INFO | train_inner | epoch 041:    565 / 1474 loss=3.915, trans_loss=5.072, nll_loss=2.295, w2v_ctc_loss=1.112, task_loss=0, contrastive_loss=0.162, total=4145.57, n_correct=2844.46, ppl=4.91, accuracy=68.614, wps=11297.5, ups=2.73, wpb=4145.6, bsz=153.3, num_updates=59500, lr=5.79771e-05, gnorm=1.046, clip=0, loss_scale=64, train_wall=36, gb_free=14.8, wall=29462
2023-07-04 12:05:33 | INFO | train_inner | epoch 041:    665 / 1474 loss=3.905, trans_loss=5.066, nll_loss=2.287, w2v_ctc_loss=1.101, task_loss=0, contrastive_loss=0.135, total=4187.21, n_correct=2874.03, ppl=4.88, accuracy=68.638, wps=11460, ups=2.74, wpb=4187.2, bsz=158.8, num_updates=59600, lr=5.79284e-05, gnorm=1.054, clip=0, loss_scale=64, train_wall=36, gb_free=17, wall=29499
2023-07-04 12:06:09 | INFO | train_inner | epoch 041:    765 / 1474 loss=3.913, trans_loss=5.075, nll_loss=2.299, w2v_ctc_loss=1.111, task_loss=0, contrastive_loss=0.127, total=4144.35, n_correct=2835.48, ppl=4.92, accuracy=68.418, wps=11243.5, ups=2.71, wpb=4144.4, bsz=149.6, num_updates=59700, lr=5.78799e-05, gnorm=1.056, clip=0, loss_scale=64, train_wall=36, gb_free=17.9, wall=29535
2023-07-04 12:06:46 | INFO | train_inner | epoch 041:    865 / 1474 loss=3.915, trans_loss=5.076, nll_loss=2.3, w2v_ctc_loss=1.113, task_loss=0, contrastive_loss=0.132, total=4112.51, n_correct=2813.72, ppl=4.93, accuracy=68.419, wps=11211.1, ups=2.73, wpb=4112.5, bsz=148.5, num_updates=59800, lr=5.78315e-05, gnorm=1.062, clip=0, loss_scale=64, train_wall=36, gb_free=16.3, wall=29572
2023-07-04 12:07:23 | INFO | train_inner | epoch 041:    965 / 1474 loss=3.951, trans_loss=5.098, nll_loss=2.329, w2v_ctc_loss=1.143, task_loss=0, contrastive_loss=0.313, total=4119.19, n_correct=2805.88, ppl=5.02, accuracy=68.117, wps=11024.5, ups=2.68, wpb=4119.2, bsz=149.5, num_updates=59900, lr=5.77832e-05, gnorm=1.064, clip=0, loss_scale=64, train_wall=37, gb_free=16.7, wall=29610
2023-07-04 12:08:00 | INFO | train_inner | epoch 041:   1065 / 1474 loss=3.919, trans_loss=5.085, nll_loss=2.313, w2v_ctc_loss=1.102, task_loss=0, contrastive_loss=0.138, total=4142.3, n_correct=2826.4, ppl=4.97, accuracy=68.233, wps=11313.3, ups=2.73, wpb=4142.3, bsz=152.5, num_updates=60000, lr=5.7735e-05, gnorm=1.05, clip=0, loss_scale=64, train_wall=36, gb_free=16.7, wall=29646
2023-07-04 12:08:00 | INFO | fairseq_cli.train | Stopping training due to num_updates: 60000 >= max_update: 60000
2023-07-04 12:08:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 12:08:24 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 4.379 | trans_loss 5.557 | nll_loss 2.831 | w2v_ctc_loss 1.499 | task_loss 0 | contrastive_loss 0.272 | total 4003.4 | n_correct 2498.1 | ppl 7.12 | accuracy 62.399 | uer 16.654 | wer 18.43 | raw_wer 18.43 | bleu 20.33 | wps 2275.8 | wpb 4003.4 | bsz 141.8 | num_updates 60000 | best_bleu 20.67
2023-07-04 12:08:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 60000 updates
2023-07-04 12:08:24 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_41_60000.pt
2023-07-04 12:08:26 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_41_60000.pt
2023-07-04 12:08:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_baseline/checkpoint_41_60000.pt (epoch 41 @ 60000 updates, score 20.33) (writing took 5.13384212879464 seconds)
2023-07-04 12:08:30 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-07-04 12:08:30 | INFO | train | epoch 041 | loss 3.914 | trans_loss 5.072 | nll_loss 2.295 | w2v_ctc_loss 1.108 | task_loss 0 | contrastive_loss 0.18 | total 4144.74 | n_correct 2840.27 | ppl 4.91 | accuracy 68.527 | wps 10140.2 | ups 2.45 | wpb 4144.7 | bsz 153 | num_updates 60000 | lr 5.7735e-05 | gnorm 1.056 | clip 0 | loss_scale 64 | train_wall 393 | gb_free 16.7 | wall 29676
2023-07-04 12:08:30 | INFO | fairseq_cli.train | done training in 29605.5 seconds
/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1776 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
