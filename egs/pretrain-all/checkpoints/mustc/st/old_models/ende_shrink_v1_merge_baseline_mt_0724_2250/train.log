2023-07-24 22:51:09 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:12273
2023-07-24 22:51:10 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:12273
2023-07-24 22:51:10 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:12273
2023-07-24 22:51:10 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:12273
2023-07-24 22:51:10 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:12273
2023-07-24 22:51:10 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-24 22:51:10 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:12273
2023-07-24 22:51:10 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-24 22:51:10 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:12273
2023-07-24 22:51:10 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-24 22:51:10 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:12273
2023-07-24 22:51:10 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-24 22:51:10 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-24 22:51:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-24 22:51:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-24 22:51:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-24 22:51:11 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-24 22:51:11 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-07-24 22:51:11 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-24 22:51:11 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-07-24 22:51:11 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-24 22:51:11 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-24 22:51:11 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-24 22:51:11 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-07-24 22:51:11 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-07-24 22:51:11 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-07-24 22:51:11 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-24 22:51:11 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-07-24 22:51:11 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-24 22:51:11 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-07-24 22:51:11 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-24 22:51:11 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-07-24 22:51:15 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12273', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-07-24 22:51:15 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-07-24 22:51:15 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-07-24 22:51:15 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-24 22:51:15 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 1.0
2023-07-24 22:51:15 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-24 22:51:19 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-07-24 22:51:19 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-24 22:51:19 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-24 22:51:21 | INFO | root | load pretrained hubert
2023-07-24 22:51:24 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-24 22:51:24 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-24 22:51:25 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-24 22:51:25 | INFO | root | share the sematic adapter and textual encoder
2023-07-24 22:51:25 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-24 22:51:25 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-07-24 22:51:25 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-24 22:51:25 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-07-24 22:51:25 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-24 22:51:25 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-24 22:51:25 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-24 22:51:25 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-24 22:51:25 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-24 22:51:25 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-24 22:51:30 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-24 22:51:31 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-24 22:51:31 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-24 22:51:31 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-24 22:51:31 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-24 22:51:31 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-24 22:51:31 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-24 22:51:31 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-24 22:51:31 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-24 22:51:31 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-24 22:51:31 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-24 22:51:31 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-24 22:51:31 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-24 22:51:31 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-24 22:51:31 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-24 22:51:31 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_last.pt
2023-07-24 22:51:31 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_last.pt
2023-07-24 22:51:31 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-24 22:51:31 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-24 22:51:31 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-24 22:51:31 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-24 22:51:33 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-24 22:51:34 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-24 22:51:36 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-24 22:52:46 | INFO | fairseq.optim.adam | using FusedAdam
2023-07-24 22:52:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-24 22:52:46 | INFO | fairseq.trainer | begin training epoch 1
2023-07-24 22:52:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-24 22:54:02 | INFO | train_inner | epoch 001:    100 / 1474 loss=19.616, trans_loss=5.599, nll_loss=4.164, w2v_ctc_loss=23.048, task_loss=0, contrastive_loss=3.325, total=4207.04, n_correct=209.22, ppl=17.93, accuracy=4.973, wps=20236.9, ups=1.61, wpb=12551.1, bsz=471.4, num_updates=100, lr=4.098e-06, gnorm=0.913, clip=0, loss_scale=128, train_wall=67, gb_free=19.5, wall=151
2023-07-24 22:54:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-24 22:55:05 | INFO | train_inner | epoch 001:    201 / 1474 loss=17.415, trans_loss=5.473, nll_loss=4.06, w2v_ctc_loss=19.847, task_loss=0, contrastive_loss=3.283, total=4121.36, n_correct=224.28, ppl=16.68, accuracy=5.442, wps=19475.7, ups=1.58, wpb=12305.5, bsz=461.4, num_updates=200, lr=8.096e-06, gnorm=3.718, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=214
2023-07-24 22:56:06 | INFO | train_inner | epoch 001:    301 / 1474 loss=10.344, trans_loss=5.503, nll_loss=4.15, w2v_ctc_loss=8.993, task_loss=0, contrastive_loss=3.204, total=4079.62, n_correct=201.45, ppl=17.76, accuracy=4.938, wps=19941.2, ups=1.64, wpb=12186.7, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=4.711, clip=0, loss_scale=64, train_wall=61, gb_free=19.9, wall=275
2023-07-24 22:57:08 | INFO | train_inner | epoch 001:    401 / 1474 loss=9.069, trans_loss=5.523, nll_loss=4.198, w2v_ctc_loss=6.983, task_loss=0, contrastive_loss=3.236, total=4174.14, n_correct=191.98, ppl=18.35, accuracy=4.599, wps=20383.2, ups=1.64, wpb=12463.5, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=3.015, clip=0, loss_scale=64, train_wall=61, gb_free=18.9, wall=336
2023-07-24 22:58:09 | INFO | train_inner | epoch 001:    501 / 1474 loss=8.63, trans_loss=5.497, nll_loss=4.181, w2v_ctc_loss=6.334, task_loss=0, contrastive_loss=3.231, total=4176.18, n_correct=185.25, ppl=18.13, accuracy=4.436, wps=20393.7, ups=1.63, wpb=12479.7, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=1.448, clip=0, loss_scale=64, train_wall=61, gb_free=19.2, wall=398
2023-07-24 22:59:12 | INFO | train_inner | epoch 001:    601 / 1474 loss=8.377, trans_loss=5.525, nll_loss=4.216, w2v_ctc_loss=5.959, task_loss=0, contrastive_loss=3.287, total=4147.79, n_correct=182.23, ppl=18.58, accuracy=4.393, wps=19613.7, ups=1.59, wpb=12371.6, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.752, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=461
2023-07-24 23:00:12 | INFO | train_inner | epoch 001:    701 / 1474 loss=8.202, trans_loss=5.521, nll_loss=4.216, w2v_ctc_loss=5.831, task_loss=0, contrastive_loss=3.037, total=4152.1, n_correct=196.05, ppl=18.59, accuracy=4.722, wps=20474.8, ups=1.65, wpb=12395.5, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=0.564, clip=0, loss_scale=64, train_wall=60, gb_free=19.5, wall=521
2023-07-24 23:01:14 | INFO | train_inner | epoch 001:    801 / 1474 loss=7.926, trans_loss=5.462, nll_loss=4.154, w2v_ctc_loss=5.602, task_loss=0, contrastive_loss=2.945, total=4123.83, n_correct=239.23, ppl=17.8, accuracy=5.801, wps=20123.6, ups=1.64, wpb=12306.1, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=0.815, clip=0, loss_scale=64, train_wall=61, gb_free=19.2, wall=582
2023-07-24 23:02:15 | INFO | train_inner | epoch 001:    901 / 1474 loss=7.65, trans_loss=5.425, nll_loss=4.12, w2v_ctc_loss=5.407, task_loss=0, contrastive_loss=2.704, total=4163.61, n_correct=264.14, ppl=17.38, accuracy=6.344, wps=20279.5, ups=1.63, wpb=12433.9, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=1.329, clip=0, loss_scale=64, train_wall=61, gb_free=18.9, wall=644
2023-07-24 23:03:16 | INFO | train_inner | epoch 001:   1001 / 1474 loss=7.384, trans_loss=5.406, nll_loss=4.106, w2v_ctc_loss=5.19, task_loss=0, contrastive_loss=2.55, total=4135.34, n_correct=286.15, ppl=17.22, accuracy=6.92, wps=20068.3, ups=1.62, wpb=12353.2, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=1.464, clip=0, loss_scale=64, train_wall=61, gb_free=19, wall=705
2023-07-24 23:04:19 | INFO | train_inner | epoch 001:   1101 / 1474 loss=7.107, trans_loss=5.395, nll_loss=4.096, w2v_ctc_loss=4.986, task_loss=0, contrastive_loss=2.328, total=4147.38, n_correct=310.2, ppl=17.1, accuracy=7.479, wps=19696.5, ups=1.59, wpb=12367, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=1.701, clip=0, loss_scale=64, train_wall=62, gb_free=18.9, wall=768
2023-07-24 23:05:20 | INFO | train_inner | epoch 001:   1201 / 1474 loss=6.87, trans_loss=5.371, nll_loss=4.073, w2v_ctc_loss=4.812, task_loss=0, contrastive_loss=2.118, total=4139.9, n_correct=316.99, ppl=16.83, accuracy=7.657, wps=20289.4, ups=1.64, wpb=12366.5, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=1.751, clip=0, loss_scale=64, train_wall=60, gb_free=19, wall=829
2023-07-24 23:06:21 | INFO | train_inner | epoch 001:   1301 / 1474 loss=6.655, trans_loss=5.371, nll_loss=4.075, w2v_ctc_loss=4.614, task_loss=0, contrastive_loss=1.939, total=4046.58, n_correct=321.3, ppl=16.85, accuracy=7.94, wps=19987.7, ups=1.65, wpb=12081.6, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=1.849, clip=0, loss_scale=64, train_wall=60, gb_free=19.7, wall=889
2023-07-24 23:07:22 | INFO | train_inner | epoch 001:   1401 / 1474 loss=6.453, trans_loss=5.364, nll_loss=4.071, w2v_ctc_loss=4.413, task_loss=0, contrastive_loss=2.009, total=4133.18, n_correct=328.98, ppl=16.8, accuracy=7.959, wps=20202.9, ups=1.64, wpb=12350, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=1.754, clip=0, loss_scale=64, train_wall=61, gb_free=19.9, wall=951
2023-07-24 23:08:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-24 23:08:47 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.96 | trans_loss 11.002 | nll_loss 10.004 | w2v_ctc_loss 5.795 | task_loss 0 | contrastive_loss 2.358 | total 4003.4 | n_correct 359.1 | ppl 1027.12 | accuracy 8.97 | uer 71.725 | wer 69.662 | raw_wer 69.662 | bleu 0.02 | wps 1165.8 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-07-24 23:08:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-07-24 23:08:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-24 23:08:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-24 23:08:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.02) (writing took 5.7687115855515 seconds)
2023-07-24 23:08:53 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-07-24 23:08:53 | INFO | train | epoch 001 | loss 9.264 | trans_loss 5.455 | nll_loss 4.131 | w2v_ctc_loss 7.831 | task_loss 0 | contrastive_loss 2.759 | total 4138.36 | n_correct 251.261 | ppl 17.52 | accuracy 6.072 | wps 19095.8 | ups 1.55 | wpb 12355 | bsz 458.4 | num_updates 1473 | lr 5.89905e-05 | gnorm 1.835 | clip 0 | loss_scale 64 | train_wall 906 | gb_free 19.2 | wall 1042
2023-07-24 23:08:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-24 23:08:54 | INFO | fairseq.trainer | begin training epoch 2
2023-07-24 23:08:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-24 23:09:20 | INFO | train_inner | epoch 002:     27 / 1474 loss=6.267, trans_loss=5.355, nll_loss=4.054, w2v_ctc_loss=4.222, task_loss=0, contrastive_loss=1.858, total=4162.95, n_correct=335.71, ppl=16.61, accuracy=8.064, wps=10547.2, ups=0.85, wpb=12416.8, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=1.699, clip=0, loss_scale=64, train_wall=62, gb_free=19.7, wall=1068
2023-07-24 23:10:21 | INFO | train_inner | epoch 002:    127 / 1474 loss=6.089, trans_loss=5.348, nll_loss=4.045, w2v_ctc_loss=4.098, task_loss=0, contrastive_loss=1.649, total=4155.98, n_correct=337.62, ppl=16.51, accuracy=8.124, wps=20266.3, ups=1.64, wpb=12394.8, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=1.673, clip=0, loss_scale=64, train_wall=61, gb_free=18.9, wall=1130
2023-07-24 23:11:21 | INFO | train_inner | epoch 002:    227 / 1474 loss=5.93, trans_loss=5.326, nll_loss=4.022, w2v_ctc_loss=3.902, task_loss=0, contrastive_loss=1.679, total=4179.21, n_correct=347.35, ppl=16.25, accuracy=8.311, wps=20612, ups=1.65, wpb=12484.6, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=1.484, clip=0, loss_scale=64, train_wall=60, gb_free=19, wall=1190
2023-07-24 23:12:22 | INFO | train_inner | epoch 002:    327 / 1474 loss=5.757, trans_loss=5.328, nll_loss=4.021, w2v_ctc_loss=3.801, task_loss=0, contrastive_loss=1.391, total=4146.1, n_correct=349.43, ppl=16.23, accuracy=8.428, wps=20288.9, ups=1.64, wpb=12374.1, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=1.469, clip=0, loss_scale=64, train_wall=61, gb_free=18.8, wall=1251
2023-07-24 23:13:24 | INFO | train_inner | epoch 002:    427 / 1474 loss=5.606, trans_loss=5.32, nll_loss=4.016, w2v_ctc_loss=3.699, task_loss=0, contrastive_loss=1.208, total=4037.99, n_correct=342.41, ppl=16.17, accuracy=8.48, wps=19491.1, ups=1.61, wpb=12069.2, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=1.433, clip=0, loss_scale=64, train_wall=61, gb_free=19, wall=1313
2023-07-24 23:14:25 | INFO | train_inner | epoch 002:    527 / 1474 loss=5.504, trans_loss=5.305, nll_loss=3.993, w2v_ctc_loss=3.54, task_loss=0, contrastive_loss=1.309, total=4176.97, n_correct=363.75, ppl=15.92, accuracy=8.708, wps=20489.6, ups=1.64, wpb=12463.5, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=1.352, clip=0, loss_scale=64, train_wall=60, gb_free=19.6, wall=1374
2023-07-24 23:14:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-24 23:15:04 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 9.296 | trans_loss 10.79 | nll_loss 9.731 | w2v_ctc_loss 4.675 | task_loss 0 | contrastive_loss 1.654 | total 4003.4 | n_correct 406.8 | ppl 849.69 | accuracy 10.161 | uer 61.344 | wer 59.2 | raw_wer 59.2 | bleu 0.05 | wps 1195.9 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.05
2023-07-24 23:15:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-07-24 23:15:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_2_2000.pt
2023-07-24 23:15:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_2_2000.pt
2023-07-24 23:15:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.05) (writing took 21.440349485725164 seconds)
2023-07-24 23:16:26 | INFO | train_inner | epoch 002:    627 / 1474 loss=5.363, trans_loss=5.293, nll_loss=3.977, w2v_ctc_loss=3.431, task_loss=0, contrastive_loss=1.111, total=4126.49, n_correct=368.87, ppl=15.75, accuracy=8.939, wps=10192.7, ups=0.83, wpb=12314.9, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=1.202, clip=0, loss_scale=64, train_wall=60, gb_free=19.2, wall=1495
2023-07-24 23:17:26 | INFO | train_inner | epoch 002:    727 / 1474 loss=5.295, trans_loss=5.282, nll_loss=3.967, w2v_ctc_loss=3.347, task_loss=0, contrastive_loss=1.21, total=4149.06, n_correct=374.52, ppl=15.64, accuracy=9.027, wps=20454.5, ups=1.65, wpb=12386.4, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=1.144, clip=0, loss_scale=64, train_wall=60, gb_free=19.2, wall=1555
2023-07-24 23:18:28 | INFO | train_inner | epoch 002:    827 / 1474 loss=5.206, trans_loss=5.271, nll_loss=3.954, w2v_ctc_loss=3.275, task_loss=0, contrastive_loss=1.159, total=4175.4, n_correct=384.41, ppl=15.5, accuracy=9.207, wps=20301.6, ups=1.63, wpb=12471.9, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=1.066, clip=0, loss_scale=128, train_wall=61, gb_free=19.8, wall=1617
2023-07-24 23:19:30 | INFO | train_inner | epoch 002:    927 / 1474 loss=5.106, trans_loss=5.254, nll_loss=3.932, w2v_ctc_loss=3.178, task_loss=0, contrastive_loss=1.142, total=4104.2, n_correct=381.15, ppl=15.26, accuracy=9.287, wps=19864.1, ups=1.62, wpb=12253.1, bsz=445.9, num_updates=2400, lr=9.6052e-05, gnorm=1.064, clip=0, loss_scale=128, train_wall=61, gb_free=19, wall=1678
2023-07-24 23:20:30 | INFO | train_inner | epoch 002:   1027 / 1474 loss=5.022, trans_loss=5.248, nll_loss=3.927, w2v_ctc_loss=3.107, task_loss=0, contrastive_loss=0.995, total=4102.5, n_correct=386.45, ppl=15.21, accuracy=9.42, wps=20204, ups=1.65, wpb=12251.2, bsz=456.3, num_updates=2500, lr=0.00010005, gnorm=0.916, clip=0, loss_scale=128, train_wall=60, gb_free=19.3, wall=1739
2023-07-24 23:21:32 | INFO | train_inner | epoch 002:   1127 / 1474 loss=4.985, trans_loss=5.242, nll_loss=3.918, w2v_ctc_loss=3.019, task_loss=0, contrastive_loss=1.208, total=4187.61, n_correct=399.73, ppl=15.12, accuracy=9.546, wps=20361.5, ups=1.63, wpb=12495.7, bsz=487.1, num_updates=2600, lr=0.000104048, gnorm=0.93, clip=0, loss_scale=128, train_wall=61, gb_free=19.5, wall=1800
2023-07-24 23:22:33 | INFO | train_inner | epoch 002:   1227 / 1474 loss=4.921, trans_loss=5.227, nll_loss=3.9, w2v_ctc_loss=2.973, task_loss=0, contrastive_loss=1.129, total=4221.06, n_correct=417.42, ppl=14.93, accuracy=9.889, wps=20353.1, ups=1.62, wpb=12596.1, bsz=492.8, num_updates=2700, lr=0.000108046, gnorm=0.839, clip=0, loss_scale=128, train_wall=61, gb_free=19.5, wall=1862
2023-07-24 23:23:35 | INFO | train_inner | epoch 002:   1327 / 1474 loss=4.82, trans_loss=5.216, nll_loss=3.89, w2v_ctc_loss=2.934, task_loss=0, contrastive_loss=0.839, total=4157.86, n_correct=412.02, ppl=14.83, accuracy=9.909, wps=20195.9, ups=1.63, wpb=12425.5, bsz=460.7, num_updates=2800, lr=0.000112044, gnorm=0.796, clip=0, loss_scale=128, train_wall=61, gb_free=19.5, wall=1924
2023-07-24 23:24:36 | INFO | train_inner | epoch 002:   1427 / 1474 loss=4.78, trans_loss=5.223, nll_loss=3.899, w2v_ctc_loss=2.891, task_loss=0, contrastive_loss=0.925, total=4054.34, n_correct=400.96, ppl=14.92, accuracy=9.89, wps=19881.6, ups=1.64, wpb=12107, bsz=438.8, num_updates=2900, lr=0.000116042, gnorm=0.761, clip=0, loss_scale=128, train_wall=60, gb_free=19.4, wall=1985
2023-07-24 23:25:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-24 23:25:43 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.526 | trans_loss 10.31 | nll_loss 9.14 | w2v_ctc_loss 3.742 | task_loss 0 | contrastive_loss 1.002 | total 4003.4 | n_correct 493.8 | ppl 564.09 | accuracy 12.335 | uer 52.032 | wer 50.632 | raw_wer 50.632 | bleu 0.13 | wps 1195.3 | wpb 4003.4 | bsz 141.8 | num_updates 2947 | best_bleu 0.13
2023-07-24 23:25:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2947 updates
2023-07-24 23:25:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-24 23:25:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-24 23:26:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt (epoch 2 @ 2947 updates, score 0.13) (writing took 19.524428695440292 seconds)
2023-07-24 23:26:02 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-07-24 23:26:02 | INFO | train | epoch 002 | loss 5.312 | trans_loss 5.277 | nll_loss 3.961 | w2v_ctc_loss 3.369 | task_loss 0 | contrastive_loss 1.213 | total 4138.65 | n_correct 376.508 | ppl 15.57 | accuracy 9.097 | wps 17698.2 | ups 1.43 | wpb 12355.8 | bsz 458.5 | num_updates 2947 | lr 0.000117921 | gnorm 1.15 | clip 0 | loss_scale 128 | train_wall 893 | gb_free 19.3 | wall 2071
2023-07-24 23:26:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-24 23:26:03 | INFO | fairseq.trainer | begin training epoch 3
2023-07-24 23:26:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-24 23:26:44 | INFO | train_inner | epoch 003:     53 / 1474 loss=4.705, trans_loss=5.195, nll_loss=3.864, w2v_ctc_loss=2.828, task_loss=0, contrastive_loss=0.828, total=4071.2, n_correct=421.18, ppl=14.56, accuracy=10.345, wps=9515.6, ups=0.78, wpb=12154.1, bsz=442.6, num_updates=3000, lr=0.00012004, gnorm=0.75, clip=0, loss_scale=128, train_wall=60, gb_free=19.1, wall=2112
2023-07-24 23:26:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-24 23:26:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-24 23:26:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-24 23:26:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-24 23:26:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-07-24 23:28:06 | INFO | train_inner | epoch 003:    158 / 1474 loss=3.935, trans_loss=4.472, nll_loss=2.922, w2v_ctc_loss=2.477, task_loss=0, contrastive_loss=0.746, total=4144.18, n_correct=1065.35, ppl=7.58, accuracy=25.707, wps=15051, ups=1.22, wpb=12374.6, bsz=458.6, num_updates=3100, lr=0.000124038, gnorm=1.775, clip=1, loss_scale=4, train_wall=82, gb_free=16.8, wall=2195
2023-07-24 23:29:27 | INFO | train_inner | epoch 003:    258 / 1474 loss=3.472, trans_loss=4.187, nll_loss=2.546, w2v_ctc_loss=2.195, task_loss=0, contrastive_loss=0.632, total=4161.13, n_correct=1383.93, ppl=5.84, accuracy=33.259, wps=15342, ups=1.23, wpb=12431.5, bsz=467, num_updates=3200, lr=0.000128036, gnorm=1.181, clip=0, loss_scale=4, train_wall=81, gb_free=17.3, wall=2276
2023-07-24 23:30:46 | INFO | train_inner | epoch 003:    358 / 1474 loss=3.322, trans_loss=4.101, nll_loss=2.428, w2v_ctc_loss=2.084, task_loss=0, contrastive_loss=0.668, total=4150.02, n_correct=1495.98, ppl=5.38, accuracy=36.048, wps=15613.7, ups=1.26, wpb=12384.9, bsz=461.6, num_updates=3300, lr=0.000132034, gnorm=1.178, clip=0, loss_scale=4, train_wall=79, gb_free=17.3, wall=2355
2023-07-24 23:32:06 | INFO | train_inner | epoch 003:    458 / 1474 loss=3.179, trans_loss=4.03, nll_loss=2.335, w2v_ctc_loss=1.993, task_loss=0, contrastive_loss=0.519, total=4209.57, n_correct=1630.72, ppl=5.05, accuracy=38.738, wps=15794.1, ups=1.26, wpb=12566, bsz=476.8, num_updates=3400, lr=0.000136032, gnorm=1.066, clip=0, loss_scale=4, train_wall=79, gb_free=16.3, wall=2435
2023-07-24 23:33:25 | INFO | train_inner | epoch 003:    558 / 1474 loss=3.066, trans_loss=3.988, nll_loss=2.282, w2v_ctc_loss=1.913, task_loss=0, contrastive_loss=0.48, total=4088.48, n_correct=1639.73, ppl=4.86, accuracy=40.106, wps=15437.4, ups=1.26, wpb=12212.5, bsz=439.7, num_updates=3500, lr=0.00014003, gnorm=1.033, clip=0, loss_scale=4, train_wall=79, gb_free=17.8, wall=2514
2023-07-24 23:34:46 | INFO | train_inner | epoch 003:    658 / 1474 loss=3.008, trans_loss=3.948, nll_loss=2.225, w2v_ctc_loss=1.844, task_loss=0, contrastive_loss=0.593, total=4221.58, n_correct=1762.13, ppl=4.67, accuracy=41.741, wps=15568.9, ups=1.24, wpb=12587.8, bsz=481.9, num_updates=3600, lr=0.000144028, gnorm=1.036, clip=0, loss_scale=4, train_wall=80, gb_free=16.6, wall=2595
2023-07-24 23:36:05 | INFO | train_inner | epoch 003:    758 / 1474 loss=2.925, trans_loss=3.91, nll_loss=2.18, w2v_ctc_loss=1.815, task_loss=0, contrastive_loss=0.357, total=4167.41, n_correct=1791.2, ppl=4.53, accuracy=42.981, wps=15787.7, ups=1.27, wpb=12447.6, bsz=472.6, num_updates=3700, lr=0.000148026, gnorm=0.988, clip=0, loss_scale=4, train_wall=78, gb_free=16.6, wall=2673
2023-07-24 23:37:24 | INFO | train_inner | epoch 003:    858 / 1474 loss=2.864, trans_loss=3.895, nll_loss=2.159, w2v_ctc_loss=1.766, task_loss=0, contrastive_loss=0.314, total=4165.53, n_correct=1827.16, ppl=4.47, accuracy=43.864, wps=15705.1, ups=1.26, wpb=12437.8, bsz=456.1, num_updates=3800, lr=0.000152024, gnorm=0.953, clip=0, loss_scale=4, train_wall=79, gb_free=17.3, wall=2753
2023-07-24 23:38:44 | INFO | train_inner | epoch 003:    958 / 1474 loss=2.834, trans_loss=3.872, nll_loss=2.128, w2v_ctc_loss=1.74, task_loss=0, contrastive_loss=0.345, total=4162.3, n_correct=1871.23, ppl=4.37, accuracy=44.957, wps=15500.6, ups=1.25, wpb=12417, bsz=469.2, num_updates=3900, lr=0.000156022, gnorm=0.945, clip=0, loss_scale=4, train_wall=80, gb_free=17, wall=2833
2023-07-24 23:40:03 | INFO | train_inner | epoch 003:   1058 / 1474 loss=2.803, trans_loss=3.855, nll_loss=2.108, w2v_ctc_loss=1.729, task_loss=0, contrastive_loss=0.302, total=4069.95, n_correct=1844.41, ppl=4.31, accuracy=45.318, wps=15271.9, ups=1.26, wpb=12153.7, bsz=443.6, num_updates=4000, lr=0.00016002, gnorm=0.944, clip=0, loss_scale=4, train_wall=79, gb_free=16.5, wall=2912
2023-07-24 23:40:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-24 23:40:34 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.095 | trans_loss 6.311 | nll_loss 3.823 | w2v_ctc_loss 2.037 | task_loss 0 | contrastive_loss 0.413 | total 4003.4 | n_correct 2024.2 | ppl 14.16 | accuracy 50.562 | uer 28.846 | wer 29.902 | raw_wer 29.902 | bleu 12.57 | wps 1493.3 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 12.57
2023-07-24 23:40:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-07-24 23:40:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_3_4000.pt
2023-07-24 23:40:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_3_4000.pt
2023-07-24 23:41:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 12.57) (writing took 26.67041034065187 seconds)
2023-07-24 23:42:19 | INFO | train_inner | epoch 003:   1158 / 1474 loss=2.756, trans_loss=3.844, nll_loss=2.092, w2v_ctc_loss=1.687, task_loss=0, contrastive_loss=0.279, total=4038.49, n_correct=1852.99, ppl=4.26, accuracy=45.883, wps=8902.2, ups=0.74, wpb=12054.8, bsz=432.5, num_updates=4100, lr=0.000164018, gnorm=0.935, clip=0, loss_scale=4, train_wall=78, gb_free=16.6, wall=3048
2023-07-24 23:43:37 | INFO | train_inner | epoch 003:   1258 / 1474 loss=2.714, trans_loss=3.825, nll_loss=2.069, w2v_ctc_loss=1.653, task_loss=0, contrastive_loss=0.262, total=4064.31, n_correct=1897.15, ppl=4.2, accuracy=46.678, wps=15464.6, ups=1.27, wpb=12136.8, bsz=433.9, num_updates=4200, lr=0.000168016, gnorm=0.908, clip=0, loss_scale=4, train_wall=78, gb_free=17.5, wall=3126
2023-07-24 23:44:58 | INFO | train_inner | epoch 003:   1358 / 1474 loss=2.702, trans_loss=3.809, nll_loss=2.048, w2v_ctc_loss=1.619, task_loss=0, contrastive_loss=0.371, total=4134.58, n_correct=1957.02, ppl=4.14, accuracy=47.333, wps=15287, ups=1.24, wpb=12343.8, bsz=460.7, num_updates=4300, lr=0.000172014, gnorm=0.912, clip=0, loss_scale=4, train_wall=80, gb_free=17.9, wall=3207
2023-07-24 23:46:17 | INFO | train_inner | epoch 003:   1458 / 1474 loss=2.679, trans_loss=3.798, nll_loss=2.035, w2v_ctc_loss=1.604, task_loss=0, contrastive_loss=0.353, total=4209.94, n_correct=2013.18, ppl=4.1, accuracy=47.82, wps=15889.8, ups=1.26, wpb=12573.5, bsz=477.4, num_updates=4400, lr=0.000176012, gnorm=0.903, clip=0, loss_scale=4, train_wall=79, gb_free=17.2, wall=3286
2023-07-24 23:46:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-24 23:46:54 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 4.966 | trans_loss 6.202 | nll_loss 3.68 | w2v_ctc_loss 1.874 | task_loss 0 | contrastive_loss 0.403 | total 4003.4 | n_correct 2098.9 | ppl 12.82 | accuracy 52.428 | uer 28.293 | wer 29.112 | raw_wer 29.112 | bleu 13.73 | wps 1976.7 | wpb 4003.4 | bsz 141.8 | num_updates 4416 | best_bleu 13.73
2023-07-24 23:46:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4416 updates
2023-07-24 23:46:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-24 23:47:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-24 23:47:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt (epoch 3 @ 4416 updates, score 13.73) (writing took 19.301229994744062 seconds)
2023-07-24 23:47:14 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-07-24 23:47:14 | INFO | train | epoch 003 | loss 3.076 | trans_loss 4.01 | nll_loss 2.31 | w2v_ctc_loss 1.897 | task_loss 0 | contrastive_loss 0.461 | total 4140.05 | n_correct 1672.28 | ppl 4.96 | accuracy 40.393 | wps 14278.6 | ups 1.16 | wpb 12360.1 | bsz 459 | num_updates 4416 | lr 0.000176652 | gnorm 1.041 | clip 0.1 | loss_scale 4 | train_wall 1154 | gb_free 16.6 | wall 3343
2023-07-24 23:47:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-24 23:47:14 | INFO | fairseq.trainer | begin training epoch 4
2023-07-24 23:47:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-24 23:48:28 | INFO | train_inner | epoch 004:     84 / 1474 loss=2.594, trans_loss=3.766, nll_loss=1.99, w2v_ctc_loss=1.551, task_loss=0, contrastive_loss=0.206, total=4099.41, n_correct=1995.04, ppl=3.97, accuracy=48.667, wps=9365.8, ups=0.77, wpb=12237, bsz=439.5, num_updates=4500, lr=0.00018001, gnorm=0.879, clip=0, loss_scale=4, train_wall=77, gb_free=16.5, wall=3417
2023-07-24 23:49:46 | INFO | train_inner | epoch 004:    184 / 1474 loss=2.58, trans_loss=3.747, nll_loss=1.966, w2v_ctc_loss=1.534, task_loss=0, contrastive_loss=0.235, total=4175.15, n_correct=2062.34, ppl=3.91, accuracy=49.396, wps=15914.7, ups=1.28, wpb=12464.9, bsz=468.3, num_updates=4600, lr=0.000184008, gnorm=0.873, clip=0, loss_scale=4, train_wall=78, gb_free=16.9, wall=3495
2023-07-24 23:51:06 | INFO | train_inner | epoch 004:    284 / 1474 loss=2.595, trans_loss=3.751, nll_loss=1.974, w2v_ctc_loss=1.534, task_loss=0, contrastive_loss=0.358, total=4145.23, n_correct=2044.4, ppl=3.93, accuracy=49.319, wps=15549.4, ups=1.26, wpb=12382.4, bsz=463, num_updates=4700, lr=0.000188006, gnorm=0.861, clip=0, loss_scale=4, train_wall=79, gb_free=16.2, wall=3575
2023-07-24 23:52:24 | INFO | train_inner | epoch 004:    384 / 1474 loss=2.556, trans_loss=3.752, nll_loss=1.97, w2v_ctc_loss=1.517, task_loss=0, contrastive_loss=0.204, total=4127.66, n_correct=2044.47, ppl=3.92, accuracy=49.531, wps=15690.8, ups=1.27, wpb=12314.6, bsz=443.5, num_updates=4800, lr=0.000192004, gnorm=0.851, clip=0, loss_scale=4, train_wall=78, gb_free=17.6, wall=3653
2023-07-24 23:53:44 | INFO | train_inner | epoch 004:    484 / 1474 loss=2.593, trans_loss=3.735, nll_loss=1.952, w2v_ctc_loss=1.486, task_loss=0, contrastive_loss=0.601, total=4218.78, n_correct=2115.57, ppl=3.87, accuracy=50.146, wps=15858.9, ups=1.26, wpb=12592.4, bsz=497.8, num_updates=4900, lr=0.000196002, gnorm=0.87, clip=0, loss_scale=4, train_wall=79, gb_free=16.7, wall=3733
2023-07-24 23:55:04 | INFO | train_inner | epoch 004:    584 / 1474 loss=2.555, trans_loss=3.731, nll_loss=1.948, w2v_ctc_loss=1.509, task_loss=0, contrastive_loss=0.28, total=4217.52, n_correct=2125.37, ppl=3.86, accuracy=50.394, wps=15730.6, ups=1.25, wpb=12591.1, bsz=485.9, num_updates=5000, lr=0.0002, gnorm=0.864, clip=0, loss_scale=4, train_wall=80, gb_free=16.3, wall=3813
mt_weight tensor(1.)
asr_weight tensor(0.4786, device='cuda:0')
2023-07-24 23:56:24 | INFO | train_inner | epoch 004:    684 / 1474 loss=2.517, trans_loss=3.733, nll_loss=1.945, w2v_ctc_loss=1.465, task_loss=0, contrastive_loss=0.321, total=4176.39, n_correct=2118.7, ppl=3.85, accuracy=50.73, wps=15487.8, ups=1.24, wpb=12448.9, bsz=455.8, num_updates=5100, lr=0.00019803, gnorm=0.553, clip=0, loss_scale=8, train_wall=80, gb_free=17.3, wall=3893
2023-07-24 23:57:43 | INFO | train_inner | epoch 004:    784 / 1474 loss=2.501, trans_loss=3.726, nll_loss=1.941, w2v_ctc_loss=1.479, task_loss=0, contrastive_loss=0.192, total=4026.63, n_correct=2045.4, ppl=3.84, accuracy=50.797, wps=15271.9, ups=1.27, wpb=12025, bsz=420.6, num_updates=5200, lr=0.000196116, gnorm=0.562, clip=0, loss_scale=8, train_wall=78, gb_free=13.6, wall=3972
2023-07-24 23:59:02 | INFO | train_inner | epoch 004:    884 / 1474 loss=2.525, trans_loss=3.712, nll_loss=1.925, w2v_ctc_loss=1.476, task_loss=0, contrastive_loss=0.369, total=4186.04, n_correct=2141.16, ppl=3.8, accuracy=51.15, wps=15763.5, ups=1.26, wpb=12501.4, bsz=466.3, num_updates=5300, lr=0.000194257, gnorm=0.562, clip=0, loss_scale=8, train_wall=79, gb_free=17.8, wall=4051
2023-07-25 00:00:23 | INFO | train_inner | epoch 004:    984 / 1474 loss=2.484, trans_loss=3.703, nll_loss=1.914, w2v_ctc_loss=1.455, task_loss=0, contrastive_loss=0.244, total=4125.02, n_correct=2127.45, ppl=3.77, accuracy=51.574, wps=15228.5, ups=1.24, wpb=12321, bsz=457.1, num_updates=5400, lr=0.00019245, gnorm=0.553, clip=0, loss_scale=8, train_wall=80, gb_free=13.1, wall=4132
2023-07-25 00:01:42 | INFO | train_inner | epoch 004:   1084 / 1474 loss=2.484, trans_loss=3.713, nll_loss=1.925, w2v_ctc_loss=1.462, task_loss=0, contrastive_loss=0.218, total=4075.6, n_correct=2099.6, ppl=3.8, accuracy=51.516, wps=15336, ups=1.26, wpb=12163.4, bsz=435.7, num_updates=5500, lr=0.000190693, gnorm=0.553, clip=0, loss_scale=8, train_wall=79, gb_free=16.3, wall=4211
2023-07-25 00:03:01 | INFO | train_inner | epoch 004:   1184 / 1474 loss=2.495, trans_loss=3.701, nll_loss=1.913, w2v_ctc_loss=1.453, task_loss=0, contrastive_loss=0.333, total=4161.18, n_correct=2155, ppl=3.77, accuracy=51.788, wps=15754, ups=1.27, wpb=12431.8, bsz=483.4, num_updates=5600, lr=0.000188982, gnorm=0.552, clip=0, loss_scale=8, train_wall=78, gb_free=17, wall=4290
2023-07-25 00:04:21 | INFO | train_inner | epoch 004:   1284 / 1474 loss=2.465, trans_loss=3.692, nll_loss=1.9, w2v_ctc_loss=1.432, task_loss=0, contrastive_loss=0.29, total=4156.53, n_correct=2174.23, ppl=3.73, accuracy=52.309, wps=15633.9, ups=1.26, wpb=12411.4, bsz=472.7, num_updates=5700, lr=0.000187317, gnorm=0.546, clip=0, loss_scale=8, train_wall=79, gb_free=16.1, wall=4370
2023-07-25 00:05:40 | INFO | train_inner | epoch 004:   1384 / 1474 loss=2.438, trans_loss=3.693, nll_loss=1.901, w2v_ctc_loss=1.43, task_loss=0, contrastive_loss=0.169, total=4101.23, n_correct=2145.65, ppl=3.74, accuracy=52.317, wps=15408, ups=1.26, wpb=12249, bsz=437.6, num_updates=5800, lr=0.000185695, gnorm=0.542, clip=0, loss_scale=8, train_wall=79, gb_free=15.9, wall=4449
2023-07-25 00:06:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.4786, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.4786, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.4786, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.4786, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.4786, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.4786, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.4786, device='cuda:1')
2023-07-25 00:07:14 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.664 | trans_loss 5.91 | nll_loss 3.286 | w2v_ctc_loss 1.606 | task_loss 0 | contrastive_loss 0.313 | total 4003.4 | n_correct 2261.8 | ppl 9.76 | accuracy 56.497 | uer 23.407 | wer 25.066 | raw_wer 25.066 | bleu 16.1 | wps 2127.3 | wpb 4003.4 | bsz 141.8 | num_updates 5890 | best_bleu 16.1
2023-07-25 00:07:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5890 updates
2023-07-25 00:07:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 00:07:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 00:07:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt (epoch 4 @ 5890 updates, score 16.1) (writing took 19.111790953204036 seconds)
2023-07-25 00:07:34 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-07-25 00:07:34 | INFO | train | epoch 004 | loss 2.521 | trans_loss 3.722 | nll_loss 1.937 | w2v_ctc_loss 1.479 | task_loss 0 | contrastive_loss 0.286 | total 4138.65 | n_correct 2103.26 | ppl 3.83 | accuracy 50.82 | wps 14928.7 | ups 1.21 | wpb 12355.8 | bsz 458.5 | num_updates 5890 | lr 0.000184271 | gnorm 0.676 | clip 0 | loss_scale 8 | train_wall 1161 | gb_free 15.1 | wall 4563
2023-07-25 00:07:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 00:07:34 | INFO | fairseq.trainer | begin training epoch 5
2023-07-25 00:07:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 00:07:50 | INFO | train_inner | epoch 005:     10 / 1474 loss=2.421, trans_loss=3.684, nll_loss=1.889, w2v_ctc_loss=1.404, task_loss=0, contrastive_loss=0.192, total=4037.7, n_correct=2123.77, ppl=3.7, accuracy=52.599, wps=9299.9, ups=0.77, wpb=12055.9, bsz=439.3, num_updates=5900, lr=0.000184115, gnorm=0.544, clip=0, loss_scale=8, train_wall=78, gb_free=17, wall=4579
2023-07-25 00:09:09 | INFO | train_inner | epoch 005:    110 / 1474 loss=2.347, trans_loss=3.623, nll_loss=1.81, w2v_ctc_loss=1.326, task_loss=0, contrastive_loss=0.2, total=4247.37, n_correct=2309.2, ppl=3.51, accuracy=54.368, wps=16021.8, ups=1.26, wpb=12683.4, bsz=495.1, num_updates=6000, lr=0.000182574, gnorm=0.522, clip=0, loss_scale=8, train_wall=79, gb_free=16.9, wall=4658
2023-07-25 00:09:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 00:09:32 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.654 | trans_loss 5.904 | nll_loss 3.279 | w2v_ctc_loss 1.578 | task_loss 0 | contrastive_loss 0.319 | total 4003.4 | n_correct 2264.3 | ppl 9.7 | accuracy 56.559 | uer 23.019 | wer 24.567 | raw_wer 24.567 | bleu 16.53 | wps 2295.8 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 16.53
2023-07-25 00:09:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-07-25 00:09:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_5_6000.pt
2023-07-25 00:09:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_5_6000.pt
2023-07-25 00:09:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 16.53) (writing took 20.6509770154953 seconds)
2023-07-25 00:11:11 | INFO | train_inner | epoch 005:    210 / 1474 loss=2.387, trans_loss=3.636, nll_loss=1.824, w2v_ctc_loss=1.344, task_loss=0, contrastive_loss=0.415, total=4189.85, n_correct=2265.71, ppl=3.54, accuracy=54.076, wps=10220.4, ups=0.82, wpb=12500.5, bsz=488.2, num_updates=6100, lr=0.000181071, gnorm=0.527, clip=0, loss_scale=8, train_wall=78, gb_free=17.9, wall=4780
2023-07-25 00:12:30 | INFO | train_inner | epoch 005:    310 / 1474 loss=2.37, trans_loss=3.632, nll_loss=1.825, w2v_ctc_loss=1.357, task_loss=0, contrastive_loss=0.257, total=4090.1, n_correct=2202.69, ppl=3.54, accuracy=53.854, wps=15498.9, ups=1.27, wpb=12228.1, bsz=443.9, num_updates=6200, lr=0.000179605, gnorm=0.532, clip=0, loss_scale=8, train_wall=78, gb_free=16.4, wall=4859
2023-07-25 00:13:49 | INFO | train_inner | epoch 005:    410 / 1474 loss=2.365, trans_loss=3.625, nll_loss=1.816, w2v_ctc_loss=1.325, task_loss=0, contrastive_loss=0.351, total=4147.17, n_correct=2252.77, ppl=3.52, accuracy=54.321, wps=15722.8, ups=1.27, wpb=12395.1, bsz=472.5, num_updates=6300, lr=0.000178174, gnorm=0.537, clip=0, loss_scale=8, train_wall=78, gb_free=15.1, wall=4938
2023-07-25 00:15:07 | INFO | train_inner | epoch 005:    510 / 1474 loss=2.335, trans_loss=3.636, nll_loss=1.828, w2v_ctc_loss=1.335, task_loss=0, contrastive_loss=0.142, total=4026.81, n_correct=2175.83, ppl=3.55, accuracy=54.034, wps=15363.2, ups=1.28, wpb=12029.7, bsz=416.6, num_updates=6400, lr=0.000176777, gnorm=0.526, clip=0, loss_scale=8, train_wall=78, gb_free=17.5, wall=5016
2023-07-25 00:16:27 | INFO | train_inner | epoch 005:    610 / 1474 loss=2.358, trans_loss=3.641, nll_loss=1.832, w2v_ctc_loss=1.325, task_loss=0, contrastive_loss=0.317, total=4107.75, n_correct=2224.51, ppl=3.56, accuracy=54.154, wps=15380.8, ups=1.26, wpb=12253.8, bsz=451.2, num_updates=6500, lr=0.000175412, gnorm=0.539, clip=0, loss_scale=8, train_wall=79, gb_free=16.4, wall=5096
2023-07-25 00:17:46 | INFO | train_inner | epoch 005:    710 / 1474 loss=2.361, trans_loss=3.635, nll_loss=1.827, w2v_ctc_loss=1.328, task_loss=0, contrastive_loss=0.295, total=4178.85, n_correct=2272.33, ppl=3.55, accuracy=54.377, wps=15892.4, ups=1.27, wpb=12473.1, bsz=480.9, num_updates=6600, lr=0.000174078, gnorm=0.534, clip=0, loss_scale=8, train_wall=78, gb_free=17.8, wall=5174
2023-07-25 00:19:05 | INFO | train_inner | epoch 005:    810 / 1474 loss=2.339, trans_loss=3.635, nll_loss=1.825, w2v_ctc_loss=1.321, task_loss=0, contrastive_loss=0.219, total=4127.73, n_correct=2248.01, ppl=3.54, accuracy=54.461, wps=15587.3, ups=1.27, wpb=12320.4, bsz=449.2, num_updates=6700, lr=0.000172774, gnorm=0.526, clip=0, loss_scale=8, train_wall=79, gb_free=15.4, wall=5253
2023-07-25 00:20:23 | INFO | train_inner | epoch 005:    910 / 1474 loss=2.314, trans_loss=3.624, nll_loss=1.814, w2v_ctc_loss=1.308, task_loss=0, contrastive_loss=0.179, total=4095.48, n_correct=2240.77, ppl=3.52, accuracy=54.713, wps=15571.4, ups=1.27, wpb=12229.5, bsz=445.3, num_updates=6800, lr=0.000171499, gnorm=0.52, clip=0, loss_scale=8, train_wall=78, gb_free=15.8, wall=5332
2023-07-25 00:21:42 | INFO | train_inner | epoch 005:   1010 / 1474 loss=2.329, trans_loss=3.629, nll_loss=1.82, w2v_ctc_loss=1.311, task_loss=0, contrastive_loss=0.262, total=4165.12, n_correct=2274.09, ppl=3.53, accuracy=54.598, wps=15686.7, ups=1.26, wpb=12433.6, bsz=463.5, num_updates=6900, lr=0.000170251, gnorm=0.52, clip=0, loss_scale=8, train_wall=79, gb_free=15.9, wall=5411
2023-07-25 00:23:02 | INFO | train_inner | epoch 005:   1110 / 1474 loss=2.34, trans_loss=3.628, nll_loss=1.817, w2v_ctc_loss=1.318, task_loss=0, contrastive_loss=0.265, total=4176.72, n_correct=2289.24, ppl=3.52, accuracy=54.81, wps=15715.7, ups=1.26, wpb=12459.2, bsz=466.1, num_updates=7000, lr=0.000169031, gnorm=0.519, clip=0, loss_scale=8, train_wall=79, gb_free=16.9, wall=5491
2023-07-25 00:24:21 | INFO | train_inner | epoch 005:   1210 / 1474 loss=2.301, trans_loss=3.625, nll_loss=1.812, w2v_ctc_loss=1.293, task_loss=0, contrastive_loss=0.168, total=4164.13, n_correct=2290.79, ppl=3.51, accuracy=55.012, wps=15621.5, ups=1.26, wpb=12420.9, bsz=453.8, num_updates=7100, lr=0.000167836, gnorm=0.52, clip=0, loss_scale=16, train_wall=79, gb_free=17.2, wall=5570
2023-07-25 00:25:41 | INFO | train_inner | epoch 005:   1310 / 1474 loss=2.29, trans_loss=3.625, nll_loss=1.814, w2v_ctc_loss=1.286, task_loss=0, contrastive_loss=0.136, total=4134.91, n_correct=2273.99, ppl=3.52, accuracy=54.995, wps=15570.2, ups=1.26, wpb=12341.4, bsz=445.6, num_updates=7200, lr=0.000166667, gnorm=0.513, clip=0, loss_scale=16, train_wall=79, gb_free=16.5, wall=5649
2023-07-25 00:27:00 | INFO | train_inner | epoch 005:   1410 / 1474 loss=2.299, trans_loss=3.623, nll_loss=1.815, w2v_ctc_loss=1.282, task_loss=0, contrastive_loss=0.202, total=4134.37, n_correct=2276.04, ppl=3.52, accuracy=55.052, wps=15574.4, ups=1.26, wpb=12347.5, bsz=458.5, num_updates=7300, lr=0.000165521, gnorm=0.514, clip=0, loss_scale=16, train_wall=79, gb_free=17.9, wall=5729
2023-07-25 00:27:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 00:28:13 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.571 | trans_loss 5.836 | nll_loss 3.193 | w2v_ctc_loss 1.454 | task_loss 0 | contrastive_loss 0.327 | total 4003.4 | n_correct 2305 | ppl 9.15 | accuracy 57.576 | uer 21.862 | wer 23.459 | raw_wer 23.459 | bleu 17.28 | wps 2270.7 | wpb 4003.4 | bsz 141.8 | num_updates 7364 | best_bleu 17.28
2023-07-25 00:28:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7364 updates
2023-07-25 00:28:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 00:28:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 00:28:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt (epoch 5 @ 7364 updates, score 17.28) (writing took 20.2106555365026 seconds)
2023-07-25 00:28:33 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-07-25 00:28:33 | INFO | train | epoch 005 | loss 2.337 | trans_loss 3.629 | nll_loss 1.819 | w2v_ctc_loss 1.318 | task_loss 0 | contrastive_loss 0.244 | total 4138.65 | n_correct 2255.95 | ppl 3.53 | accuracy 54.509 | wps 14459.8 | ups 1.17 | wpb 12355.8 | bsz 458.5 | num_updates 7364 | lr 0.0001648 | gnorm 0.526 | clip 0 | loss_scale 16 | train_wall 1158 | gb_free 16.5 | wall 5822
2023-07-25 00:28:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 00:28:34 | INFO | fairseq.trainer | begin training epoch 6
2023-07-25 00:28:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 00:29:11 | INFO | train_inner | epoch 006:     36 / 1474 loss=2.283, trans_loss=3.6, nll_loss=1.783, w2v_ctc_loss=1.275, task_loss=0, contrastive_loss=0.199, total=4115.45, n_correct=2287.09, ppl=3.44, accuracy=55.573, wps=9366.8, ups=0.76, wpb=12281.2, bsz=447.9, num_updates=7400, lr=0.000164399, gnorm=0.526, clip=0, loss_scale=16, train_wall=79, gb_free=16.6, wall=5860
2023-07-25 00:30:30 | INFO | train_inner | epoch 006:    136 / 1474 loss=2.241, trans_loss=3.568, nll_loss=1.741, w2v_ctc_loss=1.228, task_loss=0, contrastive_loss=0.241, total=4154.25, n_correct=2335.53, ppl=3.34, accuracy=56.22, wps=15776.5, ups=1.27, wpb=12407.4, bsz=456.1, num_updates=7500, lr=0.000163299, gnorm=0.511, clip=0, loss_scale=16, train_wall=78, gb_free=15.8, wall=5938
2023-07-25 00:31:49 | INFO | train_inner | epoch 006:    236 / 1474 loss=2.249, trans_loss=3.579, nll_loss=1.756, w2v_ctc_loss=1.257, task_loss=0, contrastive_loss=0.148, total=4112.66, n_correct=2303.36, ppl=3.38, accuracy=56.007, wps=15421.6, ups=1.26, wpb=12287.2, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.512, clip=0, loss_scale=16, train_wall=79, gb_free=16.4, wall=6018
2023-07-25 00:33:09 | INFO | train_inner | epoch 006:    336 / 1474 loss=2.267, trans_loss=3.567, nll_loss=1.741, w2v_ctc_loss=1.209, task_loss=0, contrastive_loss=0.458, total=4177.51, n_correct=2363.3, ppl=3.34, accuracy=56.572, wps=15575.9, ups=1.25, wpb=12473.8, bsz=491.3, num_updates=7700, lr=0.000161165, gnorm=0.519, clip=0, loss_scale=16, train_wall=80, gb_free=16.3, wall=6098
2023-07-25 00:34:28 | INFO | train_inner | epoch 006:    436 / 1474 loss=2.224, trans_loss=3.571, nll_loss=1.746, w2v_ctc_loss=1.219, task_loss=0, contrastive_loss=0.166, total=4154.57, n_correct=2350.62, ppl=3.35, accuracy=56.579, wps=15852.3, ups=1.28, wpb=12405.5, bsz=470.2, num_updates=7800, lr=0.000160128, gnorm=0.511, clip=0, loss_scale=16, train_wall=78, gb_free=16.3, wall=6176
2023-07-25 00:35:46 | INFO | train_inner | epoch 006:    536 / 1474 loss=2.231, trans_loss=3.579, nll_loss=1.754, w2v_ctc_loss=1.232, task_loss=0, contrastive_loss=0.152, total=4167.79, n_correct=2353.79, ppl=3.37, accuracy=56.476, wps=15794.5, ups=1.27, wpb=12438.5, bsz=455.2, num_updates=7900, lr=0.000159111, gnorm=0.51, clip=0, loss_scale=16, train_wall=78, gb_free=16, wall=6255
2023-07-25 00:37:06 | INFO | train_inner | epoch 006:    636 / 1474 loss=2.23, trans_loss=3.579, nll_loss=1.757, w2v_ctc_loss=1.214, task_loss=0, contrastive_loss=0.207, total=4146.17, n_correct=2339.29, ppl=3.38, accuracy=56.421, wps=15542.5, ups=1.26, wpb=12376.6, bsz=471.6, num_updates=8000, lr=0.000158114, gnorm=0.509, clip=0, loss_scale=16, train_wall=79, gb_free=16.5, wall=6335
2023-07-25 00:37:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 00:37:28 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.544 | trans_loss 5.78 | nll_loss 3.111 | w2v_ctc_loss 1.519 | task_loss 0 | contrastive_loss 0.289 | total 4003.4 | n_correct 2341.9 | ppl 8.64 | accuracy 58.498 | uer 20.866 | wer 22.62 | raw_wer 22.62 | bleu 17.79 | wps 2319.9 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 17.79
2023-07-25 00:37:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-07-25 00:37:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_6_8000.pt
2023-07-25 00:37:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_6_8000.pt
2023-07-25 00:38:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 17.79) (writing took 35.20358473621309 seconds)
2023-07-25 00:39:22 | INFO | train_inner | epoch 006:    736 / 1474 loss=2.232, trans_loss=3.582, nll_loss=1.76, w2v_ctc_loss=1.231, task_loss=0, contrastive_loss=0.162, total=4148.65, n_correct=2339.02, ppl=3.39, accuracy=56.38, wps=9075.1, ups=0.73, wpb=12388, bsz=453.7, num_updates=8100, lr=0.000157135, gnorm=0.507, clip=0, loss_scale=16, train_wall=78, gb_free=15.8, wall=6471
2023-07-25 00:40:42 | INFO | train_inner | epoch 006:    836 / 1474 loss=2.226, trans_loss=3.59, nll_loss=1.77, w2v_ctc_loss=1.223, task_loss=0, contrastive_loss=0.145, total=4114.34, n_correct=2313.67, ppl=3.41, accuracy=56.234, wps=15529.3, ups=1.26, wpb=12282.2, bsz=441.6, num_updates=8200, lr=0.000156174, gnorm=0.509, clip=0, loss_scale=16, train_wall=79, gb_free=15.3, wall=6550
2023-07-25 00:42:01 | INFO | train_inner | epoch 006:    936 / 1474 loss=2.243, trans_loss=3.589, nll_loss=1.769, w2v_ctc_loss=1.225, task_loss=0, contrastive_loss=0.24, total=4081.53, n_correct=2297.61, ppl=3.41, accuracy=56.293, wps=15345, ups=1.26, wpb=12181.3, bsz=444.5, num_updates=8300, lr=0.00015523, gnorm=0.511, clip=0, loss_scale=16, train_wall=79, gb_free=17.9, wall=6630
2023-07-25 00:43:21 | INFO | train_inner | epoch 006:   1036 / 1474 loss=2.236, trans_loss=3.575, nll_loss=1.753, w2v_ctc_loss=1.206, task_loss=0, contrastive_loss=0.316, total=4165.84, n_correct=2356.69, ppl=3.37, accuracy=56.572, wps=15534, ups=1.25, wpb=12435.7, bsz=477.2, num_updates=8400, lr=0.000154303, gnorm=0.516, clip=0, loss_scale=16, train_wall=80, gb_free=17, wall=6710
2023-07-25 00:44:40 | INFO | train_inner | epoch 006:   1136 / 1474 loss=2.221, trans_loss=3.582, nll_loss=1.76, w2v_ctc_loss=1.221, task_loss=0, contrastive_loss=0.146, total=4072.29, n_correct=2296.44, ppl=3.39, accuracy=56.392, wps=15483.1, ups=1.27, wpb=12157.6, bsz=428, num_updates=8500, lr=0.000153393, gnorm=0.511, clip=0, loss_scale=16, train_wall=78, gb_free=17.2, wall=6788
2023-07-25 00:45:59 | INFO | train_inner | epoch 006:   1236 / 1474 loss=2.256, trans_loss=3.572, nll_loss=1.751, w2v_ctc_loss=1.207, task_loss=0, contrastive_loss=0.464, total=4141.55, n_correct=2346.19, ppl=3.37, accuracy=56.65, wps=15512.3, ups=1.25, wpb=12370.9, bsz=474.8, num_updates=8600, lr=0.000152499, gnorm=0.509, clip=0, loss_scale=16, train_wall=79, gb_free=13.6, wall=6868
2023-07-25 00:47:18 | INFO | train_inner | epoch 006:   1336 / 1474 loss=2.204, trans_loss=3.582, nll_loss=1.759, w2v_ctc_loss=1.203, task_loss=0, contrastive_loss=0.132, total=4125.31, n_correct=2338.52, ppl=3.38, accuracy=56.687, wps=15593.4, ups=1.27, wpb=12305, bsz=452.6, num_updates=8700, lr=0.00015162, gnorm=0.509, clip=0, loss_scale=16, train_wall=78, gb_free=17.9, wall=6947
2023-07-25 00:48:38 | INFO | train_inner | epoch 006:   1436 / 1474 loss=2.203, trans_loss=3.573, nll_loss=1.75, w2v_ctc_loss=1.204, task_loss=0, contrastive_loss=0.139, total=4196.2, n_correct=2389.88, ppl=3.36, accuracy=56.953, wps=15725.7, ups=1.26, wpb=12525.2, bsz=461.5, num_updates=8800, lr=0.000150756, gnorm=0.495, clip=0, loss_scale=16, train_wall=79, gb_free=11.9, wall=7027
2023-07-25 00:49:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 00:49:30 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.49 | trans_loss 5.746 | nll_loss 3.079 | w2v_ctc_loss 1.421 | task_loss 0 | contrastive_loss 0.293 | total 4003.4 | n_correct 2360.7 | ppl 8.45 | accuracy 58.967 | uer 19.99 | wer 21.67 | raw_wer 21.67 | bleu 18.09 | wps 2255.5 | wpb 4003.4 | bsz 141.8 | num_updates 8838 | best_bleu 18.09
2023-07-25 00:49:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8838 updates
2023-07-25 00:49:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 00:49:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 00:49:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt (epoch 6 @ 8838 updates, score 18.09) (writing took 19.89521404542029 seconds)
2023-07-25 00:49:50 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-07-25 00:49:50 | INFO | train | epoch 006 | loss 2.232 | trans_loss 3.577 | nll_loss 1.754 | w2v_ctc_loss 1.219 | task_loss 0 | contrastive_loss 0.222 | total 4138.65 | n_correct 2337.33 | ppl 3.37 | accuracy 56.476 | wps 14262.6 | ups 1.15 | wpb 12355.8 | bsz 458.5 | num_updates 8838 | lr 0.000150431 | gnorm 0.51 | clip 0 | loss_scale 16 | train_wall 1161 | gb_free 15.4 | wall 7099
2023-07-25 00:49:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 00:49:51 | INFO | fairseq.trainer | begin training epoch 7
2023-07-25 00:49:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 00:50:48 | INFO | train_inner | epoch 007:     62 / 1474 loss=2.172, trans_loss=3.548, nll_loss=1.718, w2v_ctc_loss=1.173, task_loss=0, contrastive_loss=0.157, total=4108.19, n_correct=2363.96, ppl=3.29, accuracy=57.543, wps=9426.9, ups=0.77, wpb=12266.6, bsz=461.9, num_updates=8900, lr=0.000149906, gnorm=0.506, clip=0, loss_scale=16, train_wall=78, gb_free=17.3, wall=7157
2023-07-25 00:52:07 | INFO | train_inner | epoch 007:    162 / 1474 loss=2.168, trans_loss=3.537, nll_loss=1.703, w2v_ctc_loss=1.156, task_loss=0, contrastive_loss=0.226, total=4106.05, n_correct=2370.86, ppl=3.25, accuracy=57.741, wps=15568.2, ups=1.27, wpb=12258.7, bsz=455.4, num_updates=9000, lr=0.000149071, gnorm=0.509, clip=0, loss_scale=16, train_wall=78, gb_free=16.9, wall=7236
2023-07-25 00:53:26 | INFO | train_inner | epoch 007:    262 / 1474 loss=2.152, trans_loss=3.533, nll_loss=1.696, w2v_ctc_loss=1.16, task_loss=0, contrastive_loss=0.134, total=4129.3, n_correct=2396.26, ppl=3.24, accuracy=58.031, wps=15480.1, ups=1.26, wpb=12322.8, bsz=451.8, num_updates=9100, lr=0.00014825, gnorm=0.505, clip=0, loss_scale=16, train_wall=79, gb_free=17.4, wall=7315
2023-07-25 00:54:46 | INFO | train_inner | epoch 007:    362 / 1474 loss=2.188, trans_loss=3.542, nll_loss=1.708, w2v_ctc_loss=1.151, task_loss=0, contrastive_loss=0.392, total=4201.67, n_correct=2422.89, ppl=3.27, accuracy=57.665, wps=15763.6, ups=1.26, wpb=12539.8, bsz=479.7, num_updates=9200, lr=0.000147442, gnorm=0.5, clip=0, loss_scale=32, train_wall=79, gb_free=15.6, wall=7395
2023-07-25 00:56:04 | INFO | train_inner | epoch 007:    462 / 1474 loss=2.177, trans_loss=3.542, nll_loss=1.712, w2v_ctc_loss=1.15, task_loss=0, contrastive_loss=0.316, total=4155.31, n_correct=2393.84, ppl=3.28, accuracy=57.609, wps=15818.4, ups=1.27, wpb=12410.9, bsz=465.5, num_updates=9300, lr=0.000146647, gnorm=0.507, clip=0, loss_scale=32, train_wall=78, gb_free=16.9, wall=7473
2023-07-25 00:57:24 | INFO | train_inner | epoch 007:    562 / 1474 loss=2.152, trans_loss=3.543, nll_loss=1.708, w2v_ctc_loss=1.152, task_loss=0, contrastive_loss=0.144, total=4165.88, n_correct=2408.79, ppl=3.27, accuracy=57.822, wps=15690.9, ups=1.26, wpb=12426.4, bsz=459, num_updates=9400, lr=0.000145865, gnorm=0.499, clip=0, loss_scale=32, train_wall=79, gb_free=17.4, wall=7552
2023-07-25 00:58:43 | INFO | train_inner | epoch 007:    662 / 1474 loss=2.144, trans_loss=3.542, nll_loss=1.708, w2v_ctc_loss=1.148, task_loss=0, contrastive_loss=0.128, total=4149.29, n_correct=2405.07, ppl=3.27, accuracy=57.963, wps=15514.3, ups=1.25, wpb=12381.3, bsz=451.6, num_updates=9500, lr=0.000145095, gnorm=0.504, clip=0, loss_scale=32, train_wall=79, gb_free=17.3, wall=7632
2023-07-25 01:00:03 | INFO | train_inner | epoch 007:    762 / 1474 loss=2.145, trans_loss=3.536, nll_loss=1.702, w2v_ctc_loss=1.149, task_loss=0, contrastive_loss=0.128, total=4134.54, n_correct=2396.74, ppl=3.25, accuracy=57.969, wps=15585.9, ups=1.26, wpb=12345.4, bsz=449.8, num_updates=9600, lr=0.000144338, gnorm=0.502, clip=0, loss_scale=32, train_wall=79, gb_free=14.1, wall=7711
2023-07-25 01:01:22 | INFO | train_inner | epoch 007:    862 / 1474 loss=2.149, trans_loss=3.547, nll_loss=1.716, w2v_ctc_loss=1.148, task_loss=0, contrastive_loss=0.149, total=4151.77, n_correct=2396.5, ppl=3.29, accuracy=57.722, wps=15669.1, ups=1.26, wpb=12391.6, bsz=461.9, num_updates=9700, lr=0.000143592, gnorm=0.504, clip=0, loss_scale=32, train_wall=79, gb_free=15.1, wall=7791
2023-07-25 01:02:42 | INFO | train_inner | epoch 007:    962 / 1474 loss=2.158, trans_loss=3.541, nll_loss=1.709, w2v_ctc_loss=1.138, task_loss=0, contrastive_loss=0.245, total=4124.8, n_correct=2389.09, ppl=3.27, accuracy=57.92, wps=15377.6, ups=1.25, wpb=12313.3, bsz=471.2, num_updates=9800, lr=0.000142857, gnorm=0.504, clip=0, loss_scale=32, train_wall=80, gb_free=16.8, wall=7871
2023-07-25 01:04:01 | INFO | train_inner | epoch 007:   1062 / 1474 loss=2.146, trans_loss=3.553, nll_loss=1.725, w2v_ctc_loss=1.151, task_loss=0, contrastive_loss=0.112, total=4113.08, n_correct=2373.27, ppl=3.31, accuracy=57.701, wps=15526.1, ups=1.26, wpb=12279.6, bsz=439.4, num_updates=9900, lr=0.000142134, gnorm=0.502, clip=0, loss_scale=32, train_wall=79, gb_free=15, wall=7950
2023-07-25 01:05:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-25 01:05:21 | INFO | train_inner | epoch 007:   1163 / 1474 loss=2.156, trans_loss=3.537, nll_loss=1.708, w2v_ctc_loss=1.144, task_loss=0, contrastive_loss=0.22, total=4113.08, n_correct=2387.04, ppl=3.27, accuracy=58.035, wps=15417, ups=1.25, wpb=12290.8, bsz=459.5, num_updates=10000, lr=0.000141421, gnorm=0.504, clip=0, loss_scale=16, train_wall=79, gb_free=16.2, wall=8029
2023-07-25 01:05:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 01:05:42 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.444 | trans_loss 5.7 | nll_loss 3.019 | w2v_ctc_loss 1.38 | task_loss 0 | contrastive_loss 0.283 | total 4003.4 | n_correct 2383.4 | ppl 8.1 | accuracy 59.534 | uer 18.939 | wer 20.544 | raw_wer 20.544 | bleu 18.67 | wps 2469.3 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 18.67
2023-07-25 01:05:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-07-25 01:05:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_7_10000.pt
2023-07-25 01:05:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_7_10000.pt
2023-07-25 01:06:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 18.67) (writing took 26.625168627128005 seconds)
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:0')
2023-07-25 01:07:28 | INFO | train_inner | epoch 007:   1263 / 1474 loss=2.136, trans_loss=3.544, nll_loss=1.715, w2v_ctc_loss=1.136, task_loss=0, contrastive_loss=0.14, total=4129.52, n_correct=2394.31, ppl=3.28, accuracy=57.98, wps=9689.6, ups=0.79, wpb=12331.4, bsz=450.2, num_updates=10100, lr=0.00014072, gnorm=0.421, clip=0, loss_scale=16, train_wall=78, gb_free=16.9, wall=8157
2023-07-25 01:08:48 | INFO | train_inner | epoch 007:   1363 / 1474 loss=2.151, trans_loss=3.539, nll_loss=1.708, w2v_ctc_loss=1.145, task_loss=0, contrastive_loss=0.177, total=4172.87, n_correct=2425.94, ppl=3.27, accuracy=58.136, wps=15614.5, ups=1.25, wpb=12458.1, bsz=476.2, num_updates=10200, lr=0.000140028, gnorm=0.418, clip=0, loss_scale=16, train_wall=79, gb_free=17.3, wall=8236
2023-07-25 01:10:07 | INFO | train_inner | epoch 007:   1463 / 1474 loss=2.158, trans_loss=3.543, nll_loss=1.716, w2v_ctc_loss=1.144, task_loss=0, contrastive_loss=0.242, total=4109.42, n_correct=2376.83, ppl=3.28, accuracy=57.839, wps=15379.9, ups=1.25, wpb=12278.1, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.423, clip=0, loss_scale=16, train_wall=79, gb_free=16.7, wall=8316
2023-07-25 01:10:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:1')
2023-07-25 01:10:39 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.452 | trans_loss 5.701 | nll_loss 3.016 | w2v_ctc_loss 1.402 | task_loss 0 | contrastive_loss 0.289 | total 4003.4 | n_correct 2379.2 | ppl 8.09 | accuracy 59.429 | uer 19.29 | wer 20.995 | raw_wer 20.995 | bleu 18.44 | wps 2235.2 | wpb 4003.4 | bsz 141.8 | num_updates 10311 | best_bleu 18.67
2023-07-25 01:10:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10311 updates
2023-07-25 01:10:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_18.4401.pt
2023-07-25 01:10:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_18.4401.pt
2023-07-25 01:10:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_18.4401.pt (epoch 7 @ 10311 updates, score 18.44) (writing took 11.828800035640597 seconds)
2023-07-25 01:10:51 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-07-25 01:10:51 | INFO | train | epoch 007 | loss 2.156 | trans_loss 3.541 | nll_loss 1.709 | w2v_ctc_loss 1.148 | task_loss 0 | contrastive_loss 0.195 | total 4137.25 | n_correct 2394.21 | ppl 3.27 | accuracy 57.87 | wps 14430.7 | ups 1.17 | wpb 12351.7 | bsz 457.8 | num_updates 10311 | lr 0.000139272 | gnorm 0.486 | clip 0 | loss_scale 16 | train_wall 1161 | gb_free 13.5 | wall 8360
2023-07-25 01:10:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 01:10:51 | INFO | fairseq.trainer | begin training epoch 8
2023-07-25 01:10:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 01:12:10 | INFO | train_inner | epoch 008:     89 / 1474 loss=2.104, trans_loss=3.518, nll_loss=1.676, w2v_ctc_loss=1.106, task_loss=0, contrastive_loss=0.136, total=4116.25, n_correct=2417.56, ppl=3.19, accuracy=58.732, wps=10041.6, ups=0.82, wpb=12273, bsz=443.3, num_updates=10400, lr=0.000138675, gnorm=0.419, clip=0, loss_scale=16, train_wall=78, gb_free=17.2, wall=8439
2023-07-25 01:13:28 | INFO | train_inner | epoch 008:    189 / 1474 loss=2.101, trans_loss=3.51, nll_loss=1.666, w2v_ctc_loss=1.101, task_loss=0, contrastive_loss=0.155, total=4037.23, n_correct=2379.29, ppl=3.17, accuracy=58.934, wps=15288, ups=1.27, wpb=12041.5, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.426, clip=0, loss_scale=16, train_wall=78, gb_free=13.1, wall=8517
2023-07-25 01:14:48 | INFO | train_inner | epoch 008:    289 / 1474 loss=2.105, trans_loss=3.506, nll_loss=1.663, w2v_ctc_loss=1.103, task_loss=0, contrastive_loss=0.157, total=4207.78, n_correct=2486.91, ppl=3.17, accuracy=59.103, wps=15802.3, ups=1.26, wpb=12556.5, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.419, clip=0, loss_scale=16, train_wall=79, gb_free=13.4, wall=8597
2023-07-25 01:16:07 | INFO | train_inner | epoch 008:    389 / 1474 loss=2.117, trans_loss=3.515, nll_loss=1.673, w2v_ctc_loss=1.119, task_loss=0, contrastive_loss=0.175, total=4127.24, n_correct=2421.45, ppl=3.19, accuracy=58.67, wps=15486.5, ups=1.26, wpb=12316.2, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=0.424, clip=0, loss_scale=16, train_wall=79, gb_free=12.2, wall=8676
2023-07-25 01:17:27 | INFO | train_inner | epoch 008:    489 / 1474 loss=2.152, trans_loss=3.51, nll_loss=1.67, w2v_ctc_loss=1.097, task_loss=0, contrastive_loss=0.443, total=4203.76, n_correct=2475.68, ppl=3.18, accuracy=58.892, wps=15691.9, ups=1.25, wpb=12548.2, bsz=504.5, num_updates=10800, lr=0.000136083, gnorm=0.424, clip=0, loss_scale=16, train_wall=79, gb_free=14.8, wall=8756
2023-07-25 01:18:47 | INFO | train_inner | epoch 008:    589 / 1474 loss=2.105, trans_loss=3.513, nll_loss=1.677, w2v_ctc_loss=1.116, task_loss=0, contrastive_loss=0.111, total=4062.5, n_correct=2375.9, ppl=3.2, accuracy=58.484, wps=15239.5, ups=1.25, wpb=12145.4, bsz=427.9, num_updates=10900, lr=0.000135457, gnorm=0.424, clip=0, loss_scale=16, train_wall=79, gb_free=11.7, wall=8836
2023-07-25 01:20:06 | INFO | train_inner | epoch 008:    689 / 1474 loss=2.101, trans_loss=3.509, nll_loss=1.667, w2v_ctc_loss=1.112, task_loss=0, contrastive_loss=0.123, total=4142.78, n_correct=2444.56, ppl=3.18, accuracy=59.008, wps=15623.1, ups=1.26, wpb=12364.4, bsz=448.6, num_updates=11000, lr=0.00013484, gnorm=0.417, clip=0, loss_scale=16, train_wall=79, gb_free=16, wall=8915
2023-07-25 01:21:25 | INFO | train_inner | epoch 008:    789 / 1474 loss=2.107, trans_loss=3.509, nll_loss=1.672, w2v_ctc_loss=1.103, task_loss=0, contrastive_loss=0.206, total=4118.9, n_correct=2425.66, ppl=3.19, accuracy=58.891, wps=15716, ups=1.28, wpb=12310.9, bsz=447.8, num_updates=11100, lr=0.000134231, gnorm=0.42, clip=0, loss_scale=16, train_wall=78, gb_free=15.4, wall=8993
2023-07-25 01:22:44 | INFO | train_inner | epoch 008:    889 / 1474 loss=2.106, trans_loss=3.511, nll_loss=1.674, w2v_ctc_loss=1.094, task_loss=0, contrastive_loss=0.22, total=4169.01, n_correct=2462.24, ppl=3.19, accuracy=59.061, wps=15726.2, ups=1.26, wpb=12452.5, bsz=473.7, num_updates=11200, lr=0.000133631, gnorm=0.422, clip=0, loss_scale=16, train_wall=79, gb_free=16.3, wall=9073
2023-07-25 01:24:03 | INFO | train_inner | epoch 008:    989 / 1474 loss=2.088, trans_loss=3.511, nll_loss=1.673, w2v_ctc_loss=1.093, task_loss=0, contrastive_loss=0.12, total=4154.69, n_correct=2455.76, ppl=3.19, accuracy=59.108, wps=15610.2, ups=1.26, wpb=12403.4, bsz=464.9, num_updates=11300, lr=0.000133038, gnorm=0.418, clip=0, loss_scale=16, train_wall=79, gb_free=17.9, wall=9152
2023-07-25 01:25:23 | INFO | train_inner | epoch 008:   1089 / 1474 loss=2.123, trans_loss=3.519, nll_loss=1.682, w2v_ctc_loss=1.097, task_loss=0, contrastive_loss=0.341, total=4199.1, n_correct=2463.48, ppl=3.21, accuracy=58.667, wps=15688.8, ups=1.25, wpb=12534.3, bsz=465.3, num_updates=11400, lr=0.000132453, gnorm=0.421, clip=0, loss_scale=16, train_wall=79, gb_free=13, wall=9232
2023-07-25 01:26:41 | INFO | train_inner | epoch 008:   1189 / 1474 loss=2.096, trans_loss=3.512, nll_loss=1.676, w2v_ctc_loss=1.099, task_loss=0, contrastive_loss=0.128, total=4177.31, n_correct=2465.33, ppl=3.2, accuracy=59.017, wps=15950.3, ups=1.28, wpb=12476.3, bsz=472.6, num_updates=11500, lr=0.000131876, gnorm=0.418, clip=0, loss_scale=16, train_wall=78, gb_free=15.2, wall=9310
2023-07-25 01:28:00 | INFO | train_inner | epoch 008:   1289 / 1474 loss=2.105, trans_loss=3.518, nll_loss=1.684, w2v_ctc_loss=1.11, task_loss=0, contrastive_loss=0.151, total=4063.85, n_correct=2382.7, ppl=3.21, accuracy=58.632, wps=15516.1, ups=1.28, wpb=12140.6, bsz=438.4, num_updates=11600, lr=0.000131306, gnorm=0.425, clip=0, loss_scale=16, train_wall=78, gb_free=17, wall=9388
2023-07-25 01:29:19 | INFO | train_inner | epoch 008:   1389 / 1474 loss=2.109, trans_loss=3.519, nll_loss=1.685, w2v_ctc_loss=1.099, task_loss=0, contrastive_loss=0.203, total=4141.5, n_correct=2439.43, ppl=3.22, accuracy=58.902, wps=15542.1, ups=1.26, wpb=12367.2, bsz=461.5, num_updates=11700, lr=0.000130744, gnorm=0.419, clip=0, loss_scale=16, train_wall=79, gb_free=16.6, wall=9468
2023-07-25 01:30:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 01:30:47 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.432 | trans_loss 5.672 | nll_loss 2.977 | w2v_ctc_loss 1.409 | task_loss 0 | contrastive_loss 0.278 | total 4003.4 | n_correct 2406.5 | ppl 7.87 | accuracy 60.111 | uer 18.743 | wer 20.51 | raw_wer 20.51 | bleu 18.82 | wps 2413 | wpb 4003.4 | bsz 141.8 | num_updates 11785 | best_bleu 18.82
2023-07-25 01:30:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11785 updates
2023-07-25 01:30:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 01:30:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 01:31:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt (epoch 8 @ 11785 updates, score 18.82) (writing took 20.012152086943388 seconds)
2023-07-25 01:31:08 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-07-25 01:31:08 | INFO | train | epoch 008 | loss 2.108 | trans_loss 3.513 | nll_loss 1.674 | w2v_ctc_loss 1.103 | task_loss 0 | contrastive_loss 0.198 | total 4138.65 | n_correct 2436.59 | ppl 3.19 | accuracy 58.874 | wps 14965.5 | ups 1.21 | wpb 12355.8 | bsz 458.5 | num_updates 11785 | lr 0.000130272 | gnorm 0.421 | clip 0 | loss_scale 16 | train_wall 1159 | gb_free 17.1 | wall 9577
2023-07-25 01:31:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 01:31:08 | INFO | fairseq.trainer | begin training epoch 9
2023-07-25 01:31:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 01:31:29 | INFO | train_inner | epoch 009:     15 / 1474 loss=2.108, trans_loss=3.511, nll_loss=1.672, w2v_ctc_loss=1.084, task_loss=0, contrastive_loss=0.325, total=4139.35, n_correct=2445.85, ppl=3.19, accuracy=59.088, wps=9509.8, ups=0.77, wpb=12350.9, bsz=472.9, num_updates=11800, lr=0.000130189, gnorm=0.423, clip=0, loss_scale=16, train_wall=79, gb_free=15.6, wall=9598
2023-07-25 01:32:48 | INFO | train_inner | epoch 009:    115 / 1474 loss=2.053, trans_loss=3.474, nll_loss=1.625, w2v_ctc_loss=1.057, task_loss=0, contrastive_loss=0.15, total=4181.9, n_correct=2511.97, ppl=3.08, accuracy=60.068, wps=15899.7, ups=1.27, wpb=12488.1, bsz=475.9, num_updates=11900, lr=0.000129641, gnorm=0.414, clip=0, loss_scale=16, train_wall=78, gb_free=16.4, wall=9676
2023-07-25 01:34:08 | INFO | train_inner | epoch 009:    215 / 1474 loss=2.049, trans_loss=3.481, nll_loss=1.633, w2v_ctc_loss=1.058, task_loss=0, contrastive_loss=0.106, total=4062.07, n_correct=2432.08, ppl=3.1, accuracy=59.873, wps=15186.5, ups=1.25, wpb=12129.1, bsz=431.6, num_updates=12000, lr=0.000129099, gnorm=0.42, clip=0, loss_scale=16, train_wall=79, gb_free=15.8, wall=9756
2023-07-25 01:34:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 01:34:30 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.419 | trans_loss 5.682 | nll_loss 2.986 | w2v_ctc_loss 1.341 | task_loss 0 | contrastive_loss 0.28 | total 4003.4 | n_correct 2400 | ppl 7.92 | accuracy 59.949 | uer 18.427 | wer 20.216 | raw_wer 20.216 | bleu 18.6 | wps 2251.6 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 18.82
2023-07-25 01:34:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-07-25 01:34:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_9_12000.pt
2023-07-25 01:34:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_9_12000.pt
2023-07-25 01:34:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.6) (writing took 14.120569996535778 seconds)
2023-07-25 01:36:05 | INFO | train_inner | epoch 009:    315 / 1474 loss=2.046, trans_loss=3.468, nll_loss=1.619, w2v_ctc_loss=1.047, task_loss=0, contrastive_loss=0.156, total=4152.1, n_correct=2502.8, ppl=3.07, accuracy=60.278, wps=10602, ups=0.85, wpb=12407.3, bsz=476.6, num_updates=12100, lr=0.000128565, gnorm=0.42, clip=0, loss_scale=32, train_wall=78, gb_free=16.5, wall=9873
2023-07-25 01:37:24 | INFO | train_inner | epoch 009:    415 / 1474 loss=2.051, trans_loss=3.485, nll_loss=1.639, w2v_ctc_loss=1.056, task_loss=0, contrastive_loss=0.123, total=4203.78, n_correct=2512.51, ppl=3.11, accuracy=59.768, wps=15814.2, ups=1.26, wpb=12551.8, bsz=469.8, num_updates=12200, lr=0.000128037, gnorm=0.415, clip=0, loss_scale=32, train_wall=79, gb_free=17.3, wall=9953
2023-07-25 01:38:42 | INFO | train_inner | epoch 009:    515 / 1474 loss=2.078, trans_loss=3.492, nll_loss=1.647, w2v_ctc_loss=1.081, task_loss=0, contrastive_loss=0.173, total=4112.78, n_correct=2452.49, ppl=3.13, accuracy=59.631, wps=15690.7, ups=1.28, wpb=12275.6, bsz=437.7, num_updates=12300, lr=0.000127515, gnorm=0.421, clip=0, loss_scale=32, train_wall=78, gb_free=16.3, wall=10031
2023-07-25 01:40:02 | INFO | train_inner | epoch 009:    615 / 1474 loss=2.046, trans_loss=3.482, nll_loss=1.638, w2v_ctc_loss=1.049, task_loss=0, contrastive_loss=0.135, total=4131.32, n_correct=2472.76, ppl=3.11, accuracy=59.854, wps=15451.7, ups=1.25, wpb=12347.4, bsz=455, num_updates=12400, lr=0.000127, gnorm=0.42, clip=0, loss_scale=32, train_wall=79, gb_free=17.9, wall=10111
2023-07-25 01:41:21 | INFO | train_inner | epoch 009:    715 / 1474 loss=2.081, trans_loss=3.494, nll_loss=1.652, w2v_ctc_loss=1.076, task_loss=0, contrastive_loss=0.219, total=4082.11, n_correct=2429.75, ppl=3.14, accuracy=59.522, wps=15508.5, ups=1.27, wpb=12194.8, bsz=449.7, num_updates=12500, lr=0.000126491, gnorm=0.43, clip=0, loss_scale=32, train_wall=78, gb_free=17.2, wall=10190
2023-07-25 01:42:40 | INFO | train_inner | epoch 009:    815 / 1474 loss=2.107, trans_loss=3.487, nll_loss=1.646, w2v_ctc_loss=1.07, task_loss=0, contrastive_loss=0.369, total=4221.08, n_correct=2520.32, ppl=3.13, accuracy=59.708, wps=15900.5, ups=1.26, wpb=12613.9, bsz=501.6, num_updates=12600, lr=0.000125988, gnorm=0.429, clip=0, loss_scale=32, train_wall=79, gb_free=17.7, wall=10269
2023-07-25 01:44:00 | INFO | train_inner | epoch 009:    915 / 1474 loss=2.083, trans_loss=3.494, nll_loss=1.649, w2v_ctc_loss=1.063, task_loss=0, contrastive_loss=0.337, total=4142.34, n_correct=2469.72, ppl=3.14, accuracy=59.621, wps=15505.9, ups=1.25, wpb=12359.9, bsz=448.9, num_updates=12700, lr=0.000125491, gnorm=0.419, clip=0, loss_scale=32, train_wall=79, gb_free=17.4, wall=10349
2023-07-25 01:45:19 | INFO | train_inner | epoch 009:   1015 / 1474 loss=2.065, trans_loss=3.502, nll_loss=1.66, w2v_ctc_loss=1.074, task_loss=0, contrastive_loss=0.12, total=4097.15, n_correct=2431.35, ppl=3.16, accuracy=59.342, wps=15442.4, ups=1.26, wpb=12228.7, bsz=422.6, num_updates=12800, lr=0.000125, gnorm=0.422, clip=0, loss_scale=32, train_wall=79, gb_free=16.9, wall=10428
2023-07-25 01:46:37 | INFO | train_inner | epoch 009:   1115 / 1474 loss=2.062, trans_loss=3.496, nll_loss=1.65, w2v_ctc_loss=1.061, task_loss=0, contrastive_loss=0.147, total=4182.29, n_correct=2500.45, ppl=3.14, accuracy=59.787, wps=15941.3, ups=1.28, wpb=12467.1, bsz=477.6, num_updates=12900, lr=0.000124515, gnorm=0.418, clip=0, loss_scale=32, train_wall=78, gb_free=17.4, wall=10506
2023-07-25 01:47:56 | INFO | train_inner | epoch 009:   1215 / 1474 loss=2.07, trans_loss=3.498, nll_loss=1.657, w2v_ctc_loss=1.079, task_loss=0, contrastive_loss=0.128, total=4141.43, n_correct=2465.89, ppl=3.15, accuracy=59.542, wps=15645.4, ups=1.27, wpb=12364.7, bsz=446.6, num_updates=13000, lr=0.000124035, gnorm=0.423, clip=0, loss_scale=32, train_wall=79, gb_free=17.6, wall=10585
2023-07-25 01:49:15 | INFO | train_inner | epoch 009:   1315 / 1474 loss=2.084, trans_loss=3.492, nll_loss=1.649, w2v_ctc_loss=1.056, task_loss=0, contrastive_loss=0.318, total=4203.91, n_correct=2514.84, ppl=3.14, accuracy=59.821, wps=15956.2, ups=1.27, wpb=12545.2, bsz=492.3, num_updates=13100, lr=0.00012356, gnorm=0.416, clip=0, loss_scale=32, train_wall=78, gb_free=17.4, wall=10664
2023-07-25 01:50:34 | INFO | train_inner | epoch 009:   1415 / 1474 loss=2.059, trans_loss=3.504, nll_loss=1.663, w2v_ctc_loss=1.068, task_loss=0, contrastive_loss=0.102, total=4077.08, n_correct=2424.74, ppl=3.17, accuracy=59.472, wps=15425.4, ups=1.27, wpb=12165, bsz=429.1, num_updates=13200, lr=0.000123091, gnorm=0.422, clip=0, loss_scale=32, train_wall=78, gb_free=17.5, wall=10743
2023-07-25 01:51:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 01:51:41 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.399 | trans_loss 5.654 | nll_loss 2.955 | w2v_ctc_loss 1.345 | task_loss 0 | contrastive_loss 0.273 | total 4003.4 | n_correct 2421.5 | ppl 7.75 | accuracy 60.486 | uer 18.183 | wer 20.059 | raw_wer 20.059 | bleu 18.73 | wps 2366.1 | wpb 4003.4 | bsz 141.8 | num_updates 13259 | best_bleu 18.82
2023-07-25 01:51:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13259 updates
2023-07-25 01:51:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_18.7305.pt
2023-07-25 01:51:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_18.7305.pt
2023-07-25 01:51:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_18.7305.pt (epoch 9 @ 13259 updates, score 18.73) (writing took 14.10739528387785 seconds)
2023-07-25 01:51:56 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-07-25 01:51:56 | INFO | train | epoch 009 | loss 2.067 | trans_loss 3.489 | nll_loss 1.645 | w2v_ctc_loss 1.064 | task_loss 0 | contrastive_loss 0.19 | total 4138.65 | n_correct 2472.51 | ppl 3.13 | accuracy 59.742 | wps 14596.2 | ups 1.18 | wpb 12355.8 | bsz 458.5 | num_updates 13259 | lr 0.000122817 | gnorm 0.421 | clip 0 | loss_scale 32 | train_wall 1157 | gb_free 12 | wall 10825
2023-07-25 01:51:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 01:51:56 | INFO | fairseq.trainer | begin training epoch 10
2023-07-25 01:51:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 01:52:37 | INFO | train_inner | epoch 010:     41 / 1474 loss=2.053, trans_loss=3.481, nll_loss=1.634, w2v_ctc_loss=1.044, task_loss=0, contrastive_loss=0.203, total=4100.86, n_correct=2468.48, ppl=3.1, accuracy=60.194, wps=9915.7, ups=0.81, wpb=12239.9, bsz=470.2, num_updates=13300, lr=0.000122628, gnorm=0.42, clip=0, loss_scale=32, train_wall=77, gb_free=16.6, wall=10866
2023-07-25 01:53:56 | INFO | train_inner | epoch 010:    141 / 1474 loss=2.008, trans_loss=3.455, nll_loss=1.602, w2v_ctc_loss=1.014, task_loss=0, contrastive_loss=0.128, total=4240.18, n_correct=2578.82, ppl=3.04, accuracy=60.819, wps=16090.8, ups=1.27, wpb=12664, bsz=479.1, num_updates=13400, lr=0.000122169, gnorm=0.412, clip=0, loss_scale=32, train_wall=78, gb_free=15.2, wall=10945
2023-07-25 01:55:15 | INFO | train_inner | epoch 010:    241 / 1474 loss=2.036, trans_loss=3.459, nll_loss=1.604, w2v_ctc_loss=1.028, task_loss=0, contrastive_loss=0.249, total=4126.3, n_correct=2507.11, ppl=3.04, accuracy=60.759, wps=15602.1, ups=1.27, wpb=12312.3, bsz=460.9, num_updates=13500, lr=0.000121716, gnorm=0.418, clip=0, loss_scale=32, train_wall=78, gb_free=15.8, wall=11024
2023-07-25 01:56:34 | INFO | train_inner | epoch 010:    341 / 1474 loss=2.018, trans_loss=3.458, nll_loss=1.608, w2v_ctc_loss=1.023, task_loss=0, contrastive_loss=0.158, total=4132.25, n_correct=2503.67, ppl=3.05, accuracy=60.589, wps=15648.6, ups=1.27, wpb=12352, bsz=452.8, num_updates=13600, lr=0.000121268, gnorm=0.419, clip=0, loss_scale=32, train_wall=78, gb_free=14.9, wall=11103
2023-07-25 01:57:53 | INFO | train_inner | epoch 010:    441 / 1474 loss=2.038, trans_loss=3.463, nll_loss=1.612, w2v_ctc_loss=1.012, task_loss=0, contrastive_loss=0.336, total=4203.14, n_correct=2547.75, ppl=3.06, accuracy=60.615, wps=15851.3, ups=1.26, wpb=12548.6, bsz=481.7, num_updates=13700, lr=0.000120824, gnorm=0.42, clip=0, loss_scale=32, train_wall=79, gb_free=16.5, wall=11182
2023-07-25 01:59:12 | INFO | train_inner | epoch 010:    541 / 1474 loss=2.036, trans_loss=3.477, nll_loss=1.626, w2v_ctc_loss=1.046, task_loss=0, contrastive_loss=0.115, total=4106.5, n_correct=2473.73, ppl=3.09, accuracy=60.239, wps=15532.8, ups=1.27, wpb=12244.6, bsz=440, num_updates=13800, lr=0.000120386, gnorm=0.423, clip=0, loss_scale=32, train_wall=78, gb_free=16.6, wall=11261
2023-07-25 02:00:32 | INFO | train_inner | epoch 010:    641 / 1474 loss=2.048, trans_loss=3.472, nll_loss=1.623, w2v_ctc_loss=1.038, task_loss=0, contrastive_loss=0.234, total=4170.61, n_correct=2522.86, ppl=3.08, accuracy=60.491, wps=15558.5, ups=1.25, wpb=12448.2, bsz=476.1, num_updates=13900, lr=0.000119952, gnorm=0.423, clip=0, loss_scale=32, train_wall=80, gb_free=11.3, wall=11341
2023-07-25 02:01:50 | INFO | train_inner | epoch 010:    741 / 1474 loss=2.037, trans_loss=3.475, nll_loss=1.626, w2v_ctc_loss=1.05, task_loss=0, contrastive_loss=0.113, total=4123.31, n_correct=2486.73, ppl=3.09, accuracy=60.309, wps=15724.2, ups=1.28, wpb=12306.7, bsz=453, num_updates=14000, lr=0.000119523, gnorm=0.424, clip=0, loss_scale=32, train_wall=78, gb_free=17.2, wall=11419
2023-07-25 02:01:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 02:02:13 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.399 | trans_loss 5.649 | nll_loss 2.947 | w2v_ctc_loss 1.354 | task_loss 0 | contrastive_loss 0.276 | total 4003.4 | n_correct 2422.7 | ppl 7.71 | accuracy 60.516 | uer 18.331 | wer 19.943 | raw_wer 19.943 | bleu 19.25 | wps 2145.8 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 19.25
2023-07-25 02:02:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-07-25 02:02:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_10_14000.pt
2023-07-25 02:02:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_10_14000.pt
2023-07-25 02:02:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 19.25) (writing took 41.35104507394135 seconds)
2023-07-25 02:04:14 | INFO | train_inner | epoch 010:    841 / 1474 loss=2.013, trans_loss=3.468, nll_loss=1.619, w2v_ctc_loss=1.021, task_loss=0, contrastive_loss=0.114, total=4125.69, n_correct=2498.59, ppl=3.07, accuracy=60.562, wps=8568.4, ups=0.7, wpb=12321, bsz=456.1, num_updates=14100, lr=0.000119098, gnorm=0.417, clip=0, loss_scale=64, train_wall=78, gb_free=15.9, wall=11563
2023-07-25 02:05:32 | INFO | train_inner | epoch 010:    941 / 1474 loss=2.034, trans_loss=3.472, nll_loss=1.621, w2v_ctc_loss=1.033, task_loss=0, contrastive_loss=0.157, total=4170.41, n_correct=2523.01, ppl=3.08, accuracy=60.498, wps=15800.3, ups=1.27, wpb=12437.5, bsz=470.8, num_updates=14200, lr=0.000118678, gnorm=0.419, clip=0, loss_scale=64, train_wall=78, gb_free=16.3, wall=11641
2023-07-25 02:06:51 | INFO | train_inner | epoch 010:   1041 / 1474 loss=2.029, trans_loss=3.475, nll_loss=1.627, w2v_ctc_loss=1.036, task_loss=0, contrastive_loss=0.128, total=4072.57, n_correct=2452.47, ppl=3.09, accuracy=60.219, wps=15466.6, ups=1.27, wpb=12161.8, bsz=434.8, num_updates=14300, lr=0.000118262, gnorm=0.423, clip=0, loss_scale=64, train_wall=78, gb_free=17.1, wall=11720
2023-07-25 02:08:09 | INFO | train_inner | epoch 010:   1141 / 1474 loss=2.039, trans_loss=3.485, nll_loss=1.64, w2v_ctc_loss=1.053, task_loss=0, contrastive_loss=0.108, total=4041.97, n_correct=2419.97, ppl=3.12, accuracy=59.871, wps=15482, ups=1.28, wpb=12067, bsz=421.9, num_updates=14400, lr=0.000117851, gnorm=0.426, clip=0, loss_scale=64, train_wall=77, gb_free=16.7, wall=11798
2023-07-25 02:09:27 | INFO | train_inner | epoch 010:   1241 / 1474 loss=2.028, trans_loss=3.471, nll_loss=1.627, w2v_ctc_loss=1.045, task_loss=0, contrastive_loss=0.105, total=4103.65, n_correct=2472.34, ppl=3.09, accuracy=60.247, wps=15658.8, ups=1.28, wpb=12271.8, bsz=443.9, num_updates=14500, lr=0.000117444, gnorm=0.422, clip=0, loss_scale=64, train_wall=78, gb_free=15.8, wall=11876
2023-07-25 02:10:47 | INFO | train_inner | epoch 010:   1341 / 1474 loss=2.027, trans_loss=3.477, nll_loss=1.632, w2v_ctc_loss=1.037, task_loss=0, contrastive_loss=0.118, total=4121.93, n_correct=2488.98, ppl=3.1, accuracy=60.384, wps=15460.9, ups=1.26, wpb=12309.4, bsz=451.2, num_updates=14600, lr=0.000117041, gnorm=0.422, clip=0, loss_scale=64, train_wall=79, gb_free=16.9, wall=11956
2023-07-25 02:11:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-25 02:12:07 | INFO | train_inner | epoch 010:   1442 / 1474 loss=2.041, trans_loss=3.481, nll_loss=1.634, w2v_ctc_loss=1.025, task_loss=0, contrastive_loss=0.225, total=4172.44, n_correct=2518.47, ppl=3.1, accuracy=60.36, wps=15575.8, ups=1.25, wpb=12446.1, bsz=470, num_updates=14700, lr=0.000116642, gnorm=0.42, clip=0, loss_scale=32, train_wall=79, gb_free=17.2, wall=12036
2023-07-25 02:12:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 02:12:54 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.399 | trans_loss 5.635 | nll_loss 2.927 | w2v_ctc_loss 1.39 | task_loss 0 | contrastive_loss 0.27 | total 4003.4 | n_correct 2432 | ppl 7.61 | accuracy 60.748 | uer 17.843 | wer 19.582 | raw_wer 19.582 | bleu 19.25 | wps 2414.5 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 19.25
2023-07-25 02:12:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-07-25 02:12:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 02:13:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 02:13:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt (epoch 10 @ 14732 updates, score 19.25) (writing took 21.289142344146967 seconds)
2023-07-25 02:13:16 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-07-25 02:13:16 | INFO | train | epoch 010 | loss 2.031 | trans_loss 3.47 | nll_loss 1.621 | w2v_ctc_loss 1.031 | task_loss 0 | contrastive_loss 0.174 | total 4137.35 | n_correct 2500.63 | ppl 3.08 | accuracy 60.44 | wps 14219 | ups 1.15 | wpb 12351.9 | bsz 457.7 | num_updates 14732 | lr 0.000116516 | gnorm 0.421 | clip 0 | loss_scale 32 | train_wall 1154 | gb_free 17.4 | wall 12104
2023-07-25 02:13:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 02:13:16 | INFO | fairseq.trainer | begin training epoch 11
2023-07-25 02:13:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 02:14:16 | INFO | train_inner | epoch 011:     68 / 1474 loss=2.004, trans_loss=3.445, nll_loss=1.588, w2v_ctc_loss=1.004, task_loss=0, contrastive_loss=0.194, total=4175.24, n_correct=2557.8, ppl=3.01, accuracy=61.261, wps=9650.9, ups=0.77, wpb=12463.5, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.417, clip=0, loss_scale=32, train_wall=77, gb_free=17, wall=12165
2023-07-25 02:15:35 | INFO | train_inner | epoch 011:    168 / 1474 loss=1.992, trans_loss=3.445, nll_loss=1.591, w2v_ctc_loss=1.006, task_loss=0, contrastive_loss=0.111, total=4087.78, n_correct=2500.99, ppl=3.01, accuracy=61.182, wps=15458.5, ups=1.27, wpb=12214.2, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.42, clip=0, loss_scale=32, train_wall=79, gb_free=16.6, wall=12244
2023-07-25 02:16:54 | INFO | train_inner | epoch 011:    268 / 1474 loss=1.983, trans_loss=3.446, nll_loss=1.589, w2v_ctc_loss=0.996, task_loss=0, contrastive_loss=0.107, total=4118.77, n_correct=2524.45, ppl=3.01, accuracy=61.291, wps=15573.2, ups=1.27, wpb=12299.1, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.415, clip=0, loss_scale=32, train_wall=79, gb_free=12.7, wall=12323
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:0')
2023-07-25 02:17:50 | INFO | train_inner | epoch 011:    368 / 1474 loss=2.176, trans_loss=5.122, nll_loss=2.368, w2v_ctc_loss=0.758, task_loss=0, contrastive_loss=0.086, total=4097.83, n_correct=2502.47, ppl=5.16, accuracy=61.068, wps=14799.2, ups=1.8, wpb=8240.8, bsz=298, num_updates=15100, lr=0.000115087, gnorm=0.567, clip=0, loss_scale=32, train_wall=55, gb_free=15.8, wall=12379
2023-07-25 02:18:46 | INFO | train_inner | epoch 011:    468 / 1474 loss=2.194, trans_loss=5.161, nll_loss=2.394, w2v_ctc_loss=0.754, task_loss=0, contrastive_loss=0.204, total=4110.64, n_correct=2500.56, ppl=5.26, accuracy=60.831, wps=14641.7, ups=1.78, wpb=8221.3, bsz=300.4, num_updates=15200, lr=0.000114708, gnorm=0.567, clip=0, loss_scale=32, train_wall=56, gb_free=16.6, wall=12435
2023-07-25 02:19:43 | INFO | train_inner | epoch 011:    568 / 1474 loss=2.194, trans_loss=5.157, nll_loss=2.391, w2v_ctc_loss=0.766, task_loss=0, contrastive_loss=0.203, total=4071.69, n_correct=2473.05, ppl=5.24, accuracy=60.738, wps=14309.2, ups=1.76, wpb=8143.4, bsz=293.7, num_updates=15300, lr=0.000114332, gnorm=0.572, clip=0, loss_scale=32, train_wall=56, gb_free=16.2, wall=12492
2023-07-25 02:20:40 | INFO | train_inner | epoch 011:    668 / 1474 loss=2.201, trans_loss=5.162, nll_loss=2.397, w2v_ctc_loss=0.763, task_loss=0, contrastive_loss=0.255, total=4157.2, n_correct=2522.9, ppl=5.27, accuracy=60.687, wps=14571.1, ups=1.75, wpb=8314.4, bsz=309.6, num_updates=15400, lr=0.000113961, gnorm=0.566, clip=0, loss_scale=32, train_wall=57, gb_free=17, wall=12549
2023-07-25 02:21:36 | INFO | train_inner | epoch 011:    768 / 1474 loss=2.194, trans_loss=5.17, nll_loss=2.408, w2v_ctc_loss=0.774, task_loss=0, contrastive_loss=0.085, total=4174.91, n_correct=2539.1, ppl=5.31, accuracy=60.818, wps=14941.8, ups=1.79, wpb=8349.8, bsz=306.9, num_updates=15500, lr=0.000113592, gnorm=0.568, clip=0, loss_scale=32, train_wall=55, gb_free=17.3, wall=12605
2023-07-25 02:22:32 | INFO | train_inner | epoch 011:    868 / 1474 loss=2.191, trans_loss=5.173, nll_loss=2.411, w2v_ctc_loss=0.769, task_loss=0, contrastive_loss=0.072, total=4118.44, n_correct=2494.21, ppl=5.32, accuracy=60.562, wps=14713.7, ups=1.79, wpb=8236.9, bsz=293.7, num_updates=15600, lr=0.000113228, gnorm=0.569, clip=0, loss_scale=32, train_wall=55, gb_free=11.4, wall=12661
2023-07-25 02:23:29 | INFO | train_inner | epoch 011:    968 / 1474 loss=2.191, trans_loss=5.17, nll_loss=2.408, w2v_ctc_loss=0.773, task_loss=0, contrastive_loss=0.086, total=4140.92, n_correct=2514.66, ppl=5.31, accuracy=60.727, wps=14487.3, ups=1.75, wpb=8281.8, bsz=301.9, num_updates=15700, lr=0.000112867, gnorm=0.568, clip=0, loss_scale=32, train_wall=57, gb_free=15.9, wall=12718
2023-07-25 02:24:25 | INFO | train_inner | epoch 011:   1068 / 1474 loss=2.19, trans_loss=5.165, nll_loss=2.402, w2v_ctc_loss=0.769, task_loss=0, contrastive_loss=0.107, total=4136.99, n_correct=2521.52, ppl=5.29, accuracy=60.951, wps=14660.1, ups=1.77, wpb=8274, bsz=308.8, num_updates=15800, lr=0.000112509, gnorm=0.567, clip=0, loss_scale=32, train_wall=56, gb_free=17.9, wall=12774
2023-07-25 02:25:22 | INFO | train_inner | epoch 011:   1168 / 1474 loss=2.192, trans_loss=5.171, nll_loss=2.41, w2v_ctc_loss=0.771, task_loss=0, contrastive_loss=0.093, total=4185.65, n_correct=2542.5, ppl=5.31, accuracy=60.743, wps=14925.6, ups=1.78, wpb=8371.3, bsz=309.8, num_updates=15900, lr=0.000112154, gnorm=0.563, clip=0, loss_scale=32, train_wall=56, gb_free=14.4, wall=12830
2023-07-25 02:26:18 | INFO | train_inner | epoch 011:   1268 / 1474 loss=2.197, trans_loss=5.167, nll_loss=2.406, w2v_ctc_loss=0.772, task_loss=0, contrastive_loss=0.161, total=4171.89, n_correct=2532.35, ppl=5.3, accuracy=60.7, wps=14772, ups=1.77, wpb=8343.8, bsz=314.1, num_updates=16000, lr=0.000111803, gnorm=0.564, clip=0, loss_scale=32, train_wall=56, gb_free=16.2, wall=12887
2023-07-25 02:26:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:3')
2023-07-25 02:26:40 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.397 | trans_loss 5.63 | nll_loss 2.928 | w2v_ctc_loss 1.397 | task_loss 0 | contrastive_loss 0.273 | total 4003.4 | n_correct 2439.5 | ppl 7.61 | accuracy 60.936 | uer 17.939 | wer 19.861 | raw_wer 19.861 | bleu 19.23 | wps 2375.8 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.25
2023-07-25 02:26:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-07-25 02:26:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_11_16000.pt
2023-07-25 02:26:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_11_16000.pt
2023-07-25 02:27:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 19.23) (writing took 27.614847790449858 seconds)
2023-07-25 02:28:06 | INFO | train_inner | epoch 011:   1368 / 1474 loss=2.207, trans_loss=5.168, nll_loss=2.409, w2v_ctc_loss=0.762, task_loss=0, contrastive_loss=0.324, total=4190.34, n_correct=2544.93, ppl=5.31, accuracy=60.733, wps=7745.6, ups=0.92, wpb=8380.7, bsz=327.9, num_updates=16100, lr=0.000111456, gnorm=0.566, clip=0, loss_scale=32, train_wall=57, gb_free=17.3, wall=12995
2023-07-25 02:29:02 | INFO | train_inner | epoch 011:   1468 / 1474 loss=2.19, trans_loss=5.171, nll_loss=2.412, w2v_ctc_loss=0.766, task_loss=0, contrastive_loss=0.096, total=4158.39, n_correct=2526.13, ppl=5.32, accuracy=60.748, wps=14813.1, ups=1.78, wpb=8316.8, bsz=312, num_updates=16200, lr=0.000111111, gnorm=0.562, clip=0, loss_scale=32, train_wall=56, gb_free=17.1, wall=13051
2023-07-25 02:29:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 02:29:28 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.376 | trans_loss 5.628 | nll_loss 2.926 | w2v_ctc_loss 1.329 | task_loss 0 | contrastive_loss 0.274 | total 4003.4 | n_correct 2432.9 | ppl 7.6 | accuracy 60.771 | uer 17.981 | wer 19.835 | raw_wer 19.835 | bleu 19.52 | wps 2356.4 | wpb 4003.4 | bsz 141.8 | num_updates 16206 | best_bleu 19.52
2023-07-25 02:29:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16206 updates
2023-07-25 02:29:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 02:29:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 02:29:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt (epoch 11 @ 16206 updates, score 19.52) (writing took 20.17777631059289 seconds)
2023-07-25 02:29:49 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-07-25 02:29:49 | INFO | train | epoch 011 | loss 2.142 | trans_loss 4.735 | nll_loss 2.199 | w2v_ctc_loss 0.825 | task_loss 0 | contrastive_loss 0.139 | total 4138.65 | n_correct 2519.23 | ppl 4.59 | accuracy 60.871 | wps 13389.6 | ups 1.48 | wpb 9021 | bsz 333.4 | num_updates 16206 | lr 0.000111091 | gnorm 0.54 | clip 0 | loss_scale 32 | train_wall 884 | gb_free 17.5 | wall 13097
2023-07-25 02:29:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 02:29:49 | INFO | fairseq.trainer | begin training epoch 12
2023-07-25 02:29:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 02:30:50 | INFO | train_inner | epoch 012:     94 / 1474 loss=2.163, trans_loss=5.111, nll_loss=2.332, w2v_ctc_loss=0.747, task_loss=0, contrastive_loss=0.129, total=4146.82, n_correct=2563.78, ppl=5.03, accuracy=61.825, wps=7724.5, ups=0.93, wpb=8293.6, bsz=313.9, num_updates=16300, lr=0.00011077, gnorm=0.56, clip=0, loss_scale=32, train_wall=55, gb_free=16, wall=13159
2023-07-25 02:31:46 | INFO | train_inner | epoch 012:    194 / 1474 loss=2.167, trans_loss=5.122, nll_loss=2.344, w2v_ctc_loss=0.757, task_loss=0, contrastive_loss=0.078, total=4120.68, n_correct=2536.33, ppl=5.08, accuracy=61.551, wps=14614.3, ups=1.77, wpb=8241.4, bsz=294.7, num_updates=16400, lr=0.000110432, gnorm=0.57, clip=0, loss_scale=32, train_wall=56, gb_free=15.9, wall=13215
2023-07-25 02:32:43 | INFO | train_inner | epoch 012:    294 / 1474 loss=2.165, trans_loss=5.121, nll_loss=2.346, w2v_ctc_loss=0.745, task_loss=0, contrastive_loss=0.11, total=4199.46, n_correct=2586.92, ppl=5.08, accuracy=61.601, wps=14830.3, ups=1.77, wpb=8398.9, bsz=320.3, num_updates=16500, lr=0.000110096, gnorm=0.563, clip=0, loss_scale=32, train_wall=56, gb_free=16.8, wall=13272
2023-07-25 02:33:39 | INFO | train_inner | epoch 012:    394 / 1474 loss=2.17, trans_loss=5.131, nll_loss=2.357, w2v_ctc_loss=0.754, task_loss=0, contrastive_loss=0.094, total=4151.14, n_correct=2551.71, ppl=5.12, accuracy=61.47, wps=14879.8, ups=1.79, wpb=8302.3, bsz=307.8, num_updates=16600, lr=0.000109764, gnorm=0.565, clip=0, loss_scale=32, train_wall=55, gb_free=17.4, wall=13327
2023-07-25 02:34:34 | INFO | train_inner | epoch 012:    494 / 1474 loss=2.18, trans_loss=5.146, nll_loss=2.377, w2v_ctc_loss=0.763, task_loss=0, contrastive_loss=0.101, total=4110.49, n_correct=2518.45, ppl=5.2, accuracy=61.269, wps=14724.2, ups=1.79, wpb=8221, bsz=302.2, num_updates=16700, lr=0.000109435, gnorm=0.565, clip=0, loss_scale=64, train_wall=55, gb_free=14.3, wall=13383
2023-07-25 02:35:32 | INFO | train_inner | epoch 012:    594 / 1474 loss=2.176, trans_loss=5.134, nll_loss=2.363, w2v_ctc_loss=0.754, task_loss=0, contrastive_loss=0.166, total=4189.92, n_correct=2575.56, ppl=5.14, accuracy=61.47, wps=14667, ups=1.75, wpb=8379.8, bsz=315.1, num_updates=16800, lr=0.000109109, gnorm=0.567, clip=0, loss_scale=64, train_wall=57, gb_free=15.2, wall=13440
2023-07-25 02:36:27 | INFO | train_inner | epoch 012:    694 / 1474 loss=2.174, trans_loss=5.132, nll_loss=2.361, w2v_ctc_loss=0.737, task_loss=0, contrastive_loss=0.254, total=4206.3, n_correct=2591.13, ppl=5.14, accuracy=61.601, wps=15033.4, ups=1.79, wpb=8412.6, bsz=325.7, num_updates=16900, lr=0.000108786, gnorm=0.56, clip=0, loss_scale=64, train_wall=55, gb_free=16.5, wall=13496
2023-07-25 02:37:23 | INFO | train_inner | epoch 012:    794 / 1474 loss=2.17, trans_loss=5.133, nll_loss=2.361, w2v_ctc_loss=0.758, task_loss=0, contrastive_loss=0.089, total=4085.96, n_correct=2510.98, ppl=5.14, accuracy=61.454, wps=14676.9, ups=1.8, wpb=8171.9, bsz=297.1, num_updates=17000, lr=0.000108465, gnorm=0.576, clip=0, loss_scale=64, train_wall=55, gb_free=16.3, wall=13552
2023-07-25 02:38:20 | INFO | train_inner | epoch 012:    894 / 1474 loss=2.178, trans_loss=5.141, nll_loss=2.371, w2v_ctc_loss=0.753, task_loss=0, contrastive_loss=0.145, total=4169.74, n_correct=2557.61, ppl=5.17, accuracy=61.337, wps=14782.6, ups=1.77, wpb=8339.5, bsz=306.4, num_updates=17100, lr=0.000108148, gnorm=0.569, clip=0, loss_scale=64, train_wall=56, gb_free=16.3, wall=13608
2023-07-25 02:39:17 | INFO | train_inner | epoch 012:    994 / 1474 loss=2.183, trans_loss=5.151, nll_loss=2.385, w2v_ctc_loss=0.762, task_loss=0, contrastive_loss=0.151, total=4117.67, n_correct=2516.84, ppl=5.22, accuracy=61.123, wps=14426.8, ups=1.75, wpb=8235.3, bsz=301.4, num_updates=17200, lr=0.000107833, gnorm=0.569, clip=0, loss_scale=64, train_wall=57, gb_free=17.9, wall=13666
2023-07-25 02:40:13 | INFO | train_inner | epoch 012:   1094 / 1474 loss=2.189, trans_loss=5.155, nll_loss=2.391, w2v_ctc_loss=0.763, task_loss=0, contrastive_loss=0.193, total=4047.61, n_correct=2471.51, ppl=5.24, accuracy=61.061, wps=14501.1, ups=1.79, wpb=8095.2, bsz=290.4, num_updates=17300, lr=0.000107521, gnorm=0.584, clip=0, loss_scale=64, train_wall=55, gb_free=16.8, wall=13721
2023-07-25 02:41:08 | INFO | train_inner | epoch 012:   1194 / 1474 loss=2.192, trans_loss=5.162, nll_loss=2.4, w2v_ctc_loss=0.771, task_loss=0, contrastive_loss=0.15, total=4184.55, n_correct=2549.32, ppl=5.28, accuracy=60.922, wps=14965.9, ups=1.79, wpb=8369.1, bsz=314.3, num_updates=17400, lr=0.000107211, gnorm=0.566, clip=0, loss_scale=64, train_wall=55, gb_free=16.9, wall=13777
2023-07-25 02:42:05 | INFO | train_inner | epoch 012:   1294 / 1474 loss=2.185, trans_loss=5.154, nll_loss=2.388, w2v_ctc_loss=0.777, task_loss=0, contrastive_loss=0.095, total=4086.33, n_correct=2494.42, ppl=5.24, accuracy=61.043, wps=14555.8, ups=1.78, wpb=8172.7, bsz=291.4, num_updates=17500, lr=0.000106904, gnorm=0.577, clip=0, loss_scale=64, train_wall=56, gb_free=16.9, wall=13833
2023-07-25 02:43:02 | INFO | train_inner | epoch 012:   1394 / 1474 loss=2.181, trans_loss=5.155, nll_loss=2.391, w2v_ctc_loss=0.75, task_loss=0, contrastive_loss=0.18, total=4134.89, n_correct=2528.7, ppl=5.25, accuracy=61.155, wps=14459.1, ups=1.75, wpb=8269.8, bsz=304.4, num_updates=17600, lr=0.0001066, gnorm=0.569, clip=0, loss_scale=64, train_wall=57, gb_free=17.5, wall=13891
2023-07-25 02:43:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 02:44:08 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.393 | trans_loss 5.617 | nll_loss 2.907 | w2v_ctc_loss 1.411 | task_loss 0 | contrastive_loss 0.276 | total 4003.4 | n_correct 2449.2 | ppl 7.5 | accuracy 61.178 | uer 18.116 | wer 19.869 | raw_wer 19.869 | bleu 19.22 | wps 2378.3 | wpb 4003.4 | bsz 141.8 | num_updates 17680 | best_bleu 19.52
2023-07-25 02:44:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17680 updates
2023-07-25 02:44:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_19.2200.pt
2023-07-25 02:44:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_19.2200.pt
2023-07-25 02:44:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_19.2200.pt (epoch 12 @ 17680 updates, score 19.22) (writing took 14.639659084379673 seconds)
2023-07-25 02:44:23 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-07-25 02:44:23 | INFO | train | epoch 012 | loss 2.177 | trans_loss 5.14 | nll_loss 2.37 | w2v_ctc_loss 0.757 | task_loss 0 | contrastive_loss 0.136 | total 4138.65 | n_correct 2538.96 | ppl 5.17 | accuracy 61.348 | wps 13956.3 | ups 1.69 | wpb 8277.3 | bsz 305.7 | num_updates 17680 | lr 0.000106359 | gnorm 0.569 | clip 0 | loss_scale 64 | train_wall 822 | gb_free 13.3 | wall 13972
2023-07-25 02:44:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 02:44:23 | INFO | fairseq.trainer | begin training epoch 13
2023-07-25 02:44:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 02:44:43 | INFO | train_inner | epoch 013:     20 / 1474 loss=2.179, trans_loss=5.153, nll_loss=2.388, w2v_ctc_loss=0.765, task_loss=0, contrastive_loss=0.087, total=4104.86, n_correct=2515, ppl=5.23, accuracy=61.269, wps=8088.3, ups=0.99, wpb=8209.7, bsz=296.8, num_updates=17700, lr=0.000106299, gnorm=0.575, clip=0, loss_scale=64, train_wall=55, gb_free=15, wall=13992
2023-07-25 02:45:40 | INFO | train_inner | epoch 013:    120 / 1474 loss=2.153, trans_loss=5.103, nll_loss=2.321, w2v_ctc_loss=0.741, task_loss=0, contrastive_loss=0.098, total=4161.2, n_correct=2584.98, ppl=5, accuracy=62.121, wps=14806, ups=1.78, wpb=8322.4, bsz=302.9, num_updates=17800, lr=0.000106, gnorm=0.564, clip=0, loss_scale=64, train_wall=56, gb_free=16.5, wall=14048
2023-07-25 02:46:36 | INFO | train_inner | epoch 013:    220 / 1474 loss=2.173, trans_loss=5.114, nll_loss=2.338, w2v_ctc_loss=0.739, task_loss=0, contrastive_loss=0.315, total=4202.62, n_correct=2596.9, ppl=5.06, accuracy=61.792, wps=14813, ups=1.76, wpb=8405.2, bsz=328.3, num_updates=17900, lr=0.000105703, gnorm=0.567, clip=0, loss_scale=64, train_wall=56, gb_free=17.5, wall=14105
2023-07-25 02:47:32 | INFO | train_inner | epoch 013:    320 / 1474 loss=2.149, trans_loss=5.103, nll_loss=2.32, w2v_ctc_loss=0.736, task_loss=0, contrastive_loss=0.081, total=4112.8, n_correct=2555.67, ppl=4.99, accuracy=62.139, wps=14717.6, ups=1.79, wpb=8225.6, bsz=296, num_updates=18000, lr=0.000105409, gnorm=0.568, clip=0, loss_scale=64, train_wall=55, gb_free=18.1, wall=14161
2023-07-25 02:47:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 02:47:54 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.399 | trans_loss 5.622 | nll_loss 2.91 | w2v_ctc_loss 1.414 | task_loss 0 | contrastive_loss 0.284 | total 4003.4 | n_correct 2439.2 | ppl 7.51 | accuracy 60.928 | uer 18.1 | wer 19.917 | raw_wer 19.917 | bleu 19.56 | wps 2427.3 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.56
2023-07-25 02:47:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-07-25 02:47:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_13_18000.pt
2023-07-25 02:47:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_13_18000.pt
2023-07-25 02:48:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.56) (writing took 37.10537735186517 seconds)
2023-07-25 02:49:27 | INFO | train_inner | epoch 013:    420 / 1474 loss=2.158, trans_loss=5.11, nll_loss=2.331, w2v_ctc_loss=0.746, task_loss=0, contrastive_loss=0.132, total=4176.06, n_correct=2594.07, ppl=5.03, accuracy=62.118, wps=7250.3, ups=0.87, wpb=8352.1, bsz=317.5, num_updates=18100, lr=0.000105118, gnorm=0.563, clip=0, loss_scale=64, train_wall=55, gb_free=16.8, wall=14276
2023-07-25 02:50:23 | INFO | train_inner | epoch 013:    520 / 1474 loss=2.166, trans_loss=5.12, nll_loss=2.345, w2v_ctc_loss=0.746, task_loss=0, contrastive_loss=0.168, total=4197.57, n_correct=2587.94, ppl=5.08, accuracy=61.653, wps=14991.1, ups=1.79, wpb=8395.1, bsz=318.1, num_updates=18200, lr=0.000104828, gnorm=0.57, clip=0, loss_scale=64, train_wall=56, gb_free=15.6, wall=14332
2023-07-25 02:51:20 | INFO | train_inner | epoch 013:    620 / 1474 loss=2.153, trans_loss=5.115, nll_loss=2.338, w2v_ctc_loss=0.742, task_loss=0, contrastive_loss=0.078, total=4160.12, n_correct=2577.69, ppl=5.06, accuracy=61.962, wps=14658, ups=1.76, wpb=8320.2, bsz=308.7, num_updates=18300, lr=0.000104542, gnorm=0.563, clip=0, loss_scale=64, train_wall=56, gb_free=16.6, wall=14389
2023-07-25 02:52:16 | INFO | train_inner | epoch 013:    720 / 1474 loss=2.168, trans_loss=5.126, nll_loss=2.352, w2v_ctc_loss=0.766, task_loss=0, contrastive_loss=0.076, total=4101.54, n_correct=2525.61, ppl=5.1, accuracy=61.577, wps=14701.3, ups=1.79, wpb=8203.1, bsz=285.7, num_updates=18400, lr=0.000104257, gnorm=0.571, clip=0, loss_scale=64, train_wall=55, gb_free=15.9, wall=14445
2023-07-25 02:53:12 | INFO | train_inner | epoch 013:    820 / 1474 loss=2.167, trans_loss=5.125, nll_loss=2.352, w2v_ctc_loss=0.749, task_loss=0, contrastive_loss=0.128, total=4126.37, n_correct=2544.04, ppl=5.1, accuracy=61.653, wps=14640.2, ups=1.77, wpb=8252.7, bsz=307, num_updates=18500, lr=0.000103975, gnorm=0.578, clip=0, loss_scale=64, train_wall=56, gb_free=18, wall=14501
2023-07-25 02:54:09 | INFO | train_inner | epoch 013:    920 / 1474 loss=2.164, trans_loss=5.13, nll_loss=2.357, w2v_ctc_loss=0.751, task_loss=0, contrastive_loss=0.089, total=4102.78, n_correct=2531.36, ppl=5.12, accuracy=61.699, wps=14596.8, ups=1.78, wpb=8205.6, bsz=295.9, num_updates=18600, lr=0.000103695, gnorm=0.582, clip=0, loss_scale=64, train_wall=56, gb_free=16.8, wall=14557
2023-07-25 02:55:05 | INFO | train_inner | epoch 013:   1020 / 1474 loss=2.172, trans_loss=5.132, nll_loss=2.361, w2v_ctc_loss=0.757, task_loss=0, contrastive_loss=0.139, total=4071.32, n_correct=2502.41, ppl=5.14, accuracy=61.464, wps=14382.4, ups=1.77, wpb=8142.6, bsz=291.3, num_updates=18700, lr=0.000103418, gnorm=0.577, clip=0, loss_scale=64, train_wall=56, gb_free=12, wall=14614
2023-07-25 02:56:01 | INFO | train_inner | epoch 013:   1120 / 1474 loss=2.162, trans_loss=5.122, nll_loss=2.348, w2v_ctc_loss=0.746, task_loss=0, contrastive_loss=0.12, total=4115.28, n_correct=2543.88, ppl=5.09, accuracy=61.815, wps=14857.1, ups=1.81, wpb=8230.6, bsz=307.5, num_updates=18800, lr=0.000103142, gnorm=0.569, clip=0, loss_scale=128, train_wall=55, gb_free=12.8, wall=14669
2023-07-25 02:56:56 | INFO | train_inner | epoch 013:   1220 / 1474 loss=2.167, trans_loss=5.134, nll_loss=2.364, w2v_ctc_loss=0.757, task_loss=0, contrastive_loss=0.08, total=4105.36, n_correct=2528.36, ppl=5.15, accuracy=61.587, wps=14729, ups=1.79, wpb=8210.7, bsz=295.3, num_updates=18900, lr=0.000102869, gnorm=0.571, clip=0, loss_scale=128, train_wall=55, gb_free=16.6, wall=14725
2023-07-25 02:57:53 | INFO | train_inner | epoch 013:   1320 / 1474 loss=2.165, trans_loss=5.122, nll_loss=2.349, w2v_ctc_loss=0.747, task_loss=0, contrastive_loss=0.176, total=4114, n_correct=2548.28, ppl=5.09, accuracy=61.942, wps=14525.5, ups=1.77, wpb=8228, bsz=307.7, num_updates=19000, lr=0.000102598, gnorm=0.578, clip=0, loss_scale=128, train_wall=56, gb_free=18, wall=14782
2023-07-25 02:58:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-25 02:58:50 | INFO | train_inner | epoch 013:   1421 / 1474 loss=2.162, trans_loss=5.133, nll_loss=2.363, w2v_ctc_loss=0.747, task_loss=0, contrastive_loss=0.074, total=4159.04, n_correct=2565.07, ppl=5.14, accuracy=61.675, wps=14630.4, ups=1.76, wpb=8318.1, bsz=304.3, num_updates=19100, lr=0.000102329, gnorm=0.567, clip=0, loss_scale=64, train_wall=56, gb_free=15.7, wall=14839
2023-07-25 02:59:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 02:59:41 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.377 | trans_loss 5.614 | nll_loss 2.905 | w2v_ctc_loss 1.37 | task_loss 0 | contrastive_loss 0.27 | total 4003.4 | n_correct 2448.6 | ppl 7.49 | accuracy 61.163 | uer 17.803 | wer 19.526 | raw_wer 19.526 | bleu 19.21 | wps 2394 | wpb 4003.4 | bsz 141.8 | num_updates 19153 | best_bleu 19.56
2023-07-25 02:59:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19153 updates
2023-07-25 02:59:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_19.2107.pt
2023-07-25 02:59:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_19.2107.pt
2023-07-25 02:59:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_19.2107.pt (epoch 13 @ 19153 updates, score 19.21) (writing took 11.720203272998333 seconds)
2023-07-25 02:59:53 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-07-25 02:59:53 | INFO | train | epoch 013 | loss 2.163 | trans_loss 5.12 | nll_loss 2.345 | w2v_ctc_loss 0.748 | task_loss 0 | contrastive_loss 0.126 | total 4137.23 | n_correct 2557.07 | ppl 5.08 | accuracy 61.806 | wps 13098.3 | ups 1.58 | wpb 8274.5 | bsz 305.1 | num_updates 19153 | lr 0.000102187 | gnorm 0.571 | clip 0 | loss_scale 64 | train_wall 820 | gb_free 17.9 | wall 14902
2023-07-25 02:59:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 02:59:54 | INFO | fairseq.trainer | begin training epoch 14
2023-07-25 02:59:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 03:00:28 | INFO | train_inner | epoch 014:     47 / 1474 loss=2.143, trans_loss=5.09, nll_loss=2.309, w2v_ctc_loss=0.736, task_loss=0, contrastive_loss=0.096, total=4176.2, n_correct=2610.96, ppl=4.96, accuracy=62.52, wps=8502.8, ups=1.02, wpb=8352.4, bsz=322.3, num_updates=19200, lr=0.000102062, gnorm=0.57, clip=0, loss_scale=64, train_wall=55, gb_free=11.3, wall=14937
2023-07-25 03:01:24 | INFO | train_inner | epoch 014:    147 / 1474 loss=2.137, trans_loss=5.077, nll_loss=2.289, w2v_ctc_loss=0.736, task_loss=0, contrastive_loss=0.075, total=4080.86, n_correct=2559.57, ppl=4.89, accuracy=62.721, wps=14594.6, ups=1.79, wpb=8161.7, bsz=299.6, num_updates=19300, lr=0.000101797, gnorm=0.564, clip=0, loss_scale=64, train_wall=55, gb_free=17.3, wall=14993
2023-07-25 03:02:21 | INFO | train_inner | epoch 014:    247 / 1474 loss=2.151, trans_loss=5.097, nll_loss=2.314, w2v_ctc_loss=0.737, task_loss=0, contrastive_loss=0.175, total=4106.97, n_correct=2557.18, ppl=4.97, accuracy=62.264, wps=14452.4, ups=1.76, wpb=8213.9, bsz=293.3, num_updates=19400, lr=0.000101535, gnorm=0.57, clip=0, loss_scale=64, train_wall=56, gb_free=12.9, wall=15050
2023-07-25 03:03:17 | INFO | train_inner | epoch 014:    347 / 1474 loss=2.142, trans_loss=5.086, nll_loss=2.302, w2v_ctc_loss=0.733, task_loss=0, contrastive_loss=0.115, total=4179.8, n_correct=2617.15, ppl=4.93, accuracy=62.614, wps=14904, ups=1.78, wpb=8359.6, bsz=322.5, num_updates=19500, lr=0.000101274, gnorm=0.568, clip=0, loss_scale=64, train_wall=56, gb_free=17.6, wall=15106
2023-07-25 03:04:13 | INFO | train_inner | epoch 014:    447 / 1474 loss=2.144, trans_loss=5.103, nll_loss=2.323, w2v_ctc_loss=0.732, task_loss=0, contrastive_loss=0.071, total=4120.38, n_correct=2557.86, ppl=5, accuracy=62.078, wps=14703.7, ups=1.78, wpb=8240.8, bsz=296.3, num_updates=19600, lr=0.000101015, gnorm=0.57, clip=0, loss_scale=64, train_wall=56, gb_free=17.4, wall=15162
2023-07-25 03:05:10 | INFO | train_inner | epoch 014:    547 / 1474 loss=2.159, trans_loss=5.107, nll_loss=2.327, w2v_ctc_loss=0.755, task_loss=0, contrastive_loss=0.108, total=4089.86, n_correct=2537.38, ppl=5.02, accuracy=62.041, wps=14257.7, ups=1.74, wpb=8179.7, bsz=295.5, num_updates=19700, lr=0.000100759, gnorm=0.578, clip=0, loss_scale=64, train_wall=57, gb_free=12.6, wall=15219
2023-07-25 03:06:07 | INFO | train_inner | epoch 014:    647 / 1474 loss=2.152, trans_loss=5.102, nll_loss=2.322, w2v_ctc_loss=0.738, task_loss=0, contrastive_loss=0.15, total=4158.94, n_correct=2587.04, ppl=5, accuracy=62.204, wps=14608.3, ups=1.76, wpb=8317.9, bsz=306.7, num_updates=19800, lr=0.000100504, gnorm=0.568, clip=0, loss_scale=64, train_wall=56, gb_free=16.3, wall=15276
2023-07-25 03:07:03 | INFO | train_inner | epoch 014:    747 / 1474 loss=2.14, trans_loss=5.091, nll_loss=2.308, w2v_ctc_loss=0.732, task_loss=0, contrastive_loss=0.083, total=4150.03, n_correct=2591.21, ppl=4.95, accuracy=62.438, wps=14869.8, ups=1.79, wpb=8300.1, bsz=310.4, num_updates=19900, lr=0.000100251, gnorm=0.564, clip=0, loss_scale=64, train_wall=55, gb_free=15.9, wall=15332
2023-07-25 03:07:59 | INFO | train_inner | epoch 014:    847 / 1474 loss=2.155, trans_loss=5.097, nll_loss=2.317, w2v_ctc_loss=0.736, task_loss=0, contrastive_loss=0.197, total=4162.8, n_correct=2591.25, ppl=4.98, accuracy=62.248, wps=14831, ups=1.78, wpb=8325.6, bsz=317.2, num_updates=20000, lr=0.0001, gnorm=0.569, clip=0, loss_scale=64, train_wall=56, gb_free=17.4, wall=15388
2023-07-25 03:07:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 03:08:22 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.377 | trans_loss 5.612 | nll_loss 2.9 | w2v_ctc_loss 1.373 | task_loss 0 | contrastive_loss 0.269 | total 4003.4 | n_correct 2450.2 | ppl 7.46 | accuracy 61.203 | uer 17.885 | wer 19.843 | raw_wer 19.843 | bleu 19.7 | wps 2259 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.7
2023-07-25 03:08:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-07-25 03:08:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_14_20000.pt
2023-07-25 03:08:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_14_20000.pt
2023-07-25 03:08:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.7) (writing took 35.051541863009334 seconds)
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:0')
2023-07-25 03:09:55 | INFO | train_inner | epoch 014:    947 / 1474 loss=2.149, trans_loss=5.106, nll_loss=2.328, w2v_ctc_loss=0.74, task_loss=0, contrastive_loss=0.085, total=4159.46, n_correct=2581.47, ppl=5.02, accuracy=62.063, wps=7172.4, ups=0.86, wpb=8318.9, bsz=306.7, num_updates=20100, lr=9.97509e-05, gnorm=0.576, clip=0, loss_scale=64, train_wall=57, gb_free=15.6, wall=15504
2023-07-25 03:10:52 | INFO | train_inner | epoch 014:   1047 / 1474 loss=2.153, trans_loss=5.111, nll_loss=2.335, w2v_ctc_loss=0.73, task_loss=0, contrastive_loss=0.15, total=4155.93, n_correct=2580.7, ppl=5.04, accuracy=62.097, wps=14677.3, ups=1.77, wpb=8311.9, bsz=305.9, num_updates=20200, lr=9.95037e-05, gnorm=0.571, clip=0, loss_scale=64, train_wall=56, gb_free=16.6, wall=15561
2023-07-25 03:11:49 | INFO | train_inner | epoch 014:   1147 / 1474 loss=2.176, trans_loss=5.11, nll_loss=2.334, w2v_ctc_loss=0.746, task_loss=0, contrastive_loss=0.378, total=4228.09, n_correct=2620.44, ppl=5.04, accuracy=61.977, wps=14927.2, ups=1.77, wpb=8456.2, bsz=326.3, num_updates=20300, lr=9.92583e-05, gnorm=0.565, clip=0, loss_scale=64, train_wall=56, gb_free=17.9, wall=15617
2023-07-25 03:12:44 | INFO | train_inner | epoch 014:   1247 / 1474 loss=2.161, trans_loss=5.129, nll_loss=2.357, w2v_ctc_loss=0.756, task_loss=0, contrastive_loss=0.065, total=4027.71, n_correct=2486.68, ppl=5.12, accuracy=61.739, wps=14541.1, ups=1.81, wpb=8055.4, bsz=273.6, num_updates=20400, lr=9.90148e-05, gnorm=0.587, clip=0, loss_scale=64, train_wall=55, gb_free=16.8, wall=15673
2023-07-25 03:13:41 | INFO | train_inner | epoch 014:   1347 / 1474 loss=2.149, trans_loss=5.113, nll_loss=2.339, w2v_ctc_loss=0.735, task_loss=0, contrastive_loss=0.084, total=4198.71, n_correct=2609.59, ppl=5.06, accuracy=62.152, wps=14742.2, ups=1.76, wpb=8397.4, bsz=315.4, num_updates=20500, lr=9.8773e-05, gnorm=0.567, clip=0, loss_scale=64, train_wall=57, gb_free=16.6, wall=15730
2023-07-25 03:14:37 | INFO | train_inner | epoch 014:   1447 / 1474 loss=2.158, trans_loss=5.123, nll_loss=2.351, w2v_ctc_loss=0.738, task_loss=0, contrastive_loss=0.123, total=4140.5, n_correct=2565.19, ppl=5.1, accuracy=61.954, wps=14815.5, ups=1.79, wpb=8281, bsz=307.1, num_updates=20600, lr=9.85329e-05, gnorm=0.576, clip=0, loss_scale=64, train_wall=55, gb_free=17.9, wall=15786
2023-07-25 03:14:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:6')
2023-07-25 03:15:14 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.386 | trans_loss 5.609 | nll_loss 2.899 | w2v_ctc_loss 1.404 | task_loss 0 | contrastive_loss 0.276 | total 4003.4 | n_correct 2460.9 | ppl 7.46 | accuracy 61.47 | uer 17.986 | wer 19.895 | raw_wer 19.895 | bleu 19.44 | wps 2377.8 | wpb 4003.4 | bsz 141.8 | num_updates 20627 | best_bleu 19.7
2023-07-25 03:15:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20627 updates
2023-07-25 03:15:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_19.4406.pt
2023-07-25 03:15:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_19.4406.pt
2023-07-25 03:15:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_19.4406.pt (epoch 14 @ 20627 updates, score 19.44) (writing took 11.739764047786593 seconds)
2023-07-25 03:15:26 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-07-25 03:15:26 | INFO | train | epoch 014 | loss 2.152 | trans_loss 5.103 | nll_loss 2.324 | w2v_ctc_loss 0.739 | task_loss 0 | contrastive_loss 0.132 | total 4138.65 | n_correct 2574.15 | ppl 5.01 | accuracy 62.198 | wps 13081.8 | ups 1.58 | wpb 8277.3 | bsz 305.7 | num_updates 20627 | lr 9.84684e-05 | gnorm 0.571 | clip 0 | loss_scale 64 | train_wall 825 | gb_free 16.6 | wall 15835
2023-07-25 03:15:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 03:15:26 | INFO | fairseq.trainer | begin training epoch 15
2023-07-25 03:15:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 03:16:15 | INFO | train_inner | epoch 015:     73 / 1474 loss=2.145, trans_loss=5.09, nll_loss=2.307, w2v_ctc_loss=0.731, task_loss=0, contrastive_loss=0.169, total=4083.93, n_correct=2551.56, ppl=4.95, accuracy=62.478, wps=8273.1, ups=1.01, wpb=8167.9, bsz=300.1, num_updates=20700, lr=9.82946e-05, gnorm=0.576, clip=0, loss_scale=64, train_wall=55, gb_free=15.9, wall=15884
2023-07-25 03:17:12 | INFO | train_inner | epoch 015:    173 / 1474 loss=2.137, trans_loss=5.08, nll_loss=2.293, w2v_ctc_loss=0.738, task_loss=0, contrastive_loss=0.081, total=4122.67, n_correct=2585.65, ppl=4.9, accuracy=62.718, wps=14597.6, ups=1.77, wpb=8245.3, bsz=299.1, num_updates=20800, lr=9.80581e-05, gnorm=0.572, clip=0, loss_scale=64, train_wall=56, gb_free=17.5, wall=15941
2023-07-25 03:18:08 | INFO | train_inner | epoch 015:    273 / 1474 loss=2.129, trans_loss=5.078, nll_loss=2.291, w2v_ctc_loss=0.722, task_loss=0, contrastive_loss=0.07, total=4190.11, n_correct=2633.67, ppl=4.9, accuracy=62.854, wps=14885.8, ups=1.78, wpb=8380.2, bsz=312.6, num_updates=20900, lr=9.78232e-05, gnorm=0.567, clip=0, loss_scale=64, train_wall=56, gb_free=17.4, wall=15997
2023-07-25 03:19:04 | INFO | train_inner | epoch 015:    373 / 1474 loss=2.133, trans_loss=5.075, nll_loss=2.286, w2v_ctc_loss=0.728, task_loss=0, contrastive_loss=0.095, total=4150.33, n_correct=2601.16, ppl=4.88, accuracy=62.674, wps=14871.3, ups=1.79, wpb=8300.7, bsz=301, num_updates=21000, lr=9.759e-05, gnorm=0.571, clip=0, loss_scale=64, train_wall=55, gb_free=15.8, wall=16053
2023-07-25 03:20:00 | INFO | train_inner | epoch 015:    473 / 1474 loss=2.138, trans_loss=5.081, nll_loss=2.295, w2v_ctc_loss=0.715, task_loss=0, contrastive_loss=0.187, total=4082.7, n_correct=2554.13, ppl=4.91, accuracy=62.56, wps=14550.9, ups=1.78, wpb=8165.4, bsz=298.5, num_updates=21100, lr=9.73585e-05, gnorm=0.576, clip=0, loss_scale=64, train_wall=56, gb_free=17.4, wall=16109
2023-07-25 03:20:57 | INFO | train_inner | epoch 015:    573 / 1474 loss=2.134, trans_loss=5.082, nll_loss=2.297, w2v_ctc_loss=0.731, task_loss=0, contrastive_loss=0.075, total=4130.96, n_correct=2587.39, ppl=4.91, accuracy=62.634, wps=14663.1, ups=1.77, wpb=8261.9, bsz=293.4, num_updates=21200, lr=9.71286e-05, gnorm=0.569, clip=0, loss_scale=128, train_wall=56, gb_free=17.5, wall=16165
2023-07-25 03:21:53 | INFO | train_inner | epoch 015:    673 / 1474 loss=2.143, trans_loss=5.084, nll_loss=2.299, w2v_ctc_loss=0.733, task_loss=0, contrastive_loss=0.151, total=4138.41, n_correct=2590.86, ppl=4.92, accuracy=62.605, wps=14584.2, ups=1.76, wpb=8276.8, bsz=309.4, num_updates=21300, lr=9.69003e-05, gnorm=0.577, clip=0, loss_scale=128, train_wall=56, gb_free=17.1, wall=16222
2023-07-25 03:22:49 | INFO | train_inner | epoch 015:    773 / 1474 loss=2.14, trans_loss=5.091, nll_loss=2.309, w2v_ctc_loss=0.733, task_loss=0, contrastive_loss=0.097, total=4186.48, n_correct=2615.2, ppl=4.96, accuracy=62.468, wps=15059.2, ups=1.8, wpb=8373, bsz=307.9, num_updates=21400, lr=9.66736e-05, gnorm=0.567, clip=0, loss_scale=128, train_wall=55, gb_free=16.9, wall=16278
2023-07-25 03:23:44 | INFO | train_inner | epoch 015:    873 / 1474 loss=2.147, trans_loss=5.102, nll_loss=2.322, w2v_ctc_loss=0.743, task_loss=0, contrastive_loss=0.075, total=4054.09, n_correct=2521.65, ppl=5, accuracy=62.2, wps=14598.5, ups=1.8, wpb=8108.2, bsz=286.2, num_updates=21500, lr=9.64486e-05, gnorm=0.583, clip=0, loss_scale=128, train_wall=55, gb_free=16.2, wall=16333
2023-07-25 03:24:41 | INFO | train_inner | epoch 015:    973 / 1474 loss=2.14, trans_loss=5.091, nll_loss=2.308, w2v_ctc_loss=0.725, task_loss=0, contrastive_loss=0.16, total=4126.63, n_correct=2581.94, ppl=4.95, accuracy=62.568, wps=14612.9, ups=1.77, wpb=8253.3, bsz=303, num_updates=21600, lr=9.6225e-05, gnorm=0.571, clip=0, loss_scale=128, train_wall=56, gb_free=17.1, wall=16390
2023-07-25 03:25:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-25 03:25:38 | INFO | train_inner | epoch 015:   1074 / 1474 loss=2.15, trans_loss=5.099, nll_loss=2.32, w2v_ctc_loss=0.738, task_loss=0, contrastive_loss=0.166, total=4163.81, n_correct=2596.41, ppl=4.99, accuracy=62.357, wps=14545, ups=1.75, wpb=8327.6, bsz=313.7, num_updates=21700, lr=9.60031e-05, gnorm=0.575, clip=0, loss_scale=64, train_wall=57, gb_free=17.5, wall=16447
2023-07-25 03:26:34 | INFO | train_inner | epoch 015:   1174 / 1474 loss=2.131, trans_loss=5.085, nll_loss=2.304, w2v_ctc_loss=0.713, task_loss=0, contrastive_loss=0.126, total=4185, n_correct=2629.38, ppl=4.94, accuracy=62.829, wps=14965.6, ups=1.79, wpb=8370, bsz=329.3, num_updates=21800, lr=9.57826e-05, gnorm=0.562, clip=0, loss_scale=64, train_wall=55, gb_free=16.6, wall=16503
2023-07-25 03:27:30 | INFO | train_inner | epoch 015:   1274 / 1474 loss=2.143, trans_loss=5.095, nll_loss=2.315, w2v_ctc_loss=0.738, task_loss=0, contrastive_loss=0.082, total=4152.04, n_correct=2592.83, ppl=4.98, accuracy=62.447, wps=14783.4, ups=1.78, wpb=8304.1, bsz=303.7, num_updates=21900, lr=9.55637e-05, gnorm=0.576, clip=0, loss_scale=64, train_wall=56, gb_free=16.7, wall=16559
2023-07-25 03:28:27 | INFO | train_inner | epoch 015:   1374 / 1474 loss=2.134, trans_loss=5.096, nll_loss=2.315, w2v_ctc_loss=0.724, task_loss=0, contrastive_loss=0.065, total=4100.21, n_correct=2562.56, ppl=4.98, accuracy=62.498, wps=14496.5, ups=1.77, wpb=8200.4, bsz=293.6, num_updates=22000, lr=9.53463e-05, gnorm=0.571, clip=0, loss_scale=64, train_wall=56, gb_free=17.8, wall=16616
2023-07-25 03:28:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 03:28:50 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.355 | trans_loss 5.6 | nll_loss 2.883 | w2v_ctc_loss 1.324 | task_loss 0 | contrastive_loss 0.281 | total 4003.4 | n_correct 2455.7 | ppl 7.38 | accuracy 61.34 | uer 17.455 | wer 19.213 | raw_wer 19.213 | bleu 19.7 | wps 2173.1 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 19.7
2023-07-25 03:28:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-07-25 03:28:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_15_22000.pt
2023-07-25 03:28:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_15_22000.pt
2023-07-25 03:29:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.7) (writing took 20.226548369973898 seconds)
2023-07-25 03:30:08 | INFO | train_inner | epoch 015:   1474 / 1474 loss=2.149, trans_loss=5.101, nll_loss=2.325, w2v_ctc_loss=0.732, task_loss=0, contrastive_loss=0.159, total=4141.17, n_correct=2585.94, ppl=5.01, accuracy=62.445, wps=8198.6, ups=0.99, wpb=8282.3, bsz=314.3, num_updates=22100, lr=9.51303e-05, gnorm=0.575, clip=0, loss_scale=64, train_wall=56, gb_free=17.1, wall=16717
2023-07-25 03:30:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 03:30:30 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.374 | trans_loss 5.596 | nll_loss 2.88 | w2v_ctc_loss 1.398 | task_loss 0 | contrastive_loss 0.272 | total 4003.4 | n_correct 2460.3 | ppl 7.36 | accuracy 61.455 | uer 17.538 | wer 19.321 | raw_wer 19.321 | bleu 19.61 | wps 2414.2 | wpb 4003.4 | bsz 141.8 | num_updates 22100 | best_bleu 19.7
2023-07-25 03:30:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22100 updates
2023-07-25 03:30:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_19.6101.pt
2023-07-25 03:30:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_19.6101.pt
2023-07-25 03:30:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_19.6101.pt (epoch 15 @ 22100 updates, score 19.61) (writing took 14.670421950519085 seconds)
2023-07-25 03:30:45 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-07-25 03:30:45 | INFO | train | epoch 015 | loss 2.139 | trans_loss 5.088 | nll_loss 2.305 | w2v_ctc_loss 0.729 | task_loss 0 | contrastive_loss 0.118 | total 4136.69 | n_correct 2588.64 | ppl 4.94 | accuracy 62.578 | wps 13266.3 | ups 1.6 | wpb 8273.4 | bsz 304.9 | num_updates 22100 | lr 9.51303e-05 | gnorm 0.572 | clip 0 | loss_scale 64 | train_wall 822 | gb_free 17.1 | wall 16753
2023-07-25 03:30:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 03:30:45 | INFO | fairseq.trainer | begin training epoch 16
2023-07-25 03:30:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 03:31:48 | INFO | train_inner | epoch 016:    100 / 1474 loss=2.12, trans_loss=5.055, nll_loss=2.262, w2v_ctc_loss=0.716, task_loss=0, contrastive_loss=0.099, total=4126.22, n_correct=2608.66, ppl=4.8, accuracy=63.222, wps=8233.2, ups=1, wpb=8252.4, bsz=315.6, num_updates=22200, lr=9.49158e-05, gnorm=0.574, clip=0, loss_scale=64, train_wall=55, gb_free=16.4, wall=16817
2023-07-25 03:32:44 | INFO | train_inner | epoch 016:    200 / 1474 loss=2.114, trans_loss=5.055, nll_loss=2.261, w2v_ctc_loss=0.71, task_loss=0, contrastive_loss=0.073, total=4100.6, n_correct=2596.41, ppl=4.79, accuracy=63.318, wps=14651, ups=1.79, wpb=8201.2, bsz=296.8, num_updates=22300, lr=9.47027e-05, gnorm=0.574, clip=0, loss_scale=64, train_wall=56, gb_free=13.2, wall=16873
2023-07-25 03:33:41 | INFO | train_inner | epoch 016:    300 / 1474 loss=2.132, trans_loss=5.066, nll_loss=2.277, w2v_ctc_loss=0.725, task_loss=0, contrastive_loss=0.146, total=4166.94, n_correct=2623.58, ppl=4.85, accuracy=62.962, wps=14712.5, ups=1.77, wpb=8333.9, bsz=308.9, num_updates=22400, lr=9.44911e-05, gnorm=0.573, clip=0, loss_scale=64, train_wall=56, gb_free=17.4, wall=16930
2023-07-25 03:34:36 | INFO | train_inner | epoch 016:    400 / 1474 loss=2.134, trans_loss=5.069, nll_loss=2.278, w2v_ctc_loss=0.727, task_loss=0, contrastive_loss=0.157, total=4073.3, n_correct=2560.94, ppl=4.85, accuracy=62.871, wps=14683.1, ups=1.8, wpb=8146.6, bsz=288.1, num_updates=22500, lr=9.42809e-05, gnorm=0.577, clip=0, loss_scale=64, train_wall=55, gb_free=17.2, wall=16985
2023-07-25 03:35:33 | INFO | train_inner | epoch 016:    500 / 1474 loss=2.125, trans_loss=5.064, nll_loss=2.276, w2v_ctc_loss=0.719, task_loss=0, contrastive_loss=0.108, total=4174.67, n_correct=2640.8, ppl=4.84, accuracy=63.258, wps=14816.7, ups=1.77, wpb=8349.3, bsz=319.1, num_updates=22600, lr=9.40721e-05, gnorm=0.573, clip=0, loss_scale=64, train_wall=56, gb_free=16.3, wall=17041
2023-07-25 03:36:29 | INFO | train_inner | epoch 016:    600 / 1474 loss=2.122, trans_loss=5.069, nll_loss=2.28, w2v_ctc_loss=0.717, task_loss=0, contrastive_loss=0.067, total=4124.65, n_correct=2598.69, ppl=4.86, accuracy=63.004, wps=14749.7, ups=1.79, wpb=8249.3, bsz=297.6, num_updates=22700, lr=9.38647e-05, gnorm=0.575, clip=0, loss_scale=64, train_wall=55, gb_free=16.6, wall=17097
2023-07-25 03:37:25 | INFO | train_inner | epoch 016:    700 / 1474 loss=2.125, trans_loss=5.073, nll_loss=2.285, w2v_ctc_loss=0.721, task_loss=0, contrastive_loss=0.07, total=4095.49, n_correct=2577.21, ppl=4.87, accuracy=62.928, wps=14609.2, ups=1.78, wpb=8191, bsz=296.3, num_updates=22800, lr=9.36586e-05, gnorm=0.573, clip=0, loss_scale=64, train_wall=56, gb_free=16.3, wall=17153
2023-07-25 03:38:20 | INFO | train_inner | epoch 016:    800 / 1474 loss=2.129, trans_loss=5.075, nll_loss=2.289, w2v_ctc_loss=0.713, task_loss=0, contrastive_loss=0.131, total=4174.94, n_correct=2624.02, ppl=4.89, accuracy=62.852, wps=15030.3, ups=1.8, wpb=8349.9, bsz=310.9, num_updates=22900, lr=9.34539e-05, gnorm=0.574, clip=0, loss_scale=64, train_wall=55, gb_free=16.7, wall=17209
2023-07-25 03:39:16 | INFO | train_inner | epoch 016:    900 / 1474 loss=2.126, trans_loss=5.071, nll_loss=2.284, w2v_ctc_loss=0.716, task_loss=0, contrastive_loss=0.124, total=4163.19, n_correct=2626.56, ppl=4.87, accuracy=63.09, wps=14939.1, ups=1.79, wpb=8326.4, bsz=310.6, num_updates=23000, lr=9.32505e-05, gnorm=0.569, clip=0, loss_scale=64, train_wall=55, gb_free=17, wall=17265
2023-07-25 03:40:12 | INFO | train_inner | epoch 016:   1000 / 1474 loss=2.14, trans_loss=5.088, nll_loss=2.304, w2v_ctc_loss=0.734, task_loss=0, contrastive_loss=0.123, total=4103.45, n_correct=2565.02, ppl=4.94, accuracy=62.509, wps=14543.3, ups=1.77, wpb=8206.9, bsz=298.1, num_updates=23100, lr=9.30484e-05, gnorm=0.579, clip=0, loss_scale=64, train_wall=56, gb_free=15.3, wall=17321
2023-07-25 03:41:09 | INFO | train_inner | epoch 016:   1100 / 1474 loss=2.14, trans_loss=5.091, nll_loss=2.309, w2v_ctc_loss=0.736, task_loss=0, contrastive_loss=0.1, total=4119.27, n_correct=2573.96, ppl=4.96, accuracy=62.486, wps=14603.6, ups=1.77, wpb=8238.5, bsz=295.3, num_updates=23200, lr=9.28477e-05, gnorm=0.574, clip=0, loss_scale=64, train_wall=56, gb_free=18.1, wall=17378
2023-07-25 03:42:05 | INFO | train_inner | epoch 016:   1200 / 1474 loss=2.135, trans_loss=5.082, nll_loss=2.299, w2v_ctc_loss=0.712, task_loss=0, contrastive_loss=0.192, total=4165.11, n_correct=2610.24, ppl=4.92, accuracy=62.669, wps=14856.1, ups=1.78, wpb=8330.2, bsz=308.7, num_updates=23300, lr=9.26482e-05, gnorm=0.57, clip=0, loss_scale=64, train_wall=56, gb_free=16.9, wall=17434
2023-07-25 03:43:01 | INFO | train_inner | epoch 016:   1300 / 1474 loss=2.139, trans_loss=5.084, nll_loss=2.302, w2v_ctc_loss=0.727, task_loss=0, contrastive_loss=0.17, total=4134.61, n_correct=2595.12, ppl=4.93, accuracy=62.766, wps=14684, ups=1.78, wpb=8269.2, bsz=310.8, num_updates=23400, lr=9.245e-05, gnorm=0.575, clip=0, loss_scale=64, train_wall=56, gb_free=17, wall=17490
2023-07-25 03:43:58 | INFO | train_inner | epoch 016:   1400 / 1474 loss=2.136, trans_loss=5.087, nll_loss=2.306, w2v_ctc_loss=0.73, task_loss=0, contrastive_loss=0.106, total=4206.33, n_correct=2636, ppl=4.94, accuracy=62.667, wps=14904, ups=1.77, wpb=8412.7, bsz=322.2, num_updates=23500, lr=9.22531e-05, gnorm=0.573, clip=0, loss_scale=64, train_wall=56, gb_free=15.9, wall=17546
2023-07-25 03:44:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 03:45:00 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.358 | trans_loss 5.591 | nll_loss 2.872 | w2v_ctc_loss 1.358 | task_loss 0 | contrastive_loss 0.273 | total 4003.4 | n_correct 2463.4 | ppl 7.32 | accuracy 61.533 | uer 17.331 | wer 19.168 | raw_wer 19.168 | bleu 19.65 | wps 2451.6 | wpb 4003.4 | bsz 141.8 | num_updates 23574 | best_bleu 19.7
2023-07-25 03:45:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23574 updates
2023-07-25 03:45:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_19.6505.pt
2023-07-25 03:45:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_19.6505.pt
2023-07-25 03:45:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_19.6505.pt (epoch 16 @ 23574 updates, score 19.65) (writing took 11.69088802114129 seconds)
2023-07-25 03:45:13 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-07-25 03:45:13 | INFO | train | epoch 016 | loss 2.13 | trans_loss 5.074 | nll_loss 2.287 | w2v_ctc_loss 0.721 | task_loss 0 | contrastive_loss 0.128 | total 4138.65 | n_correct 2602.83 | ppl 4.88 | accuracy 62.891 | wps 14056.7 | ups 1.7 | wpb 8277.3 | bsz 305.7 | num_updates 23574 | lr 9.21082e-05 | gnorm 0.574 | clip 0 | loss_scale 64 | train_wall 820 | gb_free 15.8 | wall 17621
2023-07-25 03:45:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 03:45:13 | INFO | fairseq.trainer | begin training epoch 17
2023-07-25 03:45:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 03:45:35 | INFO | train_inner | epoch 017:     26 / 1474 loss=2.132, trans_loss=5.069, nll_loss=2.282, w2v_ctc_loss=0.714, task_loss=0, contrastive_loss=0.237, total=4152.31, n_correct=2614.36, ppl=4.86, accuracy=62.962, wps=8506.8, ups=1.02, wpb=8304.6, bsz=304.6, num_updates=23600, lr=9.20575e-05, gnorm=0.577, clip=0, loss_scale=64, train_wall=56, gb_free=14.2, wall=17644
2023-07-25 03:46:31 | INFO | train_inner | epoch 017:    126 / 1474 loss=2.113, trans_loss=5.045, nll_loss=2.248, w2v_ctc_loss=0.718, task_loss=0, contrastive_loss=0.074, total=4118.91, n_correct=2614.09, ppl=4.75, accuracy=63.466, wps=14863.4, ups=1.8, wpb=8237.8, bsz=295.8, num_updates=23700, lr=9.1863e-05, gnorm=0.581, clip=0, loss_scale=128, train_wall=55, gb_free=16.7, wall=17700
2023-07-25 03:46:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-25 03:47:28 | INFO | train_inner | epoch 017:    227 / 1474 loss=2.111, trans_loss=5.041, nll_loss=2.245, w2v_ctc_loss=0.702, task_loss=0, contrastive_loss=0.129, total=4123.81, n_correct=2620.29, ppl=4.74, accuracy=63.541, wps=14510.3, ups=1.76, wpb=8247.6, bsz=308.2, num_updates=23800, lr=9.16698e-05, gnorm=0.569, clip=0, loss_scale=64, train_wall=56, gb_free=17.1, wall=17756
2023-07-25 03:48:24 | INFO | train_inner | epoch 017:    327 / 1474 loss=2.122, trans_loss=5.052, nll_loss=2.259, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.241, total=4156.91, n_correct=2629.51, ppl=4.79, accuracy=63.256, wps=14746.3, ups=1.77, wpb=8313.8, bsz=305.7, num_updates=23900, lr=9.14779e-05, gnorm=0.571, clip=0, loss_scale=64, train_wall=56, gb_free=17.8, wall=17813
2023-07-25 03:49:20 | INFO | train_inner | epoch 017:    427 / 1474 loss=2.111, trans_loss=5.052, nll_loss=2.259, w2v_ctc_loss=0.708, task_loss=0, contrastive_loss=0.072, total=4146.43, n_correct=2633.47, ppl=4.79, accuracy=63.512, wps=14842.6, ups=1.79, wpb=8292.9, bsz=308, num_updates=24000, lr=9.12871e-05, gnorm=0.575, clip=0, loss_scale=64, train_wall=55, gb_free=16.5, wall=17869
2023-07-25 03:49:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 03:49:43 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.368 | trans_loss 5.599 | nll_loss 2.881 | w2v_ctc_loss 1.378 | task_loss 0 | contrastive_loss 0.262 | total 4003.4 | n_correct 2461.4 | ppl 7.37 | accuracy 61.483 | uer 17.347 | wer 19.16 | raw_wer 19.16 | bleu 19.57 | wps 2220.5 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 19.7
2023-07-25 03:49:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-07-25 03:49:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_17_24000.pt
2023-07-25 03:49:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_17_24000.pt
2023-07-25 03:49:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.57) (writing took 14.752226363867521 seconds)
2023-07-25 03:50:55 | INFO | train_inner | epoch 017:    527 / 1474 loss=2.121, trans_loss=5.057, nll_loss=2.265, w2v_ctc_loss=0.716, task_loss=0, contrastive_loss=0.12, total=4182.1, n_correct=2640.71, ppl=4.81, accuracy=63.143, wps=8760.3, ups=1.05, wpb=8364.2, bsz=307.9, num_updates=24100, lr=9.10975e-05, gnorm=0.577, clip=0, loss_scale=64, train_wall=56, gb_free=17, wall=17964
2023-07-25 03:51:51 | INFO | train_inner | epoch 017:    627 / 1474 loss=2.114, trans_loss=5.06, nll_loss=2.269, w2v_ctc_loss=0.71, task_loss=0, contrastive_loss=0.066, total=4167.27, n_correct=2638.07, ppl=4.82, accuracy=63.305, wps=14847.8, ups=1.78, wpb=8334.5, bsz=302.2, num_updates=24200, lr=9.09091e-05, gnorm=0.565, clip=0, loss_scale=64, train_wall=56, gb_free=11.4, wall=18020
2023-07-25 03:52:47 | INFO | train_inner | epoch 017:    727 / 1474 loss=2.127, trans_loss=5.065, nll_loss=2.276, w2v_ctc_loss=0.724, task_loss=0, contrastive_loss=0.118, total=4166.12, n_correct=2629.39, ppl=4.84, accuracy=63.114, wps=14884.3, ups=1.79, wpb=8332.2, bsz=308.1, num_updates=24300, lr=9.07218e-05, gnorm=0.578, clip=0, loss_scale=64, train_wall=56, gb_free=16.6, wall=18076
2023-07-25 03:53:43 | INFO | train_inner | epoch 017:    827 / 1474 loss=2.118, trans_loss=5.065, nll_loss=2.274, w2v_ctc_loss=0.715, task_loss=0, contrastive_loss=0.079, total=4091.64, n_correct=2582.11, ppl=4.84, accuracy=63.107, wps=14846.9, ups=1.81, wpb=8183.3, bsz=295.3, num_updates=24400, lr=9.05357e-05, gnorm=0.576, clip=0, loss_scale=64, train_wall=55, gb_free=17.6, wall=18131
2023-07-25 03:54:39 | INFO | train_inner | epoch 017:    927 / 1474 loss=2.118, trans_loss=5.065, nll_loss=2.277, w2v_ctc_loss=0.711, task_loss=0, contrastive_loss=0.078, total=4106.83, n_correct=2591.67, ppl=4.85, accuracy=63.106, wps=14663.2, ups=1.79, wpb=8213.7, bsz=304.6, num_updates=24500, lr=9.03508e-05, gnorm=0.581, clip=0, loss_scale=64, train_wall=56, gb_free=16.1, wall=18187
2023-07-25 03:55:35 | INFO | train_inner | epoch 017:   1027 / 1474 loss=2.117, trans_loss=5.063, nll_loss=2.274, w2v_ctc_loss=0.715, task_loss=0, contrastive_loss=0.082, total=4115.49, n_correct=2602.38, ppl=4.84, accuracy=63.234, wps=14639.7, ups=1.78, wpb=8231, bsz=305.8, num_updates=24600, lr=9.0167e-05, gnorm=0.58, clip=0, loss_scale=64, train_wall=56, gb_free=16.9, wall=18244
2023-07-25 03:56:30 | INFO | train_inner | epoch 017:   1127 / 1474 loss=2.115, trans_loss=5.064, nll_loss=2.275, w2v_ctc_loss=0.709, task_loss=0, contrastive_loss=0.068, total=4078.39, n_correct=2578.16, ppl=4.84, accuracy=63.215, wps=14727.4, ups=1.81, wpb=8156.8, bsz=293.7, num_updates=24700, lr=8.99843e-05, gnorm=0.581, clip=0, loss_scale=64, train_wall=55, gb_free=15.9, wall=18299
2023-07-25 03:57:27 | INFO | train_inner | epoch 017:   1227 / 1474 loss=2.14, trans_loss=5.073, nll_loss=2.288, w2v_ctc_loss=0.709, task_loss=0, contrastive_loss=0.315, total=4173.49, n_correct=2621.13, ppl=4.89, accuracy=62.804, wps=14800.5, ups=1.77, wpb=8347, bsz=323.7, num_updates=24800, lr=8.98027e-05, gnorm=0.576, clip=0, loss_scale=64, train_wall=56, gb_free=16.4, wall=18355
2023-07-25 03:58:23 | INFO | train_inner | epoch 017:   1327 / 1474 loss=2.121, trans_loss=5.068, nll_loss=2.282, w2v_ctc_loss=0.701, task_loss=0, contrastive_loss=0.153, total=4156.28, n_correct=2622.33, ppl=4.86, accuracy=63.093, wps=14751.5, ups=1.77, wpb=8312.6, bsz=308, num_updates=24900, lr=8.96221e-05, gnorm=0.573, clip=0, loss_scale=64, train_wall=56, gb_free=18.1, wall=18412
2023-07-25 03:59:20 | INFO | train_inner | epoch 017:   1427 / 1474 loss=2.119, trans_loss=5.073, nll_loss=2.287, w2v_ctc_loss=0.711, task_loss=0, contrastive_loss=0.073, total=4112.95, n_correct=2592.57, ppl=4.88, accuracy=63.034, wps=14532.7, ups=1.77, wpb=8225.9, bsz=303.2, num_updates=25000, lr=8.94427e-05, gnorm=0.581, clip=0, loss_scale=64, train_wall=56, gb_free=17.1, wall=18468
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:0')
2023-07-25 03:59:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:3')
2023-07-25 04:00:08 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.353 | trans_loss 5.58 | nll_loss 2.863 | w2v_ctc_loss 1.368 | task_loss 0 | contrastive_loss 0.269 | total 4003.4 | n_correct 2464.8 | ppl 7.27 | accuracy 61.568 | uer 17.371 | wer 19.157 | raw_wer 19.157 | bleu 19.73 | wps 2363.1 | wpb 4003.4 | bsz 141.8 | num_updates 25047 | best_bleu 19.73
2023-07-25 04:00:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25047 updates
2023-07-25 04:00:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 04:00:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 04:00:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt (epoch 17 @ 25047 updates, score 19.73) (writing took 21.933279851451516 seconds)
2023-07-25 04:00:31 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-07-25 04:00:31 | INFO | train | epoch 017 | loss 2.119 | trans_loss 5.06 | nll_loss 2.27 | w2v_ctc_loss 0.712 | task_loss 0 | contrastive_loss 0.118 | total 4136.62 | n_correct 2614.76 | ppl 4.82 | accuracy 63.21 | wps 13275.5 | ups 1.6 | wpb 8273.2 | bsz 305.1 | num_updates 25047 | lr 8.93588e-05 | gnorm 0.576 | clip 0 | loss_scale 64 | train_wall 819 | gb_free 16.6 | wall 18539
2023-07-25 04:00:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 04:00:31 | INFO | fairseq.trainer | begin training epoch 18
2023-07-25 04:00:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 04:01:09 | INFO | train_inner | epoch 018:     53 / 1474 loss=2.116, trans_loss=5.056, nll_loss=2.264, w2v_ctc_loss=0.718, task_loss=0, contrastive_loss=0.082, total=4139.04, n_correct=2620.34, ppl=4.8, accuracy=63.308, wps=7548.4, ups=0.91, wpb=8278.1, bsz=303.3, num_updates=25100, lr=8.92644e-05, gnorm=0.577, clip=0, loss_scale=64, train_wall=56, gb_free=17.3, wall=18578
2023-07-25 04:02:05 | INFO | train_inner | epoch 018:    153 / 1474 loss=2.105, trans_loss=5.028, nll_loss=2.227, w2v_ctc_loss=0.686, task_loss=0, contrastive_loss=0.205, total=4154.85, n_correct=2650.84, ppl=4.68, accuracy=63.801, wps=14820.1, ups=1.78, wpb=8309.7, bsz=312.7, num_updates=25200, lr=8.90871e-05, gnorm=0.574, clip=0, loss_scale=64, train_wall=56, gb_free=17, wall=18634
2023-07-25 04:03:02 | INFO | train_inner | epoch 018:    253 / 1474 loss=2.098, trans_loss=5.03, nll_loss=2.231, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.074, total=4162.72, n_correct=2664.09, ppl=4.69, accuracy=63.999, wps=14685.9, ups=1.76, wpb=8325.4, bsz=312.9, num_updates=25300, lr=8.89108e-05, gnorm=0.568, clip=0, loss_scale=64, train_wall=56, gb_free=16.4, wall=18691
2023-07-25 04:03:58 | INFO | train_inner | epoch 018:    353 / 1474 loss=2.104, trans_loss=5.039, nll_loss=2.242, w2v_ctc_loss=0.702, task_loss=0, contrastive_loss=0.088, total=4161.22, n_correct=2649.16, ppl=4.73, accuracy=63.663, wps=14829.4, ups=1.78, wpb=8322.4, bsz=301.5, num_updates=25400, lr=8.87357e-05, gnorm=0.574, clip=0, loss_scale=64, train_wall=56, gb_free=14.8, wall=18747
2023-07-25 04:04:54 | INFO | train_inner | epoch 018:    453 / 1474 loss=2.113, trans_loss=5.045, nll_loss=2.249, w2v_ctc_loss=0.699, task_loss=0, contrastive_loss=0.178, total=4092.36, n_correct=2597.73, ppl=4.75, accuracy=63.478, wps=14578.6, ups=1.78, wpb=8184.7, bsz=295.3, num_updates=25500, lr=8.85615e-05, gnorm=0.578, clip=0, loss_scale=64, train_wall=56, gb_free=16.8, wall=18803
2023-07-25 04:05:50 | INFO | train_inner | epoch 018:    553 / 1474 loss=2.098, trans_loss=5.03, nll_loss=2.232, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.09, total=4206.45, n_correct=2690.15, ppl=4.7, accuracy=63.953, wps=15015, ups=1.78, wpb=8412.9, bsz=328.9, num_updates=25600, lr=8.83883e-05, gnorm=0.565, clip=0, loss_scale=64, train_wall=56, gb_free=18.1, wall=18859
2023-07-25 04:06:46 | INFO | train_inner | epoch 018:    653 / 1474 loss=2.116, trans_loss=5.054, nll_loss=2.262, w2v_ctc_loss=0.707, task_loss=0, contrastive_loss=0.154, total=4097.96, n_correct=2597.53, ppl=4.8, accuracy=63.386, wps=14612.9, ups=1.78, wpb=8195.9, bsz=298.6, num_updates=25700, lr=8.82162e-05, gnorm=0.58, clip=0, loss_scale=64, train_wall=56, gb_free=12.6, wall=18915
2023-07-25 04:07:42 | INFO | train_inner | epoch 018:    753 / 1474 loss=2.127, trans_loss=5.054, nll_loss=2.263, w2v_ctc_loss=0.714, task_loss=0, contrastive_loss=0.25, total=4208.5, n_correct=2662.82, ppl=4.8, accuracy=63.272, wps=15013.4, ups=1.78, wpb=8417, bsz=322.6, num_updates=25800, lr=8.80451e-05, gnorm=0.575, clip=0, loss_scale=128, train_wall=56, gb_free=16.5, wall=18971
2023-07-25 04:08:38 | INFO | train_inner | epoch 018:    853 / 1474 loss=2.106, trans_loss=5.051, nll_loss=2.258, w2v_ctc_loss=0.702, task_loss=0, contrastive_loss=0.062, total=4166.07, n_correct=2646.62, ppl=4.78, accuracy=63.528, wps=14894.4, ups=1.79, wpb=8332.1, bsz=302.4, num_updates=25900, lr=8.7875e-05, gnorm=0.575, clip=0, loss_scale=128, train_wall=55, gb_free=16.1, wall=19027
2023-07-25 04:09:34 | INFO | train_inner | epoch 018:    953 / 1474 loss=2.103, trans_loss=5.045, nll_loss=2.251, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.088, total=4141.27, n_correct=2636.79, ppl=4.76, accuracy=63.671, wps=14911.5, ups=1.8, wpb=8282.5, bsz=316, num_updates=26000, lr=8.77058e-05, gnorm=0.577, clip=0, loss_scale=128, train_wall=55, gb_free=16.3, wall=19083
2023-07-25 04:09:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 04:09:56 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.38 | trans_loss 5.595 | nll_loss 2.874 | w2v_ctc_loss 1.421 | task_loss 0 | contrastive_loss 0.274 | total 4003.4 | n_correct 2457.1 | ppl 7.33 | accuracy 61.375 | uer 17.668 | wer 19.488 | raw_wer 19.488 | bleu 19.77 | wps 2329.3 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 19.77
2023-07-25 04:09:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-07-25 04:09:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_18_26000.pt
2023-07-25 04:09:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_18_26000.pt
2023-07-25 04:10:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 19.77) (writing took 21.554450580850244 seconds)
2023-07-25 04:11:15 | INFO | train_inner | epoch 018:   1053 / 1474 loss=2.106, trans_loss=5.052, nll_loss=2.26, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.076, total=4134.55, n_correct=2623.17, ppl=4.79, accuracy=63.445, wps=8187.4, ups=0.99, wpb=8269.1, bsz=300.8, num_updates=26100, lr=8.75376e-05, gnorm=0.576, clip=0, loss_scale=128, train_wall=56, gb_free=16.1, wall=19184
2023-07-25 04:11:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-25 04:12:11 | INFO | train_inner | epoch 018:   1154 / 1474 loss=2.103, trans_loss=5.04, nll_loss=2.245, w2v_ctc_loss=0.704, task_loss=0, contrastive_loss=0.07, total=4136.34, n_correct=2633.87, ppl=4.74, accuracy=63.676, wps=14655.1, ups=1.77, wpb=8272.7, bsz=306.2, num_updates=26200, lr=8.73704e-05, gnorm=0.576, clip=0, loss_scale=64, train_wall=56, gb_free=15.5, wall=19240
2023-07-25 04:13:07 | INFO | train_inner | epoch 018:   1254 / 1474 loss=2.111, trans_loss=5.064, nll_loss=2.275, w2v_ctc_loss=0.705, task_loss=0, contrastive_loss=0.068, total=4087.62, n_correct=2584.34, ppl=4.84, accuracy=63.224, wps=14706, ups=1.8, wpb=8175.2, bsz=287.1, num_updates=26300, lr=8.72041e-05, gnorm=0.577, clip=0, loss_scale=64, train_wall=55, gb_free=16.9, wall=19296
2023-07-25 04:14:03 | INFO | train_inner | epoch 018:   1354 / 1474 loss=2.124, trans_loss=5.07, nll_loss=2.284, w2v_ctc_loss=0.721, task_loss=0, contrastive_loss=0.095, total=4070.69, n_correct=2563.41, ppl=4.87, accuracy=62.972, wps=14487.3, ups=1.78, wpb=8141.4, bsz=291.7, num_updates=26400, lr=8.70388e-05, gnorm=0.583, clip=0, loss_scale=64, train_wall=56, gb_free=17.7, wall=19352
2023-07-25 04:14:59 | INFO | train_inner | epoch 018:   1454 / 1474 loss=2.116, trans_loss=5.064, nll_loss=2.276, w2v_ctc_loss=0.71, task_loss=0, contrastive_loss=0.081, total=4113.2, n_correct=2599.01, ppl=4.84, accuracy=63.187, wps=14634, ups=1.78, wpb=8226.4, bsz=297.5, num_updates=26500, lr=8.68744e-05, gnorm=0.583, clip=0, loss_scale=64, train_wall=56, gb_free=16.7, wall=19408
2023-07-25 04:15:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 04:15:32 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.386 | trans_loss 5.588 | nll_loss 2.871 | w2v_ctc_loss 1.458 | task_loss 0 | contrastive_loss 0.27 | total 4003.4 | n_correct 2474.4 | ppl 7.31 | accuracy 61.807 | uer 17.349 | wer 19.101 | raw_wer 19.101 | bleu 19.9 | wps 2474.8 | wpb 4003.4 | bsz 141.8 | num_updates 26520 | best_bleu 19.9
2023-07-25 04:15:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26520 updates
2023-07-25 04:15:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 04:15:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 04:15:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt (epoch 18 @ 26520 updates, score 19.9) (writing took 19.350792517885566 seconds)
2023-07-25 04:15:51 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-07-25 04:15:52 | INFO | train | epoch 018 | loss 2.109 | trans_loss 5.047 | nll_loss 2.253 | w2v_ctc_loss 0.702 | task_loss 0 | contrastive_loss 0.116 | total 4137.4 | n_correct 2627.97 | ppl 4.77 | accuracy 63.517 | wps 13236.2 | ups 1.6 | wpb 8274.8 | bsz 305.2 | num_updates 26520 | lr 8.68417e-05 | gnorm 0.576 | clip 0 | loss_scale 64 | train_wall 820 | gb_free 16.2 | wall 19460
2023-07-25 04:15:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 04:15:52 | INFO | fairseq.trainer | begin training epoch 19
2023-07-25 04:15:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 04:16:44 | INFO | train_inner | epoch 019:     80 / 1474 loss=2.099, trans_loss=5.024, nll_loss=2.222, w2v_ctc_loss=0.695, task_loss=0, contrastive_loss=0.128, total=4102.06, n_correct=2619.67, ppl=4.66, accuracy=63.862, wps=7849, ups=0.96, wpb=8204.1, bsz=296.9, num_updates=26600, lr=8.6711e-05, gnorm=0.577, clip=0, loss_scale=64, train_wall=55, gb_free=17.8, wall=19513
2023-07-25 04:17:40 | INFO | train_inner | epoch 019:    180 / 1474 loss=2.099, trans_loss=5.016, nll_loss=2.212, w2v_ctc_loss=0.703, task_loss=0, contrastive_loss=0.127, total=4227.7, n_correct=2708.41, ppl=4.63, accuracy=64.063, wps=14964.4, ups=1.77, wpb=8455.4, bsz=324.8, num_updates=26700, lr=8.65485e-05, gnorm=0.571, clip=0, loss_scale=64, train_wall=56, gb_free=17.3, wall=19569
2023-07-25 04:18:37 | INFO | train_inner | epoch 019:    280 / 1474 loss=2.09, trans_loss=5.018, nll_loss=2.215, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.064, total=4187.34, n_correct=2687.41, ppl=4.64, accuracy=64.179, wps=14878.1, ups=1.78, wpb=8374.7, bsz=306.4, num_updates=26800, lr=8.63868e-05, gnorm=0.57, clip=0, loss_scale=64, train_wall=56, gb_free=16.2, wall=19626
2023-07-25 04:19:32 | INFO | train_inner | epoch 019:    380 / 1474 loss=2.1, trans_loss=5.024, nll_loss=2.224, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.174, total=4170.52, n_correct=2665.57, ppl=4.67, accuracy=63.915, wps=14970.6, ups=1.79, wpb=8341, bsz=311, num_updates=26900, lr=8.62261e-05, gnorm=0.569, clip=0, loss_scale=64, train_wall=55, gb_free=16.6, wall=19681
2023-07-25 04:20:28 | INFO | train_inner | epoch 019:    480 / 1474 loss=2.101, trans_loss=5.034, nll_loss=2.236, w2v_ctc_loss=0.701, task_loss=0, contrastive_loss=0.083, total=4113.89, n_correct=2625.06, ppl=4.71, accuracy=63.81, wps=14797.7, ups=1.8, wpb=8227.8, bsz=301.5, num_updates=27000, lr=8.60663e-05, gnorm=0.58, clip=0, loss_scale=64, train_wall=55, gb_free=17.5, wall=19737
2023-07-25 04:21:24 | INFO | train_inner | epoch 019:    580 / 1474 loss=2.097, trans_loss=5.027, nll_loss=2.228, w2v_ctc_loss=0.691, task_loss=0, contrastive_loss=0.143, total=4128.58, n_correct=2640.44, ppl=4.68, accuracy=63.955, wps=14731.5, ups=1.78, wpb=8257.2, bsz=306.2, num_updates=27100, lr=8.59074e-05, gnorm=0.577, clip=0, loss_scale=64, train_wall=56, gb_free=16.9, wall=19793
2023-07-25 04:22:20 | INFO | train_inner | epoch 019:    680 / 1474 loss=2.087, trans_loss=5.029, nll_loss=2.231, w2v_ctc_loss=0.677, task_loss=0, contrastive_loss=0.072, total=4201.56, n_correct=2690.2, ppl=4.69, accuracy=64.029, wps=14977.7, ups=1.78, wpb=8403.1, bsz=321.5, num_updates=27200, lr=8.57493e-05, gnorm=0.567, clip=0, loss_scale=64, train_wall=56, gb_free=18.1, wall=19849
2023-07-25 04:23:16 | INFO | train_inner | epoch 019:    780 / 1474 loss=2.098, trans_loss=5.032, nll_loss=2.233, w2v_ctc_loss=0.7, task_loss=0, contrastive_loss=0.077, total=4124.03, n_correct=2634.94, ppl=4.7, accuracy=63.892, wps=14805.6, ups=1.8, wpb=8248.1, bsz=299, num_updates=27300, lr=8.55921e-05, gnorm=0.574, clip=0, loss_scale=64, train_wall=55, gb_free=17.8, wall=19905
2023-07-25 04:24:12 | INFO | train_inner | epoch 019:    880 / 1474 loss=2.104, trans_loss=5.045, nll_loss=2.25, w2v_ctc_loss=0.7, task_loss=0, contrastive_loss=0.075, total=4177.8, n_correct=2656.09, ppl=4.76, accuracy=63.576, wps=14976, ups=1.79, wpb=8355.6, bsz=309.6, num_updates=27400, lr=8.54358e-05, gnorm=0.581, clip=0, loss_scale=64, train_wall=55, gb_free=15.2, wall=19961
2023-07-25 04:25:09 | INFO | train_inner | epoch 019:    980 / 1474 loss=2.122, trans_loss=5.053, nll_loss=2.263, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.304, total=4084.26, n_correct=2587.81, ppl=4.8, accuracy=63.361, wps=14366.7, ups=1.76, wpb=8168.5, bsz=305.8, num_updates=27500, lr=8.52803e-05, gnorm=0.589, clip=0, loss_scale=64, train_wall=56, gb_free=16.3, wall=20017
2023-07-25 04:26:04 | INFO | train_inner | epoch 019:   1080 / 1474 loss=2.107, trans_loss=5.051, nll_loss=2.259, w2v_ctc_loss=0.695, task_loss=0, contrastive_loss=0.112, total=4042.73, n_correct=2568.6, ppl=4.79, accuracy=63.536, wps=14471.3, ups=1.79, wpb=8085.5, bsz=294, num_updates=27600, lr=8.51257e-05, gnorm=0.585, clip=0, loss_scale=64, train_wall=55, gb_free=17.6, wall=20073
2023-07-25 04:27:01 | INFO | train_inner | epoch 019:   1180 / 1474 loss=2.12, trans_loss=5.053, nll_loss=2.262, w2v_ctc_loss=0.705, task_loss=0, contrastive_loss=0.199, total=4140.95, n_correct=2621.43, ppl=4.8, accuracy=63.305, wps=14755, ups=1.78, wpb=8281.9, bsz=307.9, num_updates=27700, lr=8.49719e-05, gnorm=0.583, clip=0, loss_scale=64, train_wall=56, gb_free=13.3, wall=20129
2023-07-25 04:27:56 | INFO | train_inner | epoch 019:   1280 / 1474 loss=2.103, trans_loss=5.053, nll_loss=2.262, w2v_ctc_loss=0.689, task_loss=0, contrastive_loss=0.093, total=4135.79, n_correct=2628.59, ppl=4.8, accuracy=63.557, wps=14883.3, ups=1.8, wpb=8271.6, bsz=299.5, num_updates=27800, lr=8.48189e-05, gnorm=0.577, clip=0, loss_scale=64, train_wall=55, gb_free=18.1, wall=20185
2023-07-25 04:28:53 | INFO | train_inner | epoch 019:   1380 / 1474 loss=2.103, trans_loss=5.046, nll_loss=2.253, w2v_ctc_loss=0.699, task_loss=0, contrastive_loss=0.079, total=4138.67, n_correct=2634.64, ppl=4.77, accuracy=63.659, wps=14676.5, ups=1.77, wpb=8277.3, bsz=301.6, num_updates=27900, lr=8.46668e-05, gnorm=0.577, clip=0, loss_scale=64, train_wall=56, gb_free=16.8, wall=20241
2023-07-25 04:29:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 04:30:07 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.368 | trans_loss 5.585 | nll_loss 2.867 | w2v_ctc_loss 1.41 | task_loss 0 | contrastive_loss 0.263 | total 4003.4 | n_correct 2473.9 | ppl 7.29 | accuracy 61.795 | uer 17.068 | wer 18.899 | raw_wer 18.899 | bleu 19.89 | wps 2434.2 | wpb 4003.4 | bsz 141.8 | num_updates 27994 | best_bleu 19.9
2023-07-25 04:30:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27994 updates
2023-07-25 04:30:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_19.8901.pt
2023-07-25 04:30:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_19.8901.pt
2023-07-25 04:30:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_19.8901.pt (epoch 19 @ 27994 updates, score 19.89) (writing took 11.950233146548271 seconds)
2023-07-25 04:30:20 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-07-25 04:30:20 | INFO | train | epoch 019 | loss 2.102 | trans_loss 5.036 | nll_loss 2.239 | w2v_ctc_loss 0.695 | task_loss 0 | contrastive_loss 0.123 | total 4138.65 | n_correct 2639.05 | ppl 4.72 | accuracy 63.766 | wps 14050 | ups 1.7 | wpb 8277.3 | bsz 305.7 | num_updates 27994 | lr 8.45245e-05 | gnorm 0.577 | clip 0 | loss_scale 64 | train_wall 819 | gb_free 17.7 | wall 20329
2023-07-25 04:30:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 04:30:20 | INFO | fairseq.trainer | begin training epoch 20
2023-07-25 04:30:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 04:30:32 | INFO | train_inner | epoch 020:      6 / 1474 loss=2.105, trans_loss=5.043, nll_loss=2.25, w2v_ctc_loss=0.691, task_loss=0, contrastive_loss=0.162, total=4117.61, n_correct=2622.11, ppl=4.76, accuracy=63.68, wps=8276.2, ups=1, wpb=8235.2, bsz=303, num_updates=28000, lr=8.45154e-05, gnorm=0.584, clip=0, loss_scale=64, train_wall=56, gb_free=16.7, wall=20341
2023-07-25 04:30:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 04:30:53 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.355 | trans_loss 5.584 | nll_loss 2.863 | w2v_ctc_loss 1.368 | task_loss 0 | contrastive_loss 0.265 | total 4003.4 | n_correct 2480.6 | ppl 7.28 | accuracy 61.962 | uer 17.01 | wer 18.784 | raw_wer 18.784 | bleu 19.88 | wps 2394.8 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 19.9
2023-07-25 04:30:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-07-25 04:30:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_20_28000.pt
2023-07-25 04:30:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_20_28000.pt
2023-07-25 04:31:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 19.88) (writing took 12.321459837257862 seconds)
2023-07-25 04:32:03 | INFO | train_inner | epoch 020:    106 / 1474 loss=2.08, trans_loss=5.002, nll_loss=2.195, w2v_ctc_loss=0.68, task_loss=0, contrastive_loss=0.085, total=4192.82, n_correct=2700.52, ppl=4.58, accuracy=64.408, wps=9251.2, ups=1.1, wpb=8385.6, bsz=312.8, num_updates=28100, lr=8.43649e-05, gnorm=0.573, clip=0, loss_scale=64, train_wall=56, gb_free=16.5, wall=20432
2023-07-25 04:33:00 | INFO | train_inner | epoch 020:    206 / 1474 loss=2.089, trans_loss=5.013, nll_loss=2.208, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.135, total=4155.9, n_correct=2670.47, ppl=4.62, accuracy=64.257, wps=14566.2, ups=1.75, wpb=8311.8, bsz=302.3, num_updates=28200, lr=8.42152e-05, gnorm=0.572, clip=0, loss_scale=64, train_wall=57, gb_free=12.3, wall=20489
2023-07-25 04:33:56 | INFO | train_inner | epoch 020:    306 / 1474 loss=2.084, trans_loss=5.008, nll_loss=2.203, w2v_ctc_loss=0.688, task_loss=0, contrastive_loss=0.077, total=4192.69, n_correct=2700.97, ppl=4.6, accuracy=64.421, wps=14952.1, ups=1.78, wpb=8385.4, bsz=327.6, num_updates=28300, lr=8.40663e-05, gnorm=0.579, clip=0, loss_scale=128, train_wall=56, gb_free=17.3, wall=20545
2023-07-25 04:34:51 | INFO | train_inner | epoch 020:    406 / 1474 loss=2.083, trans_loss=5.013, nll_loss=2.209, w2v_ctc_loss=0.679, task_loss=0, contrastive_loss=0.074, total=4116.96, n_correct=2647.86, ppl=4.62, accuracy=64.316, wps=14827.1, ups=1.8, wpb=8233.9, bsz=296.8, num_updates=28400, lr=8.39181e-05, gnorm=0.576, clip=0, loss_scale=128, train_wall=55, gb_free=13.2, wall=20600
2023-07-25 04:35:47 | INFO | train_inner | epoch 020:    506 / 1474 loss=2.096, trans_loss=5.028, nll_loss=2.228, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.161, total=4100.73, n_correct=2621.87, ppl=4.68, accuracy=63.937, wps=14667, ups=1.79, wpb=8201.5, bsz=298.4, num_updates=28500, lr=8.37708e-05, gnorm=0.578, clip=0, loss_scale=128, train_wall=55, gb_free=16.5, wall=20656
2023-07-25 04:36:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-25 04:36:45 | INFO | train_inner | epoch 020:    607 / 1474 loss=2.098, trans_loss=5.026, nll_loss=2.226, w2v_ctc_loss=0.688, task_loss=0, contrastive_loss=0.159, total=4083.63, n_correct=2610.53, ppl=4.68, accuracy=63.927, wps=14276.1, ups=1.75, wpb=8167.3, bsz=293.2, num_updates=28600, lr=8.36242e-05, gnorm=0.586, clip=0, loss_scale=64, train_wall=57, gb_free=12.5, wall=20713
2023-07-25 04:37:40 | INFO | train_inner | epoch 020:    707 / 1474 loss=2.092, trans_loss=5.029, nll_loss=2.229, w2v_ctc_loss=0.692, task_loss=0, contrastive_loss=0.065, total=4140.23, n_correct=2649.09, ppl=4.69, accuracy=63.984, wps=14826.3, ups=1.79, wpb=8280.5, bsz=300.6, num_updates=28700, lr=8.34784e-05, gnorm=0.58, clip=0, loss_scale=64, train_wall=55, gb_free=16.4, wall=20769
2023-07-25 04:38:36 | INFO | train_inner | epoch 020:    807 / 1474 loss=2.092, trans_loss=5.027, nll_loss=2.229, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.07, total=4140.66, n_correct=2653.84, ppl=4.69, accuracy=64.092, wps=14956.1, ups=1.81, wpb=8281.3, bsz=305.6, num_updates=28800, lr=8.33333e-05, gnorm=0.58, clip=0, loss_scale=64, train_wall=55, gb_free=17.8, wall=20825
2023-07-25 04:38:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-25 04:39:33 | INFO | train_inner | epoch 020:    908 / 1474 loss=2.11, trans_loss=5.034, nll_loss=2.238, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.259, total=4136.06, n_correct=2638.59, ppl=4.72, accuracy=63.795, wps=14378, ups=1.74, wpb=8272.1, bsz=315.6, num_updates=28900, lr=8.3189e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=57, gb_free=17.7, wall=20882
2023-07-25 04:40:30 | INFO | train_inner | epoch 020:   1008 / 1474 loss=2.091, trans_loss=5.03, nll_loss=2.232, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.076, total=4168.14, n_correct=2668.27, ppl=4.7, accuracy=64.016, wps=14762.8, ups=1.77, wpb=8336.3, bsz=307.3, num_updates=29000, lr=8.30455e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=56, gb_free=16.7, wall=20939
2023-07-25 04:41:26 | INFO | train_inner | epoch 020:   1108 / 1474 loss=2.104, trans_loss=5.034, nll_loss=2.238, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.214, total=4166.49, n_correct=2661.61, ppl=4.72, accuracy=63.881, wps=14846.5, ups=1.78, wpb=8333, bsz=315.4, num_updates=29100, lr=8.29027e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=56, gb_free=15.1, wall=20995
2023-07-25 04:42:21 | INFO | train_inner | epoch 020:   1208 / 1474 loss=2.098, trans_loss=5.032, nll_loss=2.234, w2v_ctc_loss=0.703, task_loss=0, contrastive_loss=0.064, total=4029.18, n_correct=2569.98, ppl=4.71, accuracy=63.784, wps=14544.1, ups=1.8, wpb=8058.4, bsz=284, num_updates=29200, lr=8.27606e-05, gnorm=0.587, clip=0, loss_scale=32, train_wall=55, gb_free=12.4, wall=21050
2023-07-25 04:43:18 | INFO | train_inner | epoch 020:   1308 / 1474 loss=2.094, trans_loss=5.038, nll_loss=2.242, w2v_ctc_loss=0.689, task_loss=0, contrastive_loss=0.069, total=4123.21, n_correct=2634.95, ppl=4.73, accuracy=63.905, wps=14627.2, ups=1.77, wpb=8246.4, bsz=297.1, num_updates=29300, lr=8.26192e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=56, gb_free=17.7, wall=21107
2023-07-25 04:44:14 | INFO | train_inner | epoch 020:   1408 / 1474 loss=2.094, trans_loss=5.037, nll_loss=2.241, w2v_ctc_loss=0.689, task_loss=0, contrastive_loss=0.068, total=4116.28, n_correct=2625.9, ppl=4.73, accuracy=63.793, wps=14660.6, ups=1.78, wpb=8232.6, bsz=295, num_updates=29400, lr=8.24786e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=56, gb_free=17.8, wall=21163
2023-07-25 04:44:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 04:45:12 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.348 | trans_loss 5.58 | nll_loss 2.859 | w2v_ctc_loss 1.355 | task_loss 0 | contrastive_loss 0.264 | total 4003.4 | n_correct 2468.9 | ppl 7.25 | accuracy 61.67 | uer 17.153 | wer 18.937 | raw_wer 18.937 | bleu 19.9 | wps 2328.8 | wpb 4003.4 | bsz 141.8 | num_updates 29466 | best_bleu 19.9
2023-07-25 04:45:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29466 updates
2023-07-25 04:45:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 04:45:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 04:45:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt (epoch 20 @ 29466 updates, score 19.9) (writing took 19.20021370239556 seconds)
2023-07-25 04:45:32 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-07-25 04:45:32 | INFO | train | epoch 020 | loss 2.093 | trans_loss 5.025 | nll_loss 2.226 | w2v_ctc_loss 0.688 | task_loss 0 | contrastive_loss 0.113 | total 4136.11 | n_correct 2648.52 | ppl 4.68 | accuracy 64.034 | wps 13346.6 | ups 1.61 | wpb 8272.2 | bsz 304.9 | num_updates 29466 | lr 8.23862e-05 | gnorm 0.579 | clip 0 | loss_scale 32 | train_wall 821 | gb_free 16.4 | wall 21241
2023-07-25 04:45:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 04:45:33 | INFO | fairseq.trainer | begin training epoch 21
2023-07-25 04:45:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 04:46:00 | INFO | train_inner | epoch 021:     34 / 1474 loss=2.1, trans_loss=5.029, nll_loss=2.231, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.19, total=4152.26, n_correct=2658.25, ppl=4.69, accuracy=64.019, wps=7837.7, ups=0.94, wpb=8304.5, bsz=316.3, num_updates=29500, lr=8.23387e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=55, gb_free=16.7, wall=21269
2023-07-25 04:46:56 | INFO | train_inner | epoch 021:    134 / 1474 loss=2.084, trans_loss=4.996, nll_loss=2.187, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.182, total=4195.08, n_correct=2707.67, ppl=4.55, accuracy=64.544, wps=14982.6, ups=1.79, wpb=8390.2, bsz=319.6, num_updates=29600, lr=8.21995e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=56, gb_free=17.3, wall=21325
2023-07-25 04:47:52 | INFO | train_inner | epoch 021:    234 / 1474 loss=2.074, trans_loss=5, nll_loss=2.191, w2v_ctc_loss=0.665, task_loss=0, contrastive_loss=0.132, total=4155.31, n_correct=2685.9, ppl=4.57, accuracy=64.638, wps=14678.3, ups=1.77, wpb=8310.6, bsz=312.6, num_updates=29700, lr=8.2061e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=56, gb_free=17, wall=21381
2023-07-25 04:48:49 | INFO | train_inner | epoch 021:    334 / 1474 loss=2.084, trans_loss=5.004, nll_loss=2.197, w2v_ctc_loss=0.682, task_loss=0, contrastive_loss=0.139, total=4151.51, n_correct=2675.23, ppl=4.59, accuracy=64.44, wps=14737, ups=1.77, wpb=8303, bsz=310.8, num_updates=29800, lr=8.19232e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=56, gb_free=15.8, wall=21438
2023-07-25 04:49:44 | INFO | train_inner | epoch 021:    434 / 1474 loss=2.073, trans_loss=5.003, nll_loss=2.196, w2v_ctc_loss=0.671, task_loss=0, contrastive_loss=0.061, total=4180.85, n_correct=2699.18, ppl=4.58, accuracy=64.561, wps=15026, ups=1.8, wpb=8361.7, bsz=306.8, num_updates=29900, lr=8.17861e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=55, gb_free=16.1, wall=21493
2023-07-25 04:50:41 | INFO | train_inner | epoch 021:    534 / 1474 loss=2.076, trans_loss=5.003, nll_loss=2.195, w2v_ctc_loss=0.68, task_loss=0, contrastive_loss=0.061, total=4083.98, n_correct=2634.57, ppl=4.58, accuracy=64.51, wps=14557.6, ups=1.78, wpb=8168, bsz=295.1, num_updates=30000, lr=8.16497e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=56, gb_free=13.5, wall=21549
2023-07-25 04:50:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 04:51:02 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.359 | trans_loss 5.594 | nll_loss 2.875 | w2v_ctc_loss 1.356 | task_loss 0 | contrastive_loss 0.266 | total 4003.4 | n_correct 2466.4 | ppl 7.34 | accuracy 61.608 | uer 17.065 | wer 19.078 | raw_wer 19.078 | bleu 19.8 | wps 2359.6 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 19.9
2023-07-25 04:51:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-07-25 04:51:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_21_30000.pt
2023-07-25 04:51:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_21_30000.pt
2023-07-25 04:51:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 19.8) (writing took 16.746547048911452 seconds)
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:0')
2023-07-25 04:52:16 | INFO | train_inner | epoch 021:    634 / 1474 loss=2.091, trans_loss=5.013, nll_loss=2.21, w2v_ctc_loss=0.673, task_loss=0, contrastive_loss=0.235, total=4215.41, n_correct=2708.52, ppl=4.63, accuracy=64.253, wps=8792.3, ups=1.04, wpb=8430.8, bsz=315.4, num_updates=30100, lr=8.15139e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=56, gb_free=11.9, wall=21645
2023-07-25 04:53:13 | INFO | train_inner | epoch 021:    734 / 1474 loss=2.087, trans_loss=5.02, nll_loss=2.219, w2v_ctc_loss=0.68, task_loss=0, contrastive_loss=0.096, total=4152.97, n_correct=2664.58, ppl=4.66, accuracy=64.161, wps=14798.2, ups=1.78, wpb=8305.9, bsz=309.3, num_updates=30200, lr=8.13788e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=56, gb_free=16.6, wall=21701
2023-07-25 04:54:09 | INFO | train_inner | epoch 021:    834 / 1474 loss=2.088, trans_loss=5.023, nll_loss=2.223, w2v_ctc_loss=0.678, task_loss=0, contrastive_loss=0.106, total=4066.93, n_correct=2610.4, ppl=4.67, accuracy=64.186, wps=14417.9, ups=1.77, wpb=8133.9, bsz=294.4, num_updates=30300, lr=8.12444e-05, gnorm=0.587, clip=0, loss_scale=32, train_wall=56, gb_free=17.3, wall=21758
2023-07-25 04:55:05 | INFO | train_inner | epoch 021:    934 / 1474 loss=2.083, trans_loss=5.015, nll_loss=2.212, w2v_ctc_loss=0.681, task_loss=0, contrastive_loss=0.08, total=4103.34, n_correct=2634.7, ppl=4.63, accuracy=64.209, wps=14667.3, ups=1.79, wpb=8206.7, bsz=301, num_updates=30400, lr=8.11107e-05, gnorm=0.585, clip=0, loss_scale=32, train_wall=55, gb_free=14.4, wall=21814
2023-07-25 04:56:01 | INFO | train_inner | epoch 021:   1034 / 1474 loss=2.089, trans_loss=5.031, nll_loss=2.233, w2v_ctc_loss=0.682, task_loss=0, contrastive_loss=0.078, total=4099.86, n_correct=2623.61, ppl=4.7, accuracy=63.993, wps=14681.9, ups=1.79, wpb=8199.7, bsz=298.8, num_updates=30500, lr=8.09776e-05, gnorm=0.586, clip=0, loss_scale=32, train_wall=55, gb_free=12, wall=21870
2023-07-25 04:56:57 | INFO | train_inner | epoch 021:   1134 / 1474 loss=2.087, trans_loss=5.022, nll_loss=2.22, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.08, total=4120.75, n_correct=2643.15, ppl=4.66, accuracy=64.142, wps=14781.7, ups=1.79, wpb=8241.5, bsz=293.5, num_updates=30600, lr=8.08452e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=55, gb_free=16.1, wall=21925
2023-07-25 04:57:52 | INFO | train_inner | epoch 021:   1234 / 1474 loss=2.088, trans_loss=5.02, nll_loss=2.22, w2v_ctc_loss=0.678, task_loss=0, contrastive_loss=0.134, total=4154.73, n_correct=2665.53, ppl=4.66, accuracy=64.157, wps=14907.6, ups=1.79, wpb=8309.5, bsz=311.6, num_updates=30700, lr=8.07134e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=55, gb_free=13.1, wall=21981
2023-07-25 04:58:48 | INFO | train_inner | epoch 021:   1334 / 1474 loss=2.09, trans_loss=5.025, nll_loss=2.227, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.094, total=4147.17, n_correct=2661.87, ppl=4.68, accuracy=64.185, wps=14832.6, ups=1.79, wpb=8294.3, bsz=311.9, num_updates=30800, lr=8.05823e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=55, gb_free=16.5, wall=22037
2023-07-25 04:59:45 | INFO | train_inner | epoch 021:   1434 / 1474 loss=2.106, trans_loss=5.036, nll_loss=2.24, w2v_ctc_loss=0.699, task_loss=0, contrastive_loss=0.146, total=4133.93, n_correct=2633.55, ppl=4.72, accuracy=63.706, wps=14641, ups=1.77, wpb=8267.9, bsz=304.5, num_updates=30900, lr=8.04518e-05, gnorm=0.591, clip=0, loss_scale=64, train_wall=56, gb_free=15.9, wall=22094
2023-07-25 05:00:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:2')
2023-07-25 05:00:30 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.362 | trans_loss 5.588 | nll_loss 2.872 | w2v_ctc_loss 1.375 | task_loss 0 | contrastive_loss 0.278 | total 4003.4 | n_correct 2467 | ppl 7.32 | accuracy 61.623 | uer 17.384 | wer 19.47 | raw_wer 19.47 | bleu 19.42 | wps 2286.7 | wpb 4003.4 | bsz 141.8 | num_updates 30940 | best_bleu 19.9
2023-07-25 05:00:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30940 updates
2023-07-25 05:00:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_last.pt
2023-07-25 05:00:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_last.pt
2023-07-25 05:00:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_last.pt (epoch 21 @ 30940 updates, score 19.42) (writing took 10.815866077318788 seconds)
2023-07-25 05:00:41 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-07-25 05:00:41 | INFO | train | epoch 021 | loss 2.086 | trans_loss 5.015 | nll_loss 2.212 | w2v_ctc_loss 0.679 | task_loss 0 | contrastive_loss 0.12 | total 4138.65 | n_correct 2659.5 | ppl 4.63 | accuracy 64.26 | wps 13433.4 | ups 1.62 | wpb 8277.3 | bsz 305.7 | num_updates 30940 | lr 8.03998e-05 | gnorm 0.583 | clip 0 | loss_scale 64 | train_wall 821 | gb_free 15.7 | wall 22149
2023-07-25 05:00:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 05:00:41 | INFO | fairseq.trainer | begin training epoch 22
2023-07-25 05:00:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 05:01:23 | INFO | train_inner | epoch 022:     60 / 1474 loss=2.076, trans_loss=5.003, nll_loss=2.196, w2v_ctc_loss=0.68, task_loss=0, contrastive_loss=0.06, total=4128.84, n_correct=2667.61, ppl=4.58, accuracy=64.609, wps=8414.6, ups=1.02, wpb=8257.7, bsz=297.7, num_updates=31000, lr=8.03219e-05, gnorm=0.586, clip=0, loss_scale=64, train_wall=56, gb_free=14.6, wall=22192
2023-07-25 05:02:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-25 05:02:19 | INFO | train_inner | epoch 022:    161 / 1474 loss=2.076, trans_loss=4.99, nll_loss=2.179, w2v_ctc_loss=0.673, task_loss=0, contrastive_loss=0.146, total=4122.48, n_correct=2668.06, ppl=4.53, accuracy=64.72, wps=14555.7, ups=1.77, wpb=8245, bsz=309.7, num_updates=31100, lr=8.01927e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=56, gb_free=17, wall=22248
2023-07-25 05:03:16 | INFO | train_inner | epoch 022:    261 / 1474 loss=2.063, trans_loss=4.984, nll_loss=2.173, w2v_ctc_loss=0.659, task_loss=0, contrastive_loss=0.087, total=4272.11, n_correct=2776.77, ppl=4.51, accuracy=64.998, wps=15204.2, ups=1.78, wpb=8544.2, bsz=331.4, num_updates=31200, lr=8.00641e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=56, gb_free=18.1, wall=22305
2023-07-25 05:04:13 | INFO | train_inner | epoch 022:    361 / 1474 loss=2.091, trans_loss=5.002, nll_loss=2.196, w2v_ctc_loss=0.677, task_loss=0, contrastive_loss=0.249, total=4178.4, n_correct=2692.46, ppl=4.58, accuracy=64.438, wps=14652.2, ups=1.75, wpb=8356.8, bsz=310, num_updates=31300, lr=7.99361e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=57, gb_free=15.5, wall=22362
2023-07-25 05:05:09 | INFO | train_inner | epoch 022:    461 / 1474 loss=2.082, trans_loss=5.006, nll_loss=2.199, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.127, total=4132.96, n_correct=2664.97, ppl=4.59, accuracy=64.481, wps=14730.9, ups=1.78, wpb=8265.9, bsz=297.5, num_updates=31400, lr=7.98087e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=56, gb_free=17.3, wall=22418
2023-07-25 05:06:05 | INFO | train_inner | epoch 022:    561 / 1474 loss=2.074, trans_loss=4.999, nll_loss=2.191, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.074, total=4158.17, n_correct=2688.91, ppl=4.57, accuracy=64.666, wps=14701, ups=1.77, wpb=8316.3, bsz=307.8, num_updates=31500, lr=7.96819e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=22474
2023-07-25 05:07:01 | INFO | train_inner | epoch 022:    661 / 1474 loss=2.07, trans_loss=4.992, nll_loss=2.183, w2v_ctc_loss=0.659, task_loss=0, contrastive_loss=0.154, total=4139.66, n_correct=2682.76, ppl=4.54, accuracy=64.806, wps=14890.7, ups=1.8, wpb=8279.3, bsz=311.1, num_updates=31600, lr=7.95557e-05, gnorm=0.586, clip=0, loss_scale=32, train_wall=55, gb_free=16.4, wall=22530
2023-07-25 05:07:57 | INFO | train_inner | epoch 022:    761 / 1474 loss=2.076, trans_loss=5.001, nll_loss=2.194, w2v_ctc_loss=0.679, task_loss=0, contrastive_loss=0.075, total=4167.89, n_correct=2690.9, ppl=4.58, accuracy=64.563, wps=14887.4, ups=1.79, wpb=8335.8, bsz=303.9, num_updates=31700, lr=7.94301e-05, gnorm=0.585, clip=0, loss_scale=32, train_wall=55, gb_free=13.3, wall=22586
2023-07-25 05:08:53 | INFO | train_inner | epoch 022:    861 / 1474 loss=2.08, trans_loss=5.014, nll_loss=2.211, w2v_ctc_loss=0.679, task_loss=0, contrastive_loss=0.06, total=4075.79, n_correct=2620.09, ppl=4.63, accuracy=64.284, wps=14591.2, ups=1.79, wpb=8151.6, bsz=289, num_updates=31800, lr=7.93052e-05, gnorm=0.587, clip=0, loss_scale=32, train_wall=55, gb_free=16.6, wall=22642
2023-07-25 05:09:49 | INFO | train_inner | epoch 022:    961 / 1474 loss=2.072, trans_loss=5.006, nll_loss=2.201, w2v_ctc_loss=0.668, task_loss=0, contrastive_loss=0.061, total=4134.72, n_correct=2669.32, ppl=4.6, accuracy=64.559, wps=14686.7, ups=1.78, wpb=8269.4, bsz=303.2, num_updates=31900, lr=7.91808e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=56, gb_free=14.7, wall=22698
2023-07-25 05:10:45 | INFO | train_inner | epoch 022:   1061 / 1474 loss=2.084, trans_loss=5.006, nll_loss=2.201, w2v_ctc_loss=0.668, task_loss=0, contrastive_loss=0.231, total=4160.57, n_correct=2683.64, ppl=4.6, accuracy=64.502, wps=14926.7, ups=1.79, wpb=8321.1, bsz=315.5, num_updates=32000, lr=7.90569e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=55, gb_free=17.5, wall=22754
2023-07-25 05:10:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 05:11:07 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.355 | trans_loss 5.583 | nll_loss 2.862 | w2v_ctc_loss 1.371 | task_loss 0 | contrastive_loss 0.266 | total 4003.4 | n_correct 2474 | ppl 7.27 | accuracy 61.797 | uer 17.235 | wer 19.09 | raw_wer 19.09 | bleu 20.08 | wps 2330.3 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.08
2023-07-25 05:11:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-07-25 05:11:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_22_32000.pt
2023-07-25 05:11:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_22_32000.pt
2023-07-25 05:11:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 20.08) (writing took 20.88949554786086 seconds)
2023-07-25 05:12:25 | INFO | train_inner | epoch 022:   1161 / 1474 loss=2.091, trans_loss=5.028, nll_loss=2.23, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.111, total=4099.59, n_correct=2623.4, ppl=4.69, accuracy=63.992, wps=8183.5, ups=1, wpb=8199.2, bsz=296.2, num_updates=32100, lr=7.89337e-05, gnorm=0.586, clip=0, loss_scale=32, train_wall=55, gb_free=15.4, wall=22854
2023-07-25 05:13:22 | INFO | train_inner | epoch 022:   1261 / 1474 loss=2.086, trans_loss=5.019, nll_loss=2.22, w2v_ctc_loss=0.678, task_loss=0, contrastive_loss=0.111, total=4182.05, n_correct=2687.31, ppl=4.66, accuracy=64.258, wps=14787.5, ups=1.77, wpb=8364.1, bsz=323, num_updates=32200, lr=7.8811e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=56, gb_free=15.8, wall=22911
2023-07-25 05:14:18 | INFO | train_inner | epoch 022:   1361 / 1474 loss=2.077, trans_loss=5.011, nll_loss=2.208, w2v_ctc_loss=0.666, task_loss=0, contrastive_loss=0.128, total=4062.31, n_correct=2617.97, ppl=4.62, accuracy=64.445, wps=14434.6, ups=1.78, wpb=8124.6, bsz=299, num_updates=32300, lr=7.86889e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=56, gb_free=15.4, wall=22967
2023-07-25 05:15:14 | INFO | train_inner | epoch 022:   1461 / 1474 loss=2.088, trans_loss=5.029, nll_loss=2.23, w2v_ctc_loss=0.686, task_loss=0, contrastive_loss=0.077, total=4081.88, n_correct=2614.53, ppl=4.69, accuracy=64.052, wps=14519.5, ups=1.78, wpb=8163.8, bsz=288.9, num_updates=32400, lr=7.85674e-05, gnorm=0.585, clip=0, loss_scale=32, train_wall=56, gb_free=17.5, wall=23023
2023-07-25 05:15:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 05:15:43 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.342 | trans_loss 5.576 | nll_loss 2.852 | w2v_ctc_loss 1.348 | task_loss 0 | contrastive_loss 0.258 | total 4003.4 | n_correct 2481.5 | ppl 7.22 | accuracy 61.985 | uer 17.132 | wer 19.052 | raw_wer 19.052 | bleu 20.27 | wps 2397.9 | wpb 4003.4 | bsz 141.8 | num_updates 32413 | best_bleu 20.27
2023-07-25 05:15:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32413 updates
2023-07-25 05:15:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 05:15:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 05:16:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt (epoch 22 @ 32413 updates, score 20.27) (writing took 19.187542274594307 seconds)
2023-07-25 05:16:03 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-07-25 05:16:03 | INFO | train | epoch 022 | loss 2.079 | trans_loss 5.005 | nll_loss 2.2 | w2v_ctc_loss 0.674 | task_loss 0 | contrastive_loss 0.119 | total 4138.77 | n_correct 2669.65 | ppl 4.6 | accuracy 64.503 | wps 13217.4 | ups 1.6 | wpb 8277.5 | bsz 305.7 | num_updates 32413 | lr 7.85517e-05 | gnorm 0.584 | clip 0 | loss_scale 32 | train_wall 821 | gb_free 12.3 | wall 23072
2023-07-25 05:16:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 05:16:03 | INFO | fairseq.trainer | begin training epoch 23
2023-07-25 05:16:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 05:17:00 | INFO | train_inner | epoch 023:     87 / 1474 loss=2.065, trans_loss=4.982, nll_loss=2.169, w2v_ctc_loss=0.672, task_loss=0, contrastive_loss=0.069, total=4096.09, n_correct=2663.16, ppl=4.5, accuracy=65.017, wps=7719.2, ups=0.94, wpb=8192.2, bsz=301.2, num_updates=32500, lr=7.84465e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=55, gb_free=16.6, wall=23129
2023-07-25 05:17:56 | INFO | train_inner | epoch 023:    187 / 1474 loss=2.06, trans_loss=4.978, nll_loss=2.163, w2v_ctc_loss=0.661, task_loss=0, contrastive_loss=0.065, total=4107.77, n_correct=2671.03, ppl=4.48, accuracy=65.024, wps=14649.1, ups=1.78, wpb=8215.5, bsz=293.4, num_updates=32600, lr=7.8326e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=56, gb_free=16.7, wall=23185
2023-07-25 05:18:52 | INFO | train_inner | epoch 023:    287 / 1474 loss=2.067, trans_loss=4.986, nll_loss=2.175, w2v_ctc_loss=0.655, task_loss=0, contrastive_loss=0.144, total=4153.12, n_correct=2692.71, ppl=4.51, accuracy=64.836, wps=14876.2, ups=1.79, wpb=8306.2, bsz=306.4, num_updates=32700, lr=7.82062e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=55, gb_free=17.2, wall=23241
2023-07-25 05:19:49 | INFO | train_inner | epoch 023:    387 / 1474 loss=2.063, trans_loss=4.987, nll_loss=2.175, w2v_ctc_loss=0.663, task_loss=0, contrastive_loss=0.057, total=4116.7, n_correct=2671.59, ppl=4.52, accuracy=64.896, wps=14644.1, ups=1.78, wpb=8233.4, bsz=294, num_updates=32800, lr=7.80869e-05, gnorm=0.585, clip=0, loss_scale=32, train_wall=56, gb_free=15.7, wall=23297
2023-07-25 05:20:44 | INFO | train_inner | epoch 023:    487 / 1474 loss=2.073, trans_loss=4.992, nll_loss=2.183, w2v_ctc_loss=0.667, task_loss=0, contrastive_loss=0.118, total=4157.6, n_correct=2690.65, ppl=4.54, accuracy=64.716, wps=14912, ups=1.79, wpb=8315.2, bsz=313.5, num_updates=32900, lr=7.79681e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=55, gb_free=17.6, wall=23353
2023-07-25 05:21:40 | INFO | train_inner | epoch 023:    587 / 1474 loss=2.059, trans_loss=4.982, nll_loss=2.169, w2v_ctc_loss=0.659, task_loss=0, contrastive_loss=0.062, total=4173.42, n_correct=2712.82, ppl=4.5, accuracy=65.002, wps=14943.7, ups=1.79, wpb=8346.8, bsz=316, num_updates=33000, lr=7.78499e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=55, gb_free=13.1, wall=23409
2023-07-25 05:22:37 | INFO | train_inner | epoch 023:    687 / 1474 loss=2.066, trans_loss=4.989, nll_loss=2.178, w2v_ctc_loss=0.662, task_loss=0, contrastive_loss=0.103, total=4137.82, n_correct=2685.33, ppl=4.53, accuracy=64.897, wps=14674, ups=1.77, wpb=8275.6, bsz=302.5, num_updates=33100, lr=7.77322e-05, gnorm=0.586, clip=0, loss_scale=32, train_wall=56, gb_free=17.4, wall=23465
2023-07-25 05:23:32 | INFO | train_inner | epoch 023:    787 / 1474 loss=2.073, trans_loss=5, nll_loss=2.193, w2v_ctc_loss=0.669, task_loss=0, contrastive_loss=0.084, total=4150.99, n_correct=2685.05, ppl=4.57, accuracy=64.685, wps=14840, ups=1.79, wpb=8302, bsz=305.4, num_updates=33200, lr=7.76151e-05, gnorm=0.581, clip=0, loss_scale=64, train_wall=55, gb_free=16.5, wall=23521
2023-07-25 05:24:28 | INFO | train_inner | epoch 023:    887 / 1474 loss=2.075, trans_loss=4.994, nll_loss=2.187, w2v_ctc_loss=0.667, task_loss=0, contrastive_loss=0.164, total=4181.99, n_correct=2709.61, ppl=4.55, accuracy=64.792, wps=14943.1, ups=1.79, wpb=8364, bsz=324.7, num_updates=33300, lr=7.74984e-05, gnorm=0.578, clip=0, loss_scale=64, train_wall=55, gb_free=16.7, wall=23577
2023-07-25 05:25:25 | INFO | train_inner | epoch 023:    987 / 1474 loss=2.081, trans_loss=4.997, nll_loss=2.191, w2v_ctc_loss=0.657, task_loss=0, contrastive_loss=0.316, total=4168.73, n_correct=2695.49, ppl=4.56, accuracy=64.66, wps=14845.8, ups=1.78, wpb=8337.5, bsz=310.5, num_updates=33400, lr=7.73823e-05, gnorm=0.582, clip=0, loss_scale=64, train_wall=56, gb_free=11.5, wall=23633
2023-07-25 05:26:21 | INFO | train_inner | epoch 023:   1087 / 1474 loss=2.076, trans_loss=5.006, nll_loss=2.2, w2v_ctc_loss=0.677, task_loss=0, contrastive_loss=0.07, total=4088.49, n_correct=2640.99, ppl=4.6, accuracy=64.596, wps=14463.1, ups=1.77, wpb=8177, bsz=290, num_updates=33500, lr=7.72667e-05, gnorm=0.587, clip=0, loss_scale=64, train_wall=56, gb_free=16.1, wall=23690
2023-07-25 05:27:17 | INFO | train_inner | epoch 023:   1187 / 1474 loss=2.07, trans_loss=5.003, nll_loss=2.198, w2v_ctc_loss=0.669, task_loss=0, contrastive_loss=0.062, total=4162.7, n_correct=2688.85, ppl=4.59, accuracy=64.594, wps=14904.5, ups=1.79, wpb=8325.4, bsz=309.3, num_updates=33600, lr=7.71517e-05, gnorm=0.583, clip=0, loss_scale=64, train_wall=55, gb_free=16.3, wall=23746
2023-07-25 05:28:13 | INFO | train_inner | epoch 023:   1287 / 1474 loss=2.068, trans_loss=5.002, nll_loss=2.197, w2v_ctc_loss=0.66, task_loss=0, contrastive_loss=0.077, total=4135.53, n_correct=2679.65, ppl=4.59, accuracy=64.796, wps=14876, ups=1.8, wpb=8271.1, bsz=308.9, num_updates=33700, lr=7.70371e-05, gnorm=0.586, clip=0, loss_scale=64, train_wall=55, gb_free=17.1, wall=23801
2023-07-25 05:29:09 | INFO | train_inner | epoch 023:   1387 / 1474 loss=2.085, trans_loss=5.022, nll_loss=2.222, w2v_ctc_loss=0.673, task_loss=0, contrastive_loss=0.132, total=4143.98, n_correct=2663.75, ppl=4.67, accuracy=64.28, wps=14630.5, ups=1.77, wpb=8288, bsz=305.2, num_updates=33800, lr=7.69231e-05, gnorm=0.589, clip=0, loss_scale=64, train_wall=56, gb_free=16.2, wall=23858
2023-07-25 05:29:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 05:30:20 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.353 | trans_loss 5.574 | nll_loss 2.854 | w2v_ctc_loss 1.384 | task_loss 0 | contrastive_loss 0.268 | total 4003.4 | n_correct 2483.8 | ppl 7.23 | accuracy 62.042 | uer 16.917 | wer 18.855 | raw_wer 18.855 | bleu 19.69 | wps 2390.3 | wpb 4003.4 | bsz 141.8 | num_updates 33887 | best_bleu 20.27
2023-07-25 05:30:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33887 updates
2023-07-25 05:30:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_last.pt
2023-07-25 05:30:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_last.pt
2023-07-25 05:30:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_last.pt (epoch 23 @ 33887 updates, score 19.69) (writing took 10.257140019908547 seconds)
2023-07-25 05:30:30 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-07-25 05:30:30 | INFO | train | epoch 023 | loss 2.071 | trans_loss 4.996 | nll_loss 2.188 | w2v_ctc_loss 0.665 | task_loss 0 | contrastive_loss 0.117 | total 4138.65 | n_correct 2679.42 | ppl 4.56 | accuracy 64.741 | wps 14067.6 | ups 1.7 | wpb 8277.3 | bsz 305.7 | num_updates 33887 | lr 7.68243e-05 | gnorm 0.585 | clip 0 | loss_scale 64 | train_wall 819 | gb_free 14.1 | wall 23939
2023-07-25 05:30:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 05:30:31 | INFO | fairseq.trainer | begin training epoch 24
2023-07-25 05:30:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 05:30:47 | INFO | train_inner | epoch 024:     13 / 1474 loss=2.087, trans_loss=5.012, nll_loss=2.211, w2v_ctc_loss=0.665, task_loss=0, contrastive_loss=0.213, total=4085.11, n_correct=2631, ppl=4.63, accuracy=64.405, wps=8382.6, ups=1.03, wpb=8170.2, bsz=304.2, num_updates=33900, lr=7.68095e-05, gnorm=0.595, clip=0, loss_scale=64, train_wall=56, gb_free=13.1, wall=23956
2023-07-25 05:31:42 | INFO | train_inner | epoch 024:    113 / 1474 loss=2.066, trans_loss=4.968, nll_loss=2.151, w2v_ctc_loss=0.653, task_loss=0, contrastive_loss=0.23, total=4171.44, n_correct=2719.71, ppl=4.44, accuracy=65.198, wps=15014.8, ups=1.8, wpb=8342.9, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.583, clip=0, loss_scale=64, train_wall=55, gb_free=16.7, wall=24011
2023-07-25 05:31:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 05:32:04 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.352 | trans_loss 5.589 | nll_loss 2.867 | w2v_ctc_loss 1.348 | task_loss 0 | contrastive_loss 0.269 | total 4003.4 | n_correct 2478.5 | ppl 7.29 | accuracy 61.91 | uer 16.988 | wer 18.903 | raw_wer 18.903 | bleu 19.76 | wps 2330.3 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.27
2023-07-25 05:32:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-07-25 05:32:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_24_34000.pt
2023-07-25 05:32:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_24_34000.pt
2023-07-25 05:32:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 19.76) (writing took 15.698540136218071 seconds)
2023-07-25 05:32:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-25 05:33:17 | INFO | train_inner | epoch 024:    214 / 1474 loss=2.06, trans_loss=4.974, nll_loss=2.16, w2v_ctc_loss=0.651, task_loss=0, contrastive_loss=0.135, total=4215.87, n_correct=2749.55, ppl=4.47, accuracy=65.219, wps=8892.2, ups=1.05, wpb=8431.7, bsz=328.2, num_updates=34100, lr=7.6584e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=57, gb_free=17.1, wall=24106
2023-07-25 05:34:13 | INFO | train_inner | epoch 024:    314 / 1474 loss=2.055, trans_loss=4.977, nll_loss=2.163, w2v_ctc_loss=0.656, task_loss=0, contrastive_loss=0.058, total=4138.44, n_correct=2694.96, ppl=4.48, accuracy=65.12, wps=14764.3, ups=1.78, wpb=8276.9, bsz=307.1, num_updates=34200, lr=7.64719e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=55, gb_free=15.8, wall=24162
2023-07-25 05:35:10 | INFO | train_inner | epoch 024:    414 / 1474 loss=2.077, trans_loss=4.983, nll_loss=2.171, w2v_ctc_loss=0.669, task_loss=0, contrastive_loss=0.208, total=4153.83, n_correct=2693.35, ppl=4.5, accuracy=64.84, wps=14730.6, ups=1.77, wpb=8307.7, bsz=298.4, num_updates=34300, lr=7.63604e-05, gnorm=0.592, clip=0, loss_scale=32, train_wall=56, gb_free=16.4, wall=24218
2023-07-25 05:36:05 | INFO | train_inner | epoch 024:    514 / 1474 loss=2.063, trans_loss=4.981, nll_loss=2.168, w2v_ctc_loss=0.659, task_loss=0, contrastive_loss=0.126, total=4141.88, n_correct=2692.97, ppl=4.49, accuracy=65.018, wps=14829, ups=1.79, wpb=8283.8, bsz=302.6, num_updates=34400, lr=7.62493e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=55, gb_free=15.5, wall=24274
2023-07-25 05:37:02 | INFO | train_inner | epoch 024:    614 / 1474 loss=2.059, trans_loss=4.982, nll_loss=2.17, w2v_ctc_loss=0.651, task_loss=0, contrastive_loss=0.095, total=4162.06, n_correct=2706.86, ppl=4.5, accuracy=65.037, wps=14852.7, ups=1.78, wpb=8324.1, bsz=308.1, num_updates=34500, lr=7.61387e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=56, gb_free=17.1, wall=24330
2023-07-25 05:37:58 | INFO | train_inner | epoch 024:    714 / 1474 loss=2.066, trans_loss=4.993, nll_loss=2.183, w2v_ctc_loss=0.661, task_loss=0, contrastive_loss=0.103, total=4097.35, n_correct=2660.37, ppl=4.54, accuracy=64.929, wps=14631.3, ups=1.79, wpb=8194.7, bsz=293.8, num_updates=34600, lr=7.60286e-05, gnorm=0.594, clip=0, loss_scale=32, train_wall=56, gb_free=17.6, wall=24386
2023-07-25 05:38:54 | INFO | train_inner | epoch 024:    814 / 1474 loss=2.065, trans_loss=4.995, nll_loss=2.188, w2v_ctc_loss=0.659, task_loss=0, contrastive_loss=0.083, total=4124.25, n_correct=2674.54, ppl=4.56, accuracy=64.849, wps=14736.3, ups=1.79, wpb=8248.5, bsz=308.2, num_updates=34700, lr=7.5919e-05, gnorm=0.587, clip=0, loss_scale=32, train_wall=55, gb_free=16.3, wall=24442
2023-07-25 05:39:49 | INFO | train_inner | epoch 024:    914 / 1474 loss=2.069, trans_loss=5.001, nll_loss=2.193, w2v_ctc_loss=0.668, task_loss=0, contrastive_loss=0.053, total=4041.44, n_correct=2607.85, ppl=4.57, accuracy=64.528, wps=14587.7, ups=1.8, wpb=8082.9, bsz=280.5, num_updates=34800, lr=7.58098e-05, gnorm=0.596, clip=0, loss_scale=32, train_wall=55, gb_free=16.4, wall=24498
2023-07-25 05:40:45 | INFO | train_inner | epoch 024:   1014 / 1474 loss=2.062, trans_loss=4.995, nll_loss=2.186, w2v_ctc_loss=0.66, task_loss=0, contrastive_loss=0.058, total=4128.8, n_correct=2678.29, ppl=4.55, accuracy=64.868, wps=14717, ups=1.78, wpb=8257.6, bsz=296.5, num_updates=34900, lr=7.57011e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=56, gb_free=15.4, wall=24554
2023-07-25 05:41:41 | INFO | train_inner | epoch 024:   1114 / 1474 loss=2.065, trans_loss=4.984, nll_loss=2.174, w2v_ctc_loss=0.666, task_loss=0, contrastive_loss=0.103, total=4130.49, n_correct=2683.12, ppl=4.51, accuracy=64.959, wps=14687.5, ups=1.78, wpb=8261, bsz=308.9, num_updates=35000, lr=7.55929e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=56, gb_free=16.3, wall=24610
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:0')
2023-07-25 05:42:37 | INFO | train_inner | epoch 024:   1214 / 1474 loss=2.065, trans_loss=4.994, nll_loss=2.187, w2v_ctc_loss=0.658, task_loss=0, contrastive_loss=0.095, total=4157.47, n_correct=2695.37, ppl=4.55, accuracy=64.832, wps=14877.3, ups=1.79, wpb=8314.9, bsz=311.2, num_updates=35100, lr=7.54851e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=55, gb_free=13.2, wall=24666
2023-07-25 05:43:33 | INFO | train_inner | epoch 024:   1314 / 1474 loss=2.073, trans_loss=5.005, nll_loss=2.199, w2v_ctc_loss=0.674, task_loss=0, contrastive_loss=0.064, total=4107.23, n_correct=2649.97, ppl=4.59, accuracy=64.52, wps=14702.4, ups=1.79, wpb=8214.5, bsz=294.3, num_updates=35200, lr=7.53778e-05, gnorm=0.589, clip=0, loss_scale=32, train_wall=55, gb_free=17.8, wall=24722
2023-07-25 05:44:29 | INFO | train_inner | epoch 024:   1414 / 1474 loss=2.071, trans_loss=5.004, nll_loss=2.2, w2v_ctc_loss=0.671, task_loss=0, contrastive_loss=0.062, total=4094.39, n_correct=2644.53, ppl=4.59, accuracy=64.589, wps=14722.3, ups=1.8, wpb=8188.8, bsz=292.9, num_updates=35300, lr=7.5271e-05, gnorm=0.587, clip=0, loss_scale=32, train_wall=55, gb_free=16.5, wall=24778
2023-07-25 05:45:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:2')
2023-07-25 05:45:25 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.361 | trans_loss 5.582 | nll_loss 2.86 | w2v_ctc_loss 1.393 | task_loss 0 | contrastive_loss 0.266 | total 4003.4 | n_correct 2481.3 | ppl 7.26 | accuracy 61.98 | uer 17.004 | wer 18.888 | raw_wer 18.888 | bleu 19.91 | wps 2212.2 | wpb 4003.4 | bsz 141.8 | num_updates 35360 | best_bleu 20.27
2023-07-25 05:45:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35360 updates
2023-07-25 05:45:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_19.9109.pt
2023-07-25 05:45:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_19.9109.pt
2023-07-25 05:45:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_19.9109.pt (epoch 24 @ 35360 updates, score 19.91) (writing took 11.134812934324145 seconds)
2023-07-25 05:45:37 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-07-25 05:45:37 | INFO | train | epoch 024 | loss 2.065 | trans_loss 4.988 | nll_loss 2.178 | w2v_ctc_loss 0.661 | task_loss 0 | contrastive_loss 0.105 | total 4136.37 | n_correct 2684.81 | ppl 4.52 | accuracy 64.907 | wps 13441.8 | ups 1.62 | wpb 8272.7 | bsz 304.8 | num_updates 35360 | lr 7.52071e-05 | gnorm 0.586 | clip 0 | loss_scale 32 | train_wall 818 | gb_free 16.4 | wall 24846
2023-07-25 05:45:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 05:45:37 | INFO | fairseq.trainer | begin training epoch 25
2023-07-25 05:45:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 05:46:08 | INFO | train_inner | epoch 025:     40 / 1474 loss=2.053, trans_loss=4.976, nll_loss=2.164, w2v_ctc_loss=0.653, task_loss=0, contrastive_loss=0.07, total=4165.57, n_correct=2717.82, ppl=4.48, accuracy=65.245, wps=8395.6, ups=1.01, wpb=8331.1, bsz=311.2, num_updates=35400, lr=7.51646e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=56, gb_free=13.6, wall=24877
2023-07-25 05:47:04 | INFO | train_inner | epoch 025:    140 / 1474 loss=2.043, trans_loss=4.956, nll_loss=2.135, w2v_ctc_loss=0.645, task_loss=0, contrastive_loss=0.069, total=4135.43, n_correct=2711.38, ppl=4.39, accuracy=65.565, wps=14866.7, ups=1.8, wpb=8270.9, bsz=308.9, num_updates=35500, lr=7.50587e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=55, gb_free=18, wall=24932
2023-07-25 05:48:00 | INFO | train_inner | epoch 025:    240 / 1474 loss=2.049, trans_loss=4.964, nll_loss=2.146, w2v_ctc_loss=0.65, task_loss=0, contrastive_loss=0.073, total=4116.13, n_correct=2689.88, ppl=4.43, accuracy=65.35, wps=14615, ups=1.78, wpb=8232.3, bsz=303, num_updates=35600, lr=7.49532e-05, gnorm=0.594, clip=0, loss_scale=32, train_wall=56, gb_free=17.6, wall=24989
2023-07-25 05:48:57 | INFO | train_inner | epoch 025:    340 / 1474 loss=2.056, trans_loss=4.971, nll_loss=2.154, w2v_ctc_loss=0.652, task_loss=0, contrastive_loss=0.1, total=4141.49, n_correct=2696.59, ppl=4.45, accuracy=65.112, wps=14580.3, ups=1.76, wpb=8283, bsz=294.2, num_updates=35700, lr=7.48481e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=56, gb_free=15.5, wall=25046
2023-07-25 05:49:53 | INFO | train_inner | epoch 025:    440 / 1474 loss=2.07, trans_loss=4.974, nll_loss=2.159, w2v_ctc_loss=0.67, task_loss=0, contrastive_loss=0.18, total=4167.4, n_correct=2714.55, ppl=4.47, accuracy=65.138, wps=14774.2, ups=1.77, wpb=8334.8, bsz=297.7, num_updates=35800, lr=7.47435e-05, gnorm=0.591, clip=0, loss_scale=32, train_wall=56, gb_free=16.1, wall=25102
2023-07-25 05:50:49 | INFO | train_inner | epoch 025:    540 / 1474 loss=2.059, trans_loss=4.981, nll_loss=2.169, w2v_ctc_loss=0.658, task_loss=0, contrastive_loss=0.073, total=4160.61, n_correct=2711.38, ppl=4.5, accuracy=65.168, wps=14882.6, ups=1.79, wpb=8321.2, bsz=313.9, num_updates=35900, lr=7.46393e-05, gnorm=0.589, clip=0, loss_scale=32, train_wall=55, gb_free=17.8, wall=25158
2023-07-25 05:51:45 | INFO | train_inner | epoch 025:    640 / 1474 loss=2.061, trans_loss=4.973, nll_loss=2.159, w2v_ctc_loss=0.659, task_loss=0, contrastive_loss=0.139, total=4153.68, n_correct=2706.75, ppl=4.46, accuracy=65.165, wps=14742.8, ups=1.77, wpb=8307.4, bsz=309.6, num_updates=36000, lr=7.45356e-05, gnorm=0.589, clip=0, loss_scale=32, train_wall=56, gb_free=16.8, wall=25214
2023-07-25 05:51:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 05:52:07 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.357 | trans_loss 5.579 | nll_loss 2.854 | w2v_ctc_loss 1.39 | task_loss 0 | contrastive_loss 0.263 | total 4003.4 | n_correct 2482.7 | ppl 7.23 | accuracy 62.015 | uer 17.041 | wer 18.952 | raw_wer 18.952 | bleu 20.28 | wps 2300.2 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.28
2023-07-25 05:52:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-07-25 05:52:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_25_36000.pt
2023-07-25 05:52:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_25_36000.pt
2023-07-25 05:52:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 20.28) (writing took 20.239312244579196 seconds)
2023-07-25 05:53:25 | INFO | train_inner | epoch 025:    740 / 1474 loss=2.062, trans_loss=4.976, nll_loss=2.163, w2v_ctc_loss=0.658, task_loss=0, contrastive_loss=0.135, total=4128.34, n_correct=2685.7, ppl=4.48, accuracy=65.055, wps=8292.6, ups=1, wpb=8256.7, bsz=301.3, num_updates=36100, lr=7.44323e-05, gnorm=0.589, clip=0, loss_scale=64, train_wall=56, gb_free=17.3, wall=25314
2023-07-25 05:54:21 | INFO | train_inner | epoch 025:    840 / 1474 loss=2.057, trans_loss=4.981, nll_loss=2.169, w2v_ctc_loss=0.652, task_loss=0, contrastive_loss=0.083, total=4182.4, n_correct=2725.13, ppl=4.5, accuracy=65.157, wps=14956.9, ups=1.79, wpb=8364.8, bsz=326, num_updates=36200, lr=7.43294e-05, gnorm=0.584, clip=0, loss_scale=64, train_wall=55, gb_free=18, wall=25370
2023-07-25 05:55:17 | INFO | train_inner | epoch 025:    940 / 1474 loss=2.064, trans_loss=4.983, nll_loss=2.174, w2v_ctc_loss=0.659, task_loss=0, contrastive_loss=0.139, total=4155.21, n_correct=2704.59, ppl=4.51, accuracy=65.089, wps=14814.8, ups=1.78, wpb=8310.4, bsz=317, num_updates=36300, lr=7.4227e-05, gnorm=0.588, clip=0, loss_scale=64, train_wall=56, gb_free=14.5, wall=25426
2023-07-25 05:56:13 | INFO | train_inner | epoch 025:   1040 / 1474 loss=2.07, trans_loss=4.991, nll_loss=2.183, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.249, total=4177.7, n_correct=2711.69, ppl=4.54, accuracy=64.909, wps=14830.2, ups=1.77, wpb=8355.4, bsz=309.8, num_updates=36400, lr=7.41249e-05, gnorm=0.579, clip=0, loss_scale=64, train_wall=56, gb_free=16, wall=25482
2023-07-25 05:57:09 | INFO | train_inner | epoch 025:   1140 / 1474 loss=2.052, trans_loss=4.984, nll_loss=2.173, w2v_ctc_loss=0.648, task_loss=0, contrastive_loss=0.053, total=4039.24, n_correct=2632.03, ppl=4.51, accuracy=65.162, wps=14413.2, ups=1.78, wpb=8078.5, bsz=285.2, num_updates=36500, lr=7.40233e-05, gnorm=0.593, clip=0, loss_scale=64, train_wall=56, gb_free=16.8, wall=25538
2023-07-25 05:58:05 | INFO | train_inner | epoch 025:   1240 / 1474 loss=2.057, trans_loss=4.989, nll_loss=2.179, w2v_ctc_loss=0.651, task_loss=0, contrastive_loss=0.063, total=4090.59, n_correct=2655.48, ppl=4.53, accuracy=64.917, wps=14752.7, ups=1.8, wpb=8181.2, bsz=295.7, num_updates=36600, lr=7.39221e-05, gnorm=0.583, clip=0, loss_scale=64, train_wall=55, gb_free=17.6, wall=25594
2023-07-25 05:59:01 | INFO | train_inner | epoch 025:   1340 / 1474 loss=2.067, trans_loss=4.987, nll_loss=2.178, w2v_ctc_loss=0.66, task_loss=0, contrastive_loss=0.158, total=4164.34, n_correct=2707.02, ppl=4.52, accuracy=65.005, wps=14773.2, ups=1.77, wpb=8328.7, bsz=310.1, num_updates=36700, lr=7.38213e-05, gnorm=0.589, clip=0, loss_scale=64, train_wall=56, gb_free=17.1, wall=25650
2023-07-25 05:59:58 | INFO | train_inner | epoch 025:   1440 / 1474 loss=2.073, trans_loss=5.005, nll_loss=2.2, w2v_ctc_loss=0.663, task_loss=0, contrastive_loss=0.109, total=4099.11, n_correct=2647.24, ppl=4.6, accuracy=64.581, wps=14535.8, ups=1.77, wpb=8198.2, bsz=299.3, num_updates=36800, lr=7.3721e-05, gnorm=0.591, clip=0, loss_scale=64, train_wall=56, gb_free=12.8, wall=25706
2023-07-25 06:00:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 06:00:39 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.356 | trans_loss 5.574 | nll_loss 2.853 | w2v_ctc_loss 1.392 | task_loss 0 | contrastive_loss 0.27 | total 4003.4 | n_correct 2484.8 | ppl 7.22 | accuracy 62.067 | uer 16.991 | wer 18.974 | raw_wer 18.974 | bleu 20.05 | wps 2114.7 | wpb 4003.4 | bsz 141.8 | num_updates 36834 | best_bleu 20.28
2023-07-25 06:00:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36834 updates
2023-07-25 06:00:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_20.0507.pt
2023-07-25 06:00:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_20.0507.pt
2023-07-25 06:00:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_20.0507.pt (epoch 25 @ 36834 updates, score 20.05) (writing took 11.774294693022966 seconds)
2023-07-25 06:00:51 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-07-25 06:00:51 | INFO | train | epoch 025 | loss 2.06 | trans_loss 4.98 | nll_loss 2.167 | w2v_ctc_loss 0.656 | task_loss 0 | contrastive_loss 0.115 | total 4138.65 | n_correct 2694.16 | ppl 4.49 | accuracy 65.098 | wps 13342.4 | ups 1.61 | wpb 8277.3 | bsz 305.7 | num_updates 36834 | lr 7.36869e-05 | gnorm 0.587 | clip 0 | loss_scale 64 | train_wall 821 | gb_free 14.7 | wall 25760
2023-07-25 06:00:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 06:00:52 | INFO | fairseq.trainer | begin training epoch 26
2023-07-25 06:00:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 06:01:37 | INFO | train_inner | epoch 026:     66 / 1474 loss=2.048, trans_loss=4.958, nll_loss=2.14, w2v_ctc_loss=0.648, task_loss=0, contrastive_loss=0.095, total=4180.21, n_correct=2737.18, ppl=4.41, accuracy=65.479, wps=8457.4, ups=1.01, wpb=8360.4, bsz=318.3, num_updates=36900, lr=7.3621e-05, gnorm=0.584, clip=0, loss_scale=64, train_wall=55, gb_free=17.2, wall=25805
2023-07-25 06:02:33 | INFO | train_inner | epoch 026:    166 / 1474 loss=2.056, trans_loss=4.956, nll_loss=2.137, w2v_ctc_loss=0.635, task_loss=0, contrastive_loss=0.28, total=4270.78, n_correct=2801.72, ppl=4.4, accuracy=65.602, wps=15196.3, ups=1.78, wpb=8541.6, bsz=340.4, num_updates=37000, lr=7.35215e-05, gnorm=0.579, clip=0, loss_scale=64, train_wall=56, gb_free=15.5, wall=25862
2023-07-25 06:03:29 | INFO | train_inner | epoch 026:    266 / 1474 loss=2.056, trans_loss=4.96, nll_loss=2.142, w2v_ctc_loss=0.656, task_loss=0, contrastive_loss=0.151, total=4125.04, n_correct=2698.88, ppl=4.41, accuracy=65.427, wps=14618.5, ups=1.77, wpb=8250.1, bsz=307.1, num_updates=37100, lr=7.34223e-05, gnorm=0.589, clip=0, loss_scale=64, train_wall=56, gb_free=15.6, wall=25918
2023-07-25 06:04:25 | INFO | train_inner | epoch 026:    366 / 1474 loss=2.051, trans_loss=4.961, nll_loss=2.143, w2v_ctc_loss=0.65, task_loss=0, contrastive_loss=0.112, total=4165.74, n_correct=2727.22, ppl=4.42, accuracy=65.468, wps=14884.8, ups=1.79, wpb=8331.5, bsz=314.7, num_updates=37200, lr=7.33236e-05, gnorm=0.59, clip=0, loss_scale=64, train_wall=56, gb_free=17, wall=25974
2023-07-25 06:05:21 | INFO | train_inner | epoch 026:    466 / 1474 loss=2.05, trans_loss=4.955, nll_loss=2.136, w2v_ctc_loss=0.646, task_loss=0, contrastive_loss=0.156, total=4170.23, n_correct=2734.77, ppl=4.4, accuracy=65.578, wps=15007, ups=1.8, wpb=8340.5, bsz=315.4, num_updates=37300, lr=7.32252e-05, gnorm=0.579, clip=0, loss_scale=64, train_wall=55, gb_free=18, wall=26030
2023-07-25 06:06:17 | INFO | train_inner | epoch 026:    566 / 1474 loss=2.055, trans_loss=4.971, nll_loss=2.155, w2v_ctc_loss=0.662, task_loss=0, contrastive_loss=0.076, total=4155.02, n_correct=2713.15, ppl=4.45, accuracy=65.298, wps=14809.5, ups=1.78, wpb=8310, bsz=303.9, num_updates=37400, lr=7.31272e-05, gnorm=0.589, clip=0, loss_scale=64, train_wall=56, gb_free=18.1, wall=26086
2023-07-25 06:07:13 | INFO | train_inner | epoch 026:    666 / 1474 loss=2.046, trans_loss=4.968, nll_loss=2.152, w2v_ctc_loss=0.643, task_loss=0, contrastive_loss=0.06, total=4136.96, n_correct=2702.28, ppl=4.44, accuracy=65.32, wps=14694.2, ups=1.78, wpb=8273.9, bsz=299.2, num_updates=37500, lr=7.30297e-05, gnorm=0.587, clip=0, loss_scale=64, train_wall=56, gb_free=15.7, wall=26142
2023-07-25 06:08:09 | INFO | train_inner | epoch 026:    766 / 1474 loss=2.062, trans_loss=4.975, nll_loss=2.162, w2v_ctc_loss=0.65, task_loss=0, contrastive_loss=0.176, total=4086.28, n_correct=2662.08, ppl=4.47, accuracy=65.147, wps=14509.1, ups=1.78, wpb=8172.6, bsz=298.5, num_updates=37600, lr=7.29325e-05, gnorm=0.597, clip=0, loss_scale=64, train_wall=56, gb_free=15.4, wall=26198
2023-07-25 06:09:05 | INFO | train_inner | epoch 026:    866 / 1474 loss=2.053, trans_loss=4.973, nll_loss=2.158, w2v_ctc_loss=0.654, task_loss=0, contrastive_loss=0.075, total=4183.26, n_correct=2727.53, ppl=4.46, accuracy=65.201, wps=15109.7, ups=1.81, wpb=8366.5, bsz=308.1, num_updates=37700, lr=7.28357e-05, gnorm=0.582, clip=0, loss_scale=64, train_wall=55, gb_free=17.6, wall=26254
2023-07-25 06:10:01 | INFO | train_inner | epoch 026:    966 / 1474 loss=2.055, trans_loss=4.981, nll_loss=2.169, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.129, total=4137.96, n_correct=2693.91, ppl=4.5, accuracy=65.102, wps=14708.2, ups=1.78, wpb=8275.9, bsz=299, num_updates=37800, lr=7.27393e-05, gnorm=0.59, clip=0, loss_scale=64, train_wall=56, gb_free=17.2, wall=26310
2023-07-25 06:10:57 | INFO | train_inner | epoch 026:   1066 / 1474 loss=2.05, trans_loss=4.976, nll_loss=2.163, w2v_ctc_loss=0.648, task_loss=0, contrastive_loss=0.059, total=4120.53, n_correct=2687.27, ppl=4.48, accuracy=65.217, wps=14715.7, ups=1.79, wpb=8241.1, bsz=294.3, num_updates=37900, lr=7.26433e-05, gnorm=0.585, clip=0, loss_scale=64, train_wall=55, gb_free=16.9, wall=26366
2023-07-25 06:11:54 | INFO | train_inner | epoch 026:   1166 / 1474 loss=2.059, trans_loss=4.985, nll_loss=2.173, w2v_ctc_loss=0.652, task_loss=0, contrastive_loss=0.1, total=4113.86, n_correct=2674.66, ppl=4.51, accuracy=65.016, wps=14558.8, ups=1.77, wpb=8227.7, bsz=298.5, num_updates=38000, lr=7.25476e-05, gnorm=0.588, clip=0, loss_scale=64, train_wall=56, gb_free=16.8, wall=26422
2023-07-25 06:11:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 06:12:17 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.355 | trans_loss 5.581 | nll_loss 2.86 | w2v_ctc_loss 1.379 | task_loss 0 | contrastive_loss 0.26 | total 4003.4 | n_correct 2485.4 | ppl 7.26 | accuracy 62.082 | uer 16.97 | wer 18.836 | raw_wer 18.836 | bleu 19.73 | wps 2236.8 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.28
2023-07-25 06:12:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-07-25 06:12:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_26_38000.pt
2023-07-25 06:12:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_26_38000.pt
2023-07-25 06:12:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 19.73) (writing took 31.50673931837082 seconds)
2023-07-25 06:13:45 | INFO | train_inner | epoch 026:   1266 / 1474 loss=2.065, trans_loss=4.995, nll_loss=2.187, w2v_ctc_loss=0.668, task_loss=0, contrastive_loss=0.063, total=3996.19, n_correct=2583.97, ppl=4.55, accuracy=64.661, wps=7208.1, ups=0.9, wpb=7992.4, bsz=279.3, num_updates=38100, lr=7.24524e-05, gnorm=0.603, clip=0, loss_scale=64, train_wall=55, gb_free=18, wall=26533
2023-07-25 06:14:41 | INFO | train_inner | epoch 026:   1366 / 1474 loss=2.054, trans_loss=4.985, nll_loss=2.174, w2v_ctc_loss=0.644, task_loss=0, contrastive_loss=0.079, total=4159.74, n_correct=2711.34, ppl=4.51, accuracy=65.181, wps=14623, ups=1.76, wpb=8319.5, bsz=311.4, num_updates=38200, lr=7.23575e-05, gnorm=0.592, clip=0, loss_scale=128, train_wall=56, gb_free=17.5, wall=26590
2023-07-25 06:15:38 | INFO | train_inner | epoch 026:   1466 / 1474 loss=2.049, trans_loss=4.979, nll_loss=2.168, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.071, total=4165.66, n_correct=2723.86, ppl=4.5, accuracy=65.388, wps=14809.8, ups=1.78, wpb=8331.3, bsz=317.5, num_updates=38300, lr=7.22629e-05, gnorm=0.585, clip=0, loss_scale=128, train_wall=56, gb_free=16.5, wall=26647
2023-07-25 06:15:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 06:16:05 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.353 | trans_loss 5.584 | nll_loss 2.863 | w2v_ctc_loss 1.363 | task_loss 0 | contrastive_loss 0.263 | total 4003.4 | n_correct 2477.7 | ppl 7.27 | accuracy 61.89 | uer 16.967 | wer 18.758 | raw_wer 18.758 | bleu 19.59 | wps 2133 | wpb 4003.4 | bsz 141.8 | num_updates 38308 | best_bleu 20.28
2023-07-25 06:16:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38308 updates
2023-07-25 06:16:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_last.pt
2023-07-25 06:16:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_last.pt
2023-07-25 06:16:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_last.pt (epoch 26 @ 38308 updates, score 19.59) (writing took 10.57972359471023 seconds)
2023-07-25 06:16:16 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-07-25 06:16:16 | INFO | train | epoch 026 | loss 2.053 | trans_loss 4.971 | nll_loss 2.156 | w2v_ctc_loss 0.649 | task_loss 0 | contrastive_loss 0.113 | total 4138.65 | n_correct 2702.03 | ppl 4.46 | accuracy 65.288 | wps 13193.7 | ups 1.59 | wpb 8277.3 | bsz 305.7 | num_updates 38308 | lr 7.22554e-05 | gnorm 0.588 | clip 0 | loss_scale 128 | train_wall 820 | gb_free 16.3 | wall 26685
2023-07-25 06:16:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 06:16:16 | INFO | fairseq.trainer | begin training epoch 27
2023-07-25 06:16:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 06:17:15 | INFO | train_inner | epoch 027:     92 / 1474 loss=2.03, trans_loss=4.938, nll_loss=2.111, w2v_ctc_loss=0.633, task_loss=0, contrastive_loss=0.048, total=4054.57, n_correct=2669.92, ppl=4.32, accuracy=65.85, wps=8299.8, ups=1.02, wpb=8109.1, bsz=282.4, num_updates=38400, lr=7.21688e-05, gnorm=0.595, clip=0, loss_scale=128, train_wall=54, gb_free=16.5, wall=26744
2023-07-25 06:18:12 | INFO | train_inner | epoch 027:    192 / 1474 loss=2.037, trans_loss=4.942, nll_loss=2.119, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.082, total=4195.2, n_correct=2765.6, ppl=4.34, accuracy=65.923, wps=14869.2, ups=1.77, wpb=8390.4, bsz=323.2, num_updates=38500, lr=7.2075e-05, gnorm=0.583, clip=0, loss_scale=128, train_wall=56, gb_free=17.4, wall=26801
2023-07-25 06:19:08 | INFO | train_inner | epoch 027:    292 / 1474 loss=2.038, trans_loss=4.95, nll_loss=2.128, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.061, total=4162.23, n_correct=2735.65, ppl=4.37, accuracy=65.726, wps=14810.3, ups=1.78, wpb=8324.5, bsz=305.5, num_updates=38600, lr=7.19816e-05, gnorm=0.582, clip=0, loss_scale=128, train_wall=56, gb_free=17.4, wall=26857
2023-07-25 06:19:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-25 06:20:05 | INFO | train_inner | epoch 027:    393 / 1474 loss=2.043, trans_loss=4.956, nll_loss=2.135, w2v_ctc_loss=0.64, task_loss=0, contrastive_loss=0.127, total=4052.96, n_correct=2661.48, ppl=4.39, accuracy=65.668, wps=14176.1, ups=1.75, wpb=8105.9, bsz=288.5, num_updates=38700, lr=7.18885e-05, gnorm=0.593, clip=0, loss_scale=64, train_wall=57, gb_free=18, wall=26914
2023-07-25 06:21:01 | INFO | train_inner | epoch 027:    493 / 1474 loss=2.054, trans_loss=4.964, nll_loss=2.148, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.185, total=4249.35, n_correct=2778.45, ppl=4.43, accuracy=65.385, wps=15216.4, ups=1.79, wpb=8498.7, bsz=331.9, num_updates=38800, lr=7.17958e-05, gnorm=0.578, clip=0, loss_scale=64, train_wall=55, gb_free=12.6, wall=26970
2023-07-25 06:21:58 | INFO | train_inner | epoch 027:    593 / 1474 loss=2.05, trans_loss=4.96, nll_loss=2.142, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.122, total=4133.39, n_correct=2706.41, ppl=4.41, accuracy=65.477, wps=14651.4, ups=1.77, wpb=8266.8, bsz=312, num_updates=38900, lr=7.17035e-05, gnorm=0.587, clip=0, loss_scale=64, train_wall=56, gb_free=12.7, wall=27026
2023-07-25 06:22:54 | INFO | train_inner | epoch 027:    693 / 1474 loss=2.05, trans_loss=4.967, nll_loss=2.15, w2v_ctc_loss=0.648, task_loss=0, contrastive_loss=0.1, total=4162.71, n_correct=2722.8, ppl=4.44, accuracy=65.409, wps=14835.4, ups=1.78, wpb=8325.4, bsz=305.4, num_updates=39000, lr=7.16115e-05, gnorm=0.593, clip=0, loss_scale=64, train_wall=56, gb_free=16.6, wall=27082
2023-07-25 06:23:49 | INFO | train_inner | epoch 027:    793 / 1474 loss=2.048, trans_loss=4.968, nll_loss=2.152, w2v_ctc_loss=0.649, task_loss=0, contrastive_loss=0.064, total=4103.81, n_correct=2681.61, ppl=4.44, accuracy=65.344, wps=14745, ups=1.8, wpb=8207.6, bsz=294.2, num_updates=39100, lr=7.15199e-05, gnorm=0.595, clip=0, loss_scale=64, train_wall=55, gb_free=16.5, wall=27138
2023-07-25 06:24:45 | INFO | train_inner | epoch 027:    893 / 1474 loss=2.041, trans_loss=4.972, nll_loss=2.156, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.052, total=4101.56, n_correct=2686.06, ppl=4.46, accuracy=65.489, wps=14726.2, ups=1.8, wpb=8203.1, bsz=292.1, num_updates=39200, lr=7.14286e-05, gnorm=0.591, clip=0, loss_scale=64, train_wall=55, gb_free=18, wall=27194
2023-07-25 06:25:42 | INFO | train_inner | epoch 027:    993 / 1474 loss=2.056, trans_loss=4.968, nll_loss=2.153, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.242, total=4199.56, n_correct=2745.35, ppl=4.45, accuracy=65.372, wps=14729.1, ups=1.75, wpb=8399.1, bsz=316.8, num_updates=39300, lr=7.13376e-05, gnorm=0.581, clip=0, loss_scale=64, train_wall=56, gb_free=12.2, wall=27251
2023-07-25 06:26:38 | INFO | train_inner | epoch 027:   1093 / 1474 loss=2.042, trans_loss=4.965, nll_loss=2.148, w2v_ctc_loss=0.636, task_loss=0, contrastive_loss=0.075, total=4150.97, n_correct=2715.52, ppl=4.43, accuracy=65.419, wps=14865, ups=1.79, wpb=8301.9, bsz=305, num_updates=39400, lr=7.1247e-05, gnorm=0.585, clip=0, loss_scale=64, train_wall=55, gb_free=12.6, wall=27307
2023-07-25 06:27:34 | INFO | train_inner | epoch 027:   1193 / 1474 loss=2.055, trans_loss=4.974, nll_loss=2.16, w2v_ctc_loss=0.656, task_loss=0, contrastive_loss=0.078, total=4103.06, n_correct=2678.01, ppl=4.47, accuracy=65.269, wps=14653.5, ups=1.79, wpb=8206.1, bsz=297.7, num_updates=39500, lr=7.11568e-05, gnorm=0.596, clip=0, loss_scale=64, train_wall=56, gb_free=16.8, wall=27363
2023-07-25 06:28:30 | INFO | train_inner | epoch 027:   1293 / 1474 loss=2.06, trans_loss=4.981, nll_loss=2.17, w2v_ctc_loss=0.652, task_loss=0, contrastive_loss=0.129, total=4062.52, n_correct=2640.93, ppl=4.5, accuracy=65.007, wps=14525.3, ups=1.79, wpb=8125, bsz=292.2, num_updates=39600, lr=7.10669e-05, gnorm=0.603, clip=0, loss_scale=64, train_wall=55, gb_free=16.9, wall=27419
2023-07-25 06:29:26 | INFO | train_inner | epoch 027:   1393 / 1474 loss=2.049, trans_loss=4.973, nll_loss=2.159, w2v_ctc_loss=0.64, task_loss=0, contrastive_loss=0.11, total=4152, n_correct=2712.35, ppl=4.47, accuracy=65.326, wps=14898.9, ups=1.79, wpb=8304, bsz=312.5, num_updates=39700, lr=7.09773e-05, gnorm=0.583, clip=0, loss_scale=64, train_wall=55, gb_free=16.9, wall=27474
2023-07-25 06:30:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 06:30:34 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.35 | trans_loss 5.575 | nll_loss 2.85 | w2v_ctc_loss 1.378 | task_loss 0 | contrastive_loss 0.258 | total 4003.4 | n_correct 2485 | ppl 7.21 | accuracy 62.072 | uer 16.887 | wer 18.754 | raw_wer 18.754 | bleu 20.14 | wps 2195.5 | wpb 4003.4 | bsz 141.8 | num_updates 39781 | best_bleu 20.28
2023-07-25 06:30:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39781 updates
2023-07-25 06:30:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_20.1406.pt
2023-07-25 06:30:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_20.1406.pt
2023-07-25 06:30:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_20.1406.pt (epoch 27 @ 39781 updates, score 20.14) (writing took 11.544258652254939 seconds)
2023-07-25 06:30:46 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-07-25 06:30:46 | INFO | train | epoch 027 | loss 2.046 | trans_loss 4.963 | nll_loss 2.145 | w2v_ctc_loss 0.642 | task_loss 0 | contrastive_loss 0.105 | total 4136.97 | n_correct 2708.99 | ppl 4.42 | accuracy 65.482 | wps 14015.6 | ups 1.69 | wpb 8273.9 | bsz 305.1 | num_updates 39781 | lr 7.0905e-05 | gnorm 0.589 | clip 0 | loss_scale 64 | train_wall 818 | gb_free 18.1 | wall 27554
2023-07-25 06:30:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 06:30:46 | INFO | fairseq.trainer | begin training epoch 28
2023-07-25 06:30:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 06:31:05 | INFO | train_inner | epoch 028:     19 / 1474 loss=2.039, trans_loss=4.963, nll_loss=2.147, w2v_ctc_loss=0.633, task_loss=0, contrastive_loss=0.063, total=4108.43, n_correct=2696.31, ppl=4.43, accuracy=65.629, wps=8280.2, ups=1.01, wpb=8216.9, bsz=305.1, num_updates=39800, lr=7.08881e-05, gnorm=0.593, clip=0, loss_scale=64, train_wall=55, gb_free=16.6, wall=27574
2023-07-25 06:32:00 | INFO | train_inner | epoch 028:    119 / 1474 loss=2.027, trans_loss=4.931, nll_loss=2.103, w2v_ctc_loss=0.632, task_loss=0, contrastive_loss=0.058, total=4113.41, n_correct=2721.31, ppl=4.3, accuracy=66.157, wps=14815.7, ups=1.8, wpb=8226.8, bsz=293.9, num_updates=39900, lr=7.07992e-05, gnorm=0.59, clip=0, loss_scale=64, train_wall=55, gb_free=17.1, wall=27629
2023-07-25 06:32:57 | INFO | train_inner | epoch 028:    219 / 1474 loss=2.031, trans_loss=4.941, nll_loss=2.117, w2v_ctc_loss=0.632, task_loss=0, contrastive_loss=0.066, total=4191.56, n_correct=2766.19, ppl=4.34, accuracy=65.994, wps=14792.9, ups=1.76, wpb=8383.1, bsz=315.2, num_updates=40000, lr=7.07107e-05, gnorm=0.586, clip=0, loss_scale=64, train_wall=56, gb_free=15.4, wall=27686
2023-07-25 06:32:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 06:33:20 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.372 | trans_loss 5.579 | nll_loss 2.856 | w2v_ctc_loss 1.44 | task_loss 0 | contrastive_loss 0.261 | total 4003.4 | n_correct 2478.8 | ppl 7.24 | accuracy 61.917 | uer 17.012 | wer 18.802 | raw_wer 18.802 | bleu 20.17 | wps 2195.8 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.28
2023-07-25 06:33:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-07-25 06:33:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_28_40000.pt
2023-07-25 06:33:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_28_40000.pt
2023-07-25 06:33:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 20.17) (writing took 25.8375548068434 seconds)
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:0')
2023-07-25 06:34:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-25 06:34:44 | INFO | train_inner | epoch 028:    320 / 1474 loss=2.049, trans_loss=4.948, nll_loss=2.127, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.291, total=4127.08, n_correct=2710.6, ppl=4.37, accuracy=65.678, wps=7715.8, ups=0.93, wpb=8254.2, bsz=308.8, num_updates=40100, lr=7.06225e-05, gnorm=0.593, clip=0, loss_scale=32, train_wall=57, gb_free=13.8, wall=27793
2023-07-25 06:35:40 | INFO | train_inner | epoch 028:    420 / 1474 loss=2.036, trans_loss=4.948, nll_loss=2.125, w2v_ctc_loss=0.64, task_loss=0, contrastive_loss=0.053, total=4089.84, n_correct=2692.55, ppl=4.36, accuracy=65.835, wps=14598.7, ups=1.78, wpb=8179.7, bsz=295.7, num_updates=40200, lr=7.05346e-05, gnorm=0.589, clip=0, loss_scale=32, train_wall=55, gb_free=16.8, wall=27849
2023-07-25 06:36:36 | INFO | train_inner | epoch 028:    520 / 1474 loss=2.035, trans_loss=4.95, nll_loss=2.129, w2v_ctc_loss=0.634, task_loss=0, contrastive_loss=0.065, total=4098.92, n_correct=2693.95, ppl=4.37, accuracy=65.723, wps=14713.1, ups=1.79, wpb=8197.8, bsz=295.7, num_updates=40300, lr=7.0447e-05, gnorm=0.592, clip=0, loss_scale=32, train_wall=55, gb_free=17.2, wall=27905
2023-07-25 06:37:32 | INFO | train_inner | epoch 028:    620 / 1474 loss=2.042, trans_loss=4.962, nll_loss=2.144, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.066, total=4180.1, n_correct=2740.94, ppl=4.42, accuracy=65.571, wps=14897.1, ups=1.78, wpb=8360.2, bsz=305.3, num_updates=40400, lr=7.03598e-05, gnorm=0.593, clip=0, loss_scale=32, train_wall=56, gb_free=16.8, wall=27961
2023-07-25 06:38:28 | INFO | train_inner | epoch 028:    720 / 1474 loss=2.048, trans_loss=4.958, nll_loss=2.141, w2v_ctc_loss=0.636, task_loss=0, contrastive_loss=0.182, total=4191.62, n_correct=2750.73, ppl=4.41, accuracy=65.625, wps=14897.6, ups=1.78, wpb=8383.2, bsz=329.2, num_updates=40500, lr=7.02728e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=56, gb_free=17.3, wall=28017
2023-07-25 06:39:24 | INFO | train_inner | epoch 028:    820 / 1474 loss=2.033, trans_loss=4.953, nll_loss=2.134, w2v_ctc_loss=0.632, task_loss=0, contrastive_loss=0.056, total=4088.91, n_correct=2692.85, ppl=4.39, accuracy=65.857, wps=14660.5, ups=1.79, wpb=8177.8, bsz=304.3, num_updates=40600, lr=7.01862e-05, gnorm=0.591, clip=0, loss_scale=32, train_wall=55, gb_free=17.3, wall=28073
2023-07-25 06:40:20 | INFO | train_inner | epoch 028:    920 / 1474 loss=2.05, trans_loss=4.968, nll_loss=2.153, w2v_ctc_loss=0.643, task_loss=0, contrastive_loss=0.121, total=4117.01, n_correct=2689.34, ppl=4.45, accuracy=65.323, wps=14675.5, ups=1.78, wpb=8234, bsz=299.7, num_updates=40700, lr=7.01e-05, gnorm=0.594, clip=0, loss_scale=32, train_wall=56, gb_free=15.6, wall=28129
2023-07-25 06:41:17 | INFO | train_inner | epoch 028:   1020 / 1474 loss=2.056, trans_loss=4.967, nll_loss=2.151, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.175, total=4182.85, n_correct=2732.57, ppl=4.44, accuracy=65.328, wps=14786.9, ups=1.77, wpb=8365.7, bsz=312, num_updates=40800, lr=7.0014e-05, gnorm=0.595, clip=0, loss_scale=32, train_wall=56, gb_free=16.7, wall=28185
2023-07-25 06:42:13 | INFO | train_inner | epoch 028:   1120 / 1474 loss=2.038, trans_loss=4.953, nll_loss=2.135, w2v_ctc_loss=0.634, task_loss=0, contrastive_loss=0.082, total=4220.16, n_correct=2770.9, ppl=4.39, accuracy=65.659, wps=14985.3, ups=1.78, wpb=8440.3, bsz=321, num_updates=40900, lr=6.99284e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=56, gb_free=16.2, wall=28242
2023-07-25 06:43:08 | INFO | train_inner | epoch 028:   1220 / 1474 loss=2.041, trans_loss=4.965, nll_loss=2.149, w2v_ctc_loss=0.634, task_loss=0, contrastive_loss=0.066, total=4092.46, n_correct=2682.98, ppl=4.43, accuracy=65.559, wps=14763.2, ups=1.8, wpb=8184.9, bsz=303.1, num_updates=41000, lr=6.9843e-05, gnorm=0.594, clip=0, loss_scale=32, train_wall=55, gb_free=17.9, wall=28297
2023-07-25 06:44:05 | INFO | train_inner | epoch 028:   1320 / 1474 loss=2.05, trans_loss=4.971, nll_loss=2.156, w2v_ctc_loss=0.652, task_loss=0, contrastive_loss=0.081, total=4084.55, n_correct=2666.58, ppl=4.46, accuracy=65.285, wps=14497.1, ups=1.77, wpb=8169.1, bsz=285.1, num_updates=41100, lr=6.9758e-05, gnorm=0.597, clip=0, loss_scale=32, train_wall=56, gb_free=16.1, wall=28354
2023-07-25 06:45:01 | INFO | train_inner | epoch 028:   1420 / 1474 loss=2.044, trans_loss=4.966, nll_loss=2.149, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.102, total=4154.09, n_correct=2720.56, ppl=4.44, accuracy=65.491, wps=14710.8, ups=1.77, wpb=8308.2, bsz=299.3, num_updates=41200, lr=6.96733e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=56, gb_free=16.3, wall=28410
2023-07-25 06:45:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:4')
2023-07-25 06:45:54 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.355 | trans_loss 5.576 | nll_loss 2.85 | w2v_ctc_loss 1.388 | task_loss 0 | contrastive_loss 0.262 | total 4003.4 | n_correct 2484.8 | ppl 7.21 | accuracy 62.067 | uer 16.877 | wer 18.821 | raw_wer 18.821 | bleu 20.08 | wps 2222.6 | wpb 4003.4 | bsz 141.8 | num_updates 41254 | best_bleu 20.28
2023-07-25 06:45:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41254 updates
2023-07-25 06:45:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_20.0803.pt
2023-07-25 06:45:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_20.0803.pt
2023-07-25 06:46:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_20.0803.pt (epoch 28 @ 41254 updates, score 20.08) (writing took 11.612531263381243 seconds)
2023-07-25 06:46:06 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-07-25 06:46:06 | INFO | train | epoch 028 | loss 2.041 | trans_loss 4.956 | nll_loss 2.136 | w2v_ctc_loss 0.638 | task_loss 0 | contrastive_loss 0.104 | total 4137.55 | n_correct 2716.67 | ppl 4.4 | accuracy 65.659 | wps 13238.9 | ups 1.6 | wpb 8275.1 | bsz 305.2 | num_updates 41254 | lr 6.96277e-05 | gnorm 0.59 | clip 0 | loss_scale 32 | train_wall 820 | gb_free 16.7 | wall 28475
2023-07-25 06:46:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 06:46:07 | INFO | fairseq.trainer | begin training epoch 29
2023-07-25 06:46:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 06:46:41 | INFO | train_inner | epoch 029:     46 / 1474 loss=2.035, trans_loss=4.943, nll_loss=2.121, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.08, total=4169.12, n_correct=2750.74, ppl=4.35, accuracy=65.979, wps=8393.8, ups=1.01, wpb=8338.2, bsz=316.4, num_updates=41300, lr=6.95889e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=55, gb_free=16.7, wall=28509
2023-07-25 06:47:37 | INFO | train_inner | epoch 029:    146 / 1474 loss=2.033, trans_loss=4.938, nll_loss=2.112, w2v_ctc_loss=0.634, task_loss=0, contrastive_loss=0.096, total=4105.72, n_correct=2710.57, ppl=4.32, accuracy=66.019, wps=14679, ups=1.79, wpb=8211.4, bsz=304.1, num_updates=41400, lr=6.95048e-05, gnorm=0.591, clip=0, loss_scale=32, train_wall=55, gb_free=16.2, wall=28565
2023-07-25 06:48:33 | INFO | train_inner | epoch 029:    246 / 1474 loss=2.031, trans_loss=4.929, nll_loss=2.103, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.182, total=4199.67, n_correct=2781.15, ppl=4.3, accuracy=66.223, wps=14844.6, ups=1.77, wpb=8399.3, bsz=330.5, num_updates=41500, lr=6.9421e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=56, gb_free=15.9, wall=28622
2023-07-25 06:49:29 | INFO | train_inner | epoch 029:    346 / 1474 loss=2.038, trans_loss=4.951, nll_loss=2.13, w2v_ctc_loss=0.643, task_loss=0, contrastive_loss=0.061, total=4095.17, n_correct=2691.61, ppl=4.38, accuracy=65.726, wps=14569.1, ups=1.78, wpb=8190.3, bsz=291.2, num_updates=41600, lr=6.93375e-05, gnorm=0.597, clip=0, loss_scale=32, train_wall=56, gb_free=17, wall=28678
2023-07-25 06:50:26 | INFO | train_inner | epoch 029:    446 / 1474 loss=2.022, trans_loss=4.928, nll_loss=2.1, w2v_ctc_loss=0.626, task_loss=0, contrastive_loss=0.053, total=4157.44, n_correct=2753.07, ppl=4.29, accuracy=66.22, wps=14765.8, ups=1.78, wpb=8314.9, bsz=307.7, num_updates=41700, lr=6.92543e-05, gnorm=0.592, clip=0, loss_scale=32, train_wall=56, gb_free=16.8, wall=28734
2023-07-25 06:51:22 | INFO | train_inner | epoch 029:    546 / 1474 loss=2.043, trans_loss=4.953, nll_loss=2.133, w2v_ctc_loss=0.632, task_loss=0, contrastive_loss=0.15, total=4150.87, n_correct=2723.3, ppl=4.39, accuracy=65.608, wps=14730.4, ups=1.77, wpb=8301.7, bsz=294.9, num_updates=41800, lr=6.91714e-05, gnorm=0.591, clip=0, loss_scale=32, train_wall=56, gb_free=16.1, wall=28791
2023-07-25 06:52:18 | INFO | train_inner | epoch 029:    646 / 1474 loss=2.039, trans_loss=4.94, nll_loss=2.117, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.22, total=4143.02, n_correct=2730.99, ppl=4.34, accuracy=65.918, wps=14699.1, ups=1.77, wpb=8286, bsz=318.6, num_updates=41900, lr=6.90889e-05, gnorm=0.592, clip=0, loss_scale=32, train_wall=56, gb_free=17.4, wall=28847
2023-07-25 06:53:15 | INFO | train_inner | epoch 029:    746 / 1474 loss=2.034, trans_loss=4.941, nll_loss=2.117, w2v_ctc_loss=0.623, task_loss=0, contrastive_loss=0.141, total=4249.79, n_correct=2805.79, ppl=4.34, accuracy=66.022, wps=15073.5, ups=1.77, wpb=8499.6, bsz=330, num_updates=42000, lr=6.90066e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=28904
2023-07-25 06:53:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 06:53:38 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.354 | trans_loss 5.58 | nll_loss 2.855 | w2v_ctc_loss 1.379 | task_loss 0 | contrastive_loss 0.261 | total 4003.4 | n_correct 2481.8 | ppl 7.23 | accuracy 61.992 | uer 16.861 | wer 18.657 | raw_wer 18.657 | bleu 20.04 | wps 2218 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.28
2023-07-25 06:53:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-07-25 06:53:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_29_42000.pt
2023-07-25 06:53:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_29_42000.pt
2023-07-25 06:54:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 20.04) (writing took 25.03432492725551 seconds)
2023-07-25 06:54:59 | INFO | train_inner | epoch 029:    846 / 1474 loss=2.038, trans_loss=4.963, nll_loss=2.145, w2v_ctc_loss=0.635, task_loss=0, contrastive_loss=0.052, total=4027.19, n_correct=2640.5, ppl=4.42, accuracy=65.567, wps=7694.5, ups=0.96, wpb=8054.4, bsz=280.6, num_updates=42100, lr=6.89246e-05, gnorm=0.603, clip=0, loss_scale=64, train_wall=55, gb_free=17.6, wall=29008
2023-07-25 06:55:55 | INFO | train_inner | epoch 029:    946 / 1474 loss=2.04, trans_loss=4.962, nll_loss=2.145, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.066, total=4082.14, n_correct=2680.25, ppl=4.42, accuracy=65.658, wps=14731.2, ups=1.8, wpb=8164.3, bsz=296.3, num_updates=42200, lr=6.88428e-05, gnorm=0.6, clip=0, loss_scale=64, train_wall=55, gb_free=15.7, wall=29064
2023-07-25 06:56:51 | INFO | train_inner | epoch 029:   1046 / 1474 loss=2.036, trans_loss=4.948, nll_loss=2.127, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.139, total=4148.18, n_correct=2731.78, ppl=4.37, accuracy=65.855, wps=14829.9, ups=1.79, wpb=8296.4, bsz=308.2, num_updates=42300, lr=6.87614e-05, gnorm=0.592, clip=0, loss_scale=64, train_wall=55, gb_free=16.3, wall=29120
2023-07-25 06:57:47 | INFO | train_inner | epoch 029:   1146 / 1474 loss=2.038, trans_loss=4.964, nll_loss=2.147, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.048, total=4063.95, n_correct=2660.94, ppl=4.43, accuracy=65.477, wps=14523.5, ups=1.79, wpb=8127.9, bsz=283, num_updates=42400, lr=6.86803e-05, gnorm=0.593, clip=0, loss_scale=64, train_wall=55, gb_free=13.8, wall=29176
2023-07-25 06:58:43 | INFO | train_inner | epoch 029:   1246 / 1474 loss=2.039, trans_loss=4.965, nll_loss=2.149, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.058, total=4158.81, n_correct=2727.42, ppl=4.44, accuracy=65.582, wps=14859.3, ups=1.79, wpb=8317.6, bsz=301.2, num_updates=42500, lr=6.85994e-05, gnorm=0.594, clip=0, loss_scale=64, train_wall=55, gb_free=16, wall=29232
2023-07-25 06:59:39 | INFO | train_inner | epoch 029:   1346 / 1474 loss=2.04, trans_loss=4.957, nll_loss=2.139, w2v_ctc_loss=0.63, task_loss=0, contrastive_loss=0.124, total=4166.34, n_correct=2736.5, ppl=4.4, accuracy=65.681, wps=14855.3, ups=1.78, wpb=8332.7, bsz=310.7, num_updates=42600, lr=6.85189e-05, gnorm=0.589, clip=0, loss_scale=64, train_wall=56, gb_free=18.1, wall=29288
2023-07-25 07:00:35 | INFO | train_inner | epoch 029:   1446 / 1474 loss=2.045, trans_loss=4.958, nll_loss=2.141, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.152, total=4162.2, n_correct=2728.55, ppl=4.41, accuracy=65.555, wps=14931.5, ups=1.79, wpb=8324.4, bsz=311.5, num_updates=42700, lr=6.84386e-05, gnorm=0.593, clip=0, loss_scale=64, train_wall=55, gb_free=17.6, wall=29343
2023-07-25 07:00:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 07:01:13 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.352 | trans_loss 5.574 | nll_loss 2.852 | w2v_ctc_loss 1.383 | task_loss 0 | contrastive_loss 0.262 | total 4003.4 | n_correct 2486.4 | ppl 7.22 | accuracy 62.107 | uer 16.71 | wer 18.523 | raw_wer 18.523 | bleu 20.29 | wps 2296.5 | wpb 4003.4 | bsz 141.8 | num_updates 42728 | best_bleu 20.29
2023-07-25 07:01:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42728 updates
2023-07-25 07:01:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 07:01:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 07:01:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt (epoch 29 @ 42728 updates, score 20.29) (writing took 19.687604416161776 seconds)
2023-07-25 07:01:33 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-07-25 07:01:33 | INFO | train | epoch 029 | loss 2.037 | trans_loss 4.949 | nll_loss 2.128 | w2v_ctc_loss 0.632 | task_loss 0 | contrastive_loss 0.11 | total 4138.65 | n_correct 2723.63 | ppl 4.37 | accuracy 65.81 | wps 13168.6 | ups 1.59 | wpb 8277.3 | bsz 305.7 | num_updates 42728 | lr 6.84162e-05 | gnorm 0.593 | clip 0 | loss_scale 64 | train_wall 819 | gb_free 16.3 | wall 29402
2023-07-25 07:01:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 07:01:33 | INFO | fairseq.trainer | begin training epoch 30
2023-07-25 07:01:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 07:02:21 | INFO | train_inner | epoch 030:     72 / 1474 loss=2.031, trans_loss=4.934, nll_loss=2.109, w2v_ctc_loss=0.619, task_loss=0, contrastive_loss=0.167, total=4182.65, n_correct=2764.59, ppl=4.31, accuracy=66.097, wps=7831.7, ups=0.94, wpb=8365.3, bsz=320.5, num_updates=42800, lr=6.83586e-05, gnorm=0.587, clip=0, loss_scale=64, train_wall=56, gb_free=13.9, wall=29450
2023-07-25 07:03:17 | INFO | train_inner | epoch 030:    172 / 1474 loss=2.022, trans_loss=4.917, nll_loss=2.087, w2v_ctc_loss=0.626, task_loss=0, contrastive_loss=0.102, total=4203.05, n_correct=2795.08, ppl=4.25, accuracy=66.501, wps=15104.9, ups=1.8, wpb=8406.1, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.59, clip=0, loss_scale=64, train_wall=55, gb_free=17.7, wall=29506
2023-07-25 07:04:13 | INFO | train_inner | epoch 030:    272 / 1474 loss=2.027, trans_loss=4.933, nll_loss=2.105, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.052, total=4116.93, n_correct=2723.69, ppl=4.3, accuracy=66.158, wps=14798.8, ups=1.8, wpb=8233.9, bsz=295.1, num_updates=43000, lr=6.81994e-05, gnorm=0.589, clip=0, loss_scale=64, train_wall=55, gb_free=17.2, wall=29562
2023-07-25 07:05:09 | INFO | train_inner | epoch 030:    372 / 1474 loss=2.019, trans_loss=4.927, nll_loss=2.098, w2v_ctc_loss=0.622, task_loss=0, contrastive_loss=0.056, total=4173.13, n_correct=2768.76, ppl=4.28, accuracy=66.347, wps=14782.6, ups=1.77, wpb=8346.3, bsz=305.6, num_updates=43100, lr=6.81203e-05, gnorm=0.587, clip=0, loss_scale=64, train_wall=56, gb_free=12.4, wall=29618
2023-07-25 07:06:05 | INFO | train_inner | epoch 030:    472 / 1474 loss=2.026, trans_loss=4.931, nll_loss=2.106, w2v_ctc_loss=0.619, task_loss=0, contrastive_loss=0.122, total=4135.2, n_correct=2735.68, ppl=4.3, accuracy=66.156, wps=14780.6, ups=1.79, wpb=8270.4, bsz=314.8, num_updates=43200, lr=6.80414e-05, gnorm=0.594, clip=0, loss_scale=64, train_wall=56, gb_free=17.2, wall=29674
2023-07-25 07:07:01 | INFO | train_inner | epoch 030:    572 / 1474 loss=2.029, trans_loss=4.94, nll_loss=2.116, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.084, total=4168.65, n_correct=2755.13, ppl=4.33, accuracy=66.092, wps=14963.5, ups=1.79, wpb=8337.3, bsz=312.1, num_updates=43300, lr=6.79628e-05, gnorm=0.592, clip=0, loss_scale=64, train_wall=55, gb_free=16.2, wall=29730
2023-07-25 07:07:57 | INFO | train_inner | epoch 030:    672 / 1474 loss=2.035, trans_loss=4.941, nll_loss=2.118, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.101, total=4183.65, n_correct=2758.88, ppl=4.34, accuracy=65.944, wps=14794.7, ups=1.77, wpb=8367.3, bsz=314.5, num_updates=43400, lr=6.78844e-05, gnorm=0.594, clip=0, loss_scale=64, train_wall=56, gb_free=17.1, wall=29786
2023-07-25 07:08:54 | INFO | train_inner | epoch 030:    772 / 1474 loss=2.05, trans_loss=4.955, nll_loss=2.137, w2v_ctc_loss=0.645, task_loss=0, contrastive_loss=0.179, total=4106.9, n_correct=2696.15, ppl=4.4, accuracy=65.649, wps=14555.4, ups=1.77, wpb=8213.8, bsz=302.9, num_updates=43500, lr=6.78064e-05, gnorm=0.603, clip=0, loss_scale=64, train_wall=56, gb_free=12.5, wall=29843
2023-07-25 07:09:50 | INFO | train_inner | epoch 030:    872 / 1474 loss=2.029, trans_loss=4.946, nll_loss=2.123, w2v_ctc_loss=0.628, task_loss=0, contrastive_loss=0.058, total=4089.18, n_correct=2694.97, ppl=4.36, accuracy=65.905, wps=14677.8, ups=1.79, wpb=8178.4, bsz=291.4, num_updates=43600, lr=6.77285e-05, gnorm=0.603, clip=0, loss_scale=64, train_wall=55, gb_free=16.7, wall=29898
2023-07-25 07:10:45 | INFO | train_inner | epoch 030:    972 / 1474 loss=2.035, trans_loss=4.95, nll_loss=2.13, w2v_ctc_loss=0.632, task_loss=0, contrastive_loss=0.079, total=4140.03, n_correct=2724.5, ppl=4.38, accuracy=65.809, wps=14820.6, ups=1.79, wpb=8280.1, bsz=303.9, num_updates=43700, lr=6.7651e-05, gnorm=0.593, clip=0, loss_scale=64, train_wall=55, gb_free=14.3, wall=29954
2023-07-25 07:11:42 | INFO | train_inner | epoch 030:   1072 / 1474 loss=2.043, trans_loss=4.959, nll_loss=2.14, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.144, total=4101.12, n_correct=2690.59, ppl=4.41, accuracy=65.606, wps=14575.3, ups=1.78, wpb=8202.2, bsz=282.8, num_updates=43800, lr=6.75737e-05, gnorm=0.599, clip=0, loss_scale=64, train_wall=56, gb_free=16.8, wall=30011
2023-07-25 07:12:38 | INFO | train_inner | epoch 030:   1172 / 1474 loss=2.032, trans_loss=4.948, nll_loss=2.128, w2v_ctc_loss=0.618, task_loss=0, contrastive_loss=0.129, total=4168.22, n_correct=2749.66, ppl=4.37, accuracy=65.967, wps=14855.7, ups=1.78, wpb=8336.4, bsz=314.5, num_updates=43900, lr=6.74967e-05, gnorm=0.593, clip=0, loss_scale=64, train_wall=56, gb_free=17, wall=30067
2023-07-25 07:13:34 | INFO | train_inner | epoch 030:   1272 / 1474 loss=2.038, trans_loss=4.958, nll_loss=2.139, w2v_ctc_loss=0.638, task_loss=0, contrastive_loss=0.062, total=4032.74, n_correct=2647.21, ppl=4.4, accuracy=65.643, wps=14448.4, ups=1.79, wpb=8065.5, bsz=281.8, num_updates=44000, lr=6.742e-05, gnorm=0.609, clip=0, loss_scale=64, train_wall=55, gb_free=17.1, wall=30123
2023-07-25 07:13:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 07:13:58 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.349 | trans_loss 5.577 | nll_loss 2.851 | w2v_ctc_loss 1.367 | task_loss 0 | contrastive_loss 0.259 | total 4003.4 | n_correct 2482.5 | ppl 7.22 | accuracy 62.01 | uer 16.858 | wer 18.702 | raw_wer 18.702 | bleu 20.32 | wps 1969.9 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.32
2023-07-25 07:13:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-07-25 07:13:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_30_44000.pt
2023-07-25 07:14:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_30_44000.pt
2023-07-25 07:14:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 20.32) (writing took 19.80488972365856 seconds)
2023-07-25 07:15:15 | INFO | train_inner | epoch 030:   1372 / 1474 loss=2.03, trans_loss=4.946, nll_loss=2.126, w2v_ctc_loss=0.626, task_loss=0, contrastive_loss=0.075, total=4166.96, n_correct=2751.06, ppl=4.37, accuracy=66.021, wps=8218.3, ups=0.99, wpb=8333.9, bsz=322.3, num_updates=44100, lr=6.73435e-05, gnorm=0.593, clip=0, loss_scale=64, train_wall=56, gb_free=15.4, wall=30224
2023-07-25 07:16:11 | INFO | train_inner | epoch 030:   1472 / 1474 loss=2.038, trans_loss=4.953, nll_loss=2.135, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.215, total=4125.17, n_correct=2716.73, ppl=4.39, accuracy=65.857, wps=14757.6, ups=1.79, wpb=8250.3, bsz=310, num_updates=44200, lr=6.72673e-05, gnorm=0.592, clip=0, loss_scale=128, train_wall=55, gb_free=17.2, wall=30280
2023-07-25 07:16:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 07:16:37 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.347 | trans_loss 5.57 | nll_loss 2.844 | w2v_ctc_loss 1.374 | task_loss 0 | contrastive_loss 0.264 | total 4003.4 | n_correct 2490.4 | ppl 7.18 | accuracy 62.207 | uer 16.943 | wer 18.728 | raw_wer 18.728 | bleu 20.57 | wps 2029.1 | wpb 4003.4 | bsz 141.8 | num_updates 44202 | best_bleu 20.57
2023-07-25 07:16:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44202 updates
2023-07-25 07:16:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 07:16:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt
2023-07-25 07:16:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_best.pt (epoch 30 @ 44202 updates, score 20.57) (writing took 19.29353284649551 seconds)
2023-07-25 07:16:57 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-07-25 07:16:57 | INFO | train | epoch 030 | loss 2.032 | trans_loss 4.942 | nll_loss 2.119 | w2v_ctc_loss 0.629 | task_loss 0 | contrastive_loss 0.11 | total 4138.65 | n_correct 2731.07 | ppl 4.35 | accuracy 65.989 | wps 13206.8 | ups 1.6 | wpb 8277.3 | bsz 305.7 | num_updates 44202 | lr 6.72658e-05 | gnorm 0.595 | clip 0 | loss_scale 128 | train_wall 819 | gb_free 17.4 | wall 30326
2023-07-25 07:16:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 07:16:57 | INFO | fairseq.trainer | begin training epoch 31
2023-07-25 07:16:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 07:17:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-25 07:18:01 | INFO | train_inner | epoch 031:     99 / 1474 loss=2.021, trans_loss=4.923, nll_loss=2.092, w2v_ctc_loss=0.63, task_loss=0, contrastive_loss=0.059, total=4076.84, n_correct=2706.51, ppl=4.26, accuracy=66.387, wps=7419.3, ups=0.91, wpb=8153.7, bsz=294.2, num_updates=44300, lr=6.71913e-05, gnorm=0.598, clip=0, loss_scale=64, train_wall=56, gb_free=16.7, wall=30390
2023-07-25 07:18:57 | INFO | train_inner | epoch 031:    199 / 1474 loss=2.025, trans_loss=4.927, nll_loss=2.099, w2v_ctc_loss=0.63, task_loss=0, contrastive_loss=0.086, total=4147.4, n_correct=2750.71, ppl=4.28, accuracy=66.324, wps=14790.3, ups=1.78, wpb=8294.8, bsz=302.2, num_updates=44400, lr=6.71156e-05, gnorm=0.598, clip=0, loss_scale=64, train_wall=56, gb_free=17.1, wall=30446
2023-07-25 07:19:54 | INFO | train_inner | epoch 031:    299 / 1474 loss=2.023, trans_loss=4.923, nll_loss=2.094, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.122, total=4149.21, n_correct=2753.34, ppl=4.27, accuracy=66.358, wps=14670.5, ups=1.77, wpb=8298.4, bsz=301.6, num_updates=44500, lr=6.70402e-05, gnorm=0.591, clip=0, loss_scale=64, train_wall=56, gb_free=16.5, wall=30502
2023-07-25 07:20:50 | INFO | train_inner | epoch 031:    399 / 1474 loss=2.024, trans_loss=4.936, nll_loss=2.11, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.058, total=4092.62, n_correct=2701.78, ppl=4.32, accuracy=66.016, wps=14619.9, ups=1.79, wpb=8185.2, bsz=285.6, num_updates=44600, lr=6.6965e-05, gnorm=0.6, clip=0, loss_scale=64, train_wall=56, gb_free=17.5, wall=30558
2023-07-25 07:21:45 | INFO | train_inner | epoch 031:    499 / 1474 loss=2.027, trans_loss=4.93, nll_loss=2.103, w2v_ctc_loss=0.636, task_loss=0, contrastive_loss=0.07, total=4111.85, n_correct=2718.39, ppl=4.3, accuracy=66.111, wps=14711.5, ups=1.79, wpb=8223.7, bsz=300.3, num_updates=44700, lr=6.689e-05, gnorm=0.606, clip=0, loss_scale=64, train_wall=55, gb_free=11.6, wall=30614
2023-07-25 07:22:41 | INFO | train_inner | epoch 031:    599 / 1474 loss=2.019, trans_loss=4.93, nll_loss=2.103, w2v_ctc_loss=0.618, task_loss=0, contrastive_loss=0.058, total=4083.44, n_correct=2706.37, ppl=4.3, accuracy=66.277, wps=14596.6, ups=1.79, wpb=8166.9, bsz=294.5, num_updates=44800, lr=6.68153e-05, gnorm=0.594, clip=0, loss_scale=64, train_wall=55, gb_free=17, wall=30670
2023-07-25 07:23:37 | INFO | train_inner | epoch 031:    699 / 1474 loss=2.017, trans_loss=4.929, nll_loss=2.102, w2v_ctc_loss=0.616, task_loss=0, contrastive_loss=0.059, total=4213.98, n_correct=2793.67, ppl=4.29, accuracy=66.295, wps=15165.1, ups=1.8, wpb=8428, bsz=315.7, num_updates=44900, lr=6.67409e-05, gnorm=0.587, clip=0, loss_scale=64, train_wall=55, gb_free=16.5, wall=30726
2023-07-25 07:24:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-25 07:24:34 | INFO | train_inner | epoch 031:    800 / 1474 loss=2.029, trans_loss=4.945, nll_loss=2.122, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.07, total=4085.74, n_correct=2691.33, ppl=4.35, accuracy=65.871, wps=14425.2, ups=1.77, wpb=8171.5, bsz=291.2, num_updates=45000, lr=6.66667e-05, gnorm=0.603, clip=0, loss_scale=32, train_wall=56, gb_free=15.6, wall=30782
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:0')
2023-07-25 07:25:29 | INFO | train_inner | epoch 031:    900 / 1474 loss=2.027, trans_loss=4.936, nll_loss=2.111, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.075, total=4099.13, n_correct=2705.54, ppl=4.32, accuracy=66.003, wps=14716.8, ups=1.8, wpb=8198.3, bsz=294.3, num_updates=45100, lr=6.65927e-05, gnorm=0.606, clip=0, loss_scale=32, train_wall=55, gb_free=15.5, wall=30838
2023-07-25 07:26:25 | INFO | train_inner | epoch 031:   1000 / 1474 loss=2.033, trans_loss=4.944, nll_loss=2.122, w2v_ctc_loss=0.621, task_loss=0, contrastive_loss=0.159, total=4186.81, n_correct=2764.27, ppl=4.35, accuracy=66.023, wps=14934.6, ups=1.78, wpb=8373.6, bsz=320.9, num_updates=45200, lr=6.6519e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=56, gb_free=13.8, wall=30894
2023-07-25 07:27:21 | INFO | train_inner | epoch 031:   1100 / 1474 loss=2.029, trans_loss=4.94, nll_loss=2.117, w2v_ctc_loss=0.621, task_loss=0, contrastive_loss=0.109, total=4149.25, n_correct=2739.48, ppl=4.34, accuracy=66.023, wps=14884.3, ups=1.79, wpb=8298.5, bsz=315.2, num_updates=45300, lr=6.64455e-05, gnorm=0.596, clip=0, loss_scale=32, train_wall=55, gb_free=16.2, wall=30950
2023-07-25 07:28:17 | INFO | train_inner | epoch 031:   1200 / 1474 loss=2.036, trans_loss=4.943, nll_loss=2.122, w2v_ctc_loss=0.621, task_loss=0, contrastive_loss=0.221, total=4187.45, n_correct=2765.69, ppl=4.35, accuracy=66.047, wps=14995.8, ups=1.79, wpb=8374.9, bsz=320.3, num_updates=45400, lr=6.63723e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=55, gb_free=17.3, wall=31006
2023-07-25 07:29:13 | INFO | train_inner | epoch 031:   1300 / 1474 loss=2.027, trans_loss=4.943, nll_loss=2.123, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.066, total=4227.39, n_correct=2794.87, ppl=4.35, accuracy=66.113, wps=15240, ups=1.8, wpb=8454.8, bsz=326.7, num_updates=45500, lr=6.62994e-05, gnorm=0.592, clip=0, loss_scale=32, train_wall=55, gb_free=17.2, wall=31061
2023-07-25 07:30:09 | INFO | train_inner | epoch 031:   1400 / 1474 loss=2.047, trans_loss=4.946, nll_loss=2.126, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.271, total=4191.1, n_correct=2761.63, ppl=4.36, accuracy=65.893, wps=14934.5, ups=1.78, wpb=8382.2, bsz=327, num_updates=45600, lr=6.62266e-05, gnorm=0.597, clip=0, loss_scale=32, train_wall=56, gb_free=16.8, wall=31117
2023-07-25 07:30:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2498, device='cuda:2')
2023-07-25 07:31:13 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.354 | trans_loss 5.575 | nll_loss 2.852 | w2v_ctc_loss 1.388 | task_loss 0 | contrastive_loss 0.26 | total 4003.4 | n_correct 2485.3 | ppl 7.22 | accuracy 62.08 | uer 16.744 | wer 18.638 | raw_wer 18.638 | bleu 19.94 | wps 2265.6 | wpb 4003.4 | bsz 141.8 | num_updates 45674 | best_bleu 20.57
2023-07-25 07:31:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45674 updates
2023-07-25 07:31:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_last.pt
2023-07-25 07:31:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_last.pt
2023-07-25 07:31:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_last.pt (epoch 31 @ 45674 updates, score 19.94) (writing took 10.403980754315853 seconds)
2023-07-25 07:31:23 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-07-25 07:31:23 | INFO | train | epoch 031 | loss 2.028 | trans_loss 4.936 | nll_loss 2.111 | w2v_ctc_loss 0.625 | task_loss 0 | contrastive_loss 0.105 | total 4138.04 | n_correct 2735.71 | ppl 4.32 | accuracy 66.111 | wps 14059.7 | ups 1.7 | wpb 8276.1 | bsz 305.4 | num_updates 45674 | lr 6.61729e-05 | gnorm 0.597 | clip 0 | loss_scale 32 | train_wall 818 | gb_free 12.7 | wall 31192
2023-07-25 07:31:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 07:31:23 | INFO | fairseq.trainer | begin training epoch 32
2023-07-25 07:31:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 07:31:46 | INFO | train_inner | epoch 032:     26 / 1474 loss=2.024, trans_loss=4.937, nll_loss=2.113, w2v_ctc_loss=0.626, task_loss=0, contrastive_loss=0.054, total=4040.88, n_correct=2669.27, ppl=4.33, accuracy=66.057, wps=8322.6, ups=1.03, wpb=8081.8, bsz=288.7, num_updates=45700, lr=6.61541e-05, gnorm=0.606, clip=0, loss_scale=32, train_wall=56, gb_free=15.9, wall=31215
2023-07-25 07:32:42 | INFO | train_inner | epoch 032:    126 / 1474 loss=2.001, trans_loss=4.898, nll_loss=2.063, w2v_ctc_loss=0.602, task_loss=0, contrastive_loss=0.066, total=4222.14, n_correct=2826.49, ppl=4.18, accuracy=66.944, wps=15088.1, ups=1.79, wpb=8444.3, bsz=322.6, num_updates=45800, lr=6.60819e-05, gnorm=0.585, clip=0, loss_scale=32, train_wall=55, gb_free=15.8, wall=31271
2023-07-25 07:33:38 | INFO | train_inner | epoch 032:    226 / 1474 loss=2.015, trans_loss=4.918, nll_loss=2.088, w2v_ctc_loss=0.614, task_loss=0, contrastive_loss=0.077, total=4159.77, n_correct=2769.12, ppl=4.25, accuracy=66.569, wps=14869.2, ups=1.79, wpb=8319.5, bsz=320.8, num_updates=45900, lr=6.60098e-05, gnorm=0.591, clip=0, loss_scale=32, train_wall=56, gb_free=16.5, wall=31327
2023-07-25 07:34:33 | INFO | train_inner | epoch 032:    326 / 1474 loss=2.005, trans_loss=4.907, nll_loss=2.074, w2v_ctc_loss=0.604, task_loss=0, contrastive_loss=0.069, total=4179.65, n_correct=2790.18, ppl=4.21, accuracy=66.756, wps=14982.8, ups=1.79, wpb=8359.3, bsz=313.8, num_updates=46000, lr=6.5938e-05, gnorm=0.598, clip=0, loss_scale=32, train_wall=55, gb_free=16.6, wall=31382
2023-07-25 07:34:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 07:34:55 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.351 | trans_loss 5.58 | nll_loss 2.858 | w2v_ctc_loss 1.369 | task_loss 0 | contrastive_loss 0.259 | total 4003.4 | n_correct 2489.1 | ppl 7.25 | accuracy 62.175 | uer 16.858 | wer 18.754 | raw_wer 18.754 | bleu 20.24 | wps 2345.2 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.57
2023-07-25 07:34:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-07-25 07:34:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_32_46000.pt
2023-07-25 07:34:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_32_46000.pt
2023-07-25 07:35:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 20.24) (writing took 15.831141244620085 seconds)
2023-07-25 07:36:08 | INFO | train_inner | epoch 032:    426 / 1474 loss=2.013, trans_loss=4.916, nll_loss=2.085, w2v_ctc_loss=0.617, task_loss=0, contrastive_loss=0.066, total=4172.34, n_correct=2781.48, ppl=4.24, accuracy=66.665, wps=8804.2, ups=1.06, wpb=8344.7, bsz=309.9, num_updates=46100, lr=6.58665e-05, gnorm=0.595, clip=0, loss_scale=32, train_wall=56, gb_free=17.4, wall=31477
2023-07-25 07:37:05 | INFO | train_inner | epoch 032:    526 / 1474 loss=2.027, trans_loss=4.927, nll_loss=2.1, w2v_ctc_loss=0.622, task_loss=0, contrastive_loss=0.15, total=4191.15, n_correct=2781.35, ppl=4.29, accuracy=66.362, wps=14888.2, ups=1.78, wpb=8382.3, bsz=315.1, num_updates=46200, lr=6.57952e-05, gnorm=0.592, clip=0, loss_scale=32, train_wall=56, gb_free=15.4, wall=31533
2023-07-25 07:38:01 | INFO | train_inner | epoch 032:    626 / 1474 loss=2.022, trans_loss=4.932, nll_loss=2.105, w2v_ctc_loss=0.622, task_loss=0, contrastive_loss=0.073, total=4138.05, n_correct=2740.18, ppl=4.3, accuracy=66.219, wps=14657.1, ups=1.77, wpb=8276.1, bsz=299.5, num_updates=46300, lr=6.57241e-05, gnorm=0.598, clip=0, loss_scale=32, train_wall=56, gb_free=13.8, wall=31590
2023-07-25 07:38:58 | INFO | train_inner | epoch 032:    726 / 1474 loss=2.022, trans_loss=4.931, nll_loss=2.105, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.057, total=4156.23, n_correct=2755.13, ppl=4.3, accuracy=66.289, wps=14725.7, ups=1.77, wpb=8312.5, bsz=303, num_updates=46400, lr=6.56532e-05, gnorm=0.593, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=31646
2023-07-25 07:39:53 | INFO | train_inner | epoch 032:    826 / 1474 loss=2.016, trans_loss=4.93, nll_loss=2.103, w2v_ctc_loss=0.616, task_loss=0, contrastive_loss=0.053, total=4112.3, n_correct=2728.05, ppl=4.3, accuracy=66.339, wps=14756.5, ups=1.79, wpb=8224.6, bsz=293.9, num_updates=46500, lr=6.55826e-05, gnorm=0.594, clip=0, loss_scale=32, train_wall=55, gb_free=16.2, wall=31702
2023-07-25 07:40:49 | INFO | train_inner | epoch 032:    926 / 1474 loss=2.016, trans_loss=4.931, nll_loss=2.105, w2v_ctc_loss=0.611, task_loss=0, contrastive_loss=0.052, total=4139.37, n_correct=2742.36, ppl=4.3, accuracy=66.251, wps=14858, ups=1.79, wpb=8278.7, bsz=298.6, num_updates=46600, lr=6.55122e-05, gnorm=0.599, clip=0, loss_scale=32, train_wall=55, gb_free=13.3, wall=31758
2023-07-25 07:41:45 | INFO | train_inner | epoch 032:   1026 / 1474 loss=2.031, trans_loss=4.941, nll_loss=2.118, w2v_ctc_loss=0.622, task_loss=0, contrastive_loss=0.147, total=4121.85, n_correct=2720.28, ppl=4.34, accuracy=65.997, wps=14771.7, ups=1.79, wpb=8243.7, bsz=306.1, num_updates=46700, lr=6.5442e-05, gnorm=0.601, clip=0, loss_scale=32, train_wall=55, gb_free=17.1, wall=31814
2023-07-25 07:42:41 | INFO | train_inner | epoch 032:   1126 / 1474 loss=2.029, trans_loss=4.945, nll_loss=2.122, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.089, total=4015.59, n_correct=2646.03, ppl=4.35, accuracy=65.894, wps=14263, ups=1.78, wpb=8031.2, bsz=270.1, num_updates=46800, lr=6.5372e-05, gnorm=0.607, clip=0, loss_scale=32, train_wall=56, gb_free=17.5, wall=31870
2023-07-25 07:43:37 | INFO | train_inner | epoch 032:   1226 / 1474 loss=2.039, trans_loss=4.949, nll_loss=2.129, w2v_ctc_loss=0.622, task_loss=0, contrastive_loss=0.199, total=4153.44, n_correct=2731.88, ppl=4.37, accuracy=65.774, wps=14734, ups=1.77, wpb=8306.9, bsz=310.8, num_updates=46900, lr=6.53023e-05, gnorm=0.605, clip=0, loss_scale=32, train_wall=56, gb_free=16.6, wall=31926
2023-07-25 07:44:33 | INFO | train_inner | epoch 032:   1326 / 1474 loss=2.026, trans_loss=4.941, nll_loss=2.118, w2v_ctc_loss=0.626, task_loss=0, contrastive_loss=0.052, total=4075.86, n_correct=2693.92, ppl=4.34, accuracy=66.095, wps=14733.8, ups=1.81, wpb=8151.7, bsz=295.4, num_updates=47000, lr=6.52328e-05, gnorm=0.603, clip=0, loss_scale=32, train_wall=55, gb_free=17.1, wall=31982
2023-07-25 07:45:29 | INFO | train_inner | epoch 032:   1426 / 1474 loss=2.045, trans_loss=4.945, nll_loss=2.123, w2v_ctc_loss=0.63, task_loss=0, contrastive_loss=0.283, total=4116.4, n_correct=2712.43, ppl=4.36, accuracy=65.893, wps=14618.4, ups=1.78, wpb=8232.8, bsz=307.6, num_updates=47100, lr=6.51635e-05, gnorm=0.597, clip=0, loss_scale=64, train_wall=56, gb_free=17, wall=32038
2023-07-25 07:45:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 07:46:21 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.371 | trans_loss 5.577 | nll_loss 2.856 | w2v_ctc_loss 1.44 | task_loss 0 | contrastive_loss 0.269 | total 4003.4 | n_correct 2485.4 | ppl 7.24 | accuracy 62.082 | uer 16.792 | wer 18.594 | raw_wer 18.594 | bleu 20.15 | wps 2022.9 | wpb 4003.4 | bsz 141.8 | num_updates 47148 | best_bleu 20.57
2023-07-25 07:46:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47148 updates
2023-07-25 07:46:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_20.1500.pt
2023-07-25 07:46:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_20.1500.pt
2023-07-25 07:46:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint.best_bleu_20.1500.pt (epoch 32 @ 47148 updates, score 20.15) (writing took 11.61068077199161 seconds)
2023-07-25 07:46:32 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-07-25 07:46:33 | INFO | train | epoch 032 | loss 2.022 | trans_loss 4.929 | nll_loss 2.103 | w2v_ctc_loss 0.618 | task_loss 0 | contrastive_loss 0.108 | total 4138.65 | n_correct 2743.63 | ppl 4.29 | accuracy 66.293 | wps 13417.6 | ups 1.62 | wpb 8277.3 | bsz 305.7 | num_updates 47148 | lr 6.51303e-05 | gnorm 0.597 | clip 0 | loss_scale 64 | train_wall 820 | gb_free 16.7 | wall 32101
2023-07-25 07:46:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 07:46:33 | INFO | fairseq.trainer | begin training epoch 33
2023-07-25 07:46:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 07:47:11 | INFO | train_inner | epoch 033:     52 / 1474 loss=2.024, trans_loss=4.926, nll_loss=2.099, w2v_ctc_loss=0.613, task_loss=0, contrastive_loss=0.159, total=4149.21, n_correct=2754.08, ppl=4.29, accuracy=66.376, wps=8163.4, ups=0.98, wpb=8298.4, bsz=320.5, num_updates=47200, lr=6.50945e-05, gnorm=0.598, clip=0, loss_scale=64, train_wall=56, gb_free=17.3, wall=32140
2023-07-25 07:48:07 | INFO | train_inner | epoch 033:    152 / 1474 loss=2.003, trans_loss=4.907, nll_loss=2.072, w2v_ctc_loss=0.601, task_loss=0, contrastive_loss=0.042, total=4073.9, n_correct=2717.59, ppl=4.2, accuracy=66.707, wps=14576.3, ups=1.79, wpb=8147.8, bsz=284.8, num_updates=47300, lr=6.50256e-05, gnorm=0.593, clip=0, loss_scale=64, train_wall=55, gb_free=15.6, wall=32196
2023-07-25 07:49:03 | INFO | train_inner | epoch 033:    252 / 1474 loss=2.023, trans_loss=4.906, nll_loss=2.075, w2v_ctc_loss=0.608, task_loss=0, contrastive_loss=0.225, total=4280.14, n_correct=2857.49, ppl=4.21, accuracy=66.762, wps=15283.7, ups=1.79, wpb=8560.3, bsz=346.5, num_updates=47400, lr=6.4957e-05, gnorm=0.594, clip=0, loss_scale=64, train_wall=56, gb_free=16.8, wall=32252
2023-07-25 07:49:59 | INFO | train_inner | epoch 033:    352 / 1474 loss=2.014, trans_loss=4.918, nll_loss=2.087, w2v_ctc_loss=0.615, task_loss=0, contrastive_loss=0.076, total=4120.27, n_correct=2739.61, ppl=4.25, accuracy=66.491, wps=14646.5, ups=1.78, wpb=8240.5, bsz=300.7, num_updates=47500, lr=6.48886e-05, gnorm=0.607, clip=0, loss_scale=64, train_wall=56, gb_free=17.6, wall=32308
2023-07-25 07:50:54 | INFO | train_inner | epoch 033:    452 / 1474 loss=2.003, trans_loss=4.906, nll_loss=2.072, w2v_ctc_loss=0.608, task_loss=0, contrastive_loss=0.052, total=4141.22, n_correct=2764.94, ppl=4.2, accuracy=66.766, wps=14920.6, ups=1.8, wpb=8282.4, bsz=310.8, num_updates=47600, lr=6.48204e-05, gnorm=0.595, clip=0, loss_scale=64, train_wall=55, gb_free=16.7, wall=32363
2023-07-25 07:51:50 | INFO | train_inner | epoch 033:    552 / 1474 loss=2.02, trans_loss=4.926, nll_loss=2.096, w2v_ctc_loss=0.621, task_loss=0, contrastive_loss=0.074, total=4133.59, n_correct=2740.22, ppl=4.28, accuracy=66.292, wps=14822.4, ups=1.79, wpb=8267.2, bsz=294, num_updates=47700, lr=6.47524e-05, gnorm=0.603, clip=0, loss_scale=64, train_wall=55, gb_free=15.6, wall=32419
2023-07-25 07:52:46 | INFO | train_inner | epoch 033:    652 / 1474 loss=2.023, trans_loss=4.936, nll_loss=2.111, w2v_ctc_loss=0.615, task_loss=0, contrastive_loss=0.108, total=4157.63, n_correct=2751.22, ppl=4.32, accuracy=66.173, wps=14845.6, ups=1.79, wpb=8315.3, bsz=301.6, num_updates=47800, lr=6.46846e-05, gnorm=0.593, clip=0, loss_scale=64, train_wall=56, gb_free=18, wall=32475
2023-07-25 07:53:42 | INFO | train_inner | epoch 033:    752 / 1474 loss=2.023, trans_loss=4.932, nll_loss=2.105, w2v_ctc_loss=0.63, task_loss=0, contrastive_loss=0.052, total=4070.75, n_correct=2696.52, ppl=4.3, accuracy=66.241, wps=14490.9, ups=1.78, wpb=8141.5, bsz=287.2, num_updates=47900, lr=6.46171e-05, gnorm=0.602, clip=0, loss_scale=64, train_wall=56, gb_free=16.7, wall=32531
2023-07-25 07:54:39 | INFO | train_inner | epoch 033:    852 / 1474 loss=2.009, trans_loss=4.917, nll_loss=2.088, w2v_ctc_loss=0.598, task_loss=0, contrastive_loss=0.122, total=4130.24, n_correct=2754.83, ppl=4.25, accuracy=66.699, wps=14657.1, ups=1.77, wpb=8260.5, bsz=316.3, num_updates=48000, lr=6.45497e-05, gnorm=0.592, clip=0, loss_scale=64, train_wall=56, gb_free=16.9, wall=32588
2023-07-25 07:54:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 07:55:04 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.365 | trans_loss 5.581 | nll_loss 2.855 | w2v_ctc_loss 1.412 | task_loss 0 | contrastive_loss 0.261 | total 4003.4 | n_correct 2488.4 | ppl 7.24 | accuracy 62.157 | uer 16.731 | wer 18.605 | raw_wer 18.605 | bleu 19.98 | wps 2001.3 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.57
2023-07-25 07:55:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-07-25 07:55:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_33_48000.pt
2023-07-25 07:55:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_33_48000.pt
2023-07-25 07:55:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 19.98) (writing took 14.683296468108892 seconds)
2023-07-25 07:56:15 | INFO | train_inner | epoch 033:    952 / 1474 loss=2.022, trans_loss=4.93, nll_loss=2.104, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.067, total=4151.18, n_correct=2751.06, ppl=4.3, accuracy=66.272, wps=8646.5, ups=1.04, wpb=8302.4, bsz=308.3, num_updates=48100, lr=6.44826e-05, gnorm=0.606, clip=0, loss_scale=64, train_wall=55, gb_free=11.9, wall=32684
2023-07-25 07:56:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-25 07:57:12 | INFO | train_inner | epoch 033:   1053 / 1474 loss=2.015, trans_loss=4.924, nll_loss=2.096, w2v_ctc_loss=0.616, task_loss=0, contrastive_loss=0.058, total=4120.84, n_correct=2737.48, ppl=4.27, accuracy=66.43, wps=14511.9, ups=1.76, wpb=8241.7, bsz=300, num_updates=48200, lr=6.44157e-05, gnorm=0.608, clip=0, loss_scale=32, train_wall=56, gb_free=16.1, wall=32740
2023-07-25 07:58:08 | INFO | train_inner | epoch 033:   1153 / 1474 loss=2.025, trans_loss=4.934, nll_loss=2.109, w2v_ctc_loss=0.611, task_loss=0, contrastive_loss=0.158, total=4181.58, n_correct=2768.05, ppl=4.31, accuracy=66.196, wps=14853.2, ups=1.78, wpb=8363.2, bsz=310, num_updates=48300, lr=6.43489e-05, gnorm=0.604, clip=0, loss_scale=32, train_wall=56, gb_free=15.5, wall=32797
2023-07-25 07:59:04 | INFO | train_inner | epoch 033:   1253 / 1474 loss=2.02, trans_loss=4.931, nll_loss=2.104, w2v_ctc_loss=0.622, task_loss=0, contrastive_loss=0.058, total=4115.76, n_correct=2725.56, ppl=4.3, accuracy=66.223, wps=14625, ups=1.78, wpb=8231.5, bsz=294.7, num_updates=48400, lr=6.42824e-05, gnorm=0.605, clip=0, loss_scale=32, train_wall=56, gb_free=17.1, wall=32853
2023-07-25 08:00:01 | INFO | train_inner | epoch 033:   1353 / 1474 loss=2.02, trans_loss=4.932, nll_loss=2.107, w2v_ctc_loss=0.618, task_loss=0, contrastive_loss=0.08, total=4120.69, n_correct=2731.38, ppl=4.31, accuracy=66.285, wps=14599.7, ups=1.77, wpb=8241.4, bsz=311.9, num_updates=48500, lr=6.42161e-05, gnorm=0.605, clip=0, loss_scale=32, train_wall=56, gb_free=17.1, wall=32910
2023-07-25 08:00:57 | INFO | train_inner | epoch 033:   1453 / 1474 loss=2.028, trans_loss=4.932, nll_loss=2.108, w2v_ctc_loss=0.615, task_loss=0, contrastive_loss=0.222, total=4125.28, n_correct=2735.22, ppl=4.31, accuracy=66.304, wps=14692.5, ups=1.78, wpb=8250.6, bsz=308.7, num_updates=48600, lr=6.415e-05, gnorm=0.602, clip=0, loss_scale=32, train_wall=56, gb_free=17.2, wall=32966
2023-07-25 08:01:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 08:01:33 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.363 | trans_loss 5.58 | nll_loss 2.854 | w2v_ctc_loss 1.41 | task_loss 0 | contrastive_loss 0.262 | total 4003.4 | n_correct 2483.7 | ppl 7.23 | accuracy 62.04 | uer 16.585 | wer 18.486 | raw_wer 18.486 | bleu 20.04 | wps 1994.7 | wpb 4003.4 | bsz 141.8 | num_updates 48621 | best_bleu 20.57
2023-07-25 08:01:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48621 updates
2023-07-25 08:01:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_last.pt
2023-07-25 08:01:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_last.pt
2023-07-25 08:01:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_last.pt (epoch 33 @ 48621 updates, score 20.04) (writing took 10.748811196535826 seconds)
2023-07-25 08:01:44 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-07-25 08:01:44 | INFO | train | epoch 033 | loss 2.017 | trans_loss 4.923 | nll_loss 2.095 | w2v_ctc_loss 0.615 | task_loss 0 | contrastive_loss 0.099 | total 4137.28 | n_correct 2748.07 | ppl 4.27 | accuracy 66.422 | wps 13374.9 | ups 1.62 | wpb 8274.6 | bsz 305.2 | num_updates 48621 | lr 6.41362e-05 | gnorm 0.6 | clip 0 | loss_scale 32 | train_wall 820 | gb_free 18.1 | wall 33013
2023-07-25 08:01:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 08:01:44 | INFO | fairseq.trainer | begin training epoch 34
2023-07-25 08:01:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 08:02:37 | INFO | train_inner | epoch 034:     79 / 1474 loss=2.006, trans_loss=4.905, nll_loss=2.07, w2v_ctc_loss=0.612, task_loss=0, contrastive_loss=0.059, total=4131.47, n_correct=2761.13, ppl=4.2, accuracy=66.832, wps=8255.8, ups=1, wpb=8262.9, bsz=301.7, num_updates=48700, lr=6.40841e-05, gnorm=0.605, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=33066
2023-07-25 08:03:33 | INFO | train_inner | epoch 034:    179 / 1474 loss=2.003, trans_loss=4.899, nll_loss=2.062, w2v_ctc_loss=0.607, task_loss=0, contrastive_loss=0.061, total=4065.88, n_correct=2719.24, ppl=4.18, accuracy=66.879, wps=14616.5, ups=1.8, wpb=8131.8, bsz=295.1, num_updates=48800, lr=6.40184e-05, gnorm=0.604, clip=0, loss_scale=32, train_wall=55, gb_free=16.3, wall=33121
2023-07-25 08:04:29 | INFO | train_inner | epoch 034:    279 / 1474 loss=2.03, trans_loss=4.92, nll_loss=2.091, w2v_ctc_loss=0.607, task_loss=0, contrastive_loss=0.272, total=4246.3, n_correct=2820.3, ppl=4.26, accuracy=66.418, wps=14985, ups=1.76, wpb=8492.6, bsz=328.7, num_updates=48900, lr=6.39529e-05, gnorm=0.593, clip=0, loss_scale=32, train_wall=56, gb_free=18, wall=33178
2023-07-25 08:05:26 | INFO | train_inner | epoch 034:    379 / 1474 loss=2.008, trans_loss=4.9, nll_loss=2.065, w2v_ctc_loss=0.601, task_loss=0, contrastive_loss=0.159, total=4156.17, n_correct=2782.63, ppl=4.18, accuracy=66.952, wps=14697.7, ups=1.77, wpb=8312.3, bsz=316.7, num_updates=49000, lr=6.38877e-05, gnorm=0.592, clip=0, loss_scale=32, train_wall=56, gb_free=18, wall=33235
2023-07-25 08:06:22 | INFO | train_inner | epoch 034:    479 / 1474 loss=2.015, trans_loss=4.919, nll_loss=2.088, w2v_ctc_loss=0.622, task_loss=0, contrastive_loss=0.054, total=4070.55, n_correct=2706.82, ppl=4.25, accuracy=66.498, wps=14446.9, ups=1.77, wpb=8141.1, bsz=284.6, num_updates=49100, lr=6.38226e-05, gnorm=0.608, clip=0, loss_scale=32, train_wall=56, gb_free=17.7, wall=33291
2023-07-25 08:07:18 | INFO | train_inner | epoch 034:    579 / 1474 loss=2.005, trans_loss=4.905, nll_loss=2.071, w2v_ctc_loss=0.608, task_loss=0, contrastive_loss=0.056, total=4119.38, n_correct=2754.53, ppl=4.2, accuracy=66.868, wps=14784, ups=1.79, wpb=8238.8, bsz=300.3, num_updates=49200, lr=6.37577e-05, gnorm=0.6, clip=0, loss_scale=32, train_wall=55, gb_free=13.6, wall=33347
2023-07-25 08:08:14 | INFO | train_inner | epoch 034:    679 / 1474 loss=2.005, trans_loss=4.911, nll_loss=2.08, w2v_ctc_loss=0.605, task_loss=0, contrastive_loss=0.05, total=4124.83, n_correct=2752.95, ppl=4.23, accuracy=66.741, wps=14766.3, ups=1.79, wpb=8249.7, bsz=300.2, num_updates=49300, lr=6.3693e-05, gnorm=0.597, clip=0, loss_scale=32, train_wall=55, gb_free=14.7, wall=33403
2023-07-25 08:09:10 | INFO | train_inner | epoch 034:    779 / 1474 loss=2.017, trans_loss=4.931, nll_loss=2.105, w2v_ctc_loss=0.603, task_loss=0, contrastive_loss=0.12, total=4082.07, n_correct=2706.16, ppl=4.3, accuracy=66.294, wps=14501, ups=1.78, wpb=8164.1, bsz=295, num_updates=49400, lr=6.36285e-05, gnorm=0.605, clip=0, loss_scale=32, train_wall=56, gb_free=16, wall=33459
2023-07-25 08:10:06 | INFO | train_inner | epoch 034:    879 / 1474 loss=2.016, trans_loss=4.924, nll_loss=2.096, w2v_ctc_loss=0.614, task_loss=0, contrastive_loss=0.082, total=4100.9, n_correct=2727.86, ppl=4.28, accuracy=66.519, wps=14700.7, ups=1.79, wpb=8201.8, bsz=296.6, num_updates=49500, lr=6.35642e-05, gnorm=0.608, clip=0, loss_scale=32, train_wall=55, gb_free=12.7, wall=33515
2023-07-25 08:11:02 | INFO | train_inner | epoch 034:    979 / 1474 loss=2.016, trans_loss=4.921, nll_loss=2.092, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.076, total=4168.39, n_correct=2773.73, ppl=4.26, accuracy=66.542, wps=14946.1, ups=1.79, wpb=8336.8, bsz=311.9, num_updates=49600, lr=6.35001e-05, gnorm=0.603, clip=0, loss_scale=32, train_wall=55, gb_free=16.1, wall=33570
2023-07-25 08:11:58 | INFO | train_inner | epoch 034:   1079 / 1474 loss=2.015, trans_loss=4.924, nll_loss=2.097, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.057, total=4150.57, n_correct=2758.85, ppl=4.28, accuracy=66.469, wps=14827.1, ups=1.79, wpb=8301.1, bsz=308.5, num_updates=49700, lr=6.34361e-05, gnorm=0.595, clip=0, loss_scale=32, train_wall=56, gb_free=17.1, wall=33626
2023-07-25 08:12:54 | INFO | train_inner | epoch 034:   1179 / 1474 loss=2.013, trans_loss=4.926, nll_loss=2.098, w2v_ctc_loss=0.61, task_loss=0, contrastive_loss=0.068, total=4098.77, n_correct=2724.95, ppl=4.28, accuracy=66.482, wps=14595.2, ups=1.78, wpb=8197.5, bsz=297.1, num_updates=49800, lr=6.33724e-05, gnorm=0.6, clip=0, loss_scale=32, train_wall=56, gb_free=17.2, wall=33683
2023-07-25 08:13:50 | INFO | train_inner | epoch 034:   1279 / 1474 loss=2.011, trans_loss=4.923, nll_loss=2.095, w2v_ctc_loss=0.61, task_loss=0, contrastive_loss=0.053, total=4150.54, n_correct=2757.61, ppl=4.27, accuracy=66.44, wps=14845.4, ups=1.79, wpb=8301.1, bsz=301, num_updates=49900, lr=6.33089e-05, gnorm=0.598, clip=0, loss_scale=32, train_wall=55, gb_free=17.5, wall=33739
2023-07-25 08:14:46 | INFO | train_inner | epoch 034:   1379 / 1474 loss=2.026, trans_loss=4.929, nll_loss=2.104, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.12, total=4196.91, n_correct=2780.42, ppl=4.3, accuracy=66.249, wps=14899.6, ups=1.78, wpb=8393.8, bsz=321.4, num_updates=50000, lr=6.32456e-05, gnorm=0.599, clip=0, loss_scale=32, train_wall=56, gb_free=16.3, wall=33795
2023-07-25 08:14:46 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-07-25 08:14:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 08:15:10 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.354 | trans_loss 5.576 | nll_loss 2.851 | w2v_ctc_loss 1.389 | task_loss 0 | contrastive_loss 0.259 | total 4003.4 | n_correct 2488 | ppl 7.22 | accuracy 62.147 | uer 16.702 | wer 18.538 | raw_wer 18.538 | bleu 20.01 | wps 2021.8 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.57
2023-07-25 08:15:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-07-25 08:15:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_34_50000.pt
2023-07-25 08:15:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_34_50000.pt
2023-07-25 08:15:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_baseline_mt_0724_2250/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 20.01) (writing took 11.443282188847661 seconds)
2023-07-25 08:15:22 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-07-25 08:15:22 | INFO | train | epoch 034 | loss 2.013 | trans_loss 4.917 | nll_loss 2.086 | w2v_ctc_loss 0.612 | task_loss 0 | contrastive_loss 0.094 | total 4133.04 | n_correct 2752.08 | ppl 4.25 | accuracy 66.587 | wps 13925.7 | ups 1.68 | wpb 8266.1 | bsz 304.2 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.6 | clip 0 | loss_scale 32 | train_wall 768 | gb_free 16.3 | wall 33831
2023-07-25 08:15:22 | INFO | fairseq_cli.train | done training in 33756.7 seconds
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
