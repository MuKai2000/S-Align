2023-08-01 10:43:22 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:12497
2023-08-01 10:43:22 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:12497
2023-08-01 10:43:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-01 10:43:22 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:12497
2023-08-01 10:43:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-01 10:43:22 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:12497
2023-08-01 10:43:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-01 10:43:22 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:12497
2023-08-01 10:43:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-01 10:43:22 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:12497
2023-08-01 10:43:22 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:12497
2023-08-01 10:43:22 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:12497
2023-08-01 10:43:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-01 10:43:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-01 10:43:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-01 10:43:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-01 10:43:22 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-01 10:43:22 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-08-01 10:43:22 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-01 10:43:22 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-01 10:43:22 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-01 10:43:22 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-01 10:43:22 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-08-01 10:43:22 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-08-01 10:43:22 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-01 10:43:22 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-08-01 10:43:22 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-08-01 10:43:22 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-08-01 10:43:22 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-01 10:43:22 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-01 10:43:22 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-08-01 10:43:22 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-08-01 10:43:26 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12497', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-01 10:43:26 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-01 10:43:26 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-01 10:43:26 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-01 10:43:26 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-01 10:43:26 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-01 10:43:31 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-01 10:43:31 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-01 10:43:31 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-01 10:43:32 | INFO | root | load pretrained hubert
2023-08-01 10:43:34 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-01 10:43:35 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-01 10:43:36 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-01 10:43:36 | INFO | root | share the sematic adapter and textual encoder
2023-08-01 10:43:36 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-01 10:43:36 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-01 10:43:36 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-01 10:43:36 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-01 10:43:36 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-08-01 10:43:36 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-01 10:43:36 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-01 10:43:36 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-01 10:43:36 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-01 10:43:36 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-01 10:43:39 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-01 10:43:45 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-01 10:43:45 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-01 10:43:46 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-01 10:43:46 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-01 10:43:46 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-01 10:43:46 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-01 10:43:46 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-01 10:43:46 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-01 10:43:46 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-01 10:43:46 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-01 10:43:46 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-01 10:43:46 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-01 10:43:46 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-01 10:43:46 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-01 10:43:46 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_last.pt
2023-08-01 10:43:46 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_last.pt
2023-08-01 10:43:46 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-01 10:43:46 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-01 10:43:46 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-01 10:43:46 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-01 10:43:47 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-01 10:43:49 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-01 10:44:36 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-01 10:44:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 10:44:36 | INFO | fairseq.trainer | begin training epoch 1
2023-08-01 10:44:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 10:45:54 | INFO | train_inner | epoch 001:    100 / 1474 loss=19.136, trans_loss=5.598, nll_loss=4.163, w2v_ctc_loss=22.485, task_loss=1.749, contrastive_loss=3.325, total=4207.04, n_correct=209.18, ppl=17.91, accuracy=4.972, wps=19505.1, ups=1.55, wpb=12551.1, bsz=471.4, num_updates=100, lr=4.098e-06, gnorm=0.884, clip=0, loss_scale=128, train_wall=69, gb_free=19.5, wall=128
2023-08-01 10:46:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-01 10:46:59 | INFO | train_inner | epoch 001:    201 / 1474 loss=16.985, trans_loss=5.479, nll_loss=4.066, w2v_ctc_loss=19.348, task_loss=1.707, contrastive_loss=3.277, total=4124.14, n_correct=223.22, ppl=16.75, accuracy=5.413, wps=19000.6, ups=1.54, wpb=12313.4, bsz=461, num_updates=200, lr=8.096e-06, gnorm=3.628, clip=0, loss_scale=64, train_wall=64, gb_free=19.2, wall=193
2023-08-01 10:48:02 | INFO | train_inner | epoch 001:    301 / 1474 loss=10.074, trans_loss=5.488, nll_loss=4.132, w2v_ctc_loss=8.756, task_loss=1.706, contrastive_loss=3.202, total=4079.62, n_correct=206, ppl=17.53, accuracy=5.049, wps=19273.3, ups=1.58, wpb=12186.7, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=4.593, clip=0, loss_scale=64, train_wall=63, gb_free=19.9, wall=256
2023-08-01 10:49:05 | INFO | train_inner | epoch 001:    401 / 1474 loss=8.836, trans_loss=5.515, nll_loss=4.187, w2v_ctc_loss=6.8, task_loss=1.496, contrastive_loss=3.236, total=4174.14, n_correct=195.4, ppl=18.21, accuracy=4.681, wps=19648.4, ups=1.58, wpb=12463.5, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=2.932, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=319
2023-08-01 10:50:09 | INFO | train_inner | epoch 001:    501 / 1474 loss=8.406, trans_loss=5.494, nll_loss=4.177, w2v_ctc_loss=6.167, task_loss=1.369, contrastive_loss=3.229, total=4176.18, n_correct=189.76, ppl=18.09, accuracy=4.544, wps=19583.4, ups=1.57, wpb=12479.7, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=1.406, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=383
2023-08-01 10:51:13 | INFO | train_inner | epoch 001:    601 / 1474 loss=8.154, trans_loss=5.523, nll_loss=4.212, w2v_ctc_loss=5.8, task_loss=1.275, contrastive_loss=3.282, total=4147.79, n_correct=187.85, ppl=18.54, accuracy=4.529, wps=19239.7, ups=1.56, wpb=12371.6, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.72, clip=0, loss_scale=64, train_wall=64, gb_free=18.9, wall=448
2023-08-01 10:52:16 | INFO | train_inner | epoch 001:    701 / 1474 loss=7.994, trans_loss=5.518, nll_loss=4.213, w2v_ctc_loss=5.682, task_loss=1.325, contrastive_loss=3.031, total=4152.1, n_correct=200.55, ppl=18.54, accuracy=4.83, wps=19629.6, ups=1.58, wpb=12395.5, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=0.555, clip=0, loss_scale=64, train_wall=63, gb_free=19.5, wall=511
2023-08-01 10:53:20 | INFO | train_inner | epoch 001:    801 / 1474 loss=7.717, trans_loss=5.45, nll_loss=4.14, w2v_ctc_loss=5.46, task_loss=1.281, contrastive_loss=2.939, total=4123.83, n_correct=246.29, ppl=17.63, accuracy=5.972, wps=19454.6, ups=1.58, wpb=12306.1, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=0.83, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=574
2023-08-01 10:54:22 | INFO | train_inner | epoch 001:    901 / 1474 loss=7.463, trans_loss=5.419, nll_loss=4.114, w2v_ctc_loss=5.281, task_loss=1.302, contrastive_loss=2.7, total=4163.61, n_correct=270.74, ppl=17.32, accuracy=6.503, wps=19810.5, ups=1.59, wpb=12433.9, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=1.378, clip=0, loss_scale=64, train_wall=62, gb_free=18.9, wall=637
2023-08-01 10:55:27 | INFO | train_inner | epoch 001:   1001 / 1474 loss=7.206, trans_loss=5.397, nll_loss=4.096, w2v_ctc_loss=5.072, task_loss=1.311, contrastive_loss=2.551, total=4135.34, n_correct=289.42, ppl=17.1, accuracy=6.999, wps=19199.5, ups=1.55, wpb=12353.2, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=1.429, clip=0, loss_scale=64, train_wall=64, gb_free=19, wall=701
2023-08-01 10:56:30 | INFO | train_inner | epoch 001:   1101 / 1474 loss=6.937, trans_loss=5.386, nll_loss=4.085, w2v_ctc_loss=4.872, task_loss=1.322, contrastive_loss=2.328, total=4147.38, n_correct=312.65, ppl=16.97, accuracy=7.538, wps=19677.7, ups=1.59, wpb=12367, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=1.671, clip=0, loss_scale=64, train_wall=62, gb_free=18.9, wall=764
2023-08-01 10:57:33 | INFO | train_inner | epoch 001:   1201 / 1474 loss=6.715, trans_loss=5.368, nll_loss=4.069, w2v_ctc_loss=4.703, task_loss=1.377, contrastive_loss=2.123, total=4139.9, n_correct=318.37, ppl=16.79, accuracy=7.69, wps=19610, ups=1.59, wpb=12366.5, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=1.749, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=827
2023-08-01 10:58:35 | INFO | train_inner | epoch 001:   1301 / 1474 loss=6.488, trans_loss=5.366, nll_loss=4.069, w2v_ctc_loss=4.502, task_loss=1.324, contrastive_loss=1.93, total=4046.58, n_correct=322.7, ppl=16.78, accuracy=7.975, wps=19254.5, ups=1.59, wpb=12081.6, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=1.748, clip=0, loss_scale=64, train_wall=62, gb_free=19.7, wall=890
2023-08-01 10:59:40 | INFO | train_inner | epoch 001:   1401 / 1474 loss=6.277, trans_loss=5.357, nll_loss=4.061, w2v_ctc_loss=4.295, task_loss=1.308, contrastive_loss=1.996, total=4133.18, n_correct=335.2, ppl=16.69, accuracy=8.11, wps=19196.8, ups=1.55, wpb=12350, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=1.614, clip=0, loss_scale=64, train_wall=64, gb_free=19.9, wall=954
2023-08-01 11:00:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 11:01:06 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.542 | trans_loss 10.907 | nll_loss 9.888 | w2v_ctc_loss 5.571 | task_loss 7.547 | contrastive_loss 2.34 | total 4003.4 | n_correct 386.1 | ppl 947.54 | accuracy 9.644 | uer 71.935 | wer 69.833 | raw_wer 69.833 | bleu 0.03 | wps 1155.1 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-08-01 11:01:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-08-01 11:01:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 11:01:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 11:01:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.03) (writing took 6.39070138335228 seconds)
2023-08-01 11:01:12 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-01 11:01:12 | INFO | train | epoch 001 | loss 9.031 | trans_loss 5.45 | nll_loss 4.124 | w2v_ctc_loss 7.635 | task_loss 1.41 | contrastive_loss 2.755 | total 4138.55 | n_correct 254.762 | ppl 17.43 | accuracy 6.156 | wps 18520.3 | ups 1.5 | wpb 12355.5 | bsz 458.4 | num_updates 1473 | lr 5.89905e-05 | gnorm 1.789 | clip 0 | loss_scale 64 | train_wall 935 | gb_free 19.2 | wall 1046
2023-08-01 11:01:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 11:01:12 | INFO | fairseq.trainer | begin training epoch 2
2023-08-01 11:01:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 11:01:38 | INFO | train_inner | epoch 002:     27 / 1474 loss=6.082, trans_loss=5.351, nll_loss=4.049, w2v_ctc_loss=4.095, task_loss=1.246, contrastive_loss=1.837, total=4162.95, n_correct=338.99, ppl=16.55, accuracy=8.143, wps=10487.3, ups=0.84, wpb=12416.8, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=1.629, clip=0, loss_scale=64, train_wall=63, gb_free=19.6, wall=1072
2023-08-01 11:02:41 | INFO | train_inner | epoch 002:    127 / 1474 loss=5.916, trans_loss=5.346, nll_loss=4.042, w2v_ctc_loss=3.972, task_loss=1.33, contrastive_loss=1.632, total=4155.98, n_correct=340.84, ppl=16.47, accuracy=8.201, wps=19727.2, ups=1.59, wpb=12394.8, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=1.703, clip=0, loss_scale=64, train_wall=62, gb_free=18.9, wall=1135
2023-08-01 11:03:44 | INFO | train_inner | epoch 002:    227 / 1474 loss=5.745, trans_loss=5.325, nll_loss=4.022, w2v_ctc_loss=3.771, task_loss=1.153, contrastive_loss=1.657, total=4179.21, n_correct=349.19, ppl=16.24, accuracy=8.355, wps=19801.8, ups=1.59, wpb=12484.6, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=1.485, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=1198
2023-08-01 11:04:48 | INFO | train_inner | epoch 002:    327 / 1474 loss=5.581, trans_loss=5.324, nll_loss=4.017, w2v_ctc_loss=3.677, task_loss=1.325, contrastive_loss=1.364, total=4146.1, n_correct=355.17, ppl=16.18, accuracy=8.566, wps=19258.3, ups=1.56, wpb=12374.1, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=1.371, clip=0, loss_scale=64, train_wall=64, gb_free=18.8, wall=1263
2023-08-01 11:05:51 | INFO | train_inner | epoch 002:    427 / 1474 loss=5.437, trans_loss=5.316, nll_loss=4.01, w2v_ctc_loss=3.575, task_loss=1.456, contrastive_loss=1.185, total=4037.99, n_correct=343.19, ppl=16.11, accuracy=8.499, wps=19255.2, ups=1.6, wpb=12069.2, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=1.411, clip=0, loss_scale=64, train_wall=62, gb_free=19, wall=1325
2023-08-01 11:06:54 | INFO | train_inner | epoch 002:    527 / 1474 loss=5.326, trans_loss=5.305, nll_loss=3.993, w2v_ctc_loss=3.414, task_loss=1.266, contrastive_loss=1.278, total=4176.97, n_correct=362.42, ppl=15.92, accuracy=8.677, wps=19735.3, ups=1.58, wpb=12463.5, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=1.26, clip=0, loss_scale=64, train_wall=63, gb_free=19.6, wall=1388
2023-08-01 11:06:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 11:07:34 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.92 | trans_loss 10.749 | nll_loss 9.673 | w2v_ctc_loss 4.454 | task_loss 7.546 | contrastive_loss 1.601 | total 4003.4 | n_correct 415.3 | ppl 816.21 | accuracy 10.374 | uer 61.105 | wer 59.11 | raw_wer 59.11 | bleu 0.04 | wps 1157.9 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.04
2023-08-01 11:07:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-01 11:07:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_2_2000.pt
2023-08-01 11:07:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_2_2000.pt
2023-08-01 11:07:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.04) (writing took 21.2601888012141 seconds)
2023-08-01 11:08:59 | INFO | train_inner | epoch 002:    627 / 1474 loss=5.191, trans_loss=5.298, nll_loss=3.984, w2v_ctc_loss=3.308, task_loss=1.309, contrastive_loss=1.076, total=4126.49, n_correct=366.38, ppl=15.82, accuracy=8.879, wps=9851.1, ups=0.8, wpb=12314.9, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=1.139, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=1513
2023-08-01 11:10:03 | INFO | train_inner | epoch 002:    727 / 1474 loss=5.119, trans_loss=5.281, nll_loss=3.966, w2v_ctc_loss=3.224, task_loss=1.283, contrastive_loss=1.177, total=4149.06, n_correct=378.85, ppl=15.62, accuracy=9.131, wps=19429.6, ups=1.57, wpb=12386.4, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=1.127, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=1577
2023-08-01 11:11:06 | INFO | train_inner | epoch 002:    827 / 1474 loss=5.029, trans_loss=5.266, nll_loss=3.949, w2v_ctc_loss=3.155, task_loss=1.317, contrastive_loss=1.124, total=4175.4, n_correct=385.92, ppl=15.44, accuracy=9.243, wps=19656.6, ups=1.58, wpb=12471.9, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=0.99, clip=0, loss_scale=128, train_wall=63, gb_free=19.8, wall=1641
2023-08-01 11:12:09 | INFO | train_inner | epoch 002:    927 / 1474 loss=4.938, trans_loss=5.253, nll_loss=3.931, w2v_ctc_loss=3.063, task_loss=1.344, contrastive_loss=1.108, total=4104.2, n_correct=383.61, ppl=15.25, accuracy=9.347, wps=19532.2, ups=1.59, wpb=12253.1, bsz=445.9, num_updates=2400, lr=9.6052e-05, gnorm=0.994, clip=0, loss_scale=128, train_wall=62, gb_free=19, wall=1703
2023-08-01 11:13:13 | INFO | train_inner | epoch 002:   1027 / 1474 loss=4.852, trans_loss=5.245, nll_loss=3.924, w2v_ctc_loss=2.994, task_loss=1.305, contrastive_loss=0.957, total=4102.5, n_correct=388.67, ppl=15.18, accuracy=9.474, wps=19264.3, ups=1.57, wpb=12251.2, bsz=456.3, num_updates=2500, lr=0.00010005, gnorm=0.868, clip=0, loss_scale=128, train_wall=63, gb_free=19.2, wall=1767
2023-08-01 11:14:17 | INFO | train_inner | epoch 002:   1127 / 1474 loss=4.809, trans_loss=5.239, nll_loss=3.914, w2v_ctc_loss=2.905, task_loss=1.187, contrastive_loss=1.169, total=4187.61, n_correct=401.14, ppl=15.08, accuracy=9.579, wps=19429.3, ups=1.55, wpb=12495.7, bsz=487.1, num_updates=2600, lr=0.000104048, gnorm=0.881, clip=0, loss_scale=128, train_wall=64, gb_free=19.5, wall=1831
2023-08-01 11:15:21 | INFO | train_inner | epoch 002:   1227 / 1474 loss=4.753, trans_loss=5.227, nll_loss=3.9, w2v_ctc_loss=2.863, task_loss=1.194, contrastive_loss=1.091, total=4221.06, n_correct=420.45, ppl=14.93, accuracy=9.961, wps=19728, ups=1.57, wpb=12596.1, bsz=492.8, num_updates=2700, lr=0.000108046, gnorm=0.792, clip=0, loss_scale=128, train_wall=63, gb_free=19.5, wall=1895
2023-08-01 11:16:23 | INFO | train_inner | epoch 002:   1327 / 1474 loss=4.661, trans_loss=5.219, nll_loss=3.894, w2v_ctc_loss=2.829, task_loss=1.259, contrastive_loss=0.798, total=4157.86, n_correct=418.05, ppl=14.87, accuracy=10.054, wps=19883.6, ups=1.6, wpb=12425.5, bsz=460.7, num_updates=2800, lr=0.000112044, gnorm=0.752, clip=0, loss_scale=128, train_wall=62, gb_free=19.5, wall=1958
2023-08-01 11:17:27 | INFO | train_inner | epoch 002:   1427 / 1474 loss=4.626, trans_loss=5.225, nll_loss=3.901, w2v_ctc_loss=2.79, task_loss=1.414, contrastive_loss=0.888, total=4054.34, n_correct=402.57, ppl=14.94, accuracy=9.929, wps=19174.2, ups=1.58, wpb=12107, bsz=438.8, num_updates=2900, lr=0.000116042, gnorm=0.708, clip=0, loss_scale=128, train_wall=63, gb_free=19.4, wall=2021
2023-08-01 11:17:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 11:18:36 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.154 | trans_loss 10.233 | nll_loss 9.046 | w2v_ctc_loss 3.575 | task_loss 7.547 | contrastive_loss 0.935 | total 4003.4 | n_correct 505.4 | ppl 528.51 | accuracy 12.624 | uer 51.477 | wer 50.334 | raw_wer 50.334 | bleu 0.12 | wps 1163.9 | wpb 4003.4 | bsz 141.8 | num_updates 2947 | best_bleu 0.12
2023-08-01 11:18:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2947 updates
2023-08-01 11:18:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 11:18:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 11:18:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt (epoch 2 @ 2947 updates, score 0.12) (writing took 22.32607151195407 seconds)
2023-08-01 11:18:59 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-01 11:18:59 | INFO | train | epoch 002 | loss 5.141 | trans_loss 5.276 | nll_loss 3.96 | w2v_ctc_loss 3.252 | task_loss 1.292 | contrastive_loss 1.181 | total 4138.65 | n_correct 378.586 | ppl 15.56 | accuracy 9.148 | wps 17069.3 | ups 1.38 | wpb 12355.8 | bsz 458.5 | num_updates 2947 | lr 0.000117921 | gnorm 1.1 | clip 0 | loss_scale 128 | train_wall 927 | gb_free 19.3 | wall 2113
2023-08-01 11:18:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 11:18:59 | INFO | fairseq.trainer | begin training epoch 3
2023-08-01 11:18:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 11:19:40 | INFO | train_inner | epoch 003:     53 / 1474 loss=4.552, trans_loss=5.199, nll_loss=3.868, w2v_ctc_loss=2.729, task_loss=1.324, contrastive_loss=0.788, total=4071.2, n_correct=419.2, ppl=14.61, accuracy=10.297, wps=9076.5, ups=0.75, wpb=12154.1, bsz=442.6, num_updates=3000, lr=0.00012004, gnorm=0.689, clip=0, loss_scale=128, train_wall=64, gb_free=19.1, wall=2155
2023-08-01 11:19:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-01 11:19:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-01 11:19:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-01 11:19:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-01 11:19:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-01 11:21:15 | INFO | train_inner | epoch 003:    158 / 1474 loss=3.759, trans_loss=4.364, nll_loss=2.774, w2v_ctc_loss=2.42, task_loss=0.903, contrastive_loss=0.729, total=4144.18, n_correct=1168.64, ppl=6.84, accuracy=28.2, wps=13075.8, ups=1.06, wpb=12374.6, bsz=458.6, num_updates=3100, lr=0.000124038, gnorm=2.11, clip=1, loss_scale=4, train_wall=94, gb_free=16.6, wall=2249
2023-08-01 11:22:47 | INFO | train_inner | epoch 003:    258 / 1474 loss=3.368, trans_loss=4.141, nll_loss=2.485, w2v_ctc_loss=2.185, task_loss=0.915, contrastive_loss=0.608, total=4161.13, n_correct=1441.13, ppl=5.6, accuracy=34.633, wps=13495.9, ups=1.09, wpb=12431.5, bsz=467, num_updates=3200, lr=0.000128036, gnorm=1.465, clip=0, loss_scale=4, train_wall=92, gb_free=17.1, wall=2341
2023-08-01 11:24:19 | INFO | train_inner | epoch 003:    358 / 1474 loss=3.262, trans_loss=4.093, nll_loss=2.417, w2v_ctc_loss=2.094, task_loss=0.921, contrastive_loss=0.652, total=4150.02, n_correct=1513.17, ppl=5.34, accuracy=36.462, wps=13554.4, ups=1.09, wpb=12384.9, bsz=461.6, num_updates=3300, lr=0.000132034, gnorm=1.489, clip=0, loss_scale=4, train_wall=91, gb_free=17.1, wall=2433
2023-08-01 11:25:51 | INFO | train_inner | epoch 003:    458 / 1474 loss=3.151, trans_loss=4.044, nll_loss=2.354, w2v_ctc_loss=2.022, task_loss=0.891, contrastive_loss=0.508, total=4209.57, n_correct=1617.53, ppl=5.11, accuracy=38.425, wps=13648.2, ups=1.09, wpb=12566, bsz=476.8, num_updates=3400, lr=0.000136032, gnorm=1.452, clip=0, loss_scale=4, train_wall=92, gb_free=16.1, wall=2525
2023-08-01 11:27:21 | INFO | train_inner | epoch 003:    558 / 1474 loss=3.055, trans_loss=4.016, nll_loss=2.319, w2v_ctc_loss=1.945, task_loss=0.978, contrastive_loss=0.472, total=4088.48, n_correct=1611.2, ppl=4.99, accuracy=39.408, wps=13464.7, ups=1.1, wpb=12212.5, bsz=439.7, num_updates=3500, lr=0.00014003, gnorm=1.25, clip=0, loss_scale=4, train_wall=90, gb_free=17.7, wall=2616
2023-08-01 11:28:54 | INFO | train_inner | epoch 003:    658 / 1474 loss=3.005, trans_loss=3.984, nll_loss=2.272, w2v_ctc_loss=1.881, task_loss=0.879, contrastive_loss=0.59, total=4221.58, n_correct=1723.3, ppl=4.83, accuracy=40.821, wps=13632.8, ups=1.08, wpb=12587.8, bsz=481.9, num_updates=3600, lr=0.000144028, gnorm=1.209, clip=0, loss_scale=4, train_wall=92, gb_free=16.4, wall=2708
2023-08-01 11:30:25 | INFO | train_inner | epoch 003:    758 / 1474 loss=2.923, trans_loss=3.95, nll_loss=2.233, w2v_ctc_loss=1.846, task_loss=0.877, contrastive_loss=0.356, total=4167.41, n_correct=1746.16, ppl=4.7, accuracy=41.9, wps=13598.3, ups=1.09, wpb=12447.6, bsz=472.6, num_updates=3700, lr=0.000148026, gnorm=1.148, clip=0, loss_scale=4, train_wall=91, gb_free=16.3, wall=2800
2023-08-01 11:31:57 | INFO | train_inner | epoch 003:    858 / 1474 loss=2.876, trans_loss=3.94, nll_loss=2.217, w2v_ctc_loss=1.805, task_loss=0.928, contrastive_loss=0.321, total=4165.53, n_correct=1774.28, ppl=4.65, accuracy=42.594, wps=13562.3, ups=1.09, wpb=12437.8, bsz=456.1, num_updates=3800, lr=0.000152024, gnorm=1.157, clip=0, loss_scale=4, train_wall=91, gb_free=17.1, wall=2891
2023-08-01 11:33:28 | INFO | train_inner | epoch 003:    958 / 1474 loss=2.842, trans_loss=3.919, nll_loss=2.188, w2v_ctc_loss=1.774, task_loss=0.894, contrastive_loss=0.35, total=4162.3, n_correct=1814.09, ppl=4.56, accuracy=43.584, wps=13573.2, ups=1.09, wpb=12417, bsz=469.2, num_updates=3900, lr=0.000156022, gnorm=1.136, clip=0, loss_scale=4, train_wall=91, gb_free=16.8, wall=2983
2023-08-01 11:35:00 | INFO | train_inner | epoch 003:   1058 / 1474 loss=2.806, trans_loss=3.898, nll_loss=2.162, w2v_ctc_loss=1.76, task_loss=0.98, contrastive_loss=0.302, total=4069.95, n_correct=1794.44, ppl=4.48, accuracy=44.09, wps=13284.3, ups=1.09, wpb=12153.7, bsz=443.6, num_updates=4000, lr=0.00016002, gnorm=1.059, clip=0, loss_scale=4, train_wall=91, gb_free=16.3, wall=3074
2023-08-01 11:35:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 11:35:24 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.046 | trans_loss 6.424 | nll_loss 3.972 | w2v_ctc_loss 2.121 | task_loss 4.329 | contrastive_loss 0.424 | total 4003.4 | n_correct 1965.1 | ppl 15.69 | accuracy 49.086 | uer 30.674 | wer 31.438 | raw_wer 31.438 | bleu 10.97 | wps 2033.9 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 10.97
2023-08-01 11:35:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-01 11:35:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_3_4000.pt
2023-08-01 11:35:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_3_4000.pt
2023-08-01 11:35:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 10.97) (writing took 21.9044523332268 seconds)
2023-08-01 11:37:17 | INFO | train_inner | epoch 003:   1158 / 1474 loss=2.768, trans_loss=3.891, nll_loss=2.152, w2v_ctc_loss=1.721, task_loss=0.997, contrastive_loss=0.287, total=4038.49, n_correct=1799.95, ppl=4.44, accuracy=44.57, wps=8792, ups=0.73, wpb=12054.8, bsz=432.5, num_updates=4100, lr=0.000164018, gnorm=1.024, clip=0, loss_scale=4, train_wall=90, gb_free=16.4, wall=3211
2023-08-01 11:38:48 | INFO | train_inner | epoch 003:   1258 / 1474 loss=2.718, trans_loss=3.868, nll_loss=2.123, w2v_ctc_loss=1.682, task_loss=0.977, contrastive_loss=0.264, total=4064.31, n_correct=1847.84, ppl=4.36, accuracy=45.465, wps=13293.2, ups=1.1, wpb=12136.8, bsz=433.9, num_updates=4200, lr=0.000168016, gnorm=0.982, clip=0, loss_scale=4, train_wall=91, gb_free=17.3, wall=3303
2023-08-01 11:40:21 | INFO | train_inner | epoch 003:   1358 / 1474 loss=2.699, trans_loss=3.85, nll_loss=2.1, w2v_ctc_loss=1.643, task_loss=0.931, contrastive_loss=0.374, total=4134.58, n_correct=1906.31, ppl=4.29, accuracy=46.106, wps=13378.1, ups=1.08, wpb=12343.8, bsz=460.7, num_updates=4300, lr=0.000172014, gnorm=0.981, clip=0, loss_scale=4, train_wall=92, gb_free=17.8, wall=3395
2023-08-01 11:41:53 | INFO | train_inner | epoch 003:   1458 / 1474 loss=2.691, trans_loss=3.845, nll_loss=2.095, w2v_ctc_loss=1.64, task_loss=0.88, contrastive_loss=0.363, total=4209.94, n_correct=1955.02, ppl=4.27, accuracy=46.438, wps=13615.4, ups=1.08, wpb=12573.5, bsz=477.4, num_updates=4400, lr=0.000176012, gnorm=1.12, clip=0, loss_scale=4, train_wall=92, gb_free=17, wall=3487
2023-08-01 11:42:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 11:42:32 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 4.894 | trans_loss 6.286 | nll_loss 3.785 | w2v_ctc_loss 1.939 | task_loss 4.242 | contrastive_loss 0.411 | total 4003.4 | n_correct 2049.9 | ppl 13.79 | accuracy 51.204 | uer 29.708 | wer 30.323 | raw_wer 30.323 | bleu 12.83 | wps 1974 | wpb 4003.4 | bsz 141.8 | num_updates 4416 | best_bleu 12.83
2023-08-01 11:42:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4416 updates
2023-08-01 11:42:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 11:42:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 11:42:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt (epoch 3 @ 4416 updates, score 12.83) (writing took 20.658619109541178 seconds)
2023-08-01 11:42:53 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-01 11:42:53 | INFO | train | epoch 003 | loss 3.048 | trans_loss 4.028 | nll_loss 2.333 | w2v_ctc_loss 1.915 | task_loss 0.938 | contrastive_loss 0.457 | total 4140.05 | n_correct 1649.86 | ppl 5.04 | accuracy 39.851 | wps 12659.9 | ups 1.02 | wpb 12360.1 | bsz 459 | num_updates 4416 | lr 0.000176652 | gnorm 1.232 | clip 0.1 | loss_scale 4 | train_wall 1327 | gb_free 16.4 | wall 3548
2023-08-01 11:42:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 11:42:54 | INFO | fairseq.trainer | begin training epoch 4
2023-08-01 11:42:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 11:44:18 | INFO | train_inner | epoch 004:     84 / 1474 loss=2.603, trans_loss=3.813, nll_loss=2.049, w2v_ctc_loss=1.583, task_loss=0.954, contrastive_loss=0.213, total=4099.41, n_correct=1942.73, ppl=4.14, accuracy=47.39, wps=8452.4, ups=0.69, wpb=12237, bsz=439.5, num_updates=4500, lr=0.00018001, gnorm=0.931, clip=0, loss_scale=4, train_wall=91, gb_free=16.3, wall=3632
2023-08-01 11:45:48 | INFO | train_inner | epoch 004:    184 / 1474 loss=2.578, trans_loss=3.789, nll_loss=2.019, w2v_ctc_loss=1.559, task_loss=0.882, contrastive_loss=0.238, total=4175.15, n_correct=2019.95, ppl=4.05, accuracy=48.38, wps=13783.2, ups=1.11, wpb=12464.9, bsz=468.3, num_updates=4600, lr=0.000184008, gnorm=0.915, clip=0, loss_scale=4, train_wall=90, gb_free=16.6, wall=3722
2023-08-01 11:47:20 | INFO | train_inner | epoch 004:    284 / 1474 loss=2.591, trans_loss=3.792, nll_loss=2.024, w2v_ctc_loss=1.556, task_loss=0.926, contrastive_loss=0.364, total=4145.23, n_correct=2001.41, ppl=4.07, accuracy=48.282, wps=13482.9, ups=1.09, wpb=12382.4, bsz=463, num_updates=4700, lr=0.000188006, gnorm=0.864, clip=0, loss_scale=4, train_wall=91, gb_free=15.9, wall=3814
2023-08-01 11:48:51 | INFO | train_inner | epoch 004:    384 / 1474 loss=2.55, trans_loss=3.79, nll_loss=2.019, w2v_ctc_loss=1.536, task_loss=0.965, contrastive_loss=0.207, total=4127.66, n_correct=2006.41, ppl=4.05, accuracy=48.609, wps=13486.4, ups=1.1, wpb=12314.6, bsz=443.5, num_updates=4800, lr=0.000192004, gnorm=0.855, clip=0, loss_scale=4, train_wall=91, gb_free=17.4, wall=3906
2023-08-01 11:50:25 | INFO | train_inner | epoch 004:    484 / 1474 loss=2.577, trans_loss=3.772, nll_loss=1.998, w2v_ctc_loss=1.497, task_loss=0.838, contrastive_loss=0.608, total=4218.78, n_correct=2076.12, ppl=4, accuracy=49.211, wps=13464, ups=1.07, wpb=12592.4, bsz=497.8, num_updates=4900, lr=0.000196002, gnorm=0.883, clip=0, loss_scale=4, train_wall=93, gb_free=16.5, wall=3999
2023-08-01 11:51:57 | INFO | train_inner | epoch 004:    584 / 1474 loss=2.538, trans_loss=3.767, nll_loss=1.992, w2v_ctc_loss=1.52, task_loss=0.873, contrastive_loss=0.283, total=4217.52, n_correct=2093.57, ppl=3.98, accuracy=49.64, wps=13699.3, ups=1.09, wpb=12591.1, bsz=485.9, num_updates=5000, lr=0.0002, gnorm=0.87, clip=0, loss_scale=4, train_wall=91, gb_free=16.1, wall=4091
mt_weight tensor(0.5000)
asr_weight tensor(0.4720, device='cuda:0')
2023-08-01 11:53:30 | INFO | train_inner | epoch 004:    684 / 1474 loss=2.511, trans_loss=3.771, nll_loss=1.993, w2v_ctc_loss=1.483, task_loss=0.951, contrastive_loss=0.329, total=4176.39, n_correct=2078.23, ppl=3.98, accuracy=49.761, wps=13363.5, ups=1.07, wpb=12448.9, bsz=455.8, num_updates=5100, lr=0.00019803, gnorm=0.58, clip=0, loss_scale=8, train_wall=93, gb_free=17.1, wall=4184
2023-08-01 11:55:02 | INFO | train_inner | epoch 004:    784 / 1474 loss=2.489, trans_loss=3.758, nll_loss=1.981, w2v_ctc_loss=1.491, task_loss=1.02, contrastive_loss=0.194, total=4026.63, n_correct=2017.43, ppl=3.95, accuracy=50.102, wps=13102.6, ups=1.09, wpb=12025, bsz=420.6, num_updates=5200, lr=0.000196116, gnorm=0.558, clip=0, loss_scale=8, train_wall=91, gb_free=13.2, wall=4276
2023-08-01 11:56:34 | INFO | train_inner | epoch 004:    884 / 1474 loss=2.508, trans_loss=3.744, nll_loss=1.963, w2v_ctc_loss=1.486, task_loss=0.924, contrastive_loss=0.377, total=4186.04, n_correct=2111.43, ppl=3.9, accuracy=50.44, wps=13550.1, ups=1.08, wpb=12501.4, bsz=466.3, num_updates=5300, lr=0.000194257, gnorm=0.576, clip=0, loss_scale=8, train_wall=92, gb_free=17.7, wall=4368
2023-08-01 11:58:06 | INFO | train_inner | epoch 004:    984 / 1474 loss=2.465, trans_loss=3.734, nll_loss=1.952, w2v_ctc_loss=1.465, task_loss=0.941, contrastive_loss=0.241, total=4125.02, n_correct=2102.4, ppl=3.87, accuracy=50.967, wps=13429.5, ups=1.09, wpb=12321, bsz=457.1, num_updates=5400, lr=0.00019245, gnorm=0.556, clip=0, loss_scale=8, train_wall=91, gb_free=12.7, wall=4460
2023-08-01 11:59:38 | INFO | train_inner | epoch 004:   1084 / 1474 loss=2.464, trans_loss=3.743, nll_loss=1.961, w2v_ctc_loss=1.468, task_loss=1.001, contrastive_loss=0.217, total=4075.6, n_correct=2071.15, ppl=3.89, accuracy=50.818, wps=13236.1, ups=1.09, wpb=12163.4, bsz=435.7, num_updates=5500, lr=0.000190693, gnorm=0.544, clip=0, loss_scale=8, train_wall=91, gb_free=16, wall=4552
2023-08-01 12:01:09 | INFO | train_inner | epoch 004:   1184 / 1474 loss=2.473, trans_loss=3.73, nll_loss=1.949, w2v_ctc_loss=1.462, task_loss=0.87, contrastive_loss=0.331, total=4161.18, n_correct=2127.7, ppl=3.86, accuracy=51.132, wps=13573.3, ups=1.09, wpb=12431.8, bsz=483.4, num_updates=5600, lr=0.000188982, gnorm=0.565, clip=0, loss_scale=8, train_wall=91, gb_free=16.8, wall=4644
2023-08-01 12:02:41 | INFO | train_inner | epoch 004:   1284 / 1474 loss=2.441, trans_loss=3.719, nll_loss=1.933, w2v_ctc_loss=1.437, task_loss=0.886, contrastive_loss=0.293, total=4156.53, n_correct=2151.87, ppl=3.82, accuracy=51.771, wps=13464.6, ups=1.08, wpb=12411.4, bsz=472.7, num_updates=5700, lr=0.000187317, gnorm=0.535, clip=0, loss_scale=8, train_wall=92, gb_free=15.8, wall=4736
2023-08-01 12:04:12 | INFO | train_inner | epoch 004:   1384 / 1474 loss=2.414, trans_loss=3.717, nll_loss=1.93, w2v_ctc_loss=1.433, task_loss=0.951, contrastive_loss=0.171, total=4101.23, n_correct=2125.6, ppl=3.81, accuracy=51.828, wps=13587.8, ups=1.11, wpb=12249, bsz=437.6, num_updates=5800, lr=0.000185695, gnorm=0.522, clip=0, loss_scale=8, train_wall=90, gb_free=15.6, wall=4826
2023-08-01 12:05:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.4720, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.4720, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.4720, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.4720, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.4720, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.4720, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.4720, device='cuda:2')
2023-08-01 12:05:57 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.54 | trans_loss 5.936 | nll_loss 3.317 | w2v_ctc_loss 1.605 | task_loss 4.432 | contrastive_loss 0.313 | total 4003.4 | n_correct 2241.7 | ppl 9.97 | accuracy 55.995 | uer 23.863 | wer 25.197 | raw_wer 25.197 | bleu 16.28 | wps 2139.3 | wpb 4003.4 | bsz 141.8 | num_updates 5890 | best_bleu 16.28
2023-08-01 12:05:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5890 updates
2023-08-01 12:05:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 12:06:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 12:06:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt (epoch 4 @ 5890 updates, score 16.28) (writing took 20.696323016658425 seconds)
2023-08-01 12:06:18 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-01 12:06:18 | INFO | train | epoch 004 | loss 2.507 | trans_loss 3.756 | nll_loss 1.979 | w2v_ctc_loss 1.492 | task_loss 0.927 | contrastive_loss 0.289 | total 4138.65 | n_correct 2071.15 | ppl 3.94 | accuracy 50.044 | wps 12969 | ups 1.05 | wpb 12355.8 | bsz 458.5 | num_updates 5890 | lr 0.000184271 | gnorm 0.684 | clip 0 | loss_scale 8 | train_wall 1345 | gb_free 14.8 | wall 4952
2023-08-01 12:06:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 12:06:18 | INFO | fairseq.trainer | begin training epoch 5
2023-08-01 12:06:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 12:06:34 | INFO | train_inner | epoch 005:     10 / 1474 loss=2.395, trans_loss=3.708, nll_loss=1.917, w2v_ctc_loss=1.408, task_loss=0.964, contrastive_loss=0.191, total=4037.7, n_correct=2107.52, ppl=3.78, accuracy=52.196, wps=8442.5, ups=0.7, wpb=12055.9, bsz=439.3, num_updates=5900, lr=0.000184115, gnorm=0.539, clip=0, loss_scale=8, train_wall=90, gb_free=16.9, wall=4969
2023-08-01 12:08:06 | INFO | train_inner | epoch 005:    110 / 1474 loss=2.321, trans_loss=3.653, nll_loss=1.846, w2v_ctc_loss=1.331, task_loss=0.839, contrastive_loss=0.198, total=4247.37, n_correct=2293.21, ppl=3.6, accuracy=53.991, wps=13782.4, ups=1.09, wpb=12683.4, bsz=495.1, num_updates=6000, lr=0.000182574, gnorm=0.502, clip=0, loss_scale=8, train_wall=92, gb_free=16.7, wall=5061
2023-08-01 12:08:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 12:08:30 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.53 | trans_loss 5.929 | nll_loss 3.307 | w2v_ctc_loss 1.582 | task_loss 4.461 | contrastive_loss 0.326 | total 4003.4 | n_correct 2248.6 | ppl 9.9 | accuracy 56.167 | uer 23.81 | wer 25.193 | raw_wer 25.193 | bleu 16.28 | wps 2081.1 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 16.28
2023-08-01 12:08:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-08-01 12:08:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_5_6000.pt
2023-08-01 12:08:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_5_6000.pt
2023-08-01 12:08:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 16.28) (writing took 21.600691417232156 seconds)
2023-08-01 12:10:23 | INFO | train_inner | epoch 005:    210 / 1474 loss=2.358, trans_loss=3.664, nll_loss=1.858, w2v_ctc_loss=1.344, task_loss=0.86, contrastive_loss=0.419, total=4189.85, n_correct=2248.32, ppl=3.63, accuracy=53.661, wps=9144.3, ups=0.73, wpb=12500.5, bsz=488.2, num_updates=6100, lr=0.000181071, gnorm=0.505, clip=0, loss_scale=8, train_wall=91, gb_free=17.8, wall=5197
2023-08-01 12:11:54 | INFO | train_inner | epoch 005:    310 / 1474 loss=2.346, trans_loss=3.658, nll_loss=1.856, w2v_ctc_loss=1.361, task_loss=0.956, contrastive_loss=0.261, total=4090.1, n_correct=2188.03, ppl=3.62, accuracy=53.496, wps=13517.6, ups=1.11, wpb=12228.1, bsz=443.9, num_updates=6200, lr=0.000179605, gnorm=0.524, clip=0, loss_scale=8, train_wall=90, gb_free=16.2, wall=5288
2023-08-01 12:13:25 | INFO | train_inner | epoch 005:    410 / 1474 loss=2.335, trans_loss=3.65, nll_loss=1.847, w2v_ctc_loss=1.327, task_loss=0.897, contrastive_loss=0.35, total=4147.17, n_correct=2238.85, ppl=3.6, accuracy=53.985, wps=13527.8, ups=1.09, wpb=12395.1, bsz=472.5, num_updates=6300, lr=0.000178174, gnorm=0.516, clip=0, loss_scale=8, train_wall=91, gb_free=14.8, wall=5380
2023-08-01 12:14:56 | INFO | train_inner | epoch 005:    510 / 1474 loss=2.311, trans_loss=3.662, nll_loss=1.859, w2v_ctc_loss=1.338, task_loss=1.045, contrastive_loss=0.144, total=4026.81, n_correct=2160.72, ppl=3.63, accuracy=53.658, wps=13189.1, ups=1.1, wpb=12029.7, bsz=416.6, num_updates=6400, lr=0.000176777, gnorm=0.515, clip=0, loss_scale=8, train_wall=91, gb_free=17.4, wall=5471
2023-08-01 12:16:28 | INFO | train_inner | epoch 005:    610 / 1474 loss=2.328, trans_loss=3.666, nll_loss=1.863, w2v_ctc_loss=1.324, task_loss=0.954, contrastive_loss=0.32, total=4107.75, n_correct=2209.91, ppl=3.64, accuracy=53.799, wps=13320.1, ups=1.09, wpb=12253.8, bsz=451.2, num_updates=6500, lr=0.000175412, gnorm=0.53, clip=0, loss_scale=8, train_wall=91, gb_free=16.1, wall=5563
2023-08-01 12:18:00 | INFO | train_inner | epoch 005:    710 / 1474 loss=2.324, trans_loss=3.657, nll_loss=1.854, w2v_ctc_loss=1.322, task_loss=0.881, contrastive_loss=0.295, total=4178.85, n_correct=2260.49, ppl=3.61, accuracy=54.094, wps=13610.6, ups=1.09, wpb=12473.1, bsz=480.9, num_updates=6600, lr=0.000174078, gnorm=0.51, clip=0, loss_scale=8, train_wall=91, gb_free=17.7, wall=5654
2023-08-01 12:19:33 | INFO | train_inner | epoch 005:    810 / 1474 loss=2.304, trans_loss=3.657, nll_loss=1.852, w2v_ctc_loss=1.315, task_loss=0.956, contrastive_loss=0.217, total=4127.73, n_correct=2239.27, ppl=3.61, accuracy=54.249, wps=13307.8, ups=1.08, wpb=12320.4, bsz=449.2, num_updates=6700, lr=0.000172774, gnorm=0.507, clip=0, loss_scale=8, train_wall=92, gb_free=15.1, wall=5747
2023-08-01 12:21:04 | INFO | train_inner | epoch 005:    910 / 1474 loss=2.283, trans_loss=3.647, nll_loss=1.841, w2v_ctc_loss=1.305, task_loss=0.961, contrastive_loss=0.177, total=4095.48, n_correct=2232.48, ppl=3.58, accuracy=54.511, wps=13415.1, ups=1.1, wpb=12229.5, bsz=445.3, num_updates=6800, lr=0.000171499, gnorm=0.497, clip=0, loss_scale=8, train_wall=91, gb_free=15.6, wall=5838
2023-08-01 12:22:35 | INFO | train_inner | epoch 005:   1010 / 1474 loss=2.295, trans_loss=3.651, nll_loss=1.845, w2v_ctc_loss=1.306, task_loss=0.919, contrastive_loss=0.259, total=4165.12, n_correct=2265.17, ppl=3.59, accuracy=54.384, wps=13610, ups=1.09, wpb=12433.6, bsz=463.5, num_updates=6900, lr=0.000170251, gnorm=0.498, clip=0, loss_scale=8, train_wall=91, gb_free=15.6, wall=5929
2023-08-01 12:24:08 | INFO | train_inner | epoch 005:   1110 / 1474 loss=2.308, trans_loss=3.651, nll_loss=1.845, w2v_ctc_loss=1.317, task_loss=0.918, contrastive_loss=0.261, total=4176.72, n_correct=2278.79, ppl=3.59, accuracy=54.559, wps=13450, ups=1.08, wpb=12459.2, bsz=466.1, num_updates=7000, lr=0.000169031, gnorm=0.511, clip=0, loss_scale=8, train_wall=92, gb_free=16.7, wall=6022
2023-08-01 12:25:40 | INFO | train_inner | epoch 005:   1210 / 1474 loss=2.267, trans_loss=3.646, nll_loss=1.838, w2v_ctc_loss=1.288, task_loss=0.948, contrastive_loss=0.163, total=4164.13, n_correct=2283.07, ppl=3.57, accuracy=54.827, wps=13539.3, ups=1.09, wpb=12420.9, bsz=453.8, num_updates=7100, lr=0.000167836, gnorm=0.501, clip=0, loss_scale=16, train_wall=91, gb_free=16.9, wall=6114
2023-08-01 12:27:12 | INFO | train_inner | epoch 005:   1310 / 1474 loss=2.255, trans_loss=3.644, nll_loss=1.837, w2v_ctc_loss=1.278, task_loss=0.947, contrastive_loss=0.137, total=4134.91, n_correct=2266.24, ppl=3.57, accuracy=54.807, wps=13407.9, ups=1.09, wpb=12341.4, bsz=445.6, num_updates=7200, lr=0.000166667, gnorm=0.483, clip=0, loss_scale=16, train_wall=92, gb_free=16.3, wall=6206
2023-08-01 12:28:44 | INFO | train_inner | epoch 005:   1410 / 1474 loss=2.26, trans_loss=3.643, nll_loss=1.838, w2v_ctc_loss=1.272, task_loss=0.94, contrastive_loss=0.199, total=4134.37, n_correct=2267.9, ppl=3.58, accuracy=54.855, wps=13401.7, ups=1.09, wpb=12347.5, bsz=458.5, num_updates=7300, lr=0.000165521, gnorm=0.49, clip=0, loss_scale=16, train_wall=92, gb_free=17.8, wall=6298
2023-08-01 12:29:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 12:30:06 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.431 | trans_loss 5.843 | nll_loss 3.204 | w2v_ctc_loss 1.434 | task_loss 4.477 | contrastive_loss 0.341 | total 4003.4 | n_correct 2300.5 | ppl 9.22 | accuracy 57.464 | uer 22.658 | wer 24.257 | raw_wer 24.257 | bleu 17.15 | wps 2097.8 | wpb 4003.4 | bsz 141.8 | num_updates 7364 | best_bleu 17.15
2023-08-01 12:30:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7364 updates
2023-08-01 12:30:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 12:30:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 12:30:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt (epoch 5 @ 7364 updates, score 17.15) (writing took 21.89920911565423 seconds)
2023-08-01 12:30:28 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-01 12:30:28 | INFO | train | epoch 005 | loss 2.306 | trans_loss 3.653 | nll_loss 1.848 | w2v_ctc_loss 1.316 | task_loss 0.929 | contrastive_loss 0.243 | total 4138.65 | n_correct 2244.55 | ppl 3.6 | accuracy 54.234 | wps 12559.7 | ups 1.02 | wpb 12355.8 | bsz 458.5 | num_updates 7364 | lr 0.0001648 | gnorm 0.507 | clip 0 | loss_scale 16 | train_wall 1343 | gb_free 16.2 | wall 6402
2023-08-01 12:30:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 12:30:28 | INFO | fairseq.trainer | begin training epoch 6
2023-08-01 12:30:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 12:31:09 | INFO | train_inner | epoch 006:     36 / 1474 loss=2.245, trans_loss=3.619, nll_loss=1.805, w2v_ctc_loss=1.267, task_loss=0.954, contrastive_loss=0.195, total=4115.45, n_correct=2284.29, ppl=3.49, accuracy=55.505, wps=8448.5, ups=0.69, wpb=12281.2, bsz=447.9, num_updates=7400, lr=0.000164399, gnorm=0.498, clip=0, loss_scale=16, train_wall=91, gb_free=16.4, wall=6443
2023-08-01 12:32:40 | INFO | train_inner | epoch 006:    136 / 1474 loss=2.204, trans_loss=3.59, nll_loss=1.768, w2v_ctc_loss=1.22, task_loss=0.928, contrastive_loss=0.24, total=4154.25, n_correct=2331.38, ppl=3.4, accuracy=56.12, wps=13634.8, ups=1.1, wpb=12407.4, bsz=456.1, num_updates=7500, lr=0.000163299, gnorm=0.489, clip=0, loss_scale=16, train_wall=90, gb_free=15.5, wall=6534
2023-08-01 12:34:12 | INFO | train_inner | epoch 006:    236 / 1474 loss=2.213, trans_loss=3.599, nll_loss=1.78, w2v_ctc_loss=1.25, task_loss=0.998, contrastive_loss=0.146, total=4112.66, n_correct=2301.17, ppl=3.43, accuracy=55.953, wps=13361.7, ups=1.09, wpb=12287.2, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.487, clip=0, loss_scale=16, train_wall=91, gb_free=16.1, wall=6626
2023-08-01 12:35:45 | INFO | train_inner | epoch 006:    336 / 1474 loss=2.225, trans_loss=3.586, nll_loss=1.764, w2v_ctc_loss=1.2, task_loss=0.865, contrastive_loss=0.457, total=4177.51, n_correct=2361.77, ppl=3.4, accuracy=56.535, wps=13483.9, ups=1.08, wpb=12473.8, bsz=491.3, num_updates=7700, lr=0.000161165, gnorm=0.497, clip=0, loss_scale=16, train_wall=92, gb_free=16.1, wall=6719
2023-08-01 12:37:15 | INFO | train_inner | epoch 006:    436 / 1474 loss=2.185, trans_loss=3.591, nll_loss=1.77, w2v_ctc_loss=1.21, task_loss=0.894, contrastive_loss=0.16, total=4154.57, n_correct=2347.55, ppl=3.41, accuracy=56.505, wps=13682.7, ups=1.1, wpb=12405.5, bsz=470.2, num_updates=7800, lr=0.000160128, gnorm=0.49, clip=0, loss_scale=16, train_wall=90, gb_free=16.1, wall=6810
2023-08-01 12:38:47 | INFO | train_inner | epoch 006:    536 / 1474 loss=2.193, trans_loss=3.599, nll_loss=1.779, w2v_ctc_loss=1.224, task_loss=0.937, contrastive_loss=0.15, total=4167.79, n_correct=2351.82, ppl=3.43, accuracy=56.428, wps=13544.8, ups=1.09, wpb=12438.5, bsz=455.2, num_updates=7900, lr=0.000159111, gnorm=0.491, clip=0, loss_scale=16, train_wall=91, gb_free=15.7, wall=6901
2023-08-01 12:40:18 | INFO | train_inner | epoch 006:    636 / 1474 loss=2.186, trans_loss=3.599, nll_loss=1.78, w2v_ctc_loss=1.201, task_loss=0.881, contrastive_loss=0.205, total=4146.17, n_correct=2338.91, ppl=3.43, accuracy=56.411, wps=13572.9, ups=1.1, wpb=12376.6, bsz=471.6, num_updates=8000, lr=0.000158114, gnorm=0.482, clip=0, loss_scale=16, train_wall=91, gb_free=16.3, wall=6993
2023-08-01 12:40:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 12:40:42 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.382 | trans_loss 5.78 | nll_loss 3.114 | w2v_ctc_loss 1.446 | task_loss 4.521 | contrastive_loss 0.29 | total 4003.4 | n_correct 2339.6 | ppl 8.66 | accuracy 58.44 | uer 21.482 | wer 23.183 | raw_wer 23.183 | bleu 17.96 | wps 2133 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 17.96
2023-08-01 12:40:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-08-01 12:40:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_6_8000.pt
2023-08-01 12:40:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_6_8000.pt
2023-08-01 12:41:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 17.96) (writing took 21.37184419296682 seconds)
2023-08-01 12:42:35 | INFO | train_inner | epoch 006:    736 / 1474 loss=2.192, trans_loss=3.6, nll_loss=1.782, w2v_ctc_loss=1.22, task_loss=0.951, contrastive_loss=0.16, total=4148.65, n_correct=2338.54, ppl=3.44, accuracy=56.369, wps=9050, ups=0.73, wpb=12388, bsz=453.7, num_updates=8100, lr=0.000157135, gnorm=0.482, clip=0, loss_scale=16, train_wall=91, gb_free=15.5, wall=7129
2023-08-01 12:44:07 | INFO | train_inner | epoch 006:    836 / 1474 loss=2.188, trans_loss=3.608, nll_loss=1.792, w2v_ctc_loss=1.214, task_loss=0.976, contrastive_loss=0.14, total=4114.34, n_correct=2311.78, ppl=3.46, accuracy=56.188, wps=13421.7, ups=1.09, wpb=12282.2, bsz=441.6, num_updates=8200, lr=0.000156174, gnorm=0.482, clip=0, loss_scale=16, train_wall=91, gb_free=15, wall=7221
2023-08-01 12:45:38 | INFO | train_inner | epoch 006:    936 / 1474 loss=2.203, trans_loss=3.606, nll_loss=1.79, w2v_ctc_loss=1.214, task_loss=0.97, contrastive_loss=0.237, total=4081.53, n_correct=2294.95, ppl=3.46, accuracy=56.228, wps=13334.5, ups=1.09, wpb=12181.3, bsz=444.5, num_updates=8300, lr=0.00015523, gnorm=0.488, clip=0, loss_scale=16, train_wall=91, gb_free=17.8, wall=7312
2023-08-01 12:47:09 | INFO | train_inner | epoch 006:   1036 / 1474 loss=2.192, trans_loss=3.592, nll_loss=1.773, w2v_ctc_loss=1.195, task_loss=0.883, contrastive_loss=0.315, total=4165.84, n_correct=2358.16, ppl=3.42, accuracy=56.607, wps=13680.5, ups=1.1, wpb=12435.7, bsz=477.2, num_updates=8400, lr=0.000154303, gnorm=0.5, clip=0, loss_scale=16, train_wall=90, gb_free=16.8, wall=7403
2023-08-01 12:48:40 | INFO | train_inner | epoch 006:   1136 / 1474 loss=2.181, trans_loss=3.599, nll_loss=1.781, w2v_ctc_loss=1.21, task_loss=1.028, contrastive_loss=0.142, total=4072.29, n_correct=2298.95, ppl=3.44, accuracy=56.453, wps=13304.2, ups=1.09, wpb=12157.6, bsz=428, num_updates=8500, lr=0.000153393, gnorm=0.484, clip=0, loss_scale=16, train_wall=91, gb_free=16.9, wall=7495
2023-08-01 12:50:12 | INFO | train_inner | epoch 006:   1236 / 1474 loss=2.209, trans_loss=3.589, nll_loss=1.771, w2v_ctc_loss=1.19, task_loss=0.903, contrastive_loss=0.459, total=4141.55, n_correct=2344.67, ppl=3.41, accuracy=56.613, wps=13438.4, ups=1.09, wpb=12370.9, bsz=474.8, num_updates=8600, lr=0.000152499, gnorm=0.485, clip=0, loss_scale=16, train_wall=92, gb_free=13.1, wall=7587
2023-08-01 12:51:43 | INFO | train_inner | epoch 006:   1336 / 1474 loss=2.161, trans_loss=3.598, nll_loss=1.778, w2v_ctc_loss=1.191, task_loss=0.93, contrastive_loss=0.128, total=4125.31, n_correct=2341.79, ppl=3.43, accuracy=56.766, wps=13629.6, ups=1.11, wpb=12305, bsz=452.6, num_updates=8700, lr=0.00015162, gnorm=0.484, clip=0, loss_scale=16, train_wall=90, gb_free=17.8, wall=7677
2023-08-01 12:53:15 | INFO | train_inner | epoch 006:   1436 / 1474 loss=2.158, trans_loss=3.589, nll_loss=1.769, w2v_ctc_loss=1.188, task_loss=0.929, contrastive_loss=0.135, total=4196.2, n_correct=2389.72, ppl=3.41, accuracy=56.95, wps=13570.6, ups=1.08, wpb=12525.2, bsz=461.5, num_updates=8800, lr=0.000150756, gnorm=0.469, clip=0, loss_scale=16, train_wall=92, gb_free=11.2, wall=7769
2023-08-01 12:53:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 12:54:12 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.331 | trans_loss 5.731 | nll_loss 3.054 | w2v_ctc_loss 1.39 | task_loss 4.581 | contrastive_loss 0.282 | total 4003.4 | n_correct 2370 | ppl 8.3 | accuracy 59.2 | uer 20.259 | wer 21.957 | raw_wer 21.957 | bleu 18.15 | wps 2220.2 | wpb 4003.4 | bsz 141.8 | num_updates 8838 | best_bleu 18.15
2023-08-01 12:54:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8838 updates
2023-08-01 12:54:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 12:54:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 12:54:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt (epoch 6 @ 8838 updates, score 18.15) (writing took 20.813791822642088 seconds)
2023-08-01 12:54:33 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-01 12:54:33 | INFO | train | epoch 006 | loss 2.191 | trans_loss 3.596 | nll_loss 1.777 | w2v_ctc_loss 1.208 | task_loss 0.931 | contrastive_loss 0.219 | total 4138.65 | n_correct 2336.54 | ppl 3.43 | accuracy 56.457 | wps 12597.5 | ups 1.02 | wpb 12355.8 | bsz 458.5 | num_updates 8838 | lr 0.000150431 | gnorm 0.486 | clip 0 | loss_scale 16 | train_wall 1341 | gb_free 15.1 | wall 7848
2023-08-01 12:54:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 12:54:34 | INFO | fairseq.trainer | begin training epoch 7
2023-08-01 12:54:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 12:55:39 | INFO | train_inner | epoch 007:     62 / 1474 loss=2.127, trans_loss=3.566, nll_loss=1.739, w2v_ctc_loss=1.159, task_loss=0.908, contrastive_loss=0.15, total=4108.19, n_correct=2367.35, ppl=3.34, accuracy=57.625, wps=8516.7, ups=0.69, wpb=12266.6, bsz=461.9, num_updates=8900, lr=0.000149906, gnorm=0.479, clip=0, loss_scale=16, train_wall=91, gb_free=17.1, wall=7913
2023-08-01 12:57:10 | INFO | train_inner | epoch 007:    162 / 1474 loss=2.124, trans_loss=3.555, nll_loss=1.724, w2v_ctc_loss=1.143, task_loss=0.944, contrastive_loss=0.223, total=4106.05, n_correct=2373.42, ppl=3.3, accuracy=57.803, wps=13502.3, ups=1.1, wpb=12258.7, bsz=455.4, num_updates=9000, lr=0.000149071, gnorm=0.479, clip=0, loss_scale=16, train_wall=90, gb_free=16.7, wall=8004
2023-08-01 12:58:41 | INFO | train_inner | epoch 007:    262 / 1474 loss=2.113, trans_loss=3.551, nll_loss=1.718, w2v_ctc_loss=1.15, task_loss=0.944, contrastive_loss=0.13, total=4129.3, n_correct=2399.65, ppl=3.29, accuracy=58.113, wps=13566.6, ups=1.1, wpb=12322.8, bsz=451.8, num_updates=9100, lr=0.00014825, gnorm=0.484, clip=0, loss_scale=16, train_wall=90, gb_free=17.3, wall=8095
2023-08-01 13:00:13 | INFO | train_inner | epoch 007:    362 / 1474 loss=2.144, trans_loss=3.56, nll_loss=1.731, w2v_ctc_loss=1.138, task_loss=0.897, contrastive_loss=0.393, total=4201.67, n_correct=2423.23, ppl=3.32, accuracy=57.673, wps=13520.8, ups=1.08, wpb=12539.8, bsz=479.7, num_updates=9200, lr=0.000147442, gnorm=0.482, clip=0, loss_scale=32, train_wall=92, gb_free=15.4, wall=8188
2023-08-01 13:01:44 | INFO | train_inner | epoch 007:    462 / 1474 loss=2.132, trans_loss=3.559, nll_loss=1.732, w2v_ctc_loss=1.136, task_loss=0.915, contrastive_loss=0.317, total=4155.31, n_correct=2395.64, ppl=3.32, accuracy=57.652, wps=13681.6, ups=1.1, wpb=12410.9, bsz=465.5, num_updates=9300, lr=0.000146647, gnorm=0.48, clip=0, loss_scale=32, train_wall=90, gb_free=16.7, wall=8278
2023-08-01 13:03:15 | INFO | train_inner | epoch 007:    562 / 1474 loss=2.108, trans_loss=3.56, nll_loss=1.729, w2v_ctc_loss=1.139, task_loss=0.913, contrastive_loss=0.138, total=4165.88, n_correct=2412.12, ppl=3.31, accuracy=57.902, wps=13668.2, ups=1.1, wpb=12426.4, bsz=459, num_updates=9400, lr=0.000145865, gnorm=0.475, clip=0, loss_scale=32, train_wall=90, gb_free=17.2, wall=8369
2023-08-01 13:04:47 | INFO | train_inner | epoch 007:    662 / 1474 loss=2.099, trans_loss=3.558, nll_loss=1.728, w2v_ctc_loss=1.132, task_loss=0.934, contrastive_loss=0.123, total=4149.29, n_correct=2409.87, ppl=3.31, accuracy=58.079, wps=13538.5, ups=1.09, wpb=12381.3, bsz=451.6, num_updates=9500, lr=0.000145095, gnorm=0.475, clip=0, loss_scale=32, train_wall=91, gb_free=17, wall=8461
2023-08-01 13:06:19 | INFO | train_inner | epoch 007:    762 / 1474 loss=2.101, trans_loss=3.553, nll_loss=1.723, w2v_ctc_loss=1.135, task_loss=0.966, contrastive_loss=0.124, total=4134.54, n_correct=2398.86, ppl=3.3, accuracy=58.02, wps=13364.5, ups=1.08, wpb=12345.4, bsz=449.8, num_updates=9600, lr=0.000144338, gnorm=0.473, clip=0, loss_scale=32, train_wall=92, gb_free=13.7, wall=8553
2023-08-01 13:07:50 | INFO | train_inner | epoch 007:    862 / 1474 loss=2.105, trans_loss=3.563, nll_loss=1.736, w2v_ctc_loss=1.134, task_loss=0.936, contrastive_loss=0.143, total=4151.77, n_correct=2402.09, ppl=3.33, accuracy=57.857, wps=13538.1, ups=1.09, wpb=12391.6, bsz=461.9, num_updates=9700, lr=0.000143592, gnorm=0.477, clip=0, loss_scale=32, train_wall=91, gb_free=14.8, wall=8645
2023-08-01 13:09:22 | INFO | train_inner | epoch 007:    962 / 1474 loss=2.109, trans_loss=3.557, nll_loss=1.73, w2v_ctc_loss=1.121, task_loss=0.894, contrastive_loss=0.237, total=4124.8, n_correct=2390.07, ppl=3.32, accuracy=57.944, wps=13435.6, ups=1.09, wpb=12313.3, bsz=471.2, num_updates=9800, lr=0.000142857, gnorm=0.478, clip=0, loss_scale=32, train_wall=91, gb_free=16.6, wall=8736
2023-08-01 13:10:53 | INFO | train_inner | epoch 007:   1062 / 1474 loss=2.102, trans_loss=3.57, nll_loss=1.746, w2v_ctc_loss=1.136, task_loss=0.969, contrastive_loss=0.108, total=4113.08, n_correct=2373.97, ppl=3.35, accuracy=57.718, wps=13465.3, ups=1.1, wpb=12279.6, bsz=439.4, num_updates=9900, lr=0.000142134, gnorm=0.48, clip=0, loss_scale=32, train_wall=91, gb_free=14.7, wall=8828
2023-08-01 13:12:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-01 13:12:28 | INFO | train_inner | epoch 007:   1163 / 1474 loss=2.11, trans_loss=3.553, nll_loss=1.728, w2v_ctc_loss=1.129, task_loss=0.929, contrastive_loss=0.215, total=4113.08, n_correct=2388.89, ppl=3.31, accuracy=58.08, wps=13035.8, ups=1.06, wpb=12290.8, bsz=459.5, num_updates=10000, lr=0.000141421, gnorm=0.476, clip=0, loss_scale=16, train_wall=94, gb_free=15.9, wall=8922
2023-08-01 13:12:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 13:12:51 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.292 | trans_loss 5.688 | nll_loss 3.003 | w2v_ctc_loss 1.366 | task_loss 4.592 | contrastive_loss 0.27 | total 4003.4 | n_correct 2395.1 | ppl 8.01 | accuracy 59.827 | uer 19.247 | wer 20.879 | raw_wer 20.879 | bleu 19 | wps 2149.8 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 19
2023-08-01 13:12:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-08-01 13:12:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_7_10000.pt
2023-08-01 13:12:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_7_10000.pt
2023-08-01 13:13:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 19.0) (writing took 38.59236004576087 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:0')
2023-08-01 13:15:01 | INFO | train_inner | epoch 007:   1263 / 1474 loss=2.091, trans_loss=3.56, nll_loss=1.735, w2v_ctc_loss=1.119, task_loss=0.942, contrastive_loss=0.135, total=4129.52, n_correct=2392.04, ppl=3.33, accuracy=57.925, wps=8030, ups=0.65, wpb=12331.4, bsz=450.2, num_updates=10100, lr=0.00014072, gnorm=0.398, clip=0, loss_scale=16, train_wall=90, gb_free=16.7, wall=9075
2023-08-01 13:16:33 | INFO | train_inner | epoch 007:   1363 / 1474 loss=2.105, trans_loss=3.553, nll_loss=1.726, w2v_ctc_loss=1.131, task_loss=0.877, contrastive_loss=0.172, total=4172.87, n_correct=2432.26, ppl=3.31, accuracy=58.287, wps=13624.2, ups=1.09, wpb=12458.1, bsz=476.2, num_updates=10200, lr=0.000140028, gnorm=0.396, clip=0, loss_scale=16, train_wall=91, gb_free=17.2, wall=9167
2023-08-01 13:18:06 | INFO | train_inner | epoch 007:   1463 / 1474 loss=2.113, trans_loss=3.559, nll_loss=1.735, w2v_ctc_loss=1.129, task_loss=1.006, contrastive_loss=0.235, total=4109.42, n_correct=2379.72, ppl=3.33, accuracy=57.909, wps=13139.7, ups=1.07, wpb=12278.1, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.399, clip=0, loss_scale=16, train_wall=93, gb_free=16.4, wall=9260
2023-08-01 13:18:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:4')
2023-08-01 13:18:39 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.281 | trans_loss 5.686 | nll_loss 2.995 | w2v_ctc_loss 1.334 | task_loss 4.588 | contrastive_loss 0.27 | total 4003.4 | n_correct 2392.2 | ppl 7.97 | accuracy 59.754 | uer 19.414 | wer 21.14 | raw_wer 21.14 | bleu 18.7 | wps 2283.8 | wpb 4003.4 | bsz 141.8 | num_updates 10311 | best_bleu 19
2023-08-01 13:18:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10311 updates
2023-08-01 13:18:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_18.7000.pt
2023-08-01 13:18:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_18.7000.pt
2023-08-01 13:18:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_18.7000.pt (epoch 7 @ 10311 updates, score 18.7) (writing took 16.260985331609845 seconds)
2023-08-01 13:18:55 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-01 13:18:55 | INFO | train | epoch 007 | loss 2.111 | trans_loss 3.558 | nll_loss 1.729 | w2v_ctc_loss 1.134 | task_loss 0.933 | contrastive_loss 0.191 | total 4137.25 | n_correct 2396.73 | ppl 3.32 | accuracy 57.93 | wps 12447.1 | ups 1.01 | wpb 12351.7 | bsz 457.8 | num_updates 10311 | lr 0.000139272 | gnorm 0.462 | clip 0 | loss_scale 16 | train_wall 1344 | gb_free 13.1 | wall 9309
2023-08-01 13:18:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 13:18:55 | INFO | fairseq.trainer | begin training epoch 8
2023-08-01 13:18:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 13:20:25 | INFO | train_inner | epoch 008:     89 / 1474 loss=2.06, trans_loss=3.536, nll_loss=1.698, w2v_ctc_loss=1.092, task_loss=0.984, contrastive_loss=0.131, total=4116.25, n_correct=2420.46, ppl=3.24, accuracy=58.803, wps=8849.1, ups=0.72, wpb=12273, bsz=443.3, num_updates=10400, lr=0.000138675, gnorm=0.399, clip=0, loss_scale=16, train_wall=91, gb_free=16.9, wall=9399
2023-08-01 13:21:56 | INFO | train_inner | epoch 008:    189 / 1474 loss=2.057, trans_loss=3.527, nll_loss=1.686, w2v_ctc_loss=1.087, task_loss=1.01, contrastive_loss=0.15, total=4037.23, n_correct=2381.4, ppl=3.22, accuracy=58.986, wps=13195, ups=1.1, wpb=12041.5, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.402, clip=0, loss_scale=16, train_wall=91, gb_free=12.6, wall=9490
2023-08-01 13:23:27 | INFO | train_inner | epoch 008:    289 / 1474 loss=2.055, trans_loss=3.522, nll_loss=1.684, w2v_ctc_loss=1.086, task_loss=0.874, contrastive_loss=0.15, total=4207.78, n_correct=2487.57, ppl=3.21, accuracy=59.118, wps=13758.8, ups=1.1, wpb=12556.5, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.41, clip=0, loss_scale=16, train_wall=91, gb_free=12.8, wall=9582
2023-08-01 13:25:00 | INFO | train_inner | epoch 008:    389 / 1474 loss=2.075, trans_loss=3.532, nll_loss=1.695, w2v_ctc_loss=1.106, task_loss=0.993, contrastive_loss=0.172, total=4127.24, n_correct=2425.56, ppl=3.24, accuracy=58.77, wps=13272.1, ups=1.08, wpb=12316.2, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=0.407, clip=0, loss_scale=16, train_wall=92, gb_free=11.6, wall=9674
2023-08-01 13:26:32 | INFO | train_inner | epoch 008:    489 / 1474 loss=2.099, trans_loss=3.526, nll_loss=1.69, w2v_ctc_loss=1.079, task_loss=0.833, contrastive_loss=0.432, total=4203.76, n_correct=2481.4, ppl=3.23, accuracy=59.028, wps=13634.8, ups=1.09, wpb=12548.2, bsz=504.5, num_updates=10800, lr=0.000136083, gnorm=0.401, clip=0, loss_scale=16, train_wall=92, gb_free=14.5, wall=9766
2023-08-01 13:28:04 | INFO | train_inner | epoch 008:    589 / 1474 loss=2.062, trans_loss=3.529, nll_loss=1.696, w2v_ctc_loss=1.102, task_loss=1.017, contrastive_loss=0.105, total=4062.5, n_correct=2382.97, ppl=3.24, accuracy=58.658, wps=13232.5, ups=1.09, wpb=12145.4, bsz=427.9, num_updates=10900, lr=0.000135457, gnorm=0.395, clip=0, loss_scale=16, train_wall=91, gb_free=11.1, wall=9858
2023-08-01 13:29:35 | INFO | train_inner | epoch 008:    689 / 1474 loss=2.054, trans_loss=3.524, nll_loss=1.686, w2v_ctc_loss=1.096, task_loss=0.96, contrastive_loss=0.117, total=4142.78, n_correct=2448.92, ppl=3.22, accuracy=59.113, wps=13549.7, ups=1.1, wpb=12364.4, bsz=448.6, num_updates=11000, lr=0.00013484, gnorm=0.392, clip=0, loss_scale=16, train_wall=91, gb_free=15.8, wall=9949
2023-08-01 13:31:07 | INFO | train_inner | epoch 008:    789 / 1474 loss=2.064, trans_loss=3.524, nll_loss=1.692, w2v_ctc_loss=1.09, task_loss=0.955, contrastive_loss=0.203, total=4118.9, n_correct=2429.48, ppl=3.23, accuracy=58.984, wps=13452.3, ups=1.09, wpb=12310.9, bsz=447.8, num_updates=11100, lr=0.000134231, gnorm=0.397, clip=0, loss_scale=16, train_wall=91, gb_free=15.1, wall=10041
2023-08-01 13:32:39 | INFO | train_inner | epoch 008:    889 / 1474 loss=2.06, trans_loss=3.526, nll_loss=1.694, w2v_ctc_loss=1.079, task_loss=0.895, contrastive_loss=0.214, total=4169.01, n_correct=2467, ppl=3.23, accuracy=59.175, wps=13553.8, ups=1.09, wpb=12452.5, bsz=473.7, num_updates=11200, lr=0.000133631, gnorm=0.402, clip=0, loss_scale=16, train_wall=91, gb_free=16, wall=10133
2023-08-01 13:34:09 | INFO | train_inner | epoch 008:    989 / 1474 loss=2.041, trans_loss=3.527, nll_loss=1.693, w2v_ctc_loss=1.077, task_loss=0.892, contrastive_loss=0.114, total=4154.69, n_correct=2458.79, ppl=3.23, accuracy=59.181, wps=13697.8, ups=1.1, wpb=12403.4, bsz=464.9, num_updates=11300, lr=0.000133038, gnorm=0.396, clip=0, loss_scale=16, train_wall=90, gb_free=17.7, wall=10223
2023-08-01 13:35:41 | INFO | train_inner | epoch 008:   1089 / 1474 loss=2.075, trans_loss=3.534, nll_loss=1.701, w2v_ctc_loss=1.08, task_loss=0.928, contrastive_loss=0.339, total=4199.1, n_correct=2471.54, ppl=3.25, accuracy=58.859, wps=13638.2, ups=1.09, wpb=12534.3, bsz=465.3, num_updates=11400, lr=0.000132453, gnorm=0.402, clip=0, loss_scale=16, train_wall=91, gb_free=12.5, wall=10315
2023-08-01 13:37:12 | INFO | train_inner | epoch 008:   1189 / 1474 loss=2.046, trans_loss=3.525, nll_loss=1.692, w2v_ctc_loss=1.079, task_loss=0.882, contrastive_loss=0.123, total=4177.31, n_correct=2470.6, ppl=3.23, accuracy=59.143, wps=13714.8, ups=1.1, wpb=12476.3, bsz=472.6, num_updates=11500, lr=0.000131876, gnorm=0.388, clip=0, loss_scale=16, train_wall=90, gb_free=14.8, wall=10406
2023-08-01 13:38:42 | INFO | train_inner | epoch 008:   1289 / 1474 loss=2.057, trans_loss=3.532, nll_loss=1.7, w2v_ctc_loss=1.091, task_loss=0.974, contrastive_loss=0.145, total=4063.85, n_correct=2391.4, ppl=3.25, accuracy=58.846, wps=13415.8, ups=1.11, wpb=12140.6, bsz=438.4, num_updates=11600, lr=0.000131306, gnorm=0.406, clip=0, loss_scale=16, train_wall=90, gb_free=16.7, wall=10497
2023-08-01 13:40:13 | INFO | train_inner | epoch 008:   1389 / 1474 loss=2.063, trans_loss=3.533, nll_loss=1.702, w2v_ctc_loss=1.084, task_loss=0.921, contrastive_loss=0.199, total=4141.5, n_correct=2443.69, ppl=3.25, accuracy=59.005, wps=13595.9, ups=1.1, wpb=12367.2, bsz=461.5, num_updates=11700, lr=0.000130744, gnorm=0.399, clip=0, loss_scale=16, train_wall=90, gb_free=16.3, wall=10588
2023-08-01 13:41:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 13:41:54 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.257 | trans_loss 5.653 | nll_loss 2.952 | w2v_ctc_loss 1.33 | task_loss 4.579 | contrastive_loss 0.264 | total 4003.4 | n_correct 2415.2 | ppl 7.74 | accuracy 60.329 | uer 18.857 | wer 20.581 | raw_wer 20.581 | bleu 19.14 | wps 2213 | wpb 4003.4 | bsz 141.8 | num_updates 11785 | best_bleu 19.14
2023-08-01 13:41:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11785 updates
2023-08-01 13:41:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 13:42:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 13:42:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt (epoch 8 @ 11785 updates, score 19.14) (writing took 21.08869919553399 seconds)
2023-08-01 13:42:15 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-01 13:42:15 | INFO | train | epoch 008 | loss 2.062 | trans_loss 3.528 | nll_loss 1.694 | w2v_ctc_loss 1.087 | task_loss 0.932 | contrastive_loss 0.192 | total 4138.65 | n_correct 2441.51 | ppl 3.23 | accuracy 58.993 | wps 13006.7 | ups 1.05 | wpb 12355.8 | bsz 458.5 | num_updates 11785 | lr 0.000130272 | gnorm 0.399 | clip 0 | loss_scale 16 | train_wall 1340 | gb_free 16.8 | wall 10710
2023-08-01 13:42:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 13:42:16 | INFO | fairseq.trainer | begin training epoch 9
2023-08-01 13:42:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 13:42:37 | INFO | train_inner | epoch 009:     15 / 1474 loss=2.061, trans_loss=3.526, nll_loss=1.69, w2v_ctc_loss=1.067, task_loss=0.899, contrastive_loss=0.324, total=4139.35, n_correct=2453.52, ppl=3.23, accuracy=59.273, wps=8591.7, ups=0.7, wpb=12350.9, bsz=472.9, num_updates=11800, lr=0.000130189, gnorm=0.393, clip=0, loss_scale=16, train_wall=91, gb_free=15.4, wall=10731
2023-08-01 13:44:09 | INFO | train_inner | epoch 009:    115 / 1474 loss=2.005, trans_loss=3.489, nll_loss=1.644, w2v_ctc_loss=1.039, task_loss=0.886, contrastive_loss=0.143, total=4181.9, n_correct=2519.96, ppl=3.12, accuracy=60.259, wps=13675.3, ups=1.1, wpb=12488.1, bsz=475.9, num_updates=11900, lr=0.000129641, gnorm=0.39, clip=0, loss_scale=16, train_wall=91, gb_free=16.2, wall=10823
2023-08-01 13:45:41 | INFO | train_inner | epoch 009:    215 / 1474 loss=2.004, trans_loss=3.498, nll_loss=1.654, w2v_ctc_loss=1.043, task_loss=1.005, contrastive_loss=0.101, total=4062.07, n_correct=2437.25, ppl=3.15, accuracy=60, wps=13135.5, ups=1.08, wpb=12129.1, bsz=431.6, num_updates=12000, lr=0.000129099, gnorm=0.398, clip=0, loss_scale=16, train_wall=92, gb_free=15.5, wall=10915
2023-08-01 13:45:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 13:46:04 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.253 | trans_loss 5.659 | nll_loss 2.96 | w2v_ctc_loss 1.303 | task_loss 4.566 | contrastive_loss 0.264 | total 4003.4 | n_correct 2405.8 | ppl 7.78 | accuracy 60.094 | uer 18.671 | wer 20.54 | raw_wer 20.54 | bleu 18.98 | wps 2215.9 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 19.14
2023-08-01 13:46:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-08-01 13:46:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_9_12000.pt
2023-08-01 13:46:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_9_12000.pt
2023-08-01 13:46:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.98) (writing took 24.76182809844613 seconds)
2023-08-01 13:48:00 | INFO | train_inner | epoch 009:    315 / 1474 loss=1.997, trans_loss=3.484, nll_loss=1.639, w2v_ctc_loss=1.029, task_loss=0.873, contrastive_loss=0.15, total=4152.1, n_correct=2508.2, ppl=3.12, accuracy=60.408, wps=8909.3, ups=0.72, wpb=12407.3, bsz=476.6, num_updates=12100, lr=0.000128565, gnorm=0.388, clip=0, loss_scale=32, train_wall=90, gb_free=16.2, wall=11054
2023-08-01 13:49:32 | INFO | train_inner | epoch 009:    415 / 1474 loss=2.004, trans_loss=3.501, nll_loss=1.659, w2v_ctc_loss=1.04, task_loss=0.91, contrastive_loss=0.119, total=4203.78, n_correct=2522.32, ppl=3.16, accuracy=60.001, wps=13629.7, ups=1.09, wpb=12551.8, bsz=469.8, num_updates=12200, lr=0.000128037, gnorm=0.394, clip=0, loss_scale=32, train_wall=92, gb_free=17.1, wall=11147
2023-08-01 13:51:04 | INFO | train_inner | epoch 009:    515 / 1474 loss=2.033, trans_loss=3.507, nll_loss=1.665, w2v_ctc_loss=1.065, task_loss=0.981, contrastive_loss=0.169, total=4112.78, n_correct=2458.39, ppl=3.17, accuracy=59.774, wps=13373.8, ups=1.09, wpb=12275.6, bsz=437.7, num_updates=12300, lr=0.000127515, gnorm=0.396, clip=0, loss_scale=32, train_wall=91, gb_free=16.1, wall=11238
2023-08-01 13:52:35 | INFO | train_inner | epoch 009:    615 / 1474 loss=1.997, trans_loss=3.497, nll_loss=1.657, w2v_ctc_loss=1.032, task_loss=0.949, contrastive_loss=0.128, total=4131.32, n_correct=2478.58, ppl=3.15, accuracy=59.995, wps=13543.4, ups=1.1, wpb=12347.4, bsz=455, num_updates=12400, lr=0.000127, gnorm=0.389, clip=0, loss_scale=32, train_wall=91, gb_free=17.8, wall=11329
2023-08-01 13:54:05 | INFO | train_inner | epoch 009:    715 / 1474 loss=2.033, trans_loss=3.508, nll_loss=1.67, w2v_ctc_loss=1.059, task_loss=0.952, contrastive_loss=0.212, total=4082.11, n_correct=2437.65, ppl=3.18, accuracy=59.715, wps=13529.9, ups=1.11, wpb=12194.8, bsz=449.7, num_updates=12500, lr=0.000126491, gnorm=0.399, clip=0, loss_scale=32, train_wall=90, gb_free=16.9, wall=11420
2023-08-01 13:55:37 | INFO | train_inner | epoch 009:    815 / 1474 loss=2.053, trans_loss=3.501, nll_loss=1.664, w2v_ctc_loss=1.049, task_loss=0.843, contrastive_loss=0.358, total=4221.08, n_correct=2526.17, ppl=3.17, accuracy=59.847, wps=13755.6, ups=1.09, wpb=12613.9, bsz=501.6, num_updates=12600, lr=0.000125988, gnorm=0.4, clip=0, loss_scale=32, train_wall=91, gb_free=17.6, wall=11511
2023-08-01 13:57:10 | INFO | train_inner | epoch 009:    915 / 1474 loss=2.036, trans_loss=3.507, nll_loss=1.666, w2v_ctc_loss=1.045, task_loss=0.965, contrastive_loss=0.335, total=4142.34, n_correct=2475.58, ppl=3.17, accuracy=59.763, wps=13289.3, ups=1.08, wpb=12359.9, bsz=448.9, num_updates=12700, lr=0.000125491, gnorm=0.39, clip=0, loss_scale=32, train_wall=93, gb_free=17.2, wall=11604
2023-08-01 13:58:42 | INFO | train_inner | epoch 009:   1015 / 1474 loss=2.022, trans_loss=3.516, nll_loss=1.678, w2v_ctc_loss=1.057, task_loss=1.047, contrastive_loss=0.116, total=4097.15, n_correct=2439.47, ppl=3.2, accuracy=59.541, wps=13335, ups=1.09, wpb=12228.7, bsz=422.6, num_updates=12800, lr=0.000125, gnorm=0.394, clip=0, loss_scale=32, train_wall=91, gb_free=16.8, wall=11696
2023-08-01 14:00:12 | INFO | train_inner | epoch 009:   1115 / 1474 loss=2.013, trans_loss=3.51, nll_loss=1.668, w2v_ctc_loss=1.044, task_loss=0.872, contrastive_loss=0.141, total=4182.29, n_correct=2510.21, ppl=3.18, accuracy=60.02, wps=13743.2, ups=1.1, wpb=12467.1, bsz=477.6, num_updates=12900, lr=0.000124515, gnorm=0.397, clip=0, loss_scale=32, train_wall=90, gb_free=17.2, wall=11787
2023-08-01 14:01:44 | INFO | train_inner | epoch 009:   1215 / 1474 loss=2.021, trans_loss=3.512, nll_loss=1.674, w2v_ctc_loss=1.06, task_loss=0.99, contrastive_loss=0.122, total=4141.43, n_correct=2472.92, ppl=3.19, accuracy=59.712, wps=13521.2, ups=1.09, wpb=12364.7, bsz=446.6, num_updates=13000, lr=0.000124035, gnorm=0.392, clip=0, loss_scale=32, train_wall=91, gb_free=17.5, wall=11878
2023-08-01 14:03:16 | INFO | train_inner | epoch 009:   1315 / 1474 loss=2.032, trans_loss=3.506, nll_loss=1.667, w2v_ctc_loss=1.037, task_loss=0.847, contrastive_loss=0.315, total=4203.91, n_correct=2522.23, ppl=3.18, accuracy=59.997, wps=13668.7, ups=1.09, wpb=12545.2, bsz=492.3, num_updates=13100, lr=0.00012356, gnorm=0.393, clip=0, loss_scale=32, train_wall=91, gb_free=17.2, wall=11970
2023-08-01 14:04:47 | INFO | train_inner | epoch 009:   1415 / 1474 loss=2.015, trans_loss=3.517, nll_loss=1.68, w2v_ctc_loss=1.053, task_loss=1.006, contrastive_loss=0.099, total=4077.08, n_correct=2431.31, ppl=3.2, accuracy=59.634, wps=13334.5, ups=1.1, wpb=12165, bsz=429.1, num_updates=13200, lr=0.000123091, gnorm=0.395, clip=0, loss_scale=32, train_wall=91, gb_free=17.3, wall=12061
2023-08-01 14:05:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 14:06:02 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.236 | trans_loss 5.632 | nll_loss 2.927 | w2v_ctc_loss 1.315 | task_loss 4.609 | contrastive_loss 0.255 | total 4003.4 | n_correct 2416.9 | ppl 7.61 | accuracy 60.371 | uer 18.355 | wer 20.242 | raw_wer 20.242 | bleu 19.31 | wps 2305 | wpb 4003.4 | bsz 141.8 | num_updates 13259 | best_bleu 19.31
2023-08-01 14:06:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13259 updates
2023-08-01 14:06:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 14:06:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 14:06:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt (epoch 9 @ 13259 updates, score 19.31) (writing took 20.464212642982602 seconds)
2023-08-01 14:06:23 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-01 14:06:23 | INFO | train | epoch 009 | loss 2.019 | trans_loss 3.504 | nll_loss 1.663 | w2v_ctc_loss 1.047 | task_loss 0.933 | contrastive_loss 0.185 | total 4138.65 | n_correct 2479.5 | ppl 3.17 | accuracy 59.911 | wps 12581.6 | ups 1.02 | wpb 12355.8 | bsz 458.5 | num_updates 13259 | lr 0.000122817 | gnorm 0.394 | clip 0 | loss_scale 32 | train_wall 1340 | gb_free 11.4 | wall 12157
2023-08-01 14:06:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 14:06:23 | INFO | fairseq.trainer | begin training epoch 10
2023-08-01 14:06:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 14:07:09 | INFO | train_inner | epoch 010:     41 / 1474 loss=2.004, trans_loss=3.496, nll_loss=1.654, w2v_ctc_loss=1.027, task_loss=0.888, contrastive_loss=0.197, total=4100.86, n_correct=2477.48, ppl=3.15, accuracy=60.414, wps=8633.4, ups=0.71, wpb=12239.9, bsz=470.2, num_updates=13300, lr=0.000122628, gnorm=0.39, clip=0, loss_scale=32, train_wall=90, gb_free=16.4, wall=12203
2023-08-01 14:08:40 | INFO | train_inner | epoch 010:    141 / 1474 loss=1.96, trans_loss=3.471, nll_loss=1.621, w2v_ctc_loss=0.997, task_loss=0.88, contrastive_loss=0.121, total=4240.18, n_correct=2585.91, ppl=3.08, accuracy=60.986, wps=13884.8, ups=1.1, wpb=12664, bsz=479.1, num_updates=13400, lr=0.000122169, gnorm=0.384, clip=0, loss_scale=32, train_wall=91, gb_free=14.8, wall=12294
2023-08-01 14:10:11 | INFO | train_inner | epoch 010:    241 / 1474 loss=1.99, trans_loss=3.474, nll_loss=1.623, w2v_ctc_loss=1.012, task_loss=0.924, contrastive_loss=0.249, total=4126.3, n_correct=2513.29, ppl=3.08, accuracy=60.909, wps=13466.9, ups=1.09, wpb=12312.3, bsz=460.9, num_updates=13500, lr=0.000121716, gnorm=0.395, clip=0, loss_scale=32, train_wall=91, gb_free=15.4, wall=12386
2023-08-01 14:11:43 | INFO | train_inner | epoch 010:    341 / 1474 loss=1.97, trans_loss=3.471, nll_loss=1.624, w2v_ctc_loss=1.005, task_loss=0.95, contrastive_loss=0.156, total=4132.25, n_correct=2514.52, ppl=3.08, accuracy=60.851, wps=13526.3, ups=1.1, wpb=12352, bsz=452.8, num_updates=13600, lr=0.000121268, gnorm=0.393, clip=0, loss_scale=32, train_wall=91, gb_free=14.6, wall=12477
2023-08-01 14:13:15 | INFO | train_inner | epoch 010:    441 / 1474 loss=1.986, trans_loss=3.478, nll_loss=1.63, w2v_ctc_loss=0.993, task_loss=0.894, contrastive_loss=0.33, total=4203.14, n_correct=2553.15, ppl=3.1, accuracy=60.744, wps=13617.6, ups=1.09, wpb=12548.6, bsz=481.7, num_updates=13700, lr=0.000120824, gnorm=0.391, clip=0, loss_scale=32, train_wall=92, gb_free=16.3, wall=12569
2023-08-01 14:14:47 | INFO | train_inner | epoch 010:    541 / 1474 loss=1.987, trans_loss=3.493, nll_loss=1.645, w2v_ctc_loss=1.028, task_loss=0.993, contrastive_loss=0.109, total=4106.5, n_correct=2480.39, ppl=3.13, accuracy=60.402, wps=13328, ups=1.09, wpb=12244.6, bsz=440, num_updates=13800, lr=0.000120386, gnorm=0.397, clip=0, loss_scale=32, train_wall=91, gb_free=16.3, wall=12661
2023-08-01 14:16:19 | INFO | train_inner | epoch 010:    641 / 1474 loss=1.997, trans_loss=3.486, nll_loss=1.641, w2v_ctc_loss=1.018, task_loss=0.89, contrastive_loss=0.224, total=4170.61, n_correct=2527.97, ppl=3.12, accuracy=60.614, wps=13560.4, ups=1.09, wpb=12448.2, bsz=476.1, num_updates=13900, lr=0.000119952, gnorm=0.396, clip=0, loss_scale=32, train_wall=91, gb_free=10.6, wall=12753
2023-08-01 14:17:49 | INFO | train_inner | epoch 010:    741 / 1474 loss=1.991, trans_loss=3.489, nll_loss=1.645, w2v_ctc_loss=1.034, task_loss=0.939, contrastive_loss=0.108, total=4123.31, n_correct=2493.35, ppl=3.13, accuracy=60.47, wps=13565.8, ups=1.1, wpb=12306.7, bsz=453, num_updates=14000, lr=0.000119523, gnorm=0.399, clip=0, loss_scale=32, train_wall=90, gb_free=16.9, wall=12844
2023-08-01 14:17:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 14:18:12 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.238 | trans_loss 5.631 | nll_loss 2.922 | w2v_ctc_loss 1.319 | task_loss 4.588 | contrastive_loss 0.265 | total 4003.4 | n_correct 2431.7 | ppl 7.58 | accuracy 60.741 | uer 18.796 | wer 20.685 | raw_wer 20.685 | bleu 19.41 | wps 2173.6 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 19.41
2023-08-01 14:18:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-08-01 14:18:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_10_14000.pt
2023-08-01 14:18:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_10_14000.pt
2023-08-01 14:18:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 19.41) (writing took 21.00217097438872 seconds)
2023-08-01 14:20:05 | INFO | train_inner | epoch 010:    841 / 1474 loss=1.967, trans_loss=3.482, nll_loss=1.637, w2v_ctc_loss=1.005, task_loss=0.921, contrastive_loss=0.11, total=4125.69, n_correct=2507.36, ppl=3.11, accuracy=60.774, wps=9053.5, ups=0.73, wpb=12321, bsz=456.1, num_updates=14100, lr=0.000119098, gnorm=0.388, clip=0, loss_scale=64, train_wall=90, gb_free=15.7, wall=12980
2023-08-01 14:21:36 | INFO | train_inner | epoch 010:    941 / 1474 loss=1.984, trans_loss=3.486, nll_loss=1.639, w2v_ctc_loss=1.015, task_loss=0.891, contrastive_loss=0.15, total=4170.41, n_correct=2530.09, ppl=3.11, accuracy=60.668, wps=13648.9, ups=1.1, wpb=12437.5, bsz=470.8, num_updates=14200, lr=0.000118678, gnorm=0.4, clip=0, loss_scale=64, train_wall=91, gb_free=16, wall=13071
2023-08-01 14:23:08 | INFO | train_inner | epoch 010:   1041 / 1474 loss=1.982, trans_loss=3.489, nll_loss=1.646, w2v_ctc_loss=1.018, task_loss=1.012, contrastive_loss=0.122, total=4072.57, n_correct=2457.5, ppl=3.13, accuracy=60.343, wps=13227.6, ups=1.09, wpb=12161.8, bsz=434.8, num_updates=14300, lr=0.000118262, gnorm=0.395, clip=0, loss_scale=64, train_wall=91, gb_free=16.8, wall=13163
2023-08-01 14:24:39 | INFO | train_inner | epoch 010:   1141 / 1474 loss=1.992, trans_loss=3.498, nll_loss=1.656, w2v_ctc_loss=1.033, task_loss=1.039, contrastive_loss=0.103, total=4041.97, n_correct=2431.08, ppl=3.15, accuracy=60.146, wps=13309.5, ups=1.1, wpb=12067, bsz=421.9, num_updates=14400, lr=0.000117851, gnorm=0.403, clip=0, loss_scale=64, train_wall=90, gb_free=16.4, wall=13253
2023-08-01 14:26:10 | INFO | train_inner | epoch 010:   1241 / 1474 loss=1.98, trans_loss=3.484, nll_loss=1.644, w2v_ctc_loss=1.025, task_loss=0.961, contrastive_loss=0.1, total=4103.65, n_correct=2482.35, ppl=3.13, accuracy=60.491, wps=13502.3, ups=1.1, wpb=12271.8, bsz=443.9, num_updates=14500, lr=0.000117444, gnorm=0.397, clip=0, loss_scale=64, train_wall=90, gb_free=15.5, wall=13344
2023-08-01 14:27:42 | INFO | train_inner | epoch 010:   1341 / 1474 loss=1.981, trans_loss=3.491, nll_loss=1.649, w2v_ctc_loss=1.022, task_loss=0.953, contrastive_loss=0.112, total=4121.93, n_correct=2495.62, ppl=3.14, accuracy=60.545, wps=13419.4, ups=1.09, wpb=12309.4, bsz=451.2, num_updates=14600, lr=0.000117041, gnorm=0.401, clip=0, loss_scale=64, train_wall=91, gb_free=16.7, wall=13436
2023-08-01 14:29:14 | INFO | train_inner | epoch 010:   1441 / 1474 loss=2.016, trans_loss=3.497, nll_loss=1.655, w2v_ctc_loss=1.004, task_loss=0.879, contrastive_loss=0.365, total=4194.27, n_correct=2530.94, ppl=3.15, accuracy=60.343, wps=13533.2, ups=1.08, wpb=12512.4, bsz=482, num_updates=14700, lr=0.000116642, gnorm=0.4, clip=0, loss_scale=64, train_wall=92, gb_free=17.4, wall=13528
2023-08-01 14:29:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 14:30:07 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.23 | trans_loss 5.615 | nll_loss 2.904 | w2v_ctc_loss 1.329 | task_loss 4.614 | contrastive_loss 0.262 | total 4003.4 | n_correct 2441.7 | ppl 7.48 | accuracy 60.991 | uer 18.039 | wer 19.783 | raw_wer 19.783 | bleu 19.22 | wps 2237.7 | wpb 4003.4 | bsz 141.8 | num_updates 14733 | best_bleu 19.41
2023-08-01 14:30:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14733 updates
2023-08-01 14:30:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_19.2206.pt
2023-08-01 14:30:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_19.2206.pt
2023-08-01 14:30:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_19.2206.pt (epoch 10 @ 14733 updates, score 19.22) (writing took 34.03038522042334 seconds)
2023-08-01 14:30:41 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-01 14:30:41 | INFO | train | epoch 010 | loss 1.984 | trans_loss 3.484 | nll_loss 1.639 | w2v_ctc_loss 1.013 | task_loss 0.934 | contrastive_loss 0.179 | total 4138.65 | n_correct 2508.51 | ppl 3.11 | accuracy 60.612 | wps 12489.7 | ups 1.01 | wpb 12355.8 | bsz 458.5 | num_updates 14733 | lr 0.000116512 | gnorm 0.395 | clip 0 | loss_scale 64 | train_wall 1339 | gb_free 17.2 | wall 13616
2023-08-01 14:30:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 14:30:42 | INFO | fairseq.trainer | begin training epoch 11
2023-08-01 14:30:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 14:31:50 | INFO | train_inner | epoch 011:     67 / 1474 loss=1.951, trans_loss=3.458, nll_loss=1.605, w2v_ctc_loss=0.983, task_loss=0.865, contrastive_loss=0.188, total=4174.41, n_correct=2567.98, ppl=3.04, accuracy=61.517, wps=7998.8, ups=0.64, wpb=12460.9, bsz=479.3, num_updates=14800, lr=0.000116248, gnorm=0.387, clip=0, loss_scale=64, train_wall=90, gb_free=15.5, wall=13684
2023-08-01 14:33:21 | INFO | train_inner | epoch 011:    167 / 1474 loss=1.948, trans_loss=3.461, nll_loss=1.611, w2v_ctc_loss=0.991, task_loss=0.969, contrastive_loss=0.106, total=4082.44, n_correct=2503.58, ppl=3.05, accuracy=61.326, wps=13412, ups=1.1, wpb=12197.2, bsz=443.6, num_updates=14900, lr=0.000115857, gnorm=0.397, clip=0, loss_scale=64, train_wall=90, gb_free=16.2, wall=13775
2023-08-01 14:34:52 | INFO | train_inner | epoch 011:    267 / 1474 loss=1.937, trans_loss=3.46, nll_loss=1.608, w2v_ctc_loss=0.98, task_loss=0.957, contrastive_loss=0.101, total=4122.02, n_correct=2532.08, ppl=3.05, accuracy=61.428, wps=13518.7, ups=1.1, wpb=12309.2, bsz=447, num_updates=15000, lr=0.00011547, gnorm=0.389, clip=0, loss_scale=64, train_wall=90, gb_free=17.3, wall=13866
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:0')
2023-08-01 14:36:00 | INFO | train_inner | epoch 011:    367 / 1474 loss=2.096, trans_loss=5.146, nll_loss=2.397, w2v_ctc_loss=0.737, task_loss=1.429, contrastive_loss=0.081, total=4098.52, n_correct=2508.14, ppl=5.27, accuracy=61.196, wps=12130.9, ups=1.47, wpb=8238.4, bsz=298.1, num_updates=15100, lr=0.000115087, gnorm=0.513, clip=0, loss_scale=64, train_wall=67, gb_free=17.5, wall=13934
2023-08-01 14:37:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-01 14:37:09 | INFO | train_inner | epoch 011:    468 / 1474 loss=2.104, trans_loss=5.181, nll_loss=2.42, w2v_ctc_loss=0.734, task_loss=1.492, contrastive_loss=0.082, total=4090.54, n_correct=2494.65, ppl=5.35, accuracy=60.986, wps=11854.5, ups=1.45, wpb=8181.1, bsz=293.5, num_updates=15200, lr=0.000114708, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=14003
2023-08-01 14:38:17 | INFO | train_inner | epoch 011:    568 / 1474 loss=2.115, trans_loss=5.179, nll_loss=2.419, w2v_ctc_loss=0.747, task_loss=1.499, contrastive_loss=0.198, total=4071.69, n_correct=2483.78, ppl=5.35, accuracy=61.001, wps=11929.9, ups=1.46, wpb=8143.4, bsz=293.7, num_updates=15300, lr=0.000114332, gnorm=0.517, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=14071
2023-08-01 14:39:25 | INFO | train_inner | epoch 011:    668 / 1474 loss=2.114, trans_loss=5.178, nll_loss=2.418, w2v_ctc_loss=0.735, task_loss=1.371, contrastive_loss=0.254, total=4157.2, n_correct=2537.82, ppl=5.34, accuracy=61.046, wps=12170, ups=1.46, wpb=8314.4, bsz=309.6, num_updates=15400, lr=0.000113961, gnorm=0.516, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=14140
2023-08-01 14:40:34 | INFO | train_inner | epoch 011:    768 / 1474 loss=2.108, trans_loss=5.188, nll_loss=2.432, w2v_ctc_loss=0.745, task_loss=1.405, contrastive_loss=0.08, total=4174.91, n_correct=2549.89, ppl=5.4, accuracy=61.077, wps=12107, ups=1.45, wpb=8349.8, bsz=306.9, num_updates=15500, lr=0.000113592, gnorm=0.517, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=14209
2023-08-01 14:41:42 | INFO | train_inner | epoch 011:    868 / 1474 loss=2.111, trans_loss=5.19, nll_loss=2.434, w2v_ctc_loss=0.747, task_loss=1.464, contrastive_loss=0.068, total=4118.44, n_correct=2506.44, ppl=5.4, accuracy=60.859, wps=12223.2, ups=1.48, wpb=8236.9, bsz=293.7, num_updates=15600, lr=0.000113228, gnorm=0.518, clip=0, loss_scale=32, train_wall=67, gb_free=10.6, wall=14276
2023-08-01 14:42:50 | INFO | train_inner | epoch 011:    968 / 1474 loss=2.108, trans_loss=5.187, nll_loss=2.431, w2v_ctc_loss=0.746, task_loss=1.43, contrastive_loss=0.081, total=4140.92, n_correct=2527.51, ppl=5.39, accuracy=61.037, wps=12170, ups=1.47, wpb=8281.8, bsz=301.9, num_updates=15700, lr=0.000112867, gnorm=0.516, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=14344
2023-08-01 14:43:58 | INFO | train_inner | epoch 011:   1068 / 1474 loss=2.108, trans_loss=5.184, nll_loss=2.428, w2v_ctc_loss=0.748, task_loss=1.376, contrastive_loss=0.1, total=4136.99, n_correct=2528.6, ppl=5.38, accuracy=61.122, wps=12179.6, ups=1.47, wpb=8274, bsz=308.8, num_updates=15800, lr=0.000112509, gnorm=0.512, clip=0, loss_scale=32, train_wall=67, gb_free=17.6, wall=14412
2023-08-01 14:45:06 | INFO | train_inner | epoch 011:   1168 / 1474 loss=2.107, trans_loss=5.19, nll_loss=2.435, w2v_ctc_loss=0.742, task_loss=1.395, contrastive_loss=0.087, total=4185.65, n_correct=2551.68, ppl=5.41, accuracy=60.963, wps=12192.9, ups=1.46, wpb=8371.3, bsz=309.8, num_updates=15900, lr=0.000112154, gnorm=0.516, clip=0, loss_scale=32, train_wall=68, gb_free=13.9, wall=14481
2023-08-01 14:46:15 | INFO | train_inner | epoch 011:   1268 / 1474 loss=2.117, trans_loss=5.188, nll_loss=2.433, w2v_ctc_loss=0.754, task_loss=1.342, contrastive_loss=0.157, total=4171.89, n_correct=2540.24, ppl=5.4, accuracy=60.889, wps=12265.3, ups=1.47, wpb=8343.8, bsz=314.1, num_updates=16000, lr=0.000111803, gnorm=0.556, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=14549
2023-08-01 14:46:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:5')
2023-08-01 14:46:38 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.226 | trans_loss 5.607 | nll_loss 2.899 | w2v_ctc_loss 1.336 | task_loss 4.602 | contrastive_loss 0.261 | total 4003.4 | n_correct 2446.2 | ppl 7.46 | accuracy 61.103 | uer 17.912 | wer 19.85 | raw_wer 19.85 | bleu 19.37 | wps 2223.6 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.41
2023-08-01 14:46:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-08-01 14:46:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_11_16000.pt
2023-08-01 14:46:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_11_16000.pt
2023-08-01 14:46:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 19.37) (writing took 18.762650664895773 seconds)
2023-08-01 14:48:06 | INFO | train_inner | epoch 011:   1368 / 1474 loss=2.118, trans_loss=5.187, nll_loss=2.433, w2v_ctc_loss=0.736, task_loss=1.295, contrastive_loss=0.317, total=4190.34, n_correct=2551.36, ppl=5.4, accuracy=60.887, wps=7523.4, ups=0.9, wpb=8380.7, bsz=327.9, num_updates=16100, lr=0.000111456, gnorm=0.51, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=14660
2023-08-01 14:49:15 | INFO | train_inner | epoch 011:   1468 / 1474 loss=2.105, trans_loss=5.191, nll_loss=2.437, w2v_ctc_loss=0.74, task_loss=1.353, contrastive_loss=0.09, total=4158.39, n_correct=2535.16, ppl=5.42, accuracy=60.965, wps=12123.9, ups=1.46, wpb=8316.8, bsz=312, num_updates=16200, lr=0.000111111, gnorm=0.517, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=14729
2023-08-01 14:49:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 14:49:42 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.215 | trans_loss 5.604 | nll_loss 2.896 | w2v_ctc_loss 1.303 | task_loss 4.592 | contrastive_loss 0.262 | total 4003.4 | n_correct 2443.9 | ppl 7.44 | accuracy 61.046 | uer 18.236 | wer 19.999 | raw_wer 19.999 | bleu 19.2 | wps 2185.4 | wpb 4003.4 | bsz 141.8 | num_updates 16206 | best_bleu 19.41
2023-08-01 14:49:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16206 updates
2023-08-01 14:49:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_19.2002.pt
2023-08-01 14:49:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_19.2002.pt
2023-08-01 14:49:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_19.2002.pt (epoch 11 @ 16206 updates, score 19.2) (writing took 13.316396476700902 seconds)
2023-08-01 14:49:56 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-01 14:49:56 | INFO | train | epoch 011 | loss 2.068 | trans_loss 4.755 | nll_loss 2.223 | w2v_ctc_loss 0.802 | task_loss 1.285 | contrastive_loss 0.126 | total 4137.31 | n_correct 2527.3 | ppl 4.67 | accuracy 61.086 | wps 11500.7 | ups 1.28 | wpb 9015.8 | bsz 332.8 | num_updates 16206 | lr 0.000111091 | gnorm 0.496 | clip 0 | loss_scale 32 | train_wall 1059 | gb_free 17.2 | wall 14770
2023-08-01 14:49:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 14:49:56 | INFO | fairseq.trainer | begin training epoch 12
2023-08-01 14:49:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 14:51:08 | INFO | train_inner | epoch 012:     94 / 1474 loss=2.081, trans_loss=5.133, nll_loss=2.361, w2v_ctc_loss=0.727, task_loss=1.338, contrastive_loss=0.121, total=4146.82, n_correct=2573.56, ppl=5.14, accuracy=62.061, wps=7337.1, ups=0.88, wpb=8293.6, bsz=313.9, num_updates=16300, lr=0.00011077, gnorm=0.525, clip=0, loss_scale=32, train_wall=67, gb_free=15.7, wall=14842
2023-08-01 14:52:15 | INFO | train_inner | epoch 012:    194 / 1474 loss=2.089, trans_loss=5.145, nll_loss=2.374, w2v_ctc_loss=0.739, task_loss=1.447, contrastive_loss=0.072, total=4120.68, n_correct=2544.77, ppl=5.18, accuracy=61.756, wps=12192.4, ups=1.48, wpb=8241.4, bsz=294.7, num_updates=16400, lr=0.000110432, gnorm=0.513, clip=0, loss_scale=32, train_wall=67, gb_free=15.6, wall=14909
2023-08-01 14:53:24 | INFO | train_inner | epoch 012:    294 / 1474 loss=2.08, trans_loss=5.14, nll_loss=2.37, w2v_ctc_loss=0.72, task_loss=1.317, contrastive_loss=0.105, total=4199.46, n_correct=2598.13, ppl=5.17, accuracy=61.868, wps=12276.8, ups=1.46, wpb=8398.9, bsz=320.3, num_updates=16500, lr=0.000110096, gnorm=0.521, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=14978
2023-08-01 14:54:32 | INFO | train_inner | epoch 012:    394 / 1474 loss=2.084, trans_loss=5.148, nll_loss=2.379, w2v_ctc_loss=0.728, task_loss=1.369, contrastive_loss=0.087, total=4151.14, n_correct=2565.57, ppl=5.2, accuracy=61.804, wps=12121.2, ups=1.46, wpb=8302.3, bsz=307.8, num_updates=16600, lr=0.000109764, gnorm=0.514, clip=0, loss_scale=32, train_wall=68, gb_free=17.1, wall=15046
2023-08-01 14:55:40 | INFO | train_inner | epoch 012:    494 / 1474 loss=2.097, trans_loss=5.164, nll_loss=2.401, w2v_ctc_loss=0.742, task_loss=1.405, contrastive_loss=0.095, total=4110.49, n_correct=2528.24, ppl=5.28, accuracy=61.507, wps=12063.9, ups=1.47, wpb=8221, bsz=302.2, num_updates=16700, lr=0.000109435, gnorm=0.52, clip=0, loss_scale=32, train_wall=68, gb_free=13.7, wall=15115
2023-08-01 14:56:48 | INFO | train_inner | epoch 012:    594 / 1474 loss=2.093, trans_loss=5.154, nll_loss=2.389, w2v_ctc_loss=0.734, task_loss=1.341, contrastive_loss=0.159, total=4189.92, n_correct=2584.34, ppl=5.24, accuracy=61.68, wps=12324.9, ups=1.47, wpb=8379.8, bsz=315.1, num_updates=16800, lr=0.000109109, gnorm=0.516, clip=0, loss_scale=32, train_wall=68, gb_free=14.8, wall=15183
2023-08-01 14:57:56 | INFO | train_inner | epoch 012:    694 / 1474 loss=2.09, trans_loss=5.152, nll_loss=2.387, w2v_ctc_loss=0.717, task_loss=1.281, contrastive_loss=0.25, total=4206.3, n_correct=2601.39, ppl=5.23, accuracy=61.845, wps=12438.4, ups=1.48, wpb=8412.6, bsz=325.7, num_updates=16900, lr=0.000108786, gnorm=0.5, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=15250
2023-08-01 14:59:04 | INFO | train_inner | epoch 012:    794 / 1474 loss=2.092, trans_loss=5.154, nll_loss=2.389, w2v_ctc_loss=0.738, task_loss=1.426, contrastive_loss=0.086, total=4085.96, n_correct=2519.26, ppl=5.24, accuracy=61.657, wps=11997.1, ups=1.47, wpb=8171.9, bsz=297.1, num_updates=17000, lr=0.000108465, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=15318
2023-08-01 15:00:12 | INFO | train_inner | epoch 012:    894 / 1474 loss=2.095, trans_loss=5.159, nll_loss=2.395, w2v_ctc_loss=0.731, task_loss=1.429, contrastive_loss=0.137, total=4169.74, n_correct=2570.72, ppl=5.26, accuracy=61.652, wps=12223.6, ups=1.47, wpb=8339.5, bsz=306.4, num_updates=17100, lr=0.000108148, gnorm=0.519, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=15387
2023-08-01 15:01:20 | INFO | train_inner | epoch 012:    994 / 1474 loss=2.1, trans_loss=5.168, nll_loss=2.408, w2v_ctc_loss=0.737, task_loss=1.428, contrastive_loss=0.145, total=4117.67, n_correct=2527.18, ppl=5.31, accuracy=61.374, wps=12097, ups=1.47, wpb=8235.3, bsz=301.4, num_updates=17200, lr=0.000107833, gnorm=0.52, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=15455
2023-08-01 15:02:28 | INFO | train_inner | epoch 012:   1094 / 1474 loss=2.106, trans_loss=5.172, nll_loss=2.412, w2v_ctc_loss=0.737, task_loss=1.466, contrastive_loss=0.189, total=4047.61, n_correct=2483.01, ppl=5.32, accuracy=61.345, wps=11936.4, ups=1.47, wpb=8095.2, bsz=290.4, num_updates=17300, lr=0.000107521, gnorm=0.523, clip=0, loss_scale=64, train_wall=67, gb_free=16.5, wall=15522
2023-08-01 15:03:37 | INFO | train_inner | epoch 012:   1194 / 1474 loss=2.109, trans_loss=5.182, nll_loss=2.427, w2v_ctc_loss=0.749, task_loss=1.388, contrastive_loss=0.145, total=4184.55, n_correct=2557.35, ppl=5.38, accuracy=61.114, wps=12177.3, ups=1.46, wpb=8369.1, bsz=314.3, num_updates=17400, lr=0.000107211, gnorm=0.512, clip=0, loss_scale=64, train_wall=68, gb_free=16.6, wall=15591
2023-08-01 15:04:45 | INFO | train_inner | epoch 012:   1294 / 1474 loss=2.105, trans_loss=5.174, nll_loss=2.416, w2v_ctc_loss=0.751, task_loss=1.528, contrastive_loss=0.09, total=4086.33, n_correct=2503.98, ppl=5.34, accuracy=61.277, wps=12005.9, ups=1.47, wpb=8172.7, bsz=291.4, num_updates=17500, lr=0.000106904, gnorm=0.53, clip=0, loss_scale=64, train_wall=68, gb_free=16.6, wall=15659
2023-08-01 15:05:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-01 15:05:53 | INFO | train_inner | epoch 012:   1395 / 1474 loss=2.098, trans_loss=5.172, nll_loss=2.414, w2v_ctc_loss=0.727, task_loss=1.409, contrastive_loss=0.175, total=4141.14, n_correct=2541.05, ppl=5.33, accuracy=61.361, wps=12125, ups=1.46, wpb=8282.3, bsz=305.9, num_updates=17600, lr=0.0001066, gnorm=0.522, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=15728
2023-08-01 15:06:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 15:07:11 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.218 | trans_loss 5.587 | nll_loss 2.87 | w2v_ctc_loss 1.353 | task_loss 4.614 | contrastive_loss 0.26 | total 4003.4 | n_correct 2455.6 | ppl 7.31 | accuracy 61.338 | uer 17.968 | wer 19.768 | raw_wer 19.768 | bleu 19.44 | wps 2154.2 | wpb 4003.4 | bsz 141.8 | num_updates 17679 | best_bleu 19.44
2023-08-01 15:07:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17679 updates
2023-08-01 15:07:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 15:07:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 15:07:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt (epoch 12 @ 17679 updates, score 19.44) (writing took 20.664787784218788 seconds)
2023-08-01 15:07:32 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-01 15:07:32 | INFO | train | epoch 012 | loss 2.094 | trans_loss 5.159 | nll_loss 2.396 | w2v_ctc_loss 0.735 | task_loss 1.399 | contrastive_loss 0.131 | total 4138.8 | n_correct 2548.74 | ppl 5.26 | accuracy 61.582 | wps 11546.4 | ups 1.39 | wpb 8277.6 | bsz 305.7 | num_updates 17679 | lr 0.000106362 | gnorm 0.519 | clip 0 | loss_scale 32 | train_wall 997 | gb_free 12.7 | wall 15826
2023-08-01 15:07:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 15:07:32 | INFO | fairseq.trainer | begin training epoch 13
2023-08-01 15:07:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 15:07:55 | INFO | train_inner | epoch 013:     21 / 1474 loss=2.102, trans_loss=5.174, nll_loss=2.416, w2v_ctc_loss=0.75, task_loss=1.455, contrastive_loss=0.08, total=4096.49, n_correct=2513.43, ppl=5.34, accuracy=61.356, wps=6751.2, ups=0.82, wpb=8193, bsz=295.4, num_updates=17700, lr=0.000106299, gnorm=0.521, clip=0, loss_scale=32, train_wall=68, gb_free=14.5, wall=15849
2023-08-01 15:09:03 | INFO | train_inner | epoch 013:    121 / 1474 loss=2.072, trans_loss=5.123, nll_loss=2.347, w2v_ctc_loss=0.72, task_loss=1.402, contrastive_loss=0.092, total=4160.97, n_correct=2591.79, ppl=5.09, accuracy=62.288, wps=12148.5, ups=1.46, wpb=8321.9, bsz=302.9, num_updates=17800, lr=0.000106, gnorm=0.517, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=15917
2023-08-01 15:10:12 | INFO | train_inner | epoch 013:    221 / 1474 loss=2.085, trans_loss=5.133, nll_loss=2.362, w2v_ctc_loss=0.714, task_loss=1.29, contrastive_loss=0.308, total=4212.08, n_correct=2617.47, ppl=5.14, accuracy=62.142, wps=12297.9, ups=1.46, wpb=8424.2, bsz=329.7, num_updates=17900, lr=0.000105703, gnorm=0.515, clip=0, loss_scale=32, train_wall=68, gb_free=14.5, wall=15986
2023-08-01 15:11:20 | INFO | train_inner | epoch 013:    321 / 1474 loss=2.071, trans_loss=5.125, nll_loss=2.35, w2v_ctc_loss=0.716, task_loss=1.451, contrastive_loss=0.075, total=4102.3, n_correct=2555.15, ppl=5.1, accuracy=62.286, wps=12015, ups=1.46, wpb=8204.6, bsz=294.1, num_updates=18000, lr=0.000105409, gnorm=0.518, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=16054
2023-08-01 15:11:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 15:11:44 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.216 | trans_loss 5.596 | nll_loss 2.882 | w2v_ctc_loss 1.325 | task_loss 4.6 | contrastive_loss 0.267 | total 4003.4 | n_correct 2448.9 | ppl 7.37 | accuracy 61.171 | uer 18.292 | wer 20.111 | raw_wer 20.111 | bleu 19.3 | wps 2164.8 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.44
2023-08-01 15:11:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-08-01 15:11:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_13_18000.pt
2023-08-01 15:11:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_13_18000.pt
2023-08-01 15:12:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.3) (writing took 17.403048301115632 seconds)
2023-08-01 15:13:10 | INFO | train_inner | epoch 013:    421 / 1474 loss=2.076, trans_loss=5.132, nll_loss=2.361, w2v_ctc_loss=0.724, task_loss=1.309, contrastive_loss=0.125, total=4177.29, n_correct=2603.81, ppl=5.14, accuracy=62.333, wps=7585.8, ups=0.91, wpb=8354.6, bsz=318.4, num_updates=18100, lr=0.000105118, gnorm=0.515, clip=0, loss_scale=32, train_wall=68, gb_free=17.5, wall=16164
2023-08-01 15:14:19 | INFO | train_inner | epoch 013:    521 / 1474 loss=2.08, trans_loss=5.138, nll_loss=2.368, w2v_ctc_loss=0.719, task_loss=1.356, contrastive_loss=0.163, total=4201.22, n_correct=2603.47, ppl=5.16, accuracy=61.969, wps=12251.9, ups=1.46, wpb=8402.4, bsz=319, num_updates=18200, lr=0.000104828, gnorm=0.522, clip=0, loss_scale=32, train_wall=68, gb_free=12.8, wall=16233
2023-08-01 15:15:27 | INFO | train_inner | epoch 013:    621 / 1474 loss=2.068, trans_loss=5.131, nll_loss=2.36, w2v_ctc_loss=0.715, task_loss=1.359, contrastive_loss=0.073, total=4161.98, n_correct=2591.39, ppl=5.14, accuracy=62.263, wps=12230.2, ups=1.47, wpb=8324, bsz=308.3, num_updates=18300, lr=0.000104542, gnorm=0.517, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=16301
2023-08-01 15:16:35 | INFO | train_inner | epoch 013:    721 / 1474 loss=2.088, trans_loss=5.146, nll_loss=2.378, w2v_ctc_loss=0.739, task_loss=1.557, contrastive_loss=0.071, total=4096.76, n_correct=2533.81, ppl=5.2, accuracy=61.849, wps=11971.9, ups=1.46, wpb=8193.5, bsz=284.6, num_updates=18400, lr=0.000104257, gnorm=0.522, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=16369
2023-08-01 15:17:44 | INFO | train_inner | epoch 013:    821 / 1474 loss=2.085, trans_loss=5.144, nll_loss=2.378, w2v_ctc_loss=0.727, task_loss=1.414, contrastive_loss=0.122, total=4121.73, n_correct=2553.06, ppl=5.2, accuracy=61.941, wps=11947.1, ups=1.45, wpb=8243.5, bsz=306.7, num_updates=18500, lr=0.000103975, gnorm=0.543, clip=0, loss_scale=32, train_wall=69, gb_free=14.8, wall=16438
2023-08-01 15:18:52 | INFO | train_inner | epoch 013:    921 / 1474 loss=2.081, trans_loss=5.146, nll_loss=2.38, w2v_ctc_loss=0.724, task_loss=1.433, contrastive_loss=0.082, total=4107.01, n_correct=2544.34, ppl=5.2, accuracy=61.951, wps=12068.9, ups=1.47, wpb=8214, bsz=296.5, num_updates=18600, lr=0.000103695, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=16506
2023-08-01 15:20:00 | INFO | train_inner | epoch 013:   1021 / 1474 loss=2.09, trans_loss=5.149, nll_loss=2.383, w2v_ctc_loss=0.734, task_loss=1.481, contrastive_loss=0.134, total=4081.02, n_correct=2522.06, ppl=5.22, accuracy=61.8, wps=12034, ups=1.47, wpb=8162, bsz=293.4, num_updates=18700, lr=0.000103418, gnorm=0.52, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=16574
2023-08-01 15:21:08 | INFO | train_inner | epoch 013:   1121 / 1474 loss=2.078, trans_loss=5.139, nll_loss=2.372, w2v_ctc_loss=0.723, task_loss=1.382, contrastive_loss=0.114, total=4105.62, n_correct=2549.85, ppl=5.18, accuracy=62.106, wps=12171.4, ups=1.48, wpb=8211.2, bsz=305.9, num_updates=18800, lr=0.000103142, gnorm=0.519, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=16642
2023-08-01 15:22:16 | INFO | train_inner | epoch 013:   1221 / 1474 loss=2.091, trans_loss=5.157, nll_loss=2.396, w2v_ctc_loss=0.742, task_loss=1.494, contrastive_loss=0.076, total=4110.35, n_correct=2538.97, ppl=5.26, accuracy=61.77, wps=12025.8, ups=1.46, wpb=8220.7, bsz=295.1, num_updates=18900, lr=0.000102869, gnorm=0.535, clip=0, loss_scale=32, train_wall=68, gb_free=14.8, wall=16710
2023-08-01 15:23:24 | INFO | train_inner | epoch 013:   1321 / 1474 loss=2.08, trans_loss=5.138, nll_loss=2.372, w2v_ctc_loss=0.72, task_loss=1.376, contrastive_loss=0.172, total=4112.2, n_correct=2559.88, ppl=5.17, accuracy=62.251, wps=11989.7, ups=1.46, wpb=8224.4, bsz=308.2, num_updates=19000, lr=0.000102598, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=16779
2023-08-01 15:24:33 | INFO | train_inner | epoch 013:   1421 / 1474 loss=2.09, trans_loss=5.154, nll_loss=2.392, w2v_ctc_loss=0.723, task_loss=1.373, contrastive_loss=0.187, total=4180.88, n_correct=2583.33, ppl=5.25, accuracy=61.789, wps=12268.6, ups=1.47, wpb=8361.8, bsz=312.2, num_updates=19100, lr=0.000102329, gnorm=0.521, clip=0, loss_scale=32, train_wall=68, gb_free=15.2, wall=16847
2023-08-01 15:25:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 15:25:31 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.21 | trans_loss 5.59 | nll_loss 2.872 | w2v_ctc_loss 1.323 | task_loss 4.596 | contrastive_loss 0.26 | total 4003.4 | n_correct 2458.1 | ppl 7.32 | accuracy 61.4 | uer 18.008 | wer 19.705 | raw_wer 19.705 | bleu 19.94 | wps 2179.4 | wpb 4003.4 | bsz 141.8 | num_updates 19153 | best_bleu 19.94
2023-08-01 15:25:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19153 updates
2023-08-01 15:25:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 15:25:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 15:25:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt (epoch 13 @ 19153 updates, score 19.94) (writing took 21.485010946169496 seconds)
2023-08-01 15:25:53 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-01 15:25:53 | INFO | train | epoch 013 | loss 2.081 | trans_loss 5.139 | nll_loss 2.371 | w2v_ctc_loss 0.725 | task_loss 1.4 | contrastive_loss 0.128 | total 4138.65 | n_correct 2568.27 | ppl 5.17 | accuracy 62.056 | wps 11077.4 | ups 1.34 | wpb 8277.3 | bsz 305.7 | num_updates 19153 | lr 0.000102187 | gnorm 0.522 | clip 0 | loss_scale 32 | train_wall 999 | gb_free 17.6 | wall 16928
2023-08-01 15:25:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 15:25:54 | INFO | fairseq.trainer | begin training epoch 14
2023-08-01 15:25:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 15:26:33 | INFO | train_inner | epoch 014:     47 / 1474 loss=2.06, trans_loss=5.111, nll_loss=2.337, w2v_ctc_loss=0.712, task_loss=1.283, contrastive_loss=0.089, total=4176.2, n_correct=2618.92, ppl=5.05, accuracy=62.711, wps=6928.7, ups=0.83, wpb=8352.4, bsz=322.3, num_updates=19200, lr=0.000102062, gnorm=0.518, clip=0, loss_scale=32, train_wall=67, gb_free=10.5, wall=16967
2023-08-01 15:27:41 | INFO | train_inner | epoch 014:    147 / 1474 loss=2.056, trans_loss=5.098, nll_loss=2.317, w2v_ctc_loss=0.711, task_loss=1.414, contrastive_loss=0.072, total=4080.86, n_correct=2571.16, ppl=4.98, accuracy=63.005, wps=12040.3, ups=1.48, wpb=8161.7, bsz=299.6, num_updates=19300, lr=0.000101797, gnorm=0.52, clip=0, loss_scale=32, train_wall=67, gb_free=16.9, wall=17035
2023-08-01 15:28:50 | INFO | train_inner | epoch 014:    247 / 1474 loss=2.071, trans_loss=5.115, nll_loss=2.339, w2v_ctc_loss=0.713, task_loss=1.471, contrastive_loss=0.172, total=4106.97, n_correct=2570.39, ppl=5.06, accuracy=62.586, wps=11987.1, ups=1.46, wpb=8213.9, bsz=293.3, num_updates=19400, lr=0.000101535, gnorm=0.517, clip=0, loss_scale=32, train_wall=68, gb_free=12.2, wall=17104
2023-08-01 15:29:58 | INFO | train_inner | epoch 014:    347 / 1474 loss=2.056, trans_loss=5.105, nll_loss=2.327, w2v_ctc_loss=0.71, task_loss=1.285, contrastive_loss=0.106, total=4179.8, n_correct=2629.72, ppl=5.02, accuracy=62.915, wps=12251.7, ups=1.47, wpb=8359.6, bsz=322.5, num_updates=19500, lr=0.000101274, gnorm=0.515, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=17172
2023-08-01 15:31:06 | INFO | train_inner | epoch 014:    447 / 1474 loss=2.063, trans_loss=5.121, nll_loss=2.347, w2v_ctc_loss=0.711, task_loss=1.442, contrastive_loss=0.066, total=4120.38, n_correct=2575.44, ppl=5.09, accuracy=62.505, wps=12166.4, ups=1.48, wpb=8240.8, bsz=296.3, num_updates=19600, lr=0.000101015, gnorm=0.526, clip=0, loss_scale=32, train_wall=67, gb_free=17.2, wall=17240
2023-08-01 15:32:14 | INFO | train_inner | epoch 014:    547 / 1474 loss=2.078, trans_loss=5.126, nll_loss=2.353, w2v_ctc_loss=0.732, task_loss=1.481, contrastive_loss=0.103, total=4089.86, n_correct=2547.7, ppl=5.11, accuracy=62.293, wps=11882.1, ups=1.45, wpb=8179.7, bsz=295.5, num_updates=19700, lr=0.000100759, gnorm=0.534, clip=0, loss_scale=64, train_wall=68, gb_free=11.9, wall=17309
2023-08-01 15:33:23 | INFO | train_inner | epoch 014:    647 / 1474 loss=2.073, trans_loss=5.125, nll_loss=2.352, w2v_ctc_loss=0.715, task_loss=1.404, contrastive_loss=0.146, total=4158.94, n_correct=2592.68, ppl=5.11, accuracy=62.34, wps=12159.5, ups=1.46, wpb=8317.9, bsz=306.7, num_updates=19800, lr=0.000100504, gnorm=0.516, clip=0, loss_scale=64, train_wall=68, gb_free=16.1, wall=17377
2023-08-01 15:34:31 | INFO | train_inner | epoch 014:    747 / 1474 loss=2.059, trans_loss=5.112, nll_loss=2.337, w2v_ctc_loss=0.711, task_loss=1.359, contrastive_loss=0.078, total=4150.03, n_correct=2598.78, ppl=5.05, accuracy=62.621, wps=12156.1, ups=1.46, wpb=8300.1, bsz=310.4, num_updates=19900, lr=0.000100251, gnorm=0.52, clip=0, loss_scale=64, train_wall=68, gb_free=15.5, wall=17445
2023-08-01 15:34:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-01 15:35:40 | INFO | train_inner | epoch 014:    848 / 1474 loss=2.069, trans_loss=5.116, nll_loss=2.343, w2v_ctc_loss=0.711, task_loss=1.344, contrastive_loss=0.19, total=4165.2, n_correct=2606.97, ppl=5.07, accuracy=62.589, wps=12136, ups=1.46, wpb=8330.4, bsz=317.9, num_updates=20000, lr=0.0001, gnorm=0.51, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=17514
2023-08-01 15:35:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 15:36:04 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.217 | trans_loss 5.584 | nll_loss 2.864 | w2v_ctc_loss 1.361 | task_loss 4.62 | contrastive_loss 0.256 | total 4003.4 | n_correct 2460.5 | ppl 7.28 | accuracy 61.46 | uer 17.986 | wer 19.895 | raw_wer 19.895 | bleu 19.74 | wps 2067.4 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.94
2023-08-01 15:36:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-08-01 15:36:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_14_20000.pt
2023-08-01 15:36:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_14_20000.pt
2023-08-01 15:36:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.74) (writing took 12.406365055590868 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:0')
2023-08-01 15:37:26 | INFO | train_inner | epoch 014:    948 / 1474 loss=2.066, trans_loss=5.123, nll_loss=2.351, w2v_ctc_loss=0.709, task_loss=1.404, contrastive_loss=0.123, total=4167.75, n_correct=2601.19, ppl=5.1, accuracy=62.412, wps=7832.5, ups=0.94, wpb=8335.5, bsz=310.1, num_updates=20100, lr=9.97509e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=17620
2023-08-01 15:38:35 | INFO | train_inner | epoch 014:   1048 / 1474 loss=2.071, trans_loss=5.131, nll_loss=2.362, w2v_ctc_loss=0.715, task_loss=1.429, contrastive_loss=0.101, total=4143.92, n_correct=2582.83, ppl=5.14, accuracy=62.328, wps=12019, ups=1.45, wpb=8287.8, bsz=300.7, num_updates=20200, lr=9.95037e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=17689
2023-08-01 15:39:43 | INFO | train_inner | epoch 014:   1148 / 1474 loss=2.086, trans_loss=5.127, nll_loss=2.359, w2v_ctc_loss=0.715, task_loss=1.308, contrastive_loss=0.373, total=4228.69, n_correct=2633.83, ppl=5.13, accuracy=62.285, wps=12399.1, ups=1.47, wpb=8457.4, bsz=327.2, num_updates=20300, lr=9.92583e-05, gnorm=0.512, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=17758
2023-08-01 15:40:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-01 15:40:52 | INFO | train_inner | epoch 014:   1249 / 1474 loss=2.087, trans_loss=5.149, nll_loss=2.383, w2v_ctc_loss=0.739, task_loss=1.644, contrastive_loss=0.06, total=4024.07, n_correct=2488.1, ppl=5.22, accuracy=61.83, wps=11733.7, ups=1.46, wpb=8048.1, bsz=272.2, num_updates=20400, lr=9.90148e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=68, gb_free=17.6, wall=17826
2023-08-01 15:42:00 | INFO | train_inner | epoch 014:   1349 / 1474 loss=2.061, trans_loss=5.131, nll_loss=2.363, w2v_ctc_loss=0.702, task_loss=1.329, contrastive_loss=0.078, total=4205.07, n_correct=2625.63, ppl=5.14, accuracy=62.44, wps=12330.3, ups=1.47, wpb=8410.1, bsz=317.3, num_updates=20500, lr=9.8773e-05, gnorm=0.507, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=17894
2023-08-01 15:43:09 | INFO | train_inner | epoch 014:   1449 / 1474 loss=2.074, trans_loss=5.139, nll_loss=2.373, w2v_ctc_loss=0.715, task_loss=1.399, contrastive_loss=0.117, total=4126.44, n_correct=2565.65, ppl=5.18, accuracy=62.176, wps=12044.3, ups=1.46, wpb=8252.9, bsz=303.9, num_updates=20600, lr=9.85329e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=68, gb_free=16.1, wall=17963
2023-08-01 15:43:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:1')
2023-08-01 15:43:49 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.201 | trans_loss 5.577 | nll_loss 2.858 | w2v_ctc_loss 1.324 | task_loss 4.599 | contrastive_loss 0.255 | total 4003.4 | n_correct 2467.5 | ppl 7.25 | accuracy 61.635 | uer 17.883 | wer 19.749 | raw_wer 19.749 | bleu 19.6 | wps 2262 | wpb 4003.4 | bsz 141.8 | num_updates 20625 | best_bleu 19.94
2023-08-01 15:43:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20625 updates
2023-08-01 15:43:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_19.6002.pt
2023-08-01 15:43:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_19.6002.pt
2023-08-01 15:44:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_19.6002.pt (epoch 14 @ 20625 updates, score 19.6) (writing took 15.330005969852209 seconds)
2023-08-01 15:44:04 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-01 15:44:04 | INFO | train | epoch 014 | loss 2.069 | trans_loss 5.122 | nll_loss 2.35 | w2v_ctc_loss 0.715 | task_loss 1.402 | contrastive_loss 0.127 | total 4138.17 | n_correct 2584.87 | ppl 5.1 | accuracy 62.464 | wps 11166.3 | ups 1.35 | wpb 8276.3 | bsz 305.5 | num_updates 20625 | lr 9.84732e-05 | gnorm 0.52 | clip 0 | loss_scale 16 | train_wall 1000 | gb_free 16.4 | wall 18019
2023-08-01 15:44:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 15:44:05 | INFO | fairseq.trainer | begin training epoch 15
2023-08-01 15:44:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 15:45:03 | INFO | train_inner | epoch 015:     75 / 1474 loss=2.06, trans_loss=5.107, nll_loss=2.33, w2v_ctc_loss=0.702, task_loss=1.404, contrastive_loss=0.166, total=4090.99, n_correct=2570.8, ppl=5.03, accuracy=62.841, wps=7144.5, ups=0.87, wpb=8182, bsz=300.8, num_updates=20700, lr=9.82946e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=67, gb_free=16.8, wall=18077
2023-08-01 15:46:11 | INFO | train_inner | epoch 015:    175 / 1474 loss=2.059, trans_loss=5.101, nll_loss=2.321, w2v_ctc_loss=0.717, task_loss=1.448, contrastive_loss=0.075, total=4115.56, n_correct=2585.99, ppl=5, accuracy=62.834, wps=12055, ups=1.46, wpb=8231.1, bsz=298.5, num_updates=20800, lr=9.80581e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=18146
2023-08-01 15:47:19 | INFO | train_inner | epoch 015:    275 / 1474 loss=2.047, trans_loss=5.099, nll_loss=2.319, w2v_ctc_loss=0.699, task_loss=1.36, contrastive_loss=0.066, total=4182.19, n_correct=2640.1, ppl=4.99, accuracy=63.127, wps=12346.3, ups=1.48, wpb=8364.4, bsz=310.5, num_updates=20900, lr=9.78232e-05, gnorm=0.511, clip=0, loss_scale=16, train_wall=67, gb_free=16.4, wall=18213
2023-08-01 15:48:27 | INFO | train_inner | epoch 015:    375 / 1474 loss=2.048, trans_loss=5.092, nll_loss=2.31, w2v_ctc_loss=0.698, task_loss=1.395, contrastive_loss=0.092, total=4172.52, n_correct=2629.62, ppl=4.96, accuracy=63.022, wps=12277.8, ups=1.47, wpb=8345, bsz=307.7, num_updates=21000, lr=9.759e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=67, gb_free=16.6, wall=18281
2023-08-01 15:49:35 | INFO | train_inner | epoch 015:    475 / 1474 loss=2.064, trans_loss=5.107, nll_loss=2.33, w2v_ctc_loss=0.704, task_loss=1.466, contrastive_loss=0.181, total=4076.84, n_correct=2556.35, ppl=5.03, accuracy=62.704, wps=11984.2, ups=1.47, wpb=8153.7, bsz=293.4, num_updates=21100, lr=9.73585e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=18350
2023-08-01 15:50:43 | INFO | train_inner | epoch 015:    575 / 1474 loss=2.057, trans_loss=5.102, nll_loss=2.324, w2v_ctc_loss=0.711, task_loss=1.43, contrastive_loss=0.095, total=4156.05, n_correct=2612.64, ppl=5.01, accuracy=62.864, wps=12222.8, ups=1.47, wpb=8312.1, bsz=302.8, num_updates=21200, lr=9.71286e-05, gnorm=0.513, clip=0, loss_scale=16, train_wall=67, gb_free=11.6, wall=18418
2023-08-01 15:51:51 | INFO | train_inner | epoch 015:    675 / 1474 loss=2.058, trans_loss=5.1, nll_loss=2.321, w2v_ctc_loss=0.705, task_loss=1.433, contrastive_loss=0.138, total=4118.87, n_correct=2592.36, ppl=5, accuracy=62.939, wps=12079.8, ups=1.47, wpb=8237.7, bsz=303, num_updates=21300, lr=9.69003e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=18486
2023-08-01 15:53:00 | INFO | train_inner | epoch 015:    775 / 1474 loss=2.06, trans_loss=5.113, nll_loss=2.339, w2v_ctc_loss=0.716, task_loss=1.41, contrastive_loss=0.077, total=4176.64, n_correct=2619.67, ppl=5.06, accuracy=62.722, wps=12224.6, ups=1.46, wpb=8353.3, bsz=305.3, num_updates=21400, lr=9.66736e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=68, gb_free=13.9, wall=18554
2023-08-01 15:54:07 | INFO | train_inner | epoch 015:    875 / 1474 loss=2.063, trans_loss=5.116, nll_loss=2.343, w2v_ctc_loss=0.712, task_loss=1.514, contrastive_loss=0.072, total=4056.99, n_correct=2537.2, ppl=5.07, accuracy=62.539, wps=12033, ups=1.48, wpb=8114, bsz=288, num_updates=21500, lr=9.64486e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=67, gb_free=17.3, wall=18621
2023-08-01 15:55:15 | INFO | train_inner | epoch 015:    975 / 1474 loss=2.06, trans_loss=5.11, nll_loss=2.335, w2v_ctc_loss=0.703, task_loss=1.394, contrastive_loss=0.157, total=4134.44, n_correct=2596.21, ppl=5.05, accuracy=62.795, wps=12172.6, ups=1.47, wpb=8268.9, bsz=304.8, num_updates=21600, lr=9.6225e-05, gnorm=0.516, clip=0, loss_scale=16, train_wall=67, gb_free=16, wall=18689
2023-08-01 15:56:24 | INFO | train_inner | epoch 015:   1075 / 1474 loss=2.072, trans_loss=5.116, nll_loss=2.344, w2v_ctc_loss=0.707, task_loss=1.316, contrastive_loss=0.314, total=4185.02, n_correct=2619.14, ppl=5.08, accuracy=62.584, wps=12236.9, ups=1.46, wpb=8370, bsz=324.2, num_updates=21700, lr=9.60031e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=18758
2023-08-01 15:57:31 | INFO | train_inner | epoch 015:   1175 / 1474 loss=2.045, trans_loss=5.104, nll_loss=2.331, w2v_ctc_loss=0.687, task_loss=1.251, contrastive_loss=0.12, total=4187.68, n_correct=2642.46, ppl=5.03, accuracy=63.101, wps=12331.9, ups=1.47, wpb=8375.4, bsz=329.7, num_updates=21800, lr=9.57826e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=67, gb_free=16.6, wall=18826
2023-08-01 15:58:39 | INFO | train_inner | epoch 015:   1275 / 1474 loss=2.063, trans_loss=5.115, nll_loss=2.342, w2v_ctc_loss=0.719, task_loss=1.442, contrastive_loss=0.075, total=4141.6, n_correct=2594.09, ppl=5.07, accuracy=62.635, wps=12249.9, ups=1.48, wpb=8283.2, bsz=301.1, num_updates=21900, lr=9.55637e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=67, gb_free=13.4, wall=18893
2023-08-01 15:59:47 | INFO | train_inner | epoch 015:   1375 / 1474 loss=2.058, trans_loss=5.116, nll_loss=2.342, w2v_ctc_loss=0.708, task_loss=1.451, contrastive_loss=0.06, total=4099.6, n_correct=2572.19, ppl=5.07, accuracy=62.742, wps=12075.6, ups=1.47, wpb=8199.2, bsz=293.2, num_updates=22000, lr=9.53463e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=67, gb_free=14.3, wall=18961
2023-08-01 15:59:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 16:00:10 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.195 | trans_loss 5.576 | nll_loss 2.853 | w2v_ctc_loss 1.309 | task_loss 4.602 | contrastive_loss 0.249 | total 4003.4 | n_correct 2466.3 | ppl 7.22 | accuracy 61.605 | uer 17.716 | wer 19.436 | raw_wer 19.436 | bleu 19.78 | wps 2242.1 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 19.94
2023-08-01 16:00:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-08-01 16:00:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_15_22000.pt
2023-08-01 16:00:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_15_22000.pt
2023-08-01 16:00:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.78) (writing took 14.507731944322586 seconds)
2023-08-01 16:01:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 16:01:58 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.192 | trans_loss 5.571 | nll_loss 2.848 | w2v_ctc_loss 1.308 | task_loss 4.592 | contrastive_loss 0.255 | total 4003.4 | n_correct 2467.9 | ppl 7.2 | accuracy 61.645 | uer 17.652 | wer 19.395 | raw_wer 19.395 | bleu 19.65 | wps 2111.3 | wpb 4003.4 | bsz 141.8 | num_updates 22099 | best_bleu 19.94
2023-08-01 16:01:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22099 updates
2023-08-01 16:01:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_19.6509.pt
2023-08-01 16:02:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_19.6509.pt
2023-08-01 16:02:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_19.6509.pt (epoch 15 @ 22099 updates, score 19.65) (writing took 16.119865529239178 seconds)
2023-08-01 16:02:14 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-01 16:02:14 | INFO | train | epoch 015 | loss 2.058 | trans_loss 5.107 | nll_loss 2.331 | w2v_ctc_loss 0.706 | task_loss 1.4 | contrastive_loss 0.124 | total 4138.65 | n_correct 2600.28 | ppl 5.03 | accuracy 62.829 | wps 11198.9 | ups 1.35 | wpb 8277.3 | bsz 305.7 | num_updates 22099 | lr 9.51325e-05 | gnorm 0.522 | clip 0 | loss_scale 16 | train_wall 996 | gb_free 16.9 | wall 19108
2023-08-01 16:02:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 16:02:14 | INFO | fairseq.trainer | begin training epoch 16
2023-08-01 16:02:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 16:02:23 | INFO | train_inner | epoch 016:      1 / 1474 loss=2.065, trans_loss=5.119, nll_loss=2.35, w2v_ctc_loss=0.712, task_loss=1.34, contrastive_loss=0.152, total=4149.9, n_correct=2601.18, ppl=5.1, accuracy=62.681, wps=5330, ups=0.64, wpb=8299.8, bsz=316.3, num_updates=22100, lr=9.51303e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=17.4, wall=19117
2023-08-01 16:03:30 | INFO | train_inner | epoch 016:    101 / 1474 loss=2.034, trans_loss=5.073, nll_loss=2.288, w2v_ctc_loss=0.692, task_loss=1.347, contrastive_loss=0.094, total=4118.73, n_correct=2619.16, ppl=4.88, accuracy=63.591, wps=12246.4, ups=1.49, wpb=8237.5, bsz=314, num_updates=22200, lr=9.49158e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=67, gb_free=16.2, wall=19184
2023-08-01 16:04:38 | INFO | train_inner | epoch 016:    201 / 1474 loss=2.034, trans_loss=5.073, nll_loss=2.286, w2v_ctc_loss=0.687, task_loss=1.44, contrastive_loss=0.068, total=4106.45, n_correct=2610.38, ppl=4.88, accuracy=63.568, wps=12047.1, ups=1.47, wpb=8212.9, bsz=297.4, num_updates=22300, lr=9.47027e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=19252
2023-08-01 16:05:47 | INFO | train_inner | epoch 016:    301 / 1474 loss=2.05, trans_loss=5.085, nll_loss=2.303, w2v_ctc_loss=0.704, task_loss=1.382, contrastive_loss=0.141, total=4169.65, n_correct=2637.76, ppl=4.93, accuracy=63.261, wps=12200.7, ups=1.46, wpb=8339.3, bsz=309.9, num_updates=22400, lr=9.44911e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=68, gb_free=10.6, wall=19321
2023-08-01 16:06:54 | INFO | train_inner | epoch 016:    401 / 1474 loss=2.05, trans_loss=5.085, nll_loss=2.301, w2v_ctc_loss=0.697, task_loss=1.501, contrastive_loss=0.153, total=4063.79, n_correct=2570.27, ppl=4.93, accuracy=63.248, wps=11962, ups=1.47, wpb=8127.6, bsz=286.5, num_updates=22500, lr=9.42809e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=67, gb_free=12.6, wall=19389
2023-08-01 16:08:03 | INFO | train_inner | epoch 016:    501 / 1474 loss=2.043, trans_loss=5.085, nll_loss=2.303, w2v_ctc_loss=0.7, task_loss=1.345, contrastive_loss=0.099, total=4179.53, n_correct=2649.68, ppl=4.94, accuracy=63.397, wps=12242.4, ups=1.46, wpb=8359.1, bsz=319.5, num_updates=22600, lr=9.40721e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=68, gb_free=17.7, wall=19457
2023-08-01 16:09:10 | INFO | train_inner | epoch 016:    601 / 1474 loss=2.042, trans_loss=5.089, nll_loss=2.307, w2v_ctc_loss=0.695, task_loss=1.413, contrastive_loss=0.061, total=4121.37, n_correct=2606.98, ppl=4.95, accuracy=63.255, wps=12207.1, ups=1.48, wpb=8242.7, bsz=297.5, num_updates=22700, lr=9.38647e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=67, gb_free=17.8, wall=19525
2023-08-01 16:10:18 | INFO | train_inner | epoch 016:    701 / 1474 loss=2.045, trans_loss=5.093, nll_loss=2.312, w2v_ctc_loss=0.703, task_loss=1.434, contrastive_loss=0.064, total=4099.17, n_correct=2590.95, ppl=4.97, accuracy=63.207, wps=12099.9, ups=1.48, wpb=8198.3, bsz=297.5, num_updates=22800, lr=9.36586e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=19592
2023-08-01 16:11:27 | INFO | train_inner | epoch 016:    801 / 1474 loss=2.046, trans_loss=5.093, nll_loss=2.314, w2v_ctc_loss=0.691, task_loss=1.339, contrastive_loss=0.128, total=4184.53, n_correct=2639.95, ppl=4.97, accuracy=63.088, wps=12200.5, ups=1.46, wpb=8369.1, bsz=313, num_updates=22900, lr=9.34539e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=13.3, wall=19661
2023-08-01 16:12:34 | INFO | train_inner | epoch 016:    901 / 1474 loss=2.045, trans_loss=5.091, nll_loss=2.311, w2v_ctc_loss=0.692, task_loss=1.377, contrastive_loss=0.118, total=4151.84, n_correct=2624.97, ppl=4.96, accuracy=63.224, wps=12293, ups=1.48, wpb=8303.7, bsz=307, num_updates=23000, lr=9.32505e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=67, gb_free=16.8, wall=19728
2023-08-01 16:13:42 | INFO | train_inner | epoch 016:   1001 / 1474 loss=2.059, trans_loss=5.105, nll_loss=2.328, w2v_ctc_loss=0.713, task_loss=1.451, contrastive_loss=0.116, total=4112.79, n_correct=2585.13, ppl=5.02, accuracy=62.856, wps=12071.3, ups=1.47, wpb=8225.6, bsz=299.5, num_updates=23100, lr=9.30484e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=14.9, wall=19797
2023-08-01 16:14:51 | INFO | train_inner | epoch 016:   1101 / 1474 loss=2.058, trans_loss=5.108, nll_loss=2.334, w2v_ctc_loss=0.711, task_loss=1.491, contrastive_loss=0.092, total=4111.6, n_correct=2581.51, ppl=5.04, accuracy=62.786, wps=12032.7, ups=1.46, wpb=8223.2, bsz=295.6, num_updates=23200, lr=9.28477e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=14.6, wall=19865
2023-08-01 16:16:00 | INFO | train_inner | epoch 016:   1201 / 1474 loss=2.055, trans_loss=5.104, nll_loss=2.33, w2v_ctc_loss=0.691, task_loss=1.429, contrastive_loss=0.188, total=4157.51, n_correct=2613.38, ppl=5.03, accuracy=62.859, wps=12012.8, ups=1.44, wpb=8315, bsz=306.6, num_updates=23300, lr=9.26482e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=14.8, wall=19934
2023-08-01 16:17:08 | INFO | train_inner | epoch 016:   1301 / 1474 loss=2.057, trans_loss=5.102, nll_loss=2.326, w2v_ctc_loss=0.709, task_loss=1.361, contrastive_loss=0.167, total=4151.03, n_correct=2616.64, ppl=5.01, accuracy=63.036, wps=12195, ups=1.47, wpb=8302.1, bsz=314.5, num_updates=23400, lr=9.245e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=20002
2023-08-01 16:18:17 | INFO | train_inner | epoch 016:   1401 / 1474 loss=2.046, trans_loss=5.101, nll_loss=2.326, w2v_ctc_loss=0.698, task_loss=1.34, contrastive_loss=0.096, total=4201.47, n_correct=2652.71, ppl=5.01, accuracy=63.138, wps=12258.3, ups=1.46, wpb=8402.9, bsz=320.7, num_updates=23500, lr=9.22531e-05, gnorm=0.512, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=20071
2023-08-01 16:19:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 16:19:29 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.193 | trans_loss 5.567 | nll_loss 2.841 | w2v_ctc_loss 1.319 | task_loss 4.637 | contrastive_loss 0.25 | total 4003.4 | n_correct 2471.9 | ppl 7.16 | accuracy 61.745 | uer 17.506 | wer 19.324 | raw_wer 19.324 | bleu 19.93 | wps 2269.9 | wpb 4003.4 | bsz 141.8 | num_updates 23573 | best_bleu 19.94
2023-08-01 16:19:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23573 updates
2023-08-01 16:19:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_19.9309.pt
2023-08-01 16:19:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_19.9309.pt
2023-08-01 16:19:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_19.9309.pt (epoch 16 @ 23573 updates, score 19.93) (writing took 12.470815531909466 seconds)
2023-08-01 16:19:42 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-01 16:19:42 | INFO | train | epoch 016 | loss 2.048 | trans_loss 5.092 | nll_loss 2.313 | w2v_ctc_loss 0.698 | task_loss 1.402 | contrastive_loss 0.122 | total 4138.65 | n_correct 2614.35 | ppl 4.97 | accuracy 63.169 | wps 11641.7 | ups 1.41 | wpb 8277.3 | bsz 305.7 | num_updates 23573 | lr 9.21102e-05 | gnorm 0.524 | clip 0 | loss_scale 32 | train_wall 997 | gb_free 15.4 | wall 20156
2023-08-01 16:19:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 16:19:42 | INFO | fairseq.trainer | begin training epoch 17
2023-08-01 16:19:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 16:20:08 | INFO | train_inner | epoch 017:     27 / 1474 loss=2.048, trans_loss=5.084, nll_loss=2.302, w2v_ctc_loss=0.688, task_loss=1.431, contrastive_loss=0.235, total=4145.04, n_correct=2626.27, ppl=4.93, accuracy=63.359, wps=7416.1, ups=0.89, wpb=8290.1, bsz=302.4, num_updates=23600, lr=9.20575e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=20183
2023-08-01 16:21:16 | INFO | train_inner | epoch 017:    127 / 1474 loss=2.032, trans_loss=5.062, nll_loss=2.272, w2v_ctc_loss=0.695, task_loss=1.437, contrastive_loss=0.066, total=4117.27, n_correct=2624.88, ppl=4.83, accuracy=63.753, wps=12078.3, ups=1.47, wpb=8234.5, bsz=296.2, num_updates=23700, lr=9.1863e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=68, gb_free=17.8, wall=20251
2023-08-01 16:22:24 | INFO | train_inner | epoch 017:    227 / 1474 loss=2.036, trans_loss=5.062, nll_loss=2.273, w2v_ctc_loss=0.676, task_loss=1.329, contrastive_loss=0.236, total=4159.6, n_correct=2652.62, ppl=4.83, accuracy=63.771, wps=12342.8, ups=1.48, wpb=8319.2, bsz=317.6, num_updates=23800, lr=9.16698e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=67, gb_free=16.9, wall=20318
2023-08-01 16:23:32 | INFO | train_inner | epoch 017:    327 / 1474 loss=2.042, trans_loss=5.071, nll_loss=2.285, w2v_ctc_loss=0.688, task_loss=1.39, contrastive_loss=0.237, total=4156.91, n_correct=2641.91, ppl=4.87, accuracy=63.555, wps=12257.7, ups=1.47, wpb=8313.8, bsz=305.7, num_updates=23900, lr=9.14779e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=67, gb_free=17.4, wall=20386
2023-08-01 16:24:41 | INFO | train_inner | epoch 017:    427 / 1474 loss=2.028, trans_loss=5.069, nll_loss=2.283, w2v_ctc_loss=0.685, task_loss=1.387, contrastive_loss=0.067, total=4146.43, n_correct=2643.41, ppl=4.87, accuracy=63.751, wps=12013.2, ups=1.45, wpb=8292.9, bsz=308, num_updates=24000, lr=9.12871e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=20455
2023-08-01 16:24:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 16:25:05 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.197 | trans_loss 5.568 | nll_loss 2.841 | w2v_ctc_loss 1.336 | task_loss 4.604 | contrastive_loss 0.247 | total 4003.4 | n_correct 2471.7 | ppl 7.16 | accuracy 61.74 | uer 17.522 | wer 19.313 | raw_wer 19.313 | bleu 19.77 | wps 2174.4 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 19.94
2023-08-01 16:25:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-08-01 16:25:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_17_24000.pt
2023-08-01 16:25:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_17_24000.pt
2023-08-01 16:25:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.77) (writing took 20.02482884377241 seconds)
2023-08-01 16:26:35 | INFO | train_inner | epoch 017:    527 / 1474 loss=2.04, trans_loss=5.077, nll_loss=2.293, w2v_ctc_loss=0.695, task_loss=1.448, contrastive_loss=0.113, total=4182.1, n_correct=2652.33, ppl=4.9, accuracy=63.421, wps=7351.2, ups=0.88, wpb=8364.2, bsz=307.9, num_updates=24100, lr=9.10975e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=20569
2023-08-01 16:27:42 | INFO | train_inner | epoch 017:    627 / 1474 loss=2.029, trans_loss=5.075, nll_loss=2.289, w2v_ctc_loss=0.681, task_loss=1.409, contrastive_loss=0.061, total=4167.27, n_correct=2654.72, ppl=4.89, accuracy=63.704, wps=12273.6, ups=1.47, wpb=8334.5, bsz=302.2, num_updates=24200, lr=9.09091e-05, gnorm=0.511, clip=0, loss_scale=32, train_wall=67, gb_free=10.6, wall=20637
2023-08-01 16:28:51 | INFO | train_inner | epoch 017:    727 / 1474 loss=2.042, trans_loss=5.081, nll_loss=2.299, w2v_ctc_loss=0.696, task_loss=1.384, contrastive_loss=0.112, total=4166.12, n_correct=2644.08, ppl=4.92, accuracy=63.466, wps=12242.7, ups=1.47, wpb=8332.2, bsz=308.1, num_updates=24300, lr=9.07218e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=20705
2023-08-01 16:29:58 | INFO | train_inner | epoch 017:    827 / 1474 loss=2.037, trans_loss=5.083, nll_loss=2.3, w2v_ctc_loss=0.69, task_loss=1.418, contrastive_loss=0.075, total=4091.64, n_correct=2595.08, ppl=4.93, accuracy=63.424, wps=12093.6, ups=1.48, wpb=8183.3, bsz=295.3, num_updates=24400, lr=9.05357e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=67, gb_free=17.3, wall=20772
2023-08-01 16:31:06 | INFO | train_inner | epoch 017:    927 / 1474 loss=2.031, trans_loss=5.08, nll_loss=2.297, w2v_ctc_loss=0.684, task_loss=1.381, contrastive_loss=0.073, total=4106.83, n_correct=2609.8, ppl=4.91, accuracy=63.548, wps=12168.1, ups=1.48, wpb=8213.7, bsz=304.6, num_updates=24500, lr=9.03508e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=67, gb_free=15.8, wall=20840
2023-08-01 16:32:13 | INFO | train_inner | epoch 017:   1027 / 1474 loss=2.033, trans_loss=5.079, nll_loss=2.298, w2v_ctc_loss=0.688, task_loss=1.385, contrastive_loss=0.077, total=4115.49, n_correct=2617.13, ppl=4.92, accuracy=63.592, wps=12182.5, ups=1.48, wpb=8231, bsz=305.8, num_updates=24600, lr=9.0167e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=67, gb_free=16.6, wall=20908
2023-08-01 16:33:21 | INFO | train_inner | epoch 017:   1127 / 1474 loss=2.029, trans_loss=5.078, nll_loss=2.294, w2v_ctc_loss=0.678, task_loss=1.452, contrastive_loss=0.062, total=4078.39, n_correct=2594.83, ppl=4.9, accuracy=63.624, wps=12069.5, ups=1.48, wpb=8156.8, bsz=293.7, num_updates=24700, lr=8.99843e-05, gnorm=0.518, clip=0, loss_scale=64, train_wall=67, gb_free=15.5, wall=20975
2023-08-01 16:34:30 | INFO | train_inner | epoch 017:   1227 / 1474 loss=2.056, trans_loss=5.093, nll_loss=2.316, w2v_ctc_loss=0.687, task_loss=1.359, contrastive_loss=0.309, total=4173.49, n_correct=2629.83, ppl=4.98, accuracy=63.013, wps=12056.2, ups=1.44, wpb=8347, bsz=323.7, num_updates=24800, lr=8.98027e-05, gnorm=0.537, clip=0, loss_scale=64, train_wall=69, gb_free=16, wall=21044
2023-08-01 16:35:39 | INFO | train_inner | epoch 017:   1327 / 1474 loss=2.041, trans_loss=5.089, nll_loss=2.31, w2v_ctc_loss=0.681, task_loss=1.384, contrastive_loss=0.147, total=4156.28, n_correct=2629.39, ppl=4.96, accuracy=63.263, wps=12150.8, ups=1.46, wpb=8312.6, bsz=308, num_updates=24900, lr=8.96221e-05, gnorm=0.534, clip=0, loss_scale=64, train_wall=68, gb_free=17.8, wall=21113
2023-08-01 16:36:46 | INFO | train_inner | epoch 017:   1427 / 1474 loss=2.035, trans_loss=5.087, nll_loss=2.307, w2v_ctc_loss=0.684, task_loss=1.41, contrastive_loss=0.067, total=4112.95, n_correct=2604.38, ppl=4.95, accuracy=63.321, wps=12137.8, ups=1.48, wpb=8225.9, bsz=303.2, num_updates=25000, lr=8.94427e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=67, gb_free=16.8, wall=21181
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:0')
2023-08-01 16:36:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-01 16:37:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:6')
2023-08-01 16:37:41 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.183 | trans_loss 5.556 | nll_loss 2.831 | w2v_ctc_loss 1.317 | task_loss 4.62 | contrastive_loss 0.249 | total 4003.4 | n_correct 2476.8 | ppl 7.12 | accuracy 61.867 | uer 17.331 | wer 19.104 | raw_wer 19.104 | bleu 19.68 | wps 2272.9 | wpb 4003.4 | bsz 141.8 | num_updates 25046 | best_bleu 19.94
2023-08-01 16:37:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25046 updates
2023-08-01 16:37:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_19.6800.pt
2023-08-01 16:37:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_19.6800.pt
2023-08-01 16:37:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_19.6800.pt (epoch 17 @ 25046 updates, score 19.68) (writing took 15.312633533030748 seconds)
2023-08-01 16:37:57 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-01 16:37:57 | INFO | train | epoch 017 | loss 2.036 | trans_loss 5.077 | nll_loss 2.294 | w2v_ctc_loss 0.687 | task_loss 1.399 | contrastive_loss 0.121 | total 4138.94 | n_correct 2629.2 | ppl 4.9 | accuracy 63.523 | wps 11139.6 | ups 1.35 | wpb 8277.9 | bsz 305.7 | num_updates 25046 | lr 8.93605e-05 | gnorm 0.525 | clip 0 | loss_scale 32 | train_wall 996 | gb_free 16.3 | wall 21251
2023-08-01 16:37:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 16:37:57 | INFO | fairseq.trainer | begin training epoch 18
2023-08-01 16:37:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 16:38:42 | INFO | train_inner | epoch 018:     54 / 1474 loss=2.033, trans_loss=5.073, nll_loss=2.289, w2v_ctc_loss=0.691, task_loss=1.425, contrastive_loss=0.077, total=4139.57, n_correct=2634.64, ppl=4.89, accuracy=63.645, wps=7154.8, ups=0.86, wpb=8279.1, bsz=303.7, num_updates=25100, lr=8.92644e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=17.7, wall=21296
2023-08-01 16:39:51 | INFO | train_inner | epoch 018:    154 / 1474 loss=2.023, trans_loss=5.048, nll_loss=2.255, w2v_ctc_loss=0.664, task_loss=1.332, contrastive_loss=0.201, total=4158.88, n_correct=2666.39, ppl=4.77, accuracy=64.113, wps=12143.1, ups=1.46, wpb=8317.8, bsz=314, num_updates=25200, lr=8.90871e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=21365
2023-08-01 16:40:59 | INFO | train_inner | epoch 018:    254 / 1474 loss=2.017, trans_loss=5.05, nll_loss=2.259, w2v_ctc_loss=0.678, task_loss=1.36, contrastive_loss=0.069, total=4164.11, n_correct=2671.51, ppl=4.79, accuracy=64.156, wps=12163.7, ups=1.46, wpb=8328.2, bsz=312.5, num_updates=25300, lr=8.89108e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=68, gb_free=14.9, wall=21433
2023-08-01 16:42:07 | INFO | train_inner | epoch 018:    354 / 1474 loss=2.02, trans_loss=5.055, nll_loss=2.264, w2v_ctc_loss=0.673, task_loss=1.419, contrastive_loss=0.082, total=4163.13, n_correct=2661.92, ppl=4.8, accuracy=63.94, wps=12215.2, ups=1.47, wpb=8326.3, bsz=301.5, num_updates=25400, lr=8.87357e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=21501
2023-08-01 16:43:16 | INFO | train_inner | epoch 018:    454 / 1474 loss=2.033, trans_loss=5.063, nll_loss=2.275, w2v_ctc_loss=0.679, task_loss=1.495, contrastive_loss=0.174, total=4087.83, n_correct=2605.58, ppl=4.84, accuracy=63.74, wps=11897.8, ups=1.46, wpb=8175.7, bsz=295.3, num_updates=25500, lr=8.85615e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=21570
2023-08-01 16:44:24 | INFO | train_inner | epoch 018:    554 / 1474 loss=2.012, trans_loss=5.049, nll_loss=2.259, w2v_ctc_loss=0.669, task_loss=1.257, contrastive_loss=0.083, total=4204.41, n_correct=2698.25, ppl=4.79, accuracy=64.177, wps=12349.9, ups=1.47, wpb=8408.8, bsz=328, num_updates=25600, lr=8.83883e-05, gnorm=0.514, clip=0, loss_scale=32, train_wall=68, gb_free=17.4, wall=21638
2023-08-01 16:45:32 | INFO | train_inner | epoch 018:    654 / 1474 loss=2.037, trans_loss=5.076, nll_loss=2.292, w2v_ctc_loss=0.685, task_loss=1.445, contrastive_loss=0.152, total=4096.81, n_correct=2605.52, ppl=4.9, accuracy=63.599, wps=12131, ups=1.48, wpb=8193.6, bsz=298.9, num_updates=25700, lr=8.82162e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=21706
2023-08-01 16:46:40 | INFO | train_inner | epoch 018:    754 / 1474 loss=2.036, trans_loss=5.068, nll_loss=2.283, w2v_ctc_loss=0.683, task_loss=1.335, contrastive_loss=0.241, total=4208.29, n_correct=2679.68, ppl=4.87, accuracy=63.676, wps=12310.4, ups=1.46, wpb=8416.6, bsz=322.8, num_updates=25800, lr=8.80451e-05, gnorm=0.513, clip=0, loss_scale=32, train_wall=68, gb_free=17.8, wall=21774
2023-08-01 16:47:48 | INFO | train_inner | epoch 018:    854 / 1474 loss=2.027, trans_loss=5.069, nll_loss=2.283, w2v_ctc_loss=0.681, task_loss=1.421, contrastive_loss=0.058, total=4166.81, n_correct=2657.72, ppl=4.87, accuracy=63.783, wps=12228.7, ups=1.47, wpb=8333.6, bsz=301.9, num_updates=25900, lr=8.7875e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=68, gb_free=12.5, wall=21842
2023-08-01 16:48:56 | INFO | train_inner | epoch 018:    954 / 1474 loss=2.016, trans_loss=5.06, nll_loss=2.272, w2v_ctc_loss=0.667, task_loss=1.301, contrastive_loss=0.081, total=4142.65, n_correct=2650.78, ppl=4.83, accuracy=63.988, wps=12210.6, ups=1.47, wpb=8285.3, bsz=316.1, num_updates=26000, lr=8.77058e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=67, gb_free=14.8, wall=21910
2023-08-01 16:48:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 16:49:19 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.193 | trans_loss 5.56 | nll_loss 2.833 | w2v_ctc_loss 1.339 | task_loss 4.637 | contrastive_loss 0.247 | total 4003.4 | n_correct 2474.3 | ppl 7.12 | accuracy 61.805 | uer 17.471 | wer 19.309 | raw_wer 19.309 | bleu 19.94 | wps 2249.1 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 19.94
2023-08-01 16:49:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-08-01 16:49:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_18_26000.pt
2023-08-01 16:49:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_18_26000.pt
2023-08-01 16:49:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 19.94) (writing took 21.649289032444358 seconds)
2023-08-01 16:50:50 | INFO | train_inner | epoch 018:   1054 / 1474 loss=2.026, trans_loss=5.07, nll_loss=2.286, w2v_ctc_loss=0.675, task_loss=1.46, contrastive_loss=0.07, total=4137.77, n_correct=2636.78, ppl=4.88, accuracy=63.725, wps=7266.8, ups=0.88, wpb=8275.5, bsz=300.5, num_updates=26100, lr=8.75376e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=22024
2023-08-01 16:51:58 | INFO | train_inner | epoch 018:   1154 / 1474 loss=2.028, trans_loss=5.059, nll_loss=2.271, w2v_ctc_loss=0.676, task_loss=1.33, contrastive_loss=0.174, total=4153.69, n_correct=2653.98, ppl=4.83, accuracy=63.895, wps=12176.4, ups=1.47, wpb=8307.4, bsz=314.9, num_updates=26200, lr=8.73704e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=68, gb_free=15, wall=22092
2023-08-01 16:53:06 | INFO | train_inner | epoch 018:   1254 / 1474 loss=2.034, trans_loss=5.082, nll_loss=2.301, w2v_ctc_loss=0.683, task_loss=1.506, contrastive_loss=0.064, total=4087.62, n_correct=2597.84, ppl=4.93, accuracy=63.554, wps=11984, ups=1.47, wpb=8175.2, bsz=287.1, num_updates=26300, lr=8.72041e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=22161
2023-08-01 16:54:14 | INFO | train_inner | epoch 018:   1354 / 1474 loss=2.042, trans_loss=5.087, nll_loss=2.307, w2v_ctc_loss=0.698, task_loss=1.495, contrastive_loss=0.089, total=4070.69, n_correct=2581.82, ppl=4.95, accuracy=63.425, wps=11953.9, ups=1.47, wpb=8141.4, bsz=291.7, num_updates=26400, lr=8.70388e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=22229
2023-08-01 16:55:23 | INFO | train_inner | epoch 018:   1454 / 1474 loss=2.035, trans_loss=5.081, nll_loss=2.3, w2v_ctc_loss=0.688, task_loss=1.478, contrastive_loss=0.076, total=4113.2, n_correct=2611.89, ppl=4.92, accuracy=63.5, wps=12062.2, ups=1.47, wpb=8226.4, bsz=297.5, num_updates=26500, lr=8.68744e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=22297
2023-08-01 16:55:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 16:56:00 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.181 | trans_loss 5.556 | nll_loss 2.829 | w2v_ctc_loss 1.309 | task_loss 4.616 | contrastive_loss 0.242 | total 4003.4 | n_correct 2477.6 | ppl 7.11 | accuracy 61.887 | uer 17.129 | wer 18.907 | raw_wer 18.907 | bleu 19.95 | wps 2144.5 | wpb 4003.4 | bsz 141.8 | num_updates 26520 | best_bleu 19.95
2023-08-01 16:56:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26520 updates
2023-08-01 16:56:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 16:56:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 16:56:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt (epoch 18 @ 26520 updates, score 19.95) (writing took 20.474458834156394 seconds)
2023-08-01 16:56:21 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-01 16:56:21 | INFO | train | epoch 018 | loss 2.028 | trans_loss 5.065 | nll_loss 2.279 | w2v_ctc_loss 0.678 | task_loss 1.4 | contrastive_loss 0.119 | total 4138.65 | n_correct 2640.72 | ppl 4.85 | accuracy 63.806 | wps 11043.9 | ups 1.33 | wpb 8277.3 | bsz 305.7 | num_updates 26520 | lr 8.68417e-05 | gnorm 0.523 | clip 0 | loss_scale 32 | train_wall 999 | gb_free 15.9 | wall 22356
2023-08-01 16:56:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 16:56:22 | INFO | fairseq.trainer | begin training epoch 19
2023-08-01 16:56:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 16:57:24 | INFO | train_inner | epoch 019:     80 / 1474 loss=2.018, trans_loss=5.042, nll_loss=2.247, w2v_ctc_loss=0.672, task_loss=1.405, contrastive_loss=0.126, total=4102.06, n_correct=2635.61, ppl=4.75, accuracy=64.251, wps=6764.4, ups=0.82, wpb=8204.1, bsz=296.9, num_updates=26600, lr=8.6711e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=68, gb_free=17.4, wall=22418
2023-08-01 16:58:33 | INFO | train_inner | epoch 019:    180 / 1474 loss=2.012, trans_loss=5.032, nll_loss=2.236, w2v_ctc_loss=0.676, task_loss=1.306, contrastive_loss=0.119, total=4227.7, n_correct=2724.84, ppl=4.71, accuracy=64.452, wps=12239.2, ups=1.45, wpb=8455.4, bsz=324.8, num_updates=26700, lr=8.65485e-05, gnorm=0.507, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=22487
2023-08-01 16:59:41 | INFO | train_inner | epoch 019:    280 / 1474 loss=2.007, trans_loss=5.036, nll_loss=2.239, w2v_ctc_loss=0.668, task_loss=1.384, contrastive_loss=0.06, total=4187.34, n_correct=2703.1, ppl=4.72, accuracy=64.554, wps=12246.7, ups=1.46, wpb=8374.7, bsz=306.4, num_updates=26800, lr=8.63868e-05, gnorm=0.514, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=22556
2023-08-01 17:00:49 | INFO | train_inner | epoch 019:    380 / 1474 loss=2.019, trans_loss=5.044, nll_loss=2.252, w2v_ctc_loss=0.668, task_loss=1.379, contrastive_loss=0.167, total=4170.52, n_correct=2678.59, ppl=4.76, accuracy=64.227, wps=12352.6, ups=1.48, wpb=8341, bsz=311, num_updates=26900, lr=8.62261e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=67, gb_free=16.3, wall=22623
2023-08-01 17:01:56 | INFO | train_inner | epoch 019:    480 / 1474 loss=2.015, trans_loss=5.048, nll_loss=2.256, w2v_ctc_loss=0.673, task_loss=1.435, contrastive_loss=0.077, total=4113.89, n_correct=2641.96, ppl=4.78, accuracy=64.22, wps=12181.8, ups=1.48, wpb=8227.8, bsz=301.5, num_updates=27000, lr=8.60663e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=67, gb_free=17.1, wall=22691
2023-08-01 17:03:04 | INFO | train_inner | epoch 019:    580 / 1474 loss=2.015, trans_loss=5.047, nll_loss=2.255, w2v_ctc_loss=0.667, task_loss=1.372, contrastive_loss=0.14, total=4128.58, n_correct=2651.66, ppl=4.77, accuracy=64.227, wps=12199.4, ups=1.48, wpb=8257.2, bsz=306.2, num_updates=27100, lr=8.59074e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=67, gb_free=16.6, wall=22758
2023-08-01 17:04:12 | INFO | train_inner | epoch 019:    680 / 1474 loss=2.005, trans_loss=5.049, nll_loss=2.259, w2v_ctc_loss=0.656, task_loss=1.272, contrastive_loss=0.066, total=4201.56, n_correct=2702.37, ppl=4.79, accuracy=64.318, wps=12355.8, ups=1.47, wpb=8403.1, bsz=321.5, num_updates=27200, lr=8.57493e-05, gnorm=0.516, clip=0, loss_scale=64, train_wall=68, gb_free=17.8, wall=22826
2023-08-01 17:05:20 | INFO | train_inner | epoch 019:    780 / 1474 loss=2.02, trans_loss=5.051, nll_loss=2.26, w2v_ctc_loss=0.682, task_loss=1.443, contrastive_loss=0.072, total=4124.03, n_correct=2645.26, ppl=4.79, accuracy=64.143, wps=12147.9, ups=1.47, wpb=8248.1, bsz=299, num_updates=27300, lr=8.55921e-05, gnorm=0.521, clip=0, loss_scale=64, train_wall=67, gb_free=17.5, wall=22894
2023-08-01 17:06:28 | INFO | train_inner | epoch 019:    880 / 1474 loss=2.019, trans_loss=5.061, nll_loss=2.273, w2v_ctc_loss=0.676, task_loss=1.397, contrastive_loss=0.069, total=4177.8, n_correct=2671.66, ppl=4.83, accuracy=63.949, wps=12290.4, ups=1.47, wpb=8355.6, bsz=309.6, num_updates=27400, lr=8.54358e-05, gnorm=0.521, clip=0, loss_scale=64, train_wall=68, gb_free=14.8, wall=22962
2023-08-01 17:07:37 | INFO | train_inner | epoch 019:    980 / 1474 loss=2.039, trans_loss=5.072, nll_loss=2.289, w2v_ctc_loss=0.675, task_loss=1.423, contrastive_loss=0.3, total=4084.26, n_correct=2603.76, ppl=4.89, accuracy=63.751, wps=11812.6, ups=1.45, wpb=8168.5, bsz=305.8, num_updates=27500, lr=8.52803e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=69, gb_free=16.1, wall=23031
2023-08-01 17:08:45 | INFO | train_inner | epoch 019:   1080 / 1474 loss=2.028, trans_loss=5.071, nll_loss=2.287, w2v_ctc_loss=0.676, task_loss=1.471, contrastive_loss=0.106, total=4042.73, n_correct=2578.56, ppl=4.88, accuracy=63.783, wps=11854.1, ups=1.47, wpb=8085.5, bsz=294, num_updates=27600, lr=8.51257e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=68, gb_free=17.2, wall=23100
2023-08-01 17:09:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-01 17:09:55 | INFO | train_inner | epoch 019:   1181 / 1474 loss=2.034, trans_loss=5.07, nll_loss=2.285, w2v_ctc_loss=0.676, task_loss=1.422, contrastive_loss=0.188, total=4140.32, n_correct=2635.97, ppl=4.87, accuracy=63.666, wps=11964, ups=1.44, wpb=8280.6, bsz=308.3, num_updates=27700, lr=8.49719e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=14.8, wall=23169
2023-08-01 17:11:02 | INFO | train_inner | epoch 019:   1281 / 1474 loss=2.024, trans_loss=5.072, nll_loss=2.288, w2v_ctc_loss=0.673, task_loss=1.418, contrastive_loss=0.085, total=4141.89, n_correct=2644.09, ppl=4.88, accuracy=63.838, wps=12233, ups=1.48, wpb=8283.8, bsz=300.1, num_updates=27800, lr=8.48189e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=67, gb_free=15.5, wall=23237
2023-08-01 17:12:11 | INFO | train_inner | epoch 019:   1381 / 1474 loss=2.022, trans_loss=5.064, nll_loss=2.279, w2v_ctc_loss=0.675, task_loss=1.432, contrastive_loss=0.073, total=4133.26, n_correct=2641.93, ppl=4.85, accuracy=63.919, wps=12069.1, ups=1.46, wpb=8266.5, bsz=301, num_updates=27900, lr=8.46668e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=23305
2023-08-01 17:13:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 17:13:37 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.186 | trans_loss 5.548 | nll_loss 2.821 | w2v_ctc_loss 1.341 | task_loss 4.647 | contrastive_loss 0.249 | total 4003.4 | n_correct 2477.9 | ppl 7.06 | accuracy 61.895 | uer 17.323 | wer 19.022 | raw_wer 19.022 | bleu 20.34 | wps 2264 | wpb 4003.4 | bsz 141.8 | num_updates 27993 | best_bleu 20.34
2023-08-01 17:13:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27993 updates
2023-08-01 17:13:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 17:13:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 17:13:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt (epoch 19 @ 27993 updates, score 20.34) (writing took 20.96678996272385 seconds)
2023-08-01 17:13:59 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-01 17:13:59 | INFO | train | epoch 019 | loss 2.02 | trans_loss 5.054 | nll_loss 2.265 | w2v_ctc_loss 0.672 | task_loss 1.399 | contrastive_loss 0.117 | total 4138.77 | n_correct 2652.84 | ppl 4.81 | accuracy 64.097 | wps 11531.6 | ups 1.39 | wpb 8277.5 | bsz 305.7 | num_updates 27993 | lr 8.4526e-05 | gnorm 0.523 | clip 0 | loss_scale 32 | train_wall 998 | gb_free 17.3 | wall 23413
2023-08-01 17:13:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 17:13:59 | INFO | fairseq.trainer | begin training epoch 20
2023-08-01 17:13:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 17:14:11 | INFO | train_inner | epoch 020:      7 / 1474 loss=2.022, trans_loss=5.058, nll_loss=2.271, w2v_ctc_loss=0.67, task_loss=1.41, contrastive_loss=0.158, total=4119.08, n_correct=2638.32, ppl=4.83, accuracy=64.051, wps=6858.7, ups=0.83, wpb=8238.2, bsz=304.1, num_updates=28000, lr=8.45154e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=23425
2023-08-01 17:14:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 17:14:34 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.19 | trans_loss 5.55 | nll_loss 2.821 | w2v_ctc_loss 1.352 | task_loss 4.641 | contrastive_loss 0.249 | total 4003.4 | n_correct 2482.9 | ppl 7.07 | accuracy 62.02 | uer 17.323 | wer 19.075 | raw_wer 19.075 | bleu 20.24 | wps 2171.9 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.34
2023-08-01 17:14:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-08-01 17:14:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_20_28000.pt
2023-08-01 17:14:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_20_28000.pt
2023-08-01 17:14:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 20.24) (writing took 12.464194163680077 seconds)
2023-08-01 17:15:56 | INFO | train_inner | epoch 020:    107 / 1474 loss=1.999, trans_loss=5.023, nll_loss=2.224, w2v_ctc_loss=0.658, task_loss=1.352, contrastive_loss=0.08, total=4195.03, n_correct=2715.74, ppl=4.67, accuracy=64.737, wps=7995.1, ups=0.95, wpb=8390.1, bsz=313.7, num_updates=28100, lr=8.43649e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=68, gb_free=14.9, wall=23530
2023-08-01 17:16:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-01 17:17:05 | INFO | train_inner | epoch 020:    208 / 1474 loss=2.006, trans_loss=5.03, nll_loss=2.233, w2v_ctc_loss=0.659, task_loss=1.458, contrastive_loss=0.131, total=4153.77, n_correct=2684, ppl=4.7, accuracy=64.616, wps=12030.7, ups=1.45, wpb=8307.5, bsz=300.1, num_updates=28200, lr=8.42152e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=15.6, wall=23599
2023-08-01 17:18:13 | INFO | train_inner | epoch 020:    308 / 1474 loss=1.995, trans_loss=5.023, nll_loss=2.225, w2v_ctc_loss=0.657, task_loss=1.26, contrastive_loss=0.07, total=4191.34, n_correct=2715.51, ppl=4.67, accuracy=64.789, wps=12316.4, ups=1.47, wpb=8382.7, bsz=326.2, num_updates=28300, lr=8.40663e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=68, gb_free=15.7, wall=23667
2023-08-01 17:19:21 | INFO | train_inner | epoch 020:    408 / 1474 loss=2.006, trans_loss=5.032, nll_loss=2.236, w2v_ctc_loss=0.663, task_loss=1.417, contrastive_loss=0.069, total=4114.19, n_correct=2656.78, ppl=4.71, accuracy=64.576, wps=12014.3, ups=1.46, wpb=8228.4, bsz=297.5, num_updates=28400, lr=8.39181e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=68, gb_free=15.2, wall=23736
2023-08-01 17:20:30 | INFO | train_inner | epoch 020:    508 / 1474 loss=2.016, trans_loss=5.046, nll_loss=2.254, w2v_ctc_loss=0.663, task_loss=1.437, contrastive_loss=0.158, total=4108.2, n_correct=2642.58, ppl=4.77, accuracy=64.325, wps=12045.5, ups=1.47, wpb=8216.4, bsz=299.5, num_updates=28500, lr=8.37708e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=23804
2023-08-01 17:21:38 | INFO | train_inner | epoch 020:    608 / 1474 loss=2.023, trans_loss=5.048, nll_loss=2.257, w2v_ctc_loss=0.672, task_loss=1.47, contrastive_loss=0.162, total=4092.44, n_correct=2625.83, ppl=4.78, accuracy=64.163, wps=12049.3, ups=1.47, wpb=8184.9, bsz=295.9, num_updates=28600, lr=8.36242e-05, gnorm=0.555, clip=0, loss_scale=16, train_wall=67, gb_free=17.5, wall=23872
2023-08-01 17:22:45 | INFO | train_inner | epoch 020:    708 / 1474 loss=2.016, trans_loss=5.05, nll_loss=2.258, w2v_ctc_loss=0.678, task_loss=1.405, contrastive_loss=0.062, total=4137.06, n_correct=2654.92, ppl=4.78, accuracy=64.174, wps=12207.4, ups=1.48, wpb=8274.1, bsz=300.5, num_updates=28700, lr=8.34784e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=67, gb_free=16.5, wall=23940
2023-08-01 17:23:53 | INFO | train_inner | epoch 020:    808 / 1474 loss=2.008, trans_loss=5.044, nll_loss=2.252, w2v_ctc_loss=0.667, task_loss=1.383, contrastive_loss=0.065, total=4146.78, n_correct=2670.8, ppl=4.76, accuracy=64.407, wps=12197.7, ups=1.47, wpb=8293.6, bsz=307.3, num_updates=28800, lr=8.33333e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=68, gb_free=15.2, wall=24008
2023-08-01 17:25:02 | INFO | train_inner | epoch 020:    908 / 1474 loss=2.032, trans_loss=5.051, nll_loss=2.263, w2v_ctc_loss=0.665, task_loss=1.331, contrastive_loss=0.36, total=4161, n_correct=2669.52, ppl=4.8, accuracy=64.156, wps=12107.6, ups=1.45, wpb=8322, bsz=323.2, num_updates=28900, lr=8.3189e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=68, gb_free=17.4, wall=24076
2023-08-01 17:26:10 | INFO | train_inner | epoch 020:   1008 / 1474 loss=2.009, trans_loss=5.047, nll_loss=2.256, w2v_ctc_loss=0.661, task_loss=1.399, contrastive_loss=0.071, total=4168.14, n_correct=2680.03, ppl=4.78, accuracy=64.298, wps=12206.1, ups=1.46, wpb=8336.3, bsz=307.3, num_updates=29000, lr=8.30455e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=24145
2023-08-01 17:27:18 | INFO | train_inner | epoch 020:   1108 / 1474 loss=2.019, trans_loss=5.051, nll_loss=2.262, w2v_ctc_loss=0.66, task_loss=1.354, contrastive_loss=0.208, total=4166.49, n_correct=2675.52, ppl=4.8, accuracy=64.215, wps=12293.3, ups=1.48, wpb=8333, bsz=315.4, num_updates=29100, lr=8.29027e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=67, gb_free=14.7, wall=24212
2023-08-01 17:28:27 | INFO | train_inner | epoch 020:   1208 / 1474 loss=2.018, trans_loss=5.049, nll_loss=2.258, w2v_ctc_loss=0.68, task_loss=1.548, contrastive_loss=0.058, total=4029.18, n_correct=2586.82, ppl=4.78, accuracy=64.202, wps=11711.3, ups=1.45, wpb=8058.4, bsz=284, num_updates=29200, lr=8.27606e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=68, gb_free=11.7, wall=24281
2023-08-01 17:29:35 | INFO | train_inner | epoch 020:   1308 / 1474 loss=2.018, trans_loss=5.059, nll_loss=2.272, w2v_ctc_loss=0.673, task_loss=1.476, contrastive_loss=0.063, total=4123.21, n_correct=2643.35, ppl=4.83, accuracy=64.109, wps=12082, ups=1.47, wpb=8246.4, bsz=297.1, num_updates=29300, lr=8.26192e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=68, gb_free=17.4, wall=24350
2023-08-01 17:30:43 | INFO | train_inner | epoch 020:   1408 / 1474 loss=2.014, trans_loss=5.053, nll_loss=2.265, w2v_ctc_loss=0.668, task_loss=1.475, contrastive_loss=0.061, total=4116.28, n_correct=2641.06, ppl=4.81, accuracy=64.161, wps=12071.9, ups=1.47, wpb=8232.6, bsz=295, num_updates=29400, lr=8.24786e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=68, gb_free=17.5, wall=24418
2023-08-01 17:31:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 17:31:53 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.193 | trans_loss 5.559 | nll_loss 2.831 | w2v_ctc_loss 1.338 | task_loss 4.602 | contrastive_loss 0.254 | total 4003.4 | n_correct 2480.5 | ppl 7.11 | accuracy 61.96 | uer 17.44 | wer 19.123 | raw_wer 19.123 | bleu 20.31 | wps 1969.5 | wpb 4003.4 | bsz 141.8 | num_updates 29466 | best_bleu 20.34
2023-08-01 17:31:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29466 updates
2023-08-01 17:31:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.3104.pt
2023-08-01 17:31:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.3104.pt
2023-08-01 17:32:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.3104.pt (epoch 20 @ 29466 updates, score 20.31) (writing took 15.2030587811023 seconds)
2023-08-01 17:32:08 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-01 17:32:08 | INFO | train | epoch 020 | loss 2.013 | trans_loss 5.044 | nll_loss 2.252 | w2v_ctc_loss 0.666 | task_loss 1.401 | contrastive_loss 0.116 | total 4138.82 | n_correct 2663.25 | ppl 4.76 | accuracy 64.348 | wps 11190.1 | ups 1.35 | wpb 8277.6 | bsz 305.6 | num_updates 29466 | lr 8.23862e-05 | gnorm 0.532 | clip 0 | loss_scale 16 | train_wall 998 | gb_free 16.1 | wall 24503
2023-08-01 17:32:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 17:32:09 | INFO | fairseq.trainer | begin training epoch 21
2023-08-01 17:32:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 17:32:39 | INFO | train_inner | epoch 021:     34 / 1474 loss=2.016, trans_loss=5.048, nll_loss=2.258, w2v_ctc_loss=0.663, task_loss=1.333, contrastive_loss=0.185, total=4152.26, n_correct=2672.09, ppl=4.78, accuracy=64.353, wps=7187.6, ups=0.87, wpb=8304.5, bsz=316.3, num_updates=29500, lr=8.23387e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=67, gb_free=16.4, wall=24533
2023-08-01 17:33:48 | INFO | train_inner | epoch 021:    134 / 1474 loss=2.001, trans_loss=5.015, nll_loss=2.215, w2v_ctc_loss=0.655, task_loss=1.308, contrastive_loss=0.176, total=4195.08, n_correct=2719.27, ppl=4.64, accuracy=64.82, wps=12208.5, ups=1.46, wpb=8390.2, bsz=319.6, num_updates=29600, lr=8.21995e-05, gnorm=0.517, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=24602
2023-08-01 17:34:56 | INFO | train_inner | epoch 021:    234 / 1474 loss=1.993, trans_loss=5.018, nll_loss=2.218, w2v_ctc_loss=0.645, task_loss=1.334, contrastive_loss=0.128, total=4155.31, n_correct=2697.01, ppl=4.65, accuracy=64.905, wps=12238.1, ups=1.47, wpb=8310.6, bsz=312.6, num_updates=29700, lr=8.2061e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=67, gb_free=16.7, wall=24670
2023-08-01 17:36:04 | INFO | train_inner | epoch 021:    334 / 1474 loss=2.004, trans_loss=5.023, nll_loss=2.224, w2v_ctc_loss=0.664, task_loss=1.387, contrastive_loss=0.133, total=4151.51, n_correct=2688.57, ppl=4.67, accuracy=64.761, wps=12149.6, ups=1.46, wpb=8303, bsz=310.8, num_updates=29800, lr=8.19232e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=68, gb_free=15.5, wall=24738
2023-08-01 17:37:12 | INFO | train_inner | epoch 021:    434 / 1474 loss=1.993, trans_loss=5.023, nll_loss=2.224, w2v_ctc_loss=0.649, task_loss=1.358, contrastive_loss=0.057, total=4180.85, n_correct=2712.68, ppl=4.67, accuracy=64.883, wps=12346.1, ups=1.48, wpb=8361.7, bsz=306.8, num_updates=29900, lr=8.17861e-05, gnorm=0.515, clip=0, loss_scale=16, train_wall=67, gb_free=15.7, wall=24806
2023-08-01 17:38:20 | INFO | train_inner | epoch 021:    534 / 1474 loss=1.998, trans_loss=5.022, nll_loss=2.224, w2v_ctc_loss=0.66, task_loss=1.46, contrastive_loss=0.056, total=4083.98, n_correct=2644.04, ppl=4.67, accuracy=64.742, wps=11986.4, ups=1.47, wpb=8168, bsz=295.1, num_updates=30000, lr=8.16497e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=68, gb_free=12.9, wall=24874
2023-08-01 17:38:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 17:38:44 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.187 | trans_loss 5.564 | nll_loss 2.835 | w2v_ctc_loss 1.313 | task_loss 4.62 | contrastive_loss 0.242 | total 4003.4 | n_correct 2480.4 | ppl 7.13 | accuracy 61.957 | uer 17.551 | wer 19.332 | raw_wer 19.332 | bleu 20.02 | wps 2036.6 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.34
2023-08-01 17:38:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-08-01 17:38:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_21_30000.pt
2023-08-01 17:38:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_21_30000.pt
2023-08-01 17:39:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 20.02) (writing took 17.379861740395427 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:0')
2023-08-01 17:40:11 | INFO | train_inner | epoch 021:    634 / 1474 loss=2.008, trans_loss=5.027, nll_loss=2.231, w2v_ctc_loss=0.653, task_loss=1.388, contrastive_loss=0.229, total=4215.41, n_correct=2723.67, ppl=4.69, accuracy=64.612, wps=7572.5, ups=0.9, wpb=8430.8, bsz=315.4, num_updates=30100, lr=8.15139e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=68, gb_free=11.2, wall=24986
2023-08-01 17:41:20 | INFO | train_inner | epoch 021:    734 / 1474 loss=2.002, trans_loss=5.036, nll_loss=2.242, w2v_ctc_loss=0.655, task_loss=1.393, contrastive_loss=0.09, total=4152.97, n_correct=2686.39, ppl=4.73, accuracy=64.686, wps=12147.5, ups=1.46, wpb=8305.9, bsz=309.3, num_updates=30200, lr=8.13788e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=25054
2023-08-01 17:42:28 | INFO | train_inner | epoch 021:    834 / 1474 loss=2.009, trans_loss=5.041, nll_loss=2.248, w2v_ctc_loss=0.659, task_loss=1.479, contrastive_loss=0.101, total=4066.93, n_correct=2621.39, ppl=4.75, accuracy=64.456, wps=11871.1, ups=1.46, wpb=8133.9, bsz=294.4, num_updates=30300, lr=8.12444e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=25122
2023-08-01 17:43:36 | INFO | train_inner | epoch 021:    934 / 1474 loss=2.002, trans_loss=5.033, nll_loss=2.238, w2v_ctc_loss=0.66, task_loss=1.401, contrastive_loss=0.077, total=4103.34, n_correct=2648.25, ppl=4.72, accuracy=64.539, wps=12123.3, ups=1.48, wpb=8206.7, bsz=301, num_updates=30400, lr=8.11107e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=67, gb_free=13.9, wall=25190
2023-08-01 17:44:44 | INFO | train_inner | epoch 021:   1034 / 1474 loss=2.008, trans_loss=5.048, nll_loss=2.258, w2v_ctc_loss=0.661, task_loss=1.429, contrastive_loss=0.072, total=4099.86, n_correct=2639.23, ppl=4.78, accuracy=64.374, wps=12079.3, ups=1.47, wpb=8199.7, bsz=298.8, num_updates=30500, lr=8.09776e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=67, gb_free=11.2, wall=25258
2023-08-01 17:45:51 | INFO | train_inner | epoch 021:   1134 / 1474 loss=2.008, trans_loss=5.04, nll_loss=2.246, w2v_ctc_loss=0.661, task_loss=1.507, contrastive_loss=0.074, total=4120.75, n_correct=2655.18, ppl=4.74, accuracy=64.434, wps=12160.9, ups=1.48, wpb=8241.5, bsz=293.5, num_updates=30600, lr=8.08452e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=67, gb_free=15.8, wall=25326
2023-08-01 17:46:59 | INFO | train_inner | epoch 021:   1234 / 1474 loss=2.006, trans_loss=5.039, nll_loss=2.247, w2v_ctc_loss=0.657, task_loss=1.328, contrastive_loss=0.127, total=4154.73, n_correct=2674.62, ppl=4.75, accuracy=64.375, wps=12248.4, ups=1.47, wpb=8309.5, bsz=311.6, num_updates=30700, lr=8.07134e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=67, gb_free=12.5, wall=25394
2023-08-01 17:48:07 | INFO | train_inner | epoch 021:   1334 / 1474 loss=2.008, trans_loss=5.042, nll_loss=2.252, w2v_ctc_loss=0.664, task_loss=1.357, contrastive_loss=0.09, total=4147.17, n_correct=2669.11, ppl=4.76, accuracy=64.36, wps=12208.5, ups=1.47, wpb=8294.3, bsz=311.9, num_updates=30800, lr=8.05823e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=25462
2023-08-01 17:49:16 | INFO | train_inner | epoch 021:   1434 / 1474 loss=2.022, trans_loss=5.052, nll_loss=2.263, w2v_ctc_loss=0.676, task_loss=1.463, contrastive_loss=0.139, total=4133.93, n_correct=2653, ppl=4.8, accuracy=64.176, wps=11946.4, ups=1.44, wpb=8267.9, bsz=304.5, num_updates=30900, lr=8.04518e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=69, gb_free=15.5, wall=25531
2023-08-01 17:49:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:5')
2023-08-01 17:50:07 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.177 | trans_loss 5.558 | nll_loss 2.833 | w2v_ctc_loss 1.291 | task_loss 4.603 | contrastive_loss 0.245 | total 4003.4 | n_correct 2477.4 | ppl 7.12 | accuracy 61.882 | uer 17.41 | wer 19.194 | raw_wer 19.194 | bleu 19.99 | wps 2215.5 | wpb 4003.4 | bsz 141.8 | num_updates 30940 | best_bleu 20.34
2023-08-01 17:50:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30940 updates
2023-08-01 17:50:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_19.9906.pt
2023-08-01 17:50:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_19.9906.pt
2023-08-01 17:50:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_19.9906.pt (epoch 21 @ 30940 updates, score 19.99) (writing took 15.174666175618768 seconds)
2023-08-01 17:50:23 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-01 17:50:23 | INFO | train | epoch 021 | loss 2.005 | trans_loss 5.033 | nll_loss 2.238 | w2v_ctc_loss 0.658 | task_loss 1.401 | contrastive_loss 0.115 | total 4138.65 | n_correct 2672.91 | ppl 4.72 | accuracy 64.584 | wps 11145.9 | ups 1.35 | wpb 8277.3 | bsz 305.7 | num_updates 30940 | lr 8.03998e-05 | gnorm 0.527 | clip 0 | loss_scale 32 | train_wall 999 | gb_free 15.4 | wall 25597
2023-08-01 17:50:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 17:50:23 | INFO | fairseq.trainer | begin training epoch 22
2023-08-01 17:50:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 17:51:12 | INFO | train_inner | epoch 022:     60 / 1474 loss=1.996, trans_loss=5.02, nll_loss=2.221, w2v_ctc_loss=0.656, task_loss=1.421, contrastive_loss=0.055, total=4128.84, n_correct=2681.28, ppl=4.66, accuracy=64.94, wps=7142.5, ups=0.86, wpb=8257.7, bsz=297.7, num_updates=31000, lr=8.03219e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=69, gb_free=14.1, wall=25646
2023-08-01 17:52:21 | INFO | train_inner | epoch 022:    160 / 1474 loss=1.994, trans_loss=5.008, nll_loss=2.205, w2v_ctc_loss=0.653, task_loss=1.409, contrastive_loss=0.14, total=4123.35, n_correct=2682.5, ppl=4.61, accuracy=65.056, wps=11946.3, ups=1.45, wpb=8246.7, bsz=310.3, num_updates=31100, lr=8.01927e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=14.6, wall=25715
2023-08-01 17:53:30 | INFO | train_inner | epoch 022:    260 / 1474 loss=1.977, trans_loss=5.002, nll_loss=2.199, w2v_ctc_loss=0.632, task_loss=1.231, contrastive_loss=0.079, total=4267.16, n_correct=2787.45, ppl=4.59, accuracy=65.323, wps=12321.7, ups=1.44, wpb=8534.3, bsz=329.9, num_updates=31200, lr=8.00641e-05, gnorm=0.508, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=25785
2023-08-01 17:54:40 | INFO | train_inner | epoch 022:    360 / 1474 loss=2.007, trans_loss=5.02, nll_loss=2.221, w2v_ctc_loss=0.652, task_loss=1.419, contrastive_loss=0.241, total=4180.09, n_correct=2711.28, ppl=4.66, accuracy=64.862, wps=11936.8, ups=1.43, wpb=8360.2, bsz=310, num_updates=31300, lr=7.99361e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=70, gb_free=17.5, wall=25855
2023-08-01 17:55:50 | INFO | train_inner | epoch 022:    460 / 1474 loss=2.003, trans_loss=5.025, nll_loss=2.227, w2v_ctc_loss=0.655, task_loss=1.474, contrastive_loss=0.12, total=4132.62, n_correct=2676.34, ppl=4.68, accuracy=64.761, wps=11860.8, ups=1.44, wpb=8265.2, bsz=297.2, num_updates=31400, lr=7.98087e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=25924
2023-08-01 17:57:00 | INFO | train_inner | epoch 022:    560 / 1474 loss=1.992, trans_loss=5.016, nll_loss=2.215, w2v_ctc_loss=0.652, task_loss=1.407, contrastive_loss=0.068, total=4155.5, n_correct=2697.32, ppl=4.64, accuracy=64.91, wps=11906.9, ups=1.43, wpb=8311, bsz=307.3, num_updates=31500, lr=7.96819e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=25994
2023-08-01 17:58:08 | INFO | train_inner | epoch 022:    660 / 1474 loss=1.988, trans_loss=5.011, nll_loss=2.21, w2v_ctc_loss=0.638, task_loss=1.323, contrastive_loss=0.15, total=4147.84, n_correct=2701.14, ppl=4.63, accuracy=65.122, wps=12129.3, ups=1.46, wpb=8295.7, bsz=313.1, num_updates=31600, lr=7.95557e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=68, gb_free=12.9, wall=26063
2023-08-01 17:59:17 | INFO | train_inner | epoch 022:    760 / 1474 loss=1.995, trans_loss=5.019, nll_loss=2.22, w2v_ctc_loss=0.655, task_loss=1.432, contrastive_loss=0.07, total=4166.89, n_correct=2702.13, ppl=4.66, accuracy=64.848, wps=12137.9, ups=1.46, wpb=8333.8, bsz=304.3, num_updates=31700, lr=7.94301e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=26131
2023-08-01 18:00:25 | INFO | train_inner | epoch 022:    860 / 1474 loss=2.001, trans_loss=5.032, nll_loss=2.237, w2v_ctc_loss=0.656, task_loss=1.522, contrastive_loss=0.056, total=4074.75, n_correct=2630.17, ppl=4.71, accuracy=64.548, wps=11923.9, ups=1.46, wpb=8149.5, bsz=288.4, num_updates=31800, lr=7.93052e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=68, gb_free=17.5, wall=26200
2023-08-01 18:01:34 | INFO | train_inner | epoch 022:    960 / 1474 loss=1.994, trans_loss=5.026, nll_loss=2.229, w2v_ctc_loss=0.65, task_loss=1.406, contrastive_loss=0.057, total=4136.34, n_correct=2680.28, ppl=4.69, accuracy=64.798, wps=12081.5, ups=1.46, wpb=8272.7, bsz=303.7, num_updates=31900, lr=7.91808e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=26268
2023-08-01 18:02:41 | INFO | train_inner | epoch 022:   1060 / 1474 loss=1.997, trans_loss=5.02, nll_loss=2.222, w2v_ctc_loss=0.64, task_loss=1.335, contrastive_loss=0.228, total=4157.21, n_correct=2699.88, ppl=4.67, accuracy=64.945, wps=12315.4, ups=1.48, wpb=8314.4, bsz=315.4, num_updates=32000, lr=7.90569e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=67, gb_free=11.9, wall=26336
2023-08-01 18:02:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 18:03:07 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.173 | trans_loss 5.551 | nll_loss 2.823 | w2v_ctc_loss 1.295 | task_loss 4.635 | contrastive_loss 0.244 | total 4003.4 | n_correct 2483.6 | ppl 7.08 | accuracy 62.037 | uer 17.296 | wer 19.123 | raw_wer 19.123 | bleu 19.93 | wps 1875.2 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.34
2023-08-01 18:03:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-08-01 18:03:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_22_32000.pt
2023-08-01 18:03:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_22_32000.pt
2023-08-01 18:03:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 19.93) (writing took 13.005909722298384 seconds)
2023-08-01 18:04:29 | INFO | train_inner | epoch 022:   1160 / 1474 loss=2.014, trans_loss=5.048, nll_loss=2.258, w2v_ctc_loss=0.666, task_loss=1.459, contrastive_loss=0.108, total=4092.91, n_correct=2633.19, ppl=4.78, accuracy=64.335, wps=7583, ups=0.93, wpb=8185.8, bsz=294.3, num_updates=32100, lr=7.89337e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=26444
2023-08-01 18:05:37 | INFO | train_inner | epoch 022:   1260 / 1474 loss=2.002, trans_loss=5.039, nll_loss=2.248, w2v_ctc_loss=0.653, task_loss=1.297, contrastive_loss=0.105, total=4182.65, n_correct=2697.8, ppl=4.75, accuracy=64.5, wps=12295.6, ups=1.47, wpb=8365.3, bsz=323.6, num_updates=32200, lr=7.8811e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=26512
2023-08-01 18:06:45 | INFO | train_inner | epoch 022:   1360 / 1474 loss=1.994, trans_loss=5.027, nll_loss=2.231, w2v_ctc_loss=0.641, task_loss=1.392, contrastive_loss=0.125, total=4071.58, n_correct=2640.9, ppl=4.69, accuracy=64.862, wps=12002.6, ups=1.47, wpb=8143.2, bsz=300.6, num_updates=32300, lr=7.86889e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=67, gb_free=16.6, wall=26579
2023-08-01 18:07:53 | INFO | train_inner | epoch 022:   1460 / 1474 loss=2.009, trans_loss=5.046, nll_loss=2.255, w2v_ctc_loss=0.666, task_loss=1.498, contrastive_loss=0.071, total=4077.83, n_correct=2626.18, ppl=4.77, accuracy=64.401, wps=12016.2, ups=1.47, wpb=8155.7, bsz=288, num_updates=32400, lr=7.85674e-05, gnorm=0.531, clip=0, loss_scale=64, train_wall=67, gb_free=16.1, wall=26647
2023-08-01 18:08:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 18:08:25 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.185 | trans_loss 5.55 | nll_loss 2.821 | w2v_ctc_loss 1.339 | task_loss 4.593 | contrastive_loss 0.245 | total 4003.4 | n_correct 2494 | ppl 7.06 | accuracy 62.297 | uer 17.471 | wer 19.268 | raw_wer 19.268 | bleu 20.29 | wps 2253.5 | wpb 4003.4 | bsz 141.8 | num_updates 32414 | best_bleu 20.34
2023-08-01 18:08:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32414 updates
2023-08-01 18:08:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.2903.pt
2023-08-01 18:08:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.2903.pt
2023-08-01 18:08:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.2903.pt (epoch 22 @ 32414 updates, score 20.29) (writing took 12.308546235784888 seconds)
2023-08-01 18:08:38 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-01 18:08:38 | INFO | train | epoch 022 | loss 1.997 | trans_loss 5.023 | nll_loss 2.226 | w2v_ctc_loss 0.651 | task_loss 1.4 | contrastive_loss 0.114 | total 4138.65 | n_correct 2682.67 | ppl 4.68 | accuracy 64.82 | wps 11140.2 | ups 1.35 | wpb 8277.3 | bsz 305.7 | num_updates 32414 | lr 7.85505e-05 | gnorm 0.529 | clip 0 | loss_scale 64 | train_wall 1005 | gb_free 11.6 | wall 26692
2023-08-01 18:08:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 18:08:38 | INFO | fairseq.trainer | begin training epoch 23
2023-08-01 18:08:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 18:08:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-01 18:09:45 | INFO | train_inner | epoch 023:     87 / 1474 loss=1.986, trans_loss=5.001, nll_loss=2.197, w2v_ctc_loss=0.652, task_loss=1.441, contrastive_loss=0.063, total=4095.91, n_correct=2672.06, ppl=4.58, accuracy=65.237, wps=7339.8, ups=0.9, wpb=8191.8, bsz=300, num_updates=32500, lr=7.84465e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=26759
2023-08-01 18:10:53 | INFO | train_inner | epoch 023:    187 / 1474 loss=1.982, trans_loss=4.997, nll_loss=2.191, w2v_ctc_loss=0.641, task_loss=1.49, contrastive_loss=0.061, total=4107.77, n_correct=2686.27, ppl=4.57, accuracy=65.395, wps=11937.6, ups=1.45, wpb=8215.5, bsz=293.4, num_updates=32600, lr=7.8326e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=26828
2023-08-01 18:12:03 | INFO | train_inner | epoch 023:    287 / 1474 loss=1.987, trans_loss=5.006, nll_loss=2.204, w2v_ctc_loss=0.635, task_loss=1.405, contrastive_loss=0.14, total=4153.12, n_correct=2707.44, ppl=4.61, accuracy=65.191, wps=12029, ups=1.45, wpb=8306.2, bsz=306.4, num_updates=32700, lr=7.82062e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=26897
2023-08-01 18:13:11 | INFO | train_inner | epoch 023:    387 / 1474 loss=1.983, trans_loss=5.005, nll_loss=2.201, w2v_ctc_loss=0.641, task_loss=1.453, contrastive_loss=0.052, total=4116.7, n_correct=2688.95, ppl=4.6, accuracy=65.318, wps=12104.5, ups=1.47, wpb=8233.4, bsz=294, num_updates=32800, lr=7.80869e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=67, gb_free=15.2, wall=26965
2023-08-01 18:14:18 | INFO | train_inner | epoch 023:    487 / 1474 loss=1.988, trans_loss=5.008, nll_loss=2.206, w2v_ctc_loss=0.643, task_loss=1.358, contrastive_loss=0.11, total=4157.6, n_correct=2707.04, ppl=4.61, accuracy=65.111, wps=12274.2, ups=1.48, wpb=8315.2, bsz=313.5, num_updates=32900, lr=7.79681e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=67, gb_free=17.3, wall=27033
2023-08-01 18:15:26 | INFO | train_inner | epoch 023:    587 / 1474 loss=1.976, trans_loss=5, nll_loss=2.195, w2v_ctc_loss=0.636, task_loss=1.325, contrastive_loss=0.058, total=4173.42, n_correct=2729.53, ppl=4.58, accuracy=65.403, wps=12293.5, ups=1.47, wpb=8346.8, bsz=316, num_updates=33000, lr=7.78499e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=67, gb_free=12.5, wall=27101
2023-08-01 18:16:34 | INFO | train_inner | epoch 023:    687 / 1474 loss=1.986, trans_loss=5.007, nll_loss=2.205, w2v_ctc_loss=0.641, task_loss=1.403, contrastive_loss=0.097, total=4137.82, n_correct=2695.61, ppl=4.61, accuracy=65.146, wps=12170, ups=1.47, wpb=8275.6, bsz=302.5, num_updates=33100, lr=7.77322e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=68, gb_free=17.1, wall=27169
2023-08-01 18:17:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-01 18:17:42 | INFO | train_inner | epoch 023:    788 / 1474 loss=1.993, trans_loss=5.019, nll_loss=2.22, w2v_ctc_loss=0.65, task_loss=1.421, contrastive_loss=0.078, total=4148.48, n_correct=2696.63, ppl=4.66, accuracy=65.003, wps=12209.9, ups=1.47, wpb=8297, bsz=304.6, num_updates=33200, lr=7.76151e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=67, gb_free=16.9, wall=27236
2023-08-01 18:18:50 | INFO | train_inner | epoch 023:    888 / 1474 loss=1.989, trans_loss=5.011, nll_loss=2.211, w2v_ctc_loss=0.642, task_loss=1.28, contrastive_loss=0.158, total=4182.69, n_correct=2722.86, ppl=4.63, accuracy=65.098, wps=12360, ups=1.48, wpb=8365.4, bsz=325, num_updates=33300, lr=7.74984e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=67, gb_free=16.8, wall=27304
2023-08-01 18:19:58 | INFO | train_inner | epoch 023:    988 / 1474 loss=2.002, trans_loss=5.017, nll_loss=2.218, w2v_ctc_loss=0.64, task_loss=1.405, contrastive_loss=0.31, total=4165.01, n_correct=2702.41, ppl=4.65, accuracy=64.884, wps=12305, ups=1.48, wpb=8330, bsz=309.6, num_updates=33400, lr=7.73823e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=67, gb_free=17.7, wall=27372
2023-08-01 18:21:06 | INFO | train_inner | epoch 023:   1088 / 1474 loss=1.996, trans_loss=5.023, nll_loss=2.225, w2v_ctc_loss=0.654, task_loss=1.487, contrastive_loss=0.065, total=4092.37, n_correct=2655.32, ppl=4.68, accuracy=64.885, wps=11926, ups=1.46, wpb=8184.7, bsz=290.8, num_updates=33500, lr=7.72667e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=68, gb_free=17.3, wall=27440
2023-08-01 18:22:14 | INFO | train_inner | epoch 023:   1188 / 1474 loss=1.991, trans_loss=5.024, nll_loss=2.228, w2v_ctc_loss=0.649, task_loss=1.393, contrastive_loss=0.056, total=4164.9, n_correct=2703.5, ppl=4.68, accuracy=64.912, wps=12229.1, ups=1.47, wpb=8329.8, bsz=309.2, num_updates=33600, lr=7.71517e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=68, gb_free=13.6, wall=27509
2023-08-01 18:23:22 | INFO | train_inner | epoch 023:   1288 / 1474 loss=1.986, trans_loss=5.02, nll_loss=2.223, w2v_ctc_loss=0.639, task_loss=1.36, contrastive_loss=0.07, total=4136.96, n_correct=2687.48, ppl=4.67, accuracy=64.963, wps=12253, ups=1.48, wpb=8273.9, bsz=309.8, num_updates=33700, lr=7.70371e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=67, gb_free=16.6, wall=27576
2023-08-01 18:24:30 | INFO | train_inner | epoch 023:   1388 / 1474 loss=2.004, trans_loss=5.042, nll_loss=2.251, w2v_ctc_loss=0.651, task_loss=1.414, contrastive_loss=0.127, total=4142.84, n_correct=2675.79, ppl=4.76, accuracy=64.588, wps=12207.9, ups=1.47, wpb=8285.7, bsz=304.8, num_updates=33800, lr=7.69231e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=67, gb_free=16.1, wall=27644
2023-08-01 18:25:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 18:25:52 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.183 | trans_loss 5.551 | nll_loss 2.822 | w2v_ctc_loss 1.33 | task_loss 4.614 | contrastive_loss 0.243 | total 4003.4 | n_correct 2483 | ppl 7.07 | accuracy 62.022 | uer 17.063 | wer 18.873 | raw_wer 18.873 | bleu 20.26 | wps 2152.3 | wpb 4003.4 | bsz 141.8 | num_updates 33886 | best_bleu 20.34
2023-08-01 18:25:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33886 updates
2023-08-01 18:25:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.2602.pt
2023-08-01 18:25:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.2602.pt
2023-08-01 18:26:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.2602.pt (epoch 23 @ 33886 updates, score 20.26) (writing took 12.349109785631299 seconds)
2023-08-01 18:26:05 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-01 18:26:05 | INFO | train | epoch 023 | loss 1.99 | trans_loss 5.014 | nll_loss 2.214 | w2v_ctc_loss 0.644 | task_loss 1.401 | contrastive_loss 0.112 | total 4138.65 | n_correct 2692.34 | ppl 4.64 | accuracy 65.054 | wps 11635.2 | ups 1.41 | wpb 8277.3 | bsz 305.6 | num_updates 33886 | lr 7.68254e-05 | gnorm 0.536 | clip 0 | loss_scale 16 | train_wall 996 | gb_free 13.6 | wall 27740
2023-08-01 18:26:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 18:26:06 | INFO | fairseq.trainer | begin training epoch 24
2023-08-01 18:26:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 18:26:23 | INFO | train_inner | epoch 024:     14 / 1474 loss=2.006, trans_loss=5.032, nll_loss=2.239, w2v_ctc_loss=0.646, task_loss=1.415, contrastive_loss=0.205, total=4084.21, n_correct=2641.91, ppl=4.72, accuracy=64.686, wps=7193.3, ups=0.88, wpb=8168.4, bsz=303.7, num_updates=33900, lr=7.68095e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=68, gb_free=15.3, wall=27758
2023-08-01 18:27:31 | INFO | train_inner | epoch 024:    114 / 1474 loss=1.979, trans_loss=4.985, nll_loss=2.176, w2v_ctc_loss=0.628, task_loss=1.293, contrastive_loss=0.222, total=4168.61, n_correct=2736.39, ppl=4.52, accuracy=65.643, wps=12259, ups=1.47, wpb=8337.2, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=68, gb_free=11.3, wall=27826
2023-08-01 18:27:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 18:27:56 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.19 | trans_loss 5.556 | nll_loss 2.826 | w2v_ctc_loss 1.338 | task_loss 4.621 | contrastive_loss 0.246 | total 4003.4 | n_correct 2483.1 | ppl 7.09 | accuracy 62.025 | uer 17.049 | wer 18.817 | raw_wer 18.817 | bleu 20.26 | wps 1969.6 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.34
2023-08-01 18:27:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-08-01 18:27:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_24_34000.pt
2023-08-01 18:27:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_24_34000.pt
2023-08-01 18:28:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 20.26) (writing took 16.880452012643218 seconds)
2023-08-01 18:29:22 | INFO | train_inner | epoch 024:    214 / 1474 loss=1.981, trans_loss=4.989, nll_loss=2.183, w2v_ctc_loss=0.622, task_loss=1.222, contrastive_loss=0.28, total=4252.53, n_correct=2783.53, ppl=4.54, accuracy=65.456, wps=7662.9, ups=0.9, wpb=8505.1, bsz=341.3, num_updates=34100, lr=7.6584e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=27937
2023-08-01 18:30:30 | INFO | train_inner | epoch 024:    314 / 1474 loss=1.972, trans_loss=4.992, nll_loss=2.184, w2v_ctc_loss=0.633, task_loss=1.363, contrastive_loss=0.053, total=4138.44, n_correct=2713.65, ppl=4.54, accuracy=65.572, wps=12234.1, ups=1.48, wpb=8276.9, bsz=307.1, num_updates=34200, lr=7.64719e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=67, gb_free=15.5, wall=28004
2023-08-01 18:31:39 | INFO | train_inner | epoch 024:    414 / 1474 loss=1.997, trans_loss=5, nll_loss=2.196, w2v_ctc_loss=0.646, task_loss=1.477, contrastive_loss=0.203, total=4153.83, n_correct=2707.59, ppl=4.58, accuracy=65.183, wps=12099.1, ups=1.46, wpb=8307.7, bsz=298.4, num_updates=34300, lr=7.63604e-05, gnorm=0.553, clip=0, loss_scale=16, train_wall=68, gb_free=16.1, wall=28073
2023-08-01 18:32:47 | INFO | train_inner | epoch 024:    514 / 1474 loss=1.983, trans_loss=4.999, nll_loss=2.194, w2v_ctc_loss=0.637, task_loss=1.426, contrastive_loss=0.123, total=4141.88, n_correct=2705.14, ppl=4.58, accuracy=65.312, wps=12171.7, ups=1.47, wpb=8283.8, bsz=302.6, num_updates=34400, lr=7.62493e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=68, gb_free=15.1, wall=28141
2023-08-01 18:33:54 | INFO | train_inner | epoch 024:    614 / 1474 loss=1.98, trans_loss=5, nll_loss=2.196, w2v_ctc_loss=0.634, task_loss=1.406, contrastive_loss=0.089, total=4162.06, n_correct=2719.97, ppl=4.58, accuracy=65.352, wps=12290, ups=1.48, wpb=8324.1, bsz=308.1, num_updates=34500, lr=7.61387e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=67, gb_free=16.8, wall=28209
2023-08-01 18:35:03 | INFO | train_inner | epoch 024:    714 / 1474 loss=1.988, trans_loss=5.011, nll_loss=2.21, w2v_ctc_loss=0.641, task_loss=1.45, contrastive_loss=0.098, total=4097.35, n_correct=2673.24, ppl=4.63, accuracy=65.243, wps=12032.2, ups=1.47, wpb=8194.7, bsz=293.8, num_updates=34600, lr=7.60286e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=68, gb_free=17.2, wall=28277
2023-08-01 18:36:11 | INFO | train_inner | epoch 024:    814 / 1474 loss=1.983, trans_loss=5.012, nll_loss=2.212, w2v_ctc_loss=0.637, task_loss=1.398, contrastive_loss=0.077, total=4124.25, n_correct=2685.88, ppl=4.63, accuracy=65.124, wps=12047.9, ups=1.46, wpb=8248.5, bsz=308.2, num_updates=34700, lr=7.5919e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=68, gb_free=16, wall=28345
2023-08-01 18:37:18 | INFO | train_inner | epoch 024:    914 / 1474 loss=1.994, trans_loss=5.02, nll_loss=2.22, w2v_ctc_loss=0.65, task_loss=1.563, contrastive_loss=0.05, total=4041.44, n_correct=2621.24, ppl=4.66, accuracy=64.859, wps=11984.6, ups=1.48, wpb=8082.9, bsz=280.5, num_updates=34800, lr=7.58098e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=67, gb_free=16.1, wall=28413
2023-08-01 18:38:26 | INFO | train_inner | epoch 024:   1014 / 1474 loss=1.984, trans_loss=5.014, nll_loss=2.214, w2v_ctc_loss=0.639, task_loss=1.46, contrastive_loss=0.053, total=4128.8, n_correct=2690.36, ppl=4.64, accuracy=65.161, wps=12180, ups=1.48, wpb=8257.6, bsz=296.5, num_updates=34900, lr=7.57011e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=67, gb_free=15, wall=28481
2023-08-01 18:39:34 | INFO | train_inner | epoch 024:   1114 / 1474 loss=1.983, trans_loss=5.002, nll_loss=2.199, w2v_ctc_loss=0.642, task_loss=1.349, contrastive_loss=0.098, total=4130.49, n_correct=2694.08, ppl=4.59, accuracy=65.224, wps=12139.4, ups=1.47, wpb=8261, bsz=308.9, num_updates=35000, lr=7.55929e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=68, gb_free=16, wall=28549
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:0')
2023-08-01 18:40:43 | INFO | train_inner | epoch 024:   1214 / 1474 loss=1.982, trans_loss=5.011, nll_loss=2.211, w2v_ctc_loss=0.634, task_loss=1.388, contrastive_loss=0.089, total=4157.47, n_correct=2710.28, ppl=4.63, accuracy=65.191, wps=12115.8, ups=1.46, wpb=8314.9, bsz=311.2, num_updates=35100, lr=7.54851e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=68, gb_free=12.6, wall=28617
2023-08-01 18:41:51 | INFO | train_inner | epoch 024:   1314 / 1474 loss=1.994, trans_loss=5.02, nll_loss=2.223, w2v_ctc_loss=0.656, task_loss=1.488, contrastive_loss=0.06, total=4107.23, n_correct=2667.4, ppl=4.67, accuracy=64.944, wps=11997, ups=1.46, wpb=8214.5, bsz=294.3, num_updates=35200, lr=7.53778e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=68, gb_free=17.5, wall=28686
2023-08-01 18:42:59 | INFO | train_inner | epoch 024:   1414 / 1474 loss=1.991, trans_loss=5.023, nll_loss=2.226, w2v_ctc_loss=0.648, task_loss=1.466, contrastive_loss=0.058, total=4094.39, n_correct=2658.76, ppl=4.68, accuracy=64.937, wps=12118.8, ups=1.48, wpb=8188.8, bsz=292.9, num_updates=35300, lr=7.5271e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=28753
2023-08-01 18:43:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:1')
2023-08-01 18:44:04 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.177 | trans_loss 5.546 | nll_loss 2.813 | w2v_ctc_loss 1.32 | task_loss 4.633 | contrastive_loss 0.243 | total 4003.4 | n_correct 2495.4 | ppl 7.03 | accuracy 62.332 | uer 16.925 | wer 18.862 | raw_wer 18.862 | bleu 20.16 | wps 2149 | wpb 4003.4 | bsz 141.8 | num_updates 35360 | best_bleu 20.34
2023-08-01 18:44:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35360 updates
2023-08-01 18:44:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.1600.pt
2023-08-01 18:44:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.1600.pt
2023-08-01 18:44:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.1600.pt (epoch 24 @ 35360 updates, score 20.16) (writing took 15.715896030887961 seconds)
2023-08-01 18:44:20 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-01 18:44:20 | INFO | train | epoch 024 | loss 1.984 | trans_loss 5.005 | nll_loss 2.203 | w2v_ctc_loss 0.639 | task_loss 1.401 | contrastive_loss 0.111 | total 4138.65 | n_correct 2699.87 | ppl 4.6 | accuracy 65.236 | wps 11149.7 | ups 1.35 | wpb 8277.3 | bsz 305.7 | num_updates 35360 | lr 7.52071e-05 | gnorm 0.536 | clip 0 | loss_scale 32 | train_wall 997 | gb_free 16.1 | wall 28834
2023-08-01 18:44:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 18:44:20 | INFO | fairseq.trainer | begin training epoch 25
2023-08-01 18:44:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 18:44:55 | INFO | train_inner | epoch 025:     40 / 1474 loss=1.972, trans_loss=4.994, nll_loss=2.19, w2v_ctc_loss=0.632, task_loss=1.35, contrastive_loss=0.065, total=4165.57, n_correct=2732.42, ppl=4.56, accuracy=65.595, wps=7172.9, ups=0.86, wpb=8331.1, bsz=311.2, num_updates=35400, lr=7.51646e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=13, wall=28869
2023-08-01 18:46:03 | INFO | train_inner | epoch 025:    140 / 1474 loss=1.961, trans_loss=4.974, nll_loss=2.162, w2v_ctc_loss=0.62, task_loss=1.358, contrastive_loss=0.063, total=4135.43, n_correct=2724.07, ppl=4.48, accuracy=65.872, wps=12199.9, ups=1.48, wpb=8270.9, bsz=308.9, num_updates=35500, lr=7.50587e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=67, gb_free=17.7, wall=28937
2023-08-01 18:47:11 | INFO | train_inner | epoch 025:    240 / 1474 loss=1.972, trans_loss=4.985, nll_loss=2.177, w2v_ctc_loss=0.635, task_loss=1.438, contrastive_loss=0.068, total=4116.13, n_correct=2702.05, ppl=4.52, accuracy=65.645, wps=12024.1, ups=1.46, wpb=8232.3, bsz=303, num_updates=35600, lr=7.49532e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=29006
2023-08-01 18:48:20 | INFO | train_inner | epoch 025:    340 / 1474 loss=1.978, trans_loss=4.99, nll_loss=2.181, w2v_ctc_loss=0.634, task_loss=1.495, contrastive_loss=0.096, total=4141.49, n_correct=2707.02, ppl=4.53, accuracy=65.363, wps=12022.6, ups=1.45, wpb=8283, bsz=294.2, num_updates=35700, lr=7.48481e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=68, gb_free=15.1, wall=29075
2023-08-01 18:49:29 | INFO | train_inner | epoch 025:    440 / 1474 loss=1.99, trans_loss=4.993, nll_loss=2.186, w2v_ctc_loss=0.645, task_loss=1.463, contrastive_loss=0.173, total=4167.4, n_correct=2725.87, ppl=4.55, accuracy=65.409, wps=12193.1, ups=1.46, wpb=8334.8, bsz=297.7, num_updates=35800, lr=7.47435e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=29143
2023-08-01 18:50:37 | INFO | train_inner | epoch 025:    540 / 1474 loss=1.974, trans_loss=4.998, nll_loss=2.193, w2v_ctc_loss=0.633, task_loss=1.368, contrastive_loss=0.067, total=4160.61, n_correct=2725.01, ppl=4.57, accuracy=65.495, wps=12252.7, ups=1.47, wpb=8321.2, bsz=313.9, num_updates=35900, lr=7.46393e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=67, gb_free=17.5, wall=29211
2023-08-01 18:51:44 | INFO | train_inner | epoch 025:    640 / 1474 loss=1.979, trans_loss=4.991, nll_loss=2.185, w2v_ctc_loss=0.638, task_loss=1.386, contrastive_loss=0.135, total=4153.68, n_correct=2720.82, ppl=4.55, accuracy=65.504, wps=12250.6, ups=1.47, wpb=8307.4, bsz=309.6, num_updates=36000, lr=7.45356e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=67, gb_free=16.4, wall=29279
2023-08-01 18:51:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 18:52:07 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.182 | trans_loss 5.55 | nll_loss 2.819 | w2v_ctc_loss 1.327 | task_loss 4.597 | contrastive_loss 0.241 | total 4003.4 | n_correct 2490.2 | ppl 7.06 | accuracy 62.202 | uer 17.079 | wer 18.855 | raw_wer 18.855 | bleu 20.11 | wps 2240.8 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.34
2023-08-01 18:52:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-08-01 18:52:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_25_36000.pt
2023-08-01 18:52:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_25_36000.pt
2023-08-01 18:52:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 20.11) (writing took 12.828248005360365 seconds)
2023-08-01 18:53:29 | INFO | train_inner | epoch 025:    740 / 1474 loss=1.983, trans_loss=4.995, nll_loss=2.189, w2v_ctc_loss=0.638, task_loss=1.419, contrastive_loss=0.13, total=4128.34, n_correct=2703.34, ppl=4.56, accuracy=65.482, wps=7911.7, ups=0.96, wpb=8256.7, bsz=301.3, num_updates=36100, lr=7.44323e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=67, gb_free=17, wall=29383
2023-08-01 18:54:37 | INFO | train_inner | epoch 025:    840 / 1474 loss=1.973, trans_loss=4.999, nll_loss=2.196, w2v_ctc_loss=0.631, task_loss=1.292, contrastive_loss=0.076, total=4182.4, n_correct=2739.15, ppl=4.58, accuracy=65.492, wps=12283, ups=1.47, wpb=8364.8, bsz=326, num_updates=36200, lr=7.43294e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=68, gb_free=17.7, wall=29451
2023-08-01 18:55:45 | INFO | train_inner | epoch 025:    940 / 1474 loss=1.982, trans_loss=5.003, nll_loss=2.202, w2v_ctc_loss=0.639, task_loss=1.33, contrastive_loss=0.134, total=4155.21, n_correct=2715.02, ppl=4.6, accuracy=65.34, wps=12208.9, ups=1.47, wpb=8310.4, bsz=317, num_updates=36300, lr=7.4227e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=14, wall=29519
2023-08-01 18:56:53 | INFO | train_inner | epoch 025:   1040 / 1474 loss=1.989, trans_loss=5.01, nll_loss=2.209, w2v_ctc_loss=0.627, task_loss=1.389, contrastive_loss=0.244, total=4177.7, n_correct=2722.59, ppl=4.62, accuracy=65.17, wps=12238.2, ups=1.46, wpb=8355.4, bsz=309.8, num_updates=36400, lr=7.41249e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=29587
2023-08-01 18:58:01 | INFO | train_inner | epoch 025:   1140 / 1474 loss=1.978, trans_loss=5.006, nll_loss=2.203, w2v_ctc_loss=0.631, task_loss=1.513, contrastive_loss=0.048, total=4039.24, n_correct=2640.15, ppl=4.61, accuracy=65.363, wps=11919.8, ups=1.48, wpb=8078.5, bsz=285.2, num_updates=36500, lr=7.40233e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=67, gb_free=16.4, wall=29655
2023-08-01 18:59:08 | INFO | train_inner | epoch 025:   1240 / 1474 loss=1.977, trans_loss=5.007, nll_loss=2.206, w2v_ctc_loss=0.63, task_loss=1.417, contrastive_loss=0.058, total=4090.59, n_correct=2671.28, ppl=4.61, accuracy=65.303, wps=12155, ups=1.49, wpb=8181.2, bsz=295.7, num_updates=36600, lr=7.39221e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=67, gb_free=17.2, wall=29723
2023-08-01 19:00:16 | INFO | train_inner | epoch 025:   1340 / 1474 loss=1.983, trans_loss=5.002, nll_loss=2.2, w2v_ctc_loss=0.636, task_loss=1.362, contrastive_loss=0.152, total=4164.34, n_correct=2723.37, ppl=4.6, accuracy=65.397, wps=12257.3, ups=1.47, wpb=8328.7, bsz=310.1, num_updates=36700, lr=7.38213e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=67, gb_free=16.8, wall=29791
2023-08-01 19:01:25 | INFO | train_inner | epoch 025:   1440 / 1474 loss=1.99, trans_loss=5.021, nll_loss=2.224, w2v_ctc_loss=0.64, task_loss=1.459, contrastive_loss=0.102, total=4099.11, n_correct=2661.63, ppl=4.67, accuracy=64.932, wps=11896.9, ups=1.45, wpb=8198.2, bsz=299.3, num_updates=36800, lr=7.3721e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=68, gb_free=12.1, wall=29859
2023-08-01 19:01:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 19:02:12 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.164 | trans_loss 5.538 | nll_loss 2.807 | w2v_ctc_loss 1.295 | task_loss 4.64 | contrastive_loss 0.246 | total 4003.4 | n_correct 2494.3 | ppl 7 | accuracy 62.305 | uer 16.861 | wer 18.802 | raw_wer 18.802 | bleu 20.26 | wps 2173.1 | wpb 4003.4 | bsz 141.8 | num_updates 36834 | best_bleu 20.34
2023-08-01 19:02:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36834 updates
2023-08-01 19:02:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.2601.pt
2023-08-01 19:02:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.2601.pt
2023-08-01 19:02:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.2601.pt (epoch 25 @ 36834 updates, score 20.26) (writing took 12.282491784542799 seconds)
2023-08-01 19:02:25 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-01 19:02:25 | INFO | train | epoch 025 | loss 1.979 | trans_loss 4.998 | nll_loss 2.194 | w2v_ctc_loss 0.634 | task_loss 1.4 | contrastive_loss 0.109 | total 4138.65 | n_correct 2707.47 | ppl 4.57 | accuracy 65.419 | wps 11245.1 | ups 1.36 | wpb 8277.3 | bsz 305.7 | num_updates 36834 | lr 7.36869e-05 | gnorm 0.536 | clip 0 | loss_scale 32 | train_wall 998 | gb_free 14.2 | wall 29919
2023-08-01 19:02:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 19:02:25 | INFO | fairseq.trainer | begin training epoch 26
2023-08-01 19:02:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 19:03:18 | INFO | train_inner | epoch 026:     66 / 1474 loss=1.966, trans_loss=4.978, nll_loss=2.168, w2v_ctc_loss=0.626, task_loss=1.314, contrastive_loss=0.089, total=4180.21, n_correct=2754.12, ppl=4.5, accuracy=65.885, wps=7413.9, ups=0.89, wpb=8360.4, bsz=318.3, num_updates=36900, lr=7.3621e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=29972
2023-08-01 19:04:26 | INFO | train_inner | epoch 026:    166 / 1474 loss=1.969, trans_loss=4.972, nll_loss=2.161, w2v_ctc_loss=0.613, task_loss=1.23, contrastive_loss=0.274, total=4270.78, n_correct=2819.38, ppl=4.47, accuracy=66.016, wps=12463.1, ups=1.46, wpb=8541.6, bsz=340.4, num_updates=37000, lr=7.35215e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=68, gb_free=15.2, wall=30041
2023-08-01 19:05:35 | INFO | train_inner | epoch 026:    266 / 1474 loss=1.974, trans_loss=4.977, nll_loss=2.167, w2v_ctc_loss=0.634, task_loss=1.389, contrastive_loss=0.146, total=4125.04, n_correct=2711.76, ppl=4.49, accuracy=65.739, wps=12105.1, ups=1.47, wpb=8250.1, bsz=307.1, num_updates=37100, lr=7.34223e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=68, gb_free=15.1, wall=30109
2023-08-01 19:06:43 | INFO | train_inner | epoch 026:    366 / 1474 loss=1.967, trans_loss=4.977, nll_loss=2.167, w2v_ctc_loss=0.628, task_loss=1.34, contrastive_loss=0.107, total=4165.74, n_correct=2743.71, ppl=4.49, accuracy=65.864, wps=12239.8, ups=1.47, wpb=8331.5, bsz=314.7, num_updates=37200, lr=7.33236e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=30177
2023-08-01 19:07:51 | INFO | train_inner | epoch 026:    466 / 1474 loss=1.97, trans_loss=4.975, nll_loss=2.164, w2v_ctc_loss=0.627, task_loss=1.33, contrastive_loss=0.151, total=4170.23, n_correct=2744.45, ppl=4.48, accuracy=65.811, wps=12304.7, ups=1.48, wpb=8340.5, bsz=315.4, num_updates=37300, lr=7.32252e-05, gnorm=0.531, clip=0, loss_scale=64, train_wall=67, gb_free=17.8, wall=30245
2023-08-01 19:08:59 | INFO | train_inner | epoch 026:    566 / 1474 loss=1.974, trans_loss=4.989, nll_loss=2.182, w2v_ctc_loss=0.639, task_loss=1.413, contrastive_loss=0.071, total=4155.02, n_correct=2726.34, ppl=4.54, accuracy=65.616, wps=12079.5, ups=1.45, wpb=8310, bsz=303.9, num_updates=37400, lr=7.31272e-05, gnorm=0.531, clip=0, loss_scale=64, train_wall=68, gb_free=17.8, wall=30314
2023-08-01 19:09:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-01 19:10:08 | INFO | train_inner | epoch 026:    667 / 1474 loss=1.97, trans_loss=4.989, nll_loss=2.183, w2v_ctc_loss=0.626, task_loss=1.436, contrastive_loss=0.057, total=4129.11, n_correct=2708.04, ppl=4.54, accuracy=65.584, wps=12017.5, ups=1.46, wpb=8258.2, bsz=297.7, num_updates=37500, lr=7.30297e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=68, gb_free=13.8, wall=30382
2023-08-01 19:11:16 | INFO | train_inner | epoch 026:    767 / 1474 loss=1.977, trans_loss=4.989, nll_loss=2.182, w2v_ctc_loss=0.625, task_loss=1.412, contrastive_loss=0.172, total=4096.84, n_correct=2687.08, ppl=4.54, accuracy=65.589, wps=12006.1, ups=1.47, wpb=8193.7, bsz=300.5, num_updates=37600, lr=7.29325e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=30451
2023-08-01 19:12:24 | INFO | train_inner | epoch 026:    867 / 1474 loss=1.973, trans_loss=4.99, nll_loss=2.183, w2v_ctc_loss=0.632, task_loss=1.395, contrastive_loss=0.07, total=4176.27, n_correct=2738.33, ppl=4.54, accuracy=65.569, wps=12350.2, ups=1.48, wpb=8352.5, bsz=306.4, num_updates=37700, lr=7.28357e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=67, gb_free=16.3, wall=30518
2023-08-01 19:13:32 | INFO | train_inner | epoch 026:    967 / 1474 loss=1.977, trans_loss=4.998, nll_loss=2.194, w2v_ctc_loss=0.625, task_loss=1.444, contrastive_loss=0.124, total=4141.01, n_correct=2707.05, ppl=4.58, accuracy=65.372, wps=12106.8, ups=1.46, wpb=8282, bsz=299.7, num_updates=37800, lr=7.27393e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=15.5, wall=30587
2023-08-01 19:14:41 | INFO | train_inner | epoch 026:   1067 / 1474 loss=1.974, trans_loss=4.998, nll_loss=2.193, w2v_ctc_loss=0.63, task_loss=1.477, contrastive_loss=0.055, total=4113.69, n_correct=2694.37, ppl=4.57, accuracy=65.498, wps=12036.5, ups=1.46, wpb=8227.4, bsz=293, num_updates=37900, lr=7.26433e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=68, gb_free=15.5, wall=30655
2023-08-01 19:15:49 | INFO | train_inner | epoch 026:   1167 / 1474 loss=1.979, trans_loss=5.001, nll_loss=2.198, w2v_ctc_loss=0.632, task_loss=1.462, contrastive_loss=0.095, total=4116.78, n_correct=2691.64, ppl=4.59, accuracy=65.382, wps=12039.1, ups=1.46, wpb=8233.6, bsz=299, num_updates=38000, lr=7.25476e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=30723
2023-08-01 19:15:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 19:16:12 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.186 | trans_loss 5.552 | nll_loss 2.823 | w2v_ctc_loss 1.336 | task_loss 4.609 | contrastive_loss 0.246 | total 4003.4 | n_correct 2489.2 | ppl 7.08 | accuracy 62.177 | uer 17.195 | wer 18.966 | raw_wer 18.966 | bleu 20.15 | wps 2256.2 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.34
2023-08-01 19:16:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-08-01 19:16:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_26_38000.pt
2023-08-01 19:16:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_26_38000.pt
2023-08-01 19:16:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 20.15) (writing took 30.381772354245186 seconds)
2023-08-01 19:17:51 | INFO | train_inner | epoch 026:   1267 / 1474 loss=1.987, trans_loss=5.013, nll_loss=2.213, w2v_ctc_loss=0.648, task_loss=1.553, contrastive_loss=0.057, total=4001.06, n_correct=2604.86, ppl=4.64, accuracy=65.104, wps=6564, ups=0.82, wpb=8002.1, bsz=280.6, num_updates=38100, lr=7.24524e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=30845
2023-08-01 19:19:00 | INFO | train_inner | epoch 026:   1367 / 1474 loss=1.973, trans_loss=5.004, nll_loss=2.203, w2v_ctc_loss=0.625, task_loss=1.403, contrastive_loss=0.073, total=4157.69, n_correct=2720.4, ppl=4.6, accuracy=65.431, wps=12023.5, ups=1.45, wpb=8315.4, bsz=310.5, num_updates=38200, lr=7.23575e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=30914
2023-08-01 19:20:08 | INFO | train_inner | epoch 026:   1467 / 1474 loss=1.968, trans_loss=4.998, nll_loss=2.196, w2v_ctc_loss=0.619, task_loss=1.33, contrastive_loss=0.066, total=4158.47, n_correct=2727.77, ppl=4.58, accuracy=65.596, wps=12292.9, ups=1.48, wpb=8316.9, bsz=316.5, num_updates=38300, lr=7.22629e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=67, gb_free=17.3, wall=30982
2023-08-01 19:20:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 19:20:36 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.178 | trans_loss 5.548 | nll_loss 2.821 | w2v_ctc_loss 1.316 | task_loss 4.609 | contrastive_loss 0.25 | total 4003.4 | n_correct 2491.1 | ppl 7.07 | accuracy 62.225 | uer 17.238 | wer 19.142 | raw_wer 19.142 | bleu 19.99 | wps 2105.2 | wpb 4003.4 | bsz 141.8 | num_updates 38307 | best_bleu 20.34
2023-08-01 19:20:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38307 updates
2023-08-01 19:20:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_last.pt
2023-08-01 19:20:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_last.pt
2023-08-01 19:20:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_last.pt (epoch 26 @ 38307 updates, score 19.99) (writing took 11.305339071899652 seconds)
2023-08-01 19:20:48 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-01 19:20:48 | INFO | train | epoch 026 | loss 1.973 | trans_loss 4.989 | nll_loss 2.183 | w2v_ctc_loss 0.628 | task_loss 1.4 | contrastive_loss 0.108 | total 4138.45 | n_correct 2715.6 | ppl 4.54 | accuracy 65.619 | wps 11052.6 | ups 1.34 | wpb 8276.9 | bsz 305.6 | num_updates 38307 | lr 7.22563e-05 | gnorm 0.537 | clip 0 | loss_scale 32 | train_wall 999 | gb_free 15.9 | wall 31022
2023-08-01 19:20:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 19:20:48 | INFO | fairseq.trainer | begin training epoch 27
2023-08-01 19:20:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 19:21:58 | INFO | train_inner | epoch 027:     93 / 1474 loss=1.954, trans_loss=4.955, nll_loss=2.136, w2v_ctc_loss=0.617, task_loss=1.495, contrastive_loss=0.045, total=4067.62, n_correct=2695.9, ppl=4.4, accuracy=66.277, wps=7384.6, ups=0.91, wpb=8135.2, bsz=284.4, num_updates=38400, lr=7.21688e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=67, gb_free=14.8, wall=31092
2023-08-01 19:23:06 | INFO | train_inner | epoch 027:    193 / 1474 loss=1.952, trans_loss=4.959, nll_loss=2.144, w2v_ctc_loss=0.616, task_loss=1.341, contrastive_loss=0.074, total=4185.52, n_correct=2774.38, ppl=4.42, accuracy=66.285, wps=12271.7, ups=1.47, wpb=8371, bsz=321.7, num_updates=38500, lr=7.2075e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=31160
2023-08-01 19:24:16 | INFO | train_inner | epoch 027:    293 / 1474 loss=1.958, trans_loss=4.97, nll_loss=2.156, w2v_ctc_loss=0.618, task_loss=1.398, contrastive_loss=0.056, total=4167.92, n_correct=2757.3, ppl=4.46, accuracy=66.155, wps=12024.1, ups=1.44, wpb=8335.8, bsz=306.8, num_updates=38600, lr=7.19816e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=31230
2023-08-01 19:25:24 | INFO | train_inner | epoch 027:    393 / 1474 loss=1.974, trans_loss=4.977, nll_loss=2.166, w2v_ctc_loss=0.616, task_loss=1.47, contrastive_loss=0.24, total=4075.21, n_correct=2681.84, ppl=4.49, accuracy=65.809, wps=11854.3, ups=1.45, wpb=8150.4, bsz=296, num_updates=38700, lr=7.18885e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=17.7, wall=31299
2023-08-01 19:26:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-01 19:26:33 | INFO | train_inner | epoch 027:    494 / 1474 loss=1.97, trans_loss=4.984, nll_loss=2.176, w2v_ctc_loss=0.62, task_loss=1.283, contrastive_loss=0.178, total=4242.37, n_correct=2786.33, ppl=4.52, accuracy=65.679, wps=12335.1, ups=1.45, wpb=8484.7, bsz=331.1, num_updates=38800, lr=7.17958e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=31367
2023-08-01 19:27:41 | INFO | train_inner | epoch 027:    594 / 1474 loss=1.966, trans_loss=4.978, nll_loss=2.168, w2v_ctc_loss=0.625, task_loss=1.373, contrastive_loss=0.115, total=4134.93, n_correct=2726.27, ppl=4.49, accuracy=65.933, wps=12152.7, ups=1.47, wpb=8269.9, bsz=312, num_updates=38900, lr=7.17035e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=68, gb_free=17.6, wall=31435
2023-08-01 19:28:50 | INFO | train_inner | epoch 027:    694 / 1474 loss=1.97, trans_loss=4.985, nll_loss=2.178, w2v_ctc_loss=0.627, task_loss=1.398, contrastive_loss=0.094, total=4162.17, n_correct=2737.24, ppl=4.52, accuracy=65.765, wps=12125, ups=1.46, wpb=8324.3, bsz=305.1, num_updates=39000, lr=7.16115e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=68, gb_free=15.4, wall=31504
2023-08-01 19:29:57 | INFO | train_inner | epoch 027:    794 / 1474 loss=1.967, trans_loss=4.983, nll_loss=2.175, w2v_ctc_loss=0.625, task_loss=1.467, contrastive_loss=0.058, total=4107.17, n_correct=2699.04, ppl=4.51, accuracy=65.715, wps=12229.1, ups=1.49, wpb=8214.3, bsz=294.3, num_updates=39100, lr=7.15199e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=67, gb_free=11.4, wall=31571
2023-08-01 19:31:05 | INFO | train_inner | epoch 027:    894 / 1474 loss=1.961, trans_loss=4.988, nll_loss=2.18, w2v_ctc_loss=0.612, task_loss=1.454, contrastive_loss=0.047, total=4101.4, n_correct=2700.34, ppl=4.53, accuracy=65.839, wps=12032.6, ups=1.47, wpb=8202.8, bsz=292.8, num_updates=39200, lr=7.14286e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=31639
2023-08-01 19:32:14 | INFO | train_inner | epoch 027:    994 / 1474 loss=1.974, trans_loss=4.983, nll_loss=2.176, w2v_ctc_loss=0.622, task_loss=1.357, contrastive_loss=0.237, total=4195.5, n_correct=2758.67, ppl=4.52, accuracy=65.753, wps=12218.6, ups=1.46, wpb=8391, bsz=315.9, num_updates=39300, lr=7.13376e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=31708
2023-08-01 19:33:22 | INFO | train_inner | epoch 027:   1094 / 1474 loss=1.962, trans_loss=4.983, nll_loss=2.174, w2v_ctc_loss=0.619, task_loss=1.411, contrastive_loss=0.067, total=4147.99, n_correct=2731.74, ppl=4.51, accuracy=65.857, wps=12173.5, ups=1.47, wpb=8296, bsz=304.7, num_updates=39400, lr=7.1247e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=68, gb_free=16.1, wall=31776
2023-08-01 19:34:30 | INFO | train_inner | epoch 027:   1194 / 1474 loss=1.975, trans_loss=4.994, nll_loss=2.189, w2v_ctc_loss=0.633, task_loss=1.465, contrastive_loss=0.074, total=4104.84, n_correct=2688.45, ppl=4.56, accuracy=65.495, wps=12120.8, ups=1.48, wpb=8209.7, bsz=297.2, num_updates=39500, lr=7.11568e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=67, gb_free=12.1, wall=31844
2023-08-01 19:35:38 | INFO | train_inner | epoch 027:   1294 / 1474 loss=1.979, trans_loss=4.998, nll_loss=2.194, w2v_ctc_loss=0.627, task_loss=1.484, contrastive_loss=0.123, total=4062.86, n_correct=2656.58, ppl=4.58, accuracy=65.387, wps=11979.1, ups=1.47, wpb=8125.7, bsz=293.6, num_updates=39600, lr=7.10669e-05, gnorm=0.555, clip=0, loss_scale=16, train_wall=67, gb_free=16.5, wall=31912
2023-08-01 19:36:45 | INFO | train_inner | epoch 027:   1394 / 1474 loss=1.968, trans_loss=4.992, nll_loss=2.188, w2v_ctc_loss=0.62, task_loss=1.317, contrastive_loss=0.108, total=4157.6, n_correct=2728.64, ppl=4.56, accuracy=65.63, wps=12387.9, ups=1.49, wpb=8315.2, bsz=314, num_updates=39700, lr=7.09773e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=67, gb_free=17.6, wall=31979
2023-08-01 19:37:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 19:38:03 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.174 | trans_loss 5.544 | nll_loss 2.812 | w2v_ctc_loss 1.316 | task_loss 4.606 | contrastive_loss 0.24 | total 4003.4 | n_correct 2492.8 | ppl 7.02 | accuracy 62.267 | uer 17.076 | wer 18.84 | raw_wer 18.84 | bleu 20.4 | wps 2233.2 | wpb 4003.4 | bsz 141.8 | num_updates 39780 | best_bleu 20.4
2023-08-01 19:38:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39780 updates
2023-08-01 19:38:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 19:38:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 19:38:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt (epoch 27 @ 39780 updates, score 20.4) (writing took 20.82484933361411 seconds)
2023-08-01 19:38:24 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-01 19:38:24 | INFO | train | epoch 027 | loss 1.966 | trans_loss 4.981 | nll_loss 2.172 | w2v_ctc_loss 0.621 | task_loss 1.4 | contrastive_loss 0.107 | total 4138.18 | n_correct 2724.14 | ppl 4.51 | accuracy 65.829 | wps 11539.8 | ups 1.39 | wpb 8276.4 | bsz 305.6 | num_updates 39780 | lr 7.09059e-05 | gnorm 0.535 | clip 0 | loss_scale 16 | train_wall 997 | gb_free 17.8 | wall 32078
2023-08-01 19:38:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 19:38:24 | INFO | fairseq.trainer | begin training epoch 28
2023-08-01 19:38:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 19:38:45 | INFO | train_inner | epoch 028:     20 / 1474 loss=1.958, trans_loss=4.982, nll_loss=2.173, w2v_ctc_loss=0.612, task_loss=1.358, contrastive_loss=0.057, total=4107.3, n_correct=2708.07, ppl=4.51, accuracy=65.933, wps=6826.4, ups=0.83, wpb=8214.6, bsz=304.5, num_updates=39800, lr=7.08881e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=67, gb_free=17.3, wall=32099
2023-08-01 19:39:53 | INFO | train_inner | epoch 028:    120 / 1474 loss=1.952, trans_loss=4.952, nll_loss=2.133, w2v_ctc_loss=0.616, task_loss=1.465, contrastive_loss=0.052, total=4112.44, n_correct=2731.55, ppl=4.39, accuracy=66.422, wps=12148.7, ups=1.48, wpb=8224.9, bsz=292.7, num_updates=39900, lr=7.07992e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=67, gb_free=13.7, wall=32167
2023-08-01 19:41:01 | INFO | train_inner | epoch 028:    220 / 1474 loss=1.947, trans_loss=4.959, nll_loss=2.143, w2v_ctc_loss=0.606, task_loss=1.324, contrastive_loss=0.062, total=4193.3, n_correct=2784.42, ppl=4.42, accuracy=66.402, wps=12250.3, ups=1.46, wpb=8386.6, bsz=316.4, num_updates=40000, lr=7.07107e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=32235
2023-08-01 19:41:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 19:41:26 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.19 | trans_loss 5.554 | nll_loss 2.822 | w2v_ctc_loss 1.348 | task_loss 4.621 | contrastive_loss 0.24 | total 4003.4 | n_correct 2490.6 | ppl 7.07 | accuracy 62.212 | uer 17.259 | wer 19.056 | raw_wer 19.056 | bleu 20.08 | wps 2071.8 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.4
2023-08-01 19:41:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-08-01 19:41:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_28_40000.pt
2023-08-01 19:41:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_28_40000.pt
2023-08-01 19:41:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 20.08) (writing took 12.805654162541032 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:0')
2023-08-01 19:42:51 | INFO | train_inner | epoch 028:    320 / 1474 loss=1.978, trans_loss=4.97, nll_loss=2.157, w2v_ctc_loss=0.609, task_loss=1.399, contrastive_loss=0.395, total=4138.69, n_correct=2726.49, ppl=4.46, accuracy=65.878, wps=7563.7, ups=0.91, wpb=8277.4, bsz=314.4, num_updates=40100, lr=7.06225e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=71, gb_free=13.2, wall=32345
2023-08-01 19:44:04 | INFO | train_inner | epoch 028:    420 / 1474 loss=1.956, trans_loss=4.966, nll_loss=2.152, w2v_ctc_loss=0.617, task_loss=1.449, contrastive_loss=0.049, total=4089.84, n_correct=2708.35, ppl=4.45, accuracy=66.221, wps=11136.1, ups=1.36, wpb=8179.7, bsz=295.7, num_updates=40200, lr=7.05346e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=73, gb_free=16.6, wall=32418
2023-08-01 19:45:16 | INFO | train_inner | epoch 028:    520 / 1474 loss=1.956, trans_loss=4.968, nll_loss=2.154, w2v_ctc_loss=0.613, task_loss=1.456, contrastive_loss=0.06, total=4098.92, n_correct=2710.38, ppl=4.45, accuracy=66.124, wps=11377.7, ups=1.39, wpb=8197.8, bsz=295.7, num_updates=40300, lr=7.0447e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=72, gb_free=16.9, wall=32490
2023-08-01 19:46:26 | INFO | train_inner | epoch 028:    620 / 1474 loss=1.96, trans_loss=4.979, nll_loss=2.17, w2v_ctc_loss=0.618, task_loss=1.409, contrastive_loss=0.06, total=4180.1, n_correct=2757.8, ppl=4.5, accuracy=65.974, wps=11884.6, ups=1.42, wpb=8360.2, bsz=305.3, num_updates=40400, lr=7.03598e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=70, gb_free=16.5, wall=32561
2023-08-01 19:47:35 | INFO | train_inner | epoch 028:    720 / 1474 loss=1.964, trans_loss=4.978, nll_loss=2.169, w2v_ctc_loss=0.615, task_loss=1.265, contrastive_loss=0.173, total=4191.62, n_correct=2762.47, ppl=4.5, accuracy=65.905, wps=12303.9, ups=1.47, wpb=8383.2, bsz=329.2, num_updates=40500, lr=7.02728e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=32629
2023-08-01 19:48:42 | INFO | train_inner | epoch 028:    820 / 1474 loss=1.955, trans_loss=4.973, nll_loss=2.163, w2v_ctc_loss=0.614, task_loss=1.382, contrastive_loss=0.051, total=4088.91, n_correct=2702.66, ppl=4.48, accuracy=66.097, wps=12074.5, ups=1.48, wpb=8177.8, bsz=304.3, num_updates=40600, lr=7.01862e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=67, gb_free=17, wall=32697
2023-08-01 19:49:51 | INFO | train_inner | epoch 028:    920 / 1474 loss=1.968, trans_loss=4.983, nll_loss=2.174, w2v_ctc_loss=0.619, task_loss=1.445, contrastive_loss=0.117, total=4117.01, n_correct=2710.45, ppl=4.51, accuracy=65.835, wps=11943.3, ups=1.45, wpb=8234, bsz=299.7, num_updates=40700, lr=7.01e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=68, gb_free=15.3, wall=32766
2023-08-01 19:51:00 | INFO | train_inner | epoch 028:   1020 / 1474 loss=1.972, trans_loss=4.982, nll_loss=2.174, w2v_ctc_loss=0.625, task_loss=1.364, contrastive_loss=0.168, total=4182.85, n_correct=2755.13, ppl=4.51, accuracy=65.867, wps=12264.2, ups=1.47, wpb=8365.7, bsz=312, num_updates=40800, lr=7.0014e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=32834
2023-08-01 19:52:08 | INFO | train_inner | epoch 028:   1120 / 1474 loss=1.955, trans_loss=4.971, nll_loss=2.161, w2v_ctc_loss=0.613, task_loss=1.342, contrastive_loss=0.075, total=4220.16, n_correct=2787.21, ppl=4.47, accuracy=66.045, wps=12305.2, ups=1.46, wpb=8440.3, bsz=321, num_updates=40900, lr=6.99284e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=32902
2023-08-01 19:53:16 | INFO | train_inner | epoch 028:   1220 / 1474 loss=1.959, trans_loss=4.982, nll_loss=2.174, w2v_ctc_loss=0.613, task_loss=1.391, contrastive_loss=0.059, total=4092.46, n_correct=2696.94, ppl=4.51, accuracy=65.9, wps=12134.7, ups=1.48, wpb=8184.9, bsz=303.1, num_updates=41000, lr=6.9843e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=67, gb_free=17.6, wall=32970
2023-08-01 19:54:24 | INFO | train_inner | epoch 028:   1320 / 1474 loss=1.974, trans_loss=4.989, nll_loss=2.182, w2v_ctc_loss=0.632, task_loss=1.532, contrastive_loss=0.075, total=4084.55, n_correct=2679.58, ppl=4.54, accuracy=65.603, wps=11885.2, ups=1.45, wpb=8169.1, bsz=285.1, num_updates=41100, lr=6.9758e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=33039
2023-08-01 19:55:33 | INFO | train_inner | epoch 028:   1420 / 1474 loss=1.968, trans_loss=4.986, nll_loss=2.179, w2v_ctc_loss=0.621, task_loss=1.458, contrastive_loss=0.096, total=4154.09, n_correct=2731.82, ppl=4.53, accuracy=65.762, wps=12097, ups=1.46, wpb=8308.2, bsz=299.3, num_updates=41200, lr=6.96733e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=33107
2023-08-01 19:56:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:2')
2023-08-01 19:56:34 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.172 | trans_loss 5.547 | nll_loss 2.815 | w2v_ctc_loss 1.302 | task_loss 4.588 | contrastive_loss 0.243 | total 4003.4 | n_correct 2491.6 | ppl 7.04 | accuracy 62.237 | uer 16.893 | wer 18.616 | raw_wer 18.616 | bleu 20.26 | wps 2031.2 | wpb 4003.4 | bsz 141.8 | num_updates 41254 | best_bleu 20.4
2023-08-01 19:56:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41254 updates
2023-08-01 19:56:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.2604.pt
2023-08-01 19:56:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.2604.pt
2023-08-01 19:56:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.2604.pt (epoch 28 @ 41254 updates, score 20.26) (writing took 17.482825649902225 seconds)
2023-08-01 19:56:52 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-01 19:56:52 | INFO | train | epoch 028 | loss 1.961 | trans_loss 4.974 | nll_loss 2.163 | w2v_ctc_loss 0.617 | task_loss 1.399 | contrastive_loss 0.106 | total 4138.65 | n_correct 2732.14 | ppl 4.48 | accuracy 66.015 | wps 11008.7 | ups 1.33 | wpb 8277.3 | bsz 305.7 | num_updates 41254 | lr 6.96277e-05 | gnorm 0.539 | clip 0 | loss_scale 32 | train_wall 1013 | gb_free 16.4 | wall 33187
2023-08-01 19:56:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 19:56:53 | INFO | fairseq.trainer | begin training epoch 29
2023-08-01 19:56:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 19:57:33 | INFO | train_inner | epoch 029:     46 / 1474 loss=1.952, trans_loss=4.959, nll_loss=2.145, w2v_ctc_loss=0.617, task_loss=1.342, contrastive_loss=0.072, total=4169.12, n_correct=2765.6, ppl=4.42, accuracy=66.335, wps=6973, ups=0.84, wpb=8338.2, bsz=316.4, num_updates=41300, lr=6.95889e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=33227
2023-08-01 19:58:40 | INFO | train_inner | epoch 029:    146 / 1474 loss=1.956, trans_loss=4.961, nll_loss=2.145, w2v_ctc_loss=0.618, task_loss=1.396, contrastive_loss=0.09, total=4105.72, n_correct=2720.8, ppl=4.42, accuracy=66.269, wps=12105, ups=1.47, wpb=8211.4, bsz=304.1, num_updates=41400, lr=6.95048e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=33295
2023-08-01 19:59:49 | INFO | train_inner | epoch 029:    246 / 1474 loss=1.946, trans_loss=4.948, nll_loss=2.131, w2v_ctc_loss=0.597, task_loss=1.275, contrastive_loss=0.174, total=4199.67, n_correct=2793.39, ppl=4.38, accuracy=66.515, wps=12220.9, ups=1.45, wpb=8399.3, bsz=330.5, num_updates=41500, lr=6.9421e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=33363
2023-08-01 20:00:57 | INFO | train_inner | epoch 029:    346 / 1474 loss=1.959, trans_loss=4.97, nll_loss=2.157, w2v_ctc_loss=0.623, task_loss=1.496, contrastive_loss=0.056, total=4095.17, n_correct=2709.15, ppl=4.46, accuracy=66.155, wps=12041.1, ups=1.47, wpb=8190.3, bsz=291.2, num_updates=41600, lr=6.93375e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=33431
2023-08-01 20:02:06 | INFO | train_inner | epoch 029:    446 / 1474 loss=1.941, trans_loss=4.946, nll_loss=2.126, w2v_ctc_loss=0.601, task_loss=1.347, contrastive_loss=0.05, total=4157.44, n_correct=2767.68, ppl=4.36, accuracy=66.572, wps=12146.2, ups=1.46, wpb=8314.9, bsz=307.7, num_updates=41700, lr=6.92543e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=33500
2023-08-01 20:03:14 | INFO | train_inner | epoch 029:    546 / 1474 loss=1.966, trans_loss=4.972, nll_loss=2.16, w2v_ctc_loss=0.612, task_loss=1.487, contrastive_loss=0.147, total=4150.87, n_correct=2739.66, ppl=4.47, accuracy=66.002, wps=12163.2, ups=1.47, wpb=8301.7, bsz=294.9, num_updates=41800, lr=6.91714e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=33568
2023-08-01 20:04:22 | INFO | train_inner | epoch 029:    646 / 1474 loss=1.958, trans_loss=4.961, nll_loss=2.147, w2v_ctc_loss=0.611, task_loss=1.321, contrastive_loss=0.216, total=4143.02, n_correct=2744.97, ppl=4.43, accuracy=66.255, wps=12184, ups=1.47, wpb=8286, bsz=318.6, num_updates=41900, lr=6.90889e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=33636
2023-08-01 20:05:30 | INFO | train_inner | epoch 029:    746 / 1474 loss=1.949, trans_loss=4.958, nll_loss=2.143, w2v_ctc_loss=0.603, task_loss=1.291, contrastive_loss=0.134, total=4249.79, n_correct=2817.79, ppl=4.42, accuracy=66.304, wps=12403.4, ups=1.46, wpb=8499.6, bsz=330, num_updates=42000, lr=6.90066e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=33705
2023-08-01 20:05:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 20:05:53 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.191 | trans_loss 5.549 | nll_loss 2.819 | w2v_ctc_loss 1.358 | task_loss 4.589 | contrastive_loss 0.25 | total 4003.4 | n_correct 2493.4 | ppl 7.06 | accuracy 62.282 | uer 17.254 | wer 19.041 | raw_wer 19.041 | bleu 20.17 | wps 2174.2 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.4
2023-08-01 20:05:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-08-01 20:05:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_29_42000.pt
2023-08-01 20:05:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_29_42000.pt
2023-08-01 20:06:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 20.17) (writing took 15.678893592208624 seconds)
2023-08-01 20:07:18 | INFO | train_inner | epoch 029:    846 / 1474 loss=1.963, trans_loss=4.983, nll_loss=2.174, w2v_ctc_loss=0.615, task_loss=1.554, contrastive_loss=0.049, total=4027.19, n_correct=2649.71, ppl=4.51, accuracy=65.796, wps=7490.6, ups=0.93, wpb=8054.4, bsz=280.6, num_updates=42100, lr=6.89246e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=33812
2023-08-01 20:08:25 | INFO | train_inner | epoch 029:    946 / 1474 loss=1.958, trans_loss=4.978, nll_loss=2.168, w2v_ctc_loss=0.614, task_loss=1.424, contrastive_loss=0.06, total=4082.14, n_correct=2696.68, ppl=4.49, accuracy=66.06, wps=12111.3, ups=1.48, wpb=8164.3, bsz=296.3, num_updates=42200, lr=6.88428e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=67, gb_free=15.3, wall=33880
2023-08-01 20:09:33 | INFO | train_inner | epoch 029:   1046 / 1474 loss=1.957, trans_loss=4.968, nll_loss=2.156, w2v_ctc_loss=0.608, task_loss=1.393, contrastive_loss=0.135, total=4148.18, n_correct=2742.08, ppl=4.46, accuracy=66.103, wps=12223.4, ups=1.47, wpb=8296.4, bsz=308.2, num_updates=42300, lr=6.87614e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=33948
2023-08-01 20:10:41 | INFO | train_inner | epoch 029:   1146 / 1474 loss=1.962, trans_loss=4.982, nll_loss=2.173, w2v_ctc_loss=0.62, task_loss=1.532, contrastive_loss=0.044, total=4063.95, n_correct=2681.3, ppl=4.51, accuracy=65.978, wps=12001, ups=1.48, wpb=8127.9, bsz=283, num_updates=42400, lr=6.86803e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=67, gb_free=13.2, wall=34015
2023-08-01 20:11:49 | INFO | train_inner | epoch 029:   1246 / 1474 loss=1.961, trans_loss=4.981, nll_loss=2.172, w2v_ctc_loss=0.621, task_loss=1.42, contrastive_loss=0.053, total=4158.81, n_correct=2745, ppl=4.51, accuracy=66.004, wps=12180.5, ups=1.46, wpb=8317.6, bsz=301.2, num_updates=42500, lr=6.85994e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=34084
2023-08-01 20:12:58 | INFO | train_inner | epoch 029:   1346 / 1474 loss=1.96, trans_loss=4.975, nll_loss=2.165, w2v_ctc_loss=0.611, task_loss=1.377, contrastive_loss=0.117, total=4166.34, n_correct=2747.81, ppl=4.49, accuracy=65.953, wps=12162.8, ups=1.46, wpb=8332.7, bsz=310.7, num_updates=42600, lr=6.85189e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=68, gb_free=17.8, wall=34152
2023-08-01 20:14:06 | INFO | train_inner | epoch 029:   1446 / 1474 loss=1.961, trans_loss=4.973, nll_loss=2.164, w2v_ctc_loss=0.613, task_loss=1.374, contrastive_loss=0.146, total=4162.2, n_correct=2747.37, ppl=4.48, accuracy=66.008, wps=12250.2, ups=1.47, wpb=8324.4, bsz=311.5, num_updates=42700, lr=6.84386e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=67, gb_free=17.3, wall=34220
2023-08-01 20:14:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 20:14:47 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.179 | trans_loss 5.541 | nll_loss 2.808 | w2v_ctc_loss 1.34 | task_loss 4.609 | contrastive_loss 0.243 | total 4003.4 | n_correct 2496.6 | ppl 7 | accuracy 62.362 | uer 16.736 | wer 18.676 | raw_wer 18.676 | bleu 20.17 | wps 2281.2 | wpb 4003.4 | bsz 141.8 | num_updates 42728 | best_bleu 20.4
2023-08-01 20:14:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42728 updates
2023-08-01 20:14:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.1702.pt
2023-08-01 20:14:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.1702.pt
2023-08-01 20:14:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.1702.pt (epoch 29 @ 42728 updates, score 20.17) (writing took 12.04662344045937 seconds)
2023-08-01 20:15:00 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-01 20:15:00 | INFO | train | epoch 029 | loss 1.956 | trans_loss 4.967 | nll_loss 2.155 | w2v_ctc_loss 0.612 | task_loss 1.398 | contrastive_loss 0.105 | total 4138.65 | n_correct 2737.93 | ppl 4.45 | accuracy 66.155 | wps 11221.7 | ups 1.36 | wpb 8277.3 | bsz 305.7 | num_updates 42728 | lr 6.84162e-05 | gnorm 0.539 | clip 0 | loss_scale 32 | train_wall 998 | gb_free 16 | wall 34274
2023-08-01 20:15:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 20:15:00 | INFO | fairseq.trainer | begin training epoch 30
2023-08-01 20:15:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 20:15:56 | INFO | train_inner | epoch 030:     72 / 1474 loss=1.947, trans_loss=4.951, nll_loss=2.134, w2v_ctc_loss=0.596, task_loss=1.324, contrastive_loss=0.164, total=4182.65, n_correct=2778.47, ppl=4.39, accuracy=66.428, wps=7562.6, ups=0.9, wpb=8365.3, bsz=320.5, num_updates=42800, lr=6.83586e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=67, gb_free=13.4, wall=34331
2023-08-01 20:17:05 | INFO | train_inner | epoch 030:    172 / 1474 loss=1.942, trans_loss=4.935, nll_loss=2.112, w2v_ctc_loss=0.608, task_loss=1.31, contrastive_loss=0.096, total=4203.05, n_correct=2807.77, ppl=4.32, accuracy=66.803, wps=12303.2, ups=1.46, wpb=8406.1, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=68, gb_free=17.4, wall=34399
2023-08-01 20:18:12 | INFO | train_inner | epoch 030:    272 / 1474 loss=1.948, trans_loss=4.951, nll_loss=2.133, w2v_ctc_loss=0.615, task_loss=1.44, contrastive_loss=0.048, total=4116.93, n_correct=2739.97, ppl=4.39, accuracy=66.554, wps=12206.9, ups=1.48, wpb=8233.9, bsz=295.1, num_updates=43000, lr=6.81994e-05, gnorm=0.546, clip=0, loss_scale=64, train_wall=67, gb_free=17, wall=34466
2023-08-01 20:19:21 | INFO | train_inner | epoch 030:    372 / 1474 loss=1.938, trans_loss=4.943, nll_loss=2.122, w2v_ctc_loss=0.601, task_loss=1.404, contrastive_loss=0.051, total=4173.13, n_correct=2787.3, ppl=4.35, accuracy=66.792, wps=12148.5, ups=1.46, wpb=8346.3, bsz=305.6, num_updates=43100, lr=6.81203e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=68, gb_free=11.7, wall=34535
2023-08-01 20:20:28 | INFO | train_inner | epoch 030:    472 / 1474 loss=1.946, trans_loss=4.951, nll_loss=2.134, w2v_ctc_loss=0.601, task_loss=1.333, contrastive_loss=0.115, total=4135.2, n_correct=2752.21, ppl=4.39, accuracy=66.556, wps=12319.1, ups=1.49, wpb=8270.4, bsz=314.8, num_updates=43200, lr=6.80414e-05, gnorm=0.542, clip=0, loss_scale=64, train_wall=67, gb_free=16.8, wall=34602
2023-08-01 20:20:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-01 20:21:37 | INFO | train_inner | epoch 030:    573 / 1474 loss=1.945, trans_loss=4.957, nll_loss=2.142, w2v_ctc_loss=0.603, task_loss=1.365, contrastive_loss=0.077, total=4165.08, n_correct=2770.79, ppl=4.41, accuracy=66.524, wps=12130.8, ups=1.46, wpb=8330.2, bsz=311.8, num_updates=43300, lr=6.79628e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=34671
2023-08-01 20:22:45 | INFO | train_inner | epoch 030:    673 / 1474 loss=1.951, trans_loss=4.955, nll_loss=2.14, w2v_ctc_loss=0.612, task_loss=1.382, contrastive_loss=0.094, total=4187.95, n_correct=2780.67, ppl=4.41, accuracy=66.397, wps=12257.2, ups=1.46, wpb=8375.9, bsz=315, num_updates=43400, lr=6.78844e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=34739
2023-08-01 20:23:53 | INFO | train_inner | epoch 030:    773 / 1474 loss=1.967, trans_loss=4.971, nll_loss=2.159, w2v_ctc_loss=0.621, task_loss=1.432, contrastive_loss=0.173, total=4105.32, n_correct=2709.37, ppl=4.47, accuracy=65.997, wps=12038.9, ups=1.47, wpb=8210.6, bsz=302.6, num_updates=43500, lr=6.78064e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=68, gb_free=12.9, wall=34807
2023-08-01 20:25:01 | INFO | train_inner | epoch 030:    873 / 1474 loss=1.948, trans_loss=4.963, nll_loss=2.149, w2v_ctc_loss=0.603, task_loss=1.446, contrastive_loss=0.063, total=4102.11, n_correct=2722.14, ppl=4.44, accuracy=66.36, wps=12112.2, ups=1.48, wpb=8204.2, bsz=295.6, num_updates=43600, lr=6.77285e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=67, gb_free=17.4, wall=34875
2023-08-01 20:26:10 | INFO | train_inner | epoch 030:    973 / 1474 loss=1.954, trans_loss=4.969, nll_loss=2.156, w2v_ctc_loss=0.61, task_loss=1.43, contrastive_loss=0.065, total=4129.98, n_correct=2731.12, ppl=4.46, accuracy=66.129, wps=12033.6, ups=1.46, wpb=8260, bsz=300.4, num_updates=43700, lr=6.7651e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=34944
2023-08-01 20:27:19 | INFO | train_inner | epoch 030:   1073 / 1474 loss=1.971, trans_loss=4.981, nll_loss=2.172, w2v_ctc_loss=0.622, task_loss=1.567, contrastive_loss=0.141, total=4101.17, n_correct=2698.61, ppl=4.51, accuracy=65.801, wps=11877.6, ups=1.45, wpb=8202.3, bsz=282.3, num_updates=43800, lr=6.75737e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=35013
2023-08-01 20:28:27 | INFO | train_inner | epoch 030:   1173 / 1474 loss=1.949, trans_loss=4.964, nll_loss=2.152, w2v_ctc_loss=0.598, task_loss=1.343, contrastive_loss=0.121, total=4168.36, n_correct=2765.7, ppl=4.44, accuracy=66.35, wps=12212.8, ups=1.46, wpb=8336.7, bsz=314, num_updates=43900, lr=6.74967e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=35081
2023-08-01 20:29:35 | INFO | train_inner | epoch 030:   1273 / 1474 loss=1.958, trans_loss=4.974, nll_loss=2.163, w2v_ctc_loss=0.615, task_loss=1.543, contrastive_loss=0.057, total=4036.17, n_correct=2667.48, ppl=4.48, accuracy=66.089, wps=11880.6, ups=1.47, wpb=8072.3, bsz=284.3, num_updates=44000, lr=6.742e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=67, gb_free=15.7, wall=35149
2023-08-01 20:29:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 20:29:58 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.182 | trans_loss 5.546 | nll_loss 2.816 | w2v_ctc_loss 1.337 | task_loss 4.626 | contrastive_loss 0.244 | total 4003.4 | n_correct 2489.8 | ppl 7.04 | accuracy 62.192 | uer 16.962 | wer 18.739 | raw_wer 18.739 | bleu 20.31 | wps 2243.7 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.4
2023-08-01 20:29:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-08-01 20:29:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_30_44000.pt
2023-08-01 20:30:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_30_44000.pt
2023-08-01 20:30:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 20.31) (writing took 14.7034763507545 seconds)
2023-08-01 20:31:23 | INFO | train_inner | epoch 030:   1373 / 1474 loss=1.945, trans_loss=4.963, nll_loss=2.152, w2v_ctc_loss=0.604, task_loss=1.322, contrastive_loss=0.068, total=4165.07, n_correct=2765.7, ppl=4.44, accuracy=66.402, wps=7673.5, ups=0.92, wpb=8330.1, bsz=321.6, num_updates=44100, lr=6.73435e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=35258
2023-08-01 20:32:31 | INFO | train_inner | epoch 030:   1473 / 1474 loss=1.96, trans_loss=4.973, nll_loss=2.164, w2v_ctc_loss=0.605, task_loss=1.318, contrastive_loss=0.214, total=4141.76, n_correct=2738.22, ppl=4.48, accuracy=66.112, wps=12291.4, ups=1.48, wpb=8283.5, bsz=314.3, num_updates=44200, lr=6.72673e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=67, gb_free=16.3, wall=35325
2023-08-01 20:32:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 20:32:55 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.173 | trans_loss 5.545 | nll_loss 2.816 | w2v_ctc_loss 1.311 | task_loss 4.6 | contrastive_loss 0.239 | total 4003.4 | n_correct 2495 | ppl 7.04 | accuracy 62.322 | uer 17.214 | wer 19.119 | raw_wer 19.119 | bleu 20.1 | wps 2229.4 | wpb 4003.4 | bsz 141.8 | num_updates 44201 | best_bleu 20.4
2023-08-01 20:32:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44201 updates
2023-08-01 20:32:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_last.pt
2023-08-01 20:33:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_last.pt
2023-08-01 20:33:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_last.pt (epoch 30 @ 44201 updates, score 20.1) (writing took 10.953626934438944 seconds)
2023-08-01 20:33:06 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-01 20:33:06 | INFO | train | epoch 030 | loss 1.951 | trans_loss 4.96 | nll_loss 2.145 | w2v_ctc_loss 0.608 | task_loss 1.399 | contrastive_loss 0.104 | total 4138.73 | n_correct 2746.39 | ppl 4.42 | accuracy 66.358 | wps 11227.9 | ups 1.36 | wpb 8277.5 | bsz 305.7 | num_updates 44201 | lr 6.72665e-05 | gnorm 0.54 | clip 0 | loss_scale 32 | train_wall 997 | gb_free 17.1 | wall 35360
2023-08-01 20:33:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 20:33:06 | INFO | fairseq.trainer | begin training epoch 31
2023-08-01 20:33:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 20:34:22 | INFO | train_inner | epoch 031:     99 / 1474 loss=1.943, trans_loss=4.943, nll_loss=2.121, w2v_ctc_loss=0.609, task_loss=1.496, contrastive_loss=0.05, total=4054.44, n_correct=2702.12, ppl=4.35, accuracy=66.646, wps=7325.7, ups=0.9, wpb=8108.9, bsz=288.2, num_updates=44300, lr=6.71913e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=35436
2023-08-01 20:35:30 | INFO | train_inner | epoch 031:    199 / 1474 loss=1.941, trans_loss=4.942, nll_loss=2.12, w2v_ctc_loss=0.602, task_loss=1.436, contrastive_loss=0.08, total=4147.4, n_correct=2769.01, ppl=4.35, accuracy=66.765, wps=12198.2, ups=1.47, wpb=8294.8, bsz=302.2, num_updates=44400, lr=6.71156e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=35504
2023-08-01 20:36:38 | INFO | train_inner | epoch 031:    299 / 1474 loss=1.947, trans_loss=4.945, nll_loss=2.125, w2v_ctc_loss=0.606, task_loss=1.429, contrastive_loss=0.117, total=4149.21, n_correct=2765.05, ppl=4.36, accuracy=66.64, wps=12053.9, ups=1.45, wpb=8298.4, bsz=301.6, num_updates=44500, lr=6.70402e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=35573
2023-08-01 20:37:46 | INFO | train_inner | epoch 031:    399 / 1474 loss=1.946, trans_loss=4.954, nll_loss=2.136, w2v_ctc_loss=0.603, task_loss=1.529, contrastive_loss=0.053, total=4092.62, n_correct=2719.66, ppl=4.39, accuracy=66.453, wps=12068.4, ups=1.47, wpb=8185.2, bsz=285.6, num_updates=44600, lr=6.6965e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=67, gb_free=17.2, wall=35640
2023-08-01 20:38:55 | INFO | train_inner | epoch 031:    499 / 1474 loss=1.944, trans_loss=4.947, nll_loss=2.128, w2v_ctc_loss=0.609, task_loss=1.463, contrastive_loss=0.064, total=4111.85, n_correct=2734.96, ppl=4.37, accuracy=66.514, wps=12009.7, ups=1.46, wpb=8223.7, bsz=300.3, num_updates=44700, lr=6.689e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=68, gb_free=10.8, wall=35709
2023-08-01 20:40:03 | INFO | train_inner | epoch 031:    599 / 1474 loss=1.944, trans_loss=4.95, nll_loss=2.132, w2v_ctc_loss=0.605, task_loss=1.462, contrastive_loss=0.055, total=4083.44, n_correct=2717.71, ppl=4.38, accuracy=66.554, wps=11944.7, ups=1.46, wpb=8166.9, bsz=294.5, num_updates=44800, lr=6.68153e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=35777
2023-08-01 20:41:11 | INFO | train_inner | epoch 031:    699 / 1474 loss=1.935, trans_loss=4.946, nll_loss=2.126, w2v_ctc_loss=0.594, task_loss=1.333, contrastive_loss=0.054, total=4213.98, n_correct=2811.13, ppl=4.37, accuracy=66.71, wps=12399.6, ups=1.47, wpb=8428, bsz=315.7, num_updates=44900, lr=6.67409e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=35845
2023-08-01 20:42:19 | INFO | train_inner | epoch 031:    799 / 1474 loss=1.954, trans_loss=4.962, nll_loss=2.147, w2v_ctc_loss=0.604, task_loss=1.462, contrastive_loss=0.125, total=4097.37, n_correct=2715.04, ppl=4.43, accuracy=66.263, wps=12044.7, ups=1.47, wpb=8194.7, bsz=295.8, num_updates=45000, lr=6.66667e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=68, gb_free=12.9, wall=35913
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:0')
2023-08-01 20:43:27 | INFO | train_inner | epoch 031:    899 / 1474 loss=1.943, trans_loss=4.948, nll_loss=2.13, w2v_ctc_loss=0.6, task_loss=1.46, contrastive_loss=0.069, total=4096.72, n_correct=2729.44, ppl=4.38, accuracy=66.625, wps=12054.3, ups=1.47, wpb=8193.4, bsz=296.1, num_updates=45100, lr=6.65927e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=35981
2023-08-01 20:44:35 | INFO | train_inner | epoch 031:    999 / 1474 loss=1.95, trans_loss=4.962, nll_loss=2.149, w2v_ctc_loss=0.601, task_loss=1.321, contrastive_loss=0.153, total=4187.84, n_correct=2778.54, ppl=4.44, accuracy=66.348, wps=12361.2, ups=1.48, wpb=8375.7, bsz=319.5, num_updates=45200, lr=6.6519e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=67, gb_free=17.2, wall=36049
2023-08-01 20:45:43 | INFO | train_inner | epoch 031:   1099 / 1474 loss=1.946, trans_loss=4.956, nll_loss=2.141, w2v_ctc_loss=0.6, task_loss=1.368, contrastive_loss=0.102, total=4149.44, n_correct=2757.28, ppl=4.41, accuracy=66.449, wps=12198.5, ups=1.47, wpb=8298.9, bsz=315, num_updates=45300, lr=6.64455e-05, gnorm=0.539, clip=0, loss_scale=64, train_wall=68, gb_free=17.5, wall=36117
2023-08-01 20:46:51 | INFO | train_inner | epoch 031:   1199 / 1474 loss=1.953, trans_loss=4.962, nll_loss=2.15, w2v_ctc_loss=0.599, task_loss=1.31, contrastive_loss=0.216, total=4189.76, n_correct=2779.45, ppl=4.44, accuracy=66.339, wps=12386, ups=1.48, wpb=8379.5, bsz=321.3, num_updates=45400, lr=6.63723e-05, gnorm=0.534, clip=0, loss_scale=64, train_wall=67, gb_free=13.1, wall=36185
2023-08-01 20:47:58 | INFO | train_inner | epoch 031:   1299 / 1474 loss=1.941, trans_loss=4.961, nll_loss=2.148, w2v_ctc_loss=0.599, task_loss=1.26, contrastive_loss=0.06, total=4227.44, n_correct=2809.72, ppl=4.43, accuracy=66.464, wps=12540.7, ups=1.48, wpb=8454.9, bsz=326.3, num_updates=45500, lr=6.62994e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=67, gb_free=16.4, wall=36252
2023-08-01 20:48:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-01 20:49:07 | INFO | train_inner | epoch 031:   1400 / 1474 loss=1.947, trans_loss=4.956, nll_loss=2.142, w2v_ctc_loss=0.599, task_loss=1.309, contrastive_loss=0.158, total=4162.83, n_correct=2766.46, ppl=4.41, accuracy=66.456, wps=12028.2, ups=1.44, wpb=8325.7, bsz=319.1, num_updates=45600, lr=6.62266e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=36321
2023-08-01 20:49:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:5')
2023-08-01 20:50:21 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.172 | trans_loss 5.543 | nll_loss 2.812 | w2v_ctc_loss 1.31 | task_loss 4.611 | contrastive_loss 0.246 | total 4003.4 | n_correct 2496.4 | ppl 7.02 | accuracy 62.357 | uer 16.795 | wer 18.597 | raw_wer 18.597 | bleu 20.46 | wps 2106 | wpb 4003.4 | bsz 141.8 | num_updates 45674 | best_bleu 20.46
2023-08-01 20:50:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45674 updates
2023-08-01 20:50:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 20:50:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt
2023-08-01 20:50:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_best.pt (epoch 31 @ 45674 updates, score 20.46) (writing took 21.166943138465285 seconds)
2023-08-01 20:50:43 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-01 20:50:43 | INFO | train | epoch 031 | loss 1.946 | trans_loss 4.953 | nll_loss 2.136 | w2v_ctc_loss 0.602 | task_loss 1.402 | contrastive_loss 0.096 | total 4136.77 | n_correct 2751.26 | ppl 4.4 | accuracy 66.507 | wps 11525.6 | ups 1.39 | wpb 8273.5 | bsz 305.1 | num_updates 45674 | lr 6.61729e-05 | gnorm 0.54 | clip 0 | loss_scale 32 | train_wall 997 | gb_free 12 | wall 36417
2023-08-01 20:50:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 20:50:43 | INFO | fairseq.trainer | begin training epoch 32
2023-08-01 20:50:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 20:51:08 | INFO | train_inner | epoch 032:     26 / 1474 loss=1.945, trans_loss=4.954, nll_loss=2.138, w2v_ctc_loss=0.604, task_loss=1.477, contrastive_loss=0.05, total=4040.88, n_correct=2688.83, ppl=4.4, accuracy=66.541, wps=6675, ups=0.83, wpb=8081.8, bsz=288.7, num_updates=45700, lr=6.61541e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=67, gb_free=15.5, wall=36443
2023-08-01 20:52:16 | INFO | train_inner | epoch 032:    126 / 1474 loss=1.92, trans_loss=4.919, nll_loss=2.092, w2v_ctc_loss=0.581, task_loss=1.294, contrastive_loss=0.06, total=4222.14, n_correct=2838.84, ppl=4.26, accuracy=67.237, wps=12418.4, ups=1.47, wpb=8444.3, bsz=322.6, num_updates=45800, lr=6.60819e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=68, gb_free=15.4, wall=36511
2023-08-01 20:53:25 | INFO | train_inner | epoch 032:    226 / 1474 loss=1.932, trans_loss=4.935, nll_loss=2.113, w2v_ctc_loss=0.595, task_loss=1.331, contrastive_loss=0.071, total=4159.77, n_correct=2784.54, ppl=4.33, accuracy=66.94, wps=12187.5, ups=1.46, wpb=8319.5, bsz=320.8, num_updates=45900, lr=6.60098e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=36579
2023-08-01 20:54:33 | INFO | train_inner | epoch 032:    326 / 1474 loss=1.925, trans_loss=4.925, nll_loss=2.101, w2v_ctc_loss=0.585, task_loss=1.325, contrastive_loss=0.063, total=4179.65, n_correct=2810.03, ppl=4.29, accuracy=67.231, wps=12249.5, ups=1.47, wpb=8359.3, bsz=313.8, num_updates=46000, lr=6.5938e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=36647
2023-08-01 20:54:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 20:54:56 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.187 | trans_loss 5.55 | nll_loss 2.821 | w2v_ctc_loss 1.345 | task_loss 4.592 | contrastive_loss 0.241 | total 4003.4 | n_correct 2495.6 | ppl 7.07 | accuracy 62.337 | uer 17.065 | wer 19.004 | raw_wer 19.004 | bleu 20.11 | wps 2230.1 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.46
2023-08-01 20:54:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-08-01 20:54:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_32_46000.pt
2023-08-01 20:54:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_32_46000.pt
2023-08-01 20:55:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 20.11) (writing took 11.296889802441001 seconds)
2023-08-01 20:56:16 | INFO | train_inner | epoch 032:    426 / 1474 loss=1.933, trans_loss=4.935, nll_loss=2.113, w2v_ctc_loss=0.594, task_loss=1.365, contrastive_loss=0.061, total=4172.34, n_correct=2791.98, ppl=4.33, accuracy=66.916, wps=8110.8, ups=0.97, wpb=8344.7, bsz=309.9, num_updates=46100, lr=6.58665e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=68, gb_free=17.1, wall=36750
2023-08-01 20:57:24 | INFO | train_inner | epoch 032:    526 / 1474 loss=1.948, trans_loss=4.946, nll_loss=2.128, w2v_ctc_loss=0.606, task_loss=1.365, contrastive_loss=0.143, total=4191.15, n_correct=2796.98, ppl=4.37, accuracy=66.735, wps=12245, ups=1.46, wpb=8382.3, bsz=315.1, num_updates=46200, lr=6.57952e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=68, gb_free=14.9, wall=36818
2023-08-01 20:58:32 | INFO | train_inner | epoch 032:    626 / 1474 loss=1.946, trans_loss=4.953, nll_loss=2.135, w2v_ctc_loss=0.607, task_loss=1.46, contrastive_loss=0.068, total=4138.05, n_correct=2749.11, ppl=4.39, accuracy=66.435, wps=12107.6, ups=1.46, wpb=8276.1, bsz=299.5, num_updates=46300, lr=6.57241e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=68, gb_free=13.2, wall=36887
2023-08-01 20:59:41 | INFO | train_inner | epoch 032:    726 / 1474 loss=1.94, trans_loss=4.947, nll_loss=2.129, w2v_ctc_loss=0.603, task_loss=1.414, contrastive_loss=0.051, total=4156.23, n_correct=2773.41, ppl=4.37, accuracy=66.729, wps=12106.9, ups=1.46, wpb=8312.5, bsz=303, num_updates=46400, lr=6.56532e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=36955
2023-08-01 21:00:49 | INFO | train_inner | epoch 032:    826 / 1474 loss=1.938, trans_loss=4.949, nll_loss=2.13, w2v_ctc_loss=0.593, task_loss=1.453, contrastive_loss=0.048, total=4112.3, n_correct=2744.59, ppl=4.38, accuracy=66.741, wps=12182.1, ups=1.48, wpb=8224.6, bsz=293.9, num_updates=46500, lr=6.55826e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=67, gb_free=15.8, wall=37023
2023-08-01 21:01:57 | INFO | train_inner | epoch 032:    926 / 1474 loss=1.942, trans_loss=4.952, nll_loss=2.136, w2v_ctc_loss=0.599, task_loss=1.451, contrastive_loss=0.047, total=4139.37, n_correct=2752.67, ppl=4.39, accuracy=66.5, wps=12148.9, ups=1.47, wpb=8278.7, bsz=298.6, num_updates=46600, lr=6.55122e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=68, gb_free=12.7, wall=37091
2023-08-01 21:03:04 | INFO | train_inner | epoch 032:   1026 / 1474 loss=1.951, trans_loss=4.958, nll_loss=2.143, w2v_ctc_loss=0.604, task_loss=1.38, contrastive_loss=0.143, total=4121.85, n_correct=2735.91, ppl=4.42, accuracy=66.376, wps=12206.7, ups=1.48, wpb=8243.7, bsz=306.1, num_updates=46700, lr=6.5442e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=67, gb_free=16.8, wall=37159
2023-08-01 21:04:14 | INFO | train_inner | epoch 032:   1126 / 1474 loss=1.956, trans_loss=4.964, nll_loss=2.149, w2v_ctc_loss=0.607, task_loss=1.66, contrastive_loss=0.085, total=4015.59, n_correct=2657.98, ppl=4.43, accuracy=66.192, wps=11608.2, ups=1.45, wpb=8031.2, bsz=270.1, num_updates=46800, lr=6.5372e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=37228
2023-08-01 21:05:22 | INFO | train_inner | epoch 032:   1226 / 1474 loss=1.956, trans_loss=4.965, nll_loss=2.154, w2v_ctc_loss=0.597, task_loss=1.381, contrastive_loss=0.192, total=4153.44, n_correct=2751.9, ppl=4.45, accuracy=66.256, wps=12215.3, ups=1.47, wpb=8306.9, bsz=310.8, num_updates=46900, lr=6.53023e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=37296
2023-08-01 21:06:29 | INFO | train_inner | epoch 032:   1326 / 1474 loss=1.942, trans_loss=4.956, nll_loss=2.14, w2v_ctc_loss=0.599, task_loss=1.444, contrastive_loss=0.047, total=4075.86, n_correct=2710.13, ppl=4.41, accuracy=66.492, wps=12072.5, ups=1.48, wpb=8151.7, bsz=295.4, num_updates=47000, lr=6.52328e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=67, gb_free=16.8, wall=37363
2023-08-01 21:07:37 | INFO | train_inner | epoch 032:   1426 / 1474 loss=1.958, trans_loss=4.959, nll_loss=2.144, w2v_ctc_loss=0.603, task_loss=1.395, contrastive_loss=0.28, total=4116.4, n_correct=2731.34, ppl=4.42, accuracy=66.353, wps=12181.7, ups=1.48, wpb=8232.8, bsz=307.6, num_updates=47100, lr=6.51635e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=37431
2023-08-01 21:08:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 21:08:32 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.181 | trans_loss 5.541 | nll_loss 2.812 | w2v_ctc_loss 1.345 | task_loss 4.599 | contrastive_loss 0.241 | total 4003.4 | n_correct 2497.4 | ppl 7.02 | accuracy 62.382 | uer 16.816 | wer 18.638 | raw_wer 18.638 | bleu 20.31 | wps 2183.2 | wpb 4003.4 | bsz 141.8 | num_updates 47148 | best_bleu 20.46
2023-08-01 21:08:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47148 updates
2023-08-01 21:08:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.3103.pt
2023-08-01 21:08:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.3103.pt
2023-08-01 21:08:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.3103.pt (epoch 32 @ 47148 updates, score 20.31) (writing took 25.536798806861043 seconds)
2023-08-01 21:08:58 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-01 21:08:58 | INFO | train | epoch 032 | loss 1.942 | trans_loss 4.947 | nll_loss 2.129 | w2v_ctc_loss 0.597 | task_loss 1.399 | contrastive_loss 0.102 | total 4138.65 | n_correct 2758.81 | ppl 4.37 | accuracy 66.66 | wps 11141.7 | ups 1.35 | wpb 8277.3 | bsz 305.7 | num_updates 47148 | lr 6.51303e-05 | gnorm 0.541 | clip 0 | loss_scale 32 | train_wall 996 | gb_free 16.5 | wall 37512
2023-08-01 21:08:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 21:08:58 | INFO | fairseq.trainer | begin training epoch 33
2023-08-01 21:08:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 21:09:41 | INFO | train_inner | epoch 033:     52 / 1474 loss=1.937, trans_loss=4.939, nll_loss=2.12, w2v_ctc_loss=0.588, task_loss=1.32, contrastive_loss=0.152, total=4149.21, n_correct=2772.77, ppl=4.35, accuracy=66.826, wps=6649, ups=0.8, wpb=8298.4, bsz=320.5, num_updates=47200, lr=6.50945e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=67, gb_free=17, wall=37556
2023-08-01 21:10:50 | INFO | train_inner | epoch 033:    152 / 1474 loss=1.924, trans_loss=4.923, nll_loss=2.096, w2v_ctc_loss=0.579, task_loss=1.501, contrastive_loss=0.038, total=4073.9, n_correct=2737.19, ppl=4.27, accuracy=67.188, wps=11955.8, ups=1.47, wpb=8147.8, bsz=284.8, num_updates=47300, lr=6.50256e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=68, gb_free=15.2, wall=37624
2023-08-01 21:11:58 | INFO | train_inner | epoch 033:    252 / 1474 loss=1.937, trans_loss=4.924, nll_loss=2.101, w2v_ctc_loss=0.59, task_loss=1.193, contrastive_loss=0.218, total=4280.14, n_correct=2870.89, ppl=4.29, accuracy=67.075, wps=12519.9, ups=1.46, wpb=8560.3, bsz=346.5, num_updates=47400, lr=6.4957e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=37692
2023-08-01 21:13:06 | INFO | train_inner | epoch 033:    352 / 1474 loss=1.933, trans_loss=4.936, nll_loss=2.114, w2v_ctc_loss=0.591, task_loss=1.427, contrastive_loss=0.07, total=4120.27, n_correct=2756.37, ppl=4.33, accuracy=66.898, wps=12055.9, ups=1.46, wpb=8240.5, bsz=300.7, num_updates=47500, lr=6.48886e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=37761
2023-08-01 21:14:14 | INFO | train_inner | epoch 033:    452 / 1474 loss=1.92, trans_loss=4.922, nll_loss=2.095, w2v_ctc_loss=0.582, task_loss=1.329, contrastive_loss=0.048, total=4141.22, n_correct=2783.41, ppl=4.27, accuracy=67.212, wps=12181.9, ups=1.47, wpb=8282.4, bsz=310.8, num_updates=47600, lr=6.48204e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=37829
2023-08-01 21:15:23 | INFO | train_inner | epoch 033:    552 / 1474 loss=1.941, trans_loss=4.943, nll_loss=2.123, w2v_ctc_loss=0.6, task_loss=1.457, contrastive_loss=0.069, total=4133.59, n_correct=2754.16, ppl=4.36, accuracy=66.629, wps=12079, ups=1.46, wpb=8267.2, bsz=294, num_updates=47700, lr=6.47524e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=68, gb_free=15.2, wall=37897
2023-08-01 21:16:31 | INFO | train_inner | epoch 033:    652 / 1474 loss=1.943, trans_loss=4.953, nll_loss=2.135, w2v_ctc_loss=0.595, task_loss=1.43, contrastive_loss=0.103, total=4157.63, n_correct=2767.94, ppl=4.39, accuracy=66.575, wps=12203.7, ups=1.47, wpb=8315.3, bsz=301.6, num_updates=47800, lr=6.46846e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=68, gb_free=17.7, wall=37965
2023-08-01 21:17:39 | INFO | train_inner | epoch 033:    752 / 1474 loss=1.948, trans_loss=4.95, nll_loss=2.133, w2v_ctc_loss=0.613, task_loss=1.521, contrastive_loss=0.048, total=4070.75, n_correct=2709.73, ppl=4.38, accuracy=66.566, wps=12017, ups=1.48, wpb=8141.5, bsz=287.2, num_updates=47900, lr=6.46171e-05, gnorm=0.54, clip=0, loss_scale=64, train_wall=67, gb_free=16.4, wall=38033
2023-08-01 21:18:47 | INFO | train_inner | epoch 033:    852 / 1474 loss=1.924, trans_loss=4.933, nll_loss=2.112, w2v_ctc_loss=0.574, task_loss=1.329, contrastive_loss=0.117, total=4130.24, n_correct=2774.87, ppl=4.32, accuracy=67.184, wps=12115.9, ups=1.47, wpb=8260.5, bsz=316.3, num_updates=48000, lr=6.45497e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=68, gb_free=16.7, wall=38101
2023-08-01 21:18:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 21:19:10 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.205 | trans_loss 5.549 | nll_loss 2.817 | w2v_ctc_loss 1.406 | task_loss 4.611 | contrastive_loss 0.248 | total 4003.4 | n_correct 2494.3 | ppl 7.05 | accuracy 62.305 | uer 16.959 | wer 18.713 | raw_wer 18.713 | bleu 20 | wps 2184.4 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.46
2023-08-01 21:19:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-08-01 21:19:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_33_48000.pt
2023-08-01 21:19:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_33_48000.pt
2023-08-01 21:19:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 20.0) (writing took 24.19923911616206 seconds)
2023-08-01 21:20:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-01 21:20:43 | INFO | train_inner | epoch 033:    953 / 1474 loss=1.939, trans_loss=4.943, nll_loss=2.124, w2v_ctc_loss=0.604, task_loss=1.385, contrastive_loss=0.062, total=4157.71, n_correct=2776.83, ppl=4.36, accuracy=66.787, wps=7141.6, ups=0.86, wpb=8315.4, bsz=309.8, num_updates=48100, lr=6.44826e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=68, gb_free=17.4, wall=38218
2023-08-01 21:21:52 | INFO | train_inner | epoch 033:   1053 / 1474 loss=1.948, trans_loss=4.948, nll_loss=2.131, w2v_ctc_loss=0.597, task_loss=1.418, contrastive_loss=0.166, total=4134.8, n_correct=2751.67, ppl=4.38, accuracy=66.549, wps=12077.6, ups=1.46, wpb=8269.6, bsz=306, num_updates=48200, lr=6.44157e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=38286
2023-08-01 21:23:01 | INFO | train_inner | epoch 033:   1153 / 1474 loss=1.944, trans_loss=4.952, nll_loss=2.136, w2v_ctc_loss=0.589, task_loss=1.4, contrastive_loss=0.155, total=4181.58, n_correct=2784.73, ppl=4.4, accuracy=66.595, wps=12154.5, ups=1.45, wpb=8363.2, bsz=310, num_updates=48300, lr=6.43489e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=68, gb_free=15, wall=38355
2023-08-01 21:24:09 | INFO | train_inner | epoch 033:   1253 / 1474 loss=1.942, trans_loss=4.95, nll_loss=2.132, w2v_ctc_loss=0.602, task_loss=1.473, contrastive_loss=0.053, total=4115.76, n_correct=2742.39, ppl=4.38, accuracy=66.631, wps=11999.1, ups=1.46, wpb=8231.5, bsz=294.7, num_updates=48400, lr=6.42824e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=38423
2023-08-01 21:25:17 | INFO | train_inner | epoch 033:   1353 / 1474 loss=1.937, trans_loss=4.949, nll_loss=2.132, w2v_ctc_loss=0.597, task_loss=1.375, contrastive_loss=0.073, total=4120.69, n_correct=2747.62, ppl=4.38, accuracy=66.679, wps=12103.1, ups=1.47, wpb=8241.4, bsz=311.9, num_updates=48500, lr=6.42161e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=38492
2023-08-01 21:26:25 | INFO | train_inner | epoch 033:   1453 / 1474 loss=1.946, trans_loss=4.949, nll_loss=2.133, w2v_ctc_loss=0.592, task_loss=1.395, contrastive_loss=0.22, total=4125.28, n_correct=2747.88, ppl=4.39, accuracy=66.611, wps=12154.2, ups=1.47, wpb=8250.6, bsz=308.7, num_updates=48600, lr=6.415e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=67, gb_free=16.9, wall=38559
2023-08-01 21:26:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 21:27:02 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.196 | trans_loss 5.544 | nll_loss 2.811 | w2v_ctc_loss 1.386 | task_loss 4.635 | contrastive_loss 0.247 | total 4003.4 | n_correct 2499.7 | ppl 7.02 | accuracy 62.439 | uer 17.1 | wer 18.896 | raw_wer 18.896 | bleu 20.35 | wps 2235.9 | wpb 4003.4 | bsz 141.8 | num_updates 48621 | best_bleu 20.46
2023-08-01 21:27:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48621 updates
2023-08-01 21:27:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.3509.pt
2023-08-01 21:27:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.3509.pt
2023-08-01 21:27:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint.best_bleu_20.3509.pt (epoch 33 @ 48621 updates, score 20.35) (writing took 12.691626876592636 seconds)
2023-08-01 21:27:15 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-01 21:27:15 | INFO | train | epoch 033 | loss 1.937 | trans_loss 4.941 | nll_loss 2.12 | w2v_ctc_loss 0.593 | task_loss 1.399 | contrastive_loss 0.102 | total 4138.67 | n_correct 2765.04 | ppl 4.35 | accuracy 66.81 | wps 11113.5 | ups 1.34 | wpb 8277.3 | bsz 305.7 | num_updates 48621 | lr 6.41362e-05 | gnorm 0.544 | clip 0 | loss_scale 32 | train_wall 999 | gb_free 17.8 | wall 38610
2023-08-01 21:27:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-01 21:27:15 | INFO | fairseq.trainer | begin training epoch 34
2023-08-01 21:27:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-01 21:28:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-01 21:28:18 | INFO | train_inner | epoch 034:     80 / 1474 loss=1.925, trans_loss=4.92, nll_loss=2.093, w2v_ctc_loss=0.59, task_loss=1.38, contrastive_loss=0.054, total=4133.97, n_correct=2779.57, ppl=4.27, accuracy=67.237, wps=7334.9, ups=0.89, wpb=8267.9, bsz=302.3, num_updates=48700, lr=6.40841e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=68, gb_free=16, wall=38672
2023-08-01 21:29:26 | INFO | train_inner | epoch 034:    180 / 1474 loss=1.924, trans_loss=4.917, nll_loss=2.089, w2v_ctc_loss=0.588, task_loss=1.462, contrastive_loss=0.056, total=4066.35, n_correct=2735.05, ppl=4.26, accuracy=67.261, wps=11896.5, ups=1.46, wpb=8132.7, bsz=295.2, num_updates=48800, lr=6.40184e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=38741
2023-08-01 21:30:35 | INFO | train_inner | epoch 034:    280 / 1474 loss=1.944, trans_loss=4.935, nll_loss=2.114, w2v_ctc_loss=0.585, task_loss=1.306, contrastive_loss=0.266, total=4247.33, n_correct=2836.75, ppl=4.33, accuracy=66.789, wps=12414.8, ups=1.46, wpb=8494.7, bsz=329.5, num_updates=48900, lr=6.39529e-05, gnorm=0.56, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=38809
2023-08-01 21:31:43 | INFO | train_inner | epoch 034:    380 / 1474 loss=1.925, trans_loss=4.919, nll_loss=2.093, w2v_ctc_loss=0.577, task_loss=1.333, contrastive_loss=0.154, total=4152.22, n_correct=2794.49, ppl=4.27, accuracy=67.301, wps=12241.5, ups=1.47, wpb=8304.4, bsz=316.1, num_updates=49000, lr=6.38877e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=67, gb_free=15.9, wall=38877
2023-08-01 21:32:51 | INFO | train_inner | epoch 034:    480 / 1474 loss=1.933, trans_loss=4.935, nll_loss=2.111, w2v_ctc_loss=0.591, task_loss=1.524, contrastive_loss=0.049, total=4080.7, n_correct=2729.26, ppl=4.32, accuracy=66.882, wps=11907.3, ups=1.46, wpb=8161.4, bsz=286.7, num_updates=49100, lr=6.38226e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=38945
2023-08-01 21:33:59 | INFO | train_inner | epoch 034:    580 / 1474 loss=1.925, trans_loss=4.924, nll_loss=2.098, w2v_ctc_loss=0.587, task_loss=1.419, contrastive_loss=0.051, total=4126.98, n_correct=2775.72, ppl=4.28, accuracy=67.258, wps=12217.6, ups=1.48, wpb=8254, bsz=300.1, num_updates=49200, lr=6.37577e-05, gnorm=0.558, clip=0, loss_scale=16, train_wall=67, gb_free=16.2, wall=39013
2023-08-01 21:35:07 | INFO | train_inner | epoch 034:    680 / 1474 loss=1.925, trans_loss=4.928, nll_loss=2.104, w2v_ctc_loss=0.586, task_loss=1.44, contrastive_loss=0.045, total=4110.23, n_correct=2758.3, ppl=4.3, accuracy=67.108, wps=12032.9, ups=1.46, wpb=8220.5, bsz=297.1, num_updates=49300, lr=6.3693e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=39081
2023-08-01 21:36:19 | INFO | train_inner | epoch 034:    780 / 1474 loss=1.939, trans_loss=4.951, nll_loss=2.134, w2v_ctc_loss=0.582, task_loss=1.453, contrastive_loss=0.116, total=4087.05, n_correct=2723.45, ppl=4.39, accuracy=66.636, wps=11355.7, ups=1.39, wpb=8174.1, bsz=297.4, num_updates=49400, lr=6.36285e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=71, gb_free=16.1, wall=39153
2023-08-01 21:37:32 | INFO | train_inner | epoch 034:    880 / 1474 loss=1.938, trans_loss=4.943, nll_loss=2.125, w2v_ctc_loss=0.592, task_loss=1.492, contrastive_loss=0.076, total=4088.94, n_correct=2731.95, ppl=4.36, accuracy=66.813, wps=11168.7, ups=1.37, wpb=8177.9, bsz=294.2, num_updates=49500, lr=6.35642e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=73, gb_free=14.7, wall=39226
2023-08-01 21:38:44 | INFO | train_inner | epoch 034:    980 / 1474 loss=1.936, trans_loss=4.94, nll_loss=2.121, w2v_ctc_loss=0.598, task_loss=1.373, contrastive_loss=0.07, total=4175.9, n_correct=2789.61, ppl=4.35, accuracy=66.803, wps=11705.7, ups=1.4, wpb=8351.8, bsz=312.7, num_updates=49600, lr=6.35001e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=71, gb_free=13.7, wall=39298
2023-08-01 21:39:55 | INFO | train_inner | epoch 034:   1080 / 1474 loss=1.935, trans_loss=4.945, nll_loss=2.127, w2v_ctc_loss=0.594, task_loss=1.355, contrastive_loss=0.052, total=4152.17, n_correct=2768.49, ppl=4.37, accuracy=66.676, wps=11677.1, ups=1.41, wpb=8304.3, bsz=309, num_updates=49700, lr=6.34361e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=71, gb_free=14.4, wall=39369
2023-08-01 21:41:07 | INFO | train_inner | epoch 034:   1180 / 1474 loss=1.933, trans_loss=4.941, nll_loss=2.121, w2v_ctc_loss=0.589, task_loss=1.441, contrastive_loss=0.063, total=4101.68, n_correct=2740.44, ppl=4.35, accuracy=66.813, wps=11297.6, ups=1.38, wpb=8203.4, bsz=298, num_updates=49800, lr=6.33724e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=72, gb_free=16.2, wall=39442
2023-08-01 21:42:19 | INFO | train_inner | epoch 034:   1280 / 1474 loss=1.934, trans_loss=4.941, nll_loss=2.122, w2v_ctc_loss=0.593, task_loss=1.413, contrastive_loss=0.049, total=4146.01, n_correct=2767.88, ppl=4.35, accuracy=66.76, wps=11503.7, ups=1.39, wpb=8292, bsz=300.6, num_updates=49900, lr=6.33089e-05, gnorm=0.562, clip=0, loss_scale=16, train_wall=72, gb_free=17.3, wall=39514
2023-08-01 21:43:30 | INFO | train_inner | epoch 034:   1380 / 1474 loss=1.941, trans_loss=4.946, nll_loss=2.129, w2v_ctc_loss=0.598, task_loss=1.342, contrastive_loss=0.112, total=4197.99, n_correct=2799.06, ppl=4.37, accuracy=66.676, wps=11964.8, ups=1.43, wpb=8396, bsz=321.1, num_updates=50000, lr=6.32456e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=70, gb_free=17.2, wall=39584
2023-08-01 21:43:30 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-01 21:43:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-01 21:43:58 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.192 | trans_loss 5.546 | nll_loss 2.816 | w2v_ctc_loss 1.368 | task_loss 4.609 | contrastive_loss 0.245 | total 4003.4 | n_correct 2502.5 | ppl 7.04 | accuracy 62.509 | uer 16.93 | wer 18.631 | raw_wer 18.631 | bleu 20.17 | wps 1716.5 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.46
2023-08-01 21:43:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-08-01 21:43:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_34_50000.pt
2023-08-01 21:44:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_34_50000.pt
2023-08-01 21:44:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_0731_0.5mt_1.0at/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 20.17) (writing took 21.740201447159052 seconds)
2023-08-01 21:44:20 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-01 21:44:20 | INFO | train | epoch 034 | loss 1.932 | trans_loss 4.935 | nll_loss 2.113 | w2v_ctc_loss 0.589 | task_loss 1.409 | contrastive_loss 0.089 | total 4133.39 | n_correct 2766.47 | ppl 4.33 | accuracy 66.93 | wps 11127.2 | ups 1.35 | wpb 8266.8 | bsz 304.3 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.55 | clip 0 | loss_scale 16 | train_wall 960 | gb_free 17.2 | wall 39634
2023-08-01 21:44:20 | INFO | fairseq_cli.train | done training in 39583.6 seconds
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    raise EOFError
EOFError
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
