2023-07-02 06:08:55 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:10806
2023-07-02 06:08:55 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:10806
2023-07-02 06:08:55 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:10806
2023-07-02 06:08:55 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:10806
2023-07-02 06:08:55 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:10806
2023-07-02 06:08:55 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:10806
2023-07-02 06:08:55 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:10806
2023-07-02 06:08:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-02 06:08:55 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:10806
2023-07-02 06:08:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-02 06:08:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-02 06:08:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-02 06:08:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-02 06:08:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-02 06:08:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-02 06:08:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-02 06:08:55 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-02 06:08:55 | INFO | fairseq.distributed.utils | initialized host capios as rank 5
2023-07-02 06:08:55 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-02 06:08:55 | INFO | fairseq.distributed.utils | initialized host capios as rank 7
2023-07-02 06:08:55 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-02 06:08:55 | INFO | fairseq.distributed.utils | initialized host capios as rank 6
2023-07-02 06:08:55 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-02 06:08:55 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-02 06:08:55 | INFO | fairseq.distributed.utils | initialized host capios as rank 1
2023-07-02 06:08:55 | INFO | fairseq.distributed.utils | initialized host capios as rank 2
2023-07-02 06:08:55 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-02 06:08:55 | INFO | fairseq.distributed.utils | initialized host capios as rank 0
2023-07-02 06:08:55 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-02 06:08:55 | INFO | fairseq.distributed.utils | initialized host capios as rank 3
2023-07-02 06:08:55 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-02 06:08:55 | INFO | fairseq.distributed.utils | initialized host capios as rank 4
2023-07-02 06:08:57 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_scale10', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:10806', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 40000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_scale10', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=40000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_scale10', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_scale10', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=40000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_scale10', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_scale10', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=40000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_scale10', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_scale10', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-02 06:08:57 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-02 06:08:57 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-02 06:08:57 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-02 06:08:57 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-02 06:08:57 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-02 06:09:02 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-02 06:09:02 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-02 06:09:02 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-02 06:09:03 | INFO | root | load pretrained hubert
2023-07-02 06:09:07 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-02 06:09:08 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-02 06:09:11 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-02 06:09:11 | INFO | root | share the sematic adapter and textual encoder
2023-07-02 06:09:11 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-02 06:09:11 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-02 06:09:11 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-02 06:09:11 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-02 06:09:11 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-02 06:09:11 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-02 06:09:11 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-02 06:09:11 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-02 06:09:11 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-02 06:09:11 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-02 06:09:18 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-02 06:09:20 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-02 06:09:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-02 06:09:21 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-02 06:09:21 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-02 06:09:21 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-02 06:09:21 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-02 06:09:21 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-02 06:09:21 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-02 06:09:21 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-02 06:09:21 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-02 06:09:21 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-02 06:09:21 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-02 06:09:21 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-02 06:09:21 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-02 06:09:21 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_last.pt
2023-07-02 06:09:21 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_last.pt
2023-07-02 06:09:21 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-02 06:09:21 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-02 06:09:21 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-02 06:09:21 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-02 06:09:22 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-02 06:09:24 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-02 06:09:26 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-02 06:10:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 06:10:30 | INFO | fairseq.trainer | begin training epoch 1
2023-07-02 06:10:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 06:10:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-02 06:11:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-02 06:11:57 | INFO | train_inner | epoch 001:    102 / 1474 loss=20.798, trans_loss=5.641, nll_loss=4.216, w2v_ctc_loss=22.542, task_loss=0.691, contrastive_loss=3.293, total=4189.34, n_correct=211.98, ppl=18.58, accuracy=5.06, wps=16470.8, ups=1.31, wpb=12516, bsz=463.9, num_updates=100, lr=4.098e-06, gnorm=0.961, clip=0, loss_scale=32, train_wall=79, gb_free=19, wall=157
2023-07-02 06:13:11 | INFO | train_inner | epoch 001:    202 / 1474 loss=18.545, trans_loss=5.445, nll_loss=4.032, w2v_ctc_loss=19.35, task_loss=0.723, contrastive_loss=3.286, total=4125.46, n_correct=253.71, ppl=16.35, accuracy=6.15, wps=16650.6, ups=1.35, wpb=12321.8, bsz=461.7, num_updates=200, lr=8.096e-06, gnorm=3.64, clip=0, loss_scale=32, train_wall=74, gb_free=19, wall=231
2023-07-02 06:13:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-02 06:14:25 | INFO | train_inner | epoch 001:    303 / 1474 loss=11.654, trans_loss=5.429, nll_loss=4.071, w2v_ctc_loss=8.838, task_loss=0.775, contrastive_loss=3.144, total=4060.43, n_correct=248.77, ppl=16.8, accuracy=6.127, wps=16493.2, ups=1.36, wpb=12143.6, bsz=427, num_updates=300, lr=1.2094e-05, gnorm=4.68, clip=0, loss_scale=16, train_wall=73, gb_free=18.8, wall=304
2023-07-02 06:15:38 | INFO | train_inner | epoch 001:    403 / 1474 loss=10.43, trans_loss=5.496, nll_loss=4.184, w2v_ctc_loss=6.826, task_loss=0.808, contrastive_loss=3.261, total=4179.69, n_correct=200.95, ppl=18.18, accuracy=4.808, wps=17086.3, ups=1.37, wpb=12477.1, bsz=463.3, num_updates=400, lr=1.6092e-05, gnorm=3.006, clip=0, loss_scale=16, train_wall=73, gb_free=19.4, wall=377
2023-07-02 06:16:52 | INFO | train_inner | epoch 001:    503 / 1474 loss=10.053, trans_loss=5.582, nll_loss=4.328, w2v_ctc_loss=6.136, task_loss=0.803, contrastive_loss=3.358, total=4193.79, n_correct=195.34, ppl=20.09, accuracy=4.658, wps=16997.8, ups=1.35, wpb=12561.2, bsz=488.9, num_updates=500, lr=2.009e-05, gnorm=1.467, clip=0, loss_scale=16, train_wall=73, gb_free=19.8, wall=451
2023-07-02 06:18:05 | INFO | train_inner | epoch 001:    603 / 1474 loss=9.805, trans_loss=5.553, nll_loss=4.337, w2v_ctc_loss=5.834, task_loss=0.8, contrastive_loss=3.289, total=4124.15, n_correct=319.58, ppl=20.21, accuracy=7.749, wps=16944.1, ups=1.38, wpb=12303, bsz=470.9, num_updates=600, lr=2.4088e-05, gnorm=0.794, clip=0, loss_scale=16, train_wall=72, gb_free=19.6, wall=524
2023-07-02 06:19:17 | INFO | train_inner | epoch 001:    703 / 1474 loss=9.635, trans_loss=5.525, nll_loss=4.286, w2v_ctc_loss=5.688, task_loss=0.732, contrastive_loss=3.139, total=4155.16, n_correct=278.05, ppl=19.51, accuracy=6.692, wps=17090.2, ups=1.38, wpb=12385.8, bsz=458.1, num_updates=700, lr=2.8086e-05, gnorm=0.671, clip=0, loss_scale=16, train_wall=72, gb_free=19.2, wall=596
2023-07-02 06:20:30 | INFO | train_inner | epoch 001:    803 / 1474 loss=9.341, trans_loss=5.471, nll_loss=4.192, w2v_ctc_loss=5.446, task_loss=0.641, contrastive_loss=3.029, total=4121.86, n_correct=236.03, ppl=18.28, accuracy=5.726, wps=16931.1, ups=1.38, wpb=12302.5, bsz=462, num_updates=800, lr=3.2084e-05, gnorm=0.836, clip=0, loss_scale=16, train_wall=72, gb_free=19.3, wall=669
2023-07-02 06:21:42 | INFO | train_inner | epoch 001:    903 / 1474 loss=9.039, trans_loss=5.384, nll_loss=4.09, w2v_ctc_loss=5.264, task_loss=0.595, contrastive_loss=2.783, total=4165.51, n_correct=290.49, ppl=17.03, accuracy=6.974, wps=17244.7, ups=1.39, wpb=12415.9, bsz=458.2, num_updates=900, lr=3.6082e-05, gnorm=1.271, clip=0, loss_scale=16, train_wall=72, gb_free=19.2, wall=741
2023-07-02 06:22:54 | INFO | train_inner | epoch 001:   1003 / 1474 loss=8.78, trans_loss=5.367, nll_loss=4.066, w2v_ctc_loss=5.041, task_loss=0.588, contrastive_loss=2.643, total=4140.85, n_correct=303.97, ppl=16.75, accuracy=7.341, wps=17035.7, ups=1.38, wpb=12381.1, bsz=459.7, num_updates=1000, lr=4.008e-05, gnorm=1.667, clip=0, loss_scale=16, train_wall=72, gb_free=18.9, wall=814
2023-07-02 06:24:07 | INFO | train_inner | epoch 001:   1103 / 1474 loss=8.521, trans_loss=5.346, nll_loss=4.043, w2v_ctc_loss=4.871, task_loss=0.61, contrastive_loss=2.402, total=4140.11, n_correct=326.32, ppl=16.48, accuracy=7.882, wps=17084.3, ups=1.38, wpb=12336.2, bsz=450.3, num_updates=1100, lr=4.4078e-05, gnorm=1.689, clip=0, loss_scale=16, train_wall=72, gb_free=19.9, wall=886
2023-07-02 06:25:19 | INFO | train_inner | epoch 001:   1203 / 1474 loss=8.288, trans_loss=5.327, nll_loss=4.019, w2v_ctc_loss=4.689, task_loss=0.552, contrastive_loss=2.192, total=4137.6, n_correct=333.28, ppl=16.21, accuracy=8.055, wps=17143.4, ups=1.38, wpb=12380.3, bsz=438.9, num_updates=1200, lr=4.8076e-05, gnorm=1.805, clip=0, loss_scale=16, train_wall=72, gb_free=19, wall=958
2023-07-02 06:26:31 | INFO | train_inner | epoch 001:   1303 / 1474 loss=8.061, trans_loss=5.323, nll_loss=4.013, w2v_ctc_loss=4.5, task_loss=0.506, contrastive_loss=2.005, total=4055.88, n_correct=324.35, ppl=16.15, accuracy=7.997, wps=16870.3, ups=1.39, wpb=12116, bsz=443.9, num_updates=1300, lr=5.2074e-05, gnorm=1.891, clip=0, loss_scale=16, train_wall=71, gb_free=19.5, wall=1030
2023-07-02 06:27:43 | INFO | train_inner | epoch 001:   1403 / 1474 loss=7.875, trans_loss=5.31, nll_loss=4.008, w2v_ctc_loss=4.333, task_loss=0.492, contrastive_loss=2.058, total=4127.47, n_correct=340.18, ppl=16.09, accuracy=8.242, wps=16904.4, ups=1.38, wpb=12285.3, bsz=452, num_updates=1400, lr=5.6072e-05, gnorm=1.907, clip=0, loss_scale=16, train_wall=72, gb_free=19.4, wall=1103
2023-07-02 06:28:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-07-02 06:29:09 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.885 | trans_loss 10.856 | nll_loss 9.831 | w2v_ctc_loss 5.822 | task_loss 0 | contrastive_loss 2.435 | total 4003.4 | n_correct 366.6 | ppl 910.52 | accuracy 9.157 | uer 71.866 | wer 69.96 | raw_wer 69.96 | bleu 0.03 | wps 1443.5 | wpb 4003.4 | bsz 141.8 | num_updates 1471
2023-07-02 06:29:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1471 updates
2023-07-02 06:29:09 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt
2023-07-02 06:29:11 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt
2023-07-02 06:29:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt (epoch 1 @ 1471 updates, score 0.03) (writing took 4.701177787967026 seconds)
2023-07-02 06:29:14 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-07-02 06:29:14 | INFO | train | epoch 001 | loss 10.635 | trans_loss 5.437 | nll_loss 4.128 | w2v_ctc_loss 7.649 | task_loss 0.658 | contrastive_loss 2.809 | total 4136.43 | n_correct 279.581 | ppl 17.49 | accuracy 6.759 | wps 16332.3 | ups 1.32 | wpb 12349.8 | bsz 457.3 | num_updates 1471 | lr 5.89106e-05 | gnorm 1.87 | clip 0 | loss_scale 16 | train_wall 1070 | gb_free 19.2 | wall 1193
2023-07-02 06:29:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 06:29:14 | INFO | fairseq.trainer | begin training epoch 2
2023-07-02 06:29:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 06:29:43 | INFO | train_inner | epoch 002:     29 / 1474 loss=7.678, trans_loss=5.308, nll_loss=3.997, w2v_ctc_loss=4.136, task_loss=0.487, contrastive_loss=1.899, total=4165.52, n_correct=352.21, ppl=15.97, accuracy=8.455, wps=10342, ups=0.83, wpb=12423.9, bsz=471.4, num_updates=1500, lr=6.007e-05, gnorm=1.718, clip=0, loss_scale=16, train_wall=73, gb_free=18.9, wall=1223
2023-07-02 06:30:56 | INFO | train_inner | epoch 002:    129 / 1474 loss=7.51, trans_loss=5.308, nll_loss=3.996, w2v_ctc_loss=4.01, task_loss=0.485, contrastive_loss=1.684, total=4149.27, n_correct=351.93, ppl=15.96, accuracy=8.482, wps=17092.8, ups=1.38, wpb=12372.2, bsz=451.7, num_updates=1600, lr=6.4068e-05, gnorm=1.692, clip=0, loss_scale=16, train_wall=72, gb_free=18.9, wall=1295
2023-07-02 06:32:09 | INFO | train_inner | epoch 002:    229 / 1474 loss=7.344, trans_loss=5.284, nll_loss=3.973, w2v_ctc_loss=3.816, task_loss=0.485, contrastive_loss=1.727, total=4199.2, n_correct=360.54, ppl=15.7, accuracy=8.586, wps=17233.7, ups=1.37, wpb=12539.7, bsz=494.4, num_updates=1700, lr=6.8066e-05, gnorm=1.535, clip=0, loss_scale=16, train_wall=72, gb_free=19.1, wall=1368
2023-07-02 06:33:21 | INFO | train_inner | epoch 002:    329 / 1474 loss=7.184, trans_loss=5.286, nll_loss=3.972, w2v_ctc_loss=3.728, task_loss=0.484, contrastive_loss=1.414, total=4130.92, n_correct=359.4, ppl=15.69, accuracy=8.7, wps=16999.9, ups=1.38, wpb=12341.2, bsz=442.3, num_updates=1800, lr=7.2064e-05, gnorm=1.539, clip=0, loss_scale=16, train_wall=72, gb_free=18.9, wall=1440
2023-07-02 06:34:33 | INFO | train_inner | epoch 002:    429 / 1474 loss=7.046, trans_loss=5.275, nll_loss=3.961, w2v_ctc_loss=3.63, task_loss=0.484, contrastive_loss=1.249, total=4036.18, n_correct=351.39, ppl=15.58, accuracy=8.706, wps=16766.6, ups=1.39, wpb=12075.5, bsz=416.3, num_updates=1900, lr=7.6062e-05, gnorm=1.527, clip=0, loss_scale=16, train_wall=72, gb_free=19.2, wall=1512
2023-07-02 06:35:45 | INFO | train_inner | epoch 002:    529 / 1474 loss=6.944, trans_loss=5.27, nll_loss=3.951, w2v_ctc_loss=3.469, task_loss=0.484, contrastive_loss=1.351, total=4185.63, n_correct=373.92, ppl=15.46, accuracy=8.933, wps=17330, ups=1.39, wpb=12493.4, bsz=470.3, num_updates=2000, lr=8.006e-05, gnorm=1.378, clip=0, loss_scale=16, train_wall=72, gb_free=18.9, wall=1585
2023-07-02 06:35:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 06:36:19 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 9.243 | trans_loss 10.702 | nll_loss 9.624 | w2v_ctc_loss 4.696 | task_loss 0 | contrastive_loss 1.672 | total 4003.4 | n_correct 406.1 | ppl 789.03 | accuracy 10.144 | uer 61.495 | wer 59.55 | raw_wer 59.55 | bleu 0.04 | wps 1455.6 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.04
2023-07-02 06:36:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-07-02 06:36:19 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_2_2000.pt
2023-07-02 06:36:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_2_2000.pt
2023-07-02 06:36:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.04) (writing took 8.581420924980193 seconds)
2023-07-02 06:37:40 | INFO | train_inner | epoch 002:    629 / 1474 loss=6.802, trans_loss=5.257, nll_loss=3.938, w2v_ctc_loss=3.366, task_loss=0.484, contrastive_loss=1.127, total=4116.05, n_correct=375.07, ppl=15.32, accuracy=9.112, wps=10669, ups=0.87, wpb=12275.3, bsz=443.4, num_updates=2100, lr=8.4058e-05, gnorm=1.159, clip=0, loss_scale=16, train_wall=72, gb_free=19.8, wall=1700
2023-07-02 06:38:53 | INFO | train_inner | epoch 002:    729 / 1474 loss=6.728, trans_loss=5.243, nll_loss=3.923, w2v_ctc_loss=3.278, task_loss=0.484, contrastive_loss=1.228, total=4152.4, n_correct=386.03, ppl=15.16, accuracy=9.297, wps=17080.3, ups=1.38, wpb=12377.4, bsz=463.6, num_updates=2200, lr=8.8056e-05, gnorm=1.153, clip=0, loss_scale=16, train_wall=72, gb_free=19.1, wall=1772
2023-07-02 06:40:06 | INFO | train_inner | epoch 002:    829 / 1474 loss=6.637, trans_loss=5.227, nll_loss=3.901, w2v_ctc_loss=3.205, task_loss=0.484, contrastive_loss=1.176, total=4168.87, n_correct=394.23, ppl=14.94, accuracy=9.457, wps=17108.4, ups=1.37, wpb=12459.6, bsz=461.2, num_updates=2300, lr=9.2054e-05, gnorm=1.045, clip=0, loss_scale=16, train_wall=72, gb_free=18.9, wall=1845
2023-07-02 06:41:18 | INFO | train_inner | epoch 002:    929 / 1474 loss=6.541, trans_loss=5.221, nll_loss=3.895, w2v_ctc_loss=3.107, task_loss=0.484, contrastive_loss=1.153, total=4104.79, n_correct=385.92, ppl=14.88, accuracy=9.402, wps=16958.8, ups=1.38, wpb=12246.1, bsz=445.6, num_updates=2400, lr=9.6052e-05, gnorm=1.024, clip=0, loss_scale=32, train_wall=72, gb_free=19.1, wall=1917
2023-07-02 06:42:30 | INFO | train_inner | epoch 002:   1029 / 1474 loss=6.457, trans_loss=5.212, nll_loss=3.881, w2v_ctc_loss=3.03, task_loss=0.484, contrastive_loss=1.013, total=4100.85, n_correct=394.88, ppl=14.73, accuracy=9.629, wps=17048.5, ups=1.39, wpb=12264.3, bsz=455.2, num_updates=2500, lr=0.00010005, gnorm=0.941, clip=0, loss_scale=32, train_wall=72, gb_free=19.5, wall=1989
2023-07-02 06:43:43 | INFO | train_inner | epoch 002:   1129 / 1474 loss=6.416, trans_loss=5.204, nll_loss=3.874, w2v_ctc_loss=2.95, task_loss=0.484, contrastive_loss=1.221, total=4195.47, n_correct=412.44, ppl=14.66, accuracy=9.831, wps=17123.7, ups=1.37, wpb=12512, bsz=489.6, num_updates=2600, lr=0.000104048, gnorm=0.875, clip=0, loss_scale=32, train_wall=73, gb_free=19.1, wall=2062
2023-07-02 06:44:56 | INFO | train_inner | epoch 002:   1229 / 1474 loss=6.355, trans_loss=5.193, nll_loss=3.859, w2v_ctc_loss=2.904, task_loss=0.484, contrastive_loss=1.137, total=4220.45, n_correct=422.54, ppl=14.51, accuracy=10.012, wps=17252.2, ups=1.37, wpb=12583.3, bsz=492, num_updates=2700, lr=0.000108046, gnorm=0.814, clip=0, loss_scale=32, train_wall=72, gb_free=19.9, wall=2135
2023-07-02 06:46:08 | INFO | train_inner | epoch 002:   1329 / 1474 loss=6.253, trans_loss=5.169, nll_loss=3.833, w2v_ctc_loss=2.863, task_loss=0.484, contrastive_loss=0.853, total=4159.97, n_correct=428.12, ppl=14.25, accuracy=10.291, wps=17307.6, ups=1.39, wpb=12432.2, bsz=462.1, num_updates=2800, lr=0.000112044, gnorm=0.79, clip=0, loss_scale=32, train_wall=71, gb_free=19.7, wall=2207
2023-07-02 06:47:21 | INFO | train_inner | epoch 002:   1429 / 1474 loss=6.219, trans_loss=5.174, nll_loss=3.833, w2v_ctc_loss=2.817, task_loss=0.484, contrastive_loss=0.939, total=4050.6, n_correct=414.27, ppl=14.25, accuracy=10.227, wps=16615.7, ups=1.37, wpb=12118.3, bsz=438.3, num_updates=2900, lr=0.000116042, gnorm=0.762, clip=0, loss_scale=32, train_wall=73, gb_free=19.8, wall=2280
2023-07-02 06:47:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 06:48:27 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.431 | trans_loss 10.186 | nll_loss 8.976 | w2v_ctc_loss 3.722 | task_loss 0 | contrastive_loss 1.002 | total 4003.4 | n_correct 517.8 | ppl 503.38 | accuracy 12.934 | uer 51.666 | wer 50.427 | raw_wer 50.427 | bleu 0.13 | wps 1460.2 | wpb 4003.4 | bsz 141.8 | num_updates 2945 | best_bleu 0.13
2023-07-02 06:48:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2945 updates
2023-07-02 06:48:27 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt
2023-07-02 06:48:32 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt
2023-07-02 06:48:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt (epoch 2 @ 2945 updates, score 0.13) (writing took 8.145775618962944 seconds)
2023-07-02 06:48:36 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-07-02 06:48:36 | INFO | train | epoch 002 | loss 6.746 | trans_loss 5.237 | nll_loss 3.913 | w2v_ctc_loss 3.299 | task_loss 0.484 | contrastive_loss 1.237 | total 4138.65 | n_correct 386.723 | ppl 15.06 | accuracy 9.344 | wps 15674.5 | ups 1.27 | wpb 12355.8 | bsz 458.5 | num_updates 2945 | lr 0.000117841 | gnorm 1.157 | clip 0 | loss_scale 32 | train_wall 1063 | gb_free 19.3 | wall 2355
2023-07-02 06:48:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 06:48:36 | INFO | fairseq.trainer | begin training epoch 3
2023-07-02 06:48:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 06:49:24 | INFO | train_inner | epoch 003:     55 / 1474 loss=6.145, trans_loss=5.154, nll_loss=3.81, w2v_ctc_loss=2.767, task_loss=0.484, contrastive_loss=0.838, total=4066.57, n_correct=427.4, ppl=14.02, accuracy=10.51, wps=9839.2, ups=0.81, wpb=12132.7, bsz=441.1, num_updates=3000, lr=0.00012004, gnorm=0.747, clip=0, loss_scale=32, train_wall=73, gb_free=19, wall=2403
2023-07-02 06:49:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-02 06:49:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-02 06:49:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-07-02 06:51:06 | INFO | train_inner | epoch 003:    158 / 1474 loss=5.43, trans_loss=4.398, nll_loss=2.82, w2v_ctc_loss=2.501, task_loss=0.484, contrastive_loss=0.755, total=4145.69, n_correct=1111.78, ppl=7.06, accuracy=26.818, wps=12122.4, ups=0.98, wpb=12381.9, bsz=457.3, num_updates=3100, lr=0.000124038, gnorm=2.687, clip=1, loss_scale=4, train_wall=102, gb_free=16.7, wall=2505
2023-07-02 06:52:47 | INFO | train_inner | epoch 003:    258 / 1474 loss=5.08, trans_loss=4.164, nll_loss=2.515, w2v_ctc_loss=2.307, task_loss=0.484, contrastive_loss=0.673, total=4161.13, n_correct=1385.13, ppl=5.71, accuracy=33.287, wps=12361.9, ups=0.99, wpb=12444.3, bsz=467, num_updates=3200, lr=0.000128036, gnorm=2.067, clip=1, loss_scale=4, train_wall=100, gb_free=17.3, wall=2606
2023-07-02 06:54:27 | INFO | train_inner | epoch 003:    358 / 1474 loss=5.004, trans_loss=4.12, nll_loss=2.457, w2v_ctc_loss=2.252, task_loss=0.484, contrastive_loss=0.712, total=4150.02, n_correct=1457.43, ppl=5.49, accuracy=35.119, wps=12401.7, ups=1, wpb=12369, bsz=461.6, num_updates=3300, lr=0.000132034, gnorm=2.277, clip=0, loss_scale=4, train_wall=99, gb_free=17.3, wall=2706
2023-07-02 06:56:07 | INFO | train_inner | epoch 003:    458 / 1474 loss=4.87, trans_loss=4.071, nll_loss=2.394, w2v_ctc_loss=2.156, task_loss=0.484, contrastive_loss=0.565, total=4209.57, n_correct=1549.92, ppl=5.26, accuracy=36.819, wps=12493.6, ups=1, wpb=12537.6, bsz=476.8, num_updates=3400, lr=0.000136032, gnorm=1.939, clip=0, loss_scale=4, train_wall=100, gb_free=16.2, wall=2806
2023-07-02 06:57:46 | INFO | train_inner | epoch 003:    558 / 1474 loss=4.796, trans_loss=4.054, nll_loss=2.366, w2v_ctc_loss=2.087, task_loss=0.484, contrastive_loss=0.528, total=4088.48, n_correct=1538.63, ppl=5.16, accuracy=37.633, wps=12327.2, ups=1.01, wpb=12237.1, bsz=439.7, num_updates=3500, lr=0.00014003, gnorm=1.914, clip=0, loss_scale=4, train_wall=99, gb_free=17.8, wall=2905
2023-07-02 06:59:28 | INFO | train_inner | epoch 003:    658 / 1474 loss=4.731, trans_loss=4.018, nll_loss=2.322, w2v_ctc_loss=2.017, task_loss=0.484, contrastive_loss=0.631, total=4221.58, n_correct=1648.97, ppl=5, accuracy=39.06, wps=12388.9, ups=0.99, wpb=12558.6, bsz=481.9, num_updates=3600, lr=0.000144028, gnorm=1.578, clip=0, loss_scale=4, train_wall=101, gb_free=16.5, wall=3007
2023-07-02 07:01:07 | INFO | train_inner | epoch 003:    758 / 1474 loss=4.64, trans_loss=3.987, nll_loss=2.28, w2v_ctc_loss=1.962, task_loss=0.484, contrastive_loss=0.398, total=4167.41, n_correct=1672.69, ppl=4.86, accuracy=40.137, wps=12520.1, ups=1, wpb=12462.8, bsz=472.6, num_updates=3700, lr=0.000148026, gnorm=1.473, clip=0, loss_scale=4, train_wall=99, gb_free=16.6, wall=3106
2023-07-02 07:02:47 | INFO | train_inner | epoch 003:    858 / 1474 loss=4.594, trans_loss=3.97, nll_loss=2.258, w2v_ctc_loss=1.929, task_loss=0.484, contrastive_loss=0.358, total=4165.53, n_correct=1698.41, ppl=4.78, accuracy=40.773, wps=12435, ups=1, wpb=12445.3, bsz=456.1, num_updates=3800, lr=0.000152024, gnorm=1.441, clip=0, loss_scale=4, train_wall=100, gb_free=17.2, wall=3206
2023-07-02 07:04:27 | INFO | train_inner | epoch 003:    958 / 1474 loss=4.562, trans_loss=3.944, nll_loss=2.224, w2v_ctc_loss=1.901, task_loss=0.484, contrastive_loss=0.399, total=4162.3, n_correct=1739.79, ppl=4.67, accuracy=41.799, wps=12385.3, ups=1, wpb=12408.5, bsz=469.2, num_updates=3900, lr=0.000156022, gnorm=1.452, clip=0, loss_scale=4, train_wall=100, gb_free=16.9, wall=3307
2023-07-02 07:06:06 | INFO | train_inner | epoch 003:   1058 / 1474 loss=4.523, trans_loss=3.935, nll_loss=2.211, w2v_ctc_loss=1.876, task_loss=0.484, contrastive_loss=0.343, total=4069.95, n_correct=1718.25, ppl=4.63, accuracy=42.218, wps=12293.7, ups=1.01, wpb=12168.2, bsz=443.6, num_updates=4000, lr=0.00016002, gnorm=1.336, clip=0, loss_scale=4, train_wall=99, gb_free=16.5, wall=3406
2023-07-02 07:06:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 07:06:33 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.398 | trans_loss 6.585 | nll_loss 4.188 | w2v_ctc_loss 2.372 | task_loss 0 | contrastive_loss 0.478 | total 4003.4 | n_correct 1872 | ppl 18.22 | accuracy 46.76 | uer 32.986 | wer 33.366 | raw_wer 33.366 | bleu 9.14 | wps 2049.2 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 9.14
2023-07-02 07:06:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-07-02 07:06:33 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_3_4000.pt
2023-07-02 07:06:35 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_3_4000.pt
2023-07-02 07:06:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 9.14) (writing took 8.888874779921025 seconds)
2023-07-02 07:08:21 | INFO | train_inner | epoch 003:   1158 / 1474 loss=4.471, trans_loss=3.919, nll_loss=2.189, w2v_ctc_loss=1.825, task_loss=0.484, contrastive_loss=0.312, total=4038.49, n_correct=1733.52, ppl=4.56, accuracy=42.925, wps=8970.5, ups=0.74, wpb=12064, bsz=432.5, num_updates=4100, lr=0.000164018, gnorm=1.223, clip=0, loss_scale=4, train_wall=98, gb_free=16.6, wall=3540
2023-07-02 07:10:00 | INFO | train_inner | epoch 003:   1258 / 1474 loss=4.433, trans_loss=3.904, nll_loss=2.171, w2v_ctc_loss=1.789, task_loss=0.484, contrastive_loss=0.291, total=4064.31, n_correct=1775.65, ppl=4.5, accuracy=43.689, wps=12257.9, ups=1.01, wpb=12147.9, bsz=433.9, num_updates=4200, lr=0.000168016, gnorm=1.197, clip=0, loss_scale=4, train_wall=99, gb_free=17.5, wall=3639
2023-07-02 07:11:40 | INFO | train_inner | epoch 003:   1358 / 1474 loss=4.396, trans_loss=3.874, nll_loss=2.135, w2v_ctc_loss=1.747, task_loss=0.484, contrastive_loss=0.401, total=4134.58, n_correct=1840.97, ppl=4.39, accuracy=44.526, wps=12279.3, ups=1, wpb=12326.9, bsz=460.7, num_updates=4300, lr=0.000172014, gnorm=1.074, clip=0, loss_scale=4, train_wall=100, gb_free=17.9, wall=3740
2023-07-02 07:13:21 | INFO | train_inner | epoch 003:   1458 / 1474 loss=4.35, trans_loss=3.856, nll_loss=2.111, w2v_ctc_loss=1.704, task_loss=0.484, contrastive_loss=0.377, total=4209.94, n_correct=1908.13, ppl=4.32, accuracy=45.324, wps=12470, ups=0.99, wpb=12573.7, bsz=477.4, num_updates=4400, lr=0.000176012, gnorm=1.025, clip=0, loss_scale=4, train_wall=100, gb_free=17.2, wall=3840
2023-07-02 07:13:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 07:14:04 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.222 | trans_loss 6.461 | nll_loss 4.02 | w2v_ctc_loss 2.12 | task_loss 0 | contrastive_loss 0.407 | total 4003.4 | n_correct 1963.5 | ppl 16.22 | accuracy 49.046 | uer 31.062 | wer 31.158 | raw_wer 31.158 | bleu 8.78 | wps 1986.4 | wpb 4003.4 | bsz 141.8 | num_updates 4416 | best_bleu 9.14
2023-07-02 07:14:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4416 updates
2023-07-02 07:14:04 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_8.7806.pt
2023-07-02 07:14:07 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_8.7806.pt
2023-07-02 07:14:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_8.7806.pt (epoch 3 @ 4416 updates, score 8.78) (writing took 5.275372423231602 seconds)
2023-07-02 07:14:10 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-07-02 07:14:10 | INFO | train | epoch 003 | loss 4.756 | trans_loss 4.056 | nll_loss 2.372 | w2v_ctc_loss 2.029 | task_loss 0.484 | contrastive_loss 0.497 | total 4139.57 | n_correct 1584.35 | ppl 5.18 | accuracy 38.273 | wps 11850.1 | ups 0.96 | wpb 12358.5 | bsz 458.7 | num_updates 4416 | lr 0.000176652 | gnorm 1.582 | clip 0.1 | loss_scale 4 | train_wall 1451 | gb_free 16.8 | wall 3889
2023-07-02 07:14:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 07:14:10 | INFO | fairseq.trainer | begin training epoch 4
2023-07-02 07:14:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 07:15:41 | INFO | train_inner | epoch 004:     84 / 1474 loss=4.282, trans_loss=3.832, nll_loss=2.078, w2v_ctc_loss=1.676, task_loss=0.484, contrastive_loss=0.231, total=4099.41, n_correct=1883.1, ppl=4.22, accuracy=45.936, wps=8744.3, ups=0.72, wpb=12215.8, bsz=439.5, num_updates=4500, lr=0.00018001, gnorm=1.038, clip=0, loss_scale=4, train_wall=99, gb_free=16.6, wall=3980
2023-07-02 07:17:20 | INFO | train_inner | epoch 004:    184 / 1474 loss=4.246, trans_loss=3.809, nll_loss=2.047, w2v_ctc_loss=1.639, task_loss=0.484, contrastive_loss=0.251, total=4175.15, n_correct=1956.91, ppl=4.13, accuracy=46.87, wps=12581, ups=1.01, wpb=12466.1, bsz=468.3, num_updates=4600, lr=0.000184008, gnorm=0.97, clip=0, loss_scale=4, train_wall=99, gb_free=16.8, wall=4079
2023-07-02 07:19:00 | INFO | train_inner | epoch 004:    284 / 1474 loss=4.259, trans_loss=3.807, nll_loss=2.046, w2v_ctc_loss=1.63, task_loss=0.484, contrastive_loss=0.382, total=4145.23, n_correct=1947.52, ppl=4.13, accuracy=46.982, wps=12364, ups=1, wpb=12387.3, bsz=463, num_updates=4700, lr=0.000188006, gnorm=1.019, clip=0, loss_scale=4, train_wall=100, gb_free=16.1, wall=4179
2023-07-02 07:20:39 | INFO | train_inner | epoch 004:    384 / 1474 loss=4.216, trans_loss=3.803, nll_loss=2.039, w2v_ctc_loss=1.606, task_loss=0.484, contrastive_loss=0.218, total=4127.66, n_correct=1951.99, ppl=4.11, accuracy=47.29, wps=12420.4, ups=1.01, wpb=12298.8, bsz=443.5, num_updates=4800, lr=0.000192004, gnorm=0.922, clip=0, loss_scale=4, train_wall=99, gb_free=17.6, wall=4278
2023-07-02 07:22:20 | INFO | train_inner | epoch 004:    484 / 1474 loss=4.229, trans_loss=3.782, nll_loss=2.015, w2v_ctc_loss=1.564, task_loss=0.484, contrastive_loss=0.621, total=4218.78, n_correct=2029.84, ppl=4.04, accuracy=48.114, wps=12466.2, ups=0.99, wpb=12578.2, bsz=497.8, num_updates=4900, lr=0.000196002, gnorm=0.961, clip=0, loss_scale=4, train_wall=100, gb_free=16.7, wall=4379
2023-07-02 07:24:01 | INFO | train_inner | epoch 004:    584 / 1474 loss=4.194, trans_loss=3.777, nll_loss=2.009, w2v_ctc_loss=1.586, task_loss=0.484, contrastive_loss=0.293, total=4217.52, n_correct=2037.9, ppl=4.02, accuracy=48.32, wps=12518.8, ups=0.99, wpb=12583.6, bsz=485.9, num_updates=5000, lr=0.0002, gnorm=0.932, clip=0, loss_scale=4, train_wall=100, gb_free=16.3, wall=4480
tensor(0.8426, device='cuda:0')
tensor(0.7950, device='cuda:0')
2023-07-02 07:25:43 | INFO | train_inner | epoch 004:    684 / 1474 loss=4.176, trans_loss=3.78, nll_loss=2.007, w2v_ctc_loss=1.555, task_loss=0.484, contrastive_loss=0.336, total=4176.39, n_correct=2028.87, ppl=4.02, accuracy=48.58, wps=12211.5, ups=0.98, wpb=12440.1, bsz=455.8, num_updates=5100, lr=0.00019803, gnorm=0.804, clip=0, loss_scale=8, train_wall=101, gb_free=17.2, wall=4582
2023-07-02 07:27:22 | INFO | train_inner | epoch 004:    784 / 1474 loss=4.144, trans_loss=3.766, nll_loss=1.99, w2v_ctc_loss=1.545, task_loss=0.484, contrastive_loss=0.205, total=4026.63, n_correct=1971.27, ppl=3.97, accuracy=48.956, wps=12085.5, ups=1, wpb=12049.9, bsz=420.6, num_updates=5200, lr=0.000196116, gnorm=0.74, clip=0, loss_scale=8, train_wall=99, gb_free=13.5, wall=4681
2023-07-02 07:29:02 | INFO | train_inner | epoch 004:    884 / 1474 loss=4.141, trans_loss=3.749, nll_loss=1.973, w2v_ctc_loss=1.526, task_loss=0.484, contrastive_loss=0.379, total=4186.04, n_correct=2073.25, ppl=3.92, accuracy=49.528, wps=12474.9, ups=1, wpb=12493.4, bsz=466.3, num_updates=5300, lr=0.000194257, gnorm=0.71, clip=0, loss_scale=8, train_wall=100, gb_free=17.8, wall=4782
2023-07-02 07:30:42 | INFO | train_inner | epoch 004:    984 / 1474 loss=4.089, trans_loss=3.736, nll_loss=1.956, w2v_ctc_loss=1.495, task_loss=0.484, contrastive_loss=0.242, total=4125.02, n_correct=2068.03, ppl=3.88, accuracy=50.134, wps=12313.1, ups=1, wpb=12319.9, bsz=457.1, num_updates=5400, lr=0.00019245, gnorm=0.705, clip=0, loss_scale=8, train_wall=100, gb_free=13.1, wall=4882
2023-07-02 07:32:22 | INFO | train_inner | epoch 004:   1084 / 1474 loss=4.1, trans_loss=3.745, nll_loss=1.964, w2v_ctc_loss=1.502, task_loss=0.484, contrastive_loss=0.217, total=4075.6, n_correct=2036.96, ppl=3.9, accuracy=49.979, wps=12197.9, ups=1, wpb=12166.1, bsz=435.7, num_updates=5500, lr=0.000190693, gnorm=0.726, clip=0, loss_scale=8, train_wall=99, gb_free=16.2, wall=4981
2023-07-02 07:34:02 | INFO | train_inner | epoch 004:   1184 / 1474 loss=4.088, trans_loss=3.73, nll_loss=1.947, w2v_ctc_loss=1.474, task_loss=0.484, contrastive_loss=0.327, total=4161.18, n_correct=2111.64, ppl=3.86, accuracy=50.746, wps=12521.8, ups=1.01, wpb=12451.8, bsz=483.4, num_updates=5600, lr=0.000188982, gnorm=0.694, clip=0, loss_scale=8, train_wall=99, gb_free=16.9, wall=5081
2023-07-02 07:35:41 | INFO | train_inner | epoch 004:   1284 / 1474 loss=4.067, trans_loss=3.721, nll_loss=1.935, w2v_ctc_loss=1.457, task_loss=0.484, contrastive_loss=0.291, total=4156.53, n_correct=2127.45, ppl=3.82, accuracy=51.183, wps=12443.1, ups=1, wpb=12424.6, bsz=472.7, num_updates=5700, lr=0.000187317, gnorm=0.689, clip=0, loss_scale=8, train_wall=99, gb_free=16.2, wall=5181
2023-07-02 07:37:21 | INFO | train_inner | epoch 004:   1384 / 1474 loss=4.041, trans_loss=3.717, nll_loss=1.93, w2v_ctc_loss=1.458, task_loss=0.484, contrastive_loss=0.169, total=4101.23, n_correct=2098.85, ppl=3.81, accuracy=51.176, wps=12372.9, ups=1.01, wpb=12255, bsz=437.6, num_updates=5800, lr=0.000185695, gnorm=0.683, clip=0, loss_scale=8, train_wall=99, gb_free=15.9, wall=5280
2023-07-02 07:38:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.8426, device='cuda:4')
tensor(0.7950, device='cuda:4')
tensor(0.8426, device='cuda:5')
tensor(0.7950, device='cuda:5')
tensor(0.8426, device='cuda:7')
tensor(0.7950, device='cuda:7')
tensor(0.8426, device='cuda:2')
tensor(0.7950, device='cuda:2')
tensor(0.8426, device='cuda:1')
tensor(0.7950, device='cuda:1')
tensor(0.8426, device='cuda:3')
tensor(0.7950, device='cuda:3')
tensor(0.8426, device='cuda:6')
tensor(0.7950, device='cuda:6')
2023-07-02 07:39:20 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.812 | trans_loss 6.077 | nll_loss 3.519 | w2v_ctc_loss 1.714 | task_loss 0 | contrastive_loss 0.303 | total 4003.4 | n_correct 2161.8 | ppl 11.46 | accuracy 53.999 | uer 24.901 | wer 26.654 | raw_wer 26.654 | bleu 12.85 | wps 1725.6 | wpb 4003.4 | bsz 141.8 | num_updates 5890 | best_bleu 12.85
2023-07-02 07:39:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5890 updates
2023-07-02 07:39:20 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt
2023-07-02 07:39:24 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt
2023-07-02 07:39:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt (epoch 4 @ 5890 updates, score 12.85) (writing took 8.300191722344607 seconds)
2023-07-02 07:39:28 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-07-02 07:39:28 | INFO | train | epoch 004 | loss 4.152 | trans_loss 3.764 | nll_loss 1.99 | w2v_ctc_loss 1.542 | task_loss 0.484 | contrastive_loss 0.295 | total 4138.65 | n_correct 2029.5 | ppl 3.97 | accuracy 49.038 | wps 11995.8 | ups 0.97 | wpb 12355.8 | bsz 458.5 | num_updates 5890 | lr 0.000184271 | gnorm 0.816 | clip 0 | loss_scale 8 | train_wall 1466 | gb_free 15 | wall 5407
2023-07-02 07:39:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 07:39:28 | INFO | fairseq.trainer | begin training epoch 5
2023-07-02 07:39:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 07:39:47 | INFO | train_inner | epoch 005:     10 / 1474 loss=4.017, trans_loss=3.709, nll_loss=1.919, w2v_ctc_loss=1.428, task_loss=0.484, contrastive_loss=0.186, total=4037.7, n_correct=2083.4, ppl=3.78, accuracy=51.599, wps=8259.9, ups=0.68, wpb=12062.8, bsz=439.3, num_updates=5900, lr=0.000184115, gnorm=0.679, clip=0, loss_scale=8, train_wall=99, gb_free=17, wall=5426
2023-07-02 07:41:27 | INFO | train_inner | epoch 005:    110 / 1474 loss=3.921, trans_loss=3.656, nll_loss=1.851, w2v_ctc_loss=1.346, task_loss=0.484, contrastive_loss=0.194, total=4247.37, n_correct=2257.9, ppl=3.61, accuracy=53.16, wps=12633.6, ups=1, wpb=12683.8, bsz=495.1, num_updates=6000, lr=0.000182574, gnorm=0.654, clip=0, loss_scale=8, train_wall=100, gb_free=16.8, wall=5526
2023-07-02 07:41:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 07:41:57 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.767 | trans_loss 6.038 | nll_loss 3.457 | w2v_ctc_loss 1.654 | task_loss 0 | contrastive_loss 0.309 | total 4003.4 | n_correct 2185.4 | ppl 10.98 | accuracy 54.589 | uer 24.564 | wer 26.17 | raw_wer 26.17 | bleu 13.2 | wps 1719.7 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 13.2
2023-07-02 07:41:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-07-02 07:41:57 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_5_6000.pt
2023-07-02 07:42:00 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_5_6000.pt
2023-07-02 07:42:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 13.2) (writing took 9.226916875690222 seconds)
2023-07-02 07:43:46 | INFO | train_inner | epoch 005:    210 / 1474 loss=3.963, trans_loss=3.663, nll_loss=1.858, w2v_ctc_loss=1.361, task_loss=0.484, contrastive_loss=0.418, total=4189.85, n_correct=2222.77, ppl=3.63, accuracy=53.051, wps=9018, ups=0.72, wpb=12492.8, bsz=488.2, num_updates=6100, lr=0.000181071, gnorm=0.654, clip=0, loss_scale=8, train_wall=99, gb_free=17.9, wall=5665
2023-07-02 07:45:24 | INFO | train_inner | epoch 005:    310 / 1474 loss=3.958, trans_loss=3.662, nll_loss=1.86, w2v_ctc_loss=1.381, task_loss=0.484, contrastive_loss=0.263, total=4090.1, n_correct=2162.15, ppl=3.63, accuracy=52.863, wps=12378.5, ups=1.01, wpb=12240, bsz=443.9, num_updates=6200, lr=0.000179605, gnorm=0.678, clip=0, loss_scale=8, train_wall=98, gb_free=16.4, wall=5764
2023-07-02 07:47:04 | INFO | train_inner | epoch 005:    410 / 1474 loss=3.932, trans_loss=3.652, nll_loss=1.851, w2v_ctc_loss=1.335, task_loss=0.484, contrastive_loss=0.342, total=4147.17, n_correct=2211.81, ppl=3.61, accuracy=53.333, wps=12391.5, ups=1, wpb=12381.8, bsz=472.5, num_updates=6300, lr=0.000178174, gnorm=0.66, clip=0, loss_scale=8, train_wall=99, gb_free=15, wall=5864
2023-07-02 07:48:44 | INFO | train_inner | epoch 005:    510 / 1474 loss=3.924, trans_loss=3.665, nll_loss=1.861, w2v_ctc_loss=1.35, task_loss=0.484, contrastive_loss=0.136, total=4026.81, n_correct=2136.22, ppl=3.63, accuracy=53.05, wps=12105.4, ups=1, wpb=12047.2, bsz=416.6, num_updates=6400, lr=0.000176777, gnorm=0.653, clip=0, loss_scale=8, train_wall=99, gb_free=17.5, wall=5963
2023-07-02 07:50:24 | INFO | train_inner | epoch 005:    610 / 1474 loss=3.923, trans_loss=3.657, nll_loss=1.851, w2v_ctc_loss=1.33, task_loss=0.484, contrastive_loss=0.308, total=4107.75, n_correct=2190.1, ppl=3.61, accuracy=53.316, wps=12173.2, ups=0.99, wpb=12245.3, bsz=451.2, num_updates=6500, lr=0.000175412, gnorm=0.668, clip=0, loss_scale=8, train_wall=100, gb_free=16.3, wall=6064
2023-07-02 07:52:04 | INFO | train_inner | epoch 005:    710 / 1474 loss=3.927, trans_loss=3.652, nll_loss=1.847, w2v_ctc_loss=1.339, task_loss=0.484, contrastive_loss=0.288, total=4178.85, n_correct=2233.32, ppl=3.6, accuracy=53.443, wps=12487.7, ups=1, wpb=12462.3, bsz=480.9, num_updates=6600, lr=0.000174078, gnorm=0.659, clip=0, loss_scale=8, train_wall=99, gb_free=17.8, wall=6163
2023-07-02 07:53:45 | INFO | train_inner | epoch 005:    810 / 1474 loss=3.914, trans_loss=3.653, nll_loss=1.847, w2v_ctc_loss=1.328, task_loss=0.484, contrastive_loss=0.214, total=4127.73, n_correct=2211.95, ppl=3.6, accuracy=53.588, wps=12235.8, ups=0.99, wpb=12320.4, bsz=449.2, num_updates=6700, lr=0.000172774, gnorm=0.649, clip=0, loss_scale=8, train_wall=100, gb_free=15.4, wall=6264
2023-07-02 07:55:24 | INFO | train_inner | epoch 005:    910 / 1474 loss=3.891, trans_loss=3.648, nll_loss=1.842, w2v_ctc_loss=1.316, task_loss=0.484, contrastive_loss=0.174, total=4095.48, n_correct=2202.63, ppl=3.58, accuracy=53.782, wps=12297.8, ups=1, wpb=12237.9, bsz=445.3, num_updates=6800, lr=0.000171499, gnorm=0.651, clip=0, loss_scale=8, train_wall=99, gb_free=15.8, wall=6364
2023-07-02 07:57:04 | INFO | train_inner | epoch 005:   1010 / 1474 loss=3.907, trans_loss=3.651, nll_loss=1.846, w2v_ctc_loss=1.321, task_loss=0.484, contrastive_loss=0.254, total=4165.12, n_correct=2244.32, ppl=3.6, accuracy=53.884, wps=12514.7, ups=1.01, wpb=12426.3, bsz=463.5, num_updates=6900, lr=0.000170251, gnorm=0.638, clip=0, loss_scale=8, train_wall=99, gb_free=15.9, wall=6463
2023-07-02 07:58:44 | INFO | train_inner | epoch 005:   1110 / 1474 loss=3.911, trans_loss=3.648, nll_loss=1.839, w2v_ctc_loss=1.318, task_loss=0.484, contrastive_loss=0.261, total=4176.72, n_correct=2260.32, ppl=3.58, accuracy=54.117, wps=12399.1, ups=0.99, wpb=12467.3, bsz=466.1, num_updates=7000, lr=0.000169031, gnorm=0.638, clip=0, loss_scale=8, train_wall=100, gb_free=16.9, wall=6564
2023-07-02 08:00:25 | INFO | train_inner | epoch 005:   1210 / 1474 loss=3.878, trans_loss=3.645, nll_loss=1.837, w2v_ctc_loss=1.3, task_loss=0.484, contrastive_loss=0.159, total=4164.13, n_correct=2257.66, ppl=3.57, accuracy=54.217, wps=12385.2, ups=1, wpb=12416.1, bsz=453.8, num_updates=7100, lr=0.000167836, gnorm=0.639, clip=0, loss_scale=8, train_wall=100, gb_free=17.1, wall=6664
2023-07-02 08:02:05 | INFO | train_inner | epoch 005:   1310 / 1474 loss=3.861, trans_loss=3.639, nll_loss=1.828, w2v_ctc_loss=1.284, task_loss=0.484, contrastive_loss=0.129, total=4134.91, n_correct=2250.22, ppl=3.55, accuracy=54.42, wps=12342.6, ups=1, wpb=12356.4, bsz=445.6, num_updates=7200, lr=0.000166667, gnorm=0.632, clip=0, loss_scale=16, train_wall=100, gb_free=16.6, wall=6764
2023-07-02 08:03:45 | INFO | train_inner | epoch 005:   1410 / 1474 loss=3.861, trans_loss=3.632, nll_loss=1.825, w2v_ctc_loss=1.286, task_loss=0.484, contrastive_loss=0.192, total=4134.37, n_correct=2245.89, ppl=3.54, accuracy=54.322, wps=12363.8, ups=1, wpb=12339.9, bsz=458.5, num_updates=7300, lr=0.000165521, gnorm=0.637, clip=0, loss_scale=16, train_wall=99, gb_free=17.9, wall=6864
2023-07-02 08:04:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 08:05:19 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.701 | trans_loss 5.991 | nll_loss 3.4 | w2v_ctc_loss 1.549 | task_loss 0 | contrastive_loss 0.294 | total 4003.4 | n_correct 2220 | ppl 10.56 | accuracy 55.453 | uer 23.914 | wer 25.555 | raw_wer 25.555 | bleu 14.26 | wps 1652.4 | wpb 4003.4 | bsz 141.8 | num_updates 7364 | best_bleu 14.26
2023-07-02 08:05:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7364 updates
2023-07-02 08:05:19 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt
2023-07-02 08:05:23 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt
2023-07-02 08:05:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt (epoch 5 @ 7364 updates, score 14.26) (writing took 8.18914961302653 seconds)
2023-07-02 08:05:28 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-07-02 08:05:28 | INFO | train | epoch 005 | loss 3.911 | trans_loss 3.651 | nll_loss 1.845 | w2v_ctc_loss 1.327 | task_loss 0.484 | contrastive_loss 0.238 | total 4138.65 | n_correct 2220.48 | ppl 3.59 | accuracy 53.652 | wps 11678 | ups 0.95 | wpb 12355.8 | bsz 458.5 | num_updates 7364 | lr 0.0001648 | gnorm 0.651 | clip 0 | loss_scale 16 | train_wall 1466 | gb_free 16.4 | wall 6967
2023-07-02 08:05:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 08:05:28 | INFO | fairseq.trainer | begin training epoch 6
2023-07-02 08:05:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 08:06:13 | INFO | train_inner | epoch 006:     36 / 1474 loss=3.841, trans_loss=3.616, nll_loss=1.8, w2v_ctc_loss=1.269, task_loss=0.484, contrastive_loss=0.188, total=4115.45, n_correct=2268.98, ppl=3.48, accuracy=55.133, wps=8291.4, ups=0.68, wpb=12279.2, bsz=447.9, num_updates=7400, lr=0.000164399, gnorm=0.649, clip=0, loss_scale=16, train_wall=100, gb_free=16.6, wall=7012
2023-07-02 08:07:53 | INFO | train_inner | epoch 006:    136 / 1474 loss=3.787, trans_loss=3.591, nll_loss=1.768, w2v_ctc_loss=1.216, task_loss=0.484, contrastive_loss=0.233, total=4154.25, n_correct=2312.28, ppl=3.41, accuracy=55.661, wps=12423.7, ups=1, wpb=12409.6, bsz=456.1, num_updates=7500, lr=0.000163299, gnorm=0.631, clip=0, loss_scale=16, train_wall=99, gb_free=15.7, wall=7112
2023-07-02 08:09:32 | INFO | train_inner | epoch 006:    236 / 1474 loss=3.805, trans_loss=3.599, nll_loss=1.781, w2v_ctc_loss=1.255, task_loss=0.484, contrastive_loss=0.141, total=4112.66, n_correct=2271.64, ppl=3.44, accuracy=55.235, wps=12325.9, ups=1, wpb=12281.7, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.637, clip=0, loss_scale=16, train_wall=99, gb_free=16.3, wall=7211
2023-07-02 08:11:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-02 08:11:14 | INFO | train_inner | epoch 006:    337 / 1474 loss=3.79, trans_loss=3.587, nll_loss=1.765, w2v_ctc_loss=1.212, task_loss=0.484, contrastive_loss=0.297, total=4140.92, n_correct=2319.19, ppl=3.4, accuracy=56.007, wps=12109.7, ups=0.98, wpb=12362.4, bsz=473.5, num_updates=7700, lr=0.000161165, gnorm=0.628, clip=0, loss_scale=8, train_wall=102, gb_free=15.8, wall=7313
2023-07-02 08:12:53 | INFO | train_inner | epoch 006:    437 / 1474 loss=3.773, trans_loss=3.59, nll_loss=1.769, w2v_ctc_loss=1.212, task_loss=0.484, contrastive_loss=0.154, total=4154.89, n_correct=2325.99, ppl=3.41, accuracy=55.982, wps=12530.9, ups=1.01, wpb=12406.7, bsz=470.4, num_updates=7800, lr=0.000160128, gnorm=0.629, clip=0, loss_scale=8, train_wall=99, gb_free=16.6, wall=7412
2023-07-02 08:14:34 | INFO | train_inner | epoch 006:    537 / 1474 loss=3.775, trans_loss=3.59, nll_loss=1.769, w2v_ctc_loss=1.22, task_loss=0.484, contrastive_loss=0.142, total=4174.46, n_correct=2334.54, ppl=3.41, accuracy=55.924, wps=12329.1, ups=0.99, wpb=12441.4, bsz=458.3, num_updates=7900, lr=0.000159111, gnorm=0.627, clip=0, loss_scale=8, train_wall=100, gb_free=17.3, wall=7513
2023-07-02 08:16:14 | INFO | train_inner | epoch 006:    637 / 1474 loss=3.777, trans_loss=3.593, nll_loss=1.769, w2v_ctc_loss=1.204, task_loss=0.484, contrastive_loss=0.198, total=4145.19, n_correct=2318.28, ppl=3.41, accuracy=55.927, wps=12471.3, ups=1.01, wpb=12391.8, bsz=470.9, num_updates=8000, lr=0.000158114, gnorm=0.654, clip=0, loss_scale=8, train_wall=99, gb_free=16, wall=7613
2023-07-02 08:16:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 08:16:43 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.607 | trans_loss 5.876 | nll_loss 3.249 | w2v_ctc_loss 1.515 | task_loss 0 | contrastive_loss 0.283 | total 4003.4 | n_correct 2280.1 | ppl 9.51 | accuracy 56.954 | uer 21.639 | wer 23.456 | raw_wer 23.456 | bleu 14.72 | wps 1747.9 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 14.72
2023-07-02 08:16:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-07-02 08:16:43 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_6_8000.pt
2023-07-02 08:16:45 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_6_8000.pt
2023-07-02 08:16:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 14.72) (writing took 8.805303440894932 seconds)
2023-07-02 08:18:33 | INFO | train_inner | epoch 006:    737 / 1474 loss=3.787, trans_loss=3.595, nll_loss=1.775, w2v_ctc_loss=1.226, task_loss=0.484, contrastive_loss=0.152, total=4151.01, n_correct=2321.66, ppl=3.42, accuracy=55.93, wps=8900.9, ups=0.72, wpb=12384.3, bsz=454.2, num_updates=8100, lr=0.000157135, gnorm=0.628, clip=0, loss_scale=8, train_wall=100, gb_free=13.2, wall=7752
2023-07-02 08:20:13 | INFO | train_inner | epoch 006:    837 / 1474 loss=3.778, trans_loss=3.599, nll_loss=1.779, w2v_ctc_loss=1.21, task_loss=0.484, contrastive_loss=0.134, total=4108.83, n_correct=2290.42, ppl=3.43, accuracy=55.744, wps=12295.2, ups=1, wpb=12275.7, bsz=439.4, num_updates=8200, lr=0.000156174, gnorm=0.627, clip=0, loss_scale=8, train_wall=99, gb_free=17.2, wall=7852
2023-07-02 08:21:52 | INFO | train_inner | epoch 006:    937 / 1474 loss=3.795, trans_loss=3.597, nll_loss=1.778, w2v_ctc_loss=1.221, task_loss=0.484, contrastive_loss=0.233, total=4076.46, n_correct=2273.91, ppl=3.43, accuracy=55.781, wps=12183.9, ups=1, wpb=12153.2, bsz=443, num_updates=8300, lr=0.00015523, gnorm=0.64, clip=0, loss_scale=8, train_wall=99, gb_free=12.9, wall=7951
2023-07-02 08:23:32 | INFO | train_inner | epoch 006:   1037 / 1474 loss=3.789, trans_loss=3.589, nll_loss=1.767, w2v_ctc_loss=1.202, task_loss=0.484, contrastive_loss=0.307, total=4175.9, n_correct=2348.73, ppl=3.4, accuracy=56.245, wps=12491.1, ups=1, wpb=12465.4, bsz=480.4, num_updates=8400, lr=0.000154303, gnorm=0.643, clip=0, loss_scale=8, train_wall=99, gb_free=14.4, wall=8051
2023-07-02 08:25:12 | INFO | train_inner | epoch 006:   1137 / 1474 loss=3.775, trans_loss=3.594, nll_loss=1.773, w2v_ctc_loss=1.208, task_loss=0.484, contrastive_loss=0.138, total=4077.2, n_correct=2283.32, ppl=3.42, accuracy=56.002, wps=12245.9, ups=1.01, wpb=12179.9, bsz=430.6, num_updates=8500, lr=0.000153393, gnorm=0.622, clip=0, loss_scale=8, train_wall=99, gb_free=16.4, wall=8151
2023-07-02 08:26:53 | INFO | train_inner | epoch 006:   1237 / 1474 loss=3.797, trans_loss=3.587, nll_loss=1.766, w2v_ctc_loss=1.188, task_loss=0.484, contrastive_loss=0.451, total=4133.46, n_correct=2325.46, ppl=3.4, accuracy=56.259, wps=12236.3, ups=0.99, wpb=12360.6, bsz=470.3, num_updates=8600, lr=0.000152499, gnorm=0.624, clip=0, loss_scale=8, train_wall=101, gb_free=12.6, wall=8252
2023-07-02 08:28:32 | INFO | train_inner | epoch 006:   1337 / 1474 loss=3.757, trans_loss=3.594, nll_loss=1.77, w2v_ctc_loss=1.189, task_loss=0.484, contrastive_loss=0.122, total=4127.77, n_correct=2328.69, ppl=3.41, accuracy=56.415, wps=12412.6, ups=1.01, wpb=12325.7, bsz=454.1, num_updates=8700, lr=0.00015162, gnorm=0.622, clip=0, loss_scale=8, train_wall=99, gb_free=17.1, wall=8351
2023-07-02 08:30:12 | INFO | train_inner | epoch 006:   1437 / 1474 loss=3.754, trans_loss=3.582, nll_loss=1.76, w2v_ctc_loss=1.195, task_loss=0.484, contrastive_loss=0.13, total=4190.32, n_correct=2373.59, ppl=3.39, accuracy=56.645, wps=12515.1, ups=1, wpb=12495.5, bsz=460.5, num_updates=8800, lr=0.000150756, gnorm=0.614, clip=0, loss_scale=8, train_wall=99, gb_free=17, wall=8451
2023-07-02 08:30:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 08:31:16 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.522 | trans_loss 5.803 | nll_loss 3.141 | w2v_ctc_loss 1.405 | task_loss 0 | contrastive_loss 0.273 | total 4003.4 | n_correct 2332.3 | ppl 8.82 | accuracy 58.258 | uer 20.102 | wer 21.834 | raw_wer 21.834 | bleu 16.07 | wps 1951 | wpb 4003.4 | bsz 141.8 | num_updates 8837 | best_bleu 16.07
2023-07-02 08:31:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8837 updates
2023-07-02 08:31:16 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt
2023-07-02 08:31:20 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt
2023-07-02 08:31:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt (epoch 6 @ 8837 updates, score 16.07) (writing took 8.157662997022271 seconds)
2023-07-02 08:31:24 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-07-02 08:31:24 | INFO | train | epoch 006 | loss 3.78 | trans_loss 3.591 | nll_loss 1.77 | w2v_ctc_loss 1.21 | task_loss 0.484 | contrastive_loss 0.201 | total 4136.5 | n_correct 2316.46 | ppl 3.41 | accuracy 56.001 | wps 11684.7 | ups 0.95 | wpb 12349.9 | bsz 457.4 | num_updates 8837 | lr 0.00015044 | gnorm 0.63 | clip 0 | loss_scale 8 | train_wall 1466 | gb_free 15.3 | wall 8524
2023-07-02 08:31:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 08:31:25 | INFO | fairseq.trainer | begin training epoch 7
2023-07-02 08:31:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 08:32:36 | INFO | train_inner | epoch 007:     63 / 1474 loss=3.705, trans_loss=3.557, nll_loss=1.726, w2v_ctc_loss=1.151, task_loss=0.484, contrastive_loss=0.145, total=4110.43, n_correct=2345.7, ppl=3.31, accuracy=57.067, wps=8513.1, ups=0.69, wpb=12276.6, bsz=462.8, num_updates=8900, lr=0.000149906, gnorm=0.616, clip=0, loss_scale=8, train_wall=99, gb_free=17.5, wall=8595
2023-07-02 08:34:15 | INFO | train_inner | epoch 007:    163 / 1474 loss=3.697, trans_loss=3.551, nll_loss=1.719, w2v_ctc_loss=1.136, task_loss=0.484, contrastive_loss=0.217, total=4109.53, n_correct=2354.78, ppl=3.29, accuracy=57.3, wps=12326.8, ups=1.01, wpb=12264.3, bsz=454.1, num_updates=9000, lr=0.000149071, gnorm=0.616, clip=0, loss_scale=8, train_wall=99, gb_free=13.9, wall=8695
2023-07-02 08:35:55 | INFO | train_inner | epoch 007:    263 / 1474 loss=3.688, trans_loss=3.548, nll_loss=1.713, w2v_ctc_loss=1.14, task_loss=0.484, contrastive_loss=0.126, total=4133.29, n_correct=2378.94, ppl=3.28, accuracy=57.556, wps=12392.6, ups=1, wpb=12339.3, bsz=455.5, num_updates=9100, lr=0.00014825, gnorm=0.613, clip=0, loss_scale=8, train_wall=99, gb_free=15.5, wall=8794
2023-07-02 08:37:35 | INFO | train_inner | epoch 007:    363 / 1474 loss=3.715, trans_loss=3.554, nll_loss=1.722, w2v_ctc_loss=1.13, task_loss=0.484, contrastive_loss=0.388, total=4194.76, n_correct=2399.79, ppl=3.3, accuracy=57.209, wps=12454.6, ups=1, wpb=12509.7, bsz=477.6, num_updates=9200, lr=0.000147442, gnorm=0.615, clip=0, loss_scale=8, train_wall=100, gb_free=13.3, wall=8895
2023-07-02 08:39:16 | INFO | train_inner | epoch 007:    463 / 1474 loss=3.712, trans_loss=3.553, nll_loss=1.724, w2v_ctc_loss=1.137, task_loss=0.484, contrastive_loss=0.307, total=4153.22, n_correct=2375.2, ppl=3.3, accuracy=57.189, wps=12306.4, ups=0.99, wpb=12386.6, bsz=463, num_updates=9300, lr=0.000146647, gnorm=0.619, clip=0, loss_scale=8, train_wall=100, gb_free=16.9, wall=8995
2023-07-02 08:40:56 | INFO | train_inner | epoch 007:    563 / 1474 loss=3.688, trans_loss=3.552, nll_loss=1.721, w2v_ctc_loss=1.137, task_loss=0.484, contrastive_loss=0.133, total=4168.14, n_correct=2395.03, ppl=3.3, accuracy=57.46, wps=12421.2, ups=1, wpb=12410.5, bsz=459.8, num_updates=9400, lr=0.000145865, gnorm=0.607, clip=0, loss_scale=8, train_wall=99, gb_free=17, wall=9095
2023-07-02 08:42:36 | INFO | train_inner | epoch 007:    663 / 1474 loss=3.681, trans_loss=3.555, nll_loss=1.72, w2v_ctc_loss=1.122, task_loss=0.484, contrastive_loss=0.12, total=4157.82, n_correct=2395.95, ppl=3.29, accuracy=57.625, wps=12435.5, ups=1, wpb=12417.8, bsz=455.4, num_updates=9500, lr=0.000145095, gnorm=0.609, clip=0, loss_scale=8, train_wall=99, gb_free=15.8, wall=9195
2023-07-02 08:44:16 | INFO | train_inner | epoch 007:    763 / 1474 loss=3.695, trans_loss=3.556, nll_loss=1.724, w2v_ctc_loss=1.136, task_loss=0.484, contrastive_loss=0.117, total=4122.1, n_correct=2366.42, ppl=3.3, accuracy=57.408, wps=12310.3, ups=1, wpb=12321.9, bsz=446.2, num_updates=9600, lr=0.000144338, gnorm=0.62, clip=0, loss_scale=8, train_wall=100, gb_free=15.8, wall=9295
2023-07-02 08:45:57 | INFO | train_inner | epoch 007:    863 / 1474 loss=3.688, trans_loss=3.552, nll_loss=1.719, w2v_ctc_loss=1.129, task_loss=0.484, contrastive_loss=0.137, total=4147.23, n_correct=2386.81, ppl=3.29, accuracy=57.552, wps=12332.3, ups=1, wpb=12392, bsz=460.9, num_updates=9700, lr=0.000143592, gnorm=0.623, clip=0, loss_scale=8, train_wall=100, gb_free=17.6, wall=9396
2023-07-02 08:47:36 | INFO | train_inner | epoch 007:    963 / 1474 loss=3.695, trans_loss=3.551, nll_loss=1.72, w2v_ctc_loss=1.121, task_loss=0.484, contrastive_loss=0.233, total=4140.14, n_correct=2390.98, ppl=3.29, accuracy=57.751, wps=12369, ups=1, wpb=12360, bsz=474.6, num_updates=9800, lr=0.000142857, gnorm=0.62, clip=0, loss_scale=16, train_wall=99, gb_free=16.1, wall=9496
2023-07-02 08:49:17 | INFO | train_inner | epoch 007:   1063 / 1474 loss=3.69, trans_loss=3.559, nll_loss=1.729, w2v_ctc_loss=1.133, task_loss=0.484, contrastive_loss=0.101, total=4103.51, n_correct=2358.52, ppl=3.31, accuracy=57.476, wps=12252.4, ups=1, wpb=12263.4, bsz=437.5, num_updates=9900, lr=0.000142134, gnorm=0.611, clip=0, loss_scale=16, train_wall=100, gb_free=17, wall=9596
2023-07-02 08:50:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-02 08:50:58 | INFO | train_inner | epoch 007:   1164 / 1474 loss=3.691, trans_loss=3.548, nll_loss=1.719, w2v_ctc_loss=1.127, task_loss=0.484, contrastive_loss=0.209, total=4116.21, n_correct=2373.7, ppl=3.29, accuracy=57.667, wps=12082.4, ups=0.98, wpb=12295.8, bsz=459.8, num_updates=10000, lr=0.000141421, gnorm=0.621, clip=0, loss_scale=8, train_wall=101, gb_free=16.7, wall=9697
2023-07-02 08:50:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 08:51:28 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.488 | trans_loss 5.759 | nll_loss 3.084 | w2v_ctc_loss 1.401 | task_loss 0 | contrastive_loss 0.269 | total 4003.4 | n_correct 2357.7 | ppl 8.48 | accuracy 58.892 | uer 19.176 | wer 20.995 | raw_wer 20.995 | bleu 17.11 | wps 1791.8 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 17.11
2023-07-02 08:51:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-07-02 08:51:28 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_7_10000.pt
2023-07-02 08:51:30 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_7_10000.pt
2023-07-02 08:51:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 17.11) (writing took 9.141018808819354 seconds)
tensor(0.5797, device='cuda:0')
tensor(0.4823, device='cuda:0')
2023-07-02 08:53:17 | INFO | train_inner | epoch 007:   1264 / 1474 loss=3.67, trans_loss=3.546, nll_loss=1.715, w2v_ctc_loss=1.115, task_loss=0.484, contrastive_loss=0.127, total=4129.16, n_correct=2381.35, ppl=3.28, accuracy=57.672, wps=8899.7, ups=0.72, wpb=12327, bsz=448.9, num_updates=10100, lr=0.00014072, gnorm=0.462, clip=0, loss_scale=8, train_wall=100, gb_free=16.9, wall=9836
2023-07-02 08:54:56 | INFO | train_inner | epoch 007:   1364 / 1474 loss=3.681, trans_loss=3.542, nll_loss=1.71, w2v_ctc_loss=1.125, task_loss=0.484, contrastive_loss=0.166, total=4177.71, n_correct=2423.14, ppl=3.27, accuracy=58.002, wps=12541.1, ups=1.01, wpb=12468.2, bsz=478.6, num_updates=10200, lr=0.000140028, gnorm=0.465, clip=0, loss_scale=8, train_wall=99, gb_free=17, wall=9935
2023-07-02 08:56:38 | INFO | train_inner | epoch 007:   1464 / 1474 loss=3.699, trans_loss=3.554, nll_loss=1.725, w2v_ctc_loss=1.125, task_loss=0.484, contrastive_loss=0.23, total=4107.01, n_correct=2365.89, ppl=3.31, accuracy=57.606, wps=12108.8, ups=0.99, wpb=12279.4, bsz=442.8, num_updates=10300, lr=0.000139347, gnorm=0.476, clip=0, loss_scale=8, train_wall=101, gb_free=13.5, wall=10037
2023-07-02 08:56:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.5797, device='cuda:4')
tensor(0.4823, device='cuda:4')
tensor(0.5797, device='cuda:6')
tensor(0.4823, device='cuda:6')
tensor(0.5797, device='cuda:7')
tensor(0.4823, device='cuda:7')
tensor(0.5797, device='cuda:5')
tensor(0.4823, device='cuda:5')
tensor(0.5797, device='cuda:2')
tensor(0.4823, device='cuda:2')
tensor(0.5797, device='cuda:3')
tensor(0.4823, device='cuda:3')
tensor(0.5797, device='cuda:1')
tensor(0.4823, device='cuda:1')
2023-07-02 08:57:17 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.484 | trans_loss 5.755 | nll_loss 3.088 | w2v_ctc_loss 1.397 | task_loss 0 | contrastive_loss 0.26 | total 4003.4 | n_correct 2356.1 | ppl 8.5 | accuracy 58.852 | uer 19.425 | wer 21.222 | raw_wer 21.222 | bleu 16.62 | wps 1770.9 | wpb 4003.4 | bsz 141.8 | num_updates 10310 | best_bleu 17.11
2023-07-02 08:57:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10310 updates
2023-07-02 08:57:17 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_16.6201.pt
2023-07-02 08:57:19 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_16.6201.pt
2023-07-02 08:57:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_16.6201.pt (epoch 7 @ 10310 updates, score 16.62) (writing took 5.24960514716804 seconds)
2023-07-02 08:57:22 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-07-02 08:57:22 | INFO | train | epoch 007 | loss 3.692 | trans_loss 3.551 | nll_loss 1.72 | w2v_ctc_loss 1.13 | task_loss 0.484 | contrastive_loss 0.185 | total 4137.25 | n_correct 2379.79 | ppl 3.29 | accuracy 57.521 | wps 11679.1 | ups 0.95 | wpb 12352.3 | bsz 457.8 | num_updates 10310 | lr 0.000139279 | gnorm 0.585 | clip 0 | loss_scale 8 | train_wall 1469 | gb_free 13.5 | wall 10081
2023-07-02 08:57:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 08:57:23 | INFO | fairseq.trainer | begin training epoch 8
2023-07-02 08:57:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 08:59:01 | INFO | train_inner | epoch 008:     90 / 1474 loss=3.629, trans_loss=3.525, nll_loss=1.682, w2v_ctc_loss=1.081, task_loss=0.484, contrastive_loss=0.123, total=4106.01, n_correct=2398.16, ppl=3.21, accuracy=58.406, wps=8549.5, ups=0.7, wpb=12235.6, bsz=440.9, num_updates=10400, lr=0.000138675, gnorm=0.465, clip=0, loss_scale=8, train_wall=99, gb_free=17.2, wall=10180
2023-07-02 09:00:40 | INFO | train_inner | epoch 008:    190 / 1474 loss=3.637, trans_loss=3.526, nll_loss=1.684, w2v_ctc_loss=1.082, task_loss=0.484, contrastive_loss=0.145, total=4043.12, n_correct=2370.25, ppl=3.21, accuracy=58.624, wps=12111.9, ups=1, wpb=12051.9, bsz=430, num_updates=10500, lr=0.000138013, gnorm=0.474, clip=0, loss_scale=8, train_wall=99, gb_free=13.5, wall=10279
2023-07-02 09:02:20 | INFO | train_inner | epoch 008:    290 / 1474 loss=3.616, trans_loss=3.516, nll_loss=1.673, w2v_ctc_loss=1.066, task_loss=0.484, contrastive_loss=0.143, total=4207.9, n_correct=2476.92, ppl=3.19, accuracy=58.864, wps=12627.1, ups=1, wpb=12570.8, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.457, clip=0, loss_scale=8, train_wall=99, gb_free=14.3, wall=10379
2023-07-02 09:04:01 | INFO | train_inner | epoch 008:    390 / 1474 loss=3.649, trans_loss=3.526, nll_loss=1.685, w2v_ctc_loss=1.097, task_loss=0.484, contrastive_loss=0.166, total=4134.6, n_correct=2411.78, ppl=3.22, accuracy=58.332, wps=12223.8, ups=0.99, wpb=12336.1, bsz=444.7, num_updates=10700, lr=0.000136717, gnorm=0.516, clip=0, loss_scale=8, train_wall=100, gb_free=17.4, wall=10480
2023-07-02 09:05:42 | INFO | train_inner | epoch 008:    490 / 1474 loss=3.67, trans_loss=3.524, nll_loss=1.684, w2v_ctc_loss=1.071, task_loss=0.484, contrastive_loss=0.433, total=4196.6, n_correct=2460.58, ppl=3.21, accuracy=58.633, wps=12421.7, ups=0.99, wpb=12551.9, bsz=501.4, num_updates=10800, lr=0.000136083, gnorm=0.483, clip=0, loss_scale=8, train_wall=101, gb_free=13.2, wall=10581
2023-07-02 09:07:22 | INFO | train_inner | epoch 008:    590 / 1474 loss=3.628, trans_loss=3.523, nll_loss=1.684, w2v_ctc_loss=1.081, task_loss=0.484, contrastive_loss=0.097, total=4065.55, n_correct=2375.89, ppl=3.21, accuracy=58.44, wps=12127.3, ups=1, wpb=12176.4, bsz=428.3, num_updates=10900, lr=0.000135457, gnorm=0.466, clip=0, loss_scale=8, train_wall=100, gb_free=16.3, wall=10681
2023-07-02 09:09:03 | INFO | train_inner | epoch 008:    690 / 1474 loss=3.63, trans_loss=3.519, nll_loss=1.68, w2v_ctc_loss=1.09, task_loss=0.484, contrastive_loss=0.11, total=4135.41, n_correct=2434, ppl=3.2, accuracy=58.858, wps=12295.4, ups=1, wpb=12330.3, bsz=447.2, num_updates=11000, lr=0.00013484, gnorm=0.465, clip=0, loss_scale=8, train_wall=100, gb_free=16.2, wall=10782
2023-07-02 09:10:42 | INFO | train_inner | epoch 008:    790 / 1474 loss=3.631, trans_loss=3.516, nll_loss=1.677, w2v_ctc_loss=1.075, task_loss=0.484, contrastive_loss=0.198, total=4128.86, n_correct=2428.59, ppl=3.2, accuracy=58.82, wps=12455.6, ups=1.01, wpb=12353.8, bsz=452.1, num_updates=11100, lr=0.000134231, gnorm=0.471, clip=0, loss_scale=8, train_wall=99, gb_free=16.6, wall=10881
2023-07-02 09:12:22 | INFO | train_inner | epoch 008:    890 / 1474 loss=3.628, trans_loss=3.519, nll_loss=1.681, w2v_ctc_loss=1.065, task_loss=0.484, contrastive_loss=0.206, total=4166.92, n_correct=2451.25, ppl=3.21, accuracy=58.826, wps=12421.7, ups=1, wpb=12450.6, bsz=471.5, num_updates=11200, lr=0.000133631, gnorm=0.462, clip=0, loss_scale=8, train_wall=100, gb_free=14.7, wall=10981
2023-07-02 09:14:01 | INFO | train_inner | epoch 008:    990 / 1474 loss=3.607, trans_loss=3.515, nll_loss=1.674, w2v_ctc_loss=1.063, task_loss=0.484, contrastive_loss=0.107, total=4150.39, n_correct=2447.96, ppl=3.19, accuracy=58.981, wps=12469.7, ups=1.01, wpb=12385.2, bsz=462.8, num_updates=11300, lr=0.000133038, gnorm=0.462, clip=0, loss_scale=8, train_wall=99, gb_free=17.4, wall=11080
2023-07-02 09:15:43 | INFO | train_inner | epoch 008:   1090 / 1474 loss=3.641, trans_loss=3.52, nll_loss=1.681, w2v_ctc_loss=1.067, task_loss=0.484, contrastive_loss=0.331, total=4197.39, n_correct=2459.63, ppl=3.21, accuracy=58.599, wps=12339.3, ups=0.99, wpb=12518.1, bsz=466.4, num_updates=11400, lr=0.000132453, gnorm=0.461, clip=0, loss_scale=8, train_wall=101, gb_free=16.9, wall=11182
2023-07-02 09:17:23 | INFO | train_inner | epoch 008:   1190 / 1474 loss=3.619, trans_loss=3.519, nll_loss=1.681, w2v_ctc_loss=1.071, task_loss=0.484, contrastive_loss=0.117, total=4180.55, n_correct=2462.46, ppl=3.21, accuracy=58.903, wps=12435.2, ups=1, wpb=12486.6, bsz=472.7, num_updates=11500, lr=0.000131876, gnorm=0.463, clip=0, loss_scale=8, train_wall=100, gb_free=17.4, wall=11282
2023-07-02 09:19:02 | INFO | train_inner | epoch 008:   1290 / 1474 loss=3.628, trans_loss=3.52, nll_loss=1.682, w2v_ctc_loss=1.079, task_loss=0.484, contrastive_loss=0.138, total=4062.6, n_correct=2385.87, ppl=3.21, accuracy=58.728, wps=12235.8, ups=1.01, wpb=12134.6, bsz=437.8, num_updates=11600, lr=0.000131306, gnorm=0.476, clip=0, loss_scale=8, train_wall=99, gb_free=13.4, wall=11382
2023-07-02 09:20:42 | INFO | train_inner | epoch 008:   1390 / 1474 loss=3.633, trans_loss=3.52, nll_loss=1.685, w2v_ctc_loss=1.071, task_loss=0.484, contrastive_loss=0.207, total=4159.11, n_correct=2450.07, ppl=3.22, accuracy=58.909, wps=12504.6, ups=1.01, wpb=12403.4, bsz=468.7, num_updates=11700, lr=0.000130744, gnorm=0.462, clip=0, loss_scale=8, train_wall=99, gb_free=13.5, wall=11481
2023-07-02 09:22:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 09:22:34 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.435 | trans_loss 5.707 | nll_loss 3.016 | w2v_ctc_loss 1.351 | task_loss 0 | contrastive_loss 0.258 | total 4003.4 | n_correct 2393 | ppl 8.09 | accuracy 59.774 | uer 18.483 | wer 20.413 | raw_wer 20.413 | bleu 17.07 | wps 1907.8 | wpb 4003.4 | bsz 141.8 | num_updates 11784 | best_bleu 17.11
2023-07-02 09:22:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11784 updates
2023-07-02 09:22:34 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_17.0709.pt
2023-07-02 09:22:36 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_17.0709.pt
2023-07-02 09:22:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_17.0709.pt (epoch 8 @ 11784 updates, score 17.07) (writing took 5.207820051815361 seconds)
2023-07-02 09:22:39 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-07-02 09:22:39 | INFO | train | epoch 008 | loss 3.631 | trans_loss 3.52 | nll_loss 1.681 | w2v_ctc_loss 1.075 | task_loss 0.484 | contrastive_loss 0.186 | total 4138.65 | n_correct 2430.73 | ppl 3.21 | accuracy 58.732 | wps 12009 | ups 0.97 | wpb 12355.8 | bsz 458.5 | num_updates 11784 | lr 0.000130277 | gnorm 0.47 | clip 0 | loss_scale 8 | train_wall 1468 | gb_free 17.1 | wall 11598
2023-07-02 09:22:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 09:22:39 | INFO | fairseq.trainer | begin training epoch 9
2023-07-02 09:22:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 09:23:03 | INFO | train_inner | epoch 009:     16 / 1474 loss=3.622, trans_loss=3.514, nll_loss=1.675, w2v_ctc_loss=1.053, task_loss=0.484, contrastive_loss=0.3, total=4121.25, n_correct=2435.98, ppl=3.19, accuracy=59.108, wps=8651.3, ups=0.7, wpb=12280.4, bsz=466, num_updates=11800, lr=0.000130189, gnorm=0.465, clip=0, loss_scale=8, train_wall=100, gb_free=17.8, wall=11623
2023-07-02 09:24:43 | INFO | train_inner | epoch 009:    116 / 1474 loss=3.559, trans_loss=3.487, nll_loss=1.638, w2v_ctc_loss=1.018, task_loss=0.484, contrastive_loss=0.135, total=4191.82, n_correct=2513.5, ppl=3.11, accuracy=59.962, wps=12527.5, ups=1, wpb=12521.5, bsz=479.9, num_updates=11900, lr=0.000129641, gnorm=0.46, clip=0, loss_scale=8, train_wall=100, gb_free=16.1, wall=11723
2023-07-02 09:26:24 | INFO | train_inner | epoch 009:    216 / 1474 loss=3.568, trans_loss=3.497, nll_loss=1.65, w2v_ctc_loss=1.025, task_loss=0.484, contrastive_loss=0.093, total=4061.27, n_correct=2419.38, ppl=3.14, accuracy=59.572, wps=12086.7, ups=1, wpb=12136, bsz=431.4, num_updates=12000, lr=0.000129099, gnorm=0.462, clip=0, loss_scale=8, train_wall=100, gb_free=17.7, wall=11823
2023-07-02 09:26:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 09:26:50 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.437 | trans_loss 5.708 | nll_loss 3.016 | w2v_ctc_loss 1.345 | task_loss 0 | contrastive_loss 0.271 | total 4003.4 | n_correct 2385.1 | ppl 8.09 | accuracy 59.577 | uer 18.456 | wer 20.376 | raw_wer 20.376 | bleu 18.45 | wps 2131 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 18.45
2023-07-02 09:26:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-07-02 09:26:50 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_9_12000.pt
2023-07-02 09:26:53 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_9_12000.pt
2023-07-02 09:26:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.45) (writing took 8.689216896891594 seconds)
2023-07-02 09:28:40 | INFO | train_inner | epoch 009:    316 / 1474 loss=3.556, trans_loss=3.484, nll_loss=1.635, w2v_ctc_loss=1.01, task_loss=0.484, contrastive_loss=0.143, total=4146.43, n_correct=2491.25, ppl=3.11, accuracy=60.082, wps=9127.7, ups=0.74, wpb=12407.6, bsz=474.6, num_updates=12100, lr=0.000128565, gnorm=0.457, clip=0, loss_scale=16, train_wall=100, gb_free=16.8, wall=11959
2023-07-02 09:30:21 | INFO | train_inner | epoch 009:    416 / 1474 loss=3.566, trans_loss=3.492, nll_loss=1.645, w2v_ctc_loss=1.024, task_loss=0.484, contrastive_loss=0.11, total=4194.84, n_correct=2499.68, ppl=3.13, accuracy=59.589, wps=12357.3, ups=0.99, wpb=12516.2, bsz=466.7, num_updates=12200, lr=0.000128037, gnorm=0.456, clip=0, loss_scale=16, train_wall=101, gb_free=16.3, wall=12060
2023-07-02 09:32:01 | INFO | train_inner | epoch 009:    516 / 1474 loss=3.597, trans_loss=3.501, nll_loss=1.658, w2v_ctc_loss=1.049, task_loss=0.484, contrastive_loss=0.162, total=4124.3, n_correct=2451.51, ppl=3.16, accuracy=59.441, wps=12299.6, ups=1, wpb=12292.8, bsz=439.5, num_updates=12300, lr=0.000127515, gnorm=0.471, clip=0, loss_scale=16, train_wall=99, gb_free=12, wall=12160
2023-07-02 09:33:41 | INFO | train_inner | epoch 009:    616 / 1474 loss=3.566, trans_loss=3.491, nll_loss=1.646, w2v_ctc_loss=1.022, task_loss=0.484, contrastive_loss=0.121, total=4120.96, n_correct=2463.31, ppl=3.13, accuracy=59.775, wps=12320.1, ups=1, wpb=12325.2, bsz=453.4, num_updates=12400, lr=0.000127, gnorm=0.464, clip=0, loss_scale=16, train_wall=100, gb_free=16.3, wall=12260
2023-07-02 09:35:21 | INFO | train_inner | epoch 009:    716 / 1474 loss=3.595, trans_loss=3.499, nll_loss=1.655, w2v_ctc_loss=1.04, task_loss=0.484, contrastive_loss=0.203, total=4088.53, n_correct=2432.66, ppl=3.15, accuracy=59.5, wps=12233.2, ups=1, wpb=12225.7, bsz=451.4, num_updates=12500, lr=0.000126491, gnorm=0.468, clip=0, loss_scale=16, train_wall=99, gb_free=17.1, wall=12360
2023-07-02 09:37:02 | INFO | train_inner | epoch 009:    816 / 1474 loss=3.607, trans_loss=3.488, nll_loss=1.645, w2v_ctc_loss=1.037, task_loss=0.484, contrastive_loss=0.352, total=4220.43, n_correct=2516.05, ppl=3.13, accuracy=59.616, wps=12517, ups=0.99, wpb=12596.8, bsz=501.1, num_updates=12600, lr=0.000125988, gnorm=0.477, clip=0, loss_scale=16, train_wall=100, gb_free=14.6, wall=12461
2023-07-02 09:38:42 | INFO | train_inner | epoch 009:    916 / 1474 loss=3.596, trans_loss=3.498, nll_loss=1.652, w2v_ctc_loss=1.028, task_loss=0.484, contrastive_loss=0.329, total=4146.05, n_correct=2475.65, ppl=3.14, accuracy=59.711, wps=12258.6, ups=0.99, wpb=12355.9, bsz=450.3, num_updates=12700, lr=0.000125491, gnorm=0.458, clip=0, loss_scale=16, train_wall=100, gb_free=17.9, wall=12562
2023-07-02 09:40:23 | INFO | train_inner | epoch 009:   1016 / 1474 loss=3.583, trans_loss=3.506, nll_loss=1.661, w2v_ctc_loss=1.034, task_loss=0.484, contrastive_loss=0.107, total=4101.48, n_correct=2438.53, ppl=3.16, accuracy=59.455, wps=12175, ups=0.99, wpb=12243.2, bsz=424.4, num_updates=12800, lr=0.000125, gnorm=0.464, clip=0, loss_scale=16, train_wall=100, gb_free=16.1, wall=12662
2023-07-02 09:42:03 | INFO | train_inner | epoch 009:   1116 / 1474 loss=3.578, trans_loss=3.497, nll_loss=1.651, w2v_ctc_loss=1.033, task_loss=0.484, contrastive_loss=0.132, total=4179.09, n_correct=2499.46, ppl=3.14, accuracy=59.809, wps=12451.9, ups=1, wpb=12439.9, bsz=474.7, num_updates=12900, lr=0.000124515, gnorm=0.463, clip=0, loss_scale=16, train_wall=99, gb_free=15.5, wall=12762
2023-07-02 09:43:44 | INFO | train_inner | epoch 009:   1216 / 1474 loss=3.587, trans_loss=3.505, nll_loss=1.658, w2v_ctc_loss=1.036, task_loss=0.484, contrastive_loss=0.115, total=4140.66, n_correct=2467.5, ppl=3.16, accuracy=59.592, wps=12298.2, ups=0.99, wpb=12405, bsz=448.1, num_updates=13000, lr=0.000124035, gnorm=0.462, clip=0, loss_scale=16, train_wall=100, gb_free=17.2, wall=12863
2023-07-02 09:45:24 | INFO | train_inner | epoch 009:   1316 / 1474 loss=3.581, trans_loss=3.491, nll_loss=1.644, w2v_ctc_loss=1.01, task_loss=0.484, contrastive_loss=0.304, total=4204.43, n_correct=2524.55, ppl=3.13, accuracy=60.045, wps=12558.3, ups=1, wpb=12539.3, bsz=492.5, num_updates=13100, lr=0.00012356, gnorm=0.461, clip=0, loss_scale=16, train_wall=99, gb_free=17.8, wall=12963
2023-07-02 09:47:03 | INFO | train_inner | epoch 009:   1416 / 1474 loss=3.585, trans_loss=3.508, nll_loss=1.664, w2v_ctc_loss=1.038, task_loss=0.484, contrastive_loss=0.091, total=4069.19, n_correct=2421.72, ppl=3.17, accuracy=59.514, wps=12209, ups=1, wpb=12152.5, bsz=427.7, num_updates=13200, lr=0.000123091, gnorm=0.465, clip=0, loss_scale=16, train_wall=99, gb_free=16.8, wall=13062
2023-07-02 09:48:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 09:48:27 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.416 | trans_loss 5.679 | nll_loss 2.986 | w2v_ctc_loss 1.348 | task_loss 0 | contrastive_loss 0.27 | total 4003.4 | n_correct 2399.9 | ppl 7.92 | accuracy 59.947 | uer 18.047 | wer 19.936 | raw_wer 19.936 | bleu 18.69 | wps 2031.2 | wpb 4003.4 | bsz 141.8 | num_updates 13258 | best_bleu 18.69
2023-07-02 09:48:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13258 updates
2023-07-02 09:48:27 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt
2023-07-02 09:48:31 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt
2023-07-02 09:48:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt (epoch 9 @ 13258 updates, score 18.69) (writing took 8.416323819197714 seconds)
2023-07-02 09:48:35 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-07-02 09:48:35 | INFO | train | epoch 009 | loss 3.581 | trans_loss 3.496 | nll_loss 1.65 | w2v_ctc_loss 1.029 | task_loss 0.484 | contrastive_loss 0.177 | total 4138.65 | n_correct 2470.72 | ppl 3.14 | accuracy 59.699 | wps 11701.3 | ups 0.95 | wpb 12355.8 | bsz 458.5 | num_updates 13258 | lr 0.000122822 | gnorm 0.464 | clip 0 | loss_scale 16 | train_wall 1471 | gb_free 12 | wall 13155
2023-07-02 09:48:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 09:48:36 | INFO | fairseq.trainer | begin training epoch 10
2023-07-02 09:48:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 09:49:25 | INFO | train_inner | epoch 010:     42 / 1474 loss=3.563, trans_loss=3.487, nll_loss=1.639, w2v_ctc_loss=1.01, task_loss=0.484, contrastive_loss=0.188, total=4100.8, n_correct=2466.36, ppl=3.11, accuracy=60.143, wps=8608.4, ups=0.7, wpb=12243.3, bsz=469.4, num_updates=13300, lr=0.000122628, gnorm=0.466, clip=0, loss_scale=16, train_wall=99, gb_free=16.4, wall=13205
2023-07-02 09:51:06 | INFO | train_inner | epoch 010:    142 / 1474 loss=3.517, trans_loss=3.469, nll_loss=1.613, w2v_ctc_loss=0.977, task_loss=0.484, contrastive_loss=0.111, total=4247.35, n_correct=2581.33, ppl=3.06, accuracy=60.775, wps=12661, ups=1, wpb=12717.5, bsz=479.6, num_updates=13400, lr=0.000122169, gnorm=0.452, clip=0, loss_scale=16, train_wall=100, gb_free=12.1, wall=13305
2023-07-02 09:52:46 | INFO | train_inner | epoch 010:    242 / 1474 loss=3.531, trans_loss=3.463, nll_loss=1.61, w2v_ctc_loss=0.986, task_loss=0.484, contrastive_loss=0.232, total=4122.82, n_correct=2505.58, ppl=3.05, accuracy=60.773, wps=12274.6, ups=1, wpb=12279.5, bsz=461.4, num_updates=13500, lr=0.000121716, gnorm=0.464, clip=0, loss_scale=16, train_wall=100, gb_free=16.4, wall=13405
2023-07-02 09:54:27 | INFO | train_inner | epoch 010:    342 / 1474 loss=3.528, trans_loss=3.465, nll_loss=1.614, w2v_ctc_loss=0.988, task_loss=0.484, contrastive_loss=0.151, total=4138.27, n_correct=2515.63, ppl=3.06, accuracy=60.789, wps=12297.4, ups=0.99, wpb=12378.7, bsz=453.8, num_updates=13600, lr=0.000121268, gnorm=0.465, clip=0, loss_scale=16, train_wall=100, gb_free=16.6, wall=13506
2023-07-02 09:56:08 | INFO | train_inner | epoch 010:    442 / 1474 loss=3.535, trans_loss=3.47, nll_loss=1.618, w2v_ctc_loss=0.969, task_loss=0.484, contrastive_loss=0.323, total=4196.37, n_correct=2544.36, ppl=3.07, accuracy=60.632, wps=12394.9, ups=0.99, wpb=12523.5, bsz=481.1, num_updates=13700, lr=0.000120824, gnorm=0.455, clip=0, loss_scale=16, train_wall=101, gb_free=16.6, wall=13607
2023-07-02 09:57:48 | INFO | train_inner | epoch 010:    542 / 1474 loss=3.544, trans_loss=3.481, nll_loss=1.628, w2v_ctc_loss=1.006, task_loss=0.484, contrastive_loss=0.101, total=4102.8, n_correct=2479.26, ppl=3.09, accuracy=60.428, wps=12221.6, ups=1, wpb=12224.8, bsz=437.8, num_updates=13800, lr=0.000120386, gnorm=0.462, clip=0, loss_scale=16, train_wall=100, gb_free=17.1, wall=13707
2023-07-02 09:59:28 | INFO | train_inner | epoch 010:    642 / 1474 loss=3.552, trans_loss=3.479, nll_loss=1.628, w2v_ctc_loss=0.997, task_loss=0.484, contrastive_loss=0.216, total=4176.56, n_correct=2526.71, ppl=3.09, accuracy=60.497, wps=12424.8, ups=1, wpb=12467.5, bsz=477.2, num_updates=13900, lr=0.000119952, gnorm=0.463, clip=0, loss_scale=16, train_wall=100, gb_free=16.5, wall=13807
2023-07-02 10:01:08 | INFO | train_inner | epoch 010:    742 / 1474 loss=3.548, trans_loss=3.48, nll_loss=1.63, w2v_ctc_loss=1.015, task_loss=0.484, contrastive_loss=0.1, total=4125.87, n_correct=2489.03, ppl=3.09, accuracy=60.327, wps=12358.3, ups=1, wpb=12315.5, bsz=454.4, num_updates=14000, lr=0.000119523, gnorm=0.471, clip=0, loss_scale=16, train_wall=99, gb_free=14.7, wall=13907
2023-07-02 10:01:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 10:01:37 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.422 | trans_loss 5.681 | nll_loss 2.986 | w2v_ctc_loss 1.367 | task_loss 0 | contrastive_loss 0.265 | total 4003.4 | n_correct 2397.9 | ppl 7.92 | accuracy 59.897 | uer 18.334 | wer 20.104 | raw_wer 20.104 | bleu 18.25 | wps 1859 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 18.69
2023-07-02 10:01:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-07-02 10:01:37 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_10_14000.pt
2023-07-02 10:01:39 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_10_14000.pt
2023-07-02 10:01:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 18.25) (writing took 6.062238495331258 seconds)
2023-07-02 10:03:23 | INFO | train_inner | epoch 010:    842 / 1474 loss=3.53, trans_loss=3.477, nll_loss=1.626, w2v_ctc_loss=0.988, task_loss=0.484, contrastive_loss=0.101, total=4128.44, n_correct=2499.81, ppl=3.09, accuracy=60.551, wps=9099.3, ups=0.74, wpb=12345, bsz=456.3, num_updates=14100, lr=0.000119098, gnorm=0.462, clip=0, loss_scale=32, train_wall=100, gb_free=14.9, wall=14043
2023-07-02 10:05:03 | INFO | train_inner | epoch 010:    942 / 1474 loss=3.539, trans_loss=3.473, nll_loss=1.623, w2v_ctc_loss=1.003, task_loss=0.484, contrastive_loss=0.14, total=4160.94, n_correct=2520.19, ppl=3.08, accuracy=60.568, wps=12430.3, ups=1, wpb=12380.2, bsz=468.1, num_updates=14200, lr=0.000118678, gnorm=0.465, clip=0, loss_scale=32, train_wall=99, gb_free=15.6, wall=14142
2023-07-02 10:06:43 | INFO | train_inner | epoch 010:   1042 / 1474 loss=3.542, trans_loss=3.481, nll_loss=1.632, w2v_ctc_loss=1.001, task_loss=0.484, contrastive_loss=0.113, total=4067.53, n_correct=2452.62, ppl=3.1, accuracy=60.298, wps=12111.2, ups=1, wpb=12142, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.468, clip=0, loss_scale=32, train_wall=100, gb_free=17, wall=14242
2023-07-02 10:08:23 | INFO | train_inner | epoch 010:   1142 / 1474 loss=3.543, trans_loss=3.483, nll_loss=1.634, w2v_ctc_loss=1.005, task_loss=0.484, contrastive_loss=0.094, total=4044.03, n_correct=2434.41, ppl=3.1, accuracy=60.198, wps=12130.2, ups=1, wpb=12072.9, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.465, clip=0, loss_scale=32, train_wall=99, gb_free=17.4, wall=14342
2023-07-02 10:10:03 | INFO | train_inner | epoch 010:   1242 / 1474 loss=3.532, trans_loss=3.475, nll_loss=1.628, w2v_ctc_loss=1, task_loss=0.484, contrastive_loss=0.089, total=4110.41, n_correct=2484.65, ppl=3.09, accuracy=60.448, wps=12293, ups=1, wpb=12302.3, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.463, clip=0, loss_scale=32, train_wall=100, gb_free=16.6, wall=14442
2023-07-02 10:11:43 | INFO | train_inner | epoch 010:   1342 / 1474 loss=3.533, trans_loss=3.476, nll_loss=1.626, w2v_ctc_loss=0.995, task_loss=0.484, contrastive_loss=0.103, total=4121.38, n_correct=2494.25, ppl=3.09, accuracy=60.52, wps=12269.5, ups=1, wpb=12315.5, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.465, clip=0, loss_scale=32, train_wall=100, gb_free=14.3, wall=14542
2023-07-02 10:13:24 | INFO | train_inner | epoch 010:   1442 / 1474 loss=3.567, trans_loss=3.482, nll_loss=1.636, w2v_ctc_loss=0.983, task_loss=0.484, contrastive_loss=0.357, total=4192.39, n_correct=2532.38, ppl=3.11, accuracy=60.404, wps=12410.4, ups=0.99, wpb=12477.9, bsz=482, num_updates=14700, lr=0.000116642, gnorm=0.471, clip=0, loss_scale=32, train_wall=100, gb_free=17.2, wall=14643
2023-07-02 10:13:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 10:14:22 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.391 | trans_loss 5.649 | nll_loss 2.942 | w2v_ctc_loss 1.338 | task_loss 0 | contrastive_loss 0.258 | total 4003.4 | n_correct 2424.7 | ppl 7.68 | accuracy 60.566 | uer 17.835 | wer 19.735 | raw_wer 19.735 | bleu 19.38 | wps 1951.8 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 19.38
2023-07-02 10:14:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-07-02 10:14:22 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt
2023-07-02 10:14:27 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt
2023-07-02 10:14:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt (epoch 10 @ 14732 updates, score 19.38) (writing took 8.353251030668616 seconds)
2023-07-02 10:14:31 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-07-02 10:14:31 | INFO | train | epoch 010 | loss 3.539 | trans_loss 3.475 | nll_loss 1.625 | w2v_ctc_loss 0.992 | task_loss 0.484 | contrastive_loss 0.17 | total 4138.65 | n_correct 2504.65 | ppl 3.08 | accuracy 60.518 | wps 11709.2 | ups 0.95 | wpb 12355.8 | bsz 458.5 | num_updates 14732 | lr 0.000116516 | gnorm 0.463 | clip 0 | loss_scale 32 | train_wall 1470 | gb_free 17.4 | wall 14710
2023-07-02 10:14:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 10:14:31 | INFO | fairseq.trainer | begin training epoch 11
2023-07-02 10:14:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 10:15:46 | INFO | train_inner | epoch 011:     68 / 1474 loss=3.502, trans_loss=3.456, nll_loss=1.6, w2v_ctc_loss=0.96, task_loss=0.484, contrastive_loss=0.179, total=4175.24, n_correct=2558.96, ppl=3.03, accuracy=61.289, wps=8759.5, ups=0.7, wpb=12460.8, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.455, clip=0, loss_scale=32, train_wall=99, gb_free=16.9, wall=14785
2023-07-02 10:17:26 | INFO | train_inner | epoch 011:    168 / 1474 loss=3.492, trans_loss=3.455, nll_loss=1.6, w2v_ctc_loss=0.963, task_loss=0.484, contrastive_loss=0.098, total=4087.78, n_correct=2497.66, ppl=3.03, accuracy=61.101, wps=12225.4, ups=1, wpb=12225.8, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.465, clip=0, loss_scale=32, train_wall=100, gb_free=16.7, wall=14885
2023-07-02 10:19:06 | INFO | train_inner | epoch 011:    268 / 1474 loss=3.487, trans_loss=3.454, nll_loss=1.599, w2v_ctc_loss=0.958, task_loss=0.484, contrastive_loss=0.093, total=4118.77, n_correct=2518.31, ppl=3.03, accuracy=61.142, wps=12317.7, ups=1, wpb=12285.5, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.462, clip=0, loss_scale=32, train_wall=99, gb_free=12.7, wall=14985
tensor(0.2278, device='cuda:0')
tensor(0.1439, device='cuda:0')
2023-07-02 10:20:45 | INFO | train_inner | epoch 011:    368 / 1474 loss=3.483, trans_loss=3.452, nll_loss=1.594, w2v_ctc_loss=0.951, task_loss=0.484, contrastive_loss=0.097, total=4097.83, n_correct=2512.51, ppl=3.02, accuracy=61.313, wps=12345.2, ups=1.01, wpb=12202.1, bsz=444.2, num_updates=15100, lr=0.000115087, gnorm=0.355, clip=0, loss_scale=32, train_wall=98, gb_free=16.4, wall=15084
2023-07-02 10:22:26 | INFO | train_inner | epoch 011:    468 / 1474 loss=3.524, trans_loss=3.467, nll_loss=1.61, w2v_ctc_loss=0.961, task_loss=0.484, contrastive_loss=0.257, total=4110.64, n_correct=2505.85, ppl=3.05, accuracy=60.96, wps=12156.6, ups=0.99, wpb=12265.6, bsz=450.5, num_updates=15200, lr=0.000114708, gnorm=0.356, clip=0, loss_scale=32, train_wall=100, gb_free=16.5, wall=15185
2023-07-02 10:24:06 | INFO | train_inner | epoch 011:    568 / 1474 loss=3.531, trans_loss=3.463, nll_loss=1.611, w2v_ctc_loss=0.976, task_loss=0.484, contrastive_loss=0.254, total=4071.69, n_correct=2480.19, ppl=3.06, accuracy=60.913, wps=12121.3, ups=1, wpb=12176.5, bsz=440.6, num_updates=15300, lr=0.000114332, gnorm=0.357, clip=0, loss_scale=32, train_wall=100, gb_free=16.5, wall=15285
2023-07-02 10:25:46 | INFO | train_inner | epoch 011:    668 / 1474 loss=3.529, trans_loss=3.459, nll_loss=1.603, w2v_ctc_loss=0.964, task_loss=0.484, contrastive_loss=0.331, total=4157.2, n_correct=2537.25, ppl=3.04, accuracy=61.033, wps=12402.9, ups=1, wpb=12400.2, bsz=464.4, num_updates=15400, lr=0.000113961, gnorm=0.355, clip=0, loss_scale=32, train_wall=100, gb_free=16.9, wall=15385
2023-07-02 10:27:26 | INFO | train_inner | epoch 011:    768 / 1474 loss=3.51, trans_loss=3.464, nll_loss=1.609, w2v_ctc_loss=0.975, task_loss=0.484, contrastive_loss=0.099, total=4174.91, n_correct=2550.24, ppl=3.05, accuracy=61.085, wps=12418.6, ups=1, wpb=12472.8, bsz=460.4, num_updates=15500, lr=0.000113592, gnorm=0.353, clip=0, loss_scale=32, train_wall=100, gb_free=17.1, wall=15486
2023-07-02 10:29:07 | INFO | train_inner | epoch 011:    868 / 1474 loss=3.504, trans_loss=3.462, nll_loss=1.609, w2v_ctc_loss=0.975, task_loss=0.484, contrastive_loss=0.083, total=4118.44, n_correct=2505.45, ppl=3.05, accuracy=60.835, wps=12280.1, ups=1, wpb=12290.5, bsz=440.6, num_updates=15600, lr=0.000113228, gnorm=0.356, clip=0, loss_scale=32, train_wall=100, gb_free=11.2, wall=15586
2023-07-02 10:30:47 | INFO | train_inner | epoch 011:    968 / 1474 loss=3.51, trans_loss=3.463, nll_loss=1.61, w2v_ctc_loss=0.975, task_loss=0.484, contrastive_loss=0.1, total=4140.92, n_correct=2529.32, ppl=3.05, accuracy=61.081, wps=12320.6, ups=1, wpb=12353.7, bsz=452.9, num_updates=15700, lr=0.000112867, gnorm=0.356, clip=0, loss_scale=32, train_wall=100, gb_free=15.8, wall=15686
2023-07-02 10:32:26 | INFO | train_inner | epoch 011:   1068 / 1474 loss=3.511, trans_loss=3.459, nll_loss=1.606, w2v_ctc_loss=0.974, task_loss=0.484, contrastive_loss=0.124, total=4136.99, n_correct=2534.93, ppl=3.04, accuracy=61.275, wps=12427.8, ups=1, wpb=12367, bsz=463.2, num_updates=15800, lr=0.000112509, gnorm=0.351, clip=0, loss_scale=32, train_wall=99, gb_free=17.7, wall=15785
2023-07-02 10:34:07 | INFO | train_inner | epoch 011:   1168 / 1474 loss=3.509, trans_loss=3.463, nll_loss=1.614, w2v_ctc_loss=0.977, task_loss=0.484, contrastive_loss=0.106, total=4185.65, n_correct=2554.18, ppl=3.06, accuracy=61.022, wps=12419.4, ups=1, wpb=12477.8, bsz=464.7, num_updates=15900, lr=0.000112154, gnorm=0.351, clip=0, loss_scale=32, train_wall=100, gb_free=14.3, wall=15886
2023-07-02 10:35:47 | INFO | train_inner | epoch 011:   1268 / 1474 loss=3.535, trans_loss=3.465, nll_loss=1.612, w2v_ctc_loss=0.986, task_loss=0.484, contrastive_loss=0.198, total=4171.89, n_correct=2545.72, ppl=3.06, accuracy=61.021, wps=12420.7, ups=1, wpb=12466.6, bsz=471.1, num_updates=16000, lr=0.000111803, gnorm=0.359, clip=0, loss_scale=32, train_wall=100, gb_free=16.1, wall=15986
2023-07-02 10:35:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.2278, device='cuda:6')
tensor(0.1439, device='cuda:6')
tensor(0.2278, device='cuda:3')
tensor(0.1439, device='cuda:3')
tensor(0.2278, device='cuda:1')
tensor(0.1439, device='cuda:1')
tensor(0.2278, device='cuda:7')
tensor(0.1439, device='cuda:7')
tensor(0.2278, device='cuda:2')
tensor(0.1439, device='cuda:2')
tensor(0.2278, device='cuda:4')
tensor(0.1439, device='cuda:4')
tensor(0.2278, device='cuda:5')
tensor(0.1439, device='cuda:5')
2023-07-02 10:36:14 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.401 | trans_loss 5.635 | nll_loss 2.921 | w2v_ctc_loss 1.404 | task_loss 0 | contrastive_loss 0.263 | total 4003.4 | n_correct 2436.1 | ppl 7.57 | accuracy 60.851 | uer 17.493 | wer 19.287 | raw_wer 19.287 | bleu 19.37 | wps 2000.4 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.38
2023-07-02 10:36:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-07-02 10:36:14 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_11_16000.pt
2023-07-02 10:36:16 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_11_16000.pt
2023-07-02 10:36:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 19.37) (writing took 5.96044288109988 seconds)
2023-07-02 10:38:01 | INFO | train_inner | epoch 011:   1368 / 1474 loss=3.541, trans_loss=3.462, nll_loss=1.608, w2v_ctc_loss=0.962, task_loss=0.484, contrastive_loss=0.415, total=4190.34, n_correct=2554.09, ppl=3.05, accuracy=60.952, wps=9375.3, ups=0.75, wpb=12512.8, bsz=491.8, num_updates=16100, lr=0.000111456, gnorm=0.353, clip=0, loss_scale=32, train_wall=100, gb_free=17.1, wall=16120
2023-07-02 10:39:41 | INFO | train_inner | epoch 011:   1468 / 1474 loss=3.501, trans_loss=3.461, nll_loss=1.608, w2v_ctc_loss=0.964, task_loss=0.484, contrastive_loss=0.107, total=4158.39, n_correct=2542.27, ppl=3.05, accuracy=61.136, wps=12420.9, ups=1, wpb=12421.8, bsz=468, num_updates=16200, lr=0.000111111, gnorm=0.35, clip=0, loss_scale=64, train_wall=100, gb_free=17.1, wall=16220
2023-07-02 10:39:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 10:40:13 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.382 | trans_loss 5.633 | nll_loss 2.926 | w2v_ctc_loss 1.343 | task_loss 0 | contrastive_loss 0.269 | total 4003.4 | n_correct 2427.2 | ppl 7.6 | accuracy 60.628 | uer 17.58 | wer 19.5 | raw_wer 19.5 | bleu 18.88 | wps 2078.9 | wpb 4003.4 | bsz 141.8 | num_updates 16206 | best_bleu 19.38
2023-07-02 10:40:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16206 updates
2023-07-02 10:40:13 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_18.8803.pt
2023-07-02 10:40:16 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_18.8803.pt
2023-07-02 10:40:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_18.8803.pt (epoch 11 @ 16206 updates, score 18.88) (writing took 5.587221660185605 seconds)
2023-07-02 10:40:19 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-07-02 10:40:19 | INFO | train | epoch 011 | loss 3.511 | trans_loss 3.46 | nll_loss 1.606 | w2v_ctc_loss 0.968 | task_loss 0.484 | contrastive_loss 0.166 | total 4138.65 | n_correct 2528.13 | ppl 3.04 | accuracy 61.086 | wps 11764.1 | ups 0.95 | wpb 12355.8 | bsz 458.5 | num_updates 16206 | lr 0.000111091 | gnorm 0.374 | clip 0 | loss_scale 64 | train_wall 1468 | gb_free 17.3 | wall 16258
2023-07-02 10:40:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 10:40:19 | INFO | fairseq.trainer | begin training epoch 12
2023-07-02 10:40:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 10:42:01 | INFO | train_inner | epoch 012:     94 / 1474 loss=3.474, trans_loss=3.436, nll_loss=1.573, w2v_ctc_loss=0.943, task_loss=0.484, contrastive_loss=0.151, total=4146.82, n_correct=2574.94, ppl=2.98, accuracy=62.094, wps=8820.2, ups=0.71, wpb=12379.4, bsz=470.8, num_updates=16300, lr=0.00011077, gnorm=0.348, clip=0, loss_scale=64, train_wall=99, gb_free=15.9, wall=16360
2023-07-02 10:43:41 | INFO | train_inner | epoch 012:    194 / 1474 loss=3.471, trans_loss=3.438, nll_loss=1.577, w2v_ctc_loss=0.947, task_loss=0.484, contrastive_loss=0.086, total=4120.68, n_correct=2553.12, ppl=2.98, accuracy=61.959, wps=12323.5, ups=1, wpb=12345.4, bsz=442.1, num_updates=16400, lr=0.000110432, gnorm=0.352, clip=0, loss_scale=64, train_wall=100, gb_free=15.8, wall=16460
2023-07-02 10:45:22 | INFO | train_inner | epoch 012:    294 / 1474 loss=3.467, trans_loss=3.438, nll_loss=1.579, w2v_ctc_loss=0.933, task_loss=0.484, contrastive_loss=0.128, total=4199.46, n_correct=2605.29, ppl=2.99, accuracy=62.039, wps=12452.7, ups=0.99, wpb=12539.6, bsz=480.4, num_updates=16500, lr=0.000110096, gnorm=0.348, clip=0, loss_scale=64, train_wall=100, gb_free=16.7, wall=16561
2023-07-02 10:47:03 | INFO | train_inner | epoch 012:    394 / 1474 loss=3.469, trans_loss=3.442, nll_loss=1.583, w2v_ctc_loss=0.939, task_loss=0.484, contrastive_loss=0.106, total=4151.14, n_correct=2569.6, ppl=3, accuracy=61.901, wps=12293.6, ups=0.99, wpb=12410, bsz=461.6, num_updates=16600, lr=0.000109764, gnorm=0.351, clip=0, loss_scale=64, train_wall=100, gb_free=17.2, wall=16662
2023-07-02 10:48:43 | INFO | train_inner | epoch 012:    494 / 1474 loss=3.499, trans_loss=3.455, nll_loss=1.597, w2v_ctc_loss=0.965, task_loss=0.484, contrastive_loss=0.116, total=4110.49, n_correct=2532.42, ppl=3.03, accuracy=61.609, wps=12212, ups=1, wpb=12226.9, bsz=453.3, num_updates=16700, lr=0.000109435, gnorm=0.353, clip=0, loss_scale=64, train_wall=100, gb_free=14.1, wall=16762
2023-07-02 10:50:24 | INFO | train_inner | epoch 012:    594 / 1474 loss=3.492, trans_loss=3.443, nll_loss=1.588, w2v_ctc_loss=0.95, task_loss=0.484, contrastive_loss=0.2, total=4189.92, n_correct=2584.67, ppl=3.01, accuracy=61.688, wps=12372.2, ups=0.99, wpb=12531.1, bsz=472.7, num_updates=16800, lr=0.000109109, gnorm=0.351, clip=0, loss_scale=64, train_wall=101, gb_free=15.1, wall=16863
2023-07-02 10:52:04 | INFO | train_inner | epoch 012:    694 / 1474 loss=3.485, trans_loss=3.44, nll_loss=1.582, w2v_ctc_loss=0.931, task_loss=0.484, contrastive_loss=0.321, total=4206.3, n_correct=2606.95, ppl=2.99, accuracy=61.977, wps=12549.9, ups=1, wpb=12501.9, bsz=488.5, num_updates=16900, lr=0.000108786, gnorm=0.348, clip=0, loss_scale=64, train_wall=99, gb_free=16.4, wall=16963
2023-07-02 10:53:44 | INFO | train_inner | epoch 012:    794 / 1474 loss=3.487, trans_loss=3.448, nll_loss=1.589, w2v_ctc_loss=0.954, task_loss=0.484, contrastive_loss=0.101, total=4085.96, n_correct=2526.34, ppl=3.01, accuracy=61.83, wps=12190.8, ups=1, wpb=12212.6, bsz=445.7, num_updates=17000, lr=0.000108465, gnorm=0.356, clip=0, loss_scale=64, train_wall=100, gb_free=16.6, wall=17063
2023-07-02 10:55:25 | INFO | train_inner | epoch 012:    894 / 1474 loss=3.483, trans_loss=3.442, nll_loss=1.585, w2v_ctc_loss=0.941, task_loss=0.484, contrastive_loss=0.166, total=4169.74, n_correct=2577.63, ppl=3, accuracy=61.818, wps=12338, ups=0.99, wpb=12453, bsz=459.6, num_updates=17100, lr=0.000108148, gnorm=0.349, clip=0, loss_scale=64, train_wall=100, gb_free=16.2, wall=17164
2023-07-02 10:57:05 | INFO | train_inner | epoch 012:    994 / 1474 loss=3.497, trans_loss=3.45, nll_loss=1.593, w2v_ctc_loss=0.957, task_loss=0.484, contrastive_loss=0.185, total=4117.67, n_correct=2536.63, ppl=3.02, accuracy=61.604, wps=12258.6, ups=1, wpb=12288, bsz=452.1, num_updates=17200, lr=0.000107833, gnorm=0.354, clip=0, loss_scale=64, train_wall=100, gb_free=17.8, wall=17264
2023-07-02 10:57:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-02 10:58:46 | INFO | train_inner | epoch 012:   1095 / 1474 loss=3.497, trans_loss=3.454, nll_loss=1.597, w2v_ctc_loss=0.968, task_loss=0.484, contrastive_loss=0.077, total=4014.56, n_correct=2474.42, ppl=3.03, accuracy=61.636, wps=11887.4, ups=0.99, wpb=11998.6, bsz=419.2, num_updates=17300, lr=0.000107521, gnorm=0.358, clip=0, loss_scale=32, train_wall=100, gb_free=16.1, wall=17365
2023-07-02 11:00:27 | INFO | train_inner | epoch 012:   1195 / 1474 loss=3.52, trans_loss=3.455, nll_loss=1.603, w2v_ctc_loss=0.978, task_loss=0.484, contrastive_loss=0.2, total=4201.13, n_correct=2569.05, ppl=3.04, accuracy=61.151, wps=12460, ups=0.99, wpb=12545, bsz=478.7, num_updates=17400, lr=0.000107211, gnorm=0.358, clip=0, loss_scale=32, train_wall=100, gb_free=17.4, wall=17466
2023-07-02 11:02:07 | INFO | train_inner | epoch 012:   1295 / 1474 loss=3.495, trans_loss=3.454, nll_loss=1.602, w2v_ctc_loss=0.965, task_loss=0.484, contrastive_loss=0.083, total=4070.27, n_correct=2507.54, ppl=3.03, accuracy=61.606, wps=12154.7, ups=1, wpb=12168, bsz=429.2, num_updates=17500, lr=0.000106904, gnorm=0.358, clip=0, loss_scale=32, train_wall=100, gb_free=16.1, wall=17566
2023-07-02 11:03:47 | INFO | train_inner | epoch 012:   1395 / 1474 loss=3.494, trans_loss=3.448, nll_loss=1.594, w2v_ctc_loss=0.944, task_loss=0.484, contrastive_loss=0.223, total=4139.63, n_correct=2551.06, ppl=3.02, accuracy=61.625, wps=12338.9, ups=1, wpb=12331.2, bsz=458.7, num_updates=17600, lr=0.0001066, gnorm=0.357, clip=0, loss_scale=32, train_wall=99, gb_free=17.2, wall=17666
2023-07-02 11:05:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 11:05:34 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.367 | trans_loss 5.617 | nll_loss 2.906 | w2v_ctc_loss 1.334 | task_loss 0 | contrastive_loss 0.257 | total 4003.4 | n_correct 2438.7 | ppl 7.49 | accuracy 60.916 | uer 17.639 | wer 19.462 | raw_wer 19.462 | bleu 19.33 | wps 1951.4 | wpb 4003.4 | bsz 141.8 | num_updates 17679 | best_bleu 19.38
2023-07-02 11:05:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17679 updates
2023-07-02 11:05:34 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_19.3309.pt
2023-07-02 11:05:36 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_19.3309.pt
2023-07-02 11:05:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_19.3309.pt (epoch 12 @ 17679 updates, score 19.33) (writing took 5.30017648730427 seconds)
2023-07-02 11:05:39 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-07-02 11:05:39 | INFO | train | epoch 012 | loss 3.488 | trans_loss 3.446 | nll_loss 1.589 | w2v_ctc_loss 0.952 | task_loss 0.484 | contrastive_loss 0.152 | total 4136.49 | n_correct 2553.99 | ppl 3.01 | accuracy 61.743 | wps 11966 | ups 0.97 | wpb 12350.1 | bsz 457.4 | num_updates 17679 | lr 0.000106362 | gnorm 0.353 | clip 0 | loss_scale 32 | train_wall 1472 | gb_free 13.2 | wall 17778
2023-07-02 11:05:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 11:05:39 | INFO | fairseq.trainer | begin training epoch 13
2023-07-02 11:05:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 11:06:08 | INFO | train_inner | epoch 013:     21 / 1474 loss=3.493, trans_loss=3.449, nll_loss=1.594, w2v_ctc_loss=0.966, task_loss=0.484, contrastive_loss=0.095, total=4096.49, n_correct=2522.1, ppl=3.02, accuracy=61.567, wps=8663.4, ups=0.71, wpb=12243.5, bsz=443.1, num_updates=17700, lr=0.000106299, gnorm=0.356, clip=0, loss_scale=32, train_wall=99, gb_free=14.8, wall=17807
2023-07-02 11:07:49 | INFO | train_inner | epoch 013:    121 / 1474 loss=3.446, trans_loss=3.425, nll_loss=1.562, w2v_ctc_loss=0.922, task_loss=0.484, contrastive_loss=0.11, total=4160.97, n_correct=2600.27, ppl=2.95, accuracy=62.492, wps=12311.7, ups=0.99, wpb=12418.2, bsz=454.3, num_updates=17800, lr=0.000106, gnorm=0.35, clip=0, loss_scale=32, train_wall=100, gb_free=16.4, wall=17908
2023-07-02 11:09:31 | INFO | train_inner | epoch 013:    221 / 1474 loss=3.489, trans_loss=3.427, nll_loss=1.569, w2v_ctc_loss=0.926, task_loss=0.484, contrastive_loss=0.398, total=4212.08, n_correct=2624.29, ppl=2.97, accuracy=62.304, wps=12354.8, ups=0.99, wpb=12529.8, bsz=494.6, num_updates=17900, lr=0.000105703, gnorm=0.352, clip=0, loss_scale=32, train_wall=101, gb_free=14.9, wall=18010
2023-07-02 11:11:11 | INFO | train_inner | epoch 013:    321 / 1474 loss=3.451, trans_loss=3.43, nll_loss=1.566, w2v_ctc_loss=0.923, task_loss=0.484, contrastive_loss=0.091, total=4102.3, n_correct=2569.51, ppl=2.96, accuracy=62.636, wps=12192.5, ups=1, wpb=12230, bsz=441.1, num_updates=18000, lr=0.000105409, gnorm=0.357, clip=0, loss_scale=32, train_wall=100, gb_free=17.4, wall=18110
2023-07-02 11:11:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 11:11:37 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.367 | trans_loss 5.627 | nll_loss 2.913 | w2v_ctc_loss 1.313 | task_loss 0 | contrastive_loss 0.253 | total 4003.4 | n_correct 2434.1 | ppl 7.53 | accuracy 60.801 | uer 17.612 | wer 19.496 | raw_wer 19.496 | bleu 18.83 | wps 2144.6 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.38
2023-07-02 11:11:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-07-02 11:11:37 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_13_18000.pt
2023-07-02 11:11:39 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_13_18000.pt
2023-07-02 11:11:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 18.83) (writing took 5.939480966888368 seconds)
2023-07-02 11:13:22 | INFO | train_inner | epoch 013:    421 / 1474 loss=3.468, trans_loss=3.434, nll_loss=1.573, w2v_ctc_loss=0.932, task_loss=0.484, contrastive_loss=0.154, total=4177.29, n_correct=2610.34, ppl=2.97, accuracy=62.489, wps=9471.2, ups=0.76, wpb=12461.8, bsz=477.6, num_updates=18100, lr=0.000105118, gnorm=0.35, clip=0, loss_scale=32, train_wall=99, gb_free=17.6, wall=18242
2023-07-02 11:15:03 | INFO | train_inner | epoch 013:    521 / 1474 loss=3.475, trans_loss=3.436, nll_loss=1.576, w2v_ctc_loss=0.935, task_loss=0.484, contrastive_loss=0.203, total=4201.22, n_correct=2611.94, ppl=2.98, accuracy=62.171, wps=12453.1, ups=0.99, wpb=12536.9, bsz=478.4, num_updates=18200, lr=0.000104828, gnorm=0.352, clip=0, loss_scale=32, train_wall=100, gb_free=13.2, wall=18342
2023-07-02 11:16:43 | INFO | train_inner | epoch 013:    621 / 1474 loss=3.449, trans_loss=3.43, nll_loss=1.568, w2v_ctc_loss=0.923, task_loss=0.484, contrastive_loss=0.086, total=4161.98, n_correct=2603.54, ppl=2.96, accuracy=62.555, wps=12473.4, ups=1, wpb=12435.5, bsz=462.4, num_updates=18300, lr=0.000104542, gnorm=0.347, clip=0, loss_scale=32, train_wall=99, gb_free=16, wall=18442
2023-07-02 11:18:23 | INFO | train_inner | epoch 013:    721 / 1474 loss=3.476, trans_loss=3.436, nll_loss=1.575, w2v_ctc_loss=0.957, task_loss=0.484, contrastive_loss=0.085, total=4096.76, n_correct=2546.42, ppl=2.98, accuracy=62.157, wps=12235.6, ups=1, wpb=12226.1, bsz=426.8, num_updates=18400, lr=0.000104257, gnorm=0.356, clip=0, loss_scale=32, train_wall=99, gb_free=16.8, wall=18542
2023-07-02 11:20:05 | INFO | train_inner | epoch 013:    821 / 1474 loss=3.465, trans_loss=3.435, nll_loss=1.575, w2v_ctc_loss=0.931, task_loss=0.484, contrastive_loss=0.146, total=4121.73, n_correct=2559.82, ppl=2.98, accuracy=62.105, wps=12069.3, ups=0.98, wpb=12319.8, bsz=460, num_updates=18500, lr=0.000103975, gnorm=0.358, clip=0, loss_scale=32, train_wall=102, gb_free=15, wall=18644
2023-07-02 11:21:45 | INFO | train_inner | epoch 013:    921 / 1474 loss=3.46, trans_loss=3.435, nll_loss=1.576, w2v_ctc_loss=0.934, task_loss=0.484, contrastive_loss=0.097, total=4107.01, n_correct=2557, ppl=2.98, accuracy=62.259, wps=12264.4, ups=1, wpb=12264.1, bsz=444.7, num_updates=18600, lr=0.000103695, gnorm=0.353, clip=0, loss_scale=32, train_wall=100, gb_free=16.1, wall=18744
2023-07-02 11:23:25 | INFO | train_inner | epoch 013:   1021 / 1474 loss=3.477, trans_loss=3.433, nll_loss=1.577, w2v_ctc_loss=0.944, task_loss=0.484, contrastive_loss=0.165, total=4081.02, n_correct=2529.94, ppl=2.98, accuracy=61.993, wps=12212, ups=1, wpb=12208.8, bsz=440.1, num_updates=18700, lr=0.000103418, gnorm=0.354, clip=0, loss_scale=32, train_wall=100, gb_free=16.4, wall=18844
2023-07-02 11:25:04 | INFO | train_inner | epoch 013:   1121 / 1474 loss=3.462, trans_loss=3.432, nll_loss=1.572, w2v_ctc_loss=0.927, task_loss=0.484, contrastive_loss=0.141, total=4105.62, n_correct=2564.22, ppl=2.97, accuracy=62.456, wps=12321.7, ups=1, wpb=12265.4, bsz=458.9, num_updates=18800, lr=0.000103142, gnorm=0.352, clip=0, loss_scale=32, train_wall=99, gb_free=16.9, wall=18944
2023-07-02 11:26:44 | INFO | train_inner | epoch 013:   1221 / 1474 loss=3.479, trans_loss=3.444, nll_loss=1.586, w2v_ctc_loss=0.948, task_loss=0.484, contrastive_loss=0.089, total=4110.35, n_correct=2551.78, ppl=3, accuracy=62.082, wps=12300, ups=1, wpb=12287.7, bsz=442.6, num_updates=18900, lr=0.000102869, gnorm=0.358, clip=0, loss_scale=32, train_wall=99, gb_free=15.1, wall=19043
2023-07-02 11:28:24 | INFO | train_inner | epoch 013:   1321 / 1474 loss=3.47, trans_loss=3.431, nll_loss=1.573, w2v_ctc_loss=0.93, task_loss=0.484, contrastive_loss=0.218, total=4112.2, n_correct=2568.96, ppl=2.98, accuracy=62.472, wps=12288.7, ups=1, wpb=12280.4, bsz=462.3, num_updates=19000, lr=0.000102598, gnorm=0.353, clip=0, loss_scale=32, train_wall=99, gb_free=17.7, wall=19143
2023-07-02 11:30:04 | INFO | train_inner | epoch 013:   1421 / 1474 loss=3.484, trans_loss=3.442, nll_loss=1.583, w2v_ctc_loss=0.929, task_loss=0.484, contrastive_loss=0.237, total=4180.88, n_correct=2599.4, ppl=3, accuracy=62.174, wps=12467.1, ups=1, wpb=12470.5, bsz=468.3, num_updates=19100, lr=0.000102329, gnorm=0.354, clip=0, loss_scale=32, train_wall=100, gb_free=15.5, wall=19243
2023-07-02 11:30:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 11:31:23 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.347 | trans_loss 5.598 | nll_loss 2.882 | w2v_ctc_loss 1.319 | task_loss 0 | contrastive_loss 0.239 | total 4003.4 | n_correct 2452.6 | ppl 7.37 | accuracy 61.263 | uer 17.471 | wer 19.257 | raw_wer 19.257 | bleu 19.48 | wps 2279.3 | wpb 4003.4 | bsz 141.8 | num_updates 19153 | best_bleu 19.48
2023-07-02 11:31:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19153 updates
2023-07-02 11:31:23 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt
2023-07-02 11:31:27 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt
2023-07-02 11:31:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt (epoch 13 @ 19153 updates, score 19.48) (writing took 8.359508482273668 seconds)
2023-07-02 11:31:31 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-07-02 11:31:31 | INFO | train | epoch 013 | loss 3.468 | trans_loss 3.433 | nll_loss 1.573 | w2v_ctc_loss 0.933 | task_loss 0.484 | contrastive_loss 0.159 | total 4138.65 | n_correct 2578.86 | ppl 2.98 | accuracy 62.312 | wps 11735.6 | ups 0.95 | wpb 12355.8 | bsz 458.5 | num_updates 19153 | lr 0.000102187 | gnorm 0.353 | clip 0 | loss_scale 32 | train_wall 1471 | gb_free 17.7 | wall 19330
2023-07-02 11:31:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 11:31:31 | INFO | fairseq.trainer | begin training epoch 14
2023-07-02 11:31:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 11:32:27 | INFO | train_inner | epoch 014:     47 / 1474 loss=3.431, trans_loss=3.414, nll_loss=1.55, w2v_ctc_loss=0.914, task_loss=0.484, contrastive_loss=0.105, total=4176.2, n_correct=2630.42, ppl=2.93, accuracy=62.986, wps=8776, ups=0.7, wpb=12486.4, bsz=483.4, num_updates=19200, lr=0.000102062, gnorm=0.35, clip=0, loss_scale=32, train_wall=100, gb_free=11.2, wall=19386
2023-07-02 11:34:06 | INFO | train_inner | epoch 014:    147 / 1474 loss=3.426, trans_loss=3.413, nll_loss=1.544, w2v_ctc_loss=0.907, task_loss=0.484, contrastive_loss=0.081, total=4080.86, n_correct=2585.1, ppl=2.92, accuracy=63.347, wps=12222.9, ups=1, wpb=12203.2, bsz=449.3, num_updates=19300, lr=0.000101797, gnorm=0.351, clip=0, loss_scale=64, train_wall=99, gb_free=17, wall=19486
2023-07-02 11:35:47 | INFO | train_inner | epoch 014:    247 / 1474 loss=3.452, trans_loss=3.425, nll_loss=1.561, w2v_ctc_loss=0.91, task_loss=0.484, contrastive_loss=0.217, total=4106.97, n_correct=2581.52, ppl=2.95, accuracy=62.857, wps=12206, ups=1, wpb=12224.4, bsz=440, num_updates=19400, lr=0.000101535, gnorm=0.352, clip=0, loss_scale=64, train_wall=100, gb_free=12.7, wall=19586
2023-07-02 11:37:26 | INFO | train_inner | epoch 014:    347 / 1474 loss=3.418, trans_loss=3.407, nll_loss=1.546, w2v_ctc_loss=0.905, task_loss=0.484, contrastive_loss=0.126, total=4179.8, n_correct=2635.38, ppl=2.92, accuracy=63.05, wps=12470.3, ups=1, wpb=12454.9, bsz=483.8, num_updates=19500, lr=0.000101274, gnorm=0.354, clip=0, loss_scale=64, train_wall=99, gb_free=17.4, wall=19686
2023-07-02 11:39:06 | INFO | train_inner | epoch 014:    447 / 1474 loss=3.432, trans_loss=3.422, nll_loss=1.559, w2v_ctc_loss=0.911, task_loss=0.484, contrastive_loss=0.076, total=4120.38, n_correct=2588.28, ppl=2.95, accuracy=62.817, wps=12295.8, ups=1, wpb=12283.1, bsz=444.5, num_updates=19600, lr=0.000101015, gnorm=0.358, clip=0, loss_scale=64, train_wall=99, gb_free=17.3, wall=19785
2023-07-02 11:40:47 | INFO | train_inner | epoch 014:    547 / 1474 loss=3.461, trans_loss=3.43, nll_loss=1.568, w2v_ctc_loss=0.93, task_loss=0.484, contrastive_loss=0.12, total=4089.86, n_correct=2559.25, ppl=2.96, accuracy=62.575, wps=12186.4, ups=0.99, wpb=12262.9, bsz=443.3, num_updates=19700, lr=0.000100759, gnorm=0.358, clip=0, loss_scale=64, train_wall=100, gb_free=12.4, wall=19886
2023-07-02 11:42:27 | INFO | train_inner | epoch 014:    647 / 1474 loss=3.45, trans_loss=3.425, nll_loss=1.563, w2v_ctc_loss=0.912, task_loss=0.484, contrastive_loss=0.181, total=4158.94, n_correct=2608.04, ppl=2.95, accuracy=62.709, wps=12399.4, ups=1, wpb=12415.4, bsz=460, num_updates=19800, lr=0.000100504, gnorm=0.356, clip=0, loss_scale=64, train_wall=100, gb_free=16.4, wall=19986
2023-07-02 11:44:07 | INFO | train_inner | epoch 014:    747 / 1474 loss=3.435, trans_loss=3.418, nll_loss=1.554, w2v_ctc_loss=0.912, task_loss=0.484, contrastive_loss=0.091, total=4150.03, n_correct=2617.9, ppl=2.94, accuracy=63.081, wps=12455.3, ups=1, wpb=12407.3, bsz=465.5, num_updates=19900, lr=0.000100251, gnorm=0.347, clip=0, loss_scale=64, train_wall=99, gb_free=15.7, wall=20086
2023-07-02 11:45:47 | INFO | train_inner | epoch 014:    847 / 1474 loss=3.445, trans_loss=3.414, nll_loss=1.553, w2v_ctc_loss=0.904, task_loss=0.484, contrastive_loss=0.238, total=4162.8, n_correct=2618.3, ppl=2.93, accuracy=62.898, wps=12370.6, ups=1, wpb=12422.9, bsz=475.8, num_updates=20000, lr=0.0001, gnorm=0.35, clip=0, loss_scale=64, train_wall=100, gb_free=17.2, wall=20186
2023-07-02 11:45:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 11:46:12 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.35 | trans_loss 5.592 | nll_loss 2.871 | w2v_ctc_loss 1.338 | task_loss 0 | contrastive_loss 0.251 | total 4003.4 | n_correct 2457.1 | ppl 7.32 | accuracy 61.375 | uer 16.962 | wer 18.873 | raw_wer 18.873 | bleu 19.36 | wps 2202.8 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.48
2023-07-02 11:46:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-07-02 11:46:12 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_14_20000.pt
2023-07-02 11:46:14 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_14_20000.pt
2023-07-02 11:46:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.36) (writing took 6.559992164839059 seconds)
tensor(0.0172, device='cuda:0')
tensor(0.0009, device='cuda:0')
2023-07-02 11:47:33 | INFO | train_inner | epoch 014:    947 / 1474 loss=3.956, trans_loss=5.377, nll_loss=2.727, w2v_ctc_loss=1.321, task_loss=1.408, contrastive_loss=0.141, total=4159.46, n_correct=2597.03, ppl=6.62, accuracy=62.437, wps=4017.1, ups=0.94, wpb=4251.9, bsz=158.1, num_updates=20100, lr=9.97509e-05, gnorm=0.959, clip=0, loss_scale=64, train_wall=74, gb_free=15.6, wall=20292
2023-07-02 11:48:47 | INFO | train_inner | epoch 014:   1047 / 1474 loss=3.978, trans_loss=5.443, nll_loss=2.768, w2v_ctc_loss=1.319, task_loss=1.452, contrastive_loss=0.273, total=4155.93, n_correct=2597.08, ppl=6.81, accuracy=62.491, wps=5595.1, ups=1.35, wpb=4155.9, bsz=153, num_updates=20200, lr=9.95037e-05, gnorm=0.958, clip=0, loss_scale=64, train_wall=74, gb_free=16.7, wall=20366
2023-07-02 11:50:01 | INFO | train_inner | epoch 014:   1147 / 1474 loss=4.001, trans_loss=5.448, nll_loss=2.775, w2v_ctc_loss=1.336, task_loss=1.452, contrastive_loss=0.73, total=4228.09, n_correct=2639.91, ppl=6.85, accuracy=62.437, wps=5699.9, ups=1.35, wpb=4228.1, bsz=163.2, num_updates=20300, lr=9.92583e-05, gnorm=0.95, clip=0, loss_scale=64, train_wall=74, gb_free=17.7, wall=20441
2023-07-02 11:51:15 | INFO | train_inner | epoch 014:   1247 / 1474 loss=4.005, trans_loss=5.458, nll_loss=2.785, w2v_ctc_loss=1.36, task_loss=1.452, contrastive_loss=0.11, total=4027.71, n_correct=2505.3, ppl=6.89, accuracy=62.202, wps=5513.6, ups=1.37, wpb=4027.7, bsz=136.8, num_updates=20400, lr=9.90148e-05, gnorm=0.971, clip=0, loss_scale=64, train_wall=73, gb_free=17, wall=20514
2023-07-02 11:52:28 | INFO | train_inner | epoch 014:   1347 / 1474 loss=3.956, trans_loss=5.436, nll_loss=2.759, w2v_ctc_loss=1.311, task_loss=1.452, contrastive_loss=0.139, total=4198.71, n_correct=2630.12, ppl=6.77, accuracy=62.641, wps=5728.6, ups=1.36, wpb=4198.7, bsz=157.7, num_updates=20500, lr=9.8773e-05, gnorm=0.949, clip=0, loss_scale=64, train_wall=73, gb_free=16.9, wall=20587
2023-07-02 11:53:41 | INFO | train_inner | epoch 014:   1447 / 1474 loss=3.974, trans_loss=5.447, nll_loss=2.773, w2v_ctc_loss=1.321, task_loss=1.452, contrastive_loss=0.214, total=4140.5, n_correct=2586.99, ppl=6.83, accuracy=62.48, wps=5648.8, ups=1.36, wpb=4140.5, bsz=153.5, num_updates=20600, lr=9.85329e-05, gnorm=0.959, clip=0, loss_scale=64, train_wall=73, gb_free=17.7, wall=20660
2023-07-02 11:54:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0172, device='cuda:4')
tensor(0.0009, device='cuda:4')
tensor(0.0172, device='cuda:7')
tensor(0.0009, device='cuda:7')
tensor(0.0172, device='cuda:6')
tensor(0.0009, device='cuda:6')
tensor(0.0172, device='cuda:1')
tensor(0.0009, device='cuda:1')
tensor(0.0172, device='cuda:2')
tensor(0.0009, device='cuda:2')
tensor(0.0172, device='cuda:3')
tensor(0.0009, device='cuda:3')
tensor(0.0172, device='cuda:5')
tensor(0.0009, device='cuda:5')
2023-07-02 11:54:26 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.348 | trans_loss 5.59 | nll_loss 2.873 | w2v_ctc_loss 1.34 | task_loss 0 | contrastive_loss 0.248 | total 4003.4 | n_correct 2455.4 | ppl 7.32 | accuracy 61.333 | uer 17.198 | wer 19.112 | raw_wer 19.112 | bleu 19.41 | wps 2302.9 | wpb 4003.4 | bsz 141.8 | num_updates 20627 | best_bleu 19.48
2023-07-02 11:54:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20627 updates
2023-07-02 11:54:26 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_19.4105.pt
2023-07-02 11:54:29 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_19.4105.pt
2023-07-02 11:54:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_19.4105.pt (epoch 14 @ 20627 updates, score 19.41) (writing took 5.3434468768537045 seconds)
2023-07-02 11:54:32 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-07-02 11:54:32 | INFO | train | epoch 014 | loss 3.55 | trans_loss 3.821 | nll_loss 1.796 | w2v_ctc_loss 0.997 | task_loss 0.674 | contrastive_loss 0.165 | total 4138.65 | n_correct 2596.2 | ppl 3.47 | accuracy 62.731 | wps 9460.1 | ups 1.07 | wpb 8862.4 | bsz 329.2 | num_updates 20627 | lr 9.84684e-05 | gnorm 0.61 | clip 0 | loss_scale 64 | train_wall 1303 | gb_free 16.6 | wall 20711
2023-07-02 11:54:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 11:54:32 | INFO | fairseq.trainer | begin training epoch 15
2023-07-02 11:54:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 11:55:34 | INFO | train_inner | epoch 015:     73 / 1474 loss=3.947, trans_loss=5.409, nll_loss=2.722, w2v_ctc_loss=1.293, task_loss=1.452, contrastive_loss=0.314, total=4083.93, n_correct=2574.04, ppl=6.6, accuracy=63.029, wps=3628.1, ups=0.89, wpb=4083.9, bsz=150, num_updates=20700, lr=9.82946e-05, gnorm=0.952, clip=0, loss_scale=64, train_wall=73, gb_free=15.8, wall=20773
2023-07-02 11:56:47 | INFO | train_inner | epoch 015:    173 / 1474 loss=3.942, trans_loss=5.402, nll_loss=2.712, w2v_ctc_loss=1.315, task_loss=1.452, contrastive_loss=0.132, total=4122.67, n_correct=2604.65, ppl=6.55, accuracy=63.179, wps=5593.2, ups=1.36, wpb=4122.7, bsz=149.6, num_updates=20800, lr=9.80581e-05, gnorm=0.952, clip=0, loss_scale=64, train_wall=73, gb_free=17.4, wall=20847
2023-07-02 11:58:01 | INFO | train_inner | epoch 015:    273 / 1474 loss=3.924, trans_loss=5.394, nll_loss=2.703, w2v_ctc_loss=1.296, task_loss=1.452, contrastive_loss=0.118, total=4190.11, n_correct=2652.53, ppl=6.51, accuracy=63.305, wps=5720.6, ups=1.37, wpb=4190.1, bsz=156.3, num_updates=20900, lr=9.78232e-05, gnorm=0.947, clip=0, loss_scale=64, train_wall=73, gb_free=17.3, wall=20920
2023-07-02 11:59:14 | INFO | train_inner | epoch 015:    373 / 1474 loss=3.931, trans_loss=5.392, nll_loss=2.7, w2v_ctc_loss=1.294, task_loss=1.452, contrastive_loss=0.159, total=4150.33, n_correct=2626.01, ppl=6.5, accuracy=63.272, wps=5656.5, ups=1.36, wpb=4150.3, bsz=150.5, num_updates=21000, lr=9.759e-05, gnorm=0.954, clip=0, loss_scale=64, train_wall=73, gb_free=15.7, wall=20993
2023-07-02 11:59:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-02 12:00:28 | INFO | train_inner | epoch 015:    474 / 1474 loss=3.942, trans_loss=5.405, nll_loss=2.716, w2v_ctc_loss=1.303, task_loss=1.452, contrastive_loss=0.109, total=4061.99, n_correct=2562.04, ppl=6.57, accuracy=63.074, wps=5489.9, ups=1.35, wpb=4062, bsz=144.9, num_updates=21100, lr=9.73585e-05, gnorm=0.952, clip=0, loss_scale=32, train_wall=74, gb_free=16, wall=21067
2023-07-02 12:01:41 | INFO | train_inner | epoch 015:    574 / 1474 loss=3.951, trans_loss=5.408, nll_loss=2.722, w2v_ctc_loss=1.33, task_loss=1.452, contrastive_loss=0.131, total=4140.59, n_correct=2608.25, ppl=6.6, accuracy=62.992, wps=5635.8, ups=1.36, wpb=4140.6, bsz=149.4, num_updates=21200, lr=9.71286e-05, gnorm=0.956, clip=0, loss_scale=32, train_wall=73, gb_free=12.6, wall=21141
2023-07-02 12:02:55 | INFO | train_inner | epoch 015:    674 / 1474 loss=3.951, trans_loss=5.405, nll_loss=2.717, w2v_ctc_loss=1.313, task_loss=1.452, contrastive_loss=0.297, total=4134.99, n_correct=2609.74, ppl=6.58, accuracy=63.114, wps=5604.5, ups=1.36, wpb=4135, bsz=153.5, num_updates=21300, lr=9.69003e-05, gnorm=0.971, clip=0, loss_scale=32, train_wall=73, gb_free=11.1, wall=21214
2023-07-02 12:04:09 | INFO | train_inner | epoch 015:    774 / 1474 loss=3.949, trans_loss=5.413, nll_loss=2.729, w2v_ctc_loss=1.317, task_loss=1.452, contrastive_loss=0.139, total=4173.66, n_correct=2623.5, ppl=6.63, accuracy=62.858, wps=5636.3, ups=1.35, wpb=4173.7, bsz=152.5, num_updates=21400, lr=9.66736e-05, gnorm=0.946, clip=0, loss_scale=32, train_wall=74, gb_free=16.9, wall=21288
2023-07-02 12:05:22 | INFO | train_inner | epoch 015:    874 / 1474 loss=3.957, trans_loss=5.417, nll_loss=2.734, w2v_ctc_loss=1.32, task_loss=1.452, contrastive_loss=0.129, total=4059.35, n_correct=2551.32, ppl=6.65, accuracy=62.85, wps=5599, ups=1.38, wpb=4059.3, bsz=144.1, num_updates=21500, lr=9.64486e-05, gnorm=0.978, clip=0, loss_scale=32, train_wall=72, gb_free=15.8, wall=21361
2023-07-02 12:06:35 | INFO | train_inner | epoch 015:    974 / 1474 loss=3.949, trans_loss=5.407, nll_loss=2.721, w2v_ctc_loss=1.305, task_loss=1.452, contrastive_loss=0.298, total=4122.87, n_correct=2597.35, ppl=6.59, accuracy=62.999, wps=5632.2, ups=1.37, wpb=4122.9, bsz=150.8, num_updates=21600, lr=9.6225e-05, gnorm=0.956, clip=0, loss_scale=32, train_wall=73, gb_free=17.7, wall=21434
2023-07-02 12:07:49 | INFO | train_inner | epoch 015:   1074 / 1474 loss=3.959, trans_loss=5.415, nll_loss=2.732, w2v_ctc_loss=1.297, task_loss=1.452, contrastive_loss=0.609, total=4192.24, n_correct=2636.22, ppl=6.64, accuracy=62.883, wps=5661.2, ups=1.35, wpb=4192.2, bsz=162.6, num_updates=21700, lr=9.60031e-05, gnorm=0.955, clip=0, loss_scale=32, train_wall=74, gb_free=17.3, wall=21508
2023-07-02 12:09:02 | INFO | train_inner | epoch 015:   1174 / 1474 loss=3.916, trans_loss=5.397, nll_loss=2.712, w2v_ctc_loss=1.281, task_loss=1.452, contrastive_loss=0.221, total=4185, n_correct=2648.3, ppl=6.55, accuracy=63.281, wps=5744.6, ups=1.37, wpb=4185, bsz=164.6, num_updates=21800, lr=9.57826e-05, gnorm=0.935, clip=0, loss_scale=32, train_wall=72, gb_free=16.4, wall=21581
2023-07-02 12:10:15 | INFO | train_inner | epoch 015:   1274 / 1474 loss=3.953, trans_loss=5.412, nll_loss=2.729, w2v_ctc_loss=1.336, task_loss=1.452, contrastive_loss=0.134, total=4152.04, n_correct=2611.8, ppl=6.63, accuracy=62.904, wps=5649.4, ups=1.36, wpb=4152, bsz=151.8, num_updates=21900, lr=9.55637e-05, gnorm=0.966, clip=0, loss_scale=32, train_wall=73, gb_free=16.8, wall=21655
2023-07-02 12:11:30 | INFO | train_inner | epoch 015:   1374 / 1474 loss=3.943, trans_loss=5.404, nll_loss=2.718, w2v_ctc_loss=1.31, task_loss=1.452, contrastive_loss=0.108, total=4100.21, n_correct=2588.77, ppl=6.58, accuracy=63.137, wps=5535.9, ups=1.35, wpb=4100.2, bsz=146.8, num_updates=22000, lr=9.53463e-05, gnorm=0.95, clip=0, loss_scale=32, train_wall=74, gb_free=17.6, wall=21729
2023-07-02 12:11:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 12:11:56 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.349 | trans_loss 5.589 | nll_loss 2.862 | w2v_ctc_loss 1.344 | task_loss 0 | contrastive_loss 0.245 | total 4003.4 | n_correct 2466.8 | ppl 7.27 | accuracy 61.618 | uer 17.315 | wer 19.213 | raw_wer 19.213 | bleu 19.37 | wps 2098.8 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 19.48
2023-07-02 12:11:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-07-02 12:11:56 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_15_22000.pt
2023-07-02 12:11:59 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_15_22000.pt
2023-07-02 12:12:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.37) (writing took 6.413836709689349 seconds)
2023-07-02 12:13:18 | INFO | train_inner | epoch 015:   1474 / 1474 loss=3.951, trans_loss=5.416, nll_loss=2.735, w2v_ctc_loss=1.312, task_loss=1.452, contrastive_loss=0.285, total=4141.17, n_correct=2605.07, ppl=6.66, accuracy=62.907, wps=3805.8, ups=0.92, wpb=4141.2, bsz=157.2, num_updates=22100, lr=9.51303e-05, gnorm=0.957, clip=0, loss_scale=32, train_wall=75, gb_free=17.2, wall=21838
2023-07-02 12:13:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 12:13:46 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.363 | trans_loss 5.583 | nll_loss 2.862 | w2v_ctc_loss 1.403 | task_loss 0 | contrastive_loss 0.252 | total 4003.4 | n_correct 2463.6 | ppl 7.27 | accuracy 61.538 | uer 17.455 | wer 19.41 | raw_wer 19.41 | bleu 19.59 | wps 1983.3 | wpb 4003.4 | bsz 141.8 | num_updates 22100 | best_bleu 19.59
2023-07-02 12:13:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22100 updates
2023-07-02 12:13:46 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt
2023-07-02 12:13:50 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt
2023-07-02 12:13:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt (epoch 15 @ 22100 updates, score 19.59) (writing took 8.20267111202702 seconds)
2023-07-02 12:13:54 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-07-02 12:13:54 | INFO | train | epoch 015 | loss 3.943 | trans_loss 5.405 | nll_loss 2.719 | w2v_ctc_loss 1.307 | task_loss 1.452 | contrastive_loss 0.216 | total 4136.86 | n_correct 2609.13 | ppl 6.58 | accuracy 63.07 | wps 5242.2 | ups 1.27 | wpb 4136.9 | bsz 152.6 | num_updates 22100 | lr 9.51303e-05 | gnorm 0.955 | clip 0 | loss_scale 32 | train_wall 1078 | gb_free 17.2 | wall 21874
2023-07-02 12:13:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 12:13:55 | INFO | fairseq.trainer | begin training epoch 16
2023-07-02 12:13:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 12:15:16 | INFO | train_inner | epoch 016:    100 / 1474 loss=3.891, trans_loss=5.358, nll_loss=2.658, w2v_ctc_loss=1.276, task_loss=1.452, contrastive_loss=0.161, total=4126.22, n_correct=2634.31, ppl=6.31, accuracy=63.843, wps=3512.2, ups=0.85, wpb=4126.2, bsz=157.8, num_updates=22200, lr=9.49158e-05, gnorm=0.947, clip=0, loss_scale=32, train_wall=72, gb_free=16.3, wall=21955
2023-07-02 12:16:29 | INFO | train_inner | epoch 016:    200 / 1474 loss=3.893, trans_loss=5.355, nll_loss=2.653, w2v_ctc_loss=1.259, task_loss=1.452, contrastive_loss=0.117, total=4100.6, n_correct=2621.87, ppl=6.29, accuracy=63.939, wps=5590.4, ups=1.36, wpb=4100.6, bsz=148.4, num_updates=22300, lr=9.47027e-05, gnorm=0.941, clip=0, loss_scale=32, train_wall=73, gb_free=13, wall=22028
2023-07-02 12:17:42 | INFO | train_inner | epoch 016:    300 / 1474 loss=3.931, trans_loss=5.384, nll_loss=2.692, w2v_ctc_loss=1.306, task_loss=1.452, contrastive_loss=0.266, total=4166.94, n_correct=2643.87, ppl=6.46, accuracy=63.449, wps=5691.9, ups=1.37, wpb=4166.9, bsz=154.5, num_updates=22400, lr=9.44911e-05, gnorm=0.957, clip=0, loss_scale=32, train_wall=73, gb_free=17.3, wall=22102
2023-07-02 12:18:55 | INFO | train_inner | epoch 016:    400 / 1474 loss=3.943, trans_loss=5.385, nll_loss=2.691, w2v_ctc_loss=1.31, task_loss=1.452, contrastive_loss=0.295, total=4073.3, n_correct=2582.47, ppl=6.46, accuracy=63.4, wps=5584, ups=1.37, wpb=4073.3, bsz=144, num_updates=22500, lr=9.42809e-05, gnorm=0.962, clip=0, loss_scale=32, train_wall=72, gb_free=17.2, wall=22175
2023-07-02 12:20:09 | INFO | train_inner | epoch 016:    500 / 1474 loss=3.907, trans_loss=5.374, nll_loss=2.679, w2v_ctc_loss=1.287, task_loss=1.452, contrastive_loss=0.181, total=4174.67, n_correct=2660.43, ppl=6.41, accuracy=63.728, wps=5649.6, ups=1.35, wpb=4174.7, bsz=159.5, num_updates=22600, lr=9.40721e-05, gnorm=0.953, clip=0, loss_scale=32, train_wall=73, gb_free=16.2, wall=22248
2023-07-02 12:21:23 | INFO | train_inner | epoch 016:    600 / 1474 loss=3.912, trans_loss=5.374, nll_loss=2.679, w2v_ctc_loss=1.279, task_loss=1.452, contrastive_loss=0.108, total=4124.65, n_correct=2622.77, ppl=6.41, accuracy=63.588, wps=5598.1, ups=1.36, wpb=4124.6, bsz=148.8, num_updates=22700, lr=9.38647e-05, gnorm=0.944, clip=0, loss_scale=32, train_wall=73, gb_free=16.4, wall=22322
2023-07-02 12:22:36 | INFO | train_inner | epoch 016:    700 / 1474 loss=3.924, trans_loss=5.383, nll_loss=2.691, w2v_ctc_loss=1.3, task_loss=1.452, contrastive_loss=0.114, total=4095.49, n_correct=2593.45, ppl=6.46, accuracy=63.325, wps=5584.9, ups=1.36, wpb=4095.5, bsz=148.2, num_updates=22800, lr=9.36586e-05, gnorm=0.958, clip=0, loss_scale=32, train_wall=73, gb_free=16.4, wall=22395
2023-07-02 12:23:49 | INFO | train_inner | epoch 016:    800 / 1474 loss=3.918, trans_loss=5.381, nll_loss=2.688, w2v_ctc_loss=1.278, task_loss=1.452, contrastive_loss=0.233, total=4174.94, n_correct=2646.58, ppl=6.45, accuracy=63.392, wps=5710.2, ups=1.37, wpb=4174.9, bsz=155.4, num_updates=22900, lr=9.34539e-05, gnorm=0.949, clip=0, loss_scale=32, train_wall=73, gb_free=16.6, wall=22469
2023-07-02 12:25:03 | INFO | train_inner | epoch 016:    900 / 1474 loss=3.907, trans_loss=5.369, nll_loss=2.673, w2v_ctc_loss=1.274, task_loss=1.452, contrastive_loss=0.219, total=4163.19, n_correct=2653.86, ppl=6.38, accuracy=63.746, wps=5678.2, ups=1.36, wpb=4163.2, bsz=155.3, num_updates=23000, lr=9.32505e-05, gnorm=0.932, clip=0, loss_scale=32, train_wall=73, gb_free=17.1, wall=22542
2023-07-02 12:26:16 | INFO | train_inner | epoch 016:   1000 / 1474 loss=3.94, trans_loss=5.395, nll_loss=2.706, w2v_ctc_loss=1.308, task_loss=1.452, contrastive_loss=0.213, total=4103.45, n_correct=2591.8, ppl=6.52, accuracy=63.161, wps=5587.6, ups=1.36, wpb=4103.4, bsz=149, num_updates=23100, lr=9.30484e-05, gnorm=0.949, clip=0, loss_scale=64, train_wall=73, gb_free=15.1, wall=22615
2023-07-02 12:27:30 | INFO | train_inner | epoch 016:   1100 / 1474 loss=3.945, trans_loss=5.397, nll_loss=2.71, w2v_ctc_loss=1.321, task_loss=1.452, contrastive_loss=0.166, total=4119.27, n_correct=2604.66, ppl=6.54, accuracy=63.231, wps=5577.7, ups=1.35, wpb=4119.3, bsz=147.7, num_updates=23200, lr=9.28477e-05, gnorm=0.971, clip=0, loss_scale=64, train_wall=73, gb_free=17.9, wall=22689
2023-07-02 12:28:44 | INFO | train_inner | epoch 016:   1200 / 1474 loss=3.937, trans_loss=5.393, nll_loss=2.705, w2v_ctc_loss=1.286, task_loss=1.452, contrastive_loss=0.359, total=4165.11, n_correct=2632.11, ppl=6.52, accuracy=63.194, wps=5616.6, ups=1.35, wpb=4165.1, bsz=154.3, num_updates=23300, lr=9.26482e-05, gnorm=0.946, clip=0, loss_scale=64, train_wall=74, gb_free=17, wall=22763
2023-07-02 12:29:58 | INFO | train_inner | epoch 016:   1300 / 1474 loss=3.942, trans_loss=5.399, nll_loss=2.713, w2v_ctc_loss=1.311, task_loss=1.452, contrastive_loss=0.322, total=4134.61, n_correct=2614.52, ppl=6.56, accuracy=63.235, wps=5570.7, ups=1.35, wpb=4134.6, bsz=155.4, num_updates=23400, lr=9.245e-05, gnorm=0.964, clip=0, loss_scale=64, train_wall=74, gb_free=16.9, wall=22838
2023-07-02 12:31:13 | INFO | train_inner | epoch 016:   1400 / 1474 loss=3.92, trans_loss=5.39, nll_loss=2.702, w2v_ctc_loss=1.3, task_loss=1.452, contrastive_loss=0.175, total=4206.33, n_correct=2664.12, ppl=6.51, accuracy=63.336, wps=5643.1, ups=1.34, wpb=4206.3, bsz=161.1, num_updates=23500, lr=9.22531e-05, gnorm=0.95, clip=0, loss_scale=64, train_wall=74, gb_free=15.7, wall=22912
2023-07-02 12:32:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 12:32:35 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.339 | trans_loss 5.58 | nll_loss 2.86 | w2v_ctc_loss 1.338 | task_loss 0 | contrastive_loss 0.237 | total 4003.4 | n_correct 2464.8 | ppl 7.26 | accuracy 61.568 | uer 17.15 | wer 18.84 | raw_wer 18.84 | bleu 19.92 | wps 1895.5 | wpb 4003.4 | bsz 141.8 | num_updates 23574 | best_bleu 19.92
2023-07-02 12:32:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23574 updates
2023-07-02 12:32:35 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt
2023-07-02 12:32:39 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt
2023-07-02 12:32:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt (epoch 16 @ 23574 updates, score 19.92) (writing took 7.950809340924025 seconds)
2023-07-02 12:32:43 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-07-02 12:32:43 | INFO | train | epoch 016 | loss 3.924 | trans_loss 5.382 | nll_loss 2.69 | w2v_ctc_loss 1.293 | task_loss 1.452 | contrastive_loss 0.227 | total 4138.65 | n_correct 2626.39 | ppl 6.45 | accuracy 63.46 | wps 5404.9 | ups 1.31 | wpb 4138.6 | bsz 152.8 | num_updates 23574 | lr 9.21082e-05 | gnorm 0.952 | clip 0 | loss_scale 64 | train_wall 1078 | gb_free 15.6 | wall 23002
2023-07-02 12:32:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 12:32:43 | INFO | fairseq.trainer | begin training epoch 17
2023-07-02 12:32:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 12:33:10 | INFO | train_inner | epoch 017:     26 / 1474 loss=3.928, trans_loss=5.374, nll_loss=2.681, w2v_ctc_loss=1.285, task_loss=1.452, contrastive_loss=0.447, total=4152.31, n_correct=2641.86, ppl=6.41, accuracy=63.624, wps=3534, ups=0.85, wpb=4152.3, bsz=152.3, num_updates=23600, lr=9.20575e-05, gnorm=0.962, clip=0, loss_scale=64, train_wall=74, gb_free=14.2, wall=23030
2023-07-02 12:34:24 | INFO | train_inner | epoch 017:    126 / 1474 loss=3.898, trans_loss=5.346, nll_loss=2.643, w2v_ctc_loss=1.288, task_loss=1.452, contrastive_loss=0.117, total=4118.91, n_correct=2635.8, ppl=6.25, accuracy=63.993, wps=5607.1, ups=1.36, wpb=4118.9, bsz=147.9, num_updates=23700, lr=9.1863e-05, gnorm=0.946, clip=0, loss_scale=64, train_wall=73, gb_free=16.6, wall=23103
2023-07-02 12:35:37 | INFO | train_inner | epoch 017:    226 / 1474 loss=3.906, trans_loss=5.351, nll_loss=2.651, w2v_ctc_loss=1.267, task_loss=1.452, contrastive_loss=0.46, total=4145.15, n_correct=2650.59, ppl=6.28, accuracy=63.944, wps=5658.2, ups=1.37, wpb=4145.1, bsz=157.5, num_updates=23800, lr=9.16698e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=73, gb_free=15.8, wall=23176
2023-07-02 12:36:50 | INFO | train_inner | epoch 017:    326 / 1474 loss=3.906, trans_loss=5.349, nll_loss=2.648, w2v_ctc_loss=1.27, task_loss=1.452, contrastive_loss=0.457, total=4169.51, n_correct=2665.8, ppl=6.27, accuracy=63.936, wps=5701.4, ups=1.37, wpb=4169.5, bsz=154.1, num_updates=23900, lr=9.14779e-05, gnorm=0.941, clip=0, loss_scale=64, train_wall=73, gb_free=17, wall=23249
2023-07-02 12:38:04 | INFO | train_inner | epoch 017:    426 / 1474 loss=3.894, trans_loss=5.354, nll_loss=2.654, w2v_ctc_loss=1.282, task_loss=1.452, contrastive_loss=0.116, total=4140.49, n_correct=2649.76, ppl=6.3, accuracy=63.996, wps=5618.9, ups=1.36, wpb=4140.5, bsz=153.4, num_updates=24000, lr=9.12871e-05, gnorm=0.941, clip=0, loss_scale=64, train_wall=73, gb_free=17.1, wall=23323
2023-07-02 12:38:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 12:38:29 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.34 | trans_loss 5.578 | nll_loss 2.855 | w2v_ctc_loss 1.344 | task_loss 0 | contrastive_loss 0.243 | total 4003.4 | n_correct 2466.8 | ppl 7.24 | accuracy 61.618 | uer 16.996 | wer 18.791 | raw_wer 18.791 | bleu 19.76 | wps 2182.1 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 19.92
2023-07-02 12:38:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-07-02 12:38:29 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_17_24000.pt
2023-07-02 12:38:32 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_17_24000.pt
2023-07-02 12:38:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.76) (writing took 6.153199224732816 seconds)
2023-07-02 12:39:51 | INFO | train_inner | epoch 017:    526 / 1474 loss=3.909, trans_loss=5.36, nll_loss=2.663, w2v_ctc_loss=1.291, task_loss=1.452, contrastive_loss=0.208, total=4184.16, n_correct=2668.7, ppl=6.33, accuracy=63.781, wps=3904.5, ups=0.93, wpb=4184.2, bsz=153.5, num_updates=24100, lr=9.10975e-05, gnorm=0.943, clip=0, loss_scale=64, train_wall=75, gb_free=17.4, wall=23430
2023-07-02 12:41:05 | INFO | train_inner | epoch 017:    626 / 1474 loss=3.898, trans_loss=5.357, nll_loss=2.658, w2v_ctc_loss=1.277, task_loss=1.452, contrastive_loss=0.109, total=4166.61, n_correct=2660.64, ppl=6.31, accuracy=63.856, wps=5645.7, ups=1.35, wpb=4166.6, bsz=151.7, num_updates=24200, lr=9.09091e-05, gnorm=0.936, clip=0, loss_scale=64, train_wall=73, gb_free=17.1, wall=23504
2023-07-02 12:42:19 | INFO | train_inner | epoch 017:    726 / 1474 loss=3.921, trans_loss=5.372, nll_loss=2.678, w2v_ctc_loss=1.307, task_loss=1.452, contrastive_loss=0.207, total=4167.85, n_correct=2653.61, ppl=6.4, accuracy=63.669, wps=5645.5, ups=1.35, wpb=4167.9, bsz=154.2, num_updates=24300, lr=9.07218e-05, gnorm=0.951, clip=0, loss_scale=64, train_wall=73, gb_free=15.4, wall=23578
2023-07-02 12:43:32 | INFO | train_inner | epoch 017:    826 / 1474 loss=3.91, trans_loss=5.365, nll_loss=2.668, w2v_ctc_loss=1.291, task_loss=1.452, contrastive_loss=0.131, total=4093.22, n_correct=2606.61, ppl=6.36, accuracy=63.681, wps=5609.5, ups=1.37, wpb=4093.2, bsz=148.2, num_updates=24400, lr=9.05357e-05, gnorm=0.95, clip=0, loss_scale=64, train_wall=72, gb_free=16.5, wall=23651
2023-07-02 12:44:44 | INFO | train_inner | epoch 017:    926 / 1474 loss=3.893, trans_loss=5.356, nll_loss=2.657, w2v_ctc_loss=1.267, task_loss=1.452, contrastive_loss=0.125, total=4099.33, n_correct=2619.58, ppl=6.31, accuracy=63.903, wps=5664.8, ups=1.38, wpb=4099.3, bsz=150.9, num_updates=24500, lr=9.03508e-05, gnorm=0.95, clip=0, loss_scale=64, train_wall=72, gb_free=16.5, wall=23723
2023-07-02 12:45:57 | INFO | train_inner | epoch 017:   1026 / 1474 loss=3.894, trans_loss=5.353, nll_loss=2.655, w2v_ctc_loss=1.283, task_loss=1.452, contrastive_loss=0.137, total=4123.22, n_correct=2636.96, ppl=6.3, accuracy=63.954, wps=5655.2, ups=1.37, wpb=4123.2, bsz=153.8, num_updates=24600, lr=9.0167e-05, gnorm=0.946, clip=0, loss_scale=64, train_wall=72, gb_free=17.2, wall=23796
2023-07-02 12:47:10 | INFO | train_inner | epoch 017:   1126 / 1474 loss=3.895, trans_loss=5.355, nll_loss=2.656, w2v_ctc_loss=1.266, task_loss=1.452, contrastive_loss=0.109, total=4068.18, n_correct=2597.75, ppl=6.3, accuracy=63.855, wps=5614.9, ups=1.38, wpb=4068.2, bsz=146.7, num_updates=24700, lr=8.99843e-05, gnorm=0.959, clip=0, loss_scale=64, train_wall=72, gb_free=10.8, wall=23869
2023-07-02 12:48:24 | INFO | train_inner | epoch 017:   1226 / 1474 loss=3.941, trans_loss=5.39, nll_loss=2.703, w2v_ctc_loss=1.285, task_loss=1.452, contrastive_loss=0.601, total=4170.85, n_correct=2637.94, ppl=6.51, accuracy=63.247, wps=5616.4, ups=1.35, wpb=4170.9, bsz=160.7, num_updates=24800, lr=8.98027e-05, gnorm=0.962, clip=0, loss_scale=64, train_wall=74, gb_free=14.1, wall=23943
2023-07-02 12:49:37 | INFO | train_inner | epoch 017:   1326 / 1474 loss=3.903, trans_loss=5.362, nll_loss=2.667, w2v_ctc_loss=1.264, task_loss=1.452, contrastive_loss=0.271, total=4166.32, n_correct=2653.67, ppl=6.35, accuracy=63.693, wps=5663.4, ups=1.36, wpb=4166.3, bsz=155.6, num_updates=24900, lr=8.96221e-05, gnorm=0.952, clip=0, loss_scale=64, train_wall=73, gb_free=15.9, wall=24017
2023-07-02 12:50:51 | INFO | train_inner | epoch 017:   1426 / 1474 loss=3.902, trans_loss=5.366, nll_loss=2.671, w2v_ctc_loss=1.28, task_loss=1.452, contrastive_loss=0.116, total=4115.33, n_correct=2621.45, ppl=6.37, accuracy=63.7, wps=5568, ups=1.35, wpb=4115.3, bsz=151.7, num_updates=25000, lr=8.94427e-05, gnorm=0.958, clip=0, loss_scale=64, train_wall=73, gb_free=11.9, wall=24090
tensor(0.0172, device='cuda:0')
tensor(0.0009, device='cuda:0')
2023-07-02 12:51:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0172, device='cuda:7')
tensor(0.0009, device='cuda:7')
tensor(0.0172, device='cuda:2')
tensor(0.0009, device='cuda:2')
tensor(0.0172, device='cuda:4')
tensor(0.0009, device='cuda:4')
tensor(0.0172, device='cuda:5')
tensor(0.0009, device='cuda:5')
tensor(0.0172, device='cuda:6')
tensor(0.0009, device='cuda:6')
tensor(0.0172, device='cuda:3')
tensor(0.0009, device='cuda:3')
tensor(0.0172, device='cuda:1')
tensor(0.0009, device='cuda:1')
2023-07-02 12:51:54 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.332 | trans_loss 5.565 | nll_loss 2.843 | w2v_ctc_loss 1.347 | task_loss 0 | contrastive_loss 0.24 | total 4003.4 | n_correct 2473.6 | ppl 7.17 | accuracy 61.787 | uer 17.036 | wer 18.952 | raw_wer 18.952 | bleu 19.8 | wps 2082.1 | wpb 4003.4 | bsz 141.8 | num_updates 25048 | best_bleu 19.92
2023-07-02 12:51:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25048 updates
2023-07-02 12:51:54 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_19.8000.pt
2023-07-02 12:51:56 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_19.8000.pt
2023-07-02 12:51:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_19.8000.pt (epoch 17 @ 25048 updates, score 19.8) (writing took 5.293975489679724 seconds)
2023-07-02 12:51:59 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-07-02 12:51:59 | INFO | train | epoch 017 | loss 3.905 | trans_loss 5.36 | nll_loss 2.662 | w2v_ctc_loss 1.28 | task_loss 1.452 | contrastive_loss 0.224 | total 4138.65 | n_correct 2640.8 | ppl 6.33 | accuracy 63.808 | wps 5275.7 | ups 1.27 | wpb 4138.6 | bsz 152.8 | num_updates 25048 | lr 8.9357e-05 | gnorm 0.95 | clip 0 | loss_scale 64 | train_wall 1077 | gb_free 16.6 | wall 24159
2023-07-02 12:52:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 12:52:00 | INFO | fairseq.trainer | begin training epoch 18
2023-07-02 12:52:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 12:52:47 | INFO | train_inner | epoch 018:     52 / 1474 loss=3.896, trans_loss=5.35, nll_loss=2.65, w2v_ctc_loss=1.285, task_loss=1.452, contrastive_loss=0.135, total=4144.39, n_correct=2649.66, ppl=6.28, accuracy=63.934, wps=3592.5, ups=0.87, wpb=4144.4, bsz=151.8, num_updates=25100, lr=8.92644e-05, gnorm=0.951, clip=0, loss_scale=64, train_wall=74, gb_free=14.7, wall=24206
2023-07-02 12:54:00 | INFO | train_inner | epoch 018:    152 / 1474 loss=3.871, trans_loss=5.319, nll_loss=2.609, w2v_ctc_loss=1.231, task_loss=1.452, contrastive_loss=0.384, total=4146.83, n_correct=2672.65, ppl=6.1, accuracy=64.45, wps=5650.9, ups=1.36, wpb=4146.8, bsz=155.6, num_updates=25200, lr=8.90871e-05, gnorm=0.935, clip=0, loss_scale=128, train_wall=73, gb_free=16.6, wall=24279
2023-07-02 12:55:14 | INFO | train_inner | epoch 018:    252 / 1474 loss=3.859, trans_loss=5.318, nll_loss=2.608, w2v_ctc_loss=1.254, task_loss=1.452, contrastive_loss=0.118, total=4158.7, n_correct=2682.84, ppl=6.1, accuracy=64.512, wps=5635.8, ups=1.36, wpb=4158.7, bsz=156.2, num_updates=25300, lr=8.89108e-05, gnorm=0.936, clip=0, loss_scale=128, train_wall=73, gb_free=10.5, wall=24353
2023-07-02 12:55:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-02 12:55:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-02 12:56:29 | INFO | train_inner | epoch 018:    354 / 1474 loss=3.886, trans_loss=5.337, nll_loss=2.633, w2v_ctc_loss=1.259, task_loss=1.875, contrastive_loss=0.162, total=4173.16, n_correct=2676.48, ppl=6.2, accuracy=64.136, wps=5573.6, ups=1.34, wpb=4173.2, bsz=151.6, num_updates=25400, lr=8.87357e-05, gnorm=1.015, clip=0, loss_scale=32, train_wall=74, gb_free=17.7, wall=24428
2023-07-02 12:57:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-02 12:57:44 | INFO | train_inner | epoch 018:    455 / 1474 loss=3.91, trans_loss=5.345, nll_loss=2.643, w2v_ctc_loss=1.279, task_loss=2.89, contrastive_loss=0.186, total=4066.06, n_correct=2602.33, ppl=6.24, accuracy=64.001, wps=5416.4, ups=1.33, wpb=4066.1, bsz=143.9, num_updates=25500, lr=8.85615e-05, gnorm=0.978, clip=0, loss_scale=16, train_wall=75, gb_free=17.9, wall=24503
2023-07-02 12:58:57 | INFO | train_inner | epoch 018:    555 / 1474 loss=3.913, trans_loss=5.346, nll_loss=2.647, w2v_ctc_loss=1.248, task_loss=2.869, contrastive_loss=0.325, total=4218.07, n_correct=2701.63, ppl=6.26, accuracy=64.049, wps=5735.8, ups=1.36, wpb=4218.1, bsz=164.8, num_updates=25600, lr=8.83883e-05, gnorm=1.025, clip=0, loss_scale=16, train_wall=73, gb_free=16.1, wall=24577
2023-07-02 13:00:11 | INFO | train_inner | epoch 018:    655 / 1474 loss=4.019, trans_loss=5.431, nll_loss=2.752, w2v_ctc_loss=1.288, task_loss=2.112, contrastive_loss=0.529, total=4093.44, n_correct=2566.66, ppl=6.74, accuracy=62.702, wps=5545.9, ups=1.35, wpb=4093.4, bsz=149.3, num_updates=25700, lr=8.82162e-05, gnorm=1.119, clip=0, loss_scale=16, train_wall=73, gb_free=15.4, wall=24650
2023-07-02 13:01:25 | INFO | train_inner | epoch 018:    755 / 1474 loss=3.922, trans_loss=5.363, nll_loss=2.667, w2v_ctc_loss=1.29, task_loss=2, contrastive_loss=0.504, total=4202.99, n_correct=2680.62, ppl=6.35, accuracy=63.779, wps=5680.2, ups=1.35, wpb=4203, bsz=161.2, num_updates=25800, lr=8.80451e-05, gnorm=1.027, clip=0, loss_scale=16, train_wall=74, gb_free=17.7, wall=24724
2023-07-02 13:02:39 | INFO | train_inner | epoch 018:    855 / 1474 loss=3.896, trans_loss=5.351, nll_loss=2.65, w2v_ctc_loss=1.269, task_loss=2, contrastive_loss=0.136, total=4177.43, n_correct=2672.35, ppl=6.28, accuracy=63.971, wps=5670.6, ups=1.36, wpb=4177.4, bsz=152.4, num_updates=25900, lr=8.7875e-05, gnorm=0.954, clip=0, loss_scale=16, train_wall=73, gb_free=16.4, wall=24798
2023-07-02 13:03:51 | INFO | train_inner | epoch 018:    955 / 1474 loss=3.871, trans_loss=5.336, nll_loss=2.632, w2v_ctc_loss=1.249, task_loss=2, contrastive_loss=0.148, total=4138.23, n_correct=2657.89, ppl=6.2, accuracy=64.228, wps=5727.1, ups=1.38, wpb=4138.2, bsz=157.2, num_updates=26000, lr=8.77058e-05, gnorm=0.954, clip=0, loss_scale=16, train_wall=72, gb_free=16.7, wall=24870
2023-07-02 13:03:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 13:04:16 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.333 | trans_loss 5.572 | nll_loss 2.846 | w2v_ctc_loss 1.327 | task_loss 0 | contrastive_loss 0.248 | total 4003.4 | n_correct 2471.1 | ppl 7.19 | accuracy 61.725 | uer 17.015 | wer 18.948 | raw_wer 18.948 | bleu 19.77 | wps 2332.8 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 19.92
2023-07-02 13:04:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-07-02 13:04:16 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_18_26000.pt
2023-07-02 13:04:19 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_18_26000.pt
2023-07-02 13:04:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 19.77) (writing took 6.2418295638635755 seconds)
2023-07-02 13:05:37 | INFO | train_inner | epoch 018:   1055 / 1474 loss=3.893, trans_loss=5.347, nll_loss=2.646, w2v_ctc_loss=1.265, task_loss=2, contrastive_loss=0.138, total=4133.59, n_correct=2643.49, ppl=6.26, accuracy=63.951, wps=3908.7, ups=0.95, wpb=4133.6, bsz=149.3, num_updates=26100, lr=8.75376e-05, gnorm=0.965, clip=0, loss_scale=16, train_wall=73, gb_free=16.1, wall=24976
2023-07-02 13:06:51 | INFO | train_inner | epoch 018:   1155 / 1474 loss=3.889, trans_loss=5.335, nll_loss=2.632, w2v_ctc_loss=1.263, task_loss=2, contrastive_loss=0.35, total=4154.22, n_correct=2670.07, ppl=6.2, accuracy=64.274, wps=5634.9, ups=1.36, wpb=4154.2, bsz=157.5, num_updates=26200, lr=8.73704e-05, gnorm=0.952, clip=0, loss_scale=16, train_wall=73, gb_free=15.2, wall=25050
2023-07-02 13:08:04 | INFO | train_inner | epoch 018:   1255 / 1474 loss=3.903, trans_loss=5.351, nll_loss=2.652, w2v_ctc_loss=1.274, task_loss=2, contrastive_loss=0.123, total=4089.17, n_correct=2613.48, ppl=6.28, accuracy=63.912, wps=5557, ups=1.36, wpb=4089.2, bsz=143.8, num_updates=26300, lr=8.72041e-05, gnorm=0.947, clip=0, loss_scale=16, train_wall=73, gb_free=16.9, wall=25123
2023-07-02 13:09:17 | INFO | train_inner | epoch 018:   1355 / 1474 loss=3.925, trans_loss=5.369, nll_loss=2.676, w2v_ctc_loss=1.31, task_loss=2, contrastive_loss=0.173, total=4068.84, n_correct=2593.05, ppl=6.39, accuracy=63.729, wps=5579.6, ups=1.37, wpb=4068.8, bsz=145.7, num_updates=26400, lr=8.70388e-05, gnorm=0.976, clip=0, loss_scale=16, train_wall=72, gb_free=15.6, wall=25196
2023-07-02 13:10:31 | INFO | train_inner | epoch 018:   1455 / 1474 loss=3.905, trans_loss=5.355, nll_loss=2.658, w2v_ctc_loss=1.283, task_loss=2, contrastive_loss=0.146, total=4113.23, n_correct=2623.16, ppl=6.31, accuracy=63.774, wps=5561.8, ups=1.35, wpb=4113.2, bsz=148.6, num_updates=26500, lr=8.68744e-05, gnorm=0.964, clip=0, loss_scale=16, train_wall=74, gb_free=16.7, wall=25270
2023-07-02 13:10:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 13:11:09 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.347 | trans_loss 5.571 | nll_loss 2.845 | w2v_ctc_loss 1.375 | task_loss 0 | contrastive_loss 0.252 | total 4003.4 | n_correct 2470 | ppl 7.19 | accuracy 61.698 | uer 16.935 | wer 18.929 | raw_wer 18.929 | bleu 20.31 | wps 2277.2 | wpb 4003.4 | bsz 141.8 | num_updates 26519 | best_bleu 20.31
2023-07-02 13:11:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26519 updates
2023-07-02 13:11:09 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt
2023-07-02 13:11:13 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt
2023-07-02 13:11:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_best.pt (epoch 18 @ 26519 updates, score 20.31) (writing took 8.08999592764303 seconds)
2023-07-02 13:11:18 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-07-02 13:11:18 | INFO | train | epoch 018 | loss 3.904 | trans_loss 5.349 | nll_loss 2.649 | w2v_ctc_loss 1.268 | task_loss 2.025 | contrastive_loss 0.251 | total 4138.08 | n_correct 2647.1 | ppl 6.27 | accuracy 63.969 | wps 5256 | ups 1.27 | wpb 4138.1 | bsz 152.7 | num_updates 26519 | lr 8.68433e-05 | gnorm 0.981 | clip 0 | loss_scale 16 | train_wall 1078 | gb_free 16.1 | wall 25317
2023-07-02 13:11:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 13:11:18 | INFO | fairseq.trainer | begin training epoch 19
2023-07-02 13:11:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 13:12:26 | INFO | train_inner | epoch 019:     81 / 1474 loss=3.873, trans_loss=5.315, nll_loss=2.605, w2v_ctc_loss=1.248, task_loss=2, contrastive_loss=0.246, total=4107.26, n_correct=2648.67, ppl=6.08, accuracy=64.488, wps=3573.9, ups=0.87, wpb=4107.3, bsz=148.8, num_updates=26600, lr=8.6711e-05, gnorm=0.956, clip=0, loss_scale=16, train_wall=73, gb_free=13.1, wall=25385
2023-07-02 13:13:40 | INFO | train_inner | epoch 019:    181 / 1474 loss=3.858, trans_loss=5.305, nll_loss=2.592, w2v_ctc_loss=1.261, task_loss=2, contrastive_loss=0.228, total=4222.18, n_correct=2730.43, ppl=6.03, accuracy=64.669, wps=5703.1, ups=1.35, wpb=4222.2, bsz=162.2, num_updates=26700, lr=8.65485e-05, gnorm=0.941, clip=0, loss_scale=16, train_wall=74, gb_free=12.1, wall=25459
2023-07-02 13:14:53 | INFO | train_inner | epoch 019:    281 / 1474 loss=3.85, trans_loss=5.298, nll_loss=2.582, w2v_ctc_loss=1.245, task_loss=2, contrastive_loss=0.116, total=4187.37, n_correct=2715.46, ppl=5.99, accuracy=64.849, wps=5712.6, ups=1.36, wpb=4187.4, bsz=153.5, num_updates=26800, lr=8.63868e-05, gnorm=0.933, clip=0, loss_scale=16, train_wall=73, gb_free=17.6, wall=25533
2023-07-02 13:16:08 | INFO | train_inner | epoch 019:    381 / 1474 loss=3.866, trans_loss=5.309, nll_loss=2.598, w2v_ctc_loss=1.234, task_loss=2, contrastive_loss=0.327, total=4170.67, n_correct=2691.81, ppl=6.06, accuracy=64.541, wps=5600, ups=1.34, wpb=4170.7, bsz=155.3, num_updates=26900, lr=8.62261e-05, gnorm=0.944, clip=0, loss_scale=16, train_wall=74, gb_free=17.3, wall=25607
2023-07-02 13:17:21 | INFO | train_inner | epoch 019:    481 / 1474 loss=3.869, trans_loss=5.318, nll_loss=2.609, w2v_ctc_loss=1.26, task_loss=2, contrastive_loss=0.145, total=4115.22, n_correct=2654.72, ppl=6.1, accuracy=64.51, wps=5618.6, ups=1.37, wpb=4115.2, bsz=150.9, num_updates=27000, lr=8.60663e-05, gnorm=0.953, clip=0, loss_scale=16, train_wall=73, gb_free=15.3, wall=25680
2023-07-02 13:18:34 | INFO | train_inner | epoch 019:    581 / 1474 loss=3.865, trans_loss=5.313, nll_loss=2.603, w2v_ctc_loss=1.242, task_loss=2, contrastive_loss=0.273, total=4129.22, n_correct=2663.32, ppl=6.07, accuracy=64.499, wps=5631.7, ups=1.36, wpb=4129.2, bsz=153, num_updates=27100, lr=8.59074e-05, gnorm=0.947, clip=0, loss_scale=16, train_wall=73, gb_free=16.1, wall=25754
2023-07-02 13:19:48 | INFO | train_inner | epoch 019:    681 / 1474 loss=3.846, trans_loss=5.312, nll_loss=2.602, w2v_ctc_loss=1.229, task_loss=2, contrastive_loss=0.129, total=4197.2, n_correct=2706.95, ppl=6.07, accuracy=64.494, wps=5723.9, ups=1.36, wpb=4197.2, bsz=160.4, num_updates=27200, lr=8.57493e-05, gnorm=0.942, clip=0, loss_scale=16, train_wall=73, gb_free=14.9, wall=25827
2023-07-02 13:21:01 | INFO | train_inner | epoch 019:    781 / 1474 loss=3.867, trans_loss=5.316, nll_loss=2.606, w2v_ctc_loss=1.26, task_loss=2, contrastive_loss=0.149, total=4142.6, n_correct=2671.69, ppl=6.09, accuracy=64.493, wps=5632.9, ups=1.36, wpb=4142.6, bsz=152.5, num_updates=27300, lr=8.55921e-05, gnorm=0.939, clip=0, loss_scale=16, train_wall=73, gb_free=16.6, wall=25900
2023-07-02 13:22:14 | INFO | train_inner | epoch 019:    881 / 1474 loss=3.879, trans_loss=5.331, nll_loss=2.626, w2v_ctc_loss=1.266, task_loss=2, contrastive_loss=0.12, total=4153.47, n_correct=2666.88, ppl=6.17, accuracy=64.208, wps=5681.2, ups=1.37, wpb=4153.5, bsz=151.5, num_updates=27400, lr=8.54358e-05, gnorm=0.952, clip=0, loss_scale=16, train_wall=73, gb_free=16.4, wall=25974
2023-07-02 13:23:29 | INFO | train_inner | epoch 019:    981 / 1474 loss=3.904, trans_loss=5.343, nll_loss=2.644, w2v_ctc_loss=1.254, task_loss=2, contrastive_loss=0.59, total=4101.29, n_correct=2630.96, ppl=6.25, accuracy=64.15, wps=5526.1, ups=1.35, wpb=4101.3, bsz=155, num_updates=27500, lr=8.52803e-05, gnorm=0.959, clip=0, loss_scale=16, train_wall=74, gb_free=16.8, wall=26048
2023-07-02 13:24:42 | INFO | train_inner | epoch 019:   1081 / 1474 loss=3.898, trans_loss=5.346, nll_loss=2.647, w2v_ctc_loss=1.264, task_loss=2, contrastive_loss=0.208, total=4036.97, n_correct=2587.96, ppl=6.26, accuracy=64.106, wps=5486.7, ups=1.36, wpb=4037, bsz=145.5, num_updates=27600, lr=8.51257e-05, gnorm=0.972, clip=0, loss_scale=32, train_wall=73, gb_free=14.9, wall=26121
2023-07-02 13:25:57 | INFO | train_inner | epoch 019:   1181 / 1474 loss=3.9, trans_loss=5.342, nll_loss=2.641, w2v_ctc_loss=1.269, task_loss=2, contrastive_loss=0.373, total=4137.49, n_correct=2649.53, ppl=6.24, accuracy=64.037, wps=5555.4, ups=1.34, wpb=4137.5, bsz=153.8, num_updates=27700, lr=8.49719e-05, gnorm=0.968, clip=0, loss_scale=32, train_wall=74, gb_free=15.1, wall=26196
2023-07-02 13:27:10 | INFO | train_inner | epoch 019:   1281 / 1474 loss=3.886, trans_loss=5.339, nll_loss=2.638, w2v_ctc_loss=1.251, task_loss=2, contrastive_loss=0.169, total=4141.89, n_correct=2656.45, ppl=6.23, accuracy=64.136, wps=5635.8, ups=1.36, wpb=4141.9, bsz=150.1, num_updates=27800, lr=8.48189e-05, gnorm=0.952, clip=0, loss_scale=32, train_wall=73, gb_free=15.9, wall=26269
2023-07-02 13:28:24 | INFO | train_inner | epoch 019:   1381 / 1474 loss=3.877, trans_loss=5.328, nll_loss=2.623, w2v_ctc_loss=1.257, task_loss=2, contrastive_loss=0.14, total=4133.26, n_correct=2657.15, ppl=6.16, accuracy=64.287, wps=5612, ups=1.36, wpb=4133.3, bsz=150.5, num_updates=27900, lr=8.46668e-05, gnorm=0.948, clip=0, loss_scale=32, train_wall=73, gb_free=16.4, wall=26343
2023-07-02 13:29:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-02 13:29:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 13:29:57 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.343 | trans_loss 5.555 | nll_loss 2.83 | w2v_ctc_loss 1.399 | task_loss 0 | contrastive_loss 0.259 | total 4003.4 | n_correct 2484.1 | ppl 7.11 | accuracy 62.05 | uer 17.126 | wer 19.007 | raw_wer 19.007 | bleu 20.08 | wps 2205.6 | wpb 4003.4 | bsz 141.8 | num_updates 27992 | best_bleu 20.31
2023-07-02 13:29:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27992 updates
2023-07-02 13:29:57 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.0806.pt
2023-07-02 13:29:59 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.0806.pt
2023-07-02 13:30:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.0806.pt (epoch 19 @ 27992 updates, score 20.08) (writing took 5.496833276003599 seconds)
2023-07-02 13:30:02 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-07-02 13:30:02 | INFO | train | epoch 019 | loss 3.874 | trans_loss 5.322 | nll_loss 2.615 | w2v_ctc_loss 1.253 | task_loss 2 | contrastive_loss 0.228 | total 4138.32 | n_correct 2664.91 | ppl 6.13 | accuracy 64.396 | wps 5419 | ups 1.31 | wpb 4138.3 | bsz 152.8 | num_updates 27992 | lr 8.45275e-05 | gnorm 0.951 | clip 0 | loss_scale 16 | train_wall 1078 | gb_free 17.5 | wall 26442
2023-07-02 13:30:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 13:30:03 | INFO | fairseq.trainer | begin training epoch 20
2023-07-02 13:30:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 13:30:17 | INFO | train_inner | epoch 020:      8 / 1474 loss=3.878, trans_loss=5.322, nll_loss=2.617, w2v_ctc_loss=1.249, task_loss=2, contrastive_loss=0.307, total=4113.08, n_correct=2648.22, ppl=6.13, accuracy=64.385, wps=3649.5, ups=0.89, wpb=4113.1, bsz=151.1, num_updates=28000, lr=8.45154e-05, gnorm=0.961, clip=0, loss_scale=16, train_wall=74, gb_free=17.5, wall=26456
2023-07-02 13:30:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 13:30:41 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.329 | trans_loss 5.558 | nll_loss 2.832 | w2v_ctc_loss 1.345 | task_loss 0 | contrastive_loss 0.26 | total 4003.4 | n_correct 2482 | ppl 7.12 | accuracy 61.997 | uer 16.941 | wer 18.84 | raw_wer 18.84 | bleu 20.05 | wps 2206.7 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.31
2023-07-02 13:30:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-07-02 13:30:41 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_20_28000.pt
2023-07-02 13:30:43 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_20_28000.pt
2023-07-02 13:30:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 20.05) (writing took 6.278164606075734 seconds)
2023-07-02 13:32:01 | INFO | train_inner | epoch 020:    108 / 1474 loss=3.83, trans_loss=5.281, nll_loss=2.562, w2v_ctc_loss=1.223, task_loss=2, contrastive_loss=0.153, total=4199.19, n_correct=2731.85, ppl=5.9, accuracy=65.057, wps=4003, ups=0.95, wpb=4199.2, bsz=157, num_updates=28100, lr=8.43649e-05, gnorm=0.933, clip=0, loss_scale=16, train_wall=73, gb_free=15.1, wall=26561
2023-07-02 13:33:15 | INFO | train_inner | epoch 020:    208 / 1474 loss=3.85, trans_loss=5.289, nll_loss=2.572, w2v_ctc_loss=1.233, task_loss=2, contrastive_loss=0.257, total=4148.29, n_correct=2692.55, ppl=5.95, accuracy=64.907, wps=5618.4, ups=1.35, wpb=4148.3, bsz=150.3, num_updates=28200, lr=8.42152e-05, gnorm=0.943, clip=0, loss_scale=16, train_wall=73, gb_free=15.8, wall=26634
2023-07-02 13:34:29 | INFO | train_inner | epoch 020:    308 / 1474 loss=3.821, trans_loss=5.281, nll_loss=2.562, w2v_ctc_loss=1.227, task_loss=2, contrastive_loss=0.135, total=4191.34, n_correct=2726.02, ppl=5.9, accuracy=65.039, wps=5702.8, ups=1.36, wpb=4191.3, bsz=163.1, num_updates=28300, lr=8.40663e-05, gnorm=0.935, clip=0, loss_scale=16, train_wall=73, gb_free=15.9, wall=26708
2023-07-02 13:35:43 | INFO | train_inner | epoch 020:    408 / 1474 loss=3.837, trans_loss=5.284, nll_loss=2.565, w2v_ctc_loss=1.218, task_loss=2, contrastive_loss=0.129, total=4114.19, n_correct=2674.21, ppl=5.92, accuracy=65, wps=5564, ups=1.35, wpb=4114.2, bsz=148.7, num_updates=28400, lr=8.39181e-05, gnorm=0.948, clip=0, loss_scale=16, train_wall=74, gb_free=15.6, wall=26782
2023-07-02 13:36:57 | INFO | train_inner | epoch 020:    508 / 1474 loss=3.867, trans_loss=5.31, nll_loss=2.6, w2v_ctc_loss=1.236, task_loss=2, contrastive_loss=0.311, total=4108.2, n_correct=2654.93, ppl=6.06, accuracy=64.625, wps=5544.7, ups=1.35, wpb=4108.2, bsz=149.7, num_updates=28500, lr=8.37708e-05, gnorm=0.949, clip=0, loss_scale=16, train_wall=74, gb_free=15.9, wall=26856
2023-07-02 13:38:10 | INFO | train_inner | epoch 020:    608 / 1474 loss=3.873, trans_loss=5.309, nll_loss=2.598, w2v_ctc_loss=1.242, task_loss=2, contrastive_loss=0.312, total=4092.44, n_correct=2640.64, ppl=6.05, accuracy=64.525, wps=5589.2, ups=1.37, wpb=4092.4, bsz=148, num_updates=28600, lr=8.36242e-05, gnorm=0.951, clip=0, loss_scale=16, train_wall=73, gb_free=17.7, wall=26929
2023-07-02 13:39:23 | INFO | train_inner | epoch 020:    708 / 1474 loss=3.862, trans_loss=5.311, nll_loss=2.6, w2v_ctc_loss=1.249, task_loss=2, contrastive_loss=0.118, total=4137.06, n_correct=2672.95, ppl=6.06, accuracy=64.61, wps=5660.8, ups=1.37, wpb=4137.1, bsz=150.3, num_updates=28700, lr=8.34784e-05, gnorm=0.963, clip=0, loss_scale=16, train_wall=73, gb_free=16.7, wall=27002
2023-07-02 13:40:36 | INFO | train_inner | epoch 020:    808 / 1474 loss=3.845, trans_loss=5.299, nll_loss=2.585, w2v_ctc_loss=1.234, task_loss=2, contrastive_loss=0.125, total=4146.78, n_correct=2687.65, ppl=6, accuracy=64.813, wps=5686.6, ups=1.37, wpb=4146.8, bsz=153.7, num_updates=28800, lr=8.33333e-05, gnorm=0.94, clip=0, loss_scale=16, train_wall=72, gb_free=15.4, wall=27075
2023-07-02 13:41:50 | INFO | train_inner | epoch 020:    908 / 1474 loss=3.887, trans_loss=5.322, nll_loss=2.618, w2v_ctc_loss=1.232, task_loss=2, contrastive_loss=0.709, total=4161, n_correct=2680.46, ppl=6.14, accuracy=64.419, wps=5609.1, ups=1.35, wpb=4161, bsz=161.6, num_updates=28900, lr=8.3189e-05, gnorm=0.951, clip=0, loss_scale=16, train_wall=74, gb_free=17.6, wall=27149
2023-07-02 13:43:04 | INFO | train_inner | epoch 020:   1008 / 1474 loss=3.85, trans_loss=5.304, nll_loss=2.593, w2v_ctc_loss=1.23, task_loss=2, contrastive_loss=0.134, total=4168.14, n_correct=2693.76, ppl=6.03, accuracy=64.627, wps=5637.2, ups=1.35, wpb=4168.1, bsz=153.7, num_updates=29000, lr=8.30455e-05, gnorm=0.945, clip=0, loss_scale=16, train_wall=73, gb_free=16.7, wall=27223
2023-07-02 13:44:19 | INFO | train_inner | epoch 020:   1108 / 1474 loss=3.872, trans_loss=5.316, nll_loss=2.608, w2v_ctc_loss=1.235, task_loss=2, contrastive_loss=0.408, total=4166.49, n_correct=2687.05, ppl=6.1, accuracy=64.492, wps=5606.9, ups=1.35, wpb=4166.5, bsz=157.7, num_updates=29100, lr=8.29027e-05, gnorm=0.954, clip=0, loss_scale=16, train_wall=74, gb_free=15, wall=27298
2023-07-02 13:45:32 | INFO | train_inner | epoch 020:   1208 / 1474 loss=3.872, trans_loss=5.31, nll_loss=2.601, w2v_ctc_loss=1.265, task_loss=2, contrastive_loss=0.114, total=4029.18, n_correct=2598.62, ppl=6.07, accuracy=64.495, wps=5471.7, ups=1.36, wpb=4029.2, bsz=142, num_updates=29200, lr=8.27606e-05, gnorm=0.978, clip=0, loss_scale=16, train_wall=73, gb_free=12.2, wall=27371
2023-07-02 13:46:46 | INFO | train_inner | epoch 020:   1308 / 1474 loss=3.864, trans_loss=5.314, nll_loss=2.606, w2v_ctc_loss=1.244, task_loss=2, contrastive_loss=0.122, total=4123.21, n_correct=2659.49, ppl=6.09, accuracy=64.5, wps=5601.5, ups=1.36, wpb=4123.2, bsz=148.5, num_updates=29300, lr=8.26192e-05, gnorm=0.955, clip=0, loss_scale=16, train_wall=73, gb_free=17.5, wall=27445
2023-07-02 13:48:00 | INFO | train_inner | epoch 020:   1408 / 1474 loss=3.87, trans_loss=5.316, nll_loss=2.608, w2v_ctc_loss=1.255, task_loss=2, contrastive_loss=0.121, total=4116.28, n_correct=2650.51, ppl=6.1, accuracy=64.391, wps=5571.1, ups=1.35, wpb=4116.3, bsz=147.5, num_updates=29400, lr=8.24786e-05, gnorm=0.961, clip=0, loss_scale=16, train_wall=73, gb_free=17.6, wall=27519
2023-07-02 13:48:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 13:49:13 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.303 | trans_loss 5.551 | nll_loss 2.826 | w2v_ctc_loss 1.276 | task_loss 0 | contrastive_loss 0.254 | total 4003.4 | n_correct 2480.8 | ppl 7.09 | accuracy 61.967 | uer 16.861 | wer 18.638 | raw_wer 18.638 | bleu 20.01 | wps 2068.9 | wpb 4003.4 | bsz 141.8 | num_updates 29466 | best_bleu 20.31
2023-07-02 13:49:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29466 updates
2023-07-02 13:49:13 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.0100.pt
2023-07-02 13:49:16 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.0100.pt
2023-07-02 13:49:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.0100.pt (epoch 20 @ 29466 updates, score 20.01) (writing took 5.476603138260543 seconds)
2023-07-02 13:49:19 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-07-02 13:49:19 | INFO | train | epoch 020 | loss 3.857 | trans_loss 5.304 | nll_loss 2.592 | w2v_ctc_loss 1.237 | task_loss 2 | contrastive_loss 0.226 | total 4138.65 | n_correct 2676.61 | ppl 6.03 | accuracy 64.673 | wps 5275.1 | ups 1.27 | wpb 4138.6 | bsz 152.8 | num_updates 29466 | lr 8.23862e-05 | gnorm 0.95 | clip 0 | loss_scale 16 | train_wall 1079 | gb_free 16.8 | wall 27598
2023-07-02 13:49:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 13:49:19 | INFO | fairseq.trainer | begin training epoch 21
2023-07-02 13:49:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 13:49:52 | INFO | train_inner | epoch 021:     34 / 1474 loss=3.863, trans_loss=5.312, nll_loss=2.604, w2v_ctc_loss=1.234, task_loss=2, contrastive_loss=0.357, total=4152.26, n_correct=2681.62, ppl=6.08, accuracy=64.582, wps=3681.4, ups=0.89, wpb=4152.3, bsz=158.1, num_updates=29500, lr=8.23387e-05, gnorm=0.955, clip=0, loss_scale=16, train_wall=73, gb_free=16.7, wall=27632
2023-07-02 13:51:06 | INFO | train_inner | epoch 021:    134 / 1474 loss=3.825, trans_loss=5.266, nll_loss=2.543, w2v_ctc_loss=1.207, task_loss=2, contrastive_loss=0.346, total=4195.08, n_correct=2740.66, ppl=5.83, accuracy=65.33, wps=5684.4, ups=1.36, wpb=4195.1, bsz=159.8, num_updates=29600, lr=8.21995e-05, gnorm=0.938, clip=0, loss_scale=16, train_wall=73, gb_free=17.2, wall=27705
2023-07-02 13:52:19 | INFO | train_inner | epoch 021:    234 / 1474 loss=3.82, trans_loss=5.272, nll_loss=2.55, w2v_ctc_loss=1.199, task_loss=2, contrastive_loss=0.252, total=4155.31, n_correct=2712.4, ppl=5.86, accuracy=65.276, wps=5706.7, ups=1.37, wpb=4155.3, bsz=156.3, num_updates=29700, lr=8.2061e-05, gnorm=0.949, clip=0, loss_scale=16, train_wall=72, gb_free=17, wall=27778
2023-07-02 13:53:33 | INFO | train_inner | epoch 021:    334 / 1474 loss=3.838, trans_loss=5.28, nll_loss=2.561, w2v_ctc_loss=1.231, task_loss=2, contrastive_loss=0.257, total=4151.51, n_correct=2701.59, ppl=5.9, accuracy=65.075, wps=5582.2, ups=1.34, wpb=4151.5, bsz=155.4, num_updates=29800, lr=8.19232e-05, gnorm=0.947, clip=0, loss_scale=16, train_wall=74, gb_free=15.8, wall=27853
2023-07-02 13:54:47 | INFO | train_inner | epoch 021:    434 / 1474 loss=3.819, trans_loss=5.272, nll_loss=2.55, w2v_ctc_loss=1.206, task_loss=2, contrastive_loss=0.106, total=4180.85, n_correct=2726.24, ppl=5.86, accuracy=65.208, wps=5696.8, ups=1.36, wpb=4180.9, bsz=153.4, num_updates=29900, lr=8.17861e-05, gnorm=0.943, clip=0, loss_scale=16, train_wall=73, gb_free=16, wall=27926
2023-07-02 13:56:00 | INFO | train_inner | epoch 021:    534 / 1474 loss=3.836, trans_loss=5.277, nll_loss=2.557, w2v_ctc_loss=1.236, task_loss=2, contrastive_loss=0.108, total=4083.98, n_correct=2658.69, ppl=5.89, accuracy=65.1, wps=5571.3, ups=1.36, wpb=4084, bsz=147.5, num_updates=30000, lr=8.16497e-05, gnorm=0.956, clip=0, loss_scale=16, train_wall=73, gb_free=13.4, wall=27999
2023-07-02 13:56:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 13:56:26 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.34 | trans_loss 5.561 | nll_loss 2.835 | w2v_ctc_loss 1.377 | task_loss 0 | contrastive_loss 0.258 | total 4003.4 | n_correct 2475.3 | ppl 7.14 | accuracy 61.83 | uer 16.866 | wer 18.538 | raw_wer 18.538 | bleu 19.98 | wps 2265.9 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.31
2023-07-02 13:56:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-07-02 13:56:26 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_21_30000.pt
2023-07-02 13:56:28 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_21_30000.pt
2023-07-02 13:56:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 19.98) (writing took 6.277606494259089 seconds)
tensor(0.0172, device='cuda:0')
tensor(0.0009, device='cuda:0')
2023-07-02 13:57:47 | INFO | train_inner | epoch 021:    634 / 1474 loss=3.844, trans_loss=5.284, nll_loss=2.567, w2v_ctc_loss=1.209, task_loss=2, contrastive_loss=0.451, total=4215.41, n_correct=2744.25, ppl=5.92, accuracy=65.1, wps=3964.3, ups=0.94, wpb=4215.4, bsz=157.7, num_updates=30100, lr=8.15139e-05, gnorm=0.964, clip=0, loss_scale=32, train_wall=74, gb_free=11.8, wall=28106
2023-07-02 13:59:00 | INFO | train_inner | epoch 021:    734 / 1474 loss=3.838, trans_loss=5.291, nll_loss=2.576, w2v_ctc_loss=1.219, task_loss=2, contrastive_loss=0.171, total=4152.97, n_correct=2695.63, ppl=5.96, accuracy=64.908, wps=5664.1, ups=1.36, wpb=4153, bsz=154.7, num_updates=30200, lr=8.13788e-05, gnorm=0.945, clip=0, loss_scale=32, train_wall=73, gb_free=16.5, wall=28179
2023-07-02 14:00:14 | INFO | train_inner | epoch 021:    834 / 1474 loss=3.853, trans_loss=5.297, nll_loss=2.584, w2v_ctc_loss=1.23, task_loss=2, contrastive_loss=0.198, total=4066.93, n_correct=2635.15, ppl=5.99, accuracy=64.795, wps=5488.7, ups=1.35, wpb=4066.9, bsz=147.2, num_updates=30300, lr=8.12444e-05, gnorm=0.967, clip=0, loss_scale=32, train_wall=74, gb_free=17.1, wall=28253
2023-07-02 14:01:27 | INFO | train_inner | epoch 021:    934 / 1474 loss=3.838, trans_loss=5.285, nll_loss=2.568, w2v_ctc_loss=1.229, task_loss=2, contrastive_loss=0.143, total=4103.34, n_correct=2663.11, ppl=5.93, accuracy=64.901, wps=5611.5, ups=1.37, wpb=4103.3, bsz=150.5, num_updates=30400, lr=8.11107e-05, gnorm=0.964, clip=0, loss_scale=32, train_wall=73, gb_free=14.3, wall=28326
2023-07-02 14:02:40 | INFO | train_inner | epoch 021:   1034 / 1474 loss=3.857, trans_loss=5.306, nll_loss=2.596, w2v_ctc_loss=1.243, task_loss=2, contrastive_loss=0.138, total=4099.86, n_correct=2650.07, ppl=6.04, accuracy=64.638, wps=5588.3, ups=1.36, wpb=4099.9, bsz=149.4, num_updates=30500, lr=8.09776e-05, gnorm=0.957, clip=0, loss_scale=32, train_wall=73, gb_free=11.8, wall=28400
2023-07-02 14:03:54 | INFO | train_inner | epoch 021:   1134 / 1474 loss=3.856, trans_loss=5.296, nll_loss=2.581, w2v_ctc_loss=1.242, task_loss=2, contrastive_loss=0.146, total=4120.75, n_correct=2671.54, ppl=5.98, accuracy=64.831, wps=5610, ups=1.36, wpb=4120.8, bsz=146.7, num_updates=30600, lr=8.08452e-05, gnorm=0.965, clip=0, loss_scale=32, train_wall=73, gb_free=16, wall=28473
2023-07-02 14:05:07 | INFO | train_inner | epoch 021:   1234 / 1474 loss=3.839, trans_loss=5.287, nll_loss=2.572, w2v_ctc_loss=1.221, task_loss=2, contrastive_loss=0.245, total=4154.73, n_correct=2697.38, ppl=5.95, accuracy=64.923, wps=5685.4, ups=1.37, wpb=4154.7, bsz=155.8, num_updates=30700, lr=8.07134e-05, gnorm=0.939, clip=0, loss_scale=32, train_wall=73, gb_free=13, wall=28546
2023-07-02 14:06:20 | INFO | train_inner | epoch 021:   1334 / 1474 loss=3.832, trans_loss=5.288, nll_loss=2.573, w2v_ctc_loss=1.215, task_loss=2, contrastive_loss=0.169, total=4147.17, n_correct=2695.92, ppl=5.95, accuracy=65.006, wps=5651.5, ups=1.36, wpb=4147.2, bsz=155.9, num_updates=30800, lr=8.05823e-05, gnorm=0.938, clip=0, loss_scale=32, train_wall=73, gb_free=16.4, wall=28620
2023-07-02 14:07:34 | INFO | train_inner | epoch 021:   1434 / 1474 loss=3.869, trans_loss=5.307, nll_loss=2.597, w2v_ctc_loss=1.256, task_loss=2, contrastive_loss=0.265, total=4133.93, n_correct=2668.42, ppl=6.05, accuracy=64.549, wps=5581, ups=1.35, wpb=4133.9, bsz=152.2, num_updates=30900, lr=8.04518e-05, gnorm=0.962, clip=0, loss_scale=32, train_wall=74, gb_free=15.7, wall=28694
2023-07-02 14:08:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0172, device='cuda:4')
tensor(0.0009, device='cuda:4')
tensor(0.0172, device='cuda:7')
tensor(0.0009, device='cuda:7')
tensor(0.0172, device='cuda:5')
tensor(0.0009, device='cuda:5')
tensor(0.0172, device='cuda:2')
tensor(0.0009, device='cuda:2')
tensor(0.0172, device='cuda:3')
tensor(0.0009, device='cuda:3')
tensor(0.0172, device='cuda:1')
tensor(0.0009, device='cuda:1')
tensor(0.0172, device='cuda:6')
tensor(0.0009, device='cuda:6')
2023-07-02 14:08:28 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.314 | trans_loss 5.554 | nll_loss 2.827 | w2v_ctc_loss 1.308 | task_loss 0 | contrastive_loss 0.25 | total 4003.4 | n_correct 2482.4 | ppl 7.09 | accuracy 62.007 | uer 16.779 | wer 18.858 | raw_wer 18.858 | bleu 20.14 | wps 2260.1 | wpb 4003.4 | bsz 141.8 | num_updates 30940 | best_bleu 20.31
2023-07-02 14:08:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30940 updates
2023-07-02 14:08:28 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.1400.pt
2023-07-02 14:08:31 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.1400.pt
2023-07-02 14:08:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.1400.pt (epoch 21 @ 30940 updates, score 20.14) (writing took 5.853730905801058 seconds)
2023-07-02 14:08:34 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-07-02 14:08:34 | INFO | train | epoch 021 | loss 3.841 | trans_loss 5.286 | nll_loss 2.57 | w2v_ctc_loss 1.224 | task_loss 2 | contrastive_loss 0.223 | total 4138.65 | n_correct 2688.85 | ppl 5.94 | accuracy 64.969 | wps 5280.1 | ups 1.28 | wpb 4138.6 | bsz 152.8 | num_updates 30940 | lr 8.03998e-05 | gnorm 0.953 | clip 0 | loss_scale 32 | train_wall 1078 | gb_free 15.6 | wall 28753
2023-07-02 14:08:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 14:08:34 | INFO | fairseq.trainer | begin training epoch 22
2023-07-02 14:08:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 14:09:26 | INFO | train_inner | epoch 022:     60 / 1474 loss=3.825, trans_loss=5.268, nll_loss=2.546, w2v_ctc_loss=1.22, task_loss=2, contrastive_loss=0.106, total=4128.84, n_correct=2694.43, ppl=5.84, accuracy=65.259, wps=3692.4, ups=0.89, wpb=4128.8, bsz=148.8, num_updates=31000, lr=8.03219e-05, gnorm=0.961, clip=0, loss_scale=32, train_wall=73, gb_free=14.5, wall=28805
2023-07-02 14:10:40 | INFO | train_inner | epoch 022:    160 / 1474 loss=3.816, trans_loss=5.257, nll_loss=2.531, w2v_ctc_loss=1.21, task_loss=2, contrastive_loss=0.27, total=4123.35, n_correct=2699.93, ppl=5.78, accuracy=65.479, wps=5579.1, ups=1.35, wpb=4123.4, bsz=155.1, num_updates=31100, lr=8.01927e-05, gnorm=0.951, clip=0, loss_scale=32, train_wall=73, gb_free=14.9, wall=28879
2023-07-02 14:11:54 | INFO | train_inner | epoch 022:    260 / 1474 loss=3.786, trans_loss=5.245, nll_loss=2.517, w2v_ctc_loss=1.178, task_loss=2, contrastive_loss=0.156, total=4267.16, n_correct=2800.35, ppl=5.72, accuracy=65.626, wps=5771.5, ups=1.35, wpb=4267.2, bsz=165, num_updates=31200, lr=8.00641e-05, gnorm=0.941, clip=0, loss_scale=32, train_wall=74, gb_free=17, wall=28953
2023-07-02 14:13:09 | INFO | train_inner | epoch 022:    360 / 1474 loss=3.841, trans_loss=5.272, nll_loss=2.551, w2v_ctc_loss=1.203, task_loss=2, contrastive_loss=0.46, total=4180.09, n_correct=2728.36, ppl=5.86, accuracy=65.27, wps=5589.5, ups=1.34, wpb=4180.1, bsz=155, num_updates=31300, lr=7.99361e-05, gnorm=0.957, clip=0, loss_scale=32, train_wall=74, gb_free=17.7, wall=29028
2023-07-02 14:14:23 | INFO | train_inner | epoch 022:    460 / 1474 loss=3.844, trans_loss=5.281, nll_loss=2.562, w2v_ctc_loss=1.223, task_loss=2, contrastive_loss=0.23, total=4132.62, n_correct=2689, ppl=5.9, accuracy=65.068, wps=5603.9, ups=1.36, wpb=4132.6, bsz=148.6, num_updates=31400, lr=7.98087e-05, gnorm=0.971, clip=0, loss_scale=32, train_wall=73, gb_free=16.7, wall=29102
2023-07-02 14:15:36 | INFO | train_inner | epoch 022:    560 / 1474 loss=3.821, trans_loss=5.268, nll_loss=2.546, w2v_ctc_loss=1.217, task_loss=2, contrastive_loss=0.128, total=4155.5, n_correct=2710.38, ppl=5.84, accuracy=65.224, wps=5631.3, ups=1.36, wpb=4155.5, bsz=153.7, num_updates=31500, lr=7.96819e-05, gnorm=0.948, clip=0, loss_scale=32, train_wall=73, gb_free=16.6, wall=29176
2023-07-02 14:16:49 | INFO | train_inner | epoch 022:    660 / 1474 loss=3.805, trans_loss=5.253, nll_loss=2.527, w2v_ctc_loss=1.181, task_loss=2, contrastive_loss=0.295, total=4147.84, n_correct=2718.7, ppl=5.76, accuracy=65.545, wps=5716.8, ups=1.38, wpb=4147.8, bsz=156.6, num_updates=31600, lr=7.95557e-05, gnorm=0.942, clip=0, loss_scale=32, train_wall=72, gb_free=13.4, wall=29248
2023-07-02 14:18:02 | INFO | train_inner | epoch 022:    760 / 1474 loss=3.823, trans_loss=5.266, nll_loss=2.543, w2v_ctc_loss=1.22, task_loss=2, contrastive_loss=0.134, total=4166.89, n_correct=2718.72, ppl=5.83, accuracy=65.246, wps=5679.4, ups=1.36, wpb=4166.9, bsz=152.2, num_updates=31700, lr=7.94301e-05, gnorm=0.953, clip=0, loss_scale=32, train_wall=73, gb_free=16.1, wall=29322
2023-07-02 14:19:16 | INFO | train_inner | epoch 022:    860 / 1474 loss=3.84, trans_loss=5.281, nll_loss=2.563, w2v_ctc_loss=1.226, task_loss=2, contrastive_loss=0.108, total=4074.75, n_correct=2648.08, ppl=5.91, accuracy=64.988, wps=5516.1, ups=1.35, wpb=4074.8, bsz=144.2, num_updates=31800, lr=7.93052e-05, gnorm=0.972, clip=0, loss_scale=32, train_wall=73, gb_free=17.6, wall=29395
2023-07-02 14:20:30 | INFO | train_inner | epoch 022:    960 / 1474 loss=3.819, trans_loss=5.271, nll_loss=2.551, w2v_ctc_loss=1.206, task_loss=2, contrastive_loss=0.111, total=4136.34, n_correct=2696.23, ppl=5.86, accuracy=65.184, wps=5624.5, ups=1.36, wpb=4136.3, bsz=151.8, num_updates=31900, lr=7.91808e-05, gnorm=0.962, clip=0, loss_scale=32, train_wall=73, gb_free=16.8, wall=29469
2023-07-02 14:21:44 | INFO | train_inner | epoch 022:   1060 / 1474 loss=3.826, trans_loss=5.269, nll_loss=2.549, w2v_ctc_loss=1.196, task_loss=2, contrastive_loss=0.448, total=4157.21, n_correct=2713.81, ppl=5.85, accuracy=65.28, wps=5634.9, ups=1.36, wpb=4157.2, bsz=157.7, num_updates=32000, lr=7.90569e-05, gnorm=0.957, clip=0, loss_scale=32, train_wall=73, gb_free=12.5, wall=29543
2023-07-02 14:21:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 14:22:08 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.341 | trans_loss 5.563 | nll_loss 2.838 | w2v_ctc_loss 1.378 | task_loss 0 | contrastive_loss 0.253 | total 4003.4 | n_correct 2480.1 | ppl 7.15 | accuracy 61.95 | uer 16.986 | wer 18.858 | raw_wer 18.858 | bleu 19.93 | wps 2180.7 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.31
2023-07-02 14:22:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-07-02 14:22:08 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_22_32000.pt
2023-07-02 14:22:10 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_22_32000.pt
2023-07-02 14:22:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 19.93) (writing took 6.171792838722467 seconds)
2023-07-02 14:23:28 | INFO | train_inner | epoch 022:   1160 / 1474 loss=3.854, trans_loss=5.297, nll_loss=2.585, w2v_ctc_loss=1.227, task_loss=2, contrastive_loss=0.208, total=4092.91, n_correct=2650.38, ppl=6, accuracy=64.755, wps=3923.5, ups=0.96, wpb=4092.9, bsz=147.2, num_updates=32100, lr=7.89337e-05, gnorm=0.956, clip=0, loss_scale=64, train_wall=73, gb_free=16.2, wall=29647
2023-07-02 14:24:41 | INFO | train_inner | epoch 022:   1260 / 1474 loss=3.824, trans_loss=5.282, nll_loss=2.566, w2v_ctc_loss=1.212, task_loss=2, contrastive_loss=0.203, total=4182.65, n_correct=2717.73, ppl=5.92, accuracy=64.976, wps=5717.1, ups=1.37, wpb=4182.6, bsz=161.8, num_updates=32200, lr=7.8811e-05, gnorm=0.94, clip=0, loss_scale=64, train_wall=73, gb_free=16.7, wall=29720
2023-07-02 14:25:54 | INFO | train_inner | epoch 022:   1360 / 1474 loss=3.824, trans_loss=5.272, nll_loss=2.552, w2v_ctc_loss=1.199, task_loss=2, contrastive_loss=0.247, total=4071.58, n_correct=2654.08, ppl=5.86, accuracy=65.186, wps=5578.7, ups=1.37, wpb=4071.6, bsz=150.3, num_updates=32300, lr=7.86889e-05, gnorm=0.952, clip=0, loss_scale=64, train_wall=73, gb_free=16.9, wall=29793
2023-07-02 14:27:07 | INFO | train_inner | epoch 022:   1460 / 1474 loss=3.851, trans_loss=5.29, nll_loss=2.575, w2v_ctc_loss=1.233, task_loss=2, contrastive_loss=0.141, total=4077.83, n_correct=2646.68, ppl=5.96, accuracy=64.904, wps=5573, ups=1.37, wpb=4077.8, bsz=144, num_updates=32400, lr=7.85674e-05, gnorm=0.969, clip=0, loss_scale=64, train_wall=73, gb_free=16.3, wall=29866
2023-07-02 14:27:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 14:27:43 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.334 | trans_loss 5.552 | nll_loss 2.821 | w2v_ctc_loss 1.379 | task_loss 0 | contrastive_loss 0.246 | total 4003.4 | n_correct 2491.2 | ppl 7.07 | accuracy 62.227 | uer 16.879 | wer 18.799 | raw_wer 18.799 | bleu 20.07 | wps 2161.4 | wpb 4003.4 | bsz 141.8 | num_updates 32414 | best_bleu 20.31
2023-07-02 14:27:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32414 updates
2023-07-02 14:27:43 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.0708.pt
2023-07-02 14:27:45 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.0708.pt
2023-07-02 14:27:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.0708.pt (epoch 22 @ 32414 updates, score 20.07) (writing took 5.458479824010283 seconds)
2023-07-02 14:27:48 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-07-02 14:27:48 | INFO | train | epoch 022 | loss 3.826 | trans_loss 5.271 | nll_loss 2.55 | w2v_ctc_loss 1.21 | task_loss 2 | contrastive_loss 0.22 | total 4138.65 | n_correct 2698.68 | ppl 5.86 | accuracy 65.207 | wps 5286.4 | ups 1.28 | wpb 4138.6 | bsz 152.8 | num_updates 32414 | lr 7.85505e-05 | gnorm 0.955 | clip 0 | loss_scale 64 | train_wall 1077 | gb_free 12.2 | wall 29907
2023-07-02 14:27:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 14:27:48 | INFO | fairseq.trainer | begin training epoch 23
2023-07-02 14:27:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 14:29:00 | INFO | train_inner | epoch 023:     86 / 1474 loss=3.806, trans_loss=5.247, nll_loss=2.519, w2v_ctc_loss=1.208, task_loss=2, contrastive_loss=0.123, total=4089.8, n_correct=2683.79, ppl=5.73, accuracy=65.622, wps=3627.6, ups=0.89, wpb=4089.8, bsz=149.7, num_updates=32500, lr=7.84465e-05, gnorm=0.964, clip=0, loss_scale=64, train_wall=73, gb_free=16.8, wall=29979
2023-07-02 14:30:14 | INFO | train_inner | epoch 023:    186 / 1474 loss=3.807, trans_loss=5.247, nll_loss=2.518, w2v_ctc_loss=1.202, task_loss=2, contrastive_loss=0.117, total=4117.76, n_correct=2699.69, ppl=5.73, accuracy=65.562, wps=5592.8, ups=1.36, wpb=4117.8, bsz=148, num_updates=32600, lr=7.8326e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=73, gb_free=15.7, wall=30053
2023-07-02 14:31:28 | INFO | train_inner | epoch 023:    286 / 1474 loss=3.812, trans_loss=5.251, nll_loss=2.525, w2v_ctc_loss=1.187, task_loss=2, contrastive_loss=0.274, total=4144.73, n_correct=2715.76, ppl=5.75, accuracy=65.523, wps=5584.9, ups=1.35, wpb=4144.7, bsz=152, num_updates=32700, lr=7.82062e-05, gnorm=0.945, clip=0, loss_scale=64, train_wall=74, gb_free=17.6, wall=30127
2023-07-02 14:32:41 | INFO | train_inner | epoch 023:    386 / 1474 loss=3.804, trans_loss=5.246, nll_loss=2.517, w2v_ctc_loss=1.195, task_loss=2, contrastive_loss=0.104, total=4126.79, n_correct=2710.52, ppl=5.73, accuracy=65.681, wps=5638.3, ups=1.37, wpb=4126.8, bsz=148.2, num_updates=32800, lr=7.80869e-05, gnorm=0.96, clip=0, loss_scale=64, train_wall=73, gb_free=17.3, wall=30200
2023-07-02 14:33:55 | INFO | train_inner | epoch 023:    486 / 1474 loss=3.804, trans_loss=5.252, nll_loss=2.525, w2v_ctc_loss=1.19, task_loss=2, contrastive_loss=0.216, total=4150.15, n_correct=2718.97, ppl=5.76, accuracy=65.515, wps=5649.1, ups=1.36, wpb=4150.1, bsz=156, num_updates=32900, lr=7.79681e-05, gnorm=0.953, clip=0, loss_scale=64, train_wall=73, gb_free=16.4, wall=30274
2023-07-02 14:35:08 | INFO | train_inner | epoch 023:    586 / 1474 loss=3.785, trans_loss=5.239, nll_loss=2.509, w2v_ctc_loss=1.182, task_loss=2, contrastive_loss=0.115, total=4174.6, n_correct=2745.9, ppl=5.69, accuracy=65.776, wps=5708.4, ups=1.37, wpb=4174.6, bsz=158.2, num_updates=33000, lr=7.78499e-05, gnorm=0.942, clip=0, loss_scale=64, train_wall=73, gb_free=16.6, wall=30347
2023-07-02 14:36:21 | INFO | train_inner | epoch 023:    686 / 1474 loss=3.809, trans_loss=5.247, nll_loss=2.52, w2v_ctc_loss=1.196, task_loss=2, contrastive_loss=0.193, total=4136.6, n_correct=2710.69, ppl=5.73, accuracy=65.529, wps=5665.7, ups=1.37, wpb=4136.6, bsz=150.6, num_updates=33100, lr=7.77322e-05, gnorm=0.944, clip=0, loss_scale=64, train_wall=73, gb_free=17.8, wall=30420
2023-07-02 14:37:34 | INFO | train_inner | epoch 023:    786 / 1474 loss=3.82, trans_loss=5.265, nll_loss=2.542, w2v_ctc_loss=1.211, task_loss=2, contrastive_loss=0.153, total=4147.22, n_correct=2710.68, ppl=5.83, accuracy=65.361, wps=5658, ups=1.36, wpb=4147.2, bsz=152.6, num_updates=33200, lr=7.76151e-05, gnorm=0.962, clip=0, loss_scale=64, train_wall=73, gb_free=17.4, wall=30493
2023-07-02 14:38:48 | INFO | train_inner | epoch 023:    886 / 1474 loss=3.799, trans_loss=5.249, nll_loss=2.523, w2v_ctc_loss=1.188, task_loss=2, contrastive_loss=0.308, total=4193.16, n_correct=2752.01, ppl=5.75, accuracy=65.631, wps=5700.2, ups=1.36, wpb=4193.2, bsz=163.6, num_updates=33300, lr=7.74984e-05, gnorm=0.942, clip=0, loss_scale=64, train_wall=73, gb_free=16.2, wall=30567
2023-07-02 14:40:01 | INFO | train_inner | epoch 023:    986 / 1474 loss=3.838, trans_loss=5.265, nll_loss=2.543, w2v_ctc_loss=1.195, task_loss=2, contrastive_loss=0.622, total=4164.33, n_correct=2717.42, ppl=5.83, accuracy=65.255, wps=5651.2, ups=1.36, wpb=4164.3, bsz=155.1, num_updates=33400, lr=7.73823e-05, gnorm=0.942, clip=0, loss_scale=64, train_wall=73, gb_free=17.8, wall=30640
2023-07-02 14:41:15 | INFO | train_inner | epoch 023:   1086 / 1474 loss=3.833, trans_loss=5.266, nll_loss=2.545, w2v_ctc_loss=1.227, task_loss=2, contrastive_loss=0.133, total=4088.37, n_correct=2667.26, ppl=5.84, accuracy=65.24, wps=5549.3, ups=1.36, wpb=4088.4, bsz=144.8, num_updates=33500, lr=7.72667e-05, gnorm=0.959, clip=0, loss_scale=64, train_wall=73, gb_free=15.8, wall=30714
2023-07-02 14:42:29 | INFO | train_inner | epoch 023:   1186 / 1474 loss=3.809, trans_loss=5.26, nll_loss=2.537, w2v_ctc_loss=1.199, task_loss=2, contrastive_loss=0.117, total=4162.3, n_correct=2719.29, ppl=5.8, accuracy=65.331, wps=5609.9, ups=1.35, wpb=4162.3, bsz=154.5, num_updates=33600, lr=7.71517e-05, gnorm=0.948, clip=0, loss_scale=64, train_wall=74, gb_free=15.8, wall=30788
2023-07-02 14:43:42 | INFO | train_inner | epoch 023:   1286 / 1474 loss=3.805, trans_loss=5.258, nll_loss=2.535, w2v_ctc_loss=1.19, task_loss=2, contrastive_loss=0.138, total=4131.74, n_correct=2702.3, ppl=5.8, accuracy=65.403, wps=5661.7, ups=1.37, wpb=4131.7, bsz=154.4, num_updates=33700, lr=7.70371e-05, gnorm=0.941, clip=0, loss_scale=64, train_wall=73, gb_free=17.2, wall=30861
2023-07-02 14:44:56 | INFO | train_inner | epoch 023:   1386 / 1474 loss=3.844, trans_loss=5.288, nll_loss=2.574, w2v_ctc_loss=1.218, task_loss=2, contrastive_loss=0.25, total=4141.25, n_correct=2690.82, ppl=5.95, accuracy=64.976, wps=5625.1, ups=1.36, wpb=4141.2, bsz=152.4, num_updates=33800, lr=7.69231e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=73, gb_free=16.9, wall=30935
2023-07-02 14:46:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 14:46:25 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.345 | trans_loss 5.551 | nll_loss 2.822 | w2v_ctc_loss 1.418 | task_loss 0 | contrastive_loss 0.249 | total 4003.4 | n_correct 2487.8 | ppl 7.07 | accuracy 62.142 | uer 16.72 | wer 18.541 | raw_wer 18.541 | bleu 20.09 | wps 2212.3 | wpb 4003.4 | bsz 141.8 | num_updates 33888 | best_bleu 20.31
2023-07-02 14:46:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33888 updates
2023-07-02 14:46:25 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.0904.pt
2023-07-02 14:46:27 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.0904.pt
2023-07-02 14:46:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.0904.pt (epoch 23 @ 33888 updates, score 20.09) (writing took 5.455256876070052 seconds)
2023-07-02 14:46:31 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-07-02 14:46:31 | INFO | train | epoch 023 | loss 3.814 | trans_loss 5.257 | nll_loss 2.533 | w2v_ctc_loss 1.198 | task_loss 2 | contrastive_loss 0.221 | total 4138.65 | n_correct 2708.08 | ppl 5.79 | accuracy 65.434 | wps 5435.1 | ups 1.31 | wpb 4138.6 | bsz 152.8 | num_updates 33888 | lr 7.68231e-05 | gnorm 0.953 | clip 0 | loss_scale 64 | train_wall 1077 | gb_free 14.1 | wall 31030
2023-07-02 14:46:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 14:46:31 | INFO | fairseq.trainer | begin training epoch 24
2023-07-02 14:46:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 14:46:48 | INFO | train_inner | epoch 024:     12 / 1474 loss=3.837, trans_loss=5.28, nll_loss=2.563, w2v_ctc_loss=1.19, task_loss=2, contrastive_loss=0.403, total=4095.53, n_correct=2665.84, ppl=5.91, accuracy=65.091, wps=3662, ups=0.89, wpb=4095.5, bsz=153.1, num_updates=33900, lr=7.68095e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=73, gb_free=17.5, wall=31047
2023-07-02 14:48:02 | INFO | train_inner | epoch 024:    112 / 1474 loss=3.794, trans_loss=5.231, nll_loss=2.5, w2v_ctc_loss=1.175, task_loss=2, contrastive_loss=0.45, total=4167.42, n_correct=2741.93, ppl=5.66, accuracy=65.794, wps=5630.8, ups=1.35, wpb=4167.4, bsz=161.5, num_updates=34000, lr=7.66965e-05, gnorm=0.945, clip=0, loss_scale=64, train_wall=74, gb_free=17.8, wall=31121
2023-07-02 14:48:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 14:48:27 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.324 | trans_loss 5.552 | nll_loss 2.821 | w2v_ctc_loss 1.341 | task_loss 0 | contrastive_loss 0.258 | total 4003.4 | n_correct 2492.3 | ppl 7.07 | accuracy 62.255 | uer 16.542 | wer 18.489 | raw_wer 18.489 | bleu 20.07 | wps 2187.1 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.31
2023-07-02 14:48:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-07-02 14:48:27 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_24_34000.pt
2023-07-02 14:48:29 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_24_34000.pt
2023-07-02 14:48:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 20.07) (writing took 8.009814195334911 seconds)
2023-07-02 14:49:49 | INFO | train_inner | epoch 024:    212 / 1474 loss=3.788, trans_loss=5.233, nll_loss=2.503, w2v_ctc_loss=1.152, task_loss=2, contrastive_loss=0.549, total=4247.08, n_correct=2797.95, ppl=5.67, accuracy=65.879, wps=3961.2, ups=0.93, wpb=4247.1, bsz=169.8, num_updates=34100, lr=7.6584e-05, gnorm=0.94, clip=0, loss_scale=64, train_wall=74, gb_free=16.9, wall=31228
2023-07-02 14:51:02 | INFO | train_inner | epoch 024:    312 / 1474 loss=3.775, trans_loss=5.222, nll_loss=2.487, w2v_ctc_loss=1.176, task_loss=2, contrastive_loss=0.11, total=4139.31, n_correct=2735.76, ppl=5.61, accuracy=66.092, wps=5652.7, ups=1.37, wpb=4139.3, bsz=154.2, num_updates=34200, lr=7.64719e-05, gnorm=0.94, clip=0, loss_scale=128, train_wall=73, gb_free=16.6, wall=31301
2023-07-02 14:51:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-02 14:52:16 | INFO | train_inner | epoch 024:    413 / 1474 loss=3.819, trans_loss=5.246, nll_loss=2.518, w2v_ctc_loss=1.213, task_loss=2, contrastive_loss=0.165, total=4127.95, n_correct=2709.41, ppl=5.73, accuracy=65.636, wps=5561.8, ups=1.35, wpb=4127.9, bsz=145.2, num_updates=34300, lr=7.63604e-05, gnorm=0.962, clip=0, loss_scale=64, train_wall=74, gb_free=16.8, wall=31375
2023-07-02 14:53:30 | INFO | train_inner | epoch 024:    513 / 1474 loss=3.805, trans_loss=5.242, nll_loss=2.513, w2v_ctc_loss=1.193, task_loss=2, contrastive_loss=0.248, total=4144.91, n_correct=2722.62, ppl=5.71, accuracy=65.686, wps=5627.1, ups=1.36, wpb=4144.9, bsz=151.6, num_updates=34400, lr=7.62493e-05, gnorm=0.957, clip=0, loss_scale=64, train_wall=73, gb_free=17.1, wall=31449
2023-07-02 14:54:43 | INFO | train_inner | epoch 024:    613 / 1474 loss=3.792, trans_loss=5.237, nll_loss=2.507, w2v_ctc_loss=1.175, task_loss=2, contrastive_loss=0.17, total=4165.3, n_correct=2739.78, ppl=5.69, accuracy=65.776, wps=5675.1, ups=1.36, wpb=4165.3, bsz=153.8, num_updates=34500, lr=7.61387e-05, gnorm=0.943, clip=0, loss_scale=64, train_wall=73, gb_free=16, wall=31523
2023-07-02 14:55:57 | INFO | train_inner | epoch 024:    713 / 1474 loss=3.816, trans_loss=5.251, nll_loss=2.525, w2v_ctc_loss=1.203, task_loss=2, contrastive_loss=0.195, total=4102.21, n_correct=2687.83, ppl=5.75, accuracy=65.522, wps=5602.3, ups=1.37, wpb=4102.2, bsz=147.5, num_updates=34600, lr=7.60286e-05, gnorm=0.952, clip=0, loss_scale=64, train_wall=73, gb_free=17.1, wall=31596
2023-07-02 14:57:11 | INFO | train_inner | epoch 024:    813 / 1474 loss=3.795, trans_loss=5.244, nll_loss=2.517, w2v_ctc_loss=1.18, task_loss=2, contrastive_loss=0.151, total=4110.6, n_correct=2699.66, ppl=5.72, accuracy=65.676, wps=5557.8, ups=1.35, wpb=4110.6, bsz=152.7, num_updates=34700, lr=7.5919e-05, gnorm=0.953, clip=0, loss_scale=64, train_wall=74, gb_free=16.8, wall=31670
2023-07-02 14:58:24 | INFO | train_inner | epoch 024:    913 / 1474 loss=3.822, trans_loss=5.257, nll_loss=2.531, w2v_ctc_loss=1.21, task_loss=2, contrastive_loss=0.101, total=4043.03, n_correct=2642.9, ppl=5.78, accuracy=65.369, wps=5533.6, ups=1.37, wpb=4043, bsz=140.5, num_updates=34800, lr=7.58098e-05, gnorm=0.96, clip=0, loss_scale=64, train_wall=73, gb_free=11.7, wall=31743
2023-07-02 14:59:37 | INFO | train_inner | epoch 024:   1013 / 1474 loss=3.8, trans_loss=5.248, nll_loss=2.522, w2v_ctc_loss=1.178, task_loss=2, contrastive_loss=0.111, total=4136.81, n_correct=2715.74, ppl=5.74, accuracy=65.648, wps=5640.6, ups=1.36, wpb=4136.8, bsz=149.2, num_updates=34900, lr=7.57011e-05, gnorm=0.956, clip=0, loss_scale=64, train_wall=73, gb_free=17.1, wall=31816
2023-07-02 15:00:50 | INFO | train_inner | epoch 024:   1113 / 1474 loss=3.791, trans_loss=5.234, nll_loss=2.503, w2v_ctc_loss=1.185, task_loss=2, contrastive_loss=0.195, total=4135.73, n_correct=2721.17, ppl=5.67, accuracy=65.797, wps=5659.5, ups=1.37, wpb=4135.7, bsz=154.4, num_updates=35000, lr=7.55929e-05, gnorm=0.954, clip=0, loss_scale=64, train_wall=73, gb_free=17.2, wall=31889
tensor(0.0172, device='cuda:0')
tensor(0.0009, device='cuda:0')
2023-07-02 15:02:04 | INFO | train_inner | epoch 024:   1213 / 1474 loss=3.803, trans_loss=5.255, nll_loss=2.532, w2v_ctc_loss=1.184, task_loss=2, contrastive_loss=0.173, total=4148.3, n_correct=2715.8, ppl=5.78, accuracy=65.468, wps=5638.2, ups=1.36, wpb=4148.3, bsz=155.4, num_updates=35100, lr=7.54851e-05, gnorm=0.955, clip=0, loss_scale=64, train_wall=73, gb_free=16.8, wall=31963
2023-07-02 15:03:17 | INFO | train_inner | epoch 024:   1313 / 1474 loss=3.817, trans_loss=5.257, nll_loss=2.533, w2v_ctc_loss=1.206, task_loss=2, contrastive_loss=0.121, total=4110.05, n_correct=2689.63, ppl=5.79, accuracy=65.44, wps=5585, ups=1.36, wpb=4110.1, bsz=147.1, num_updates=35200, lr=7.53778e-05, gnorm=0.957, clip=0, loss_scale=64, train_wall=73, gb_free=17.4, wall=32036
2023-07-02 15:04:30 | INFO | train_inner | epoch 024:   1413 / 1474 loss=3.823, trans_loss=5.261, nll_loss=2.539, w2v_ctc_loss=1.219, task_loss=2, contrastive_loss=0.116, total=4090.91, n_correct=2675.06, ppl=5.81, accuracy=65.39, wps=5607.6, ups=1.37, wpb=4090.9, bsz=146.4, num_updates=35300, lr=7.5271e-05, gnorm=0.966, clip=0, loss_scale=64, train_wall=73, gb_free=16.6, wall=32109
2023-07-02 15:05:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0172, device='cuda:4')
tensor(0.0009, device='cuda:4')
tensor(0.0172, device='cuda:7')
tensor(0.0009, device='cuda:7')
tensor(0.0172, device='cuda:6')
tensor(0.0009, device='cuda:6')
tensor(0.0172, device='cuda:1')
tensor(0.0009, device='cuda:1')
tensor(0.0172, device='cuda:5')
tensor(0.0009, device='cuda:5')
tensor(0.0172, device='cuda:3')
tensor(0.0009, device='cuda:3')
tensor(0.0172, device='cuda:2')
tensor(0.0009, device='cuda:2')
2023-07-02 15:05:40 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.34 | trans_loss 5.56 | nll_loss 2.834 | w2v_ctc_loss 1.377 | task_loss 0 | contrastive_loss 0.254 | total 4003.4 | n_correct 2491.1 | ppl 7.13 | accuracy 62.225 | uer 16.654 | wer 18.679 | raw_wer 18.679 | bleu 20 | wps 2246 | wpb 4003.4 | bsz 141.8 | num_updates 35361 | best_bleu 20.31
2023-07-02 15:05:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35361 updates
2023-07-02 15:05:40 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.0007.pt
2023-07-02 15:05:43 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.0007.pt
2023-07-02 15:05:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.0007.pt (epoch 24 @ 35361 updates, score 20.0) (writing took 5.370349953882396 seconds)
2023-07-02 15:05:46 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-07-02 15:05:46 | INFO | train | epoch 024 | loss 3.801 | trans_loss 5.244 | nll_loss 2.516 | w2v_ctc_loss 1.188 | task_loss 2 | contrastive_loss 0.205 | total 4137.03 | n_correct 2716.6 | ppl 5.72 | accuracy 65.665 | wps 5274.9 | ups 1.28 | wpb 4137 | bsz 152.6 | num_updates 35361 | lr 7.5206e-05 | gnorm 0.952 | clip 0 | loss_scale 64 | train_wall 1077 | gb_free 16.3 | wall 32185
2023-07-02 15:05:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 15:05:46 | INFO | fairseq.trainer | begin training epoch 25
2023-07-02 15:05:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 15:06:22 | INFO | train_inner | epoch 025:     39 / 1474 loss=3.778, trans_loss=5.226, nll_loss=2.494, w2v_ctc_loss=1.175, task_loss=2, contrastive_loss=0.13, total=4166.95, n_correct=2749.82, ppl=5.63, accuracy=65.991, wps=3720.2, ups=0.89, wpb=4166.9, bsz=156, num_updates=35400, lr=7.51646e-05, gnorm=0.937, clip=0, loss_scale=64, train_wall=72, gb_free=16.6, wall=32221
2023-07-02 15:07:36 | INFO | train_inner | epoch 025:    139 / 1474 loss=3.77, trans_loss=5.216, nll_loss=2.48, w2v_ctc_loss=1.166, task_loss=2, contrastive_loss=0.128, total=4133.64, n_correct=2733.94, ppl=5.58, accuracy=66.139, wps=5625, ups=1.36, wpb=4133.6, bsz=153.9, num_updates=35500, lr=7.50587e-05, gnorm=0.954, clip=0, loss_scale=64, train_wall=73, gb_free=16, wall=32295
2023-07-02 15:08:50 | INFO | train_inner | epoch 025:    239 / 1474 loss=3.777, trans_loss=5.215, nll_loss=2.478, w2v_ctc_loss=1.18, task_loss=2, contrastive_loss=0.137, total=4114.53, n_correct=2721.15, ppl=5.57, accuracy=66.135, wps=5550.1, ups=1.35, wpb=4114.5, bsz=151.4, num_updates=35600, lr=7.49532e-05, gnorm=0.957, clip=0, loss_scale=64, train_wall=74, gb_free=17.2, wall=32369
2023-07-02 15:10:04 | INFO | train_inner | epoch 025:    339 / 1474 loss=3.791, trans_loss=5.223, nll_loss=2.487, w2v_ctc_loss=1.173, task_loss=2, contrastive_loss=0.194, total=4148.7, n_correct=2733.79, ppl=5.61, accuracy=65.895, wps=5615, ups=1.35, wpb=4148.7, bsz=147.6, num_updates=35700, lr=7.48481e-05, gnorm=0.957, clip=0, loss_scale=64, train_wall=73, gb_free=16.8, wall=32443
2023-07-02 15:11:18 | INFO | train_inner | epoch 025:    439 / 1474 loss=3.814, trans_loss=5.234, nll_loss=2.502, w2v_ctc_loss=1.197, task_loss=2, contrastive_loss=0.345, total=4167.03, n_correct=2744.95, ppl=5.66, accuracy=65.873, wps=5629, ups=1.35, wpb=4167, bsz=149.2, num_updates=35800, lr=7.47435e-05, gnorm=0.954, clip=0, loss_scale=64, train_wall=74, gb_free=12.7, wall=32517
2023-07-02 15:12:31 | INFO | train_inner | epoch 025:    539 / 1474 loss=3.789, trans_loss=5.236, nll_loss=2.506, w2v_ctc_loss=1.191, task_loss=2, contrastive_loss=0.134, total=4156.93, n_correct=2737.11, ppl=5.68, accuracy=65.845, wps=5668.2, ups=1.36, wpb=4156.9, bsz=156.4, num_updates=35900, lr=7.46393e-05, gnorm=0.956, clip=0, loss_scale=64, train_wall=73, gb_free=17.2, wall=32590
2023-07-02 15:13:44 | INFO | train_inner | epoch 025:    639 / 1474 loss=3.79, trans_loss=5.228, nll_loss=2.496, w2v_ctc_loss=1.181, task_loss=2, contrastive_loss=0.269, total=4153.23, n_correct=2740.05, ppl=5.64, accuracy=65.974, wps=5670.1, ups=1.37, wpb=4153.2, bsz=154.8, num_updates=36000, lr=7.45356e-05, gnorm=0.969, clip=0, loss_scale=64, train_wall=73, gb_free=15.1, wall=32664
2023-07-02 15:13:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 15:14:08 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.322 | trans_loss 5.548 | nll_loss 2.819 | w2v_ctc_loss 1.344 | task_loss 0 | contrastive_loss 0.256 | total 4003.4 | n_correct 2490 | ppl 7.06 | accuracy 62.197 | uer 16.901 | wer 18.862 | raw_wer 18.862 | bleu 20.47 | wps 2430.1 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.47
2023-07-02 15:14:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-07-02 15:14:08 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_25_36000.pt
2023-07-02 15:14:10 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_25_36000.pt
2023-07-02 15:14:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 20.47) (writing took 9.039869380183518 seconds)
2023-07-02 15:15:30 | INFO | train_inner | epoch 025:    739 / 1474 loss=3.804, trans_loss=5.238, nll_loss=2.509, w2v_ctc_loss=1.187, task_loss=2, contrastive_loss=0.257, total=4123.21, n_correct=2711.08, ppl=5.69, accuracy=65.752, wps=3896, ups=0.94, wpb=4123.2, bsz=150.4, num_updates=36100, lr=7.44323e-05, gnorm=0.959, clip=0, loss_scale=64, train_wall=73, gb_free=15, wall=32769
2023-07-02 15:16:44 | INFO | train_inner | epoch 025:    839 / 1474 loss=3.766, trans_loss=5.227, nll_loss=2.495, w2v_ctc_loss=1.161, task_loss=2, contrastive_loss=0.153, total=4197.27, n_correct=2768.1, ppl=5.64, accuracy=65.95, wps=5706.5, ups=1.36, wpb=4197.3, bsz=164.1, num_updates=36200, lr=7.43294e-05, gnorm=0.949, clip=0, loss_scale=64, train_wall=73, gb_free=16.3, wall=32843
2023-07-02 15:17:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-02 15:17:58 | INFO | train_inner | epoch 025:    940 / 1474 loss=3.78, trans_loss=5.228, nll_loss=2.496, w2v_ctc_loss=1.176, task_loss=2, contrastive_loss=0.139, total=4129.02, n_correct=2722.09, ppl=5.64, accuracy=65.926, wps=5542.8, ups=1.34, wpb=4129, bsz=155.1, num_updates=36300, lr=7.4227e-05, gnorm=0.952, clip=0, loss_scale=64, train_wall=74, gb_free=14.4, wall=32917
2023-07-02 15:19:12 | INFO | train_inner | epoch 025:   1040 / 1474 loss=3.809, trans_loss=5.245, nll_loss=2.518, w2v_ctc_loss=1.162, task_loss=2, contrastive_loss=0.485, total=4177.7, n_correct=2740.34, ppl=5.73, accuracy=65.594, wps=5659.2, ups=1.35, wpb=4177.7, bsz=154.9, num_updates=36400, lr=7.41249e-05, gnorm=0.949, clip=0, loss_scale=64, train_wall=73, gb_free=15.9, wall=32991
2023-07-02 15:20:25 | INFO | train_inner | epoch 025:   1140 / 1474 loss=3.796, trans_loss=5.237, nll_loss=2.508, w2v_ctc_loss=1.176, task_loss=2, contrastive_loss=0.102, total=4039.24, n_correct=2653.37, ppl=5.69, accuracy=65.69, wps=5504, ups=1.36, wpb=4039.2, bsz=142.6, num_updates=36500, lr=7.40233e-05, gnorm=0.977, clip=0, loss_scale=64, train_wall=73, gb_free=16.6, wall=33065
2023-07-02 15:21:38 | INFO | train_inner | epoch 025:   1240 / 1474 loss=3.796, trans_loss=5.24, nll_loss=2.511, w2v_ctc_loss=1.179, task_loss=2, contrastive_loss=0.121, total=4090.59, n_correct=2686.57, ppl=5.7, accuracy=65.677, wps=5636.9, ups=1.38, wpb=4090.6, bsz=147.8, num_updates=36600, lr=7.39221e-05, gnorm=0.964, clip=0, loss_scale=64, train_wall=72, gb_free=17.4, wall=33137
2023-07-02 15:22:52 | INFO | train_inner | epoch 025:   1340 / 1474 loss=3.791, trans_loss=5.232, nll_loss=2.501, w2v_ctc_loss=1.168, task_loss=2, contrastive_loss=0.305, total=4164.34, n_correct=2742.39, ppl=5.66, accuracy=65.854, wps=5658.2, ups=1.36, wpb=4164.3, bsz=155.1, num_updates=36700, lr=7.38213e-05, gnorm=0.947, clip=0, loss_scale=64, train_wall=73, gb_free=17.1, wall=33211
2023-07-02 15:24:06 | INFO | train_inner | epoch 025:   1440 / 1474 loss=3.815, trans_loss=5.257, nll_loss=2.533, w2v_ctc_loss=1.193, task_loss=2, contrastive_loss=0.209, total=4099.11, n_correct=2684.5, ppl=5.79, accuracy=65.49, wps=5508, ups=1.34, wpb=4099.1, bsz=149.7, num_updates=36800, lr=7.3721e-05, gnorm=0.97, clip=0, loss_scale=64, train_wall=74, gb_free=12.6, wall=33285
2023-07-02 15:24:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 15:24:57 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.313 | trans_loss 5.546 | nll_loss 2.819 | w2v_ctc_loss 1.322 | task_loss 0 | contrastive_loss 0.255 | total 4003.4 | n_correct 2489.9 | ppl 7.06 | accuracy 62.195 | uer 16.537 | wer 18.672 | raw_wer 18.672 | bleu 20.1 | wps 2135.9 | wpb 4003.4 | bsz 141.8 | num_updates 36834 | best_bleu 20.47
2023-07-02 15:24:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36834 updates
2023-07-02 15:24:57 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.1001.pt
2023-07-02 15:25:00 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.1001.pt
2023-07-02 15:25:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.1001.pt (epoch 25 @ 36834 updates, score 20.1) (writing took 5.264728945679963 seconds)
2023-07-02 15:25:03 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-07-02 15:25:03 | INFO | train | epoch 025 | loss 3.791 | trans_loss 5.232 | nll_loss 2.501 | w2v_ctc_loss 1.178 | task_loss 2 | contrastive_loss 0.211 | total 4137.53 | n_correct 2724.53 | ppl 5.66 | accuracy 65.849 | wps 5268.3 | ups 1.27 | wpb 4137.5 | bsz 152.7 | num_updates 36834 | lr 7.36869e-05 | gnorm 0.958 | clip 0 | loss_scale 64 | train_wall 1078 | gb_free 14.6 | wall 33342
2023-07-02 15:25:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 15:25:03 | INFO | fairseq.trainer | begin training epoch 26
2023-07-02 15:25:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 15:26:00 | INFO | train_inner | epoch 026:     66 / 1474 loss=3.754, trans_loss=5.204, nll_loss=2.465, w2v_ctc_loss=1.145, task_loss=2, contrastive_loss=0.176, total=4180.21, n_correct=2773.07, ppl=5.52, accuracy=66.338, wps=3680.1, ups=0.88, wpb=4180.2, bsz=159.2, num_updates=36900, lr=7.3621e-05, gnorm=0.944, clip=0, loss_scale=64, train_wall=74, gb_free=17.2, wall=33399
2023-07-02 15:27:13 | INFO | train_inner | epoch 026:    166 / 1474 loss=3.758, trans_loss=5.201, nll_loss=2.462, w2v_ctc_loss=1.121, task_loss=2, contrastive_loss=0.545, total=4270.78, n_correct=2837.2, ppl=5.51, accuracy=66.433, wps=5798.6, ups=1.36, wpb=4270.8, bsz=170.2, num_updates=37000, lr=7.35215e-05, gnorm=0.937, clip=0, loss_scale=64, train_wall=73, gb_free=15.5, wall=33472
2023-07-02 15:28:27 | INFO | train_inner | epoch 026:    266 / 1474 loss=3.783, trans_loss=5.215, nll_loss=2.479, w2v_ctc_loss=1.179, task_loss=2, contrastive_loss=0.299, total=4125.04, n_correct=2729.29, ppl=5.57, accuracy=66.164, wps=5632.5, ups=1.37, wpb=4125, bsz=153.6, num_updates=37100, lr=7.34223e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=73, gb_free=15.4, wall=33546
2023-07-02 15:29:40 | INFO | train_inner | epoch 026:    366 / 1474 loss=3.766, trans_loss=5.21, nll_loss=2.472, w2v_ctc_loss=1.157, task_loss=2, contrastive_loss=0.214, total=4165.74, n_correct=2755.69, ppl=5.55, accuracy=66.151, wps=5703.2, ups=1.37, wpb=4165.7, bsz=157.3, num_updates=37200, lr=7.33236e-05, gnorm=0.956, clip=0, loss_scale=64, train_wall=73, gb_free=17, wall=33619
2023-07-02 15:30:53 | INFO | train_inner | epoch 026:    466 / 1474 loss=3.761, trans_loss=5.199, nll_loss=2.459, w2v_ctc_loss=1.152, task_loss=2, contrastive_loss=0.301, total=4170.23, n_correct=2772.56, ppl=5.5, accuracy=66.485, wps=5695, ups=1.37, wpb=4170.2, bsz=157.7, num_updates=37300, lr=7.32252e-05, gnorm=0.938, clip=0, loss_scale=64, train_wall=73, gb_free=17.9, wall=33692
2023-07-02 15:32:07 | INFO | train_inner | epoch 026:    566 / 1474 loss=3.786, trans_loss=5.22, nll_loss=2.485, w2v_ctc_loss=1.193, task_loss=2, contrastive_loss=0.144, total=4155.02, n_correct=2742.68, ppl=5.6, accuracy=66.009, wps=5628.7, ups=1.35, wpb=4155, bsz=151.9, num_updates=37400, lr=7.31272e-05, gnorm=0.96, clip=0, loss_scale=64, train_wall=73, gb_free=17.9, wall=33766
2023-07-02 15:33:20 | INFO | train_inner | epoch 026:    666 / 1474 loss=3.765, trans_loss=5.21, nll_loss=2.472, w2v_ctc_loss=1.146, task_loss=2, contrastive_loss=0.116, total=4136.96, n_correct=2738.27, ppl=5.55, accuracy=66.19, wps=5616.8, ups=1.36, wpb=4137, bsz=149.6, num_updates=37500, lr=7.30297e-05, gnorm=0.946, clip=0, loss_scale=64, train_wall=73, gb_free=15.5, wall=33839
2023-07-02 15:34:34 | INFO | train_inner | epoch 026:    766 / 1474 loss=3.795, trans_loss=5.227, nll_loss=2.495, w2v_ctc_loss=1.164, task_loss=2, contrastive_loss=0.343, total=4086.28, n_correct=2695.47, ppl=5.64, accuracy=65.964, wps=5549.8, ups=1.36, wpb=4086.3, bsz=149.2, num_updates=37600, lr=7.29325e-05, gnorm=0.971, clip=0, loss_scale=64, train_wall=73, gb_free=15.3, wall=33913
2023-07-02 15:35:47 | INFO | train_inner | epoch 026:    866 / 1474 loss=3.779, trans_loss=5.222, nll_loss=2.487, w2v_ctc_loss=1.172, task_loss=2, contrastive_loss=0.142, total=4183.26, n_correct=2758.26, ppl=5.6, accuracy=65.936, wps=5705.9, ups=1.36, wpb=4183.3, bsz=154.1, num_updates=37700, lr=7.28357e-05, gnorm=0.958, clip=0, loss_scale=64, train_wall=73, gb_free=17.5, wall=33986
2023-07-02 15:37:01 | INFO | train_inner | epoch 026:    966 / 1474 loss=3.793, trans_loss=5.232, nll_loss=2.501, w2v_ctc_loss=1.16, task_loss=2, contrastive_loss=0.255, total=4137.96, n_correct=2724.68, ppl=5.66, accuracy=65.846, wps=5639.3, ups=1.36, wpb=4138, bsz=149.5, num_updates=37800, lr=7.27393e-05, gnorm=0.951, clip=0, loss_scale=64, train_wall=73, gb_free=17.1, wall=34060
2023-07-02 15:38:14 | INFO | train_inner | epoch 026:   1066 / 1474 loss=3.788, trans_loss=5.226, nll_loss=2.494, w2v_ctc_loss=1.177, task_loss=2, contrastive_loss=0.116, total=4120.53, n_correct=2717.75, ppl=5.63, accuracy=65.956, wps=5626.6, ups=1.37, wpb=4120.5, bsz=147.1, num_updates=37900, lr=7.26433e-05, gnorm=0.964, clip=0, loss_scale=64, train_wall=73, gb_free=16.8, wall=34133
2023-07-02 15:39:28 | INFO | train_inner | epoch 026:   1166 / 1474 loss=3.799, trans_loss=5.237, nll_loss=2.507, w2v_ctc_loss=1.184, task_loss=2, contrastive_loss=0.195, total=4113.86, n_correct=2705.31, ppl=5.68, accuracy=65.761, wps=5563.6, ups=1.35, wpb=4113.9, bsz=149.2, num_updates=38000, lr=7.25476e-05, gnorm=0.967, clip=0, loss_scale=64, train_wall=74, gb_free=16.8, wall=34207
2023-07-02 15:39:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 15:39:54 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.339 | trans_loss 5.556 | nll_loss 2.828 | w2v_ctc_loss 1.389 | task_loss 0 | contrastive_loss 0.251 | total 4003.4 | n_correct 2484.6 | ppl 7.1 | accuracy 62.062 | uer 16.718 | wer 18.679 | raw_wer 18.679 | bleu 20.12 | wps 2135.6 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.47
2023-07-02 15:39:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-07-02 15:39:54 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_26_38000.pt
2023-07-02 15:39:56 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_26_38000.pt
2023-07-02 15:40:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 20.12) (writing took 6.380092511884868 seconds)
2023-07-02 15:41:14 | INFO | train_inner | epoch 026:   1266 / 1474 loss=3.815, trans_loss=5.248, nll_loss=2.521, w2v_ctc_loss=1.203, task_loss=2, contrastive_loss=0.121, total=3996.19, n_correct=2618.83, ppl=5.74, accuracy=65.533, wps=3763.6, ups=0.94, wpb=3996.2, bsz=139.6, num_updates=38100, lr=7.24524e-05, gnorm=0.991, clip=0, loss_scale=64, train_wall=73, gb_free=17.8, wall=34313
2023-07-02 15:42:28 | INFO | train_inner | epoch 026:   1366 / 1474 loss=3.781, trans_loss=5.234, nll_loss=2.504, w2v_ctc_loss=1.164, task_loss=2, contrastive_loss=0.146, total=4159.74, n_correct=2743.04, ppl=5.67, accuracy=65.943, wps=5593.4, ups=1.34, wpb=4159.7, bsz=155.7, num_updates=38200, lr=7.23575e-05, gnorm=0.958, clip=0, loss_scale=64, train_wall=74, gb_free=17.4, wall=34388
2023-07-02 15:43:42 | INFO | train_inner | epoch 026:   1466 / 1474 loss=3.769, trans_loss=5.226, nll_loss=2.495, w2v_ctc_loss=1.155, task_loss=2, contrastive_loss=0.137, total=4165.66, n_correct=2751.21, ppl=5.64, accuracy=66.045, wps=5630.1, ups=1.35, wpb=4165.7, bsz=158.7, num_updates=38300, lr=7.22629e-05, gnorm=0.948, clip=0, loss_scale=64, train_wall=74, gb_free=16.7, wall=34462
2023-07-02 15:43:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 15:44:12 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.323 | trans_loss 5.549 | nll_loss 2.819 | w2v_ctc_loss 1.348 | task_loss 0 | contrastive_loss 0.252 | total 4003.4 | n_correct 2493.5 | ppl 7.06 | accuracy 62.285 | uer 16.418 | wer 18.437 | raw_wer 18.437 | bleu 20.43 | wps 2338.9 | wpb 4003.4 | bsz 141.8 | num_updates 38308 | best_bleu 20.47
2023-07-02 15:44:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38308 updates
2023-07-02 15:44:12 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.4301.pt
2023-07-02 15:44:15 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.4301.pt
2023-07-02 15:44:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.4301.pt (epoch 26 @ 38308 updates, score 20.43) (writing took 5.383850279264152 seconds)
2023-07-02 15:44:18 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-07-02 15:44:18 | INFO | train | epoch 026 | loss 3.78 | trans_loss 5.22 | nll_loss 2.485 | w2v_ctc_loss 1.165 | task_loss 2 | contrastive_loss 0.219 | total 4138.65 | n_correct 2734.05 | ppl 5.6 | accuracy 66.061 | wps 5281.5 | ups 1.28 | wpb 4138.6 | bsz 152.8 | num_updates 38308 | lr 7.22554e-05 | gnorm 0.957 | clip 0 | loss_scale 64 | train_wall 1078 | gb_free 16.2 | wall 34497
2023-07-02 15:44:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 15:44:18 | INFO | fairseq.trainer | begin training epoch 27
2023-07-02 15:44:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 15:45:33 | INFO | train_inner | epoch 027:     92 / 1474 loss=3.75, trans_loss=5.178, nll_loss=2.429, w2v_ctc_loss=1.145, task_loss=2, contrastive_loss=0.095, total=4054.57, n_correct=2704.85, ppl=5.39, accuracy=66.711, wps=3662.9, ups=0.9, wpb=4054.6, bsz=141.2, num_updates=38400, lr=7.21688e-05, gnorm=0.974, clip=0, loss_scale=128, train_wall=72, gb_free=16.5, wall=34572
2023-07-02 15:46:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-02 15:46:47 | INFO | train_inner | epoch 027:    193 / 1474 loss=3.736, trans_loss=5.18, nll_loss=2.433, w2v_ctc_loss=1.148, task_loss=2, contrastive_loss=0.152, total=4185.71, n_correct=2789.81, ppl=5.4, accuracy=66.651, wps=5639, ups=1.35, wpb=4185.7, bsz=160.6, num_updates=38500, lr=7.2075e-05, gnorm=0.95, clip=0, loss_scale=64, train_wall=74, gb_free=17.7, wall=34646
2023-07-02 15:48:01 | INFO | train_inner | epoch 027:    293 / 1474 loss=3.753, trans_loss=5.193, nll_loss=2.45, w2v_ctc_loss=1.152, task_loss=2, contrastive_loss=0.119, total=4167.92, n_correct=2773.01, ppl=5.47, accuracy=66.532, wps=5636, ups=1.35, wpb=4167.9, bsz=153.4, num_updates=38600, lr=7.19816e-05, gnorm=0.943, clip=0, loss_scale=64, train_wall=74, gb_free=17, wall=34720
2023-07-02 15:48:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-02 15:49:17 | INFO | train_inner | epoch 027:    394 / 1474 loss=3.779, trans_loss=5.204, nll_loss=2.464, w2v_ctc_loss=1.167, task_loss=2, contrastive_loss=0.256, total=4054.47, n_correct=2686.22, ppl=5.52, accuracy=66.253, wps=5389, ups=1.33, wpb=4054.5, bsz=144.3, num_updates=38700, lr=7.18885e-05, gnorm=0.965, clip=0, loss_scale=32, train_wall=75, gb_free=16.6, wall=34796
2023-07-02 15:50:30 | INFO | train_inner | epoch 027:    494 / 1474 loss=3.764, trans_loss=5.209, nll_loss=2.472, w2v_ctc_loss=1.145, task_loss=2, contrastive_loss=0.351, total=4245.37, n_correct=2810.49, ppl=5.55, accuracy=66.201, wps=5739, ups=1.35, wpb=4245.4, bsz=165.7, num_updates=38800, lr=7.17958e-05, gnorm=0.949, clip=0, loss_scale=32, train_wall=74, gb_free=17.1, wall=34870
2023-07-02 15:51:44 | INFO | train_inner | epoch 027:    594 / 1474 loss=3.77, trans_loss=5.21, nll_loss=2.473, w2v_ctc_loss=1.163, task_loss=2, contrastive_loss=0.24, total=4134.93, n_correct=2738.65, ppl=5.55, accuracy=66.232, wps=5655.7, ups=1.37, wpb=4134.9, bsz=156, num_updates=38900, lr=7.17035e-05, gnorm=0.958, clip=0, loss_scale=32, train_wall=73, gb_free=17.7, wall=34943
2023-07-02 15:52:58 | INFO | train_inner | epoch 027:    694 / 1474 loss=3.78, trans_loss=5.217, nll_loss=2.482, w2v_ctc_loss=1.17, task_loss=2, contrastive_loss=0.192, total=4162.17, n_correct=2752.17, ppl=5.58, accuracy=66.123, wps=5624.2, ups=1.35, wpb=4162.2, bsz=152.5, num_updates=39000, lr=7.16115e-05, gnorm=0.96, clip=0, loss_scale=32, train_wall=74, gb_free=15.7, wall=35017
2023-07-02 15:54:11 | INFO | train_inner | epoch 027:    794 / 1474 loss=3.778, trans_loss=5.214, nll_loss=2.477, w2v_ctc_loss=1.173, task_loss=2, contrastive_loss=0.121, total=4107.17, n_correct=2716.43, ppl=5.57, accuracy=66.139, wps=5618, ups=1.37, wpb=4107.2, bsz=147.2, num_updates=39100, lr=7.15199e-05, gnorm=0.967, clip=0, loss_scale=32, train_wall=73, gb_free=12, wall=35090
2023-07-02 15:55:24 | INFO | train_inner | epoch 027:    894 / 1474 loss=3.77, trans_loss=5.213, nll_loss=2.476, w2v_ctc_loss=1.148, task_loss=2, contrastive_loss=0.104, total=4101.4, n_correct=2713.79, ppl=5.56, accuracy=66.167, wps=5622.3, ups=1.37, wpb=4101.4, bsz=146.4, num_updates=39200, lr=7.14286e-05, gnorm=0.964, clip=0, loss_scale=32, train_wall=72, gb_free=16.6, wall=35163
2023-07-02 15:56:38 | INFO | train_inner | epoch 027:    994 / 1474 loss=3.789, trans_loss=5.218, nll_loss=2.484, w2v_ctc_loss=1.166, task_loss=2, contrastive_loss=0.479, total=4195.5, n_correct=2771.88, ppl=5.59, accuracy=66.068, wps=5668.3, ups=1.35, wpb=4195.5, bsz=158, num_updates=39300, lr=7.13376e-05, gnorm=0.964, clip=0, loss_scale=32, train_wall=74, gb_free=17, wall=35237
2023-07-02 15:57:51 | INFO | train_inner | epoch 027:   1094 / 1474 loss=3.77, trans_loss=5.212, nll_loss=2.476, w2v_ctc_loss=1.162, task_loss=2, contrastive_loss=0.141, total=4147.99, n_correct=2742.61, ppl=5.56, accuracy=66.119, wps=5630.7, ups=1.36, wpb=4148, bsz=152.4, num_updates=39400, lr=7.1247e-05, gnorm=0.947, clip=0, loss_scale=32, train_wall=73, gb_free=16.3, wall=35311
2023-07-02 15:59:05 | INFO | train_inner | epoch 027:   1194 / 1474 loss=3.777, trans_loss=5.215, nll_loss=2.48, w2v_ctc_loss=1.164, task_loss=2, contrastive_loss=0.147, total=4104.84, n_correct=2711.68, ppl=5.58, accuracy=66.061, wps=5596.1, ups=1.36, wpb=4104.8, bsz=148.6, num_updates=39500, lr=7.11568e-05, gnorm=0.959, clip=0, loss_scale=32, train_wall=73, gb_free=12.7, wall=35384
2023-07-02 16:00:18 | INFO | train_inner | epoch 027:   1294 / 1474 loss=3.787, trans_loss=5.222, nll_loss=2.488, w2v_ctc_loss=1.159, task_loss=2, contrastive_loss=0.255, total=4062.86, n_correct=2682.06, ppl=5.61, accuracy=66.014, wps=5544.6, ups=1.36, wpb=4062.9, bsz=146.8, num_updates=39600, lr=7.10669e-05, gnorm=0.968, clip=0, loss_scale=32, train_wall=73, gb_free=16.8, wall=35457
2023-07-02 16:01:31 | INFO | train_inner | epoch 027:   1394 / 1474 loss=3.777, trans_loss=5.222, nll_loss=2.49, w2v_ctc_loss=1.162, task_loss=2, contrastive_loss=0.227, total=4157.6, n_correct=2741.75, ppl=5.62, accuracy=65.945, wps=5668.1, ups=1.36, wpb=4157.6, bsz=157, num_updates=39700, lr=7.09773e-05, gnorm=0.948, clip=0, loss_scale=32, train_wall=73, gb_free=17.7, wall=35531
2023-07-02 16:02:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 16:02:55 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.334 | trans_loss 5.551 | nll_loss 2.825 | w2v_ctc_loss 1.381 | task_loss 0 | contrastive_loss 0.25 | total 4003.4 | n_correct 2491.3 | ppl 7.09 | accuracy 62.23 | uer 16.962 | wer 18.966 | raw_wer 18.966 | bleu 20.4 | wps 2137.9 | wpb 4003.4 | bsz 141.8 | num_updates 39780 | best_bleu 20.47
2023-07-02 16:02:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39780 updates
2023-07-02 16:02:55 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.4004.pt
2023-07-02 16:02:57 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.4004.pt
2023-07-02 16:03:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint.best_bleu_20.4004.pt (epoch 27 @ 39780 updates, score 20.4) (writing took 5.432269726879895 seconds)
2023-07-02 16:03:01 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-07-02 16:03:01 | INFO | train | epoch 027 | loss 3.769 | trans_loss 5.207 | nll_loss 2.469 | w2v_ctc_loss 1.157 | task_loss 2 | contrastive_loss 0.204 | total 4136.54 | n_correct 2739.84 | ppl 5.54 | accuracy 66.235 | wps 5421.7 | ups 1.31 | wpb 4136.5 | bsz 152.5 | num_updates 39780 | lr 7.09059e-05 | gnorm 0.958 | clip 0 | loss_scale 32 | train_wall 1077 | gb_free 17.9 | wall 35620
2023-07-02 16:03:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-02 16:03:01 | INFO | fairseq.trainer | begin training epoch 28
2023-07-02 16:03:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-02 16:03:23 | INFO | train_inner | epoch 028:     20 / 1474 loss=3.745, trans_loss=5.196, nll_loss=2.455, w2v_ctc_loss=1.128, task_loss=2, contrastive_loss=0.118, total=4107.3, n_correct=2727.53, ppl=5.48, accuracy=66.407, wps=3663.9, ups=0.89, wpb=4107.3, bsz=152.3, num_updates=39800, lr=7.08881e-05, gnorm=0.953, clip=0, loss_scale=32, train_wall=73, gb_free=17.4, wall=35643
2023-07-02 16:04:37 | INFO | train_inner | epoch 028:    120 / 1474 loss=3.755, trans_loss=5.183, nll_loss=2.436, w2v_ctc_loss=1.158, task_loss=2, contrastive_loss=0.113, total=4112.44, n_correct=2742.93, ppl=5.41, accuracy=66.698, wps=5631.3, ups=1.37, wpb=4112.4, bsz=146.3, num_updates=39900, lr=7.07992e-05, gnorm=1.015, clip=0, loss_scale=32, train_wall=73, gb_free=14.1, wall=35716
2023-07-02 16:05:50 | INFO | train_inner | epoch 028:    220 / 1474 loss=3.728, trans_loss=5.176, nll_loss=2.429, w2v_ctc_loss=1.123, task_loss=2, contrastive_loss=0.13, total=4193.3, n_correct=2801.23, ppl=5.38, accuracy=66.803, wps=5701.1, ups=1.36, wpb=4193.3, bsz=158.2, num_updates=40000, lr=7.07107e-05, gnorm=0.952, clip=0, loss_scale=32, train_wall=73, gb_free=17.1, wall=35789
2023-07-02 16:05:50 | INFO | fairseq_cli.train | Stopping training due to num_updates: 40000 >= max_update: 40000
2023-07-02 16:05:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-02 16:06:15 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.337 | trans_loss 5.551 | nll_loss 2.825 | w2v_ctc_loss 1.388 | task_loss 0 | contrastive_loss 0.252 | total 4003.4 | n_correct 2494.2 | ppl 7.09 | accuracy 62.302 | uer 16.593 | wer 18.459 | raw_wer 18.459 | bleu 20.35 | wps 2204.1 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.47
2023-07-02 16:06:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-07-02 16:06:15 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_28_40000.pt
2023-07-02 16:06:17 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_28_40000.pt
2023-07-02 16:06:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_scale10/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 20.35) (writing took 6.3278568596579134 seconds)
2023-07-02 16:06:21 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-07-02 16:06:21 | INFO | train | epoch 028 | loss 3.74 | trans_loss 5.178 | nll_loss 2.431 | w2v_ctc_loss 1.138 | task_loss 2 | contrastive_loss 0.121 | total 4144.97 | n_correct 2767.34 | ppl 5.39 | accuracy 66.764 | wps 4550.5 | ups 1.1 | wpb 4145 | bsz 151.6 | num_updates 40000 | lr 7.07107e-05 | gnorm 0.98 | clip 0 | loss_scale 32 | train_wall 160 | gb_free 17.1 | wall 35820
2023-07-02 16:06:21 | INFO | fairseq_cli.train | done training in 35751.1 seconds
/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1200 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
