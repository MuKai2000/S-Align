2023-07-04 14:07:25 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:13704
2023-07-04 14:07:25 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:13704
2023-07-04 14:07:25 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:13704
2023-07-04 14:07:25 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:13704
2023-07-04 14:07:25 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:13704
2023-07-04 14:07:25 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:13704
2023-07-04 14:07:25 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:13704
2023-07-04 14:07:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-04 14:07:25 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:13704
2023-07-04 14:07:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-04 14:07:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-04 14:07:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-04 14:07:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-04 14:07:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-04 14:07:26 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-04 14:07:26 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-04 14:07:26 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-04 14:07:26 | INFO | fairseq.distributed.utils | initialized host capios as rank 2
2023-07-04 14:07:26 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-04 14:07:26 | INFO | fairseq.distributed.utils | initialized host capios as rank 3
2023-07-04 14:07:26 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-04 14:07:26 | INFO | fairseq.distributed.utils | initialized host capios as rank 4
2023-07-04 14:07:26 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-04 14:07:26 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-04 14:07:26 | INFO | fairseq.distributed.utils | initialized host capios as rank 5
2023-07-04 14:07:26 | INFO | fairseq.distributed.utils | initialized host capios as rank 7
2023-07-04 14:07:26 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-04 14:07:26 | INFO | fairseq.distributed.utils | initialized host capios as rank 0
2023-07-04 14:07:26 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-04 14:07:26 | INFO | fairseq.distributed.utils | initialized host capios as rank 6
2023-07-04 14:07:26 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-04 14:07:26 | INFO | fairseq.distributed.utils | initialized host capios as rank 1
2023-07-04 14:07:28 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13704', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-04 14:07:28 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-04 14:07:28 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-04 14:07:28 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-04 14:07:28 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-04 14:07:28 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-04 14:07:33 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-04 14:07:33 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-04 14:07:33 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-04 14:07:35 | INFO | root | load pretrained hubert
2023-07-04 14:07:39 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-04 14:07:41 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-04 14:07:44 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-04 14:07:44 | INFO | root | share the sematic adapter and textual encoder
2023-07-04 14:07:44 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-04 14:07:44 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-04 14:07:44 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-04 14:07:44 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-04 14:07:44 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-04 14:07:44 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-04 14:07:44 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-04 14:07:44 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-04 14:07:44 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-04 14:07:44 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-04 14:07:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-04 14:07:51 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-04 14:07:51 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-04 14:07:52 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-04 14:07:52 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-04 14:07:52 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-04 14:07:52 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-04 14:07:52 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-04 14:07:52 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-04 14:07:52 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-04 14:07:52 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-04 14:07:52 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-04 14:07:52 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-04 14:07:52 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-04 14:07:52 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-04 14:07:52 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt
2023-07-04 14:07:52 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt
2023-07-04 14:07:52 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-04 14:07:52 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-04 14:07:52 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-04 14:07:52 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-04 14:07:53 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-04 14:07:55 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-04 14:07:57 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-04 14:09:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 14:09:01 | INFO | fairseq.trainer | begin training epoch 1
2023-07-04 14:09:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 14:09:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-04 14:10:13 | INFO | train_inner | epoch 001:    101 / 1474 loss=11.638, trans_loss=5.652, nll_loss=4.231, w2v_ctc_loss=13.796, task_loss=0.704, contrastive_loss=0, total=4200.41, n_correct=210.78, ppl=18.78, accuracy=5.018, wps=20493.3, ups=1.63, wpb=12542.9, bsz=467.5, num_updates=100, lr=4.098e-06, gnorm=0.554, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=141
2023-07-04 14:11:13 | INFO | train_inner | epoch 001:    201 / 1474 loss=10.304, trans_loss=5.538, nll_loss=4.151, w2v_ctc_loss=11.828, task_loss=0.703, contrastive_loss=0, total=4127.38, n_correct=230.41, ppl=17.77, accuracy=5.582, wps=20513.7, ups=1.66, wpb=12327, bsz=463.1, num_updates=200, lr=8.096e-06, gnorm=2.255, clip=0, loss_scale=64, train_wall=60, gb_free=19.2, wall=201
2023-07-04 14:12:12 | INFO | train_inner | epoch 001:    301 / 1474 loss=6.101, trans_loss=5.511, nll_loss=4.174, w2v_ctc_loss=5.383, task_loss=0.762, contrastive_loss=0, total=4079.62, n_correct=228.97, ppl=18.05, accuracy=5.613, wps=20712, ups=1.7, wpb=12195.4, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=2.84, clip=0, loss_scale=64, train_wall=58, gb_free=19.9, wall=260
2023-07-04 14:13:11 | INFO | train_inner | epoch 001:    401 / 1474 loss=5.323, trans_loss=5.514, nll_loss=4.195, w2v_ctc_loss=4.186, task_loss=0.701, contrastive_loss=0, total=4174.14, n_correct=213.24, ppl=18.32, accuracy=5.109, wps=21040.2, ups=1.69, wpb=12461.1, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=1.84, clip=0, loss_scale=64, train_wall=59, gb_free=18.9, wall=319
2023-07-04 14:14:10 | INFO | train_inner | epoch 001:    501 / 1474 loss=5.033, trans_loss=5.453, nll_loss=4.134, w2v_ctc_loss=3.78, task_loss=0.63, contrastive_loss=0, total=4176.18, n_correct=230.84, ppl=17.56, accuracy=5.528, wps=21130, ups=1.69, wpb=12513, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=0.868, clip=0, loss_scale=64, train_wall=59, gb_free=19.2, wall=378
2023-07-04 14:15:09 | INFO | train_inner | epoch 001:    601 / 1474 loss=4.893, trans_loss=5.467, nll_loss=4.173, w2v_ctc_loss=3.559, task_loss=0.554, contrastive_loss=0, total=4147.79, n_correct=275.61, ppl=18.03, accuracy=6.645, wps=20907.2, ups=1.69, wpb=12368.1, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.407, clip=0, loss_scale=64, train_wall=59, gb_free=18.9, wall=438
2023-07-04 14:16:08 | INFO | train_inner | epoch 001:    701 / 1474 loss=4.844, trans_loss=5.483, nll_loss=4.214, w2v_ctc_loss=3.473, task_loss=0.584, contrastive_loss=0, total=4152.1, n_correct=289.37, ppl=18.56, accuracy=6.969, wps=21151.5, ups=1.71, wpb=12373.8, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=0.255, clip=0, loss_scale=64, train_wall=58, gb_free=19.5, wall=496
2023-07-04 14:17:07 | INFO | train_inner | epoch 001:    801 / 1474 loss=4.788, trans_loss=5.644, nll_loss=4.46, w2v_ctc_loss=3.283, task_loss=0.807, contrastive_loss=0, total=4123.83, n_correct=254.99, ppl=22.01, accuracy=6.183, wps=20982.9, ups=1.7, wpb=12311.9, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=0.307, clip=0, loss_scale=64, train_wall=58, gb_free=19.1, wall=555
2023-07-04 14:18:06 | INFO | train_inner | epoch 001:    901 / 1474 loss=4.629, trans_loss=5.552, nll_loss=4.339, w2v_ctc_loss=3.099, task_loss=0.816, contrastive_loss=0, total=4163.61, n_correct=207.28, ppl=20.23, accuracy=4.978, wps=21031.5, ups=1.69, wpb=12409.7, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=0.312, clip=0, loss_scale=64, train_wall=59, gb_free=18.8, wall=614
2023-07-04 14:19:05 | INFO | train_inner | epoch 001:   1001 / 1474 loss=4.472, trans_loss=5.526, nll_loss=4.291, w2v_ctc_loss=2.872, task_loss=0.802, contrastive_loss=0, total=4135.34, n_correct=231.84, ppl=19.57, accuracy=5.606, wps=20838.2, ups=1.69, wpb=12363.9, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=0.359, clip=0, loss_scale=64, train_wall=59, gb_free=19, wall=673
2023-07-04 14:20:04 | INFO | train_inner | epoch 001:   1101 / 1474 loss=4.42, trans_loss=5.675, nll_loss=4.468, w2v_ctc_loss=2.698, task_loss=0.81, contrastive_loss=0, total=4147.38, n_correct=210.84, ppl=22.14, accuracy=5.084, wps=21077.3, ups=1.71, wpb=12356.9, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=0.37, clip=0, loss_scale=64, train_wall=58, gb_free=18.8, wall=732
2023-07-04 14:21:03 | INFO | train_inner | epoch 001:   1201 / 1474 loss=4.327, trans_loss=5.68, nll_loss=4.438, w2v_ctc_loss=2.551, task_loss=0.851, contrastive_loss=0, total=4139.9, n_correct=104.52, ppl=21.68, accuracy=2.525, wps=21022, ups=1.7, wpb=12386.7, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=0.421, clip=0, loss_scale=64, train_wall=59, gb_free=18.9, wall=791
2023-07-04 14:22:01 | INFO | train_inner | epoch 001:   1301 / 1474 loss=4.27, trans_loss=5.732, nll_loss=4.531, w2v_ctc_loss=2.43, task_loss=0.819, contrastive_loss=0, total=4046.58, n_correct=103.7, ppl=23.12, accuracy=2.563, wps=20768.5, ups=1.72, wpb=12092.5, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=0.435, clip=0, loss_scale=64, train_wall=58, gb_free=19.7, wall=849
2023-07-04 14:22:59 | INFO | train_inner | epoch 001:   1401 / 1474 loss=4.182, trans_loss=5.673, nll_loss=4.474, w2v_ctc_loss=2.332, task_loss=0.78, contrastive_loss=0, total=4133.18, n_correct=180.87, ppl=22.23, accuracy=4.376, wps=21014.1, ups=1.71, wpb=12300.7, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=0.465, clip=0, loss_scale=64, train_wall=58, gb_free=19.9, wall=908
2023-07-04 14:23:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-07-04 14:24:16 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 5.124 | trans_loss 12.503 | nll_loss 11.841 | w2v_ctc_loss 2.493 | task_loss 4.254 | contrastive_loss 0 | total 4003.4 | n_correct 92.9 | ppl 3668.41 | accuracy 2.321 | uer 62.814 | wer 61.034 | raw_wer 61.034 | bleu 0 | wps 1460.9 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-07-04 14:24:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-07-04 14:24:16 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 14:24:19 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 14:24:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.0) (writing took 4.772610642947257 seconds)
2023-07-04 14:24:21 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-07-04 14:24:21 | INFO | train | epoch 001 | loss 5.593 | trans_loss 5.59 | nll_loss 4.322 | w2v_ctc_loss 4.553 | task_loss 0.739 | contrastive_loss 0 | total 4138.32 | n_correct 204.862 | ppl 20 | accuracy 4.95 | wps 20007.4 | ups 1.62 | wpb 12354.6 | bsz 458.3 | num_updates 1473 | lr 5.89905e-05 | gnorm 0.82 | clip 0 | loss_scale 64 | train_wall 867 | gb_free 19.2 | wall 989
2023-07-04 14:24:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 14:24:21 | INFO | fairseq.trainer | begin training epoch 2
2023-07-04 14:24:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 14:24:45 | INFO | train_inner | epoch 002:     27 / 1474 loss=4.156, trans_loss=5.787, nll_loss=4.602, w2v_ctc_loss=2.22, task_loss=0.78, contrastive_loss=0, total=4162.95, n_correct=76.31, ppl=24.29, accuracy=1.833, wps=11719.3, ups=0.94, wpb=12414, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=59, gb_free=19.6, wall=1013
2023-07-04 14:25:44 | INFO | train_inner | epoch 002:    127 / 1474 loss=4.096, trans_loss=5.74, nll_loss=4.558, w2v_ctc_loss=2.159, task_loss=0.769, contrastive_loss=0, total=4155.98, n_correct=158.34, ppl=23.55, accuracy=3.81, wps=21005.4, ups=1.7, wpb=12390, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=0.495, clip=0, loss_scale=64, train_wall=59, gb_free=18.9, wall=1072
2023-07-04 14:26:42 | INFO | train_inner | epoch 002:    227 / 1474 loss=4.014, trans_loss=5.693, nll_loss=4.503, w2v_ctc_loss=2.063, task_loss=0.657, contrastive_loss=0, total=4179.21, n_correct=144.37, ppl=22.67, accuracy=3.454, wps=21558.7, ups=1.73, wpb=12488.1, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=0.468, clip=0, loss_scale=64, train_wall=58, gb_free=19, wall=1130
2023-07-04 14:27:41 | INFO | train_inner | epoch 002:    327 / 1474 loss=4.04, trans_loss=5.826, nll_loss=4.668, w2v_ctc_loss=2.015, task_loss=0.743, contrastive_loss=0, total=4146.1, n_correct=104.54, ppl=25.42, accuracy=2.521, wps=21156.2, ups=1.71, wpb=12381, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=0.448, clip=0, loss_scale=64, train_wall=58, gb_free=18.8, wall=1189
2023-07-04 14:28:39 | INFO | train_inner | epoch 002:    427 / 1474 loss=3.935, trans_loss=5.639, nll_loss=4.439, w2v_ctc_loss=1.973, task_loss=0.78, contrastive_loss=0, total=4037.99, n_correct=115.7, ppl=21.68, accuracy=2.865, wps=20819.1, ups=1.72, wpb=12079.4, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=0.471, clip=0, loss_scale=64, train_wall=58, gb_free=18.9, wall=1247
2023-07-04 14:29:37 | INFO | train_inner | epoch 002:    527 / 1474 loss=3.905, trans_loss=5.679, nll_loss=4.495, w2v_ctc_loss=1.902, task_loss=0.732, contrastive_loss=0, total=4176.97, n_correct=148.73, ppl=22.54, accuracy=3.561, wps=21433.9, ups=1.72, wpb=12475.1, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=0.479, clip=0, loss_scale=64, train_wall=58, gb_free=19.6, wall=1305
2023-07-04 14:29:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 14:30:11 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 5.011 | trans_loss 12.535 | nll_loss 12.02 | w2v_ctc_loss 2.078 | task_loss 3.559 | contrastive_loss 0 | total 4003.4 | n_correct 42.5 | ppl 4152.69 | accuracy 1.062 | uer 55.674 | wer 54.2 | raw_wer 54.2 | bleu 0 | wps 1443.3 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0
2023-07-04 14:30:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-07-04 14:30:11 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_2_2000.pt
2023-07-04 14:30:13 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_2_2000.pt
2023-07-04 14:30:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 7.983052596449852 seconds)
2023-07-04 14:31:17 | INFO | train_inner | epoch 002:    627 / 1474 loss=3.845, trans_loss=5.607, nll_loss=4.401, w2v_ctc_loss=1.856, task_loss=0.669, contrastive_loss=0, total=4126.49, n_correct=200.92, ppl=21.13, accuracy=4.869, wps=12240.9, ups=1, wpb=12299.1, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=0.527, clip=0, loss_scale=128, train_wall=58, gb_free=19.2, wall=1406
2023-07-04 14:32:15 | INFO | train_inner | epoch 002:    727 / 1474 loss=3.862, trans_loss=5.698, nll_loss=4.523, w2v_ctc_loss=1.824, task_loss=0.702, contrastive_loss=0, total=4149.06, n_correct=164.48, ppl=23, accuracy=3.964, wps=21401.1, ups=1.73, wpb=12372.9, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=0.484, clip=0, loss_scale=128, train_wall=57, gb_free=19.2, wall=1463
2023-07-04 14:33:14 | INFO | train_inner | epoch 002:    827 / 1474 loss=3.856, trans_loss=5.723, nll_loss=4.54, w2v_ctc_loss=1.796, task_loss=0.689, contrastive_loss=0, total=4175.4, n_correct=101.16, ppl=23.26, accuracy=2.423, wps=21271.1, ups=1.7, wpb=12477.6, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=0.398, clip=0, loss_scale=128, train_wall=58, gb_free=19.8, wall=1522
2023-07-04 14:34:12 | INFO | train_inner | epoch 002:    927 / 1474 loss=3.829, trans_loss=5.731, nll_loss=4.562, w2v_ctc_loss=1.751, task_loss=0.769, contrastive_loss=0, total=4104.2, n_correct=133.02, ppl=23.62, accuracy=3.241, wps=20891.1, ups=1.71, wpb=12243.8, bsz=445.9, num_updates=2400, lr=9.6052e-05, gnorm=0.454, clip=0, loss_scale=128, train_wall=58, gb_free=19, wall=1581
2023-07-04 14:35:10 | INFO | train_inner | epoch 002:   1027 / 1474 loss=3.794, trans_loss=5.7, nll_loss=4.521, w2v_ctc_loss=1.717, task_loss=0.654, contrastive_loss=0, total=4102.5, n_correct=87.34, ppl=22.95, accuracy=2.129, wps=21192.6, ups=1.73, wpb=12270.3, bsz=456.3, num_updates=2500, lr=0.00010005, gnorm=0.423, clip=0, loss_scale=128, train_wall=58, gb_free=19.2, wall=1639
2023-07-04 14:36:09 | INFO | train_inner | epoch 002:   1127 / 1474 loss=3.789, trans_loss=5.74, nll_loss=4.564, w2v_ctc_loss=1.685, task_loss=0.657, contrastive_loss=0, total=4187.61, n_correct=167.65, ppl=23.66, accuracy=4.003, wps=21182.9, ups=1.7, wpb=12484.3, bsz=487.1, num_updates=2600, lr=0.000104048, gnorm=0.386, clip=0, loss_scale=128, train_wall=59, gb_free=19.5, wall=1698
2023-07-04 14:37:08 | INFO | train_inner | epoch 002:   1227 / 1474 loss=3.813, trans_loss=5.819, nll_loss=4.669, w2v_ctc_loss=1.668, task_loss=0.608, contrastive_loss=0, total=4221.06, n_correct=75.75, ppl=25.43, accuracy=1.795, wps=21444.5, ups=1.7, wpb=12590.1, bsz=492.8, num_updates=2700, lr=0.000108046, gnorm=0.371, clip=0, loss_scale=128, train_wall=58, gb_free=19.4, wall=1756
2023-07-04 14:38:06 | INFO | train_inner | epoch 002:   1327 / 1474 loss=3.774, trans_loss=5.752, nll_loss=4.58, w2v_ctc_loss=1.652, task_loss=0.734, contrastive_loss=0, total=4157.86, n_correct=107.83, ppl=23.91, accuracy=2.593, wps=21540.5, ups=1.73, wpb=12422.5, bsz=460.7, num_updates=2800, lr=0.000112044, gnorm=0.349, clip=0, loss_scale=128, train_wall=57, gb_free=19.5, wall=1814
2023-07-04 14:39:05 | INFO | train_inner | epoch 002:   1427 / 1474 loss=3.794, trans_loss=5.831, nll_loss=4.667, w2v_ctc_loss=1.631, task_loss=0.744, contrastive_loss=0, total=4054.34, n_correct=117.78, ppl=25.41, accuracy=2.905, wps=20459.2, ups=1.69, wpb=12128.6, bsz=438.8, num_updates=2900, lr=0.000116042, gnorm=0.395, clip=0, loss_scale=128, train_wall=59, gb_free=19.4, wall=1873
2023-07-04 14:39:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 14:40:07 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 5.092 | trans_loss 13.037 | nll_loss 12.659 | w2v_ctc_loss 1.762 | task_loss 3.103 | contrastive_loss 0 | total 4003.4 | n_correct 39 | ppl 6468.68 | accuracy 0.974 | uer 48.828 | wer 47.575 | raw_wer 47.575 | bleu 0 | wps 1449.2 | wpb 4003.4 | bsz 141.8 | num_updates 2947 | best_bleu 0
2023-07-04 14:40:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2947 updates
2023-07-04 14:40:07 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 14:40:10 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 14:40:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt (epoch 2 @ 2947 updates, score 0.0) (writing took 6.918864831328392 seconds)
2023-07-04 14:40:13 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-07-04 14:40:13 | INFO | train | epoch 002 | loss 3.882 | trans_loss 5.727 | nll_loss 4.549 | w2v_ctc_loss 1.835 | task_loss 0.707 | contrastive_loss 0 | total 4138.65 | n_correct 128.859 | ppl 23.41 | accuracy 3.114 | wps 19124.9 | ups 1.55 | wpb 12355.8 | bsz 458.5 | num_updates 2947 | lr 0.000117921 | gnorm 0.437 | clip 0 | loss_scale 128 | train_wall 855 | gb_free 19.3 | wall 1942
2023-07-04 14:40:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 14:40:14 | INFO | fairseq.trainer | begin training epoch 3
2023-07-04 14:40:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 14:40:53 | INFO | train_inner | epoch 003:     53 / 1474 loss=3.764, trans_loss=5.799, nll_loss=4.651, w2v_ctc_loss=1.606, task_loss=0.663, contrastive_loss=0, total=4071.2, n_correct=72.27, ppl=25.13, accuracy=1.775, wps=11254.3, ups=0.93, wpb=12148.3, bsz=442.6, num_updates=3000, lr=0.00012004, gnorm=0.33, clip=0, loss_scale=128, train_wall=58, gb_free=19.1, wall=1981
2023-07-04 14:40:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-04 14:40:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-04 14:40:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-04 14:40:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-04 14:42:20 | INFO | train_inner | epoch 003:    157 / 1474 loss=3.029, trans_loss=4.373, nll_loss=2.789, w2v_ctc_loss=1.395, task_loss=0.504, contrastive_loss=0, total=4140.83, n_correct=1094.42, ppl=6.91, accuracy=26.43, wps=14171.8, ups=1.15, wpb=12366.2, bsz=456.4, num_updates=3100, lr=0.000124038, gnorm=0.77, clip=0, loss_scale=8, train_wall=87, gb_free=17.1, wall=2068
2023-07-04 14:43:46 | INFO | train_inner | epoch 003:    257 / 1474 loss=2.829, trans_loss=4.139, nll_loss=2.481, w2v_ctc_loss=1.239, task_loss=0.507, contrastive_loss=0, total=4146.68, n_correct=1372.49, ppl=5.58, accuracy=33.099, wps=14520.6, ups=1.17, wpb=12407.9, bsz=461.7, num_updates=3200, lr=0.000128036, gnorm=0.548, clip=0, loss_scale=8, train_wall=85, gb_free=15.4, wall=2154
2023-07-04 14:45:10 | INFO | train_inner | epoch 003:    357 / 1474 loss=2.766, trans_loss=4.066, nll_loss=2.384, w2v_ctc_loss=1.188, task_loss=0.495, contrastive_loss=0, total=4171.72, n_correct=1509.1, ppl=5.22, accuracy=36.175, wps=14710.7, ups=1.18, wpb=12430.3, bsz=468.1, num_updates=3300, lr=0.000132034, gnorm=0.576, clip=0, loss_scale=8, train_wall=84, gb_free=17.7, wall=2238
2023-07-04 14:46:36 | INFO | train_inner | epoch 003:    457 / 1474 loss=2.709, trans_loss=3.996, nll_loss=2.293, w2v_ctc_loss=1.147, task_loss=0.491, contrastive_loss=0, total=4200.59, n_correct=1630.19, ppl=4.9, accuracy=38.809, wps=14652, ups=1.17, wpb=12508.3, bsz=475.4, num_updates=3400, lr=0.000136032, gnorm=0.534, clip=0, loss_scale=8, train_wall=85, gb_free=12.8, wall=2324
2023-07-04 14:48:00 | INFO | train_inner | epoch 003:    557 / 1474 loss=2.661, trans_loss=3.957, nll_loss=2.237, w2v_ctc_loss=1.094, task_loss=0.535, contrastive_loss=0, total=4093.13, n_correct=1655.77, ppl=4.71, accuracy=40.452, wps=14554.7, ups=1.19, wpb=12255.6, bsz=440.1, num_updates=3500, lr=0.00014003, gnorm=0.535, clip=0, loss_scale=8, train_wall=84, gb_free=17.7, wall=2408
2023-07-04 14:49:26 | INFO | train_inner | epoch 003:    657 / 1474 loss=2.618, trans_loss=3.909, nll_loss=2.176, w2v_ctc_loss=1.061, task_loss=0.477, contrastive_loss=0, total=4222.97, n_correct=1794.26, ppl=4.52, accuracy=42.488, wps=14590.3, ups=1.16, wpb=12561.4, bsz=483.6, num_updates=3600, lr=0.000144028, gnorm=0.486, clip=0, loss_scale=8, train_wall=86, gb_free=17, wall=2494
2023-07-04 14:50:51 | INFO | train_inner | epoch 003:    757 / 1474 loss=2.597, trans_loss=3.881, nll_loss=2.138, w2v_ctc_loss=1.045, task_loss=0.481, contrastive_loss=0, total=4164.5, n_correct=1814.22, ppl=4.4, accuracy=43.564, wps=14605.5, ups=1.17, wpb=12455, bsz=470.6, num_updates=3700, lr=0.000148026, gnorm=0.518, clip=0, loss_scale=8, train_wall=85, gb_free=16.9, wall=2579
2023-07-04 14:52:16 | INFO | train_inner | epoch 003:    857 / 1474 loss=2.572, trans_loss=3.859, nll_loss=2.109, w2v_ctc_loss=1.02, task_loss=0.502, contrastive_loss=0, total=4165.03, n_correct=1849.61, ppl=4.31, accuracy=44.408, wps=14720, ups=1.18, wpb=12441.6, bsz=457.7, num_updates=3800, lr=0.000152024, gnorm=0.5, clip=0, loss_scale=8, train_wall=84, gb_free=14.9, wall=2664
2023-07-04 14:53:41 | INFO | train_inner | epoch 003:    957 / 1474 loss=2.555, trans_loss=3.835, nll_loss=2.078, w2v_ctc_loss=1.011, task_loss=0.489, contrastive_loss=0, total=4159.73, n_correct=1894.04, ppl=4.22, accuracy=45.533, wps=14577.8, ups=1.18, wpb=12402.6, bsz=467.1, num_updates=3900, lr=0.000156022, gnorm=0.498, clip=0, loss_scale=8, train_wall=85, gb_free=17.1, wall=2749
2023-07-04 14:55:05 | INFO | train_inner | epoch 003:   1057 / 1474 loss=2.547, trans_loss=3.825, nll_loss=2.064, w2v_ctc_loss=1.002, task_loss=0.543, contrastive_loss=0, total=4059.97, n_correct=1869.33, ppl=4.18, accuracy=46.043, wps=14395.8, ups=1.19, wpb=12137.3, bsz=438.4, num_updates=4000, lr=0.00016002, gnorm=0.495, clip=0, loss_scale=8, train_wall=84, gb_free=17.5, wall=2833
2023-07-04 14:55:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 14:55:38 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 2.52 | trans_loss 6.359 | nll_loss 3.881 | w2v_ctc_loss 0.98 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 1978.2 | ppl 14.73 | accuracy 49.413 | uer 28.607 | wer 29.693 | raw_wer 29.693 | bleu 10.44 | wps 1518.3 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 10.44
2023-07-04 14:55:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-07-04 14:55:38 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_3_4000.pt
2023-07-04 14:55:40 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_3_4000.pt
2023-07-04 14:55:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 10.44) (writing took 9.193289647810161 seconds)
2023-07-04 14:57:11 | INFO | train_inner | epoch 003:   1157 / 1474 loss=2.528, trans_loss=3.814, nll_loss=2.049, w2v_ctc_loss=0.98, task_loss=0.539, contrastive_loss=0, total=4048.71, n_correct=1883.19, ppl=4.14, accuracy=46.513, wps=9629.1, ups=0.8, wpb=12091.3, bsz=437, num_updates=4100, lr=0.000164018, gnorm=0.482, clip=0, loss_scale=8, train_wall=83, gb_free=16.8, wall=2959
2023-07-04 14:58:34 | INFO | train_inner | epoch 003:   1257 / 1474 loss=2.509, trans_loss=3.799, nll_loss=2.03, w2v_ctc_loss=0.959, task_loss=0.534, contrastive_loss=0, total=4063.12, n_correct=1922.65, ppl=4.09, accuracy=47.32, wps=14487.8, ups=1.19, wpb=12146.3, bsz=433.7, num_updates=4200, lr=0.000168016, gnorm=0.479, clip=0, loss_scale=8, train_wall=83, gb_free=13.7, wall=3043
2023-07-04 15:00:00 | INFO | train_inner | epoch 003:   1357 / 1474 loss=2.492, trans_loss=3.774, nll_loss=2.002, w2v_ctc_loss=0.952, task_loss=0.504, contrastive_loss=0, total=4141.08, n_correct=1987.97, ppl=4.01, accuracy=48.006, wps=14480.1, ups=1.17, wpb=12348, bsz=463.4, num_updates=4300, lr=0.000172014, gnorm=0.482, clip=0, loss_scale=8, train_wall=85, gb_free=17.4, wall=3128
2023-07-04 15:01:25 | INFO | train_inner | epoch 003:   1457 / 1474 loss=2.475, trans_loss=3.763, nll_loss=1.988, w2v_ctc_loss=0.933, task_loss=0.475, contrastive_loss=0, total=4212.48, n_correct=2044.95, ppl=3.97, accuracy=48.545, wps=14674.3, ups=1.17, wpb=12581.1, bsz=478.2, num_updates=4400, lr=0.000176012, gnorm=0.467, clip=0, loss_scale=8, train_wall=85, gb_free=16.8, wall=3214
2023-07-04 15:01:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 15:02:06 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 2.444 | trans_loss 6.212 | nll_loss 3.682 | w2v_ctc_loss 0.9 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2082 | ppl 12.84 | accuracy 52.006 | uer 27.479 | wer 28.317 | raw_wer 28.317 | bleu 13.18 | wps 2032.7 | wpb 4003.4 | bsz 141.8 | num_updates 4417 | best_bleu 13.18
2023-07-04 15:02:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4417 updates
2023-07-04 15:02:06 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 15:02:11 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 15:02:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt (epoch 3 @ 4417 updates, score 13.18) (writing took 8.41230947105214 seconds)
2023-07-04 15:02:15 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-07-04 15:02:15 | INFO | train | epoch 003 | loss 2.674 | trans_loss 3.995 | nll_loss 2.289 | w2v_ctc_loss 1.091 | task_loss 0.509 | contrastive_loss 0 | total 4139.74 | n_correct 1678.7 | ppl 4.89 | accuracy 40.551 | wps 13748.6 | ups 1.11 | wpb 12359.2 | bsz 458.8 | num_updates 4417 | lr 0.000176692 | gnorm 0.519 | clip 0 | loss_scale 8 | train_wall 1230 | gb_free 16.8 | wall 3263
2023-07-04 15:02:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 15:02:15 | INFO | fairseq.trainer | begin training epoch 4
2023-07-04 15:02:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 15:03:33 | INFO | train_inner | epoch 004:     83 / 1474 loss=2.446, trans_loss=3.737, nll_loss=1.952, w2v_ctc_loss=0.908, task_loss=0.527, contrastive_loss=0, total=4088.42, n_correct=2015.57, ppl=3.87, accuracy=49.299, wps=9547.8, ups=0.78, wpb=12184.2, bsz=437, num_updates=4500, lr=0.00018001, gnorm=0.47, clip=0, loss_scale=8, train_wall=84, gb_free=16.4, wall=3341
2023-07-04 15:04:57 | INFO | train_inner | epoch 004:    183 / 1474 loss=2.431, trans_loss=3.718, nll_loss=1.926, w2v_ctc_loss=0.895, task_loss=0.476, contrastive_loss=0, total=4183.38, n_correct=2093.54, ppl=3.8, accuracy=50.044, wps=14884.4, ups=1.19, wpb=12489.2, bsz=469.7, num_updates=4600, lr=0.000184008, gnorm=0.475, clip=0, loss_scale=8, train_wall=83, gb_free=16.8, wall=3425
2023-07-04 15:06:22 | INFO | train_inner | epoch 004:    283 / 1474 loss=2.43, trans_loss=3.717, nll_loss=1.927, w2v_ctc_loss=0.894, task_loss=0.502, contrastive_loss=0, total=4142.13, n_correct=2076.16, ppl=3.8, accuracy=50.123, wps=14590.9, ups=1.18, wpb=12379.5, bsz=463.3, num_updates=4700, lr=0.000188006, gnorm=0.464, clip=0, loss_scale=8, train_wall=84, gb_free=13.5, wall=3510
2023-07-04 15:07:46 | INFO | train_inner | epoch 004:    383 / 1474 loss=2.425, trans_loss=3.718, nll_loss=1.926, w2v_ctc_loss=0.886, task_loss=0.525, contrastive_loss=0, total=4132.81, n_correct=2077.02, ppl=3.8, accuracy=50.257, wps=14592.3, ups=1.19, wpb=12313.3, bsz=443.6, num_updates=4800, lr=0.000192004, gnorm=0.464, clip=0, loss_scale=8, train_wall=84, gb_free=14.9, wall=3594
2023-07-04 15:09:11 | INFO | train_inner | epoch 004:    483 / 1474 loss=2.405, trans_loss=3.702, nll_loss=1.909, w2v_ctc_loss=0.866, task_loss=0.461, contrastive_loss=0, total=4205.11, n_correct=2142.07, ppl=3.76, accuracy=50.94, wps=14758.3, ups=1.18, wpb=12541.4, bsz=493.7, num_updates=4900, lr=0.000196002, gnorm=0.454, clip=0, loss_scale=8, train_wall=85, gb_free=17.1, wall=3679
2023-07-04 15:10:36 | INFO | train_inner | epoch 004:    583 / 1474 loss=2.414, trans_loss=3.699, nll_loss=1.905, w2v_ctc_loss=0.882, task_loss=0.472, contrastive_loss=0, total=4224.38, n_correct=2155.47, ppl=3.74, accuracy=51.025, wps=14816.9, ups=1.18, wpb=12597.9, bsz=488.9, num_updates=5000, lr=0.0002, gnorm=0.459, clip=0, loss_scale=8, train_wall=85, gb_free=12.5, wall=3765
tensor(0.8422, device='cuda:0')
tensor(0.8291, device='cuda:0')
2023-07-04 15:12:03 | INFO | train_inner | epoch 004:    683 / 1474 loss=2.404, trans_loss=3.703, nll_loss=1.905, w2v_ctc_loss=0.863, task_loss=0.516, contrastive_loss=0, total=4182.18, n_correct=2142.97, ppl=3.75, accuracy=51.241, wps=14412.9, ups=1.16, wpb=12460.6, bsz=457.4, num_updates=5100, lr=0.00019803, gnorm=0.4, clip=0, loss_scale=16, train_wall=86, gb_free=12.5, wall=3851
2023-07-04 15:13:28 | INFO | train_inner | epoch 004:    783 / 1474 loss=2.407, trans_loss=3.699, nll_loss=1.901, w2v_ctc_loss=0.866, task_loss=0.56, contrastive_loss=0, total=4025.8, n_correct=2067.74, ppl=3.73, accuracy=51.362, wps=14205.7, ups=1.18, wpb=12047, bsz=419.8, num_updates=5200, lr=0.000196116, gnorm=0.411, clip=0, loss_scale=16, train_wall=84, gb_free=16.8, wall=3936
2023-07-04 15:14:53 | INFO | train_inner | epoch 004:    883 / 1474 loss=2.394, trans_loss=3.683, nll_loss=1.885, w2v_ctc_loss=0.861, task_loss=0.507, contrastive_loss=0, total=4179.58, n_correct=2163.76, ppl=3.69, accuracy=51.77, wps=14644.6, ups=1.17, wpb=12473.5, bsz=464.4, num_updates=5300, lr=0.000194257, gnorm=0.394, clip=0, loss_scale=16, train_wall=85, gb_free=14.6, wall=4021
2023-07-04 15:16:18 | INFO | train_inner | epoch 004:    983 / 1474 loss=2.38, trans_loss=3.675, nll_loss=1.875, w2v_ctc_loss=0.845, task_loss=0.506, contrastive_loss=0, total=4131.6, n_correct=2155.05, ppl=3.67, accuracy=52.16, wps=14509, ups=1.18, wpb=12339, bsz=459.5, num_updates=5400, lr=0.00019245, gnorm=0.394, clip=0, loss_scale=16, train_wall=85, gb_free=15.1, wall=4106
2023-07-04 15:17:42 | INFO | train_inner | epoch 004:   1083 / 1474 loss=2.389, trans_loss=3.684, nll_loss=1.884, w2v_ctc_loss=0.849, task_loss=0.546, contrastive_loss=0, total=4071.42, n_correct=2121.61, ppl=3.69, accuracy=52.11, wps=14362.6, ups=1.18, wpb=12153.3, bsz=434.6, num_updates=5500, lr=0.000190693, gnorm=0.398, clip=0, loss_scale=16, train_wall=84, gb_free=16.4, wall=4191
2023-07-04 15:19:07 | INFO | train_inner | epoch 004:   1183 / 1474 loss=2.379, trans_loss=3.674, nll_loss=1.874, w2v_ctc_loss=0.84, task_loss=0.474, contrastive_loss=0, total=4161.85, n_correct=2185.59, ppl=3.66, accuracy=52.515, wps=14736.1, ups=1.18, wpb=12456.2, bsz=483.8, num_updates=5600, lr=0.000188982, gnorm=0.388, clip=0, loss_scale=16, train_wall=84, gb_free=12.7, wall=4275
2023-07-04 15:20:31 | INFO | train_inner | epoch 004:   1283 / 1474 loss=2.372, trans_loss=3.669, nll_loss=1.867, w2v_ctc_loss=0.831, task_loss=0.485, contrastive_loss=0, total=4152.03, n_correct=2193.03, ppl=3.65, accuracy=52.818, wps=14736, ups=1.19, wpb=12413.9, bsz=471, num_updates=5700, lr=0.000187317, gnorm=0.389, clip=0, loss_scale=16, train_wall=84, gb_free=16.7, wall=4359
2023-07-04 15:21:55 | INFO | train_inner | epoch 004:   1383 / 1474 loss=2.371, trans_loss=3.667, nll_loss=1.864, w2v_ctc_loss=0.832, task_loss=0.521, contrastive_loss=0, total=4099.25, n_correct=2168.61, ppl=3.64, accuracy=52.903, wps=14632.3, ups=1.19, wpb=12246, bsz=436.9, num_updates=5800, lr=0.000185695, gnorm=0.385, clip=0, loss_scale=16, train_wall=83, gb_free=12, wall=4443
2023-07-04 15:23:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.8422, device='cuda:4')
tensor(0.8291, device='cuda:4')
tensor(0.8422, device='cuda:6')
tensor(0.8291, device='cuda:6')
tensor(0.8422, device='cuda:7')
tensor(0.8291, device='cuda:7')
tensor(0.8422, device='cuda:5')
tensor(0.8291, device='cuda:5')
tensor(0.8422, device='cuda:2')
tensor(0.8291, device='cuda:2')
tensor(0.8422, device='cuda:1')
tensor(0.8291, device='cuda:1')
tensor(0.8422, device='cuda:3')
tensor(0.8291, device='cuda:3')
2023-07-04 15:23:41 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 2.307 | trans_loss 5.919 | nll_loss 3.296 | w2v_ctc_loss 0.783 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2251.5 | ppl 9.82 | accuracy 56.24 | uer 22.483 | wer 23.963 | raw_wer 23.963 | bleu 16.54 | wps 1807 | wpb 4003.4 | bsz 141.8 | num_updates 5891 | best_bleu 16.54
2023-07-04 15:23:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5891 updates
2023-07-04 15:23:41 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 15:23:45 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 15:23:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt (epoch 4 @ 5891 updates, score 16.54) (writing took 8.48163495818153 seconds)
2023-07-04 15:23:49 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-07-04 15:23:49 | INFO | train | epoch 004 | loss 2.4 | trans_loss 3.693 | nll_loss 1.896 | w2v_ctc_loss 0.862 | task_loss 0.505 | contrastive_loss 0 | total 4138.65 | n_correct 2129.87 | ppl 3.72 | accuracy 51.463 | wps 14072.8 | ups 1.14 | wpb 12355.8 | bsz 458.5 | num_updates 5891 | lr 0.000184256 | gnorm 0.422 | clip 0 | loss_scale 16 | train_wall 1243 | gb_free 15 | wall 4557
2023-07-04 15:23:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 15:23:49 | INFO | fairseq.trainer | begin training epoch 5
2023-07-04 15:23:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 15:24:05 | INFO | train_inner | epoch 005:      9 / 1474 loss=2.361, trans_loss=3.662, nll_loss=1.857, w2v_ctc_loss=0.82, task_loss=0.53, contrastive_loss=0, total=4035.57, n_correct=2143.04, ppl=3.62, accuracy=53.104, wps=9298.9, ups=0.77, wpb=12056.3, bsz=437.3, num_updates=5900, lr=0.000184115, gnorm=0.392, clip=0, loss_scale=16, train_wall=84, gb_free=16.1, wall=4573
2023-07-04 15:25:30 | INFO | train_inner | epoch 005:    109 / 1474 loss=2.3, trans_loss=3.606, nll_loss=1.785, w2v_ctc_loss=0.768, task_loss=0.452, contrastive_loss=0, total=4249.55, n_correct=2327.05, ppl=3.45, accuracy=54.76, wps=14857.8, ups=1.17, wpb=12691.5, bsz=497, num_updates=6000, lr=0.000182574, gnorm=0.373, clip=0, loss_scale=16, train_wall=85, gb_free=17.7, wall=4658
2023-07-04 15:25:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 15:25:56 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 2.297 | trans_loss 5.911 | nll_loss 3.275 | w2v_ctc_loss 0.76 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2270.5 | ppl 9.68 | accuracy 56.714 | uer 21.899 | wer 23.478 | raw_wer 23.478 | bleu 16.37 | wps 2146.4 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 16.54
2023-07-04 15:25:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-07-04 15:25:56 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_5_6000.pt
2023-07-04 15:25:58 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_5_6000.pt
2023-07-04 15:26:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 16.37) (writing took 6.505792069714516 seconds)
2023-07-04 15:27:26 | INFO | train_inner | epoch 005:    209 / 1474 loss=2.312, trans_loss=3.616, nll_loss=1.796, w2v_ctc_loss=0.78, task_loss=0.465, contrastive_loss=0, total=4195.93, n_correct=2288.88, ppl=3.47, accuracy=54.55, wps=10749.5, ups=0.86, wpb=12507.8, bsz=490.2, num_updates=6100, lr=0.000181071, gnorm=0.378, clip=0, loss_scale=16, train_wall=83, gb_free=16.2, wall=4775
2023-07-04 15:28:50 | INFO | train_inner | epoch 005:    309 / 1474 loss=2.32, trans_loss=3.617, nll_loss=1.8, w2v_ctc_loss=0.79, task_loss=0.515, contrastive_loss=0, total=4092.41, n_correct=2218.91, ppl=3.48, accuracy=54.22, wps=14556, ups=1.19, wpb=12249.4, bsz=445.2, num_updates=6200, lr=0.000179605, gnorm=0.39, clip=0, loss_scale=16, train_wall=84, gb_free=16.2, wall=4859
2023-07-04 15:30:15 | INFO | train_inner | epoch 005:    409 / 1474 loss=2.303, trans_loss=3.608, nll_loss=1.793, w2v_ctc_loss=0.769, task_loss=0.49, contrastive_loss=0, total=4142.04, n_correct=2264.24, ppl=3.47, accuracy=54.665, wps=14593, ups=1.18, wpb=12363.4, bsz=471.4, num_updates=6300, lr=0.000178174, gnorm=0.385, clip=0, loss_scale=16, train_wall=84, gb_free=17.3, wall=4943
2023-07-04 15:31:40 | INFO | train_inner | epoch 005:    509 / 1474 loss=2.315, trans_loss=3.622, nll_loss=1.804, w2v_ctc_loss=0.775, task_loss=0.566, contrastive_loss=0, total=4031.44, n_correct=2191.94, ppl=3.49, accuracy=54.371, wps=14273.9, ups=1.18, wpb=12063.4, bsz=417.2, num_updates=6400, lr=0.000176777, gnorm=0.387, clip=0, loss_scale=16, train_wall=84, gb_free=12.6, wall=5028
2023-07-04 15:33:05 | INFO | train_inner | epoch 005:    609 / 1474 loss=2.306, trans_loss=3.619, nll_loss=1.801, w2v_ctc_loss=0.768, task_loss=0.521, contrastive_loss=0, total=4113.46, n_correct=2241.23, ppl=3.48, accuracy=54.485, wps=14379.4, ups=1.17, wpb=12259.5, bsz=452, num_updates=6500, lr=0.000175412, gnorm=0.39, clip=0, loss_scale=16, train_wall=85, gb_free=17.6, wall=5113
2023-07-04 15:34:30 | INFO | train_inner | epoch 005:    709 / 1474 loss=2.307, trans_loss=3.611, nll_loss=1.794, w2v_ctc_loss=0.774, task_loss=0.483, contrastive_loss=0, total=4167.56, n_correct=2280.08, ppl=3.47, accuracy=54.71, wps=14567.3, ups=1.17, wpb=12429.2, bsz=478.3, num_updates=6600, lr=0.000174078, gnorm=0.381, clip=0, loss_scale=16, train_wall=85, gb_free=12.1, wall=5199
2023-07-04 15:35:56 | INFO | train_inner | epoch 005:    809 / 1474 loss=2.305, trans_loss=3.614, nll_loss=1.796, w2v_ctc_loss=0.766, task_loss=0.517, contrastive_loss=0, total=4135.12, n_correct=2268.55, ppl=3.47, accuracy=54.861, wps=14399.6, ups=1.17, wpb=12344, bsz=451.3, num_updates=6700, lr=0.000172774, gnorm=0.38, clip=0, loss_scale=16, train_wall=85, gb_free=16.5, wall=5284
2023-07-04 15:37:21 | INFO | train_inner | epoch 005:    909 / 1474 loss=2.301, trans_loss=3.613, nll_loss=1.795, w2v_ctc_loss=0.762, task_loss=0.529, contrastive_loss=0, total=4089.65, n_correct=2244.65, ppl=3.47, accuracy=54.886, wps=14467.6, ups=1.18, wpb=12220.6, bsz=442.2, num_updates=6800, lr=0.000171499, gnorm=0.383, clip=0, loss_scale=16, train_wall=84, gb_free=17, wall=5369
2023-07-04 15:38:45 | INFO | train_inner | epoch 005:   1009 / 1474 loss=2.304, trans_loss=3.612, nll_loss=1.796, w2v_ctc_loss=0.766, task_loss=0.497, contrastive_loss=0, total=4164.77, n_correct=2294.59, ppl=3.47, accuracy=55.095, wps=14766.3, ups=1.19, wpb=12424.9, bsz=465.4, num_updates=6900, lr=0.000170251, gnorm=0.378, clip=0, loss_scale=16, train_wall=84, gb_free=17.1, wall=5453
2023-07-04 15:40:10 | INFO | train_inner | epoch 005:   1109 / 1474 loss=2.305, trans_loss=3.614, nll_loss=1.794, w2v_ctc_loss=0.765, task_loss=0.504, contrastive_loss=0, total=4170.22, n_correct=2296.32, ppl=3.47, accuracy=55.065, wps=14571.3, ups=1.17, wpb=12451.3, bsz=464.2, num_updates=7000, lr=0.000169031, gnorm=0.374, clip=0, loss_scale=16, train_wall=85, gb_free=16, wall=5538
2023-07-04 15:41:35 | INFO | train_inner | epoch 005:   1209 / 1474 loss=2.294, trans_loss=3.609, nll_loss=1.789, w2v_ctc_loss=0.754, task_loss=0.514, contrastive_loss=0, total=4173.69, n_correct=2313.95, ppl=3.46, accuracy=55.441, wps=14617.9, ups=1.18, wpb=12438.5, bsz=455.4, num_updates=7100, lr=0.000167836, gnorm=0.377, clip=0, loss_scale=32, train_wall=85, gb_free=16.6, wall=5623
2023-07-04 15:43:00 | INFO | train_inner | epoch 005:   1309 / 1474 loss=2.291, trans_loss=3.608, nll_loss=1.786, w2v_ctc_loss=0.746, task_loss=0.516, contrastive_loss=0, total=4131.5, n_correct=2286.73, ppl=3.45, accuracy=55.349, wps=14506.8, ups=1.17, wpb=12347.9, bsz=444.3, num_updates=7200, lr=0.000166667, gnorm=0.378, clip=0, loss_scale=32, train_wall=85, gb_free=17.8, wall=5709
2023-07-04 15:44:25 | INFO | train_inner | epoch 005:   1409 / 1474 loss=2.288, trans_loss=3.601, nll_loss=1.783, w2v_ctc_loss=0.75, task_loss=0.504, contrastive_loss=0, total=4134.78, n_correct=2289.12, ppl=3.44, accuracy=55.363, wps=14513.4, ups=1.18, wpb=12344.9, bsz=458.6, num_updates=7300, lr=0.000165521, gnorm=0.38, clip=0, loss_scale=32, train_wall=85, gb_free=16.7, wall=5794
2023-07-04 15:45:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 15:45:51 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 2.264 | trans_loss 5.86 | nll_loss 3.226 | w2v_ctc_loss 0.709 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2294.3 | ppl 9.36 | accuracy 57.309 | uer 21.49 | wer 23.008 | raw_wer 23.008 | bleu 16.8 | wps 1579.2 | wpb 4003.4 | bsz 141.8 | num_updates 7365 | best_bleu 16.8
2023-07-04 15:45:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7365 updates
2023-07-04 15:45:51 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 15:45:56 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 15:46:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt (epoch 5 @ 7365 updates, score 16.8) (writing took 8.73095472669229 seconds)
2023-07-04 15:46:00 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-07-04 15:46:00 | INFO | train | epoch 005 | loss 2.303 | trans_loss 3.612 | nll_loss 1.793 | w2v_ctc_loss 0.766 | task_loss 0.505 | contrastive_loss 0 | total 4138.65 | n_correct 2271.02 | ppl 3.47 | accuracy 54.873 | wps 13683.7 | ups 1.11 | wpb 12355.8 | bsz 458.5 | num_updates 7365 | lr 0.000164789 | gnorm 0.382 | clip 0 | loss_scale 32 | train_wall 1245 | gb_free 16.4 | wall 5888
2023-07-04 15:46:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 15:46:00 | INFO | fairseq.trainer | begin training epoch 6
2023-07-04 15:46:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 15:46:38 | INFO | train_inner | epoch 006:     35 / 1474 loss=2.275, trans_loss=3.584, nll_loss=1.758, w2v_ctc_loss=0.739, task_loss=0.514, contrastive_loss=0, total=4118.2, n_correct=2309.08, ppl=3.38, accuracy=56.07, wps=9252.6, ups=0.75, wpb=12283.7, bsz=449.9, num_updates=7400, lr=0.000164399, gnorm=0.389, clip=0, loss_scale=32, train_wall=85, gb_free=15.9, wall=5926
2023-07-04 15:48:03 | INFO | train_inner | epoch 006:    135 / 1474 loss=2.242, trans_loss=3.561, nll_loss=1.728, w2v_ctc_loss=0.707, task_loss=0.503, contrastive_loss=0, total=4151.34, n_correct=2351.49, ppl=3.31, accuracy=56.644, wps=14632.8, ups=1.18, wpb=12403.4, bsz=455.9, num_updates=7500, lr=0.000163299, gnorm=0.377, clip=0, loss_scale=32, train_wall=84, gb_free=11.8, wall=6011
2023-07-04 15:49:28 | INFO | train_inner | epoch 006:    235 / 1474 loss=2.26, trans_loss=3.569, nll_loss=1.741, w2v_ctc_loss=0.73, task_loss=0.541, contrastive_loss=0, total=4116.84, n_correct=2308.85, ppl=3.34, accuracy=56.083, wps=14528.1, ups=1.18, wpb=12293.5, bsz=437.8, num_updates=7600, lr=0.000162221, gnorm=0.381, clip=0, loss_scale=32, train_wall=84, gb_free=16.7, wall=6096
2023-07-04 15:50:53 | INFO | train_inner | epoch 006:    335 / 1474 loss=2.24, trans_loss=3.559, nll_loss=1.728, w2v_ctc_loss=0.706, task_loss=0.488, contrastive_loss=0, total=4142.94, n_correct=2347.53, ppl=3.31, accuracy=56.663, wps=14431.7, ups=1.17, wpb=12367.6, bsz=474.2, num_updates=7700, lr=0.000161165, gnorm=0.374, clip=0, loss_scale=32, train_wall=85, gb_free=15.1, wall=6182
2023-07-04 15:52:18 | INFO | train_inner | epoch 006:    435 / 1474 loss=2.241, trans_loss=3.56, nll_loss=1.73, w2v_ctc_loss=0.705, task_loss=0.465, contrastive_loss=0, total=4187.43, n_correct=2374.24, ppl=3.32, accuracy=56.699, wps=14807.3, ups=1.18, wpb=12500.6, bsz=487.7, num_updates=7800, lr=0.000160128, gnorm=0.376, clip=0, loss_scale=32, train_wall=84, gb_free=12.7, wall=6266
2023-07-04 15:52:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-04 15:53:44 | INFO | train_inner | epoch 006:    536 / 1474 loss=2.249, trans_loss=3.565, nll_loss=1.736, w2v_ctc_loss=0.715, task_loss=0.508, contrastive_loss=0, total=4170.05, n_correct=2362.25, ppl=3.33, accuracy=56.648, wps=14456.5, ups=1.16, wpb=12422.4, bsz=455, num_updates=7900, lr=0.000159111, gnorm=0.375, clip=0, loss_scale=16, train_wall=86, gb_free=15.9, wall=6352
2023-07-04 15:55:08 | INFO | train_inner | epoch 006:    636 / 1474 loss=2.24, trans_loss=3.565, nll_loss=1.733, w2v_ctc_loss=0.702, task_loss=0.478, contrastive_loss=0, total=4146.17, n_correct=2348.71, ppl=3.32, accuracy=56.648, wps=14621.5, ups=1.18, wpb=12395.5, bsz=471.6, num_updates=8000, lr=0.000158114, gnorm=0.37, clip=0, loss_scale=16, train_wall=84, gb_free=16.7, wall=6437
2023-07-04 15:55:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 15:55:38 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 2.244 | trans_loss 5.802 | nll_loss 3.142 | w2v_ctc_loss 0.709 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2330.2 | ppl 8.83 | accuracy 58.206 | uer 20.046 | wer 21.602 | raw_wer 21.602 | bleu 17.47 | wps 1786 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 17.47
2023-07-04 15:55:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-07-04 15:55:38 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_6_8000.pt
2023-07-04 15:55:40 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_6_8000.pt
2023-07-04 15:55:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 17.47) (writing took 10.03044353518635 seconds)
2023-07-04 15:57:13 | INFO | train_inner | epoch 006:    736 / 1474 loss=2.252, trans_loss=3.568, nll_loss=1.74, w2v_ctc_loss=0.718, task_loss=0.513, contrastive_loss=0, total=4148.65, n_correct=2347.76, ppl=3.34, accuracy=56.591, wps=9934.9, ups=0.8, wpb=12378.4, bsz=453.7, num_updates=8100, lr=0.000157135, gnorm=0.378, clip=0, loss_scale=16, train_wall=85, gb_free=15.8, wall=6561
2023-07-04 15:58:38 | INFO | train_inner | epoch 006:    836 / 1474 loss=2.25, trans_loss=3.573, nll_loss=1.744, w2v_ctc_loss=0.709, task_loss=0.531, contrastive_loss=0, total=4114.34, n_correct=2320.08, ppl=3.35, accuracy=56.39, wps=14476.6, ups=1.18, wpb=12292.5, bsz=441.6, num_updates=8200, lr=0.000156174, gnorm=0.379, clip=0, loss_scale=16, train_wall=85, gb_free=15.3, wall=6646
2023-07-04 16:00:03 | INFO | train_inner | epoch 006:    936 / 1474 loss=2.251, trans_loss=3.571, nll_loss=1.744, w2v_ctc_loss=0.715, task_loss=0.526, contrastive_loss=0, total=4081.53, n_correct=2304.5, ppl=3.35, accuracy=56.462, wps=14364.2, ups=1.18, wpb=12166.1, bsz=444.5, num_updates=8300, lr=0.00015523, gnorm=0.381, clip=0, loss_scale=16, train_wall=84, gb_free=17.9, wall=6731
2023-07-04 16:01:27 | INFO | train_inner | epoch 006:   1036 / 1474 loss=2.244, trans_loss=3.565, nll_loss=1.736, w2v_ctc_loss=0.706, task_loss=0.48, contrastive_loss=0, total=4165.84, n_correct=2366.99, ppl=3.33, accuracy=56.819, wps=14761.2, ups=1.19, wpb=12437.3, bsz=477.2, num_updates=8400, lr=0.000154303, gnorm=0.381, clip=0, loss_scale=16, train_wall=84, gb_free=17, wall=6815
2023-07-04 16:02:51 | INFO | train_inner | epoch 006:   1136 / 1474 loss=2.251, trans_loss=3.573, nll_loss=1.744, w2v_ctc_loss=0.71, task_loss=0.561, contrastive_loss=0, total=4072.29, n_correct=2304.7, ppl=3.35, accuracy=56.595, wps=14448.8, ups=1.19, wpb=12165.1, bsz=428, num_updates=8500, lr=0.000153393, gnorm=0.379, clip=0, loss_scale=16, train_wall=84, gb_free=17.1, wall=6899
2023-07-04 16:04:16 | INFO | train_inner | epoch 006:   1236 / 1474 loss=2.239, trans_loss=3.563, nll_loss=1.734, w2v_ctc_loss=0.698, task_loss=0.489, contrastive_loss=0, total=4141.55, n_correct=2357.27, ppl=3.33, accuracy=56.918, wps=14533.8, ups=1.17, wpb=12385.8, bsz=474.8, num_updates=8600, lr=0.000152499, gnorm=0.372, clip=0, loss_scale=16, train_wall=85, gb_free=13.5, wall=6985
2023-07-04 16:05:41 | INFO | train_inner | epoch 006:   1336 / 1474 loss=2.242, trans_loss=3.57, nll_loss=1.739, w2v_ctc_loss=0.698, task_loss=0.504, contrastive_loss=0, total=4125.31, n_correct=2353.99, ppl=3.34, accuracy=57.062, wps=14593.9, ups=1.18, wpb=12316, bsz=452.6, num_updates=8700, lr=0.00015162, gnorm=0.375, clip=0, loss_scale=16, train_wall=84, gb_free=17.8, wall=7069
2023-07-04 16:07:06 | INFO | train_inner | epoch 006:   1436 / 1474 loss=2.241, trans_loss=3.56, nll_loss=1.73, w2v_ctc_loss=0.704, task_loss=0.504, contrastive_loss=0, total=4196.2, n_correct=2400.88, ppl=3.32, accuracy=57.216, wps=14620.5, ups=1.17, wpb=12515.5, bsz=461.5, num_updates=8800, lr=0.000150756, gnorm=0.369, clip=0, loss_scale=16, train_wall=85, gb_free=11.8, wall=7155
2023-07-04 16:07:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 16:08:04 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 2.228 | trans_loss 5.769 | nll_loss 3.09 | w2v_ctc_loss 0.698 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2351.4 | ppl 8.51 | accuracy 58.735 | uer 19.369 | wer 21.032 | raw_wer 21.032 | bleu 17.86 | wps 2044.9 | wpb 4003.4 | bsz 141.8 | num_updates 8838 | best_bleu 17.86
2023-07-04 16:08:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8838 updates
2023-07-04 16:08:04 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 16:08:08 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 16:08:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt (epoch 6 @ 8838 updates, score 17.86) (writing took 8.856216973159462 seconds)
2023-07-04 16:08:13 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-07-04 16:08:13 | INFO | train | epoch 006 | loss 2.245 | trans_loss 3.565 | nll_loss 1.735 | w2v_ctc_loss 0.708 | task_loss 0.505 | contrastive_loss 0 | total 4138.88 | n_correct 2346.75 | ppl 3.33 | accuracy 56.7 | wps 13659.3 | ups 1.11 | wpb 12356.5 | bsz 458.6 | num_updates 8838 | lr 0.000150431 | gnorm 0.376 | clip 0 | loss_scale 16 | train_wall 1244 | gb_free 15.3 | wall 7221
2023-07-04 16:08:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 16:08:13 | INFO | fairseq.trainer | begin training epoch 7
2023-07-04 16:08:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 16:09:14 | INFO | train_inner | epoch 007:     62 / 1474 loss=2.213, trans_loss=3.536, nll_loss=1.699, w2v_ctc_loss=0.679, task_loss=0.491, contrastive_loss=0, total=4108.19, n_correct=2370.72, ppl=3.25, accuracy=57.707, wps=9631.1, ups=0.78, wpb=12269.7, bsz=461.9, num_updates=8900, lr=0.000149906, gnorm=0.37, clip=0, loss_scale=16, train_wall=84, gb_free=17.2, wall=7282
2023-07-04 16:10:38 | INFO | train_inner | epoch 007:    162 / 1474 loss=2.202, trans_loss=3.529, nll_loss=1.689, w2v_ctc_loss=0.668, task_loss=0.512, contrastive_loss=0, total=4106.05, n_correct=2377.7, ppl=3.22, accuracy=57.907, wps=14536.6, ups=1.19, wpb=12254.3, bsz=455.4, num_updates=9000, lr=0.000149071, gnorm=0.377, clip=0, loss_scale=16, train_wall=84, gb_free=16.9, wall=7366
2023-07-04 16:12:02 | INFO | train_inner | epoch 007:    262 / 1474 loss=2.202, trans_loss=3.527, nll_loss=1.685, w2v_ctc_loss=0.671, task_loss=0.511, contrastive_loss=0, total=4129.3, n_correct=2395.49, ppl=3.21, accuracy=58.012, wps=14597.8, ups=1.18, wpb=12322.9, bsz=451.8, num_updates=9100, lr=0.00014825, gnorm=0.372, clip=0, loss_scale=16, train_wall=84, gb_free=17.4, wall=7451
2023-07-04 16:13:28 | INFO | train_inner | epoch 007:    362 / 1474 loss=2.2, trans_loss=3.532, nll_loss=1.693, w2v_ctc_loss=0.666, task_loss=0.486, contrastive_loss=0, total=4201.67, n_correct=2427.93, ppl=3.23, accuracy=57.785, wps=14661.2, ups=1.17, wpb=12533.1, bsz=479.7, num_updates=9200, lr=0.000147442, gnorm=0.371, clip=0, loss_scale=16, train_wall=85, gb_free=15.6, wall=7536
2023-07-04 16:14:53 | INFO | train_inner | epoch 007:    462 / 1474 loss=2.203, trans_loss=3.532, nll_loss=1.696, w2v_ctc_loss=0.669, task_loss=0.496, contrastive_loss=0, total=4155.31, n_correct=2396.32, ppl=3.24, accuracy=57.669, wps=14654.8, ups=1.18, wpb=12394.6, bsz=465.5, num_updates=9300, lr=0.000146647, gnorm=0.373, clip=0, loss_scale=16, train_wall=84, gb_free=16.9, wall=7621
2023-07-04 16:16:17 | INFO | train_inner | epoch 007:    562 / 1474 loss=2.206, trans_loss=3.532, nll_loss=1.694, w2v_ctc_loss=0.672, task_loss=0.494, contrastive_loss=0, total=4165.88, n_correct=2417.52, ppl=3.24, accuracy=58.031, wps=14670.9, ups=1.18, wpb=12401.8, bsz=459, num_updates=9400, lr=0.000145865, gnorm=0.374, clip=0, loss_scale=16, train_wall=84, gb_free=17.3, wall=7705
2023-07-04 16:17:42 | INFO | train_inner | epoch 007:    662 / 1474 loss=2.2, trans_loss=3.535, nll_loss=1.694, w2v_ctc_loss=0.661, task_loss=0.508, contrastive_loss=0, total=4149.29, n_correct=2409.83, ppl=3.23, accuracy=58.078, wps=14635.6, ups=1.18, wpb=12393.1, bsz=451.6, num_updates=9500, lr=0.000145095, gnorm=0.368, clip=0, loss_scale=16, train_wall=84, gb_free=17.2, wall=7790
2023-07-04 16:19:07 | INFO | train_inner | epoch 007:    762 / 1474 loss=2.207, trans_loss=3.533, nll_loss=1.694, w2v_ctc_loss=0.67, task_loss=0.525, contrastive_loss=0, total=4134.54, n_correct=2397.46, ppl=3.24, accuracy=57.986, wps=14506.3, ups=1.17, wpb=12358.8, bsz=449.8, num_updates=9600, lr=0.000144338, gnorm=0.374, clip=0, loss_scale=16, train_wall=85, gb_free=14.1, wall=7875
2023-07-04 16:20:32 | INFO | train_inner | epoch 007:    862 / 1474 loss=2.203, trans_loss=3.532, nll_loss=1.692, w2v_ctc_loss=0.665, task_loss=0.51, contrastive_loss=0, total=4151.77, n_correct=2412.58, ppl=3.23, accuracy=58.11, wps=14574.9, ups=1.17, wpb=12405.1, bsz=461.9, num_updates=9700, lr=0.000143592, gnorm=0.376, clip=0, loss_scale=16, train_wall=85, gb_free=15.1, wall=7960
2023-07-04 16:21:57 | INFO | train_inner | epoch 007:    962 / 1474 loss=2.201, trans_loss=3.532, nll_loss=1.695, w2v_ctc_loss=0.663, task_loss=0.485, contrastive_loss=0, total=4124.8, n_correct=2399, ppl=3.24, accuracy=58.16, wps=14520.7, ups=1.18, wpb=12316.5, bsz=471.2, num_updates=9800, lr=0.000142857, gnorm=0.374, clip=0, loss_scale=16, train_wall=84, gb_free=16.9, wall=8045
2023-07-04 16:23:22 | INFO | train_inner | epoch 007:   1062 / 1474 loss=2.21, trans_loss=3.541, nll_loss=1.704, w2v_ctc_loss=0.669, task_loss=0.527, contrastive_loss=0, total=4113.08, n_correct=2381.57, ppl=3.26, accuracy=57.902, wps=14526.6, ups=1.18, wpb=12291.6, bsz=439.4, num_updates=9900, lr=0.000142134, gnorm=0.375, clip=0, loss_scale=32, train_wall=84, gb_free=15, wall=8130
2023-07-04 16:24:47 | INFO | train_inner | epoch 007:   1162 / 1474 loss=2.202, trans_loss=3.53, nll_loss=1.697, w2v_ctc_loss=0.666, task_loss=0.488, contrastive_loss=0, total=4134.15, n_correct=2393.5, ppl=3.24, accuracy=57.896, wps=14519.3, ups=1.18, wpb=12340.8, bsz=470.3, num_updates=10000, lr=0.000141421, gnorm=0.375, clip=0, loss_scale=32, train_wall=85, gb_free=16.2, wall=8215
2023-07-04 16:24:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 16:25:12 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 2.21 | trans_loss 5.726 | nll_loss 3.04 | w2v_ctc_loss 0.688 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2380.2 | ppl 8.23 | accuracy 59.454 | uer 18.488 | wer 20.264 | raw_wer 20.264 | bleu 18.45 | wps 2082.9 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 18.45
2023-07-04 16:25:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-07-04 16:25:12 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_7_10000.pt
2023-07-04 16:25:14 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_7_10000.pt
2023-07-04 16:25:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 18.45) (writing took 9.980104754678905 seconds)
tensor(0.5919, device='cuda:0')
tensor(0.5050, device='cuda:0')
2023-07-04 16:26:47 | INFO | train_inner | epoch 007:   1262 / 1474 loss=2.197, trans_loss=3.527, nll_loss=1.689, w2v_ctc_loss=0.659, task_loss=0.511, contrastive_loss=0, total=4133.98, n_correct=2411.38, ppl=3.22, accuracy=58.331, wps=10237.6, ups=0.83, wpb=12339.4, bsz=450.9, num_updates=10100, lr=0.00014072, gnorm=0.284, clip=0, loss_scale=32, train_wall=85, gb_free=16.9, wall=8335
2023-07-04 16:28:11 | INFO | train_inner | epoch 007:   1362 / 1474 loss=2.2, trans_loss=3.524, nll_loss=1.687, w2v_ctc_loss=0.665, task_loss=0.474, contrastive_loss=0, total=4171.46, n_correct=2437.53, ppl=3.22, accuracy=58.433, wps=14745.9, ups=1.18, wpb=12447.6, bsz=475.5, num_updates=10200, lr=0.000140028, gnorm=0.283, clip=0, loss_scale=32, train_wall=84, gb_free=17.8, wall=8420
2023-07-04 16:29:38 | INFO | train_inner | epoch 007:   1462 / 1474 loss=2.205, trans_loss=3.536, nll_loss=1.703, w2v_ctc_loss=0.665, task_loss=0.543, contrastive_loss=0, total=4106.94, n_correct=2382.51, ppl=3.25, accuracy=58.012, wps=14242.9, ups=1.16, wpb=12278.7, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.288, clip=0, loss_scale=32, train_wall=86, gb_free=15.8, wall=8506
2023-07-04 16:29:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.5919, device='cuda:6')
tensor(0.5050, device='cuda:6')
tensor(0.5919, device='cuda:7')
tensor(0.5050, device='cuda:7')
tensor(0.5919, device='cuda:4')
tensor(0.5050, device='cuda:4')
tensor(0.5919, device='cuda:5')
tensor(0.5050, device='cuda:5')
tensor(0.5919, device='cuda:3')
tensor(0.5050, device='cuda:3')
tensor(0.5919, device='cuda:2')
tensor(0.5050, device='cuda:2')
tensor(0.5919, device='cuda:1')
tensor(0.5050, device='cuda:1')
2023-07-04 16:30:16 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 2.208 | trans_loss 5.723 | nll_loss 3.04 | w2v_ctc_loss 0.682 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2375.5 | ppl 8.22 | accuracy 59.337 | uer 18.772 | wer 20.48 | raw_wer 20.48 | bleu 18.41 | wps 1908.4 | wpb 4003.4 | bsz 141.8 | num_updates 10312 | best_bleu 18.45
2023-07-04 16:30:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10312 updates
2023-07-04 16:30:16 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_18.4107.pt
2023-07-04 16:30:18 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_18.4107.pt
2023-07-04 16:30:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_18.4107.pt (epoch 7 @ 10312 updates, score 18.41) (writing took 5.538059557322413 seconds)
2023-07-04 16:30:21 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-07-04 16:30:21 | INFO | train | epoch 007 | loss 2.203 | trans_loss 3.531 | nll_loss 1.693 | w2v_ctc_loss 0.666 | task_loss 0.505 | contrastive_loss 0 | total 4138.65 | n_correct 2401.15 | ppl 3.23 | accuracy 58.018 | wps 13707.9 | ups 1.11 | wpb 12355.8 | bsz 458.5 | num_updates 10312 | lr 0.000139266 | gnorm 0.355 | clip 0 | loss_scale 32 | train_wall 1245 | gb_free 13.5 | wall 8549
2023-07-04 16:30:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 16:30:21 | INFO | fairseq.trainer | begin training epoch 8
2023-07-04 16:30:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 16:31:45 | INFO | train_inner | epoch 008:     88 / 1474 loss=2.171, trans_loss=3.506, nll_loss=1.658, w2v_ctc_loss=0.637, task_loss=0.533, contrastive_loss=0, total=4120.74, n_correct=2425.01, ppl=3.16, accuracy=58.849, wps=9683, ups=0.79, wpb=12280.5, bsz=444.5, num_updates=10400, lr=0.000138675, gnorm=0.284, clip=0, loss_scale=32, train_wall=84, gb_free=17.3, wall=8633
2023-07-04 16:33:09 | INFO | train_inner | epoch 008:    188 / 1474 loss=2.174, trans_loss=3.509, nll_loss=1.662, w2v_ctc_loss=0.638, task_loss=0.554, contrastive_loss=0, total=4028.45, n_correct=2375.01, ppl=3.16, accuracy=58.956, wps=14253.1, ups=1.19, wpb=12007.6, bsz=426.7, num_updates=10500, lr=0.000138013, gnorm=0.287, clip=0, loss_scale=32, train_wall=84, gb_free=16.6, wall=8717
2023-07-04 16:34:33 | INFO | train_inner | epoch 008:    288 / 1474 loss=2.165, trans_loss=3.499, nll_loss=1.649, w2v_ctc_loss=0.631, task_loss=0.472, contrastive_loss=0, total=4212.3, n_correct=2494.4, ppl=3.14, accuracy=59.217, wps=14944.7, ups=1.19, wpb=12585.6, bsz=489.5, num_updates=10600, lr=0.000137361, gnorm=0.28, clip=0, loss_scale=32, train_wall=84, gb_free=16.9, wall=8801
2023-07-04 16:35:59 | INFO | train_inner | epoch 008:    388 / 1474 loss=2.179, trans_loss=3.508, nll_loss=1.661, w2v_ctc_loss=0.648, task_loss=0.538, contrastive_loss=0, total=4124.65, n_correct=2426.4, ppl=3.16, accuracy=58.827, wps=14359.5, ups=1.17, wpb=12311.8, bsz=439.9, num_updates=10700, lr=0.000136717, gnorm=0.287, clip=0, loss_scale=32, train_wall=85, gb_free=16.6, wall=8887
2023-07-04 16:37:25 | INFO | train_inner | epoch 008:    488 / 1474 loss=2.169, trans_loss=3.506, nll_loss=1.66, w2v_ctc_loss=0.634, task_loss=0.452, contrastive_loss=0, total=4205.7, n_correct=2482.75, ppl=3.16, accuracy=59.033, wps=14651.5, ups=1.17, wpb=12568.6, bsz=505.9, num_updates=10800, lr=0.000136083, gnorm=0.284, clip=0, loss_scale=32, train_wall=85, gb_free=16.6, wall=8973
2023-07-04 16:38:49 | INFO | train_inner | epoch 008:    588 / 1474 loss=2.176, trans_loss=3.506, nll_loss=1.661, w2v_ctc_loss=0.64, task_loss=0.546, contrastive_loss=0, total=4063.27, n_correct=2390.52, ppl=3.16, accuracy=58.832, wps=14336.6, ups=1.18, wpb=12176.4, bsz=428.8, num_updates=10900, lr=0.000135457, gnorm=0.287, clip=0, loss_scale=32, train_wall=84, gb_free=16.6, wall=9058
2023-07-04 16:40:15 | INFO | train_inner | epoch 008:    688 / 1474 loss=2.177, trans_loss=3.503, nll_loss=1.658, w2v_ctc_loss=0.646, task_loss=0.525, contrastive_loss=0, total=4140.15, n_correct=2449.64, ppl=3.16, accuracy=59.168, wps=14455.2, ups=1.17, wpb=12340.7, bsz=447.4, num_updates=11000, lr=0.00013484, gnorm=0.283, clip=0, loss_scale=32, train_wall=85, gb_free=16.9, wall=9143
2023-07-04 16:41:39 | INFO | train_inner | epoch 008:    788 / 1474 loss=2.17, trans_loss=3.5, nll_loss=1.656, w2v_ctc_loss=0.637, task_loss=0.516, contrastive_loss=0, total=4121.11, n_correct=2435.18, ppl=3.15, accuracy=59.09, wps=14607.1, ups=1.18, wpb=12332.7, bsz=446.8, num_updates=11100, lr=0.000134231, gnorm=0.285, clip=0, loss_scale=32, train_wall=84, gb_free=17.5, wall=9228
2023-07-04 16:43:04 | INFO | train_inner | epoch 008:    888 / 1474 loss=2.168, trans_loss=3.502, nll_loss=1.658, w2v_ctc_loss=0.632, task_loss=0.488, contrastive_loss=0, total=4158.35, n_correct=2464.54, ppl=3.16, accuracy=59.267, wps=14638, ups=1.18, wpb=12422.7, bsz=470.3, num_updates=11200, lr=0.000133631, gnorm=0.283, clip=0, loss_scale=32, train_wall=84, gb_free=16.9, wall=9312
2023-07-04 16:44:28 | INFO | train_inner | epoch 008:    988 / 1474 loss=2.163, trans_loss=3.497, nll_loss=1.652, w2v_ctc_loss=0.627, task_loss=0.472, contrastive_loss=0, total=4170.95, n_correct=2476.38, ppl=3.14, accuracy=59.372, wps=14795.4, ups=1.19, wpb=12447.1, bsz=470.7, num_updates=11300, lr=0.000133038, gnorm=0.281, clip=0, loss_scale=32, train_wall=84, gb_free=16, wall=9397
2023-07-04 16:45:54 | INFO | train_inner | epoch 008:   1088 / 1474 loss=2.169, trans_loss=3.504, nll_loss=1.661, w2v_ctc_loss=0.634, task_loss=0.506, contrastive_loss=0, total=4194.19, n_correct=2475.31, ppl=3.16, accuracy=59.018, wps=14583.6, ups=1.17, wpb=12504.4, bsz=464.3, num_updates=11400, lr=0.000132453, gnorm=0.28, clip=0, loss_scale=32, train_wall=85, gb_free=17.3, wall=9482
2023-07-04 16:47:19 | INFO | train_inner | epoch 008:   1188 / 1474 loss=2.17, trans_loss=3.504, nll_loss=1.662, w2v_ctc_loss=0.634, task_loss=0.48, contrastive_loss=0, total=4165.68, n_correct=2464.86, ppl=3.16, accuracy=59.171, wps=14566.3, ups=1.17, wpb=12444.3, bsz=467.9, num_updates=11500, lr=0.000131876, gnorm=0.283, clip=0, loss_scale=32, train_wall=85, gb_free=17.6, wall=9568
2023-07-04 16:48:43 | INFO | train_inner | epoch 008:   1288 / 1474 loss=2.173, trans_loss=3.503, nll_loss=1.66, w2v_ctc_loss=0.64, task_loss=0.518, contrastive_loss=0, total=4079.12, n_correct=2410.42, ppl=3.16, accuracy=59.092, wps=14507.9, ups=1.19, wpb=12185.3, bsz=444, num_updates=11600, lr=0.000131306, gnorm=0.282, clip=0, loss_scale=32, train_wall=84, gb_free=15.8, wall=9652
2023-07-04 16:50:08 | INFO | train_inner | epoch 008:   1388 / 1474 loss=2.173, trans_loss=3.505, nll_loss=1.665, w2v_ctc_loss=0.637, task_loss=0.502, contrastive_loss=0, total=4136.76, n_correct=2447.1, ppl=3.17, accuracy=59.155, wps=14670.1, ups=1.19, wpb=12338, bsz=459.3, num_updates=11700, lr=0.000130744, gnorm=0.281, clip=0, loss_scale=32, train_wall=84, gb_free=16.1, wall=9736
2023-07-04 16:51:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 16:51:46 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 2.198 | trans_loss 5.693 | nll_loss 2.996 | w2v_ctc_loss 0.686 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2401.4 | ppl 7.98 | accuracy 59.984 | uer 18.257 | wer 19.984 | raw_wer 19.984 | bleu 18.47 | wps 1943 | wpb 4003.4 | bsz 141.8 | num_updates 11786 | best_bleu 18.47
2023-07-04 16:51:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11786 updates
2023-07-04 16:51:46 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 16:51:51 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 16:51:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt (epoch 8 @ 11786 updates, score 18.47) (writing took 8.879002640023828 seconds)
2023-07-04 16:51:55 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-07-04 16:51:55 | INFO | train | epoch 008 | loss 2.171 | trans_loss 3.504 | nll_loss 1.659 | w2v_ctc_loss 0.636 | task_loss 0.505 | contrastive_loss 0 | total 4138.65 | n_correct 2445.74 | ppl 3.16 | accuracy 59.095 | wps 14071.4 | ups 1.14 | wpb 12355.8 | bsz 458.5 | num_updates 11786 | lr 0.000130266 | gnorm 0.283 | clip 0 | loss_scale 32 | train_wall 1244 | gb_free 17.1 | wall 9844
2023-07-04 16:51:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 16:51:56 | INFO | fairseq.trainer | begin training epoch 9
2023-07-04 16:51:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 16:52:16 | INFO | train_inner | epoch 009:     14 / 1474 loss=2.161, trans_loss=3.501, nll_loss=1.657, w2v_ctc_loss=0.624, task_loss=0.494, contrastive_loss=0, total=4126.64, n_correct=2451.91, ppl=3.15, accuracy=59.417, wps=9567.9, ups=0.78, wpb=12295.4, bsz=468.3, num_updates=11800, lr=0.000130189, gnorm=0.281, clip=0, loss_scale=32, train_wall=84, gb_free=17.5, wall=9864
2023-07-04 16:53:41 | INFO | train_inner | epoch 009:    114 / 1474 loss=2.136, trans_loss=3.473, nll_loss=1.618, w2v_ctc_loss=0.604, task_loss=0.474, contrastive_loss=0, total=4190.32, n_correct=2529.52, ppl=3.07, accuracy=60.366, wps=14782.4, ups=1.18, wpb=12520.6, bsz=478.7, num_updates=11900, lr=0.000129641, gnorm=0.278, clip=0, loss_scale=32, train_wall=84, gb_free=16.6, wall=9949
2023-07-04 16:55:06 | INFO | train_inner | epoch 009:    214 / 1474 loss=2.141, trans_loss=3.48, nll_loss=1.628, w2v_ctc_loss=0.606, task_loss=0.539, contrastive_loss=0, total=4071.85, n_correct=2442.45, ppl=3.09, accuracy=59.984, wps=14288.6, ups=1.17, wpb=12162.7, bsz=435.4, num_updates=12000, lr=0.000129099, gnorm=0.282, clip=0, loss_scale=64, train_wall=85, gb_free=16.7, wall=10034
2023-07-04 16:55:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 16:55:31 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 2.194 | trans_loss 5.691 | nll_loss 2.992 | w2v_ctc_loss 0.675 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2401.7 | ppl 7.95 | accuracy 59.992 | uer 18.013 | wer 19.831 | raw_wer 19.831 | bleu 18.77 | wps 2168.1 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 18.77
2023-07-04 16:55:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-07-04 16:55:31 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_9_12000.pt
2023-07-04 16:55:33 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_9_12000.pt
2023-07-04 16:55:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.77) (writing took 11.370980761945248 seconds)
2023-07-04 16:57:07 | INFO | train_inner | epoch 009:    314 / 1474 loss=2.132, trans_loss=3.469, nll_loss=1.615, w2v_ctc_loss=0.599, task_loss=0.472, contrastive_loss=0, total=4145.76, n_correct=2505.56, ppl=3.06, accuracy=60.437, wps=10262.6, ups=0.83, wpb=12408.2, bsz=475.4, num_updates=12100, lr=0.000128565, gnorm=0.28, clip=0, loss_scale=64, train_wall=84, gb_free=16.8, wall=10155
2023-07-04 16:58:33 | INFO | train_inner | epoch 009:    414 / 1474 loss=2.141, trans_loss=3.477, nll_loss=1.627, w2v_ctc_loss=0.608, task_loss=0.496, contrastive_loss=0, total=4204.03, n_correct=2518.69, ppl=3.09, accuracy=59.911, wps=14497.6, ups=1.16, wpb=12540.5, bsz=469.6, num_updates=12200, lr=0.000128037, gnorm=0.282, clip=0, loss_scale=64, train_wall=86, gb_free=16.3, wall=10242
2023-07-04 16:59:58 | INFO | train_inner | epoch 009:    514 / 1474 loss=2.153, trans_loss=3.487, nll_loss=1.638, w2v_ctc_loss=0.621, task_loss=0.526, contrastive_loss=0, total=4116.9, n_correct=2461.86, ppl=3.11, accuracy=59.799, wps=14534.9, ups=1.18, wpb=12271.3, bsz=438.4, num_updates=12300, lr=0.000127515, gnorm=0.285, clip=0, loss_scale=64, train_wall=84, gb_free=15.5, wall=10326
2023-07-04 17:01:23 | INFO | train_inner | epoch 009:    614 / 1474 loss=2.141, trans_loss=3.477, nll_loss=1.627, w2v_ctc_loss=0.607, task_loss=0.517, contrastive_loss=0, total=4124.71, n_correct=2476.27, ppl=3.09, accuracy=60.035, wps=14475.3, ups=1.17, wpb=12338.4, bsz=452.6, num_updates=12400, lr=0.000127, gnorm=0.283, clip=0, loss_scale=64, train_wall=85, gb_free=17.4, wall=10411
2023-07-04 17:02:47 | INFO | train_inner | epoch 009:    714 / 1474 loss=2.152, trans_loss=3.485, nll_loss=1.636, w2v_ctc_loss=0.618, task_loss=0.519, contrastive_loss=0, total=4077.28, n_correct=2437.98, ppl=3.11, accuracy=59.794, wps=14519, ups=1.19, wpb=12196.1, bsz=448.7, num_updates=12500, lr=0.000126491, gnorm=0.287, clip=0, loss_scale=64, train_wall=84, gb_free=17.2, wall=10495
2023-07-04 17:04:13 | INFO | train_inner | epoch 009:    814 / 1474 loss=2.145, trans_loss=3.473, nll_loss=1.625, w2v_ctc_loss=0.617, task_loss=0.452, contrastive_loss=0, total=4233.18, n_correct=2538.04, ppl=3.09, accuracy=59.956, wps=14777.5, ups=1.17, wpb=12635.6, bsz=504.7, num_updates=12600, lr=0.000125988, gnorm=0.282, clip=0, loss_scale=64, train_wall=85, gb_free=15.4, wall=10581
2023-07-04 17:05:39 | INFO | train_inner | epoch 009:    914 / 1474 loss=2.144, trans_loss=3.483, nll_loss=1.633, w2v_ctc_loss=0.611, task_loss=0.522, contrastive_loss=0, total=4136.02, n_correct=2477.09, ppl=3.1, accuracy=59.891, wps=14337, ups=1.16, wpb=12326.4, bsz=448.1, num_updates=12700, lr=0.000125491, gnorm=0.28, clip=0, loss_scale=64, train_wall=86, gb_free=13.4, wall=10667
2023-07-04 17:07:04 | INFO | train_inner | epoch 009:   1014 / 1474 loss=2.151, trans_loss=3.491, nll_loss=1.641, w2v_ctc_loss=0.613, task_loss=0.561, contrastive_loss=0, total=4101.79, n_correct=2451.3, ppl=3.12, accuracy=59.762, wps=14376.4, ups=1.17, wpb=12246.4, bsz=425.5, num_updates=12800, lr=0.000125, gnorm=0.284, clip=0, loss_scale=64, train_wall=85, gb_free=16.7, wall=10752
2023-07-04 17:08:29 | INFO | train_inner | epoch 009:   1114 / 1474 loss=2.146, trans_loss=3.482, nll_loss=1.631, w2v_ctc_loss=0.613, task_loss=0.477, contrastive_loss=0, total=4179.48, n_correct=2511.3, ppl=3.1, accuracy=60.086, wps=14636.8, ups=1.18, wpb=12434.9, bsz=475.5, num_updates=12900, lr=0.000124515, gnorm=0.284, clip=0, loss_scale=64, train_wall=85, gb_free=17.6, wall=10837
2023-07-04 17:09:54 | INFO | train_inner | epoch 009:   1214 / 1474 loss=2.154, trans_loss=3.492, nll_loss=1.64, w2v_ctc_loss=0.616, task_loss=0.534, contrastive_loss=0, total=4147.82, n_correct=2482.46, ppl=3.12, accuracy=59.85, wps=14486.9, ups=1.17, wpb=12423.7, bsz=447.6, num_updates=13000, lr=0.000124035, gnorm=0.282, clip=0, loss_scale=64, train_wall=85, gb_free=16.4, wall=10923
2023-07-04 17:11:19 | INFO | train_inner | epoch 009:   1314 / 1474 loss=2.135, trans_loss=3.477, nll_loss=1.626, w2v_ctc_loss=0.602, task_loss=0.458, contrastive_loss=0, total=4204.88, n_correct=2535.85, ppl=3.09, accuracy=60.307, wps=14809.8, ups=1.18, wpb=12546.5, bsz=493, num_updates=13100, lr=0.00012356, gnorm=0.279, clip=0, loss_scale=64, train_wall=84, gb_free=17.2, wall=11007
2023-07-04 17:12:44 | INFO | train_inner | epoch 009:   1414 / 1474 loss=2.154, trans_loss=3.495, nll_loss=1.647, w2v_ctc_loss=0.617, task_loss=0.552, contrastive_loss=0, total=4075, n_correct=2435.21, ppl=3.13, accuracy=59.76, wps=14377, ups=1.18, wpb=12164.1, bsz=427.2, num_updates=13200, lr=0.000123091, gnorm=0.289, clip=0, loss_scale=64, train_wall=84, gb_free=13, wall=11092
2023-07-04 17:13:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 17:14:01 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 2.183 | trans_loss 5.662 | nll_loss 2.961 | w2v_ctc_loss 0.673 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2420 | ppl 7.79 | accuracy 60.449 | uer 17.763 | wer 19.5 | raw_wer 19.5 | bleu 18.95 | wps 1988 | wpb 4003.4 | bsz 141.8 | num_updates 13260 | best_bleu 18.95
2023-07-04 17:14:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13260 updates
2023-07-04 17:14:01 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 17:14:05 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 17:14:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt (epoch 9 @ 13260 updates, score 18.95) (writing took 8.883960711304098 seconds)
2023-07-04 17:14:10 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-07-04 17:14:10 | INFO | train | epoch 009 | loss 2.145 | trans_loss 3.481 | nll_loss 1.631 | w2v_ctc_loss 0.611 | task_loss 0.505 | contrastive_loss 0 | total 4138.65 | n_correct 2483.39 | ppl 3.1 | accuracy 60.005 | wps 13648.6 | ups 1.1 | wpb 12355.8 | bsz 458.5 | num_updates 13260 | lr 0.000122813 | gnorm 0.283 | clip 0 | loss_scale 64 | train_wall 1247 | gb_free 12 | wall 11178
2023-07-04 17:14:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 17:14:10 | INFO | fairseq.trainer | begin training epoch 10
2023-07-04 17:14:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 17:14:52 | INFO | train_inner | epoch 010:     40 / 1474 loss=2.134, trans_loss=3.473, nll_loss=1.62, w2v_ctc_loss=0.602, task_loss=0.482, contrastive_loss=0, total=4088.59, n_correct=2471.36, ppl=3.07, accuracy=60.445, wps=9509.1, ups=0.78, wpb=12209.3, bsz=467.6, num_updates=13300, lr=0.000122628, gnorm=0.288, clip=0, loss_scale=64, train_wall=83, gb_free=17.1, wall=11220
2023-07-04 17:16:17 | INFO | train_inner | epoch 010:    140 / 1474 loss=2.115, trans_loss=3.456, nll_loss=1.596, w2v_ctc_loss=0.582, task_loss=0.477, contrastive_loss=0, total=4241, n_correct=2589.14, ppl=3.02, accuracy=61.05, wps=14994.9, ups=1.18, wpb=12702.9, bsz=480.3, num_updates=13400, lr=0.000122169, gnorm=0.279, clip=0, loss_scale=64, train_wall=84, gb_free=16.2, wall=11305
2023-07-04 17:17:41 | INFO | train_inner | epoch 010:    240 / 1474 loss=2.114, trans_loss=3.451, nll_loss=1.593, w2v_ctc_loss=0.587, task_loss=0.497, contrastive_loss=0, total=4135.58, n_correct=2524.6, ppl=3.02, accuracy=61.046, wps=14617.1, ups=1.19, wpb=12318.1, bsz=462.8, num_updates=13500, lr=0.000121716, gnorm=0.282, clip=0, loss_scale=64, train_wall=84, gb_free=13, wall=11389
2023-07-04 17:19:07 | INFO | train_inner | epoch 010:    340 / 1474 loss=2.117, trans_loss=3.452, nll_loss=1.596, w2v_ctc_loss=0.586, task_loss=0.509, contrastive_loss=0, total=4128.98, n_correct=2516.31, ppl=3.02, accuracy=60.943, wps=14428, ups=1.17, wpb=12344.6, bsz=453.3, num_updates=13600, lr=0.000121268, gnorm=0.282, clip=0, loss_scale=64, train_wall=85, gb_free=17.5, wall=11475
2023-07-04 17:20:33 | INFO | train_inner | epoch 010:    440 / 1474 loss=2.112, trans_loss=3.456, nll_loss=1.6, w2v_ctc_loss=0.578, task_loss=0.486, contrastive_loss=0, total=4204.32, n_correct=2557.85, ppl=3.03, accuracy=60.839, wps=14620.8, ups=1.17, wpb=12543.5, bsz=481.2, num_updates=13700, lr=0.000120824, gnorm=0.279, clip=0, loss_scale=64, train_wall=85, gb_free=15.4, wall=11561
2023-07-04 17:21:58 | INFO | train_inner | epoch 010:    540 / 1474 loss=2.13, trans_loss=3.47, nll_loss=1.613, w2v_ctc_loss=0.598, task_loss=0.542, contrastive_loss=0, total=4105.89, n_correct=2487.86, ppl=3.06, accuracy=60.592, wps=14366.3, ups=1.17, wpb=12237.8, bsz=439.7, num_updates=13800, lr=0.000120386, gnorm=0.285, clip=0, loss_scale=64, train_wall=85, gb_free=16.8, wall=11646
2023-07-04 17:23:23 | INFO | train_inner | epoch 010:    640 / 1474 loss=2.128, trans_loss=3.466, nll_loss=1.611, w2v_ctc_loss=0.596, task_loss=0.477, contrastive_loss=0, total=4173.95, n_correct=2533.59, ppl=3.05, accuracy=60.7, wps=14662.1, ups=1.18, wpb=12460.9, bsz=477.3, num_updates=13900, lr=0.000119952, gnorm=0.284, clip=0, loss_scale=64, train_wall=84, gb_free=17.8, wall=11731
2023-07-04 17:24:47 | INFO | train_inner | epoch 010:    740 / 1474 loss=2.133, trans_loss=3.467, nll_loss=1.612, w2v_ctc_loss=0.604, task_loss=0.511, contrastive_loss=0, total=4121.45, n_correct=2496, ppl=3.06, accuracy=60.561, wps=14577.6, ups=1.19, wpb=12301.7, bsz=451.9, num_updates=14000, lr=0.000119523, gnorm=0.287, clip=0, loss_scale=128, train_wall=84, gb_free=16.6, wall=11815
2023-07-04 17:24:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 17:25:14 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 2.19 | trans_loss 5.667 | nll_loss 2.967 | w2v_ctc_loss 0.687 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2415.7 | ppl 7.82 | accuracy 60.341 | uer 17.997 | wer 19.809 | raw_wer 19.809 | bleu 19.06 | wps 1988.1 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 19.06
2023-07-04 17:25:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-07-04 17:25:14 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_10_14000.pt
2023-07-04 17:25:17 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_10_14000.pt
2023-07-04 17:25:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 19.06) (writing took 9.462411473039538 seconds)
2023-07-04 17:26:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-04 17:26:50 | INFO | train_inner | epoch 010:    841 / 1474 loss=2.122, trans_loss=3.465, nll_loss=1.61, w2v_ctc_loss=0.586, task_loss=0.498, contrastive_loss=0, total=4127.11, n_correct=2507.93, ppl=3.05, accuracy=60.767, wps=10079.2, ups=0.82, wpb=12344.8, bsz=455.6, num_updates=14100, lr=0.000119098, gnorm=0.281, clip=0, loss_scale=64, train_wall=85, gb_free=15.9, wall=11938
2023-07-04 17:27:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-04 17:28:14 | INFO | train_inner | epoch 010:    942 / 1474 loss=2.125, trans_loss=3.462, nll_loss=1.608, w2v_ctc_loss=0.596, task_loss=0.483, contrastive_loss=0, total=4165.02, n_correct=2531.09, ppl=3.05, accuracy=60.77, wps=14594.7, ups=1.18, wpb=12391.1, bsz=470, num_updates=14200, lr=0.000118678, gnorm=0.284, clip=0, loss_scale=32, train_wall=84, gb_free=15.6, wall=12023
2023-07-04 17:29:40 | INFO | train_inner | epoch 010:   1042 / 1474 loss=2.129, trans_loss=3.467, nll_loss=1.614, w2v_ctc_loss=0.597, task_loss=0.548, contrastive_loss=0, total=4067.53, n_correct=2461.84, ppl=3.06, accuracy=60.524, wps=14238.8, ups=1.17, wpb=12142, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.287, clip=0, loss_scale=32, train_wall=85, gb_free=17, wall=12108
2023-07-04 17:31:04 | INFO | train_inner | epoch 010:   1142 / 1474 loss=2.131, trans_loss=3.47, nll_loss=1.617, w2v_ctc_loss=0.599, task_loss=0.563, contrastive_loss=0, total=4044.03, n_correct=2446.14, ppl=3.07, accuracy=60.488, wps=14310.4, ups=1.19, wpb=12072.9, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.289, clip=0, loss_scale=32, train_wall=84, gb_free=17.4, wall=12192
2023-07-04 17:32:29 | INFO | train_inner | epoch 010:   1242 / 1474 loss=2.128, trans_loss=3.463, nll_loss=1.611, w2v_ctc_loss=0.598, task_loss=0.516, contrastive_loss=0, total=4110.41, n_correct=2492.08, ppl=3.06, accuracy=60.629, wps=14500.7, ups=1.18, wpb=12302.3, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.286, clip=0, loss_scale=32, train_wall=84, gb_free=16.6, wall=12277
2023-07-04 17:33:54 | INFO | train_inner | epoch 010:   1342 / 1474 loss=2.125, trans_loss=3.463, nll_loss=1.609, w2v_ctc_loss=0.592, task_loss=0.514, contrastive_loss=0, total=4121.38, n_correct=2504.54, ppl=3.05, accuracy=60.769, wps=14522, ups=1.18, wpb=12315.5, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.284, clip=0, loss_scale=32, train_wall=84, gb_free=14.3, wall=12362
2023-07-04 17:35:19 | INFO | train_inner | epoch 010:   1442 / 1474 loss=2.122, trans_loss=3.469, nll_loss=1.619, w2v_ctc_loss=0.586, task_loss=0.476, contrastive_loss=0, total=4192.39, n_correct=2539.6, ppl=3.07, accuracy=60.576, wps=14669.3, ups=1.18, wpb=12477.9, bsz=482, num_updates=14700, lr=0.000116642, gnorm=0.282, clip=0, loss_scale=32, train_wall=85, gb_free=17.2, wall=12447
2023-07-04 17:35:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 17:36:14 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 2.176 | trans_loss 5.648 | nll_loss 2.942 | w2v_ctc_loss 0.664 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2428.2 | ppl 7.68 | accuracy 60.653 | uer 17.416 | wer 19.116 | raw_wer 19.116 | bleu 18.8 | wps 1887.8 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 19.06
2023-07-04 17:36:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-07-04 17:36:14 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_18.8002.pt
2023-07-04 17:36:16 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_18.8002.pt
2023-07-04 17:36:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_18.8002.pt (epoch 10 @ 14732 updates, score 18.8) (writing took 5.550810785032809 seconds)
2023-07-04 17:36:20 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-07-04 17:36:20 | INFO | train | epoch 010 | loss 2.123 | trans_loss 3.463 | nll_loss 1.608 | w2v_ctc_loss 0.591 | task_loss 0.505 | contrastive_loss 0 | total 4138.79 | n_correct 2513.88 | ppl 3.05 | accuracy 60.739 | wps 13677.8 | ups 1.11 | wpb 12356.4 | bsz 458.6 | num_updates 14732 | lr 0.000116516 | gnorm 0.284 | clip 0 | loss_scale 32 | train_wall 1243 | gb_free 17.4 | wall 12508
2023-07-04 17:36:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 17:36:20 | INFO | fairseq.trainer | begin training epoch 11
2023-07-04 17:36:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 17:37:25 | INFO | train_inner | epoch 011:     68 / 1474 loss=2.103, trans_loss=3.445, nll_loss=1.585, w2v_ctc_loss=0.574, task_loss=0.466, contrastive_loss=0, total=4175.24, n_correct=2567.2, ppl=3, accuracy=61.486, wps=9872.2, ups=0.79, wpb=12460.8, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.277, clip=0, loss_scale=32, train_wall=83, gb_free=16.9, wall=12573
2023-07-04 17:38:50 | INFO | train_inner | epoch 011:    168 / 1474 loss=2.102, trans_loss=3.444, nll_loss=1.584, w2v_ctc_loss=0.573, task_loss=0.521, contrastive_loss=0, total=4087.78, n_correct=2506.82, ppl=3, accuracy=61.325, wps=14468.3, ups=1.18, wpb=12225.8, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.285, clip=0, loss_scale=32, train_wall=84, gb_free=16.7, wall=12658
2023-07-04 17:40:15 | INFO | train_inner | epoch 011:    268 / 1474 loss=2.099, trans_loss=3.442, nll_loss=1.583, w2v_ctc_loss=0.57, task_loss=0.52, contrastive_loss=0, total=4118.77, n_correct=2529.91, ppl=3, accuracy=61.424, wps=14391.3, ups=1.17, wpb=12285.5, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.283, clip=0, loss_scale=32, train_wall=85, gb_free=12.7, wall=12743
tensor(0.2485, device='cuda:0')
tensor(0.1298, device='cuda:0')
2023-07-04 17:41:39 | INFO | train_inner | epoch 011:    368 / 1474 loss=2.097, trans_loss=3.442, nll_loss=1.58, w2v_ctc_loss=0.567, task_loss=0.521, contrastive_loss=0, total=4097.83, n_correct=2521.22, ppl=2.99, accuracy=61.526, wps=14460, ups=1.19, wpb=12202.1, bsz=444.2, num_updates=15100, lr=0.000115087, gnorm=0.211, clip=0, loss_scale=32, train_wall=84, gb_free=16.4, wall=12828
2023-07-04 17:43:06 | INFO | train_inner | epoch 011:    468 / 1474 loss=2.105, trans_loss=3.455, nll_loss=1.594, w2v_ctc_loss=0.571, task_loss=0.531, contrastive_loss=0, total=4110.64, n_correct=2512.12, ppl=3.02, accuracy=61.113, wps=14211.8, ups=1.16, wpb=12265.6, bsz=450.5, num_updates=15200, lr=0.000114708, gnorm=0.213, clip=0, loss_scale=32, train_wall=86, gb_free=16.5, wall=12914
2023-07-04 17:44:31 | INFO | train_inner | epoch 011:    568 / 1474 loss=2.114, trans_loss=3.452, nll_loss=1.597, w2v_ctc_loss=0.583, task_loss=0.538, contrastive_loss=0, total=4071.69, n_correct=2490.36, ppl=3.02, accuracy=61.163, wps=14210, ups=1.17, wpb=12176.5, bsz=440.6, num_updates=15300, lr=0.000114332, gnorm=0.215, clip=0, loss_scale=32, train_wall=85, gb_free=16.5, wall=13000
2023-07-04 17:45:57 | INFO | train_inner | epoch 011:    668 / 1474 loss=2.105, trans_loss=3.446, nll_loss=1.586, w2v_ctc_loss=0.574, task_loss=0.498, contrastive_loss=0, total=4157.2, n_correct=2549.93, ppl=3, accuracy=61.338, wps=14564.5, ups=1.17, wpb=12400.2, bsz=464.4, num_updates=15400, lr=0.000113961, gnorm=0.212, clip=0, loss_scale=32, train_wall=85, gb_free=16.9, wall=13085
2023-07-04 17:47:22 | INFO | train_inner | epoch 011:    768 / 1474 loss=2.112, trans_loss=3.451, nll_loss=1.592, w2v_ctc_loss=0.582, task_loss=0.506, contrastive_loss=0, total=4174.91, n_correct=2561.53, ppl=3.01, accuracy=61.355, wps=14620.6, ups=1.17, wpb=12472.8, bsz=460.4, num_updates=15500, lr=0.000113592, gnorm=0.212, clip=0, loss_scale=32, train_wall=85, gb_free=17.1, wall=13170
2023-07-04 17:48:47 | INFO | train_inner | epoch 011:    868 / 1474 loss=2.111, trans_loss=3.449, nll_loss=1.593, w2v_ctc_loss=0.582, task_loss=0.527, contrastive_loss=0, total=4118.44, n_correct=2518.03, ppl=3.02, accuracy=61.14, wps=14480.4, ups=1.18, wpb=12290.5, bsz=440.6, num_updates=15600, lr=0.000113228, gnorm=0.213, clip=0, loss_scale=32, train_wall=84, gb_free=11.2, wall=13255
2023-07-04 17:50:12 | INFO | train_inner | epoch 011:    968 / 1474 loss=2.11, trans_loss=3.449, nll_loss=1.591, w2v_ctc_loss=0.579, task_loss=0.514, contrastive_loss=0, total=4140.92, n_correct=2538.03, ppl=3.01, accuracy=61.291, wps=14552.5, ups=1.18, wpb=12353.7, bsz=452.9, num_updates=15700, lr=0.000112867, gnorm=0.21, clip=0, loss_scale=32, train_wall=84, gb_free=15.8, wall=13340
2023-07-04 17:51:37 | INFO | train_inner | epoch 011:   1068 / 1474 loss=2.111, trans_loss=3.447, nll_loss=1.59, w2v_ctc_loss=0.581, task_loss=0.495, contrastive_loss=0, total=4136.99, n_correct=2540.48, ppl=3.01, accuracy=61.409, wps=14501.6, ups=1.17, wpb=12367, bsz=463.2, num_updates=15800, lr=0.000112509, gnorm=0.21, clip=0, loss_scale=32, train_wall=85, gb_free=17.7, wall=13425
2023-07-04 17:53:03 | INFO | train_inner | epoch 011:   1168 / 1474 loss=2.113, trans_loss=3.45, nll_loss=1.597, w2v_ctc_loss=0.584, task_loss=0.501, contrastive_loss=0, total=4185.65, n_correct=2561.07, ppl=3.03, accuracy=61.187, wps=14515.6, ups=1.16, wpb=12477.8, bsz=464.7, num_updates=15900, lr=0.000112154, gnorm=0.212, clip=0, loss_scale=32, train_wall=86, gb_free=14.3, wall=13511
2023-07-04 17:54:28 | INFO | train_inner | epoch 011:   1268 / 1474 loss=2.119, trans_loss=3.452, nll_loss=1.596, w2v_ctc_loss=0.59, task_loss=0.486, contrastive_loss=0, total=4171.89, n_correct=2555.34, ppl=3.02, accuracy=61.251, wps=14669.5, ups=1.18, wpb=12466.6, bsz=471.1, num_updates=16000, lr=0.000111803, gnorm=0.213, clip=0, loss_scale=32, train_wall=85, gb_free=16.1, wall=13596
2023-07-04 17:54:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.2485, device='cuda:6')
tensor(0.1298, device='cuda:6')
tensor(0.2485, device='cuda:1')
tensor(0.1298, device='cuda:1')
tensor(0.2485, device='cuda:7')
tensor(0.1298, device='cuda:7')
tensor(0.2485, device='cuda:3')
tensor(0.1298, device='cuda:3')
tensor(0.2485, device='cuda:2')
tensor(0.1298, device='cuda:2')
tensor(0.2485, device='cuda:5')
tensor(0.1298, device='cuda:5')
tensor(0.2485, device='cuda:4')
tensor(0.1298, device='cuda:4')
2023-07-04 17:54:55 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 2.189 | trans_loss 5.639 | nll_loss 2.925 | w2v_ctc_loss 0.72 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2433.7 | ppl 7.59 | accuracy 60.791 | uer 17.466 | wer 19.101 | raw_wer 19.101 | bleu 19.19 | wps 1923.9 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.19
2023-07-04 17:54:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-07-04 17:54:55 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_11_16000.pt
2023-07-04 17:54:57 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_11_16000.pt
2023-07-04 17:55:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 19.19) (writing took 9.776341702323407 seconds)
2023-07-04 17:56:30 | INFO | train_inner | epoch 011:   1368 / 1474 loss=2.107, trans_loss=3.45, nll_loss=1.592, w2v_ctc_loss=0.576, task_loss=0.465, contrastive_loss=0, total=4190.34, n_correct=2565.89, ppl=3.02, accuracy=61.233, wps=10219.6, ups=0.82, wpb=12512.8, bsz=491.8, num_updates=16100, lr=0.000111456, gnorm=0.209, clip=0, loss_scale=32, train_wall=85, gb_free=17.1, wall=13719
2023-07-04 17:57:55 | INFO | train_inner | epoch 011:   1468 / 1474 loss=2.108, trans_loss=3.45, nll_loss=1.593, w2v_ctc_loss=0.576, task_loss=0.489, contrastive_loss=0, total=4158.39, n_correct=2551.24, ppl=3.02, accuracy=61.352, wps=14628.1, ups=1.18, wpb=12421.8, bsz=468, num_updates=16200, lr=0.000111111, gnorm=0.209, clip=0, loss_scale=32, train_wall=84, gb_free=17.1, wall=13803
2023-07-04 17:58:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 17:58:26 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 2.173 | trans_loss 5.63 | nll_loss 2.921 | w2v_ctc_loss 0.676 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2436.7 | ppl 7.57 | accuracy 60.866 | uer 17.453 | wer 19.186 | raw_wer 19.186 | bleu 19.64 | wps 1958.7 | wpb 4003.4 | bsz 141.8 | num_updates 16206 | best_bleu 19.64
2023-07-04 17:58:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16206 updates
2023-07-04 17:58:26 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 17:58:31 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 17:58:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt (epoch 11 @ 16206 updates, score 19.64) (writing took 8.582892144098878 seconds)
2023-07-04 17:58:35 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-07-04 17:58:35 | INFO | train | epoch 011 | loss 2.108 | trans_loss 3.448 | nll_loss 1.59 | w2v_ctc_loss 0.577 | task_loss 0.505 | contrastive_loss 0 | total 4138.65 | n_correct 2537.62 | ppl 3.01 | accuracy 61.315 | wps 13638.1 | ups 1.1 | wpb 12355.8 | bsz 458.5 | num_updates 16206 | lr 0.000111091 | gnorm 0.224 | clip 0 | loss_scale 32 | train_wall 1248 | gb_free 17.3 | wall 13843
2023-07-04 17:58:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 17:58:35 | INFO | fairseq.trainer | begin training epoch 12
2023-07-04 17:58:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 18:00:03 | INFO | train_inner | epoch 012:     94 / 1474 loss=2.089, trans_loss=3.424, nll_loss=1.558, w2v_ctc_loss=0.565, task_loss=0.484, contrastive_loss=0, total=4146.82, n_correct=2581.49, ppl=2.94, accuracy=62.252, wps=9712.2, ups=0.78, wpb=12379.4, bsz=470.8, num_updates=16300, lr=0.00011077, gnorm=0.209, clip=0, loss_scale=64, train_wall=84, gb_free=15.9, wall=13931
2023-07-04 18:01:28 | INFO | train_inner | epoch 012:    194 / 1474 loss=2.091, trans_loss=3.427, nll_loss=1.563, w2v_ctc_loss=0.565, task_loss=0.52, contrastive_loss=0, total=4120.68, n_correct=2559.71, ppl=2.95, accuracy=62.119, wps=14556.7, ups=1.18, wpb=12345.4, bsz=442.1, num_updates=16400, lr=0.000110432, gnorm=0.212, clip=0, loss_scale=64, train_wall=84, gb_free=15.8, wall=14016
2023-07-04 18:02:53 | INFO | train_inner | epoch 012:    294 / 1474 loss=2.086, trans_loss=3.426, nll_loss=1.563, w2v_ctc_loss=0.558, task_loss=0.475, contrastive_loss=0, total=4199.46, n_correct=2611.69, ppl=2.95, accuracy=62.191, wps=14620.8, ups=1.17, wpb=12539.6, bsz=480.4, num_updates=16500, lr=0.000110096, gnorm=0.208, clip=0, loss_scale=64, train_wall=85, gb_free=16.7, wall=14102
2023-07-04 18:04:18 | INFO | train_inner | epoch 012:    394 / 1474 loss=2.09, trans_loss=3.429, nll_loss=1.566, w2v_ctc_loss=0.562, task_loss=0.495, contrastive_loss=0, total=4151.14, n_correct=2579.87, ppl=2.96, accuracy=62.148, wps=14582.9, ups=1.18, wpb=12410, bsz=461.6, num_updates=16600, lr=0.000109764, gnorm=0.209, clip=0, loss_scale=64, train_wall=85, gb_free=17.2, wall=14187
2023-07-04 18:05:43 | INFO | train_inner | epoch 012:    494 / 1474 loss=2.105, trans_loss=3.443, nll_loss=1.581, w2v_ctc_loss=0.577, task_loss=0.51, contrastive_loss=0, total=4110.49, n_correct=2543.03, ppl=2.99, accuracy=61.867, wps=14471.6, ups=1.18, wpb=12226.9, bsz=453.3, num_updates=16700, lr=0.000109435, gnorm=0.213, clip=0, loss_scale=64, train_wall=84, gb_free=14.1, wall=14271
2023-07-04 18:07:08 | INFO | train_inner | epoch 012:    594 / 1474 loss=2.096, trans_loss=3.431, nll_loss=1.57, w2v_ctc_loss=0.57, task_loss=0.483, contrastive_loss=0, total=4189.92, n_correct=2594.65, ppl=2.97, accuracy=61.926, wps=14649.2, ups=1.17, wpb=12531.1, bsz=472.7, num_updates=16800, lr=0.000109109, gnorm=0.21, clip=0, loss_scale=64, train_wall=85, gb_free=15.1, wall=14357
2023-07-04 18:08:33 | INFO | train_inner | epoch 012:    694 / 1474 loss=2.084, trans_loss=3.428, nll_loss=1.566, w2v_ctc_loss=0.558, task_loss=0.464, contrastive_loss=0, total=4206.3, n_correct=2612.94, ppl=2.96, accuracy=62.12, wps=14819.5, ups=1.19, wpb=12501.9, bsz=488.5, num_updates=16900, lr=0.000108786, gnorm=0.209, clip=0, loss_scale=64, train_wall=84, gb_free=16.4, wall=14441
2023-07-04 18:09:58 | INFO | train_inner | epoch 012:    794 / 1474 loss=2.1, trans_loss=3.436, nll_loss=1.572, w2v_ctc_loss=0.571, task_loss=0.516, contrastive_loss=0, total=4085.96, n_correct=2533.64, ppl=2.97, accuracy=62.008, wps=14399.3, ups=1.18, wpb=12212.6, bsz=445.7, num_updates=17000, lr=0.000108465, gnorm=0.214, clip=0, loss_scale=64, train_wall=84, gb_free=16.7, wall=14526
2023-07-04 18:11:23 | INFO | train_inner | epoch 012:    894 / 1474 loss=2.093, trans_loss=3.432, nll_loss=1.571, w2v_ctc_loss=0.564, task_loss=0.515, contrastive_loss=0, total=4169.74, n_correct=2589.57, ppl=2.97, accuracy=62.104, wps=14598.8, ups=1.17, wpb=12453, bsz=459.6, num_updates=17100, lr=0.000108148, gnorm=0.21, clip=0, loss_scale=64, train_wall=85, gb_free=16.2, wall=14611
2023-07-04 18:12:48 | INFO | train_inner | epoch 012:    994 / 1474 loss=2.101, trans_loss=3.439, nll_loss=1.579, w2v_ctc_loss=0.572, task_loss=0.515, contrastive_loss=0, total=4117.67, n_correct=2537.57, ppl=2.99, accuracy=61.626, wps=14464.7, ups=1.18, wpb=12288, bsz=452.1, num_updates=17200, lr=0.000107833, gnorm=0.213, clip=0, loss_scale=64, train_wall=84, gb_free=17.7, wall=14696
2023-07-04 18:14:13 | INFO | train_inner | epoch 012:   1094 / 1474 loss=2.104, trans_loss=3.441, nll_loss=1.582, w2v_ctc_loss=0.575, task_loss=0.531, contrastive_loss=0, total=4047.61, n_correct=2497.21, ppl=2.99, accuracy=61.696, wps=14267.4, ups=1.18, wpb=12086.1, bsz=435.6, num_updates=17300, lr=0.000107521, gnorm=0.215, clip=0, loss_scale=64, train_wall=84, gb_free=16.9, wall=14781
2023-07-04 18:15:37 | INFO | train_inner | epoch 012:   1194 / 1474 loss=2.112, trans_loss=3.443, nll_loss=1.587, w2v_ctc_loss=0.586, task_loss=0.497, contrastive_loss=0, total=4184.55, n_correct=2572.26, ppl=3, accuracy=61.47, wps=14719.3, ups=1.18, wpb=12497.1, bsz=471.4, num_updates=17400, lr=0.000107211, gnorm=0.211, clip=0, loss_scale=64, train_wall=84, gb_free=16.9, wall=14866
2023-07-04 18:17:03 | INFO | train_inner | epoch 012:   1294 / 1474 loss=2.108, trans_loss=3.442, nll_loss=1.585, w2v_ctc_loss=0.579, task_loss=0.549, contrastive_loss=0, total=4086.33, n_correct=2524.68, ppl=3, accuracy=61.784, wps=14337.7, ups=1.17, wpb=12210.8, bsz=437.2, num_updates=17500, lr=0.000106904, gnorm=0.213, clip=0, loss_scale=64, train_wall=85, gb_free=17, wall=14951
2023-07-04 18:18:27 | INFO | train_inner | epoch 012:   1394 / 1474 loss=2.095, trans_loss=3.437, nll_loss=1.578, w2v_ctc_loss=0.564, task_loss=0.513, contrastive_loss=0, total=4134.89, n_correct=2557.29, ppl=2.98, accuracy=61.847, wps=14569.5, ups=1.18, wpb=12323.9, bsz=456.6, num_updates=17600, lr=0.0001066, gnorm=0.212, clip=0, loss_scale=64, train_wall=84, gb_free=17.4, wall=15035
2023-07-04 18:19:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 18:20:00 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 2.168 | trans_loss 5.608 | nll_loss 2.891 | w2v_ctc_loss 0.684 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2459.1 | ppl 7.42 | accuracy 61.425 | uer 17.373 | wer 19.172 | raw_wer 19.172 | bleu 19.63 | wps 2197.5 | wpb 4003.4 | bsz 141.8 | num_updates 17680 | best_bleu 19.64
2023-07-04 18:20:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17680 updates
2023-07-04 18:20:00 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_19.6304.pt
2023-07-04 18:20:02 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_19.6304.pt
2023-07-04 18:20:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_19.6304.pt (epoch 12 @ 17680 updates, score 19.63) (writing took 5.461098458152264 seconds)
2023-07-04 18:20:05 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-07-04 18:20:05 | INFO | train | epoch 012 | loss 2.097 | trans_loss 3.434 | nll_loss 1.573 | w2v_ctc_loss 0.569 | task_loss 0.505 | contrastive_loss 0 | total 4138.65 | n_correct 2563.36 | ppl 2.98 | accuracy 61.937 | wps 14115.8 | ups 1.14 | wpb 12355.8 | bsz 458.5 | num_updates 17680 | lr 0.000106359 | gnorm 0.211 | clip 0 | loss_scale 64 | train_wall 1245 | gb_free 13.2 | wall 15134
2023-07-04 18:20:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 18:20:06 | INFO | fairseq.trainer | begin training epoch 13
2023-07-04 18:20:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 18:20:31 | INFO | train_inner | epoch 013:     20 / 1474 loss=2.105, trans_loss=3.437, nll_loss=1.578, w2v_ctc_loss=0.578, task_loss=0.523, contrastive_loss=0, total=4104.86, n_correct=2539.07, ppl=2.98, accuracy=61.855, wps=9912, ups=0.81, wpb=12264.8, bsz=445.3, num_updates=17700, lr=0.000106299, gnorm=0.212, clip=0, loss_scale=64, train_wall=84, gb_free=15, wall=15159
2023-07-04 18:21:56 | INFO | train_inner | epoch 013:    120 / 1474 loss=2.075, trans_loss=3.411, nll_loss=1.544, w2v_ctc_loss=0.552, task_loss=0.507, contrastive_loss=0, total=4161.2, n_correct=2612.77, ppl=2.92, accuracy=62.789, wps=14630.5, ups=1.18, wpb=12419, bsz=454.4, num_updates=17800, lr=0.000106, gnorm=0.209, clip=0, loss_scale=64, train_wall=84, gb_free=16.3, wall=15244
2023-07-04 18:23:22 | INFO | train_inner | epoch 013:    220 / 1474 loss=2.08, trans_loss=3.417, nll_loss=1.555, w2v_ctc_loss=0.555, task_loss=0.47, contrastive_loss=0, total=4202.62, n_correct=2630.29, ppl=2.94, accuracy=62.587, wps=14576.1, ups=1.17, wpb=12504.4, bsz=492.4, num_updates=17900, lr=0.000105703, gnorm=0.209, clip=0, loss_scale=64, train_wall=85, gb_free=17.3, wall=15330
2023-07-04 18:24:47 | INFO | train_inner | epoch 013:    320 / 1474 loss=2.078, trans_loss=3.417, nll_loss=1.55, w2v_ctc_loss=0.552, task_loss=0.521, contrastive_loss=0, total=4112.8, n_correct=2583.92, ppl=2.93, accuracy=62.826, wps=14355.2, ups=1.17, wpb=12262.5, bsz=444, num_updates=18000, lr=0.000105409, gnorm=0.213, clip=0, loss_scale=64, train_wall=85, gb_free=17.9, wall=15415
2023-07-04 18:24:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 18:25:12 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 2.172 | trans_loss 5.617 | nll_loss 2.898 | w2v_ctc_loss 0.687 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2449.1 | ppl 7.45 | accuracy 61.176 | uer 17.217 | wer 19.056 | raw_wer 19.056 | bleu 19.53 | wps 2175.3 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.64
2023-07-04 18:25:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-07-04 18:25:12 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_13_18000.pt
2023-07-04 18:25:14 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_13_18000.pt
2023-07-04 18:25:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.53) (writing took 6.270537433214486 seconds)
2023-07-04 18:26:43 | INFO | train_inner | epoch 013:    420 / 1474 loss=2.086, trans_loss=3.424, nll_loss=1.559, w2v_ctc_loss=0.558, task_loss=0.478, contrastive_loss=0, total=4176.06, n_correct=2619.63, ppl=2.95, accuracy=62.73, wps=10732.9, ups=0.86, wpb=12453.9, bsz=476.2, num_updates=18100, lr=0.000105118, gnorm=0.21, clip=0, loss_scale=64, train_wall=84, gb_free=16.6, wall=15531
2023-07-04 18:28:09 | INFO | train_inner | epoch 013:    520 / 1474 loss=2.086, trans_loss=3.424, nll_loss=1.56, w2v_ctc_loss=0.56, task_loss=0.493, contrastive_loss=0, total=4197.57, n_correct=2617.28, ppl=2.95, accuracy=62.352, wps=14638, ups=1.17, wpb=12523.8, bsz=477.2, num_updates=18200, lr=0.000104828, gnorm=0.211, clip=0, loss_scale=64, train_wall=85, gb_free=15.5, wall=15617
2023-07-04 18:29:34 | INFO | train_inner | epoch 013:    620 / 1474 loss=2.082, trans_loss=3.416, nll_loss=1.551, w2v_ctc_loss=0.556, task_loss=0.487, contrastive_loss=0, total=4160.12, n_correct=2610.05, ppl=2.93, accuracy=62.74, wps=14663.9, ups=1.18, wpb=12433.1, bsz=463, num_updates=18300, lr=0.000104542, gnorm=0.21, clip=0, loss_scale=128, train_wall=84, gb_free=16.5, wall=15702
2023-07-04 18:29:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-04 18:31:00 | INFO | train_inner | epoch 013:    721 / 1474 loss=2.092, trans_loss=3.424, nll_loss=1.56, w2v_ctc_loss=0.569, task_loss=0.557, contrastive_loss=0, total=4097.44, n_correct=2553.73, ppl=2.95, accuracy=62.325, wps=14193.9, ups=1.16, wpb=12231.1, bsz=427.9, num_updates=18400, lr=0.000104257, gnorm=0.214, clip=0, loss_scale=64, train_wall=86, gb_free=16.8, wall=15788
2023-07-04 18:32:26 | INFO | train_inner | epoch 013:    821 / 1474 loss=2.084, trans_loss=3.422, nll_loss=1.558, w2v_ctc_loss=0.559, task_loss=0.511, contrastive_loss=0, total=4121.73, n_correct=2568.76, ppl=2.94, accuracy=62.322, wps=14340, ups=1.16, wpb=12319.8, bsz=460, num_updates=18500, lr=0.000103975, gnorm=0.212, clip=0, loss_scale=64, train_wall=85, gb_free=15, wall=15874
2023-07-04 18:33:51 | INFO | train_inner | epoch 013:    921 / 1474 loss=2.086, trans_loss=3.424, nll_loss=1.561, w2v_ctc_loss=0.559, task_loss=0.514, contrastive_loss=0, total=4107.01, n_correct=2562.21, ppl=2.95, accuracy=62.386, wps=14418.7, ups=1.18, wpb=12264.1, bsz=444.7, num_updates=18600, lr=0.000103695, gnorm=0.213, clip=0, loss_scale=64, train_wall=85, gb_free=16.1, wall=15959
2023-07-04 18:35:15 | INFO | train_inner | epoch 013:   1021 / 1474 loss=2.092, trans_loss=3.422, nll_loss=1.563, w2v_ctc_loss=0.568, task_loss=0.533, contrastive_loss=0, total=4081.02, n_correct=2539.76, ppl=2.95, accuracy=62.233, wps=14435.9, ups=1.18, wpb=12208.8, bsz=440.1, num_updates=18700, lr=0.000103418, gnorm=0.212, clip=0, loss_scale=64, train_wall=84, gb_free=16.4, wall=16043
2023-07-04 18:36:39 | INFO | train_inner | epoch 013:   1121 / 1474 loss=2.084, trans_loss=3.421, nll_loss=1.557, w2v_ctc_loss=0.556, task_loss=0.497, contrastive_loss=0, total=4105.62, n_correct=2572.44, ppl=2.94, accuracy=62.657, wps=14606.6, ups=1.19, wpb=12265.4, bsz=458.9, num_updates=18800, lr=0.000103142, gnorm=0.212, clip=0, loss_scale=64, train_wall=84, gb_free=16.9, wall=16127
2023-07-04 18:38:04 | INFO | train_inner | epoch 013:   1221 / 1474 loss=2.096, trans_loss=3.432, nll_loss=1.569, w2v_ctc_loss=0.567, task_loss=0.538, contrastive_loss=0, total=4110.35, n_correct=2560.15, ppl=2.97, accuracy=62.285, wps=14467.3, ups=1.18, wpb=12287.7, bsz=442.6, num_updates=18900, lr=0.000102869, gnorm=0.215, clip=0, loss_scale=64, train_wall=84, gb_free=15.1, wall=16212
2023-07-04 18:39:29 | INFO | train_inner | epoch 013:   1321 / 1474 loss=2.085, trans_loss=3.421, nll_loss=1.56, w2v_ctc_loss=0.56, task_loss=0.493, contrastive_loss=0, total=4112.2, n_correct=2575.82, ppl=2.95, accuracy=62.638, wps=14494.2, ups=1.18, wpb=12280.4, bsz=462.3, num_updates=19000, lr=0.000102598, gnorm=0.214, clip=0, loss_scale=64, train_wall=84, gb_free=17.7, wall=16297
2023-07-04 18:40:54 | INFO | train_inner | epoch 013:   1421 / 1474 loss=2.088, trans_loss=3.43, nll_loss=1.568, w2v_ctc_loss=0.558, task_loss=0.496, contrastive_loss=0, total=4180.88, n_correct=2604.31, ppl=2.96, accuracy=62.291, wps=14662.5, ups=1.18, wpb=12470.5, bsz=468.3, num_updates=19100, lr=0.000102329, gnorm=0.211, clip=0, loss_scale=64, train_wall=85, gb_free=15.5, wall=16382
2023-07-04 18:41:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 18:42:04 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 2.161 | trans_loss 5.597 | nll_loss 2.877 | w2v_ctc_loss 0.673 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2456.8 | ppl 7.35 | accuracy 61.368 | uer 16.941 | wer 18.732 | raw_wer 18.732 | bleu 19.78 | wps 2134.7 | wpb 4003.4 | bsz 141.8 | num_updates 19153 | best_bleu 19.78
2023-07-04 18:42:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19153 updates
2023-07-04 18:42:04 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 18:42:08 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 18:42:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt (epoch 13 @ 19153 updates, score 19.78) (writing took 8.51750690722838 seconds)
2023-07-04 18:42:13 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-07-04 18:42:13 | INFO | train | epoch 013 | loss 2.085 | trans_loss 3.422 | nll_loss 1.558 | w2v_ctc_loss 0.559 | task_loss 0.505 | contrastive_loss 0 | total 4138.62 | n_correct 2587.26 | ppl 2.94 | accuracy 62.515 | wps 13712.9 | ups 1.11 | wpb 12355.9 | bsz 458.6 | num_updates 19153 | lr 0.000102187 | gnorm 0.212 | clip 0 | loss_scale 64 | train_wall 1246 | gb_free 17.7 | wall 16461
2023-07-04 18:42:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 18:42:13 | INFO | fairseq.trainer | begin training epoch 14
2023-07-04 18:42:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 18:43:01 | INFO | train_inner | epoch 014:     47 / 1474 loss=2.069, trans_loss=3.401, nll_loss=1.532, w2v_ctc_loss=0.548, task_loss=0.459, contrastive_loss=0, total=4176.2, n_correct=2642.29, ppl=2.89, accuracy=63.27, wps=9853.2, ups=0.79, wpb=12486.4, bsz=483.4, num_updates=19200, lr=0.000102062, gnorm=0.208, clip=0, loss_scale=64, train_wall=84, gb_free=11.2, wall=16509
2023-07-04 18:44:26 | INFO | train_inner | epoch 014:    147 / 1474 loss=2.068, trans_loss=3.401, nll_loss=1.529, w2v_ctc_loss=0.546, task_loss=0.511, contrastive_loss=0, total=4080.86, n_correct=2592.94, ppl=2.88, accuracy=63.539, wps=14295.9, ups=1.17, wpb=12203.2, bsz=449.3, num_updates=19300, lr=0.000101797, gnorm=0.21, clip=0, loss_scale=64, train_wall=85, gb_free=17, wall=16594
2023-07-04 18:45:51 | INFO | train_inner | epoch 014:    247 / 1474 loss=2.071, trans_loss=3.414, nll_loss=1.545, w2v_ctc_loss=0.545, task_loss=0.534, contrastive_loss=0, total=4106.97, n_correct=2589.14, ppl=2.92, accuracy=63.043, wps=14355.8, ups=1.17, wpb=12224.4, bsz=440, num_updates=19400, lr=0.000101535, gnorm=0.211, clip=0, loss_scale=64, train_wall=85, gb_free=12.7, wall=16679
2023-07-04 18:47:16 | INFO | train_inner | epoch 014:    347 / 1474 loss=2.061, trans_loss=3.394, nll_loss=1.53, w2v_ctc_loss=0.544, task_loss=0.462, contrastive_loss=0, total=4179.8, n_correct=2647.1, ppl=2.89, accuracy=63.331, wps=14734.2, ups=1.18, wpb=12454.9, bsz=483.8, num_updates=19500, lr=0.000101274, gnorm=0.208, clip=0, loss_scale=64, train_wall=84, gb_free=17.4, wall=16764
2023-07-04 18:48:40 | INFO | train_inner | epoch 014:    447 / 1474 loss=2.072, trans_loss=3.41, nll_loss=1.543, w2v_ctc_loss=0.547, task_loss=0.522, contrastive_loss=0, total=4120.38, n_correct=2595.14, ppl=2.91, accuracy=62.983, wps=14507.1, ups=1.18, wpb=12283.1, bsz=444.5, num_updates=19600, lr=0.000101015, gnorm=0.212, clip=0, loss_scale=64, train_wall=84, gb_free=17.3, wall=16849
2023-07-04 18:50:06 | INFO | train_inner | epoch 014:    547 / 1474 loss=2.083, trans_loss=3.417, nll_loss=1.55, w2v_ctc_loss=0.557, task_loss=0.534, contrastive_loss=0, total=4089.86, n_correct=2569.64, ppl=2.93, accuracy=62.83, wps=14337.4, ups=1.17, wpb=12262.9, bsz=443.3, num_updates=19700, lr=0.000100759, gnorm=0.214, clip=0, loss_scale=64, train_wall=85, gb_free=12.4, wall=16934
2023-07-04 18:51:31 | INFO | train_inner | epoch 014:    647 / 1474 loss=2.073, trans_loss=3.412, nll_loss=1.546, w2v_ctc_loss=0.547, task_loss=0.503, contrastive_loss=0, total=4158.94, n_correct=2617.38, ppl=2.92, accuracy=62.934, wps=14532.8, ups=1.17, wpb=12415.4, bsz=460, num_updates=19800, lr=0.000100504, gnorm=0.211, clip=0, loss_scale=64, train_wall=85, gb_free=16.4, wall=17020
2023-07-04 18:52:56 | INFO | train_inner | epoch 014:    747 / 1474 loss=2.072, trans_loss=3.405, nll_loss=1.538, w2v_ctc_loss=0.548, task_loss=0.489, contrastive_loss=0, total=4150.03, n_correct=2624.23, ppl=2.9, accuracy=63.234, wps=14684.8, ups=1.18, wpb=12407.3, bsz=465.5, num_updates=19900, lr=0.000100251, gnorm=0.21, clip=0, loss_scale=64, train_wall=84, gb_free=15.7, wall=17104
2023-07-04 18:54:21 | INFO | train_inner | epoch 014:    847 / 1474 loss=2.065, trans_loss=3.401, nll_loss=1.536, w2v_ctc_loss=0.541, task_loss=0.48, contrastive_loss=0, total=4162.8, n_correct=2627.18, ppl=2.9, accuracy=63.111, wps=14596, ups=1.17, wpb=12422.9, bsz=475.8, num_updates=20000, lr=0.0001, gnorm=0.21, clip=0, loss_scale=64, train_wall=85, gb_free=17.2, wall=17189
2023-07-04 18:54:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 18:54:44 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 2.167 | trans_loss 5.599 | nll_loss 2.878 | w2v_ctc_loss 0.69 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2457.1 | ppl 7.35 | accuracy 61.375 | uer 17.004 | wer 18.851 | raw_wer 18.851 | bleu 19.53 | wps 2377.3 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.78
2023-07-04 18:54:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-07-04 18:54:44 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_14_20000.pt
2023-07-04 18:54:46 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_14_20000.pt
2023-07-04 18:54:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.53) (writing took 6.396656884346157 seconds)
tensor(0.0230, device='cuda:0')
tensor(0.0005, device='cuda:0')
2023-07-04 18:55:51 | INFO | train_inner | epoch 014:    947 / 1474 loss=1.416, trans_loss=5.36, nll_loss=2.704, w2v_ctc_loss=0.465, task_loss=1.486, contrastive_loss=0, total=4159.46, n_correct=2606.46, ppl=6.52, accuracy=62.663, wps=4705.6, ups=1.11, wpb=4251.9, bsz=158.1, num_updates=20100, lr=9.97509e-05, gnorm=0.337, clip=0, loss_scale=64, train_wall=60, gb_free=15.6, wall=17280
2023-07-04 18:56:52 | INFO | train_inner | epoch 014:   1047 / 1474 loss=1.405, trans_loss=5.429, nll_loss=2.749, w2v_ctc_loss=0.46, task_loss=1.517, contrastive_loss=0, total=4155.93, n_correct=2606.62, ppl=6.72, accuracy=62.72, wps=6863, ups=1.65, wpb=4155.9, bsz=153, num_updates=20200, lr=9.95037e-05, gnorm=0.333, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=17340
2023-07-04 18:57:52 | INFO | train_inner | epoch 014:   1147 / 1474 loss=1.41, trans_loss=5.433, nll_loss=2.754, w2v_ctc_loss=0.469, task_loss=1.432, contrastive_loss=0, total=4228.09, n_correct=2649.68, ppl=6.75, accuracy=62.668, wps=7009.3, ups=1.66, wpb=4228.1, bsz=163.2, num_updates=20300, lr=9.92583e-05, gnorm=0.334, clip=0, loss_scale=64, train_wall=60, gb_free=17.7, wall=17400
2023-07-04 18:58:52 | INFO | train_inner | epoch 014:   1247 / 1474 loss=1.411, trans_loss=5.447, nll_loss=2.77, w2v_ctc_loss=0.472, task_loss=1.77, contrastive_loss=0, total=4027.71, n_correct=2512.82, ppl=6.82, accuracy=62.388, wps=6771.9, ups=1.68, wpb=4027.7, bsz=136.8, num_updates=20400, lr=9.90148e-05, gnorm=0.344, clip=0, loss_scale=128, train_wall=59, gb_free=17, wall=17460
2023-07-04 18:59:51 | INFO | train_inner | epoch 014:   1347 / 1474 loss=1.403, trans_loss=5.422, nll_loss=2.74, w2v_ctc_loss=0.458, task_loss=1.448, contrastive_loss=0, total=4198.71, n_correct=2639.28, ppl=6.68, accuracy=62.859, wps=7060.3, ups=1.68, wpb=4198.7, bsz=157.7, num_updates=20500, lr=9.8773e-05, gnorm=0.335, clip=0, loss_scale=128, train_wall=59, gb_free=16.9, wall=17519
2023-07-04 19:00:51 | INFO | train_inner | epoch 014:   1447 / 1474 loss=1.406, trans_loss=5.434, nll_loss=2.756, w2v_ctc_loss=0.463, task_loss=1.494, contrastive_loss=0, total=4140.5, n_correct=2597.26, ppl=6.76, accuracy=62.728, wps=6936.2, ups=1.68, wpb=4140.5, bsz=153.5, num_updates=20600, lr=9.85329e-05, gnorm=0.336, clip=0, loss_scale=128, train_wall=59, gb_free=17.7, wall=17579
2023-07-04 19:01:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0230, device='cuda:5')
tensor(0.0005, device='cuda:5')
tensor(0.0230, device='cuda:4')
tensor(0.0005, device='cuda:4')
tensor(0.0230, device='cuda:6')
tensor(0.0005, device='cuda:6')
tensor(0.0230, device='cuda:3')
tensor(0.0005, device='cuda:3')
tensor(0.0230, device='cuda:7')
tensor(0.0005, device='cuda:7')
tensor(0.0230, device='cuda:1')
tensor(0.0005, device='cuda:1')
tensor(0.0230, device='cuda:2')
tensor(0.0005, device='cuda:2')
2023-07-04 19:01:31 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 2.165 | trans_loss 5.589 | nll_loss 2.869 | w2v_ctc_loss 0.696 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2460.3 | ppl 7.31 | accuracy 61.455 | uer 17.039 | wer 18.724 | raw_wer 18.724 | bleu 19.51 | wps 2432.3 | wpb 4003.4 | bsz 141.8 | num_updates 20627 | best_bleu 19.78
2023-07-04 19:01:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20627 updates
2023-07-04 19:01:31 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_19.5103.pt
2023-07-04 19:01:33 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_19.5103.pt
2023-07-04 19:01:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_19.5103.pt (epoch 14 @ 20627 updates, score 19.51) (writing took 5.8067614561878145 seconds)
2023-07-04 19:01:37 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-07-04 19:01:37 | INFO | train | epoch 014 | loss 1.865 | trans_loss 3.808 | nll_loss 1.779 | w2v_ctc_loss 0.521 | task_loss 0.703 | contrastive_loss 0 | total 4138.65 | n_correct 2605.19 | ppl 3.43 | accuracy 62.948 | wps 11220.8 | ups 1.27 | wpb 8862.4 | bsz 329.2 | num_updates 20627 | lr 9.84684e-05 | gnorm 0.264 | clip 0 | loss_scale 128 | train_wall 1090 | gb_free 16.6 | wall 17625
2023-07-04 19:01:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 19:01:37 | INFO | fairseq.trainer | begin training epoch 15
2023-07-04 19:01:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 19:02:28 | INFO | train_inner | epoch 015:     73 / 1474 loss=1.395, trans_loss=5.397, nll_loss=2.707, w2v_ctc_loss=0.451, task_loss=1.519, contrastive_loss=0, total=4083.93, n_correct=2580.99, ppl=6.53, accuracy=63.199, wps=4201.2, ups=1.03, wpb=4083.9, bsz=150, num_updates=20700, lr=9.82946e-05, gnorm=0.337, clip=0, loss_scale=128, train_wall=59, gb_free=15.8, wall=17676
2023-07-04 19:03:28 | INFO | train_inner | epoch 015:    173 / 1474 loss=1.395, trans_loss=5.388, nll_loss=2.694, w2v_ctc_loss=0.459, task_loss=1.572, contrastive_loss=0, total=4122.67, n_correct=2613.52, ppl=6.47, accuracy=63.394, wps=6868.6, ups=1.67, wpb=4122.7, bsz=149.6, num_updates=20800, lr=9.80581e-05, gnorm=0.336, clip=0, loss_scale=128, train_wall=60, gb_free=17.3, wall=17736
2023-07-04 19:04:28 | INFO | train_inner | epoch 015:    273 / 1474 loss=1.392, trans_loss=5.381, nll_loss=2.686, w2v_ctc_loss=0.453, task_loss=1.452, contrastive_loss=0, total=4190.11, n_correct=2664.08, ppl=6.44, accuracy=63.58, wps=7046.1, ups=1.68, wpb=4190.1, bsz=156.3, num_updates=20900, lr=9.78232e-05, gnorm=0.329, clip=0, loss_scale=128, train_wall=59, gb_free=17.3, wall=17796
2023-07-04 19:05:27 | INFO | train_inner | epoch 015:    373 / 1474 loss=1.394, trans_loss=5.382, nll_loss=2.685, w2v_ctc_loss=0.453, task_loss=1.565, contrastive_loss=0, total=4150.33, n_correct=2632.89, ppl=6.43, accuracy=63.438, wps=6947, ups=1.67, wpb=4150.3, bsz=150.5, num_updates=21000, lr=9.759e-05, gnorm=0.337, clip=0, loss_scale=128, train_wall=59, gb_free=15.7, wall=17856
2023-07-04 19:06:27 | INFO | train_inner | epoch 015:    473 / 1474 loss=1.395, trans_loss=5.397, nll_loss=2.706, w2v_ctc_loss=0.453, task_loss=1.555, contrastive_loss=0, total=4082.7, n_correct=2581.81, ppl=6.52, accuracy=63.238, wps=6848.4, ups=1.68, wpb=4082.7, bsz=149.2, num_updates=21100, lr=9.73585e-05, gnorm=0.335, clip=0, loss_scale=128, train_wall=59, gb_free=17.3, wall=17915
2023-07-04 19:07:27 | INFO | train_inner | epoch 015:    573 / 1474 loss=1.399, trans_loss=5.401, nll_loss=2.712, w2v_ctc_loss=0.465, task_loss=1.604, contrastive_loss=0, total=4130.96, n_correct=2604.61, ppl=6.55, accuracy=63.051, wps=6871, ups=1.66, wpb=4131, bsz=146.7, num_updates=21200, lr=9.71286e-05, gnorm=0.339, clip=0, loss_scale=128, train_wall=60, gb_free=17.4, wall=17975
2023-07-04 19:08:27 | INFO | train_inner | epoch 015:    673 / 1474 loss=1.394, trans_loss=5.392, nll_loss=2.701, w2v_ctc_loss=0.459, task_loss=1.501, contrastive_loss=0, total=4138.41, n_correct=2622.2, ppl=6.5, accuracy=63.362, wps=6913, ups=1.67, wpb=4138.4, bsz=154.7, num_updates=21300, lr=9.69003e-05, gnorm=0.336, clip=0, loss_scale=128, train_wall=59, gb_free=17.1, wall=18035
2023-07-04 19:09:28 | INFO | train_inner | epoch 015:    773 / 1474 loss=1.402, trans_loss=5.402, nll_loss=2.714, w2v_ctc_loss=0.463, task_loss=1.523, contrastive_loss=0, total=4186.48, n_correct=2638.33, ppl=6.56, accuracy=63.02, wps=6885.9, ups=1.64, wpb=4186.5, bsz=153.9, num_updates=21400, lr=9.66736e-05, gnorm=0.338, clip=0, loss_scale=128, train_wall=60, gb_free=16.9, wall=18096
2023-07-04 19:10:28 | INFO | train_inner | epoch 015:    873 / 1474 loss=1.396, trans_loss=5.403, nll_loss=2.716, w2v_ctc_loss=0.46, task_loss=1.645, contrastive_loss=0, total=4054.09, n_correct=2555.45, ppl=6.57, accuracy=63.034, wps=6781, ups=1.67, wpb=4054.1, bsz=143.1, num_updates=21500, lr=9.64486e-05, gnorm=0.342, clip=0, loss_scale=128, train_wall=59, gb_free=16, wall=18156
2023-07-04 19:11:27 | INFO | train_inner | epoch 015:    973 / 1474 loss=1.399, trans_loss=5.397, nll_loss=2.708, w2v_ctc_loss=0.456, task_loss=1.511, contrastive_loss=0, total=4126.63, n_correct=2607.44, ppl=6.53, accuracy=63.186, wps=6945.1, ups=1.68, wpb=4126.6, bsz=151.5, num_updates=21600, lr=9.6225e-05, gnorm=0.336, clip=0, loss_scale=128, train_wall=59, gb_free=17, wall=18215
2023-07-04 19:12:28 | INFO | train_inner | epoch 015:   1073 / 1474 loss=1.398, trans_loss=5.402, nll_loss=2.716, w2v_ctc_loss=0.456, task_loss=1.404, contrastive_loss=0, total=4199.33, n_correct=2650.02, ppl=6.57, accuracy=63.106, wps=6929.2, ups=1.65, wpb=4199.3, bsz=163.6, num_updates=21700, lr=9.60031e-05, gnorm=0.334, clip=0, loss_scale=128, train_wall=60, gb_free=11.9, wall=18276
2023-07-04 19:13:27 | INFO | train_inner | epoch 015:   1173 / 1474 loss=1.392, trans_loss=5.387, nll_loss=2.698, w2v_ctc_loss=0.451, task_loss=1.371, contrastive_loss=0, total=4172.81, n_correct=2645.23, ppl=6.49, accuracy=63.392, wps=7044.3, ups=1.69, wpb=4172.8, bsz=163.2, num_updates=21800, lr=9.57826e-05, gnorm=0.332, clip=0, loss_scale=128, train_wall=59, gb_free=13.2, wall=18335
2023-07-04 19:14:27 | INFO | train_inner | epoch 015:   1273 / 1474 loss=1.398, trans_loss=5.398, nll_loss=2.71, w2v_ctc_loss=0.464, task_loss=1.539, contrastive_loss=0, total=4152.76, n_correct=2622.06, ppl=6.54, accuracy=63.14, wps=6943.6, ups=1.67, wpb=4152.8, bsz=152.3, num_updates=21900, lr=9.55637e-05, gnorm=0.34, clip=0, loss_scale=128, train_wall=59, gb_free=16.8, wall=18395
2023-07-04 19:15:26 | INFO | train_inner | epoch 015:   1373 / 1474 loss=1.396, trans_loss=5.396, nll_loss=2.706, w2v_ctc_loss=0.459, task_loss=1.57, contrastive_loss=0, total=4107.77, n_correct=2596.23, ppl=6.53, accuracy=63.203, wps=6883.3, ups=1.68, wpb=4107.8, bsz=147, num_updates=22000, lr=9.53463e-05, gnorm=0.336, clip=0, loss_scale=128, train_wall=59, gb_free=15.5, wall=18455
2023-07-04 19:15:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 19:15:51 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 2.157 | trans_loss 5.593 | nll_loss 2.868 | w2v_ctc_loss 0.666 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2465.4 | ppl 7.3 | accuracy 61.583 | uer 17.002 | wer 18.765 | raw_wer 18.765 | bleu 19.59 | wps 2281.9 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 19.78
2023-07-04 19:15:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-07-04 19:15:51 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_15_22000.pt
2023-07-04 19:15:53 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_15_22000.pt
2023-07-04 19:15:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.59) (writing took 7.0969960619695485 seconds)
2023-07-04 19:17:00 | INFO | train_inner | epoch 015:   1473 / 1474 loss=1.397, trans_loss=5.407, nll_loss=2.724, w2v_ctc_loss=0.459, task_loss=1.474, contrastive_loss=0, total=4157.38, n_correct=2622.35, ppl=6.61, accuracy=63.077, wps=4463.3, ups=1.07, wpb=4157.4, bsz=157.4, num_updates=22100, lr=9.51303e-05, gnorm=0.335, clip=0, loss_scale=128, train_wall=61, gb_free=17.4, wall=18548
2023-07-04 19:17:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 19:17:26 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 2.161 | trans_loss 5.585 | nll_loss 2.869 | w2v_ctc_loss 0.686 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2466.5 | ppl 7.31 | accuracy 61.61 | uer 17.079 | wer 18.94 | raw_wer 18.94 | bleu 19.66 | wps 2211.8 | wpb 4003.4 | bsz 141.8 | num_updates 22101 | best_bleu 19.78
2023-07-04 19:17:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22101 updates
2023-07-04 19:17:26 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_19.6603.pt
2023-07-04 19:17:28 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_19.6603.pt
2023-07-04 19:17:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_19.6603.pt (epoch 15 @ 22101 updates, score 19.66) (writing took 5.360940402839333 seconds)
2023-07-04 19:17:31 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-07-04 19:17:31 | INFO | train | epoch 015 | loss 1.396 | trans_loss 5.394 | nll_loss 2.704 | w2v_ctc_loss 0.457 | task_loss 1.515 | contrastive_loss 0 | total 4138.65 | n_correct 2617.57 | ppl 6.52 | accuracy 63.247 | wps 6390.1 | ups 1.54 | wpb 4138.6 | bsz 152.8 | num_updates 22101 | lr 9.51281e-05 | gnorm 0.336 | clip 0 | loss_scale 128 | train_wall 876 | gb_free 17.2 | wall 18580
2023-07-04 19:17:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 19:17:32 | INFO | fairseq.trainer | begin training epoch 16
2023-07-04 19:17:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 19:18:39 | INFO | train_inner | epoch 016:     99 / 1474 loss=1.381, trans_loss=5.344, nll_loss=2.64, w2v_ctc_loss=0.448, task_loss=1.433, contrastive_loss=0, total=4113.74, n_correct=2635.1, ppl=6.23, accuracy=64.056, wps=4149.7, ups=1.01, wpb=4113.7, bsz=158, num_updates=22200, lr=9.49158e-05, gnorm=0.336, clip=0, loss_scale=128, train_wall=59, gb_free=17.7, wall=18647
2023-07-04 19:19:38 | INFO | train_inner | epoch 016:    199 / 1474 loss=1.377, trans_loss=5.347, nll_loss=2.643, w2v_ctc_loss=0.439, task_loss=1.562, contrastive_loss=0, total=4091.27, n_correct=2620.57, ppl=6.25, accuracy=64.053, wps=6836, ups=1.67, wpb=4091.3, bsz=147.2, num_updates=22300, lr=9.47027e-05, gnorm=0.333, clip=0, loss_scale=128, train_wall=59, gb_free=15, wall=18707
2023-07-04 19:20:38 | INFO | train_inner | epoch 016:    299 / 1474 loss=1.395, trans_loss=5.372, nll_loss=2.677, w2v_ctc_loss=0.459, task_loss=1.502, contrastive_loss=0, total=4169, n_correct=2654.11, ppl=6.4, accuracy=63.663, wps=6962.3, ups=1.67, wpb=4169, bsz=154.8, num_updates=22400, lr=9.44911e-05, gnorm=0.338, clip=0, loss_scale=256, train_wall=59, gb_free=13.1, wall=18767
2023-07-04 19:20:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-07-04 19:21:38 | INFO | train_inner | epoch 016:    400 / 1474 loss=1.388, trans_loss=5.369, nll_loss=2.671, w2v_ctc_loss=0.456, task_loss=1.621, contrastive_loss=0, total=4073.51, n_correct=2590.8, ppl=6.37, accuracy=63.601, wps=6791, ups=1.67, wpb=4073.5, bsz=143.2, num_updates=22500, lr=9.42809e-05, gnorm=0.34, clip=0, loss_scale=128, train_wall=60, gb_free=17.2, wall=18827
2023-07-04 19:22:39 | INFO | train_inner | epoch 016:    500 / 1474 loss=1.388, trans_loss=5.361, nll_loss=2.664, w2v_ctc_loss=0.452, task_loss=1.458, contrastive_loss=0, total=4174.67, n_correct=2664.43, ppl=6.34, accuracy=63.824, wps=6905, ups=1.65, wpb=4174.7, bsz=159.5, num_updates=22600, lr=9.40721e-05, gnorm=0.335, clip=0, loss_scale=128, train_wall=60, gb_free=16.2, wall=18887
2023-07-04 19:23:38 | INFO | train_inner | epoch 016:    600 / 1474 loss=1.386, trans_loss=5.361, nll_loss=2.661, w2v_ctc_loss=0.449, task_loss=1.538, contrastive_loss=0, total=4124.65, n_correct=2633.12, ppl=6.33, accuracy=63.839, wps=6931.9, ups=1.68, wpb=4124.6, bsz=148.8, num_updates=22700, lr=9.38647e-05, gnorm=0.339, clip=0, loss_scale=128, train_wall=59, gb_free=16.4, wall=18947
2023-07-04 19:24:38 | INFO | train_inner | epoch 016:    700 / 1474 loss=1.39, trans_loss=5.371, nll_loss=2.674, w2v_ctc_loss=0.455, task_loss=1.558, contrastive_loss=0, total=4095.49, n_correct=2605.14, ppl=6.38, accuracy=63.61, wps=6888.1, ups=1.68, wpb=4095.5, bsz=148.2, num_updates=22800, lr=9.36586e-05, gnorm=0.34, clip=0, loss_scale=128, train_wall=59, gb_free=16.4, wall=19006
2023-07-04 19:25:38 | INFO | train_inner | epoch 016:    800 / 1474 loss=1.385, trans_loss=5.366, nll_loss=2.669, w2v_ctc_loss=0.447, task_loss=1.45, contrastive_loss=0, total=4174.94, n_correct=2656.58, ppl=6.36, accuracy=63.632, wps=6976.6, ups=1.67, wpb=4174.9, bsz=155.4, num_updates=22900, lr=9.34539e-05, gnorm=0.332, clip=0, loss_scale=128, train_wall=59, gb_free=16.6, wall=19066
2023-07-04 19:26:37 | INFO | train_inner | epoch 016:    900 / 1474 loss=1.385, trans_loss=5.36, nll_loss=2.663, w2v_ctc_loss=0.448, task_loss=1.468, contrastive_loss=0, total=4163.19, n_correct=2655.73, ppl=6.33, accuracy=63.791, wps=7016.9, ups=1.69, wpb=4163.2, bsz=155.3, num_updates=23000, lr=9.32505e-05, gnorm=0.333, clip=0, loss_scale=128, train_wall=59, gb_free=17.1, wall=19125
2023-07-04 19:27:37 | INFO | train_inner | epoch 016:   1000 / 1474 loss=1.392, trans_loss=5.382, nll_loss=2.689, w2v_ctc_loss=0.458, task_loss=1.579, contrastive_loss=0, total=4103.45, n_correct=2603.45, ppl=6.45, accuracy=63.445, wps=6804, ups=1.66, wpb=4103.4, bsz=149, num_updates=23100, lr=9.30484e-05, gnorm=0.336, clip=0, loss_scale=128, train_wall=60, gb_free=15.1, wall=19186
2023-07-04 19:28:37 | INFO | train_inner | epoch 016:   1100 / 1474 loss=1.393, trans_loss=5.386, nll_loss=2.696, w2v_ctc_loss=0.461, task_loss=1.618, contrastive_loss=0, total=4119.27, n_correct=2608.53, ppl=6.48, accuracy=63.325, wps=6870.2, ups=1.67, wpb=4119.3, bsz=147.7, num_updates=23200, lr=9.28477e-05, gnorm=0.339, clip=0, loss_scale=128, train_wall=60, gb_free=17.9, wall=19245
2023-07-04 19:29:38 | INFO | train_inner | epoch 016:   1200 / 1474 loss=1.391, trans_loss=5.38, nll_loss=2.688, w2v_ctc_loss=0.45, task_loss=1.53, contrastive_loss=0, total=4165.11, n_correct=2640.61, ppl=6.45, accuracy=63.398, wps=6882.1, ups=1.65, wpb=4165.1, bsz=154.3, num_updates=23300, lr=9.26482e-05, gnorm=0.336, clip=0, loss_scale=128, train_wall=60, gb_free=17, wall=19306
2023-07-04 19:30:38 | INFO | train_inner | epoch 016:   1300 / 1474 loss=1.394, trans_loss=5.385, nll_loss=2.695, w2v_ctc_loss=0.46, task_loss=1.488, contrastive_loss=0, total=4134.61, n_correct=2622.47, ppl=6.47, accuracy=63.427, wps=6881.8, ups=1.66, wpb=4134.6, bsz=155.4, num_updates=23400, lr=9.245e-05, gnorm=0.336, clip=0, loss_scale=128, train_wall=60, gb_free=17, wall=19366
2023-07-04 19:31:38 | INFO | train_inner | epoch 016:   1400 / 1474 loss=1.393, trans_loss=5.375, nll_loss=2.683, w2v_ctc_loss=0.457, task_loss=1.441, contrastive_loss=0, total=4206.33, n_correct=2672.23, ppl=6.42, accuracy=63.529, wps=6968.4, ups=1.66, wpb=4206.3, bsz=161.1, num_updates=23500, lr=9.22531e-05, gnorm=0.334, clip=0, loss_scale=128, train_wall=60, gb_free=15.7, wall=19426
2023-07-04 19:32:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 19:32:47 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 2.159 | trans_loss 5.58 | nll_loss 2.86 | w2v_ctc_loss 0.685 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2464.1 | ppl 7.26 | accuracy 61.55 | uer 16.895 | wer 18.586 | raw_wer 18.586 | bleu 19.64 | wps 2339.5 | wpb 4003.4 | bsz 141.8 | num_updates 23574 | best_bleu 19.78
2023-07-04 19:32:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23574 updates
2023-07-04 19:32:47 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_19.6407.pt
2023-07-04 19:32:49 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_19.6407.pt
2023-07-04 19:32:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_19.6407.pt (epoch 16 @ 23574 updates, score 19.64) (writing took 5.489389697089791 seconds)
2023-07-04 19:32:52 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-07-04 19:32:52 | INFO | train | epoch 016 | loss 1.389 | trans_loss 5.369 | nll_loss 2.673 | w2v_ctc_loss 0.453 | task_loss 1.516 | contrastive_loss 0 | total 4138.61 | n_correct 2634.18 | ppl 6.38 | accuracy 63.649 | wps 6620.2 | ups 1.6 | wpb 4138.6 | bsz 152.8 | num_updates 23574 | lr 9.21082e-05 | gnorm 0.336 | clip 0 | loss_scale 128 | train_wall 876 | gb_free 15.6 | wall 19501
2023-07-04 19:32:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 19:32:53 | INFO | fairseq.trainer | begin training epoch 17
2023-07-04 19:32:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 19:33:17 | INFO | train_inner | epoch 017:     26 / 1474 loss=1.388, trans_loss=5.36, nll_loss=2.663, w2v_ctc_loss=0.451, task_loss=1.532, contrastive_loss=0, total=4152.31, n_correct=2650.96, ppl=6.33, accuracy=63.843, wps=4225.2, ups=1.02, wpb=4152.3, bsz=152.3, num_updates=23600, lr=9.20575e-05, gnorm=0.338, clip=0, loss_scale=128, train_wall=60, gb_free=14.2, wall=19525
2023-07-04 19:34:16 | INFO | train_inner | epoch 017:    126 / 1474 loss=1.382, trans_loss=5.337, nll_loss=2.631, w2v_ctc_loss=0.453, task_loss=1.571, contrastive_loss=0, total=4118.91, n_correct=2642.13, ppl=6.19, accuracy=64.146, wps=6916.6, ups=1.68, wpb=4118.9, bsz=147.9, num_updates=23700, lr=9.1863e-05, gnorm=0.333, clip=0, loss_scale=128, train_wall=59, gb_free=16.6, wall=19584
2023-07-04 19:35:16 | INFO | train_inner | epoch 017:    226 / 1474 loss=1.38, trans_loss=5.339, nll_loss=2.635, w2v_ctc_loss=0.444, task_loss=1.445, contrastive_loss=0, total=4145.15, n_correct=2659.29, ppl=6.21, accuracy=64.154, wps=6932.2, ups=1.67, wpb=4145.1, bsz=157.5, num_updates=23800, lr=9.16698e-05, gnorm=0.335, clip=0, loss_scale=128, train_wall=59, gb_free=15.8, wall=19644
2023-07-04 19:36:15 | INFO | train_inner | epoch 017:    326 / 1474 loss=1.381, trans_loss=5.337, nll_loss=2.631, w2v_ctc_loss=0.445, task_loss=1.494, contrastive_loss=0, total=4169.51, n_correct=2674.89, ppl=6.2, accuracy=64.154, wps=7006.2, ups=1.68, wpb=4169.5, bsz=154.1, num_updates=23900, lr=9.14779e-05, gnorm=0.332, clip=0, loss_scale=128, train_wall=59, gb_free=17, wall=19704
2023-07-04 19:37:15 | INFO | train_inner | epoch 017:    426 / 1474 loss=1.378, trans_loss=5.34, nll_loss=2.636, w2v_ctc_loss=0.449, task_loss=1.501, contrastive_loss=0, total=4140.49, n_correct=2659.22, ppl=6.22, accuracy=64.225, wps=6902.6, ups=1.67, wpb=4140.5, bsz=153.4, num_updates=24000, lr=9.12871e-05, gnorm=0.334, clip=0, loss_scale=128, train_wall=60, gb_free=17.1, wall=19764
2023-07-04 19:37:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 19:37:39 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 2.162 | trans_loss 5.579 | nll_loss 2.855 | w2v_ctc_loss 0.698 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2463.7 | ppl 7.24 | accuracy 61.54 | uer 17.052 | wer 18.94 | raw_wer 18.94 | bleu 20.02 | wps 2383.8 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 20.02
2023-07-04 19:37:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-07-04 19:37:39 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_17_24000.pt
2023-07-04 19:37:41 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_17_24000.pt
2023-07-04 19:37:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 20.02) (writing took 9.999416762962937 seconds)
2023-07-04 19:38:50 | INFO | train_inner | epoch 017:    526 / 1474 loss=1.386, trans_loss=5.349, nll_loss=2.647, w2v_ctc_loss=0.454, task_loss=1.59, contrastive_loss=0, total=4184.16, n_correct=2675.58, ppl=6.27, accuracy=63.945, wps=4402.5, ups=1.05, wpb=4184.2, bsz=153.5, num_updates=24100, lr=9.10975e-05, gnorm=0.331, clip=0, loss_scale=128, train_wall=61, gb_free=17.4, wall=19859
2023-07-04 19:39:51 | INFO | train_inner | epoch 017:    626 / 1474 loss=1.382, trans_loss=5.342, nll_loss=2.639, w2v_ctc_loss=0.447, task_loss=1.513, contrastive_loss=0, total=4166.61, n_correct=2671.08, ppl=6.23, accuracy=64.107, wps=6923.4, ups=1.66, wpb=4166.6, bsz=151.7, num_updates=24200, lr=9.09091e-05, gnorm=0.331, clip=0, loss_scale=128, train_wall=60, gb_free=17.1, wall=19919
2023-07-04 19:40:51 | INFO | train_inner | epoch 017:    726 / 1474 loss=1.389, trans_loss=5.361, nll_loss=2.664, w2v_ctc_loss=0.459, task_loss=1.503, contrastive_loss=0, total=4167.85, n_correct=2662.35, ppl=6.34, accuracy=63.878, wps=6901.7, ups=1.66, wpb=4167.9, bsz=154.2, num_updates=24300, lr=9.07218e-05, gnorm=0.337, clip=0, loss_scale=128, train_wall=60, gb_free=15.4, wall=19979
2023-07-04 19:41:50 | INFO | train_inner | epoch 017:    826 / 1474 loss=1.384, trans_loss=5.351, nll_loss=2.65, w2v_ctc_loss=0.452, task_loss=1.526, contrastive_loss=0, total=4093.22, n_correct=2618.06, ppl=6.28, accuracy=63.961, wps=6902.1, ups=1.69, wpb=4093.2, bsz=148.2, num_updates=24400, lr=9.05357e-05, gnorm=0.339, clip=0, loss_scale=128, train_wall=59, gb_free=16.5, wall=20039
2023-07-04 19:42:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-07-04 19:42:50 | INFO | train_inner | epoch 017:    927 / 1474 loss=1.381, trans_loss=5.344, nll_loss=2.641, w2v_ctc_loss=0.444, task_loss=1.495, contrastive_loss=0, total=4104.85, n_correct=2629.61, ppl=6.24, accuracy=64.061, wps=6877.1, ups=1.68, wpb=4104.9, bsz=152.1, num_updates=24500, lr=9.03508e-05, gnorm=0.338, clip=0, loss_scale=128, train_wall=59, gb_free=16, wall=20098
2023-07-04 19:43:49 | INFO | train_inner | epoch 017:   1027 / 1474 loss=1.382, trans_loss=5.343, nll_loss=2.641, w2v_ctc_loss=0.45, task_loss=1.49, contrastive_loss=0, total=4115.49, n_correct=2635.12, ppl=6.24, accuracy=64.029, wps=6936, ups=1.69, wpb=4115.5, bsz=152.9, num_updates=24600, lr=9.0167e-05, gnorm=0.334, clip=0, loss_scale=128, train_wall=59, gb_free=16.8, wall=20158
2023-07-04 19:44:48 | INFO | train_inner | epoch 017:   1127 / 1474 loss=1.379, trans_loss=5.344, nll_loss=2.642, w2v_ctc_loss=0.444, task_loss=1.576, contrastive_loss=0, total=4078.39, n_correct=2610.3, ppl=6.24, accuracy=64.003, wps=6922.4, ups=1.7, wpb=4078.4, bsz=146.9, num_updates=24700, lr=8.99843e-05, gnorm=0.336, clip=0, loss_scale=128, train_wall=58, gb_free=15.8, wall=20217
2023-07-04 19:45:49 | INFO | train_inner | epoch 017:   1227 / 1474 loss=1.389, trans_loss=5.374, nll_loss=2.683, w2v_ctc_loss=0.452, task_loss=1.467, contrastive_loss=0, total=4173.49, n_correct=2652.24, ppl=6.42, accuracy=63.55, wps=6928.7, ups=1.66, wpb=4173.5, bsz=161.9, num_updates=24800, lr=8.98027e-05, gnorm=0.339, clip=0, loss_scale=128, train_wall=60, gb_free=16.3, wall=20277
2023-07-04 19:46:49 | INFO | train_inner | epoch 017:   1327 / 1474 loss=1.385, trans_loss=5.356, nll_loss=2.658, w2v_ctc_loss=0.445, task_loss=1.504, contrastive_loss=0, total=4156.28, n_correct=2653.03, ppl=6.31, accuracy=63.832, wps=6926.3, ups=1.67, wpb=4156.3, bsz=154, num_updates=24900, lr=8.96221e-05, gnorm=0.337, clip=0, loss_scale=128, train_wall=60, gb_free=17.9, wall=20337
2023-07-04 19:47:49 | INFO | train_inner | epoch 017:   1427 / 1474 loss=1.378, trans_loss=5.352, nll_loss=2.653, w2v_ctc_loss=0.445, task_loss=1.524, contrastive_loss=0, total=4112.95, n_correct=2629.53, ppl=6.29, accuracy=63.933, wps=6783.7, ups=1.65, wpb=4112.9, bsz=151.6, num_updates=25000, lr=8.94427e-05, gnorm=0.332, clip=0, loss_scale=128, train_wall=60, gb_free=17, wall=20397
tensor(0.0230, device='cuda:0')
tensor(0.0005, device='cuda:0')
2023-07-04 19:48:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0230, device='cuda:6')
tensor(0.0005, device='cuda:6')
tensor(0.0230, device='cuda:2')
tensor(0.0005, device='cuda:2')
tensor(0.0230, device='cuda:7')
tensor(0.0005, device='cuda:7')
tensor(0.0230, device='cuda:4')
tensor(0.0005, device='cuda:4')
tensor(0.0230, device='cuda:3')
tensor(0.0005, device='cuda:3')
tensor(0.0230, device='cuda:5')
tensor(0.0005, device='cuda:5')
tensor(0.0230, device='cuda:1')
tensor(0.0005, device='cuda:1')
2023-07-04 19:48:42 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 2.149 | trans_loss 5.571 | nll_loss 2.847 | w2v_ctc_loss 0.663 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2470.5 | ppl 7.19 | accuracy 61.71 | uer 16.686 | wer 18.478 | raw_wer 18.478 | bleu 19.88 | wps 2198.6 | wpb 4003.4 | bsz 141.8 | num_updates 25047 | best_bleu 20.02
2023-07-04 19:48:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25047 updates
2023-07-04 19:48:42 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_19.8806.pt
2023-07-04 19:48:44 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_19.8806.pt
2023-07-04 19:48:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_19.8806.pt (epoch 17 @ 25047 updates, score 19.88) (writing took 5.487379989121109 seconds)
2023-07-04 19:48:48 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-07-04 19:48:48 | INFO | train | epoch 017 | loss 1.382 | trans_loss 5.347 | nll_loss 2.646 | w2v_ctc_loss 0.449 | task_loss 1.514 | contrastive_loss 0 | total 4138.7 | n_correct 2649.05 | ppl 6.26 | accuracy 64.007 | wps 6379.3 | ups 1.54 | wpb 4138.7 | bsz 152.9 | num_updates 25047 | lr 8.93588e-05 | gnorm 0.335 | clip 0 | loss_scale 128 | train_wall 876 | gb_free 16.6 | wall 20456
2023-07-04 19:48:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 19:48:48 | INFO | fairseq.trainer | begin training epoch 18
2023-07-04 19:48:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 19:49:29 | INFO | train_inner | epoch 018:     53 / 1474 loss=1.38, trans_loss=5.335, nll_loss=2.63, w2v_ctc_loss=0.45, task_loss=1.546, contrastive_loss=0, total=4139.04, n_correct=2656.01, ppl=6.19, accuracy=64.17, wps=4165.8, ups=1.01, wpb=4139, bsz=151.7, num_updates=25100, lr=8.92644e-05, gnorm=0.339, clip=0, loss_scale=128, train_wall=60, gb_free=17.3, wall=20497
2023-07-04 19:50:28 | INFO | train_inner | epoch 018:    153 / 1474 loss=1.369, trans_loss=5.308, nll_loss=2.594, w2v_ctc_loss=0.431, task_loss=1.445, contrastive_loss=0, total=4154.85, n_correct=2686.09, ppl=6.04, accuracy=64.65, wps=6939, ups=1.67, wpb=4154.9, bsz=156.4, num_updates=25200, lr=8.90871e-05, gnorm=0.336, clip=0, loss_scale=128, train_wall=59, gb_free=16.9, wall=20557
2023-07-04 19:51:29 | INFO | train_inner | epoch 018:    253 / 1474 loss=1.372, trans_loss=5.306, nll_loss=2.592, w2v_ctc_loss=0.442, task_loss=1.47, contrastive_loss=0, total=4162.72, n_correct=2697.52, ppl=6.03, accuracy=64.802, wps=6915.8, ups=1.66, wpb=4162.7, bsz=156.5, num_updates=25300, lr=8.89108e-05, gnorm=0.332, clip=0, loss_scale=128, train_wall=60, gb_free=16.4, wall=20617
2023-07-04 19:52:29 | INFO | train_inner | epoch 018:    353 / 1474 loss=1.373, trans_loss=5.318, nll_loss=2.607, w2v_ctc_loss=0.441, task_loss=1.544, contrastive_loss=0, total=4161.22, n_correct=2678.9, ppl=6.09, accuracy=64.378, wps=6931.6, ups=1.67, wpb=4161.2, bsz=150.7, num_updates=25400, lr=8.87357e-05, gnorm=0.334, clip=0, loss_scale=128, train_wall=60, gb_free=14.6, wall=20677
2023-07-04 19:53:30 | INFO | train_inner | epoch 018:    453 / 1474 loss=1.376, trans_loss=5.334, nll_loss=2.628, w2v_ctc_loss=0.444, task_loss=1.61, contrastive_loss=0, total=4092.36, n_correct=2630.5, ppl=6.18, accuracy=64.278, wps=6686.2, ups=1.63, wpb=4092.4, bsz=147.7, num_updates=25500, lr=8.85615e-05, gnorm=0.336, clip=0, loss_scale=128, train_wall=61, gb_free=16.9, wall=20738
2023-07-04 19:54:30 | INFO | train_inner | epoch 018:    553 / 1474 loss=1.369, trans_loss=5.307, nll_loss=2.596, w2v_ctc_loss=0.438, task_loss=1.358, contrastive_loss=0, total=4206.45, n_correct=2718.73, ppl=6.05, accuracy=64.632, wps=7029.3, ups=1.67, wpb=4206.4, bsz=164.5, num_updates=25600, lr=8.83883e-05, gnorm=0.33, clip=0, loss_scale=128, train_wall=59, gb_free=17.9, wall=20798
2023-07-04 19:55:30 | INFO | train_inner | epoch 018:    653 / 1474 loss=1.379, trans_loss=5.337, nll_loss=2.633, w2v_ctc_loss=0.444, task_loss=1.568, contrastive_loss=0, total=4097.96, n_correct=2630.43, ppl=6.2, accuracy=64.189, wps=6853.2, ups=1.67, wpb=4098, bsz=149.3, num_updates=25700, lr=8.82162e-05, gnorm=0.335, clip=0, loss_scale=128, train_wall=59, gb_free=12.7, wall=20858
2023-07-04 19:56:30 | INFO | train_inner | epoch 018:    753 / 1474 loss=1.381, trans_loss=5.337, nll_loss=2.634, w2v_ctc_loss=0.45, task_loss=1.445, contrastive_loss=0, total=4208.5, n_correct=2701.12, ppl=6.21, accuracy=64.182, wps=7006.3, ups=1.66, wpb=4208.5, bsz=161.3, num_updates=25800, lr=8.80451e-05, gnorm=0.332, clip=0, loss_scale=128, train_wall=60, gb_free=16.4, wall=20918
2023-07-04 19:57:29 | INFO | train_inner | epoch 018:    853 / 1474 loss=1.374, trans_loss=5.326, nll_loss=2.619, w2v_ctc_loss=0.443, task_loss=1.525, contrastive_loss=0, total=4166.07, n_correct=2682.29, ppl=6.14, accuracy=64.384, wps=6961.7, ups=1.67, wpb=4166.1, bsz=151.2, num_updates=25900, lr=8.7875e-05, gnorm=0.333, clip=0, loss_scale=128, train_wall=59, gb_free=16.5, wall=20978
2023-07-04 19:58:28 | INFO | train_inner | epoch 018:    953 / 1474 loss=1.376, trans_loss=5.321, nll_loss=2.613, w2v_ctc_loss=0.441, task_loss=1.406, contrastive_loss=0, total=4141.27, n_correct=2670.95, ppl=6.12, accuracy=64.496, wps=7032.3, ups=1.7, wpb=4141.3, bsz=158, num_updates=26000, lr=8.77058e-05, gnorm=0.34, clip=0, loss_scale=128, train_wall=58, gb_free=16.2, wall=21037
2023-07-04 19:58:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 19:58:52 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 2.167 | trans_loss 5.572 | nll_loss 2.845 | w2v_ctc_loss 0.722 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2475.3 | ppl 7.18 | accuracy 61.83 | uer 16.956 | wer 18.821 | raw_wer 18.821 | bleu 19.97 | wps 2245.3 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 20.02
2023-07-04 19:58:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-07-04 19:58:52 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_18_26000.pt
2023-07-04 19:58:55 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_18_26000.pt
2023-07-04 19:58:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 19.97) (writing took 6.856597983743995 seconds)
2023-07-04 20:00:00 | INFO | train_inner | epoch 018:   1053 / 1474 loss=1.376, trans_loss=5.331, nll_loss=2.625, w2v_ctc_loss=0.44, task_loss=1.573, contrastive_loss=0, total=4134.55, n_correct=2655.81, ppl=6.17, accuracy=64.235, wps=4501.2, ups=1.09, wpb=4134.6, bsz=150.4, num_updates=26100, lr=8.75376e-05, gnorm=0.337, clip=0, loss_scale=128, train_wall=60, gb_free=16.6, wall=21128
2023-07-04 20:01:01 | INFO | train_inner | epoch 018:   1153 / 1474 loss=1.375, trans_loss=5.324, nll_loss=2.617, w2v_ctc_loss=0.443, task_loss=1.445, contrastive_loss=0, total=4157.63, n_correct=2674.18, ppl=6.14, accuracy=64.32, wps=6877, ups=1.65, wpb=4157.6, bsz=157, num_updates=26200, lr=8.73704e-05, gnorm=0.333, clip=0, loss_scale=128, train_wall=60, gb_free=17.2, wall=21189
2023-07-04 20:02:01 | INFO | train_inner | epoch 018:   1253 / 1474 loss=1.38, trans_loss=5.342, nll_loss=2.639, w2v_ctc_loss=0.445, task_loss=1.637, contrastive_loss=0, total=4085.66, n_correct=2614.73, ppl=6.23, accuracy=63.998, wps=6799.3, ups=1.66, wpb=4085.7, bsz=143.3, num_updates=26300, lr=8.72041e-05, gnorm=0.338, clip=0, loss_scale=128, train_wall=60, gb_free=17.6, wall=21249
2023-07-04 20:03:00 | INFO | train_inner | epoch 018:   1353 / 1474 loss=1.385, trans_loss=5.349, nll_loss=2.65, w2v_ctc_loss=0.458, task_loss=1.619, contrastive_loss=0, total=4065.6, n_correct=2601.78, ppl=6.28, accuracy=63.995, wps=6838.3, ups=1.68, wpb=4065.6, bsz=145.6, num_updates=26400, lr=8.70388e-05, gnorm=0.338, clip=0, loss_scale=128, train_wall=59, gb_free=13.5, wall=21308
2023-07-04 20:04:00 | INFO | train_inner | epoch 018:   1453 / 1474 loss=1.377, trans_loss=5.338, nll_loss=2.636, w2v_ctc_loss=0.447, task_loss=1.583, contrastive_loss=0, total=4122.48, n_correct=2641.2, ppl=6.22, accuracy=64.068, wps=6864.7, ups=1.67, wpb=4122.5, bsz=149.7, num_updates=26500, lr=8.68744e-05, gnorm=0.335, clip=0, loss_scale=128, train_wall=60, gb_free=17.3, wall=21368
2023-07-04 20:04:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 20:04:36 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 2.156 | trans_loss 5.563 | nll_loss 2.836 | w2v_ctc_loss 0.695 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2479.1 | ppl 7.14 | accuracy 61.925 | uer 16.691 | wer 18.612 | raw_wer 18.612 | bleu 20.12 | wps 2432.7 | wpb 4003.4 | bsz 141.8 | num_updates 26521 | best_bleu 20.12
2023-07-04 20:04:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26521 updates
2023-07-04 20:04:36 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 20:04:40 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 20:04:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt (epoch 18 @ 26521 updates, score 20.12) (writing took 8.787780690938234 seconds)
2023-07-04 20:04:45 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-07-04 20:04:45 | INFO | train | epoch 018 | loss 1.376 | trans_loss 5.327 | nll_loss 2.62 | w2v_ctc_loss 0.443 | task_loss 1.515 | contrastive_loss 0 | total 4138.65 | n_correct 2662.35 | ppl 6.15 | accuracy 64.329 | wps 6372.6 | ups 1.54 | wpb 4138.6 | bsz 152.8 | num_updates 26521 | lr 8.684e-05 | gnorm 0.335 | clip 0 | loss_scale 256 | train_wall 879 | gb_free 16.1 | wall 21413
2023-07-04 20:04:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 20:04:45 | INFO | fairseq.trainer | begin training epoch 19
2023-07-04 20:04:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 20:04:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-07-04 20:05:41 | INFO | train_inner | epoch 019:     80 / 1474 loss=1.37, trans_loss=5.299, nll_loss=2.584, w2v_ctc_loss=0.437, task_loss=1.521, contrastive_loss=0, total=4095.45, n_correct=2649, ppl=6, accuracy=64.682, wps=4055.7, ups=0.99, wpb=4095.5, bsz=148.5, num_updates=26600, lr=8.6711e-05, gnorm=0.336, clip=0, loss_scale=128, train_wall=60, gb_free=17.6, wall=21469
2023-07-04 20:06:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-04 20:06:42 | INFO | train_inner | epoch 019:    181 / 1474 loss=1.365, trans_loss=5.291, nll_loss=2.573, w2v_ctc_loss=0.442, task_loss=1.437, contrastive_loss=0, total=4210.09, n_correct=2734.1, ppl=5.95, accuracy=64.942, wps=6904.9, ups=1.64, wpb=4210.1, bsz=159.6, num_updates=26700, lr=8.65485e-05, gnorm=0.332, clip=0, loss_scale=64, train_wall=61, gb_free=12.1, wall=21530
2023-07-04 20:07:42 | INFO | train_inner | epoch 019:    281 / 1474 loss=1.363, trans_loss=5.282, nll_loss=2.562, w2v_ctc_loss=0.436, task_loss=1.487, contrastive_loss=0, total=4187.37, n_correct=2726.08, ppl=5.91, accuracy=65.102, wps=7035.6, ups=1.68, wpb=4187.4, bsz=153.5, num_updates=26800, lr=8.63868e-05, gnorm=0.329, clip=0, loss_scale=64, train_wall=59, gb_free=17.6, wall=21590
2023-07-04 20:08:41 | INFO | train_inner | epoch 019:    381 / 1474 loss=1.366, trans_loss=5.294, nll_loss=2.578, w2v_ctc_loss=0.433, task_loss=1.5, contrastive_loss=0, total=4170.67, n_correct=2701.57, ppl=5.97, accuracy=64.775, wps=7006.8, ups=1.68, wpb=4170.7, bsz=155.3, num_updates=26900, lr=8.62261e-05, gnorm=0.333, clip=0, loss_scale=64, train_wall=59, gb_free=17.3, wall=21649
2023-07-04 20:09:41 | INFO | train_inner | epoch 019:    481 / 1474 loss=1.369, trans_loss=5.304, nll_loss=2.59, w2v_ctc_loss=0.441, task_loss=1.547, contrastive_loss=0, total=4115.22, n_correct=2666.93, ppl=6.02, accuracy=64.806, wps=6833.5, ups=1.66, wpb=4115.2, bsz=150.9, num_updates=27000, lr=8.60663e-05, gnorm=0.337, clip=0, loss_scale=64, train_wall=60, gb_free=15.3, wall=21710
2023-07-04 20:10:41 | INFO | train_inner | epoch 019:    581 / 1474 loss=1.369, trans_loss=5.302, nll_loss=2.588, w2v_ctc_loss=0.437, task_loss=1.48, contrastive_loss=0, total=4129.22, n_correct=2672.16, ppl=6.01, accuracy=64.713, wps=6966.6, ups=1.69, wpb=4129.2, bsz=153, num_updates=27100, lr=8.59074e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=59, gb_free=16.1, wall=21769
2023-07-04 20:11:41 | INFO | train_inner | epoch 019:    681 / 1474 loss=1.366, trans_loss=5.296, nll_loss=2.582, w2v_ctc_loss=0.431, task_loss=1.384, contrastive_loss=0, total=4197.2, n_correct=2720.52, ppl=5.99, accuracy=64.817, wps=6998.6, ups=1.67, wpb=4197.2, bsz=160.4, num_updates=27200, lr=8.57493e-05, gnorm=0.334, clip=0, loss_scale=64, train_wall=60, gb_free=14.9, wall=21829
2023-07-04 20:12:41 | INFO | train_inner | epoch 019:    781 / 1474 loss=1.367, trans_loss=5.302, nll_loss=2.589, w2v_ctc_loss=0.441, task_loss=1.525, contrastive_loss=0, total=4142.6, n_correct=2681.66, ppl=6.02, accuracy=64.734, wps=6925.1, ups=1.67, wpb=4142.6, bsz=152.5, num_updates=27300, lr=8.55921e-05, gnorm=0.334, clip=0, loss_scale=64, train_wall=59, gb_free=16.7, wall=21889
2023-07-04 20:13:40 | INFO | train_inner | epoch 019:    881 / 1474 loss=1.373, trans_loss=5.313, nll_loss=2.603, w2v_ctc_loss=0.443, task_loss=1.55, contrastive_loss=0, total=4153.47, n_correct=2677.44, ppl=6.08, accuracy=64.463, wps=6941.7, ups=1.67, wpb=4153.5, bsz=151.5, num_updates=27400, lr=8.54358e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=59, gb_free=16.4, wall=21949
2023-07-04 20:14:41 | INFO | train_inner | epoch 019:    981 / 1474 loss=1.377, trans_loss=5.33, nll_loss=2.626, w2v_ctc_loss=0.442, task_loss=1.511, contrastive_loss=0, total=4101.29, n_correct=2636.45, ppl=6.17, accuracy=64.283, wps=6738.4, ups=1.64, wpb=4101.3, bsz=155, num_updates=27500, lr=8.52803e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=22010
2023-07-04 20:15:41 | INFO | train_inner | epoch 019:   1081 / 1474 loss=1.373, trans_loss=5.329, nll_loss=2.625, w2v_ctc_loss=0.442, task_loss=1.616, contrastive_loss=0, total=4036.97, n_correct=2594.56, ppl=6.17, accuracy=64.27, wps=6745.2, ups=1.67, wpb=4037, bsz=145.5, num_updates=27600, lr=8.51257e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=59, gb_free=14.9, wall=22069
2023-07-04 20:16:42 | INFO | train_inner | epoch 019:   1181 / 1474 loss=1.38, trans_loss=5.33, nll_loss=2.625, w2v_ctc_loss=0.448, task_loss=1.532, contrastive_loss=0, total=4137.49, n_correct=2655.83, ppl=6.17, accuracy=64.189, wps=6818.8, ups=1.65, wpb=4137.5, bsz=153.8, num_updates=27700, lr=8.49719e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=60, gb_free=15.1, wall=22130
2023-07-04 20:17:42 | INFO | train_inner | epoch 019:   1281 / 1474 loss=1.377, trans_loss=5.327, nll_loss=2.622, w2v_ctc_loss=0.44, task_loss=1.547, contrastive_loss=0, total=4141.89, n_correct=2660.38, ppl=6.16, accuracy=64.231, wps=6938.5, ups=1.68, wpb=4141.9, bsz=150.1, num_updates=27800, lr=8.48189e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=59, gb_free=15.9, wall=22190
2023-07-04 20:18:42 | INFO | train_inner | epoch 019:   1381 / 1474 loss=1.372, trans_loss=5.312, nll_loss=2.603, w2v_ctc_loss=0.442, task_loss=1.549, contrastive_loss=0, total=4133.26, n_correct=2666.38, ppl=6.07, accuracy=64.51, wps=6872.9, ups=1.66, wpb=4133.3, bsz=150.5, num_updates=27900, lr=8.46668e-05, gnorm=0.337, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=22250
2023-07-04 20:19:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 20:20:03 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 2.162 | trans_loss 5.565 | nll_loss 2.841 | w2v_ctc_loss 0.716 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2480.5 | ppl 7.17 | accuracy 61.96 | uer 17.057 | wer 19 | raw_wer 19 | bleu 20.06 | wps 2192.8 | wpb 4003.4 | bsz 141.8 | num_updates 27993 | best_bleu 20.12
2023-07-04 20:20:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27993 updates
2023-07-04 20:20:03 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.0601.pt
2023-07-04 20:20:05 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.0601.pt
2023-07-04 20:20:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.0601.pt (epoch 19 @ 27993 updates, score 20.06) (writing took 5.373621089849621 seconds)
2023-07-04 20:20:08 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-07-04 20:20:08 | INFO | train | epoch 019 | loss 1.37 | trans_loss 5.307 | nll_loss 2.596 | w2v_ctc_loss 0.44 | task_loss 1.516 | contrastive_loss 0 | total 4137.51 | n_correct 2673.77 | ppl 6.04 | accuracy 64.623 | wps 6597.8 | ups 1.59 | wpb 4137.5 | bsz 152.7 | num_updates 27993 | lr 8.4526e-05 | gnorm 0.337 | clip 0 | loss_scale 64 | train_wall 878 | gb_free 17.5 | wall 22337
2023-07-04 20:20:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 20:20:09 | INFO | fairseq.trainer | begin training epoch 20
2023-07-04 20:20:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 20:20:21 | INFO | train_inner | epoch 020:      7 / 1474 loss=1.368, trans_loss=5.305, nll_loss=2.593, w2v_ctc_loss=0.437, task_loss=1.53, contrastive_loss=0, total=4119.08, n_correct=2665.15, ppl=6.04, accuracy=64.703, wps=4147.7, ups=1.01, wpb=4119.1, bsz=152.1, num_updates=28000, lr=8.45154e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=22349
2023-07-04 20:20:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 20:20:46 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 2.156 | trans_loss 5.562 | nll_loss 2.837 | w2v_ctc_loss 0.699 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2485.6 | ppl 7.15 | accuracy 62.087 | uer 16.972 | wer 18.911 | raw_wer 18.911 | bleu 20.03 | wps 2096.5 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.12
2023-07-04 20:20:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-07-04 20:20:46 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_20_28000.pt
2023-07-04 20:20:49 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_20_28000.pt
2023-07-04 20:20:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 20.03) (writing took 6.305550015065819 seconds)
2023-07-04 20:21:53 | INFO | train_inner | epoch 020:    107 / 1474 loss=1.358, trans_loss=5.265, nll_loss=2.54, w2v_ctc_loss=0.43, task_loss=1.458, contrastive_loss=0, total=4195.03, n_correct=2741.1, ppl=5.82, accuracy=65.342, wps=4534.9, ups=1.08, wpb=4195, bsz=156.8, num_updates=28100, lr=8.43649e-05, gnorm=0.333, clip=0, loss_scale=64, train_wall=60, gb_free=15.3, wall=22442
2023-07-04 20:22:54 | INFO | train_inner | epoch 020:    207 / 1474 loss=1.36, trans_loss=5.275, nll_loss=2.553, w2v_ctc_loss=0.431, task_loss=1.573, contrastive_loss=0, total=4154.14, n_correct=2706.03, ppl=5.87, accuracy=65.141, wps=6852.9, ups=1.65, wpb=4154.1, bsz=150.5, num_updates=28200, lr=8.42152e-05, gnorm=0.337, clip=0, loss_scale=64, train_wall=60, gb_free=17.4, wall=22502
2023-07-04 20:23:54 | INFO | train_inner | epoch 020:    307 / 1474 loss=1.36, trans_loss=5.268, nll_loss=2.544, w2v_ctc_loss=0.431, task_loss=1.368, contrastive_loss=0, total=4188.05, n_correct=2733.37, ppl=5.83, accuracy=65.266, wps=6937.6, ups=1.66, wpb=4188.1, bsz=163.1, num_updates=28300, lr=8.40663e-05, gnorm=0.337, clip=0, loss_scale=64, train_wall=60, gb_free=15.7, wall=22563
2023-07-04 20:24:54 | INFO | train_inner | epoch 020:    407 / 1474 loss=1.357, trans_loss=5.276, nll_loss=2.554, w2v_ctc_loss=0.427, task_loss=1.541, contrastive_loss=0, total=4115.16, n_correct=2678.91, ppl=5.87, accuracy=65.099, wps=6886.7, ups=1.67, wpb=4115.2, bsz=148.5, num_updates=28400, lr=8.39181e-05, gnorm=0.332, clip=0, loss_scale=64, train_wall=59, gb_free=15.7, wall=22622
2023-07-04 20:25:54 | INFO | train_inner | epoch 020:    507 / 1474 loss=1.367, trans_loss=5.295, nll_loss=2.579, w2v_ctc_loss=0.433, task_loss=1.555, contrastive_loss=0, total=4108.46, n_correct=2663.5, ppl=5.98, accuracy=64.83, wps=6832.5, ups=1.66, wpb=4108.5, bsz=150.2, num_updates=28500, lr=8.37708e-05, gnorm=0.336, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=22683
2023-07-04 20:26:54 | INFO | train_inner | epoch 020:    607 / 1474 loss=1.365, trans_loss=5.296, nll_loss=2.581, w2v_ctc_loss=0.435, task_loss=1.592, contrastive_loss=0, total=4094.9, n_correct=2652.46, ppl=5.98, accuracy=64.775, wps=6877.5, ups=1.68, wpb=4094.9, bsz=148, num_updates=28600, lr=8.36242e-05, gnorm=0.334, clip=0, loss_scale=64, train_wall=59, gb_free=12.4, wall=22742
2023-07-04 20:27:53 | INFO | train_inner | epoch 020:    707 / 1474 loss=1.369, trans_loss=5.294, nll_loss=2.578, w2v_ctc_loss=0.438, task_loss=1.513, contrastive_loss=0, total=4140.23, n_correct=2683.45, ppl=5.97, accuracy=64.814, wps=6960.4, ups=1.68, wpb=4140.2, bsz=150.3, num_updates=28700, lr=8.34784e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=59, gb_free=16.4, wall=22802
2023-07-04 20:28:53 | INFO | train_inner | epoch 020:    807 / 1474 loss=1.362, trans_loss=5.287, nll_loss=2.569, w2v_ctc_loss=0.434, task_loss=1.5, contrastive_loss=0, total=4140.66, n_correct=2691.46, ppl=5.93, accuracy=65.001, wps=6933.1, ups=1.67, wpb=4140.7, bsz=152.8, num_updates=28800, lr=8.33333e-05, gnorm=0.334, clip=0, loss_scale=128, train_wall=59, gb_free=17.6, wall=22861
2023-07-04 20:29:54 | INFO | train_inner | epoch 020:    907 / 1474 loss=1.373, trans_loss=5.309, nll_loss=2.6, w2v_ctc_loss=0.435, task_loss=1.449, contrastive_loss=0, total=4157.15, n_correct=2687.74, ppl=6.06, accuracy=64.653, wps=6838.5, ups=1.64, wpb=4157.1, bsz=161.3, num_updates=28900, lr=8.3189e-05, gnorm=0.336, clip=0, loss_scale=128, train_wall=60, gb_free=17.8, wall=22922
2023-07-04 20:30:55 | INFO | train_inner | epoch 020:   1007 / 1474 loss=1.366, trans_loss=5.293, nll_loss=2.577, w2v_ctc_loss=0.433, task_loss=1.503, contrastive_loss=0, total=4171.86, n_correct=2707.66, ppl=5.97, accuracy=64.903, wps=6842, ups=1.64, wpb=4171.9, bsz=154.3, num_updates=29000, lr=8.30455e-05, gnorm=0.334, clip=0, loss_scale=128, train_wall=61, gb_free=16.2, wall=22983
2023-07-04 20:31:54 | INFO | train_inner | epoch 020:   1107 / 1474 loss=1.369, trans_loss=5.303, nll_loss=2.592, w2v_ctc_loss=0.435, task_loss=1.459, contrastive_loss=0, total=4162.96, n_correct=2695.56, ppl=6.03, accuracy=64.751, wps=6992.7, ups=1.68, wpb=4163, bsz=157.5, num_updates=29100, lr=8.29027e-05, gnorm=0.333, clip=0, loss_scale=128, train_wall=59, gb_free=17.2, wall=23043
2023-07-04 20:32:55 | INFO | train_inner | epoch 020:   1207 / 1474 loss=1.365, trans_loss=5.294, nll_loss=2.579, w2v_ctc_loss=0.44, task_loss=1.65, contrastive_loss=0, total=4033.74, n_correct=2614.47, ppl=5.98, accuracy=64.815, wps=6716.8, ups=1.67, wpb=4033.7, bsz=142.6, num_updates=29200, lr=8.27606e-05, gnorm=0.344, clip=0, loss_scale=128, train_wall=60, gb_free=17.4, wall=23103
2023-07-04 20:33:55 | INFO | train_inner | epoch 020:   1307 / 1474 loss=1.365, trans_loss=5.305, nll_loss=2.594, w2v_ctc_loss=0.435, task_loss=1.598, contrastive_loss=0, total=4124.42, n_correct=2666.84, ppl=6.04, accuracy=64.66, wps=6839.3, ups=1.66, wpb=4124.4, bsz=148.5, num_updates=29300, lr=8.26192e-05, gnorm=0.341, clip=0, loss_scale=128, train_wall=60, gb_free=16.2, wall=23163
2023-07-04 20:34:55 | INFO | train_inner | epoch 020:   1407 / 1474 loss=1.368, trans_loss=5.305, nll_loss=2.595, w2v_ctc_loss=0.439, task_loss=1.616, contrastive_loss=0, total=4114.1, n_correct=2657.59, ppl=6.04, accuracy=64.597, wps=6834.1, ups=1.66, wpb=4114.1, bsz=146.8, num_updates=29400, lr=8.24786e-05, gnorm=0.342, clip=0, loss_scale=128, train_wall=60, gb_free=14.7, wall=23223
2023-07-04 20:35:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-04 20:35:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 20:36:00 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 2.146 | trans_loss 5.561 | nll_loss 2.835 | w2v_ctc_loss 0.666 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2476.9 | ppl 7.13 | accuracy 61.87 | uer 16.598 | wer 18.415 | raw_wer 18.415 | bleu 19.84 | wps 2135.2 | wpb 4003.4 | bsz 141.8 | num_updates 29466 | best_bleu 20.12
2023-07-04 20:36:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29466 updates
2023-07-04 20:36:00 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_19.8401.pt
2023-07-04 20:36:02 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_19.8401.pt
2023-07-04 20:36:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_19.8401.pt (epoch 20 @ 29466 updates, score 19.84) (writing took 5.42561459960416 seconds)
2023-07-04 20:36:06 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-07-04 20:36:06 | INFO | train | epoch 020 | loss 1.365 | trans_loss 5.291 | nll_loss 2.575 | w2v_ctc_loss 0.434 | task_loss 1.514 | contrastive_loss 0 | total 4138.98 | n_correct 2686 | ppl 5.96 | accuracy 64.895 | wps 6367.4 | ups 1.54 | wpb 4139 | bsz 152.9 | num_updates 29466 | lr 8.23862e-05 | gnorm 0.337 | clip 0 | loss_scale 64 | train_wall 879 | gb_free 16.8 | wall 23294
2023-07-04 20:36:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 20:36:06 | INFO | fairseq.trainer | begin training epoch 21
2023-07-04 20:36:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 20:36:35 | INFO | train_inner | epoch 021:     34 / 1474 loss=1.366, trans_loss=5.298, nll_loss=2.585, w2v_ctc_loss=0.434, task_loss=1.43, contrastive_loss=0, total=4156.9, n_correct=2694.49, ppl=6, accuracy=64.82, wps=4149.8, ups=1, wpb=4156.9, bsz=158.9, num_updates=29500, lr=8.23387e-05, gnorm=0.337, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=23323
2023-07-04 20:37:35 | INFO | train_inner | epoch 021:    134 / 1474 loss=1.353, trans_loss=5.252, nll_loss=2.526, w2v_ctc_loss=0.425, task_loss=1.415, contrastive_loss=0, total=4195.08, n_correct=2750.83, ppl=5.76, accuracy=65.573, wps=6966.1, ups=1.66, wpb=4195.1, bsz=159.8, num_updates=29600, lr=8.21995e-05, gnorm=0.328, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=23384
2023-07-04 20:38:36 | INFO | train_inner | epoch 021:    234 / 1474 loss=1.353, trans_loss=5.257, nll_loss=2.531, w2v_ctc_loss=0.419, task_loss=1.442, contrastive_loss=0, total=4155.31, n_correct=2718.92, ppl=5.78, accuracy=65.432, wps=6914.8, ups=1.66, wpb=4155.3, bsz=156.3, num_updates=29700, lr=8.2061e-05, gnorm=0.335, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=23444
2023-07-04 20:39:36 | INFO | train_inner | epoch 021:    334 / 1474 loss=1.356, trans_loss=5.264, nll_loss=2.54, w2v_ctc_loss=0.432, task_loss=1.504, contrastive_loss=0, total=4151.51, n_correct=2713.62, ppl=5.82, accuracy=65.365, wps=6871.5, ups=1.66, wpb=4151.5, bsz=155.4, num_updates=29800, lr=8.19232e-05, gnorm=0.334, clip=0, loss_scale=64, train_wall=60, gb_free=15.8, wall=23504
2023-07-04 20:40:36 | INFO | train_inner | epoch 021:    434 / 1474 loss=1.353, trans_loss=5.256, nll_loss=2.53, w2v_ctc_loss=0.422, task_loss=1.473, contrastive_loss=0, total=4180.85, n_correct=2739.21, ppl=5.77, accuracy=65.518, wps=7006.8, ups=1.68, wpb=4180.9, bsz=153.4, num_updates=29900, lr=8.17861e-05, gnorm=0.332, clip=0, loss_scale=64, train_wall=59, gb_free=16, wall=23564
2023-07-04 20:41:35 | INFO | train_inner | epoch 021:    534 / 1474 loss=1.356, trans_loss=5.263, nll_loss=2.539, w2v_ctc_loss=0.433, task_loss=1.568, contrastive_loss=0, total=4083.98, n_correct=2669.45, ppl=5.81, accuracy=65.364, wps=6842.8, ups=1.68, wpb=4084, bsz=147.5, num_updates=30000, lr=8.16497e-05, gnorm=0.337, clip=0, loss_scale=64, train_wall=59, gb_free=13.4, wall=23624
2023-07-04 20:41:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 20:41:59 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 2.151 | trans_loss 5.565 | nll_loss 2.838 | w2v_ctc_loss 0.677 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2480.3 | ppl 7.15 | accuracy 61.955 | uer 16.595 | wer 18.534 | raw_wer 18.534 | bleu 19.71 | wps 2279.7 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.12
2023-07-04 20:41:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-07-04 20:41:59 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_21_30000.pt
2023-07-04 20:42:01 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_21_30000.pt
2023-07-04 20:42:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 19.71) (writing took 6.231446674093604 seconds)
tensor(0.0230, device='cuda:0')
tensor(0.0005, device='cuda:0')
2023-07-04 20:43:07 | INFO | train_inner | epoch 021:    634 / 1474 loss=1.359, trans_loss=5.266, nll_loss=2.543, w2v_ctc_loss=0.425, task_loss=1.497, contrastive_loss=0, total=4215.41, n_correct=2756.27, ppl=5.83, accuracy=65.386, wps=4609.2, ups=1.09, wpb=4215.4, bsz=157.7, num_updates=30100, lr=8.15139e-05, gnorm=0.335, clip=0, loss_scale=64, train_wall=60, gb_free=11.8, wall=23715
2023-07-04 20:44:07 | INFO | train_inner | epoch 021:    734 / 1474 loss=1.358, trans_loss=5.277, nll_loss=2.557, w2v_ctc_loss=0.427, task_loss=1.51, contrastive_loss=0, total=4152.97, n_correct=2705.7, ppl=5.88, accuracy=65.151, wps=6918.9, ups=1.67, wpb=4153, bsz=154.7, num_updates=30200, lr=8.13788e-05, gnorm=0.334, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=23775
2023-07-04 20:45:07 | INFO | train_inner | epoch 021:    834 / 1474 loss=1.36, trans_loss=5.285, nll_loss=2.567, w2v_ctc_loss=0.431, task_loss=1.603, contrastive_loss=0, total=4066.93, n_correct=2645.23, ppl=5.93, accuracy=65.042, wps=6762.8, ups=1.66, wpb=4066.9, bsz=147.2, num_updates=30300, lr=8.12444e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=23835
2023-07-04 20:46:07 | INFO | train_inner | epoch 021:    934 / 1474 loss=1.362, trans_loss=5.272, nll_loss=2.552, w2v_ctc_loss=0.433, task_loss=1.512, contrastive_loss=0, total=4103.34, n_correct=2671.35, ppl=5.86, accuracy=65.102, wps=6881.8, ups=1.68, wpb=4103.3, bsz=150.5, num_updates=30400, lr=8.11107e-05, gnorm=0.338, clip=0, loss_scale=64, train_wall=59, gb_free=14.3, wall=23895
2023-07-04 20:47:06 | INFO | train_inner | epoch 021:   1034 / 1474 loss=1.368, trans_loss=5.295, nll_loss=2.582, w2v_ctc_loss=0.437, task_loss=1.541, contrastive_loss=0, total=4099.86, n_correct=2657.98, ppl=5.99, accuracy=64.831, wps=6904.8, ups=1.68, wpb=4099.9, bsz=149.4, num_updates=30500, lr=8.09776e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=59, gb_free=11.8, wall=23954
2023-07-04 20:48:06 | INFO | train_inner | epoch 021:   1134 / 1474 loss=1.364, trans_loss=5.285, nll_loss=2.567, w2v_ctc_loss=0.436, task_loss=1.637, contrastive_loss=0, total=4120.75, n_correct=2680.29, ppl=5.93, accuracy=65.044, wps=6909.3, ups=1.68, wpb=4120.8, bsz=146.7, num_updates=30600, lr=8.08452e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=59, gb_free=16, wall=24014
2023-07-04 20:49:05 | INFO | train_inner | epoch 021:   1234 / 1474 loss=1.362, trans_loss=5.276, nll_loss=2.558, w2v_ctc_loss=0.43, task_loss=1.441, contrastive_loss=0, total=4154.73, n_correct=2704.79, ppl=5.89, accuracy=65.101, wps=6953.2, ups=1.67, wpb=4154.7, bsz=155.8, num_updates=30700, lr=8.07134e-05, gnorm=0.332, clip=0, loss_scale=64, train_wall=59, gb_free=13, wall=24074
2023-07-04 20:50:05 | INFO | train_inner | epoch 021:   1334 / 1474 loss=1.357, trans_loss=5.273, nll_loss=2.554, w2v_ctc_loss=0.428, task_loss=1.462, contrastive_loss=0, total=4147.17, n_correct=2709.66, ppl=5.87, accuracy=65.338, wps=6914.8, ups=1.67, wpb=4147.2, bsz=155.9, num_updates=30800, lr=8.05823e-05, gnorm=0.333, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=24134
2023-07-04 20:51:06 | INFO | train_inner | epoch 021:   1434 / 1474 loss=1.368, trans_loss=5.298, nll_loss=2.585, w2v_ctc_loss=0.44, task_loss=1.587, contrastive_loss=0, total=4133.93, n_correct=2677.19, ppl=6, accuracy=64.761, wps=6797.8, ups=1.64, wpb=4133.9, bsz=152.2, num_updates=30900, lr=8.04518e-05, gnorm=0.338, clip=0, loss_scale=64, train_wall=60, gb_free=15.7, wall=24194
2023-07-04 20:51:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0230, device='cuda:4')
tensor(0.0005, device='cuda:4')
tensor(0.0230, device='cuda:6')
tensor(0.0005, device='cuda:6')
tensor(0.0230, device='cuda:7')
tensor(0.0005, device='cuda:7')
tensor(0.0230, device='cuda:2')
tensor(0.0005, device='cuda:2')
tensor(0.0230, device='cuda:5')
tensor(0.0005, device='cuda:5')
tensor(0.0230, device='cuda:3')
tensor(0.0005, device='cuda:3')
tensor(0.0230, device='cuda:1')
tensor(0.0005, device='cuda:1')
2023-07-04 20:51:55 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 2.151 | trans_loss 5.558 | nll_loss 2.832 | w2v_ctc_loss 0.687 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2478.3 | ppl 7.12 | accuracy 61.905 | uer 16.439 | wer 18.333 | raw_wer 18.333 | bleu 20.15 | wps 2207.6 | wpb 4003.4 | bsz 141.8 | num_updates 30940 | best_bleu 20.15
2023-07-04 20:51:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30940 updates
2023-07-04 20:51:55 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 20:51:59 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 20:52:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt (epoch 21 @ 30940 updates, score 20.15) (writing took 8.513804820831865 seconds)
2023-07-04 20:52:04 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-07-04 20:52:04 | INFO | train | epoch 021 | loss 1.359 | trans_loss 5.273 | nll_loss 2.552 | w2v_ctc_loss 0.43 | task_loss 1.515 | contrastive_loss 0 | total 4138.65 | n_correct 2698.87 | ppl 5.87 | accuracy 65.211 | wps 6367.3 | ups 1.54 | wpb 4138.6 | bsz 152.8 | num_updates 30940 | lr 8.03998e-05 | gnorm 0.336 | clip 0 | loss_scale 64 | train_wall 878 | gb_free 15.6 | wall 24252
2023-07-04 20:52:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 20:52:04 | INFO | fairseq.trainer | begin training epoch 22
2023-07-04 20:52:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 20:52:48 | INFO | train_inner | epoch 022:     60 / 1474 loss=1.354, trans_loss=5.253, nll_loss=2.528, w2v_ctc_loss=0.429, task_loss=1.534, contrastive_loss=0, total=4128.84, n_correct=2704.51, ppl=5.77, accuracy=65.503, wps=4065.6, ups=0.98, wpb=4128.8, bsz=148.8, num_updates=31000, lr=8.03219e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=59, gb_free=14.5, wall=24296
2023-07-04 20:53:48 | INFO | train_inner | epoch 022:    160 / 1474 loss=1.351, trans_loss=5.244, nll_loss=2.514, w2v_ctc_loss=0.426, task_loss=1.533, contrastive_loss=0, total=4123.35, n_correct=2709.71, ppl=5.71, accuracy=65.716, wps=6840.3, ups=1.66, wpb=4123.4, bsz=155.1, num_updates=31100, lr=8.01927e-05, gnorm=0.336, clip=0, loss_scale=64, train_wall=60, gb_free=14.9, wall=24356
2023-07-04 20:54:48 | INFO | train_inner | epoch 022:    260 / 1474 loss=1.346, trans_loss=5.232, nll_loss=2.5, w2v_ctc_loss=0.416, task_loss=1.334, contrastive_loss=0, total=4267.16, n_correct=2812.54, ppl=5.66, accuracy=65.911, wps=7127.4, ups=1.67, wpb=4267.2, bsz=165, num_updates=31200, lr=8.00641e-05, gnorm=0.328, clip=0, loss_scale=64, train_wall=59, gb_free=17, wall=24416
2023-07-04 20:55:49 | INFO | train_inner | epoch 022:    360 / 1474 loss=1.353, trans_loss=5.256, nll_loss=2.531, w2v_ctc_loss=0.422, task_loss=1.54, contrastive_loss=0, total=4180.09, n_correct=2737.2, ppl=5.78, accuracy=65.482, wps=6860.8, ups=1.64, wpb=4180.1, bsz=155, num_updates=31300, lr=7.99361e-05, gnorm=0.333, clip=0, loss_scale=64, train_wall=60, gb_free=17.7, wall=24477
2023-07-04 20:56:49 | INFO | train_inner | epoch 022:    460 / 1474 loss=1.36, trans_loss=5.267, nll_loss=2.543, w2v_ctc_loss=0.429, task_loss=1.599, contrastive_loss=0, total=4132.62, n_correct=2699.44, ppl=5.83, accuracy=65.32, wps=6850.8, ups=1.66, wpb=4132.6, bsz=148.6, num_updates=31400, lr=7.98087e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=24537
2023-07-04 20:57:49 | INFO | train_inner | epoch 022:    560 / 1474 loss=1.353, trans_loss=5.252, nll_loss=2.525, w2v_ctc_loss=0.426, task_loss=1.534, contrastive_loss=0, total=4155.5, n_correct=2722.72, ppl=5.76, accuracy=65.521, wps=6894.2, ups=1.66, wpb=4155.5, bsz=153.7, num_updates=31500, lr=7.96819e-05, gnorm=0.338, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=24598
2023-07-04 20:58:49 | INFO | train_inner | epoch 022:    660 / 1474 loss=1.347, trans_loss=5.239, nll_loss=2.51, w2v_ctc_loss=0.414, task_loss=1.427, contrastive_loss=0, total=4147.84, n_correct=2725.33, ppl=5.69, accuracy=65.705, wps=7002.4, ups=1.69, wpb=4147.8, bsz=156.6, num_updates=31600, lr=7.95557e-05, gnorm=0.335, clip=0, loss_scale=128, train_wall=59, gb_free=13.4, wall=24657
2023-07-04 20:59:48 | INFO | train_inner | epoch 022:    760 / 1474 loss=1.355, trans_loss=5.256, nll_loss=2.53, w2v_ctc_loss=0.428, task_loss=1.55, contrastive_loss=0, total=4166.89, n_correct=2729.29, ppl=5.78, accuracy=65.499, wps=6970.3, ups=1.67, wpb=4166.9, bsz=152.2, num_updates=31700, lr=7.94301e-05, gnorm=0.336, clip=0, loss_scale=128, train_wall=59, gb_free=16.1, wall=24717
2023-07-04 21:00:49 | INFO | train_inner | epoch 022:    860 / 1474 loss=1.353, trans_loss=5.268, nll_loss=2.545, w2v_ctc_loss=0.428, task_loss=1.655, contrastive_loss=0, total=4074.75, n_correct=2658.92, ppl=5.84, accuracy=65.254, wps=6721.5, ups=1.65, wpb=4074.8, bsz=144.2, num_updates=31800, lr=7.93052e-05, gnorm=0.337, clip=0, loss_scale=128, train_wall=60, gb_free=17.6, wall=24777
2023-07-04 21:01:49 | INFO | train_inner | epoch 022:    960 / 1474 loss=1.354, trans_loss=5.256, nll_loss=2.532, w2v_ctc_loss=0.424, task_loss=1.522, contrastive_loss=0, total=4136.34, n_correct=2707.59, ppl=5.78, accuracy=65.459, wps=6889.8, ups=1.67, wpb=4136.3, bsz=151.8, num_updates=31900, lr=7.91808e-05, gnorm=0.34, clip=0, loss_scale=128, train_wall=60, gb_free=16.8, wall=24837
2023-07-04 21:02:48 | INFO | train_inner | epoch 022:   1060 / 1474 loss=1.354, trans_loss=5.257, nll_loss=2.533, w2v_ctc_loss=0.42, task_loss=1.438, contrastive_loss=0, total=4157.21, n_correct=2722.35, ppl=5.79, accuracy=65.485, wps=7005.4, ups=1.69, wpb=4157.2, bsz=157.7, num_updates=32000, lr=7.90569e-05, gnorm=0.336, clip=0, loss_scale=128, train_wall=59, gb_free=12.4, wall=24897
2023-07-04 21:02:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 21:03:12 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 2.155 | trans_loss 5.563 | nll_loss 2.84 | w2v_ctc_loss 0.694 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2483 | ppl 7.16 | accuracy 62.022 | uer 16.601 | wer 18.553 | raw_wer 18.553 | bleu 20.11 | wps 2407.3 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.15
2023-07-04 21:03:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-07-04 21:03:12 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_22_32000.pt
2023-07-04 21:03:14 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_22_32000.pt
2023-07-04 21:03:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 20.11) (writing took 6.5176158281974494 seconds)
2023-07-04 21:04:18 | INFO | train_inner | epoch 022:   1160 / 1474 loss=1.364, trans_loss=5.283, nll_loss=2.567, w2v_ctc_loss=0.431, task_loss=1.571, contrastive_loss=0, total=4092.91, n_correct=2664.71, ppl=5.92, accuracy=65.106, wps=4561.2, ups=1.11, wpb=4092.9, bsz=147.2, num_updates=32100, lr=7.89337e-05, gnorm=0.335, clip=0, loss_scale=128, train_wall=59, gb_free=16.2, wall=24986
2023-07-04 21:05:18 | INFO | train_inner | epoch 022:   1260 / 1474 loss=1.358, trans_loss=5.27, nll_loss=2.549, w2v_ctc_loss=0.428, task_loss=1.399, contrastive_loss=0, total=4182.65, n_correct=2727.14, ppl=5.85, accuracy=65.201, wps=7010.2, ups=1.68, wpb=4182.6, bsz=161.8, num_updates=32200, lr=7.8811e-05, gnorm=0.334, clip=0, loss_scale=128, train_wall=59, gb_free=16.7, wall=25046
2023-07-04 21:06:17 | INFO | train_inner | epoch 022:   1360 / 1474 loss=1.353, trans_loss=5.261, nll_loss=2.538, w2v_ctc_loss=0.421, task_loss=1.501, contrastive_loss=0, total=4071.58, n_correct=2661.31, ppl=5.81, accuracy=65.363, wps=6865.8, ups=1.69, wpb=4071.6, bsz=150.3, num_updates=32300, lr=7.86889e-05, gnorm=0.336, clip=0, loss_scale=128, train_wall=59, gb_free=16.9, wall=25105
2023-07-04 21:07:17 | INFO | train_inner | epoch 022:   1460 / 1474 loss=1.361, trans_loss=5.277, nll_loss=2.558, w2v_ctc_loss=0.432, task_loss=1.614, contrastive_loss=0, total=4077.83, n_correct=2652.52, ppl=5.89, accuracy=65.047, wps=6818.5, ups=1.67, wpb=4077.8, bsz=144, num_updates=32400, lr=7.85674e-05, gnorm=0.338, clip=0, loss_scale=128, train_wall=59, gb_free=16.3, wall=25165
2023-07-04 21:07:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 21:07:48 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 2.148 | trans_loss 5.56 | nll_loss 2.833 | w2v_ctc_loss 0.673 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2481.9 | ppl 7.13 | accuracy 61.995 | uer 16.675 | wer 18.545 | raw_wer 18.545 | bleu 20.28 | wps 2437.7 | wpb 4003.4 | bsz 141.8 | num_updates 32414 | best_bleu 20.28
2023-07-04 21:07:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32414 updates
2023-07-04 21:07:48 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 21:07:53 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 21:07:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt (epoch 22 @ 32414 updates, score 20.28) (writing took 8.273449080996215 seconds)
2023-07-04 21:07:57 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-07-04 21:07:57 | INFO | train | epoch 022 | loss 1.354 | trans_loss 5.258 | nll_loss 2.533 | w2v_ctc_loss 0.425 | task_loss 1.515 | contrastive_loss 0 | total 4138.65 | n_correct 2708.65 | ppl 5.79 | accuracy 65.448 | wps 6400 | ups 1.55 | wpb 4138.6 | bsz 152.8 | num_updates 32414 | lr 7.85505e-05 | gnorm 0.336 | clip 0 | loss_scale 128 | train_wall 877 | gb_free 12.2 | wall 25205
2023-07-04 21:07:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 21:07:57 | INFO | fairseq.trainer | begin training epoch 23
2023-07-04 21:07:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 21:08:57 | INFO | train_inner | epoch 023:     86 / 1474 loss=1.346, trans_loss=5.229, nll_loss=2.495, w2v_ctc_loss=0.423, task_loss=1.565, contrastive_loss=0, total=4089.8, n_correct=2697.52, ppl=5.64, accuracy=65.957, wps=4073, ups=1, wpb=4089.8, bsz=149.7, num_updates=32500, lr=7.84465e-05, gnorm=0.339, clip=0, loss_scale=128, train_wall=60, gb_free=16.8, wall=25266
2023-07-04 21:09:57 | INFO | train_inner | epoch 023:    186 / 1474 loss=1.347, trans_loss=5.231, nll_loss=2.497, w2v_ctc_loss=0.421, task_loss=1.598, contrastive_loss=0, total=4117.76, n_correct=2712.66, ppl=5.65, accuracy=65.877, wps=6875.4, ups=1.67, wpb=4117.8, bsz=148, num_updates=32600, lr=7.8326e-05, gnorm=0.345, clip=0, loss_scale=128, train_wall=59, gb_free=15.7, wall=25326
2023-07-04 21:10:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-04 21:10:58 | INFO | train_inner | epoch 023:    287 / 1474 loss=1.347, trans_loss=5.236, nll_loss=2.504, w2v_ctc_loss=0.415, task_loss=1.532, contrastive_loss=0, total=4146.27, n_correct=2727.92, ppl=5.67, accuracy=65.792, wps=6797.4, ups=1.64, wpb=4146.3, bsz=152.1, num_updates=32700, lr=7.82062e-05, gnorm=0.336, clip=0, loss_scale=64, train_wall=61, gb_free=17.2, wall=25387
2023-07-04 21:11:58 | INFO | train_inner | epoch 023:    387 / 1474 loss=1.346, trans_loss=5.235, nll_loss=2.503, w2v_ctc_loss=0.419, task_loss=1.573, contrastive_loss=0, total=4116.7, n_correct=2707.35, ppl=5.67, accuracy=65.765, wps=6893.8, ups=1.67, wpb=4116.7, bsz=147, num_updates=32800, lr=7.80869e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=59, gb_free=15.5, wall=25446
2023-07-04 21:12:58 | INFO | train_inner | epoch 023:    487 / 1474 loss=1.349, trans_loss=5.238, nll_loss=2.507, w2v_ctc_loss=0.42, task_loss=1.472, contrastive_loss=0, total=4157.6, n_correct=2732.73, ppl=5.68, accuracy=65.729, wps=6919.2, ups=1.66, wpb=4157.6, bsz=156.8, num_updates=32900, lr=7.79681e-05, gnorm=0.335, clip=0, loss_scale=64, train_wall=60, gb_free=17.4, wall=25506
2023-07-04 21:13:58 | INFO | train_inner | epoch 023:    587 / 1474 loss=1.343, trans_loss=5.225, nll_loss=2.491, w2v_ctc_loss=0.416, task_loss=1.427, contrastive_loss=0, total=4173.42, n_correct=2755.58, ppl=5.62, accuracy=66.027, wps=7026, ups=1.68, wpb=4173.4, bsz=158, num_updates=33000, lr=7.78499e-05, gnorm=0.336, clip=0, loss_scale=64, train_wall=59, gb_free=13.1, wall=25566
2023-07-04 21:14:58 | INFO | train_inner | epoch 023:    687 / 1474 loss=1.347, trans_loss=5.236, nll_loss=2.506, w2v_ctc_loss=0.42, task_loss=1.518, contrastive_loss=0, total=4137.82, n_correct=2724.1, ppl=5.68, accuracy=65.834, wps=6870.4, ups=1.66, wpb=4137.8, bsz=151.2, num_updates=33100, lr=7.77322e-05, gnorm=0.334, clip=0, loss_scale=64, train_wall=60, gb_free=17.3, wall=25626
2023-07-04 21:15:58 | INFO | train_inner | epoch 023:    787 / 1474 loss=1.355, trans_loss=5.253, nll_loss=2.528, w2v_ctc_loss=0.428, task_loss=1.524, contrastive_loss=0, total=4150.99, n_correct=2721.6, ppl=5.77, accuracy=65.565, wps=6939.9, ups=1.67, wpb=4151, bsz=152.7, num_updates=33200, lr=7.76151e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=59, gb_free=16.7, wall=25686
2023-07-04 21:16:57 | INFO | train_inner | epoch 023:    887 / 1474 loss=1.35, trans_loss=5.241, nll_loss=2.513, w2v_ctc_loss=0.422, task_loss=1.385, contrastive_loss=0, total=4181.99, n_correct=2750.01, ppl=5.71, accuracy=65.758, wps=7014.4, ups=1.68, wpb=4182, bsz=162.3, num_updates=33300, lr=7.74984e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=59, gb_free=16.6, wall=25745
2023-07-04 21:17:57 | INFO | train_inner | epoch 023:    987 / 1474 loss=1.355, trans_loss=5.252, nll_loss=2.527, w2v_ctc_loss=0.423, task_loss=1.514, contrastive_loss=0, total=4168.73, n_correct=2727.8, ppl=5.76, accuracy=65.435, wps=6935.4, ups=1.66, wpb=4168.7, bsz=155.2, num_updates=33400, lr=7.73823e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=60, gb_free=11.4, wall=25806
2023-07-04 21:18:58 | INFO | train_inner | epoch 023:   1087 / 1474 loss=1.353, trans_loss=5.253, nll_loss=2.526, w2v_ctc_loss=0.428, task_loss=1.618, contrastive_loss=0, total=4088.49, n_correct=2677.18, ppl=5.76, accuracy=65.481, wps=6782.1, ups=1.66, wpb=4088.5, bsz=145, num_updates=33500, lr=7.72667e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=60, gb_free=16.1, wall=25866
2023-07-04 21:19:58 | INFO | train_inner | epoch 023:   1187 / 1474 loss=1.349, trans_loss=5.244, nll_loss=2.517, w2v_ctc_loss=0.422, task_loss=1.504, contrastive_loss=0, total=4162.7, n_correct=2732.02, ppl=5.72, accuracy=65.631, wps=6854.9, ups=1.65, wpb=4162.7, bsz=154.7, num_updates=33600, lr=7.71517e-05, gnorm=0.338, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=25927
2023-07-04 21:20:58 | INFO | train_inner | epoch 023:   1287 / 1474 loss=1.35, trans_loss=5.243, nll_loss=2.515, w2v_ctc_loss=0.418, task_loss=1.476, contrastive_loss=0, total=4135.53, n_correct=2718.61, ppl=5.72, accuracy=65.738, wps=6920.4, ups=1.67, wpb=4135.5, bsz=154.5, num_updates=33700, lr=7.70371e-05, gnorm=0.331, clip=0, loss_scale=64, train_wall=59, gb_free=17, wall=25986
2023-07-04 21:21:59 | INFO | train_inner | epoch 023:   1387 / 1474 loss=1.358, trans_loss=5.27, nll_loss=2.551, w2v_ctc_loss=0.427, task_loss=1.529, contrastive_loss=0, total=4143.98, n_correct=2701.83, ppl=5.86, accuracy=65.199, wps=6853.9, ups=1.65, wpb=4144, bsz=152.6, num_updates=33800, lr=7.69231e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=60, gb_free=16.2, wall=26047
2023-07-04 21:22:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 21:23:14 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 2.156 | trans_loss 5.558 | nll_loss 2.831 | w2v_ctc_loss 0.703 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2484.1 | ppl 7.12 | accuracy 62.05 | uer 16.569 | wer 18.321 | raw_wer 18.321 | bleu 20.03 | wps 2397.7 | wpb 4003.4 | bsz 141.8 | num_updates 33887 | best_bleu 20.28
2023-07-04 21:23:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33887 updates
2023-07-04 21:23:14 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.0302.pt
2023-07-04 21:23:17 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.0302.pt
2023-07-04 21:23:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.0302.pt (epoch 23 @ 33887 updates, score 20.03) (writing took 5.636883988045156 seconds)
2023-07-04 21:23:20 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-07-04 21:23:20 | INFO | train | epoch 023 | loss 1.35 | trans_loss 5.243 | nll_loss 2.515 | w2v_ctc_loss 0.421 | task_loss 1.515 | contrastive_loss 0 | total 4138.43 | n_correct 2717.94 | ppl 5.72 | accuracy 65.676 | wps 6602.7 | ups 1.6 | wpb 4138.4 | bsz 152.8 | num_updates 33887 | lr 7.68243e-05 | gnorm 0.338 | clip 0 | loss_scale 64 | train_wall 879 | gb_free 14.1 | wall 26129
2023-07-04 21:23:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 21:23:21 | INFO | fairseq.trainer | begin training epoch 24
2023-07-04 21:23:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 21:23:37 | INFO | train_inner | epoch 024:     13 / 1474 loss=1.353, trans_loss=5.264, nll_loss=2.544, w2v_ctc_loss=0.419, task_loss=1.518, contrastive_loss=0, total=4085.11, n_correct=2668.12, ppl=5.83, accuracy=65.313, wps=4171.6, ups=1.02, wpb=4085.1, bsz=152.1, num_updates=33900, lr=7.68095e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=60, gb_free=13, wall=26145
2023-07-04 21:24:36 | INFO | train_inner | epoch 024:    113 / 1474 loss=1.343, trans_loss=5.215, nll_loss=2.479, w2v_ctc_loss=0.414, task_loss=1.395, contrastive_loss=0, total=4171.44, n_correct=2756.73, ppl=5.57, accuracy=66.086, wps=6999.7, ups=1.68, wpb=4171.4, bsz=162.3, num_updates=34000, lr=7.66965e-05, gnorm=0.334, clip=0, loss_scale=64, train_wall=59, gb_free=16.6, wall=26204
2023-07-04 21:24:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 21:24:59 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 2.152 | trans_loss 5.563 | nll_loss 2.836 | w2v_ctc_loss 0.683 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2485.4 | ppl 7.14 | accuracy 62.082 | uer 16.696 | wer 18.571 | raw_wer 18.571 | bleu 20.24 | wps 2461.1 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.28
2023-07-04 21:24:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-07-04 21:24:59 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_24_34000.pt
2023-07-04 21:25:02 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_24_34000.pt
2023-07-04 21:25:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 20.24) (writing took 7.016412473283708 seconds)
2023-07-04 21:26:07 | INFO | train_inner | epoch 024:    213 / 1474 loss=1.341, trans_loss=5.217, nll_loss=2.482, w2v_ctc_loss=0.407, task_loss=1.319, contrastive_loss=0, total=4251.29, n_correct=2811.34, ppl=5.59, accuracy=66.129, wps=4675.4, ups=1.1, wpb=4251.3, bsz=170.4, num_updates=34100, lr=7.6584e-05, gnorm=0.332, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=26295
2023-07-04 21:27:07 | INFO | train_inner | epoch 024:    313 / 1474 loss=1.34, trans_loss=5.215, nll_loss=2.477, w2v_ctc_loss=0.415, task_loss=1.485, contrastive_loss=0, total=4128.18, n_correct=2733.1, ppl=5.57, accuracy=66.206, wps=6893.4, ups=1.67, wpb=4128.2, bsz=152.8, num_updates=34200, lr=7.64719e-05, gnorm=0.336, clip=0, loss_scale=64, train_wall=59, gb_free=16.3, wall=26355
2023-07-04 21:28:07 | INFO | train_inner | epoch 024:    413 / 1474 loss=1.349, trans_loss=5.236, nll_loss=2.505, w2v_ctc_loss=0.421, task_loss=1.597, contrastive_loss=0, total=4158.92, n_correct=2737.46, ppl=5.68, accuracy=65.821, wps=6910.7, ups=1.66, wpb=4158.9, bsz=149.9, num_updates=34300, lr=7.63604e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=26415
2023-07-04 21:29:07 | INFO | train_inner | epoch 024:    513 / 1474 loss=1.346, trans_loss=5.228, nll_loss=2.494, w2v_ctc_loss=0.418, task_loss=1.533, contrastive_loss=0, total=4144.91, n_correct=2734.68, ppl=5.64, accuracy=65.977, wps=6874.3, ups=1.66, wpb=4144.9, bsz=151.6, num_updates=34400, lr=7.62493e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=26476
2023-07-04 21:30:08 | INFO | train_inner | epoch 024:    613 / 1474 loss=1.343, trans_loss=5.222, nll_loss=2.487, w2v_ctc_loss=0.413, task_loss=1.528, contrastive_loss=0, total=4165.3, n_correct=2748.75, ppl=5.61, accuracy=65.992, wps=6903.5, ups=1.66, wpb=4165.3, bsz=153.8, num_updates=34500, lr=7.61387e-05, gnorm=0.334, clip=0, loss_scale=64, train_wall=60, gb_free=16, wall=26536
2023-07-04 21:31:08 | INFO | train_inner | epoch 024:    713 / 1474 loss=1.348, trans_loss=5.237, nll_loss=2.506, w2v_ctc_loss=0.422, task_loss=1.566, contrastive_loss=0, total=4102.21, n_correct=2697.28, ppl=5.68, accuracy=65.752, wps=6862.6, ups=1.67, wpb=4102.2, bsz=147.5, num_updates=34600, lr=7.60286e-05, gnorm=0.337, clip=0, loss_scale=64, train_wall=59, gb_free=17.1, wall=26596
2023-07-04 21:32:08 | INFO | train_inner | epoch 024:    813 / 1474 loss=1.345, trans_loss=5.23, nll_loss=2.498, w2v_ctc_loss=0.415, task_loss=1.529, contrastive_loss=0, total=4110.6, n_correct=2709.29, ppl=5.65, accuracy=65.91, wps=6844.7, ups=1.67, wpb=4110.6, bsz=152.7, num_updates=34700, lr=7.5919e-05, gnorm=0.337, clip=0, loss_scale=128, train_wall=60, gb_free=16.8, wall=26656
2023-07-04 21:33:07 | INFO | train_inner | epoch 024:    913 / 1474 loss=1.348, trans_loss=5.243, nll_loss=2.513, w2v_ctc_loss=0.423, task_loss=1.671, contrastive_loss=0, total=4043.03, n_correct=2654.38, ppl=5.71, accuracy=65.653, wps=6807.8, ups=1.68, wpb=4043, bsz=140.5, num_updates=34800, lr=7.58098e-05, gnorm=0.339, clip=0, loss_scale=128, train_wall=59, gb_free=11.7, wall=26715
2023-07-04 21:33:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-04 21:34:08 | INFO | train_inner | epoch 024:   1014 / 1474 loss=1.343, trans_loss=5.234, nll_loss=2.504, w2v_ctc_loss=0.413, task_loss=1.564, contrastive_loss=0, total=4140.24, n_correct=2725.47, ppl=5.67, accuracy=65.829, wps=6806.5, ups=1.64, wpb=4140.2, bsz=149.3, num_updates=34900, lr=7.57011e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=60, gb_free=15.3, wall=26776
2023-07-04 21:35:08 | INFO | train_inner | epoch 024:   1114 / 1474 loss=1.341, trans_loss=5.219, nll_loss=2.485, w2v_ctc_loss=0.416, task_loss=1.467, contrastive_loss=0, total=4130.49, n_correct=2727.7, ppl=5.6, accuracy=66.038, wps=6872.4, ups=1.66, wpb=4130.5, bsz=154.4, num_updates=35000, lr=7.55929e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=26836
tensor(0.0230, device='cuda:0')
tensor(0.0005, device='cuda:0')
2023-07-04 21:36:08 | INFO | train_inner | epoch 024:   1214 / 1474 loss=1.347, trans_loss=5.239, nll_loss=2.51, w2v_ctc_loss=0.416, task_loss=1.502, contrastive_loss=0, total=4157.47, n_correct=2731.28, ppl=5.7, accuracy=65.696, wps=6901.3, ups=1.66, wpb=4157.5, bsz=155.6, num_updates=35100, lr=7.54851e-05, gnorm=0.338, clip=0, loss_scale=64, train_wall=60, gb_free=13.1, wall=26896
2023-07-04 21:37:08 | INFO | train_inner | epoch 024:   1314 / 1474 loss=1.354, trans_loss=5.247, nll_loss=2.52, w2v_ctc_loss=0.425, task_loss=1.61, contrastive_loss=0, total=4107.23, n_correct=2695.38, ppl=5.74, accuracy=65.625, wps=6821.1, ups=1.66, wpb=4107.2, bsz=147.2, num_updates=35200, lr=7.53778e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=60, gb_free=17.7, wall=26957
2023-07-04 21:38:09 | INFO | train_inner | epoch 024:   1414 / 1474 loss=1.353, trans_loss=5.249, nll_loss=2.523, w2v_ctc_loss=0.427, task_loss=1.585, contrastive_loss=0, total=4094.39, n_correct=2684.3, ppl=5.75, accuracy=65.56, wps=6768.6, ups=1.65, wpb=4094.4, bsz=146.4, num_updates=35300, lr=7.5271e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=27017
2023-07-04 21:38:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0230, device='cuda:5')
tensor(0.0005, device='cuda:5')
tensor(0.0230, device='cuda:2')
tensor(0.0005, device='cuda:2')
tensor(0.0230, device='cuda:6')
tensor(0.0005, device='cuda:6')
tensor(0.0230, device='cuda:7')
tensor(0.0005, device='cuda:7')
tensor(0.0230, device='cuda:4')
tensor(0.0005, device='cuda:4')
tensor(0.0230, device='cuda:1')
tensor(0.0005, device='cuda:1')
tensor(0.0230, device='cuda:3')
tensor(0.0005, device='cuda:3')
2023-07-04 21:39:09 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 2.158 | trans_loss 5.556 | nll_loss 2.827 | w2v_ctc_loss 0.711 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2494.9 | ppl 7.1 | accuracy 62.32 | uer 16.752 | wer 18.582 | raw_wer 18.582 | bleu 20.16 | wps 2257.7 | wpb 4003.4 | bsz 141.8 | num_updates 35360 | best_bleu 20.28
2023-07-04 21:39:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35360 updates
2023-07-04 21:39:09 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.1600.pt
2023-07-04 21:39:12 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.1600.pt
2023-07-04 21:39:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.1600.pt (epoch 24 @ 35360 updates, score 20.16) (writing took 5.65661333873868 seconds)
2023-07-04 21:39:15 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-07-04 21:39:15 | INFO | train | epoch 024 | loss 1.346 | trans_loss 5.23 | nll_loss 2.498 | w2v_ctc_loss 0.417 | task_loss 1.514 | contrastive_loss 0 | total 4139.14 | n_correct 2726.99 | ppl 5.65 | accuracy 65.883 | wps 6383.8 | ups 1.54 | wpb 4139.1 | bsz 152.9 | num_updates 35360 | lr 7.52071e-05 | gnorm 0.337 | clip 0 | loss_scale 64 | train_wall 879 | gb_free 16.3 | wall 27084
2023-07-04 21:39:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 21:39:16 | INFO | fairseq.trainer | begin training epoch 25
2023-07-04 21:39:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 21:39:48 | INFO | train_inner | epoch 025:     40 / 1474 loss=1.339, trans_loss=5.213, nll_loss=2.476, w2v_ctc_loss=0.413, task_loss=1.454, contrastive_loss=0, total=4165.57, n_correct=2757.05, ppl=5.56, accuracy=66.187, wps=4223.3, ups=1.01, wpb=4165.6, bsz=155.6, num_updates=35400, lr=7.51646e-05, gnorm=0.331, clip=0, loss_scale=64, train_wall=59, gb_free=13.5, wall=27116
2023-07-04 21:40:47 | INFO | train_inner | epoch 025:    140 / 1474 loss=1.336, trans_loss=5.198, nll_loss=2.456, w2v_ctc_loss=0.41, task_loss=1.471, contrastive_loss=0, total=4135.43, n_correct=2748.43, ppl=5.49, accuracy=66.461, wps=6917.6, ups=1.67, wpb=4135.4, bsz=154.5, num_updates=35500, lr=7.50587e-05, gnorm=0.337, clip=0, loss_scale=64, train_wall=59, gb_free=17.8, wall=27176
2023-07-04 21:41:48 | INFO | train_inner | epoch 025:    240 / 1474 loss=1.336, trans_loss=5.205, nll_loss=2.466, w2v_ctc_loss=0.413, task_loss=1.554, contrastive_loss=0, total=4116.13, n_correct=2727.18, ppl=5.52, accuracy=66.256, wps=6785.5, ups=1.65, wpb=4116.1, bsz=151.5, num_updates=35600, lr=7.49532e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=60, gb_free=17.4, wall=27236
2023-07-04 21:42:49 | INFO | train_inner | epoch 025:    340 / 1474 loss=1.338, trans_loss=5.206, nll_loss=2.464, w2v_ctc_loss=0.411, task_loss=1.619, contrastive_loss=0, total=4141.49, n_correct=2743.4, ppl=5.52, accuracy=66.242, wps=6815.3, ups=1.65, wpb=4141.5, bsz=147.1, num_updates=35700, lr=7.48481e-05, gnorm=0.336, clip=0, loss_scale=64, train_wall=60, gb_free=15.4, wall=27297
2023-07-04 21:43:49 | INFO | train_inner | epoch 025:    440 / 1474 loss=1.349, trans_loss=5.221, nll_loss=2.485, w2v_ctc_loss=0.423, task_loss=1.586, contrastive_loss=0, total=4167.4, n_correct=2753.21, ppl=5.6, accuracy=66.065, wps=6874.2, ups=1.65, wpb=4167.4, bsz=148.8, num_updates=35800, lr=7.47435e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=60, gb_free=16, wall=27358
2023-07-04 21:44:50 | INFO | train_inner | epoch 025:    540 / 1474 loss=1.343, trans_loss=5.225, nll_loss=2.492, w2v_ctc_loss=0.42, task_loss=1.479, contrastive_loss=0, total=4160.61, n_correct=2745.78, ppl=5.62, accuracy=65.995, wps=6903.6, ups=1.66, wpb=4160.6, bsz=157, num_updates=35900, lr=7.46393e-05, gnorm=0.337, clip=0, loss_scale=64, train_wall=60, gb_free=17.7, wall=27418
2023-07-04 21:45:49 | INFO | train_inner | epoch 025:    640 / 1474 loss=1.34, trans_loss=5.213, nll_loss=2.477, w2v_ctc_loss=0.414, task_loss=1.505, contrastive_loss=0, total=4153.68, n_correct=2748.94, ppl=5.57, accuracy=66.181, wps=6994.8, ups=1.68, wpb=4153.7, bsz=154.8, num_updates=36000, lr=7.45356e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=59, gb_free=16.6, wall=27477
2023-07-04 21:45:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 21:46:13 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 2.155 | trans_loss 5.56 | nll_loss 2.834 | w2v_ctc_loss 0.696 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2485.6 | ppl 7.13 | accuracy 62.087 | uer 16.627 | wer 18.568 | raw_wer 18.568 | bleu 19.96 | wps 2283 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.28
2023-07-04 21:46:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-07-04 21:46:13 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_25_36000.pt
2023-07-04 21:46:16 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_25_36000.pt
2023-07-04 21:46:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 19.96) (writing took 5.7077908692881465 seconds)
2023-07-04 21:47:19 | INFO | train_inner | epoch 025:    740 / 1474 loss=1.341, trans_loss=5.218, nll_loss=2.482, w2v_ctc_loss=0.415, task_loss=1.537, contrastive_loss=0, total=4128.34, n_correct=2727.75, ppl=5.59, accuracy=66.074, wps=4584, ups=1.11, wpb=4128.3, bsz=150.6, num_updates=36100, lr=7.44323e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=59, gb_free=17.2, wall=27567
2023-07-04 21:48:19 | INFO | train_inner | epoch 025:    840 / 1474 loss=1.342, trans_loss=5.216, nll_loss=2.481, w2v_ctc_loss=0.411, task_loss=1.39, contrastive_loss=0, total=4182.4, n_correct=2767.13, ppl=5.58, accuracy=66.161, wps=7013.8, ups=1.68, wpb=4182.4, bsz=163, num_updates=36200, lr=7.43294e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=59, gb_free=17.8, wall=27627
2023-07-04 21:49:19 | INFO | train_inner | epoch 025:    940 / 1474 loss=1.342, trans_loss=5.218, nll_loss=2.484, w2v_ctc_loss=0.414, task_loss=1.437, contrastive_loss=0, total=4155.21, n_correct=2747.31, ppl=5.59, accuracy=66.117, wps=6893.2, ups=1.66, wpb=4155.2, bsz=158.5, num_updates=36300, lr=7.4227e-05, gnorm=0.336, clip=0, loss_scale=64, train_wall=60, gb_free=14.4, wall=27687
2023-07-04 21:50:19 | INFO | train_inner | epoch 025:   1040 / 1474 loss=1.345, trans_loss=5.233, nll_loss=2.502, w2v_ctc_loss=0.409, task_loss=1.511, contrastive_loss=0, total=4177.7, n_correct=2749.03, ppl=5.67, accuracy=65.802, wps=6953.9, ups=1.66, wpb=4177.7, bsz=154.9, num_updates=36400, lr=7.41249e-05, gnorm=0.337, clip=0, loss_scale=64, train_wall=60, gb_free=15.9, wall=27747
2023-07-04 21:51:19 | INFO | train_inner | epoch 025:   1140 / 1474 loss=1.341, trans_loss=5.223, nll_loss=2.489, w2v_ctc_loss=0.412, task_loss=1.634, contrastive_loss=0, total=4039.24, n_correct=2663.46, ppl=5.61, accuracy=65.94, wps=6741, ups=1.67, wpb=4039.2, bsz=142.6, num_updates=36500, lr=7.40233e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=59, gb_free=16.6, wall=27807
2023-07-04 21:52:18 | INFO | train_inner | epoch 025:   1240 / 1474 loss=1.344, trans_loss=5.225, nll_loss=2.492, w2v_ctc_loss=0.414, task_loss=1.536, contrastive_loss=0, total=4090.59, n_correct=2699.48, ppl=5.63, accuracy=65.992, wps=6916.5, ups=1.69, wpb=4090.6, bsz=147.8, num_updates=36600, lr=7.39221e-05, gnorm=0.338, clip=0, loss_scale=64, train_wall=59, gb_free=17.4, wall=27866
2023-07-04 21:53:19 | INFO | train_inner | epoch 025:   1340 / 1474 loss=1.344, trans_loss=5.218, nll_loss=2.484, w2v_ctc_loss=0.413, task_loss=1.473, contrastive_loss=0, total=4164.34, n_correct=2753.65, ppl=5.59, accuracy=66.125, wps=6885.4, ups=1.65, wpb=4164.3, bsz=155.1, num_updates=36700, lr=7.38213e-05, gnorm=0.337, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=27927
2023-07-04 21:54:19 | INFO | train_inner | epoch 025:   1440 / 1474 loss=1.347, trans_loss=5.246, nll_loss=2.518, w2v_ctc_loss=0.418, task_loss=1.577, contrastive_loss=0, total=4099.11, n_correct=2690.55, ppl=5.73, accuracy=65.637, wps=6769.9, ups=1.65, wpb=4099.1, bsz=149.7, num_updates=36800, lr=7.3721e-05, gnorm=0.338, clip=0, loss_scale=64, train_wall=60, gb_free=12.7, wall=27987
2023-07-04 21:54:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 21:55:04 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 2.144 | trans_loss 5.547 | nll_loss 2.821 | w2v_ctc_loss 0.673 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2491.5 | ppl 7.07 | accuracy 62.235 | uer 16.465 | wer 18.59 | raw_wer 18.59 | bleu 19.97 | wps 2206.9 | wpb 4003.4 | bsz 141.8 | num_updates 36834 | best_bleu 20.28
2023-07-04 21:55:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36834 updates
2023-07-04 21:55:04 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt
2023-07-04 21:55:09 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt
2023-07-04 21:55:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt (epoch 25 @ 36834 updates, score 19.97) (writing took 4.4025005688890815 seconds)
2023-07-04 21:55:09 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-07-04 21:55:09 | INFO | train | epoch 025 | loss 1.342 | trans_loss 5.219 | nll_loss 2.483 | w2v_ctc_loss 0.414 | task_loss 1.515 | contrastive_loss 0 | total 4138.65 | n_correct 2734.75 | ppl 5.59 | accuracy 66.078 | wps 6398 | ups 1.55 | wpb 4138.6 | bsz 152.8 | num_updates 36834 | lr 7.36869e-05 | gnorm 0.338 | clip 0 | loss_scale 64 | train_wall 879 | gb_free 14.6 | wall 28037
2023-07-04 21:55:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 21:55:09 | INFO | fairseq.trainer | begin training epoch 26
2023-07-04 21:55:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 21:55:57 | INFO | train_inner | epoch 026:     66 / 1474 loss=1.329, trans_loss=5.191, nll_loss=2.448, w2v_ctc_loss=0.402, task_loss=1.419, contrastive_loss=0, total=4180.21, n_correct=2782.31, ppl=5.46, accuracy=66.559, wps=4291.9, ups=1.03, wpb=4180.2, bsz=159.2, num_updates=36900, lr=7.3621e-05, gnorm=0.335, clip=0, loss_scale=64, train_wall=59, gb_free=17.2, wall=28085
2023-07-04 21:56:57 | INFO | train_inner | epoch 026:    166 / 1474 loss=1.332, trans_loss=5.187, nll_loss=2.443, w2v_ctc_loss=0.398, task_loss=1.326, contrastive_loss=0, total=4270.78, n_correct=2851.77, ppl=5.44, accuracy=66.774, wps=7091, ups=1.66, wpb=4270.8, bsz=170.2, num_updates=37000, lr=7.35215e-05, gnorm=0.329, clip=0, loss_scale=128, train_wall=60, gb_free=15.5, wall=28145
2023-07-04 21:57:57 | INFO | train_inner | epoch 026:    266 / 1474 loss=1.34, trans_loss=5.204, nll_loss=2.464, w2v_ctc_loss=0.415, task_loss=1.503, contrastive_loss=0, total=4125.04, n_correct=2734.24, ppl=5.52, accuracy=66.284, wps=6906.8, ups=1.67, wpb=4125, bsz=153.6, num_updates=37100, lr=7.34223e-05, gnorm=0.34, clip=0, loss_scale=128, train_wall=59, gb_free=15.4, wall=28205
2023-07-04 21:58:56 | INFO | train_inner | epoch 026:    366 / 1474 loss=1.334, trans_loss=5.195, nll_loss=2.453, w2v_ctc_loss=0.406, task_loss=1.451, contrastive_loss=0, total=4165.74, n_correct=2767.99, ppl=5.47, accuracy=66.447, wps=6990, ups=1.68, wpb=4165.7, bsz=157.3, num_updates=37200, lr=7.33236e-05, gnorm=0.335, clip=0, loss_scale=128, train_wall=59, gb_free=17, wall=28264
2023-07-04 21:59:56 | INFO | train_inner | epoch 026:    466 / 1474 loss=1.336, trans_loss=5.188, nll_loss=2.444, w2v_ctc_loss=0.407, task_loss=1.44, contrastive_loss=0, total=4170.23, n_correct=2780.62, ppl=5.44, accuracy=66.678, wps=6936, ups=1.66, wpb=4170.2, bsz=157.7, num_updates=37300, lr=7.32252e-05, gnorm=0.334, clip=0, loss_scale=128, train_wall=60, gb_free=17.9, wall=28325
2023-07-04 22:00:56 | INFO | train_inner | epoch 026:    566 / 1474 loss=1.337, trans_loss=5.206, nll_loss=2.467, w2v_ctc_loss=0.417, task_loss=1.52, contrastive_loss=0, total=4155.02, n_correct=2754.18, ppl=5.53, accuracy=66.286, wps=6909.4, ups=1.66, wpb=4155, bsz=151.9, num_updates=37400, lr=7.31272e-05, gnorm=0.337, clip=0, loss_scale=128, train_wall=60, gb_free=17.9, wall=28385
2023-07-04 22:01:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-04 22:01:57 | INFO | train_inner | epoch 026:    667 / 1474 loss=1.333, trans_loss=5.195, nll_loss=2.453, w2v_ctc_loss=0.403, task_loss=1.546, contrastive_loss=0, total=4132.23, n_correct=2746.24, ppl=5.47, accuracy=66.459, wps=6837.9, ups=1.65, wpb=4132.2, bsz=149.4, num_updates=37500, lr=7.30297e-05, gnorm=0.338, clip=0, loss_scale=64, train_wall=60, gb_free=14.2, wall=28445
2023-07-04 22:02:56 | INFO | train_inner | epoch 026:    767 / 1474 loss=1.339, trans_loss=5.21, nll_loss=2.472, w2v_ctc_loss=0.409, task_loss=1.528, contrastive_loss=0, total=4096.84, n_correct=2712.16, ppl=5.55, accuracy=66.201, wps=6879.6, ups=1.68, wpb=4096.8, bsz=150.3, num_updates=37600, lr=7.29325e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=59, gb_free=16.9, wall=28505
2023-07-04 22:03:57 | INFO | train_inner | epoch 026:    867 / 1474 loss=1.342, trans_loss=5.205, nll_loss=2.465, w2v_ctc_loss=0.414, task_loss=1.512, contrastive_loss=0, total=4176.27, n_correct=2768.89, ppl=5.52, accuracy=66.301, wps=6940.9, ups=1.66, wpb=4176.3, bsz=153.2, num_updates=37700, lr=7.28357e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=28565
2023-07-04 22:04:56 | INFO | train_inner | epoch 026:    967 / 1474 loss=1.34, trans_loss=5.217, nll_loss=2.481, w2v_ctc_loss=0.407, task_loss=1.557, contrastive_loss=0, total=4141.01, n_correct=2736.43, ppl=5.58, accuracy=66.081, wps=6925, ups=1.67, wpb=4141, bsz=149.8, num_updates=37800, lr=7.27393e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=59, gb_free=15.7, wall=28625
2023-07-04 22:05:57 | INFO | train_inner | epoch 026:   1067 / 1474 loss=1.337, trans_loss=5.211, nll_loss=2.474, w2v_ctc_loss=0.411, task_loss=1.603, contrastive_loss=0, total=4113.69, n_correct=2722.93, ppl=5.56, accuracy=66.192, wps=6845.3, ups=1.66, wpb=4113.7, bsz=146.5, num_updates=37900, lr=7.26433e-05, gnorm=0.338, clip=0, loss_scale=64, train_wall=60, gb_free=15.8, wall=28685
2023-07-04 22:06:57 | INFO | train_inner | epoch 026:   1167 / 1474 loss=1.344, trans_loss=5.225, nll_loss=2.492, w2v_ctc_loss=0.416, task_loss=1.589, contrastive_loss=0, total=4116.78, n_correct=2715.05, ppl=5.63, accuracy=65.951, wps=6786.5, ups=1.65, wpb=4116.8, bsz=149.5, num_updates=38000, lr=7.25476e-05, gnorm=0.344, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=28745
2023-07-04 22:06:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 22:07:22 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 2.157 | trans_loss 5.56 | nll_loss 2.833 | w2v_ctc_loss 0.705 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2487.3 | ppl 7.13 | accuracy 62.13 | uer 16.649 | wer 18.5 | raw_wer 18.5 | bleu 20.12 | wps 2119.9 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.28
2023-07-04 22:07:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-07-04 22:07:22 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_26_38000.pt
2023-07-04 22:07:25 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_26_38000.pt
2023-07-04 22:07:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 20.12) (writing took 6.756653678137809 seconds)
2023-07-04 22:08:30 | INFO | train_inner | epoch 026:   1267 / 1474 loss=1.346, trans_loss=5.236, nll_loss=2.506, w2v_ctc_loss=0.421, task_loss=1.68, contrastive_loss=0, total=4001.06, n_correct=2628.91, ppl=5.68, accuracy=65.705, wps=4325.2, ups=1.08, wpb=4001.1, bsz=140.3, num_updates=38100, lr=7.24524e-05, gnorm=0.347, clip=0, loss_scale=64, train_wall=60, gb_free=15.9, wall=28838
2023-07-04 22:09:30 | INFO | train_inner | epoch 026:   1367 / 1474 loss=1.34, trans_loss=5.219, nll_loss=2.485, w2v_ctc_loss=0.41, task_loss=1.523, contrastive_loss=0, total=4157.69, n_correct=2749.09, ppl=5.6, accuracy=66.121, wps=6857.8, ups=1.65, wpb=4157.7, bsz=155.3, num_updates=38200, lr=7.23575e-05, gnorm=0.338, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=28899
2023-07-04 22:10:30 | INFO | train_inner | epoch 026:   1467 / 1474 loss=1.336, trans_loss=5.211, nll_loss=2.475, w2v_ctc_loss=0.405, task_loss=1.442, contrastive_loss=0, total=4158.47, n_correct=2755.49, ppl=5.56, accuracy=66.262, wps=6970.7, ups=1.68, wpb=4158.5, bsz=158.3, num_updates=38300, lr=7.22629e-05, gnorm=0.337, clip=0, loss_scale=64, train_wall=59, gb_free=17.5, wall=28958
2023-07-04 22:10:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 22:10:59 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 2.147 | trans_loss 5.553 | nll_loss 2.828 | w2v_ctc_loss 0.68 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2491.4 | ppl 7.1 | accuracy 62.232 | uer 16.426 | wer 18.266 | raw_wer 18.266 | bleu 20.01 | wps 2150.5 | wpb 4003.4 | bsz 141.8 | num_updates 38307 | best_bleu 20.28
2023-07-04 22:10:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38307 updates
2023-07-04 22:10:59 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt
2023-07-04 22:11:04 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt
2023-07-04 22:11:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt (epoch 26 @ 38307 updates, score 20.01) (writing took 4.38037190027535 seconds)
2023-07-04 22:11:04 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-07-04 22:11:04 | INFO | train | epoch 026 | loss 1.338 | trans_loss 5.206 | nll_loss 2.467 | w2v_ctc_loss 0.409 | task_loss 1.514 | contrastive_loss 0 | total 4138.66 | n_correct 2743.94 | ppl 5.53 | accuracy 66.3 | wps 6384.4 | ups 1.54 | wpb 4138.7 | bsz 152.9 | num_updates 38307 | lr 7.22563e-05 | gnorm 0.338 | clip 0 | loss_scale 64 | train_wall 878 | gb_free 16.2 | wall 28992
2023-07-04 22:11:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 22:11:04 | INFO | fairseq.trainer | begin training epoch 27
2023-07-04 22:11:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 22:12:07 | INFO | train_inner | epoch 027:     93 / 1474 loss=1.327, trans_loss=5.164, nll_loss=2.411, w2v_ctc_loss=0.402, task_loss=1.625, contrastive_loss=0, total=4067.62, n_correct=2722.69, ppl=5.32, accuracy=66.936, wps=4189, ups=1.03, wpb=4067.6, bsz=142.2, num_updates=38400, lr=7.21688e-05, gnorm=0.344, clip=0, loss_scale=64, train_wall=59, gb_free=15.1, wall=29055
2023-07-04 22:13:07 | INFO | train_inner | epoch 027:    193 / 1474 loss=1.328, trans_loss=5.17, nll_loss=2.42, w2v_ctc_loss=0.405, task_loss=1.439, contrastive_loss=0, total=4185.52, n_correct=2799.75, ppl=5.35, accuracy=66.891, wps=6995.4, ups=1.67, wpb=4185.5, bsz=160.8, num_updates=38500, lr=7.2075e-05, gnorm=0.337, clip=0, loss_scale=64, train_wall=59, gb_free=17.7, wall=29115
2023-07-04 22:14:07 | INFO | train_inner | epoch 027:    293 / 1474 loss=1.33, trans_loss=5.183, nll_loss=2.436, w2v_ctc_loss=0.405, task_loss=1.509, contrastive_loss=0, total=4167.92, n_correct=2782.01, ppl=5.41, accuracy=66.748, wps=6923.3, ups=1.66, wpb=4167.9, bsz=153.4, num_updates=38600, lr=7.19816e-05, gnorm=0.334, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=29175
2023-07-04 22:15:08 | INFO | train_inner | epoch 027:    393 / 1474 loss=1.335, trans_loss=5.2, nll_loss=2.459, w2v_ctc_loss=0.407, task_loss=1.594, contrastive_loss=0, total=4075.21, n_correct=2706.11, ppl=5.5, accuracy=66.404, wps=6681.7, ups=1.64, wpb=4075.2, bsz=148, num_updates=38700, lr=7.18885e-05, gnorm=0.336, clip=0, loss_scale=64, train_wall=61, gb_free=17.8, wall=29236
2023-07-04 22:16:09 | INFO | train_inner | epoch 027:    493 / 1474 loss=1.335, trans_loss=5.198, nll_loss=2.457, w2v_ctc_loss=0.406, task_loss=1.381, contrastive_loss=0, total=4249.35, n_correct=2821.02, ppl=5.49, accuracy=66.387, wps=7028.2, ups=1.65, wpb=4249.4, bsz=166, num_updates=38800, lr=7.17958e-05, gnorm=0.334, clip=0, loss_scale=64, train_wall=60, gb_free=12.4, wall=29297
2023-07-04 22:17:08 | INFO | train_inner | epoch 027:    593 / 1474 loss=1.334, trans_loss=5.196, nll_loss=2.455, w2v_ctc_loss=0.407, task_loss=1.492, contrastive_loss=0, total=4133.39, n_correct=2748.14, ppl=5.48, accuracy=66.486, wps=6940, ups=1.68, wpb=4133.4, bsz=156, num_updates=38900, lr=7.17035e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=59, gb_free=12.5, wall=29356
2023-07-04 22:18:08 | INFO | train_inner | epoch 027:    693 / 1474 loss=1.339, trans_loss=5.207, nll_loss=2.469, w2v_ctc_loss=0.413, task_loss=1.51, contrastive_loss=0, total=4162.71, n_correct=2759.84, ppl=5.54, accuracy=66.299, wps=6988.1, ups=1.68, wpb=4162.7, bsz=152.7, num_updates=39000, lr=7.16115e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=59, gb_free=16.5, wall=29416
2023-07-04 22:19:07 | INFO | train_inner | epoch 027:    793 / 1474 loss=1.337, trans_loss=5.2, nll_loss=2.459, w2v_ctc_loss=0.412, task_loss=1.591, contrastive_loss=0, total=4103.81, n_correct=2721.79, ppl=5.5, accuracy=66.323, wps=6918.1, ups=1.69, wpb=4103.8, bsz=147.1, num_updates=39100, lr=7.15199e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=59, gb_free=16.7, wall=29475
2023-07-04 22:20:06 | INFO | train_inner | epoch 027:    893 / 1474 loss=1.336, trans_loss=5.199, nll_loss=2.457, w2v_ctc_loss=0.404, task_loss=1.582, contrastive_loss=0, total=4101.56, n_correct=2723.52, ppl=5.49, accuracy=66.402, wps=6926.5, ups=1.69, wpb=4101.6, bsz=146.1, num_updates=39200, lr=7.14286e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=59, gb_free=17.8, wall=29535
2023-07-04 22:21:07 | INFO | train_inner | epoch 027:    993 / 1474 loss=1.336, trans_loss=5.206, nll_loss=2.469, w2v_ctc_loss=0.41, task_loss=1.462, contrastive_loss=0, total=4199.56, n_correct=2785.07, ppl=5.54, accuracy=66.318, wps=6971.3, ups=1.66, wpb=4199.6, bsz=158.4, num_updates=39300, lr=7.13376e-05, gnorm=0.336, clip=0, loss_scale=64, train_wall=60, gb_free=12.1, wall=29595
2023-07-04 22:22:06 | INFO | train_inner | epoch 027:   1093 / 1474 loss=1.333, trans_loss=5.196, nll_loss=2.455, w2v_ctc_loss=0.408, task_loss=1.525, contrastive_loss=0, total=4150.97, n_correct=2756.84, ppl=5.48, accuracy=66.414, wps=6936, ups=1.67, wpb=4151, bsz=152.5, num_updates=39400, lr=7.1247e-05, gnorm=0.338, clip=0, loss_scale=64, train_wall=59, gb_free=12.4, wall=29655
2023-07-04 22:23:07 | INFO | train_inner | epoch 027:   1193 / 1474 loss=1.335, trans_loss=5.203, nll_loss=2.463, w2v_ctc_loss=0.408, task_loss=1.58, contrastive_loss=0, total=4103.06, n_correct=2720.73, ppl=5.51, accuracy=66.31, wps=6770.1, ups=1.65, wpb=4103.1, bsz=148.8, num_updates=39500, lr=7.11568e-05, gnorm=0.335, clip=0, loss_scale=128, train_wall=60, gb_free=16.8, wall=29715
2023-07-04 22:24:07 | INFO | train_inner | epoch 027:   1293 / 1474 loss=1.335, trans_loss=5.208, nll_loss=2.47, w2v_ctc_loss=0.406, task_loss=1.621, contrastive_loss=0, total=4062.52, n_correct=2690.82, ppl=5.54, accuracy=66.235, wps=6829, ups=1.68, wpb=4062.5, bsz=146.1, num_updates=39600, lr=7.10669e-05, gnorm=0.342, clip=0, loss_scale=128, train_wall=59, gb_free=16.7, wall=29775
2023-07-04 22:25:05 | INFO | train_inner | epoch 027:   1393 / 1474 loss=1.339, trans_loss=5.207, nll_loss=2.47, w2v_ctc_loss=0.409, task_loss=1.433, contrastive_loss=0, total=4152, n_correct=2748.26, ppl=5.54, accuracy=66.191, wps=7048.4, ups=1.7, wpb=4152, bsz=156.2, num_updates=39700, lr=7.09773e-05, gnorm=0.343, clip=0, loss_scale=128, train_wall=58, gb_free=16.8, wall=29834
2023-07-04 22:25:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 22:26:19 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 2.147 | trans_loss 5.55 | nll_loss 2.822 | w2v_ctc_loss 0.683 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2490.5 | ppl 7.07 | accuracy 62.21 | uer 16.553 | wer 18.459 | raw_wer 18.459 | bleu 20.07 | wps 2160.1 | wpb 4003.4 | bsz 141.8 | num_updates 39781 | best_bleu 20.28
2023-07-04 22:26:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39781 updates
2023-07-04 22:26:19 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.0701.pt
2023-07-04 22:26:21 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.0701.pt
2023-07-04 22:26:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.0701.pt (epoch 27 @ 39781 updates, score 20.07) (writing took 5.713682414963841 seconds)
2023-07-04 22:26:25 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-07-04 22:26:25 | INFO | train | epoch 027 | loss 1.334 | trans_loss 5.195 | nll_loss 2.453 | w2v_ctc_loss 0.407 | task_loss 1.515 | contrastive_loss 0 | total 4138.65 | n_correct 2750.89 | ppl 5.47 | accuracy 66.468 | wps 6622.3 | ups 1.6 | wpb 4138.6 | bsz 152.8 | num_updates 39781 | lr 7.0905e-05 | gnorm 0.338 | clip 0 | loss_scale 128 | train_wall 875 | gb_free 17.9 | wall 29913
2023-07-04 22:26:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 22:26:25 | INFO | fairseq.trainer | begin training epoch 28
2023-07-04 22:26:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 22:26:44 | INFO | train_inner | epoch 028:     19 / 1474 loss=1.331, trans_loss=5.183, nll_loss=2.438, w2v_ctc_loss=0.399, task_loss=1.466, contrastive_loss=0, total=4108.43, n_correct=2742.49, ppl=5.42, accuracy=66.753, wps=4157.9, ups=1.01, wpb=4108.4, bsz=152.6, num_updates=39800, lr=7.08881e-05, gnorm=0.339, clip=0, loss_scale=128, train_wall=59, gb_free=16.5, wall=29932
2023-07-04 22:27:44 | INFO | train_inner | epoch 028:    119 / 1474 loss=1.33, trans_loss=5.169, nll_loss=2.418, w2v_ctc_loss=0.406, task_loss=1.587, contrastive_loss=0, total=4113.41, n_correct=2753.68, ppl=5.34, accuracy=66.944, wps=6929.3, ups=1.68, wpb=4113.4, bsz=147, num_updates=39900, lr=7.07992e-05, gnorm=0.345, clip=0, loss_scale=128, train_wall=59, gb_free=17.2, wall=29992
2023-07-04 22:28:43 | INFO | train_inner | epoch 028:    219 / 1474 loss=1.325, trans_loss=5.165, nll_loss=2.414, w2v_ctc_loss=0.399, task_loss=1.434, contrastive_loss=0, total=4191.56, n_correct=2809.55, ppl=5.33, accuracy=67.029, wps=7037.3, ups=1.68, wpb=4191.6, bsz=157.6, num_updates=40000, lr=7.07107e-05, gnorm=0.336, clip=0, loss_scale=128, train_wall=59, gb_free=15.4, wall=30051
2023-07-04 22:28:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 22:29:08 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 2.152 | trans_loss 5.554 | nll_loss 2.825 | w2v_ctc_loss 0.693 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2495.1 | ppl 7.08 | accuracy 62.325 | uer 16.595 | wer 18.59 | raw_wer 18.59 | bleu 20.26 | wps 2122.4 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.28
2023-07-04 22:29:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-07-04 22:29:08 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_28_40000.pt
2023-07-04 22:29:10 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_28_40000.pt
2023-07-04 22:29:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 20.26) (writing took 6.850219143088907 seconds)
tensor(0.0230, device='cuda:0')
tensor(0.0005, device='cuda:0')
2023-07-04 22:30:16 | INFO | train_inner | epoch 028:    319 / 1474 loss=1.331, trans_loss=5.182, nll_loss=2.437, w2v_ctc_loss=0.395, task_loss=1.502, contrastive_loss=0, total=4145.32, n_correct=2762.98, ppl=5.41, accuracy=66.653, wps=4458.8, ups=1.08, wpb=4145.3, bsz=158.1, num_updates=40100, lr=7.06225e-05, gnorm=0.338, clip=0, loss_scale=128, train_wall=60, gb_free=15.9, wall=30144
2023-07-04 22:31:16 | INFO | train_inner | epoch 028:    419 / 1474 loss=1.329, trans_loss=5.178, nll_loss=2.43, w2v_ctc_loss=0.407, task_loss=1.563, contrastive_loss=0, total=4092.14, n_correct=2731.93, ppl=5.39, accuracy=66.76, wps=6802.1, ups=1.66, wpb=4092.1, bsz=147.8, num_updates=40200, lr=7.05346e-05, gnorm=0.348, clip=0, loss_scale=128, train_wall=60, gb_free=16.6, wall=30205
2023-07-04 22:32:16 | INFO | train_inner | epoch 028:    519 / 1474 loss=1.328, trans_loss=5.176, nll_loss=2.429, w2v_ctc_loss=0.401, task_loss=1.577, contrastive_loss=0, total=4096.35, n_correct=2732.7, ppl=5.39, accuracy=66.711, wps=6882.1, ups=1.68, wpb=4096.4, bsz=147.8, num_updates=40300, lr=7.0447e-05, gnorm=0.339, clip=0, loss_scale=128, train_wall=59, gb_free=16.2, wall=30264
2023-07-04 22:33:16 | INFO | train_inner | epoch 028:    619 / 1474 loss=1.33, trans_loss=5.183, nll_loss=2.437, w2v_ctc_loss=0.403, task_loss=1.526, contrastive_loss=0, total=4178.12, n_correct=2784.43, ppl=5.41, accuracy=66.643, wps=6996.5, ups=1.67, wpb=4178.1, bsz=152.7, num_updates=40400, lr=7.03598e-05, gnorm=0.339, clip=0, loss_scale=128, train_wall=59, gb_free=16.1, wall=30324
2023-07-04 22:34:16 | INFO | train_inner | epoch 028:    719 / 1474 loss=1.33, trans_loss=5.184, nll_loss=2.44, w2v_ctc_loss=0.398, task_loss=1.374, contrastive_loss=0, total=4185.82, n_correct=2792.14, ppl=5.43, accuracy=66.705, wps=6981.7, ups=1.67, wpb=4185.8, bsz=163.2, num_updates=40500, lr=7.02728e-05, gnorm=0.338, clip=0, loss_scale=128, train_wall=60, gb_free=16.1, wall=30384
2023-07-04 22:35:15 | INFO | train_inner | epoch 028:    819 / 1474 loss=1.329, trans_loss=5.178, nll_loss=2.431, w2v_ctc_loss=0.4, task_loss=1.484, contrastive_loss=0, total=4096.2, n_correct=2736.46, ppl=5.39, accuracy=66.805, wps=6902.1, ups=1.68, wpb=4096.2, bsz=153.5, num_updates=40600, lr=7.01862e-05, gnorm=0.341, clip=0, loss_scale=128, train_wall=59, gb_free=15.9, wall=30443
2023-07-04 22:36:15 | INFO | train_inner | epoch 028:    919 / 1474 loss=1.332, trans_loss=5.197, nll_loss=2.455, w2v_ctc_loss=0.406, task_loss=1.555, contrastive_loss=0, total=4120.27, n_correct=2737.12, ppl=5.48, accuracy=66.431, wps=6815.4, ups=1.65, wpb=4120.3, bsz=150.4, num_updates=40700, lr=7.01e-05, gnorm=0.342, clip=0, loss_scale=128, train_wall=60, gb_free=17.5, wall=30504
2023-07-04 22:37:16 | INFO | train_inner | epoch 028:   1019 / 1474 loss=1.334, trans_loss=5.196, nll_loss=2.455, w2v_ctc_loss=0.406, task_loss=1.481, contrastive_loss=0, total=4177.86, n_correct=2775.36, ppl=5.48, accuracy=66.43, wps=6947.6, ups=1.66, wpb=4177.9, bsz=155.5, num_updates=40800, lr=7.0014e-05, gnorm=0.34, clip=0, loss_scale=128, train_wall=60, gb_free=16.6, wall=30564
2023-07-04 22:38:16 | INFO | train_inner | epoch 028:   1119 / 1474 loss=1.328, trans_loss=5.177, nll_loss=2.431, w2v_ctc_loss=0.401, task_loss=1.469, contrastive_loss=0, total=4210.86, n_correct=2807.66, ppl=5.39, accuracy=66.677, wps=6953.8, ups=1.65, wpb=4210.9, bsz=159.4, num_updates=40900, lr=6.99284e-05, gnorm=0.335, clip=0, loss_scale=128, train_wall=60, gb_free=17.6, wall=30624
2023-07-04 22:39:16 | INFO | train_inner | epoch 028:   1219 / 1474 loss=1.33, trans_loss=5.19, nll_loss=2.448, w2v_ctc_loss=0.402, task_loss=1.496, contrastive_loss=0, total=4104.61, n_correct=2731.07, ppl=5.46, accuracy=66.537, wps=6841.8, ups=1.67, wpb=4104.6, bsz=152.8, num_updates=41000, lr=6.9843e-05, gnorm=0.341, clip=0, loss_scale=128, train_wall=60, gb_free=16.7, wall=30684
2023-07-04 22:40:17 | INFO | train_inner | epoch 028:   1319 / 1474 loss=1.336, trans_loss=5.2, nll_loss=2.46, w2v_ctc_loss=0.412, task_loss=1.663, contrastive_loss=0, total=4087.78, n_correct=2713.3, ppl=5.5, accuracy=66.376, wps=6748.3, ups=1.65, wpb=4087.8, bsz=142.6, num_updates=41100, lr=6.9758e-05, gnorm=0.342, clip=0, loss_scale=128, train_wall=60, gb_free=15.3, wall=30745
2023-07-04 22:41:17 | INFO | train_inner | epoch 028:   1419 / 1474 loss=1.334, trans_loss=5.199, nll_loss=2.458, w2v_ctc_loss=0.406, task_loss=1.595, contrastive_loss=0, total=4145.03, n_correct=2747.85, ppl=5.5, accuracy=66.293, wps=6888.2, ups=1.66, wpb=4145, bsz=148.8, num_updates=41200, lr=6.96733e-05, gnorm=0.339, clip=0, loss_scale=128, train_wall=60, gb_free=17.8, wall=30805
2023-07-04 22:41:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0230, device='cuda:4')
tensor(0.0005, device='cuda:4')
tensor(0.0230, device='cuda:7')
tensor(0.0005, device='cuda:7')
tensor(0.0230, device='cuda:3')
tensor(0.0005, device='cuda:3')
tensor(0.0230, device='cuda:2')
tensor(0.0005, device='cuda:2')
tensor(0.0230, device='cuda:5')
tensor(0.0005, device='cuda:5')
tensor(0.0230, device='cuda:6')
tensor(0.0005, device='cuda:6')
tensor(0.0230, device='cuda:1')
tensor(0.0005, device='cuda:1')
2023-07-04 22:42:14 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 2.147 | trans_loss 5.553 | nll_loss 2.825 | w2v_ctc_loss 0.679 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2492.8 | ppl 7.09 | accuracy 62.267 | uer 16.303 | wer 18.042 | raw_wer 18.042 | bleu 20.07 | wps 2290.5 | wpb 4003.4 | bsz 141.8 | num_updates 41255 | best_bleu 20.28
2023-07-04 22:42:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41255 updates
2023-07-04 22:42:14 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.0708.pt
2023-07-04 22:42:16 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.0708.pt
2023-07-04 22:42:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.0708.pt (epoch 28 @ 41255 updates, score 20.07) (writing took 5.804315427783877 seconds)
2023-07-04 22:42:20 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-07-04 22:42:20 | INFO | train | epoch 028 | loss 1.33 | trans_loss 5.183 | nll_loss 2.438 | w2v_ctc_loss 0.403 | task_loss 1.515 | contrastive_loss 0 | total 4138.65 | n_correct 2758.6 | ppl 5.42 | accuracy 66.655 | wps 6389.4 | ups 1.54 | wpb 4138.6 | bsz 152.8 | num_updates 41255 | lr 6.96268e-05 | gnorm 0.34 | clip 0 | loss_scale 128 | train_wall 877 | gb_free 16.8 | wall 30868
2023-07-04 22:42:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 22:42:20 | INFO | fairseq.trainer | begin training epoch 29
2023-07-04 22:42:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 22:42:55 | INFO | train_inner | epoch 029:     45 / 1474 loss=1.327, trans_loss=5.167, nll_loss=2.418, w2v_ctc_loss=0.404, task_loss=1.463, contrastive_loss=0, total=4163.06, n_correct=2789.99, ppl=5.35, accuracy=67.018, wps=4242.3, ups=1.02, wpb=4163.1, bsz=157, num_updates=41300, lr=6.95889e-05, gnorm=0.337, clip=0, loss_scale=128, train_wall=59, gb_free=16.5, wall=30903
2023-07-04 22:43:55 | INFO | train_inner | epoch 029:    145 / 1474 loss=1.324, trans_loss=5.162, nll_loss=2.41, w2v_ctc_loss=0.398, task_loss=1.49, contrastive_loss=0, total=4116.29, n_correct=2762.27, ppl=5.31, accuracy=67.106, wps=6886.7, ups=1.67, wpb=4116.3, bsz=154.3, num_updates=41400, lr=6.95048e-05, gnorm=0.34, clip=0, loss_scale=128, train_wall=59, gb_free=14.4, wall=30963
2023-07-04 22:44:56 | INFO | train_inner | epoch 029:    245 / 1474 loss=1.321, trans_loss=5.157, nll_loss=2.404, w2v_ctc_loss=0.393, task_loss=1.388, contrastive_loss=0, total=4197.24, n_correct=2818.56, ppl=5.29, accuracy=67.153, wps=6898.4, ups=1.64, wpb=4197.2, bsz=165, num_updates=41500, lr=6.9421e-05, gnorm=0.336, clip=0, loss_scale=128, train_wall=60, gb_free=17.3, wall=31024
2023-07-04 22:45:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-07-04 22:45:56 | INFO | train_inner | epoch 029:    346 / 1474 loss=1.33, trans_loss=5.181, nll_loss=2.435, w2v_ctc_loss=0.408, task_loss=1.621, contrastive_loss=0, total=4096.13, n_correct=2735.34, ppl=5.41, accuracy=66.779, wps=6735.7, ups=1.64, wpb=4096.1, bsz=145.8, num_updates=41600, lr=6.93375e-05, gnorm=0.341, clip=0, loss_scale=128, train_wall=60, gb_free=16.8, wall=31085
2023-07-04 22:46:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-04 22:46:57 | INFO | train_inner | epoch 029:    447 / 1474 loss=1.319, trans_loss=5.147, nll_loss=2.39, w2v_ctc_loss=0.394, task_loss=1.452, contrastive_loss=0, total=4154.87, n_correct=2793.89, ppl=5.24, accuracy=67.244, wps=6847.4, ups=1.65, wpb=4154.9, bsz=154.3, num_updates=41700, lr=6.92543e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=60, gb_free=14.9, wall=31145
2023-07-04 22:47:57 | INFO | train_inner | epoch 029:    547 / 1474 loss=1.336, trans_loss=5.193, nll_loss=2.45, w2v_ctc_loss=0.408, task_loss=1.626, contrastive_loss=0, total=4149.27, n_correct=2760.39, ppl=5.47, accuracy=66.527, wps=6900.4, ups=1.66, wpb=4149.3, bsz=146.6, num_updates=41800, lr=6.91714e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=60, gb_free=15.6, wall=31205
2023-07-04 22:48:57 | INFO | train_inner | epoch 029:    647 / 1474 loss=1.326, trans_loss=5.171, nll_loss=2.424, w2v_ctc_loss=0.401, task_loss=1.415, contrastive_loss=0, total=4145.39, n_correct=2772.33, ppl=5.37, accuracy=66.877, wps=6921.3, ups=1.67, wpb=4145.4, bsz=159.6, num_updates=41900, lr=6.90889e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=59, gb_free=17.5, wall=31265
2023-07-04 22:49:58 | INFO | train_inner | epoch 029:    747 / 1474 loss=1.323, trans_loss=5.166, nll_loss=2.416, w2v_ctc_loss=0.396, task_loss=1.397, contrastive_loss=0, total=4242.46, n_correct=2841.29, ppl=5.34, accuracy=66.973, wps=7018.6, ups=1.65, wpb=4242.5, bsz=164.9, num_updates=42000, lr=6.90066e-05, gnorm=0.331, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=31326
2023-07-04 22:49:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 22:50:22 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 2.16 | trans_loss 5.559 | nll_loss 2.831 | w2v_ctc_loss 0.714 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2486 | ppl 7.11 | accuracy 62.097 | uer 16.587 | wer 18.336 | raw_wer 18.336 | bleu 19.72 | wps 2257.7 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.28
2023-07-04 22:50:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-07-04 22:50:22 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_29_42000.pt
2023-07-04 22:50:24 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_29_42000.pt
2023-07-04 22:50:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 19.72) (writing took 5.357033333275467 seconds)
2023-07-04 22:51:27 | INFO | train_inner | epoch 029:    847 / 1474 loss=1.33, trans_loss=5.188, nll_loss=2.444, w2v_ctc_loss=0.401, task_loss=1.682, contrastive_loss=0, total=4027.03, n_correct=2680.05, ppl=5.44, accuracy=66.552, wps=4487.5, ups=1.11, wpb=4027, bsz=140.2, num_updates=42100, lr=6.89246e-05, gnorm=0.347, clip=0, loss_scale=64, train_wall=59, gb_free=17.5, wall=31416
2023-07-04 22:52:27 | INFO | train_inner | epoch 029:    947 / 1474 loss=1.329, trans_loss=5.182, nll_loss=2.437, w2v_ctc_loss=0.404, task_loss=1.548, contrastive_loss=0, total=4086.72, n_correct=2728, ppl=5.41, accuracy=66.753, wps=6836.5, ups=1.67, wpb=4086.7, bsz=148.2, num_updates=42200, lr=6.88428e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=59, gb_free=15.6, wall=31475
2023-07-04 22:53:27 | INFO | train_inner | epoch 029:   1047 / 1474 loss=1.324, trans_loss=5.168, nll_loss=2.419, w2v_ctc_loss=0.397, task_loss=1.516, contrastive_loss=0, total=4139.4, n_correct=2766.48, ppl=5.35, accuracy=66.833, wps=6855.5, ups=1.66, wpb=4139.4, bsz=153.7, num_updates=42300, lr=6.87614e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=60, gb_free=15.8, wall=31536
2023-07-04 22:54:27 | INFO | train_inner | epoch 029:   1147 / 1474 loss=1.331, trans_loss=5.186, nll_loss=2.442, w2v_ctc_loss=0.405, task_loss=1.646, contrastive_loss=0, total=4072.33, n_correct=2711.37, ppl=5.43, accuracy=66.58, wps=6839.1, ups=1.68, wpb=4072.3, bsz=142, num_updates=42400, lr=6.86803e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=59, gb_free=17, wall=31595
2023-07-04 22:55:27 | INFO | train_inner | epoch 029:   1247 / 1474 loss=1.332, trans_loss=5.186, nll_loss=2.442, w2v_ctc_loss=0.405, task_loss=1.532, contrastive_loss=0, total=4160.52, n_correct=2771.38, ppl=5.43, accuracy=66.611, wps=6967, ups=1.67, wpb=4160.5, bsz=150.8, num_updates=42500, lr=6.85994e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=59, gb_free=15.8, wall=31655
2023-07-04 22:56:27 | INFO | train_inner | epoch 029:   1347 / 1474 loss=1.329, trans_loss=5.174, nll_loss=2.427, w2v_ctc_loss=0.398, task_loss=1.501, contrastive_loss=0, total=4168.02, n_correct=2781.97, ppl=5.38, accuracy=66.746, wps=6914.2, ups=1.66, wpb=4168, bsz=155.1, num_updates=42600, lr=6.85189e-05, gnorm=0.336, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=31715
2023-07-04 22:57:26 | INFO | train_inner | epoch 029:   1447 / 1474 loss=1.327, trans_loss=5.173, nll_loss=2.427, w2v_ctc_loss=0.396, task_loss=1.482, contrastive_loss=0, total=4166.06, n_correct=2783.81, ppl=5.38, accuracy=66.821, wps=7036.4, ups=1.69, wpb=4166.1, bsz=156.6, num_updates=42700, lr=6.84386e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=59, gb_free=17, wall=31774
2023-07-04 22:57:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 22:58:06 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 2.146 | trans_loss 5.546 | nll_loss 2.813 | w2v_ctc_loss 0.682 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2501.4 | ppl 7.03 | accuracy 62.482 | uer 16.295 | wer 18.12 | raw_wer 18.12 | bleu 20.05 | wps 2255.5 | wpb 4003.4 | bsz 141.8 | num_updates 42727 | best_bleu 20.28
2023-07-04 22:58:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42727 updates
2023-07-04 22:58:06 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt
2023-07-04 22:58:11 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt
2023-07-04 22:58:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt (epoch 29 @ 42727 updates, score 20.05) (writing took 4.177141824737191 seconds)
2023-07-04 22:58:11 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-07-04 22:58:11 | INFO | train | epoch 029 | loss 1.327 | trans_loss 5.173 | nll_loss 2.425 | w2v_ctc_loss 0.4 | task_loss 1.514 | contrastive_loss 0 | total 4138.38 | n_correct 2766 | ppl 5.37 | accuracy 66.838 | wps 6406 | ups 1.55 | wpb 4138.4 | bsz 152.8 | num_updates 42727 | lr 6.8417e-05 | gnorm 0.34 | clip 0 | loss_scale 64 | train_wall 877 | gb_free 16.4 | wall 31819
2023-07-04 22:58:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 22:58:11 | INFO | fairseq.trainer | begin training epoch 30
2023-07-04 22:58:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 22:59:03 | INFO | train_inner | epoch 030:     73 / 1474 loss=1.321, trans_loss=5.155, nll_loss=2.401, w2v_ctc_loss=0.392, task_loss=1.443, contrastive_loss=0, total=4175.11, n_correct=2802.64, ppl=5.28, accuracy=67.127, wps=4309.1, ups=1.03, wpb=4175.1, bsz=159.3, num_updates=42800, lr=6.83586e-05, gnorm=0.337, clip=0, loss_scale=64, train_wall=59, gb_free=17.3, wall=31871
2023-07-04 23:00:03 | INFO | train_inner | epoch 030:    173 / 1474 loss=1.317, trans_loss=5.136, nll_loss=2.377, w2v_ctc_loss=0.395, task_loss=1.423, contrastive_loss=0, total=4202.64, n_correct=2838.44, ppl=5.19, accuracy=67.539, wps=6992.3, ups=1.66, wpb=4202.6, bsz=159.2, num_updates=42900, lr=6.82789e-05, gnorm=0.335, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=31932
2023-07-04 23:01:04 | INFO | train_inner | epoch 030:    273 / 1474 loss=1.323, trans_loss=5.152, nll_loss=2.397, w2v_ctc_loss=0.403, task_loss=1.563, contrastive_loss=0, total=4120.21, n_correct=2771.69, ppl=5.27, accuracy=67.271, wps=6779.1, ups=1.65, wpb=4120.2, bsz=147.5, num_updates=43000, lr=6.81994e-05, gnorm=0.336, clip=0, loss_scale=64, train_wall=60, gb_free=15.6, wall=31992
2023-07-04 23:02:05 | INFO | train_inner | epoch 030:    373 / 1474 loss=1.318, trans_loss=5.141, nll_loss=2.382, w2v_ctc_loss=0.391, task_loss=1.515, contrastive_loss=0, total=4178.23, n_correct=2817.21, ppl=5.21, accuracy=67.426, wps=6889.8, ups=1.65, wpb=4178.2, bsz=153.8, num_updates=43100, lr=6.81203e-05, gnorm=0.337, clip=0, loss_scale=64, train_wall=60, gb_free=10.6, wall=32053
2023-07-04 23:03:04 | INFO | train_inner | epoch 030:    473 / 1474 loss=1.319, trans_loss=5.152, nll_loss=2.398, w2v_ctc_loss=0.392, task_loss=1.449, contrastive_loss=0, total=4124.47, n_correct=2773.02, ppl=5.27, accuracy=67.233, wps=6994.8, ups=1.7, wpb=4124.5, bsz=156.3, num_updates=43200, lr=6.80414e-05, gnorm=0.337, clip=0, loss_scale=64, train_wall=59, gb_free=17.7, wall=32112
2023-07-04 23:04:03 | INFO | train_inner | epoch 030:    573 / 1474 loss=1.318, trans_loss=5.153, nll_loss=2.399, w2v_ctc_loss=0.391, task_loss=1.47, contrastive_loss=0, total=4168.41, n_correct=2799.79, ppl=5.28, accuracy=67.167, wps=6990.4, ups=1.68, wpb=4168.4, bsz=156.2, num_updates=43300, lr=6.79628e-05, gnorm=0.336, clip=0, loss_scale=64, train_wall=59, gb_free=17.4, wall=32172
2023-07-04 23:05:04 | INFO | train_inner | epoch 030:    673 / 1474 loss=1.323, trans_loss=5.159, nll_loss=2.407, w2v_ctc_loss=0.398, task_loss=1.497, contrastive_loss=0, total=4187.95, n_correct=2808.35, ppl=5.3, accuracy=67.058, wps=6947.4, ups=1.66, wpb=4187.9, bsz=157.5, num_updates=43400, lr=6.78844e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=60, gb_free=16.1, wall=32232
2023-07-04 23:06:04 | INFO | train_inner | epoch 030:    773 / 1474 loss=1.33, trans_loss=5.175, nll_loss=2.427, w2v_ctc_loss=0.403, task_loss=1.546, contrastive_loss=0, total=4105.32, n_correct=2742.56, ppl=5.38, accuracy=66.805, wps=6834.5, ups=1.66, wpb=4105.3, bsz=151.3, num_updates=43500, lr=6.78064e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=60, gb_free=13.4, wall=32292
2023-07-04 23:07:03 | INFO | train_inner | epoch 030:    873 / 1474 loss=1.324, trans_loss=5.167, nll_loss=2.417, w2v_ctc_loss=0.395, task_loss=1.561, contrastive_loss=0, total=4102.11, n_correct=2746.12, ppl=5.34, accuracy=66.944, wps=6861.3, ups=1.67, wpb=4102.1, bsz=147.8, num_updates=43600, lr=6.77285e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=59, gb_free=17.5, wall=32352
2023-07-04 23:08:04 | INFO | train_inner | epoch 030:    973 / 1474 loss=1.327, trans_loss=5.169, nll_loss=2.42, w2v_ctc_loss=0.403, task_loss=1.56, contrastive_loss=0, total=4129.98, n_correct=2760.67, ppl=5.35, accuracy=66.845, wps=6792.4, ups=1.64, wpb=4130, bsz=150.2, num_updates=43700, lr=6.7651e-05, gnorm=0.341, clip=0, loss_scale=128, train_wall=60, gb_free=16.8, wall=32412
2023-07-04 23:09:05 | INFO | train_inner | epoch 030:   1073 / 1474 loss=1.33, trans_loss=5.179, nll_loss=2.431, w2v_ctc_loss=0.399, task_loss=1.697, contrastive_loss=0, total=4101.17, n_correct=2732.51, ppl=5.39, accuracy=66.628, wps=6739.7, ups=1.64, wpb=4101.2, bsz=141.2, num_updates=43800, lr=6.75737e-05, gnorm=0.343, clip=0, loss_scale=128, train_wall=60, gb_free=15.9, wall=32473
2023-07-04 23:10:05 | INFO | train_inner | epoch 030:   1173 / 1474 loss=1.323, trans_loss=5.168, nll_loss=2.419, w2v_ctc_loss=0.395, task_loss=1.461, contrastive_loss=0, total=4168.36, n_correct=2787.48, ppl=5.35, accuracy=66.872, wps=6942.7, ups=1.67, wpb=4168.4, bsz=157, num_updates=43900, lr=6.74967e-05, gnorm=0.341, clip=0, loss_scale=128, train_wall=60, gb_free=16.2, wall=32533
2023-07-04 23:11:05 | INFO | train_inner | epoch 030:   1273 / 1474 loss=1.327, trans_loss=5.18, nll_loss=2.433, w2v_ctc_loss=0.403, task_loss=1.679, contrastive_loss=0, total=4036.17, n_correct=2691.74, ppl=5.4, accuracy=66.69, wps=6705.8, ups=1.66, wpb=4036.2, bsz=142.1, num_updates=44000, lr=6.742e-05, gnorm=0.349, clip=0, loss_scale=128, train_wall=60, gb_free=15.9, wall=32594
2023-07-04 23:11:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 23:11:30 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 2.151 | trans_loss 5.552 | nll_loss 2.824 | w2v_ctc_loss 0.691 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2492 | ppl 7.08 | accuracy 62.247 | uer 16.5 | wer 18.303 | raw_wer 18.303 | bleu 20.08 | wps 2147 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.28
2023-07-04 23:11:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-07-04 23:11:30 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_30_44000.pt
2023-07-04 23:11:33 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_30_44000.pt
2023-07-04 23:11:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 20.08) (writing took 6.622634341008961 seconds)
2023-07-04 23:12:37 | INFO | train_inner | epoch 030:   1373 / 1474 loss=1.321, trans_loss=5.159, nll_loss=2.409, w2v_ctc_loss=0.395, task_loss=1.419, contrastive_loss=0, total=4165.07, n_correct=2795.94, ppl=5.31, accuracy=67.128, wps=4536, ups=1.09, wpb=4165.1, bsz=160.8, num_updates=44100, lr=6.73435e-05, gnorm=0.338, clip=0, loss_scale=128, train_wall=59, gb_free=16.9, wall=32685
2023-07-04 23:13:36 | INFO | train_inner | epoch 030:   1473 / 1474 loss=1.325, trans_loss=5.168, nll_loss=2.42, w2v_ctc_loss=0.392, task_loss=1.425, contrastive_loss=0, total=4141.76, n_correct=2769.56, ppl=5.35, accuracy=66.869, wps=7003.3, ups=1.69, wpb=4141.8, bsz=157.2, num_updates=44200, lr=6.72673e-05, gnorm=0.342, clip=0, loss_scale=128, train_wall=59, gb_free=16.6, wall=32745
2023-07-04 23:13:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 23:14:02 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 2.152 | trans_loss 5.555 | nll_loss 2.831 | w2v_ctc_loss 0.693 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2492.8 | ppl 7.11 | accuracy 62.267 | uer 16.726 | wer 18.549 | raw_wer 18.549 | bleu 20.3 | wps 2123.1 | wpb 4003.4 | bsz 141.8 | num_updates 44201 | best_bleu 20.3
2023-07-04 23:14:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44201 updates
2023-07-04 23:14:02 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 23:14:06 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 23:14:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt (epoch 30 @ 44201 updates, score 20.3) (writing took 8.287567330058664 seconds)
2023-07-04 23:14:11 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-07-04 23:14:11 | INFO | train | epoch 030 | loss 1.323 | trans_loss 5.16 | nll_loss 2.409 | w2v_ctc_loss 0.396 | task_loss 1.515 | contrastive_loss 0 | total 4138.65 | n_correct 2774.91 | ppl 5.31 | accuracy 67.049 | wps 6353.7 | ups 1.54 | wpb 4138.6 | bsz 152.8 | num_updates 44201 | lr 6.72665e-05 | gnorm 0.34 | clip 0 | loss_scale 128 | train_wall 879 | gb_free 17.2 | wall 32779
2023-07-04 23:14:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 23:14:11 | INFO | fairseq.trainer | begin training epoch 31
2023-07-04 23:14:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 23:15:19 | INFO | train_inner | epoch 031:     99 / 1474 loss=1.318, trans_loss=5.145, nll_loss=2.387, w2v_ctc_loss=0.397, task_loss=1.613, contrastive_loss=0, total=4054.44, n_correct=2731.9, ppl=5.23, accuracy=67.38, wps=3950.2, ups=0.97, wpb=4054.4, bsz=144.1, num_updates=44300, lr=6.71913e-05, gnorm=0.345, clip=0, loss_scale=128, train_wall=59, gb_free=16.6, wall=32847
2023-07-04 23:16:20 | INFO | train_inner | epoch 031:    199 / 1474 loss=1.319, trans_loss=5.146, nll_loss=2.389, w2v_ctc_loss=0.394, task_loss=1.552, contrastive_loss=0, total=4147.4, n_correct=2790.99, ppl=5.24, accuracy=67.295, wps=6800.6, ups=1.64, wpb=4147.4, bsz=151.1, num_updates=44400, lr=6.71156e-05, gnorm=0.34, clip=0, loss_scale=128, train_wall=61, gb_free=16.9, wall=32908
2023-07-04 23:17:21 | INFO | train_inner | epoch 031:    299 / 1474 loss=1.319, trans_loss=5.146, nll_loss=2.389, w2v_ctc_loss=0.393, task_loss=1.553, contrastive_loss=0, total=4149.21, n_correct=2795.06, ppl=5.24, accuracy=67.364, wps=6842.8, ups=1.65, wpb=4149.2, bsz=150.8, num_updates=44500, lr=6.70402e-05, gnorm=0.336, clip=0, loss_scale=128, train_wall=60, gb_free=16.3, wall=32969
2023-07-04 23:18:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-04 23:18:21 | INFO | train_inner | epoch 031:    400 / 1474 loss=1.321, trans_loss=5.149, nll_loss=2.392, w2v_ctc_loss=0.393, task_loss=1.689, contrastive_loss=0, total=4080.96, n_correct=2744.17, ppl=5.25, accuracy=67.243, wps=6756.7, ups=1.66, wpb=4081, bsz=140.9, num_updates=44600, lr=6.6965e-05, gnorm=0.336, clip=0, loss_scale=64, train_wall=60, gb_free=13.8, wall=33029
2023-07-04 23:19:21 | INFO | train_inner | epoch 031:    500 / 1474 loss=1.318, trans_loss=5.143, nll_loss=2.385, w2v_ctc_loss=0.396, task_loss=1.578, contrastive_loss=0, total=4115.61, n_correct=2771.48, ppl=5.22, accuracy=67.341, wps=6857.5, ups=1.67, wpb=4115.6, bsz=150.3, num_updates=44700, lr=6.689e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=33089
2023-07-04 23:20:21 | INFO | train_inner | epoch 031:    600 / 1474 loss=1.321, trans_loss=5.151, nll_loss=2.396, w2v_ctc_loss=0.395, task_loss=1.594, contrastive_loss=0, total=4075.9, n_correct=2738.85, ppl=5.26, accuracy=67.196, wps=6822.2, ups=1.67, wpb=4075.9, bsz=146.7, num_updates=44800, lr=6.68153e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=59, gb_free=12.3, wall=33149
2023-07-04 23:21:20 | INFO | train_inner | epoch 031:    700 / 1474 loss=1.315, trans_loss=5.138, nll_loss=2.379, w2v_ctc_loss=0.389, task_loss=1.444, contrastive_loss=0, total=4208.99, n_correct=2836.33, ppl=5.2, accuracy=67.387, wps=7086.5, ups=1.68, wpb=4209, bsz=157.5, num_updates=44900, lr=6.67409e-05, gnorm=0.338, clip=0, loss_scale=64, train_wall=59, gb_free=17.9, wall=33208
2023-07-04 23:22:20 | INFO | train_inner | epoch 031:    800 / 1474 loss=1.317, trans_loss=5.158, nll_loss=2.405, w2v_ctc_loss=0.391, task_loss=1.568, contrastive_loss=0, total=4104.19, n_correct=2752.26, ppl=5.3, accuracy=67.06, wps=6836.7, ups=1.67, wpb=4104.2, bsz=148.7, num_updates=45000, lr=6.66667e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=60, gb_free=15.5, wall=33268
tensor(0.0230, device='cuda:0')
tensor(0.0005, device='cuda:0')
2023-07-04 23:23:20 | INFO | train_inner | epoch 031:    900 / 1474 loss=1.32, trans_loss=5.151, nll_loss=2.397, w2v_ctc_loss=0.393, task_loss=1.601, contrastive_loss=0, total=4099.13, n_correct=2752.8, ppl=5.27, accuracy=67.156, wps=6804.1, ups=1.66, wpb=4099.1, bsz=147.2, num_updates=45100, lr=6.65927e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=60, gb_free=15.4, wall=33329
2023-07-04 23:24:20 | INFO | train_inner | epoch 031:   1000 / 1474 loss=1.323, trans_loss=5.157, nll_loss=2.406, w2v_ctc_loss=0.39, task_loss=1.411, contrastive_loss=0, total=4186.81, n_correct=2809.52, ppl=5.3, accuracy=67.104, wps=7035.2, ups=1.68, wpb=4186.8, bsz=160.4, num_updates=45200, lr=6.6519e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=59, gb_free=13.6, wall=33388
2023-07-04 23:25:20 | INFO | train_inner | epoch 031:   1100 / 1474 loss=1.322, trans_loss=5.164, nll_loss=2.415, w2v_ctc_loss=0.395, task_loss=1.487, contrastive_loss=0, total=4149.25, n_correct=2782.68, ppl=5.33, accuracy=67.065, wps=6930.5, ups=1.67, wpb=4149.2, bsz=157.6, num_updates=45300, lr=6.64455e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=59, gb_free=16.2, wall=33448
2023-07-04 23:26:19 | INFO | train_inner | epoch 031:   1200 / 1474 loss=1.327, trans_loss=5.168, nll_loss=2.42, w2v_ctc_loss=0.398, task_loss=1.424, contrastive_loss=0, total=4187.45, n_correct=2800.84, ppl=5.35, accuracy=66.887, wps=7056.5, ups=1.69, wpb=4187.4, bsz=160.1, num_updates=45400, lr=6.63723e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=59, gb_free=17.2, wall=33507
2023-07-04 23:27:19 | INFO | train_inner | epoch 031:   1300 / 1474 loss=1.321, trans_loss=5.152, nll_loss=2.399, w2v_ctc_loss=0.393, task_loss=1.35, contrastive_loss=0, total=4227.39, n_correct=2842.99, ppl=5.28, accuracy=67.252, wps=7077.6, ups=1.67, wpb=4227.4, bsz=163.4, num_updates=45500, lr=6.62994e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=59, gb_free=17.2, wall=33567
2023-07-04 23:28:19 | INFO | train_inner | epoch 031:   1400 / 1474 loss=1.324, trans_loss=5.166, nll_loss=2.418, w2v_ctc_loss=0.394, task_loss=1.382, contrastive_loss=0, total=4191.1, n_correct=2806.1, ppl=5.34, accuracy=66.954, wps=6958.8, ups=1.66, wpb=4191.1, bsz=163.5, num_updates=45600, lr=6.62266e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=33627
2023-07-04 23:29:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0230, device='cuda:4')
tensor(0.0005, device='cuda:4')
tensor(0.0230, device='cuda:7')
tensor(0.0005, device='cuda:7')
tensor(0.0230, device='cuda:6')
tensor(0.0005, device='cuda:6')
tensor(0.0230, device='cuda:5')
tensor(0.0005, device='cuda:5')
tensor(0.0230, device='cuda:1')
tensor(0.0005, device='cuda:1')
tensor(0.0230, device='cuda:2')
tensor(0.0005, device='cuda:2')
tensor(0.0230, device='cuda:3')
tensor(0.0005, device='cuda:3')
2023-07-04 23:29:27 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 2.153 | trans_loss 5.55 | nll_loss 2.822 | w2v_ctc_loss 0.703 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2497.6 | ppl 7.07 | accuracy 62.387 | uer 16.625 | wer 18.396 | raw_wer 18.396 | bleu 20.53 | wps 2295.1 | wpb 4003.4 | bsz 141.8 | num_updates 45674 | best_bleu 20.53
2023-07-04 23:29:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45674 updates
2023-07-04 23:29:27 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 23:29:31 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt
2023-07-04 23:29:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_best.pt (epoch 31 @ 45674 updates, score 20.53) (writing took 8.904625712893903 seconds)
2023-07-04 23:29:36 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-07-04 23:29:36 | INFO | train | epoch 031 | loss 1.32 | trans_loss 5.153 | nll_loss 2.399 | w2v_ctc_loss 0.394 | task_loss 1.516 | contrastive_loss 0 | total 4137.69 | n_correct 2779.74 | ppl 5.27 | accuracy 67.181 | wps 6586.7 | ups 1.59 | wpb 4137.7 | bsz 152.7 | num_updates 45674 | lr 6.61729e-05 | gnorm 0.341 | clip 0 | loss_scale 64 | train_wall 877 | gb_free 12.5 | wall 33704
2023-07-04 23:29:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 23:29:36 | INFO | fairseq.trainer | begin training epoch 32
2023-07-04 23:29:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 23:30:00 | INFO | train_inner | epoch 032:     26 / 1474 loss=1.318, trans_loss=5.147, nll_loss=2.391, w2v_ctc_loss=0.392, task_loss=1.6, contrastive_loss=0, total=4040.88, n_correct=2716.63, ppl=5.25, accuracy=67.229, wps=4005.8, ups=0.99, wpb=4040.9, bsz=144.4, num_updates=45700, lr=6.61541e-05, gnorm=0.348, clip=0, loss_scale=64, train_wall=59, gb_free=15.7, wall=33728
2023-07-04 23:31:01 | INFO | train_inner | epoch 032:    126 / 1474 loss=1.304, trans_loss=5.106, nll_loss=2.338, w2v_ctc_loss=0.376, task_loss=1.401, contrastive_loss=0, total=4222.14, n_correct=2869.61, ppl=5.06, accuracy=67.966, wps=6968.7, ups=1.65, wpb=4222.1, bsz=161.3, num_updates=45800, lr=6.60819e-05, gnorm=0.331, clip=0, loss_scale=64, train_wall=60, gb_free=15.8, wall=33789
2023-07-04 23:32:01 | INFO | train_inner | epoch 032:    226 / 1474 loss=1.31, trans_loss=5.131, nll_loss=2.37, w2v_ctc_loss=0.39, task_loss=1.445, contrastive_loss=0, total=4159.77, n_correct=2808.58, ppl=5.17, accuracy=67.518, wps=6871.7, ups=1.65, wpb=4159.8, bsz=160.4, num_updates=45900, lr=6.60098e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=33849
2023-07-04 23:33:01 | INFO | train_inner | epoch 032:    326 / 1474 loss=1.312, trans_loss=5.119, nll_loss=2.355, w2v_ctc_loss=0.386, task_loss=1.44, contrastive_loss=0, total=4179.65, n_correct=2831.81, ppl=5.12, accuracy=67.752, wps=7001.2, ups=1.68, wpb=4179.6, bsz=156.9, num_updates=46000, lr=6.5938e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=59, gb_free=16.5, wall=33909
2023-07-04 23:33:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 23:33:25 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 2.16 | trans_loss 5.563 | nll_loss 2.838 | w2v_ctc_loss 0.709 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2497.1 | ppl 7.15 | accuracy 62.374 | uer 16.638 | wer 18.433 | raw_wer 18.433 | bleu 20.29 | wps 2263.1 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.53
2023-07-04 23:33:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-07-04 23:33:25 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_32_46000.pt
2023-07-04 23:33:28 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_32_46000.pt
2023-07-04 23:33:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 20.29) (writing took 6.350908353924751 seconds)
2023-07-04 23:34:32 | INFO | train_inner | epoch 032:    426 / 1474 loss=1.312, trans_loss=5.128, nll_loss=2.366, w2v_ctc_loss=0.388, task_loss=1.478, contrastive_loss=0, total=4172.34, n_correct=2818.88, ppl=5.16, accuracy=67.561, wps=4575.4, ups=1.1, wpb=4172.3, bsz=155, num_updates=46100, lr=6.58665e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=59, gb_free=17.2, wall=34000
2023-07-04 23:35:32 | INFO | train_inner | epoch 032:    526 / 1474 loss=1.318, trans_loss=5.143, nll_loss=2.386, w2v_ctc_loss=0.392, task_loss=1.486, contrastive_loss=0, total=4191.15, n_correct=2824.63, ppl=5.23, accuracy=67.395, wps=6945.5, ups=1.66, wpb=4191.1, bsz=157.5, num_updates=46200, lr=6.57952e-05, gnorm=0.332, clip=0, loss_scale=64, train_wall=60, gb_free=15.3, wall=34061
2023-07-04 23:36:33 | INFO | train_inner | epoch 032:    626 / 1474 loss=1.319, trans_loss=5.149, nll_loss=2.394, w2v_ctc_loss=0.394, task_loss=1.58, contrastive_loss=0, total=4138.05, n_correct=2779.52, ppl=5.25, accuracy=67.17, wps=6850.5, ups=1.66, wpb=4138.1, bsz=149.8, num_updates=46300, lr=6.57241e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=60, gb_free=13.7, wall=34121
2023-07-04 23:37:33 | INFO | train_inner | epoch 032:    726 / 1474 loss=1.322, trans_loss=5.145, nll_loss=2.389, w2v_ctc_loss=0.398, task_loss=1.536, contrastive_loss=0, total=4156.23, n_correct=2798.55, ppl=5.24, accuracy=67.334, wps=6889.8, ups=1.66, wpb=4156.2, bsz=151.5, num_updates=46400, lr=6.56532e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=34181
2023-07-04 23:38:33 | INFO | train_inner | epoch 032:    826 / 1474 loss=1.313, trans_loss=5.137, nll_loss=2.378, w2v_ctc_loss=0.387, task_loss=1.57, contrastive_loss=0, total=4112.3, n_correct=2773.85, ppl=5.2, accuracy=67.453, wps=6857.4, ups=1.67, wpb=4112.3, bsz=147, num_updates=46500, lr=6.55826e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=59, gb_free=16.1, wall=34241
2023-07-04 23:39:33 | INFO | train_inner | epoch 032:    926 / 1474 loss=1.318, trans_loss=5.145, nll_loss=2.389, w2v_ctc_loss=0.388, task_loss=1.57, contrastive_loss=0, total=4139.37, n_correct=2785.36, ppl=5.24, accuracy=67.289, wps=6876.2, ups=1.66, wpb=4139.4, bsz=149.3, num_updates=46600, lr=6.55122e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=60, gb_free=13.2, wall=34302
2023-07-04 23:40:33 | INFO | train_inner | epoch 032:   1026 / 1474 loss=1.314, trans_loss=5.146, nll_loss=2.389, w2v_ctc_loss=0.385, task_loss=1.485, contrastive_loss=0, total=4121.85, n_correct=2771.85, ppl=5.24, accuracy=67.248, wps=6884.3, ups=1.67, wpb=4121.9, bsz=153, num_updates=46700, lr=6.5442e-05, gnorm=0.335, clip=0, loss_scale=128, train_wall=59, gb_free=17.1, wall=34361
2023-07-04 23:41:33 | INFO | train_inner | epoch 032:   1126 / 1474 loss=1.322, trans_loss=5.161, nll_loss=2.409, w2v_ctc_loss=0.393, task_loss=1.805, contrastive_loss=0, total=4015.59, n_correct=2687.37, ppl=5.31, accuracy=66.923, wps=6678.4, ups=1.66, wpb=4015.6, bsz=135.1, num_updates=46800, lr=6.5372e-05, gnorm=0.349, clip=0, loss_scale=128, train_wall=60, gb_free=17.4, wall=34422
2023-07-04 23:41:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-04 23:42:34 | INFO | train_inner | epoch 032:   1227 / 1474 loss=1.325, trans_loss=5.165, nll_loss=2.416, w2v_ctc_loss=0.393, task_loss=1.488, contrastive_loss=0, total=4155.24, n_correct=2779.98, ppl=5.34, accuracy=66.903, wps=6880.5, ups=1.66, wpb=4155.2, bsz=155.4, num_updates=46900, lr=6.53023e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=34482
2023-07-04 23:43:33 | INFO | train_inner | epoch 032:   1327 / 1474 loss=1.321, trans_loss=5.153, nll_loss=2.4, w2v_ctc_loss=0.395, task_loss=1.544, contrastive_loss=0, total=4079.56, n_correct=2740.9, ppl=5.28, accuracy=67.186, wps=6869, ups=1.68, wpb=4079.6, bsz=149, num_updates=47000, lr=6.52328e-05, gnorm=0.347, clip=0, loss_scale=64, train_wall=59, gb_free=17.3, wall=34541
2023-07-04 23:44:33 | INFO | train_inner | epoch 032:   1427 / 1474 loss=1.327, trans_loss=5.169, nll_loss=2.42, w2v_ctc_loss=0.399, task_loss=1.535, contrastive_loss=0, total=4107.37, n_correct=2750.03, ppl=5.35, accuracy=66.954, wps=6882.7, ups=1.68, wpb=4107.4, bsz=152.1, num_updates=47100, lr=6.51635e-05, gnorm=0.344, clip=0, loss_scale=64, train_wall=59, gb_free=17.5, wall=34601
2023-07-04 23:45:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 23:45:24 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 2.165 | trans_loss 5.557 | nll_loss 2.829 | w2v_ctc_loss 0.733 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2493 | ppl 7.1 | accuracy 62.272 | uer 16.85 | wer 18.56 | raw_wer 18.56 | bleu 19.93 | wps 2343.3 | wpb 4003.4 | bsz 141.8 | num_updates 47147 | best_bleu 20.53
2023-07-04 23:45:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47147 updates
2023-07-04 23:45:24 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt
2023-07-04 23:45:28 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt
2023-07-04 23:45:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt (epoch 32 @ 47147 updates, score 19.93) (writing took 4.288798664696515 seconds)
2023-07-04 23:45:28 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-07-04 23:45:28 | INFO | train | epoch 032 | loss 1.317 | trans_loss 5.142 | nll_loss 2.386 | w2v_ctc_loss 0.39 | task_loss 1.515 | contrastive_loss 0 | total 4138.75 | n_correct 2786.97 | ppl 5.23 | accuracy 67.338 | wps 6402.2 | ups 1.55 | wpb 4138.7 | bsz 152.8 | num_updates 47147 | lr 6.5131e-05 | gnorm 0.34 | clip 0 | loss_scale 64 | train_wall 877 | gb_free 16.8 | wall 34657
2023-07-04 23:45:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-04 23:45:29 | INFO | fairseq.trainer | begin training epoch 33
2023-07-04 23:45:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-04 23:46:10 | INFO | train_inner | epoch 033:     53 / 1474 loss=1.318, trans_loss=5.142, nll_loss=2.386, w2v_ctc_loss=0.39, task_loss=1.434, contrastive_loss=0, total=4146.91, n_correct=2793.92, ppl=5.23, accuracy=67.374, wps=4288.2, ups=1.03, wpb=4146.9, bsz=159.9, num_updates=47200, lr=6.50945e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=59, gb_free=16.3, wall=34698
2023-07-04 23:47:09 | INFO | train_inner | epoch 033:    153 / 1474 loss=1.306, trans_loss=5.116, nll_loss=2.35, w2v_ctc_loss=0.379, task_loss=1.625, contrastive_loss=0, total=4073.36, n_correct=2762.12, ppl=5.1, accuracy=67.809, wps=6824.2, ups=1.68, wpb=4073.4, bsz=142.6, num_updates=47300, lr=6.50256e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=59, gb_free=16.9, wall=34757
2023-07-04 23:48:10 | INFO | train_inner | epoch 033:    253 / 1474 loss=1.308, trans_loss=5.12, nll_loss=2.358, w2v_ctc_loss=0.383, task_loss=1.28, contrastive_loss=0, total=4283.64, n_correct=2903.1, ppl=5.13, accuracy=67.772, wps=7069, ups=1.65, wpb=4283.6, bsz=173.8, num_updates=47400, lr=6.4957e-05, gnorm=0.332, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=34818
2023-07-04 23:49:10 | INFO | train_inner | epoch 033:    353 / 1474 loss=1.317, trans_loss=5.132, nll_loss=2.373, w2v_ctc_loss=0.391, task_loss=1.547, contrastive_loss=0, total=4131.27, n_correct=2788.78, ppl=5.18, accuracy=67.504, wps=6897.7, ups=1.67, wpb=4131.3, bsz=151.1, num_updates=47500, lr=6.48886e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=59, gb_free=16.4, wall=34878
2023-07-04 23:50:09 | INFO | train_inner | epoch 033:    453 / 1474 loss=1.306, trans_loss=5.105, nll_loss=2.336, w2v_ctc_loss=0.38, task_loss=1.435, contrastive_loss=0, total=4135.1, n_correct=2809.02, ppl=5.05, accuracy=67.931, wps=7018.1, ups=1.7, wpb=4135.1, bsz=154.8, num_updates=47600, lr=6.48204e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=58, gb_free=15.8, wall=34937
2023-07-04 23:51:09 | INFO | train_inner | epoch 033:    553 / 1474 loss=1.318, trans_loss=5.137, nll_loss=2.378, w2v_ctc_loss=0.388, task_loss=1.576, contrastive_loss=0, total=4132.78, n_correct=2785.25, ppl=5.2, accuracy=67.394, wps=6867.4, ups=1.66, wpb=4132.8, bsz=147.1, num_updates=47700, lr=6.47524e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=60, gb_free=17.9, wall=34997
2023-07-04 23:52:09 | INFO | train_inner | epoch 033:    653 / 1474 loss=1.318, trans_loss=5.148, nll_loss=2.392, w2v_ctc_loss=0.389, task_loss=1.563, contrastive_loss=0, total=4156.26, n_correct=2791.5, ppl=5.25, accuracy=67.164, wps=6905.7, ups=1.66, wpb=4156.3, bsz=150.4, num_updates=47800, lr=6.46846e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=35057
2023-07-04 23:53:09 | INFO | train_inner | epoch 033:    753 / 1474 loss=1.321, trans_loss=5.146, nll_loss=2.39, w2v_ctc_loss=0.397, task_loss=1.634, contrastive_loss=0, total=4074.99, n_correct=2742.39, ppl=5.24, accuracy=67.298, wps=6780.2, ups=1.66, wpb=4075, bsz=144.1, num_updates=47900, lr=6.46171e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=35117
2023-07-04 23:54:09 | INFO | train_inner | epoch 033:    853 / 1474 loss=1.31, trans_loss=5.13, nll_loss=2.371, w2v_ctc_loss=0.383, task_loss=1.453, contrastive_loss=0, total=4127.6, n_correct=2791.2, ppl=5.17, accuracy=67.623, wps=6953.2, ups=1.68, wpb=4127.6, bsz=157.7, num_updates=48000, lr=6.45497e-05, gnorm=0.338, clip=0, loss_scale=64, train_wall=59, gb_free=16.4, wall=35177
2023-07-04 23:54:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-04 23:54:32 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 2.154 | trans_loss 5.556 | nll_loss 2.829 | w2v_ctc_loss 0.699 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2498.1 | ppl 7.11 | accuracy 62.399 | uer 16.81 | wer 18.556 | raw_wer 18.556 | bleu 20.26 | wps 2323 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.53
2023-07-04 23:54:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-07-04 23:54:32 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_33_48000.pt
2023-07-04 23:54:35 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_33_48000.pt
2023-07-04 23:54:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 20.26) (writing took 6.382434777915478 seconds)
2023-07-04 23:55:40 | INFO | train_inner | epoch 033:    953 / 1474 loss=1.314, trans_loss=5.136, nll_loss=2.378, w2v_ctc_loss=0.39, task_loss=1.499, contrastive_loss=0, total=4157.37, n_correct=2802.34, ppl=5.2, accuracy=67.407, wps=4566.2, ups=1.1, wpb=4157.4, bsz=155, num_updates=48100, lr=6.44826e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=60, gb_free=17.5, wall=35268
2023-07-04 23:56:40 | INFO | train_inner | epoch 033:   1053 / 1474 loss=1.318, trans_loss=5.145, nll_loss=2.389, w2v_ctc_loss=0.392, task_loss=1.538, contrastive_loss=0, total=4134.8, n_correct=2780.85, ppl=5.24, accuracy=67.255, wps=6854, ups=1.66, wpb=4134.8, bsz=153, num_updates=48200, lr=6.44157e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=60, gb_free=15.9, wall=35328
2023-07-04 23:57:40 | INFO | train_inner | epoch 033:   1153 / 1474 loss=1.316, trans_loss=5.141, nll_loss=2.385, w2v_ctc_loss=0.383, task_loss=1.512, contrastive_loss=0, total=4181.58, n_correct=2815.94, ppl=5.22, accuracy=67.342, wps=6982.7, ups=1.67, wpb=4181.6, bsz=155, num_updates=48300, lr=6.43489e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=59, gb_free=15.4, wall=35388
2023-07-04 23:58:40 | INFO | train_inner | epoch 033:   1253 / 1474 loss=1.317, trans_loss=5.144, nll_loss=2.387, w2v_ctc_loss=0.394, task_loss=1.593, contrastive_loss=0, total=4115.76, n_correct=2772.76, ppl=5.23, accuracy=67.369, wps=6832.3, ups=1.66, wpb=4115.8, bsz=147.3, num_updates=48400, lr=6.42824e-05, gnorm=0.35, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=35448
2023-07-04 23:59:40 | INFO | train_inner | epoch 033:   1353 / 1474 loss=1.311, trans_loss=5.135, nll_loss=2.378, w2v_ctc_loss=0.389, task_loss=1.48, contrastive_loss=0, total=4120.69, n_correct=2780.78, ppl=5.2, accuracy=67.483, wps=6851.3, ups=1.66, wpb=4120.7, bsz=156, num_updates=48500, lr=6.42161e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=35508
2023-07-05 00:00:40 | INFO | train_inner | epoch 033:   1453 / 1474 loss=1.318, trans_loss=5.146, nll_loss=2.392, w2v_ctc_loss=0.388, task_loss=1.504, contrastive_loss=0, total=4125.28, n_correct=2773.03, ppl=5.25, accuracy=67.22, wps=6861.6, ups=1.66, wpb=4125.3, bsz=154.3, num_updates=48600, lr=6.415e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=35569
2023-07-05 00:00:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-05 00:01:17 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 2.162 | trans_loss 5.563 | nll_loss 2.833 | w2v_ctc_loss 0.716 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2489.9 | ppl 7.12 | accuracy 62.195 | uer 16.688 | wer 18.582 | raw_wer 18.582 | bleu 20.48 | wps 2365.4 | wpb 4003.4 | bsz 141.8 | num_updates 48621 | best_bleu 20.53
2023-07-05 00:01:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48621 updates
2023-07-05 00:01:17 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.4806.pt
2023-07-05 00:01:19 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.4806.pt
2023-07-05 00:01:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.4806.pt (epoch 33 @ 48621 updates, score 20.48) (writing took 5.422348408028483 seconds)
2023-07-05 00:01:23 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-07-05 00:01:23 | INFO | train | epoch 033 | loss 1.314 | trans_loss 5.134 | nll_loss 2.375 | w2v_ctc_loss 0.388 | task_loss 1.515 | contrastive_loss 0 | total 4138.65 | n_correct 2792.65 | ppl 5.19 | accuracy 67.477 | wps 6392.5 | ups 1.54 | wpb 4138.6 | bsz 152.8 | num_updates 48621 | lr 6.41362e-05 | gnorm 0.342 | clip 0 | loss_scale 64 | train_wall 877 | gb_free 18 | wall 35611
2023-07-05 00:01:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-05 00:01:23 | INFO | fairseq.trainer | begin training epoch 34
2023-07-05 00:01:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-05 00:02:19 | INFO | train_inner | epoch 034:     79 / 1474 loss=1.307, trans_loss=5.109, nll_loss=2.342, w2v_ctc_loss=0.384, task_loss=1.502, contrastive_loss=0, total=4131.47, n_correct=2805.09, ppl=5.07, accuracy=67.896, wps=4188.6, ups=1.01, wpb=4131.5, bsz=150.8, num_updates=48700, lr=6.40841e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=59, gb_free=16.8, wall=35667
2023-07-05 00:03:19 | INFO | train_inner | epoch 034:    179 / 1474 loss=1.308, trans_loss=5.113, nll_loss=2.347, w2v_ctc_loss=0.389, task_loss=1.582, contrastive_loss=0, total=4065.88, n_correct=2760.4, ppl=5.09, accuracy=67.892, wps=6764.7, ups=1.66, wpb=4065.9, bsz=147.5, num_updates=48800, lr=6.40184e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=60, gb_free=16.2, wall=35727
2023-07-05 00:04:19 | INFO | train_inner | epoch 034:    279 / 1474 loss=1.315, trans_loss=5.131, nll_loss=2.372, w2v_ctc_loss=0.382, task_loss=1.417, contrastive_loss=0, total=4246.3, n_correct=2871.33, ppl=5.18, accuracy=67.62, wps=7037.9, ups=1.66, wpb=4246.3, bsz=164.4, num_updates=48900, lr=6.39529e-05, gnorm=0.337, clip=0, loss_scale=128, train_wall=60, gb_free=17.9, wall=35788
2023-07-05 00:05:19 | INFO | train_inner | epoch 034:    379 / 1474 loss=1.308, trans_loss=5.113, nll_loss=2.347, w2v_ctc_loss=0.383, task_loss=1.439, contrastive_loss=0, total=4156.17, n_correct=2823.11, ppl=5.09, accuracy=67.926, wps=6938.6, ups=1.67, wpb=4156.2, bsz=158.4, num_updates=49000, lr=6.38877e-05, gnorm=0.341, clip=0, loss_scale=128, train_wall=59, gb_free=17.9, wall=35848
2023-07-05 00:06:20 | INFO | train_inner | epoch 034:    479 / 1474 loss=1.313, trans_loss=5.126, nll_loss=2.363, w2v_ctc_loss=0.39, task_loss=1.663, contrastive_loss=0, total=4070.55, n_correct=2751.07, ppl=5.15, accuracy=67.585, wps=6725.2, ups=1.65, wpb=4070.6, bsz=142.3, num_updates=49100, lr=6.38226e-05, gnorm=0.346, clip=0, loss_scale=128, train_wall=60, gb_free=17.6, wall=35908
2023-07-05 00:07:19 | INFO | train_inner | epoch 034:    579 / 1474 loss=1.309, trans_loss=5.113, nll_loss=2.347, w2v_ctc_loss=0.385, task_loss=1.541, contrastive_loss=0, total=4119.38, n_correct=2796.42, ppl=5.09, accuracy=67.884, wps=6946.6, ups=1.69, wpb=4119.4, bsz=150.1, num_updates=49200, lr=6.37577e-05, gnorm=0.344, clip=0, loss_scale=128, train_wall=59, gb_free=13.5, wall=35967
2023-07-05 00:08:19 | INFO | train_inner | epoch 034:    679 / 1474 loss=1.308, trans_loss=5.114, nll_loss=2.35, w2v_ctc_loss=0.382, task_loss=1.539, contrastive_loss=0, total=4124.83, n_correct=2796.27, ppl=5.1, accuracy=67.791, wps=6880.9, ups=1.67, wpb=4124.8, bsz=150.1, num_updates=49300, lr=6.3693e-05, gnorm=0.338, clip=0, loss_scale=128, train_wall=59, gb_free=14.6, wall=36027
2023-07-05 00:09:19 | INFO | train_inner | epoch 034:    779 / 1474 loss=1.314, trans_loss=5.137, nll_loss=2.379, w2v_ctc_loss=0.382, task_loss=1.592, contrastive_loss=0, total=4082.07, n_correct=2751.97, ppl=5.2, accuracy=67.416, wps=6847.3, ups=1.68, wpb=4082.1, bsz=147.5, num_updates=49400, lr=6.36285e-05, gnorm=0.345, clip=0, loss_scale=128, train_wall=59, gb_free=15.8, wall=36087
2023-07-05 00:10:19 | INFO | train_inner | epoch 034:    879 / 1474 loss=1.314, trans_loss=5.134, nll_loss=2.375, w2v_ctc_loss=0.386, task_loss=1.596, contrastive_loss=0, total=4100.9, n_correct=2771.02, ppl=5.19, accuracy=67.571, wps=6803.1, ups=1.66, wpb=4100.9, bsz=148.3, num_updates=49500, lr=6.35642e-05, gnorm=0.347, clip=0, loss_scale=128, train_wall=60, gb_free=12.6, wall=36147
2023-07-05 00:11:19 | INFO | train_inner | epoch 034:    979 / 1474 loss=1.312, trans_loss=5.13, nll_loss=2.37, w2v_ctc_loss=0.387, task_loss=1.481, contrastive_loss=0, total=4168.39, n_correct=2816.3, ppl=5.17, accuracy=67.563, wps=6941.7, ups=1.67, wpb=4168.4, bsz=156, num_updates=49600, lr=6.35001e-05, gnorm=0.341, clip=0, loss_scale=128, train_wall=60, gb_free=16.1, wall=36207
2023-07-05 00:12:18 | INFO | train_inner | epoch 034:   1079 / 1474 loss=1.317, trans_loss=5.135, nll_loss=2.376, w2v_ctc_loss=0.391, task_loss=1.467, contrastive_loss=0, total=4150.57, n_correct=2801.17, ppl=5.19, accuracy=67.489, wps=7004.7, ups=1.69, wpb=4150.6, bsz=154.2, num_updates=49700, lr=6.34361e-05, gnorm=0.343, clip=0, loss_scale=128, train_wall=59, gb_free=17, wall=36267
2023-07-05 00:13:18 | INFO | train_inner | epoch 034:   1179 / 1474 loss=1.313, trans_loss=5.13, nll_loss=2.37, w2v_ctc_loss=0.385, task_loss=1.558, contrastive_loss=0, total=4098.77, n_correct=2765.2, ppl=5.17, accuracy=67.464, wps=6826.5, ups=1.67, wpb=4098.8, bsz=148.6, num_updates=49800, lr=6.33724e-05, gnorm=0.342, clip=0, loss_scale=128, train_wall=60, gb_free=17.1, wall=36327
2023-07-05 00:14:18 | INFO | train_inner | epoch 034:   1279 / 1474 loss=1.308, trans_loss=5.123, nll_loss=2.362, w2v_ctc_loss=0.382, task_loss=1.53, contrastive_loss=0, total=4150.54, n_correct=2806.21, ppl=5.14, accuracy=67.611, wps=6960.6, ups=1.68, wpb=4150.5, bsz=150.5, num_updates=49900, lr=6.33089e-05, gnorm=0.343, clip=0, loss_scale=128, train_wall=59, gb_free=17.3, wall=36386
2023-07-05 00:15:19 | INFO | train_inner | epoch 034:   1379 / 1474 loss=1.314, trans_loss=5.136, nll_loss=2.379, w2v_ctc_loss=0.389, task_loss=1.441, contrastive_loss=0, total=4196.91, n_correct=2829.04, ppl=5.2, accuracy=67.408, wps=6895.3, ups=1.64, wpb=4196.9, bsz=160.7, num_updates=50000, lr=6.32456e-05, gnorm=0.342, clip=0, loss_scale=128, train_wall=60, gb_free=16.3, wall=36447
2023-07-05 00:15:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-05 00:15:44 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 2.154 | trans_loss 5.559 | nll_loss 2.831 | w2v_ctc_loss 0.695 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2496.4 | ppl 7.12 | accuracy 62.357 | uer 16.463 | wer 18.418 | raw_wer 18.418 | bleu 20.1 | wps 2135.4 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.53
2023-07-05 00:15:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-07-05 00:15:44 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_34_50000.pt
2023-07-05 00:15:46 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_34_50000.pt
2023-07-05 00:15:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 20.1) (writing took 5.671391494572163 seconds)
tensor(0.0230, device='cuda:0')
tensor(0.0005, device='cuda:0')
2023-07-05 00:16:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0230, device='cuda:4')
tensor(0.0005, device='cuda:4')
tensor(0.0230, device='cuda:6')
tensor(0.0005, device='cuda:6')
tensor(0.0230, device='cuda:3')
tensor(0.0005, device='cuda:3')
tensor(0.0230, device='cuda:7')
tensor(0.0005, device='cuda:7')
tensor(0.0230, device='cuda:5')
tensor(0.0005, device='cuda:5')
tensor(0.0230, device='cuda:1')
tensor(0.0005, device='cuda:1')
tensor(0.0230, device='cuda:2')
tensor(0.0005, device='cuda:2')
2023-07-05 00:17:12 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 2.161 | trans_loss 5.552 | nll_loss 2.825 | w2v_ctc_loss 0.726 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2493.1 | ppl 7.09 | accuracy 62.275 | uer 16.635 | wer 18.452 | raw_wer 18.452 | bleu 19.75 | wps 2168.2 | wpb 4003.4 | bsz 141.8 | num_updates 50095 | best_bleu 20.53
2023-07-05 00:17:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50095 updates
2023-07-05 00:17:12 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt
2023-07-05 00:17:17 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt
2023-07-05 00:17:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt (epoch 34 @ 50095 updates, score 19.75) (writing took 4.799162427894771 seconds)
2023-07-05 00:17:17 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-07-05 00:17:17 | INFO | train | epoch 034 | loss 1.312 | trans_loss 5.126 | nll_loss 2.364 | w2v_ctc_loss 0.385 | task_loss 1.515 | contrastive_loss 0 | total 4138.65 | n_correct 2799.17 | ppl 5.15 | accuracy 67.635 | wps 6391.8 | ups 1.54 | wpb 4138.6 | bsz 152.8 | num_updates 50095 | lr 6.31856e-05 | gnorm 0.342 | clip 0 | loss_scale 128 | train_wall 877 | gb_free 17.5 | wall 36565
2023-07-05 00:17:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-05 00:17:17 | INFO | fairseq.trainer | begin training epoch 35
2023-07-05 00:17:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-05 00:17:29 | INFO | train_inner | epoch 035:      5 / 1474 loss=1.316, trans_loss=5.135, nll_loss=2.378, w2v_ctc_loss=0.384, task_loss=1.392, contrastive_loss=0, total=4213.19, n_correct=2842.74, ppl=5.2, accuracy=67.472, wps=3235.8, ups=0.77, wpb=4213.2, bsz=163.1, num_updates=50100, lr=6.31824e-05, gnorm=0.337, clip=0, loss_scale=128, train_wall=60, gb_free=17.5, wall=36577
2023-07-05 00:18:29 | INFO | train_inner | epoch 035:    105 / 1474 loss=1.303, trans_loss=5.104, nll_loss=2.336, w2v_ctc_loss=0.375, task_loss=1.457, contrastive_loss=0, total=4166.04, n_correct=2833.17, ppl=5.05, accuracy=68.006, wps=6928.8, ups=1.66, wpb=4166, bsz=156.6, num_updates=50200, lr=6.31194e-05, gnorm=0.341, clip=0, loss_scale=128, train_wall=60, gb_free=16.8, wall=36637
2023-07-05 00:19:29 | INFO | train_inner | epoch 035:    205 / 1474 loss=1.301, trans_loss=5.095, nll_loss=2.324, w2v_ctc_loss=0.375, task_loss=1.422, contrastive_loss=0, total=4171.82, n_correct=2843.38, ppl=5.01, accuracy=68.157, wps=6950.1, ups=1.67, wpb=4171.8, bsz=158.3, num_updates=50300, lr=6.30567e-05, gnorm=0.339, clip=0, loss_scale=128, train_wall=60, gb_free=17.2, wall=36698
2023-07-05 00:20:30 | INFO | train_inner | epoch 035:    305 / 1474 loss=1.304, trans_loss=5.108, nll_loss=2.34, w2v_ctc_loss=0.38, task_loss=1.573, contrastive_loss=0, total=4111.19, n_correct=2796.32, ppl=5.06, accuracy=68.017, wps=6795.7, ups=1.65, wpb=4111.2, bsz=150, num_updates=50400, lr=6.29941e-05, gnorm=0.339, clip=0, loss_scale=128, train_wall=60, gb_free=16.3, wall=36758
2023-07-05 00:21:30 | INFO | train_inner | epoch 035:    405 / 1474 loss=1.312, trans_loss=5.113, nll_loss=2.346, w2v_ctc_loss=0.387, task_loss=1.692, contrastive_loss=0, total=4070.26, n_correct=2758.84, ppl=5.08, accuracy=67.78, wps=6785.7, ups=1.67, wpb=4070.3, bsz=141.3, num_updates=50500, lr=6.29317e-05, gnorm=0.348, clip=0, loss_scale=128, train_wall=59, gb_free=17, wall=36818
2023-07-05 00:22:30 | INFO | train_inner | epoch 035:    505 / 1474 loss=1.31, trans_loss=5.114, nll_loss=2.348, w2v_ctc_loss=0.381, task_loss=1.542, contrastive_loss=0, total=4154.8, n_correct=2821.16, ppl=5.09, accuracy=67.901, wps=6865.9, ups=1.65, wpb=4154.8, bsz=152.4, num_updates=50600, lr=6.28695e-05, gnorm=0.34, clip=0, loss_scale=128, train_wall=60, gb_free=14, wall=36879
2023-07-05 00:23:31 | INFO | train_inner | epoch 035:    605 / 1474 loss=1.305, trans_loss=5.109, nll_loss=2.342, w2v_ctc_loss=0.378, task_loss=1.498, contrastive_loss=0, total=4170.95, n_correct=2833.64, ppl=5.07, accuracy=67.938, wps=6901.9, ups=1.65, wpb=4170.9, bsz=155, num_updates=50700, lr=6.28074e-05, gnorm=0.34, clip=0, loss_scale=128, train_wall=60, gb_free=16.3, wall=36939
2023-07-05 00:24:31 | INFO | train_inner | epoch 035:    705 / 1474 loss=1.311, trans_loss=5.118, nll_loss=2.354, w2v_ctc_loss=0.388, task_loss=1.585, contrastive_loss=0, total=4081.06, n_correct=2768.18, ppl=5.11, accuracy=67.83, wps=6816.9, ups=1.67, wpb=4081.1, bsz=147.4, num_updates=50800, lr=6.27456e-05, gnorm=0.348, clip=0, loss_scale=128, train_wall=59, gb_free=17.2, wall=36999
2023-07-05 00:25:31 | INFO | train_inner | epoch 035:    805 / 1474 loss=1.308, trans_loss=5.117, nll_loss=2.353, w2v_ctc_loss=0.386, task_loss=1.498, contrastive_loss=0, total=4151.95, n_correct=2813.95, ppl=5.11, accuracy=67.774, wps=6928.5, ups=1.67, wpb=4151.9, bsz=155.1, num_updates=50900, lr=6.26839e-05, gnorm=0.339, clip=0, loss_scale=128, train_wall=59, gb_free=15.9, wall=37059
2023-07-05 00:25:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-07-05 00:26:32 | INFO | train_inner | epoch 035:    906 / 1474 loss=1.311, trans_loss=5.118, nll_loss=2.354, w2v_ctc_loss=0.387, task_loss=1.59, contrastive_loss=0, total=4099.12, n_correct=2777.15, ppl=5.11, accuracy=67.75, wps=6675.3, ups=1.63, wpb=4099.1, bsz=147.2, num_updates=51000, lr=6.26224e-05, gnorm=0.346, clip=0, loss_scale=128, train_wall=61, gb_free=16.2, wall=37120
2023-07-05 00:27:32 | INFO | train_inner | epoch 035:   1006 / 1474 loss=1.312, trans_loss=5.126, nll_loss=2.366, w2v_ctc_loss=0.383, task_loss=1.538, contrastive_loss=0, total=4141.74, n_correct=2799.34, ppl=5.15, accuracy=67.589, wps=6934.2, ups=1.67, wpb=4141.7, bsz=153.1, num_updates=51100, lr=6.25611e-05, gnorm=0.34, clip=0, loss_scale=128, train_wall=59, gb_free=17.7, wall=37180
2023-07-05 00:28:31 | INFO | train_inner | epoch 035:   1106 / 1474 loss=1.311, trans_loss=5.121, nll_loss=2.359, w2v_ctc_loss=0.387, task_loss=1.45, contrastive_loss=0, total=4182.91, n_correct=2835.08, ppl=5.13, accuracy=67.778, wps=7006.6, ups=1.68, wpb=4182.9, bsz=155.7, num_updates=51200, lr=6.25e-05, gnorm=0.343, clip=0, loss_scale=128, train_wall=59, gb_free=10.7, wall=37240
2023-07-05 00:29:31 | INFO | train_inner | epoch 035:   1206 / 1474 loss=1.312, trans_loss=5.123, nll_loss=2.362, w2v_ctc_loss=0.382, task_loss=1.405, contrastive_loss=0, total=4207.87, n_correct=2848.63, ppl=5.14, accuracy=67.698, wps=7035.7, ups=1.67, wpb=4207.9, bsz=160.2, num_updates=51300, lr=6.24391e-05, gnorm=0.337, clip=0, loss_scale=128, train_wall=59, gb_free=15.1, wall=37299
2023-07-05 00:30:31 | INFO | train_inner | epoch 035:   1306 / 1474 loss=1.307, trans_loss=5.122, nll_loss=2.36, w2v_ctc_loss=0.383, task_loss=1.448, contrastive_loss=0, total=4141.67, n_correct=2803.4, ppl=5.13, accuracy=67.688, wps=6904.3, ups=1.67, wpb=4141.7, bsz=157, num_updates=51400, lr=6.23783e-05, gnorm=0.345, clip=0, loss_scale=128, train_wall=60, gb_free=16.5, wall=37359
2023-07-05 00:31:31 | INFO | train_inner | epoch 035:   1406 / 1474 loss=1.313, trans_loss=5.134, nll_loss=2.375, w2v_ctc_loss=0.387, task_loss=1.654, contrastive_loss=0, total=4057.93, n_correct=2736.98, ppl=5.19, accuracy=67.448, wps=6776.3, ups=1.67, wpb=4057.9, bsz=142.8, num_updates=51500, lr=6.23177e-05, gnorm=0.348, clip=0, loss_scale=128, train_wall=59, gb_free=15.6, wall=37419
2023-07-05 00:32:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-05 00:32:38 | INFO | dev_st | epoch 035 | valid on 'dev_st' subset | loss 2.157 | trans_loss 5.556 | nll_loss 2.829 | w2v_ctc_loss 0.709 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2495.9 | ppl 7.1 | accuracy 62.345 | uer 16.619 | wer 18.482 | raw_wer 18.482 | bleu 20.42 | wps 2052 | wpb 4003.4 | bsz 141.8 | num_updates 51568 | best_bleu 20.53
2023-07-05 00:32:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 51568 updates
2023-07-05 00:32:38 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.4201.pt
2023-07-05 00:32:40 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.4201.pt
2023-07-05 00:32:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.4201.pt (epoch 35 @ 51568 updates, score 20.42) (writing took 5.451708159875125 seconds)
2023-07-05 00:32:44 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-07-05 00:32:44 | INFO | train | epoch 035 | loss 1.308 | trans_loss 5.116 | nll_loss 2.352 | w2v_ctc_loss 0.382 | task_loss 1.514 | contrastive_loss 0 | total 4138.82 | n_correct 2806.47 | ppl 5.1 | accuracy 67.808 | wps 6579 | ups 1.59 | wpb 4138.8 | bsz 152.9 | num_updates 51568 | lr 6.22766e-05 | gnorm 0.342 | clip 0 | loss_scale 128 | train_wall 879 | gb_free 17.4 | wall 37492
2023-07-05 00:32:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-05 00:32:44 | INFO | fairseq.trainer | begin training epoch 36
2023-07-05 00:32:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-05 00:33:11 | INFO | train_inner | epoch 036:     32 / 1474 loss=1.307, trans_loss=5.11, nll_loss=2.344, w2v_ctc_loss=0.38, task_loss=1.473, contrastive_loss=0, total=4128.66, n_correct=2803.81, ppl=5.08, accuracy=67.911, wps=4117.3, ups=1, wpb=4128.7, bsz=154.5, num_updates=51600, lr=6.22573e-05, gnorm=0.344, clip=0, loss_scale=128, train_wall=59, gb_free=16.5, wall=37520
2023-07-05 00:34:12 | INFO | train_inner | epoch 036:    132 / 1474 loss=1.304, trans_loss=5.1, nll_loss=2.329, w2v_ctc_loss=0.381, task_loss=1.58, contrastive_loss=0, total=4101.15, n_correct=2793.86, ppl=5.03, accuracy=68.124, wps=6783.5, ups=1.65, wpb=4101.1, bsz=149.4, num_updates=51700, lr=6.2197e-05, gnorm=0.348, clip=0, loss_scale=128, train_wall=60, gb_free=16.7, wall=37580
2023-07-05 00:35:12 | INFO | train_inner | epoch 036:    232 / 1474 loss=1.303, trans_loss=5.096, nll_loss=2.326, w2v_ctc_loss=0.377, task_loss=1.537, contrastive_loss=0, total=4153.27, n_correct=2832.75, ppl=5.01, accuracy=68.205, wps=6897.6, ups=1.66, wpb=4153.3, bsz=151.8, num_updates=51800, lr=6.2137e-05, gnorm=0.341, clip=0, loss_scale=128, train_wall=60, gb_free=17, wall=37640
2023-07-05 00:36:11 | INFO | train_inner | epoch 036:    332 / 1474 loss=1.3, trans_loss=5.094, nll_loss=2.322, w2v_ctc_loss=0.371, task_loss=1.438, contrastive_loss=0, total=4162.11, n_correct=2839.45, ppl=5, accuracy=68.221, wps=7007.2, ups=1.68, wpb=4162.1, bsz=155.1, num_updates=51900, lr=6.20771e-05, gnorm=0.341, clip=0, loss_scale=128, train_wall=59, gb_free=16.9, wall=37700
2023-07-05 00:37:11 | INFO | train_inner | epoch 036:    432 / 1474 loss=1.304, trans_loss=5.097, nll_loss=2.328, w2v_ctc_loss=0.374, task_loss=1.326, contrastive_loss=0, total=4234.05, n_correct=2882.6, ppl=5.02, accuracy=68.081, wps=7106.5, ups=1.68, wpb=4234.1, bsz=166.6, num_updates=52000, lr=6.20174e-05, gnorm=0.338, clip=0, loss_scale=128, train_wall=59, gb_free=16.3, wall=37759
2023-07-05 00:37:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-05 00:37:36 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 2.166 | trans_loss 5.563 | nll_loss 2.838 | w2v_ctc_loss 0.731 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2489.2 | ppl 7.15 | accuracy 62.177 | uer 16.726 | wer 18.515 | raw_wer 18.515 | bleu 20.1 | wps 2098.5 | wpb 4003.4 | bsz 141.8 | num_updates 52000 | best_bleu 20.53
2023-07-05 00:37:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 52000 updates
2023-07-05 00:37:36 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_36_52000.pt
2023-07-05 00:37:39 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_36_52000.pt
2023-07-05 00:37:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_36_52000.pt (epoch 36 @ 52000 updates, score 20.1) (writing took 5.4455388630740345 seconds)
2023-07-05 00:38:43 | INFO | train_inner | epoch 036:    532 / 1474 loss=1.305, trans_loss=5.116, nll_loss=2.352, w2v_ctc_loss=0.374, task_loss=1.513, contrastive_loss=0, total=4149.22, n_correct=2812.61, ppl=5.11, accuracy=67.786, wps=4514.8, ups=1.09, wpb=4149.2, bsz=156.2, num_updates=52100, lr=6.19578e-05, gnorm=0.343, clip=0, loss_scale=128, train_wall=60, gb_free=17.9, wall=37851
2023-07-05 00:39:43 | INFO | train_inner | epoch 036:    632 / 1474 loss=1.303, trans_loss=5.096, nll_loss=2.326, w2v_ctc_loss=0.379, task_loss=1.459, contrastive_loss=0, total=4179.05, n_correct=2846.99, ppl=5.01, accuracy=68.125, wps=6946.2, ups=1.66, wpb=4179.1, bsz=158.4, num_updates=52200, lr=6.18984e-05, gnorm=0.342, clip=0, loss_scale=128, train_wall=60, gb_free=17.3, wall=37911
2023-07-05 00:40:44 | INFO | train_inner | epoch 036:    732 / 1474 loss=1.309, trans_loss=5.116, nll_loss=2.353, w2v_ctc_loss=0.384, task_loss=1.471, contrastive_loss=0, total=4180.07, n_correct=2833.26, ppl=5.11, accuracy=67.78, wps=6873.7, ups=1.64, wpb=4180.1, bsz=157.8, num_updates=52300, lr=6.18392e-05, gnorm=0.342, clip=0, loss_scale=128, train_wall=60, gb_free=14, wall=37972
2023-07-05 00:41:44 | INFO | train_inner | epoch 036:    832 / 1474 loss=1.314, trans_loss=5.129, nll_loss=2.37, w2v_ctc_loss=0.381, task_loss=1.421, contrastive_loss=0, total=4178.14, n_correct=2825.65, ppl=5.17, accuracy=67.629, wps=6967.1, ups=1.67, wpb=4178.1, bsz=160.9, num_updates=52400, lr=6.17802e-05, gnorm=0.341, clip=0, loss_scale=128, train_wall=59, gb_free=16.5, wall=38032
2023-07-05 00:42:44 | INFO | train_inner | epoch 036:    932 / 1474 loss=1.303, trans_loss=5.105, nll_loss=2.338, w2v_ctc_loss=0.378, task_loss=1.53, contrastive_loss=0, total=4175.34, n_correct=2835, ppl=5.06, accuracy=67.899, wps=6929.5, ups=1.66, wpb=4175.3, bsz=152.7, num_updates=52500, lr=6.17213e-05, gnorm=0.341, clip=0, loss_scale=128, train_wall=60, gb_free=17.7, wall=38092
2023-07-05 00:43:44 | INFO | train_inner | epoch 036:   1032 / 1474 loss=1.307, trans_loss=5.112, nll_loss=2.346, w2v_ctc_loss=0.382, task_loss=1.566, contrastive_loss=0, total=4176.5, n_correct=2834.42, ppl=5.08, accuracy=67.866, wps=6999.5, ups=1.68, wpb=4176.5, bsz=150.8, num_updates=52600, lr=6.16626e-05, gnorm=0.339, clip=0, loss_scale=128, train_wall=59, gb_free=16.5, wall=38152
2023-07-05 00:44:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-05 00:44:44 | INFO | train_inner | epoch 036:   1133 / 1474 loss=1.305, trans_loss=5.11, nll_loss=2.344, w2v_ctc_loss=0.383, task_loss=1.529, contrastive_loss=0, total=4126.43, n_correct=2799.22, ppl=5.08, accuracy=67.836, wps=6807.9, ups=1.65, wpb=4126.4, bsz=152, num_updates=52700, lr=6.16041e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=38213
2023-07-05 00:45:44 | INFO | train_inner | epoch 036:   1233 / 1474 loss=1.305, trans_loss=5.111, nll_loss=2.343, w2v_ctc_loss=0.381, task_loss=1.681, contrastive_loss=0, total=4050.06, n_correct=2748.55, ppl=5.07, accuracy=67.864, wps=6774.5, ups=1.67, wpb=4050.1, bsz=140, num_updates=52800, lr=6.15457e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=59, gb_free=16.9, wall=38272
2023-07-05 00:46:44 | INFO | train_inner | epoch 036:   1333 / 1474 loss=1.309, trans_loss=5.116, nll_loss=2.352, w2v_ctc_loss=0.383, task_loss=1.503, contrastive_loss=0, total=4110.28, n_correct=2786.59, ppl=5.11, accuracy=67.796, wps=6903.9, ups=1.68, wpb=4110.3, bsz=153.2, num_updates=52900, lr=6.14875e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=59, gb_free=16.6, wall=38332
2023-07-05 00:47:44 | INFO | train_inner | epoch 036:   1433 / 1474 loss=1.313, trans_loss=5.133, nll_loss=2.373, w2v_ctc_loss=0.385, task_loss=1.721, contrastive_loss=0, total=4043.82, n_correct=2725.03, ppl=5.18, accuracy=67.388, wps=6740.9, ups=1.67, wpb=4043.8, bsz=138.5, num_updates=53000, lr=6.14295e-05, gnorm=0.356, clip=0, loss_scale=64, train_wall=60, gb_free=17.5, wall=38392
2023-07-05 00:48:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-05 00:48:31 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 2.152 | trans_loss 5.553 | nll_loss 2.825 | w2v_ctc_loss 0.695 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2499.9 | ppl 7.09 | accuracy 62.444 | uer 16.489 | wer 18.295 | raw_wer 18.295 | bleu 20.28 | wps 2374.3 | wpb 4003.4 | bsz 141.8 | num_updates 53041 | best_bleu 20.53
2023-07-05 00:48:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 53041 updates
2023-07-05 00:48:31 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.2800.pt
2023-07-05 00:48:34 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.2800.pt
2023-07-05 00:48:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.2800.pt (epoch 36 @ 53041 updates, score 20.28) (writing took 5.501221730839461 seconds)
2023-07-05 00:48:37 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-07-05 00:48:37 | INFO | train | epoch 036 | loss 1.306 | trans_loss 5.108 | nll_loss 2.342 | w2v_ctc_loss 0.38 | task_loss 1.515 | contrastive_loss 0 | total 4138.3 | n_correct 2810.64 | ppl 5.07 | accuracy 67.918 | wps 6393.9 | ups 1.55 | wpb 4138.3 | bsz 152.8 | num_updates 53041 | lr 6.14058e-05 | gnorm 0.343 | clip 0 | loss_scale 64 | train_wall 877 | gb_free 17 | wall 38445
2023-07-05 00:48:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-05 00:48:37 | INFO | fairseq.trainer | begin training epoch 37
2023-07-05 00:48:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-05 00:49:21 | INFO | train_inner | epoch 037:     59 / 1474 loss=1.3, trans_loss=5.089, nll_loss=2.317, w2v_ctc_loss=0.376, task_loss=1.515, contrastive_loss=0, total=4094.27, n_correct=2796.93, ppl=4.98, accuracy=68.313, wps=4202.2, ups=1.03, wpb=4094.3, bsz=150.1, num_updates=53100, lr=6.13716e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=59, gb_free=16, wall=38489
2023-07-05 00:50:21 | INFO | train_inner | epoch 037:    159 / 1474 loss=1.302, trans_loss=5.093, nll_loss=2.321, w2v_ctc_loss=0.376, task_loss=1.536, contrastive_loss=0, total=4128.52, n_correct=2818.65, ppl=5, accuracy=68.273, wps=6890.6, ups=1.67, wpb=4128.5, bsz=153.7, num_updates=53200, lr=6.13139e-05, gnorm=0.351, clip=0, loss_scale=64, train_wall=59, gb_free=15.6, wall=38549
2023-07-05 00:51:21 | INFO | train_inner | epoch 037:    259 / 1474 loss=1.294, trans_loss=5.076, nll_loss=2.299, w2v_ctc_loss=0.365, task_loss=1.413, contrastive_loss=0, total=4191.64, n_correct=2871.1, ppl=4.92, accuracy=68.496, wps=7013.8, ups=1.67, wpb=4191.6, bsz=160, num_updates=53300, lr=6.12564e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=59, gb_free=16.8, wall=38609
2023-07-05 00:52:21 | INFO | train_inner | epoch 037:    359 / 1474 loss=1.304, trans_loss=5.09, nll_loss=2.317, w2v_ctc_loss=0.379, task_loss=1.535, contrastive_loss=0, total=4168.16, n_correct=2844.68, ppl=4.98, accuracy=68.248, wps=6936.7, ups=1.66, wpb=4168.2, bsz=152.7, num_updates=53400, lr=6.1199e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=38669
2023-07-05 00:53:22 | INFO | train_inner | epoch 037:    459 / 1474 loss=1.308, trans_loss=5.114, nll_loss=2.351, w2v_ctc_loss=0.374, task_loss=1.46, contrastive_loss=0, total=4179.15, n_correct=2832.73, ppl=5.1, accuracy=67.782, wps=6866.5, ups=1.64, wpb=4179.1, bsz=158.9, num_updates=53500, lr=6.11418e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=60, gb_free=14.1, wall=38730
2023-07-05 00:54:22 | INFO | train_inner | epoch 037:    559 / 1474 loss=1.301, trans_loss=5.092, nll_loss=2.321, w2v_ctc_loss=0.381, task_loss=1.565, contrastive_loss=0, total=4092.13, n_correct=2788.51, ppl=5, accuracy=68.143, wps=6791.8, ups=1.66, wpb=4092.1, bsz=149.9, num_updates=53600, lr=6.10847e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=38790
2023-07-05 00:55:22 | INFO | train_inner | epoch 037:    659 / 1474 loss=1.305, trans_loss=5.104, nll_loss=2.336, w2v_ctc_loss=0.386, task_loss=1.586, contrastive_loss=0, total=4102.49, n_correct=2786.87, ppl=5.05, accuracy=67.931, wps=6866, ups=1.67, wpb=4102.5, bsz=146, num_updates=53700, lr=6.10278e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=59, gb_free=17.2, wall=38850
2023-07-05 00:56:22 | INFO | train_inner | epoch 037:    759 / 1474 loss=1.299, trans_loss=5.096, nll_loss=2.326, w2v_ctc_loss=0.372, task_loss=1.512, contrastive_loss=0, total=4123.95, n_correct=2808.09, ppl=5.01, accuracy=68.092, wps=6900.3, ups=1.67, wpb=4123.9, bsz=152.4, num_updates=53800, lr=6.09711e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=59, gb_free=16.9, wall=38910
2023-07-05 00:57:21 | INFO | train_inner | epoch 037:    859 / 1474 loss=1.301, trans_loss=5.091, nll_loss=2.319, w2v_ctc_loss=0.372, task_loss=1.424, contrastive_loss=0, total=4159.03, n_correct=2835.2, ppl=4.99, accuracy=68.17, wps=6965.2, ups=1.67, wpb=4159, bsz=157.9, num_updates=53900, lr=6.09145e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=59, gb_free=15.9, wall=38970
2023-07-05 00:58:21 | INFO | train_inner | epoch 037:    959 / 1474 loss=1.307, trans_loss=5.115, nll_loss=2.35, w2v_ctc_loss=0.384, task_loss=1.617, contrastive_loss=0, total=4097.89, n_correct=2782.73, ppl=5.1, accuracy=67.906, wps=6860.1, ups=1.67, wpb=4097.9, bsz=146.2, num_updates=54000, lr=6.08581e-05, gnorm=0.347, clip=0, loss_scale=64, train_wall=59, gb_free=16.1, wall=39029
2023-07-05 00:58:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-05 00:58:45 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 2.163 | trans_loss 5.557 | nll_loss 2.831 | w2v_ctc_loss 0.725 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2502.1 | ppl 7.12 | accuracy 62.499 | uer 16.572 | wer 18.344 | raw_wer 18.344 | bleu 20.21 | wps 2401.4 | wpb 4003.4 | bsz 141.8 | num_updates 54000 | best_bleu 20.53
2023-07-05 00:58:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54000 updates
2023-07-05 00:58:45 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_37_54000.pt
2023-07-05 00:58:47 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_37_54000.pt
2023-07-05 00:58:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_37_54000.pt (epoch 37 @ 54000 updates, score 20.21) (writing took 5.475945984013379 seconds)
2023-07-05 00:59:51 | INFO | train_inner | epoch 037:   1059 / 1474 loss=1.299, trans_loss=5.097, nll_loss=2.329, w2v_ctc_loss=0.373, task_loss=1.417, contrastive_loss=0, total=4162.64, n_correct=2836.55, ppl=5.02, accuracy=68.143, wps=4648.5, ups=1.12, wpb=4162.6, bsz=159.9, num_updates=54100, lr=6.08018e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=39119
2023-07-05 01:00:51 | INFO | train_inner | epoch 037:   1159 / 1474 loss=1.305, trans_loss=5.112, nll_loss=2.347, w2v_ctc_loss=0.376, task_loss=1.469, contrastive_loss=0, total=4176.35, n_correct=2834.18, ppl=5.09, accuracy=67.863, wps=6956.9, ups=1.67, wpb=4176.4, bsz=156.1, num_updates=54200, lr=6.07457e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=60, gb_free=16.2, wall=39179
2023-07-05 01:01:51 | INFO | train_inner | epoch 037:   1259 / 1474 loss=1.304, trans_loss=5.106, nll_loss=2.339, w2v_ctc_loss=0.377, task_loss=1.468, contrastive_loss=0, total=4167.2, n_correct=2834.04, ppl=5.06, accuracy=68.008, wps=6941.9, ups=1.67, wpb=4167.2, bsz=155.9, num_updates=54300, lr=6.06897e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=60, gb_free=16.2, wall=39239
2023-07-05 01:02:51 | INFO | train_inner | epoch 037:   1359 / 1474 loss=1.314, trans_loss=5.119, nll_loss=2.355, w2v_ctc_loss=0.395, task_loss=1.664, contrastive_loss=0, total=4072.63, n_correct=2758.43, ppl=5.11, accuracy=67.731, wps=6777, ups=1.66, wpb=4072.6, bsz=143, num_updates=54400, lr=6.06339e-05, gnorm=0.355, clip=0, loss_scale=64, train_wall=60, gb_free=16.1, wall=39299
2023-07-05 01:03:51 | INFO | train_inner | epoch 037:   1459 / 1474 loss=1.306, trans_loss=5.113, nll_loss=2.349, w2v_ctc_loss=0.378, task_loss=1.503, contrastive_loss=0, total=4155.97, n_correct=2821.5, ppl=5.09, accuracy=67.89, wps=6944.7, ups=1.67, wpb=4156, bsz=152.6, num_updates=54500, lr=6.05783e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=59, gb_free=16.3, wall=39359
2023-07-05 01:04:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-05 01:04:25 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 2.157 | trans_loss 5.554 | nll_loss 2.827 | w2v_ctc_loss 0.712 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2497.3 | ppl 7.09 | accuracy 62.379 | uer 16.508 | wer 18.452 | raw_wer 18.452 | bleu 19.83 | wps 2146.6 | wpb 4003.4 | bsz 141.8 | num_updates 54515 | best_bleu 20.53
2023-07-05 01:04:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54515 updates
2023-07-05 01:04:25 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt
2023-07-05 01:04:29 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt
2023-07-05 01:04:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt (epoch 37 @ 54515 updates, score 19.83) (writing took 4.41470164898783 seconds)
2023-07-05 01:04:29 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-07-05 01:04:29 | INFO | train | epoch 037 | loss 1.304 | trans_loss 5.101 | nll_loss 2.332 | w2v_ctc_loss 0.378 | task_loss 1.515 | contrastive_loss 0 | total 4138.65 | n_correct 2816.66 | ppl 5.04 | accuracy 68.057 | wps 6407.3 | ups 1.55 | wpb 4138.6 | bsz 152.8 | num_updates 54515 | lr 6.05699e-05 | gnorm 0.345 | clip 0 | loss_scale 64 | train_wall 878 | gb_free 13.3 | wall 39397
2023-07-05 01:04:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-05 01:04:29 | INFO | fairseq.trainer | begin training epoch 38
2023-07-05 01:04:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-05 01:05:29 | INFO | train_inner | epoch 038:     85 / 1474 loss=1.298, trans_loss=5.08, nll_loss=2.304, w2v_ctc_loss=0.373, task_loss=1.582, contrastive_loss=0, total=4085.19, n_correct=2794.05, ppl=4.94, accuracy=68.395, wps=4168.8, ups=1.02, wpb=4085.2, bsz=146.8, num_updates=54600, lr=6.05228e-05, gnorm=0.347, clip=0, loss_scale=64, train_wall=59, gb_free=17.1, wall=39457
2023-07-05 01:06:28 | INFO | train_inner | epoch 038:    185 / 1474 loss=1.297, trans_loss=5.084, nll_loss=2.309, w2v_ctc_loss=0.373, task_loss=1.587, contrastive_loss=0, total=4081.12, n_correct=2788.86, ppl=4.96, accuracy=68.336, wps=6841.8, ups=1.68, wpb=4081.1, bsz=146.3, num_updates=54700, lr=6.04674e-05, gnorm=0.346, clip=0, loss_scale=128, train_wall=59, gb_free=17, wall=39517
2023-07-05 01:07:28 | INFO | train_inner | epoch 038:    285 / 1474 loss=1.299, trans_loss=5.086, nll_loss=2.313, w2v_ctc_loss=0.375, task_loss=1.582, contrastive_loss=0, total=4073.75, n_correct=2784.8, ppl=4.97, accuracy=68.36, wps=6785.9, ups=1.67, wpb=4073.8, bsz=147.9, num_updates=54800, lr=6.04122e-05, gnorm=0.348, clip=0, loss_scale=128, train_wall=60, gb_free=17.1, wall=39577
2023-07-05 01:07:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-05 01:08:29 | INFO | train_inner | epoch 038:    386 / 1474 loss=1.3, trans_loss=5.087, nll_loss=2.314, w2v_ctc_loss=0.378, task_loss=1.52, contrastive_loss=0, total=4164.03, n_correct=2845.92, ppl=4.97, accuracy=68.345, wps=6881.7, ups=1.65, wpb=4164, bsz=152.7, num_updates=54900, lr=6.03572e-05, gnorm=0.348, clip=0, loss_scale=64, train_wall=60, gb_free=13.2, wall=39637
2023-07-05 01:09:28 | INFO | train_inner | epoch 038:    486 / 1474 loss=1.297, trans_loss=5.078, nll_loss=2.303, w2v_ctc_loss=0.371, task_loss=1.457, contrastive_loss=0, total=4194, n_correct=2871.56, ppl=4.93, accuracy=68.468, wps=7046.5, ups=1.68, wpb=4194, bsz=156.5, num_updates=55000, lr=6.03023e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=59, gb_free=16.3, wall=39697
tensor(0.0230, device='cuda:0')
tensor(0.0005, device='cuda:0')
2023-07-05 01:10:30 | INFO | train_inner | epoch 038:    586 / 1474 loss=1.305, trans_loss=5.107, nll_loss=2.34, w2v_ctc_loss=0.375, task_loss=1.519, contrastive_loss=0, total=4172.06, n_correct=2833.35, ppl=5.06, accuracy=67.912, wps=6782.4, ups=1.63, wpb=4172.1, bsz=154.2, num_updates=55100, lr=6.02475e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=61, gb_free=15.2, wall=39758
2023-07-05 01:11:30 | INFO | train_inner | epoch 038:    686 / 1474 loss=1.297, trans_loss=5.086, nll_loss=2.314, w2v_ctc_loss=0.369, task_loss=1.434, contrastive_loss=0, total=4173.18, n_correct=2850.19, ppl=4.97, accuracy=68.298, wps=6894.2, ups=1.65, wpb=4173.2, bsz=160.9, num_updates=55200, lr=6.01929e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=39819
2023-07-05 01:12:30 | INFO | train_inner | epoch 038:    786 / 1474 loss=1.294, trans_loss=5.077, nll_loss=2.302, w2v_ctc_loss=0.365, task_loss=1.384, contrastive_loss=0, total=4187.51, n_correct=2866.21, ppl=4.93, accuracy=68.447, wps=6985.7, ups=1.67, wpb=4187.5, bsz=163.6, num_updates=55300, lr=6.01385e-05, gnorm=0.339, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=39879
2023-07-05 01:13:29 | INFO | train_inner | epoch 038:    886 / 1474 loss=1.296, trans_loss=5.083, nll_loss=2.31, w2v_ctc_loss=0.373, task_loss=1.429, contrastive_loss=0, total=4124.92, n_correct=2816.02, ppl=4.96, accuracy=68.268, wps=6992.4, ups=1.7, wpb=4124.9, bsz=155.8, num_updates=55400, lr=6.00842e-05, gnorm=0.341, clip=0, loss_scale=64, train_wall=59, gb_free=13.7, wall=39938
2023-07-05 01:14:29 | INFO | train_inner | epoch 038:    986 / 1474 loss=1.3, trans_loss=5.106, nll_loss=2.338, w2v_ctc_loss=0.377, task_loss=1.526, contrastive_loss=0, total=4110.21, n_correct=2796.14, ppl=5.06, accuracy=68.029, wps=6859, ups=1.67, wpb=4110.2, bsz=150.3, num_updates=55500, lr=6.003e-05, gnorm=0.338, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=39998
2023-07-05 01:15:29 | INFO | train_inner | epoch 038:   1086 / 1474 loss=1.302, trans_loss=5.09, nll_loss=2.319, w2v_ctc_loss=0.375, task_loss=1.375, contrastive_loss=0, total=4250.47, n_correct=2900.12, ppl=4.99, accuracy=68.231, wps=7125.6, ups=1.68, wpb=4250.5, bsz=164.7, num_updates=55600, lr=5.9976e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=59, gb_free=15.9, wall=40057
2023-07-05 01:16:30 | INFO | train_inner | epoch 038:   1186 / 1474 loss=1.307, trans_loss=5.11, nll_loss=2.345, w2v_ctc_loss=0.384, task_loss=1.646, contrastive_loss=0, total=4090.6, n_correct=2779.85, ppl=5.08, accuracy=67.957, wps=6756.1, ups=1.65, wpb=4090.6, bsz=145.1, num_updates=55700, lr=5.99222e-05, gnorm=0.35, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=40118
2023-07-05 01:17:30 | INFO | train_inner | epoch 038:   1286 / 1474 loss=1.308, trans_loss=5.111, nll_loss=2.345, w2v_ctc_loss=0.38, task_loss=1.625, contrastive_loss=0, total=4140.1, n_correct=2809.87, ppl=5.08, accuracy=67.87, wps=6841.2, ups=1.65, wpb=4140.1, bsz=147.2, num_updates=55800, lr=5.98684e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=60, gb_free=15.8, wall=40178
2023-07-05 01:18:30 | INFO | train_inner | epoch 038:   1386 / 1474 loss=1.31, trans_loss=5.111, nll_loss=2.347, w2v_ctc_loss=0.381, task_loss=1.511, contrastive_loss=0, total=4145.35, n_correct=2813.2, ppl=5.09, accuracy=67.864, wps=6900.8, ups=1.66, wpb=4145.4, bsz=154.2, num_updates=55900, lr=5.98149e-05, gnorm=0.351, clip=0, loss_scale=64, train_wall=60, gb_free=15.9, wall=40238
2023-07-05 01:19:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0230, device='cuda:4')
tensor(0.0005, device='cuda:4')
tensor(0.0230, device='cuda:7')
tensor(0.0005, device='cuda:7')
tensor(0.0230, device='cuda:5')
tensor(0.0005, device='cuda:5')
tensor(0.0230, device='cuda:6')
tensor(0.0005, device='cuda:6')
tensor(0.0230, device='cuda:1')
tensor(0.0005, device='cuda:1')
tensor(0.0230, device='cuda:3')
tensor(0.0005, device='cuda:3')
tensor(0.0230, device='cuda:2')
tensor(0.0005, device='cuda:2')
2023-07-05 01:19:47 | INFO | dev_st | epoch 038 | valid on 'dev_st' subset | loss 2.159 | trans_loss 5.556 | nll_loss 2.826 | w2v_ctc_loss 0.717 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2501.7 | ppl 7.09 | accuracy 62.489 | uer 16.444 | wer 18.262 | raw_wer 18.262 | bleu 19.9 | wps 2281.5 | wpb 4003.4 | bsz 141.8 | num_updates 55988 | best_bleu 20.53
2023-07-05 01:19:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 55988 updates
2023-07-05 01:19:47 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt
2023-07-05 01:19:51 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt
2023-07-05 01:19:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt (epoch 38 @ 55988 updates, score 19.9) (writing took 4.373995292931795 seconds)
2023-07-05 01:19:51 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-07-05 01:19:51 | INFO | train | epoch 038 | loss 1.301 | trans_loss 5.093 | nll_loss 2.322 | w2v_ctc_loss 0.375 | task_loss 1.515 | contrastive_loss 0 | total 4138.13 | n_correct 2821.82 | ppl 5 | accuracy 68.191 | wps 6610.6 | ups 1.6 | wpb 4138.1 | bsz 152.8 | num_updates 55988 | lr 5.97678e-05 | gnorm 0.345 | clip 0 | loss_scale 64 | train_wall 879 | gb_free 16.8 | wall 40320
2023-07-05 01:19:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-05 01:19:52 | INFO | fairseq.trainer | begin training epoch 39
2023-07-05 01:19:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-05 01:20:07 | INFO | train_inner | epoch 039:     12 / 1474 loss=1.304, trans_loss=5.102, nll_loss=2.334, w2v_ctc_loss=0.377, task_loss=1.616, contrastive_loss=0, total=4040.68, n_correct=2749.88, ppl=5.04, accuracy=68.055, wps=4182.4, ups=1.04, wpb=4040.7, bsz=143.6, num_updates=56000, lr=5.97614e-05, gnorm=0.355, clip=0, loss_scale=64, train_wall=59, gb_free=16.3, wall=40335
2023-07-05 01:20:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-05 01:20:30 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 2.158 | trans_loss 5.554 | nll_loss 2.822 | w2v_ctc_loss 0.713 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2500.8 | ppl 7.07 | accuracy 62.467 | uer 16.439 | wer 18.359 | raw_wer 18.359 | bleu 20.29 | wps 2412.4 | wpb 4003.4 | bsz 141.8 | num_updates 56000 | best_bleu 20.53
2023-07-05 01:20:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 56000 updates
2023-07-05 01:20:30 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_39_56000.pt
2023-07-05 01:20:33 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_39_56000.pt
2023-07-05 01:20:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_39_56000.pt (epoch 39 @ 56000 updates, score 20.29) (writing took 8.761048723943532 seconds)
2023-07-05 01:21:38 | INFO | train_inner | epoch 039:    112 / 1474 loss=1.294, trans_loss=5.065, nll_loss=2.284, w2v_ctc_loss=0.373, task_loss=1.622, contrastive_loss=0, total=4056.32, n_correct=2786.42, ppl=4.87, accuracy=68.693, wps=4439.1, ups=1.09, wpb=4056.3, bsz=143, num_updates=56100, lr=5.97081e-05, gnorm=0.348, clip=0, loss_scale=64, train_wall=59, gb_free=15.9, wall=40426
2023-07-05 01:22:38 | INFO | train_inner | epoch 039:    212 / 1474 loss=1.294, trans_loss=5.065, nll_loss=2.285, w2v_ctc_loss=0.371, task_loss=1.543, contrastive_loss=0, total=4133.67, n_correct=2838.73, ppl=4.87, accuracy=68.673, wps=6849.5, ups=1.66, wpb=4133.7, bsz=150.3, num_updates=56200, lr=5.9655e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=40487
2023-07-05 01:23:38 | INFO | train_inner | epoch 039:    312 / 1474 loss=1.292, trans_loss=5.065, nll_loss=2.284, w2v_ctc_loss=0.371, task_loss=1.55, contrastive_loss=0, total=4134.37, n_correct=2840.44, ppl=4.87, accuracy=68.703, wps=6921.5, ups=1.67, wpb=4134.4, bsz=149.4, num_updates=56300, lr=5.9602e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=59, gb_free=16.5, wall=40546
2023-07-05 01:24:39 | INFO | train_inner | epoch 039:    412 / 1474 loss=1.295, trans_loss=5.078, nll_loss=2.304, w2v_ctc_loss=0.37, task_loss=1.485, contrastive_loss=0, total=4130.57, n_correct=2825.91, ppl=4.94, accuracy=68.415, wps=6816, ups=1.65, wpb=4130.6, bsz=156.9, num_updates=56400, lr=5.95491e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=40607
2023-07-05 01:25:39 | INFO | train_inner | epoch 039:    512 / 1474 loss=1.296, trans_loss=5.087, nll_loss=2.314, w2v_ctc_loss=0.373, task_loss=1.498, contrastive_loss=0, total=4144.84, n_correct=2827.69, ppl=4.97, accuracy=68.222, wps=6855.5, ups=1.65, wpb=4144.8, bsz=155.4, num_updates=56500, lr=5.94964e-05, gnorm=0.344, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=40668
2023-07-05 01:26:40 | INFO | train_inner | epoch 039:    612 / 1474 loss=1.3, trans_loss=5.089, nll_loss=2.317, w2v_ctc_loss=0.373, task_loss=1.527, contrastive_loss=0, total=4133.85, n_correct=2819.42, ppl=4.98, accuracy=68.203, wps=6850.7, ups=1.66, wpb=4133.9, bsz=151.9, num_updates=56600, lr=5.94438e-05, gnorm=0.344, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=40728
2023-07-05 01:27:39 | INFO | train_inner | epoch 039:    712 / 1474 loss=1.301, trans_loss=5.091, nll_loss=2.319, w2v_ctc_loss=0.371, task_loss=1.478, contrastive_loss=0, total=4137.3, n_correct=2819.88, ppl=4.99, accuracy=68.157, wps=6986.9, ups=1.69, wpb=4137.3, bsz=152.9, num_updates=56700, lr=5.93914e-05, gnorm=0.346, clip=0, loss_scale=64, train_wall=59, gb_free=16.2, wall=40787
2023-07-05 01:28:39 | INFO | train_inner | epoch 039:    812 / 1474 loss=1.3, trans_loss=5.087, nll_loss=2.314, w2v_ctc_loss=0.376, task_loss=1.538, contrastive_loss=0, total=4165.72, n_correct=2842.57, ppl=4.97, accuracy=68.237, wps=6887.7, ups=1.65, wpb=4165.7, bsz=153.7, num_updates=56800, lr=5.93391e-05, gnorm=0.347, clip=0, loss_scale=64, train_wall=60, gb_free=15.5, wall=40848
2023-07-05 01:29:39 | INFO | train_inner | epoch 039:    912 / 1474 loss=1.298, trans_loss=5.087, nll_loss=2.316, w2v_ctc_loss=0.373, task_loss=1.558, contrastive_loss=0, total=4131.2, n_correct=2819.85, ppl=4.98, accuracy=68.257, wps=6907.1, ups=1.67, wpb=4131.2, bsz=150.3, num_updates=56900, lr=5.92869e-05, gnorm=0.343, clip=0, loss_scale=128, train_wall=59, gb_free=12.6, wall=40907
2023-07-05 01:30:40 | INFO | train_inner | epoch 039:   1012 / 1474 loss=1.304, trans_loss=5.099, nll_loss=2.33, w2v_ctc_loss=0.376, task_loss=1.479, contrastive_loss=0, total=4199.31, n_correct=2858.45, ppl=5.03, accuracy=68.07, wps=6915.6, ups=1.65, wpb=4199.3, bsz=159.6, num_updates=57000, lr=5.92349e-05, gnorm=0.346, clip=0, loss_scale=128, train_wall=60, gb_free=16.8, wall=40968
2023-07-05 01:31:40 | INFO | train_inner | epoch 039:   1112 / 1474 loss=1.298, trans_loss=5.082, nll_loss=2.309, w2v_ctc_loss=0.369, task_loss=1.419, contrastive_loss=0, total=4192.7, n_correct=2867.27, ppl=4.95, accuracy=68.387, wps=6990.3, ups=1.67, wpb=4192.7, bsz=160.9, num_updates=57100, lr=5.9183e-05, gnorm=0.342, clip=0, loss_scale=128, train_wall=60, gb_free=12.5, wall=41028
2023-07-05 01:32:40 | INFO | train_inner | epoch 039:   1212 / 1474 loss=1.301, trans_loss=5.097, nll_loss=2.328, w2v_ctc_loss=0.374, task_loss=1.503, contrastive_loss=0, total=4126.68, n_correct=2810.94, ppl=5.02, accuracy=68.116, wps=6856.6, ups=1.66, wpb=4126.7, bsz=154.6, num_updates=57200, lr=5.91312e-05, gnorm=0.348, clip=0, loss_scale=128, train_wall=60, gb_free=16.8, wall=41088
2023-07-05 01:32:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-05 01:33:41 | INFO | train_inner | epoch 039:   1313 / 1474 loss=1.3, trans_loss=5.092, nll_loss=2.321, w2v_ctc_loss=0.375, task_loss=1.45, contrastive_loss=0, total=4174.73, n_correct=2848.67, ppl=5, accuracy=68.236, wps=6818.3, ups=1.63, wpb=4174.7, bsz=157.6, num_updates=57300, lr=5.90796e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=61, gb_free=12.7, wall=41150
2023-07-05 01:34:41 | INFO | train_inner | epoch 039:   1413 / 1474 loss=1.301, trans_loss=5.092, nll_loss=2.321, w2v_ctc_loss=0.374, task_loss=1.642, contrastive_loss=0, total=4062.74, n_correct=2771.36, ppl=5, accuracy=68.214, wps=6804.7, ups=1.67, wpb=4062.7, bsz=140.3, num_updates=57400, lr=5.90281e-05, gnorm=0.355, clip=0, loss_scale=64, train_wall=59, gb_free=16.6, wall=41209
2023-07-05 01:35:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-05 01:35:43 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 2.154 | trans_loss 5.553 | nll_loss 2.827 | w2v_ctc_loss 0.701 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2503.5 | ppl 7.1 | accuracy 62.534 | uer 16.585 | wer 18.396 | raw_wer 18.396 | bleu 20.03 | wps 2136.7 | wpb 4003.4 | bsz 141.8 | num_updates 57461 | best_bleu 20.53
2023-07-05 01:35:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 57461 updates
2023-07-05 01:35:43 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt
2023-07-05 01:35:47 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt
2023-07-05 01:35:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_last.pt (epoch 39 @ 57461 updates, score 20.03) (writing took 4.492916053161025 seconds)
2023-07-05 01:35:47 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-07-05 01:35:47 | INFO | train | epoch 039 | loss 1.298 | trans_loss 5.084 | nll_loss 2.311 | w2v_ctc_loss 0.372 | task_loss 1.514 | contrastive_loss 0 | total 4138.7 | n_correct 2827.55 | ppl 4.96 | accuracy 68.32 | wps 6375.9 | ups 1.54 | wpb 4138.7 | bsz 152.9 | num_updates 57461 | lr 5.89968e-05 | gnorm 0.345 | clip 0 | loss_scale 64 | train_wall 879 | gb_free 15.7 | wall 41276
2023-07-05 01:35:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-05 01:35:48 | INFO | fairseq.trainer | begin training epoch 40
2023-07-05 01:35:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-05 01:36:20 | INFO | train_inner | epoch 040:     39 / 1474 loss=1.295, trans_loss=5.084, nll_loss=2.312, w2v_ctc_loss=0.365, task_loss=1.472, contrastive_loss=0, total=4157.73, n_correct=2838.87, ppl=4.96, accuracy=68.279, wps=4210.6, ups=1.01, wpb=4157.7, bsz=155, num_updates=57500, lr=5.89768e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=59, gb_free=15.5, wall=41308
2023-07-05 01:37:20 | INFO | train_inner | epoch 040:    139 / 1474 loss=1.291, trans_loss=5.051, nll_loss=2.266, w2v_ctc_loss=0.369, task_loss=1.51, contrastive_loss=0, total=4158.81, n_correct=2866.12, ppl=4.81, accuracy=68.917, wps=6938.5, ups=1.67, wpb=4158.8, bsz=153.3, num_updates=57600, lr=5.89256e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=59, gb_free=16.3, wall=41368
2023-07-05 01:38:19 | INFO | train_inner | epoch 040:    239 / 1474 loss=1.293, trans_loss=5.067, nll_loss=2.288, w2v_ctc_loss=0.374, task_loss=1.552, contrastive_loss=0, total=4104.08, n_correct=2816.6, ppl=4.88, accuracy=68.629, wps=6921.8, ups=1.69, wpb=4104.1, bsz=150, num_updates=57700, lr=5.88745e-05, gnorm=0.348, clip=0, loss_scale=64, train_wall=59, gb_free=17.7, wall=41427
2023-07-05 01:39:19 | INFO | train_inner | epoch 040:    339 / 1474 loss=1.29, trans_loss=5.059, nll_loss=2.279, w2v_ctc_loss=0.365, task_loss=1.411, contrastive_loss=0, total=4149.88, n_correct=2856.12, ppl=4.85, accuracy=68.824, wps=6947.6, ups=1.67, wpb=4149.9, bsz=159.5, num_updates=57800, lr=5.88235e-05, gnorm=0.344, clip=0, loss_scale=64, train_wall=59, gb_free=14.2, wall=41487
2023-07-05 01:40:19 | INFO | train_inner | epoch 040:    439 / 1474 loss=1.295, trans_loss=5.072, nll_loss=2.295, w2v_ctc_loss=0.371, task_loss=1.502, contrastive_loss=0, total=4147.99, n_correct=2844.3, ppl=4.91, accuracy=68.571, wps=6881.8, ups=1.66, wpb=4148, bsz=156.2, num_updates=57900, lr=5.87727e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=41547
2023-07-05 01:41:19 | INFO | train_inner | epoch 040:    539 / 1474 loss=1.292, trans_loss=5.07, nll_loss=2.293, w2v_ctc_loss=0.366, task_loss=1.465, contrastive_loss=0, total=4166.35, n_correct=2857.97, ppl=4.9, accuracy=68.596, wps=6931.5, ups=1.66, wpb=4166.4, bsz=157.8, num_updates=58000, lr=5.8722e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=60, gb_free=17.7, wall=41607
2023-07-05 01:41:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-05 01:41:44 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 2.161 | trans_loss 5.56 | nll_loss 2.834 | w2v_ctc_loss 0.716 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2492.9 | ppl 7.13 | accuracy 62.27 | uer 16.479 | wer 18.307 | raw_wer 18.307 | bleu 19.89 | wps 2179.8 | wpb 4003.4 | bsz 141.8 | num_updates 58000 | best_bleu 20.53
2023-07-05 01:41:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58000 updates
2023-07-05 01:41:44 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_40_58000.pt
2023-07-05 01:41:46 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_40_58000.pt
2023-07-05 01:41:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_40_58000.pt (epoch 40 @ 58000 updates, score 19.89) (writing took 5.493072028737515 seconds)
2023-07-05 01:42:50 | INFO | train_inner | epoch 040:    639 / 1474 loss=1.3, trans_loss=5.093, nll_loss=2.322, w2v_ctc_loss=0.381, task_loss=1.58, contrastive_loss=0, total=4121.6, n_correct=2807.42, ppl=5, accuracy=68.115, wps=4552.9, ups=1.1, wpb=4121.6, bsz=148.6, num_updates=58100, lr=5.86715e-05, gnorm=0.354, clip=0, loss_scale=64, train_wall=60, gb_free=13.1, wall=41698
2023-07-05 01:43:49 | INFO | train_inner | epoch 040:    739 / 1474 loss=1.293, trans_loss=5.069, nll_loss=2.291, w2v_ctc_loss=0.368, task_loss=1.456, contrastive_loss=0, total=4135.27, n_correct=2835.54, ppl=4.89, accuracy=68.57, wps=6974.9, ups=1.69, wpb=4135.3, bsz=154.8, num_updates=58200, lr=5.8621e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=59, gb_free=17.7, wall=41757
2023-07-05 01:44:50 | INFO | train_inner | epoch 040:    839 / 1474 loss=1.299, trans_loss=5.088, nll_loss=2.318, w2v_ctc_loss=0.369, task_loss=1.377, contrastive_loss=0, total=4211.77, n_correct=2876.76, ppl=4.99, accuracy=68.303, wps=6944.6, ups=1.65, wpb=4211.8, bsz=164.1, num_updates=58300, lr=5.85707e-05, gnorm=0.344, clip=0, loss_scale=64, train_wall=60, gb_free=15.7, wall=41818
2023-07-05 01:45:50 | INFO | train_inner | epoch 040:    939 / 1474 loss=1.297, trans_loss=5.085, nll_loss=2.311, w2v_ctc_loss=0.375, task_loss=1.594, contrastive_loss=0, total=4091.87, n_correct=2792.72, ppl=4.96, accuracy=68.25, wps=6810.9, ups=1.66, wpb=4091.9, bsz=147.1, num_updates=58400, lr=5.85206e-05, gnorm=0.349, clip=0, loss_scale=64, train_wall=60, gb_free=17.9, wall=41878
2023-07-05 01:46:50 | INFO | train_inner | epoch 040:   1039 / 1474 loss=1.304, trans_loss=5.101, nll_loss=2.333, w2v_ctc_loss=0.374, task_loss=1.644, contrastive_loss=0, total=4124.03, n_correct=2802.05, ppl=5.04, accuracy=67.944, wps=6875.8, ups=1.67, wpb=4124, bsz=143.8, num_updates=58500, lr=5.84705e-05, gnorm=0.35, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=41938
2023-07-05 01:47:51 | INFO | train_inner | epoch 040:   1139 / 1474 loss=1.298, trans_loss=5.088, nll_loss=2.315, w2v_ctc_loss=0.376, task_loss=1.571, contrastive_loss=0, total=4131.03, n_correct=2819.48, ppl=4.98, accuracy=68.251, wps=6794.4, ups=1.64, wpb=4131, bsz=149.6, num_updates=58600, lr=5.84206e-05, gnorm=0.347, clip=0, loss_scale=64, train_wall=60, gb_free=15.3, wall=41999
2023-07-05 01:48:51 | INFO | train_inner | epoch 040:   1239 / 1474 loss=1.296, trans_loss=5.075, nll_loss=2.299, w2v_ctc_loss=0.369, task_loss=1.502, contrastive_loss=0, total=4191.39, n_correct=2872.33, ppl=4.92, accuracy=68.529, wps=6929.1, ups=1.65, wpb=4191.4, bsz=154.6, num_updates=58700, lr=5.83708e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=42059
2023-07-05 01:49:51 | INFO | train_inner | epoch 040:   1339 / 1474 loss=1.295, trans_loss=5.081, nll_loss=2.307, w2v_ctc_loss=0.366, task_loss=1.526, contrastive_loss=0, total=4119.9, n_correct=2816.05, ppl=4.95, accuracy=68.352, wps=6874.3, ups=1.67, wpb=4119.9, bsz=152.7, num_updates=58800, lr=5.83212e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=59, gb_free=15.4, wall=42119
2023-07-05 01:50:51 | INFO | train_inner | epoch 040:   1439 / 1474 loss=1.302, trans_loss=5.091, nll_loss=2.32, w2v_ctc_loss=0.375, task_loss=1.507, contrastive_loss=0, total=4125.85, n_correct=2816.2, ppl=4.99, accuracy=68.257, wps=6885.4, ups=1.67, wpb=4125.9, bsz=152.7, num_updates=58900, lr=5.82717e-05, gnorm=0.349, clip=0, loss_scale=64, train_wall=59, gb_free=18, wall=42179
2023-07-05 01:51:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-05 01:51:36 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 2.168 | trans_loss 5.563 | nll_loss 2.835 | w2v_ctc_loss 0.736 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2496.7 | ppl 7.14 | accuracy 62.364 | uer 16.81 | wer 18.616 | raw_wer 18.616 | bleu 20.35 | wps 2232.3 | wpb 4003.4 | bsz 141.8 | num_updates 58935 | best_bleu 20.53
2023-07-05 01:51:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58935 updates
2023-07-05 01:51:36 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.3509.pt
2023-07-05 01:51:39 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.3509.pt
2023-07-05 01:51:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint.best_bleu_20.3509.pt (epoch 40 @ 58935 updates, score 20.35) (writing took 5.949672185815871 seconds)
2023-07-05 01:51:42 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-07-05 01:51:42 | INFO | train | epoch 040 | loss 1.296 | trans_loss 5.077 | nll_loss 2.302 | w2v_ctc_loss 0.371 | task_loss 1.515 | contrastive_loss 0 | total 4138.65 | n_correct 2832.55 | ppl 4.93 | accuracy 68.442 | wps 6388.6 | ups 1.54 | wpb 4138.6 | bsz 152.8 | num_updates 58935 | lr 5.82543e-05 | gnorm 0.347 | clip 0 | loss_scale 64 | train_wall 877 | gb_free 16 | wall 42231
2023-07-05 01:51:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-05 01:51:43 | INFO | fairseq.trainer | begin training epoch 41
2023-07-05 01:51:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-05 01:52:30 | INFO | train_inner | epoch 041:     65 / 1474 loss=1.295, trans_loss=5.064, nll_loss=2.284, w2v_ctc_loss=0.367, task_loss=1.546, contrastive_loss=0, total=4098.68, n_correct=2814.93, ppl=4.87, accuracy=68.679, wps=4139.5, ups=1.01, wpb=4098.7, bsz=149.7, num_updates=59000, lr=5.82223e-05, gnorm=0.351, clip=0, loss_scale=64, train_wall=59, gb_free=16.6, wall=42278
2023-07-05 01:53:30 | INFO | train_inner | epoch 041:    165 / 1474 loss=1.287, trans_loss=5.049, nll_loss=2.265, w2v_ctc_loss=0.364, task_loss=1.497, contrastive_loss=0, total=4132.72, n_correct=2848.76, ppl=4.81, accuracy=68.932, wps=6892.9, ups=1.67, wpb=4132.7, bsz=153.5, num_updates=59100, lr=5.8173e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=59, gb_free=11.6, wall=42338
2023-07-05 01:54:30 | INFO | train_inner | epoch 041:    265 / 1474 loss=1.291, trans_loss=5.059, nll_loss=2.277, w2v_ctc_loss=0.364, task_loss=1.408, contrastive_loss=0, total=4180.79, n_correct=2876.6, ppl=4.85, accuracy=68.805, wps=6993.8, ups=1.67, wpb=4180.8, bsz=159.4, num_updates=59200, lr=5.81238e-05, gnorm=0.342, clip=0, loss_scale=64, train_wall=59, gb_free=17, wall=42398
2023-07-05 01:55:30 | INFO | train_inner | epoch 041:    365 / 1474 loss=1.291, trans_loss=5.062, nll_loss=2.282, w2v_ctc_loss=0.368, task_loss=1.5, contrastive_loss=0, total=4152.45, n_correct=2851.45, ppl=4.87, accuracy=68.669, wps=6926.4, ups=1.67, wpb=4152.4, bsz=153.2, num_updates=59300, lr=5.80748e-05, gnorm=0.346, clip=0, loss_scale=128, train_wall=60, gb_free=15.1, wall=42458
2023-07-05 01:56:30 | INFO | train_inner | epoch 041:    465 / 1474 loss=1.289, trans_loss=5.058, nll_loss=2.277, w2v_ctc_loss=0.365, task_loss=1.521, contrastive_loss=0, total=4144.35, n_correct=2851.39, ppl=4.85, accuracy=68.802, wps=6863, ups=1.66, wpb=4144.4, bsz=151.8, num_updates=59400, lr=5.80259e-05, gnorm=0.346, clip=0, loss_scale=128, train_wall=60, gb_free=15.3, wall=42518
2023-07-05 01:57:30 | INFO | train_inner | epoch 041:    565 / 1474 loss=1.293, trans_loss=5.069, nll_loss=2.29, w2v_ctc_loss=0.371, task_loss=1.517, contrastive_loss=0, total=4145.57, n_correct=2844.26, ppl=4.89, accuracy=68.61, wps=6960.5, ups=1.68, wpb=4145.6, bsz=153.3, num_updates=59500, lr=5.79771e-05, gnorm=0.347, clip=0, loss_scale=128, train_wall=59, gb_free=14.5, wall=42578
2023-07-05 01:58:29 | INFO | train_inner | epoch 041:    665 / 1474 loss=1.288, trans_loss=5.052, nll_loss=2.269, w2v_ctc_loss=0.362, task_loss=1.428, contrastive_loss=0, total=4187.21, n_correct=2886.55, ppl=4.82, accuracy=68.937, wps=7020.4, ups=1.68, wpb=4187.2, bsz=158.8, num_updates=59600, lr=5.79284e-05, gnorm=0.342, clip=0, loss_scale=128, train_wall=59, gb_free=16.8, wall=42637
2023-07-05 01:59:29 | INFO | train_inner | epoch 041:    765 / 1474 loss=1.294, trans_loss=5.07, nll_loss=2.292, w2v_ctc_loss=0.368, task_loss=1.543, contrastive_loss=0, total=4144.35, n_correct=2838.64, ppl=4.9, accuracy=68.494, wps=6899.9, ups=1.66, wpb=4144.4, bsz=149.6, num_updates=59700, lr=5.78799e-05, gnorm=0.347, clip=0, loss_scale=128, train_wall=60, gb_free=17.7, wall=42698
2023-07-05 02:00:29 | INFO | train_inner | epoch 041:    865 / 1474 loss=1.293, trans_loss=5.063, nll_loss=2.283, w2v_ctc_loss=0.366, task_loss=1.564, contrastive_loss=0, total=4112.51, n_correct=2824.6, ppl=4.87, accuracy=68.683, wps=6927, ups=1.68, wpb=4112.5, bsz=148.5, num_updates=59800, lr=5.78315e-05, gnorm=0.348, clip=0, loss_scale=128, train_wall=59, gb_free=16, wall=42757
2023-07-05 02:01:29 | INFO | train_inner | epoch 041:    965 / 1474 loss=1.299, trans_loss=5.081, nll_loss=2.306, w2v_ctc_loss=0.374, task_loss=1.577, contrastive_loss=0, total=4119.19, n_correct=2817.06, ppl=4.95, accuracy=68.389, wps=6799.9, ups=1.65, wpb=4119.2, bsz=149.5, num_updates=59900, lr=5.77832e-05, gnorm=0.348, clip=0, loss_scale=128, train_wall=60, gb_free=16.5, wall=42817
2023-07-05 02:02:29 | INFO | train_inner | epoch 041:   1065 / 1474 loss=1.295, trans_loss=5.079, nll_loss=2.305, w2v_ctc_loss=0.369, task_loss=1.497, contrastive_loss=0, total=4142.3, n_correct=2830.17, ppl=4.94, accuracy=68.324, wps=6985.9, ups=1.69, wpb=4142.3, bsz=152.5, num_updates=60000, lr=5.7735e-05, gnorm=0.346, clip=0, loss_scale=128, train_wall=59, gb_free=16.5, wall=42877
2023-07-05 02:02:29 | INFO | fairseq_cli.train | Stopping training due to num_updates: 60000 >= max_update: 60000
2023-07-05 02:02:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-05 02:02:52 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 2.165 | trans_loss 5.566 | nll_loss 2.841 | w2v_ctc_loss 0.724 | task_loss 2.365 | contrastive_loss 0 | total 4003.4 | n_correct 2492.1 | ppl 7.16 | accuracy 62.25 | uer 16.407 | wer 18.217 | raw_wer 18.217 | bleu 20.36 | wps 2305.3 | wpb 4003.4 | bsz 141.8 | num_updates 60000 | best_bleu 20.53
2023-07-05 02:02:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 60000 updates
2023-07-05 02:02:53 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_41_60000.pt
2023-07-05 02:02:55 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_41_60000.pt
2023-07-05 02:02:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_nocontrastiveA/checkpoint_41_60000.pt (epoch 41 @ 60000 updates, score 20.36) (writing took 6.876832699403167 seconds)
2023-07-05 02:03:00 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-07-05 02:03:00 | INFO | train | epoch 041 | loss 1.292 | trans_loss 5.064 | nll_loss 2.284 | w2v_ctc_loss 0.367 | task_loss 1.505 | contrastive_loss 0 | total 4144.74 | n_correct 2846.47 | ppl 4.87 | accuracy 68.677 | wps 6515.1 | ups 1.57 | wpb 4144.7 | bsz 153 | num_updates 60000 | lr 5.7735e-05 | gnorm 0.346 | clip 0 | loss_scale 128 | train_wall 632 | gb_free 16.5 | wall 42908
2023-07-05 02:03:00 | INFO | fairseq_cli.train | done training in 42838.7 seconds
/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1776 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
