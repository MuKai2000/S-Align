2023-08-10 13:08:36 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:11137
2023-08-10 13:08:36 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:11137
2023-08-10 13:08:36 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11137
2023-08-10 13:08:36 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11137
2023-08-10 13:08:37 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11137
2023-08-10 13:08:37 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:11137
2023-08-10 13:08:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-10 13:08:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-10 13:08:37 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:11137
2023-08-10 13:08:37 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11137
2023-08-10 13:08:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-10 13:08:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-10 13:08:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-10 13:08:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-10 13:08:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-10 13:08:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-10 13:08:37 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-10 13:08:37 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-10 13:08:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-08-10 13:08:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-08-10 13:08:37 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-10 13:08:37 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-10 13:08:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-08-10 13:08:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-08-10 13:08:37 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-10 13:08:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-08-10 13:08:37 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-10 13:08:37 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-10 13:08:37 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-10 13:08:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-08-10 13:08:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-08-10 13:08:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-08-10 13:08:42 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11137', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=2.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=2.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=2.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-10 13:08:42 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-10 13:08:42 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-10 13:08:42 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-10 13:08:42 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-10 13:08:42 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-10 13:08:46 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-10 13:08:46 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-10 13:08:46 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-10 13:08:48 | INFO | root | load pretrained hubert
2023-08-10 13:08:49 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-10 13:08:51 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-10 13:08:53 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-10 13:08:53 | INFO | root | share the sematic adapter and textual encoder
2023-08-10 13:08:53 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-10 13:08:53 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-10 13:08:53 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-10 13:08:53 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-10 13:08:53 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-08-10 13:08:53 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-10 13:08:53 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-10 13:08:53 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-10 13:08:53 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-10 13:08:53 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-10 13:08:53 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-10 13:08:57 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-10 13:08:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-10 13:08:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-10 13:08:57 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-10 13:08:57 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-10 13:08:57 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-10 13:08:57 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-10 13:08:57 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-10 13:08:57 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-10 13:08:57 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-10 13:08:57 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-10 13:08:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-10 13:08:57 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-10 13:08:57 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-10 13:08:57 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_last.pt
2023-08-10 13:08:57 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_last.pt
2023-08-10 13:08:57 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-10 13:08:57 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-10 13:08:57 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-10 13:08:57 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-10 13:08:59 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-10 13:09:00 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-10 13:09:48 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-10 13:09:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 13:09:48 | INFO | fairseq.trainer | begin training epoch 1
2023-08-10 13:09:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 13:11:07 | INFO | train_inner | epoch 001:    100 / 1474 loss=20.948, trans_loss=5.598, nll_loss=4.162, w2v_ctc_loss=22.489, task_loss=1.749, contrastive_loss=3.325, total=4207.04, n_correct=209.47, ppl=17.9, accuracy=4.979, wps=19316.2, ups=1.54, wpb=12551.1, bsz=471.4, num_updates=100, lr=4.098e-06, gnorm=0.962, clip=0, loss_scale=128, train_wall=71, gb_free=19.5, wall=130
2023-08-10 13:12:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-10 13:12:12 | INFO | train_inner | epoch 001:    201 / 1474 loss=18.858, trans_loss=5.475, nll_loss=4.061, w2v_ctc_loss=19.512, task_loss=1.704, contrastive_loss=3.285, total=4123.37, n_correct=223.32, ppl=16.69, accuracy=5.416, wps=18819.9, ups=1.53, wpb=12310.5, bsz=462.6, num_updates=200, lr=8.096e-06, gnorm=3.523, clip=0, loss_scale=64, train_wall=65, gb_free=19.2, wall=195
2023-08-10 13:13:16 | INFO | train_inner | epoch 001:    301 / 1474 loss=11.832, trans_loss=5.484, nll_loss=4.126, w2v_ctc_loss=8.812, task_loss=1.706, contrastive_loss=3.202, total=4079.62, n_correct=205.82, ppl=17.45, accuracy=5.045, wps=19219, ups=1.58, wpb=12186.7, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=4.65, clip=0, loss_scale=64, train_wall=63, gb_free=19.9, wall=259
2023-08-10 13:14:20 | INFO | train_inner | epoch 001:    401 / 1474 loss=10.583, trans_loss=5.516, nll_loss=4.189, w2v_ctc_loss=6.809, task_loss=1.496, contrastive_loss=3.233, total=4174.14, n_correct=195.72, ppl=18.24, accuracy=4.689, wps=19530.8, ups=1.57, wpb=12463.5, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=2.949, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=323
2023-08-10 13:15:23 | INFO | train_inner | epoch 001:    501 / 1474 loss=10.141, trans_loss=5.494, nll_loss=4.177, w2v_ctc_loss=6.182, task_loss=1.369, contrastive_loss=3.219, total=4176.18, n_correct=191.39, ppl=18.08, accuracy=4.583, wps=19549, ups=1.57, wpb=12479.7, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=1.465, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=386
2023-08-10 13:16:28 | INFO | train_inner | epoch 001:    601 / 1474 loss=9.843, trans_loss=5.516, nll_loss=4.202, w2v_ctc_loss=5.829, task_loss=1.277, contrastive_loss=3.258, total=4147.79, n_correct=196.7, ppl=18.41, accuracy=4.742, wps=19146.3, ups=1.55, wpb=12371.6, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.898, clip=0, loss_scale=64, train_wall=64, gb_free=18.9, wall=451
2023-08-10 13:17:31 | INFO | train_inner | epoch 001:    701 / 1474 loss=9.582, trans_loss=5.501, nll_loss=4.193, w2v_ctc_loss=5.732, task_loss=1.327, contrastive_loss=2.987, total=4152.1, n_correct=215.58, ppl=18.29, accuracy=5.192, wps=19559.8, ups=1.58, wpb=12395.5, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=1.071, clip=0, loss_scale=64, train_wall=63, gb_free=19.5, wall=514
2023-08-10 13:18:35 | INFO | train_inner | epoch 001:    801 / 1474 loss=9.274, trans_loss=5.447, nll_loss=4.138, w2v_ctc_loss=5.575, task_loss=1.282, contrastive_loss=2.9, total=4123.83, n_correct=253.26, ppl=17.61, accuracy=6.141, wps=19331, ups=1.57, wpb=12306.1, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=1.541, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=578
2023-08-10 13:19:38 | INFO | train_inner | epoch 001:    901 / 1474 loss=8.996, trans_loss=5.423, nll_loss=4.119, w2v_ctc_loss=5.485, task_loss=1.302, contrastive_loss=2.687, total=4163.61, n_correct=269.69, ppl=17.37, accuracy=6.477, wps=19652.8, ups=1.58, wpb=12433.9, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=2.433, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=641
2023-08-10 13:20:43 | INFO | train_inner | epoch 001:   1001 / 1474 loss=8.711, trans_loss=5.399, nll_loss=4.096, w2v_ctc_loss=5.347, task_loss=1.31, contrastive_loss=2.565, total=4135.34, n_correct=290.95, ppl=17.1, accuracy=7.036, wps=19155.9, ups=1.55, wpb=12353.2, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=2.622, clip=0, loss_scale=64, train_wall=64, gb_free=19, wall=706
2023-08-10 13:21:47 | INFO | train_inner | epoch 001:   1101 / 1474 loss=8.396, trans_loss=5.391, nll_loss=4.089, w2v_ctc_loss=5.21, task_loss=1.321, contrastive_loss=2.375, total=4147.38, n_correct=309.56, ppl=17.02, accuracy=7.464, wps=19437.6, ups=1.57, wpb=12367, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=3.092, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=769
2023-08-10 13:22:50 | INFO | train_inner | epoch 001:   1201 / 1474 loss=8.124, trans_loss=5.372, nll_loss=4.073, w2v_ctc_loss=5.095, task_loss=1.376, contrastive_loss=2.183, total=4139.9, n_correct=318.25, ppl=16.83, accuracy=7.687, wps=19441.4, ups=1.57, wpb=12366.5, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=3.063, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=833
2023-08-10 13:23:53 | INFO | train_inner | epoch 001:   1301 / 1474 loss=7.841, trans_loss=5.37, nll_loss=4.073, w2v_ctc_loss=4.928, task_loss=1.324, contrastive_loss=2.004, total=4046.58, n_correct=315.91, ppl=16.84, accuracy=7.807, wps=19249.4, ups=1.59, wpb=12081.6, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=3.117, clip=0, loss_scale=64, train_wall=62, gb_free=19.7, wall=896
2023-08-10 13:24:58 | INFO | train_inner | epoch 001:   1401 / 1474 loss=7.573, trans_loss=5.363, nll_loss=4.07, w2v_ctc_loss=4.734, task_loss=1.308, contrastive_loss=2.068, total=4133.18, n_correct=326.7, ppl=16.79, accuracy=7.904, wps=19021.6, ups=1.54, wpb=12350, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=2.835, clip=0, loss_scale=64, train_wall=64, gb_free=19.9, wall=961
2023-08-10 13:25:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 13:26:24 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 10.367 | trans_loss 10.975 | nll_loss 9.978 | w2v_ctc_loss 6.263 | task_loss 7.546 | contrastive_loss 2.484 | total 4003.4 | n_correct 377.4 | ppl 1008.45 | accuracy 9.427 | uer 79.208 | wer 78.711 | raw_wer 78.711 | bleu 0.02 | wps 1164.1 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-08-10 13:26:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-08-10 13:26:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 13:26:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 13:26:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.02) (writing took 6.047743825241923 seconds)
2023-08-10 13:26:30 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-10 13:26:30 | INFO | train | epoch 001 | loss 10.608 | trans_loss 5.449 | nll_loss 4.123 | w2v_ctc_loss 7.827 | task_loss 1.411 | contrastive_loss 2.768 | total 4138.5 | n_correct 255.489 | ppl 17.43 | accuracy 6.173 | wps 18418.7 | ups 1.49 | wpb 12355.3 | bsz 458.5 | num_updates 1473 | lr 5.89905e-05 | gnorm 2.47 | clip 0 | loss_scale 64 | train_wall 941 | gb_free 19.2 | wall 1053
2023-08-10 13:26:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 13:26:30 | INFO | fairseq.trainer | begin training epoch 2
2023-08-10 13:26:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 13:26:55 | INFO | train_inner | epoch 002:     27 / 1474 loss=7.327, trans_loss=5.361, nll_loss=4.064, w2v_ctc_loss=4.536, task_loss=1.246, contrastive_loss=1.916, total=4162.95, n_correct=332.57, ppl=16.72, accuracy=7.989, wps=10581.8, ups=0.85, wpb=12416.8, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=2.972, clip=0, loss_scale=64, train_wall=63, gb_free=19.6, wall=1078
2023-08-10 13:27:59 | INFO | train_inner | epoch 002:    127 / 1474 loss=7.07, trans_loss=5.362, nll_loss=4.064, w2v_ctc_loss=4.411, task_loss=1.33, contrastive_loss=1.707, total=4155.98, n_correct=330.73, ppl=16.73, accuracy=7.958, wps=19570, ups=1.58, wpb=12394.8, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=3.093, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=1141
2023-08-10 13:29:02 | INFO | train_inner | epoch 002:    227 / 1474 loss=6.868, trans_loss=5.345, nll_loss=4.048, w2v_ctc_loss=4.194, task_loss=1.153, contrastive_loss=1.729, total=4179.21, n_correct=336.32, ppl=16.54, accuracy=8.047, wps=19612.6, ups=1.57, wpb=12484.6, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=2.767, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=1205
2023-08-10 13:30:06 | INFO | train_inner | epoch 002:    327 / 1474 loss=6.583, trans_loss=5.348, nll_loss=4.047, w2v_ctc_loss=4.084, task_loss=1.325, contrastive_loss=1.431, total=4146.1, n_correct=339.69, ppl=16.53, accuracy=8.193, wps=19282.7, ups=1.56, wpb=12374.1, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=2.495, clip=0, loss_scale=64, train_wall=64, gb_free=18.8, wall=1269
2023-08-10 13:31:09 | INFO | train_inner | epoch 002:    427 / 1474 loss=6.344, trans_loss=5.343, nll_loss=4.045, w2v_ctc_loss=3.965, task_loss=1.456, contrastive_loss=1.24, total=4037.99, n_correct=330.45, ppl=16.51, accuracy=8.184, wps=19146.1, ups=1.59, wpb=12069.2, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=2.571, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=1332
2023-08-10 13:32:13 | INFO | train_inner | epoch 002:    527 / 1474 loss=6.208, trans_loss=5.331, nll_loss=4.026, w2v_ctc_loss=3.771, task_loss=1.266, contrastive_loss=1.327, total=4176.97, n_correct=350.22, ppl=16.29, accuracy=8.385, wps=19694.6, ups=1.58, wpb=12463.5, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=2.29, clip=0, loss_scale=64, train_wall=63, gb_free=19.6, wall=1396
2023-08-10 13:32:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 13:32:52 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 9.512 | trans_loss 10.869 | nll_loss 9.828 | w2v_ctc_loss 4.987 | task_loss 7.546 | contrastive_loss 1.672 | total 4003.4 | n_correct 392.7 | ppl 908.86 | accuracy 9.809 | uer 66.772 | wer 64.308 | raw_wer 64.308 | bleu 0.03 | wps 1174.2 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.03
2023-08-10 13:32:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-10 13:32:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_2_2000.pt
2023-08-10 13:32:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_2_2000.pt
2023-08-10 13:33:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.03) (writing took 43.32597360573709 seconds)
2023-08-10 13:34:39 | INFO | train_inner | epoch 002:    627 / 1474 loss=5.993, trans_loss=5.325, nll_loss=4.018, w2v_ctc_loss=3.64, task_loss=1.309, contrastive_loss=1.12, total=4126.49, n_correct=354.06, ppl=16.2, accuracy=8.58, wps=8389.3, ups=0.68, wpb=12314.9, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=2.076, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=1542
2023-08-10 13:35:44 | INFO | train_inner | epoch 002:    727 / 1474 loss=5.887, trans_loss=5.307, nll_loss=3.998, w2v_ctc_loss=3.522, task_loss=1.283, contrastive_loss=1.216, total=4149.06, n_correct=363.19, ppl=15.98, accuracy=8.754, wps=19341, ups=1.56, wpb=12386.4, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=1.902, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=1606
2023-08-10 13:36:47 | INFO | train_inner | epoch 002:    827 / 1474 loss=5.739, trans_loss=5.292, nll_loss=3.981, w2v_ctc_loss=3.43, task_loss=1.317, contrastive_loss=1.155, total=4175.4, n_correct=370.34, ppl=15.79, accuracy=8.87, wps=19689.7, ups=1.58, wpb=12471.9, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=1.718, clip=0, loss_scale=128, train_wall=63, gb_free=19.8, wall=1670
2023-08-10 13:37:50 | INFO | train_inner | epoch 002:    927 / 1474 loss=5.603, trans_loss=5.279, nll_loss=3.963, w2v_ctc_loss=3.314, task_loss=1.344, contrastive_loss=1.133, total=4104.2, n_correct=367.75, ppl=15.6, accuracy=8.96, wps=19298.4, ups=1.57, wpb=12253.1, bsz=445.9, num_updates=2400, lr=9.6052e-05, gnorm=1.699, clip=0, loss_scale=128, train_wall=63, gb_free=19, wall=1733
2023-08-10 13:38:54 | INFO | train_inner | epoch 002:   1027 / 1474 loss=5.469, trans_loss=5.273, nll_loss=3.958, w2v_ctc_loss=3.221, task_loss=1.305, contrastive_loss=0.982, total=4102.5, n_correct=372.72, ppl=15.54, accuracy=9.085, wps=19409.4, ups=1.58, wpb=12251.2, bsz=456.3, num_updates=2500, lr=0.00010005, gnorm=1.445, clip=0, loss_scale=128, train_wall=63, gb_free=19.2, wall=1796
2023-08-10 13:39:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-10 13:39:59 | INFO | train_inner | epoch 002:   1128 / 1474 loss=5.394, trans_loss=5.263, nll_loss=3.945, w2v_ctc_loss=3.129, task_loss=1.219, contrastive_loss=1.053, total=4166.43, n_correct=386.95, ppl=15.4, accuracy=9.287, wps=18979.8, ups=1.53, wpb=12432.5, bsz=474.9, num_updates=2600, lr=0.000104048, gnorm=1.466, clip=0, loss_scale=64, train_wall=65, gb_free=18.9, wall=1862
2023-08-10 13:41:03 | INFO | train_inner | epoch 002:   1228 / 1474 loss=5.33, trans_loss=5.247, nll_loss=3.926, w2v_ctc_loss=3.054, task_loss=1.197, contrastive_loss=1.103, total=4219.96, n_correct=404, ppl=15.2, accuracy=9.574, wps=19787.6, ups=1.57, wpb=12591.9, bsz=491.8, num_updates=2700, lr=0.000108046, gnorm=1.28, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=1926
2023-08-10 13:42:06 | INFO | train_inner | epoch 002:   1328 / 1474 loss=5.159, trans_loss=5.227, nll_loss=3.903, w2v_ctc_loss=3.003, task_loss=1.25, contrastive_loss=0.813, total=4163.26, n_correct=406.19, ppl=14.96, accuracy=9.757, wps=19767.1, ups=1.59, wpb=12441.6, bsz=463, num_updates=2800, lr=0.000112044, gnorm=1.194, clip=0, loss_scale=64, train_wall=62, gb_free=19, wall=1989
2023-08-10 13:43:09 | INFO | train_inner | epoch 002:   1428 / 1474 loss=5.094, trans_loss=5.236, nll_loss=3.914, w2v_ctc_loss=2.952, task_loss=1.417, contrastive_loss=0.895, total=4049.42, n_correct=394.65, ppl=15.07, accuracy=9.746, wps=19081.7, ups=1.58, wpb=12091.6, bsz=437.6, num_updates=2900, lr=0.000116042, gnorm=1.132, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=2052
2023-08-10 13:43:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 13:44:18 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.446 | trans_loss 10.303 | nll_loss 9.123 | w2v_ctc_loss 3.793 | task_loss 7.546 | contrastive_loss 0.97 | total 4003.4 | n_correct 495.8 | ppl 557.53 | accuracy 12.384 | uer 54.801 | wer 53.167 | raw_wer 53.167 | bleu 0.14 | wps 1166.3 | wpb 4003.4 | bsz 141.8 | num_updates 2946 | best_bleu 0.14
2023-08-10 13:44:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2946 updates
2023-08-10 13:44:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 13:44:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 13:44:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt (epoch 2 @ 2946 updates, score 0.14) (writing took 24.02096649631858 seconds)
2023-08-10 13:44:42 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-10 13:44:42 | INFO | train | epoch 002 | loss 5.908 | trans_loss 5.297 | nll_loss 3.987 | w2v_ctc_loss 3.547 | task_loss 1.294 | contrastive_loss 1.21 | total 4137.19 | n_correct 365.439 | ppl 15.86 | accuracy 8.833 | wps 16659.3 | ups 1.35 | wpb 12351.4 | bsz 457.7 | num_updates 2946 | lr 0.000117881 | gnorm 1.931 | clip 0 | loss_scale 64 | train_wall 930 | gb_free 19.3 | wall 2145
2023-08-10 13:44:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 13:44:42 | INFO | fairseq.trainer | begin training epoch 3
2023-08-10 13:44:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 13:45:25 | INFO | train_inner | epoch 003:     54 / 1474 loss=4.981, trans_loss=5.205, nll_loss=3.875, w2v_ctc_loss=2.88, task_loss=1.33, contrastive_loss=0.791, total=4067, n_correct=415.06, ppl=14.67, accuracy=10.206, wps=8942.9, ups=0.74, wpb=12142, bsz=441.4, num_updates=3000, lr=0.00012004, gnorm=1.095, clip=0, loss_scale=64, train_wall=64, gb_free=19.2, wall=2188
2023-08-10 13:45:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-10 13:45:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-10 13:45:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-10 13:45:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-10 13:47:00 | INFO | train_inner | epoch 003:    158 / 1474 loss=4.198, trans_loss=4.515, nll_loss=2.971, w2v_ctc_loss=2.535, task_loss=0.909, contrastive_loss=0.697, total=4144.24, n_correct=1043.8, ppl=7.84, accuracy=25.187, wps=13044, ups=1.05, wpb=12374.7, bsz=457.6, num_updates=3100, lr=0.000124038, gnorm=2.32, clip=1, loss_scale=4, train_wall=94, gb_free=16.5, wall=2283
2023-08-10 13:48:32 | INFO | train_inner | epoch 003:    258 / 1474 loss=3.664, trans_loss=4.233, nll_loss=2.603, w2v_ctc_loss=2.233, task_loss=0.915, contrastive_loss=0.584, total=4161.13, n_correct=1352.18, ppl=6.07, accuracy=32.496, wps=13444.8, ups=1.08, wpb=12431.5, bsz=467, num_updates=3200, lr=0.000128036, gnorm=1.458, clip=0, loss_scale=4, train_wall=92, gb_free=17.1, wall=2375
2023-08-10 13:50:05 | INFO | train_inner | epoch 003:    358 / 1474 loss=3.51, trans_loss=4.147, nll_loss=2.485, w2v_ctc_loss=2.117, task_loss=0.917, contrastive_loss=0.631, total=4150.02, n_correct=1463.51, ppl=5.6, accuracy=35.265, wps=13336.4, ups=1.08, wpb=12384.9, bsz=461.6, num_updates=3300, lr=0.000132034, gnorm=1.443, clip=0, loss_scale=4, train_wall=92, gb_free=17.1, wall=2468
2023-08-10 13:51:37 | INFO | train_inner | epoch 003:    458 / 1474 loss=3.326, trans_loss=4.074, nll_loss=2.39, w2v_ctc_loss=2.013, task_loss=0.891, contrastive_loss=0.478, total=4209.57, n_correct=1595.16, ppl=5.24, accuracy=37.894, wps=13632.9, ups=1.08, wpb=12566, bsz=476.8, num_updates=3400, lr=0.000136032, gnorm=1.274, clip=0, loss_scale=4, train_wall=92, gb_free=16, wall=2560
2023-08-10 13:53:09 | INFO | train_inner | epoch 003:    558 / 1474 loss=3.196, trans_loss=4.028, nll_loss=2.331, w2v_ctc_loss=1.931, task_loss=0.977, contrastive_loss=0.453, total=4088.48, n_correct=1612.95, ppl=5.03, accuracy=39.451, wps=13342.2, ups=1.09, wpb=12212.5, bsz=439.7, num_updates=3500, lr=0.00014003, gnorm=1.212, clip=0, loss_scale=4, train_wall=91, gb_free=17.6, wall=2652
2023-08-10 13:54:43 | INFO | train_inner | epoch 003:    658 / 1474 loss=3.138, trans_loss=3.982, nll_loss=2.267, w2v_ctc_loss=1.852, task_loss=0.878, contrastive_loss=0.561, total=4221.58, n_correct=1743.75, ppl=4.81, accuracy=41.306, wps=13384.4, ups=1.06, wpb=12587.8, bsz=481.9, num_updates=3600, lr=0.000144028, gnorm=1.148, clip=0, loss_scale=4, train_wall=94, gb_free=16.4, wall=2746
2023-08-10 13:56:15 | INFO | train_inner | epoch 003:    758 / 1474 loss=3.017, trans_loss=3.941, nll_loss=2.219, w2v_ctc_loss=1.818, task_loss=0.877, contrastive_loss=0.33, total=4167.41, n_correct=1776.34, ppl=4.65, accuracy=42.625, wps=13545.2, ups=1.09, wpb=12447.6, bsz=472.6, num_updates=3700, lr=0.000148026, gnorm=1.123, clip=0, loss_scale=4, train_wall=91, gb_free=16.3, wall=2838
2023-08-10 13:57:47 | INFO | train_inner | epoch 003:    858 / 1474 loss=2.943, trans_loss=3.924, nll_loss=2.193, w2v_ctc_loss=1.768, task_loss=0.93, contrastive_loss=0.292, total=4165.53, n_correct=1814.9, ppl=4.57, accuracy=43.569, wps=13521.6, ups=1.09, wpb=12437.8, bsz=456.1, num_updates=3800, lr=0.000152024, gnorm=1.09, clip=0, loss_scale=4, train_wall=91, gb_free=17, wall=2930
2023-08-10 13:59:19 | INFO | train_inner | epoch 003:    958 / 1474 loss=2.911, trans_loss=3.898, nll_loss=2.159, w2v_ctc_loss=1.74, task_loss=0.891, contrastive_loss=0.319, total=4162.3, n_correct=1863.02, ppl=4.47, accuracy=44.759, wps=13447, ups=1.08, wpb=12417, bsz=469.2, num_updates=3900, lr=0.000156022, gnorm=1.069, clip=0, loss_scale=4, train_wall=92, gb_free=16.8, wall=3022
2023-08-10 14:00:50 | INFO | train_inner | epoch 003:   1058 / 1474 loss=2.864, trans_loss=3.876, nll_loss=2.133, w2v_ctc_loss=1.728, task_loss=0.979, contrastive_loss=0.276, total=4069.95, n_correct=1841.71, ppl=4.39, accuracy=45.251, wps=13347.1, ups=1.1, wpb=12153.7, bsz=443.6, num_updates=4000, lr=0.00016002, gnorm=1.057, clip=0, loss_scale=4, train_wall=91, gb_free=16.3, wall=3113
2023-08-10 14:00:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 14:01:25 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.023 | trans_loss 6.336 | nll_loss 3.852 | w2v_ctc_loss 2.073 | task_loss 4.353 | contrastive_loss 0.38 | total 4003.4 | n_correct 1999.7 | ppl 14.44 | accuracy 49.95 | uer 29.868 | wer 30.733 | raw_wer 30.733 | bleu 11.1 | wps 1251.3 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 11.1
2023-08-10 14:01:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-10 14:01:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_3_4000.pt
2023-08-10 14:01:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_3_4000.pt
2023-08-10 14:01:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 11.1) (writing took 26.276541048660874 seconds)
2023-08-10 14:03:23 | INFO | train_inner | epoch 003:   1158 / 1474 loss=2.811, trans_loss=3.867, nll_loss=2.119, w2v_ctc_loss=1.684, task_loss=0.995, contrastive_loss=0.256, total=4038.49, n_correct=1851.16, ppl=4.34, accuracy=45.838, wps=7879.6, ups=0.65, wpb=12054.8, bsz=432.5, num_updates=4100, lr=0.000164018, gnorm=1.027, clip=0, loss_scale=4, train_wall=91, gb_free=16.3, wall=3266
2023-08-10 14:04:54 | INFO | train_inner | epoch 003:   1258 / 1474 loss=2.762, trans_loss=3.844, nll_loss=2.091, w2v_ctc_loss=1.651, task_loss=0.976, contrastive_loss=0.239, total=4064.31, n_correct=1896.04, ppl=4.26, accuracy=46.651, wps=13298.4, ups=1.1, wpb=12136.8, bsz=433.9, num_updates=4200, lr=0.000168016, gnorm=1.002, clip=0, loss_scale=4, train_wall=91, gb_free=17.3, wall=3357
2023-08-10 14:06:27 | INFO | train_inner | epoch 003:   1358 / 1474 loss=2.765, trans_loss=3.828, nll_loss=2.07, w2v_ctc_loss=1.615, task_loss=0.931, contrastive_loss=0.348, total=4134.58, n_correct=1955.86, ppl=4.2, accuracy=47.305, wps=13374.3, ups=1.08, wpb=12343.8, bsz=460.7, num_updates=4300, lr=0.000172014, gnorm=1.031, clip=0, loss_scale=4, train_wall=92, gb_free=17.7, wall=3450
2023-08-10 14:07:59 | INFO | train_inner | epoch 003:   1458 / 1474 loss=2.737, trans_loss=3.816, nll_loss=2.056, w2v_ctc_loss=1.599, task_loss=0.879, contrastive_loss=0.329, total=4209.94, n_correct=2017.34, ppl=4.16, accuracy=47.918, wps=13573.3, ups=1.08, wpb=12573.5, bsz=477.4, num_updates=4400, lr=0.000176012, gnorm=0.988, clip=0, loss_scale=4, train_wall=92, gb_free=17, wall=3542
2023-08-10 14:08:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 14:08:43 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 4.89 | trans_loss 6.211 | nll_loss 3.687 | w2v_ctc_loss 1.921 | task_loss 4.229 | contrastive_loss 0.38 | total 4003.4 | n_correct 2095.5 | ppl 12.88 | accuracy 52.343 | uer 28.877 | wer 29.231 | raw_wer 29.231 | bleu 13.55 | wps 1570.9 | wpb 4003.4 | bsz 141.8 | num_updates 4416 | best_bleu 13.55
2023-08-10 14:08:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4416 updates
2023-08-10 14:08:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 14:08:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 14:09:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt (epoch 3 @ 4416 updates, score 13.55) (writing took 25.687613170593977 seconds)
2023-08-10 14:09:09 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-10 14:09:09 | INFO | train | epoch 003 | loss 3.196 | trans_loss 4.04 | nll_loss 2.347 | w2v_ctc_loss 1.911 | task_loss 0.938 | contrastive_loss 0.43 | total 4139.74 | n_correct 1657.21 | ppl 5.09 | accuracy 40.032 | wps 12388 | ups 1 | wpb 12359.1 | bsz 458.8 | num_updates 4416 | lr 0.000176652 | gnorm 1.223 | clip 0.1 | loss_scale 4 | train_wall 1335 | gb_free 16.4 | wall 3612
2023-08-10 14:09:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 14:09:09 | INFO | fairseq.trainer | begin training epoch 4
2023-08-10 14:09:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 14:10:33 | INFO | train_inner | epoch 004:     84 / 1474 loss=2.625, trans_loss=3.786, nll_loss=2.014, w2v_ctc_loss=1.547, task_loss=0.955, contrastive_loss=0.185, total=4099.41, n_correct=2000.6, ppl=4.04, accuracy=48.802, wps=7959.1, ups=0.65, wpb=12237, bsz=439.5, num_updates=4500, lr=0.00018001, gnorm=0.937, clip=0, loss_scale=4, train_wall=90, gb_free=16.3, wall=3696
2023-08-10 14:12:04 | INFO | train_inner | epoch 004:    184 / 1474 loss=2.613, trans_loss=3.766, nll_loss=1.989, w2v_ctc_loss=1.53, task_loss=0.881, contrastive_loss=0.208, total=4175.15, n_correct=2069.23, ppl=3.97, accuracy=49.561, wps=13679.1, ups=1.1, wpb=12464.9, bsz=468.3, num_updates=4600, lr=0.000184008, gnorm=0.945, clip=0, loss_scale=4, train_wall=91, gb_free=16.6, wall=3787
2023-08-10 14:13:36 | INFO | train_inner | epoch 004:    284 / 1474 loss=2.643, trans_loss=3.77, nll_loss=1.997, w2v_ctc_loss=1.527, task_loss=0.925, contrastive_loss=0.334, total=4145.23, n_correct=2046.79, ppl=3.99, accuracy=49.377, wps=13415, ups=1.08, wpb=12382.4, bsz=463, num_updates=4700, lr=0.000188006, gnorm=0.934, clip=0, loss_scale=4, train_wall=92, gb_free=15.9, wall=3879
2023-08-10 14:15:08 | INFO | train_inner | epoch 004:    384 / 1474 loss=2.587, trans_loss=3.772, nll_loss=1.994, w2v_ctc_loss=1.512, task_loss=0.965, contrastive_loss=0.183, total=4127.66, n_correct=2046.61, ppl=3.98, accuracy=49.583, wps=13384, ups=1.09, wpb=12314.6, bsz=443.5, num_updates=4800, lr=0.000192004, gnorm=0.926, clip=0, loss_scale=4, train_wall=92, gb_free=17.4, wall=3971
2023-08-10 14:16:41 | INFO | train_inner | epoch 004:    484 / 1474 loss=2.671, trans_loss=3.752, nll_loss=1.972, w2v_ctc_loss=1.477, task_loss=0.838, contrastive_loss=0.571, total=4218.78, n_correct=2121.38, ppl=3.92, accuracy=50.284, wps=13560.4, ups=1.08, wpb=12592.4, bsz=497.8, num_updates=4900, lr=0.000196002, gnorm=0.935, clip=0, loss_scale=4, train_wall=92, gb_free=16.4, wall=4064
2023-08-10 14:18:14 | INFO | train_inner | epoch 004:    584 / 1474 loss=2.588, trans_loss=3.746, nll_loss=1.966, w2v_ctc_loss=1.498, task_loss=0.871, contrastive_loss=0.252, total=4217.52, n_correct=2135.82, ppl=3.91, accuracy=50.642, wps=13622.5, ups=1.08, wpb=12591.1, bsz=485.9, num_updates=5000, lr=0.0002, gnorm=0.928, clip=0, loss_scale=4, train_wall=92, gb_free=16.1, wall=4157
mt_weight tensor(0.5000)
asr_weight tensor(0.4246, device='cuda:0')
2023-08-10 14:19:47 | INFO | train_inner | epoch 004:    684 / 1474 loss=2.551, trans_loss=3.747, nll_loss=1.961, w2v_ctc_loss=1.456, task_loss=0.951, contrastive_loss=0.299, total=4176.39, n_correct=2128.51, ppl=3.89, accuracy=50.965, wps=13277.8, ups=1.07, wpb=12448.9, bsz=455.8, num_updates=5100, lr=0.00019803, gnorm=0.545, clip=0, loss_scale=8, train_wall=93, gb_free=17.1, wall=4250
2023-08-10 14:21:19 | INFO | train_inner | epoch 004:    784 / 1474 loss=2.519, trans_loss=3.74, nll_loss=1.958, w2v_ctc_loss=1.47, task_loss=1.019, contrastive_loss=0.171, total=4026.63, n_correct=2051.2, ppl=3.88, accuracy=50.941, wps=13166.5, ups=1.09, wpb=12025, bsz=420.6, num_updates=5200, lr=0.000196116, gnorm=0.543, clip=0, loss_scale=8, train_wall=91, gb_free=13.1, wall=4342
2023-08-10 14:22:52 | INFO | train_inner | epoch 004:    884 / 1474 loss=2.564, trans_loss=3.724, nll_loss=1.938, w2v_ctc_loss=1.462, task_loss=0.925, contrastive_loss=0.343, total=4186.04, n_correct=2151.13, ppl=3.83, accuracy=51.388, wps=13470.7, ups=1.08, wpb=12501.4, bsz=466.3, num_updates=5300, lr=0.000194257, gnorm=0.546, clip=0, loss_scale=8, train_wall=92, gb_free=17.7, wall=4435
2023-08-10 14:24:24 | INFO | train_inner | epoch 004:    984 / 1474 loss=2.502, trans_loss=3.717, nll_loss=1.93, w2v_ctc_loss=1.442, task_loss=0.941, contrastive_loss=0.214, total=4125.02, n_correct=2139.58, ppl=3.81, accuracy=51.868, wps=13343, ups=1.08, wpb=12321, bsz=457.1, num_updates=5400, lr=0.00019245, gnorm=0.538, clip=0, loss_scale=8, train_wall=92, gb_free=12.7, wall=4527
2023-08-10 14:25:56 | INFO | train_inner | epoch 004:   1084 / 1474 loss=2.501, trans_loss=3.725, nll_loss=1.939, w2v_ctc_loss=1.448, task_loss=1, contrastive_loss=0.193, total=4075.6, n_correct=2106.49, ppl=3.83, accuracy=51.685, wps=13209.4, ups=1.09, wpb=12163.4, bsz=435.7, num_updates=5500, lr=0.000190693, gnorm=0.541, clip=0, loss_scale=8, train_wall=92, gb_free=15.9, wall=4619
2023-08-10 14:27:28 | INFO | train_inner | epoch 004:   1184 / 1474 loss=2.53, trans_loss=3.713, nll_loss=1.927, w2v_ctc_loss=1.44, task_loss=0.871, contrastive_loss=0.303, total=4161.18, n_correct=2161.79, ppl=3.8, accuracy=51.951, wps=13538.8, ups=1.09, wpb=12431.8, bsz=483.4, num_updates=5600, lr=0.000188982, gnorm=0.546, clip=0, loss_scale=8, train_wall=91, gb_free=16.7, wall=4711
2023-08-10 14:28:59 | INFO | train_inner | epoch 004:   1284 / 1474 loss=2.497, trans_loss=3.704, nll_loss=1.913, w2v_ctc_loss=1.421, task_loss=0.885, contrastive_loss=0.27, total=4156.53, n_correct=2180.47, ppl=3.77, accuracy=52.459, wps=13555.7, ups=1.09, wpb=12411.4, bsz=472.7, num_updates=5700, lr=0.000187317, gnorm=0.544, clip=0, loss_scale=8, train_wall=91, gb_free=15.8, wall=4802
2023-08-10 14:30:30 | INFO | train_inner | epoch 004:   1384 / 1474 loss=2.446, trans_loss=3.703, nll_loss=1.912, w2v_ctc_loss=1.417, task_loss=0.953, contrastive_loss=0.15, total=4101.23, n_correct=2157.46, ppl=3.76, accuracy=52.605, wps=13518.1, ups=1.1, wpb=12249, bsz=437.6, num_updates=5800, lr=0.000185695, gnorm=0.52, clip=0, loss_scale=8, train_wall=90, gb_free=15.6, wall=4893
2023-08-10 14:31:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.4246, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.4246, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.4246, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.4246, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.4246, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.4246, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.4246, device='cuda:3')
2023-08-10 14:32:17 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.548 | trans_loss 5.902 | nll_loss 3.274 | w2v_ctc_loss 1.583 | task_loss 4.43 | contrastive_loss 0.294 | total 4003.4 | n_correct 2263.2 | ppl 9.68 | accuracy 56.532 | uer 23.98 | wer 25.543 | raw_wer 25.543 | bleu 16.52 | wps 2006.6 | wpb 4003.4 | bsz 141.8 | num_updates 5890 | best_bleu 16.52
2023-08-10 14:32:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5890 updates
2023-08-10 14:32:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 14:32:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 14:32:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt (epoch 4 @ 5890 updates, score 16.52) (writing took 26.47157097607851 seconds)
2023-08-10 14:32:43 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-10 14:32:43 | INFO | train | epoch 004 | loss 2.552 | trans_loss 3.737 | nll_loss 1.954 | w2v_ctc_loss 1.469 | task_loss 0.927 | contrastive_loss 0.262 | total 4138.65 | n_correct 2111.05 | ppl 3.87 | accuracy 51.008 | wps 12876.8 | ups 1.04 | wpb 12355.8 | bsz 458.5 | num_updates 5890 | lr 0.000184271 | gnorm 0.695 | clip 0 | loss_scale 8 | train_wall 1349 | gb_free 14.7 | wall 5026
2023-08-10 14:32:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 14:32:44 | INFO | fairseq.trainer | begin training epoch 5
2023-08-10 14:32:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 14:33:00 | INFO | train_inner | epoch 005:     10 / 1474 loss=2.432, trans_loss=3.694, nll_loss=1.9, w2v_ctc_loss=1.391, task_loss=0.964, contrastive_loss=0.169, total=4037.7, n_correct=2135.46, ppl=3.73, accuracy=52.888, wps=8051.1, ups=0.67, wpb=12055.9, bsz=439.3, num_updates=5900, lr=0.000184115, gnorm=0.528, clip=0, loss_scale=8, train_wall=91, gb_free=16.9, wall=5043
2023-08-10 14:34:32 | INFO | train_inner | epoch 005:    110 / 1474 loss=2.356, trans_loss=3.638, nll_loss=1.827, w2v_ctc_loss=1.314, task_loss=0.839, contrastive_loss=0.173, total=4247.37, n_correct=2320.57, ppl=3.55, accuracy=54.635, wps=13818.4, ups=1.09, wpb=12683.4, bsz=495.1, num_updates=6000, lr=0.000182574, gnorm=0.508, clip=0, loss_scale=8, train_wall=91, gb_free=16.7, wall=5135
2023-08-10 14:34:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 14:34:58 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.528 | trans_loss 5.883 | nll_loss 3.249 | w2v_ctc_loss 1.555 | task_loss 4.468 | contrastive_loss 0.297 | total 4003.4 | n_correct 2275.3 | ppl 9.51 | accuracy 56.834 | uer 23.285 | wer 24.798 | raw_wer 24.798 | bleu 16.58 | wps 1956.4 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 16.58
2023-08-10 14:34:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-08-10 14:34:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_5_6000.pt
2023-08-10 14:35:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_5_6000.pt
2023-08-10 14:35:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 16.58) (writing took 42.51881366968155 seconds)
2023-08-10 14:37:12 | INFO | train_inner | epoch 005:    210 / 1474 loss=2.428, trans_loss=3.651, nll_loss=1.842, w2v_ctc_loss=1.334, task_loss=0.858, contrastive_loss=0.394, total=4189.85, n_correct=2274.83, ppl=3.58, accuracy=54.294, wps=7803, ups=0.62, wpb=12500.5, bsz=488.2, num_updates=6100, lr=0.000181071, gnorm=0.527, clip=0, loss_scale=8, train_wall=91, gb_free=17.8, wall=5295
2023-08-10 14:38:43 | INFO | train_inner | epoch 005:    310 / 1474 loss=2.386, trans_loss=3.644, nll_loss=1.838, w2v_ctc_loss=1.345, task_loss=0.956, contrastive_loss=0.237, total=4090.1, n_correct=2216.13, ppl=3.57, accuracy=54.183, wps=13417.6, ups=1.1, wpb=12228.1, bsz=443.9, num_updates=6200, lr=0.000179605, gnorm=0.515, clip=0, loss_scale=8, train_wall=91, gb_free=16.2, wall=5386
2023-08-10 14:40:16 | INFO | train_inner | epoch 005:    410 / 1474 loss=2.397, trans_loss=3.638, nll_loss=1.831, w2v_ctc_loss=1.316, task_loss=0.899, contrastive_loss=0.322, total=4147.17, n_correct=2264.42, ppl=3.56, accuracy=54.602, wps=13361.4, ups=1.08, wpb=12395.1, bsz=472.5, num_updates=6300, lr=0.000178174, gnorm=0.518, clip=0, loss_scale=8, train_wall=92, gb_free=14.8, wall=5479
2023-08-10 14:41:47 | INFO | train_inner | epoch 005:    510 / 1474 loss=2.332, trans_loss=3.649, nll_loss=1.842, w2v_ctc_loss=1.323, task_loss=1.045, contrastive_loss=0.122, total=4026.81, n_correct=2188.74, ppl=3.59, accuracy=54.354, wps=13140.3, ups=1.09, wpb=12029.7, bsz=416.6, num_updates=6400, lr=0.000176777, gnorm=0.5, clip=0, loss_scale=8, train_wall=91, gb_free=17.4, wall=5570
2023-08-10 14:43:20 | INFO | train_inner | epoch 005:    610 / 1474 loss=2.373, trans_loss=3.652, nll_loss=1.844, w2v_ctc_loss=1.309, task_loss=0.955, contrastive_loss=0.285, total=4107.75, n_correct=2237.96, ppl=3.59, accuracy=54.481, wps=13282.7, ups=1.08, wpb=12253.8, bsz=451.2, num_updates=6500, lr=0.000175412, gnorm=0.513, clip=0, loss_scale=8, train_wall=92, gb_free=16.1, wall=5662
2023-08-10 14:44:52 | INFO | train_inner | epoch 005:    710 / 1474 loss=2.377, trans_loss=3.646, nll_loss=1.839, w2v_ctc_loss=1.309, task_loss=0.881, contrastive_loss=0.267, total=4178.85, n_correct=2285.5, ppl=3.58, accuracy=54.692, wps=13541.6, ups=1.09, wpb=12473.1, bsz=480.9, num_updates=6600, lr=0.000174078, gnorm=0.513, clip=0, loss_scale=8, train_wall=92, gb_free=17.7, wall=5755
2023-08-10 14:46:24 | INFO | train_inner | epoch 005:    810 / 1474 loss=2.344, trans_loss=3.644, nll_loss=1.835, w2v_ctc_loss=1.304, task_loss=0.956, contrastive_loss=0.196, total=4127.73, n_correct=2259.75, ppl=3.57, accuracy=54.746, wps=13325.4, ups=1.08, wpb=12320.4, bsz=449.2, num_updates=6700, lr=0.000172774, gnorm=0.503, clip=0, loss_scale=8, train_wall=92, gb_free=15, wall=5847
2023-08-10 14:47:56 | INFO | train_inner | epoch 005:    910 / 1474 loss=2.318, trans_loss=3.636, nll_loss=1.827, w2v_ctc_loss=1.295, task_loss=0.961, contrastive_loss=0.158, total=4095.48, n_correct=2253.16, ppl=3.55, accuracy=55.016, wps=13295.2, ups=1.09, wpb=12229.5, bsz=445.3, num_updates=6800, lr=0.000171499, gnorm=0.504, clip=0, loss_scale=8, train_wall=91, gb_free=15.6, wall=5939
2023-08-10 14:49:28 | INFO | train_inner | epoch 005:   1010 / 1474 loss=2.342, trans_loss=3.64, nll_loss=1.831, w2v_ctc_loss=1.295, task_loss=0.918, contrastive_loss=0.242, total=4165.12, n_correct=2288.84, ppl=3.56, accuracy=54.953, wps=13570, ups=1.09, wpb=12433.6, bsz=463.5, num_updates=6900, lr=0.000170251, gnorm=0.503, clip=0, loss_scale=8, train_wall=91, gb_free=15.6, wall=6031
2023-08-10 14:51:00 | INFO | train_inner | epoch 005:   1110 / 1474 loss=2.358, trans_loss=3.641, nll_loss=1.832, w2v_ctc_loss=1.306, task_loss=0.92, contrastive_loss=0.24, total=4176.72, n_correct=2303.97, ppl=3.56, accuracy=55.162, wps=13443.5, ups=1.08, wpb=12459.2, bsz=466.1, num_updates=7000, lr=0.000169031, gnorm=0.507, clip=0, loss_scale=8, train_wall=92, gb_free=16.6, wall=6123
2023-08-10 14:52:33 | INFO | train_inner | epoch 005:   1210 / 1474 loss=2.3, trans_loss=3.635, nll_loss=1.824, w2v_ctc_loss=1.278, task_loss=0.948, contrastive_loss=0.145, total=4164.13, n_correct=2304.99, ppl=3.54, accuracy=55.353, wps=13456.6, ups=1.08, wpb=12420.9, bsz=453.8, num_updates=7100, lr=0.000167836, gnorm=0.501, clip=0, loss_scale=16, train_wall=92, gb_free=16.9, wall=6216
2023-08-10 14:54:04 | INFO | train_inner | epoch 005:   1310 / 1474 loss=2.285, trans_loss=3.634, nll_loss=1.824, w2v_ctc_loss=1.271, task_loss=0.946, contrastive_loss=0.117, total=4134.91, n_correct=2288.26, ppl=3.54, accuracy=55.34, wps=13469.3, ups=1.09, wpb=12341.4, bsz=445.6, num_updates=7200, lr=0.000166667, gnorm=0.49, clip=0, loss_scale=16, train_wall=91, gb_free=16.3, wall=6307
2023-08-10 14:55:36 | INFO | train_inner | epoch 005:   1410 / 1474 loss=2.302, trans_loss=3.634, nll_loss=1.827, w2v_ctc_loss=1.266, task_loss=0.938, contrastive_loss=0.176, total=4134.37, n_correct=2287.94, ppl=3.55, accuracy=55.34, wps=13468.6, ups=1.09, wpb=12347.5, bsz=458.5, num_updates=7300, lr=0.000165521, gnorm=0.495, clip=0, loss_scale=16, train_wall=91, gb_free=17.7, wall=6399
2023-08-10 14:56:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 14:56:59 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.485 | trans_loss 5.847 | nll_loss 3.211 | w2v_ctc_loss 1.461 | task_loss 4.418 | contrastive_loss 0.316 | total 4003.4 | n_correct 2303.6 | ppl 9.26 | accuracy 57.541 | uer 23.462 | wer 25.312 | raw_wer 25.312 | bleu 17.45 | wps 2016.4 | wpb 4003.4 | bsz 141.8 | num_updates 7364 | best_bleu 17.45
2023-08-10 14:56:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7364 updates
2023-08-10 14:56:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 14:57:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 14:57:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt (epoch 5 @ 7364 updates, score 17.45) (writing took 25.262837450951338 seconds)
2023-08-10 14:57:24 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-10 14:57:24 | INFO | train | epoch 005 | loss 2.349 | trans_loss 3.641 | nll_loss 1.832 | w2v_ctc_loss 1.304 | task_loss 0.929 | contrastive_loss 0.22 | total 4138.65 | n_correct 2268.67 | ppl 3.56 | accuracy 54.817 | wps 12298.7 | ups 1 | wpb 12355.8 | bsz 458.5 | num_updates 7364 | lr 0.0001648 | gnorm 0.507 | clip 0 | loss_scale 16 | train_wall 1348 | gb_free 16.2 | wall 6507
2023-08-10 14:57:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 14:57:24 | INFO | fairseq.trainer | begin training epoch 6
2023-08-10 14:57:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 14:58:06 | INFO | train_inner | epoch 006:     36 / 1474 loss=2.286, trans_loss=3.611, nll_loss=1.794, w2v_ctc_loss=1.261, task_loss=0.956, contrastive_loss=0.173, total=4115.45, n_correct=2300.27, ppl=3.47, accuracy=55.894, wps=8181.6, ups=0.67, wpb=12281.2, bsz=447.9, num_updates=7400, lr=0.000164399, gnorm=0.502, clip=0, loss_scale=16, train_wall=92, gb_free=16.4, wall=6549
2023-08-10 14:59:38 | INFO | train_inner | epoch 006:    136 / 1474 loss=2.247, trans_loss=3.579, nll_loss=1.754, w2v_ctc_loss=1.214, task_loss=0.928, contrastive_loss=0.219, total=4154.25, n_correct=2355.45, ppl=3.37, accuracy=56.7, wps=13489.9, ups=1.09, wpb=12407.4, bsz=456.1, num_updates=7500, lr=0.000163299, gnorm=0.486, clip=0, loss_scale=16, train_wall=91, gb_free=15.5, wall=6641
2023-08-10 15:01:09 | INFO | train_inner | epoch 006:    236 / 1474 loss=2.242, trans_loss=3.59, nll_loss=1.769, w2v_ctc_loss=1.242, task_loss=0.998, contrastive_loss=0.126, total=4112.66, n_correct=2317.04, ppl=3.41, accuracy=56.339, wps=13451.5, ups=1.09, wpb=12287.2, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.485, clip=0, loss_scale=16, train_wall=91, gb_free=16.1, wall=6732
2023-08-10 15:02:43 | INFO | train_inner | epoch 006:    336 / 1474 loss=2.306, trans_loss=3.579, nll_loss=1.756, w2v_ctc_loss=1.195, task_loss=0.865, contrastive_loss=0.429, total=4177.51, n_correct=2373.07, ppl=3.38, accuracy=56.806, wps=13334.1, ups=1.07, wpb=12473.8, bsz=491.3, num_updates=7700, lr=0.000161165, gnorm=0.507, clip=0, loss_scale=16, train_wall=93, gb_free=16, wall=6826
2023-08-10 15:04:14 | INFO | train_inner | epoch 006:    436 / 1474 loss=2.221, trans_loss=3.582, nll_loss=1.759, w2v_ctc_loss=1.206, task_loss=0.894, contrastive_loss=0.142, total=4154.57, n_correct=2365.5, ppl=3.38, accuracy=56.937, wps=13578.3, ups=1.09, wpb=12405.5, bsz=470.2, num_updates=7800, lr=0.000160128, gnorm=0.486, clip=0, loss_scale=16, train_wall=91, gb_free=16, wall=6917
2023-08-10 15:05:46 | INFO | train_inner | epoch 006:    536 / 1474 loss=2.224, trans_loss=3.589, nll_loss=1.766, w2v_ctc_loss=1.217, task_loss=0.936, contrastive_loss=0.13, total=4167.79, n_correct=2370.22, ppl=3.4, accuracy=56.87, wps=13565.2, ups=1.09, wpb=12438.5, bsz=455.2, num_updates=7900, lr=0.000159111, gnorm=0.486, clip=0, loss_scale=16, train_wall=91, gb_free=15.7, wall=7009
2023-08-10 15:07:17 | INFO | train_inner | epoch 006:    636 / 1474 loss=2.23, trans_loss=3.591, nll_loss=1.771, w2v_ctc_loss=1.199, task_loss=0.881, contrastive_loss=0.184, total=4146.17, n_correct=2354.65, ppl=3.41, accuracy=56.791, wps=13595.2, ups=1.1, wpb=12376.6, bsz=471.6, num_updates=8000, lr=0.000158114, gnorm=0.487, clip=0, loss_scale=16, train_wall=91, gb_free=16.3, wall=7100
2023-08-10 15:07:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 15:07:42 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.397 | trans_loss 5.759 | nll_loss 3.087 | w2v_ctc_loss 1.428 | task_loss 4.532 | contrastive_loss 0.273 | total 4003.4 | n_correct 2349.8 | ppl 8.5 | accuracy 58.695 | uer 21.501 | wer 23.381 | raw_wer 23.381 | bleu 17.98 | wps 2035.5 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 17.98
2023-08-10 15:07:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-08-10 15:07:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_6_8000.pt
2023-08-10 15:07:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_6_8000.pt
2023-08-10 15:08:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 17.98) (writing took 45.39577933959663 seconds)
2023-08-10 15:09:59 | INFO | train_inner | epoch 006:    736 / 1474 loss=2.225, trans_loss=3.592, nll_loss=1.772, w2v_ctc_loss=1.215, task_loss=0.952, contrastive_loss=0.138, total=4148.65, n_correct=2351.54, ppl=3.42, accuracy=56.682, wps=7638.2, ups=0.62, wpb=12388, bsz=453.7, num_updates=8100, lr=0.000157135, gnorm=0.483, clip=0, loss_scale=16, train_wall=91, gb_free=15.5, wall=7262
2023-08-10 15:11:31 | INFO | train_inner | epoch 006:    836 / 1474 loss=2.22, trans_loss=3.6, nll_loss=1.782, w2v_ctc_loss=1.211, task_loss=0.975, contrastive_loss=0.123, total=4114.34, n_correct=2325.96, ppl=3.44, accuracy=56.533, wps=13360.2, ups=1.09, wpb=12282.2, bsz=441.6, num_updates=8200, lr=0.000156174, gnorm=0.483, clip=0, loss_scale=16, train_wall=91, gb_free=15, wall=7354
2023-08-10 15:13:03 | INFO | train_inner | epoch 006:    936 / 1474 loss=2.251, trans_loss=3.599, nll_loss=1.78, w2v_ctc_loss=1.212, task_loss=0.967, contrastive_loss=0.218, total=4081.53, n_correct=2312.81, ppl=3.43, accuracy=56.665, wps=13281.1, ups=1.09, wpb=12181.3, bsz=444.5, num_updates=8300, lr=0.00015523, gnorm=0.49, clip=0, loss_scale=16, train_wall=91, gb_free=17.8, wall=7446
2023-08-10 15:14:34 | INFO | train_inner | epoch 006:   1036 / 1474 loss=2.25, trans_loss=3.585, nll_loss=1.765, w2v_ctc_loss=1.189, task_loss=0.881, contrastive_loss=0.29, total=4165.84, n_correct=2375.89, ppl=3.4, accuracy=57.033, wps=13601.7, ups=1.09, wpb=12435.7, bsz=477.2, num_updates=8400, lr=0.000154303, gnorm=0.491, clip=0, loss_scale=16, train_wall=91, gb_free=16.8, wall=7537
2023-08-10 15:16:06 | INFO | train_inner | epoch 006:   1136 / 1474 loss=2.214, trans_loss=3.592, nll_loss=1.772, w2v_ctc_loss=1.207, task_loss=1.028, contrastive_loss=0.125, total=4072.29, n_correct=2313.03, ppl=3.42, accuracy=56.799, wps=13202.8, ups=1.09, wpb=12157.6, bsz=428, num_updates=8500, lr=0.000153393, gnorm=0.486, clip=0, loss_scale=16, train_wall=92, gb_free=16.9, wall=7629
2023-08-10 15:17:39 | INFO | train_inner | epoch 006:   1236 / 1474 loss=2.288, trans_loss=3.582, nll_loss=1.762, w2v_ctc_loss=1.189, task_loss=0.903, contrastive_loss=0.436, total=4141.55, n_correct=2362.21, ppl=3.39, accuracy=57.037, wps=13326.4, ups=1.08, wpb=12370.9, bsz=474.8, num_updates=8600, lr=0.000152499, gnorm=0.487, clip=0, loss_scale=16, train_wall=92, gb_free=13.1, wall=7722
2023-08-10 15:19:10 | INFO | train_inner | epoch 006:   1336 / 1474 loss=2.189, trans_loss=3.59, nll_loss=1.769, w2v_ctc_loss=1.185, task_loss=0.928, contrastive_loss=0.111, total=4125.31, n_correct=2356.49, ppl=3.41, accuracy=57.123, wps=13588.4, ups=1.1, wpb=12305, bsz=452.6, num_updates=8700, lr=0.00015162, gnorm=0.48, clip=0, loss_scale=16, train_wall=90, gb_free=17.8, wall=7813
2023-08-10 15:20:42 | INFO | train_inner | epoch 006:   1436 / 1474 loss=2.191, trans_loss=3.583, nll_loss=1.761, w2v_ctc_loss=1.189, task_loss=0.93, contrastive_loss=0.115, total=4196.2, n_correct=2404.57, ppl=3.39, accuracy=57.304, wps=13625.3, ups=1.09, wpb=12525.2, bsz=461.5, num_updates=8800, lr=0.000150756, gnorm=0.473, clip=0, loss_scale=16, train_wall=91, gb_free=11.2, wall=7905
2023-08-10 15:21:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 15:21:40 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.357 | trans_loss 5.724 | nll_loss 3.049 | w2v_ctc_loss 1.387 | task_loss 4.561 | contrastive_loss 0.261 | total 4003.4 | n_correct 2362.4 | ppl 8.27 | accuracy 59.01 | uer 20.381 | wer 22.169 | raw_wer 22.169 | bleu 18 | wps 2147.7 | wpb 4003.4 | bsz 141.8 | num_updates 8838 | best_bleu 18
2023-08-10 15:21:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8838 updates
2023-08-10 15:21:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 15:21:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 15:22:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt (epoch 6 @ 8838 updates, score 18.0) (writing took 26.150723731145263 seconds)
2023-08-10 15:22:06 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-10 15:22:06 | INFO | train | epoch 006 | loss 2.234 | trans_loss 3.588 | nll_loss 1.767 | w2v_ctc_loss 1.204 | task_loss 0.93 | contrastive_loss 0.198 | total 4138.65 | n_correct 2352.68 | ppl 3.4 | accuracy 56.847 | wps 12290.9 | ups 0.99 | wpb 12355.8 | bsz 458.5 | num_updates 8838 | lr 0.000150431 | gnorm 0.486 | clip 0 | loss_scale 16 | train_wall 1346 | gb_free 15.1 | wall 7989
2023-08-10 15:22:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 15:22:06 | INFO | fairseq.trainer | begin training epoch 7
2023-08-10 15:22:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 15:23:11 | INFO | train_inner | epoch 007:     62 / 1474 loss=2.162, trans_loss=3.56, nll_loss=1.732, w2v_ctc_loss=1.159, task_loss=0.91, contrastive_loss=0.131, total=4108.19, n_correct=2374.52, ppl=3.32, accuracy=57.8, wps=8205.9, ups=0.67, wpb=12266.6, bsz=461.9, num_updates=8900, lr=0.000149906, gnorm=0.478, clip=0, loss_scale=16, train_wall=91, gb_free=17.1, wall=8054
2023-08-10 15:24:42 | INFO | train_inner | epoch 007:    162 / 1474 loss=2.168, trans_loss=3.55, nll_loss=1.718, w2v_ctc_loss=1.144, task_loss=0.945, contrastive_loss=0.202, total=4106.05, n_correct=2386.32, ppl=3.29, accuracy=58.117, wps=13454.3, ups=1.1, wpb=12258.7, bsz=455.4, num_updates=9000, lr=0.000149071, gnorm=0.483, clip=0, loss_scale=16, train_wall=91, gb_free=16.7, wall=8145
2023-08-10 15:26:14 | INFO | train_inner | epoch 007:    262 / 1474 loss=2.141, trans_loss=3.545, nll_loss=1.711, w2v_ctc_loss=1.146, task_loss=0.943, contrastive_loss=0.111, total=4129.3, n_correct=2411.7, ppl=3.27, accuracy=58.405, wps=13466.4, ups=1.09, wpb=12322.8, bsz=451.8, num_updates=9100, lr=0.00014825, gnorm=0.48, clip=0, loss_scale=16, train_wall=91, gb_free=17.2, wall=8237
2023-08-10 15:27:47 | INFO | train_inner | epoch 007:    362 / 1474 loss=2.208, trans_loss=3.554, nll_loss=1.723, w2v_ctc_loss=1.136, task_loss=0.898, contrastive_loss=0.369, total=4201.67, n_correct=2439.2, ppl=3.3, accuracy=58.053, wps=13500, ups=1.08, wpb=12539.8, bsz=479.7, num_updates=9200, lr=0.000147442, gnorm=0.476, clip=0, loss_scale=32, train_wall=92, gb_free=15.4, wall=8330
2023-08-10 15:29:18 | INFO | train_inner | epoch 007:    462 / 1474 loss=2.188, trans_loss=3.553, nll_loss=1.725, w2v_ctc_loss=1.134, task_loss=0.915, contrastive_loss=0.296, total=4155.31, n_correct=2410.93, ppl=3.31, accuracy=58.02, wps=13604.3, ups=1.1, wpb=12410.9, bsz=465.5, num_updates=9300, lr=0.000146647, gnorm=0.478, clip=0, loss_scale=32, train_wall=91, gb_free=16.7, wall=8421
2023-08-10 15:30:49 | INFO | train_inner | epoch 007:    562 / 1474 loss=2.141, trans_loss=3.554, nll_loss=1.722, w2v_ctc_loss=1.139, task_loss=0.915, contrastive_loss=0.119, total=4165.88, n_correct=2424.82, ppl=3.3, accuracy=58.207, wps=13645.1, ups=1.1, wpb=12426.4, bsz=459, num_updates=9400, lr=0.000145865, gnorm=0.478, clip=0, loss_scale=32, train_wall=91, gb_free=17.2, wall=8512
2023-08-10 15:32:22 | INFO | train_inner | epoch 007:    662 / 1474 loss=2.128, trans_loss=3.552, nll_loss=1.721, w2v_ctc_loss=1.13, task_loss=0.937, contrastive_loss=0.107, total=4149.29, n_correct=2422.9, ppl=3.3, accuracy=58.393, wps=13398.2, ups=1.08, wpb=12381.3, bsz=451.6, num_updates=9500, lr=0.000145095, gnorm=0.473, clip=0, loss_scale=32, train_wall=92, gb_free=17, wall=8604
2023-08-10 15:33:54 | INFO | train_inner | epoch 007:    762 / 1474 loss=2.132, trans_loss=3.546, nll_loss=1.715, w2v_ctc_loss=1.136, task_loss=0.965, contrastive_loss=0.107, total=4134.54, n_correct=2413.46, ppl=3.28, accuracy=58.373, wps=13382, ups=1.08, wpb=12345.4, bsz=449.8, num_updates=9600, lr=0.000144338, gnorm=0.478, clip=0, loss_scale=32, train_wall=92, gb_free=13.7, wall=8697
2023-08-10 15:35:27 | INFO | train_inner | epoch 007:    862 / 1474 loss=2.138, trans_loss=3.558, nll_loss=1.729, w2v_ctc_loss=1.134, task_loss=0.935, contrastive_loss=0.124, total=4151.77, n_correct=2411.35, ppl=3.32, accuracy=58.08, wps=13363.3, ups=1.08, wpb=12391.6, bsz=461.9, num_updates=9700, lr=0.000143592, gnorm=0.475, clip=0, loss_scale=32, train_wall=92, gb_free=14.8, wall=8789
2023-08-10 15:36:59 | INFO | train_inner | epoch 007:    962 / 1474 loss=2.156, trans_loss=3.551, nll_loss=1.722, w2v_ctc_loss=1.12, task_loss=0.895, contrastive_loss=0.213, total=4124.8, n_correct=2406.61, ppl=3.3, accuracy=58.345, wps=13376.9, ups=1.09, wpb=12313.3, bsz=471.2, num_updates=9800, lr=0.000142857, gnorm=0.481, clip=0, loss_scale=32, train_wall=91, gb_free=16.5, wall=8882
2023-08-10 15:38:31 | INFO | train_inner | epoch 007:   1062 / 1474 loss=2.129, trans_loss=3.562, nll_loss=1.737, w2v_ctc_loss=1.136, task_loss=0.973, contrastive_loss=0.093, total=4113.08, n_correct=2388.15, ppl=3.33, accuracy=58.062, wps=13352.2, ups=1.09, wpb=12279.6, bsz=439.4, num_updates=9900, lr=0.000142134, gnorm=0.476, clip=0, loss_scale=32, train_wall=91, gb_free=14.6, wall=8973
2023-08-10 15:39:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-10 15:40:03 | INFO | train_inner | epoch 007:   1163 / 1474 loss=2.154, trans_loss=3.547, nll_loss=1.72, w2v_ctc_loss=1.127, task_loss=0.929, contrastive_loss=0.193, total=4113.08, n_correct=2402.12, ppl=3.29, accuracy=58.402, wps=13247.4, ups=1.08, wpb=12290.8, bsz=459.5, num_updates=10000, lr=0.000141421, gnorm=0.478, clip=0, loss_scale=16, train_wall=92, gb_free=15.9, wall=9066
2023-08-10 15:40:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 15:40:28 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.324 | trans_loss 5.683 | nll_loss 2.997 | w2v_ctc_loss 1.37 | task_loss 4.595 | contrastive_loss 0.263 | total 4003.4 | n_correct 2398.4 | ppl 7.98 | accuracy 59.909 | uer 19.3 | wer 20.946 | raw_wer 20.946 | bleu 18.92 | wps 2118.2 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 18.92
2023-08-10 15:40:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-08-10 15:40:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_7_10000.pt
2023-08-10 15:40:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_7_10000.pt
2023-08-10 15:41:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 18.92) (writing took 39.465306928381324 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:0')
2023-08-10 15:42:38 | INFO | train_inner | epoch 007:   1263 / 1474 loss=2.123, trans_loss=3.553, nll_loss=1.727, w2v_ctc_loss=1.121, task_loss=0.944, contrastive_loss=0.117, total=4129.52, n_correct=2405.35, ppl=3.31, accuracy=58.248, wps=7958.5, ups=0.65, wpb=12331.4, bsz=450.2, num_updates=10100, lr=0.00014072, gnorm=0.403, clip=0, loss_scale=16, train_wall=90, gb_free=16.7, wall=9221
2023-08-10 15:44:09 | INFO | train_inner | epoch 007:   1363 / 1474 loss=2.143, trans_loss=3.548, nll_loss=1.719, w2v_ctc_loss=1.129, task_loss=0.877, contrastive_loss=0.151, total=4172.87, n_correct=2441.05, ppl=3.29, accuracy=58.498, wps=13663, ups=1.1, wpb=12458.1, bsz=476.2, num_updates=10200, lr=0.000140028, gnorm=0.402, clip=0, loss_scale=16, train_wall=91, gb_free=17.1, wall=9312
2023-08-10 15:45:43 | INFO | train_inner | epoch 007:   1463 / 1474 loss=2.159, trans_loss=3.554, nll_loss=1.729, w2v_ctc_loss=1.13, task_loss=1.005, contrastive_loss=0.217, total=4109.42, n_correct=2390.94, ppl=3.31, accuracy=58.182, wps=13180.7, ups=1.07, wpb=12278.1, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.41, clip=0, loss_scale=16, train_wall=93, gb_free=16.3, wall=9406
2023-08-10 15:45:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:5')
2023-08-10 15:46:16 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.312 | trans_loss 5.673 | nll_loss 2.982 | w2v_ctc_loss 1.357 | task_loss 4.573 | contrastive_loss 0.261 | total 4003.4 | n_correct 2397.9 | ppl 7.9 | accuracy 59.897 | uer 19.545 | wer 21.528 | raw_wer 21.528 | bleu 19.06 | wps 2076 | wpb 4003.4 | bsz 141.8 | num_updates 10311 | best_bleu 19.06
2023-08-10 15:46:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10311 updates
2023-08-10 15:46:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 15:46:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 15:46:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt (epoch 7 @ 10311 updates, score 19.06) (writing took 24.76615777425468 seconds)
2023-08-10 15:46:42 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-10 15:46:42 | INFO | train | epoch 007 | loss 2.15 | trans_loss 3.552 | nll_loss 1.722 | w2v_ctc_loss 1.134 | task_loss 0.934 | contrastive_loss 0.171 | total 4137.25 | n_correct 2409.38 | ppl 3.3 | accuracy 58.236 | wps 12329.3 | ups 1 | wpb 12351.7 | bsz 457.8 | num_updates 10311 | lr 0.000139272 | gnorm 0.462 | clip 0 | loss_scale 16 | train_wall 1346 | gb_free 13.1 | wall 9465
2023-08-10 15:46:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 15:46:42 | INFO | fairseq.trainer | begin training epoch 8
2023-08-10 15:46:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 15:48:12 | INFO | train_inner | epoch 008:     89 / 1474 loss=2.087, trans_loss=3.529, nll_loss=1.689, w2v_ctc_loss=1.089, task_loss=0.983, contrastive_loss=0.112, total=4116.25, n_correct=2434.18, ppl=3.23, accuracy=59.136, wps=8222, ups=0.67, wpb=12273, bsz=443.3, num_updates=10400, lr=0.000138675, gnorm=0.402, clip=0, loss_scale=16, train_wall=91, gb_free=16.9, wall=9555
2023-08-10 15:49:44 | INFO | train_inner | epoch 008:    189 / 1474 loss=2.088, trans_loss=3.52, nll_loss=1.678, w2v_ctc_loss=1.087, task_loss=1.009, contrastive_loss=0.129, total=4037.23, n_correct=2390.52, ppl=3.2, accuracy=59.212, wps=13142.2, ups=1.09, wpb=12041.5, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.404, clip=0, loss_scale=16, train_wall=91, gb_free=12.6, wall=9646
2023-08-10 15:51:16 | INFO | train_inner | epoch 008:    289 / 1474 loss=2.088, trans_loss=3.517, nll_loss=1.677, w2v_ctc_loss=1.086, task_loss=0.874, contrastive_loss=0.127, total=4207.78, n_correct=2499.59, ppl=3.2, accuracy=59.404, wps=13634.8, ups=1.09, wpb=12556.5, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.401, clip=0, loss_scale=16, train_wall=92, gb_free=12.7, wall=9739
2023-08-10 15:52:49 | INFO | train_inner | epoch 008:    389 / 1474 loss=2.108, trans_loss=3.525, nll_loss=1.686, w2v_ctc_loss=1.104, task_loss=0.995, contrastive_loss=0.152, total=4127.24, n_correct=2436.7, ppl=3.22, accuracy=59.039, wps=13257, ups=1.08, wpb=12316.2, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=0.404, clip=0, loss_scale=16, train_wall=92, gb_free=11.6, wall=9831
2023-08-10 15:53:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-10 15:54:22 | INFO | train_inner | epoch 008:    490 / 1474 loss=2.132, trans_loss=3.52, nll_loss=1.683, w2v_ctc_loss=1.084, task_loss=0.859, contrastive_loss=0.272, total=4177.48, n_correct=2480.98, ppl=3.21, accuracy=59.389, wps=13282.2, ups=1.07, wpb=12470.1, bsz=491.5, num_updates=10800, lr=0.000136083, gnorm=0.406, clip=0, loss_scale=8, train_wall=93, gb_free=12.6, wall=9925
2023-08-10 15:55:54 | INFO | train_inner | epoch 008:    590 / 1474 loss=2.089, trans_loss=3.524, nll_loss=1.69, w2v_ctc_loss=1.104, task_loss=1.013, contrastive_loss=0.09, total=4065.55, n_correct=2400.11, ppl=3.23, accuracy=59.035, wps=13231.3, ups=1.09, wpb=12153.4, bsz=428.3, num_updates=10900, lr=0.000135457, gnorm=0.406, clip=0, loss_scale=8, train_wall=91, gb_free=16.1, wall=10017
2023-08-10 15:57:26 | INFO | train_inner | epoch 008:    690 / 1474 loss=2.082, trans_loss=3.518, nll_loss=1.68, w2v_ctc_loss=1.097, task_loss=0.965, contrastive_loss=0.099, total=4135.41, n_correct=2459.29, ppl=3.2, accuracy=59.469, wps=13441.7, ups=1.09, wpb=12343.8, bsz=447.2, num_updates=11000, lr=0.00013484, gnorm=0.397, clip=0, loss_scale=8, train_wall=91, gb_free=15.8, wall=10109
2023-08-10 15:58:58 | INFO | train_inner | epoch 008:    790 / 1474 loss=2.101, trans_loss=3.519, nll_loss=1.685, w2v_ctc_loss=1.087, task_loss=0.943, contrastive_loss=0.185, total=4128.86, n_correct=2448.55, ppl=3.22, accuracy=59.303, wps=13433.3, ups=1.09, wpb=12339, bsz=452.1, num_updates=11100, lr=0.000134231, gnorm=0.403, clip=0, loss_scale=8, train_wall=91, gb_free=16.2, wall=10201
2023-08-10 16:00:30 | INFO | train_inner | epoch 008:    890 / 1474 loss=2.105, trans_loss=3.521, nll_loss=1.687, w2v_ctc_loss=1.078, task_loss=0.899, contrastive_loss=0.196, total=4166.92, n_correct=2474.68, ppl=3.22, accuracy=59.389, wps=13536, ups=1.09, wpb=12446.8, bsz=471.5, num_updates=11200, lr=0.000133631, gnorm=0.408, clip=0, loss_scale=8, train_wall=91, gb_free=14.3, wall=10293
2023-08-10 16:02:01 | INFO | train_inner | epoch 008:    990 / 1474 loss=2.071, trans_loss=3.522, nll_loss=1.686, w2v_ctc_loss=1.08, task_loss=0.899, contrastive_loss=0.098, total=4150.39, n_correct=2467.4, ppl=3.22, accuracy=59.45, wps=13566.9, ups=1.09, wpb=12390.2, bsz=462.8, num_updates=11300, lr=0.000133038, gnorm=0.398, clip=0, loss_scale=8, train_wall=91, gb_free=17.2, wall=10384
2023-08-10 16:03:34 | INFO | train_inner | epoch 008:   1090 / 1474 loss=2.128, trans_loss=3.528, nll_loss=1.694, w2v_ctc_loss=1.076, task_loss=0.922, contrastive_loss=0.319, total=4197.39, n_correct=2479.36, ppl=3.24, accuracy=59.069, wps=13583.6, ups=1.08, wpb=12529.5, bsz=466.4, num_updates=11400, lr=0.000132453, gnorm=0.4, clip=0, loss_scale=8, train_wall=92, gb_free=16.8, wall=10476
2023-08-10 16:05:05 | INFO | train_inner | epoch 008:   1190 / 1474 loss=2.08, trans_loss=3.521, nll_loss=1.688, w2v_ctc_loss=1.083, task_loss=0.883, contrastive_loss=0.106, total=4180.55, n_correct=2481.33, ppl=3.22, accuracy=59.354, wps=13642.7, ups=1.09, wpb=12487.2, bsz=472.7, num_updates=11500, lr=0.000131876, gnorm=0.398, clip=0, loss_scale=8, train_wall=91, gb_free=17.2, wall=10568
2023-08-10 16:06:36 | INFO | train_inner | epoch 008:   1290 / 1474 loss=2.09, trans_loss=3.528, nll_loss=1.696, w2v_ctc_loss=1.092, task_loss=0.974, contrastive_loss=0.127, total=4062.6, n_correct=2399.81, ppl=3.24, accuracy=59.071, wps=13275.3, ups=1.09, wpb=12135.3, bsz=437.8, num_updates=11600, lr=0.000131306, gnorm=0.406, clip=0, loss_scale=8, train_wall=91, gb_free=12.9, wall=10659
2023-08-10 16:08:08 | INFO | train_inner | epoch 008:   1390 / 1474 loss=2.104, trans_loss=3.528, nll_loss=1.696, w2v_ctc_loss=1.078, task_loss=0.905, contrastive_loss=0.192, total=4159.11, n_correct=2466.38, ppl=3.24, accuracy=59.301, wps=13619.3, ups=1.1, wpb=12419, bsz=468.7, num_updates=11700, lr=0.000130744, gnorm=0.401, clip=0, loss_scale=8, train_wall=91, gb_free=13.2, wall=10751
2023-08-10 16:09:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 16:09:48 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.291 | trans_loss 5.651 | nll_loss 2.949 | w2v_ctc_loss 1.342 | task_loss 4.585 | contrastive_loss 0.255 | total 4003.4 | n_correct 2417.4 | ppl 7.72 | accuracy 60.384 | uer 19.03 | wer 20.644 | raw_wer 20.644 | bleu 18.99 | wps 2205.3 | wpb 4003.4 | bsz 141.8 | num_updates 11784 | best_bleu 19.06
2023-08-10 16:09:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11784 updates
2023-08-10 16:09:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_18.9909.pt
2023-08-10 16:09:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_18.9909.pt
2023-08-10 16:10:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_18.9909.pt (epoch 8 @ 11784 updates, score 18.99) (writing took 16.8199297003448 seconds)
2023-08-10 16:10:08 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-10 16:10:08 | INFO | train | epoch 008 | loss 2.097 | trans_loss 3.523 | nll_loss 1.687 | w2v_ctc_loss 1.086 | task_loss 0.934 | contrastive_loss 0.162 | total 4137.01 | n_correct 2452.13 | ppl 3.22 | accuracy 59.273 | wps 12940.1 | ups 1.05 | wpb 12350.9 | bsz 457.7 | num_updates 11784 | lr 0.000130277 | gnorm 0.402 | clip 0 | loss_scale 8 | train_wall 1347 | gb_free 16.8 | wall 10870
2023-08-10 16:10:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 16:10:08 | INFO | fairseq.trainer | begin training epoch 9
2023-08-10 16:10:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 16:10:31 | INFO | train_inner | epoch 009:     16 / 1474 loss=2.108, trans_loss=3.52, nll_loss=1.684, w2v_ctc_loss=1.066, task_loss=0.912, contrastive_loss=0.286, total=4121.25, n_correct=2453.8, ppl=3.21, accuracy=59.54, wps=8605.8, ups=0.7, wpb=12298.5, bsz=466, num_updates=11800, lr=0.000130189, gnorm=0.404, clip=0, loss_scale=8, train_wall=91, gb_free=17.7, wall=10893
2023-08-10 16:12:02 | INFO | train_inner | epoch 009:    116 / 1474 loss=2.038, trans_loss=3.485, nll_loss=1.638, w2v_ctc_loss=1.039, task_loss=0.878, contrastive_loss=0.125, total=4191.82, n_correct=2538.11, ppl=3.11, accuracy=60.549, wps=13713.4, ups=1.1, wpb=12518.2, bsz=479.9, num_updates=11900, lr=0.000129641, gnorm=0.393, clip=0, loss_scale=8, train_wall=91, gb_free=15.9, wall=10985
2023-08-10 16:13:34 | INFO | train_inner | epoch 009:    216 / 1474 loss=2.029, trans_loss=3.492, nll_loss=1.647, w2v_ctc_loss=1.045, task_loss=1.003, contrastive_loss=0.084, total=4061.27, n_correct=2447.65, ppl=3.13, accuracy=60.268, wps=13116.3, ups=1.08, wpb=12126.5, bsz=431.4, num_updates=12000, lr=0.000129099, gnorm=0.401, clip=0, loss_scale=8, train_wall=92, gb_free=17.5, wall=11077
2023-08-10 16:13:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 16:13:57 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.277 | trans_loss 5.652 | nll_loss 2.952 | w2v_ctc_loss 1.295 | task_loss 4.556 | contrastive_loss 0.252 | total 4003.4 | n_correct 2417 | ppl 7.74 | accuracy 60.374 | uer 18.825 | wer 20.685 | raw_wer 20.685 | bleu 19.21 | wps 2254.8 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 19.21
2023-08-10 16:13:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-08-10 16:13:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_9_12000.pt
2023-08-10 16:14:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_9_12000.pt
2023-08-10 16:14:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 19.21) (writing took 24.9735118560493 seconds)
2023-08-10 16:15:55 | INFO | train_inner | epoch 009:    316 / 1474 loss=2.03, trans_loss=3.481, nll_loss=1.636, w2v_ctc_loss=1.029, task_loss=0.88, contrastive_loss=0.13, total=4146.43, n_correct=2513.62, ppl=3.11, accuracy=60.621, wps=8828.1, ups=0.71, wpb=12389.9, bsz=474.6, num_updates=12100, lr=0.000128565, gnorm=0.397, clip=0, loss_scale=8, train_wall=91, gb_free=16.2, wall=11218
2023-08-10 16:17:27 | INFO | train_inner | epoch 009:    416 / 1474 loss=2.029, trans_loss=3.496, nll_loss=1.653, w2v_ctc_loss=1.038, task_loss=0.913, contrastive_loss=0.098, total=4194.84, n_correct=2520.03, ppl=3.15, accuracy=60.075, wps=13554.1, ups=1.08, wpb=12524.6, bsz=466.7, num_updates=12200, lr=0.000128037, gnorm=0.393, clip=0, loss_scale=8, train_wall=92, gb_free=16.1, wall=11310
2023-08-10 16:18:59 | INFO | train_inner | epoch 009:    516 / 1474 loss=2.067, trans_loss=3.503, nll_loss=1.66, w2v_ctc_loss=1.064, task_loss=0.979, contrastive_loss=0.15, total=4124.3, n_correct=2475.25, ppl=3.16, accuracy=60.016, wps=13449.7, ups=1.09, wpb=12310.3, bsz=439.5, num_updates=12300, lr=0.000127515, gnorm=0.4, clip=0, loss_scale=8, train_wall=91, gb_free=11.3, wall=11402
2023-08-10 16:20:31 | INFO | train_inner | epoch 009:    616 / 1474 loss=2.028, trans_loss=3.491, nll_loss=1.65, w2v_ctc_loss=1.036, task_loss=0.956, contrastive_loss=0.11, total=4120.96, n_correct=2485.04, ppl=3.14, accuracy=60.302, wps=13339.8, ups=1.08, wpb=12316.4, bsz=453.4, num_updates=12400, lr=0.000127, gnorm=0.398, clip=0, loss_scale=8, train_wall=92, gb_free=16.1, wall=11494
2023-08-10 16:22:02 | INFO | train_inner | epoch 009:    716 / 1474 loss=2.073, trans_loss=3.505, nll_loss=1.666, w2v_ctc_loss=1.058, task_loss=0.948, contrastive_loss=0.192, total=4088.53, n_correct=2449.02, ppl=3.17, accuracy=59.9, wps=13389.4, ups=1.1, wpb=12213.7, bsz=451.4, num_updates=12500, lr=0.000126491, gnorm=0.408, clip=0, loss_scale=8, train_wall=91, gb_free=16.9, wall=11585
2023-08-10 16:23:34 | INFO | train_inner | epoch 009:    816 / 1474 loss=2.119, trans_loss=3.497, nll_loss=1.658, w2v_ctc_loss=1.049, task_loss=0.842, contrastive_loss=0.332, total=4220.43, n_correct=2534.86, ppl=3.16, accuracy=60.062, wps=13705.2, ups=1.09, wpb=12611.1, bsz=501.1, num_updates=12600, lr=0.000125988, gnorm=0.41, clip=0, loss_scale=8, train_wall=91, gb_free=14.3, wall=11677
2023-08-10 16:25:07 | INFO | train_inner | epoch 009:    916 / 1474 loss=2.092, trans_loss=3.503, nll_loss=1.661, w2v_ctc_loss=1.05, task_loss=0.961, contrastive_loss=0.317, total=4146.05, n_correct=2490.49, ppl=3.16, accuracy=60.069, wps=13352.5, ups=1.08, wpb=12371.5, bsz=450.3, num_updates=12700, lr=0.000125491, gnorm=0.398, clip=0, loss_scale=8, train_wall=92, gb_free=17.7, wall=11770
2023-08-10 16:26:38 | INFO | train_inner | epoch 009:   1016 / 1474 loss=2.044, trans_loss=3.511, nll_loss=1.671, w2v_ctc_loss=1.056, task_loss=1.039, contrastive_loss=0.098, total=4101.48, n_correct=2453.11, ppl=3.18, accuracy=59.81, wps=13384.2, ups=1.09, wpb=12241.7, bsz=424.4, num_updates=12800, lr=0.000125, gnorm=0.398, clip=0, loss_scale=16, train_wall=91, gb_free=15.9, wall=11861
2023-08-10 16:28:10 | INFO | train_inner | epoch 009:   1116 / 1474 loss=2.047, trans_loss=3.508, nll_loss=1.665, w2v_ctc_loss=1.048, task_loss=0.875, contrastive_loss=0.12, total=4179.09, n_correct=2512.2, ppl=3.17, accuracy=60.114, wps=13607.5, ups=1.09, wpb=12457.7, bsz=474.7, num_updates=12900, lr=0.000124515, gnorm=0.398, clip=0, loss_scale=16, train_wall=91, gb_free=15.1, wall=11953
2023-08-10 16:29:42 | INFO | train_inner | epoch 009:   1216 / 1474 loss=2.046, trans_loss=3.506, nll_loss=1.668, w2v_ctc_loss=1.058, task_loss=0.988, contrastive_loss=0.103, total=4140.66, n_correct=2483.81, ppl=3.18, accuracy=59.986, wps=13347.6, ups=1.08, wpb=12363.4, bsz=448.1, num_updates=13000, lr=0.000124035, gnorm=0.398, clip=0, loss_scale=16, train_wall=92, gb_free=17, wall=12045
2023-08-10 16:31:14 | INFO | train_inner | epoch 009:   1316 / 1474 loss=2.091, trans_loss=3.502, nll_loss=1.662, w2v_ctc_loss=1.038, task_loss=0.848, contrastive_loss=0.293, total=4204.43, n_correct=2532.36, ppl=3.16, accuracy=60.231, wps=13697, ups=1.09, wpb=12544.9, bsz=492.5, num_updates=13100, lr=0.00012356, gnorm=0.405, clip=0, loss_scale=16, train_wall=91, gb_free=17.6, wall=12137
2023-08-10 16:32:46 | INFO | train_inner | epoch 009:   1416 / 1474 loss=2.039, trans_loss=3.515, nll_loss=1.678, w2v_ctc_loss=1.054, task_loss=1.01, contrastive_loss=0.083, total=4069.19, n_correct=2435.71, ppl=3.2, accuracy=59.857, wps=13252, ups=1.09, wpb=12143.2, bsz=427.7, num_updates=13200, lr=0.000123091, gnorm=0.396, clip=0, loss_scale=16, train_wall=91, gb_free=16.5, wall=12229
2023-08-10 16:33:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 16:34:02 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.269 | trans_loss 5.632 | nll_loss 2.93 | w2v_ctc_loss 1.321 | task_loss 4.562 | contrastive_loss 0.251 | total 4003.4 | n_correct 2424.8 | ppl 7.62 | accuracy 60.569 | uer 18.642 | wer 20.469 | raw_wer 20.469 | bleu 19.21 | wps 2124.9 | wpb 4003.4 | bsz 141.8 | num_updates 13258 | best_bleu 19.21
2023-08-10 16:34:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13258 updates
2023-08-10 16:34:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 16:34:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 16:34:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt (epoch 9 @ 13258 updates, score 19.21) (writing took 25.973908020183444 seconds)
2023-08-10 16:34:28 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-10 16:34:28 | INFO | train | epoch 009 | loss 2.056 | trans_loss 3.5 | nll_loss 1.658 | w2v_ctc_loss 1.047 | task_loss 0.933 | contrastive_loss 0.165 | total 4138.65 | n_correct 2488.87 | ppl 3.16 | accuracy 60.137 | wps 12467.6 | ups 1.01 | wpb 12355.8 | bsz 458.5 | num_updates 13258 | lr 0.000122822 | gnorm 0.4 | clip 0 | loss_scale 16 | train_wall 1346 | gb_free 11.4 | wall 12331
2023-08-10 16:34:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 16:34:29 | INFO | fairseq.trainer | begin training epoch 10
2023-08-10 16:34:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 16:35:15 | INFO | train_inner | epoch 010:     42 / 1474 loss=2.044, trans_loss=3.493, nll_loss=1.65, w2v_ctc_loss=1.027, task_loss=0.89, contrastive_loss=0.178, total=4100.8, n_correct=2483.73, ppl=3.14, accuracy=60.567, wps=8212.1, ups=0.67, wpb=12238.2, bsz=469.4, num_updates=13300, lr=0.000122628, gnorm=0.401, clip=0, loss_scale=16, train_wall=91, gb_free=16.2, wall=12378
2023-08-10 16:36:47 | INFO | train_inner | epoch 010:    142 / 1474 loss=1.987, trans_loss=3.465, nll_loss=1.614, w2v_ctc_loss=0.998, task_loss=0.881, contrastive_loss=0.102, total=4247.35, n_correct=2599.18, ppl=3.06, accuracy=61.195, wps=13800.8, ups=1.09, wpb=12684.5, bsz=479.6, num_updates=13400, lr=0.000122169, gnorm=0.39, clip=0, loss_scale=16, train_wall=91, gb_free=11.4, wall=12470
2023-08-10 16:38:19 | INFO | train_inner | epoch 010:    242 / 1474 loss=2.034, trans_loss=3.469, nll_loss=1.617, w2v_ctc_loss=1.013, task_loss=0.924, contrastive_loss=0.227, total=4122.82, n_correct=2521.36, ppl=3.07, accuracy=61.156, wps=13362.8, ups=1.09, wpb=12303.3, bsz=461.4, num_updates=13500, lr=0.000121716, gnorm=0.398, clip=0, loss_scale=16, train_wall=92, gb_free=16.2, wall=12562
2023-08-10 16:39:51 | INFO | train_inner | epoch 010:    342 / 1474 loss=2.003, trans_loss=3.468, nll_loss=1.622, w2v_ctc_loss=1.005, task_loss=0.943, contrastive_loss=0.137, total=4138.27, n_correct=2525.67, ppl=3.08, accuracy=61.032, wps=13424, ups=1.09, wpb=12371, bsz=453.8, num_updates=13600, lr=0.000121268, gnorm=0.394, clip=0, loss_scale=16, train_wall=92, gb_free=16.3, wall=12654
2023-08-10 16:41:24 | INFO | train_inner | epoch 010:    442 / 1474 loss=2.039, trans_loss=3.473, nll_loss=1.624, w2v_ctc_loss=0.993, task_loss=0.898, contrastive_loss=0.308, total=4196.37, n_correct=2559.6, ppl=3.08, accuracy=60.996, wps=13520.6, ups=1.08, wpb=12528, bsz=481.1, num_updates=13700, lr=0.000120824, gnorm=0.392, clip=0, loss_scale=16, train_wall=92, gb_free=15.9, wall=12747
2023-08-10 16:42:56 | INFO | train_inner | epoch 010:    542 / 1474 loss=2.012, trans_loss=3.488, nll_loss=1.64, w2v_ctc_loss=1.028, task_loss=1.003, contrastive_loss=0.091, total=4102.8, n_correct=2487.94, ppl=3.12, accuracy=60.64, wps=13232.6, ups=1.08, wpb=12234.1, bsz=437.8, num_updates=13800, lr=0.000120386, gnorm=0.398, clip=0, loss_scale=16, train_wall=92, gb_free=17, wall=12839
2023-08-10 16:44:28 | INFO | train_inner | epoch 010:    642 / 1474 loss=2.04, trans_loss=3.483, nll_loss=1.637, w2v_ctc_loss=1.017, task_loss=0.886, contrastive_loss=0.204, total=4176.56, n_correct=2542.74, ppl=3.11, accuracy=60.881, wps=13486.3, ups=1.08, wpb=12464, bsz=477.2, num_updates=13900, lr=0.000119952, gnorm=0.398, clip=0, loss_scale=16, train_wall=92, gb_free=16, wall=12931
2023-08-10 16:46:00 | INFO | train_inner | epoch 010:    742 / 1474 loss=2.017, trans_loss=3.483, nll_loss=1.638, w2v_ctc_loss=1.035, task_loss=0.934, contrastive_loss=0.091, total=4125.87, n_correct=2506.39, ppl=3.11, accuracy=60.748, wps=13497.4, ups=1.1, wpb=12315.3, bsz=454.4, num_updates=14000, lr=0.000119523, gnorm=0.404, clip=0, loss_scale=16, train_wall=91, gb_free=14.2, wall=13023
2023-08-10 16:46:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 16:46:23 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.27 | trans_loss 5.628 | nll_loss 2.918 | w2v_ctc_loss 1.33 | task_loss 4.6 | contrastive_loss 0.255 | total 4003.4 | n_correct 2430.8 | ppl 7.56 | accuracy 60.718 | uer 19.048 | wer 20.756 | raw_wer 20.756 | bleu 19.57 | wps 2224 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 19.57
2023-08-10 16:46:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-08-10 16:46:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_10_14000.pt
2023-08-10 16:46:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_10_14000.pt
2023-08-10 16:46:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 19.57) (writing took 25.686233824118972 seconds)
2023-08-10 16:48:21 | INFO | train_inner | epoch 010:    842 / 1474 loss=1.992, trans_loss=3.479, nll_loss=1.633, w2v_ctc_loss=1.005, task_loss=0.924, contrastive_loss=0.092, total=4128.44, n_correct=2517.67, ppl=3.1, accuracy=60.984, wps=8708.1, ups=0.71, wpb=12327.8, bsz=456.3, num_updates=14100, lr=0.000119098, gnorm=0.39, clip=0, loss_scale=16, train_wall=91, gb_free=14.6, wall=13164
2023-08-10 16:49:53 | INFO | train_inner | epoch 010:    942 / 1474 loss=2.016, trans_loss=3.481, nll_loss=1.634, w2v_ctc_loss=1.015, task_loss=0.895, contrastive_loss=0.128, total=4160.94, n_correct=2532.98, ppl=3.1, accuracy=60.875, wps=13591.1, ups=1.1, wpb=12411.1, bsz=468.1, num_updates=14200, lr=0.000118678, gnorm=0.397, clip=0, loss_scale=16, train_wall=91, gb_free=15.3, wall=13256
2023-08-10 16:51:24 | INFO | train_inner | epoch 010:   1042 / 1474 loss=2.009, trans_loss=3.485, nll_loss=1.64, w2v_ctc_loss=1.02, task_loss=1.007, contrastive_loss=0.104, total=4067.53, n_correct=2463.84, ppl=3.12, accuracy=60.573, wps=13291.2, ups=1.09, wpb=12145, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.402, clip=0, loss_scale=16, train_wall=91, gb_free=16.8, wall=13347
2023-08-10 16:52:55 | INFO | train_inner | epoch 010:   1142 / 1474 loss=2.015, trans_loss=3.493, nll_loss=1.65, w2v_ctc_loss=1.034, task_loss=1.042, contrastive_loss=0.088, total=4044.03, n_correct=2441.58, ppl=3.14, accuracy=60.375, wps=13269.1, ups=1.1, wpb=12074.4, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.403, clip=0, loss_scale=16, train_wall=90, gb_free=17.3, wall=13438
2023-08-10 16:54:26 | INFO | train_inner | epoch 010:   1242 / 1474 loss=2.004, trans_loss=3.481, nll_loss=1.64, w2v_ctc_loss=1.025, task_loss=0.954, contrastive_loss=0.084, total=4110.41, n_correct=2497.22, ppl=3.12, accuracy=60.754, wps=13433.5, ups=1.09, wpb=12291.6, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.398, clip=0, loss_scale=16, train_wall=91, gb_free=16.4, wall=13529
2023-08-10 16:55:58 | INFO | train_inner | epoch 010:   1342 / 1474 loss=2.004, trans_loss=3.488, nll_loss=1.647, w2v_ctc_loss=1.019, task_loss=0.954, contrastive_loss=0.094, total=4121.38, n_correct=2502.25, ppl=3.13, accuracy=60.714, wps=13400.2, ups=1.09, wpb=12308.4, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.396, clip=0, loss_scale=16, train_wall=91, gb_free=13.9, wall=13621
2023-08-10 16:57:31 | INFO | train_inner | epoch 010:   1442 / 1474 loss=2.086, trans_loss=3.492, nll_loss=1.649, w2v_ctc_loss=1.008, task_loss=0.879, contrastive_loss=0.341, total=4192.39, n_correct=2543.29, ppl=3.14, accuracy=60.664, wps=13558.9, ups=1.08, wpb=12506.1, bsz=482, num_updates=14700, lr=0.000116642, gnorm=0.407, clip=0, loss_scale=16, train_wall=92, gb_free=17, wall=13714
2023-08-10 16:58:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 16:58:23 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.253 | trans_loss 5.609 | nll_loss 2.899 | w2v_ctc_loss 1.313 | task_loss 4.581 | contrastive_loss 0.259 | total 4003.4 | n_correct 2436.8 | ppl 7.46 | accuracy 60.868 | uer 17.96 | wer 19.82 | raw_wer 19.82 | bleu 19.47 | wps 2231.6 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 19.57
2023-08-10 16:58:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-08-10 16:58:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_19.4703.pt
2023-08-10 16:58:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_19.4703.pt
2023-08-10 16:58:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_19.4703.pt (epoch 10 @ 14732 updates, score 19.47) (writing took 14.280391363427043 seconds)
2023-08-10 16:58:38 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-10 16:58:38 | INFO | train | epoch 010 | loss 2.02 | trans_loss 3.48 | nll_loss 1.634 | w2v_ctc_loss 1.014 | task_loss 0.933 | contrastive_loss 0.16 | total 4138.65 | n_correct 2518.05 | ppl 3.1 | accuracy 60.842 | wps 12565.3 | ups 1.02 | wpb 12355.8 | bsz 458.5 | num_updates 14732 | lr 0.000116516 | gnorm 0.397 | clip 0 | loss_scale 16 | train_wall 1347 | gb_free 17.2 | wall 13781
2023-08-10 16:58:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 16:58:38 | INFO | fairseq.trainer | begin training epoch 11
2023-08-10 16:58:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 16:59:48 | INFO | train_inner | epoch 011:     68 / 1474 loss=1.988, trans_loss=3.456, nll_loss=1.603, w2v_ctc_loss=0.985, task_loss=0.864, contrastive_loss=0.167, total=4175.24, n_correct=2575.61, ppl=3.04, accuracy=61.688, wps=9102, ups=0.73, wpb=12463.5, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.389, clip=0, loss_scale=16, train_wall=91, gb_free=16.7, wall=13850
2023-08-10 17:01:19 | INFO | train_inner | epoch 011:    168 / 1474 loss=1.969, trans_loss=3.456, nll_loss=1.605, w2v_ctc_loss=0.991, task_loss=0.961, contrastive_loss=0.088, total=4087.78, n_correct=2518.19, ppl=3.04, accuracy=61.603, wps=13318.2, ups=1.09, wpb=12214.2, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.395, clip=0, loss_scale=32, train_wall=91, gb_free=16.3, wall=13942
2023-08-10 17:02:50 | INFO | train_inner | epoch 011:    268 / 1474 loss=1.959, trans_loss=3.456, nll_loss=1.604, w2v_ctc_loss=0.98, task_loss=0.961, contrastive_loss=0.084, total=4118.77, n_correct=2540.71, ppl=3.04, accuracy=61.686, wps=13496.4, ups=1.1, wpb=12299.1, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.393, clip=0, loss_scale=32, train_wall=91, gb_free=12.2, wall=14033
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:0')
2023-08-10 17:03:59 | INFO | train_inner | epoch 011:    368 / 1474 loss=2.102, trans_loss=5.137, nll_loss=2.388, w2v_ctc_loss=0.738, task_loss=1.427, contrastive_loss=0.068, total=4097.83, n_correct=2520.74, ppl=5.23, accuracy=61.514, wps=12016.7, ups=1.46, wpb=8240.8, bsz=298, num_updates=15100, lr=0.000115087, gnorm=0.527, clip=0, loss_scale=32, train_wall=68, gb_free=15.4, wall=14102
2023-08-10 17:05:08 | INFO | train_inner | epoch 011:    468 / 1474 loss=2.124, trans_loss=5.175, nll_loss=2.413, w2v_ctc_loss=0.731, task_loss=1.46, contrastive_loss=0.185, total=4110.64, n_correct=2515.9, ppl=5.33, accuracy=61.205, wps=11919.3, ups=1.45, wpb=8221.3, bsz=300.4, num_updates=15200, lr=0.000114708, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=14171
2023-08-10 17:06:17 | INFO | train_inner | epoch 011:    568 / 1474 loss=2.126, trans_loss=5.174, nll_loss=2.413, w2v_ctc_loss=0.742, task_loss=1.498, contrastive_loss=0.185, total=4071.69, n_correct=2495.15, ppl=5.33, accuracy=61.28, wps=11812.8, ups=1.45, wpb=8143.4, bsz=293.7, num_updates=15300, lr=0.000114332, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=14240
2023-08-10 17:07:26 | INFO | train_inner | epoch 011:    668 / 1474 loss=2.133, trans_loss=5.175, nll_loss=2.415, w2v_ctc_loss=0.739, task_loss=1.37, contrastive_loss=0.239, total=4157.2, n_correct=2542.76, ppl=5.33, accuracy=61.165, wps=12101.9, ups=1.46, wpb=8314.4, bsz=309.6, num_updates=15400, lr=0.000113961, gnorm=0.527, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=14309
2023-08-10 17:08:35 | INFO | train_inner | epoch 011:    768 / 1474 loss=2.117, trans_loss=5.185, nll_loss=2.428, w2v_ctc_loss=0.752, task_loss=1.408, contrastive_loss=0.067, total=4174.91, n_correct=2554.35, ppl=5.38, accuracy=61.183, wps=11947.9, ups=1.43, wpb=8349.8, bsz=306.9, num_updates=15500, lr=0.000113592, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=14378
2023-08-10 17:09:44 | INFO | train_inner | epoch 011:    868 / 1474 loss=2.116, trans_loss=5.187, nll_loss=2.43, w2v_ctc_loss=0.747, task_loss=1.465, contrastive_loss=0.057, total=4118.44, n_correct=2510.93, ppl=5.39, accuracy=60.968, wps=11978.3, ups=1.45, wpb=8236.9, bsz=293.7, num_updates=15600, lr=0.000113228, gnorm=0.521, clip=0, loss_scale=32, train_wall=68, gb_free=10.5, wall=14447
2023-08-10 17:10:53 | INFO | train_inner | epoch 011:    968 / 1474 loss=2.115, trans_loss=5.183, nll_loss=2.425, w2v_ctc_loss=0.75, task_loss=1.431, contrastive_loss=0.068, total=4140.92, n_correct=2532.13, ppl=5.37, accuracy=61.149, wps=12082.3, ups=1.46, wpb=8281.8, bsz=301.9, num_updates=15700, lr=0.000112867, gnorm=0.523, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=14516
2023-08-10 17:12:01 | INFO | train_inner | epoch 011:   1068 / 1474 loss=2.112, trans_loss=5.177, nll_loss=2.419, w2v_ctc_loss=0.746, task_loss=1.375, contrastive_loss=0.085, total=4136.99, n_correct=2535.59, ppl=5.35, accuracy=61.291, wps=12076.8, ups=1.46, wpb=8274, bsz=308.8, num_updates=15800, lr=0.000112509, gnorm=0.521, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=14584
2023-08-10 17:13:10 | INFO | train_inner | epoch 011:   1168 / 1474 loss=2.116, trans_loss=5.187, nll_loss=2.432, w2v_ctc_loss=0.748, task_loss=1.39, contrastive_loss=0.073, total=4185.65, n_correct=2557.16, ppl=5.4, accuracy=61.093, wps=12170.1, ups=1.45, wpb=8371.3, bsz=309.8, num_updates=15900, lr=0.000112154, gnorm=0.52, clip=0, loss_scale=32, train_wall=68, gb_free=13.9, wall=14653
2023-08-10 17:14:19 | INFO | train_inner | epoch 011:   1268 / 1474 loss=2.125, trans_loss=5.181, nll_loss=2.425, w2v_ctc_loss=0.75, task_loss=1.342, contrastive_loss=0.138, total=4171.89, n_correct=2553.61, ppl=5.37, accuracy=61.21, wps=12084.4, ups=1.45, wpb=8343.8, bsz=314.1, num_updates=16000, lr=0.000111803, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=14722
2023-08-10 17:14:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:2')
2023-08-10 17:14:43 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.247 | trans_loss 5.603 | nll_loss 2.89 | w2v_ctc_loss 1.318 | task_loss 4.605 | contrastive_loss 0.246 | total 4003.4 | n_correct 2452.5 | ppl 7.41 | accuracy 61.26 | uer 17.838 | wer 19.753 | raw_wer 19.753 | bleu 19.48 | wps 2167.2 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.57
2023-08-10 17:14:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-08-10 17:14:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_11_16000.pt
2023-08-10 17:14:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_11_16000.pt
2023-08-10 17:15:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 19.48) (writing took 30.992718303576112 seconds)
2023-08-10 17:16:23 | INFO | train_inner | epoch 011:   1368 / 1474 loss=2.138, trans_loss=5.182, nll_loss=2.428, w2v_ctc_loss=0.735, task_loss=1.291, contrastive_loss=0.298, total=4190.34, n_correct=2562.61, ppl=5.38, accuracy=61.155, wps=6747.6, ups=0.81, wpb=8380.7, bsz=327.9, num_updates=16100, lr=0.000111456, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=14846
2023-08-10 17:17:32 | INFO | train_inner | epoch 011:   1468 / 1474 loss=2.11, trans_loss=5.183, nll_loss=2.428, w2v_ctc_loss=0.74, task_loss=1.354, contrastive_loss=0.075, total=4158.39, n_correct=2543.32, ppl=5.38, accuracy=61.161, wps=12172.3, ups=1.46, wpb=8316.8, bsz=312, num_updates=16200, lr=0.000111111, gnorm=0.516, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=14915
2023-08-10 17:17:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 17:17:58 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.234 | trans_loss 5.599 | nll_loss 2.886 | w2v_ctc_loss 1.283 | task_loss 4.6 | contrastive_loss 0.241 | total 4003.4 | n_correct 2451.9 | ppl 7.39 | accuracy 61.245 | uer 18.159 | wer 20.007 | raw_wer 20.007 | bleu 19.19 | wps 2313.6 | wpb 4003.4 | bsz 141.8 | num_updates 16206 | best_bleu 19.57
2023-08-10 17:17:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16206 updates
2023-08-10 17:17:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_19.1905.pt
2023-08-10 17:18:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_19.1905.pt
2023-08-10 17:18:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_19.1905.pt (epoch 11 @ 16206 updates, score 19.19) (writing took 14.045322382822633 seconds)
2023-08-10 17:18:13 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-10 17:18:13 | INFO | train | epoch 011 | loss 2.081 | trans_loss 4.749 | nll_loss 2.217 | w2v_ctc_loss 0.803 | task_loss 1.282 | contrastive_loss 0.118 | total 4138.65 | n_correct 2536.62 | ppl 4.65 | accuracy 61.291 | wps 11317.7 | ups 1.25 | wpb 9021 | bsz 333.4 | num_updates 16206 | lr 0.000111091 | gnorm 0.501 | clip 0 | loss_scale 32 | train_wall 1067 | gb_free 17.2 | wall 14956
2023-08-10 17:18:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 17:18:13 | INFO | fairseq.trainer | begin training epoch 12
2023-08-10 17:18:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 17:19:25 | INFO | train_inner | epoch 012:     94 / 1474 loss=2.088, trans_loss=5.126, nll_loss=2.352, w2v_ctc_loss=0.723, task_loss=1.338, contrastive_loss=0.109, total=4146.82, n_correct=2579.04, ppl=5.1, accuracy=62.193, wps=7326.9, ups=0.88, wpb=8293.6, bsz=313.9, num_updates=16300, lr=0.00011077, gnorm=0.517, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=15028
2023-08-10 17:20:34 | INFO | train_inner | epoch 012:    194 / 1474 loss=2.092, trans_loss=5.138, nll_loss=2.366, w2v_ctc_loss=0.735, task_loss=1.446, contrastive_loss=0.061, total=4120.68, n_correct=2553.66, ppl=5.15, accuracy=61.972, wps=11999.8, ups=1.46, wpb=8241.4, bsz=294.7, num_updates=16400, lr=0.000110432, gnorm=0.522, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=15096
2023-08-10 17:21:42 | INFO | train_inner | epoch 012:    294 / 1474 loss=2.087, trans_loss=5.136, nll_loss=2.365, w2v_ctc_loss=0.719, task_loss=1.318, contrastive_loss=0.089, total=4199.46, n_correct=2605.01, ppl=5.15, accuracy=62.032, wps=12188.7, ups=1.45, wpb=8398.9, bsz=320.3, num_updates=16500, lr=0.000110096, gnorm=0.516, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=15165
2023-08-10 17:22:51 | INFO | train_inner | epoch 012:    394 / 1474 loss=2.093, trans_loss=5.146, nll_loss=2.378, w2v_ctc_loss=0.73, task_loss=1.372, contrastive_loss=0.074, total=4151.14, n_correct=2568.48, ppl=5.2, accuracy=61.874, wps=12045.3, ups=1.45, wpb=8302.3, bsz=307.8, num_updates=16600, lr=0.000109764, gnorm=0.523, clip=0, loss_scale=32, train_wall=68, gb_free=17.1, wall=15234
2023-08-10 17:24:00 | INFO | train_inner | epoch 012:    494 / 1474 loss=2.104, trans_loss=5.161, nll_loss=2.398, w2v_ctc_loss=0.739, task_loss=1.403, contrastive_loss=0.081, total=4110.49, n_correct=2535.25, ppl=5.27, accuracy=61.678, wps=12017.6, ups=1.46, wpb=8221, bsz=302.2, num_updates=16700, lr=0.000109435, gnorm=0.524, clip=0, loss_scale=32, train_wall=68, gb_free=13.6, wall=15303
2023-08-10 17:25:09 | INFO | train_inner | epoch 012:    594 / 1474 loss=2.103, trans_loss=5.149, nll_loss=2.383, w2v_ctc_loss=0.732, task_loss=1.34, contrastive_loss=0.144, total=4189.92, n_correct=2591.97, ppl=5.22, accuracy=61.862, wps=12092.4, ups=1.44, wpb=8379.8, bsz=315.1, num_updates=16800, lr=0.000109109, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=14.8, wall=15372
2023-08-10 17:26:18 | INFO | train_inner | epoch 012:    694 / 1474 loss=2.104, trans_loss=5.146, nll_loss=2.38, w2v_ctc_loss=0.714, task_loss=1.282, contrastive_loss=0.232, total=4206.3, n_correct=2611.2, ppl=5.2, accuracy=62.078, wps=12263.9, ups=1.46, wpb=8412.6, bsz=325.7, num_updates=16900, lr=0.000108786, gnorm=0.513, clip=0, loss_scale=64, train_wall=68, gb_free=16.1, wall=15441
2023-08-10 17:27:26 | INFO | train_inner | epoch 012:    794 / 1474 loss=2.095, trans_loss=5.148, nll_loss=2.381, w2v_ctc_loss=0.735, task_loss=1.425, contrastive_loss=0.071, total=4085.96, n_correct=2527.09, ppl=5.21, accuracy=61.848, wps=11926, ups=1.46, wpb=8171.9, bsz=297.1, num_updates=17000, lr=0.000108465, gnorm=0.527, clip=0, loss_scale=64, train_wall=68, gb_free=16.1, wall=15509
2023-08-10 17:28:36 | INFO | train_inner | epoch 012:    894 / 1474 loss=2.102, trans_loss=5.152, nll_loss=2.387, w2v_ctc_loss=0.728, task_loss=1.428, contrastive_loss=0.119, total=4169.74, n_correct=2576.3, ppl=5.23, accuracy=61.786, wps=12026.2, ups=1.44, wpb=8339.5, bsz=306.4, num_updates=17100, lr=0.000108148, gnorm=0.521, clip=0, loss_scale=64, train_wall=69, gb_free=15.9, wall=15579
2023-08-10 17:29:44 | INFO | train_inner | epoch 012:    994 / 1474 loss=2.109, trans_loss=5.164, nll_loss=2.403, w2v_ctc_loss=0.736, task_loss=1.429, contrastive_loss=0.132, total=4117.67, n_correct=2536.14, ppl=5.29, accuracy=61.592, wps=11970.9, ups=1.45, wpb=8235.3, bsz=301.4, num_updates=17200, lr=0.000107833, gnorm=0.527, clip=0, loss_scale=64, train_wall=68, gb_free=17.6, wall=15647
2023-08-10 17:30:52 | INFO | train_inner | epoch 012:   1094 / 1474 loss=2.122, trans_loss=5.17, nll_loss=2.41, w2v_ctc_loss=0.741, task_loss=1.468, contrastive_loss=0.178, total=4047.61, n_correct=2484.98, ppl=5.32, accuracy=61.394, wps=11906.6, ups=1.47, wpb=8095.2, bsz=290.4, num_updates=17300, lr=0.000107521, gnorm=0.537, clip=0, loss_scale=64, train_wall=67, gb_free=16.4, wall=15715
2023-08-10 17:32:01 | INFO | train_inner | epoch 012:   1194 / 1474 loss=2.116, trans_loss=5.176, nll_loss=2.419, w2v_ctc_loss=0.744, task_loss=1.386, contrastive_loss=0.128, total=4184.55, n_correct=2567.18, ppl=5.35, accuracy=61.349, wps=12145.3, ups=1.45, wpb=8369.1, bsz=314.3, num_updates=17400, lr=0.000107211, gnorm=0.52, clip=0, loss_scale=64, train_wall=68, gb_free=16.6, wall=15784
2023-08-10 17:33:10 | INFO | train_inner | epoch 012:   1294 / 1474 loss=2.112, trans_loss=5.169, nll_loss=2.41, w2v_ctc_loss=0.754, task_loss=1.525, contrastive_loss=0.076, total=4086.33, n_correct=2508.25, ppl=5.32, accuracy=61.381, wps=11937.9, ups=1.46, wpb=8172.7, bsz=291.4, num_updates=17500, lr=0.000106904, gnorm=0.533, clip=0, loss_scale=64, train_wall=68, gb_free=16.5, wall=15853
2023-08-10 17:34:18 | INFO | train_inner | epoch 012:   1394 / 1474 loss=2.11, trans_loss=5.168, nll_loss=2.41, w2v_ctc_loss=0.728, task_loss=1.419, contrastive_loss=0.161, total=4134.89, n_correct=2543.32, ppl=5.32, accuracy=61.509, wps=12073, ups=1.46, wpb=8269.8, bsz=304.4, num_updates=17600, lr=0.0001066, gnorm=0.526, clip=0, loss_scale=64, train_wall=68, gb_free=17.2, wall=15921
2023-08-10 17:35:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 17:35:37 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.247 | trans_loss 5.59 | nll_loss 2.874 | w2v_ctc_loss 1.338 | task_loss 4.593 | contrastive_loss 0.255 | total 4003.4 | n_correct 2462.5 | ppl 7.33 | accuracy 61.51 | uer 18.204 | wer 19.943 | raw_wer 19.943 | bleu 19.56 | wps 1996.9 | wpb 4003.4 | bsz 141.8 | num_updates 17680 | best_bleu 19.57
2023-08-10 17:35:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17680 updates
2023-08-10 17:35:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_19.5604.pt
2023-08-10 17:35:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_19.5604.pt
2023-08-10 17:35:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_19.5604.pt (epoch 12 @ 17680 updates, score 19.56) (writing took 14.61369801312685 seconds)
2023-08-10 17:35:53 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-10 17:35:53 | INFO | train | epoch 012 | loss 2.102 | trans_loss 5.154 | nll_loss 2.39 | w2v_ctc_loss 0.733 | task_loss 1.399 | contrastive_loss 0.116 | total 4138.65 | n_correct 2555.57 | ppl 5.24 | accuracy 61.749 | wps 11511.5 | ups 1.39 | wpb 8277.3 | bsz 305.7 | num_updates 17680 | lr 0.000106359 | gnorm 0.523 | clip 0 | loss_scale 64 | train_wall 1005 | gb_free 12.6 | wall 16015
2023-08-10 17:35:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 17:35:53 | INFO | fairseq.trainer | begin training epoch 13
2023-08-10 17:35:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 17:36:14 | INFO | train_inner | epoch 013:     20 / 1474 loss=2.104, trans_loss=5.168, nll_loss=2.408, w2v_ctc_loss=0.742, task_loss=1.444, contrastive_loss=0.068, total=4104.86, n_correct=2530.01, ppl=5.31, accuracy=61.635, wps=7104.1, ups=0.87, wpb=8209.7, bsz=296.8, num_updates=17700, lr=0.000106299, gnorm=0.531, clip=0, loss_scale=64, train_wall=68, gb_free=14.5, wall=16037
2023-08-10 17:37:22 | INFO | train_inner | epoch 013:    120 / 1474 loss=2.077, trans_loss=5.119, nll_loss=2.342, w2v_ctc_loss=0.718, task_loss=1.4, contrastive_loss=0.078, total=4161.2, n_correct=2599.07, ppl=5.07, accuracy=62.46, wps=12152.2, ups=1.46, wpb=8322.4, bsz=302.9, num_updates=17800, lr=0.000106, gnorm=0.518, clip=0, loss_scale=64, train_wall=68, gb_free=16.1, wall=16105
2023-08-10 17:38:31 | INFO | train_inner | epoch 013:    220 / 1474 loss=2.106, trans_loss=5.13, nll_loss=2.359, w2v_ctc_loss=0.713, task_loss=1.295, contrastive_loss=0.291, total=4202.62, n_correct=2617.71, ppl=5.13, accuracy=62.288, wps=12174, ups=1.45, wpb=8405.2, bsz=328.3, num_updates=17900, lr=0.000105703, gnorm=0.524, clip=0, loss_scale=64, train_wall=69, gb_free=17.2, wall=16174
2023-08-10 17:39:40 | INFO | train_inner | epoch 013:    320 / 1474 loss=2.073, trans_loss=5.118, nll_loss=2.341, w2v_ctc_loss=0.712, task_loss=1.441, contrastive_loss=0.064, total=4112.8, n_correct=2573.88, ppl=5.07, accuracy=62.582, wps=11947, ups=1.45, wpb=8225.6, bsz=296, num_updates=18000, lr=0.000105409, gnorm=0.528, clip=0, loss_scale=64, train_wall=68, gb_free=17.8, wall=16243
2023-08-10 17:39:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 17:40:03 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.258 | trans_loss 5.596 | nll_loss 2.88 | w2v_ctc_loss 1.36 | task_loss 4.594 | contrastive_loss 0.258 | total 4003.4 | n_correct 2453.5 | ppl 7.36 | accuracy 61.285 | uer 18 | wer 19.675 | raw_wer 19.675 | bleu 19.22 | wps 2245.1 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.57
2023-08-10 17:40:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-08-10 17:40:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_13_18000.pt
2023-08-10 17:40:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_13_18000.pt
2023-08-10 17:40:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.22) (writing took 40.36767794750631 seconds)
2023-08-10 17:41:55 | INFO | train_inner | epoch 013:    420 / 1474 loss=2.083, trans_loss=5.125, nll_loss=2.353, w2v_ctc_loss=0.722, task_loss=1.318, contrastive_loss=0.109, total=4176.06, n_correct=2610.84, ppl=5.11, accuracy=62.519, wps=6213.8, ups=0.74, wpb=8352.1, bsz=317.5, num_updates=18100, lr=0.000105118, gnorm=0.519, clip=0, loss_scale=64, train_wall=68, gb_free=16.4, wall=16378
2023-08-10 17:43:03 | INFO | train_inner | epoch 013:    520 / 1474 loss=2.092, trans_loss=5.135, nll_loss=2.365, w2v_ctc_loss=0.721, task_loss=1.363, contrastive_loss=0.145, total=4197.57, n_correct=2607.98, ppl=5.15, accuracy=62.131, wps=12215.8, ups=1.46, wpb=8395.1, bsz=318.1, num_updates=18200, lr=0.000104828, gnorm=0.528, clip=0, loss_scale=64, train_wall=68, gb_free=15.2, wall=16446
2023-08-10 17:44:12 | INFO | train_inner | epoch 013:    620 / 1474 loss=2.075, trans_loss=5.129, nll_loss=2.358, w2v_ctc_loss=0.718, task_loss=1.354, contrastive_loss=0.06, total=4160.12, n_correct=2596.61, ppl=5.13, accuracy=62.417, wps=12171.2, ups=1.46, wpb=8320.2, bsz=308.7, num_updates=18300, lr=0.000104542, gnorm=0.516, clip=0, loss_scale=64, train_wall=68, gb_free=16.2, wall=16515
2023-08-10 17:45:21 | INFO | train_inner | epoch 013:    720 / 1474 loss=2.093, trans_loss=5.141, nll_loss=2.372, w2v_ctc_loss=0.743, task_loss=1.55, contrastive_loss=0.06, total=4101.54, n_correct=2541.71, ppl=5.18, accuracy=61.97, wps=11851.2, ups=1.44, wpb=8203.1, bsz=285.7, num_updates=18400, lr=0.000104257, gnorm=0.524, clip=0, loss_scale=64, train_wall=69, gb_free=15.6, wall=16584
2023-08-10 17:46:30 | INFO | train_inner | epoch 013:    820 / 1474 loss=2.091, trans_loss=5.138, nll_loss=2.371, w2v_ctc_loss=0.726, task_loss=1.415, contrastive_loss=0.104, total=4126.37, n_correct=2564.15, ppl=5.17, accuracy=62.141, wps=11913.5, ups=1.44, wpb=8252.7, bsz=307, num_updates=18500, lr=0.000103975, gnorm=0.533, clip=0, loss_scale=64, train_wall=69, gb_free=17.7, wall=16653
2023-08-10 17:47:39 | INFO | train_inner | epoch 013:    920 / 1474 loss=2.088, trans_loss=5.144, nll_loss=2.378, w2v_ctc_loss=0.727, task_loss=1.44, contrastive_loss=0.07, total=4102.78, n_correct=2550.68, ppl=5.2, accuracy=62.17, wps=11919.9, ups=1.45, wpb=8205.6, bsz=295.9, num_updates=18600, lr=0.000103695, gnorm=0.529, clip=0, loss_scale=64, train_wall=68, gb_free=16.5, wall=16722
2023-08-10 17:48:48 | INFO | train_inner | epoch 013:   1020 / 1474 loss=2.1, trans_loss=5.147, nll_loss=2.381, w2v_ctc_loss=0.733, task_loss=1.498, contrastive_loss=0.119, total=4071.32, n_correct=2522.23, ppl=5.21, accuracy=61.951, wps=11869.6, ups=1.46, wpb=8142.6, bsz=291.3, num_updates=18700, lr=0.000103418, gnorm=0.532, clip=0, loss_scale=64, train_wall=68, gb_free=11.3, wall=16791
2023-08-10 17:49:56 | INFO | train_inner | epoch 013:   1120 / 1474 loss=2.087, trans_loss=5.136, nll_loss=2.368, w2v_ctc_loss=0.721, task_loss=1.376, contrastive_loss=0.103, total=4115.28, n_correct=2559.5, ppl=5.16, accuracy=62.195, wps=12046, ups=1.46, wpb=8230.6, bsz=307.5, num_updates=18800, lr=0.000103142, gnorm=0.529, clip=0, loss_scale=64, train_wall=68, gb_free=12, wall=16859
2023-08-10 17:51:05 | INFO | train_inner | epoch 013:   1220 / 1474 loss=2.092, trans_loss=5.152, nll_loss=2.389, w2v_ctc_loss=0.733, task_loss=1.487, contrastive_loss=0.061, total=4105.36, n_correct=2542.41, ppl=5.24, accuracy=61.929, wps=11976.8, ups=1.46, wpb=8210.7, bsz=295.3, num_updates=18900, lr=0.000102869, gnorm=0.528, clip=0, loss_scale=64, train_wall=68, gb_free=16.3, wall=16927
2023-08-10 17:51:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-10 17:52:14 | INFO | train_inner | epoch 013:   1321 / 1474 loss=2.083, trans_loss=5.136, nll_loss=2.369, w2v_ctc_loss=0.726, task_loss=1.419, contrastive_loss=0.064, total=4096.9, n_correct=2555.99, ppl=5.17, accuracy=62.388, wps=11785, ups=1.44, wpb=8193.8, bsz=300.4, num_updates=19000, lr=0.000102598, gnorm=0.525, clip=0, loss_scale=64, train_wall=69, gb_free=17.6, wall=16997
2023-08-10 17:53:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-10 17:53:23 | INFO | train_inner | epoch 013:   1422 / 1474 loss=2.086, trans_loss=5.148, nll_loss=2.385, w2v_ctc_loss=0.723, task_loss=1.419, contrastive_loss=0.059, total=4156.59, n_correct=2577.26, ppl=5.22, accuracy=62.004, wps=12019.1, ups=1.45, wpb=8313.2, bsz=303.4, num_updates=19100, lr=0.000102329, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=17066
2023-08-10 17:53:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 17:54:23 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.237 | trans_loss 5.581 | nll_loss 2.864 | w2v_ctc_loss 1.329 | task_loss 4.609 | contrastive_loss 0.251 | total 4003.4 | n_correct 2459.8 | ppl 7.28 | accuracy 61.443 | uer 18.146 | wer 19.723 | raw_wer 19.723 | bleu 20.09 | wps 2024.7 | wpb 4003.4 | bsz 141.8 | num_updates 19152 | best_bleu 20.09
2023-08-10 17:54:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19152 updates
2023-08-10 17:54:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 17:54:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 17:54:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt (epoch 13 @ 19152 updates, score 20.09) (writing took 27.00258601270616 seconds)
2023-08-10 17:54:51 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-10 17:54:51 | INFO | train | epoch 013 | loss 2.087 | trans_loss 5.135 | nll_loss 2.366 | w2v_ctc_loss 0.724 | task_loss 1.406 | contrastive_loss 0.1 | total 4136.12 | n_correct 2574.21 | ppl 5.15 | accuracy 62.237 | wps 10697 | ups 1.29 | wpb 8272.2 | bsz 304.7 | num_updates 19152 | lr 0.00010219 | gnorm 0.525 | clip 0 | loss_scale 32 | train_wall 1006 | gb_free 17.6 | wall 17154
2023-08-10 17:54:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 17:54:51 | INFO | fairseq.trainer | begin training epoch 14
2023-08-10 17:54:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 17:55:32 | INFO | train_inner | epoch 014:     48 / 1474 loss=2.063, trans_loss=5.102, nll_loss=2.326, w2v_ctc_loss=0.709, task_loss=1.287, contrastive_loss=0.074, total=4179.66, n_correct=2630.64, ppl=5.01, accuracy=62.939, wps=6490.3, ups=0.78, wpb=8359.3, bsz=322, num_updates=19200, lr=0.000102062, gnorm=0.519, clip=0, loss_scale=32, train_wall=68, gb_free=10.2, wall=17195
2023-08-10 17:56:40 | INFO | train_inner | epoch 014:    148 / 1474 loss=2.06, trans_loss=5.091, nll_loss=2.309, w2v_ctc_loss=0.713, task_loss=1.402, contrastive_loss=0.058, total=4081.01, n_correct=2576.18, ppl=4.95, accuracy=63.126, wps=11930.3, ups=1.46, wpb=8162, bsz=300.6, num_updates=19300, lr=0.000101797, gnorm=0.524, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=17263
2023-08-10 17:57:49 | INFO | train_inner | epoch 014:    248 / 1474 loss=2.081, trans_loss=5.111, nll_loss=2.335, w2v_ctc_loss=0.714, task_loss=1.461, contrastive_loss=0.158, total=4109.83, n_correct=2578.89, ppl=5.05, accuracy=62.749, wps=11996.9, ups=1.46, wpb=8219.7, bsz=295.2, num_updates=19400, lr=0.000101535, gnorm=0.52, clip=0, loss_scale=32, train_wall=68, gb_free=15.5, wall=17332
2023-08-10 17:58:57 | INFO | train_inner | epoch 014:    348 / 1474 loss=2.063, trans_loss=5.101, nll_loss=2.322, w2v_ctc_loss=0.708, task_loss=1.307, contrastive_loss=0.09, total=4171.83, n_correct=2629.14, ppl=5, accuracy=63.021, wps=12202.4, ups=1.46, wpb=8343.7, bsz=319.7, num_updates=19500, lr=0.000101274, gnorm=0.522, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=17400
2023-08-10 18:00:06 | INFO | train_inner | epoch 014:    448 / 1474 loss=2.068, trans_loss=5.114, nll_loss=2.339, w2v_ctc_loss=0.709, task_loss=1.404, contrastive_loss=0.067, total=4142.75, n_correct=2597.35, ppl=5.06, accuracy=62.696, wps=12072, ups=1.46, wpb=8285.5, bsz=302.2, num_updates=19600, lr=0.000101015, gnorm=0.523, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=17469
2023-08-10 18:01:15 | INFO | train_inner | epoch 014:    548 / 1474 loss=2.082, trans_loss=5.121, nll_loss=2.347, w2v_ctc_loss=0.729, task_loss=1.508, contrastive_loss=0.075, total=4073.76, n_correct=2545.16, ppl=5.09, accuracy=62.477, wps=11843, ups=1.45, wpb=8147.5, bsz=290.9, num_updates=19700, lr=0.000100759, gnorm=0.535, clip=0, loss_scale=32, train_wall=68, gb_free=15.4, wall=17538
2023-08-10 18:02:24 | INFO | train_inner | epoch 014:    648 / 1474 loss=2.079, trans_loss=5.118, nll_loss=2.343, w2v_ctc_loss=0.713, task_loss=1.399, contrastive_loss=0.131, total=4158.79, n_correct=2602.14, ppl=5.07, accuracy=62.57, wps=12009.5, ups=1.44, wpb=8317.6, bsz=306.8, num_updates=19800, lr=0.000100504, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=17607
2023-08-10 18:03:33 | INFO | train_inner | epoch 014:    748 / 1474 loss=2.063, trans_loss=5.107, nll_loss=2.33, w2v_ctc_loss=0.708, task_loss=1.363, contrastive_loss=0.065, total=4145.47, n_correct=2607.01, ppl=5.03, accuracy=62.888, wps=12113.3, ups=1.46, wpb=8290.9, bsz=309.6, num_updates=19900, lr=0.000100251, gnorm=0.518, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=17675
2023-08-10 18:04:41 | INFO | train_inner | epoch 014:    848 / 1474 loss=2.081, trans_loss=5.11, nll_loss=2.336, w2v_ctc_loss=0.709, task_loss=1.332, contrastive_loss=0.174, total=4171.1, n_correct=2617.14, ppl=5.05, accuracy=62.745, wps=12109.8, ups=1.45, wpb=8342.2, bsz=319.7, num_updates=20000, lr=0.0001, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=17744
2023-08-10 18:04:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 18:05:04 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.237 | trans_loss 5.578 | nll_loss 2.858 | w2v_ctc_loss 1.336 | task_loss 4.587 | contrastive_loss 0.25 | total 4003.4 | n_correct 2464.3 | ppl 7.25 | accuracy 61.555 | uer 17.769 | wer 19.645 | raw_wer 19.645 | bleu 19.56 | wps 2314.5 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 20.09
2023-08-10 18:05:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-08-10 18:05:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_14_20000.pt
2023-08-10 18:05:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_14_20000.pt
2023-08-10 18:05:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.56) (writing took 24.942233327776194 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:0')
2023-08-10 18:06:39 | INFO | train_inner | epoch 014:    948 / 1474 loss=2.076, trans_loss=5.119, nll_loss=2.346, w2v_ctc_loss=0.711, task_loss=1.403, contrastive_loss=0.111, total=4167.75, n_correct=2607.99, ppl=5.08, accuracy=62.575, wps=7119.9, ups=0.85, wpb=8335.5, bsz=310.1, num_updates=20100, lr=9.97509e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=17861
2023-08-10 18:07:47 | INFO | train_inner | epoch 014:   1048 / 1474 loss=2.076, trans_loss=5.125, nll_loss=2.355, w2v_ctc_loss=0.712, task_loss=1.422, contrastive_loss=0.085, total=4143.92, n_correct=2589.36, ppl=5.12, accuracy=62.486, wps=12033.2, ups=1.45, wpb=8287.8, bsz=300.7, num_updates=20200, lr=9.95037e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=17930
2023-08-10 18:08:57 | INFO | train_inner | epoch 014:   1148 / 1474 loss=2.112, trans_loss=5.125, nll_loss=2.356, w2v_ctc_loss=0.719, task_loss=1.309, contrastive_loss=0.355, total=4228.69, n_correct=2636.88, ppl=5.12, accuracy=62.357, wps=12183.2, ups=1.44, wpb=8457.4, bsz=327.2, num_updates=20300, lr=9.92583e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=18000
2023-08-10 18:10:05 | INFO | train_inner | epoch 014:   1248 / 1474 loss=2.089, trans_loss=5.144, nll_loss=2.377, w2v_ctc_loss=0.733, task_loss=1.648, contrastive_loss=0.049, total=4021.19, n_correct=2499.09, ppl=5.19, accuracy=62.148, wps=11785, ups=1.47, wpb=8042.4, bsz=271.7, num_updates=20400, lr=9.90148e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=18068
2023-08-10 18:11:14 | INFO | train_inner | epoch 014:   1348 / 1474 loss=2.069, trans_loss=5.127, nll_loss=2.358, w2v_ctc_loss=0.707, task_loss=1.318, contrastive_loss=0.065, total=4213.9, n_correct=2635.2, ppl=5.13, accuracy=62.536, wps=12304.9, ups=1.46, wpb=8427.8, bsz=319.4, num_updates=20500, lr=9.8773e-05, gnorm=0.513, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=18136
2023-08-10 18:12:22 | INFO | train_inner | epoch 014:   1448 / 1474 loss=2.081, trans_loss=5.135, nll_loss=2.369, w2v_ctc_loss=0.713, task_loss=1.398, contrastive_loss=0.101, total=4130.28, n_correct=2577.89, ppl=5.17, accuracy=62.414, wps=12033, ups=1.46, wpb=8260.6, bsz=304.1, num_updates=20600, lr=9.85329e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=68, gb_free=15.3, wall=18205
2023-08-10 18:12:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:2')
2023-08-10 18:13:04 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.224 | trans_loss 5.582 | nll_loss 2.867 | w2v_ctc_loss 1.289 | task_loss 4.593 | contrastive_loss 0.248 | total 4003.4 | n_correct 2464.5 | ppl 7.29 | accuracy 61.56 | uer 17.904 | wer 19.664 | raw_wer 19.664 | bleu 19.85 | wps 1850.7 | wpb 4003.4 | bsz 141.8 | num_updates 20626 | best_bleu 20.09
2023-08-10 18:13:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20626 updates
2023-08-10 18:13:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_19.8502.pt
2023-08-10 18:13:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_19.8502.pt
2023-08-10 18:13:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_19.8502.pt (epoch 14 @ 20626 updates, score 19.85) (writing took 17.74347803927958 seconds)
2023-08-10 18:13:22 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-10 18:13:22 | INFO | train | epoch 014 | loss 2.077 | trans_loss 5.117 | nll_loss 2.344 | w2v_ctc_loss 0.714 | task_loss 1.4 | contrastive_loss 0.113 | total 4138.65 | n_correct 2592.22 | ppl 5.08 | accuracy 62.635 | wps 10977.3 | ups 1.33 | wpb 8277.3 | bsz 305.7 | num_updates 20626 | lr 9.84708e-05 | gnorm 0.524 | clip 0 | loss_scale 32 | train_wall 1006 | gb_free 16.3 | wall 18265
2023-08-10 18:13:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 18:13:23 | INFO | fairseq.trainer | begin training epoch 15
2023-08-10 18:13:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 18:14:21 | INFO | train_inner | epoch 015:     74 / 1474 loss=2.073, trans_loss=5.103, nll_loss=2.326, w2v_ctc_loss=0.706, task_loss=1.407, contrastive_loss=0.153, total=4083.88, n_correct=2570.91, ppl=5.01, accuracy=62.953, wps=6898.6, ups=0.84, wpb=8167.8, bsz=300.2, num_updates=20700, lr=9.82946e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=18324
2023-08-10 18:15:29 | INFO | train_inner | epoch 015:    174 / 1474 loss=2.059, trans_loss=5.093, nll_loss=2.311, w2v_ctc_loss=0.711, task_loss=1.456, contrastive_loss=0.061, total=4115.73, n_correct=2593.65, ppl=4.96, accuracy=63.018, wps=12022.6, ups=1.46, wpb=8231.5, bsz=297.8, num_updates=20800, lr=9.80581e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=18392
2023-08-10 18:16:38 | INFO | train_inner | epoch 015:    274 / 1474 loss=2.051, trans_loss=5.094, nll_loss=2.313, w2v_ctc_loss=0.698, task_loss=1.344, contrastive_loss=0.055, total=4193.15, n_correct=2655.45, ppl=4.97, accuracy=63.328, wps=12211.1, ups=1.46, wpb=8386.3, bsz=312.6, num_updates=20900, lr=9.78232e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=68, gb_free=12.6, wall=18461
2023-08-10 18:17:47 | INFO | train_inner | epoch 015:    374 / 1474 loss=2.056, trans_loss=5.087, nll_loss=2.304, w2v_ctc_loss=0.703, task_loss=1.411, contrastive_loss=0.077, total=4167.66, n_correct=2632.44, ppl=4.94, accuracy=63.164, wps=12074.7, ups=1.45, wpb=8335.3, bsz=306, num_updates=21000, lr=9.759e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=18530
2023-08-10 18:18:55 | INFO | train_inner | epoch 015:    474 / 1474 loss=2.073, trans_loss=5.099, nll_loss=2.319, w2v_ctc_loss=0.695, task_loss=1.458, contrastive_loss=0.172, total=4074.53, n_correct=2563.05, ppl=4.99, accuracy=62.904, wps=11972, ups=1.47, wpb=8149.1, bsz=294.2, num_updates=21100, lr=9.73585e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=18598
2023-08-10 18:20:04 | INFO | train_inner | epoch 015:    574 / 1474 loss=2.057, trans_loss=5.094, nll_loss=2.314, w2v_ctc_loss=0.706, task_loss=1.45, contrastive_loss=0.061, total=4140.59, n_correct=2611.32, ppl=4.97, accuracy=63.066, wps=12023.6, ups=1.45, wpb=8281.2, bsz=298.8, num_updates=21200, lr=9.71286e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=68, gb_free=11.9, wall=18667
2023-08-10 18:21:13 | INFO | train_inner | epoch 015:    674 / 1474 loss=2.072, trans_loss=5.097, nll_loss=2.317, w2v_ctc_loss=0.71, task_loss=1.415, contrastive_loss=0.141, total=4134.99, n_correct=2609.41, ppl=4.98, accuracy=63.106, wps=11997, ups=1.45, wpb=8270, bsz=307.1, num_updates=21300, lr=9.69003e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=68, gb_free=10.4, wall=18736
2023-08-10 18:22:21 | INFO | train_inner | epoch 015:    774 / 1474 loss=2.063, trans_loss=5.105, nll_loss=2.329, w2v_ctc_loss=0.712, task_loss=1.418, contrastive_loss=0.063, total=4173.66, n_correct=2624.49, ppl=5.02, accuracy=62.882, wps=12153.9, ups=1.46, wpb=8347.3, bsz=305, num_updates=21400, lr=9.66736e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=68, gb_free=16.7, wall=18804
2023-08-10 18:23:30 | INFO | train_inner | epoch 015:    874 / 1474 loss=2.068, trans_loss=5.112, nll_loss=2.338, w2v_ctc_loss=0.717, task_loss=1.507, contrastive_loss=0.059, total=4059.35, n_correct=2547.07, ppl=5.05, accuracy=62.746, wps=11906.5, ups=1.47, wpb=8118.7, bsz=288.3, num_updates=21500, lr=9.64486e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=68, gb_free=15.5, wall=18872
2023-08-10 18:24:38 | INFO | train_inner | epoch 015:    974 / 1474 loss=2.068, trans_loss=5.105, nll_loss=2.329, w2v_ctc_loss=0.702, task_loss=1.41, contrastive_loss=0.14, total=4122.87, n_correct=2597.99, ppl=5.02, accuracy=63.014, wps=12087.9, ups=1.47, wpb=8245.7, bsz=301.7, num_updates=21600, lr=9.6225e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=68, gb_free=17.5, wall=18941
2023-08-10 18:25:47 | INFO | train_inner | epoch 015:   1074 / 1474 loss=2.094, trans_loss=5.114, nll_loss=2.342, w2v_ctc_loss=0.707, task_loss=1.314, contrastive_loss=0.298, total=4192.24, n_correct=2625.75, ppl=5.07, accuracy=62.634, wps=12067.4, ups=1.44, wpb=8384.5, bsz=325.2, num_updates=21700, lr=9.60031e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=69, gb_free=17.1, wall=19010
2023-08-10 18:26:56 | INFO | train_inner | epoch 015:   1174 / 1474 loss=2.054, trans_loss=5.1, nll_loss=2.325, w2v_ctc_loss=0.689, task_loss=1.257, contrastive_loss=0.106, total=4185, n_correct=2645.45, ppl=5.01, accuracy=63.213, wps=12204.6, ups=1.46, wpb=8370, bsz=329.3, num_updates=21800, lr=9.57826e-05, gnorm=0.521, clip=0, loss_scale=64, train_wall=68, gb_free=16.2, wall=19079
2023-08-10 18:28:04 | INFO | train_inner | epoch 015:   1274 / 1474 loss=2.065, trans_loss=5.108, nll_loss=2.334, w2v_ctc_loss=0.714, task_loss=1.423, contrastive_loss=0.063, total=4152.04, n_correct=2607.6, ppl=5.04, accuracy=62.803, wps=12130.1, ups=1.46, wpb=8304.1, bsz=303.7, num_updates=21900, lr=9.55637e-05, gnorm=0.531, clip=0, loss_scale=64, train_wall=68, gb_free=16.3, wall=19147
2023-08-10 18:29:13 | INFO | train_inner | epoch 015:   1374 / 1474 loss=2.059, trans_loss=5.109, nll_loss=2.334, w2v_ctc_loss=0.703, task_loss=1.446, contrastive_loss=0.05, total=4100.21, n_correct=2584.44, ppl=5.04, accuracy=63.032, wps=11931.1, ups=1.45, wpb=8200.4, bsz=293.6, num_updates=22000, lr=9.53463e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=68, gb_free=17.4, wall=19216
2023-08-10 18:29:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 18:29:37 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.204 | trans_loss 5.574 | nll_loss 2.85 | w2v_ctc_loss 1.246 | task_loss 4.587 | contrastive_loss 0.242 | total 4003.4 | n_correct 2468.6 | ppl 7.21 | accuracy 61.663 | uer 17.405 | wer 19.149 | raw_wer 19.149 | bleu 19.94 | wps 2064.2 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 20.09
2023-08-10 18:29:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-08-10 18:29:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_15_22000.pt
2023-08-10 18:29:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_15_22000.pt
2023-08-10 18:30:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.94) (writing took 34.290619565173984 seconds)
2023-08-10 18:31:22 | INFO | train_inner | epoch 015:   1474 / 1474 loss=2.075, trans_loss=5.114, nll_loss=2.343, w2v_ctc_loss=0.707, task_loss=1.355, contrastive_loss=0.136, total=4141.17, n_correct=2603.09, ppl=5.07, accuracy=62.859, wps=6416, ups=0.77, wpb=8282.3, bsz=314.3, num_updates=22100, lr=9.51303e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=69, gb_free=16.8, wall=19345
2023-08-10 18:31:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 18:31:47 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.228 | trans_loss 5.573 | nll_loss 2.852 | w2v_ctc_loss 1.325 | task_loss 4.614 | contrastive_loss 0.247 | total 4003.4 | n_correct 2467.3 | ppl 7.22 | accuracy 61.63 | uer 17.596 | wer 19.295 | raw_wer 19.295 | bleu 19.81 | wps 1825.7 | wpb 4003.4 | bsz 141.8 | num_updates 22100 | best_bleu 20.09
2023-08-10 18:31:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22100 updates
2023-08-10 18:31:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_19.8104.pt
2023-08-10 18:31:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_19.8104.pt
2023-08-10 18:32:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_19.8104.pt (epoch 15 @ 22100 updates, score 19.81) (writing took 17.473544204607606 seconds)
2023-08-10 18:32:05 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-10 18:32:05 | INFO | train | epoch 015 | loss 2.065 | trans_loss 5.101 | nll_loss 2.324 | w2v_ctc_loss 0.705 | task_loss 1.4 | contrastive_loss 0.111 | total 4138.65 | n_correct 2607.42 | ppl 5.01 | accuracy 63.002 | wps 10872.1 | ups 1.31 | wpb 8277.3 | bsz 305.7 | num_updates 22100 | lr 9.51303e-05 | gnorm 0.525 | clip 0 | loss_scale 64 | train_wall 1005 | gb_free 16.8 | wall 19388
2023-08-10 18:32:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 18:32:05 | INFO | fairseq.trainer | begin training epoch 16
2023-08-10 18:32:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 18:33:20 | INFO | train_inner | epoch 016:    100 / 1474 loss=2.041, trans_loss=5.07, nll_loss=2.283, w2v_ctc_loss=0.691, task_loss=1.333, contrastive_loss=0.077, total=4126.22, n_correct=2630.14, ppl=4.87, accuracy=63.742, wps=7014.7, ups=0.85, wpb=8252.4, bsz=315.6, num_updates=22200, lr=9.49158e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=67, gb_free=16, wall=19463
2023-08-10 18:34:28 | INFO | train_inner | epoch 016:    200 / 1474 loss=2.04, trans_loss=5.07, nll_loss=2.282, w2v_ctc_loss=0.688, task_loss=1.439, contrastive_loss=0.057, total=4100.6, n_correct=2609.74, ppl=4.86, accuracy=63.643, wps=12006.1, ups=1.46, wpb=8201.2, bsz=296.8, num_updates=22300, lr=9.47027e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=68, gb_free=12.5, wall=19531
2023-08-10 18:35:37 | INFO | train_inner | epoch 016:    300 / 1474 loss=2.057, trans_loss=5.079, nll_loss=2.296, w2v_ctc_loss=0.699, task_loss=1.388, contrastive_loss=0.126, total=4166.94, n_correct=2642.27, ppl=4.91, accuracy=63.41, wps=12014, ups=1.44, wpb=8333.9, bsz=308.9, num_updates=22400, lr=9.44911e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=69, gb_free=17.1, wall=19600
2023-08-10 18:36:46 | INFO | train_inner | epoch 016:    400 / 1474 loss=2.062, trans_loss=5.083, nll_loss=2.3, w2v_ctc_loss=0.703, task_loss=1.489, contrastive_loss=0.14, total=4073.3, n_correct=2580.99, ppl=4.92, accuracy=63.364, wps=11916.4, ups=1.46, wpb=8146.6, bsz=288.1, num_updates=22500, lr=9.42809e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=68, gb_free=16.9, wall=19669
2023-08-10 18:37:55 | INFO | train_inner | epoch 016:    500 / 1474 loss=2.047, trans_loss=5.079, nll_loss=2.296, w2v_ctc_loss=0.693, task_loss=1.345, contrastive_loss=0.086, total=4174.67, n_correct=2656.03, ppl=4.91, accuracy=63.623, wps=12112.5, ups=1.45, wpb=8349.3, bsz=319.1, num_updates=22600, lr=9.40721e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=68, gb_free=15.9, wall=19738
2023-08-10 18:39:03 | INFO | train_inner | epoch 016:    600 / 1474 loss=2.046, trans_loss=5.084, nll_loss=2.301, w2v_ctc_loss=0.693, task_loss=1.412, contrastive_loss=0.051, total=4124.65, n_correct=2617.28, ppl=4.93, accuracy=63.455, wps=12033.3, ups=1.46, wpb=8249.3, bsz=297.6, num_updates=22700, lr=9.38647e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=68, gb_free=16.2, wall=19806
2023-08-10 18:40:11 | INFO | train_inner | epoch 016:    700 / 1474 loss=2.049, trans_loss=5.089, nll_loss=2.308, w2v_ctc_loss=0.698, task_loss=1.436, contrastive_loss=0.054, total=4095.49, n_correct=2594.66, ppl=4.95, accuracy=63.354, wps=12095.2, ups=1.48, wpb=8191, bsz=296.3, num_updates=22800, lr=9.36586e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=67, gb_free=16.1, wall=19874
2023-08-10 18:41:19 | INFO | train_inner | epoch 016:    800 / 1474 loss=2.053, trans_loss=5.089, nll_loss=2.308, w2v_ctc_loss=0.689, task_loss=1.343, contrastive_loss=0.112, total=4174.94, n_correct=2644.94, ppl=4.95, accuracy=63.353, wps=12206.6, ups=1.46, wpb=8349.9, bsz=310.9, num_updates=22900, lr=9.34539e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=68, gb_free=16.4, wall=19942
2023-08-10 18:42:28 | INFO | train_inner | epoch 016:    900 / 1474 loss=2.051, trans_loss=5.086, nll_loss=2.305, w2v_ctc_loss=0.69, task_loss=1.355, contrastive_loss=0.105, total=4163.19, n_correct=2643.79, ppl=4.94, accuracy=63.504, wps=12179.4, ups=1.46, wpb=8326.4, bsz=310.6, num_updates=23000, lr=9.32505e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=68, gb_free=16.7, wall=20011
2023-08-10 18:43:36 | INFO | train_inner | epoch 016:   1000 / 1474 loss=2.064, trans_loss=5.099, nll_loss=2.321, w2v_ctc_loss=0.709, task_loss=1.462, contrastive_loss=0.101, total=4103.45, n_correct=2588.13, ppl=5, accuracy=63.072, wps=11963.1, ups=1.46, wpb=8206.9, bsz=298.1, num_updates=23100, lr=9.30484e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=68, gb_free=14.7, wall=20079
2023-08-10 18:44:45 | INFO | train_inner | epoch 016:   1100 / 1474 loss=2.066, trans_loss=5.105, nll_loss=2.33, w2v_ctc_loss=0.712, task_loss=1.492, contrastive_loss=0.078, total=4119.27, n_correct=2591.25, ppl=5.03, accuracy=62.906, wps=11972.7, ups=1.45, wpb=8238.5, bsz=295.3, num_updates=23200, lr=9.28477e-05, gnorm=0.531, clip=0, loss_scale=128, train_wall=68, gb_free=17.8, wall=20148
2023-08-10 18:45:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-10 18:45:55 | INFO | train_inner | epoch 016:   1201 / 1474 loss=2.047, trans_loss=5.094, nll_loss=2.316, w2v_ctc_loss=0.69, task_loss=1.471, contrastive_loss=0.058, total=4132.57, n_correct=2617.4, ppl=4.98, accuracy=63.336, wps=11859.7, ups=1.43, wpb=8265.1, bsz=298.8, num_updates=23300, lr=9.26482e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=69, gb_free=14.7, wall=20218
2023-08-10 18:47:04 | INFO | train_inner | epoch 016:   1301 / 1474 loss=2.065, trans_loss=5.096, nll_loss=2.319, w2v_ctc_loss=0.704, task_loss=1.36, contrastive_loss=0.151, total=4151.03, n_correct=2625.21, ppl=4.99, accuracy=63.242, wps=12101.1, ups=1.46, wpb=8302.1, bsz=314.5, num_updates=23400, lr=9.245e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=68, gb_free=16, wall=20286
2023-08-10 18:48:12 | INFO | train_inner | epoch 016:   1401 / 1474 loss=2.055, trans_loss=5.098, nll_loss=2.322, w2v_ctc_loss=0.7, task_loss=1.338, contrastive_loss=0.081, total=4201.47, n_correct=2657.87, ppl=5, accuracy=63.26, wps=12223.3, ups=1.45, wpb=8402.9, bsz=320.7, num_updates=23500, lr=9.22531e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=68, gb_free=15.8, wall=20355
2023-08-10 18:49:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 18:49:27 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.216 | trans_loss 5.563 | nll_loss 2.84 | w2v_ctc_loss 1.3 | task_loss 4.59 | contrastive_loss 0.248 | total 4003.4 | n_correct 2477.4 | ppl 7.16 | accuracy 61.882 | uer 17.469 | wer 19.377 | raw_wer 19.377 | bleu 20.24 | wps 2050.9 | wpb 4003.4 | bsz 141.8 | num_updates 23573 | best_bleu 20.24
2023-08-10 18:49:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23573 updates
2023-08-10 18:49:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 18:49:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 18:49:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt (epoch 16 @ 23573 updates, score 20.24) (writing took 25.37197693809867 seconds)
2023-08-10 18:49:53 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-10 18:49:53 | INFO | train | epoch 016 | loss 2.054 | trans_loss 5.088 | nll_loss 2.307 | w2v_ctc_loss 0.697 | task_loss 1.403 | contrastive_loss 0.101 | total 4137.02 | n_correct 2621.41 | ppl 4.95 | accuracy 63.365 | wps 11410.2 | ups 1.38 | wpb 8274 | bsz 305.1 | num_updates 23573 | lr 9.21102e-05 | gnorm 0.527 | clip 0 | loss_scale 64 | train_wall 1003 | gb_free 15.4 | wall 20456
2023-08-10 18:49:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 18:49:53 | INFO | fairseq.trainer | begin training epoch 17
2023-08-10 18:49:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 18:50:20 | INFO | train_inner | epoch 017:     27 / 1474 loss=2.064, trans_loss=5.082, nll_loss=2.3, w2v_ctc_loss=0.691, task_loss=1.429, contrastive_loss=0.218, total=4145.04, n_correct=2627.89, ppl=4.92, accuracy=63.398, wps=6508.5, ups=0.79, wpb=8290.1, bsz=302.4, num_updates=23600, lr=9.20575e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=68, gb_free=15.6, wall=20483
2023-08-10 18:51:28 | INFO | train_inner | epoch 017:    127 / 1474 loss=2.037, trans_loss=5.057, nll_loss=2.266, w2v_ctc_loss=0.694, task_loss=1.437, contrastive_loss=0.055, total=4117.27, n_correct=2635.05, ppl=4.81, accuracy=64, wps=12085, ups=1.47, wpb=8234.5, bsz=296.2, num_updates=23700, lr=9.1863e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=68, gb_free=17.8, wall=20551
2023-08-10 18:51:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-10 18:52:37 | INFO | train_inner | epoch 017:    228 / 1474 loss=2.036, trans_loss=5.056, nll_loss=2.266, w2v_ctc_loss=0.678, task_loss=1.354, contrastive_loss=0.11, total=4133.06, n_correct=2646.58, ppl=4.81, accuracy=64.034, wps=11933.6, ups=1.44, wpb=8266.1, bsz=310.7, num_updates=23800, lr=9.16698e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=15.8, wall=20620
2023-08-10 18:53:45 | INFO | train_inner | epoch 017:    328 / 1474 loss=2.055, trans_loss=5.067, nll_loss=2.28, w2v_ctc_loss=0.683, task_loss=1.397, contrastive_loss=0.224, total=4157.94, n_correct=2647.77, ppl=4.86, accuracy=63.68, wps=12186.7, ups=1.47, wpb=8315.9, bsz=305, num_updates=23900, lr=9.14779e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=68, gb_free=14.3, wall=20688
2023-08-10 18:54:54 | INFO | train_inner | epoch 017:    428 / 1474 loss=2.033, trans_loss=5.067, nll_loss=2.279, w2v_ctc_loss=0.683, task_loss=1.397, contrastive_loss=0.054, total=4141.8, n_correct=2643.09, ppl=4.85, accuracy=63.815, wps=12113.4, ups=1.46, wpb=8283.6, bsz=306.7, num_updates=24000, lr=9.12871e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=20757
2023-08-10 18:54:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 18:55:19 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.226 | trans_loss 5.568 | nll_loss 2.845 | w2v_ctc_loss 1.326 | task_loss 4.583 | contrastive_loss 0.247 | total 4003.4 | n_correct 2475.5 | ppl 7.19 | accuracy 61.835 | uer 17.846 | wer 19.731 | raw_wer 19.731 | bleu 19.54 | wps 1966.2 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 20.24
2023-08-10 18:55:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-08-10 18:55:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_17_24000.pt
2023-08-10 18:55:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_17_24000.pt
2023-08-10 18:55:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.54) (writing took 31.09109785221517 seconds)
2023-08-10 18:57:01 | INFO | train_inner | epoch 017:    528 / 1474 loss=2.043, trans_loss=5.07, nll_loss=2.285, w2v_ctc_loss=0.69, task_loss=1.457, contrastive_loss=0.097, total=4180.09, n_correct=2664.9, ppl=4.87, accuracy=63.752, wps=6582, ups=0.79, wpb=8360.2, bsz=307.5, num_updates=24100, lr=9.10975e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=17.1, wall=20884
2023-08-10 18:58:09 | INFO | train_inner | epoch 017:    628 / 1474 loss=2.037, trans_loss=5.076, nll_loss=2.291, w2v_ctc_loss=0.686, task_loss=1.413, contrastive_loss=0.05, total=4166.6, n_correct=2657.43, ppl=4.9, accuracy=63.779, wps=12139, ups=1.46, wpb=8333.2, bsz=302.3, num_updates=24200, lr=9.09091e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=20952
2023-08-10 18:59:18 | INFO | train_inner | epoch 017:    728 / 1474 loss=2.052, trans_loss=5.079, nll_loss=2.296, w2v_ctc_loss=0.701, task_loss=1.386, contrastive_loss=0.095, total=4168.97, n_correct=2649.3, ppl=4.91, accuracy=63.548, wps=12111.9, ups=1.45, wpb=8337.9, bsz=308.4, num_updates=24300, lr=9.07218e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=21021
2023-08-10 19:00:26 | INFO | train_inner | epoch 017:    828 / 1474 loss=2.041, trans_loss=5.078, nll_loss=2.294, w2v_ctc_loss=0.69, task_loss=1.41, contrastive_loss=0.062, total=4097.38, n_correct=2607.91, ppl=4.9, accuracy=63.648, wps=12058.1, ups=1.47, wpb=8194.8, bsz=297.3, num_updates=24400, lr=9.05357e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=67, gb_free=10.4, wall=21089
2023-08-10 19:01:34 | INFO | train_inner | epoch 017:    928 / 1474 loss=2.038, trans_loss=5.078, nll_loss=2.296, w2v_ctc_loss=0.683, task_loss=1.383, contrastive_loss=0.06, total=4105.01, n_correct=2611.05, ppl=4.91, accuracy=63.606, wps=12190.2, ups=1.48, wpb=8210, bsz=304.1, num_updates=24500, lr=9.03508e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=21156
2023-08-10 19:02:42 | INFO | train_inner | epoch 017:   1028 / 1474 loss=2.042, trans_loss=5.079, nll_loss=2.296, w2v_ctc_loss=0.692, task_loss=1.4, contrastive_loss=0.064, total=4105.88, n_correct=2610.48, ppl=4.91, accuracy=63.579, wps=11992.7, ups=1.46, wpb=8211.8, bsz=303.4, num_updates=24600, lr=9.0167e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=21225
2023-08-10 19:03:50 | INFO | train_inner | epoch 017:   1128 / 1474 loss=2.038, trans_loss=5.078, nll_loss=2.295, w2v_ctc_loss=0.685, task_loss=1.433, contrastive_loss=0.055, total=4095.58, n_correct=2606.34, ppl=4.91, accuracy=63.638, wps=12002.4, ups=1.47, wpb=8191.2, bsz=298.5, num_updates=24700, lr=8.99843e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=68, gb_free=15.4, wall=21293
2023-08-10 19:05:00 | INFO | train_inner | epoch 017:   1228 / 1474 loss=2.074, trans_loss=5.089, nll_loss=2.311, w2v_ctc_loss=0.682, task_loss=1.373, contrastive_loss=0.289, total=4162.14, n_correct=2631.38, ppl=4.96, accuracy=63.222, wps=12018.6, ups=1.44, wpb=8324.3, bsz=320.2, num_updates=24800, lr=8.98027e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=21362
2023-08-10 19:06:08 | INFO | train_inner | epoch 017:   1328 / 1474 loss=2.05, trans_loss=5.086, nll_loss=2.306, w2v_ctc_loss=0.679, task_loss=1.393, contrastive_loss=0.132, total=4149.03, n_correct=2633.54, ppl=4.95, accuracy=63.474, wps=12099.9, ups=1.46, wpb=8298.1, bsz=306.7, num_updates=24900, lr=8.96221e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=21431
2023-08-10 19:07:17 | INFO | train_inner | epoch 017:   1428 / 1474 loss=2.04, trans_loss=5.084, nll_loss=2.303, w2v_ctc_loss=0.686, task_loss=1.408, contrastive_loss=0.055, total=4117.13, n_correct=2616.1, ppl=4.93, accuracy=63.542, wps=12000.1, ups=1.46, wpb=8234.3, bsz=303.7, num_updates=25000, lr=8.94427e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=68, gb_free=17.5, wall=21500
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:0')
2023-08-10 19:07:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:6')
2023-08-10 19:08:13 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.222 | trans_loss 5.557 | nll_loss 2.833 | w2v_ctc_loss 1.344 | task_loss 4.636 | contrastive_loss 0.243 | total 4003.4 | n_correct 2488.3 | ppl 7.12 | accuracy 62.155 | uer 17.548 | wer 19.179 | raw_wer 19.179 | bleu 20.14 | wps 2029.7 | wpb 4003.4 | bsz 141.8 | num_updates 25046 | best_bleu 20.24
2023-08-10 19:08:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25046 updates
2023-08-10 19:08:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.1408.pt
2023-08-10 19:08:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.1408.pt
2023-08-10 19:08:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.1408.pt (epoch 17 @ 25046 updates, score 20.14) (writing took 19.23247778043151 seconds)
2023-08-10 19:08:33 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-10 19:08:33 | INFO | train | epoch 017 | loss 2.044 | trans_loss 5.074 | nll_loss 2.29 | w2v_ctc_loss 0.687 | task_loss 1.403 | contrastive_loss 0.099 | total 4136.62 | n_correct 2633.69 | ppl 4.89 | accuracy 63.668 | wps 10883 | ups 1.32 | wpb 8273.2 | bsz 305.1 | num_updates 25046 | lr 8.93605e-05 | gnorm 0.526 | clip 0 | loss_scale 32 | train_wall 1003 | gb_free 16.3 | wall 21575
2023-08-10 19:08:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 19:08:33 | INFO | fairseq.trainer | begin training epoch 18
2023-08-10 19:08:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 19:09:18 | INFO | train_inner | epoch 018:     54 / 1474 loss=2.037, trans_loss=5.068, nll_loss=2.281, w2v_ctc_loss=0.691, task_loss=1.426, contrastive_loss=0.063, total=4138.21, n_correct=2641.21, ppl=4.86, accuracy=63.825, wps=6821, ups=0.82, wpb=8276.4, bsz=303.2, num_updates=25100, lr=8.92644e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=17.7, wall=21621
2023-08-10 19:10:27 | INFO | train_inner | epoch 018:    154 / 1474 loss=2.035, trans_loss=5.044, nll_loss=2.25, w2v_ctc_loss=0.662, task_loss=1.332, contrastive_loss=0.182, total=4158.88, n_correct=2669.77, ppl=4.76, accuracy=64.194, wps=12016.1, ups=1.44, wpb=8317.8, bsz=314, num_updates=25200, lr=8.90871e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=21690
2023-08-10 19:11:36 | INFO | train_inner | epoch 018:    254 / 1474 loss=2.017, trans_loss=5.042, nll_loss=2.248, w2v_ctc_loss=0.67, task_loss=1.357, contrastive_loss=0.055, total=4164.11, n_correct=2681.69, ppl=4.75, accuracy=64.4, wps=12058.1, ups=1.45, wpb=8328.2, bsz=312.5, num_updates=25300, lr=8.89108e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=14.8, wall=21759
2023-08-10 19:12:45 | INFO | train_inner | epoch 018:    354 / 1474 loss=2.028, trans_loss=5.053, nll_loss=2.261, w2v_ctc_loss=0.678, task_loss=1.42, contrastive_loss=0.068, total=4163.13, n_correct=2670.96, ppl=4.79, accuracy=64.157, wps=12098.1, ups=1.45, wpb=8326.3, bsz=301.5, num_updates=25400, lr=8.87357e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=21828
2023-08-10 19:13:54 | INFO | train_inner | epoch 018:    454 / 1474 loss=2.045, trans_loss=5.061, nll_loss=2.273, w2v_ctc_loss=0.68, task_loss=1.492, contrastive_loss=0.159, total=4087.83, n_correct=2610.62, ppl=4.83, accuracy=63.863, wps=11820.8, ups=1.45, wpb=8175.7, bsz=295.3, num_updates=25500, lr=8.85615e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=21897
2023-08-10 19:15:03 | INFO | train_inner | epoch 018:    554 / 1474 loss=2.019, trans_loss=5.046, nll_loss=2.254, w2v_ctc_loss=0.67, task_loss=1.259, contrastive_loss=0.069, total=4204.41, n_correct=2702.75, ppl=4.77, accuracy=64.284, wps=12301.5, ups=1.46, wpb=8408.8, bsz=328, num_updates=25600, lr=8.83883e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=17.4, wall=21966
2023-08-10 19:16:11 | INFO | train_inner | epoch 018:    654 / 1474 loss=2.046, trans_loss=5.072, nll_loss=2.287, w2v_ctc_loss=0.684, task_loss=1.449, contrastive_loss=0.136, total=4096.81, n_correct=2610.94, ppl=4.88, accuracy=63.731, wps=11992.9, ups=1.46, wpb=8193.6, bsz=298.9, num_updates=25700, lr=8.82162e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=22034
2023-08-10 19:17:20 | INFO | train_inner | epoch 018:    754 / 1474 loss=2.054, trans_loss=5.066, nll_loss=2.281, w2v_ctc_loss=0.687, task_loss=1.338, contrastive_loss=0.225, total=4208.29, n_correct=2682.61, ppl=4.86, accuracy=63.746, wps=12182.2, ups=1.45, wpb=8416.6, bsz=322.8, num_updates=25800, lr=8.80451e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=69, gb_free=17.8, wall=22103
2023-08-10 19:18:29 | INFO | train_inner | epoch 018:    854 / 1474 loss=2.03, trans_loss=5.066, nll_loss=2.28, w2v_ctc_loss=0.678, task_loss=1.424, contrastive_loss=0.047, total=4166.81, n_correct=2662.25, ppl=4.86, accuracy=63.892, wps=12123.6, ups=1.45, wpb=8333.6, bsz=301.9, num_updates=25900, lr=8.7875e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=68, gb_free=12.4, wall=22172
2023-08-10 19:19:37 | INFO | train_inner | epoch 018:    954 / 1474 loss=2.022, trans_loss=5.057, nll_loss=2.268, w2v_ctc_loss=0.667, task_loss=1.303, contrastive_loss=0.067, total=4142.65, n_correct=2657.31, ppl=4.82, accuracy=64.145, wps=12212.5, ups=1.47, wpb=8285.3, bsz=316.1, num_updates=26000, lr=8.77058e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=67, gb_free=14.8, wall=22240
2023-08-10 19:19:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 19:20:03 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.226 | trans_loss 5.561 | nll_loss 2.832 | w2v_ctc_loss 1.336 | task_loss 4.63 | contrastive_loss 0.252 | total 4003.4 | n_correct 2480.6 | ppl 7.12 | accuracy 61.962 | uer 17.726 | wer 19.474 | raw_wer 19.474 | bleu 20.13 | wps 1828.4 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 20.24
2023-08-10 19:20:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-08-10 19:20:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_18_26000.pt
2023-08-10 19:20:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_18_26000.pt
2023-08-10 19:20:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 20.13) (writing took 19.81285348162055 seconds)
2023-08-10 19:21:32 | INFO | train_inner | epoch 018:   1054 / 1474 loss=2.029, trans_loss=5.066, nll_loss=2.28, w2v_ctc_loss=0.672, task_loss=1.461, contrastive_loss=0.057, total=4137.77, n_correct=2644.72, ppl=4.86, accuracy=63.917, wps=7158.5, ups=0.87, wpb=8275.5, bsz=300.5, num_updates=26100, lr=8.75376e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=68, gb_free=17.3, wall=22355
2023-08-10 19:22:41 | INFO | train_inner | epoch 018:   1154 / 1474 loss=2.039, trans_loss=5.055, nll_loss=2.266, w2v_ctc_loss=0.675, task_loss=1.328, contrastive_loss=0.163, total=4153.69, n_correct=2665.82, ppl=4.81, accuracy=64.18, wps=12112.6, ups=1.46, wpb=8307.4, bsz=314.9, num_updates=26200, lr=8.73704e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=68, gb_free=15.1, wall=22424
2023-08-10 19:23:49 | INFO | train_inner | epoch 018:   1254 / 1474 loss=2.035, trans_loss=5.077, nll_loss=2.294, w2v_ctc_loss=0.68, task_loss=1.501, contrastive_loss=0.05, total=4087.62, n_correct=2604.98, ppl=4.9, accuracy=63.729, wps=11952.9, ups=1.46, wpb=8175.2, bsz=287.1, num_updates=26300, lr=8.72041e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=68, gb_free=16.6, wall=22492
2023-08-10 19:24:57 | INFO | train_inner | epoch 018:   1354 / 1474 loss=2.047, trans_loss=5.082, nll_loss=2.302, w2v_ctc_loss=0.695, task_loss=1.492, contrastive_loss=0.074, total=4070.69, n_correct=2586.86, ppl=4.93, accuracy=63.548, wps=12027.1, ups=1.48, wpb=8141.4, bsz=291.7, num_updates=26400, lr=8.70388e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=67, gb_free=17.3, wall=22560
2023-08-10 19:26:06 | INFO | train_inner | epoch 018:   1454 / 1474 loss=2.037, trans_loss=5.075, nll_loss=2.293, w2v_ctc_loss=0.685, task_loss=1.48, contrastive_loss=0.062, total=4113.2, n_correct=2621.14, ppl=4.9, accuracy=63.725, wps=11957.1, ups=1.45, wpb=8226.4, bsz=297.5, num_updates=26500, lr=8.68744e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=68, gb_free=16.4, wall=22629
2023-08-10 19:26:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 19:26:44 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.226 | trans_loss 5.556 | nll_loss 2.832 | w2v_ctc_loss 1.353 | task_loss 4.627 | contrastive_loss 0.247 | total 4003.4 | n_correct 2480.2 | ppl 7.12 | accuracy 61.952 | uer 17.233 | wer 19.015 | raw_wer 19.015 | bleu 19.56 | wps 2012.6 | wpb 4003.4 | bsz 141.8 | num_updates 26520 | best_bleu 20.24
2023-08-10 19:26:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26520 updates
2023-08-10 19:26:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_last.pt
2023-08-10 19:26:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_last.pt
2023-08-10 19:26:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_last.pt (epoch 18 @ 26520 updates, score 19.56) (writing took 13.323144791647792 seconds)
2023-08-10 19:26:58 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-10 19:26:58 | INFO | train | epoch 018 | loss 2.035 | trans_loss 5.061 | nll_loss 2.274 | w2v_ctc_loss 0.677 | task_loss 1.4 | contrastive_loss 0.104 | total 4138.65 | n_correct 2647.46 | ppl 4.84 | accuracy 63.969 | wps 11040.4 | ups 1.33 | wpb 8277.3 | bsz 305.7 | num_updates 26520 | lr 8.68417e-05 | gnorm 0.528 | clip 0 | loss_scale 64 | train_wall 1005 | gb_free 15.8 | wall 22681
2023-08-10 19:26:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 19:26:58 | INFO | fairseq.trainer | begin training epoch 19
2023-08-10 19:26:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 19:28:00 | INFO | train_inner | epoch 019:     80 / 1474 loss=2.025, trans_loss=5.038, nll_loss=2.243, w2v_ctc_loss=0.671, task_loss=1.405, contrastive_loss=0.113, total=4102.06, n_correct=2639.55, ppl=4.73, accuracy=64.347, wps=7187.4, ups=0.88, wpb=8204.1, bsz=296.9, num_updates=26600, lr=8.6711e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=68, gb_free=17.4, wall=22743
2023-08-10 19:29:09 | INFO | train_inner | epoch 019:    180 / 1474 loss=2.022, trans_loss=5.031, nll_loss=2.234, w2v_ctc_loss=0.678, task_loss=1.307, contrastive_loss=0.1, total=4227.7, n_correct=2730.62, ppl=4.71, accuracy=64.589, wps=12281.1, ups=1.45, wpb=8455.4, bsz=324.8, num_updates=26700, lr=8.65485e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=68, gb_free=17, wall=22812
2023-08-10 19:30:17 | INFO | train_inner | epoch 019:    280 / 1474 loss=2.013, trans_loss=5.032, nll_loss=2.235, w2v_ctc_loss=0.671, task_loss=1.382, contrastive_loss=0.048, total=4187.34, n_correct=2705.74, ppl=4.71, accuracy=64.617, wps=12205.2, ups=1.46, wpb=8374.7, bsz=306.4, num_updates=26800, lr=8.63868e-05, gnorm=0.519, clip=0, loss_scale=64, train_wall=68, gb_free=15.8, wall=22880
2023-08-10 19:30:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-10 19:31:27 | INFO | train_inner | epoch 019:    381 / 1474 loss=2.021, trans_loss=5.037, nll_loss=2.243, w2v_ctc_loss=0.661, task_loss=1.399, contrastive_loss=0.11, total=4159.99, n_correct=2681.94, ppl=4.73, accuracy=64.47, wps=12001.6, ups=1.44, wpb=8320, bsz=306.9, num_updates=26900, lr=8.62261e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=22950
2023-08-10 19:32:35 | INFO | train_inner | epoch 019:    481 / 1474 loss=2.023, trans_loss=5.047, nll_loss=2.255, w2v_ctc_loss=0.677, task_loss=1.438, contrastive_loss=0.062, total=4115.22, n_correct=2647.3, ppl=4.77, accuracy=64.329, wps=12074.1, ups=1.47, wpb=8230.4, bsz=301.9, num_updates=27000, lr=8.60663e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=15.1, wall=23018
2023-08-10 19:33:44 | INFO | train_inner | epoch 019:    581 / 1474 loss=2.024, trans_loss=5.043, nll_loss=2.251, w2v_ctc_loss=0.667, task_loss=1.372, contrastive_loss=0.124, total=4129.22, n_correct=2659.65, ppl=4.76, accuracy=64.41, wps=12001.8, ups=1.45, wpb=8258.4, bsz=306, num_updates=27100, lr=8.59074e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=23087
2023-08-10 19:34:52 | INFO | train_inner | epoch 019:    681 / 1474 loss=2.008, trans_loss=5.043, nll_loss=2.252, w2v_ctc_loss=0.654, task_loss=1.276, contrastive_loss=0.054, total=4197.2, n_correct=2708.07, ppl=4.76, accuracy=64.521, wps=12269.2, ups=1.46, wpb=8394.4, bsz=320.8, num_updates=27200, lr=8.57493e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=68, gb_free=14.6, wall=23155
2023-08-10 19:36:01 | INFO | train_inner | epoch 019:    781 / 1474 loss=2.022, trans_loss=5.045, nll_loss=2.253, w2v_ctc_loss=0.677, task_loss=1.407, contrastive_loss=0.066, total=4142.6, n_correct=2664.5, ppl=4.77, accuracy=64.32, wps=12048.6, ups=1.45, wpb=8285.2, bsz=305.1, num_updates=27300, lr=8.55921e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=23224
2023-08-10 19:37:10 | INFO | train_inner | epoch 019:    881 / 1474 loss=2.025, trans_loss=5.057, nll_loss=2.268, w2v_ctc_loss=0.675, task_loss=1.429, contrastive_loss=0.051, total=4153.47, n_correct=2659.45, ppl=4.82, accuracy=64.03, wps=12102.3, ups=1.46, wpb=8306.9, bsz=303.1, num_updates=27400, lr=8.54358e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=23293
2023-08-10 19:38:19 | INFO | train_inner | epoch 019:    981 / 1474 loss=2.057, trans_loss=5.068, nll_loss=2.284, w2v_ctc_loss=0.672, task_loss=1.399, contrastive_loss=0.285, total=4101.29, n_correct=2616.94, ppl=4.87, accuracy=63.808, wps=11791.1, ups=1.44, wpb=8202.6, bsz=309.9, num_updates=27500, lr=8.52803e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=23362
2023-08-10 19:39:28 | INFO | train_inner | epoch 019:   1081 / 1474 loss=2.033, trans_loss=5.068, nll_loss=2.283, w2v_ctc_loss=0.672, task_loss=1.501, contrastive_loss=0.091, total=4036.97, n_correct=2583.92, ppl=4.87, accuracy=64.006, wps=11813, ups=1.46, wpb=8073.9, bsz=291, num_updates=27600, lr=8.51257e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=14.6, wall=23430
2023-08-10 19:40:36 | INFO | train_inner | epoch 019:   1181 / 1474 loss=2.048, trans_loss=5.066, nll_loss=2.281, w2v_ctc_loss=0.68, task_loss=1.42, contrastive_loss=0.175, total=4137.49, n_correct=2639.8, ppl=4.86, accuracy=63.802, wps=12017.5, ups=1.45, wpb=8275, bsz=307.7, num_updates=27700, lr=8.49719e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=14.6, wall=23499
2023-08-10 19:41:45 | INFO | train_inner | epoch 019:   1281 / 1474 loss=2.029, trans_loss=5.067, nll_loss=2.281, w2v_ctc_loss=0.668, task_loss=1.418, contrastive_loss=0.072, total=4141.89, n_correct=2650.46, ppl=4.86, accuracy=63.992, wps=12149.7, ups=1.47, wpb=8283.8, bsz=300.1, num_updates=27800, lr=8.48189e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=68, gb_free=15.5, wall=23568
2023-08-10 19:42:53 | INFO | train_inner | epoch 019:   1381 / 1474 loss=2.026, trans_loss=5.061, nll_loss=2.275, w2v_ctc_loss=0.672, task_loss=1.43, contrastive_loss=0.059, total=4133.26, n_correct=2649.74, ppl=4.84, accuracy=64.108, wps=12106.5, ups=1.46, wpb=8266.5, bsz=301, num_updates=27900, lr=8.46668e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=23636
2023-08-10 19:43:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 19:44:22 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.216 | trans_loss 5.555 | nll_loss 2.829 | w2v_ctc_loss 1.323 | task_loss 4.635 | contrastive_loss 0.249 | total 4003.4 | n_correct 2490.3 | ppl 7.1 | accuracy 62.205 | uer 17.323 | wer 19 | raw_wer 19 | bleu 20.15 | wps 1963.9 | wpb 4003.4 | bsz 141.8 | num_updates 27993 | best_bleu 20.24
2023-08-10 19:44:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27993 updates
2023-08-10 19:44:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.1503.pt
2023-08-10 19:44:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.1503.pt
2023-08-10 19:44:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.1503.pt (epoch 19 @ 27993 updates, score 20.15) (writing took 14.616919292137027 seconds)
2023-08-10 19:44:37 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-10 19:44:37 | INFO | train | epoch 019 | loss 2.027 | trans_loss 5.05 | nll_loss 2.26 | w2v_ctc_loss 0.671 | task_loss 1.401 | contrastive_loss 0.1 | total 4138.07 | n_correct 2658.35 | ppl 4.79 | accuracy 64.241 | wps 11507.4 | ups 1.39 | wpb 8276.1 | bsz 305.4 | num_updates 27993 | lr 8.4526e-05 | gnorm 0.527 | clip 0 | loss_scale 32 | train_wall 1004 | gb_free 17.3 | wall 23740
2023-08-10 19:44:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 19:44:37 | INFO | fairseq.trainer | begin training epoch 20
2023-08-10 19:44:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 19:44:49 | INFO | train_inner | epoch 020:      7 / 1474 loss=2.029, trans_loss=5.053, nll_loss=2.265, w2v_ctc_loss=0.664, task_loss=1.412, contrastive_loss=0.143, total=4119.08, n_correct=2645, ppl=4.81, accuracy=64.213, wps=7068.3, ups=0.86, wpb=8238.2, bsz=304.1, num_updates=28000, lr=8.45154e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=23752
2023-08-10 19:44:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 19:45:15 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.211 | trans_loss 5.556 | nll_loss 2.829 | w2v_ctc_loss 1.306 | task_loss 4.626 | contrastive_loss 0.246 | total 4003.4 | n_correct 2490.6 | ppl 7.11 | accuracy 62.212 | uer 17.222 | wer 18.937 | raw_wer 18.937 | bleu 20.14 | wps 1979.3 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.24
2023-08-10 19:45:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-08-10 19:45:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_20_28000.pt
2023-08-10 19:45:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_20_28000.pt
2023-08-10 19:45:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 20.14) (writing took 16.026468781754375 seconds)
2023-08-10 19:46:41 | INFO | train_inner | epoch 020:    107 / 1474 loss=2.002, trans_loss=5.015, nll_loss=2.214, w2v_ctc_loss=0.655, task_loss=1.352, contrastive_loss=0.066, total=4195.03, n_correct=2725.47, ppl=4.64, accuracy=64.969, wps=7539.9, ups=0.9, wpb=8390.1, bsz=313.7, num_updates=28100, lr=8.43649e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=14.9, wall=23864
2023-08-10 19:47:50 | INFO | train_inner | epoch 020:    207 / 1474 loss=2.014, trans_loss=5.026, nll_loss=2.227, w2v_ctc_loss=0.66, task_loss=1.454, contrastive_loss=0.117, total=4154.14, n_correct=2689.94, ppl=4.68, accuracy=64.753, wps=12074.6, ups=1.45, wpb=8308.3, bsz=301, num_updates=28200, lr=8.42152e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=23932
2023-08-10 19:48:58 | INFO | train_inner | epoch 020:    307 / 1474 loss=2.002, trans_loss=5.02, nll_loss=2.221, w2v_ctc_loss=0.662, task_loss=1.261, contrastive_loss=0.057, total=4188.05, n_correct=2713.99, ppl=4.66, accuracy=64.803, wps=12217.7, ups=1.46, wpb=8376.1, bsz=326.2, num_updates=28300, lr=8.40663e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=68, gb_free=15.5, wall=24001
2023-08-10 19:50:07 | INFO | train_inner | epoch 020:    407 / 1474 loss=2.005, trans_loss=5.026, nll_loss=2.228, w2v_ctc_loss=0.655, task_loss=1.419, contrastive_loss=0.055, total=4115.16, n_correct=2664.46, ppl=4.68, accuracy=64.747, wps=11975.7, ups=1.46, wpb=8230.3, bsz=297, num_updates=28400, lr=8.39181e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=68, gb_free=15.4, wall=24070
2023-08-10 19:51:15 | INFO | train_inner | epoch 020:    507 / 1474 loss=2.024, trans_loss=5.042, nll_loss=2.249, w2v_ctc_loss=0.66, task_loss=1.434, contrastive_loss=0.142, total=4108.46, n_correct=2646.82, ppl=4.75, accuracy=64.424, wps=12006.9, ups=1.46, wpb=8216.9, bsz=300.4, num_updates=28500, lr=8.37708e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=24138
2023-08-10 19:52:23 | INFO | train_inner | epoch 020:    607 / 1474 loss=2.03, trans_loss=5.042, nll_loss=2.249, w2v_ctc_loss=0.666, task_loss=1.473, contrastive_loss=0.144, total=4094.9, n_correct=2632.68, ppl=4.75, accuracy=64.292, wps=12021.3, ups=1.47, wpb=8189.8, bsz=296.1, num_updates=28600, lr=8.36242e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=68, gb_free=11.8, wall=24206
2023-08-10 19:53:32 | INFO | train_inner | epoch 020:    707 / 1474 loss=2.014, trans_loss=5.042, nll_loss=2.249, w2v_ctc_loss=0.668, task_loss=1.404, contrastive_loss=0.049, total=4140.23, n_correct=2668.54, ppl=4.75, accuracy=64.454, wps=12130.5, ups=1.46, wpb=8280.5, bsz=300.6, num_updates=28700, lr=8.34784e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=24275
2023-08-10 19:54:40 | INFO | train_inner | epoch 020:    807 / 1474 loss=2.015, trans_loss=5.041, nll_loss=2.249, w2v_ctc_loss=0.669, task_loss=1.389, contrastive_loss=0.053, total=4140.66, n_correct=2671.37, ppl=4.75, accuracy=64.516, wps=12134.6, ups=1.47, wpb=8281.3, bsz=305.6, num_updates=28800, lr=8.33333e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=17.5, wall=24343
2023-08-10 19:54:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-10 19:55:50 | INFO | train_inner | epoch 020:    908 / 1474 loss=2.039, trans_loss=5.046, nll_loss=2.256, w2v_ctc_loss=0.666, task_loss=1.37, contrastive_loss=0.24, total=4136.06, n_correct=2661.58, ppl=4.78, accuracy=64.351, wps=11818.5, ups=1.43, wpb=8272.1, bsz=315.6, num_updates=28900, lr=8.3189e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=17.4, wall=24413
2023-08-10 19:56:59 | INFO | train_inner | epoch 020:   1008 / 1474 loss=2.013, trans_loss=5.044, nll_loss=2.253, w2v_ctc_loss=0.659, task_loss=1.395, contrastive_loss=0.057, total=4168.14, n_correct=2686.74, ppl=4.77, accuracy=64.459, wps=12054.4, ups=1.45, wpb=8336.3, bsz=307.3, num_updates=29000, lr=8.30455e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=24482
2023-08-10 19:58:08 | INFO | train_inner | epoch 020:   1108 / 1474 loss=2.033, trans_loss=5.046, nll_loss=2.256, w2v_ctc_loss=0.662, task_loss=1.348, contrastive_loss=0.189, total=4166.49, n_correct=2681.82, ppl=4.78, accuracy=64.366, wps=12179.9, ups=1.46, wpb=8333, bsz=315.4, num_updates=29100, lr=8.29027e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=68, gb_free=14.7, wall=24550
2023-08-10 19:59:16 | INFO | train_inner | epoch 020:   1208 / 1474 loss=2.022, trans_loss=5.046, nll_loss=2.254, w2v_ctc_loss=0.68, task_loss=1.545, contrastive_loss=0.048, total=4029.18, n_correct=2592.82, ppl=4.77, accuracy=64.351, wps=11735.5, ups=1.46, wpb=8058.4, bsz=284, num_updates=29200, lr=8.27606e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=68, gb_free=11.6, wall=24619
2023-08-10 20:00:25 | INFO | train_inner | epoch 020:   1308 / 1474 loss=2.017, trans_loss=5.052, nll_loss=2.263, w2v_ctc_loss=0.664, task_loss=1.473, contrastive_loss=0.051, total=4123.21, n_correct=2655.83, ppl=4.8, accuracy=64.412, wps=11899.7, ups=1.44, wpb=8246.4, bsz=297.1, num_updates=29300, lr=8.26192e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=24688
2023-08-10 20:01:34 | INFO | train_inner | epoch 020:   1408 / 1474 loss=2.017, trans_loss=5.049, nll_loss=2.259, w2v_ctc_loss=0.665, task_loss=1.477, contrastive_loss=0.051, total=4116.28, n_correct=2647.66, ppl=4.79, accuracy=64.322, wps=11972, ups=1.45, wpb=8232.6, bsz=295, num_updates=29400, lr=8.24786e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=68, gb_free=17.4, wall=24757
2023-08-10 20:02:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 20:02:43 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.203 | trans_loss 5.553 | nll_loss 2.825 | w2v_ctc_loss 1.283 | task_loss 4.604 | contrastive_loss 0.247 | total 4003.4 | n_correct 2483.3 | ppl 7.09 | accuracy 62.03 | uer 17.163 | wer 18.892 | raw_wer 18.892 | bleu 20.05 | wps 2128.1 | wpb 4003.4 | bsz 141.8 | num_updates 29466 | best_bleu 20.24
2023-08-10 20:02:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29466 updates
2023-08-10 20:02:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.0500.pt
2023-08-10 20:02:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.0500.pt
2023-08-10 20:03:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.0500.pt (epoch 20 @ 29466 updates, score 20.05) (writing took 37.05439202673733 seconds)
2023-08-10 20:03:20 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-10 20:03:20 | INFO | train | epoch 020 | loss 2.018 | trans_loss 5.039 | nll_loss 2.245 | w2v_ctc_loss 0.663 | task_loss 1.403 | contrastive_loss 0.094 | total 4136.98 | n_correct 2668.92 | ppl 4.74 | accuracy 64.514 | wps 10849.9 | ups 1.31 | wpb 8274 | bsz 305.1 | num_updates 29466 | lr 8.23862e-05 | gnorm 0.528 | clip 0 | loss_scale 16 | train_wall 1005 | gb_free 16.1 | wall 24863
2023-08-10 20:03:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 20:03:21 | INFO | fairseq.trainer | begin training epoch 21
2023-08-10 20:03:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 20:03:52 | INFO | train_inner | epoch 021:     34 / 1474 loss=2.027, trans_loss=5.043, nll_loss=2.251, w2v_ctc_loss=0.661, task_loss=1.331, contrastive_loss=0.168, total=4152.26, n_correct=2678.59, ppl=4.76, accuracy=64.509, wps=6022, ups=0.73, wpb=8304.5, bsz=316.3, num_updates=29500, lr=8.23387e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=24895
2023-08-10 20:05:01 | INFO | train_inner | epoch 021:    134 / 1474 loss=2.011, trans_loss=5.011, nll_loss=2.209, w2v_ctc_loss=0.649, task_loss=1.309, contrastive_loss=0.161, total=4195.08, n_correct=2729.44, ppl=4.62, accuracy=65.063, wps=12108.2, ups=1.44, wpb=8390.2, bsz=319.6, num_updates=29600, lr=8.21995e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=69, gb_free=16.9, wall=24964
2023-08-10 20:06:11 | INFO | train_inner | epoch 021:    234 / 1474 loss=2, trans_loss=5.016, nll_loss=2.215, w2v_ctc_loss=0.64, task_loss=1.334, contrastive_loss=0.117, total=4155.31, n_correct=2701.85, ppl=4.64, accuracy=65.022, wps=12011.4, ups=1.45, wpb=8310.6, bsz=312.6, num_updates=29700, lr=8.2061e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=16.7, wall=25034
2023-08-10 20:07:20 | INFO | train_inner | epoch 021:    334 / 1474 loss=2.008, trans_loss=5.017, nll_loss=2.217, w2v_ctc_loss=0.656, task_loss=1.386, contrastive_loss=0.119, total=4151.51, n_correct=2693.99, ppl=4.65, accuracy=64.892, wps=12025.9, ups=1.45, wpb=8303, bsz=310.8, num_updates=29800, lr=8.19232e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=15.5, wall=25103
2023-08-10 20:08:28 | INFO | train_inner | epoch 021:    434 / 1474 loss=1.995, trans_loss=5.017, nll_loss=2.216, w2v_ctc_loss=0.646, task_loss=1.356, contrastive_loss=0.045, total=4180.85, n_correct=2718.31, ppl=4.65, accuracy=65.018, wps=12211, ups=1.46, wpb=8361.7, bsz=306.8, num_updates=29900, lr=8.17861e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=25171
2023-08-10 20:09:37 | INFO | train_inner | epoch 021:    534 / 1474 loss=1.999, trans_loss=5.017, nll_loss=2.217, w2v_ctc_loss=0.657, task_loss=1.46, contrastive_loss=0.045, total=4083.98, n_correct=2656.51, ppl=4.65, accuracy=65.047, wps=11924.8, ups=1.46, wpb=8168, bsz=295.1, num_updates=30000, lr=8.16497e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=68, gb_free=12.9, wall=25240
2023-08-10 20:09:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 20:10:00 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.215 | trans_loss 5.562 | nll_loss 2.836 | w2v_ctc_loss 1.305 | task_loss 4.619 | contrastive_loss 0.246 | total 4003.4 | n_correct 2479.5 | ppl 7.14 | accuracy 61.935 | uer 17.11 | wer 18.784 | raw_wer 18.784 | bleu 20.03 | wps 2092 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.24
2023-08-10 20:10:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-08-10 20:10:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_21_30000.pt
2023-08-10 20:10:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_21_30000.pt
2023-08-10 20:10:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 20.03) (writing took 39.692596828565 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:0')
2023-08-10 20:11:54 | INFO | train_inner | epoch 021:    634 / 1474 loss=2.02, trans_loss=5.025, nll_loss=2.228, w2v_ctc_loss=0.648, task_loss=1.386, contrastive_loss=0.216, total=4215.41, n_correct=2729.9, ppl=4.68, accuracy=64.76, wps=6140.6, ups=0.73, wpb=8430.8, bsz=315.4, num_updates=30100, lr=8.15139e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=70, gb_free=11.1, wall=25377
2023-08-10 20:13:03 | INFO | train_inner | epoch 021:    734 / 1474 loss=2.01, trans_loss=5.034, nll_loss=2.24, w2v_ctc_loss=0.657, task_loss=1.391, contrastive_loss=0.074, total=4152.97, n_correct=2685.67, ppl=4.72, accuracy=64.669, wps=12028.4, ups=1.45, wpb=8305.9, bsz=309.3, num_updates=30200, lr=8.13788e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=25446
2023-08-10 20:14:12 | INFO | train_inner | epoch 021:    834 / 1474 loss=2.015, trans_loss=5.039, nll_loss=2.246, w2v_ctc_loss=0.656, task_loss=1.481, contrastive_loss=0.087, total=4066.93, n_correct=2625.86, ppl=4.74, accuracy=64.566, wps=11830.7, ups=1.45, wpb=8133.9, bsz=294.4, num_updates=30300, lr=8.12444e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=25515
2023-08-10 20:15:20 | INFO | train_inner | epoch 021:    934 / 1474 loss=2.005, trans_loss=5.028, nll_loss=2.231, w2v_ctc_loss=0.656, task_loss=1.402, contrastive_loss=0.061, total=4103.34, n_correct=2654.85, ppl=4.69, accuracy=64.7, wps=12038, ups=1.47, wpb=8206.7, bsz=301, num_updates=30400, lr=8.11107e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=68, gb_free=13.9, wall=25583
2023-08-10 20:16:28 | INFO | train_inner | epoch 021:   1034 / 1474 loss=2.012, trans_loss=5.045, nll_loss=2.254, w2v_ctc_loss=0.657, task_loss=1.426, contrastive_loss=0.058, total=4099.86, n_correct=2640.69, ppl=4.77, accuracy=64.409, wps=12007.7, ups=1.46, wpb=8199.7, bsz=298.8, num_updates=30500, lr=8.09776e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=68, gb_free=11.2, wall=25651
2023-08-10 20:17:37 | INFO | train_inner | epoch 021:   1134 / 1474 loss=2.012, trans_loss=5.036, nll_loss=2.242, w2v_ctc_loss=0.661, task_loss=1.504, contrastive_loss=0.063, total=4120.75, n_correct=2662.76, ppl=4.73, accuracy=64.618, wps=11979.3, ups=1.45, wpb=8241.5, bsz=293.5, num_updates=30600, lr=8.08452e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=68, gb_free=15.7, wall=25720
2023-08-10 20:18:46 | INFO | train_inner | epoch 021:   1234 / 1474 loss=2.013, trans_loss=5.034, nll_loss=2.24, w2v_ctc_loss=0.654, task_loss=1.328, contrastive_loss=0.112, total=4154.73, n_correct=2682.58, ppl=4.72, accuracy=64.567, wps=12083.9, ups=1.45, wpb=8309.5, bsz=311.6, num_updates=30700, lr=8.07134e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=68, gb_free=12.5, wall=25789
2023-08-10 20:19:54 | INFO | train_inner | epoch 021:   1334 / 1474 loss=2.011, trans_loss=5.036, nll_loss=2.244, w2v_ctc_loss=0.658, task_loss=1.353, contrastive_loss=0.072, total=4147.17, n_correct=2680.12, ppl=4.74, accuracy=64.625, wps=12105.6, ups=1.46, wpb=8294.3, bsz=311.9, num_updates=30800, lr=8.05823e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=25857
2023-08-10 20:21:04 | INFO | train_inner | epoch 021:   1434 / 1474 loss=2.03, trans_loss=5.047, nll_loss=2.257, w2v_ctc_loss=0.674, task_loss=1.461, contrastive_loss=0.122, total=4133.93, n_correct=2657.51, ppl=4.78, accuracy=64.285, wps=11910.5, ups=1.44, wpb=8267.9, bsz=304.5, num_updates=30900, lr=8.04518e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=69, gb_free=15.5, wall=25927
2023-08-10 20:21:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:2')
2023-08-10 20:21:56 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.204 | trans_loss 5.556 | nll_loss 2.831 | w2v_ctc_loss 1.281 | task_loss 4.603 | contrastive_loss 0.246 | total 4003.4 | n_correct 2486.4 | ppl 7.12 | accuracy 62.107 | uer 17.076 | wer 18.847 | raw_wer 18.847 | bleu 20.19 | wps 2081.2 | wpb 4003.4 | bsz 141.8 | num_updates 30940 | best_bleu 20.24
2023-08-10 20:21:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30940 updates
2023-08-10 20:21:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.1907.pt
2023-08-10 20:21:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.1907.pt
2023-08-10 20:22:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.1907.pt (epoch 21 @ 30940 updates, score 20.19) (writing took 14.71217730268836 seconds)
2023-08-10 20:22:11 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-10 20:22:11 | INFO | train | epoch 021 | loss 2.011 | trans_loss 5.029 | nll_loss 2.233 | w2v_ctc_loss 0.655 | task_loss 1.4 | contrastive_loss 0.101 | total 4138.65 | n_correct 2679.03 | ppl 4.7 | accuracy 64.732 | wps 10790.1 | ups 1.3 | wpb 8277.3 | bsz 305.7 | num_updates 30940 | lr 8.03998e-05 | gnorm 0.529 | clip 0 | loss_scale 32 | train_wall 1008 | gb_free 15.4 | wall 25994
2023-08-10 20:22:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 20:22:11 | INFO | fairseq.trainer | begin training epoch 22
2023-08-10 20:22:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 20:23:00 | INFO | train_inner | epoch 022:     60 / 1474 loss=1.998, trans_loss=5.015, nll_loss=2.215, w2v_ctc_loss=0.655, task_loss=1.424, contrastive_loss=0.044, total=4128.84, n_correct=2686.99, ppl=4.64, accuracy=65.079, wps=7091.6, ups=0.86, wpb=8257.7, bsz=297.7, num_updates=31000, lr=8.03219e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=68, gb_free=14.1, wall=26043
2023-08-10 20:24:10 | INFO | train_inner | epoch 022:    160 / 1474 loss=2.002, trans_loss=5.005, nll_loss=2.201, w2v_ctc_loss=0.648, task_loss=1.408, contrastive_loss=0.123, total=4123.35, n_correct=2686.42, ppl=4.6, accuracy=65.151, wps=11855.4, ups=1.44, wpb=8246.7, bsz=310.3, num_updates=31100, lr=8.01927e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=14.6, wall=26113
2023-08-10 20:25:19 | INFO | train_inner | epoch 022:    260 / 1474 loss=1.983, trans_loss=4.998, nll_loss=2.194, w2v_ctc_loss=0.635, task_loss=1.232, contrastive_loss=0.065, total=4267.16, n_correct=2792.41, ppl=4.58, accuracy=65.44, wps=12333.4, ups=1.45, wpb=8534.3, bsz=329.9, num_updates=31200, lr=8.00641e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=26182
2023-08-10 20:25:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-10 20:26:30 | INFO | train_inner | epoch 022:    361 / 1474 loss=2.007, trans_loss=5.014, nll_loss=2.213, w2v_ctc_loss=0.656, task_loss=1.456, contrastive_loss=0.108, total=4154.17, n_correct=2702.71, ppl=4.64, accuracy=65.06, wps=11739, ups=1.41, wpb=8308.3, bsz=302.4, num_updates=31300, lr=7.99361e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=70, gb_free=15.3, wall=26253
2023-08-10 20:27:39 | INFO | train_inner | epoch 022:    461 / 1474 loss=2.008, trans_loss=5.019, nll_loss=2.219, w2v_ctc_loss=0.652, task_loss=1.469, contrastive_loss=0.102, total=4132.96, n_correct=2687.85, ppl=4.66, accuracy=65.035, wps=11906.2, ups=1.44, wpb=8265.9, bsz=297.5, num_updates=31400, lr=7.98087e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=69, gb_free=16.9, wall=26322
2023-08-10 20:28:49 | INFO | train_inner | epoch 022:    561 / 1474 loss=1.995, trans_loss=5.011, nll_loss=2.21, w2v_ctc_loss=0.651, task_loss=1.4, contrastive_loss=0.054, total=4158.17, n_correct=2710.37, ppl=4.63, accuracy=65.182, wps=11921.9, ups=1.43, wpb=8316.3, bsz=307.8, num_updates=31500, lr=7.96819e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=26392
2023-08-10 20:29:57 | INFO | train_inner | epoch 022:    661 / 1474 loss=1.998, trans_loss=5.008, nll_loss=2.206, w2v_ctc_loss=0.635, task_loss=1.337, contrastive_loss=0.138, total=4139.66, n_correct=2698.73, ppl=4.62, accuracy=65.192, wps=12243.8, ups=1.48, wpb=8279.3, bsz=311.1, num_updates=31600, lr=7.95557e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=67, gb_free=16.1, wall=26460
2023-08-10 20:31:06 | INFO | train_inner | epoch 022:    761 / 1474 loss=1.999, trans_loss=5.015, nll_loss=2.215, w2v_ctc_loss=0.653, task_loss=1.443, contrastive_loss=0.056, total=4167.89, n_correct=2709.18, ppl=4.64, accuracy=65.001, wps=12005.6, ups=1.44, wpb=8335.8, bsz=303.9, num_updates=31700, lr=7.94301e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=12.7, wall=26529
2023-08-10 20:32:15 | INFO | train_inner | epoch 022:    861 / 1474 loss=2.003, trans_loss=5.027, nll_loss=2.23, w2v_ctc_loss=0.655, task_loss=1.516, contrastive_loss=0.044, total=4075.79, n_correct=2639.76, ppl=4.69, accuracy=64.767, wps=11811, ups=1.45, wpb=8151.6, bsz=289, num_updates=31800, lr=7.93052e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=26598
2023-08-10 20:33:24 | INFO | train_inner | epoch 022:    961 / 1474 loss=1.993, trans_loss=5.019, nll_loss=2.22, w2v_ctc_loss=0.642, task_loss=1.408, contrastive_loss=0.045, total=4134.72, n_correct=2687.31, ppl=4.66, accuracy=64.994, wps=12046.1, ups=1.46, wpb=8269.4, bsz=303.2, num_updates=31900, lr=7.91808e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=68, gb_free=14.1, wall=26667
2023-08-10 20:34:32 | INFO | train_inner | epoch 022:   1061 / 1474 loss=2.013, trans_loss=5.017, nll_loss=2.219, w2v_ctc_loss=0.644, task_loss=1.335, contrastive_loss=0.213, total=4160.57, n_correct=2705.17, ppl=4.66, accuracy=65.019, wps=12151.3, ups=1.46, wpb=8321.1, bsz=315.5, num_updates=32000, lr=7.90569e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=68, gb_free=17.2, wall=26735
2023-08-10 20:34:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 20:34:57 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.205 | trans_loss 5.552 | nll_loss 2.823 | w2v_ctc_loss 1.299 | task_loss 4.628 | contrastive_loss 0.242 | total 4003.4 | n_correct 2488.6 | ppl 7.08 | accuracy 62.162 | uer 17.033 | wer 18.87 | raw_wer 18.87 | bleu 20.14 | wps 1944 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.24
2023-08-10 20:34:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-08-10 20:34:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_22_32000.pt
2023-08-10 20:35:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_22_32000.pt
2023-08-10 20:35:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 20.14) (writing took 38.44341229647398 seconds)
2023-08-10 20:36:46 | INFO | train_inner | epoch 022:   1161 / 1474 loss=2.018, trans_loss=5.041, nll_loss=2.25, w2v_ctc_loss=0.662, task_loss=1.444, contrastive_loss=0.094, total=4099.59, n_correct=2643.51, ppl=4.76, accuracy=64.482, wps=6142.1, ups=0.75, wpb=8199.2, bsz=296.2, num_updates=32100, lr=7.89337e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=68, gb_free=14.8, wall=26869
2023-08-10 20:37:54 | INFO | train_inner | epoch 022:   1261 / 1474 loss=2.007, trans_loss=5.033, nll_loss=2.24, w2v_ctc_loss=0.652, task_loss=1.295, contrastive_loss=0.087, total=4182.05, n_correct=2705.82, ppl=4.72, accuracy=64.701, wps=12182.5, ups=1.46, wpb=8364.1, bsz=323, num_updates=32200, lr=7.8811e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=68, gb_free=15.4, wall=26937
2023-08-10 20:39:03 | INFO | train_inner | epoch 022:   1361 / 1474 loss=2.002, trans_loss=5.023, nll_loss=2.227, w2v_ctc_loss=0.643, task_loss=1.403, contrastive_loss=0.112, total=4062.31, n_correct=2637.7, ppl=4.68, accuracy=64.931, wps=11905.1, ups=1.47, wpb=8124.6, bsz=299, num_updates=32300, lr=7.86889e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=68, gb_free=14.9, wall=27006
2023-08-10 20:40:11 | INFO | train_inner | epoch 022:   1461 / 1474 loss=2.013, trans_loss=5.043, nll_loss=2.251, w2v_ctc_loss=0.663, task_loss=1.499, contrastive_loss=0.059, total=4081.88, n_correct=2633.88, ppl=4.76, accuracy=64.526, wps=11904.9, ups=1.46, wpb=8163.8, bsz=288.9, num_updates=32400, lr=7.85674e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=68, gb_free=17.2, wall=27074
2023-08-10 20:40:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 20:40:43 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.202 | trans_loss 5.547 | nll_loss 2.817 | w2v_ctc_loss 1.304 | task_loss 4.633 | contrastive_loss 0.239 | total 4003.4 | n_correct 2496.3 | ppl 7.05 | accuracy 62.354 | uer 17.156 | wer 18.925 | raw_wer 18.925 | bleu 20.23 | wps 2141 | wpb 4003.4 | bsz 141.8 | num_updates 32413 | best_bleu 20.24
2023-08-10 20:40:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32413 updates
2023-08-10 20:40:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.2307.pt
2023-08-10 20:40:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.2307.pt
2023-08-10 20:40:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.2307.pt (epoch 22 @ 32413 updates, score 20.23) (writing took 14.51776733994484 seconds)
2023-08-10 20:40:58 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-10 20:40:58 | INFO | train | epoch 022 | loss 2.002 | trans_loss 5.019 | nll_loss 2.22 | w2v_ctc_loss 0.649 | task_loss 1.402 | contrastive_loss 0.091 | total 4136.85 | n_correct 2688.13 | ppl 4.66 | accuracy 64.98 | wps 10816.2 | ups 1.31 | wpb 8273.7 | bsz 305.1 | num_updates 32413 | lr 7.85517e-05 | gnorm 0.531 | clip 0 | loss_scale 16 | train_wall 1009 | gb_free 11.6 | wall 27121
2023-08-10 20:40:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 20:40:58 | INFO | fairseq.trainer | begin training epoch 23
2023-08-10 20:40:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 20:42:06 | INFO | train_inner | epoch 023:     87 / 1474 loss=1.986, trans_loss=4.995, nll_loss=2.188, w2v_ctc_loss=0.647, task_loss=1.43, contrastive_loss=0.05, total=4096.09, n_correct=2682.76, ppl=4.56, accuracy=65.496, wps=7158.7, ups=0.87, wpb=8192.2, bsz=301.2, num_updates=32500, lr=7.84465e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=27189
2023-08-10 20:43:14 | INFO | train_inner | epoch 023:    187 / 1474 loss=1.983, trans_loss=4.992, nll_loss=2.183, w2v_ctc_loss=0.636, task_loss=1.49, contrastive_loss=0.048, total=4107.77, n_correct=2694.11, ppl=4.54, accuracy=65.586, wps=12022.4, ups=1.46, wpb=8215.5, bsz=293.4, num_updates=32600, lr=7.8326e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=27257
2023-08-10 20:44:23 | INFO | train_inner | epoch 023:    287 / 1474 loss=1.992, trans_loss=5, nll_loss=2.196, w2v_ctc_loss=0.63, task_loss=1.4, contrastive_loss=0.122, total=4153.12, n_correct=2713.31, ppl=4.58, accuracy=65.332, wps=12026.9, ups=1.45, wpb=8306.2, bsz=306.4, num_updates=32700, lr=7.82062e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=27326
2023-08-10 20:45:32 | INFO | train_inner | epoch 023:    387 / 1474 loss=1.986, trans_loss=5.002, nll_loss=2.197, w2v_ctc_loss=0.639, task_loss=1.454, contrastive_loss=0.041, total=4116.7, n_correct=2692.21, ppl=4.58, accuracy=65.397, wps=11986.8, ups=1.46, wpb=8233.4, bsz=294, num_updates=32800, lr=7.80869e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=68, gb_free=15.2, wall=27395
2023-08-10 20:46:40 | INFO | train_inner | epoch 023:    487 / 1474 loss=1.996, trans_loss=5.006, nll_loss=2.203, w2v_ctc_loss=0.643, task_loss=1.36, contrastive_loss=0.097, total=4157.6, n_correct=2709.35, ppl=4.61, accuracy=65.166, wps=12167.7, ups=1.46, wpb=8315.2, bsz=313.5, num_updates=32900, lr=7.79681e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=68, gb_free=17.3, wall=27463
2023-08-10 20:47:49 | INFO | train_inner | epoch 023:    587 / 1474 loss=1.979, trans_loss=4.996, nll_loss=2.19, w2v_ctc_loss=0.635, task_loss=1.323, contrastive_loss=0.046, total=4173.42, n_correct=2734.39, ppl=4.56, accuracy=65.519, wps=12122.1, ups=1.45, wpb=8346.8, bsz=316, num_updates=33000, lr=7.78499e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=68, gb_free=12.4, wall=27532
2023-08-10 20:48:58 | INFO | train_inner | epoch 023:    687 / 1474 loss=1.991, trans_loss=5.003, nll_loss=2.2, w2v_ctc_loss=0.639, task_loss=1.4, contrastive_loss=0.083, total=4137.82, n_correct=2705.33, ppl=4.59, accuracy=65.381, wps=12048.5, ups=1.46, wpb=8275.6, bsz=302.5, num_updates=33100, lr=7.77322e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=68, gb_free=17.1, wall=27601
2023-08-10 20:50:06 | INFO | train_inner | epoch 023:    787 / 1474 loss=1.995, trans_loss=5.014, nll_loss=2.213, w2v_ctc_loss=0.645, task_loss=1.411, contrastive_loss=0.063, total=4150.99, n_correct=2703.34, ppl=4.64, accuracy=65.125, wps=12123.4, ups=1.46, wpb=8302, bsz=305.4, num_updates=33200, lr=7.76151e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=27669
2023-08-10 20:51:14 | INFO | train_inner | epoch 023:    887 / 1474 loss=1.998, trans_loss=5.008, nll_loss=2.207, w2v_ctc_loss=0.639, task_loss=1.278, contrastive_loss=0.141, total=4181.99, n_correct=2729.71, ppl=4.62, accuracy=65.273, wps=12292.8, ups=1.47, wpb=8364, bsz=324.7, num_updates=33300, lr=7.74984e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=27737
2023-08-10 20:52:24 | INFO | train_inner | epoch 023:    987 / 1474 loss=2.019, trans_loss=5.012, nll_loss=2.212, w2v_ctc_loss=0.633, task_loss=1.395, contrastive_loss=0.308, total=4168.73, n_correct=2710.57, ppl=4.63, accuracy=65.021, wps=12006.8, ups=1.44, wpb=8337.5, bsz=310.5, num_updates=33400, lr=7.73823e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=69, gb_free=10.7, wall=27806
2023-08-10 20:53:32 | INFO | train_inner | epoch 023:   1087 / 1474 loss=2.001, trans_loss=5.02, nll_loss=2.222, w2v_ctc_loss=0.654, task_loss=1.495, contrastive_loss=0.052, total=4088.49, n_correct=2654.18, ppl=4.66, accuracy=64.918, wps=11887.1, ups=1.45, wpb=8177, bsz=290, num_updates=33500, lr=7.72667e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=27875
2023-08-10 20:54:42 | INFO | train_inner | epoch 023:   1187 / 1474 loss=1.991, trans_loss=5.018, nll_loss=2.22, w2v_ctc_loss=0.644, task_loss=1.389, contrastive_loss=0.046, total=4162.7, n_correct=2705.3, ppl=4.66, accuracy=64.989, wps=11994.4, ups=1.44, wpb=8325.4, bsz=309.3, num_updates=33600, lr=7.71517e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=27945
2023-08-10 20:55:50 | INFO | train_inner | epoch 023:   1287 / 1474 loss=1.989, trans_loss=5.016, nll_loss=2.217, w2v_ctc_loss=0.637, task_loss=1.359, contrastive_loss=0.057, total=4135.53, n_correct=2697.5, ppl=4.65, accuracy=65.227, wps=12138.4, ups=1.47, wpb=8271.1, bsz=308.9, num_updates=33700, lr=7.70371e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=28013
2023-08-10 20:56:59 | INFO | train_inner | epoch 023:   1387 / 1474 loss=2.009, trans_loss=5.034, nll_loss=2.241, w2v_ctc_loss=0.647, task_loss=1.413, contrastive_loss=0.11, total=4143.98, n_correct=2684.05, ppl=4.73, accuracy=64.77, wps=12046.9, ups=1.45, wpb=8288, bsz=305.2, num_updates=33800, lr=7.69231e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=28082
2023-08-10 20:57:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 20:58:23 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.219 | trans_loss 5.552 | nll_loss 2.824 | w2v_ctc_loss 1.345 | task_loss 4.625 | contrastive_loss 0.242 | total 4003.4 | n_correct 2497.4 | ppl 7.08 | accuracy 62.382 | uer 17.193 | wer 18.925 | raw_wer 18.925 | bleu 20.12 | wps 2066 | wpb 4003.4 | bsz 141.8 | num_updates 33887 | best_bleu 20.24
2023-08-10 20:58:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33887 updates
2023-08-10 20:58:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.1204.pt
2023-08-10 20:58:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.1204.pt
2023-08-10 20:58:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.1204.pt (epoch 23 @ 33887 updates, score 20.12) (writing took 30.90299062244594 seconds)
2023-08-10 20:58:54 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-10 20:58:54 | INFO | train | epoch 023 | loss 1.996 | trans_loss 5.01 | nll_loss 2.208 | w2v_ctc_loss 0.641 | task_loss 1.399 | contrastive_loss 0.099 | total 4138.65 | n_correct 2698.27 | ppl 4.62 | accuracy 65.197 | wps 11335 | ups 1.37 | wpb 8277.3 | bsz 305.7 | num_updates 33887 | lr 7.68243e-05 | gnorm 0.531 | clip 0 | loss_scale 32 | train_wall 1006 | gb_free 13.5 | wall 28197
2023-08-10 20:58:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 20:58:55 | INFO | fairseq.trainer | begin training epoch 24
2023-08-10 20:58:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 20:59:11 | INFO | train_inner | epoch 024:     13 / 1474 loss=2.018, trans_loss=5.026, nll_loss=2.232, w2v_ctc_loss=0.641, task_loss=1.406, contrastive_loss=0.194, total=4085.11, n_correct=2648.7, ppl=4.7, accuracy=64.838, wps=6185.9, ups=0.76, wpb=8170.2, bsz=304.2, num_updates=33900, lr=7.68095e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=69, gb_free=12.5, wall=28214
2023-08-10 21:00:20 | INFO | train_inner | epoch 024:    113 / 1474 loss=1.993, trans_loss=4.98, nll_loss=2.169, w2v_ctc_loss=0.627, task_loss=1.291, contrastive_loss=0.209, total=4171.44, n_correct=2743.12, ppl=4.5, accuracy=65.76, wps=12098.3, ups=1.45, wpb=8342.9, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=28283
2023-08-10 21:00:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 21:00:45 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.211 | trans_loss 5.558 | nll_loss 2.831 | w2v_ctc_loss 1.306 | task_loss 4.608 | contrastive_loss 0.244 | total 4003.4 | n_correct 2488.8 | ppl 7.11 | accuracy 62.167 | uer 17.19 | wer 18.881 | raw_wer 18.881 | bleu 19.88 | wps 2036 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.24
2023-08-10 21:00:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-08-10 21:00:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_24_34000.pt
2023-08-10 21:00:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_24_34000.pt
2023-08-10 21:01:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 19.88) (writing took 32.09206301346421 seconds)
2023-08-10 21:02:27 | INFO | train_inner | epoch 024:    213 / 1474 loss=1.995, trans_loss=4.984, nll_loss=2.176, w2v_ctc_loss=0.618, task_loss=1.223, contrastive_loss=0.257, total=4251.29, n_correct=2796.17, ppl=4.52, accuracy=65.772, wps=6704.3, ups=0.79, wpb=8502.6, bsz=340.8, num_updates=34100, lr=7.6584e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=28410
2023-08-10 21:03:35 | INFO | train_inner | epoch 024:    313 / 1474 loss=1.976, trans_loss=4.989, nll_loss=2.181, w2v_ctc_loss=0.633, task_loss=1.368, contrastive_loss=0.043, total=4128.18, n_correct=2710.51, ppl=4.53, accuracy=65.659, wps=12036.4, ups=1.46, wpb=8256.4, bsz=305.5, num_updates=34200, lr=7.64719e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=28478
2023-08-10 21:04:44 | INFO | train_inner | epoch 024:    413 / 1474 loss=2.009, trans_loss=4.999, nll_loss=2.194, w2v_ctc_loss=0.644, task_loss=1.463, contrastive_loss=0.185, total=4158.92, n_correct=2714.72, ppl=4.58, accuracy=65.275, wps=12045.1, ups=1.45, wpb=8317.8, bsz=299.7, num_updates=34300, lr=7.63604e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=28547
2023-08-10 21:05:53 | INFO | train_inner | epoch 024:    513 / 1474 loss=1.987, trans_loss=4.991, nll_loss=2.184, w2v_ctc_loss=0.636, task_loss=1.423, contrastive_loss=0.11, total=4144.91, n_correct=2720.52, ppl=4.54, accuracy=65.635, wps=12042.2, ups=1.45, wpb=8289.8, bsz=303.3, num_updates=34400, lr=7.62493e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=28616
2023-08-10 21:07:02 | INFO | train_inner | epoch 024:    613 / 1474 loss=1.981, trans_loss=4.993, nll_loss=2.187, w2v_ctc_loss=0.627, task_loss=1.408, contrastive_loss=0.072, total=4165.3, n_correct=2729.88, ppl=4.55, accuracy=65.539, wps=12153.2, ups=1.46, wpb=8330.6, bsz=307.7, num_updates=34500, lr=7.61387e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=28685
2023-08-10 21:08:10 | INFO | train_inner | epoch 024:    713 / 1474 loss=1.992, trans_loss=5.007, nll_loss=2.204, w2v_ctc_loss=0.636, task_loss=1.442, contrastive_loss=0.087, total=4102.21, n_correct=2681.2, ppl=4.61, accuracy=65.36, wps=11942.4, ups=1.46, wpb=8204.4, bsz=295.1, num_updates=34600, lr=7.60286e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=28753
2023-08-10 21:09:19 | INFO | train_inner | epoch 024:    813 / 1474 loss=1.984, trans_loss=5.004, nll_loss=2.202, w2v_ctc_loss=0.632, task_loss=1.408, contrastive_loss=0.062, total=4110.6, n_correct=2689.19, ppl=4.6, accuracy=65.421, wps=12015.7, ups=1.46, wpb=8221.2, bsz=305.3, num_updates=34700, lr=7.5919e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=28822
2023-08-10 21:10:27 | INFO | train_inner | epoch 024:    913 / 1474 loss=1.993, trans_loss=5.015, nll_loss=2.214, w2v_ctc_loss=0.645, task_loss=1.557, contrastive_loss=0.039, total=4043.03, n_correct=2629.99, ppl=4.64, accuracy=65.05, wps=11821.9, ups=1.46, wpb=8086.1, bsz=281, num_updates=34800, lr=7.58098e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=68, gb_free=11.1, wall=28890
2023-08-10 21:11:36 | INFO | train_inner | epoch 024:   1013 / 1474 loss=1.985, trans_loss=5.01, nll_loss=2.209, w2v_ctc_loss=0.636, task_loss=1.447, contrastive_loss=0.043, total=4136.81, n_correct=2703.97, ppl=4.62, accuracy=65.364, wps=11963, ups=1.45, wpb=8273.6, bsz=298.4, num_updates=34900, lr=7.57011e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=28959
2023-08-10 21:12:44 | INFO | train_inner | epoch 024:   1113 / 1474 loss=1.987, trans_loss=4.996, nll_loss=2.192, w2v_ctc_loss=0.639, task_loss=1.349, contrastive_loss=0.084, total=4135.73, n_correct=2708.89, ppl=4.57, accuracy=65.5, wps=12145.3, ups=1.47, wpb=8271.5, bsz=308.9, num_updates=35000, lr=7.55929e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=29027
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:0')
2023-08-10 21:13:53 | INFO | train_inner | epoch 024:   1213 / 1474 loss=1.988, trans_loss=5.008, nll_loss=2.208, w2v_ctc_loss=0.634, task_loss=1.386, contrastive_loss=0.074, total=4148.3, n_correct=2708.9, ppl=4.62, accuracy=65.301, wps=12067.2, ups=1.45, wpb=8296.6, bsz=310.8, num_updates=35100, lr=7.54851e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=29096
2023-08-10 21:15:02 | INFO | train_inner | epoch 024:   1313 / 1474 loss=1.994, trans_loss=5.016, nll_loss=2.217, w2v_ctc_loss=0.649, task_loss=1.489, contrastive_loss=0.047, total=4110.05, n_correct=2676.91, ppl=4.65, accuracy=65.131, wps=11932.5, ups=1.45, wpb=8220.1, bsz=294.3, num_updates=35200, lr=7.53778e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=68, gb_free=17.1, wall=29165
2023-08-10 21:16:10 | INFO | train_inner | epoch 024:   1413 / 1474 loss=1.995, trans_loss=5.018, nll_loss=2.221, w2v_ctc_loss=0.649, task_loss=1.465, contrastive_loss=0.047, total=4090.91, n_correct=2663.21, ppl=4.66, accuracy=65.101, wps=12036.3, ups=1.47, wpb=8181.8, bsz=292.7, num_updates=35300, lr=7.5271e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=29233
2023-08-10 21:16:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:3')
2023-08-10 21:17:16 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.215 | trans_loss 5.552 | nll_loss 2.822 | w2v_ctc_loss 1.333 | task_loss 4.628 | contrastive_loss 0.245 | total 4003.4 | n_correct 2497.1 | ppl 7.07 | accuracy 62.374 | uer 16.996 | wer 18.773 | raw_wer 18.773 | bleu 20.08 | wps 1946.6 | wpb 4003.4 | bsz 141.8 | num_updates 35361 | best_bleu 20.24
2023-08-10 21:17:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35361 updates
2023-08-10 21:17:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_last.pt
2023-08-10 21:17:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_last.pt
2023-08-10 21:17:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_last.pt (epoch 24 @ 35361 updates, score 20.08) (writing took 13.12211237102747 seconds)
2023-08-10 21:17:29 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-10 21:17:29 | INFO | train | epoch 024 | loss 1.989 | trans_loss 5.001 | nll_loss 2.197 | w2v_ctc_loss 0.635 | task_loss 1.399 | contrastive_loss 0.097 | total 4138.65 | n_correct 2707.87 | ppl 4.59 | accuracy 65.429 | wps 10943.6 | ups 1.32 | wpb 8277.3 | bsz 305.7 | num_updates 35361 | lr 7.5206e-05 | gnorm 0.53 | clip 0 | loss_scale 64 | train_wall 1006 | gb_free 16.1 | wall 29312
2023-08-10 21:17:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 21:17:29 | INFO | fairseq.trainer | begin training epoch 25
2023-08-10 21:17:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 21:18:03 | INFO | train_inner | epoch 025:     39 / 1474 loss=1.974, trans_loss=4.991, nll_loss=2.186, w2v_ctc_loss=0.628, task_loss=1.341, contrastive_loss=0.052, total=4166.95, n_correct=2739.82, ppl=4.55, accuracy=65.751, wps=7394, ups=0.89, wpb=8333.9, bsz=312, num_updates=35400, lr=7.51646e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=68, gb_free=16.4, wall=29346
2023-08-10 21:19:11 | INFO | train_inner | epoch 025:    139 / 1474 loss=1.967, trans_loss=4.974, nll_loss=2.162, w2v_ctc_loss=0.623, task_loss=1.367, contrastive_loss=0.05, total=4133.64, n_correct=2728.02, ppl=4.47, accuracy=65.996, wps=12055.5, ups=1.46, wpb=8267.3, bsz=307.7, num_updates=35500, lr=7.50587e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=68, gb_free=15.8, wall=29414
2023-08-10 21:20:21 | INFO | train_inner | epoch 025:    239 / 1474 loss=1.972, trans_loss=4.978, nll_loss=2.168, w2v_ctc_loss=0.628, task_loss=1.437, contrastive_loss=0.055, total=4114.53, n_correct=2710.87, ppl=4.49, accuracy=65.885, wps=11855.9, ups=1.44, wpb=8229.1, bsz=302.7, num_updates=35600, lr=7.49532e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=69, gb_free=16.9, wall=29484
2023-08-10 21:21:30 | INFO | train_inner | epoch 025:    339 / 1474 loss=1.982, trans_loss=4.982, nll_loss=2.171, w2v_ctc_loss=0.63, task_loss=1.489, contrastive_loss=0.085, total=4148.7, n_correct=2722.15, ppl=4.5, accuracy=65.615, wps=12056.7, ups=1.45, wpb=8297.4, bsz=295.1, num_updates=35700, lr=7.48481e-05, gnorm=0.538, clip=0, loss_scale=64, train_wall=68, gb_free=16.3, wall=29553
2023-08-10 21:22:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-10 21:22:39 | INFO | train_inner | epoch 025:    440 / 1474 loss=1.986, trans_loss=4.989, nll_loss=2.181, w2v_ctc_loss=0.649, task_loss=1.504, contrastive_loss=0.044, total=4142.33, n_correct=2717.96, ppl=4.54, accuracy=65.614, wps=11897.7, ups=1.44, wpb=8284.7, bsz=289.3, num_updates=35800, lr=7.47435e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=29622
2023-08-10 21:23:48 | INFO | train_inner | epoch 025:    540 / 1474 loss=1.98, trans_loss=4.995, nll_loss=2.19, w2v_ctc_loss=0.634, task_loss=1.364, contrastive_loss=0.053, total=4160.61, n_correct=2729.87, ppl=4.56, accuracy=65.612, wps=12073.5, ups=1.45, wpb=8321.2, bsz=313.9, num_updates=35900, lr=7.46393e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=68, gb_free=17.5, wall=29691
2023-08-10 21:24:57 | INFO | train_inner | epoch 025:    640 / 1474 loss=1.984, trans_loss=4.984, nll_loss=2.176, w2v_ctc_loss=0.633, task_loss=1.386, contrastive_loss=0.12, total=4153.68, n_correct=2731.05, ppl=4.52, accuracy=65.75, wps=12083.3, ups=1.45, wpb=8307.4, bsz=309.6, num_updates=36000, lr=7.45356e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=29760
2023-08-10 21:24:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 21:25:21 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.222 | trans_loss 5.554 | nll_loss 2.824 | w2v_ctc_loss 1.35 | task_loss 4.597 | contrastive_loss 0.244 | total 4003.4 | n_correct 2495.1 | ppl 7.08 | accuracy 62.325 | uer 17.047 | wer 18.84 | raw_wer 18.84 | bleu 20.28 | wps 2141.3 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.28
2023-08-10 21:25:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-08-10 21:25:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_25_36000.pt
2023-08-10 21:25:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_25_36000.pt
2023-08-10 21:25:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 20.28) (writing took 25.312671644613147 seconds)
2023-08-10 21:26:55 | INFO | train_inner | epoch 025:    740 / 1474 loss=1.987, trans_loss=4.989, nll_loss=2.182, w2v_ctc_loss=0.631, task_loss=1.419, contrastive_loss=0.112, total=4128.34, n_correct=2711.35, ppl=4.54, accuracy=65.677, wps=6968.2, ups=0.84, wpb=8256.7, bsz=301.3, num_updates=36100, lr=7.44323e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=29878
2023-08-10 21:28:04 | INFO | train_inner | epoch 025:    840 / 1474 loss=1.975, trans_loss=4.993, nll_loss=2.187, w2v_ctc_loss=0.626, task_loss=1.289, contrastive_loss=0.062, total=4182.4, n_correct=2747.71, ppl=4.55, accuracy=65.697, wps=12194.2, ups=1.46, wpb=8364.8, bsz=326, num_updates=36200, lr=7.43294e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=17.7, wall=29947
2023-08-10 21:29:12 | INFO | train_inner | epoch 025:    940 / 1474 loss=1.987, trans_loss=4.997, nll_loss=2.195, w2v_ctc_loss=0.634, task_loss=1.327, contrastive_loss=0.117, total=4155.21, n_correct=2725.22, ppl=4.58, accuracy=65.586, wps=12200.5, ups=1.47, wpb=8310.4, bsz=317, num_updates=36300, lr=7.4227e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=13.9, wall=30015
2023-08-10 21:30:21 | INFO | train_inner | epoch 025:   1040 / 1474 loss=2.001, trans_loss=5.004, nll_loss=2.202, w2v_ctc_loss=0.623, task_loss=1.388, contrastive_loss=0.229, total=4177.7, n_correct=2731.92, ppl=4.6, accuracy=65.393, wps=12138.3, ups=1.45, wpb=8355.4, bsz=309.8, num_updates=36400, lr=7.41249e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=30084
2023-08-10 21:31:30 | INFO | train_inner | epoch 025:   1140 / 1474 loss=1.976, trans_loss=4.998, nll_loss=2.194, w2v_ctc_loss=0.623, task_loss=1.514, contrastive_loss=0.038, total=4039.24, n_correct=2652.44, ppl=4.57, accuracy=65.667, wps=11789.1, ups=1.46, wpb=8078.5, bsz=285.2, num_updates=36500, lr=7.40233e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=30152
2023-08-10 21:32:37 | INFO | train_inner | epoch 025:   1240 / 1474 loss=1.981, trans_loss=5.003, nll_loss=2.201, w2v_ctc_loss=0.629, task_loss=1.413, contrastive_loss=0.047, total=4090.59, n_correct=2675.24, ppl=4.6, accuracy=65.4, wps=12111.3, ups=1.48, wpb=8181.2, bsz=295.7, num_updates=36600, lr=7.39221e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=67, gb_free=17.1, wall=30220
2023-08-10 21:33:45 | INFO | train_inner | epoch 025:   1340 / 1474 loss=1.992, trans_loss=5, nll_loss=2.197, w2v_ctc_loss=0.633, task_loss=1.364, contrastive_loss=0.14, total=4164.34, n_correct=2724.29, ppl=4.58, accuracy=65.419, wps=12209.4, ups=1.47, wpb=8328.7, bsz=310.1, num_updates=36700, lr=7.38213e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=30288
2023-08-10 21:34:55 | INFO | train_inner | epoch 025:   1440 / 1474 loss=1.995, trans_loss=5.016, nll_loss=2.217, w2v_ctc_loss=0.638, task_loss=1.454, contrastive_loss=0.088, total=4099.11, n_correct=2670.93, ppl=4.65, accuracy=65.159, wps=11841, ups=1.44, wpb=8198.2, bsz=299.3, num_updates=36800, lr=7.3721e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=69, gb_free=12.1, wall=30357
2023-08-10 21:35:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 21:35:43 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.208 | trans_loss 5.549 | nll_loss 2.823 | w2v_ctc_loss 1.311 | task_loss 4.612 | contrastive_loss 0.252 | total 4003.4 | n_correct 2493.4 | ppl 7.08 | accuracy 62.282 | uer 17.015 | wer 18.825 | raw_wer 18.825 | bleu 20.19 | wps 1980.9 | wpb 4003.4 | bsz 141.8 | num_updates 36834 | best_bleu 20.28
2023-08-10 21:35:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36834 updates
2023-08-10 21:35:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.1907.pt
2023-08-10 21:35:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.1907.pt
2023-08-10 21:36:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.1907.pt (epoch 25 @ 36834 updates, score 20.19) (writing took 24.633103968575597 seconds)
2023-08-10 21:36:08 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-10 21:36:08 | INFO | train | epoch 025 | loss 1.983 | trans_loss 4.993 | nll_loss 2.187 | w2v_ctc_loss 0.631 | task_loss 1.401 | contrastive_loss 0.088 | total 4137.25 | n_correct 2714.47 | ppl 4.55 | accuracy 65.61 | wps 10893.9 | ups 1.32 | wpb 8274.5 | bsz 305.1 | num_updates 36834 | lr 7.36869e-05 | gnorm 0.531 | clip 0 | loss_scale 32 | train_wall 1005 | gb_free 14.1 | wall 30431
2023-08-10 21:36:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 21:36:08 | INFO | fairseq.trainer | begin training epoch 26
2023-08-10 21:36:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 21:37:01 | INFO | train_inner | epoch 026:     66 / 1474 loss=1.969, trans_loss=4.972, nll_loss=2.161, w2v_ctc_loss=0.621, task_loss=1.317, contrastive_loss=0.073, total=4180.21, n_correct=2759.62, ppl=4.47, accuracy=66.016, wps=6596.4, ups=0.79, wpb=8360.4, bsz=318.3, num_updates=36900, lr=7.3621e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=30484
2023-08-10 21:38:10 | INFO | train_inner | epoch 026:    166 / 1474 loss=1.985, trans_loss=4.968, nll_loss=2.157, w2v_ctc_loss=0.609, task_loss=1.231, contrastive_loss=0.256, total=4270.78, n_correct=2825.76, ppl=4.46, accuracy=66.165, wps=12384.7, ups=1.45, wpb=8541.6, bsz=340.4, num_updates=37000, lr=7.35215e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=15.2, wall=30553
2023-08-10 21:39:19 | INFO | train_inner | epoch 026:    266 / 1474 loss=1.98, trans_loss=4.972, nll_loss=2.16, w2v_ctc_loss=0.63, task_loss=1.387, contrastive_loss=0.13, total=4125.04, n_correct=2719.16, ppl=4.47, accuracy=65.918, wps=12046.9, ups=1.46, wpb=8250.1, bsz=307.1, num_updates=37100, lr=7.34223e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=68, gb_free=15, wall=30622
2023-08-10 21:40:27 | INFO | train_inner | epoch 026:    366 / 1474 loss=1.973, trans_loss=4.975, nll_loss=2.164, w2v_ctc_loss=0.625, task_loss=1.341, contrastive_loss=0.09, total=4165.74, n_correct=2747.85, ppl=4.48, accuracy=65.963, wps=12196.9, ups=1.46, wpb=8331.5, bsz=314.7, num_updates=37200, lr=7.33236e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=30690
2023-08-10 21:41:35 | INFO | train_inner | epoch 026:    466 / 1474 loss=1.975, trans_loss=4.969, nll_loss=2.156, w2v_ctc_loss=0.62, task_loss=1.331, contrastive_loss=0.138, total=4170.23, n_correct=2757.43, ppl=4.46, accuracy=66.122, wps=12270.1, ups=1.47, wpb=8340.5, bsz=315.4, num_updates=37300, lr=7.32252e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=68, gb_free=17.7, wall=30758
2023-08-10 21:42:44 | INFO | train_inner | epoch 026:    566 / 1474 loss=1.978, trans_loss=4.985, nll_loss=2.176, w2v_ctc_loss=0.639, task_loss=1.414, contrastive_loss=0.057, total=4155.02, n_correct=2734.33, ppl=4.52, accuracy=65.808, wps=12123.1, ups=1.46, wpb=8310, bsz=303.9, num_updates=37400, lr=7.31272e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=68, gb_free=17.7, wall=30827
2023-08-10 21:43:52 | INFO | train_inner | epoch 026:    666 / 1474 loss=1.969, trans_loss=4.982, nll_loss=2.173, w2v_ctc_loss=0.619, task_loss=1.428, contrastive_loss=0.044, total=4136.96, n_correct=2723.32, ppl=4.51, accuracy=65.829, wps=12074.2, ups=1.46, wpb=8273.9, bsz=299.2, num_updates=37500, lr=7.30297e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=68, gb_free=15.3, wall=30895
2023-08-10 21:45:00 | INFO | train_inner | epoch 026:    766 / 1474 loss=1.991, trans_loss=4.991, nll_loss=2.185, w2v_ctc_loss=0.625, task_loss=1.422, contrastive_loss=0.158, total=4086.28, n_correct=2680.97, ppl=4.55, accuracy=65.609, wps=11973.8, ups=1.47, wpb=8172.6, bsz=298.5, num_updates=37600, lr=7.29325e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=68, gb_free=15, wall=30963
2023-08-10 21:46:09 | INFO | train_inner | epoch 026:    866 / 1474 loss=1.976, trans_loss=4.986, nll_loss=2.178, w2v_ctc_loss=0.63, task_loss=1.385, contrastive_loss=0.057, total=4183.26, n_correct=2747.31, ppl=4.53, accuracy=65.674, wps=12195.3, ups=1.46, wpb=8366.5, bsz=308.1, num_updates=37700, lr=7.28357e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=31032
2023-08-10 21:47:18 | INFO | train_inner | epoch 026:    966 / 1474 loss=1.982, trans_loss=4.996, nll_loss=2.191, w2v_ctc_loss=0.617, task_loss=1.449, contrastive_loss=0.111, total=4137.96, n_correct=2714.61, ppl=4.57, accuracy=65.603, wps=12013.7, ups=1.45, wpb=8275.9, bsz=299, num_updates=37800, lr=7.27393e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=31101
2023-08-10 21:48:26 | INFO | train_inner | epoch 026:   1066 / 1474 loss=1.974, trans_loss=4.991, nll_loss=2.185, w2v_ctc_loss=0.627, task_loss=1.467, contrastive_loss=0.044, total=4120.53, n_correct=2708.16, ppl=4.55, accuracy=65.724, wps=12021.2, ups=1.46, wpb=8241.1, bsz=294.3, num_updates=37900, lr=7.26433e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=68, gb_free=16.6, wall=31169
2023-08-10 21:49:35 | INFO | train_inner | epoch 026:   1166 / 1474 loss=1.983, trans_loss=4.998, nll_loss=2.194, w2v_ctc_loss=0.627, task_loss=1.465, contrastive_loss=0.083, total=4113.86, n_correct=2695.13, ppl=4.57, accuracy=65.513, wps=11999.8, ups=1.46, wpb=8227.7, bsz=298.5, num_updates=38000, lr=7.25476e-05, gnorm=0.534, clip=0, loss_scale=64, train_wall=68, gb_free=16.5, wall=31238
2023-08-10 21:49:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 21:49:59 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.213 | trans_loss 5.548 | nll_loss 2.82 | w2v_ctc_loss 1.335 | task_loss 4.618 | contrastive_loss 0.244 | total 4003.4 | n_correct 2497.7 | ppl 7.06 | accuracy 62.389 | uer 17.214 | wer 18.94 | raw_wer 18.94 | bleu 20.15 | wps 2067.6 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.28
2023-08-10 21:49:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-08-10 21:49:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_26_38000.pt
2023-08-10 21:50:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_26_38000.pt
2023-08-10 21:50:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 20.15) (writing took 35.6091279797256 seconds)
2023-08-10 21:51:43 | INFO | train_inner | epoch 026:   1266 / 1474 loss=1.989, trans_loss=5.009, nll_loss=2.208, w2v_ctc_loss=0.644, task_loss=1.562, contrastive_loss=0.046, total=3996.19, n_correct=2606.41, ppl=4.62, accuracy=65.222, wps=6229.5, ups=0.78, wpb=7992.4, bsz=279.3, num_updates=38100, lr=7.24524e-05, gnorm=0.537, clip=0, loss_scale=64, train_wall=68, gb_free=17.7, wall=31366
2023-08-10 21:52:53 | INFO | train_inner | epoch 026:   1366 / 1474 loss=1.974, trans_loss=4.997, nll_loss=2.194, w2v_ctc_loss=0.619, task_loss=1.393, contrastive_loss=0.058, total=4159.74, n_correct=2734.42, ppl=4.57, accuracy=65.735, wps=12001.4, ups=1.44, wpb=8319.5, bsz=311.4, num_updates=38200, lr=7.23575e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=69, gb_free=17.1, wall=31436
2023-08-10 21:54:01 | INFO | train_inner | epoch 026:   1466 / 1474 loss=1.969, trans_loss=4.993, nll_loss=2.189, w2v_ctc_loss=0.615, task_loss=1.324, contrastive_loss=0.053, total=4165.66, n_correct=2739.69, ppl=4.56, accuracy=65.768, wps=12179.3, ups=1.46, wpb=8331.3, bsz=317.5, num_updates=38300, lr=7.22629e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=68, gb_free=16.1, wall=31504
2023-08-10 21:54:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 21:54:31 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.201 | trans_loss 5.546 | nll_loss 2.817 | w2v_ctc_loss 1.298 | task_loss 4.588 | contrastive_loss 0.245 | total 4003.4 | n_correct 2492.4 | ppl 7.05 | accuracy 62.257 | uer 16.97 | wer 18.56 | raw_wer 18.56 | bleu 20.07 | wps 2071.8 | wpb 4003.4 | bsz 141.8 | num_updates 38308 | best_bleu 20.28
2023-08-10 21:54:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38308 updates
2023-08-10 21:54:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_last.pt
2023-08-10 21:54:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_last.pt
2023-08-10 21:54:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_last.pt (epoch 26 @ 38308 updates, score 20.07) (writing took 13.481438403949142 seconds)
2023-08-10 21:54:44 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-10 21:54:44 | INFO | train | epoch 026 | loss 1.978 | trans_loss 4.985 | nll_loss 2.177 | w2v_ctc_loss 0.624 | task_loss 1.399 | contrastive_loss 0.094 | total 4138.65 | n_correct 2722.92 | ppl 4.52 | accuracy 65.792 | wps 10929.8 | ups 1.32 | wpb 8277.3 | bsz 305.7 | num_updates 38308 | lr 7.22554e-05 | gnorm 0.534 | clip 0 | loss_scale 64 | train_wall 1003 | gb_free 15.9 | wall 31547
2023-08-10 21:54:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 21:54:44 | INFO | fairseq.trainer | begin training epoch 27
2023-08-10 21:54:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 21:55:54 | INFO | train_inner | epoch 027:     92 / 1474 loss=1.954, trans_loss=4.95, nll_loss=2.13, w2v_ctc_loss=0.61, task_loss=1.505, contrastive_loss=0.036, total=4054.57, n_correct=2693.9, ppl=4.38, accuracy=66.441, wps=7147.8, ups=0.88, wpb=8109.1, bsz=282.4, num_updates=38400, lr=7.21688e-05, gnorm=0.536, clip=0, loss_scale=64, train_wall=67, gb_free=16.2, wall=31617
2023-08-10 21:57:03 | INFO | train_inner | epoch 027:    192 / 1474 loss=1.956, trans_loss=4.954, nll_loss=2.137, w2v_ctc_loss=0.617, task_loss=1.331, contrastive_loss=0.059, total=4195.2, n_correct=2786.65, ppl=4.4, accuracy=66.425, wps=12266.9, ups=1.46, wpb=8390.4, bsz=323.2, num_updates=38500, lr=7.2075e-05, gnorm=0.529, clip=0, loss_scale=64, train_wall=68, gb_free=17.1, wall=31686
2023-08-10 21:58:12 | INFO | train_inner | epoch 027:    292 / 1474 loss=1.959, trans_loss=4.963, nll_loss=2.148, w2v_ctc_loss=0.617, task_loss=1.401, contrastive_loss=0.045, total=4162.23, n_correct=2761.18, ppl=4.43, accuracy=66.339, wps=12036.6, ups=1.45, wpb=8324.5, bsz=305.5, num_updates=38600, lr=7.19816e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=69, gb_free=17, wall=31755
2023-08-10 21:58:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-10 21:59:22 | INFO | train_inner | epoch 027:    393 / 1474 loss=1.971, trans_loss=4.97, nll_loss=2.157, w2v_ctc_loss=0.617, task_loss=1.51, contrastive_loss=0.112, total=4052.96, n_correct=2679.79, ppl=4.46, accuracy=66.119, wps=11635.9, ups=1.44, wpb=8105.9, bsz=288.5, num_updates=38700, lr=7.18885e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=17.6, wall=31825
2023-08-10 22:00:31 | INFO | train_inner | epoch 027:    493 / 1474 loss=1.978, trans_loss=4.978, nll_loss=2.169, w2v_ctc_loss=0.616, task_loss=1.279, contrastive_loss=0.161, total=4249.35, n_correct=2802.98, ppl=4.5, accuracy=65.963, wps=12339.1, ups=1.45, wpb=8498.7, bsz=331.9, num_updates=38800, lr=7.17958e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=68, gb_free=11.9, wall=31894
2023-08-10 22:01:39 | INFO | train_inner | epoch 027:    593 / 1474 loss=1.974, trans_loss=4.975, nll_loss=2.165, w2v_ctc_loss=0.622, task_loss=1.37, contrastive_loss=0.102, total=4133.39, n_correct=2727.95, ppl=4.48, accuracy=65.998, wps=12016, ups=1.45, wpb=8266.8, bsz=312, num_updates=38900, lr=7.17035e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=68, gb_free=12, wall=31962
2023-08-10 22:02:48 | INFO | train_inner | epoch 027:    693 / 1474 loss=1.975, trans_loss=4.981, nll_loss=2.172, w2v_ctc_loss=0.624, task_loss=1.397, contrastive_loss=0.079, total=4162.71, n_correct=2743.04, ppl=4.51, accuracy=65.896, wps=12224.5, ups=1.47, wpb=8325.4, bsz=305.4, num_updates=39000, lr=7.16115e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=32030
2023-08-10 22:03:56 | INFO | train_inner | epoch 027:    793 / 1474 loss=1.971, trans_loss=4.981, nll_loss=2.172, w2v_ctc_loss=0.625, task_loss=1.473, contrastive_loss=0.046, total=4103.81, n_correct=2703.45, ppl=4.51, accuracy=65.877, wps=12028, ups=1.47, wpb=8207.6, bsz=294.2, num_updates=39100, lr=7.15199e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=32099
2023-08-10 22:05:05 | INFO | train_inner | epoch 027:    893 / 1474 loss=1.964, trans_loss=4.985, nll_loss=2.176, w2v_ctc_loss=0.613, task_loss=1.458, contrastive_loss=0.038, total=4101.56, n_correct=2706.75, ppl=4.52, accuracy=65.993, wps=11894.1, ups=1.45, wpb=8203.1, bsz=292.1, num_updates=39200, lr=7.14286e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=17.7, wall=32168
2023-08-10 22:06:13 | INFO | train_inner | epoch 027:    993 / 1474 loss=1.987, trans_loss=4.981, nll_loss=2.173, w2v_ctc_loss=0.615, task_loss=1.356, contrastive_loss=0.222, total=4199.56, n_correct=2767.97, ppl=4.51, accuracy=65.911, wps=12226.1, ups=1.46, wpb=8399.1, bsz=316.8, num_updates=39300, lr=7.13376e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=11.5, wall=32236
2023-08-10 22:07:21 | INFO | train_inner | epoch 027:   1093 / 1474 loss=1.963, trans_loss=4.978, nll_loss=2.169, w2v_ctc_loss=0.611, task_loss=1.409, contrastive_loss=0.055, total=4150.97, n_correct=2737.08, ppl=4.5, accuracy=65.938, wps=12202, ups=1.47, wpb=8301.9, bsz=305, num_updates=39400, lr=7.1247e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=11.9, wall=32304
2023-08-10 22:08:30 | INFO | train_inner | epoch 027:   1193 / 1474 loss=1.976, trans_loss=4.987, nll_loss=2.181, w2v_ctc_loss=0.63, task_loss=1.461, contrastive_loss=0.058, total=4103.06, n_correct=2697.52, ppl=4.53, accuracy=65.744, wps=11922, ups=1.45, wpb=8206.1, bsz=297.7, num_updates=39500, lr=7.11568e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=32373
2023-08-10 22:09:38 | INFO | train_inner | epoch 027:   1293 / 1474 loss=1.986, trans_loss=4.994, nll_loss=2.189, w2v_ctc_loss=0.627, task_loss=1.499, contrastive_loss=0.111, total=4062.52, n_correct=2663.21, ppl=4.56, accuracy=65.556, wps=11934.2, ups=1.47, wpb=8125, bsz=292.2, num_updates=39600, lr=7.10669e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=32441
2023-08-10 22:10:46 | INFO | train_inner | epoch 027:   1393 / 1474 loss=1.972, trans_loss=4.986, nll_loss=2.179, w2v_ctc_loss=0.614, task_loss=1.321, contrastive_loss=0.092, total=4152, n_correct=2734.07, ppl=4.53, accuracy=65.849, wps=12274.3, ups=1.48, wpb=8304, bsz=312.5, num_updates=39700, lr=7.09773e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=32509
2023-08-10 22:11:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 22:12:06 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.192 | trans_loss 5.54 | nll_loss 2.809 | w2v_ctc_loss 1.287 | task_loss 4.602 | contrastive_loss 0.236 | total 4003.4 | n_correct 2500.3 | ppl 7.01 | accuracy 62.454 | uer 16.672 | wer 18.504 | raw_wer 18.504 | bleu 20.37 | wps 2128.8 | wpb 4003.4 | bsz 141.8 | num_updates 39781 | best_bleu 20.37
2023-08-10 22:12:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39781 updates
2023-08-10 22:12:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 22:12:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 22:12:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt (epoch 27 @ 39781 updates, score 20.37) (writing took 24.727728199213743 seconds)
2023-08-10 22:12:31 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-10 22:12:31 | INFO | train | epoch 027 | loss 1.97 | trans_loss 4.976 | nll_loss 2.166 | w2v_ctc_loss 0.618 | task_loss 1.402 | contrastive_loss 0.086 | total 4136.97 | n_correct 2730.68 | ppl 4.49 | accuracy 66.007 | wps 11423.5 | ups 1.38 | wpb 8273.9 | bsz 305.1 | num_updates 39781 | lr 7.0905e-05 | gnorm 0.533 | clip 0 | loss_scale 32 | train_wall 1003 | gb_free 17.8 | wall 32614
2023-08-10 22:12:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 22:12:31 | INFO | fairseq.trainer | begin training epoch 28
2023-08-10 22:12:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 22:12:52 | INFO | train_inner | epoch 028:     19 / 1474 loss=1.96, trans_loss=4.977, nll_loss=2.168, w2v_ctc_loss=0.61, task_loss=1.353, contrastive_loss=0.046, total=4108.43, n_correct=2717.02, ppl=4.49, accuracy=66.133, wps=6529.2, ups=0.79, wpb=8216.9, bsz=305.1, num_updates=39800, lr=7.08881e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=32635
2023-08-10 22:14:00 | INFO | train_inner | epoch 028:    119 / 1474 loss=1.95, trans_loss=4.946, nll_loss=2.126, w2v_ctc_loss=0.608, task_loss=1.46, contrastive_loss=0.043, total=4113.41, n_correct=2742.39, ppl=4.36, accuracy=66.67, wps=12045.4, ups=1.46, wpb=8226.8, bsz=293.9, num_updates=39900, lr=7.07992e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=32703
2023-08-10 22:15:09 | INFO | train_inner | epoch 028:    219 / 1474 loss=1.951, trans_loss=4.955, nll_loss=2.138, w2v_ctc_loss=0.607, task_loss=1.326, contrastive_loss=0.049, total=4191.56, n_correct=2789.31, ppl=4.4, accuracy=66.546, wps=12204.4, ups=1.46, wpb=8383.1, bsz=315.2, num_updates=40000, lr=7.07107e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=15.1, wall=32772
2023-08-10 22:15:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 22:15:33 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.217 | trans_loss 5.556 | nll_loss 2.828 | w2v_ctc_loss 1.33 | task_loss 4.609 | contrastive_loss 0.241 | total 4003.4 | n_correct 2497.2 | ppl 7.1 | accuracy 62.377 | uer 16.834 | wer 18.527 | raw_wer 18.527 | bleu 20.01 | wps 2054.7 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.37
2023-08-10 22:15:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-08-10 22:15:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_28_40000.pt
2023-08-10 22:15:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_28_40000.pt
2023-08-10 22:16:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 20.01) (writing took 32.191859217360616 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:0')
2023-08-10 22:17:17 | INFO | train_inner | epoch 028:    319 / 1474 loss=1.998, trans_loss=4.963, nll_loss=2.149, w2v_ctc_loss=0.603, task_loss=1.387, contrastive_loss=0.377, total=4145.32, n_correct=2740.48, ppl=4.44, accuracy=66.11, wps=6465.4, ups=0.78, wpb=8290.6, bsz=316.1, num_updates=40100, lr=7.06225e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=32900
2023-08-10 22:18:25 | INFO | train_inner | epoch 028:    419 / 1474 loss=1.959, trans_loss=4.962, nll_loss=2.147, w2v_ctc_loss=0.618, task_loss=1.446, contrastive_loss=0.039, total=4092.14, n_correct=2713.88, ppl=4.43, accuracy=66.319, wps=12088.6, ups=1.48, wpb=8184.3, bsz=295.7, num_updates=40200, lr=7.05346e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=32968
2023-08-10 22:19:33 | INFO | train_inner | epoch 028:    519 / 1474 loss=1.959, trans_loss=4.964, nll_loss=2.15, w2v_ctc_loss=0.611, task_loss=1.455, contrastive_loss=0.05, total=4096.35, n_correct=2713.18, ppl=4.44, accuracy=66.234, wps=11978.5, ups=1.46, wpb=8192.7, bsz=295.5, num_updates=40300, lr=7.0447e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=33036
2023-08-10 22:20:42 | INFO | train_inner | epoch 028:    619 / 1474 loss=1.963, trans_loss=4.975, nll_loss=2.165, w2v_ctc_loss=0.615, task_loss=1.409, contrastive_loss=0.049, total=4178.12, n_correct=2760.1, ppl=4.48, accuracy=66.061, wps=12158.1, ups=1.45, wpb=8356.2, bsz=305.3, num_updates=40400, lr=7.03598e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=33105
2023-08-10 22:21:50 | INFO | train_inner | epoch 028:    719 / 1474 loss=1.972, trans_loss=4.971, nll_loss=2.161, w2v_ctc_loss=0.609, task_loss=1.273, contrastive_loss=0.157, total=4185.82, n_correct=2768.88, ppl=4.47, accuracy=66.149, wps=12253.4, ups=1.46, wpb=8371.6, bsz=326.4, num_updates=40500, lr=7.02728e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=33173
2023-08-10 22:22:58 | INFO | train_inner | epoch 028:    819 / 1474 loss=1.955, trans_loss=4.968, nll_loss=2.156, w2v_ctc_loss=0.609, task_loss=1.372, contrastive_loss=0.042, total=4096.2, n_correct=2718.05, ppl=4.46, accuracy=66.355, wps=12044.8, ups=1.47, wpb=8192.4, bsz=307, num_updates=40600, lr=7.01862e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=33241
2023-08-10 22:23:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-10 22:24:08 | INFO | train_inner | epoch 028:    920 / 1474 loss=1.968, trans_loss=4.979, nll_loss=2.17, w2v_ctc_loss=0.621, task_loss=1.47, contrastive_loss=0.044, total=4101.4, n_correct=2704.56, ppl=4.5, accuracy=65.942, wps=11747.3, ups=1.43, wpb=8202.8, bsz=294.5, num_updates=40700, lr=7.01e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=69, gb_free=15.3, wall=33311
2023-08-10 22:25:16 | INFO | train_inner | epoch 028:   1020 / 1474 loss=1.983, trans_loss=4.98, nll_loss=2.171, w2v_ctc_loss=0.622, task_loss=1.366, contrastive_loss=0.151, total=4182.85, n_correct=2757.54, ppl=4.5, accuracy=65.925, wps=12316.7, ups=1.47, wpb=8365.7, bsz=312, num_updates=40800, lr=7.0014e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=67, gb_free=16.4, wall=33379
2023-08-10 22:26:25 | INFO | train_inner | epoch 028:   1120 / 1474 loss=1.958, trans_loss=4.969, nll_loss=2.158, w2v_ctc_loss=0.61, task_loss=1.345, contrastive_loss=0.06, total=4220.16, n_correct=2792.11, ppl=4.46, accuracy=66.161, wps=12274.4, ups=1.45, wpb=8440.3, bsz=321, num_updates=40900, lr=6.99284e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=33448
2023-08-10 22:27:33 | INFO | train_inner | epoch 028:   1220 / 1474 loss=1.96, trans_loss=4.978, nll_loss=2.169, w2v_ctc_loss=0.608, task_loss=1.391, contrastive_loss=0.047, total=4092.46, n_correct=2702.65, ppl=4.5, accuracy=66.04, wps=12010.6, ups=1.47, wpb=8184.9, bsz=303.1, num_updates=41000, lr=6.9843e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=33516
2023-08-10 22:28:42 | INFO | train_inner | epoch 028:   1320 / 1474 loss=1.976, trans_loss=4.985, nll_loss=2.176, w2v_ctc_loss=0.629, task_loss=1.534, contrastive_loss=0.061, total=4084.55, n_correct=2686.47, ppl=4.52, accuracy=65.772, wps=11924.5, ups=1.46, wpb=8169.1, bsz=285.1, num_updates=41100, lr=6.9758e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=33584
2023-08-10 22:29:50 | INFO | train_inner | epoch 028:   1420 / 1474 loss=1.97, trans_loss=4.98, nll_loss=2.17, w2v_ctc_loss=0.613, task_loss=1.459, contrastive_loss=0.084, total=4154.09, n_correct=2739.76, ppl=4.5, accuracy=65.953, wps=12049.1, ups=1.45, wpb=8308.2, bsz=299.3, num_updates=41200, lr=6.96733e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=33653
2023-08-10 22:30:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:5')
2023-08-10 22:30:51 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.201 | trans_loss 5.547 | nll_loss 2.817 | w2v_ctc_loss 1.3 | task_loss 4.613 | contrastive_loss 0.239 | total 4003.4 | n_correct 2504.4 | ppl 7.05 | accuracy 62.557 | uer 16.787 | wer 18.482 | raw_wer 18.482 | bleu 20.54 | wps 2155.9 | wpb 4003.4 | bsz 141.8 | num_updates 41254 | best_bleu 20.54
2023-08-10 22:30:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41254 updates
2023-08-10 22:30:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 22:31:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt
2023-08-10 22:31:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_best.pt (epoch 28 @ 41254 updates, score 20.54) (writing took 24.15821010991931 seconds)
2023-08-10 22:31:16 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-10 22:31:16 | INFO | train | epoch 028 | loss 1.966 | trans_loss 4.969 | nll_loss 2.157 | w2v_ctc_loss 0.613 | task_loss 1.4 | contrastive_loss 0.089 | total 4137.68 | n_correct 2738.03 | ppl 4.46 | accuracy 66.173 | wps 10839.6 | ups 1.31 | wpb 8275.4 | bsz 305.3 | num_updates 41254 | lr 6.96277e-05 | gnorm 0.536 | clip 0 | loss_scale 32 | train_wall 1002 | gb_free 16.4 | wall 33739
2023-08-10 22:31:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 22:31:16 | INFO | fairseq.trainer | begin training epoch 29
2023-08-10 22:31:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 22:31:55 | INFO | train_inner | epoch 029:     46 / 1474 loss=1.954, trans_loss=4.954, nll_loss=2.138, w2v_ctc_loss=0.613, task_loss=1.344, contrastive_loss=0.058, total=4169.12, n_correct=2775.09, ppl=4.4, accuracy=66.563, wps=6686.1, ups=0.8, wpb=8338.2, bsz=316.4, num_updates=41300, lr=6.95889e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=33778
2023-08-10 22:33:03 | INFO | train_inner | epoch 029:    146 / 1474 loss=1.957, trans_loss=4.953, nll_loss=2.135, w2v_ctc_loss=0.61, task_loss=1.393, contrastive_loss=0.073, total=4105.72, n_correct=2729.53, ppl=4.39, accuracy=66.481, wps=12062.2, ups=1.47, wpb=8211.4, bsz=304.1, num_updates=41400, lr=6.95048e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=33846
2023-08-10 22:34:13 | INFO | train_inner | epoch 029:    246 / 1474 loss=1.958, trans_loss=4.944, nll_loss=2.125, w2v_ctc_loss=0.596, task_loss=1.277, contrastive_loss=0.16, total=4199.67, n_correct=2800.32, ppl=4.36, accuracy=66.68, wps=12093.6, ups=1.44, wpb=8399.3, bsz=330.5, num_updates=41500, lr=6.9421e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=33916
2023-08-10 22:35:21 | INFO | train_inner | epoch 029:    346 / 1474 loss=1.962, trans_loss=4.967, nll_loss=2.153, w2v_ctc_loss=0.62, task_loss=1.5, contrastive_loss=0.045, total=4095.17, n_correct=2711.73, ppl=4.45, accuracy=66.218, wps=11999.5, ups=1.47, wpb=8190.3, bsz=291.2, num_updates=41600, lr=6.93375e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=33984
2023-08-10 22:36:29 | INFO | train_inner | epoch 029:    446 / 1474 loss=1.942, trans_loss=4.941, nll_loss=2.119, w2v_ctc_loss=0.6, task_loss=1.352, contrastive_loss=0.039, total=4157.44, n_correct=2775.81, ppl=4.34, accuracy=66.767, wps=12222.6, ups=1.47, wpb=8314.9, bsz=307.7, num_updates=41700, lr=6.92543e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=34052
2023-08-10 22:37:38 | INFO | train_inner | epoch 029:    546 / 1474 loss=1.972, trans_loss=4.966, nll_loss=2.152, w2v_ctc_loss=0.608, task_loss=1.493, contrastive_loss=0.132, total=4150.87, n_correct=2748.33, ppl=4.44, accuracy=66.211, wps=12055.6, ups=1.45, wpb=8301.7, bsz=294.9, num_updates=41800, lr=6.91714e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=34121
2023-08-10 22:38:46 | INFO | train_inner | epoch 029:    646 / 1474 loss=1.966, trans_loss=4.954, nll_loss=2.138, w2v_ctc_loss=0.601, task_loss=1.324, contrastive_loss=0.203, total=4143.02, n_correct=2754.89, ppl=4.4, accuracy=66.495, wps=12182.7, ups=1.47, wpb=8286, bsz=318.6, num_updates=41900, lr=6.90889e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=67, gb_free=17, wall=34189
2023-08-10 22:39:55 | INFO | train_inner | epoch 029:    746 / 1474 loss=1.957, trans_loss=4.955, nll_loss=2.14, w2v_ctc_loss=0.6, task_loss=1.294, contrastive_loss=0.118, total=4249.79, n_correct=2824.71, ppl=4.41, accuracy=66.467, wps=12291.2, ups=1.45, wpb=8499.6, bsz=330, num_updates=42000, lr=6.90066e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=34258
2023-08-10 22:39:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 22:40:19 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.228 | trans_loss 5.549 | nll_loss 2.821 | w2v_ctc_loss 1.383 | task_loss 4.627 | contrastive_loss 0.244 | total 4003.4 | n_correct 2495.9 | ppl 7.06 | accuracy 62.345 | uer 17.36 | wer 19.041 | raw_wer 19.041 | bleu 20.22 | wps 2156.7 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.54
2023-08-10 22:40:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-08-10 22:40:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_29_42000.pt
2023-08-10 22:40:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_29_42000.pt
2023-08-10 22:40:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 20.22) (writing took 21.71062601543963 seconds)
2023-08-10 22:41:50 | INFO | train_inner | epoch 029:    846 / 1474 loss=1.964, trans_loss=4.979, nll_loss=2.169, w2v_ctc_loss=0.614, task_loss=1.558, contrastive_loss=0.038, total=4027.19, n_correct=2658.59, ppl=4.5, accuracy=66.016, wps=7002.7, ups=0.87, wpb=8054.4, bsz=280.6, num_updates=42100, lr=6.89246e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=34373
2023-08-10 22:42:57 | INFO | train_inner | epoch 029:    946 / 1474 loss=1.961, trans_loss=4.973, nll_loss=2.162, w2v_ctc_loss=0.615, task_loss=1.427, contrastive_loss=0.048, total=4082.14, n_correct=2701.75, ppl=4.48, accuracy=66.185, wps=12111.6, ups=1.48, wpb=8164.3, bsz=296.3, num_updates=42200, lr=6.88428e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=67, gb_free=15.3, wall=34440
2023-08-10 22:44:06 | INFO | train_inner | epoch 029:   1046 / 1474 loss=1.96, trans_loss=4.961, nll_loss=2.148, w2v_ctc_loss=0.601, task_loss=1.395, contrastive_loss=0.118, total=4148.18, n_correct=2752.94, ppl=4.43, accuracy=66.365, wps=12188.4, ups=1.47, wpb=8296.4, bsz=308.2, num_updates=42300, lr=6.87614e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=34508
2023-08-10 22:45:14 | INFO | train_inner | epoch 029:   1146 / 1474 loss=1.963, trans_loss=4.978, nll_loss=2.169, w2v_ctc_loss=0.616, task_loss=1.533, contrastive_loss=0.035, total=4063.95, n_correct=2685.66, ppl=4.5, accuracy=66.085, wps=11877, ups=1.46, wpb=8127.9, bsz=283, num_updates=42400, lr=6.86803e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=13.1, wall=34577
2023-08-10 22:46:22 | INFO | train_inner | epoch 029:   1246 / 1474 loss=1.962, trans_loss=4.977, nll_loss=2.168, w2v_ctc_loss=0.616, task_loss=1.421, contrastive_loss=0.042, total=4158.81, n_correct=2750.62, ppl=4.49, accuracy=66.14, wps=12156.1, ups=1.46, wpb=8317.6, bsz=301.2, num_updates=42500, lr=6.85994e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=15.5, wall=34645
2023-08-10 22:47:31 | INFO | train_inner | epoch 029:   1346 / 1474 loss=1.965, trans_loss=4.968, nll_loss=2.156, w2v_ctc_loss=0.607, task_loss=1.377, contrastive_loss=0.104, total=4166.34, n_correct=2763.57, ppl=4.46, accuracy=66.331, wps=12234.5, ups=1.47, wpb=8332.7, bsz=310.7, num_updates=42600, lr=6.85189e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=68, gb_free=17.8, wall=34713
2023-08-10 22:48:39 | INFO | train_inner | epoch 029:   1446 / 1474 loss=1.97, trans_loss=4.97, nll_loss=2.16, w2v_ctc_loss=0.611, task_loss=1.375, contrastive_loss=0.136, total=4162.2, n_correct=2752.39, ppl=4.47, accuracy=66.128, wps=12177, ups=1.46, wpb=8324.4, bsz=311.5, num_updates=42700, lr=6.84386e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=34782
2023-08-10 22:48:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 22:49:22 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.202 | trans_loss 5.542 | nll_loss 2.808 | w2v_ctc_loss 1.316 | task_loss 4.63 | contrastive_loss 0.243 | total 4003.4 | n_correct 2500 | ppl 7 | accuracy 62.447 | uer 16.601 | wer 18.21 | raw_wer 18.21 | bleu 20.28 | wps 2111.4 | wpb 4003.4 | bsz 141.8 | num_updates 42728 | best_bleu 20.54
2023-08-10 22:49:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42728 updates
2023-08-10 22:49:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.2803.pt
2023-08-10 22:49:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.2803.pt
2023-08-10 22:49:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.2803.pt (epoch 29 @ 42728 updates, score 20.28) (writing took 29.576411129906774 seconds)
2023-08-10 22:49:52 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-10 22:49:52 | INFO | train | epoch 029 | loss 1.961 | trans_loss 4.963 | nll_loss 2.148 | w2v_ctc_loss 0.608 | task_loss 1.4 | contrastive_loss 0.092 | total 4138.65 | n_correct 2745.75 | ppl 4.43 | accuracy 66.344 | wps 10933.7 | ups 1.32 | wpb 8277.3 | bsz 305.7 | num_updates 42728 | lr 6.84162e-05 | gnorm 0.536 | clip 0 | loss_scale 64 | train_wall 1001 | gb_free 16.1 | wall 34855
2023-08-10 22:49:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 22:49:52 | INFO | fairseq.trainer | begin training epoch 30
2023-08-10 22:49:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 22:50:50 | INFO | train_inner | epoch 030:     72 / 1474 loss=1.956, trans_loss=4.946, nll_loss=2.128, w2v_ctc_loss=0.595, task_loss=1.324, contrastive_loss=0.15, total=4182.65, n_correct=2786.79, ppl=4.37, accuracy=66.627, wps=6374.6, ups=0.76, wpb=8365.3, bsz=320.5, num_updates=42800, lr=6.83586e-05, gnorm=0.534, clip=0, loss_scale=64, train_wall=68, gb_free=13.4, wall=34913
2023-08-10 22:51:58 | INFO | train_inner | epoch 030:    172 / 1474 loss=1.944, trans_loss=4.929, nll_loss=2.105, w2v_ctc_loss=0.601, task_loss=1.312, contrastive_loss=0.079, total=4203.05, n_correct=2820.27, ppl=4.3, accuracy=67.101, wps=12381.9, ups=1.47, wpb=8406.1, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=67, gb_free=17.4, wall=34981
2023-08-10 22:53:06 | INFO | train_inner | epoch 030:    272 / 1474 loss=1.949, trans_loss=4.947, nll_loss=2.127, w2v_ctc_loss=0.612, task_loss=1.445, contrastive_loss=0.037, total=4116.93, n_correct=2745.09, ppl=4.37, accuracy=66.678, wps=12089.6, ups=1.47, wpb=8233.9, bsz=295.1, num_updates=43000, lr=6.81994e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=68, gb_free=16.9, wall=35049
2023-08-10 22:54:15 | INFO | train_inner | epoch 030:    372 / 1474 loss=1.941, trans_loss=4.94, nll_loss=2.119, w2v_ctc_loss=0.597, task_loss=1.409, contrastive_loss=0.041, total=4173.13, n_correct=2791.63, ppl=4.34, accuracy=66.895, wps=12195.7, ups=1.46, wpb=8346.3, bsz=305.6, num_updates=43100, lr=6.81203e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=68, gb_free=11.7, wall=35117
2023-08-10 22:55:22 | INFO | train_inner | epoch 030:    472 / 1474 loss=1.948, trans_loss=4.944, nll_loss=2.124, w2v_ctc_loss=0.594, task_loss=1.331, contrastive_loss=0.101, total=4135.2, n_correct=2762.34, ppl=4.36, accuracy=66.801, wps=12253.7, ups=1.48, wpb=8270.4, bsz=314.8, num_updates=43200, lr=6.80414e-05, gnorm=0.539, clip=0, loss_scale=64, train_wall=67, gb_free=16.8, wall=35185
2023-08-10 22:56:30 | INFO | train_inner | epoch 030:    572 / 1474 loss=1.951, trans_loss=4.956, nll_loss=2.14, w2v_ctc_loss=0.602, task_loss=1.365, contrastive_loss=0.064, total=4168.65, n_correct=2773.56, ppl=4.41, accuracy=66.534, wps=12191.6, ups=1.46, wpb=8337.3, bsz=312.1, num_updates=43300, lr=6.79628e-05, gnorm=0.54, clip=0, loss_scale=64, train_wall=68, gb_free=15.8, wall=35253
2023-08-10 22:57:39 | INFO | train_inner | epoch 030:    672 / 1474 loss=1.956, trans_loss=4.953, nll_loss=2.136, w2v_ctc_loss=0.611, task_loss=1.382, contrastive_loss=0.076, total=4183.65, n_correct=2780.71, ppl=4.4, accuracy=66.466, wps=12184.7, ups=1.46, wpb=8367.3, bsz=314.5, num_updates=43400, lr=6.78844e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=68, gb_free=16.7, wall=35322
2023-08-10 22:58:48 | INFO | train_inner | epoch 030:    772 / 1474 loss=1.977, trans_loss=4.967, nll_loss=2.155, w2v_ctc_loss=0.619, task_loss=1.431, contrastive_loss=0.159, total=4106.9, n_correct=2719.17, ppl=4.45, accuracy=66.21, wps=11992.2, ups=1.46, wpb=8213.8, bsz=302.9, num_updates=43500, lr=6.78064e-05, gnorm=0.546, clip=0, loss_scale=64, train_wall=68, gb_free=11.8, wall=35391
2023-08-10 22:59:56 | INFO | train_inner | epoch 030:    872 / 1474 loss=1.952, trans_loss=4.96, nll_loss=2.144, w2v_ctc_loss=0.603, task_loss=1.468, contrastive_loss=0.042, total=4089.18, n_correct=2716.44, ppl=4.42, accuracy=66.43, wps=11977.2, ups=1.46, wpb=8178.4, bsz=291.4, num_updates=43600, lr=6.77285e-05, gnorm=0.534, clip=0, loss_scale=64, train_wall=68, gb_free=16.3, wall=35459
2023-08-10 23:01:04 | INFO | train_inner | epoch 030:    972 / 1474 loss=1.958, trans_loss=4.966, nll_loss=2.153, w2v_ctc_loss=0.608, task_loss=1.409, contrastive_loss=0.059, total=4140.03, n_correct=2742.35, ppl=4.45, accuracy=66.24, wps=12088.9, ups=1.46, wpb=8280.1, bsz=303.9, num_updates=43700, lr=6.7651e-05, gnorm=0.536, clip=0, loss_scale=64, train_wall=68, gb_free=13.7, wall=35527
2023-08-10 23:02:13 | INFO | train_inner | epoch 030:   1072 / 1474 loss=1.974, trans_loss=4.975, nll_loss=2.163, w2v_ctc_loss=0.614, task_loss=1.566, contrastive_loss=0.131, total=4101.12, n_correct=2708.24, ppl=4.48, accuracy=66.037, wps=11932.2, ups=1.45, wpb=8202.2, bsz=282.8, num_updates=43800, lr=6.75737e-05, gnorm=0.544, clip=0, loss_scale=64, train_wall=68, gb_free=16.6, wall=35596
2023-08-10 23:03:22 | INFO | train_inner | epoch 030:   1172 / 1474 loss=1.957, trans_loss=4.961, nll_loss=2.148, w2v_ctc_loss=0.594, task_loss=1.341, contrastive_loss=0.109, total=4168.22, n_correct=2768.61, ppl=4.43, accuracy=66.422, wps=12133.2, ups=1.46, wpb=8336.4, bsz=314.5, num_updates=43900, lr=6.74967e-05, gnorm=0.536, clip=0, loss_scale=64, train_wall=68, gb_free=16.7, wall=35665
2023-08-10 23:04:30 | INFO | train_inner | epoch 030:   1272 / 1474 loss=1.963, trans_loss=4.972, nll_loss=2.159, w2v_ctc_loss=0.614, task_loss=1.563, contrastive_loss=0.045, total=4032.74, n_correct=2667.36, ppl=4.47, accuracy=66.143, wps=11777.4, ups=1.46, wpb=8065.5, bsz=281.8, num_updates=44000, lr=6.742e-05, gnorm=0.544, clip=0, loss_scale=64, train_wall=68, gb_free=16.8, wall=35733
2023-08-10 23:04:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 23:04:55 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.202 | trans_loss 5.549 | nll_loss 2.818 | w2v_ctc_loss 1.299 | task_loss 4.604 | contrastive_loss 0.237 | total 4003.4 | n_correct 2495.6 | ppl 7.05 | accuracy 62.337 | uer 16.821 | wer 18.538 | raw_wer 18.538 | bleu 20.06 | wps 1965.1 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.54
2023-08-10 23:04:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-08-10 23:04:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_30_44000.pt
2023-08-10 23:04:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_30_44000.pt
2023-08-10 23:05:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 20.06) (writing took 18.979061359539628 seconds)
2023-08-10 23:06:22 | INFO | train_inner | epoch 030:   1372 / 1474 loss=1.949, trans_loss=4.96, nll_loss=2.148, w2v_ctc_loss=0.601, task_loss=1.317, contrastive_loss=0.055, total=4166.96, n_correct=2770.32, ppl=4.43, accuracy=66.483, wps=7433.3, ups=0.89, wpb=8333.9, bsz=322.3, num_updates=44100, lr=6.73435e-05, gnorm=0.534, clip=0, loss_scale=64, train_wall=68, gb_free=15.2, wall=35845
2023-08-10 23:07:31 | INFO | train_inner | epoch 030:   1472 / 1474 loss=1.969, trans_loss=4.965, nll_loss=2.154, w2v_ctc_loss=0.598, task_loss=1.336, contrastive_loss=0.202, total=4125.17, n_correct=2736.86, ppl=4.45, accuracy=66.345, wps=12061.6, ups=1.46, wpb=8250.3, bsz=310, num_updates=44200, lr=6.72673e-05, gnorm=0.537, clip=0, loss_scale=64, train_wall=68, gb_free=16.8, wall=35914
2023-08-10 23:07:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 23:07:55 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.198 | trans_loss 5.541 | nll_loss 2.808 | w2v_ctc_loss 1.302 | task_loss 4.594 | contrastive_loss 0.244 | total 4003.4 | n_correct 2502.9 | ppl 7 | accuracy 62.519 | uer 16.829 | wer 18.579 | raw_wer 18.579 | bleu 20.14 | wps 2324.3 | wpb 4003.4 | bsz 141.8 | num_updates 44202 | best_bleu 20.54
2023-08-10 23:07:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44202 updates
2023-08-10 23:07:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_last.pt
2023-08-10 23:08:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_last.pt
2023-08-10 23:08:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_last.pt (epoch 30 @ 44202 updates, score 20.14) (writing took 13.667138935998082 seconds)
2023-08-10 23:08:08 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-10 23:08:08 | INFO | train | epoch 030 | loss 1.956 | trans_loss 4.956 | nll_loss 2.14 | w2v_ctc_loss 0.604 | task_loss 1.399 | contrastive_loss 0.091 | total 4138.65 | n_correct 2752.19 | ppl 4.41 | accuracy 66.5 | wps 11126 | ups 1.34 | wpb 8277.3 | bsz 305.7 | num_updates 44202 | lr 6.72658e-05 | gnorm 0.537 | clip 0 | loss_scale 64 | train_wall 1000 | gb_free 17 | wall 35951
2023-08-10 23:08:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 23:08:09 | INFO | fairseq.trainer | begin training epoch 31
2023-08-10 23:08:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 23:09:23 | INFO | train_inner | epoch 031:     98 / 1474 loss=1.943, trans_loss=4.937, nll_loss=2.113, w2v_ctc_loss=0.603, task_loss=1.45, contrastive_loss=0.042, total=4081.34, n_correct=2733.9, ppl=4.33, accuracy=66.985, wps=7249.8, ups=0.89, wpb=8162.7, bsz=294.7, num_updates=44300, lr=6.71913e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=68, gb_free=16.4, wall=36026
2023-08-10 23:10:32 | INFO | train_inner | epoch 031:    198 / 1474 loss=1.948, trans_loss=4.941, nll_loss=2.12, w2v_ctc_loss=0.605, task_loss=1.431, contrastive_loss=0.065, total=4146.03, n_correct=2768.89, ppl=4.35, accuracy=66.784, wps=12138.4, ups=1.46, wpb=8292.1, bsz=302.2, num_updates=44400, lr=6.71156e-05, gnorm=0.545, clip=0, loss_scale=64, train_wall=68, gb_free=13.2, wall=36095
2023-08-10 23:11:41 | INFO | train_inner | epoch 031:    298 / 1474 loss=1.949, trans_loss=4.937, nll_loss=2.115, w2v_ctc_loss=0.597, task_loss=1.435, contrastive_loss=0.104, total=4146.75, n_correct=2773.76, ppl=4.33, accuracy=66.89, wps=12055.8, ups=1.45, wpb=8293.5, bsz=300.7, num_updates=44500, lr=6.70402e-05, gnorm=0.531, clip=0, loss_scale=64, train_wall=68, gb_free=17.5, wall=36164
2023-08-10 23:12:49 | INFO | train_inner | epoch 031:    398 / 1474 loss=1.95, trans_loss=4.951, nll_loss=2.132, w2v_ctc_loss=0.603, task_loss=1.527, contrastive_loss=0.043, total=4089.43, n_correct=2723.73, ppl=4.38, accuracy=66.604, wps=11979.7, ups=1.46, wpb=8178.9, bsz=285.5, num_updates=44600, lr=6.6965e-05, gnorm=0.541, clip=0, loss_scale=64, train_wall=68, gb_free=16.2, wall=36232
2023-08-10 23:13:58 | INFO | train_inner | epoch 031:    498 / 1474 loss=1.948, trans_loss=4.943, nll_loss=2.123, w2v_ctc_loss=0.61, task_loss=1.458, contrastive_loss=0.05, total=4114.41, n_correct=2745.57, ppl=4.36, accuracy=66.731, wps=11962, ups=1.45, wpb=8228.8, bsz=300.9, num_updates=44700, lr=6.689e-05, gnorm=0.54, clip=0, loss_scale=64, train_wall=68, gb_free=16.1, wall=36301
2023-08-10 23:15:06 | INFO | train_inner | epoch 031:    598 / 1474 loss=1.941, trans_loss=4.944, nll_loss=2.123, w2v_ctc_loss=0.593, task_loss=1.458, contrastive_loss=0.041, total=4084.36, n_correct=2727.78, ppl=4.36, accuracy=66.786, wps=11949.8, ups=1.46, wpb=8168.7, bsz=295, num_updates=44800, lr=6.68153e-05, gnorm=0.536, clip=0, loss_scale=128, train_wall=68, gb_free=16.4, wall=36369
2023-08-10 23:16:14 | INFO | train_inner | epoch 031:    698 / 1474 loss=1.938, trans_loss=4.942, nll_loss=2.121, w2v_ctc_loss=0.591, task_loss=1.336, contrastive_loss=0.042, total=4210.09, n_correct=2814.86, ppl=4.35, accuracy=66.86, wps=12342.4, ups=1.47, wpb=8420.2, bsz=314.9, num_updates=44900, lr=6.67409e-05, gnorm=0.524, clip=0, loss_scale=128, train_wall=68, gb_free=14.6, wall=36437
2023-08-10 23:16:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-10 23:17:24 | INFO | train_inner | epoch 031:    799 / 1474 loss=1.958, trans_loss=4.958, nll_loss=2.142, w2v_ctc_loss=0.602, task_loss=1.491, contrastive_loss=0.095, total=4082.6, n_correct=2713.26, ppl=4.41, accuracy=66.459, wps=11741.4, ups=1.44, wpb=8165.2, bsz=291.2, num_updates=45000, lr=6.66667e-05, gnorm=0.542, clip=0, loss_scale=64, train_wall=69, gb_free=12.8, wall=36507
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:0')
2023-08-10 23:18:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-10 23:18:33 | INFO | train_inner | epoch 031:    900 / 1474 loss=1.95, trans_loss=4.949, nll_loss=2.13, w2v_ctc_loss=0.604, task_loss=1.48, contrastive_loss=0.055, total=4088.7, n_correct=2724.16, ppl=4.38, accuracy=66.627, wps=11839.9, ups=1.45, wpb=8177.4, bsz=292.3, num_updates=45100, lr=6.65927e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=69, gb_free=15.1, wall=36576
2023-08-10 23:19:41 | INFO | train_inner | epoch 031:   1000 / 1474 loss=1.958, trans_loss=4.958, nll_loss=2.143, w2v_ctc_loss=0.596, task_loss=1.307, contrastive_loss=0.139, total=4186.81, n_correct=2784.6, ppl=4.42, accuracy=66.509, wps=12287.7, ups=1.47, wpb=8373.6, bsz=320.9, num_updates=45200, lr=6.6519e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=13.3, wall=36644
2023-08-10 23:20:49 | INFO | train_inner | epoch 031:   1100 / 1474 loss=1.951, trans_loss=4.952, nll_loss=2.136, w2v_ctc_loss=0.597, task_loss=1.367, contrastive_loss=0.084, total=4149.25, n_correct=2763.27, ppl=4.4, accuracy=66.597, wps=12200.7, ups=1.47, wpb=8298.5, bsz=315.2, num_updates=45300, lr=6.64455e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=36712
2023-08-10 23:21:57 | INFO | train_inner | epoch 031:   1200 / 1474 loss=1.964, trans_loss=4.954, nll_loss=2.14, w2v_ctc_loss=0.597, task_loss=1.321, contrastive_loss=0.204, total=4187.45, n_correct=2787.97, ppl=4.41, accuracy=66.579, wps=12271.7, ups=1.47, wpb=8374.9, bsz=320.3, num_updates=45400, lr=6.63723e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=36780
2023-08-10 23:23:05 | INFO | train_inner | epoch 031:   1300 / 1474 loss=1.945, trans_loss=4.956, nll_loss=2.141, w2v_ctc_loss=0.599, task_loss=1.255, contrastive_loss=0.048, total=4227.39, n_correct=2816.9, ppl=4.41, accuracy=66.634, wps=12417.2, ups=1.47, wpb=8454.8, bsz=326.7, num_updates=45500, lr=6.62994e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=36848
2023-08-10 23:24:14 | INFO | train_inner | epoch 031:   1400 / 1474 loss=1.979, trans_loss=4.96, nll_loss=2.148, w2v_ctc_loss=0.6, task_loss=1.278, contrastive_loss=0.25, total=4191.1, n_correct=2775.83, ppl=4.43, accuracy=66.232, wps=12177.6, ups=1.45, wpb=8382.2, bsz=327, num_updates=45600, lr=6.62266e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=36917
2023-08-10 23:25:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2386, device='cuda:7')
2023-08-10 23:25:27 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.21 | trans_loss 5.544 | nll_loss 2.814 | w2v_ctc_loss 1.337 | task_loss 4.621 | contrastive_loss 0.238 | total 4003.4 | n_correct 2499.9 | ppl 7.03 | accuracy 62.444 | uer 16.72 | wer 18.474 | raw_wer 18.474 | bleu 20.39 | wps 2238.4 | wpb 4003.4 | bsz 141.8 | num_updates 45674 | best_bleu 20.54
2023-08-10 23:25:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45674 updates
2023-08-10 23:25:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.3903.pt
2023-08-10 23:25:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.3903.pt
2023-08-10 23:26:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.3903.pt (epoch 31 @ 45674 updates, score 20.39) (writing took 35.646255660802126 seconds)
2023-08-10 23:26:03 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-10 23:26:03 | INFO | train | epoch 031 | loss 1.952 | trans_loss 4.949 | nll_loss 2.132 | w2v_ctc_loss 0.6 | task_loss 1.401 | contrastive_loss 0.089 | total 4136.92 | n_correct 2757.17 | ppl 4.38 | accuracy 66.648 | wps 11327.9 | ups 1.37 | wpb 8273.8 | bsz 305.2 | num_updates 45674 | lr 6.61729e-05 | gnorm 0.537 | clip 0 | loss_scale 32 | train_wall 1000 | gb_free 12 | wall 37026
2023-08-10 23:26:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 23:26:04 | INFO | fairseq.trainer | begin training epoch 32
2023-08-10 23:26:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 23:26:29 | INFO | train_inner | epoch 032:     26 / 1474 loss=1.947, trans_loss=4.951, nll_loss=2.134, w2v_ctc_loss=0.601, task_loss=1.476, contrastive_loss=0.039, total=4040.88, n_correct=2691.33, ppl=4.39, accuracy=66.603, wps=6000.2, ups=0.74, wpb=8081.8, bsz=288.7, num_updates=45700, lr=6.61541e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=68, gb_free=15.5, wall=37052
2023-08-10 23:27:37 | INFO | train_inner | epoch 032:    126 / 1474 loss=1.922, trans_loss=4.915, nll_loss=2.086, w2v_ctc_loss=0.578, task_loss=1.293, contrastive_loss=0.048, total=4222.14, n_correct=2843.6, ppl=4.25, accuracy=67.35, wps=12345.2, ups=1.46, wpb=8444.3, bsz=322.6, num_updates=45800, lr=6.60819e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=68, gb_free=15.4, wall=37120
2023-08-10 23:28:46 | INFO | train_inner | epoch 032:    226 / 1474 loss=1.934, trans_loss=4.932, nll_loss=2.11, w2v_ctc_loss=0.59, task_loss=1.331, contrastive_loss=0.056, total=4159.77, n_correct=2787.31, ppl=4.32, accuracy=67.006, wps=12098.6, ups=1.45, wpb=8319.5, bsz=320.8, num_updates=45900, lr=6.60098e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=37189
2023-08-10 23:29:54 | INFO | train_inner | epoch 032:    326 / 1474 loss=1.927, trans_loss=4.921, nll_loss=2.095, w2v_ctc_loss=0.581, task_loss=1.326, contrastive_loss=0.049, total=4179.65, n_correct=2813.03, ppl=4.27, accuracy=67.303, wps=12277.6, ups=1.47, wpb=8359.3, bsz=313.8, num_updates=46000, lr=6.5938e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=37257
2023-08-10 23:29:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 23:30:19 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.216 | trans_loss 5.552 | nll_loss 2.824 | w2v_ctc_loss 1.333 | task_loss 4.641 | contrastive_loss 0.246 | total 4003.4 | n_correct 2496.8 | ppl 7.08 | accuracy 62.367 | uer 16.688 | wer 18.594 | raw_wer 18.594 | bleu 20.29 | wps 1844.9 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.54
2023-08-10 23:30:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-08-10 23:30:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_32_46000.pt
2023-08-10 23:30:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_32_46000.pt
2023-08-10 23:30:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 20.29) (writing took 39.96738940663636 seconds)
2023-08-10 23:32:11 | INFO | train_inner | epoch 032:    426 / 1474 loss=1.934, trans_loss=4.93, nll_loss=2.106, w2v_ctc_loss=0.592, task_loss=1.368, contrastive_loss=0.05, total=4172.34, n_correct=2803.51, ppl=4.31, accuracy=67.193, wps=6114.8, ups=0.73, wpb=8344.7, bsz=309.9, num_updates=46100, lr=6.58665e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=17.1, wall=37394
2023-08-10 23:33:20 | INFO | train_inner | epoch 032:    526 / 1474 loss=1.951, trans_loss=4.939, nll_loss=2.118, w2v_ctc_loss=0.597, task_loss=1.366, contrastive_loss=0.126, total=4191.15, n_correct=2805.81, ppl=4.34, accuracy=66.946, wps=12125.9, ups=1.45, wpb=8382.3, bsz=315.1, num_updates=46200, lr=6.57952e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=69, gb_free=14.9, wall=37463
2023-08-10 23:34:29 | INFO | train_inner | epoch 032:    626 / 1474 loss=1.946, trans_loss=4.946, nll_loss=2.127, w2v_ctc_loss=0.599, task_loss=1.468, contrastive_loss=0.053, total=4138.05, n_correct=2757.66, ppl=4.37, accuracy=66.642, wps=11951.5, ups=1.44, wpb=8276.1, bsz=299.5, num_updates=46300, lr=6.57241e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=69, gb_free=13.2, wall=37532
2023-08-10 23:35:38 | INFO | train_inner | epoch 032:    726 / 1474 loss=1.944, trans_loss=4.945, nll_loss=2.126, w2v_ctc_loss=0.603, task_loss=1.42, contrastive_loss=0.04, total=4156.23, n_correct=2779, ppl=4.37, accuracy=66.863, wps=12107.7, ups=1.46, wpb=8312.5, bsz=303, num_updates=46400, lr=6.56532e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=37601
2023-08-10 23:36:45 | INFO | train_inner | epoch 032:    826 / 1474 loss=1.937, trans_loss=4.943, nll_loss=2.122, w2v_ctc_loss=0.59, task_loss=1.451, contrastive_loss=0.037, total=4112.3, n_correct=2752.52, ppl=4.35, accuracy=66.934, wps=12144.4, ups=1.48, wpb=8224.6, bsz=293.9, num_updates=46500, lr=6.55826e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=67, gb_free=15.8, wall=37668
2023-08-10 23:37:54 | INFO | train_inner | epoch 032:    926 / 1474 loss=1.939, trans_loss=4.947, nll_loss=2.128, w2v_ctc_loss=0.588, task_loss=1.447, contrastive_loss=0.037, total=4139.37, n_correct=2761.96, ppl=4.37, accuracy=66.724, wps=12000.1, ups=1.45, wpb=8278.7, bsz=298.6, num_updates=46600, lr=6.55122e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=12.6, wall=37737
2023-08-10 23:39:02 | INFO | train_inner | epoch 032:   1026 / 1474 loss=1.957, trans_loss=4.953, nll_loss=2.136, w2v_ctc_loss=0.599, task_loss=1.378, contrastive_loss=0.13, total=4121.85, n_correct=2743.11, ppl=4.4, accuracy=66.55, wps=12156.8, ups=1.47, wpb=8243.7, bsz=306.1, num_updates=46700, lr=6.5442e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=67, gb_free=16.8, wall=37805
2023-08-10 23:40:11 | INFO | train_inner | epoch 032:   1126 / 1474 loss=1.958, trans_loss=4.959, nll_loss=2.142, w2v_ctc_loss=0.603, task_loss=1.66, contrastive_loss=0.072, total=4015.59, n_correct=2667.67, ppl=4.42, accuracy=66.433, wps=11714.3, ups=1.46, wpb=8031.2, bsz=270.1, num_updates=46800, lr=6.5372e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=68, gb_free=17.1, wall=37874
2023-08-10 23:41:20 | INFO | train_inner | epoch 032:   1226 / 1474 loss=1.968, trans_loss=4.962, nll_loss=2.149, w2v_ctc_loss=0.596, task_loss=1.381, contrastive_loss=0.176, total=4153.44, n_correct=2756.44, ppl=4.44, accuracy=66.365, wps=11990.7, ups=1.44, wpb=8306.9, bsz=310.8, num_updates=46900, lr=6.53023e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=37943
2023-08-10 23:42:28 | INFO | train_inner | epoch 032:   1326 / 1474 loss=1.947, trans_loss=4.953, nll_loss=2.136, w2v_ctc_loss=0.602, task_loss=1.445, contrastive_loss=0.037, total=4075.86, n_correct=2711.26, ppl=4.4, accuracy=66.52, wps=12004.7, ups=1.47, wpb=8151.7, bsz=295.4, num_updates=47000, lr=6.52328e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=38011
2023-08-10 23:43:36 | INFO | train_inner | epoch 032:   1426 / 1474 loss=1.977, trans_loss=4.958, nll_loss=2.143, w2v_ctc_loss=0.604, task_loss=1.396, contrastive_loss=0.267, total=4116.4, n_correct=2735.48, ppl=4.42, accuracy=66.453, wps=12086.6, ups=1.47, wpb=8232.8, bsz=307.6, num_updates=47100, lr=6.51635e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=38079
2023-08-10 23:44:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 23:44:33 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.205 | trans_loss 5.542 | nll_loss 2.815 | w2v_ctc_loss 1.323 | task_loss 4.635 | contrastive_loss 0.244 | total 4003.4 | n_correct 2499.1 | ppl 7.04 | accuracy 62.424 | uer 16.704 | wer 18.448 | raw_wer 18.448 | bleu 20.3 | wps 2075.8 | wpb 4003.4 | bsz 141.8 | num_updates 47148 | best_bleu 20.54
2023-08-10 23:44:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47148 updates
2023-08-10 23:44:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.3000.pt
2023-08-10 23:44:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.3000.pt
2023-08-10 23:44:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint.best_bleu_20.3000.pt (epoch 32 @ 47148 updates, score 20.3) (writing took 14.281615983694792 seconds)
2023-08-10 23:44:47 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-10 23:44:47 | INFO | train | epoch 032 | loss 1.946 | trans_loss 4.943 | nll_loss 2.123 | w2v_ctc_loss 0.594 | task_loss 1.4 | contrastive_loss 0.089 | total 4138.65 | n_correct 2765.12 | ppl 4.36 | accuracy 66.812 | wps 10855 | ups 1.31 | wpb 8277.3 | bsz 305.7 | num_updates 47148 | lr 6.51303e-05 | gnorm 0.537 | clip 0 | loss_scale 64 | train_wall 1002 | gb_free 16.3 | wall 38150
2023-08-10 23:44:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-10 23:44:48 | INFO | fairseq.trainer | begin training epoch 33
2023-08-10 23:44:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-10 23:45:32 | INFO | train_inner | epoch 033:     52 / 1474 loss=1.95, trans_loss=4.939, nll_loss=2.12, w2v_ctc_loss=0.588, task_loss=1.323, contrastive_loss=0.138, total=4149.21, n_correct=2776.62, ppl=4.35, accuracy=66.919, wps=7179.3, ups=0.87, wpb=8298.4, bsz=320.5, num_updates=47200, lr=6.50945e-05, gnorm=0.546, clip=0, loss_scale=64, train_wall=68, gb_free=17, wall=38195
2023-08-10 23:46:40 | INFO | train_inner | epoch 033:    152 / 1474 loss=1.926, trans_loss=4.92, nll_loss=2.091, w2v_ctc_loss=0.577, task_loss=1.506, contrastive_loss=0.031, total=4073.9, n_correct=2741.23, ppl=4.26, accuracy=67.288, wps=11911, ups=1.46, wpb=8147.8, bsz=284.8, num_updates=47300, lr=6.50256e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=68, gb_free=15.2, wall=38263
2023-08-10 23:47:49 | INFO | train_inner | epoch 033:    252 / 1474 loss=1.948, trans_loss=4.92, nll_loss=2.095, w2v_ctc_loss=0.581, task_loss=1.196, contrastive_loss=0.195, total=4280.14, n_correct=2878.03, ppl=4.27, accuracy=67.241, wps=12508.1, ups=1.46, wpb=8560.3, bsz=346.5, num_updates=47400, lr=6.4957e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=68, gb_free=16.4, wall=38331
2023-08-10 23:48:57 | INFO | train_inner | epoch 033:    352 / 1474 loss=1.936, trans_loss=4.931, nll_loss=2.108, w2v_ctc_loss=0.591, task_loss=1.431, contrastive_loss=0.055, total=4120.27, n_correct=2764.28, ppl=4.31, accuracy=67.09, wps=12025.8, ups=1.46, wpb=8240.5, bsz=300.7, num_updates=47500, lr=6.48886e-05, gnorm=0.544, clip=0, loss_scale=64, train_wall=68, gb_free=17.2, wall=38400
2023-08-10 23:50:05 | INFO | train_inner | epoch 033:    452 / 1474 loss=1.922, trans_loss=4.917, nll_loss=2.089, w2v_ctc_loss=0.583, task_loss=1.33, contrastive_loss=0.037, total=4141.22, n_correct=2788.86, ppl=4.26, accuracy=67.344, wps=12215.6, ups=1.47, wpb=8282.4, bsz=310.8, num_updates=47600, lr=6.48204e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=67, gb_free=16.3, wall=38468
2023-08-10 23:50:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-10 23:51:13 | INFO | train_inner | epoch 033:    553 / 1474 loss=1.94, trans_loss=4.94, nll_loss=2.118, w2v_ctc_loss=0.596, task_loss=1.49, contrastive_loss=0.037, total=4112.44, n_correct=2747.4, ppl=4.34, accuracy=66.807, wps=12009.2, ups=1.46, wpb=8224.9, bsz=287.9, num_updates=47700, lr=6.47524e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=68, gb_free=17.7, wall=38536
2023-08-10 23:52:22 | INFO | train_inner | epoch 033:    653 / 1474 loss=1.949, trans_loss=4.95, nll_loss=2.132, w2v_ctc_loss=0.594, task_loss=1.439, contrastive_loss=0.09, total=4156.26, n_correct=2770.42, ppl=4.38, accuracy=66.657, wps=12060.4, ups=1.45, wpb=8312.5, bsz=300.7, num_updates=47800, lr=6.46846e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=38605
2023-08-10 23:53:31 | INFO | train_inner | epoch 033:    753 / 1474 loss=1.946, trans_loss=4.945, nll_loss=2.126, w2v_ctc_loss=0.607, task_loss=1.512, contrastive_loss=0.038, total=4074.99, n_correct=2720.33, ppl=4.36, accuracy=66.757, wps=11883.6, ups=1.46, wpb=8150, bsz=288.2, num_updates=47900, lr=6.46171e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=38674
2023-08-10 23:54:39 | INFO | train_inner | epoch 033:    853 / 1474 loss=1.932, trans_loss=4.931, nll_loss=2.109, w2v_ctc_loss=0.573, task_loss=1.339, contrastive_loss=0.105, total=4127.6, n_correct=2772.66, ppl=4.31, accuracy=67.174, wps=12209.4, ups=1.48, wpb=8255.2, bsz=315.3, num_updates=48000, lr=6.45497e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=38741
2023-08-10 23:54:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-10 23:55:01 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.211 | trans_loss 5.551 | nll_loss 2.819 | w2v_ctc_loss 1.328 | task_loss 4.626 | contrastive_loss 0.236 | total 4003.4 | n_correct 2498.3 | ppl 7.06 | accuracy 62.404 | uer 16.564 | wer 18.113 | raw_wer 18.113 | bleu 20.26 | wps 2306.9 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.54
2023-08-10 23:55:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-08-10 23:55:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_33_48000.pt
2023-08-10 23:55:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_33_48000.pt
2023-08-10 23:55:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 20.26) (writing took 37.58837941288948 seconds)
2023-08-10 23:56:49 | INFO | train_inner | epoch 033:    953 / 1474 loss=1.941, trans_loss=4.94, nll_loss=2.12, w2v_ctc_loss=0.599, task_loss=1.388, contrastive_loss=0.048, total=4157.37, n_correct=2781.9, ppl=4.35, accuracy=66.915, wps=6370.1, ups=0.77, wpb=8314.7, bsz=310.1, num_updates=48100, lr=6.44826e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=69, gb_free=17.4, wall=38872
2023-08-10 23:56:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-10 23:57:59 | INFO | train_inner | epoch 033:   1054 / 1474 loss=1.936, trans_loss=4.938, nll_loss=2.117, w2v_ctc_loss=0.591, task_loss=1.446, contrastive_loss=0.042, total=4117.83, n_correct=2759.49, ppl=4.34, accuracy=67.013, wps=11849, ups=1.44, wpb=8235.7, bsz=298.8, num_updates=48200, lr=6.44157e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=69, gb_free=16.7, wall=38941
2023-08-10 23:59:07 | INFO | train_inner | epoch 033:   1154 / 1474 loss=1.952, trans_loss=4.949, nll_loss=2.132, w2v_ctc_loss=0.588, task_loss=1.407, contrastive_loss=0.139, total=4177.62, n_correct=2783.57, ppl=4.38, accuracy=66.631, wps=12135.2, ups=1.45, wpb=8355.2, bsz=309.6, num_updates=48300, lr=6.43489e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=39010
2023-08-11 00:00:16 | INFO | train_inner | epoch 033:   1254 / 1474 loss=1.941, trans_loss=4.942, nll_loss=2.122, w2v_ctc_loss=0.596, task_loss=1.47, contrastive_loss=0.042, total=4115.15, n_correct=2752.58, ppl=4.35, accuracy=66.889, wps=11995.4, ups=1.46, wpb=8230.3, bsz=294.4, num_updates=48400, lr=6.42824e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=68, gb_free=16.1, wall=39079
2023-08-11 00:01:24 | INFO | train_inner | epoch 033:   1354 / 1474 loss=1.941, trans_loss=4.946, nll_loss=2.129, w2v_ctc_loss=0.593, task_loss=1.375, contrastive_loss=0.059, total=4121.6, n_correct=2752.71, ppl=4.37, accuracy=66.787, wps=12045.1, ups=1.46, wpb=8243.2, bsz=311.7, num_updates=48500, lr=6.42161e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=68, gb_free=15.3, wall=39147
2023-08-11 00:02:33 | INFO | train_inner | epoch 033:   1454 / 1474 loss=1.958, trans_loss=4.945, nll_loss=2.128, w2v_ctc_loss=0.59, task_loss=1.389, contrastive_loss=0.205, total=4131.62, n_correct=2758.81, ppl=4.37, accuracy=66.773, wps=12088.2, ups=1.46, wpb=8263.2, bsz=309.9, num_updates=48600, lr=6.415e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=39216
2023-08-11 00:02:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 00:03:11 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.223 | trans_loss 5.547 | nll_loss 2.814 | w2v_ctc_loss 1.371 | task_loss 4.609 | contrastive_loss 0.24 | total 4003.4 | n_correct 2494.9 | ppl 7.03 | accuracy 62.32 | uer 16.864 | wer 18.579 | raw_wer 18.579 | bleu 20.2 | wps 2079.5 | wpb 4003.4 | bsz 141.8 | num_updates 48620 | best_bleu 20.54
2023-08-11 00:03:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48620 updates
2023-08-11 00:03:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_last.pt
2023-08-11 00:03:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_last.pt
2023-08-11 00:03:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_last.pt (epoch 33 @ 48620 updates, score 20.2) (writing took 13.140012810006738 seconds)
2023-08-11 00:03:24 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-11 00:03:24 | INFO | train | epoch 033 | loss 1.94 | trans_loss 4.936 | nll_loss 2.115 | w2v_ctc_loss 0.59 | task_loss 1.405 | contrastive_loss 0.08 | total 4135.86 | n_correct 2769.29 | ppl 4.33 | accuracy 66.958 | wps 10906.8 | ups 1.32 | wpb 8271.7 | bsz 304.7 | num_updates 48620 | lr 6.41368e-05 | gnorm 0.539 | clip 0 | loss_scale 16 | train_wall 1002 | gb_free 17.8 | wall 39267
2023-08-11 00:03:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 00:03:24 | INFO | fairseq.trainer | begin training epoch 34
2023-08-11 00:03:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 00:04:27 | INFO | train_inner | epoch 034:     80 / 1474 loss=1.927, trans_loss=4.916, nll_loss=2.088, w2v_ctc_loss=0.586, task_loss=1.389, contrastive_loss=0.043, total=4123.05, n_correct=2777.73, ppl=4.25, accuracy=67.371, wps=7220.5, ups=0.88, wpb=8246.1, bsz=300.6, num_updates=48700, lr=6.40841e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=68, gb_free=16, wall=39330
2023-08-11 00:05:35 | INFO | train_inner | epoch 034:    180 / 1474 loss=1.923, trans_loss=4.91, nll_loss=2.08, w2v_ctc_loss=0.582, task_loss=1.459, contrastive_loss=0.044, total=4066.35, n_correct=2747.12, ppl=4.23, accuracy=67.557, wps=11888.3, ups=1.46, wpb=8132.7, bsz=295.2, num_updates=48800, lr=6.40184e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=39398
2023-08-11 00:06:44 | INFO | train_inner | epoch 034:    280 / 1474 loss=1.959, trans_loss=4.931, nll_loss=2.109, w2v_ctc_loss=0.58, task_loss=1.308, contrastive_loss=0.247, total=4247.33, n_correct=2845.41, ppl=4.31, accuracy=66.993, wps=12371, ups=1.46, wpb=8494.7, bsz=329.5, num_updates=48900, lr=6.39529e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=39467
2023-08-11 00:07:52 | INFO | train_inner | epoch 034:    380 / 1474 loss=1.935, trans_loss=4.917, nll_loss=2.09, w2v_ctc_loss=0.579, task_loss=1.333, contrastive_loss=0.138, total=4152.22, n_correct=2795.72, ppl=4.26, accuracy=67.331, wps=12169.8, ups=1.47, wpb=8304.4, bsz=316.1, num_updates=49000, lr=6.38877e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=68, gb_free=15.8, wall=39535
2023-08-11 00:09:00 | INFO | train_inner | epoch 034:    480 / 1474 loss=1.936, trans_loss=4.93, nll_loss=2.105, w2v_ctc_loss=0.596, task_loss=1.523, contrastive_loss=0.039, total=4080.7, n_correct=2734.25, ppl=4.3, accuracy=67.004, wps=12011.9, ups=1.47, wpb=8161.4, bsz=286.7, num_updates=49100, lr=6.38226e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=67, gb_free=15.6, wall=39603
2023-08-11 00:10:08 | INFO | train_inner | epoch 034:    580 / 1474 loss=1.927, trans_loss=4.919, nll_loss=2.092, w2v_ctc_loss=0.585, task_loss=1.421, contrastive_loss=0.04, total=4126.98, n_correct=2782.28, ppl=4.26, accuracy=67.417, wps=12157.3, ups=1.47, wpb=8254, bsz=300.1, num_updates=49200, lr=6.37577e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=67, gb_free=16.1, wall=39671
2023-08-11 00:11:16 | INFO | train_inner | epoch 034:    680 / 1474 loss=1.929, trans_loss=4.926, nll_loss=2.102, w2v_ctc_loss=0.585, task_loss=1.439, contrastive_loss=0.036, total=4110.23, n_correct=2763.34, ppl=4.29, accuracy=67.231, wps=12041.9, ups=1.46, wpb=8220.5, bsz=297.1, num_updates=49300, lr=6.3693e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=39739
2023-08-11 00:12:25 | INFO | train_inner | epoch 034:    780 / 1474 loss=1.942, trans_loss=4.946, nll_loss=2.127, w2v_ctc_loss=0.576, task_loss=1.453, contrastive_loss=0.102, total=4087.05, n_correct=2730.69, ppl=4.37, accuracy=66.813, wps=12014, ups=1.47, wpb=8174.1, bsz=297.4, num_updates=49400, lr=6.36285e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=68, gb_free=16.1, wall=39807
2023-08-11 00:13:33 | INFO | train_inner | epoch 034:    880 / 1474 loss=1.941, trans_loss=4.939, nll_loss=2.119, w2v_ctc_loss=0.591, task_loss=1.496, contrastive_loss=0.061, total=4088.94, n_correct=2735.95, ppl=4.34, accuracy=66.911, wps=11968.5, ups=1.46, wpb=8177.9, bsz=294.2, num_updates=49500, lr=6.35642e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=68, gb_free=14.7, wall=39876
2023-08-11 00:14:41 | INFO | train_inner | epoch 034:    980 / 1474 loss=1.939, trans_loss=4.936, nll_loss=2.115, w2v_ctc_loss=0.596, task_loss=1.374, contrastive_loss=0.057, total=4175.9, n_correct=2795.53, ppl=4.33, accuracy=66.944, wps=12241, ups=1.47, wpb=8351.8, bsz=312.7, num_updates=49600, lr=6.35001e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=68, gb_free=13.7, wall=39944
2023-08-11 00:15:49 | INFO | train_inner | epoch 034:   1080 / 1474 loss=1.937, trans_loss=4.94, nll_loss=2.119, w2v_ctc_loss=0.594, task_loss=1.354, contrastive_loss=0.041, total=4152.17, n_correct=2781.62, ppl=4.34, accuracy=66.992, wps=12256.4, ups=1.48, wpb=8304.3, bsz=309, num_updates=49700, lr=6.34361e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=67, gb_free=14.4, wall=40012
2023-08-11 00:16:57 | INFO | train_inner | epoch 034:   1180 / 1474 loss=1.937, trans_loss=4.939, nll_loss=2.118, w2v_ctc_loss=0.588, task_loss=1.443, contrastive_loss=0.052, total=4101.68, n_correct=2744.29, ppl=4.34, accuracy=66.906, wps=12033.8, ups=1.47, wpb=8203.4, bsz=298, num_updates=49800, lr=6.33724e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=40080
2023-08-11 00:18:05 | INFO | train_inner | epoch 034:   1280 / 1474 loss=1.933, trans_loss=4.935, nll_loss=2.114, w2v_ctc_loss=0.588, task_loss=1.413, contrastive_loss=0.038, total=4146.01, n_correct=2775.97, ppl=4.33, accuracy=66.955, wps=12116.2, ups=1.46, wpb=8292, bsz=300.6, num_updates=49900, lr=6.33089e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=68, gb_free=17.2, wall=40148
2023-08-11 00:19:14 | INFO | train_inner | epoch 034:   1380 / 1474 loss=1.95, trans_loss=4.944, nll_loss=2.126, w2v_ctc_loss=0.6, task_loss=1.341, contrastive_loss=0.099, total=4197.99, n_correct=2801.9, ppl=4.36, accuracy=66.744, wps=12172.9, ups=1.45, wpb=8396, bsz=321.1, num_updates=50000, lr=6.32456e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=69, gb_free=17.2, wall=40217
2023-08-11 00:19:14 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-11 00:19:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 00:19:37 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.211 | trans_loss 5.549 | nll_loss 2.818 | w2v_ctc_loss 1.331 | task_loss 4.636 | contrastive_loss 0.237 | total 4003.4 | n_correct 2498.4 | ppl 7.05 | accuracy 62.407 | uer 16.518 | wer 18.359 | raw_wer 18.359 | bleu 20.36 | wps 2271.6 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.54
2023-08-11 00:19:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-08-11 00:19:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_34_50000.pt
2023-08-11 00:19:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_34_50000.pt
2023-08-11 00:20:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0810_AT_sentence_mixup0.1_0.5_alpha2.0_mt0.5/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 20.36) (writing took 37.36504419706762 seconds)
2023-08-11 00:20:15 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-11 00:20:15 | INFO | train | epoch 034 | loss 1.937 | trans_loss 4.93 | nll_loss 2.107 | w2v_ctc_loss 0.587 | task_loss 1.41 | contrastive_loss 0.076 | total 4133.03 | n_correct 2772.74 | ppl 4.31 | accuracy 67.087 | wps 11279.6 | ups 1.36 | wpb 8266.1 | bsz 304.3 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.541 | clip 0 | loss_scale 16 | train_wall 936 | gb_free 17.2 | wall 40278
2023-08-11 00:20:15 | INFO | fairseq_cli.train | done training in 40226.8 seconds
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    raise EOFError
EOFError
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
