2023-08-31 20:05:35 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11685
2023-08-31 20:05:35 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11685
2023-08-31 20:05:35 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11685
2023-08-31 20:05:35 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:11685
2023-08-31 20:05:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-31 20:05:35 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:11685
2023-08-31 20:05:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-31 20:05:36 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:11685
2023-08-31 20:05:36 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:11685
2023-08-31 20:05:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-31 20:05:36 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11685
2023-08-31 20:05:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-31 20:05:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-31 20:05:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-31 20:05:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-31 20:05:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-31 20:05:36 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-31 20:05:36 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-31 20:05:36 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-31 20:05:36 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-31 20:05:36 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-31 20:05:36 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-31 20:05:36 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-31 20:05:36 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-31 20:05:36 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-31 20:05:36 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-31 20:05:36 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-31 20:05:36 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-31 20:05:36 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-31 20:05:36 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-31 20:05:36 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-31 20:05:36 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-31 20:05:40 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11685', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enes_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enes_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enes_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-31 20:05:40 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-31 20:05:40 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-31 20:05:40 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-31 20:05:40 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-31 20:05:40 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline
2023-08-31 20:05:44 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-31 20:05:44 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enes_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-31 20:05:44 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-31 20:05:45 | INFO | root | load pretrained hubert
2023-08-31 20:05:52 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline
2023-08-31 20:05:55 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt
2023-08-31 20:06:00 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt
2023-08-31 20:06:00 | INFO | root | share the sematic adapter and textual encoder
2023-08-31 20:06:00 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-31 20:06:00 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-31 20:06:00 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-31 20:06:00 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-31 20:06:00 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-08-31 20:06:00 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-31 20:06:00 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-31 20:06:00 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enes_lcrm/sentencepiece.bpe.model'}
2023-08-31 20:06:00 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enes_lcrm/sentencepiece.bpe.model'}
2023-08-31 20:06:00 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1312, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-31 20:06:17 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-31 20:06:19 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-31 20:06:19 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-31 20:06:19 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-31 20:06:19 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-31 20:06:19 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-31 20:06:19 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-31 20:06:19 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-31 20:06:19 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-31 20:06:19 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-31 20:06:19 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-31 20:06:19 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-31 20:06:19 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-31 20:06:19 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-31 20:06:19 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-31 20:06:19 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_last.pt
2023-08-31 20:06:19 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_last.pt
2023-08-31 20:06:19 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-31 20:06:19 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-31 20:06:19 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enes_lcrm/sentencepiece.bpe.model'}
2023-08-31 20:06:19 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enes_lcrm/sentencepiece.bpe.model'}
2023-08-31 20:06:21 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=260049, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-31 20:06:23 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=260049, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-31 20:07:11 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-31 20:07:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 20:07:11 | INFO | fairseq.trainer | begin training epoch 1
2023-08-31 20:07:11 | INFO | fairseq_cli.train | Start iterating over samples
True False
None None None
2023-08-31 20:07:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
True False
None None None
2023-08-31 20:07:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
2023-08-31 20:08:23 | INFO | train_inner | epoch 001:    102 / 1826 loss=17.957, trans_loss=5.725, nll_loss=4.568, w2v_ctc_loss=23.234, task_loss=5.582, contrastive_loss=0, total=3940, n_correct=63.88, ppl=23.72, accuracy=1.621, wps=20163.4, ups=1.7, wpb=11837.1, bsz=400.3, num_updates=100, lr=4.098e-06, gnorm=3.665, clip=0, loss_scale=32, train_wall=64, gb_free=19, wall=123
2023-08-31 20:09:21 | INFO | train_inner | epoch 001:    202 / 1826 loss=12.997, trans_loss=5.742, nll_loss=4.614, w2v_ctc_loss=15.592, task_loss=4.552, contrastive_loss=0, total=4000.63, n_correct=63.09, ppl=24.49, accuracy=1.577, wps=20765.3, ups=1.72, wpb=12045.3, bsz=454.7, num_updates=200, lr=8.096e-06, gnorm=8.415, clip=33, loss_scale=32, train_wall=57, gb_free=19.6, wall=181
2023-08-31 20:10:19 | INFO | train_inner | epoch 001:    302 / 1826 loss=7.209, trans_loss=5.71, nll_loss=4.596, w2v_ctc_loss=6.714, task_loss=4.261, contrastive_loss=0, total=3981.48, n_correct=61.09, ppl=24.19, accuracy=1.534, wps=20533.5, ups=1.72, wpb=11963.3, bsz=445.6, num_updates=300, lr=1.2094e-05, gnorm=1.331, clip=0, loss_scale=32, train_wall=58, gb_free=18.6, wall=239
2023-08-31 20:10:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-31 20:11:18 | INFO | train_inner | epoch 001:    403 / 1826 loss=6.743, trans_loss=5.612, nll_loss=4.505, w2v_ctc_loss=6.092, task_loss=4.008, contrastive_loss=0, total=4007.21, n_correct=82.43, ppl=22.7, accuracy=2.057, wps=20357.1, ups=1.69, wpb=12059.5, bsz=431.7, num_updates=400, lr=1.6092e-05, gnorm=0.613, clip=0, loss_scale=16, train_wall=59, gb_free=19.7, wall=299
2023-08-31 20:12:16 | INFO | train_inner | epoch 001:    503 / 1826 loss=6.493, trans_loss=5.543, nll_loss=4.422, w2v_ctc_loss=5.778, task_loss=3.617, contrastive_loss=0, total=3994.6, n_correct=81.51, ppl=21.44, accuracy=2.041, wps=20635.3, ups=1.72, wpb=12013, bsz=442.9, num_updates=500, lr=2.009e-05, gnorm=0.44, clip=0, loss_scale=16, train_wall=58, gb_free=19.1, wall=357
2023-08-31 20:13:14 | INFO | train_inner | epoch 001:    603 / 1826 loss=6.344, trans_loss=5.524, nll_loss=4.41, w2v_ctc_loss=5.569, task_loss=3.678, contrastive_loss=0, total=3946.86, n_correct=98.51, ppl=21.25, accuracy=2.496, wps=20424.4, ups=1.72, wpb=11872, bsz=424.9, num_updates=600, lr=2.4088e-05, gnorm=0.423, clip=0, loss_scale=16, train_wall=58, gb_free=18.5, wall=415
2023-08-31 20:14:12 | INFO | train_inner | epoch 001:    703 / 1826 loss=6.045, trans_loss=5.521, nll_loss=4.402, w2v_ctc_loss=5.114, task_loss=3.432, contrastive_loss=0, total=3953.79, n_correct=104.1, ppl=21.13, accuracy=2.633, wps=20553.8, ups=1.73, wpb=11877.7, bsz=431.2, num_updates=700, lr=2.8086e-05, gnorm=0.585, clip=0, loss_scale=16, train_wall=57, gb_free=18.8, wall=473
2023-08-31 20:15:10 | INFO | train_inner | epoch 001:    803 / 1826 loss=5.791, trans_loss=5.516, nll_loss=4.4, w2v_ctc_loss=4.727, task_loss=3.471, contrastive_loss=0, total=3973.13, n_correct=87.89, ppl=21.11, accuracy=2.212, wps=20622, ups=1.73, wpb=11951.9, bsz=428.7, num_updates=800, lr=3.2084e-05, gnorm=0.726, clip=0, loss_scale=16, train_wall=57, gb_free=18.7, wall=531
2023-08-31 20:16:09 | INFO | train_inner | epoch 001:    903 / 1826 loss=5.582, trans_loss=5.522, nll_loss=4.408, w2v_ctc_loss=4.399, task_loss=3.322, contrastive_loss=0, total=3998.85, n_correct=98.79, ppl=21.23, accuracy=2.47, wps=20597, ups=1.71, wpb=12033.4, bsz=439.4, num_updates=900, lr=3.6082e-05, gnorm=0.898, clip=0, loss_scale=16, train_wall=58, gb_free=19.1, wall=589
2023-08-31 20:17:07 | INFO | train_inner | epoch 001:   1003 / 1826 loss=5.45, trans_loss=5.538, nll_loss=4.421, w2v_ctc_loss=4.179, task_loss=3.187, contrastive_loss=0, total=3988.93, n_correct=99.45, ppl=21.42, accuracy=2.493, wps=20573.6, ups=1.71, wpb=12000.5, bsz=449.7, num_updates=1000, lr=4.008e-05, gnorm=0.91, clip=0, loss_scale=16, train_wall=58, gb_free=18.8, wall=647
2023-08-31 20:18:05 | INFO | train_inner | epoch 001:   1103 / 1826 loss=5.372, trans_loss=5.56, nll_loss=4.445, w2v_ctc_loss=4.03, task_loss=3.62, contrastive_loss=0, total=3947.12, n_correct=101.81, ppl=21.78, accuracy=2.579, wps=20476.9, ups=1.72, wpb=11874.1, bsz=420.8, num_updates=1100, lr=4.4078e-05, gnorm=1.033, clip=0, loss_scale=16, train_wall=57, gb_free=18.7, wall=705
2023-08-31 20:19:03 | INFO | train_inner | epoch 001:   1203 / 1826 loss=5.283, trans_loss=5.57, nll_loss=4.453, w2v_ctc_loss=3.882, task_loss=3.69, contrastive_loss=0, total=3914.85, n_correct=115.48, ppl=21.9, accuracy=2.95, wps=20370, ups=1.73, wpb=11775.7, bsz=401.2, num_updates=1200, lr=4.8076e-05, gnorm=1.074, clip=0, loss_scale=16, train_wall=57, gb_free=18.5, wall=763
2023-08-31 20:20:01 | INFO | train_inner | epoch 001:   1303 / 1826 loss=5.195, trans_loss=5.568, nll_loss=4.45, w2v_ctc_loss=3.749, task_loss=3.571, contrastive_loss=0, total=3925.76, n_correct=119.7, ppl=21.85, accuracy=3.049, wps=20426.7, ups=1.73, wpb=11815, bsz=424.1, num_updates=1300, lr=5.2074e-05, gnorm=1.019, clip=0, loss_scale=16, train_wall=57, gb_free=19.2, wall=821
2023-08-31 20:20:58 | INFO | train_inner | epoch 001:   1403 / 1826 loss=5.135, trans_loss=5.575, nll_loss=4.455, w2v_ctc_loss=3.649, task_loss=3.576, contrastive_loss=0, total=3918.07, n_correct=126.39, ppl=21.93, accuracy=3.226, wps=20499, ups=1.74, wpb=11779.6, bsz=410.4, num_updates=1400, lr=5.6072e-05, gnorm=1.17, clip=0, loss_scale=16, train_wall=57, gb_free=18.8, wall=879
2023-08-31 20:21:57 | INFO | train_inner | epoch 001:   1503 / 1826 loss=5.056, trans_loss=5.579, nll_loss=4.458, w2v_ctc_loss=3.526, task_loss=3.516, contrastive_loss=0, total=3995.02, n_correct=129.49, ppl=21.98, accuracy=3.241, wps=20432.2, ups=1.7, wpb=12005.7, bsz=425.9, num_updates=1500, lr=6.007e-05, gnorm=1.064, clip=0, loss_scale=16, train_wall=58, gb_free=19.6, wall=937
2023-08-31 20:22:54 | INFO | train_inner | epoch 001:   1603 / 1826 loss=5.003, trans_loss=5.565, nll_loss=4.444, w2v_ctc_loss=3.453, task_loss=3.61, contrastive_loss=0, total=3877.45, n_correct=127.92, ppl=21.77, accuracy=3.299, wps=20264.3, ups=1.74, wpb=11667.5, bsz=409.1, num_updates=1600, lr=6.4068e-05, gnorm=1.073, clip=0, loss_scale=16, train_wall=57, gb_free=19.6, wall=995
2023-08-31 20:23:52 | INFO | train_inner | epoch 001:   1703 / 1826 loss=4.938, trans_loss=5.568, nll_loss=4.448, w2v_ctc_loss=3.354, task_loss=3.399, contrastive_loss=0, total=3947.06, n_correct=131, ppl=21.83, accuracy=3.319, wps=20553.9, ups=1.73, wpb=11879.5, bsz=425.7, num_updates=1700, lr=6.8066e-05, gnorm=1.179, clip=0, loss_scale=16, train_wall=57, gb_free=18.7, wall=1053
2023-08-31 20:24:49 | INFO | train_inner | epoch 001:   1803 / 1826 loss=4.889, trans_loss=5.569, nll_loss=4.45, w2v_ctc_loss=3.278, task_loss=3.384, contrastive_loss=0, total=3948.71, n_correct=132.92, ppl=21.85, accuracy=3.366, wps=20898.6, ups=1.76, wpb=11885.2, bsz=430.7, num_updates=1800, lr=7.2064e-05, gnorm=1.037, clip=0, loss_scale=16, train_wall=56, gb_free=18.8, wall=1110
2023-08-31 20:25:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
tensor([5.9605e-08], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 20:25:56 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.447 | trans_loss 12.078 | nll_loss 11.519 | w2v_ctc_loss 4.235 | task_loss 22.626 | contrastive_loss 0 | total 3505.91 | n_correct 178.273 | ppl 2934.99 | accuracy 5.085 | uer 56.353 | wer 55.832 | raw_wer 55.832 | bleu 0 | wps 820.5 | wpb 3505.9 | bsz 119.3 | num_updates 1823
2023-08-31 20:25:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1823 updates
2023-08-31 20:25:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-08-31 20:25:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-08-31 20:26:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt (epoch 1 @ 1823 updates, score 0.0) (writing took 4.7276368440070655 seconds)
2023-08-31 20:26:00 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-31 20:26:00 | INFO | train | epoch 001 | loss 6.729 | trans_loss 5.584 | nll_loss 4.464 | w2v_ctc_loss 6.099 | task_loss 3.742 | contrastive_loss 0 | total 3956.53 | n_correct 101.789 | ppl 22.07 | accuracy 2.573 | wps 19432.5 | ups 1.63 | wpb 11900.6 | bsz 427.4 | num_updates 1823 | lr 7.29835e-05 | gnorm 1.476 | clip 1.8 | loss_scale 16 | train_wall 1053 | gb_free 19 | wall 1181
2023-08-31 20:26:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 20:26:00 | INFO | fairseq.trainer | begin training epoch 2
2023-08-31 20:26:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 20:26:52 | INFO | train_inner | epoch 002:     77 / 1826 loss=4.853, trans_loss=5.567, nll_loss=4.446, w2v_ctc_loss=3.22, task_loss=3.489, contrastive_loss=0, total=3877.76, n_correct=130.71, ppl=21.8, accuracy=3.371, wps=9481.7, ups=0.81, wpb=11670.1, bsz=418.5, num_updates=1900, lr=7.6062e-05, gnorm=0.929, clip=0, loss_scale=16, train_wall=57, gb_free=19.4, wall=1233
2023-08-31 20:27:51 | INFO | train_inner | epoch 002:    177 / 1826 loss=4.807, trans_loss=5.566, nll_loss=4.447, w2v_ctc_loss=3.147, task_loss=3.539, contrastive_loss=0, total=3945.55, n_correct=134.62, ppl=21.81, accuracy=3.412, wps=20341.2, ups=1.71, wpb=11878.2, bsz=423.1, num_updates=2000, lr=8.006e-05, gnorm=1.034, clip=0, loss_scale=16, train_wall=58, gb_free=19.5, wall=1291
2023-08-31 20:27:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([5.9605e-08], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 20:28:44 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 9.399 | trans_loss 12.086 | nll_loss 11.532 | w2v_ctc_loss 4.057 | task_loss 22.626 | contrastive_loss 0 | total 3505.91 | n_correct 178 | ppl 2960.97 | accuracy 5.077 | uer 54.84 | wer 54.2 | raw_wer 54.2 | bleu 0 | wps 824.7 | wpb 3505.9 | bsz 119.3 | num_updates 2000 | best_bleu 0
2023-08-31 20:28:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-31 20:28:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_2_2000.pt
2023-08-31 20:28:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_2_2000.pt
2023-08-31 20:28:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 12.464167269994505 seconds)
2023-08-31 20:29:54 | INFO | train_inner | epoch 002:    277 / 1826 loss=4.753, trans_loss=5.57, nll_loss=4.451, w2v_ctc_loss=3.063, task_loss=3.556, contrastive_loss=0, total=3980.57, n_correct=140.32, ppl=21.87, accuracy=3.525, wps=9667.4, ups=0.81, wpb=11976.8, bsz=426.2, num_updates=2100, lr=8.4058e-05, gnorm=0.964, clip=0, loss_scale=16, train_wall=58, gb_free=18.6, wall=1415
2023-08-31 20:30:52 | INFO | train_inner | epoch 002:    377 / 1826 loss=4.73, trans_loss=5.577, nll_loss=4.458, w2v_ctc_loss=3.025, task_loss=3.441, contrastive_loss=0, total=3951.89, n_correct=135.28, ppl=21.97, accuracy=3.423, wps=20672.9, ups=1.74, wpb=11884.4, bsz=426.5, num_updates=2200, lr=8.8056e-05, gnorm=0.91, clip=0, loss_scale=16, train_wall=57, gb_free=19.3, wall=1472
2023-08-31 20:31:49 | INFO | train_inner | epoch 002:    477 / 1826 loss=4.668, trans_loss=5.577, nll_loss=4.459, w2v_ctc_loss=2.931, task_loss=3.172, contrastive_loss=0, total=3989.48, n_correct=137.19, ppl=22, accuracy=3.439, wps=20936.9, ups=1.74, wpb=11999.9, bsz=452.2, num_updates=2300, lr=9.2054e-05, gnorm=0.953, clip=0, loss_scale=16, train_wall=57, gb_free=19.4, wall=1530
2023-08-31 20:32:47 | INFO | train_inner | epoch 002:    577 / 1826 loss=4.646, trans_loss=5.576, nll_loss=4.459, w2v_ctc_loss=2.897, task_loss=3.248, contrastive_loss=0, total=4010.91, n_correct=139.53, ppl=21.99, accuracy=3.479, wps=20914.1, ups=1.73, wpb=12062.1, bsz=444.2, num_updates=2400, lr=9.6052e-05, gnorm=0.801, clip=0, loss_scale=32, train_wall=57, gb_free=19.2, wall=1587
2023-08-31 20:33:44 | INFO | train_inner | epoch 002:    677 / 1826 loss=4.63, trans_loss=5.555, nll_loss=4.436, w2v_ctc_loss=2.876, task_loss=3.68, contrastive_loss=0, total=3863.36, n_correct=139.09, ppl=21.65, accuracy=3.6, wps=20302, ups=1.74, wpb=11638.9, bsz=397.9, num_updates=2500, lr=0.00010005, gnorm=0.904, clip=0, loss_scale=32, train_wall=57, gb_free=19.4, wall=1645
2023-08-31 20:34:42 | INFO | train_inner | epoch 002:    777 / 1826 loss=4.598, trans_loss=5.571, nll_loss=4.455, w2v_ctc_loss=2.824, task_loss=3.374, contrastive_loss=0, total=3968.04, n_correct=138.08, ppl=21.93, accuracy=3.48, wps=20820.9, ups=1.74, wpb=11939.6, bsz=431.9, num_updates=2600, lr=0.000104048, gnorm=0.881, clip=0, loss_scale=32, train_wall=57, gb_free=19.3, wall=1702
2023-08-31 20:35:40 | INFO | train_inner | epoch 002:    877 / 1826 loss=4.581, trans_loss=5.573, nll_loss=4.457, w2v_ctc_loss=2.796, task_loss=3.312, contrastive_loss=0, total=3980.03, n_correct=135.6, ppl=21.97, accuracy=3.407, wps=20644.2, ups=1.72, wpb=11977.6, bsz=438.8, num_updates=2700, lr=0.000108046, gnorm=0.9, clip=0, loss_scale=32, train_wall=57, gb_free=18.8, wall=1760
2023-08-31 20:36:37 | INFO | train_inner | epoch 002:    977 / 1826 loss=4.566, trans_loss=5.577, nll_loss=4.463, w2v_ctc_loss=2.766, task_loss=3.496, contrastive_loss=0, total=3945.98, n_correct=137.41, ppl=22.05, accuracy=3.482, wps=20613.8, ups=1.74, wpb=11874, bsz=425.1, num_updates=2800, lr=0.000112044, gnorm=0.841, clip=0, loss_scale=32, train_wall=57, gb_free=19.4, wall=1818
2023-08-31 20:37:34 | INFO | train_inner | epoch 002:   1077 / 1826 loss=4.524, trans_loss=5.59, nll_loss=4.476, w2v_ctc_loss=2.697, task_loss=3.289, contrastive_loss=0, total=3979.79, n_correct=134.62, ppl=22.25, accuracy=3.383, wps=20996.8, ups=1.76, wpb=11956.7, bsz=440.4, num_updates=2900, lr=0.000116042, gnorm=0.779, clip=0, loss_scale=32, train_wall=56, gb_free=19.2, wall=1875
2023-08-31 20:38:31 | INFO | train_inner | epoch 002:   1177 / 1826 loss=4.533, trans_loss=5.586, nll_loss=4.472, w2v_ctc_loss=2.702, task_loss=3.776, contrastive_loss=0, total=3887.16, n_correct=134.8, ppl=22.19, accuracy=3.468, wps=20426, ups=1.75, wpb=11682, bsz=391.1, num_updates=3000, lr=0.00012004, gnorm=0.769, clip=0, loss_scale=32, train_wall=57, gb_free=18.5, wall=1932
2023-08-31 20:38:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-31 20:38:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-31 20:39:59 | INFO | train_inner | epoch 002:   1279 / 1826 loss=3.855, trans_loss=4.929, nll_loss=3.62, w2v_ctc_loss=2.359, task_loss=2.45, contrastive_loss=0, total=3925.15, n_correct=376.41, ppl=12.29, accuracy=9.59, wps=13444.7, ups=1.14, wpb=11799.1, bsz=417.6, num_updates=3100, lr=0.000124038, gnorm=1.492, clip=0, loss_scale=8, train_wall=87, gb_free=15.9, wall=2020
2023-08-31 20:40:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-31 20:41:26 | INFO | train_inner | epoch 002:   1380 / 1826 loss=3.238, trans_loss=4.258, nll_loss=2.726, w2v_ctc_loss=2.123, task_loss=2.271, contrastive_loss=0, total=3993.2, n_correct=1017.45, ppl=6.62, accuracy=25.48, wps=13865.4, ups=1.15, wpb=12007.9, bsz=439.5, num_updates=3200, lr=0.000128036, gnorm=1.296, clip=0, loss_scale=4, train_wall=86, gb_free=16.2, wall=2106
2023-08-31 20:42:53 | INFO | train_inner | epoch 002:   1480 / 1826 loss=3.095, trans_loss=4.149, nll_loss=2.588, w2v_ctc_loss=2.015, task_loss=2.213, contrastive_loss=0, total=4011.89, n_correct=1168.49, ppl=6.01, accuracy=29.126, wps=13902.2, ups=1.15, wpb=12062.1, bsz=451.9, num_updates=3300, lr=0.000132034, gnorm=1.281, clip=0, loss_scale=4, train_wall=86, gb_free=16.9, wall=2193
2023-08-31 20:44:19 | INFO | train_inner | epoch 002:   1580 / 1826 loss=3.039, trans_loss=4.115, nll_loss=2.547, w2v_ctc_loss=1.957, task_loss=2.402, contrastive_loss=0, total=4002.24, n_correct=1204.09, ppl=5.84, accuracy=30.085, wps=13945.7, ups=1.16, wpb=12045.9, bsz=431.3, num_updates=3400, lr=0.000136032, gnorm=1.151, clip=0, loss_scale=4, train_wall=86, gb_free=16.3, wall=2279
2023-08-31 20:45:44 | INFO | train_inner | epoch 002:   1680 / 1826 loss=2.97, trans_loss=4.097, nll_loss=2.521, w2v_ctc_loss=1.87, task_loss=2.35, contrastive_loss=0, total=3944.6, n_correct=1211.92, ppl=5.74, accuracy=30.724, wps=14005.7, ups=1.18, wpb=11859.3, bsz=423.6, num_updates=3500, lr=0.00014003, gnorm=0.974, clip=0, loss_scale=4, train_wall=84, gb_free=16, wall=2364
2023-08-31 20:47:10 | INFO | train_inner | epoch 002:   1780 / 1826 loss=2.943, trans_loss=4.093, nll_loss=2.515, w2v_ctc_loss=1.833, task_loss=2.531, contrastive_loss=0, total=3964.45, n_correct=1226.8, ppl=5.72, accuracy=30.945, wps=13818.1, ups=1.16, wpb=11912.3, bsz=413.8, num_updates=3600, lr=0.000144028, gnorm=0.998, clip=0, loss_scale=4, train_wall=86, gb_free=15.8, wall=2450
2023-08-31 20:47:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.0032], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 20:48:30 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 5.868 | trans_loss 7.702 | nll_loss 5.743 | w2v_ctc_loss 2.181 | task_loss 12.817 | contrastive_loss 0 | total 3505.91 | n_correct 1077.36 | ppl 53.54 | accuracy 30.73 | uer 31.824 | wer 32.339 | raw_wer 32.339 | bleu 0.36 | wps 1097.7 | wpb 3505.9 | bsz 119.3 | num_updates 3646 | best_bleu 0.36
2023-08-31 20:48:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 3646 updates
2023-08-31 20:48:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-08-31 20:48:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-08-31 20:48:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt (epoch 2 @ 3646 updates, score 0.36) (writing took 12.575987365999026 seconds)
2023-08-31 20:48:42 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-31 20:48:43 | INFO | train | epoch 002 | loss 4.127 | trans_loss 5.108 | nll_loss 3.846 | w2v_ctc_loss 2.588 | task_loss 3.063 | contrastive_loss 0 | total 3955.01 | n_correct 458.377 | ppl 14.38 | accuracy 11.59 | wps 15919.8 | ups 1.34 | wpb 11896 | bsz 426.7 | num_updates 3646 | lr 0.000145867 | gnorm 0.99 | clip 0 | loss_scale 4 | train_wall 1224 | gb_free 16.4 | wall 2543
2023-08-31 20:48:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 20:48:43 | INFO | fairseq.trainer | begin training epoch 3
2023-08-31 20:48:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 20:49:37 | INFO | train_inner | epoch 003:     54 / 1826 loss=2.905, trans_loss=4.076, nll_loss=2.494, w2v_ctc_loss=1.784, task_loss=2.495, contrastive_loss=0, total=3866.85, n_correct=1209.89, ppl=5.64, accuracy=31.289, wps=7925.2, ups=0.68, wpb=11625.8, bsz=401.1, num_updates=3700, lr=0.000148026, gnorm=1.007, clip=0, loss_scale=4, train_wall=85, gb_free=15.3, wall=2597
2023-08-31 20:51:01 | INFO | train_inner | epoch 003:    154 / 1826 loss=2.849, trans_loss=4.059, nll_loss=2.477, w2v_ctc_loss=1.712, task_loss=2.23, contrastive_loss=0, total=3969.28, n_correct=1248.66, ppl=5.57, accuracy=31.458, wps=14101.1, ups=1.18, wpb=11948.4, bsz=442.1, num_updates=3800, lr=0.000152024, gnorm=0.88, clip=0, loss_scale=4, train_wall=84, gb_free=16.1, wall=2682
2023-08-31 20:52:27 | INFO | train_inner | epoch 003:    254 / 1826 loss=2.848, trans_loss=4.06, nll_loss=2.475, w2v_ctc_loss=1.715, task_loss=2.285, contrastive_loss=0, total=3997.68, n_correct=1267.09, ppl=5.56, accuracy=31.696, wps=13974.9, ups=1.16, wpb=12022.8, bsz=439.1, num_updates=3900, lr=0.000156022, gnorm=1.055, clip=0, loss_scale=4, train_wall=85, gb_free=14.6, wall=2768
2023-08-31 20:53:53 | INFO | train_inner | epoch 003:    354 / 1826 loss=2.805, trans_loss=4.059, nll_loss=2.472, w2v_ctc_loss=1.655, task_loss=2.121, contrastive_loss=0, total=4043.01, n_correct=1284.81, ppl=5.55, accuracy=31.779, wps=14203.7, ups=1.17, wpb=12155.1, bsz=462.1, num_updates=4000, lr=0.00016002, gnorm=0.984, clip=0, loss_scale=4, train_wall=85, gb_free=12, wall=2853
2023-08-31 20:53:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([8.0466e-06], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 20:54:31 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.794 | trans_loss 7.612 | nll_loss 5.63 | w2v_ctc_loss 2.138 | task_loss 12.628 | contrastive_loss 0 | total 3505.91 | n_correct 1104.82 | ppl 49.51 | accuracy 31.513 | uer 30.332 | wer 31.187 | raw_wer 31.187 | bleu 0.22 | wps 1211.3 | wpb 3505.9 | bsz 119.3 | num_updates 4000 | best_bleu 0.36
2023-08-31 20:54:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-31 20:54:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_3_4000.pt
2023-08-31 20:54:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_3_4000.pt
2023-08-31 20:54:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 0.22) (writing took 7.1143605609977385 seconds)
2023-08-31 20:56:03 | INFO | train_inner | epoch 003:    454 / 1826 loss=2.805, trans_loss=4.057, nll_loss=2.471, w2v_ctc_loss=1.654, task_loss=2.398, contrastive_loss=0, total=3929.75, n_correct=1246.96, ppl=5.54, accuracy=31.731, wps=9090.2, ups=0.77, wpb=11819.9, bsz=420.9, num_updates=4100, lr=0.000164018, gnorm=0.873, clip=0, loss_scale=4, train_wall=84, gb_free=15.7, wall=2983
2023-08-31 20:57:29 | INFO | train_inner | epoch 003:    554 / 1826 loss=2.794, trans_loss=4.049, nll_loss=2.464, w2v_ctc_loss=1.648, task_loss=2.308, contrastive_loss=0, total=3965.34, n_correct=1270.3, ppl=5.52, accuracy=32.035, wps=13795.4, ups=1.16, wpb=11936.1, bsz=439.3, num_updates=4200, lr=0.000168016, gnorm=0.896, clip=0, loss_scale=4, train_wall=86, gb_free=16.5, wall=3070
2023-08-31 20:58:54 | INFO | train_inner | epoch 003:    654 / 1826 loss=2.761, trans_loss=4.042, nll_loss=2.454, w2v_ctc_loss=1.604, task_loss=2.175, contrastive_loss=0, total=4008.32, n_correct=1291.44, ppl=5.48, accuracy=32.219, wps=14190, ups=1.18, wpb=12065.1, bsz=445.4, num_updates=4300, lr=0.000172014, gnorm=0.871, clip=0, loss_scale=4, train_wall=84, gb_free=15.8, wall=3155
2023-08-31 21:00:20 | INFO | train_inner | epoch 003:    754 / 1826 loss=2.77, trans_loss=4.039, nll_loss=2.449, w2v_ctc_loss=1.616, task_loss=2.326, contrastive_loss=0, total=3974.64, n_correct=1283.28, ppl=5.46, accuracy=32.287, wps=13966.6, ups=1.17, wpb=11956.7, bsz=427.8, num_updates=4400, lr=0.000176012, gnorm=0.898, clip=0, loss_scale=4, train_wall=85, gb_free=15.8, wall=3241
2023-08-31 21:01:45 | INFO | train_inner | epoch 003:    854 / 1826 loss=2.75, trans_loss=4.045, nll_loss=2.454, w2v_ctc_loss=1.579, task_loss=2.539, contrastive_loss=0, total=3916.61, n_correct=1260.17, ppl=5.48, accuracy=32.175, wps=13795.5, ups=1.17, wpb=11772.9, bsz=405.5, num_updates=4500, lr=0.00018001, gnorm=0.818, clip=0, loss_scale=4, train_wall=85, gb_free=13.5, wall=3326
2023-08-31 21:03:11 | INFO | train_inner | epoch 003:    954 / 1826 loss=2.731, trans_loss=4.025, nll_loss=2.432, w2v_ctc_loss=1.562, task_loss=2.33, contrastive_loss=0, total=3978.17, n_correct=1290.2, ppl=5.39, accuracy=32.432, wps=14041.2, ups=1.17, wpb=11971.8, bsz=430.3, num_updates=4600, lr=0.000184008, gnorm=0.846, clip=0, loss_scale=4, train_wall=85, gb_free=12.7, wall=3411
2023-08-31 21:04:37 | INFO | train_inner | epoch 003:   1054 / 1826 loss=2.73, trans_loss=4.031, nll_loss=2.438, w2v_ctc_loss=1.562, task_loss=2.33, contrastive_loss=0, total=3976.07, n_correct=1294.95, ppl=5.42, accuracy=32.569, wps=13898.8, ups=1.16, wpb=11957.1, bsz=435.4, num_updates=4700, lr=0.000188006, gnorm=0.83, clip=0, loss_scale=4, train_wall=85, gb_free=12.8, wall=3497
2023-08-31 21:06:03 | INFO | train_inner | epoch 003:   1154 / 1826 loss=2.704, trans_loss=4.028, nll_loss=2.434, w2v_ctc_loss=1.522, task_loss=2.482, contrastive_loss=0, total=3901.42, n_correct=1265.78, ppl=5.4, accuracy=32.444, wps=13597.5, ups=1.16, wpb=11738.2, bsz=407, num_updates=4800, lr=0.000192004, gnorm=0.791, clip=0, loss_scale=4, train_wall=86, gb_free=15.7, wall=3584
2023-08-31 21:07:29 | INFO | train_inner | epoch 003:   1254 / 1826 loss=2.703, trans_loss=4.032, nll_loss=2.438, w2v_ctc_loss=1.525, task_loss=2.402, contrastive_loss=0, total=4003, n_correct=1309.54, ppl=5.42, accuracy=32.714, wps=14068.6, ups=1.17, wpb=12035.7, bsz=427.7, num_updates=4900, lr=0.000196002, gnorm=0.824, clip=0, loss_scale=4, train_wall=85, gb_free=14.9, wall=3669
2023-08-31 21:08:54 | INFO | train_inner | epoch 003:   1354 / 1826 loss=2.698, trans_loss=4.027, nll_loss=2.432, w2v_ctc_loss=1.516, task_loss=2.556, contrastive_loss=0, total=3935.75, n_correct=1285.9, ppl=5.4, accuracy=32.672, wps=13875.1, ups=1.17, wpb=11835, bsz=404.8, num_updates=5000, lr=0.0002, gnorm=0.805, clip=0, loss_scale=4, train_wall=85, gb_free=15.6, wall=3754
mt_weight tensor(0.5000)
asr_weight tensor(0.3100, device='cuda:0')
2023-08-31 21:10:18 | INFO | train_inner | epoch 003:   1454 / 1826 loss=2.669, trans_loss=4.017, nll_loss=2.42, w2v_ctc_loss=1.481, task_loss=2.418, contrastive_loss=0, total=3857.16, n_correct=1270.09, ppl=5.35, accuracy=32.928, wps=13734.5, ups=1.18, wpb=11599.2, bsz=413.9, num_updates=5100, lr=0.00019803, gnorm=0.403, clip=0, loss_scale=4, train_wall=84, gb_free=11.4, wall=3839
2023-08-31 21:11:43 | INFO | train_inner | epoch 003:   1554 / 1826 loss=2.679, trans_loss=4.023, nll_loss=2.428, w2v_ctc_loss=1.497, task_loss=2.466, contrastive_loss=0, total=3912.36, n_correct=1282.97, ppl=5.38, accuracy=32.793, wps=13849.6, ups=1.18, wpb=11771.6, bsz=407.2, num_updates=5200, lr=0.000196116, gnorm=0.396, clip=0, loss_scale=8, train_wall=84, gb_free=16.9, wall=3924
2023-08-31 21:13:09 | INFO | train_inner | epoch 003:   1654 / 1826 loss=2.661, trans_loss=4.015, nll_loss=2.417, w2v_ctc_loss=1.477, task_loss=2.366, contrastive_loss=0, total=3941.21, n_correct=1306.98, ppl=5.34, accuracy=33.162, wps=13767.8, ups=1.16, wpb=11854.8, bsz=430.9, num_updates=5300, lr=0.000194257, gnorm=0.402, clip=0, loss_scale=8, train_wall=86, gb_free=16.4, wall=4010
2023-08-31 21:14:34 | INFO | train_inner | epoch 003:   1754 / 1826 loss=2.641, trans_loss=4.009, nll_loss=2.408, w2v_ctc_loss=1.452, task_loss=2.299, contrastive_loss=0, total=3972.84, n_correct=1325.4, ppl=5.31, accuracy=33.362, wps=14097.7, ups=1.18, wpb=11942.6, bsz=442.3, num_updates=5400, lr=0.00019245, gnorm=0.393, clip=0, loss_scale=8, train_wall=84, gb_free=17.6, wall=4095
2023-08-31 21:15:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.3100, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.3100, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.3100, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.3100, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.3100, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.3100, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.3100, device='cuda:5')
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 21:16:16 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.546 | trans_loss 7.469 | nll_loss 5.448 | w2v_ctc_loss 1.63 | task_loss 13.455 | contrastive_loss 0 | total 3505.91 | n_correct 1158.09 | ppl 43.65 | accuracy 33.033 | uer 24.288 | wer 25.925 | raw_wer 25.925 | bleu 0.22 | wps 1113.8 | wpb 3505.9 | bsz 119.3 | num_updates 5472 | best_bleu 0.36
2023-08-31 21:16:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 5472 updates
2023-08-31 21:16:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_0.2207.pt
2023-08-31 21:16:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_0.2207.pt
2023-08-31 21:16:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_0.2207.pt (epoch 3 @ 5472 updates, score 0.22) (writing took 6.247317414992722 seconds)
2023-08-31 21:16:23 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-31 21:16:23 | INFO | train | epoch 003 | loss 2.743 | trans_loss 4.036 | nll_loss 2.445 | w2v_ctc_loss 1.577 | task_loss 2.355 | contrastive_loss 0 | total 3956.37 | n_correct 1281 | ppl 5.44 | accuracy 32.378 | wps 13089.4 | ups 1.1 | wpb 11900.1 | bsz 427.2 | num_updates 5472 | lr 0.00019118 | gnorm 0.756 | clip 0 | loss_scale 8 | train_wall 1548 | gb_free 17 | wall 4203
2023-08-31 21:16:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 21:16:23 | INFO | fairseq.trainer | begin training epoch 4
2023-08-31 21:16:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 21:16:55 | INFO | train_inner | epoch 004:     28 / 1826 loss=2.646, trans_loss=4.004, nll_loss=2.402, w2v_ctc_loss=1.46, task_loss=2.304, contrastive_loss=0, total=3992.31, n_correct=1332.17, ppl=5.29, accuracy=33.368, wps=8580.8, ups=0.71, wpb=12005.1, bsz=430.1, num_updates=5500, lr=0.000190693, gnorm=0.402, clip=0, loss_scale=8, train_wall=85, gb_free=15.4, wall=4235
2023-08-31 21:18:20 | INFO | train_inner | epoch 004:    128 / 1826 loss=2.602, trans_loss=3.986, nll_loss=2.381, w2v_ctc_loss=1.405, task_loss=2.339, contrastive_loss=0, total=3976.39, n_correct=1342.42, ppl=5.21, accuracy=33.76, wps=14109.9, ups=1.18, wpb=11968, bsz=431.8, num_updates=5600, lr=0.000188982, gnorm=0.409, clip=0, loss_scale=8, train_wall=84, gb_free=15.3, wall=4320
2023-08-31 21:19:44 | INFO | train_inner | epoch 004:    228 / 1826 loss=2.592, trans_loss=3.983, nll_loss=2.375, w2v_ctc_loss=1.397, task_loss=2.29, contrastive_loss=0, total=3980.52, n_correct=1352.75, ppl=5.19, accuracy=33.984, wps=14168.4, ups=1.18, wpb=11968.6, bsz=432.9, num_updates=5700, lr=0.000187317, gnorm=0.416, clip=0, loss_scale=8, train_wall=84, gb_free=16.1, wall=4405
2023-08-31 21:21:09 | INFO | train_inner | epoch 004:    328 / 1826 loss=2.583, trans_loss=3.975, nll_loss=2.364, w2v_ctc_loss=1.39, task_loss=2.223, contrastive_loss=0, total=3979.62, n_correct=1361.93, ppl=5.15, accuracy=34.223, wps=14099.3, ups=1.18, wpb=11964.8, bsz=446.1, num_updates=5800, lr=0.000185695, gnorm=0.393, clip=0, loss_scale=8, train_wall=84, gb_free=15, wall=4489
2023-08-31 21:22:34 | INFO | train_inner | epoch 004:    428 / 1826 loss=2.588, trans_loss=3.97, nll_loss=2.357, w2v_ctc_loss=1.394, task_loss=2.319, contrastive_loss=0, total=3994.06, n_correct=1369.68, ppl=5.12, accuracy=34.293, wps=14091.7, ups=1.17, wpb=12007.9, bsz=436.3, num_updates=5900, lr=0.000184115, gnorm=0.388, clip=0, loss_scale=8, train_wall=85, gb_free=16.8, wall=4575
2023-08-31 21:23:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-31 21:24:01 | INFO | train_inner | epoch 004:    529 / 1826 loss=2.584, trans_loss=3.976, nll_loss=2.366, w2v_ctc_loss=1.389, task_loss=2.542, contrastive_loss=0, total=3890.91, n_correct=1327.04, ppl=5.16, accuracy=34.106, wps=13489.4, ups=1.15, wpb=11703.4, bsz=408.2, num_updates=6000, lr=0.000182574, gnorm=0.428, clip=0, loss_scale=4, train_wall=86, gb_free=16.3, wall=4661
2023-08-31 21:24:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 21:24:41 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 5.521 | trans_loss 7.416 | nll_loss 5.375 | w2v_ctc_loss 1.669 | task_loss 13.339 | contrastive_loss 0 | total 3505.91 | n_correct 1187.73 | ppl 41.51 | accuracy 33.878 | uer 24.191 | wer 25.52 | raw_wer 25.52 | bleu 0.4 | wps 1126.3 | wpb 3505.9 | bsz 119.3 | num_updates 6000 | best_bleu 0.4
2023-08-31 21:24:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 6000 updates
2023-08-31 21:24:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_4_6000.pt
2023-08-31 21:24:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_4_6000.pt
2023-08-31 21:24:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_4_6000.pt (epoch 4 @ 6000 updates, score 0.4) (writing took 12.335635344003094 seconds)
2023-08-31 21:26:18 | INFO | train_inner | epoch 004:    629 / 1826 loss=2.596, trans_loss=3.981, nll_loss=2.369, w2v_ctc_loss=1.409, task_loss=2.309, contrastive_loss=0, total=4013.62, n_correct=1376.14, ppl=5.17, accuracy=34.287, wps=8822.1, ups=0.73, wpb=12059.1, bsz=438.2, num_updates=6100, lr=0.000181071, gnorm=0.509, clip=0, loss_scale=4, train_wall=83, gb_free=16.5, wall=4798
2023-08-31 21:27:43 | INFO | train_inner | epoch 004:    729 / 1826 loss=2.58, trans_loss=3.962, nll_loss=2.351, w2v_ctc_loss=1.394, task_loss=2.541, contrastive_loss=0, total=3910.43, n_correct=1343.52, ppl=5.1, accuracy=34.357, wps=13812, ups=1.17, wpb=11776.9, bsz=405.2, num_updates=6200, lr=0.000179605, gnorm=0.441, clip=0, loss_scale=4, train_wall=85, gb_free=17.4, wall=4883
2023-08-31 21:29:10 | INFO | train_inner | epoch 004:    829 / 1826 loss=2.57, trans_loss=3.954, nll_loss=2.337, w2v_ctc_loss=1.389, task_loss=2.167, contrastive_loss=0, total=4018.4, n_correct=1406.72, ppl=5.05, accuracy=35.007, wps=13915.5, ups=1.15, wpb=12083.9, bsz=452, num_updates=6300, lr=0.000178174, gnorm=0.503, clip=0, loss_scale=4, train_wall=86, gb_free=12.2, wall=4970
2023-08-31 21:30:35 | INFO | train_inner | epoch 004:    929 / 1826 loss=2.576, trans_loss=3.961, nll_loss=2.346, w2v_ctc_loss=1.397, task_loss=2.409, contrastive_loss=0, total=3972.03, n_correct=1384.74, ppl=5.08, accuracy=34.862, wps=13936.6, ups=1.17, wpb=11943.3, bsz=432.5, num_updates=6400, lr=0.000176777, gnorm=0.449, clip=0, loss_scale=4, train_wall=85, gb_free=14.1, wall=5056
2023-08-31 21:32:00 | INFO | train_inner | epoch 004:   1029 / 1826 loss=2.57, trans_loss=3.952, nll_loss=2.335, w2v_ctc_loss=1.389, task_loss=2.498, contrastive_loss=0, total=3921.06, n_correct=1367.74, ppl=5.05, accuracy=34.882, wps=13943.7, ups=1.18, wpb=11792.9, bsz=414.7, num_updates=6500, lr=0.000175412, gnorm=0.451, clip=0, loss_scale=4, train_wall=84, gb_free=17.2, wall=5140
2023-08-31 21:33:25 | INFO | train_inner | epoch 004:   1129 / 1826 loss=2.559, trans_loss=3.946, nll_loss=2.328, w2v_ctc_loss=1.374, task_loss=2.654, contrastive_loss=0, total=3911.31, n_correct=1371.79, ppl=5.02, accuracy=35.072, wps=13758.8, ups=1.17, wpb=11765.2, bsz=397, num_updates=6600, lr=0.000174078, gnorm=0.416, clip=0, loss_scale=4, train_wall=85, gb_free=17.4, wall=5226
2023-08-31 21:34:50 | INFO | train_inner | epoch 004:   1229 / 1826 loss=2.538, trans_loss=3.938, nll_loss=2.315, w2v_ctc_loss=1.356, task_loss=2.462, contrastive_loss=0, total=3976.2, n_correct=1414.92, ppl=4.98, accuracy=35.585, wps=14113.1, ups=1.18, wpb=11952.7, bsz=423.4, num_updates=6700, lr=0.000172774, gnorm=0.43, clip=0, loss_scale=4, train_wall=84, gb_free=16.3, wall=5311
2023-08-31 21:36:15 | INFO | train_inner | epoch 004:   1329 / 1826 loss=2.547, trans_loss=3.937, nll_loss=2.314, w2v_ctc_loss=1.374, task_loss=2.608, contrastive_loss=0, total=3851.45, n_correct=1370.76, ppl=4.97, accuracy=35.591, wps=13576.3, ups=1.17, wpb=11581, bsz=397.9, num_updates=6800, lr=0.000171499, gnorm=0.435, clip=0, loss_scale=4, train_wall=84, gb_free=16.6, wall=5396
2023-08-31 21:37:40 | INFO | train_inner | epoch 004:   1429 / 1826 loss=2.526, trans_loss=3.924, nll_loss=2.298, w2v_ctc_loss=1.361, task_loss=2.269, contrastive_loss=0, total=3977.92, n_correct=1441.48, ppl=4.92, accuracy=36.237, wps=14084.8, ups=1.18, wpb=11964.6, bsz=450.4, num_updates=6900, lr=0.000170251, gnorm=0.467, clip=0, loss_scale=4, train_wall=84, gb_free=15.9, wall=5481
2023-08-31 21:39:06 | INFO | train_inner | epoch 004:   1529 / 1826 loss=2.518, trans_loss=3.913, nll_loss=2.286, w2v_ctc_loss=1.355, task_loss=2.27, contrastive_loss=0, total=4016.81, n_correct=1468.12, ppl=4.88, accuracy=36.549, wps=14162.9, ups=1.17, wpb=12091.4, bsz=454.6, num_updates=7000, lr=0.000169031, gnorm=0.445, clip=0, loss_scale=4, train_wall=85, gb_free=15.7, wall=5566
2023-08-31 21:40:31 | INFO | train_inner | epoch 004:   1629 / 1826 loss=2.522, trans_loss=3.908, nll_loss=2.278, w2v_ctc_loss=1.361, task_loss=2.396, contrastive_loss=0, total=3952, n_correct=1446.56, ppl=4.85, accuracy=36.603, wps=13914.2, ups=1.17, wpb=11891.4, bsz=425.3, num_updates=7100, lr=0.000167836, gnorm=0.483, clip=0, loss_scale=4, train_wall=85, gb_free=16.4, wall=5652
2023-08-31 21:41:56 | INFO | train_inner | epoch 004:   1729 / 1826 loss=2.523, trans_loss=3.914, nll_loss=2.288, w2v_ctc_loss=1.36, task_loss=2.571, contrastive_loss=0, total=3873.19, n_correct=1411.96, ppl=4.88, accuracy=36.455, wps=13809.1, ups=1.18, wpb=11660, bsz=399.1, num_updates=7200, lr=0.000166667, gnorm=0.474, clip=0, loss_scale=4, train_wall=84, gb_free=17.4, wall=5736
2023-08-31 21:43:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([6.5565e-07], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 21:43:57 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 5.311 | trans_loss 7.136 | nll_loss 5.003 | w2v_ctc_loss 1.601 | task_loss 13.437 | contrastive_loss 0 | total 3505.91 | n_correct 1303 | ppl 32.08 | accuracy 37.166 | uer 23.158 | wer 24.927 | raw_wer 24.927 | bleu 1.83 | wps 1169.6 | wpb 3505.9 | bsz 119.3 | num_updates 7297 | best_bleu 1.83
2023-08-31 21:43:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 7297 updates
2023-08-31 21:43:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-08-31 21:44:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-08-31 21:44:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt (epoch 4 @ 7297 updates, score 1.83) (writing took 12.31037626399484 seconds)
2023-08-31 21:44:10 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-31 21:44:10 | INFO | train | epoch 004 | loss 2.561 | trans_loss 3.95 | nll_loss 2.332 | w2v_ctc_loss 1.381 | task_loss 2.396 | contrastive_loss 0 | total 3955.28 | n_correct 1389.6 | ppl 5.04 | accuracy 35.133 | wps 13020.5 | ups 1.09 | wpb 11896.9 | bsz 426.6 | num_updates 7297 | lr 0.000165555 | gnorm 0.445 | clip 0 | loss_scale 4 | train_wall 1542 | gb_free 16.8 | wall 5871
2023-08-31 21:44:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 21:44:10 | INFO | fairseq.trainer | begin training epoch 5
2023-08-31 21:44:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 21:44:20 | INFO | train_inner | epoch 005:      3 / 1826 loss=2.508, trans_loss=3.904, nll_loss=2.273, w2v_ctc_loss=1.349, task_loss=2.454, contrastive_loss=0, total=3929.35, n_correct=1452.91, ppl=4.83, accuracy=36.976, wps=8206.4, ups=0.69, wpb=11819.2, bsz=419.2, num_updates=7300, lr=0.000165521, gnorm=0.481, clip=0, loss_scale=4, train_wall=84, gb_free=15.1, wall=5880
2023-08-31 21:45:44 | INFO | train_inner | epoch 005:    103 / 1826 loss=2.454, trans_loss=3.87, nll_loss=2.227, w2v_ctc_loss=1.291, task_loss=2.303, contrastive_loss=0, total=3932.1, n_correct=1491.91, ppl=4.68, accuracy=37.942, wps=13947, ups=1.18, wpb=11821.8, bsz=440.1, num_updates=7400, lr=0.000164399, gnorm=0.463, clip=0, loss_scale=4, train_wall=84, gb_free=16.1, wall=5965
2023-08-31 21:47:09 | INFO | train_inner | epoch 005:    203 / 1826 loss=2.446, trans_loss=3.863, nll_loss=2.221, w2v_ctc_loss=1.289, task_loss=2.217, contrastive_loss=0, total=3985.54, n_correct=1525.35, ppl=4.66, accuracy=38.272, wps=14162.1, ups=1.18, wpb=11997.6, bsz=449.5, num_updates=7500, lr=0.000163299, gnorm=0.435, clip=0, loss_scale=4, train_wall=84, gb_free=16.5, wall=6050
2023-08-31 21:48:34 | INFO | train_inner | epoch 005:    303 / 1826 loss=2.456, trans_loss=3.864, nll_loss=2.218, w2v_ctc_loss=1.302, task_loss=2.442, contrastive_loss=0, total=3963.01, n_correct=1511.46, ppl=4.65, accuracy=38.139, wps=14043.5, ups=1.18, wpb=11915.3, bsz=423.7, num_updates=7600, lr=0.000162221, gnorm=0.447, clip=0, loss_scale=4, train_wall=84, gb_free=16.7, wall=6135
2023-08-31 21:49:59 | INFO | train_inner | epoch 005:    403 / 1826 loss=2.463, trans_loss=3.858, nll_loss=2.211, w2v_ctc_loss=1.32, task_loss=2.509, contrastive_loss=0, total=3932.81, n_correct=1512.06, ppl=4.63, accuracy=38.447, wps=13897.2, ups=1.17, wpb=11828.4, bsz=412.6, num_updates=7700, lr=0.000161165, gnorm=0.44, clip=0, loss_scale=4, train_wall=84, gb_free=10.6, wall=6220
2023-08-31 21:51:25 | INFO | train_inner | epoch 005:    503 / 1826 loss=2.416, trans_loss=3.832, nll_loss=2.181, w2v_ctc_loss=1.27, task_loss=2.284, contrastive_loss=0, total=3984.84, n_correct=1562.82, ppl=4.54, accuracy=39.219, wps=13967, ups=1.16, wpb=11997.7, bsz=446.8, num_updates=7800, lr=0.000160128, gnorm=0.461, clip=0, loss_scale=4, train_wall=85, gb_free=14.6, wall=6306
2023-08-31 21:52:50 | INFO | train_inner | epoch 005:    603 / 1826 loss=2.435, trans_loss=3.837, nll_loss=2.185, w2v_ctc_loss=1.298, task_loss=2.447, contrastive_loss=0, total=3959.36, n_correct=1555.11, ppl=4.55, accuracy=39.277, wps=13945.2, ups=1.17, wpb=11910, bsz=420.2, num_updates=7900, lr=0.000159111, gnorm=0.503, clip=0, loss_scale=4, train_wall=85, gb_free=16, wall=6391
2023-08-31 21:54:15 | INFO | train_inner | epoch 005:    703 / 1826 loss=2.428, trans_loss=3.824, nll_loss=2.168, w2v_ctc_loss=1.3, task_loss=2.495, contrastive_loss=0, total=3894.02, n_correct=1555.51, ppl=4.49, accuracy=39.946, wps=13878.7, ups=1.18, wpb=11714.6, bsz=410.3, num_updates=8000, lr=0.000158114, gnorm=0.499, clip=0, loss_scale=4, train_wall=84, gb_free=16.2, wall=6475
2023-08-31 21:54:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([5.9605e-08], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 21:54:54 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 5.141 | trans_loss 6.879 | nll_loss 4.668 | w2v_ctc_loss 1.611 | task_loss 13.373 | contrastive_loss 0 | total 3505.91 | n_correct 1431.64 | ppl 25.42 | accuracy 40.835 | uer 22.316 | wer 23.857 | raw_wer 23.857 | bleu 4.17 | wps 1199.4 | wpb 3505.9 | bsz 119.3 | num_updates 8000 | best_bleu 4.17
2023-08-31 21:54:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 8000 updates
2023-08-31 21:54:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_5_8000.pt
2023-08-31 21:54:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_5_8000.pt
2023-08-31 21:55:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_5_8000.pt (epoch 5 @ 8000 updates, score 4.17) (writing took 11.996582820996991 seconds)
2023-08-31 21:56:30 | INFO | train_inner | epoch 005:    803 / 1826 loss=2.437, trans_loss=3.818, nll_loss=2.161, w2v_ctc_loss=1.315, task_loss=2.612, contrastive_loss=0, total=3875.79, n_correct=1554.79, ppl=4.47, accuracy=40.115, wps=8612.4, ups=0.74, wpb=11658.7, bsz=403.9, num_updates=8100, lr=0.000157135, gnorm=0.574, clip=0, loss_scale=8, train_wall=84, gb_free=15, wall=6611
2023-08-31 21:57:55 | INFO | train_inner | epoch 005:    903 / 1826 loss=2.407, trans_loss=3.797, nll_loss=2.134, w2v_ctc_loss=1.301, task_loss=2.296, contrastive_loss=0, total=4005.67, n_correct=1651.64, ppl=4.39, accuracy=41.233, wps=14225, ups=1.18, wpb=12056, bsz=445.5, num_updates=8200, lr=0.000156174, gnorm=0.493, clip=0, loss_scale=8, train_wall=84, gb_free=16.7, wall=6696
2023-08-31 21:59:20 | INFO | train_inner | epoch 005:   1003 / 1826 loss=2.402, trans_loss=3.786, nll_loss=2.119, w2v_ctc_loss=1.302, task_loss=2.47, contrastive_loss=0, total=3983.05, n_correct=1662.03, ppl=4.34, accuracy=41.728, wps=14027.2, ups=1.17, wpb=11986.6, bsz=422.9, num_updates=8300, lr=0.00015523, gnorm=0.482, clip=0, loss_scale=8, train_wall=85, gb_free=17.4, wall=6781
2023-08-31 22:00:46 | INFO | train_inner | epoch 005:   1103 / 1826 loss=2.384, trans_loss=3.765, nll_loss=2.091, w2v_ctc_loss=1.305, task_loss=2.271, contrastive_loss=0, total=3974.9, n_correct=1705.44, ppl=4.26, accuracy=42.905, wps=13962.8, ups=1.17, wpb=11955.5, bsz=450.4, num_updates=8400, lr=0.000154303, gnorm=0.53, clip=0, loss_scale=8, train_wall=85, gb_free=16.5, wall=6867
2023-08-31 22:02:12 | INFO | train_inner | epoch 005:   1203 / 1826 loss=2.364, trans_loss=3.748, nll_loss=2.066, w2v_ctc_loss=1.287, task_loss=2.569, contrastive_loss=0, total=3914.61, n_correct=1702.97, ppl=4.19, accuracy=43.503, wps=13698.4, ups=1.16, wpb=11768.7, bsz=406, num_updates=8500, lr=0.000153393, gnorm=0.499, clip=0, loss_scale=8, train_wall=85, gb_free=10.9, wall=6953
2023-08-31 22:03:37 | INFO | train_inner | epoch 005:   1303 / 1826 loss=2.353, trans_loss=3.716, nll_loss=2.026, w2v_ctc_loss=1.302, task_loss=2.297, contrastive_loss=0, total=3974.31, n_correct=1779.15, ppl=4.07, accuracy=44.766, wps=14090.9, ups=1.18, wpb=11951.7, bsz=432.8, num_updates=8600, lr=0.000152499, gnorm=0.623, clip=0, loss_scale=8, train_wall=84, gb_free=12.4, wall=7037
2023-08-31 22:05:01 | INFO | train_inner | epoch 005:   1403 / 1826 loss=2.329, trans_loss=3.697, nll_loss=1.999, w2v_ctc_loss=1.293, task_loss=2.328, contrastive_loss=0, total=3984.94, n_correct=1833.27, ppl=4, accuracy=46.005, wps=14209.7, ups=1.19, wpb=11976, bsz=429, num_updates=8700, lr=0.00015162, gnorm=0.541, clip=0, loss_scale=8, train_wall=83, gb_free=13.6, wall=7122
2023-08-31 22:06:27 | INFO | train_inner | epoch 005:   1503 / 1826 loss=2.33, trans_loss=3.668, nll_loss=1.964, w2v_ctc_loss=1.319, task_loss=2.47, contrastive_loss=0, total=3938.34, n_correct=1851.4, ppl=3.9, accuracy=47.01, wps=13848, ups=1.17, wpb=11849.5, bsz=415, num_updates=8800, lr=0.000150756, gnorm=0.591, clip=0, loss_scale=8, train_wall=85, gb_free=16.6, wall=7207
2023-08-31 22:07:53 | INFO | train_inner | epoch 005:   1603 / 1826 loss=2.305, trans_loss=3.64, nll_loss=1.927, w2v_ctc_loss=1.311, task_loss=2.352, contrastive_loss=0, total=3987.37, n_correct=1923.27, ppl=3.8, accuracy=48.234, wps=13889.6, ups=1.16, wpb=11993.7, bsz=424.4, num_updates=8900, lr=0.000149906, gnorm=0.549, clip=0, loss_scale=8, train_wall=86, gb_free=16.2, wall=7294
2023-08-31 22:09:17 | INFO | train_inner | epoch 005:   1703 / 1826 loss=2.281, trans_loss=3.623, nll_loss=1.902, w2v_ctc_loss=1.3, task_loss=2.263, contrastive_loss=0, total=4009.31, n_correct=1979.8, ppl=3.74, accuracy=49.38, wps=14292.5, ups=1.19, wpb=12044.8, bsz=436.7, num_updates=9000, lr=0.000149071, gnorm=0.548, clip=0, loss_scale=8, train_wall=84, gb_free=17.2, wall=7378
2023-08-31 22:10:42 | INFO | train_inner | epoch 005:   1803 / 1826 loss=2.252, trans_loss=3.591, nll_loss=1.863, w2v_ctc_loss=1.285, task_loss=2.247, contrastive_loss=0, total=3996.35, n_correct=2016.12, ppl=3.64, accuracy=50.449, wps=14187.9, ups=1.18, wpb=12017.1, bsz=442.3, num_updates=9100, lr=0.00014825, gnorm=0.554, clip=0, loss_scale=8, train_wall=84, gb_free=16.5, wall=7463
2023-08-31 22:11:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([7.1526e-07], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 22:11:41 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.456 | trans_loss 5.93 | nll_loss 3.415 | w2v_ctc_loss 1.472 | task_loss 13.307 | contrastive_loss 0 | total 3505.91 | n_correct 1925.27 | ppl 10.67 | accuracy 54.915 | uer 21.591 | wer 23.185 | raw_wer 23.185 | bleu 16.73 | wps 1133.5 | wpb 3505.9 | bsz 119.3 | num_updates 9123 | best_bleu 16.73
2023-08-31 22:11:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 9123 updates
2023-08-31 22:11:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-08-31 22:11:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-08-31 22:11:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt (epoch 5 @ 9123 updates, score 16.73) (writing took 12.787592626002152 seconds)
2023-08-31 22:11:55 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-31 22:11:55 | INFO | train | epoch 005 | loss 2.384 | trans_loss 3.764 | nll_loss 2.09 | w2v_ctc_loss 1.3 | task_loss 2.383 | contrastive_loss 0 | total 3956.37 | n_correct 1688.61 | ppl 4.26 | accuracy 42.681 | wps 13054.7 | ups 1.1 | wpb 11900.1 | bsz 427.2 | num_updates 9123 | lr 0.000148063 | gnorm 0.515 | clip 0 | loss_scale 8 | train_wall 1540 | gb_free 17.1 | wall 7535
2023-08-31 22:11:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 22:11:55 | INFO | fairseq.trainer | begin training epoch 6
2023-08-31 22:11:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 22:13:08 | INFO | train_inner | epoch 006:     77 / 1826 loss=2.216, trans_loss=3.563, nll_loss=1.826, w2v_ctc_loss=1.255, task_loss=2.421, contrastive_loss=0, total=3901.44, n_correct=2006.53, ppl=3.55, accuracy=51.43, wps=8062.7, ups=0.69, wpb=11734.7, bsz=413.5, num_updates=9200, lr=0.000147442, gnorm=0.572, clip=0, loss_scale=8, train_wall=84, gb_free=15.6, wall=7608
2023-08-31 22:14:35 | INFO | train_inner | epoch 006:    177 / 1826 loss=2.218, trans_loss=3.548, nll_loss=1.807, w2v_ctc_loss=1.271, task_loss=2.525, contrastive_loss=0, total=3953.4, n_correct=2062.78, ppl=3.5, accuracy=52.177, wps=13671.3, ups=1.15, wpb=11891.1, bsz=414.6, num_updates=9300, lr=0.000146647, gnorm=0.529, clip=0, loss_scale=8, train_wall=86, gb_free=16.6, wall=7695
2023-08-31 22:15:59 | INFO | train_inner | epoch 006:    277 / 1826 loss=2.203, trans_loss=3.528, nll_loss=1.782, w2v_ctc_loss=1.268, task_loss=2.493, contrastive_loss=0, total=3921.44, n_correct=2077.02, ppl=3.44, accuracy=52.966, wps=13908.5, ups=1.18, wpb=11797.2, bsz=409.4, num_updates=9400, lr=0.000145865, gnorm=0.527, clip=0, loss_scale=8, train_wall=84, gb_free=16.7, wall=7780
2023-08-31 22:17:25 | INFO | train_inner | epoch 006:    377 / 1826 loss=2.176, trans_loss=3.496, nll_loss=1.743, w2v_ctc_loss=1.256, task_loss=2.294, contrastive_loss=0, total=3979.76, n_correct=2151.72, ppl=3.35, accuracy=54.067, wps=14048.5, ups=1.17, wpb=11980.1, bsz=439.9, num_updates=9500, lr=0.000145095, gnorm=0.499, clip=0, loss_scale=8, train_wall=84, gb_free=16.7, wall=7865
2023-08-31 22:18:49 | INFO | train_inner | epoch 006:    477 / 1826 loss=2.172, trans_loss=3.49, nll_loss=1.733, w2v_ctc_loss=1.261, task_loss=2.513, contrastive_loss=0, total=3916.46, n_correct=2133.53, ppl=3.33, accuracy=54.476, wps=13917.4, ups=1.18, wpb=11783.6, bsz=407.9, num_updates=9600, lr=0.000144338, gnorm=0.503, clip=0, loss_scale=8, train_wall=84, gb_free=17.5, wall=7950
2023-08-31 22:20:15 | INFO | train_inner | epoch 006:    577 / 1826 loss=2.165, trans_loss=3.487, nll_loss=1.728, w2v_ctc_loss=1.257, task_loss=2.35, contrastive_loss=0, total=3969.58, n_correct=2179.24, ppl=3.31, accuracy=54.899, wps=14003.4, ups=1.17, wpb=11936.3, bsz=429.2, num_updates=9700, lr=0.000143592, gnorm=0.514, clip=0, loss_scale=8, train_wall=85, gb_free=14.1, wall=8035
2023-08-31 22:21:39 | INFO | train_inner | epoch 006:    677 / 1826 loss=2.14, trans_loss=3.461, nll_loss=1.697, w2v_ctc_loss=1.242, task_loss=2.324, contrastive_loss=0, total=3956.62, n_correct=2207.11, ppl=3.24, accuracy=55.783, wps=14044.4, ups=1.18, wpb=11905.2, bsz=431.1, num_updates=9800, lr=0.000142857, gnorm=0.482, clip=0, loss_scale=8, train_wall=84, gb_free=15.2, wall=8120
2023-08-31 22:23:05 | INFO | train_inner | epoch 006:    777 / 1826 loss=2.133, trans_loss=3.455, nll_loss=1.688, w2v_ctc_loss=1.239, task_loss=2.332, contrastive_loss=0, total=4000.62, n_correct=2250.88, ppl=3.22, accuracy=56.263, wps=14096.7, ups=1.17, wpb=12029.9, bsz=436.1, num_updates=9900, lr=0.000142134, gnorm=0.487, clip=0, loss_scale=8, train_wall=85, gb_free=16.4, wall=8205
2023-08-31 22:24:29 | INFO | train_inner | epoch 006:    877 / 1826 loss=2.126, trans_loss=3.445, nll_loss=1.677, w2v_ctc_loss=1.238, task_loss=2.351, contrastive_loss=0, total=3963.66, n_correct=2242.19, ppl=3.2, accuracy=56.569, wps=14075.5, ups=1.18, wpb=11925.8, bsz=434.7, num_updates=10000, lr=0.000141421, gnorm=0.477, clip=0, loss_scale=8, train_wall=84, gb_free=17.5, wall=8290
2023-08-31 22:24:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 22:25:08 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.196 | trans_loss 5.525 | nll_loss 2.9 | w2v_ctc_loss 1.52 | task_loss 13.516 | contrastive_loss 0 | total 3505.91 | n_correct 2148.36 | ppl 7.46 | accuracy 61.278 | uer 20.516 | wer 22.135 | raw_wer 22.135 | bleu 22.63 | wps 1202.5 | wpb 3505.9 | bsz 119.3 | num_updates 10000 | best_bleu 22.63
2023-08-31 22:25:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 10000 updates
2023-08-31 22:25:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_6_10000.pt
2023-08-31 22:25:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_6_10000.pt
2023-08-31 22:25:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_6_10000.pt (epoch 6 @ 10000 updates, score 22.63) (writing took 11.410395215993049 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:0')
2023-08-31 22:26:43 | INFO | train_inner | epoch 006:    977 / 1826 loss=2.117, trans_loss=3.44, nll_loss=1.667, w2v_ctc_loss=1.233, task_loss=2.279, contrastive_loss=0, total=3995.48, n_correct=2276.38, ppl=3.18, accuracy=56.974, wps=8991.6, ups=0.75, wpb=12007.9, bsz=443.4, num_updates=10100, lr=0.00014072, gnorm=0.479, clip=0, loss_scale=16, train_wall=83, gb_free=12.4, wall=8424
2023-08-31 22:28:07 | INFO | train_inner | epoch 006:   1077 / 1826 loss=2.118, trans_loss=3.426, nll_loss=1.653, w2v_ctc_loss=1.245, task_loss=2.374, contrastive_loss=0, total=3953.76, n_correct=2270.68, ppl=3.14, accuracy=57.431, wps=14135, ups=1.19, wpb=11894.9, bsz=420.9, num_updates=10200, lr=0.000140028, gnorm=0.467, clip=0, loss_scale=16, train_wall=83, gb_free=11.7, wall=8508
2023-08-31 22:29:31 | INFO | train_inner | epoch 006:   1177 / 1826 loss=2.108, trans_loss=3.421, nll_loss=1.646, w2v_ctc_loss=1.235, task_loss=2.437, contrastive_loss=0, total=3920.79, n_correct=2259.65, ppl=3.13, accuracy=57.633, wps=14042.1, ups=1.19, wpb=11798.2, bsz=423.8, num_updates=10300, lr=0.000139347, gnorm=0.472, clip=0, loss_scale=16, train_wall=83, gb_free=16.6, wall=8592
2023-08-31 22:30:55 | INFO | train_inner | epoch 006:   1277 / 1826 loss=2.1, trans_loss=3.405, nll_loss=1.625, w2v_ctc_loss=1.237, task_loss=2.284, contrastive_loss=0, total=3964.52, n_correct=2304.51, ppl=3.09, accuracy=58.128, wps=14159.5, ups=1.19, wpb=11927.4, bsz=444, num_updates=10400, lr=0.000138675, gnorm=0.47, clip=0, loss_scale=16, train_wall=84, gb_free=16.4, wall=8676
2023-08-31 22:32:21 | INFO | train_inner | epoch 006:   1377 / 1826 loss=2.104, trans_loss=3.41, nll_loss=1.629, w2v_ctc_loss=1.237, task_loss=2.535, contrastive_loss=0, total=3936.09, n_correct=2286.24, ppl=3.09, accuracy=58.084, wps=13750.1, ups=1.16, wpb=11833, bsz=409.7, num_updates=10500, lr=0.000138013, gnorm=0.449, clip=0, loss_scale=16, train_wall=85, gb_free=14, wall=8762
2023-08-31 22:33:47 | INFO | train_inner | epoch 006:   1477 / 1826 loss=2.097, trans_loss=3.406, nll_loss=1.624, w2v_ctc_loss=1.234, task_loss=2.414, contrastive_loss=0, total=3935.73, n_correct=2301.17, ppl=3.08, accuracy=58.469, wps=13855.6, ups=1.17, wpb=11827.7, bsz=422.9, num_updates=10600, lr=0.000137361, gnorm=0.453, clip=0, loss_scale=16, train_wall=85, gb_free=15.7, wall=8847
2023-08-31 22:35:13 | INFO | train_inner | epoch 006:   1577 / 1826 loss=2.092, trans_loss=3.405, nll_loss=1.623, w2v_ctc_loss=1.23, task_loss=2.437, contrastive_loss=0, total=3955.9, n_correct=2321.34, ppl=3.08, accuracy=58.68, wps=13867.1, ups=1.17, wpb=11891.7, bsz=423.3, num_updates=10700, lr=0.000136717, gnorm=0.446, clip=0, loss_scale=16, train_wall=85, gb_free=16, wall=8933
2023-08-31 22:36:38 | INFO | train_inner | epoch 006:   1677 / 1826 loss=2.059, trans_loss=3.384, nll_loss=1.599, w2v_ctc_loss=1.199, task_loss=2.31, contrastive_loss=0, total=3965.67, n_correct=2352.9, ppl=3.03, accuracy=59.332, wps=14044, ups=1.18, wpb=11926.5, bsz=430.8, num_updates=10800, lr=0.000136083, gnorm=0.424, clip=0, loss_scale=16, train_wall=84, gb_free=12.9, wall=9018
2023-08-31 22:38:01 | INFO | train_inner | epoch 006:   1777 / 1826 loss=2.08, trans_loss=3.389, nll_loss=1.607, w2v_ctc_loss=1.229, task_loss=2.334, contrastive_loss=0, total=3957.28, n_correct=2342.63, ppl=3.05, accuracy=59.198, wps=14261.6, ups=1.2, wpb=11910.6, bsz=431, num_updates=10900, lr=0.000135457, gnorm=0.422, clip=0, loss_scale=16, train_wall=83, gb_free=13, wall=9102
2023-08-31 22:38:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:3')
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 22:39:23 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.084 | trans_loss 5.367 | nll_loss 2.705 | w2v_ctc_loss 1.504 | task_loss 13.523 | contrastive_loss 0 | total 3505.91 | n_correct 2221.09 | ppl 6.52 | accuracy 63.353 | uer 20.54 | wer 22.319 | raw_wer 22.319 | bleu 24.87 | wps 1130.2 | wpb 3505.9 | bsz 119.3 | num_updates 10949 | best_bleu 24.87
2023-08-31 22:39:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 10949 updates
2023-08-31 22:39:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-08-31 22:39:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-08-31 22:39:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt (epoch 6 @ 10949 updates, score 24.87) (writing took 13.09515267900133 seconds)
2023-08-31 22:39:36 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-31 22:39:36 | INFO | train | epoch 006 | loss 2.131 | trans_loss 3.45 | nll_loss 1.682 | w2v_ctc_loss 1.241 | task_loss 2.38 | contrastive_loss 0 | total 3956.37 | n_correct 2232.01 | ppl 3.21 | accuracy 56.416 | wps 13080.7 | ups 1.1 | wpb 11900.1 | bsz 427.2 | num_updates 10949 | lr 0.000135154 | gnorm 0.478 | clip 0 | loss_scale 16 | train_wall 1537 | gb_free 16.6 | wall 9196
2023-08-31 22:39:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 22:39:36 | INFO | fairseq.trainer | begin training epoch 7
2023-08-31 22:39:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 22:40:26 | INFO | train_inner | epoch 007:     51 / 1826 loss=2.059, trans_loss=3.368, nll_loss=1.58, w2v_ctc_loss=1.21, task_loss=2.31, contrastive_loss=0, total=3941.93, n_correct=2356.12, ppl=2.99, accuracy=59.771, wps=8169.5, ups=0.69, wpb=11864, bsz=430.3, num_updates=11000, lr=0.00013484, gnorm=0.428, clip=0, loss_scale=16, train_wall=84, gb_free=14.9, wall=9247
2023-08-31 22:41:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-31 22:41:52 | INFO | train_inner | epoch 007:    152 / 1826 loss=2.031, trans_loss=3.361, nll_loss=1.568, w2v_ctc_loss=1.177, task_loss=2.326, contrastive_loss=0, total=3954.25, n_correct=2377.95, ppl=2.96, accuracy=60.137, wps=13948.3, ups=1.17, wpb=11892.5, bsz=431.9, num_updates=11100, lr=0.000134231, gnorm=0.441, clip=0, loss_scale=8, train_wall=85, gb_free=12.7, wall=9332
2023-08-31 22:43:16 | INFO | train_inner | epoch 007:    252 / 1826 loss=2.044, trans_loss=3.36, nll_loss=1.566, w2v_ctc_loss=1.194, task_loss=2.605, contrastive_loss=0, total=3898.38, n_correct=2348.21, ppl=2.96, accuracy=60.236, wps=13876.1, ups=1.18, wpb=11720.9, bsz=401.6, num_updates=11200, lr=0.000133631, gnorm=0.434, clip=0, loss_scale=8, train_wall=84, gb_free=15.6, wall=9417
2023-08-31 22:44:40 | INFO | train_inner | epoch 007:    352 / 1826 loss=2.021, trans_loss=3.355, nll_loss=1.564, w2v_ctc_loss=1.169, task_loss=2.119, contrastive_loss=0, total=4034.29, n_correct=2441.44, ppl=2.96, accuracy=60.517, wps=14503.1, ups=1.19, wpb=12139.1, bsz=466.5, num_updates=11300, lr=0.000133038, gnorm=0.419, clip=0, loss_scale=8, train_wall=83, gb_free=16.9, wall=9500
2023-08-31 22:46:04 | INFO | train_inner | epoch 007:    452 / 1826 loss=2.026, trans_loss=3.351, nll_loss=1.557, w2v_ctc_loss=1.181, task_loss=2.222, contrastive_loss=0, total=3989.92, n_correct=2414.74, ppl=2.94, accuracy=60.521, wps=14170.9, ups=1.18, wpb=12006.9, bsz=444.5, num_updates=11400, lr=0.000132453, gnorm=0.442, clip=0, loss_scale=8, train_wall=84, gb_free=15.2, wall=9585
2023-08-31 22:47:29 | INFO | train_inner | epoch 007:    552 / 1826 loss=2.031, trans_loss=3.344, nll_loss=1.547, w2v_ctc_loss=1.19, task_loss=2.311, contrastive_loss=0, total=3952.57, n_correct=2406.14, ppl=2.92, accuracy=60.875, wps=14001, ups=1.18, wpb=11886.2, bsz=433.2, num_updates=11500, lr=0.000131876, gnorm=0.432, clip=0, loss_scale=8, train_wall=84, gb_free=16.8, wall=9670
2023-08-31 22:48:54 | INFO | train_inner | epoch 007:    652 / 1826 loss=2.017, trans_loss=3.345, nll_loss=1.548, w2v_ctc_loss=1.17, task_loss=2.39, contrastive_loss=0, total=3942.35, n_correct=2397.14, ppl=2.92, accuracy=60.805, wps=13964.5, ups=1.18, wpb=11857.5, bsz=423.7, num_updates=11600, lr=0.000131306, gnorm=0.423, clip=0, loss_scale=8, train_wall=84, gb_free=16.8, wall=9755
2023-08-31 22:50:19 | INFO | train_inner | epoch 007:    752 / 1826 loss=2.011, trans_loss=3.344, nll_loss=1.547, w2v_ctc_loss=1.162, task_loss=2.403, contrastive_loss=0, total=3949.88, n_correct=2410.25, ppl=2.92, accuracy=61.021, wps=14071.4, ups=1.18, wpb=11876.3, bsz=431.9, num_updates=11700, lr=0.000130744, gnorm=0.433, clip=0, loss_scale=8, train_wall=84, gb_free=15.5, wall=9839
2023-08-31 22:51:44 | INFO | train_inner | epoch 007:    852 / 1826 loss=2.025, trans_loss=3.341, nll_loss=1.544, w2v_ctc_loss=1.186, task_loss=2.581, contrastive_loss=0, total=3930.38, n_correct=2397.4, ppl=2.92, accuracy=60.997, wps=13901, ups=1.18, wpb=11820.2, bsz=404.7, num_updates=11800, lr=0.000130189, gnorm=0.442, clip=0, loss_scale=8, train_wall=84, gb_free=11.3, wall=9924
2023-08-31 22:53:09 | INFO | train_inner | epoch 007:    952 / 1826 loss=2.013, trans_loss=3.334, nll_loss=1.535, w2v_ctc_loss=1.173, task_loss=2.291, contrastive_loss=0, total=4048.82, n_correct=2483.9, ppl=2.9, accuracy=61.349, wps=14195.8, ups=1.17, wpb=12177.2, bsz=443.4, num_updates=11900, lr=0.000129641, gnorm=0.438, clip=0, loss_scale=8, train_wall=85, gb_free=15.9, wall=10010
2023-08-31 22:54:34 | INFO | train_inner | epoch 007:   1052 / 1826 loss=2.005, trans_loss=3.326, nll_loss=1.525, w2v_ctc_loss=1.167, task_loss=2.403, contrastive_loss=0, total=3928.57, n_correct=2415.97, ppl=2.88, accuracy=61.497, wps=13902.7, ups=1.18, wpb=11816.1, bsz=424.5, num_updates=12000, lr=0.000129099, gnorm=0.418, clip=0, loss_scale=8, train_wall=84, gb_free=13.8, wall=10095
2023-08-31 22:54:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 22:55:13 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.008 | trans_loss 5.274 | nll_loss 2.591 | w2v_ctc_loss 1.458 | task_loss 13.529 | contrastive_loss 0 | total 3505.91 | n_correct 2272.36 | ppl 6.03 | accuracy 64.815 | uer 20.076 | wer 21.621 | raw_wer 21.621 | bleu 26.38 | wps 1204.5 | wpb 3505.9 | bsz 119.3 | num_updates 12000 | best_bleu 26.38
2023-08-31 22:55:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 12000 updates
2023-08-31 22:55:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_7_12000.pt
2023-08-31 22:55:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_7_12000.pt
2023-08-31 22:55:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_7_12000.pt (epoch 7 @ 12000 updates, score 26.38) (writing took 14.442001885006903 seconds)
2023-08-31 22:56:54 | INFO | train_inner | epoch 007:   1152 / 1826 loss=2.027, trans_loss=3.335, nll_loss=1.537, w2v_ctc_loss=1.197, task_loss=2.619, contrastive_loss=0, total=3932.31, n_correct=2410.7, ppl=2.9, accuracy=61.305, wps=8502.6, ups=0.72, wpb=11834.7, bsz=408.4, num_updates=12100, lr=0.000128565, gnorm=0.452, clip=0, loss_scale=8, train_wall=85, gb_free=15.6, wall=10234
2023-08-31 22:58:19 | INFO | train_inner | epoch 007:   1252 / 1826 loss=2.008, trans_loss=3.332, nll_loss=1.533, w2v_ctc_loss=1.169, task_loss=2.418, contrastive_loss=0, total=3998.13, n_correct=2457.94, ppl=2.89, accuracy=61.477, wps=14112.7, ups=1.17, wpb=12030.8, bsz=433.4, num_updates=12200, lr=0.000128037, gnorm=0.445, clip=0, loss_scale=8, train_wall=85, gb_free=15.9, wall=10319
2023-08-31 22:59:43 | INFO | train_inner | epoch 007:   1352 / 1826 loss=2.009, trans_loss=3.327, nll_loss=1.527, w2v_ctc_loss=1.177, task_loss=2.527, contrastive_loss=0, total=3909.99, n_correct=2407.75, ppl=2.88, accuracy=61.579, wps=14053.3, ups=1.19, wpb=11765, bsz=411.2, num_updates=12300, lr=0.000127515, gnorm=0.432, clip=0, loss_scale=8, train_wall=83, gb_free=15.8, wall=10403
2023-08-31 23:01:09 | INFO | train_inner | epoch 007:   1452 / 1826 loss=2.005, trans_loss=3.33, nll_loss=1.528, w2v_ctc_loss=1.17, task_loss=2.29, contrastive_loss=0, total=3964.82, n_correct=2445.22, ppl=2.88, accuracy=61.673, wps=13840.9, ups=1.16, wpb=11915.6, bsz=435.9, num_updates=12400, lr=0.000127, gnorm=0.419, clip=0, loss_scale=8, train_wall=85, gb_free=17.5, wall=10489
2023-08-31 23:02:33 | INFO | train_inner | epoch 007:   1552 / 1826 loss=2.002, trans_loss=3.327, nll_loss=1.526, w2v_ctc_loss=1.167, task_loss=2.517, contrastive_loss=0, total=3929.01, n_correct=2424.36, ppl=2.88, accuracy=61.704, wps=13958.9, ups=1.18, wpb=11818.4, bsz=413.4, num_updates=12500, lr=0.000126491, gnorm=0.437, clip=0, loss_scale=8, train_wall=84, gb_free=11.7, wall=10574
2023-08-31 23:03:58 | INFO | train_inner | epoch 007:   1652 / 1826 loss=1.983, trans_loss=3.324, nll_loss=1.522, w2v_ctc_loss=1.143, task_loss=2.226, contrastive_loss=0, total=3986.3, n_correct=2464.4, ppl=2.87, accuracy=61.822, wps=14153.1, ups=1.18, wpb=11985.1, bsz=449.1, num_updates=12600, lr=0.000125988, gnorm=0.426, clip=0, loss_scale=8, train_wall=84, gb_free=16, wall=10659
2023-08-31 23:05:24 | INFO | train_inner | epoch 007:   1752 / 1826 loss=2, trans_loss=3.325, nll_loss=1.524, w2v_ctc_loss=1.168, task_loss=2.403, contrastive_loss=0, total=3979.89, n_correct=2461.8, ppl=2.88, accuracy=61.856, wps=13952.2, ups=1.17, wpb=11965.7, bsz=429.8, num_updates=12700, lr=0.000125491, gnorm=0.426, clip=0, loss_scale=8, train_wall=85, gb_free=17.4, wall=10744
2023-08-31 23:06:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 23:07:05 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 3.962 | trans_loss 5.229 | nll_loss 2.532 | w2v_ctc_loss 1.406 | task_loss 13.518 | contrastive_loss 0 | total 3505.91 | n_correct 2298 | ppl 5.79 | accuracy 65.546 | uer 19.429 | wer 21.159 | raw_wer 21.159 | bleu 26.99 | wps 1203.5 | wpb 3505.9 | bsz 119.3 | num_updates 12774 | best_bleu 26.99
2023-08-31 23:07:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 12774 updates
2023-08-31 23:07:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-08-31 23:07:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-08-31 23:07:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt (epoch 7 @ 12774 updates, score 26.99) (writing took 13.2760824910074 seconds)
2023-08-31 23:07:18 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-31 23:07:18 | INFO | train | epoch 007 | loss 2.015 | trans_loss 3.339 | nll_loss 1.541 | w2v_ctc_loss 1.175 | task_loss 2.393 | contrastive_loss 0 | total 3956.79 | n_correct 2419.16 | ppl 2.91 | accuracy 61.139 | wps 13065.2 | ups 1.1 | wpb 11901.3 | bsz 427.3 | num_updates 12774 | lr 0.000125127 | gnorm 0.433 | clip 0 | loss_scale 8 | train_wall 1538 | gb_free 16.5 | wall 10859
2023-08-31 23:07:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 23:07:18 | INFO | fairseq.trainer | begin training epoch 8
2023-08-31 23:07:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 23:07:48 | INFO | train_inner | epoch 008:     26 / 1826 loss=1.997, trans_loss=3.315, nll_loss=1.513, w2v_ctc_loss=1.166, task_loss=2.605, contrastive_loss=0, total=3885.49, n_correct=2407.41, ppl=2.85, accuracy=61.959, wps=8114.5, ups=0.69, wpb=11693.8, bsz=401.5, num_updates=12800, lr=0.000125, gnorm=0.442, clip=0, loss_scale=8, train_wall=84, gb_free=9.1, wall=10888
2023-08-31 23:09:13 | INFO | train_inner | epoch 008:    126 / 1826 loss=1.967, trans_loss=3.296, nll_loss=1.489, w2v_ctc_loss=1.137, task_loss=2.457, contrastive_loss=0, total=3955.57, n_correct=2475.79, ppl=2.81, accuracy=62.59, wps=13996.8, ups=1.18, wpb=11904.6, bsz=420.5, num_updates=12900, lr=0.000124515, gnorm=0.413, clip=0, loss_scale=8, train_wall=84, gb_free=16.9, wall=10974
2023-08-31 23:10:39 | INFO | train_inner | epoch 008:    226 / 1826 loss=1.953, trans_loss=3.29, nll_loss=1.481, w2v_ctc_loss=1.12, task_loss=2.42, contrastive_loss=0, total=3921.96, n_correct=2463.36, ppl=2.79, accuracy=62.809, wps=13776.6, ups=1.17, wpb=11805, bsz=428, num_updates=13000, lr=0.000124035, gnorm=0.41, clip=0, loss_scale=8, train_wall=85, gb_free=15.9, wall=11059
2023-08-31 23:12:03 | INFO | train_inner | epoch 008:    326 / 1826 loss=1.96, trans_loss=3.295, nll_loss=1.486, w2v_ctc_loss=1.127, task_loss=2.56, contrastive_loss=0, total=3887.36, n_correct=2440.03, ppl=2.8, accuracy=62.768, wps=13822.8, ups=1.18, wpb=11693.5, bsz=406.4, num_updates=13100, lr=0.00012356, gnorm=0.432, clip=0, loss_scale=8, train_wall=84, gb_free=11.6, wall=11144
2023-08-31 23:13:29 | INFO | train_inner | epoch 008:    426 / 1826 loss=1.962, trans_loss=3.296, nll_loss=1.486, w2v_ctc_loss=1.126, task_loss=2.529, contrastive_loss=0, total=3929.14, n_correct=2465.65, ppl=2.8, accuracy=62.753, wps=13761.6, ups=1.16, wpb=11818.2, bsz=411.9, num_updates=13200, lr=0.000123091, gnorm=0.441, clip=0, loss_scale=16, train_wall=85, gb_free=15.6, wall=11230
2023-08-31 23:14:55 | INFO | train_inner | epoch 008:    526 / 1826 loss=1.968, trans_loss=3.296, nll_loss=1.488, w2v_ctc_loss=1.141, task_loss=2.422, contrastive_loss=0, total=3997.46, n_correct=2512.1, ppl=2.8, accuracy=62.842, wps=14010.3, ups=1.16, wpb=12027.4, bsz=435.5, num_updates=13300, lr=0.000122628, gnorm=0.42, clip=0, loss_scale=16, train_wall=85, gb_free=15.5, wall=11316
2023-08-31 23:16:20 | INFO | train_inner | epoch 008:    626 / 1826 loss=1.958, trans_loss=3.296, nll_loss=1.488, w2v_ctc_loss=1.128, task_loss=2.177, contrastive_loss=0, total=4026.89, n_correct=2532.02, ppl=2.8, accuracy=62.878, wps=14213.2, ups=1.17, wpb=12112.3, bsz=460.2, num_updates=13400, lr=0.000122169, gnorm=0.428, clip=0, loss_scale=16, train_wall=85, gb_free=16.5, wall=11401
2023-08-31 23:17:44 | INFO | train_inner | epoch 008:    726 / 1826 loss=1.954, trans_loss=3.299, nll_loss=1.49, w2v_ctc_loss=1.123, task_loss=2.394, contrastive_loss=0, total=3935.44, n_correct=2478.42, ppl=2.81, accuracy=62.977, wps=14079.3, ups=1.19, wpb=11831.7, bsz=421.4, num_updates=13500, lr=0.000121716, gnorm=0.421, clip=0, loss_scale=16, train_wall=83, gb_free=15.3, wall=11485
2023-08-31 23:19:10 | INFO | train_inner | epoch 008:    826 / 1826 loss=1.954, trans_loss=3.296, nll_loss=1.484, w2v_ctc_loss=1.119, task_loss=2.368, contrastive_loss=0, total=3996.46, n_correct=2521.23, ppl=2.8, accuracy=63.087, wps=14064.9, ups=1.17, wpb=12007.6, bsz=432.5, num_updates=13600, lr=0.000121268, gnorm=0.403, clip=0, loss_scale=16, train_wall=85, gb_free=16.5, wall=11570
2023-08-31 23:20:34 | INFO | train_inner | epoch 008:    926 / 1826 loss=1.958, trans_loss=3.288, nll_loss=1.476, w2v_ctc_loss=1.131, task_loss=2.513, contrastive_loss=0, total=3885.41, n_correct=2451.86, ppl=2.78, accuracy=63.104, wps=13810.2, ups=1.18, wpb=11686, bsz=406.3, num_updates=13700, lr=0.000120824, gnorm=0.416, clip=0, loss_scale=16, train_wall=84, gb_free=11.4, wall=11655
2023-08-31 23:22:00 | INFO | train_inner | epoch 008:   1026 / 1826 loss=1.963, trans_loss=3.285, nll_loss=1.474, w2v_ctc_loss=1.14, task_loss=2.467, contrastive_loss=0, total=3950.23, n_correct=2494.68, ppl=2.78, accuracy=63.153, wps=13942.8, ups=1.17, wpb=11884.1, bsz=413.4, num_updates=13800, lr=0.000120386, gnorm=0.416, clip=0, loss_scale=16, train_wall=85, gb_free=15.7, wall=11740
2023-08-31 23:23:25 | INFO | train_inner | epoch 008:   1126 / 1826 loss=1.939, trans_loss=3.283, nll_loss=1.47, w2v_ctc_loss=1.108, task_loss=2.291, contrastive_loss=0, total=3967.4, n_correct=2519.39, ppl=2.77, accuracy=63.502, wps=13960, ups=1.17, wpb=11931.2, bsz=436.8, num_updates=13900, lr=0.000119952, gnorm=0.408, clip=0, loss_scale=16, train_wall=85, gb_free=15.1, wall=11826
2023-08-31 23:24:50 | INFO | train_inner | epoch 008:   1226 / 1826 loss=1.931, trans_loss=3.282, nll_loss=1.469, w2v_ctc_loss=1.099, task_loss=2.276, contrastive_loss=0, total=4000.75, n_correct=2539.16, ppl=2.77, accuracy=63.467, wps=14098.5, ups=1.17, wpb=12030.1, bsz=442.5, num_updates=14000, lr=0.000119523, gnorm=0.405, clip=0, loss_scale=16, train_wall=85, gb_free=16.6, wall=11911
2023-08-31 23:24:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([4.1723e-06], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 23:25:29 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 3.928 | trans_loss 5.189 | nll_loss 2.486 | w2v_ctc_loss 1.384 | task_loss 13.468 | contrastive_loss 0 | total 3505.91 | n_correct 2316.91 | ppl 5.6 | accuracy 66.086 | uer 19.434 | wer 21.073 | raw_wer 21.073 | bleu 27.84 | wps 1201.4 | wpb 3505.9 | bsz 119.3 | num_updates 14000 | best_bleu 27.84
2023-08-31 23:25:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 14000 updates
2023-08-31 23:25:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_8_14000.pt
2023-08-31 23:25:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_8_14000.pt
2023-08-31 23:25:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_8_14000.pt (epoch 8 @ 14000 updates, score 27.84) (writing took 12.686872898993897 seconds)
2023-08-31 23:27:07 | INFO | train_inner | epoch 008:   1326 / 1826 loss=1.95, trans_loss=3.291, nll_loss=1.481, w2v_ctc_loss=1.12, task_loss=2.493, contrastive_loss=0, total=3927.23, n_correct=2484.7, ppl=2.79, accuracy=63.269, wps=8664.7, ups=0.73, wpb=11813, bsz=411.5, num_updates=14100, lr=0.000119098, gnorm=0.425, clip=0, loss_scale=16, train_wall=83, gb_free=16.1, wall=12047
2023-08-31 23:28:31 | INFO | train_inner | epoch 008:   1426 / 1826 loss=1.92, trans_loss=3.281, nll_loss=1.468, w2v_ctc_loss=1.085, task_loss=2.217, contrastive_loss=0, total=3987.61, n_correct=2530.41, ppl=2.77, accuracy=63.457, wps=14167.6, ups=1.18, wpb=11989.8, bsz=441.2, num_updates=14200, lr=0.000118678, gnorm=0.418, clip=0, loss_scale=16, train_wall=84, gb_free=16.2, wall=12132
2023-08-31 23:29:55 | INFO | train_inner | epoch 008:   1526 / 1826 loss=1.939, trans_loss=3.28, nll_loss=1.469, w2v_ctc_loss=1.112, task_loss=2.213, contrastive_loss=0, total=3997.99, n_correct=2540.24, ppl=2.77, accuracy=63.538, wps=14292.4, ups=1.19, wpb=12027.4, bsz=444.4, num_updates=14300, lr=0.000118262, gnorm=0.424, clip=0, loss_scale=16, train_wall=83, gb_free=16, wall=12216
2023-08-31 23:31:20 | INFO | train_inner | epoch 008:   1626 / 1826 loss=1.951, trans_loss=3.284, nll_loss=1.474, w2v_ctc_loss=1.126, task_loss=2.438, contrastive_loss=0, total=3947.23, n_correct=2498.44, ppl=2.78, accuracy=63.296, wps=14094.3, ups=1.19, wpb=11878.9, bsz=415.7, num_updates=14400, lr=0.000117851, gnorm=0.423, clip=0, loss_scale=16, train_wall=84, gb_free=17, wall=12300
2023-08-31 23:32:45 | INFO | train_inner | epoch 008:   1726 / 1826 loss=1.954, trans_loss=3.293, nll_loss=1.483, w2v_ctc_loss=1.124, task_loss=2.332, contrastive_loss=0, total=3957.64, n_correct=2494.81, ppl=2.8, accuracy=63.038, wps=14038.5, ups=1.18, wpb=11901.8, bsz=433.4, num_updates=14500, lr=0.000117444, gnorm=0.429, clip=0, loss_scale=16, train_wall=84, gb_free=15.1, wall=12385
2023-08-31 23:34:08 | INFO | train_inner | epoch 008:   1826 / 1826 loss=1.948, trans_loss=3.285, nll_loss=1.473, w2v_ctc_loss=1.123, task_loss=2.302, contrastive_loss=0, total=3953.77, n_correct=2503.51, ppl=2.78, accuracy=63.32, wps=14167.5, ups=1.19, wpb=11888.9, bsz=433.6, num_updates=14600, lr=0.000117041, gnorm=0.443, clip=0, loss_scale=16, train_wall=83, gb_free=16.6, wall=12469
2023-08-31 23:34:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 23:34:47 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 3.917 | trans_loss 5.169 | nll_loss 2.456 | w2v_ctc_loss 1.394 | task_loss 13.615 | contrastive_loss 0 | total 3505.91 | n_correct 2328.27 | ppl 5.49 | accuracy 66.41 | uer 18.777 | wer 20.592 | raw_wer 20.592 | bleu 28.4 | wps 1206.9 | wpb 3505.9 | bsz 119.3 | num_updates 14600 | best_bleu 28.4
2023-08-31 23:34:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 14600 updates
2023-08-31 23:34:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-08-31 23:34:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-08-31 23:35:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt (epoch 8 @ 14600 updates, score 28.4) (writing took 13.356230810008128 seconds)
2023-08-31 23:35:01 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-31 23:35:01 | INFO | train | epoch 008 | loss 1.952 | trans_loss 3.29 | nll_loss 1.48 | w2v_ctc_loss 1.122 | task_loss 2.381 | contrastive_loss 0 | total 3956.37 | n_correct 2496.03 | ppl 2.79 | accuracy 63.089 | wps 13069.1 | ups 1.1 | wpb 11900.1 | bsz 427.2 | num_updates 14600 | lr 0.000117041 | gnorm 0.421 | clip 0 | loss_scale 16 | train_wall 1538 | gb_free 16.6 | wall 12521
2023-08-31 23:35:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 23:35:01 | INFO | fairseq.trainer | begin training epoch 9
2023-08-31 23:35:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 23:36:32 | INFO | train_inner | epoch 009:    100 / 1826 loss=1.91, trans_loss=3.261, nll_loss=1.441, w2v_ctc_loss=1.078, task_loss=2.42, contrastive_loss=0, total=3922.53, n_correct=2517.55, ppl=2.72, accuracy=64.182, wps=8192.2, ups=0.69, wpb=11792.7, bsz=419.4, num_updates=14700, lr=0.000116642, gnorm=0.434, clip=0, loss_scale=16, train_wall=83, gb_free=17, wall=12613
2023-08-31 23:37:56 | INFO | train_inner | epoch 009:    200 / 1826 loss=1.905, trans_loss=3.26, nll_loss=1.438, w2v_ctc_loss=1.073, task_loss=2.321, contrastive_loss=0, total=3983.09, n_correct=2561.15, ppl=2.71, accuracy=64.301, wps=14254.2, ups=1.19, wpb=11962.5, bsz=426.6, num_updates=14800, lr=0.000116248, gnorm=0.409, clip=0, loss_scale=16, train_wall=83, gb_free=15.6, wall=12697
2023-08-31 23:39:22 | INFO | train_inner | epoch 009:    300 / 1826 loss=1.907, trans_loss=3.261, nll_loss=1.443, w2v_ctc_loss=1.08, task_loss=2.307, contrastive_loss=0, total=4021.21, n_correct=2579.21, ppl=2.72, accuracy=64.14, wps=14133.1, ups=1.17, wpb=12092.6, bsz=445.2, num_updates=14900, lr=0.000115857, gnorm=0.404, clip=0, loss_scale=16, train_wall=85, gb_free=15.9, wall=12782
2023-08-31 23:40:47 | INFO | train_inner | epoch 009:    400 / 1826 loss=1.904, trans_loss=3.256, nll_loss=1.438, w2v_ctc_loss=1.077, task_loss=2.264, contrastive_loss=0, total=3972.29, n_correct=2556.95, ppl=2.71, accuracy=64.37, wps=14097, ups=1.18, wpb=11949.2, bsz=436.3, num_updates=15000, lr=0.00011547, gnorm=0.412, clip=0, loss_scale=16, train_wall=84, gb_free=17.3, wall=12867
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:0')
2023-08-31 23:41:48 | INFO | train_inner | epoch 009:    500 / 1826 loss=2.046, trans_loss=4.89, nll_loss=2.174, w2v_ctc_loss=0.831, task_loss=3.636, contrastive_loss=0, total=3930.64, n_correct=2514.72, ppl=4.51, accuracy=63.977, wps=12794, ups=1.62, wpb=7902.3, bsz=275.5, num_updates=15100, lr=0.000115087, gnorm=0.569, clip=0, loss_scale=16, train_wall=61, gb_free=17, wall=12929
2023-08-31 23:42:50 | INFO | train_inner | epoch 009:    600 / 1826 loss=2.036, trans_loss=4.911, nll_loss=2.18, w2v_ctc_loss=0.805, task_loss=3.377, contrastive_loss=0, total=3996.71, n_correct=2558.03, ppl=4.53, accuracy=64.003, wps=12997.3, ups=1.63, wpb=7993.4, bsz=293.4, num_updates=15200, lr=0.000114708, gnorm=0.551, clip=0, loss_scale=32, train_wall=61, gb_free=16.2, wall=12990
2023-08-31 23:43:52 | INFO | train_inner | epoch 009:    700 / 1826 loss=2.043, trans_loss=4.907, nll_loss=2.175, w2v_ctc_loss=0.826, task_loss=3.604, contrastive_loss=0, total=3922.45, n_correct=2514.49, ppl=4.52, accuracy=64.105, wps=12688.7, ups=1.62, wpb=7844.9, bsz=279.5, num_updates=15300, lr=0.000114332, gnorm=0.567, clip=0, loss_scale=32, train_wall=61, gb_free=15.7, wall=13052
2023-08-31 23:44:53 | INFO | train_inner | epoch 009:    800 / 1826 loss=2.044, trans_loss=4.916, nll_loss=2.186, w2v_ctc_loss=0.822, task_loss=3.631, contrastive_loss=0, total=3927.21, n_correct=2513.74, ppl=4.55, accuracy=64.008, wps=12793.6, ups=1.63, wpb=7854.4, bsz=282.8, num_updates=15400, lr=0.000113961, gnorm=0.563, clip=0, loss_scale=32, train_wall=61, gb_free=10.7, wall=13114
2023-08-31 23:45:55 | INFO | train_inner | epoch 009:    900 / 1826 loss=2.042, trans_loss=4.911, nll_loss=2.179, w2v_ctc_loss=0.822, task_loss=3.628, contrastive_loss=0, total=3925.04, n_correct=2514.32, ppl=4.53, accuracy=64.058, wps=12782, ups=1.63, wpb=7850.1, bsz=284.6, num_updates=15500, lr=0.000113592, gnorm=0.552, clip=0, loss_scale=32, train_wall=61, gb_free=15.3, wall=13175
2023-08-31 23:46:57 | INFO | train_inner | epoch 009:   1000 / 1826 loss=2.046, trans_loss=4.908, nll_loss=2.176, w2v_ctc_loss=0.836, task_loss=3.454, contrastive_loss=0, total=3978.13, n_correct=2546.08, ppl=4.52, accuracy=64.002, wps=12762.4, ups=1.6, wpb=7956.3, bsz=293.5, num_updates=15600, lr=0.000113228, gnorm=0.553, clip=0, loss_scale=32, train_wall=62, gb_free=16.5, wall=13237
2023-08-31 23:47:58 | INFO | train_inner | epoch 009:   1100 / 1826 loss=2.039, trans_loss=4.903, nll_loss=2.17, w2v_ctc_loss=0.823, task_loss=3.653, contrastive_loss=0, total=3936.56, n_correct=2527.38, ppl=4.5, accuracy=64.203, wps=12868.4, ups=1.63, wpb=7873.1, bsz=282.6, num_updates=15700, lr=0.000112867, gnorm=0.553, clip=0, loss_scale=32, train_wall=60, gb_free=10.9, wall=13299
2023-08-31 23:49:00 | INFO | train_inner | epoch 009:   1200 / 1826 loss=2.039, trans_loss=4.898, nll_loss=2.163, w2v_ctc_loss=0.829, task_loss=3.488, contrastive_loss=0, total=4012.94, n_correct=2579.83, ppl=4.48, accuracy=64.288, wps=13016.4, ups=1.62, wpb=8025.9, bsz=288.5, num_updates=15800, lr=0.000112509, gnorm=0.543, clip=0, loss_scale=32, train_wall=61, gb_free=16.4, wall=13360
2023-08-31 23:50:01 | INFO | train_inner | epoch 009:   1300 / 1826 loss=2.048, trans_loss=4.911, nll_loss=2.18, w2v_ctc_loss=0.836, task_loss=3.801, contrastive_loss=0, total=3903.69, n_correct=2501.48, ppl=4.53, accuracy=64.08, wps=12689.9, ups=1.63, wpb=7807.4, bsz=270.3, num_updates=15900, lr=0.000112154, gnorm=0.559, clip=0, loss_scale=32, train_wall=61, gb_free=14.1, wall=13422
2023-08-31 23:51:03 | INFO | train_inner | epoch 009:   1400 / 1826 loss=2.033, trans_loss=4.906, nll_loss=2.173, w2v_ctc_loss=0.814, task_loss=3.373, contrastive_loss=0, total=3983.29, n_correct=2560.96, ppl=4.51, accuracy=64.293, wps=12880.3, ups=1.62, wpb=7966.6, bsz=293.5, num_updates=16000, lr=0.000111803, gnorm=0.545, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=13484
2023-08-31 23:51:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:2')
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 23:51:42 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 3.893 | trans_loss 5.134 | nll_loss 2.415 | w2v_ctc_loss 1.391 | task_loss 13.537 | contrastive_loss 0 | total 3505.91 | n_correct 2350.91 | ppl 5.33 | accuracy 67.056 | uer 18.914 | wer 20.618 | raw_wer 20.618 | bleu 28.87 | wps 1192.6 | wpb 3505.9 | bsz 119.3 | num_updates 16000 | best_bleu 28.87
2023-08-31 23:51:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 16000 updates
2023-08-31 23:51:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_9_16000.pt
2023-08-31 23:51:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_9_16000.pt
2023-08-31 23:51:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_9_16000.pt (epoch 9 @ 16000 updates, score 28.87) (writing took 12.23607260499557 seconds)
2023-08-31 23:52:56 | INFO | train_inner | epoch 009:   1500 / 1826 loss=2.039, trans_loss=4.9, nll_loss=2.165, w2v_ctc_loss=0.833, task_loss=3.646, contrastive_loss=0, total=3939.43, n_correct=2534.93, ppl=4.49, accuracy=64.348, wps=6961.4, ups=0.88, wpb=7878.9, bsz=281.4, num_updates=16100, lr=0.000111456, gnorm=0.563, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=13597
2023-08-31 23:53:57 | INFO | train_inner | epoch 009:   1600 / 1826 loss=2.027, trans_loss=4.892, nll_loss=2.155, w2v_ctc_loss=0.815, task_loss=3.287, contrastive_loss=0, total=4013.71, n_correct=2589.07, ppl=4.45, accuracy=64.506, wps=13155.4, ups=1.64, wpb=8027.4, bsz=304.7, num_updates=16200, lr=0.000111111, gnorm=0.556, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=13658
2023-08-31 23:54:58 | INFO | train_inner | epoch 009:   1700 / 1826 loss=2.039, trans_loss=4.9, nll_loss=2.165, w2v_ctc_loss=0.831, task_loss=3.75, contrastive_loss=0, total=3918.49, n_correct=2520.01, ppl=4.49, accuracy=64.311, wps=12826.1, ups=1.64, wpb=7837, bsz=273.5, num_updates=16300, lr=0.00011077, gnorm=0.556, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=13719
2023-08-31 23:56:00 | INFO | train_inner | epoch 009:   1800 / 1826 loss=2.045, trans_loss=4.906, nll_loss=2.173, w2v_ctc_loss=0.839, task_loss=3.777, contrastive_loss=0, total=3940.79, n_correct=2533.17, ppl=4.51, accuracy=64.281, wps=12880, ups=1.63, wpb=7881.6, bsz=271.3, num_updates=16400, lr=0.000110432, gnorm=0.563, clip=0, loss_scale=32, train_wall=60, gb_free=17.6, wall=13780
2023-08-31 23:56:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 23:56:54 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 3.895 | trans_loss 5.12 | nll_loss 2.395 | w2v_ctc_loss 1.429 | task_loss 13.52 | contrastive_loss 0 | total 3505.91 | n_correct 2359.64 | ppl 5.26 | accuracy 67.305 | uer 19.504 | wer 21.279 | raw_wer 21.279 | bleu 29.28 | wps 1205.4 | wpb 3505.9 | bsz 119.3 | num_updates 16426 | best_bleu 29.28
2023-08-31 23:56:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 16426 updates
2023-08-31 23:56:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-08-31 23:57:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-08-31 23:57:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt (epoch 9 @ 16426 updates, score 29.28) (writing took 12.78457451700524 seconds)
2023-08-31 23:57:07 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-31 23:57:07 | INFO | train | epoch 009 | loss 2.001 | trans_loss 4.414 | nll_loss 1.954 | w2v_ctc_loss 0.9 | task_loss 3.198 | contrastive_loss 0 | total 3956.37 | n_correct 2539.91 | ppl 3.87 | accuracy 64.198 | wps 12102.4 | ups 1.38 | wpb 8791.1 | bsz 316.4 | num_updates 16426 | lr 0.000110344 | gnorm 0.526 | clip 0 | loss_scale 32 | train_wall 1202 | gb_free 17.5 | wall 13848
2023-08-31 23:57:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 23:57:08 | INFO | fairseq.trainer | begin training epoch 10
2023-08-31 23:57:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 23:58:01 | INFO | train_inner | epoch 010:     74 / 1826 loss=2.024, trans_loss=4.88, nll_loss=2.14, w2v_ctc_loss=0.816, task_loss=3.577, contrastive_loss=0, total=3937.23, n_correct=2550.45, ppl=4.41, accuracy=64.778, wps=6487.3, ups=0.82, wpb=7874.5, bsz=284.1, num_updates=16500, lr=0.000110096, gnorm=0.567, clip=0, loss_scale=32, train_wall=61, gb_free=11.1, wall=13902
2023-08-31 23:59:03 | INFO | train_inner | epoch 010:    174 / 1826 loss=2.024, trans_loss=4.88, nll_loss=2.139, w2v_ctc_loss=0.813, task_loss=3.654, contrastive_loss=0, total=3947.54, n_correct=2557.86, ppl=4.41, accuracy=64.796, wps=12840.1, ups=1.63, wpb=7895.1, bsz=278.6, num_updates=16600, lr=0.000109764, gnorm=0.577, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=13963
2023-09-01 00:00:03 | INFO | train_inner | epoch 010:    274 / 1826 loss=2.007, trans_loss=4.859, nll_loss=2.113, w2v_ctc_loss=0.794, task_loss=3.515, contrastive_loss=0, total=3941.33, n_correct=2574.15, ppl=4.33, accuracy=65.312, wps=12941.7, ups=1.64, wpb=7882.7, bsz=283, num_updates=16700, lr=0.000109435, gnorm=0.553, clip=0, loss_scale=32, train_wall=60, gb_free=15.8, wall=14024
2023-09-01 00:00:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-01 00:01:06 | INFO | train_inner | epoch 010:    375 / 1826 loss=2.02, trans_loss=4.883, nll_loss=2.144, w2v_ctc_loss=0.805, task_loss=3.322, contrastive_loss=0, total=3987.1, n_correct=2580.18, ppl=4.42, accuracy=64.713, wps=12852.1, ups=1.61, wpb=7974.2, bsz=302.3, num_updates=16800, lr=0.000109109, gnorm=0.57, clip=0, loss_scale=16, train_wall=61, gb_free=16.6, wall=14086
2023-09-01 00:02:07 | INFO | train_inner | epoch 010:    475 / 1826 loss=2.019, trans_loss=4.874, nll_loss=2.133, w2v_ctc_loss=0.816, task_loss=3.454, contrastive_loss=0, total=3978.12, n_correct=2585.38, ppl=4.38, accuracy=64.99, wps=12863.9, ups=1.62, wpb=7956.2, bsz=289.2, num_updates=16900, lr=0.000108786, gnorm=0.564, clip=0, loss_scale=16, train_wall=61, gb_free=17.3, wall=14148
2023-09-01 00:03:09 | INFO | train_inner | epoch 010:    575 / 1826 loss=2.011, trans_loss=4.868, nll_loss=2.125, w2v_ctc_loss=0.803, task_loss=3.409, contrastive_loss=0, total=3964.3, n_correct=2581.78, ppl=4.36, accuracy=65.126, wps=12954.4, ups=1.63, wpb=7928.6, bsz=291.7, num_updates=17000, lr=0.000108465, gnorm=0.547, clip=0, loss_scale=16, train_wall=61, gb_free=17.4, wall=14209
2023-09-01 00:04:10 | INFO | train_inner | epoch 010:    675 / 1826 loss=2.012, trans_loss=4.869, nll_loss=2.126, w2v_ctc_loss=0.795, task_loss=3.571, contrastive_loss=0, total=3916.9, n_correct=2548.7, ppl=4.37, accuracy=65.069, wps=12719.3, ups=1.62, wpb=7833.8, bsz=282.3, num_updates=17100, lr=0.000108148, gnorm=0.545, clip=0, loss_scale=16, train_wall=61, gb_free=15.3, wall=14271
2023-09-01 00:05:11 | INFO | train_inner | epoch 010:    775 / 1826 loss=2.014, trans_loss=4.866, nll_loss=2.123, w2v_ctc_loss=0.808, task_loss=3.528, contrastive_loss=0, total=3952.03, n_correct=2573.53, ppl=4.36, accuracy=65.119, wps=12897.8, ups=1.63, wpb=7904.1, bsz=283.6, num_updates=17200, lr=0.000107833, gnorm=0.538, clip=0, loss_scale=16, train_wall=60, gb_free=16.3, wall=14332
2023-09-01 00:06:13 | INFO | train_inner | epoch 010:    875 / 1826 loss=2.02, trans_loss=4.871, nll_loss=2.129, w2v_ctc_loss=0.813, task_loss=3.829, contrastive_loss=0, total=3950.06, n_correct=2568.07, ppl=4.37, accuracy=65.013, wps=12794.4, ups=1.62, wpb=7900.1, bsz=273.7, num_updates=17300, lr=0.000107521, gnorm=0.55, clip=0, loss_scale=16, train_wall=61, gb_free=15.7, wall=14394
2023-09-01 00:07:14 | INFO | train_inner | epoch 010:    975 / 1826 loss=2.018, trans_loss=4.876, nll_loss=2.135, w2v_ctc_loss=0.81, task_loss=3.347, contrastive_loss=0, total=4054.65, n_correct=2632.54, ppl=4.39, accuracy=64.926, wps=13269.8, ups=1.64, wpb=8109.3, bsz=300.1, num_updates=17400, lr=0.000107211, gnorm=0.543, clip=0, loss_scale=16, train_wall=61, gb_free=16.4, wall=14455
2023-09-01 00:08:16 | INFO | train_inner | epoch 010:   1075 / 1826 loss=2.025, trans_loss=4.885, nll_loss=2.147, w2v_ctc_loss=0.82, task_loss=3.656, contrastive_loss=0, total=3915.5, n_correct=2538.03, ppl=4.43, accuracy=64.82, wps=12726.9, ups=1.63, wpb=7831, bsz=277.5, num_updates=17500, lr=0.000106904, gnorm=0.55, clip=0, loss_scale=16, train_wall=61, gb_free=10, wall=14516
2023-09-01 00:09:17 | INFO | train_inner | epoch 010:   1175 / 1826 loss=2.01, trans_loss=4.859, nll_loss=2.114, w2v_ctc_loss=0.809, task_loss=3.597, contrastive_loss=0, total=3940.51, n_correct=2575.75, ppl=4.33, accuracy=65.366, wps=12873.5, ups=1.63, wpb=7881, bsz=282, num_updates=17600, lr=0.0001066, gnorm=0.552, clip=0, loss_scale=16, train_wall=61, gb_free=14.4, wall=14578
2023-09-01 00:10:19 | INFO | train_inner | epoch 010:   1275 / 1826 loss=2.017, trans_loss=4.872, nll_loss=2.131, w2v_ctc_loss=0.816, task_loss=3.397, contrastive_loss=0, total=4017.71, n_correct=2614.67, ppl=4.38, accuracy=65.079, wps=13059.2, ups=1.63, wpb=8035.4, bsz=299.2, num_updates=17700, lr=0.000106299, gnorm=0.562, clip=0, loss_scale=16, train_wall=61, gb_free=11.8, wall=14639
2023-09-01 00:11:20 | INFO | train_inner | epoch 010:   1375 / 1826 loss=2.022, trans_loss=4.87, nll_loss=2.128, w2v_ctc_loss=0.82, task_loss=3.845, contrastive_loss=0, total=3918.39, n_correct=2549.81, ppl=4.37, accuracy=65.073, wps=12790.5, ups=1.63, wpb=7836.8, bsz=266, num_updates=17800, lr=0.000106, gnorm=0.55, clip=0, loss_scale=16, train_wall=61, gb_free=14.2, wall=14700
2023-09-01 00:12:21 | INFO | train_inner | epoch 010:   1475 / 1826 loss=2.007, trans_loss=4.854, nll_loss=2.108, w2v_ctc_loss=0.798, task_loss=3.724, contrastive_loss=0, total=3908.82, n_correct=2556.96, ppl=4.31, accuracy=65.415, wps=12790.6, ups=1.64, wpb=7817.6, bsz=271.1, num_updates=17900, lr=0.000105703, gnorm=0.559, clip=0, loss_scale=16, train_wall=60, gb_free=15.7, wall=14762
2023-09-01 00:13:22 | INFO | train_inner | epoch 010:   1575 / 1826 loss=2.003, trans_loss=4.849, nll_loss=2.101, w2v_ctc_loss=0.8, task_loss=3.534, contrastive_loss=0, total=3958.9, n_correct=2596.57, ppl=4.29, accuracy=65.588, wps=12987.1, ups=1.64, wpb=7917.8, bsz=285.8, num_updates=18000, lr=0.000105409, gnorm=0.561, clip=0, loss_scale=16, train_wall=60, gb_free=15, wall=14823
2023-09-01 00:13:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 00:14:01 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 3.889 | trans_loss 5.103 | nll_loss 2.376 | w2v_ctc_loss 1.447 | task_loss 13.521 | contrastive_loss 0 | total 3505.91 | n_correct 2362.82 | ppl 5.19 | accuracy 67.395 | uer 19.292 | wer 21.148 | raw_wer 21.148 | bleu 29.31 | wps 1189 | wpb 3505.9 | bsz 119.3 | num_updates 18000 | best_bleu 29.31
2023-09-01 00:14:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 18000 updates
2023-09-01 00:14:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_10_18000.pt
2023-09-01 00:14:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_10_18000.pt
2023-09-01 00:14:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_10_18000.pt (epoch 10 @ 18000 updates, score 29.31) (writing took 14.564662099990528 seconds)
2023-09-01 00:15:17 | INFO | train_inner | epoch 010:   1675 / 1826 loss=2.015, trans_loss=4.866, nll_loss=2.123, w2v_ctc_loss=0.813, task_loss=3.667, contrastive_loss=0, total=3939.68, n_correct=2570.8, ppl=4.36, accuracy=65.254, wps=6827.8, ups=0.87, wpb=7879.4, bsz=278.2, num_updates=18100, lr=0.000105118, gnorm=0.568, clip=0, loss_scale=16, train_wall=61, gb_free=14.4, wall=14938
2023-09-01 00:16:19 | INFO | train_inner | epoch 010:   1775 / 1826 loss=2.012, trans_loss=4.872, nll_loss=2.132, w2v_ctc_loss=0.801, task_loss=3.33, contrastive_loss=0, total=3997.55, n_correct=2598.63, ppl=4.38, accuracy=65.006, wps=12994.2, ups=1.63, wpb=7995.1, bsz=302.4, num_updates=18200, lr=0.000104828, gnorm=0.584, clip=0, loss_scale=16, train_wall=61, gb_free=17, wall=14999
2023-09-01 00:16:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 00:17:29 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 3.868 | trans_loss 5.099 | nll_loss 2.372 | w2v_ctc_loss 1.388 | task_loss 13.525 | contrastive_loss 0 | total 3505.91 | n_correct 2366.55 | ppl 5.18 | accuracy 67.502 | uer 19.021 | wer 20.9 | raw_wer 20.9 | bleu 29.52 | wps 1206.4 | wpb 3505.9 | bsz 119.3 | num_updates 18251 | best_bleu 29.52
2023-09-01 00:17:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 18251 updates
2023-09-01 00:17:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-09-01 00:17:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-09-01 00:17:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt (epoch 10 @ 18251 updates, score 29.52) (writing took 11.840440585001488 seconds)
2023-09-01 00:17:41 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-09-01 00:17:41 | INFO | train | epoch 010 | loss 2.015 | trans_loss 4.869 | nll_loss 2.127 | w2v_ctc_loss 0.808 | task_loss 3.553 | contrastive_loss 0 | total 3956.09 | n_correct 2574.85 | ppl 4.37 | accuracy 65.086 | wps 11703.7 | ups 1.48 | wpb 7912.2 | bsz 284.8 | num_updates 18251 | lr 0.000104682 | gnorm 0.558 | clip 0 | loss_scale 16 | train_wall 1109 | gb_free 17 | wall 15082
2023-09-01 00:17:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-09-01 00:17:41 | INFO | fairseq.trainer | begin training epoch 11
2023-09-01 00:17:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 00:18:19 | INFO | train_inner | epoch 011:     49 / 1826 loss=2.007, trans_loss=4.857, nll_loss=2.112, w2v_ctc_loss=0.804, task_loss=3.625, contrastive_loss=0, total=3902.57, n_correct=2550.54, ppl=4.32, accuracy=65.355, wps=6519.8, ups=0.84, wpb=7805.1, bsz=280.6, num_updates=18300, lr=0.000104542, gnorm=0.559, clip=0, loss_scale=16, train_wall=60, gb_free=14.8, wall=15119
2023-09-01 00:19:21 | INFO | train_inner | epoch 011:    149 / 1826 loss=1.996, trans_loss=4.843, nll_loss=2.093, w2v_ctc_loss=0.789, task_loss=3.601, contrastive_loss=0, total=3987.55, n_correct=2618.5, ppl=4.27, accuracy=65.667, wps=12866.9, ups=1.61, wpb=7975.1, bsz=288.5, num_updates=18400, lr=0.000104257, gnorm=0.554, clip=0, loss_scale=16, train_wall=61, gb_free=15.4, wall=15181
2023-09-01 00:20:21 | INFO | train_inner | epoch 011:    249 / 1826 loss=2, trans_loss=4.844, nll_loss=2.095, w2v_ctc_loss=0.796, task_loss=3.652, contrastive_loss=0, total=3914.16, n_correct=2567, ppl=4.27, accuracy=65.582, wps=12870.9, ups=1.64, wpb=7828.3, bsz=278.6, num_updates=18500, lr=0.000103975, gnorm=0.56, clip=0, loss_scale=16, train_wall=60, gb_free=17.4, wall=15242
2023-09-01 00:21:23 | INFO | train_inner | epoch 011:    349 / 1826 loss=1.995, trans_loss=4.838, nll_loss=2.087, w2v_ctc_loss=0.791, task_loss=3.642, contrastive_loss=0, total=3936.35, n_correct=2588.14, ppl=4.25, accuracy=65.75, wps=12865.1, ups=1.63, wpb=7872.7, bsz=276.7, num_updates=18600, lr=0.000103695, gnorm=0.547, clip=0, loss_scale=16, train_wall=61, gb_free=16.2, wall=15303
2023-09-01 00:22:25 | INFO | train_inner | epoch 011:    449 / 1826 loss=1.998, trans_loss=4.838, nll_loss=2.087, w2v_ctc_loss=0.801, task_loss=3.676, contrastive_loss=0, total=3953.38, n_correct=2599.44, ppl=4.25, accuracy=65.752, wps=12784.3, ups=1.62, wpb=7906.8, bsz=281, num_updates=18700, lr=0.000103418, gnorm=0.545, clip=0, loss_scale=16, train_wall=61, gb_free=16.3, wall=15365
2023-09-01 00:23:26 | INFO | train_inner | epoch 011:    549 / 1826 loss=1.999, trans_loss=4.84, nll_loss=2.09, w2v_ctc_loss=0.798, task_loss=3.74, contrastive_loss=0, total=3939.99, n_correct=2594.01, ppl=4.26, accuracy=65.838, wps=12874.4, ups=1.63, wpb=7880, bsz=276.4, num_updates=18800, lr=0.000103142, gnorm=0.613, clip=0, loss_scale=16, train_wall=60, gb_free=15.4, wall=15426
2023-09-01 00:24:27 | INFO | train_inner | epoch 011:    649 / 1826 loss=1.997, trans_loss=4.839, nll_loss=2.089, w2v_ctc_loss=0.799, task_loss=3.783, contrastive_loss=0, total=3914.2, n_correct=2574.43, ppl=4.26, accuracy=65.772, wps=12810.3, ups=1.64, wpb=7828.4, bsz=276.9, num_updates=18900, lr=0.000102869, gnorm=0.55, clip=0, loss_scale=32, train_wall=60, gb_free=15.2, wall=15487
2023-09-01 00:24:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-01 00:25:29 | INFO | train_inner | epoch 011:    750 / 1826 loss=1.996, trans_loss=4.846, nll_loss=2.097, w2v_ctc_loss=0.793, task_loss=3.608, contrastive_loss=0, total=3938.14, n_correct=2588.22, ppl=4.28, accuracy=65.722, wps=12753.3, ups=1.62, wpb=7876.3, bsz=281.7, num_updates=19000, lr=0.000102598, gnorm=0.555, clip=0, loss_scale=16, train_wall=61, gb_free=10.9, wall=15549
2023-09-01 00:26:30 | INFO | train_inner | epoch 011:    850 / 1826 loss=1.997, trans_loss=4.845, nll_loss=2.097, w2v_ctc_loss=0.789, task_loss=3.718, contrastive_loss=0, total=3920.77, n_correct=2574.95, ppl=4.28, accuracy=65.675, wps=12789.6, ups=1.63, wpb=7841.5, bsz=278.5, num_updates=19100, lr=0.000102329, gnorm=0.558, clip=0, loss_scale=16, train_wall=61, gb_free=16.7, wall=15610
2023-09-01 00:27:32 | INFO | train_inner | epoch 011:    950 / 1826 loss=1.999, trans_loss=4.846, nll_loss=2.097, w2v_ctc_loss=0.795, task_loss=3.66, contrastive_loss=0, total=4000.2, n_correct=2625.11, ppl=4.28, accuracy=65.624, wps=12829.7, ups=1.6, wpb=8000.4, bsz=289.2, num_updates=19200, lr=0.000102062, gnorm=0.538, clip=0, loss_scale=16, train_wall=62, gb_free=15.8, wall=15673
2023-09-01 00:28:33 | INFO | train_inner | epoch 011:   1050 / 1826 loss=1.999, trans_loss=4.838, nll_loss=2.087, w2v_ctc_loss=0.805, task_loss=3.788, contrastive_loss=0, total=3962.25, n_correct=2608.38, ppl=4.25, accuracy=65.831, wps=12993.5, ups=1.64, wpb=7924.5, bsz=277.4, num_updates=19300, lr=0.000101797, gnorm=0.546, clip=0, loss_scale=16, train_wall=60, gb_free=16.2, wall=15734
2023-09-01 00:29:34 | INFO | train_inner | epoch 011:   1150 / 1826 loss=2.002, trans_loss=4.845, nll_loss=2.097, w2v_ctc_loss=0.804, task_loss=3.732, contrastive_loss=0, total=3942.9, n_correct=2588.51, ppl=4.28, accuracy=65.65, wps=13004.6, ups=1.65, wpb=7885.8, bsz=275.9, num_updates=19400, lr=0.000101535, gnorm=0.54, clip=0, loss_scale=16, train_wall=60, gb_free=15.8, wall=15794
2023-09-01 00:30:35 | INFO | train_inner | epoch 011:   1250 / 1826 loss=2.002, trans_loss=4.841, nll_loss=2.091, w2v_ctc_loss=0.802, task_loss=3.972, contrastive_loss=0, total=3869.34, n_correct=2538.71, ppl=4.26, accuracy=65.611, wps=12652.7, ups=1.63, wpb=7738.7, bsz=265.7, num_updates=19500, lr=0.000101274, gnorm=0.563, clip=0, loss_scale=16, train_wall=60, gb_free=12.1, wall=15856
2023-09-01 00:31:37 | INFO | train_inner | epoch 011:   1350 / 1826 loss=1.993, trans_loss=4.843, nll_loss=2.095, w2v_ctc_loss=0.793, task_loss=3.389, contrastive_loss=0, total=3983.96, n_correct=2621.59, ppl=4.27, accuracy=65.804, wps=12919.4, ups=1.62, wpb=7967.9, bsz=297.1, num_updates=19600, lr=0.000101015, gnorm=0.542, clip=0, loss_scale=16, train_wall=61, gb_free=17.1, wall=15917
2023-09-01 00:32:39 | INFO | train_inner | epoch 011:   1450 / 1826 loss=1.995, trans_loss=4.843, nll_loss=2.095, w2v_ctc_loss=0.797, task_loss=3.53, contrastive_loss=0, total=4000.92, n_correct=2634.42, ppl=4.27, accuracy=65.845, wps=12878.9, ups=1.61, wpb=8001.8, bsz=293.5, num_updates=19700, lr=0.000100759, gnorm=0.545, clip=0, loss_scale=16, train_wall=61, gb_free=15.7, wall=15979
2023-09-01 00:33:40 | INFO | train_inner | epoch 011:   1550 / 1826 loss=1.994, trans_loss=4.845, nll_loss=2.097, w2v_ctc_loss=0.793, task_loss=3.328, contrastive_loss=0, total=4013.12, n_correct=2641.46, ppl=4.28, accuracy=65.821, wps=13069.2, ups=1.63, wpb=8026.2, bsz=304.4, num_updates=19800, lr=0.000100504, gnorm=0.541, clip=0, loss_scale=16, train_wall=61, gb_free=15.5, wall=16041
2023-09-01 00:34:41 | INFO | train_inner | epoch 011:   1650 / 1826 loss=1.992, trans_loss=4.84, nll_loss=2.091, w2v_ctc_loss=0.79, task_loss=3.432, contrastive_loss=0, total=3975.76, n_correct=2622.3, ppl=4.26, accuracy=65.957, wps=13101.4, ups=1.65, wpb=7951.5, bsz=290.5, num_updates=19900, lr=0.000100251, gnorm=0.556, clip=0, loss_scale=16, train_wall=60, gb_free=16, wall=16102
2023-09-01 00:35:43 | INFO | train_inner | epoch 011:   1750 / 1826 loss=1.989, trans_loss=4.844, nll_loss=2.095, w2v_ctc_loss=0.781, task_loss=3.382, contrastive_loss=0, total=4033.09, n_correct=2652.24, ppl=4.27, accuracy=65.762, wps=13009.8, ups=1.61, wpb=8066.2, bsz=306.4, num_updates=20000, lr=0.0001, gnorm=0.545, clip=0, loss_scale=16, train_wall=61, gb_free=15.5, wall=16164
2023-09-01 00:35:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 00:36:22 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 3.864 | trans_loss 5.077 | nll_loss 2.347 | w2v_ctc_loss 1.424 | task_loss 13.598 | contrastive_loss 0 | total 3505.91 | n_correct 2387.73 | ppl 5.09 | accuracy 68.106 | uer 18.56 | wer 20.284 | raw_wer 20.284 | bleu 30.19 | wps 1204.7 | wpb 3505.9 | bsz 119.3 | num_updates 20000 | best_bleu 30.19
2023-09-01 00:36:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 20000 updates
2023-09-01 00:36:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_11_20000.pt
2023-09-01 00:36:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_11_20000.pt
2023-09-01 00:36:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_11_20000.pt (epoch 11 @ 20000 updates, score 30.19) (writing took 12.04377117700642 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:0')
2023-09-01 00:37:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:7')
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 00:37:59 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 3.846 | trans_loss 5.076 | nll_loss 2.345 | w2v_ctc_loss 1.367 | task_loss 13.508 | contrastive_loss 0 | total 3505.91 | n_correct 2386 | ppl 5.08 | accuracy 68.057 | uer 18.42 | wer 20.112 | raw_wer 20.112 | bleu 29.96 | wps 1204.1 | wpb 3505.9 | bsz 119.3 | num_updates 20076 | best_bleu 30.19
2023-09-01 00:37:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 20076 updates
2023-09-01 00:37:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_29.9609.pt
2023-09-01 00:38:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_29.9609.pt
2023-09-01 00:38:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_29.9609.pt (epoch 11 @ 20076 updates, score 29.96) (writing took 7.391515732990229 seconds)
2023-09-01 00:38:07 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-09-01 00:38:07 | INFO | train | epoch 011 | loss 1.996 | trans_loss 4.842 | nll_loss 2.092 | w2v_ctc_loss 0.795 | task_loss 3.611 | contrastive_loss 0 | total 3955.88 | n_correct 2601.4 | ppl 4.26 | accuracy 65.76 | wps 11777.1 | ups 1.49 | wpb 7911.8 | bsz 284.7 | num_updates 20076 | lr 9.98105e-05 | gnorm 0.553 | clip 0 | loss_scale 16 | train_wall 1108 | gb_free 15.7 | wall 16308
2023-09-01 00:38:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-09-01 00:38:07 | INFO | fairseq.trainer | begin training epoch 12
2023-09-01 00:38:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 00:38:29 | INFO | train_inner | epoch 012:     24 / 1826 loss=1.98, trans_loss=4.824, nll_loss=2.07, w2v_ctc_loss=0.778, task_loss=3.442, contrastive_loss=0, total=3952.69, n_correct=2617.31, ppl=4.2, accuracy=66.216, wps=4750.3, ups=0.6, wpb=7905.4, bsz=289, num_updates=20100, lr=9.97509e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=60, gb_free=16.8, wall=16330
2023-09-01 00:39:31 | INFO | train_inner | epoch 012:    124 / 1826 loss=1.99, trans_loss=4.825, nll_loss=2.07, w2v_ctc_loss=0.794, task_loss=3.964, contrastive_loss=0, total=3862.92, n_correct=2554.41, ppl=4.2, accuracy=66.126, wps=12627.5, ups=1.63, wpb=7725.8, bsz=267, num_updates=20200, lr=9.95037e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=61, gb_free=15.2, wall=16391
2023-09-01 00:40:32 | INFO | train_inner | epoch 012:    224 / 1826 loss=1.976, trans_loss=4.818, nll_loss=2.062, w2v_ctc_loss=0.772, task_loss=3.479, contrastive_loss=0, total=3993.93, n_correct=2650.32, ppl=4.18, accuracy=66.359, wps=13051.8, ups=1.63, wpb=7987.9, bsz=292.7, num_updates=20300, lr=9.92583e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=61, gb_free=11.8, wall=16452
2023-09-01 00:41:33 | INFO | train_inner | epoch 012:    324 / 1826 loss=1.977, trans_loss=4.818, nll_loss=2.062, w2v_ctc_loss=0.774, task_loss=3.5, contrastive_loss=0, total=3964.38, n_correct=2629.2, ppl=4.17, accuracy=66.321, wps=12926.8, ups=1.63, wpb=7928.8, bsz=290.2, num_updates=20400, lr=9.90148e-05, gnorm=0.558, clip=0, loss_scale=16, train_wall=61, gb_free=16.2, wall=16514
2023-09-01 00:42:34 | INFO | train_inner | epoch 012:    424 / 1826 loss=1.983, trans_loss=4.821, nll_loss=2.066, w2v_ctc_loss=0.788, task_loss=3.532, contrastive_loss=0, total=3984.39, n_correct=2641.31, ppl=4.19, accuracy=66.291, wps=13024.1, ups=1.63, wpb=7968.8, bsz=293.8, num_updates=20500, lr=9.8773e-05, gnorm=0.558, clip=0, loss_scale=16, train_wall=61, gb_free=16.4, wall=16575
2023-09-01 00:43:35 | INFO | train_inner | epoch 012:    524 / 1826 loss=1.977, trans_loss=4.812, nll_loss=2.054, w2v_ctc_loss=0.78, task_loss=3.637, contrastive_loss=0, total=3956.92, n_correct=2627.27, ppl=4.15, accuracy=66.397, wps=12964.7, ups=1.64, wpb=7913.8, bsz=283.7, num_updates=20600, lr=9.85329e-05, gnorm=0.575, clip=0, loss_scale=16, train_wall=60, gb_free=16, wall=16636
2023-09-01 00:44:36 | INFO | train_inner | epoch 012:    624 / 1826 loss=1.975, trans_loss=4.813, nll_loss=2.056, w2v_ctc_loss=0.773, task_loss=3.675, contrastive_loss=0, total=3953.03, n_correct=2626.46, ppl=4.16, accuracy=66.442, wps=13015.4, ups=1.65, wpb=7906.1, bsz=280.1, num_updates=20700, lr=9.82946e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=60, gb_free=14.5, wall=16697
2023-09-01 00:45:37 | INFO | train_inner | epoch 012:    724 / 1826 loss=1.988, trans_loss=4.825, nll_loss=2.071, w2v_ctc_loss=0.793, task_loss=3.709, contrastive_loss=0, total=3952.49, n_correct=2612.18, ppl=4.2, accuracy=66.089, wps=12928.1, ups=1.64, wpb=7905, bsz=282.3, num_updates=20800, lr=9.80581e-05, gnorm=0.58, clip=0, loss_scale=16, train_wall=60, gb_free=17.1, wall=16758
2023-09-01 00:46:38 | INFO | train_inner | epoch 012:    824 / 1826 loss=1.987, trans_loss=4.82, nll_loss=2.065, w2v_ctc_loss=0.789, task_loss=3.979, contrastive_loss=0, total=3920.99, n_correct=2598.14, ppl=4.18, accuracy=66.262, wps=12822.2, ups=1.64, wpb=7842, bsz=265.2, num_updates=20900, lr=9.78232e-05, gnorm=0.555, clip=0, loss_scale=16, train_wall=60, gb_free=15.9, wall=16819
2023-09-01 00:47:40 | INFO | train_inner | epoch 012:    924 / 1826 loss=1.966, trans_loss=4.807, nll_loss=2.049, w2v_ctc_loss=0.767, task_loss=3.106, contrastive_loss=0, total=4064.59, n_correct=2706.76, ppl=4.14, accuracy=66.594, wps=13285.5, ups=1.63, wpb=8129.2, bsz=315.7, num_updates=21000, lr=9.759e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=61, gb_free=17.2, wall=16880
2023-09-01 00:48:40 | INFO | train_inner | epoch 012:   1024 / 1826 loss=1.963, trans_loss=4.801, nll_loss=2.041, w2v_ctc_loss=0.763, task_loss=3.284, contrastive_loss=0, total=4027.9, n_correct=2686.26, ppl=4.11, accuracy=66.691, wps=13249.5, ups=1.64, wpb=8055.8, bsz=307.1, num_updates=21100, lr=9.73585e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=16941
2023-09-01 00:49:42 | INFO | train_inner | epoch 012:   1124 / 1826 loss=1.975, trans_loss=4.81, nll_loss=2.052, w2v_ctc_loss=0.78, task_loss=3.538, contrastive_loss=0, total=3982.26, n_correct=2650.31, ppl=4.15, accuracy=66.553, wps=12898.3, ups=1.62, wpb=7964.5, bsz=286.6, num_updates=21200, lr=9.71286e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=61, gb_free=15.8, wall=17003
2023-09-01 00:50:44 | INFO | train_inner | epoch 012:   1224 / 1826 loss=1.98, trans_loss=4.825, nll_loss=2.073, w2v_ctc_loss=0.78, task_loss=3.609, contrastive_loss=0, total=3949.09, n_correct=2619.37, ppl=4.21, accuracy=66.328, wps=12854, ups=1.63, wpb=7898.2, bsz=285.4, num_updates=21300, lr=9.69003e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=61, gb_free=12.4, wall=17064
2023-09-01 00:51:45 | INFO | train_inner | epoch 012:   1324 / 1826 loss=1.974, trans_loss=4.819, nll_loss=2.063, w2v_ctc_loss=0.77, task_loss=3.46, contrastive_loss=0, total=3963.34, n_correct=2630.8, ppl=4.18, accuracy=66.378, wps=12981.7, ups=1.64, wpb=7926.7, bsz=290.9, num_updates=21400, lr=9.66736e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=60, gb_free=12.9, wall=17125
2023-09-01 00:52:46 | INFO | train_inner | epoch 012:   1424 / 1826 loss=1.985, trans_loss=4.816, nll_loss=2.06, w2v_ctc_loss=0.791, task_loss=3.888, contrastive_loss=0, total=3926.15, n_correct=2600.94, ppl=4.17, accuracy=66.247, wps=12806.1, ups=1.63, wpb=7852.3, bsz=267.9, num_updates=21500, lr=9.64486e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=61, gb_free=15.7, wall=17187
2023-09-01 00:53:48 | INFO | train_inner | epoch 012:   1524 / 1826 loss=1.989, trans_loss=4.844, nll_loss=2.096, w2v_ctc_loss=0.787, task_loss=3.351, contrastive_loss=0, total=4009.37, n_correct=2642.32, ppl=4.28, accuracy=65.904, wps=13041.4, ups=1.63, wpb=8018.7, bsz=300.2, num_updates=21600, lr=9.6225e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=61, gb_free=15.4, wall=17248
2023-09-01 00:54:50 | INFO | train_inner | epoch 012:   1624 / 1826 loss=1.996, trans_loss=4.832, nll_loss=2.081, w2v_ctc_loss=0.8, task_loss=3.96, contrastive_loss=0, total=3883.94, n_correct=2560.24, ppl=4.23, accuracy=65.919, wps=12490, ups=1.61, wpb=7767.9, bsz=262.9, num_updates=21700, lr=9.60031e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=62, gb_free=16, wall=17310
2023-09-01 00:55:51 | INFO | train_inner | epoch 012:   1724 / 1826 loss=1.984, trans_loss=4.825, nll_loss=2.072, w2v_ctc_loss=0.793, task_loss=3.573, contrastive_loss=0, total=3919.88, n_correct=2593.82, ppl=4.21, accuracy=66.171, wps=12820.5, ups=1.64, wpb=7839.8, bsz=283, num_updates=21800, lr=9.57826e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=60, gb_free=15, wall=17371
2023-09-01 00:56:52 | INFO | train_inner | epoch 012:   1824 / 1826 loss=1.972, trans_loss=4.806, nll_loss=2.047, w2v_ctc_loss=0.768, task_loss=3.839, contrastive_loss=0, total=3908.91, n_correct=2604.59, ppl=4.13, accuracy=66.632, wps=12759.9, ups=1.63, wpb=7817.8, bsz=269, num_updates=21900, lr=9.55637e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=61, gb_free=16.1, wall=17433
2023-09-01 00:56:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 00:57:32 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 3.862 | trans_loss 5.059 | nll_loss 2.324 | w2v_ctc_loss 1.458 | task_loss 13.655 | contrastive_loss 0 | total 3505.91 | n_correct 2388.45 | ppl 5.01 | accuracy 68.127 | uer 18.906 | wer 20.724 | raw_wer 20.724 | bleu 30.17 | wps 1196.6 | wpb 3505.9 | bsz 119.3 | num_updates 21902 | best_bleu 30.19
2023-09-01 00:57:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 21902 updates
2023-09-01 00:57:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_30.1700.pt
2023-09-01 00:57:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_30.1700.pt
2023-09-01 00:57:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_30.1700.pt (epoch 12 @ 21902 updates, score 30.17) (writing took 6.2123552770062815 seconds)
2023-09-01 00:57:39 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-09-01 00:57:39 | INFO | train | epoch 012 | loss 1.98 | trans_loss 4.819 | nll_loss 2.063 | w2v_ctc_loss 0.781 | task_loss 3.599 | contrastive_loss 0 | total 3956.37 | n_correct 2623.89 | ppl 4.18 | accuracy 66.321 | wps 12330.5 | ups 1.56 | wpb 7912.7 | bsz 284.8 | num_updates 21902 | lr 9.55593e-05 | gnorm 0.554 | clip 0 | loss_scale 32 | train_wall 1107 | gb_free 10 | wall 17479
2023-09-01 00:57:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-09-01 00:57:39 | INFO | fairseq.trainer | begin training epoch 13
2023-09-01 00:57:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 00:58:47 | INFO | train_inner | epoch 013:     98 / 1826 loss=1.957, trans_loss=4.793, nll_loss=2.03, w2v_ctc_loss=0.757, task_loss=3.351, contrastive_loss=0, total=3964.32, n_correct=2653.31, ppl=4.08, accuracy=66.93, wps=6932.8, ups=0.87, wpb=7928.6, bsz=298.2, num_updates=22000, lr=9.53463e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=60, gb_free=17.4, wall=17547
2023-09-01 00:58:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 00:59:25 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.844 | trans_loss 5.056 | nll_loss 2.324 | w2v_ctc_loss 1.402 | task_loss 13.546 | contrastive_loss 0 | total 3505.91 | n_correct 2391.18 | ppl 5.01 | accuracy 68.204 | uer 18.407 | wer 20.123 | raw_wer 20.123 | bleu 30.14 | wps 1200.6 | wpb 3505.9 | bsz 119.3 | num_updates 22000 | best_bleu 30.19
2023-09-01 00:59:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 22000 updates
2023-09-01 00:59:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_13_22000.pt
2023-09-01 00:59:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_13_22000.pt
2023-09-01 00:59:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_13_22000.pt (epoch 13 @ 22000 updates, score 30.14) (writing took 6.718450318003306 seconds)
2023-09-01 01:00:34 | INFO | train_inner | epoch 013:    198 / 1826 loss=1.964, trans_loss=4.798, nll_loss=2.037, w2v_ctc_loss=0.767, task_loss=3.588, contrastive_loss=0, total=3968.9, n_correct=2651.97, ppl=4.11, accuracy=66.819, wps=7412.2, ups=0.93, wpb=7937.8, bsz=284.2, num_updates=22100, lr=9.51303e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=60, gb_free=15.5, wall=17654
2023-09-01 01:01:34 | INFO | train_inner | epoch 013:    298 / 1826 loss=1.962, trans_loss=4.798, nll_loss=2.037, w2v_ctc_loss=0.76, task_loss=3.557, contrastive_loss=0, total=3986, n_correct=2670.39, ppl=4.1, accuracy=66.994, wps=13147, ups=1.65, wpb=7972, bsz=284.1, num_updates=22200, lr=9.49158e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=60, gb_free=10.5, wall=17715
2023-09-01 01:02:36 | INFO | train_inner | epoch 013:    398 / 1826 loss=1.961, trans_loss=4.801, nll_loss=2.041, w2v_ctc_loss=0.755, task_loss=3.295, contrastive_loss=0, total=3998.65, n_correct=2664.47, ppl=4.12, accuracy=66.634, wps=13015.8, ups=1.63, wpb=7997.3, bsz=304.3, num_updates=22300, lr=9.47027e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=61, gb_free=16.4, wall=17776
2023-09-01 01:03:37 | INFO | train_inner | epoch 013:    498 / 1826 loss=1.965, trans_loss=4.795, nll_loss=2.033, w2v_ctc_loss=0.768, task_loss=3.583, contrastive_loss=0, total=3899.81, n_correct=2605.59, ppl=4.09, accuracy=66.813, wps=12803.3, ups=1.64, wpb=7799.6, bsz=284.4, num_updates=22400, lr=9.44911e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=60, gb_free=17.3, wall=17837
2023-09-01 01:04:38 | INFO | train_inner | epoch 013:    598 / 1826 loss=1.97, trans_loss=4.801, nll_loss=2.041, w2v_ctc_loss=0.775, task_loss=3.719, contrastive_loss=0, total=3901.11, n_correct=2600.12, ppl=4.12, accuracy=66.651, wps=12782.3, ups=1.64, wpb=7802.2, bsz=275.9, num_updates=22500, lr=9.42809e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=60, gb_free=15.8, wall=17898
2023-09-01 01:05:39 | INFO | train_inner | epoch 013:    698 / 1826 loss=1.976, trans_loss=4.803, nll_loss=2.044, w2v_ctc_loss=0.787, task_loss=3.704, contrastive_loss=0, total=3939.37, n_correct=2626.37, ppl=4.12, accuracy=66.67, wps=12841.9, ups=1.63, wpb=7878.7, bsz=273.3, num_updates=22600, lr=9.40721e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=61, gb_free=15.5, wall=17960
2023-09-01 01:06:41 | INFO | train_inner | epoch 013:    798 / 1826 loss=1.971, trans_loss=4.805, nll_loss=2.046, w2v_ctc_loss=0.774, task_loss=3.684, contrastive_loss=0, total=3978.46, n_correct=2650.43, ppl=4.13, accuracy=66.619, wps=12930.9, ups=1.63, wpb=7956.9, bsz=284.7, num_updates=22700, lr=9.38647e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=61, gb_free=15.8, wall=18021
2023-09-01 01:07:41 | INFO | train_inner | epoch 013:    898 / 1826 loss=1.964, trans_loss=4.794, nll_loss=2.032, w2v_ctc_loss=0.769, task_loss=3.541, contrastive_loss=0, total=3963.66, n_correct=2653.53, ppl=4.09, accuracy=66.946, wps=13052.9, ups=1.65, wpb=7927.3, bsz=283.7, num_updates=22800, lr=9.36586e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=60, gb_free=11.4, wall=18082
2023-09-01 01:08:42 | INFO | train_inner | epoch 013:    998 / 1826 loss=1.954, trans_loss=4.784, nll_loss=2.019, w2v_ctc_loss=0.752, task_loss=3.645, contrastive_loss=0, total=3903.96, n_correct=2620.9, ppl=4.05, accuracy=67.134, wps=12847.3, ups=1.65, wpb=7807.9, bsz=277.4, num_updates=22900, lr=9.34539e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=60, gb_free=15.2, wall=18143
2023-09-01 01:09:44 | INFO | train_inner | epoch 013:   1098 / 1826 loss=1.966, trans_loss=4.799, nll_loss=2.038, w2v_ctc_loss=0.766, task_loss=3.578, contrastive_loss=0, total=3984.36, n_correct=2660.64, ppl=4.11, accuracy=66.777, wps=12857.9, ups=1.61, wpb=7968.7, bsz=283.6, num_updates=23000, lr=9.32505e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=61, gb_free=16.7, wall=18205
2023-09-01 01:10:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-01 01:10:46 | INFO | train_inner | epoch 013:   1199 / 1826 loss=1.966, trans_loss=4.801, nll_loss=2.042, w2v_ctc_loss=0.772, task_loss=3.51, contrastive_loss=0, total=4003.85, n_correct=2669.84, ppl=4.12, accuracy=66.682, wps=12955.9, ups=1.62, wpb=8007.7, bsz=291.9, num_updates=23100, lr=9.30484e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=61, gb_free=15.5, wall=18266
2023-09-01 01:11:47 | INFO | train_inner | epoch 013:   1299 / 1826 loss=1.969, trans_loss=4.806, nll_loss=2.047, w2v_ctc_loss=0.771, task_loss=3.642, contrastive_loss=0, total=3979.84, n_correct=2655.42, ppl=4.13, accuracy=66.722, wps=12948.4, ups=1.63, wpb=7959.7, bsz=285, num_updates=23200, lr=9.28477e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=61, gb_free=14.6, wall=18328
2023-09-01 01:12:48 | INFO | train_inner | epoch 013:   1399 / 1826 loss=1.958, trans_loss=4.793, nll_loss=2.032, w2v_ctc_loss=0.76, task_loss=3.454, contrastive_loss=0, total=3968.45, n_correct=2659.24, ppl=4.09, accuracy=67.01, wps=13069.3, ups=1.65, wpb=7936.9, bsz=292.5, num_updates=23300, lr=9.26482e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=18389
2023-09-01 01:13:50 | INFO | train_inner | epoch 013:   1499 / 1826 loss=1.961, trans_loss=4.795, nll_loss=2.033, w2v_ctc_loss=0.76, task_loss=3.813, contrastive_loss=0, total=3926.75, n_correct=2627.45, ppl=4.09, accuracy=66.912, wps=12769.3, ups=1.63, wpb=7853.5, bsz=276.5, num_updates=23400, lr=9.245e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=61, gb_free=17.2, wall=18450
2023-09-01 01:14:51 | INFO | train_inner | epoch 013:   1599 / 1826 loss=1.967, trans_loss=4.793, nll_loss=2.032, w2v_ctc_loss=0.772, task_loss=3.856, contrastive_loss=0, total=3880.79, n_correct=2592.7, ppl=4.09, accuracy=66.809, wps=12698.8, ups=1.64, wpb=7761.6, bsz=270.5, num_updates=23500, lr=9.22531e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=60, gb_free=14.2, wall=18511
2023-09-01 01:15:52 | INFO | train_inner | epoch 013:   1699 / 1826 loss=1.966, trans_loss=4.798, nll_loss=2.038, w2v_ctc_loss=0.774, task_loss=3.631, contrastive_loss=0, total=3971.14, n_correct=2652.5, ppl=4.11, accuracy=66.794, wps=12910.9, ups=1.63, wpb=7942.3, bsz=286.1, num_updates=23600, lr=9.20575e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=61, gb_free=16.8, wall=18573
2023-09-01 01:16:53 | INFO | train_inner | epoch 013:   1799 / 1826 loss=1.959, trans_loss=4.806, nll_loss=2.048, w2v_ctc_loss=0.754, task_loss=3.362, contrastive_loss=0, total=4018.64, n_correct=2685.28, ppl=4.14, accuracy=66.821, wps=13209.4, ups=1.64, wpb=8037.3, bsz=301.2, num_updates=23700, lr=9.1863e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=60, gb_free=17.3, wall=18634
2023-09-01 01:17:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 01:17:48 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.836 | trans_loss 5.051 | nll_loss 2.315 | w2v_ctc_loss 1.388 | task_loss 13.552 | contrastive_loss 0 | total 3505.91 | n_correct 2395.73 | ppl 4.98 | accuracy 68.334 | uer 18.544 | wer 20.356 | raw_wer 20.356 | bleu 30.42 | wps 1208.3 | wpb 3505.9 | bsz 119.3 | num_updates 23727 | best_bleu 30.42
2023-09-01 01:17:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 23727 updates
2023-09-01 01:17:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-09-01 01:17:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-09-01 01:18:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt (epoch 13 @ 23727 updates, score 30.42) (writing took 13.637859882001067 seconds)
2023-09-01 01:18:02 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-09-01 01:18:02 | INFO | train | epoch 013 | loss 1.964 | trans_loss 4.798 | nll_loss 2.037 | w2v_ctc_loss 0.766 | task_loss 3.588 | contrastive_loss 0 | total 3956.36 | n_correct 2643.48 | ppl 4.1 | accuracy 66.816 | wps 11811.2 | ups 1.49 | wpb 7912.7 | bsz 284.9 | num_updates 23727 | lr 9.18108e-05 | gnorm 0.548 | clip 0 | loss_scale 32 | train_wall 1104 | gb_free 11.6 | wall 18702
2023-09-01 01:18:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-09-01 01:18:02 | INFO | fairseq.trainer | begin training epoch 14
2023-09-01 01:18:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 01:18:54 | INFO | train_inner | epoch 014:     73 / 1826 loss=1.959, trans_loss=4.781, nll_loss=2.016, w2v_ctc_loss=0.768, task_loss=3.791, contrastive_loss=0, total=3899.23, n_correct=2615.2, ppl=4.04, accuracy=67.07, wps=6449.9, ups=0.83, wpb=7798.5, bsz=272.6, num_updates=23800, lr=9.16698e-05, gnorm=0.589, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=18755
2023-09-01 01:19:55 | INFO | train_inner | epoch 014:    173 / 1826 loss=1.947, trans_loss=4.773, nll_loss=2.005, w2v_ctc_loss=0.752, task_loss=3.548, contrastive_loss=0, total=3935.95, n_correct=2654.58, ppl=4.01, accuracy=67.444, wps=12856.7, ups=1.63, wpb=7871.9, bsz=287.7, num_updates=23900, lr=9.14779e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=61, gb_free=16.1, wall=18816
2023-09-01 01:20:56 | INFO | train_inner | epoch 014:    273 / 1826 loss=1.949, trans_loss=4.779, nll_loss=2.014, w2v_ctc_loss=0.751, task_loss=3.435, contrastive_loss=0, total=3979.38, n_correct=2676.33, ppl=4.04, accuracy=67.255, wps=13025.7, ups=1.64, wpb=7958.8, bsz=296.7, num_updates=24000, lr=9.12871e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=61, gb_free=15.8, wall=18877
2023-09-01 01:20:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 01:21:35 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.834 | trans_loss 5.045 | nll_loss 2.307 | w2v_ctc_loss 1.394 | task_loss 13.653 | contrastive_loss 0 | total 3505.91 | n_correct 2397.64 | ppl 4.95 | accuracy 68.388 | uer 18.254 | wer 19.913 | raw_wer 19.913 | bleu 30.27 | wps 1201.2 | wpb 3505.9 | bsz 119.3 | num_updates 24000 | best_bleu 30.42
2023-09-01 01:21:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 24000 updates
2023-09-01 01:21:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_14_24000.pt
2023-09-01 01:21:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_14_24000.pt
2023-09-01 01:21:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_14_24000.pt (epoch 14 @ 24000 updates, score 30.27) (writing took 7.44748388401058 seconds)
2023-09-01 01:22:44 | INFO | train_inner | epoch 014:    373 / 1826 loss=1.953, trans_loss=4.784, nll_loss=2.019, w2v_ctc_loss=0.753, task_loss=3.684, contrastive_loss=0, total=3917.42, n_correct=2629.33, ppl=4.05, accuracy=67.119, wps=7259.9, ups=0.93, wpb=7834.8, bsz=280.6, num_updates=24100, lr=9.10975e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=18985
2023-09-01 01:23:45 | INFO | train_inner | epoch 014:    473 / 1826 loss=1.954, trans_loss=4.779, nll_loss=2.013, w2v_ctc_loss=0.756, task_loss=3.692, contrastive_loss=0, total=3905.2, n_correct=2623.48, ppl=4.04, accuracy=67.179, wps=12822.4, ups=1.64, wpb=7810.4, bsz=273.4, num_updates=24200, lr=9.09091e-05, gnorm=0.586, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=19046
2023-09-01 01:24:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-01 01:24:47 | INFO | train_inner | epoch 014:    574 / 1826 loss=1.956, trans_loss=4.784, nll_loss=2.019, w2v_ctc_loss=0.758, task_loss=3.666, contrastive_loss=0, total=3924.22, n_correct=2636.06, ppl=4.05, accuracy=67.174, wps=12717, ups=1.62, wpb=7848.4, bsz=277.9, num_updates=24300, lr=9.07218e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=61, gb_free=13.3, wall=19107
2023-09-01 01:25:48 | INFO | train_inner | epoch 014:    674 / 1826 loss=1.959, trans_loss=4.787, nll_loss=2.023, w2v_ctc_loss=0.768, task_loss=3.51, contrastive_loss=0, total=3955.77, n_correct=2651.94, ppl=4.06, accuracy=67.04, wps=12959.3, ups=1.64, wpb=7911.5, bsz=293.4, num_updates=24400, lr=9.05357e-05, gnorm=0.56, clip=0, loss_scale=16, train_wall=60, gb_free=15.8, wall=19168
2023-09-01 01:26:49 | INFO | train_inner | epoch 014:    774 / 1826 loss=1.945, trans_loss=4.775, nll_loss=2.008, w2v_ctc_loss=0.746, task_loss=3.46, contrastive_loss=0, total=4025.16, n_correct=2711.92, ppl=4.02, accuracy=67.374, wps=13174.9, ups=1.64, wpb=8050.3, bsz=294.5, num_updates=24500, lr=9.03508e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=60, gb_free=16.8, wall=19230
2023-09-01 01:27:50 | INFO | train_inner | epoch 014:    874 / 1826 loss=1.959, trans_loss=4.779, nll_loss=2.013, w2v_ctc_loss=0.764, task_loss=3.935, contrastive_loss=0, total=3993.11, n_correct=2680.69, ppl=4.04, accuracy=67.133, wps=13015.7, ups=1.63, wpb=7986.2, bsz=269.9, num_updates=24600, lr=9.0167e-05, gnorm=0.555, clip=0, loss_scale=16, train_wall=61, gb_free=15.7, wall=19291
2023-09-01 01:28:51 | INFO | train_inner | epoch 014:    974 / 1826 loss=1.947, trans_loss=4.78, nll_loss=2.015, w2v_ctc_loss=0.747, task_loss=3.414, contrastive_loss=0, total=4044.19, n_correct=2720.82, ppl=4.04, accuracy=67.277, wps=13285.6, ups=1.64, wpb=8088.4, bsz=302.6, num_updates=24700, lr=8.99843e-05, gnorm=0.553, clip=0, loss_scale=16, train_wall=60, gb_free=16.7, wall=19352
2023-09-01 01:29:53 | INFO | train_inner | epoch 014:   1074 / 1826 loss=1.949, trans_loss=4.773, nll_loss=2.006, w2v_ctc_loss=0.758, task_loss=3.65, contrastive_loss=0, total=3947.31, n_correct=2656.55, ppl=4.02, accuracy=67.3, wps=12829.5, ups=1.63, wpb=7894.6, bsz=284.2, num_updates=24800, lr=8.98027e-05, gnorm=0.557, clip=0, loss_scale=16, train_wall=61, gb_free=16.6, wall=19413
2023-09-01 01:30:55 | INFO | train_inner | epoch 014:   1174 / 1826 loss=1.955, trans_loss=4.782, nll_loss=2.017, w2v_ctc_loss=0.756, task_loss=3.704, contrastive_loss=0, total=3972.36, n_correct=2666.89, ppl=4.05, accuracy=67.136, wps=12827, ups=1.61, wpb=7944.7, bsz=284.6, num_updates=24900, lr=8.96221e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=61, gb_free=16.2, wall=19475
2023-09-01 01:31:56 | INFO | train_inner | epoch 014:   1274 / 1826 loss=1.949, trans_loss=4.78, nll_loss=2.014, w2v_ctc_loss=0.751, task_loss=3.617, contrastive_loss=0, total=3940.94, n_correct=2651.33, ppl=4.04, accuracy=67.277, wps=12954.6, ups=1.64, wpb=7881.9, bsz=286, num_updates=25000, lr=8.94427e-05, gnorm=0.555, clip=0, loss_scale=16, train_wall=60, gb_free=12.6, wall=19536
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:0')
2023-09-01 01:32:57 | INFO | train_inner | epoch 014:   1374 / 1826 loss=1.959, trans_loss=4.79, nll_loss=2.028, w2v_ctc_loss=0.763, task_loss=3.572, contrastive_loss=0, total=3938.73, n_correct=2637.63, ppl=4.08, accuracy=66.967, wps=12760.2, ups=1.62, wpb=7877.5, bsz=290.2, num_updates=25100, lr=8.92644e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=61, gb_free=16.5, wall=19598
2023-09-01 01:33:58 | INFO | train_inner | epoch 014:   1474 / 1826 loss=1.955, trans_loss=4.786, nll_loss=2.023, w2v_ctc_loss=0.755, task_loss=3.765, contrastive_loss=0, total=3956.81, n_correct=2656.21, ppl=4.06, accuracy=67.13, wps=12975.1, ups=1.64, wpb=7913.6, bsz=280, num_updates=25200, lr=8.90871e-05, gnorm=0.557, clip=0, loss_scale=16, train_wall=60, gb_free=15.4, wall=19659
2023-09-01 01:35:00 | INFO | train_inner | epoch 014:   1574 / 1826 loss=1.954, trans_loss=4.778, nll_loss=2.012, w2v_ctc_loss=0.756, task_loss=4.025, contrastive_loss=0, total=3893.92, n_correct=2619.53, ppl=4.03, accuracy=67.272, wps=12598.8, ups=1.62, wpb=7787.8, bsz=265.4, num_updates=25300, lr=8.89108e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=61, gb_free=15.4, wall=19721
2023-09-01 01:36:02 | INFO | train_inner | epoch 014:   1674 / 1826 loss=1.951, trans_loss=4.787, nll_loss=2.023, w2v_ctc_loss=0.756, task_loss=3.437, contrastive_loss=0, total=4015.62, n_correct=2697.58, ppl=4.07, accuracy=67.177, wps=13062.9, ups=1.63, wpb=8031.2, bsz=297.5, num_updates=25400, lr=8.87357e-05, gnorm=0.555, clip=0, loss_scale=16, train_wall=61, gb_free=16, wall=19782
2023-09-01 01:37:03 | INFO | train_inner | epoch 014:   1774 / 1826 loss=1.948, trans_loss=4.774, nll_loss=2.008, w2v_ctc_loss=0.75, task_loss=3.58, contrastive_loss=0, total=3969.64, n_correct=2676.55, ppl=4.02, accuracy=67.426, wps=13034.3, ups=1.64, wpb=7939.3, bsz=286.7, num_updates=25500, lr=8.85615e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=60, gb_free=16.7, wall=19843
2023-09-01 01:37:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:5')
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 01:38:13 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.823 | trans_loss 5.037 | nll_loss 2.295 | w2v_ctc_loss 1.377 | task_loss 13.548 | contrastive_loss 0 | total 3505.91 | n_correct 2407.55 | ppl 4.91 | accuracy 68.671 | uer 18.2 | wer 20.116 | raw_wer 20.116 | bleu 30.57 | wps 1192.7 | wpb 3505.9 | bsz 119.3 | num_updates 25552 | best_bleu 30.57
2023-09-01 01:38:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 25552 updates
2023-09-01 01:38:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-09-01 01:38:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-09-01 01:38:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt (epoch 14 @ 25552 updates, score 30.57) (writing took 12.454576875010389 seconds)
2023-09-01 01:38:26 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-09-01 01:38:26 | INFO | train | epoch 014 | loss 1.952 | trans_loss 4.781 | nll_loss 2.015 | w2v_ctc_loss 0.756 | task_loss 3.63 | contrastive_loss 0 | total 3956.22 | n_correct 2659.24 | ppl 4.04 | accuracy 67.217 | wps 11791.7 | ups 1.49 | wpb 7912.4 | bsz 284.8 | num_updates 25552 | lr 8.84713e-05 | gnorm 0.558 | clip 0 | loss_scale 16 | train_wall 1105 | gb_free 17 | wall 19927
2023-09-01 01:38:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-09-01 01:38:26 | INFO | fairseq.trainer | begin training epoch 15
2023-09-01 01:38:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 01:39:03 | INFO | train_inner | epoch 015:     48 / 1826 loss=1.946, trans_loss=4.775, nll_loss=2.009, w2v_ctc_loss=0.751, task_loss=3.634, contrastive_loss=0, total=3896.19, n_correct=2630.17, ppl=4.02, accuracy=67.506, wps=6477.1, ups=0.83, wpb=7792.4, bsz=281.4, num_updates=25600, lr=8.83883e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=60, gb_free=17.2, wall=19963
2023-09-01 01:40:04 | INFO | train_inner | epoch 015:    148 / 1826 loss=1.943, trans_loss=4.764, nll_loss=1.994, w2v_ctc_loss=0.75, task_loss=3.69, contrastive_loss=0, total=3927.24, n_correct=2655.77, ppl=3.98, accuracy=67.624, wps=12918.2, ups=1.64, wpb=7854.5, bsz=279.7, num_updates=25700, lr=8.82162e-05, gnorm=0.561, clip=0, loss_scale=16, train_wall=60, gb_free=14.9, wall=20024
2023-09-01 01:41:05 | INFO | train_inner | epoch 015:    248 / 1826 loss=1.94, trans_loss=4.765, nll_loss=1.994, w2v_ctc_loss=0.741, task_loss=3.697, contrastive_loss=0, total=3950.05, n_correct=2671.26, ppl=3.98, accuracy=67.626, wps=12812.1, ups=1.62, wpb=7900.1, bsz=280.6, num_updates=25800, lr=8.80451e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=61, gb_free=16.7, wall=20086
2023-09-01 01:42:07 | INFO | train_inner | epoch 015:    348 / 1826 loss=1.936, trans_loss=4.754, nll_loss=1.981, w2v_ctc_loss=0.74, task_loss=3.628, contrastive_loss=0, total=3981.94, n_correct=2699.71, ppl=3.95, accuracy=67.799, wps=12992.9, ups=1.63, wpb=7963.9, bsz=285.7, num_updates=25900, lr=8.7875e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=61, gb_free=15.5, wall=20147
2023-09-01 01:43:08 | INFO | train_inner | epoch 015:    448 / 1826 loss=1.941, trans_loss=4.761, nll_loss=1.99, w2v_ctc_loss=0.742, task_loss=3.978, contrastive_loss=0, total=3884.54, n_correct=2628.26, ppl=3.97, accuracy=67.659, wps=12702.3, ups=1.63, wpb=7769.1, bsz=265.1, num_updates=26000, lr=8.77058e-05, gnorm=0.58, clip=0, loss_scale=16, train_wall=60, gb_free=11, wall=20208
2023-09-01 01:43:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 01:43:47 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.828 | trans_loss 5.043 | nll_loss 2.301 | w2v_ctc_loss 1.382 | task_loss 13.579 | contrastive_loss 0 | total 3505.91 | n_correct 2400.45 | ppl 4.93 | accuracy 68.469 | uer 18.391 | wer 20.254 | raw_wer 20.254 | bleu 29.93 | wps 1201 | wpb 3505.9 | bsz 119.3 | num_updates 26000 | best_bleu 30.57
2023-09-01 01:43:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 26000 updates
2023-09-01 01:43:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_15_26000.pt
2023-09-01 01:43:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_15_26000.pt
2023-09-01 01:43:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_15_26000.pt (epoch 15 @ 26000 updates, score 29.93) (writing took 9.125143445999129 seconds)
2023-09-01 01:44:56 | INFO | train_inner | epoch 015:    548 / 1826 loss=1.933, trans_loss=4.758, nll_loss=1.986, w2v_ctc_loss=0.733, task_loss=3.434, contrastive_loss=0, total=3934.61, n_correct=2665.4, ppl=3.96, accuracy=67.742, wps=7243.9, ups=0.92, wpb=7869.2, bsz=294.8, num_updates=26100, lr=8.75376e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=60, gb_free=16.5, wall=20317
2023-09-01 01:45:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-01 01:45:58 | INFO | train_inner | epoch 015:    649 / 1826 loss=1.938, trans_loss=4.758, nll_loss=1.987, w2v_ctc_loss=0.746, task_loss=3.502, contrastive_loss=0, total=3953.5, n_correct=2676.37, ppl=3.96, accuracy=67.696, wps=12823.2, ups=1.62, wpb=7907, bsz=290.3, num_updates=26200, lr=8.73704e-05, gnorm=0.547, clip=0, loss_scale=8, train_wall=61, gb_free=15.4, wall=20379
2023-09-01 01:46:59 | INFO | train_inner | epoch 015:    749 / 1826 loss=1.943, trans_loss=4.766, nll_loss=1.996, w2v_ctc_loss=0.745, task_loss=3.805, contrastive_loss=0, total=3893.39, n_correct=2632.36, ppl=3.99, accuracy=67.611, wps=12727.9, ups=1.63, wpb=7786.8, bsz=272.1, num_updates=26300, lr=8.72041e-05, gnorm=0.558, clip=0, loss_scale=8, train_wall=60, gb_free=11.9, wall=20440
2023-09-01 01:48:00 | INFO | train_inner | epoch 015:    849 / 1826 loss=1.943, trans_loss=4.759, nll_loss=1.988, w2v_ctc_loss=0.75, task_loss=3.832, contrastive_loss=0, total=3925.07, n_correct=2655.49, ppl=3.97, accuracy=67.655, wps=12873.9, ups=1.64, wpb=7850.1, bsz=273.6, num_updates=26400, lr=8.70388e-05, gnorm=0.557, clip=0, loss_scale=8, train_wall=60, gb_free=15.8, wall=20501
2023-09-01 01:49:02 | INFO | train_inner | epoch 015:    949 / 1826 loss=1.944, trans_loss=4.775, nll_loss=2.009, w2v_ctc_loss=0.743, task_loss=3.682, contrastive_loss=0, total=3976.4, n_correct=2682.8, ppl=4.02, accuracy=67.468, wps=12911.9, ups=1.62, wpb=7952.8, bsz=285.9, num_updates=26500, lr=8.68744e-05, gnorm=0.538, clip=0, loss_scale=8, train_wall=61, gb_free=11.3, wall=20562
2023-09-01 01:50:03 | INFO | train_inner | epoch 015:   1049 / 1826 loss=1.939, trans_loss=4.77, nll_loss=2.002, w2v_ctc_loss=0.739, task_loss=3.559, contrastive_loss=0, total=3984.81, n_correct=2692.91, ppl=4.01, accuracy=67.579, wps=12970.1, ups=1.63, wpb=7969.6, bsz=293.2, num_updates=26600, lr=8.6711e-05, gnorm=0.534, clip=0, loss_scale=8, train_wall=61, gb_free=14.4, wall=20624
2023-09-01 01:51:05 | INFO | train_inner | epoch 015:   1149 / 1826 loss=1.943, trans_loss=4.77, nll_loss=2.001, w2v_ctc_loss=0.745, task_loss=3.835, contrastive_loss=0, total=3977.04, n_correct=2687.84, ppl=4, accuracy=67.584, wps=12954.5, ups=1.63, wpb=7954.1, bsz=278.6, num_updates=26700, lr=8.65485e-05, gnorm=0.545, clip=0, loss_scale=8, train_wall=61, gb_free=11.8, wall=20685
2023-09-01 01:52:06 | INFO | train_inner | epoch 015:   1249 / 1826 loss=1.943, trans_loss=4.765, nll_loss=1.996, w2v_ctc_loss=0.748, task_loss=3.62, contrastive_loss=0, total=3973.86, n_correct=2686.96, ppl=3.99, accuracy=67.616, wps=12898.3, ups=1.62, wpb=7947.7, bsz=285.8, num_updates=26800, lr=8.63868e-05, gnorm=0.578, clip=0, loss_scale=8, train_wall=61, gb_free=15.7, wall=20747
2023-09-01 01:53:08 | INFO | train_inner | epoch 015:   1349 / 1826 loss=1.934, trans_loss=4.762, nll_loss=1.992, w2v_ctc_loss=0.73, task_loss=3.519, contrastive_loss=0, total=3976.34, n_correct=2687.41, ppl=3.98, accuracy=67.585, wps=12930.9, ups=1.63, wpb=7952.7, bsz=298.5, num_updates=26900, lr=8.62261e-05, gnorm=0.613, clip=0, loss_scale=8, train_wall=61, gb_free=17.2, wall=20808
2023-09-01 01:54:09 | INFO | train_inner | epoch 015:   1449 / 1826 loss=1.931, trans_loss=4.762, nll_loss=1.992, w2v_ctc_loss=0.73, task_loss=3.286, contrastive_loss=0, total=4020.69, n_correct=2722.27, ppl=3.98, accuracy=67.707, wps=13209, ups=1.64, wpb=8041.4, bsz=307.7, num_updates=27000, lr=8.60663e-05, gnorm=0.529, clip=0, loss_scale=8, train_wall=60, gb_free=14.2, wall=20869
2023-09-01 01:55:10 | INFO | train_inner | epoch 015:   1549 / 1826 loss=1.947, trans_loss=4.768, nll_loss=2, w2v_ctc_loss=0.758, task_loss=3.766, contrastive_loss=0, total=3928.65, n_correct=2652.59, ppl=4, accuracy=67.519, wps=12832.6, ups=1.63, wpb=7857.3, bsz=278.6, num_updates=27100, lr=8.59074e-05, gnorm=0.532, clip=0, loss_scale=8, train_wall=61, gb_free=17, wall=20931
2023-09-01 01:56:11 | INFO | train_inner | epoch 015:   1649 / 1826 loss=1.942, trans_loss=4.763, nll_loss=1.993, w2v_ctc_loss=0.749, task_loss=3.783, contrastive_loss=0, total=3972.5, n_correct=2686.76, ppl=3.98, accuracy=67.634, wps=13019.7, ups=1.64, wpb=7945, bsz=276.9, num_updates=27200, lr=8.57493e-05, gnorm=0.538, clip=0, loss_scale=8, train_wall=60, gb_free=14.9, wall=20992
2023-09-01 01:57:13 | INFO | train_inner | epoch 015:   1749 / 1826 loss=1.949, trans_loss=4.77, nll_loss=2.003, w2v_ctc_loss=0.759, task_loss=3.747, contrastive_loss=0, total=3976.02, n_correct=2688.35, ppl=4.01, accuracy=67.614, wps=12905.7, ups=1.62, wpb=7952, bsz=282, num_updates=27300, lr=8.55921e-05, gnorm=0.547, clip=0, loss_scale=8, train_wall=61, gb_free=17.3, wall=21053
2023-09-01 01:58:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 01:58:39 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.818 | trans_loss 5.029 | nll_loss 2.287 | w2v_ctc_loss 1.376 | task_loss 13.596 | contrastive_loss 0 | total 3505.91 | n_correct 2411.82 | ppl 4.88 | accuracy 68.793 | uer 18.163 | wer 20.044 | raw_wer 20.044 | bleu 30.35 | wps 1200.8 | wpb 3505.9 | bsz 119.3 | num_updates 27377 | best_bleu 30.57
2023-09-01 01:58:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 27377 updates
2023-09-01 01:58:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_30.3505.pt
2023-09-01 01:58:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_30.3505.pt
2023-09-01 01:58:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_30.3505.pt (epoch 15 @ 27377 updates, score 30.35) (writing took 7.1330758900003275 seconds)
2023-09-01 01:58:47 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-09-01 01:58:47 | INFO | train | epoch 015 | loss 1.94 | trans_loss 4.764 | nll_loss 1.995 | w2v_ctc_loss 0.744 | task_loss 3.652 | contrastive_loss 0 | total 3956.13 | n_correct 2675.24 | ppl 3.99 | accuracy 67.623 | wps 11832 | ups 1.5 | wpb 7912.3 | bsz 284.8 | num_updates 27377 | lr 8.54716e-05 | gnorm 0.551 | clip 0 | loss_scale 8 | train_wall 1107 | gb_free 15.6 | wall 21147
2023-09-01 01:58:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-09-01 01:58:47 | INFO | fairseq.trainer | begin training epoch 16
2023-09-01 01:58:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 01:59:08 | INFO | train_inner | epoch 016:     23 / 1826 loss=1.94, trans_loss=4.768, nll_loss=2, w2v_ctc_loss=0.742, task_loss=3.55, contrastive_loss=0, total=3975.21, n_correct=2683.61, ppl=4, accuracy=67.509, wps=6878.3, ups=0.87, wpb=7950.4, bsz=290.5, num_updates=27400, lr=8.54358e-05, gnorm=0.548, clip=0, loss_scale=8, train_wall=61, gb_free=15.9, wall=21169
2023-09-01 02:00:09 | INFO | train_inner | epoch 016:    123 / 1826 loss=1.916, trans_loss=4.742, nll_loss=1.966, w2v_ctc_loss=0.714, task_loss=3.389, contrastive_loss=0, total=4011.89, n_correct=2735.42, ppl=3.91, accuracy=68.183, wps=13107.1, ups=1.63, wpb=8023.8, bsz=300.8, num_updates=27500, lr=8.52803e-05, gnorm=0.534, clip=0, loss_scale=8, train_wall=61, gb_free=16.3, wall=21230
2023-09-01 02:01:11 | INFO | train_inner | epoch 016:    223 / 1826 loss=1.933, trans_loss=4.754, nll_loss=1.982, w2v_ctc_loss=0.738, task_loss=3.566, contrastive_loss=0, total=3965.21, n_correct=2690.1, ppl=3.95, accuracy=67.843, wps=12964, ups=1.63, wpb=7930.4, bsz=289.5, num_updates=27600, lr=8.51257e-05, gnorm=0.544, clip=0, loss_scale=8, train_wall=61, gb_free=15.4, wall=21291
2023-09-01 02:02:12 | INFO | train_inner | epoch 016:    323 / 1826 loss=1.928, trans_loss=4.749, nll_loss=1.975, w2v_ctc_loss=0.727, task_loss=3.724, contrastive_loss=0, total=3905.2, n_correct=2652.66, ppl=3.93, accuracy=67.926, wps=12830, ups=1.64, wpb=7810.4, bsz=278, num_updates=27700, lr=8.49719e-05, gnorm=0.54, clip=0, loss_scale=8, train_wall=60, gb_free=15.6, wall=21352
2023-09-01 02:03:13 | INFO | train_inner | epoch 016:    423 / 1826 loss=1.929, trans_loss=4.754, nll_loss=1.982, w2v_ctc_loss=0.737, task_loss=3.43, contrastive_loss=0, total=3984.93, n_correct=2707.37, ppl=3.95, accuracy=67.94, wps=13026.6, ups=1.63, wpb=7969.9, bsz=299.3, num_updates=27800, lr=8.48189e-05, gnorm=0.536, clip=0, loss_scale=8, train_wall=61, gb_free=17.5, wall=21413
2023-09-01 02:04:14 | INFO | train_inner | epoch 016:    523 / 1826 loss=1.935, trans_loss=4.755, nll_loss=1.982, w2v_ctc_loss=0.737, task_loss=3.807, contrastive_loss=0, total=3949.35, n_correct=2679.45, ppl=3.95, accuracy=67.845, wps=12901.5, ups=1.63, wpb=7898.7, bsz=277.3, num_updates=27900, lr=8.46668e-05, gnorm=0.535, clip=0, loss_scale=8, train_wall=61, gb_free=15.5, wall=21474
2023-09-01 02:05:16 | INFO | train_inner | epoch 016:    623 / 1826 loss=1.934, trans_loss=4.75, nll_loss=1.977, w2v_ctc_loss=0.738, task_loss=3.701, contrastive_loss=0, total=3937.39, n_correct=2672.09, ppl=3.94, accuracy=67.864, wps=12748.1, ups=1.62, wpb=7874.8, bsz=283.1, num_updates=28000, lr=8.45154e-05, gnorm=0.551, clip=0, loss_scale=8, train_wall=61, gb_free=13.5, wall=21536
2023-09-01 02:05:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 02:05:54 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.822 | trans_loss 5.019 | nll_loss 2.273 | w2v_ctc_loss 1.416 | task_loss 13.708 | contrastive_loss 0 | total 3505.91 | n_correct 2409.55 | ppl 4.83 | accuracy 68.728 | uer 18.391 | wer 20.202 | raw_wer 20.202 | bleu 30.71 | wps 1199.9 | wpb 3505.9 | bsz 119.3 | num_updates 28000 | best_bleu 30.71
2023-09-01 02:05:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 28000 updates
2023-09-01 02:05:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_16_28000.pt
2023-09-01 02:05:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_16_28000.pt
2023-09-01 02:06:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_16_28000.pt (epoch 16 @ 28000 updates, score 30.71) (writing took 14.221557707991451 seconds)
2023-09-01 02:07:11 | INFO | train_inner | epoch 016:    723 / 1826 loss=1.927, trans_loss=4.748, nll_loss=1.974, w2v_ctc_loss=0.73, task_loss=3.606, contrastive_loss=0, total=3963.14, n_correct=2697.28, ppl=3.93, accuracy=68.059, wps=6890.9, ups=0.87, wpb=7926.3, bsz=287.6, num_updates=28100, lr=8.43649e-05, gnorm=0.548, clip=0, loss_scale=8, train_wall=61, gb_free=14.9, wall=21651
2023-09-01 02:08:12 | INFO | train_inner | epoch 016:    823 / 1826 loss=1.933, trans_loss=4.749, nll_loss=1.975, w2v_ctc_loss=0.739, task_loss=3.844, contrastive_loss=0, total=3929.71, n_correct=2672.72, ppl=3.93, accuracy=68.013, wps=12840.9, ups=1.63, wpb=7859.4, bsz=274.4, num_updates=28200, lr=8.42152e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=61, gb_free=16.3, wall=21712
2023-09-01 02:09:13 | INFO | train_inner | epoch 016:    923 / 1826 loss=1.934, trans_loss=4.753, nll_loss=1.981, w2v_ctc_loss=0.736, task_loss=3.867, contrastive_loss=0, total=3932.85, n_correct=2667.35, ppl=3.95, accuracy=67.822, wps=12894.2, ups=1.64, wpb=7865.7, bsz=272.2, num_updates=28300, lr=8.40663e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=60, gb_free=12.7, wall=21773
2023-09-01 02:10:14 | INFO | train_inner | epoch 016:   1023 / 1826 loss=1.933, trans_loss=4.752, nll_loss=1.979, w2v_ctc_loss=0.74, task_loss=3.694, contrastive_loss=0, total=3929.66, n_correct=2668.35, ppl=3.94, accuracy=67.903, wps=12878.4, ups=1.64, wpb=7859.3, bsz=281.7, num_updates=28400, lr=8.39181e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=60, gb_free=11.9, wall=21835
2023-09-01 02:11:15 | INFO | train_inner | epoch 016:   1123 / 1826 loss=1.929, trans_loss=4.748, nll_loss=1.974, w2v_ctc_loss=0.73, task_loss=3.614, contrastive_loss=0, total=3988.26, n_correct=2710.77, ppl=3.93, accuracy=67.969, wps=13045.7, ups=1.64, wpb=7976.5, bsz=280.8, num_updates=28500, lr=8.37708e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=61, gb_free=16.1, wall=21896
2023-09-01 02:12:16 | INFO | train_inner | epoch 016:   1223 / 1826 loss=1.922, trans_loss=4.742, nll_loss=1.967, w2v_ctc_loss=0.724, task_loss=3.55, contrastive_loss=0, total=3963.52, n_correct=2700.7, ppl=3.91, accuracy=68.139, wps=12985.5, ups=1.64, wpb=7927, bsz=290.7, num_updates=28600, lr=8.36242e-05, gnorm=0.567, clip=0, loss_scale=16, train_wall=60, gb_free=16.9, wall=21957
2023-09-01 02:13:18 | INFO | train_inner | epoch 016:   1323 / 1826 loss=1.941, trans_loss=4.752, nll_loss=1.978, w2v_ctc_loss=0.752, task_loss=4.027, contrastive_loss=0, total=3907.39, n_correct=2652.07, ppl=3.94, accuracy=67.873, wps=12668.9, ups=1.62, wpb=7814.8, bsz=268.1, num_updates=28700, lr=8.34784e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=61, gb_free=14.7, wall=22018
2023-09-01 02:13:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-01 02:14:20 | INFO | train_inner | epoch 016:   1424 / 1826 loss=1.926, trans_loss=4.746, nll_loss=1.972, w2v_ctc_loss=0.725, task_loss=3.703, contrastive_loss=0, total=3963.82, n_correct=2694.83, ppl=3.92, accuracy=67.986, wps=12770.9, ups=1.61, wpb=7927.6, bsz=286.6, num_updates=28800, lr=8.33333e-05, gnorm=0.531, clip=0, loss_scale=8, train_wall=61, gb_free=16.6, wall=22080
2023-09-01 02:15:22 | INFO | train_inner | epoch 016:   1524 / 1826 loss=1.938, trans_loss=4.758, nll_loss=1.986, w2v_ctc_loss=0.748, task_loss=3.736, contrastive_loss=0, total=3946.61, n_correct=2674.48, ppl=3.96, accuracy=67.767, wps=12782.6, ups=1.62, wpb=7893.2, bsz=281.5, num_updates=28900, lr=8.3189e-05, gnorm=0.532, clip=0, loss_scale=8, train_wall=61, gb_free=16.4, wall=22142
2023-09-01 02:16:24 | INFO | train_inner | epoch 016:   1624 / 1826 loss=1.927, trans_loss=4.752, nll_loss=1.979, w2v_ctc_loss=0.73, task_loss=3.543, contrastive_loss=0, total=3989.86, n_correct=2710.25, ppl=3.94, accuracy=67.928, wps=12861.5, ups=1.61, wpb=7979.7, bsz=293.2, num_updates=29000, lr=8.30455e-05, gnorm=0.531, clip=0, loss_scale=8, train_wall=61, gb_free=16.3, wall=22204
2023-09-01 02:17:25 | INFO | train_inner | epoch 016:   1724 / 1826 loss=1.925, trans_loss=4.752, nll_loss=1.979, w2v_ctc_loss=0.728, task_loss=3.525, contrastive_loss=0, total=4025, n_correct=2737.02, ppl=3.94, accuracy=68, wps=13035.6, ups=1.62, wpb=8050, bsz=298.7, num_updates=29100, lr=8.29027e-05, gnorm=0.537, clip=0, loss_scale=8, train_wall=61, gb_free=16.5, wall=22266
2023-09-01 02:18:26 | INFO | train_inner | epoch 016:   1824 / 1826 loss=1.927, trans_loss=4.746, nll_loss=1.972, w2v_ctc_loss=0.734, task_loss=3.462, contrastive_loss=0, total=3966.25, n_correct=2698.33, ppl=3.92, accuracy=68.032, wps=13086.5, ups=1.65, wpb=7932.5, bsz=289.4, num_updates=29200, lr=8.27606e-05, gnorm=0.543, clip=0, loss_scale=8, train_wall=60, gb_free=16.3, wall=22327
2023-09-01 02:18:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 02:19:06 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.804 | trans_loss 5.031 | nll_loss 2.289 | w2v_ctc_loss 1.328 | task_loss 13.542 | contrastive_loss 0 | total 3505.91 | n_correct 2411.55 | ppl 4.89 | accuracy 68.785 | uer 17.835 | wer 19.808 | raw_wer 19.808 | bleu 30.67 | wps 1204.8 | wpb 3505.9 | bsz 119.3 | num_updates 29202 | best_bleu 30.71
2023-09-01 02:19:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 29202 updates
2023-09-01 02:19:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_30.6701.pt
2023-09-01 02:19:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_30.6701.pt
2023-09-01 02:19:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_30.6701.pt (epoch 16 @ 29202 updates, score 30.67) (writing took 7.003400168003282 seconds)
2023-09-01 02:19:14 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-09-01 02:19:14 | INFO | train | epoch 016 | loss 1.93 | trans_loss 4.75 | nll_loss 1.977 | w2v_ctc_loss 0.734 | task_loss 3.652 | contrastive_loss 0 | total 3956.48 | n_correct 2688.44 | ppl 3.94 | accuracy 67.95 | wps 11768.5 | ups 1.49 | wpb 7913 | bsz 284.8 | num_updates 29202 | lr 8.27578e-05 | gnorm 0.544 | clip 0 | loss_scale 8 | train_wall 1108 | gb_free 15.7 | wall 22374
2023-09-01 02:19:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-09-01 02:19:14 | INFO | fairseq.trainer | begin training epoch 17
2023-09-01 02:19:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 02:20:21 | INFO | train_inner | epoch 017:     98 / 1826 loss=1.917, trans_loss=4.729, nll_loss=1.95, w2v_ctc_loss=0.722, task_loss=3.528, contrastive_loss=0, total=3932.33, n_correct=2689.16, ppl=3.86, accuracy=68.386, wps=6832.9, ups=0.87, wpb=7864.7, bsz=285, num_updates=29300, lr=8.26192e-05, gnorm=0.546, clip=0, loss_scale=8, train_wall=60, gb_free=15.7, wall=22442
2023-09-01 02:21:22 | INFO | train_inner | epoch 017:    198 / 1826 loss=1.906, trans_loss=4.716, nll_loss=1.933, w2v_ctc_loss=0.716, task_loss=3.359, contrastive_loss=0, total=3982.65, n_correct=2734.81, ppl=3.82, accuracy=68.668, wps=13112, ups=1.65, wpb=7965.3, bsz=300.8, num_updates=29400, lr=8.24786e-05, gnorm=0.546, clip=0, loss_scale=8, train_wall=60, gb_free=16.3, wall=22503
2023-09-01 02:22:23 | INFO | train_inner | epoch 017:    298 / 1826 loss=1.923, trans_loss=4.734, nll_loss=1.956, w2v_ctc_loss=0.728, task_loss=4.087, contrastive_loss=0, total=3860.54, n_correct=2637.4, ppl=3.88, accuracy=68.317, wps=12603.4, ups=1.63, wpb=7721.1, bsz=260.9, num_updates=29500, lr=8.23387e-05, gnorm=0.544, clip=0, loss_scale=8, train_wall=61, gb_free=11.9, wall=22564
2023-09-01 02:23:25 | INFO | train_inner | epoch 017:    398 / 1826 loss=1.919, trans_loss=4.731, nll_loss=1.953, w2v_ctc_loss=0.725, task_loss=3.66, contrastive_loss=0, total=3958.52, n_correct=2704.17, ppl=3.87, accuracy=68.313, wps=12916.6, ups=1.63, wpb=7917, bsz=288.1, num_updates=29600, lr=8.21995e-05, gnorm=0.531, clip=0, loss_scale=8, train_wall=61, gb_free=16.5, wall=22625
2023-09-01 02:24:25 | INFO | train_inner | epoch 017:    498 / 1826 loss=1.914, trans_loss=4.736, nll_loss=1.959, w2v_ctc_loss=0.715, task_loss=3.415, contrastive_loss=0, total=3999.44, n_correct=2734.42, ppl=3.89, accuracy=68.37, wps=13247.9, ups=1.66, wpb=7998.9, bsz=298.9, num_updates=29700, lr=8.2061e-05, gnorm=0.534, clip=0, loss_scale=8, train_wall=60, gb_free=14.8, wall=22685
2023-09-01 02:25:26 | INFO | train_inner | epoch 017:    598 / 1826 loss=1.919, trans_loss=4.737, nll_loss=1.96, w2v_ctc_loss=0.72, task_loss=3.556, contrastive_loss=0, total=3983.24, n_correct=2716.59, ppl=3.89, accuracy=68.201, wps=13099.8, ups=1.64, wpb=7966.5, bsz=289.6, num_updates=29800, lr=8.19232e-05, gnorm=0.535, clip=0, loss_scale=8, train_wall=60, gb_free=15.5, wall=22746
2023-09-01 02:26:27 | INFO | train_inner | epoch 017:    698 / 1826 loss=1.93, trans_loss=4.747, nll_loss=1.973, w2v_ctc_loss=0.736, task_loss=3.813, contrastive_loss=0, total=3915.68, n_correct=2663.15, ppl=3.93, accuracy=68.012, wps=12698.1, ups=1.62, wpb=7831.4, bsz=277.1, num_updates=29900, lr=8.17861e-05, gnorm=0.548, clip=0, loss_scale=8, train_wall=61, gb_free=14.8, wall=22808
2023-09-01 02:27:29 | INFO | train_inner | epoch 017:    798 / 1826 loss=1.927, trans_loss=4.746, nll_loss=1.971, w2v_ctc_loss=0.732, task_loss=3.866, contrastive_loss=0, total=3896.89, n_correct=2656.77, ppl=3.92, accuracy=68.177, wps=12637.1, ups=1.62, wpb=7793.8, bsz=275.3, num_updates=30000, lr=8.16497e-05, gnorm=0.544, clip=0, loss_scale=8, train_wall=61, gb_free=17, wall=22870
2023-09-01 02:27:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 02:28:08 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.811 | trans_loss 5.023 | nll_loss 2.278 | w2v_ctc_loss 1.37 | task_loss 13.641 | contrastive_loss 0 | total 3505.91 | n_correct 2408.36 | ppl 4.85 | accuracy 68.694 | uer 17.967 | wer 19.83 | raw_wer 19.83 | bleu 30.43 | wps 1197.4 | wpb 3505.9 | bsz 119.3 | num_updates 30000 | best_bleu 30.71
2023-09-01 02:28:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 30000 updates
2023-09-01 02:28:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_17_30000.pt
2023-09-01 02:28:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_17_30000.pt
2023-09-01 02:28:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_17_30000.pt (epoch 17 @ 30000 updates, score 30.43) (writing took 8.68333030800568 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:0')
2023-09-01 02:29:18 | INFO | train_inner | epoch 017:    898 / 1826 loss=1.924, trans_loss=4.74, nll_loss=1.964, w2v_ctc_loss=0.729, task_loss=3.712, contrastive_loss=0, total=3991.65, n_correct=2719.29, ppl=3.9, accuracy=68.124, wps=7315.1, ups=0.92, wpb=7983.3, bsz=280.3, num_updates=30100, lr=8.15139e-05, gnorm=0.568, clip=0, loss_scale=8, train_wall=61, gb_free=15.7, wall=22979
2023-09-01 02:30:19 | INFO | train_inner | epoch 017:    998 / 1826 loss=1.92, trans_loss=4.739, nll_loss=1.962, w2v_ctc_loss=0.718, task_loss=3.605, contrastive_loss=0, total=3997.73, n_correct=2726.83, ppl=3.9, accuracy=68.209, wps=13101.3, ups=1.64, wpb=7995.5, bsz=286.8, num_updates=30200, lr=8.13788e-05, gnorm=0.528, clip=0, loss_scale=8, train_wall=60, gb_free=16.7, wall=23040
2023-09-01 02:31:20 | INFO | train_inner | epoch 017:   1098 / 1826 loss=1.921, trans_loss=4.735, nll_loss=1.958, w2v_ctc_loss=0.722, task_loss=3.869, contrastive_loss=0, total=3920.23, n_correct=2676.28, ppl=3.88, accuracy=68.268, wps=12885.3, ups=1.64, wpb=7840.5, bsz=272, num_updates=30300, lr=8.12444e-05, gnorm=0.553, clip=0, loss_scale=8, train_wall=60, gb_free=16.6, wall=23101
2023-09-01 02:32:21 | INFO | train_inner | epoch 017:   1198 / 1826 loss=1.919, trans_loss=4.738, nll_loss=1.961, w2v_ctc_loss=0.721, task_loss=3.632, contrastive_loss=0, total=3959.66, n_correct=2702.03, ppl=3.89, accuracy=68.239, wps=12977.4, ups=1.64, wpb=7919.3, bsz=285.6, num_updates=30400, lr=8.11107e-05, gnorm=0.54, clip=0, loss_scale=8, train_wall=60, gb_free=16.1, wall=23162
2023-09-01 02:33:22 | INFO | train_inner | epoch 017:   1298 / 1826 loss=1.916, trans_loss=4.731, nll_loss=1.953, w2v_ctc_loss=0.724, task_loss=3.519, contrastive_loss=0, total=3979.69, n_correct=2721.84, ppl=3.87, accuracy=68.393, wps=13083.5, ups=1.64, wpb=7959.4, bsz=286.9, num_updates=30500, lr=8.09776e-05, gnorm=0.55, clip=0, loss_scale=8, train_wall=60, gb_free=16.8, wall=23223
2023-09-01 02:34:23 | INFO | train_inner | epoch 017:   1398 / 1826 loss=1.918, trans_loss=4.728, nll_loss=1.949, w2v_ctc_loss=0.724, task_loss=3.796, contrastive_loss=0, total=3917.91, n_correct=2680.18, ppl=3.86, accuracy=68.408, wps=12825.7, ups=1.64, wpb=7835.8, bsz=275.5, num_updates=30600, lr=8.08452e-05, gnorm=0.563, clip=0, loss_scale=8, train_wall=61, gb_free=16.5, wall=23284
2023-09-01 02:35:25 | INFO | train_inner | epoch 017:   1498 / 1826 loss=1.921, trans_loss=4.749, nll_loss=1.976, w2v_ctc_loss=0.717, task_loss=3.51, contrastive_loss=0, total=3964.73, n_correct=2692.97, ppl=3.93, accuracy=67.923, wps=12778.8, ups=1.61, wpb=7929.5, bsz=301.2, num_updates=30700, lr=8.07134e-05, gnorm=0.54, clip=0, loss_scale=8, train_wall=61, gb_free=16.1, wall=23346
2023-09-01 02:36:26 | INFO | train_inner | epoch 017:   1598 / 1826 loss=1.921, trans_loss=4.745, nll_loss=1.971, w2v_ctc_loss=0.721, task_loss=3.537, contrastive_loss=0, total=3982.88, n_correct=2711.15, ppl=3.92, accuracy=68.07, wps=13062.3, ups=1.64, wpb=7965.8, bsz=294.1, num_updates=30800, lr=8.05823e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=60, gb_free=16.1, wall=23407
2023-09-01 02:37:27 | INFO | train_inner | epoch 017:   1698 / 1826 loss=1.917, trans_loss=4.737, nll_loss=1.961, w2v_ctc_loss=0.717, task_loss=3.607, contrastive_loss=0, total=4008.39, n_correct=2737.2, ppl=3.89, accuracy=68.287, wps=13069.8, ups=1.63, wpb=8016.8, bsz=287.6, num_updates=30900, lr=8.04518e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=61, gb_free=15.7, wall=23468
2023-09-01 02:38:29 | INFO | train_inner | epoch 017:   1798 / 1826 loss=1.923, trans_loss=4.735, nll_loss=1.958, w2v_ctc_loss=0.731, task_loss=3.791, contrastive_loss=0, total=3939.69, n_correct=2690.58, ppl=3.88, accuracy=68.294, wps=12896.4, ups=1.64, wpb=7879.4, bsz=278.3, num_updates=31000, lr=8.03219e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=61, gb_free=16.3, wall=23529
2023-09-01 02:38:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:1')
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 02:39:25 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.811 | trans_loss 5.016 | nll_loss 2.27 | w2v_ctc_loss 1.387 | task_loss 13.622 | contrastive_loss 0 | total 3505.91 | n_correct 2418.18 | ppl 4.82 | accuracy 68.974 | uer 17.715 | wer 19.628 | raw_wer 19.628 | bleu 30.84 | wps 1193.7 | wpb 3505.9 | bsz 119.3 | num_updates 31028 | best_bleu 30.84
2023-09-01 02:39:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 31028 updates
2023-09-01 02:39:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-09-01 02:39:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-09-01 02:39:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt (epoch 17 @ 31028 updates, score 30.84) (writing took 12.372849053994287 seconds)
2023-09-01 02:39:38 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-09-01 02:39:38 | INFO | train | epoch 017 | loss 1.92 | trans_loss 4.736 | nll_loss 1.959 | w2v_ctc_loss 0.723 | task_loss 3.649 | contrastive_loss 0 | total 3956.37 | n_correct 2700.68 | ppl 3.89 | accuracy 68.262 | wps 11804.1 | ups 1.49 | wpb 7912.7 | bsz 284.8 | num_updates 31028 | lr 8.02857e-05 | gnorm 0.543 | clip 0 | loss_scale 16 | train_wall 1105 | gb_free 13.6 | wall 23598
2023-09-01 02:39:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-09-01 02:39:38 | INFO | fairseq.trainer | begin training epoch 18
2023-09-01 02:39:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 02:40:29 | INFO | train_inner | epoch 018:     72 / 1826 loss=1.905, trans_loss=4.719, nll_loss=1.937, w2v_ctc_loss=0.708, task_loss=3.386, contrastive_loss=0, total=4008.34, n_correct=2754.59, ppl=3.83, accuracy=68.721, wps=6638.5, ups=0.83, wpb=8016.7, bsz=299.9, num_updates=31100, lr=8.01927e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=60, gb_free=15.2, wall=23650
2023-09-01 02:41:30 | INFO | train_inner | epoch 018:    172 / 1826 loss=1.899, trans_loss=4.714, nll_loss=1.931, w2v_ctc_loss=0.704, task_loss=3.393, contrastive_loss=0, total=4007.42, n_correct=2759.84, ppl=3.81, accuracy=68.868, wps=13108.3, ups=1.64, wpb=8014.8, bsz=302.5, num_updates=31200, lr=8.00641e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=60, gb_free=16.9, wall=23711
2023-09-01 02:42:31 | INFO | train_inner | epoch 018:    272 / 1826 loss=1.9, trans_loss=4.716, nll_loss=1.933, w2v_ctc_loss=0.696, task_loss=3.54, contrastive_loss=0, total=3995.78, n_correct=2750.83, ppl=3.82, accuracy=68.843, wps=13209.4, ups=1.65, wpb=7991.6, bsz=288.8, num_updates=31300, lr=7.99361e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=60, gb_free=13.5, wall=23772
2023-09-01 02:43:33 | INFO | train_inner | epoch 018:    372 / 1826 loss=1.907, trans_loss=4.709, nll_loss=1.924, w2v_ctc_loss=0.713, task_loss=3.689, contrastive_loss=0, total=3958.9, n_correct=2723.43, ppl=3.8, accuracy=68.793, wps=12862.6, ups=1.62, wpb=7917.8, bsz=279.8, num_updates=31400, lr=7.98087e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=61, gb_free=16.7, wall=23833
2023-09-01 02:44:34 | INFO | train_inner | epoch 018:    472 / 1826 loss=1.909, trans_loss=4.72, nll_loss=1.938, w2v_ctc_loss=0.716, task_loss=3.608, contrastive_loss=0, total=3967.38, n_correct=2725.58, ppl=3.83, accuracy=68.7, wps=12952.3, ups=1.63, wpb=7934.8, bsz=289, num_updates=31500, lr=7.96819e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=61, gb_free=17.5, wall=23894
2023-09-01 02:45:35 | INFO | train_inner | epoch 018:    572 / 1826 loss=1.912, trans_loss=4.726, nll_loss=1.946, w2v_ctc_loss=0.718, task_loss=3.469, contrastive_loss=0, total=3990.39, n_correct=2734.47, ppl=3.85, accuracy=68.526, wps=12994, ups=1.63, wpb=7980.8, bsz=293, num_updates=31600, lr=7.95557e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=61, gb_free=12.8, wall=23956
2023-09-01 02:46:37 | INFO | train_inner | epoch 018:    672 / 1826 loss=1.916, trans_loss=4.725, nll_loss=1.944, w2v_ctc_loss=0.719, task_loss=3.911, contrastive_loss=0, total=3917.45, n_correct=2683.81, ppl=3.85, accuracy=68.509, wps=12705.9, ups=1.62, wpb=7834.9, bsz=272.5, num_updates=31700, lr=7.94301e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=61, gb_free=15.3, wall=24017
2023-09-01 02:47:38 | INFO | train_inner | epoch 018:    772 / 1826 loss=1.914, trans_loss=4.728, nll_loss=1.948, w2v_ctc_loss=0.712, task_loss=3.817, contrastive_loss=0, total=3952.82, n_correct=2706.07, ppl=3.86, accuracy=68.459, wps=12946.8, ups=1.64, wpb=7905.6, bsz=278.3, num_updates=31800, lr=7.93052e-05, gnorm=0.553, clip=0, loss_scale=16, train_wall=60, gb_free=16.4, wall=24078
2023-09-01 02:48:39 | INFO | train_inner | epoch 018:    872 / 1826 loss=1.909, trans_loss=4.721, nll_loss=1.94, w2v_ctc_loss=0.711, task_loss=3.694, contrastive_loss=0, total=3966.85, n_correct=2723.68, ppl=3.84, accuracy=68.661, wps=13000.5, ups=1.64, wpb=7933.7, bsz=280.9, num_updates=31900, lr=7.91808e-05, gnorm=0.566, clip=0, loss_scale=16, train_wall=61, gb_free=15.4, wall=24140
2023-09-01 02:49:40 | INFO | train_inner | epoch 018:    972 / 1826 loss=1.911, trans_loss=4.724, nll_loss=1.943, w2v_ctc_loss=0.721, task_loss=3.571, contrastive_loss=0, total=3939.06, n_correct=2703.11, ppl=3.85, accuracy=68.623, wps=12977, ups=1.65, wpb=7878.1, bsz=289.3, num_updates=32000, lr=7.90569e-05, gnorm=0.562, clip=0, loss_scale=16, train_wall=60, gb_free=16.3, wall=24200
2023-09-01 02:49:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 02:50:19 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.796 | trans_loss 5.012 | nll_loss 2.266 | w2v_ctc_loss 1.343 | task_loss 13.613 | contrastive_loss 0 | total 3505.91 | n_correct 2418.55 | ppl 4.81 | accuracy 68.985 | uer 17.964 | wer 19.755 | raw_wer 19.755 | bleu 30.74 | wps 1198.2 | wpb 3505.9 | bsz 119.3 | num_updates 32000 | best_bleu 30.84
2023-09-01 02:50:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 32000 updates
2023-09-01 02:50:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_18_32000.pt
2023-09-01 02:50:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_18_32000.pt
2023-09-01 02:50:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_18_32000.pt (epoch 18 @ 32000 updates, score 30.74) (writing took 8.344595361006213 seconds)
2023-09-01 02:51:29 | INFO | train_inner | epoch 018:   1072 / 1826 loss=1.907, trans_loss=4.724, nll_loss=1.945, w2v_ctc_loss=0.707, task_loss=3.422, contrastive_loss=0, total=4016.89, n_correct=2750.55, ppl=3.85, accuracy=68.475, wps=7327.9, ups=0.91, wpb=8033.8, bsz=303.7, num_updates=32100, lr=7.89337e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=61, gb_free=16.1, wall=24310
2023-09-01 02:52:31 | INFO | train_inner | epoch 018:   1172 / 1826 loss=1.911, trans_loss=4.722, nll_loss=1.941, w2v_ctc_loss=0.714, task_loss=3.732, contrastive_loss=0, total=3946.42, n_correct=2707.21, ppl=3.84, accuracy=68.599, wps=12808.2, ups=1.62, wpb=7892.8, bsz=279.5, num_updates=32200, lr=7.8811e-05, gnorm=0.561, clip=0, loss_scale=16, train_wall=61, gb_free=16.7, wall=24372
2023-09-01 02:53:32 | INFO | train_inner | epoch 018:   1272 / 1826 loss=1.911, trans_loss=4.722, nll_loss=1.941, w2v_ctc_loss=0.717, task_loss=3.666, contrastive_loss=0, total=3987.05, n_correct=2733.61, ppl=3.84, accuracy=68.562, wps=13097.4, ups=1.64, wpb=7974.1, bsz=281.8, num_updates=32300, lr=7.86889e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=60, gb_free=16.2, wall=24432
2023-09-01 02:54:33 | INFO | train_inner | epoch 018:   1372 / 1826 loss=1.912, trans_loss=4.734, nll_loss=1.957, w2v_ctc_loss=0.712, task_loss=3.592, contrastive_loss=0, total=3961.58, n_correct=2709.49, ppl=3.88, accuracy=68.394, wps=12907.2, ups=1.63, wpb=7923.2, bsz=289.3, num_updates=32400, lr=7.85674e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=61, gb_free=14.1, wall=24494
2023-09-01 02:55:35 | INFO | train_inner | epoch 018:   1472 / 1826 loss=1.906, trans_loss=4.719, nll_loss=1.937, w2v_ctc_loss=0.708, task_loss=3.615, contrastive_loss=0, total=3952, n_correct=2709.23, ppl=3.83, accuracy=68.553, wps=12842.4, ups=1.62, wpb=7904, bsz=285.6, num_updates=32500, lr=7.84465e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=61, gb_free=10.6, wall=24555
2023-09-01 02:56:36 | INFO | train_inner | epoch 018:   1572 / 1826 loss=1.916, trans_loss=4.725, nll_loss=1.945, w2v_ctc_loss=0.72, task_loss=4.017, contrastive_loss=0, total=3829.85, n_correct=2624.96, ppl=3.85, accuracy=68.539, wps=12526.5, ups=1.64, wpb=7659.7, bsz=261.4, num_updates=32600, lr=7.8326e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=60, gb_free=14.5, wall=24616
2023-09-01 02:57:38 | INFO | train_inner | epoch 018:   1672 / 1826 loss=1.92, trans_loss=4.73, nll_loss=1.952, w2v_ctc_loss=0.73, task_loss=3.821, contrastive_loss=0, total=3921.07, n_correct=2680.69, ppl=3.87, accuracy=68.366, wps=12731.6, ups=1.62, wpb=7842.1, bsz=277.5, num_updates=32700, lr=7.82062e-05, gnorm=0.561, clip=0, loss_scale=16, train_wall=61, gb_free=15.7, wall=24678
2023-09-01 02:58:39 | INFO | train_inner | epoch 018:   1772 / 1826 loss=1.918, trans_loss=4.739, nll_loss=1.962, w2v_ctc_loss=0.721, task_loss=3.9, contrastive_loss=0, total=3901.81, n_correct=2665.95, ppl=3.9, accuracy=68.326, wps=12768.6, ups=1.64, wpb=7803.6, bsz=274.2, num_updates=32800, lr=7.80869e-05, gnorm=0.583, clip=0, loss_scale=16, train_wall=60, gb_free=16.4, wall=24739
2023-09-01 02:59:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 02:59:50 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.795 | trans_loss 5.006 | nll_loss 2.259 | w2v_ctc_loss 1.354 | task_loss 13.619 | contrastive_loss 0 | total 3505.91 | n_correct 2418.82 | ppl 4.79 | accuracy 68.993 | uer 17.846 | wer 19.744 | raw_wer 19.744 | bleu 30.98 | wps 1200.5 | wpb 3505.9 | bsz 119.3 | num_updates 32854 | best_bleu 30.98
2023-09-01 02:59:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 32854 updates
2023-09-01 02:59:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-09-01 02:59:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-09-01 03:00:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt (epoch 18 @ 32854 updates, score 30.98) (writing took 12.652121216000523 seconds)
2023-09-01 03:00:03 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-09-01 03:00:03 | INFO | train | epoch 018 | loss 1.91 | trans_loss 4.723 | nll_loss 1.943 | w2v_ctc_loss 0.713 | task_loss 3.653 | contrastive_loss 0 | total 3956.37 | n_correct 2713.29 | ppl 3.84 | accuracy 68.58 | wps 11789.4 | ups 1.49 | wpb 7912.7 | bsz 284.8 | num_updates 32854 | lr 7.80227e-05 | gnorm 0.551 | clip 0 | loss_scale 32 | train_wall 1107 | gb_free 15.6 | wall 24824
2023-09-01 03:00:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-09-01 03:00:04 | INFO | fairseq.trainer | begin training epoch 19
2023-09-01 03:00:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 03:00:39 | INFO | train_inner | epoch 019:     46 / 1826 loss=1.905, trans_loss=4.721, nll_loss=1.94, w2v_ctc_loss=0.701, task_loss=3.634, contrastive_loss=0, total=3922.13, n_correct=2691.5, ppl=3.84, accuracy=68.623, wps=6503.5, ups=0.83, wpb=7844.3, bsz=281.3, num_updates=32900, lr=7.79681e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=24860
2023-09-01 03:01:41 | INFO | train_inner | epoch 019:    146 / 1826 loss=1.897, trans_loss=4.706, nll_loss=1.921, w2v_ctc_loss=0.701, task_loss=3.526, contrastive_loss=0, total=4007.26, n_correct=2762.81, ppl=3.79, accuracy=68.945, wps=13008.5, ups=1.62, wpb=8014.5, bsz=294.6, num_updates=33000, lr=7.78499e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=61, gb_free=16.1, wall=24921
2023-09-01 03:02:43 | INFO | train_inner | epoch 019:    246 / 1826 loss=1.897, trans_loss=4.7, nll_loss=1.913, w2v_ctc_loss=0.698, task_loss=3.746, contrastive_loss=0, total=3946.3, n_correct=2725.14, ppl=3.77, accuracy=69.056, wps=12768.6, ups=1.62, wpb=7892.6, bsz=276.9, num_updates=33100, lr=7.77322e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=61, gb_free=15, wall=24983
2023-09-01 03:03:44 | INFO | train_inner | epoch 019:    346 / 1826 loss=1.898, trans_loss=4.71, nll_loss=1.925, w2v_ctc_loss=0.698, task_loss=3.654, contrastive_loss=0, total=3951.26, n_correct=2723.78, ppl=3.8, accuracy=68.934, wps=12911.6, ups=1.63, wpb=7902.5, bsz=285, num_updates=33200, lr=7.76151e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=61, gb_free=14.4, wall=25044
2023-09-01 03:04:45 | INFO | train_inner | epoch 019:    446 / 1826 loss=1.901, trans_loss=4.705, nll_loss=1.92, w2v_ctc_loss=0.709, task_loss=3.577, contrastive_loss=0, total=3979.41, n_correct=2741.29, ppl=3.78, accuracy=68.887, wps=13054.1, ups=1.64, wpb=7958.8, bsz=287, num_updates=33300, lr=7.74984e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=25105
2023-09-01 03:05:46 | INFO | train_inner | epoch 019:    546 / 1826 loss=1.902, trans_loss=4.71, nll_loss=1.925, w2v_ctc_loss=0.705, task_loss=3.706, contrastive_loss=0, total=3972.47, n_correct=2734.2, ppl=3.8, accuracy=68.829, wps=12923.5, ups=1.63, wpb=7944.9, bsz=284.1, num_updates=33400, lr=7.73823e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=61, gb_free=16.1, wall=25167
2023-09-01 03:06:48 | INFO | train_inner | epoch 019:    646 / 1826 loss=1.902, trans_loss=4.717, nll_loss=1.935, w2v_ctc_loss=0.698, task_loss=3.622, contrastive_loss=0, total=3976.86, n_correct=2734.63, ppl=3.82, accuracy=68.764, wps=12919.5, ups=1.62, wpb=7953.7, bsz=288.8, num_updates=33500, lr=7.72667e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=61, gb_free=16.7, wall=25228
2023-09-01 03:07:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-01 03:07:50 | INFO | train_inner | epoch 019:    747 / 1826 loss=1.905, trans_loss=4.716, nll_loss=1.934, w2v_ctc_loss=0.708, task_loss=3.6, contrastive_loss=0, total=3995.09, n_correct=2749.51, ppl=3.82, accuracy=68.822, wps=12889.5, ups=1.61, wpb=7990.2, bsz=290.2, num_updates=33600, lr=7.71517e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=61, gb_free=16, wall=25290
2023-09-01 03:08:51 | INFO | train_inner | epoch 019:    847 / 1826 loss=1.909, trans_loss=4.719, nll_loss=1.937, w2v_ctc_loss=0.716, task_loss=3.757, contrastive_loss=0, total=3913.82, n_correct=2685.61, ppl=3.83, accuracy=68.619, wps=12891.5, ups=1.65, wpb=7827.6, bsz=280.2, num_updates=33700, lr=7.70371e-05, gnorm=0.56, clip=0, loss_scale=16, train_wall=60, gb_free=15.8, wall=25351
2023-09-01 03:09:52 | INFO | train_inner | epoch 019:    947 / 1826 loss=1.898, trans_loss=4.704, nll_loss=1.918, w2v_ctc_loss=0.702, task_loss=3.652, contrastive_loss=0, total=3948.02, n_correct=2722.08, ppl=3.78, accuracy=68.948, wps=12976.6, ups=1.64, wpb=7896, bsz=287.6, num_updates=33800, lr=7.69231e-05, gnorm=0.565, clip=0, loss_scale=16, train_wall=60, gb_free=16.7, wall=25412
2023-09-01 03:10:53 | INFO | train_inner | epoch 019:   1047 / 1826 loss=1.902, trans_loss=4.711, nll_loss=1.926, w2v_ctc_loss=0.704, task_loss=3.78, contrastive_loss=0, total=4005.73, n_correct=2756.99, ppl=3.8, accuracy=68.826, wps=13103.2, ups=1.64, wpb=8011.5, bsz=287.2, num_updates=33900, lr=7.68095e-05, gnorm=0.56, clip=0, loss_scale=16, train_wall=61, gb_free=16.4, wall=25473
2023-09-01 03:11:54 | INFO | train_inner | epoch 019:   1147 / 1826 loss=1.901, trans_loss=4.709, nll_loss=1.925, w2v_ctc_loss=0.703, task_loss=3.95, contrastive_loss=0, total=3884.43, n_correct=2677.58, ppl=3.8, accuracy=68.931, wps=12651.1, ups=1.63, wpb=7768.9, bsz=276.3, num_updates=34000, lr=7.66965e-05, gnorm=0.569, clip=0, loss_scale=16, train_wall=61, gb_free=17, wall=25535
2023-09-01 03:11:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 03:12:33 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.8 | trans_loss 5.006 | nll_loss 2.258 | w2v_ctc_loss 1.369 | task_loss 13.634 | contrastive_loss 0 | total 3505.91 | n_correct 2420.27 | ppl 4.78 | accuracy 69.034 | uer 17.895 | wer 19.748 | raw_wer 19.748 | bleu 30.96 | wps 1207.4 | wpb 3505.9 | bsz 119.3 | num_updates 34000 | best_bleu 30.98
2023-09-01 03:12:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 34000 updates
2023-09-01 03:12:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_19_34000.pt
2023-09-01 03:12:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_19_34000.pt
2023-09-01 03:12:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_19_34000.pt (epoch 19 @ 34000 updates, score 30.96) (writing took 9.431272424990311 seconds)
2023-09-01 03:13:44 | INFO | train_inner | epoch 019:   1247 / 1826 loss=1.905, trans_loss=4.718, nll_loss=1.937, w2v_ctc_loss=0.708, task_loss=3.63, contrastive_loss=0, total=3996.79, n_correct=2743.7, ppl=3.83, accuracy=68.648, wps=7253, ups=0.91, wpb=7993.6, bsz=299, num_updates=34100, lr=7.6584e-05, gnorm=0.593, clip=0, loss_scale=16, train_wall=61, gb_free=16.2, wall=25645
2023-09-01 03:14:45 | INFO | train_inner | epoch 019:   1347 / 1826 loss=1.908, trans_loss=4.714, nll_loss=1.931, w2v_ctc_loss=0.713, task_loss=4.024, contrastive_loss=0, total=3885.02, n_correct=2666.24, ppl=3.81, accuracy=68.629, wps=12703.5, ups=1.63, wpb=7770, bsz=275.8, num_updates=34200, lr=7.64719e-05, gnorm=0.584, clip=0, loss_scale=16, train_wall=60, gb_free=16.5, wall=25706
2023-09-01 03:15:47 | INFO | train_inner | epoch 019:   1447 / 1826 loss=1.904, trans_loss=4.717, nll_loss=1.935, w2v_ctc_loss=0.704, task_loss=3.673, contrastive_loss=0, total=3995.14, n_correct=2747.19, ppl=3.82, accuracy=68.763, wps=12997.2, ups=1.63, wpb=7990.3, bsz=291.8, num_updates=34300, lr=7.63604e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=61, gb_free=14.5, wall=25767
2023-09-01 03:16:48 | INFO | train_inner | epoch 019:   1547 / 1826 loss=1.91, trans_loss=4.722, nll_loss=1.942, w2v_ctc_loss=0.715, task_loss=3.822, contrastive_loss=0, total=3924.7, n_correct=2693.88, ppl=3.84, accuracy=68.639, wps=12909.3, ups=1.64, wpb=7849.4, bsz=279.3, num_updates=34400, lr=7.62493e-05, gnorm=0.613, clip=0, loss_scale=16, train_wall=60, gb_free=15.8, wall=25828
2023-09-01 03:17:49 | INFO | train_inner | epoch 019:   1647 / 1826 loss=1.901, trans_loss=4.709, nll_loss=1.925, w2v_ctc_loss=0.705, task_loss=3.733, contrastive_loss=0, total=3951.63, n_correct=2725.35, ppl=3.8, accuracy=68.968, wps=13008, ups=1.65, wpb=7903.3, bsz=278.5, num_updates=34500, lr=7.61387e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=60, gb_free=14.4, wall=25889
2023-09-01 03:18:50 | INFO | train_inner | epoch 019:   1747 / 1826 loss=1.903, trans_loss=4.722, nll_loss=1.942, w2v_ctc_loss=0.703, task_loss=3.572, contrastive_loss=0, total=3977.5, n_correct=2735.07, ppl=3.84, accuracy=68.764, wps=12940.8, ups=1.63, wpb=7955, bsz=290.7, num_updates=34600, lr=7.60286e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=61, gb_free=16.5, wall=25951
2023-09-01 03:19:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 03:20:17 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.789 | trans_loss 4.997 | nll_loss 2.248 | w2v_ctc_loss 1.353 | task_loss 13.617 | contrastive_loss 0 | total 3505.91 | n_correct 2428.82 | ppl 4.75 | accuracy 69.278 | uer 17.744 | wer 19.669 | raw_wer 19.669 | bleu 31.25 | wps 1194.6 | wpb 3505.9 | bsz 119.3 | num_updates 34679 | best_bleu 31.25
2023-09-01 03:20:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 34679 updates
2023-09-01 03:20:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-09-01 03:20:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-09-01 03:20:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt (epoch 19 @ 34679 updates, score 31.25) (writing took 15.366058663988952 seconds)
2023-09-01 03:20:33 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-09-01 03:20:33 | INFO | train | epoch 019 | loss 1.903 | trans_loss 4.713 | nll_loss 1.929 | w2v_ctc_loss 0.705 | task_loss 3.705 | contrastive_loss 0 | total 3956.44 | n_correct 2722.88 | ppl 3.81 | accuracy 68.822 | wps 11739.6 | ups 1.48 | wpb 7912.9 | bsz 284.9 | num_updates 34679 | lr 7.59419e-05 | gnorm 0.56 | clip 0 | loss_scale 16 | train_wall 1108 | gb_free 16.8 | wall 26054
2023-09-01 03:20:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-09-01 03:20:34 | INFO | fairseq.trainer | begin training epoch 20
2023-09-01 03:20:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 03:20:54 | INFO | train_inner | epoch 020:     21 / 1826 loss=1.907, trans_loss=4.716, nll_loss=1.934, w2v_ctc_loss=0.715, task_loss=3.711, contrastive_loss=0, total=3925.6, n_correct=2698.31, ppl=3.82, accuracy=68.736, wps=6331.7, ups=0.81, wpb=7851.2, bsz=280.6, num_updates=34700, lr=7.5919e-05, gnorm=0.559, clip=0, loss_scale=16, train_wall=61, gb_free=16.7, wall=26075
2023-09-01 03:21:55 | INFO | train_inner | epoch 020:    121 / 1826 loss=1.885, trans_loss=4.695, nll_loss=1.906, w2v_ctc_loss=0.681, task_loss=3.559, contrastive_loss=0, total=3985.99, n_correct=2763.96, ppl=3.75, accuracy=69.342, wps=13117.1, ups=1.65, wpb=7972, bsz=288.9, num_updates=34800, lr=7.58098e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=60, gb_free=16.7, wall=26135
2023-09-01 03:22:56 | INFO | train_inner | epoch 020:    221 / 1826 loss=1.889, trans_loss=4.691, nll_loss=1.901, w2v_ctc_loss=0.692, task_loss=3.729, contrastive_loss=0, total=4018, n_correct=2786.48, ppl=3.73, accuracy=69.35, wps=13067.5, ups=1.63, wpb=8036, bsz=283.8, num_updates=34900, lr=7.57011e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=61, gb_free=15.1, wall=26197
2023-09-01 03:23:58 | INFO | train_inner | epoch 020:    321 / 1826 loss=1.889, trans_loss=4.7, nll_loss=1.913, w2v_ctc_loss=0.69, task_loss=3.362, contrastive_loss=0, total=4025.8, n_correct=2786.64, ppl=3.77, accuracy=69.22, wps=13128.8, ups=1.63, wpb=8051.6, bsz=298.8, num_updates=35000, lr=7.55929e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=61, gb_free=14.6, wall=26258
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:0')
2023-09-01 03:24:59 | INFO | train_inner | epoch 020:    421 / 1826 loss=1.891, trans_loss=4.695, nll_loss=1.907, w2v_ctc_loss=0.697, task_loss=3.544, contrastive_loss=0, total=3995.83, n_correct=2764.88, ppl=3.75, accuracy=69.194, wps=12960.2, ups=1.62, wpb=7991.7, bsz=291.2, num_updates=35100, lr=7.54851e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=61, gb_free=16.4, wall=26320
2023-09-01 03:26:00 | INFO | train_inner | epoch 020:    521 / 1826 loss=1.892, trans_loss=4.701, nll_loss=1.914, w2v_ctc_loss=0.69, task_loss=3.684, contrastive_loss=0, total=3926.26, n_correct=2712.17, ppl=3.77, accuracy=69.078, wps=12874.2, ups=1.64, wpb=7852.5, bsz=279.6, num_updates=35200, lr=7.53778e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=60, gb_free=9.2, wall=26381
2023-09-01 03:27:01 | INFO | train_inner | epoch 020:    621 / 1826 loss=1.897, trans_loss=4.7, nll_loss=1.912, w2v_ctc_loss=0.706, task_loss=3.713, contrastive_loss=0, total=3951.68, n_correct=2729.09, ppl=3.76, accuracy=69.062, wps=12967.6, ups=1.64, wpb=7903.4, bsz=281.6, num_updates=35300, lr=7.5271e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=60, gb_free=15.9, wall=26442
2023-09-01 03:28:02 | INFO | train_inner | epoch 020:    721 / 1826 loss=1.895, trans_loss=4.7, nll_loss=1.912, w2v_ctc_loss=0.697, task_loss=3.782, contrastive_loss=0, total=3926.45, n_correct=2711.85, ppl=3.76, accuracy=69.066, wps=12886.6, ups=1.64, wpb=7852.9, bsz=274.8, num_updates=35400, lr=7.51646e-05, gnorm=0.572, clip=0, loss_scale=16, train_wall=60, gb_free=17.4, wall=26503
2023-09-01 03:29:03 | INFO | train_inner | epoch 020:    821 / 1826 loss=1.896, trans_loss=4.707, nll_loss=1.921, w2v_ctc_loss=0.69, task_loss=3.787, contrastive_loss=0, total=3918.38, n_correct=2700.54, ppl=3.79, accuracy=68.92, wps=12793.8, ups=1.63, wpb=7836.8, bsz=276.3, num_updates=35500, lr=7.50587e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=60, gb_free=17.6, wall=26564
2023-09-01 03:30:04 | INFO | train_inner | epoch 020:    921 / 1826 loss=1.897, trans_loss=4.696, nll_loss=1.908, w2v_ctc_loss=0.705, task_loss=3.818, contrastive_loss=0, total=3859.83, n_correct=2667.5, ppl=3.75, accuracy=69.109, wps=12699.1, ups=1.65, wpb=7719.7, bsz=273.6, num_updates=35600, lr=7.49532e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=60, gb_free=11.6, wall=26625
2023-09-01 03:31:05 | INFO | train_inner | epoch 020:   1021 / 1826 loss=1.89, trans_loss=4.701, nll_loss=1.914, w2v_ctc_loss=0.686, task_loss=3.74, contrastive_loss=0, total=3948.02, n_correct=2729.31, ppl=3.77, accuracy=69.131, wps=12930.6, ups=1.64, wpb=7896, bsz=278, num_updates=35700, lr=7.48481e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=26686
2023-09-01 03:31:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-01 03:32:07 | INFO | train_inner | epoch 020:   1122 / 1826 loss=1.889, trans_loss=4.7, nll_loss=1.913, w2v_ctc_loss=0.688, task_loss=3.521, contrastive_loss=0, total=3979.89, n_correct=2752.21, ppl=3.77, accuracy=69.153, wps=12956.2, ups=1.63, wpb=7959.8, bsz=293, num_updates=35800, lr=7.47435e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=61, gb_free=16.8, wall=26747
2023-09-01 03:33:08 | INFO | train_inner | epoch 020:   1222 / 1826 loss=1.897, trans_loss=4.715, nll_loss=1.933, w2v_ctc_loss=0.697, task_loss=3.419, contrastive_loss=0, total=4008.65, n_correct=2755.89, ppl=3.82, accuracy=68.749, wps=13012.3, ups=1.62, wpb=8017.3, bsz=304, num_updates=35900, lr=7.46393e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=61, gb_free=12.3, wall=26809
2023-09-01 03:34:10 | INFO | train_inner | epoch 020:   1322 / 1826 loss=1.894, trans_loss=4.709, nll_loss=1.924, w2v_ctc_loss=0.692, task_loss=3.345, contrastive_loss=0, total=4037.41, n_correct=2781.84, ppl=3.8, accuracy=68.902, wps=13154.2, ups=1.63, wpb=8074.8, bsz=307.8, num_updates=36000, lr=7.45356e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=61, gb_free=16.4, wall=26870
2023-09-01 03:34:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:3')
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 03:34:49 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.797 | trans_loss 5.004 | nll_loss 2.257 | w2v_ctc_loss 1.365 | task_loss 13.548 | contrastive_loss 0 | total 3505.91 | n_correct 2423.18 | ppl 4.78 | accuracy 69.117 | uer 17.868 | wer 19.74 | raw_wer 19.74 | bleu 30.97 | wps 1193.3 | wpb 3505.9 | bsz 119.3 | num_updates 36000 | best_bleu 31.25
2023-09-01 03:34:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 36000 updates
2023-09-01 03:34:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_20_36000.pt
2023-09-01 03:34:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_20_36000.pt
2023-09-01 03:34:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_20_36000.pt (epoch 20 @ 36000 updates, score 30.97) (writing took 7.588550487998873 seconds)
2023-09-01 03:35:58 | INFO | train_inner | epoch 020:   1422 / 1826 loss=1.894, trans_loss=4.693, nll_loss=1.905, w2v_ctc_loss=0.698, task_loss=3.822, contrastive_loss=0, total=3880.04, n_correct=2686.48, ppl=3.74, accuracy=69.238, wps=7182.1, ups=0.93, wpb=7760.1, bsz=273.1, num_updates=36100, lr=7.44323e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=60, gb_free=16.6, wall=26978
2023-09-01 03:37:00 | INFO | train_inner | epoch 020:   1522 / 1826 loss=1.906, trans_loss=4.704, nll_loss=1.918, w2v_ctc_loss=0.716, task_loss=4.146, contrastive_loss=0, total=3892.6, n_correct=2680.37, ppl=3.78, accuracy=68.858, wps=12511.6, ups=1.61, wpb=7785.2, bsz=260.9, num_updates=36200, lr=7.43294e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=62, gb_free=13.8, wall=27041
2023-09-01 03:38:01 | INFO | train_inner | epoch 020:   1622 / 1826 loss=1.896, trans_loss=4.7, nll_loss=1.914, w2v_ctc_loss=0.703, task_loss=3.705, contrastive_loss=0, total=3975.65, n_correct=2749.12, ppl=3.77, accuracy=69.149, wps=12961.7, ups=1.63, wpb=7951.3, bsz=283.1, num_updates=36300, lr=7.4227e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=61, gb_free=17.5, wall=27102
2023-09-01 03:39:02 | INFO | train_inner | epoch 020:   1722 / 1826 loss=1.902, trans_loss=4.705, nll_loss=1.919, w2v_ctc_loss=0.712, task_loss=3.767, contrastive_loss=0, total=3932.02, n_correct=2707.26, ppl=3.78, accuracy=68.852, wps=12930.7, ups=1.64, wpb=7864, bsz=279.2, num_updates=36400, lr=7.41249e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=60, gb_free=13.5, wall=27163
2023-09-01 03:40:03 | INFO | train_inner | epoch 020:   1822 / 1826 loss=1.897, trans_loss=4.714, nll_loss=1.932, w2v_ctc_loss=0.698, task_loss=3.419, contrastive_loss=0, total=3974.02, n_correct=2738.58, ppl=3.82, accuracy=68.912, wps=13032.2, ups=1.64, wpb=7948, bsz=298, num_updates=36500, lr=7.40233e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=60, gb_free=16.5, wall=27224
2023-09-01 03:40:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 03:40:45 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.816 | trans_loss 5.001 | nll_loss 2.253 | w2v_ctc_loss 1.436 | task_loss 13.59 | contrastive_loss 0 | total 3505.91 | n_correct 2424.09 | ppl 4.77 | accuracy 69.143 | uer 17.763 | wer 19.508 | raw_wer 19.508 | bleu 31.16 | wps 1193 | wpb 3505.9 | bsz 119.3 | num_updates 36504 | best_bleu 31.25
2023-09-01 03:40:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 36504 updates
2023-09-01 03:40:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_31.1606.pt
2023-09-01 03:40:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_31.1606.pt
2023-09-01 03:40:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_31.1606.pt (epoch 20 @ 36504 updates, score 31.16) (writing took 7.0139640089764725 seconds)
2023-09-01 03:40:52 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-09-01 03:40:52 | INFO | train | epoch 020 | loss 1.894 | trans_loss 4.701 | nll_loss 1.915 | w2v_ctc_loss 0.697 | task_loss 3.651 | contrastive_loss 0 | total 3956.12 | n_correct 2732.54 | ppl 3.77 | accuracy 69.071 | wps 11851.3 | ups 1.5 | wpb 7912.2 | bsz 284.8 | num_updates 36504 | lr 7.40193e-05 | gnorm 0.546 | clip 0 | loss_scale 16 | train_wall 1106 | gb_free 15.5 | wall 27272
2023-09-01 03:40:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-09-01 03:40:52 | INFO | fairseq.trainer | begin training epoch 21
2023-09-01 03:40:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 03:41:59 | INFO | train_inner | epoch 021:     96 / 1826 loss=1.888, trans_loss=4.697, nll_loss=1.909, w2v_ctc_loss=0.69, task_loss=3.65, contrastive_loss=0, total=3941.06, n_correct=2731.9, ppl=3.75, accuracy=69.319, wps=6804, ups=0.86, wpb=7882.1, bsz=285.7, num_updates=36600, lr=7.39221e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=61, gb_free=15.3, wall=27340
2023-09-01 03:43:00 | INFO | train_inner | epoch 021:    196 / 1826 loss=1.879, trans_loss=4.684, nll_loss=1.892, w2v_ctc_loss=0.679, task_loss=3.472, contrastive_loss=0, total=3977.85, n_correct=2766.06, ppl=3.71, accuracy=69.537, wps=13007.6, ups=1.63, wpb=7955.7, bsz=293.7, num_updates=36700, lr=7.38213e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=61, gb_free=17.4, wall=27401
2023-09-01 03:44:01 | INFO | train_inner | epoch 021:    296 / 1826 loss=1.889, trans_loss=4.69, nll_loss=1.899, w2v_ctc_loss=0.691, task_loss=3.78, contrastive_loss=0, total=3939.83, n_correct=2730.88, ppl=3.73, accuracy=69.315, wps=12969.6, ups=1.65, wpb=7879.7, bsz=276.1, num_updates=36800, lr=7.3721e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=60, gb_free=10.3, wall=27461
2023-09-01 03:45:02 | INFO | train_inner | epoch 021:    396 / 1826 loss=1.875, trans_loss=4.679, nll_loss=1.887, w2v_ctc_loss=0.678, task_loss=3.389, contrastive_loss=0, total=4052.19, n_correct=2822.61, ppl=3.7, accuracy=69.656, wps=13298.5, ups=1.64, wpb=8104.4, bsz=305.5, num_updates=36900, lr=7.3621e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=60, gb_free=14.7, wall=27522
2023-09-01 03:46:03 | INFO | train_inner | epoch 021:    496 / 1826 loss=1.891, trans_loss=4.695, nll_loss=1.906, w2v_ctc_loss=0.696, task_loss=3.707, contrastive_loss=0, total=3975.54, n_correct=2753.93, ppl=3.75, accuracy=69.272, wps=12994.6, ups=1.63, wpb=7951.1, bsz=279.9, num_updates=37000, lr=7.35215e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=61, gb_free=16.1, wall=27584
2023-09-01 03:47:04 | INFO | train_inner | epoch 021:    596 / 1826 loss=1.888, trans_loss=4.696, nll_loss=1.908, w2v_ctc_loss=0.685, task_loss=3.749, contrastive_loss=0, total=3945.03, n_correct=2729.78, ppl=3.75, accuracy=69.195, wps=12874.7, ups=1.63, wpb=7890.1, bsz=279.5, num_updates=37100, lr=7.34223e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=61, gb_free=15.3, wall=27645
2023-09-01 03:48:06 | INFO | train_inner | epoch 021:    696 / 1826 loss=1.882, trans_loss=4.686, nll_loss=1.896, w2v_ctc_loss=0.683, task_loss=3.479, contrastive_loss=0, total=3976.27, n_correct=2757.73, ppl=3.72, accuracy=69.355, wps=12936.5, ups=1.63, wpb=7952.5, bsz=295.9, num_updates=37200, lr=7.33236e-05, gnorm=0.566, clip=0, loss_scale=16, train_wall=61, gb_free=11.7, wall=27706
2023-09-01 03:49:07 | INFO | train_inner | epoch 021:    796 / 1826 loss=1.887, trans_loss=4.693, nll_loss=1.904, w2v_ctc_loss=0.685, task_loss=3.75, contrastive_loss=0, total=3943.94, n_correct=2736.27, ppl=3.74, accuracy=69.379, wps=12976.1, ups=1.65, wpb=7887.9, bsz=275, num_updates=37300, lr=7.32252e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=60, gb_free=13.3, wall=27767
2023-09-01 03:50:08 | INFO | train_inner | epoch 021:    896 / 1826 loss=1.881, trans_loss=4.679, nll_loss=1.887, w2v_ctc_loss=0.684, task_loss=3.65, contrastive_loss=0, total=3933.6, n_correct=2733.81, ppl=3.7, accuracy=69.499, wps=12866.5, ups=1.64, wpb=7867.2, bsz=286.8, num_updates=37400, lr=7.31272e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=60, gb_free=17.1, wall=27828
2023-09-01 03:51:09 | INFO | train_inner | epoch 021:    996 / 1826 loss=1.891, trans_loss=4.694, nll_loss=1.905, w2v_ctc_loss=0.699, task_loss=3.753, contrastive_loss=0, total=3921.19, n_correct=2714.78, ppl=3.75, accuracy=69.234, wps=12865.6, ups=1.64, wpb=7842.4, bsz=278.5, num_updates=37500, lr=7.30297e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=60, gb_free=16.8, wall=27889
2023-09-01 03:52:10 | INFO | train_inner | epoch 021:   1096 / 1826 loss=1.884, trans_loss=4.689, nll_loss=1.899, w2v_ctc_loss=0.685, task_loss=3.558, contrastive_loss=0, total=3949.95, n_correct=2739.34, ppl=3.73, accuracy=69.351, wps=12895.6, ups=1.63, wpb=7899.9, bsz=290.9, num_updates=37600, lr=7.29325e-05, gnorm=0.561, clip=0, loss_scale=16, train_wall=61, gb_free=16.2, wall=27951
2023-09-01 03:53:11 | INFO | train_inner | epoch 021:   1196 / 1826 loss=1.894, trans_loss=4.693, nll_loss=1.904, w2v_ctc_loss=0.699, task_loss=3.859, contrastive_loss=0, total=3907.08, n_correct=2705.67, ppl=3.74, accuracy=69.25, wps=12791.7, ups=1.64, wpb=7814.2, bsz=270.2, num_updates=37700, lr=7.28357e-05, gnorm=0.556, clip=0, loss_scale=16, train_wall=60, gb_free=17.5, wall=28012
2023-09-01 03:54:12 | INFO | train_inner | epoch 021:   1296 / 1826 loss=1.895, trans_loss=4.696, nll_loss=1.908, w2v_ctc_loss=0.703, task_loss=3.687, contrastive_loss=0, total=3953.94, n_correct=2737.27, ppl=3.75, accuracy=69.229, wps=13012.6, ups=1.65, wpb=7907.9, bsz=282.8, num_updates=37800, lr=7.27393e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=60, gb_free=17.5, wall=28072
2023-09-01 03:55:13 | INFO | train_inner | epoch 021:   1396 / 1826 loss=1.897, trans_loss=4.699, nll_loss=1.911, w2v_ctc_loss=0.699, task_loss=4.041, contrastive_loss=0, total=3944.23, n_correct=2723.25, ppl=3.76, accuracy=69.044, wps=12863.7, ups=1.63, wpb=7888.5, bsz=271.4, num_updates=37900, lr=7.26433e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=61, gb_free=13.8, wall=28134
2023-09-01 03:56:15 | INFO | train_inner | epoch 021:   1496 / 1826 loss=1.886, trans_loss=4.694, nll_loss=1.906, w2v_ctc_loss=0.686, task_loss=3.503, contrastive_loss=0, total=3962.56, n_correct=2745.73, ppl=3.75, accuracy=69.292, wps=12918.8, ups=1.63, wpb=7925.1, bsz=288.4, num_updates=38000, lr=7.25476e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=61, gb_free=17.2, wall=28195
2023-09-01 03:56:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.0095], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 03:56:54 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.793 | trans_loss 5.001 | nll_loss 2.252 | w2v_ctc_loss 1.359 | task_loss 13.745 | contrastive_loss 0 | total 3505.91 | n_correct 2427 | ppl 4.76 | accuracy 69.226 | uer 17.492 | wer 19.47 | raw_wer 19.47 | bleu 31.09 | wps 1191.2 | wpb 3505.9 | bsz 119.3 | num_updates 38000 | best_bleu 31.25
2023-09-01 03:56:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 38000 updates
2023-09-01 03:56:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_21_38000.pt
2023-09-01 03:56:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_21_38000.pt
2023-09-01 03:57:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_21_38000.pt (epoch 21 @ 38000 updates, score 31.09) (writing took 8.456267778994516 seconds)
2023-09-01 03:57:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-01 03:58:04 | INFO | train_inner | epoch 021:   1597 / 1826 loss=1.882, trans_loss=4.686, nll_loss=1.896, w2v_ctc_loss=0.682, task_loss=3.509, contrastive_loss=0, total=3992.38, n_correct=2770.44, ppl=3.72, accuracy=69.393, wps=7286, ups=0.91, wpb=7984.8, bsz=294, num_updates=38100, lr=7.24524e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=61, gb_free=16.2, wall=28305
2023-09-01 03:59:06 | INFO | train_inner | epoch 021:   1697 / 1826 loss=1.888, trans_loss=4.702, nll_loss=1.916, w2v_ctc_loss=0.684, task_loss=3.514, contrastive_loss=0, total=3959.43, n_correct=2740.53, ppl=3.77, accuracy=69.215, wps=12819.2, ups=1.62, wpb=7918.9, bsz=291.6, num_updates=38200, lr=7.23575e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=61, gb_free=15.3, wall=28366
2023-09-01 04:00:07 | INFO | train_inner | epoch 021:   1797 / 1826 loss=1.886, trans_loss=4.688, nll_loss=1.898, w2v_ctc_loss=0.696, task_loss=3.712, contrastive_loss=0, total=3935.52, n_correct=2732.66, ppl=3.73, accuracy=69.436, wps=12851.2, ups=1.63, wpb=7871, bsz=284, num_updates=38300, lr=7.22629e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=61, gb_free=11.4, wall=28428
2023-09-01 04:00:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 04:01:04 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.785 | trans_loss 4.996 | nll_loss 2.243 | w2v_ctc_loss 1.345 | task_loss 13.598 | contrastive_loss 0 | total 3505.91 | n_correct 2427.18 | ppl 4.73 | accuracy 69.231 | uer 17.345 | wer 19.129 | raw_wer 19.129 | bleu 31.2 | wps 1195.5 | wpb 3505.9 | bsz 119.3 | num_updates 38329 | best_bleu 31.25
2023-09-01 04:01:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 38329 updates
2023-09-01 04:01:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_31.2009.pt
2023-09-01 04:01:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_31.2009.pt
2023-09-01 04:01:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_31.2009.pt (epoch 21 @ 38329 updates, score 31.2) (writing took 6.772096244996646 seconds)
2023-09-01 04:01:11 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-09-01 04:01:11 | INFO | train | epoch 021 | loss 1.887 | trans_loss 4.691 | nll_loss 1.902 | w2v_ctc_loss 0.689 | task_loss 3.651 | contrastive_loss 0 | total 3956.62 | n_correct 2743.3 | ppl 3.74 | accuracy 69.334 | wps 11848 | ups 1.5 | wpb 7913.2 | bsz 284.9 | num_updates 38329 | lr 7.22356e-05 | gnorm 0.546 | clip 0 | loss_scale 16 | train_wall 1105 | gb_free 15.2 | wall 28491
2023-09-01 04:01:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-09-01 04:01:11 | INFO | fairseq.trainer | begin training epoch 22
2023-09-01 04:01:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 04:02:01 | INFO | train_inner | epoch 022:     71 / 1826 loss=1.87, trans_loss=4.676, nll_loss=1.882, w2v_ctc_loss=0.668, task_loss=3.596, contrastive_loss=0, total=3950, n_correct=2755.15, ppl=3.69, accuracy=69.751, wps=6919, ups=0.88, wpb=7900, bsz=287.1, num_updates=38400, lr=7.21688e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=60, gb_free=17, wall=28542
2023-09-01 04:03:03 | INFO | train_inner | epoch 022:    171 / 1826 loss=1.877, trans_loss=4.683, nll_loss=1.891, w2v_ctc_loss=0.669, task_loss=3.759, contrastive_loss=0, total=3976.01, n_correct=2757.64, ppl=3.71, accuracy=69.357, wps=12978.4, ups=1.63, wpb=7952, bsz=292.1, num_updates=38500, lr=7.2075e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=61, gb_free=16, wall=28603
2023-09-01 04:04:04 | INFO | train_inner | epoch 022:    271 / 1826 loss=1.875, trans_loss=4.672, nll_loss=1.877, w2v_ctc_loss=0.681, task_loss=3.505, contrastive_loss=0, total=3988.08, n_correct=2779.06, ppl=3.67, accuracy=69.684, wps=12977, ups=1.63, wpb=7976.2, bsz=291.2, num_updates=38600, lr=7.19816e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=61, gb_free=12.9, wall=28665
2023-09-01 04:05:06 | INFO | train_inner | epoch 022:    371 / 1826 loss=1.877, trans_loss=4.678, nll_loss=1.885, w2v_ctc_loss=0.684, task_loss=3.415, contrastive_loss=0, total=3988.94, n_correct=2779.68, ppl=3.69, accuracy=69.685, wps=12983.7, ups=1.63, wpb=7977.9, bsz=298.9, num_updates=38700, lr=7.18885e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=61, gb_free=11.9, wall=28726
2023-09-01 04:06:07 | INFO | train_inner | epoch 022:    471 / 1826 loss=1.873, trans_loss=4.674, nll_loss=1.88, w2v_ctc_loss=0.673, task_loss=3.647, contrastive_loss=0, total=3953.34, n_correct=2756.57, ppl=3.68, accuracy=69.728, wps=12968.7, ups=1.64, wpb=7906.7, bsz=285.4, num_updates=38800, lr=7.17958e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=60, gb_free=11.7, wall=28787
2023-09-01 04:07:08 | INFO | train_inner | epoch 022:    571 / 1826 loss=1.877, trans_loss=4.686, nll_loss=1.896, w2v_ctc_loss=0.675, task_loss=3.555, contrastive_loss=0, total=3939.3, n_correct=2738.72, ppl=3.72, accuracy=69.523, wps=12876.4, ups=1.63, wpb=7878.6, bsz=291.3, num_updates=38900, lr=7.17035e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=61, gb_free=17.5, wall=28848
2023-09-01 04:08:09 | INFO | train_inner | epoch 022:    671 / 1826 loss=1.888, trans_loss=4.691, nll_loss=1.901, w2v_ctc_loss=0.688, task_loss=3.795, contrastive_loss=0, total=3954.61, n_correct=2742.97, ppl=3.73, accuracy=69.361, wps=12900.2, ups=1.63, wpb=7909.2, bsz=277.8, num_updates=39000, lr=7.16115e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=61, gb_free=17.4, wall=28910
2023-09-01 04:09:11 | INFO | train_inner | epoch 022:    771 / 1826 loss=1.888, trans_loss=4.684, nll_loss=1.892, w2v_ctc_loss=0.694, task_loss=3.892, contrastive_loss=0, total=3987.22, n_correct=2768, ppl=3.71, accuracy=69.422, wps=12937.9, ups=1.62, wpb=7974.4, bsz=277.9, num_updates=39100, lr=7.15199e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=61, gb_free=16.7, wall=28971
2023-09-01 04:10:12 | INFO | train_inner | epoch 022:    871 / 1826 loss=1.884, trans_loss=4.686, nll_loss=1.895, w2v_ctc_loss=0.691, task_loss=3.636, contrastive_loss=0, total=3990.35, n_correct=2771.97, ppl=3.72, accuracy=69.467, wps=13031.8, ups=1.63, wpb=7980.7, bsz=288.1, num_updates=39200, lr=7.14286e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=61, gb_free=15.8, wall=29032
2023-09-01 04:11:13 | INFO | train_inner | epoch 022:    971 / 1826 loss=1.882, trans_loss=4.689, nll_loss=1.9, w2v_ctc_loss=0.678, task_loss=3.575, contrastive_loss=0, total=3975.69, n_correct=2761.07, ppl=3.73, accuracy=69.449, wps=13013.2, ups=1.64, wpb=7951.4, bsz=285, num_updates=39300, lr=7.13376e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=60, gb_free=17, wall=29094
2023-09-01 04:12:14 | INFO | train_inner | epoch 022:   1071 / 1826 loss=1.889, trans_loss=4.692, nll_loss=1.902, w2v_ctc_loss=0.696, task_loss=3.747, contrastive_loss=0, total=3976.24, n_correct=2755.56, ppl=3.74, accuracy=69.301, wps=13024.7, ups=1.64, wpb=7952.5, bsz=282, num_updates=39400, lr=7.1247e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=60, gb_free=15, wall=29155
2023-09-01 04:13:15 | INFO | train_inner | epoch 022:   1171 / 1826 loss=1.885, trans_loss=4.684, nll_loss=1.893, w2v_ctc_loss=0.688, task_loss=3.791, contrastive_loss=0, total=3951.54, n_correct=2746.43, ppl=3.71, accuracy=69.503, wps=12905.3, ups=1.63, wpb=7903.1, bsz=277.9, num_updates=39500, lr=7.11568e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=61, gb_free=16.1, wall=29216
2023-09-01 04:13:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-01 04:14:17 | INFO | train_inner | epoch 022:   1272 / 1826 loss=1.881, trans_loss=4.682, nll_loss=1.891, w2v_ctc_loss=0.68, task_loss=3.705, contrastive_loss=0, total=3914.7, n_correct=2715.28, ppl=3.71, accuracy=69.361, wps=12611.7, ups=1.61, wpb=7829.4, bsz=283.2, num_updates=39600, lr=7.10669e-05, gnorm=0.549, clip=0, loss_scale=8, train_wall=62, gb_free=16.3, wall=29278
2023-09-01 04:15:19 | INFO | train_inner | epoch 022:   1372 / 1826 loss=1.883, trans_loss=4.682, nll_loss=1.89, w2v_ctc_loss=0.687, task_loss=3.697, contrastive_loss=0, total=3927.97, n_correct=2726.91, ppl=3.71, accuracy=69.423, wps=12828.8, ups=1.63, wpb=7855.9, bsz=276.4, num_updates=39700, lr=7.09773e-05, gnorm=0.542, clip=0, loss_scale=8, train_wall=61, gb_free=15.5, wall=29339
2023-09-01 04:16:20 | INFO | train_inner | epoch 022:   1472 / 1826 loss=1.886, trans_loss=4.688, nll_loss=1.899, w2v_ctc_loss=0.693, task_loss=3.509, contrastive_loss=0, total=3961.73, n_correct=2742.14, ppl=3.73, accuracy=69.216, wps=12850.9, ups=1.62, wpb=7923.5, bsz=294.1, num_updates=39800, lr=7.08881e-05, gnorm=0.545, clip=0, loss_scale=8, train_wall=61, gb_free=17.3, wall=29401
2023-09-01 04:17:21 | INFO | train_inner | epoch 022:   1572 / 1826 loss=1.877, trans_loss=4.678, nll_loss=1.885, w2v_ctc_loss=0.683, task_loss=3.506, contrastive_loss=0, total=3949.79, n_correct=2749.9, ppl=3.69, accuracy=69.621, wps=12971, ups=1.64, wpb=7899.6, bsz=289.4, num_updates=39900, lr=7.07992e-05, gnorm=0.545, clip=0, loss_scale=8, train_wall=60, gb_free=15, wall=29462
2023-09-01 04:18:22 | INFO | train_inner | epoch 022:   1672 / 1826 loss=1.882, trans_loss=4.68, nll_loss=1.888, w2v_ctc_loss=0.686, task_loss=3.641, contrastive_loss=0, total=3942.02, n_correct=2744.04, ppl=3.7, accuracy=69.61, wps=13049.8, ups=1.66, wpb=7884, bsz=283.3, num_updates=40000, lr=7.07107e-05, gnorm=0.555, clip=0, loss_scale=8, train_wall=60, gb_free=15.7, wall=29522
2023-09-01 04:18:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 04:19:00 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.777 | trans_loss 4.986 | nll_loss 2.232 | w2v_ctc_loss 1.341 | task_loss 13.641 | contrastive_loss 0 | total 3505.91 | n_correct 2436 | ppl 4.7 | accuracy 69.483 | uer 17.272 | wer 19.252 | raw_wer 19.252 | bleu 31.39 | wps 1198.9 | wpb 3505.9 | bsz 119.3 | num_updates 40000 | best_bleu 31.39
2023-09-01 04:19:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 40000 updates
2023-09-01 04:19:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_22_40000.pt
2023-09-01 04:19:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_22_40000.pt
2023-09-01 04:19:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_22_40000.pt (epoch 22 @ 40000 updates, score 31.39) (writing took 13.421580505993916 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:0')
2023-09-01 04:20:16 | INFO | train_inner | epoch 022:   1772 / 1826 loss=1.886, trans_loss=4.686, nll_loss=1.895, w2v_ctc_loss=0.686, task_loss=3.854, contrastive_loss=0, total=3933.49, n_correct=2730.88, ppl=3.72, accuracy=69.426, wps=6903.6, ups=0.88, wpb=7867, bsz=274.4, num_updates=40100, lr=7.06225e-05, gnorm=0.577, clip=0, loss_scale=8, train_wall=61, gb_free=16.2, wall=29636
2023-09-01 04:20:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:6')
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 04:21:27 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.794 | trans_loss 4.992 | nll_loss 2.238 | w2v_ctc_loss 1.382 | task_loss 13.655 | contrastive_loss 0 | total 3505.91 | n_correct 2433.55 | ppl 4.72 | accuracy 69.413 | uer 17.565 | wer 19.44 | raw_wer 19.44 | bleu 31.41 | wps 1190.7 | wpb 3505.9 | bsz 119.3 | num_updates 40154 | best_bleu 31.41
2023-09-01 04:21:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 40154 updates
2023-09-01 04:21:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-09-01 04:21:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-09-01 04:21:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt (epoch 22 @ 40154 updates, score 31.41) (writing took 12.113407922006445 seconds)
2023-09-01 04:21:40 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-09-01 04:21:40 | INFO | train | epoch 022 | loss 1.882 | trans_loss 4.683 | nll_loss 1.892 | w2v_ctc_loss 0.684 | task_loss 3.669 | contrastive_loss 0 | total 3956.25 | n_correct 2748.99 | ppl 3.71 | accuracy 69.485 | wps 11748.5 | ups 1.48 | wpb 7912.5 | bsz 284.8 | num_updates 40154 | lr 7.0575e-05 | gnorm 0.548 | clip 0 | loss_scale 8 | train_wall 1106 | gb_free 12.6 | wall 29720
2023-09-01 04:21:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-09-01 04:21:40 | INFO | fairseq.trainer | begin training epoch 23
2023-09-01 04:21:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 04:22:16 | INFO | train_inner | epoch 023:     46 / 1826 loss=1.886, trans_loss=4.685, nll_loss=1.893, w2v_ctc_loss=0.686, task_loss=4.263, contrastive_loss=0, total=3889.53, n_correct=2701.54, ppl=3.71, accuracy=69.457, wps=6463.9, ups=0.83, wpb=7779.1, bsz=263.8, num_updates=40200, lr=7.05346e-05, gnorm=0.572, clip=0, loss_scale=8, train_wall=60, gb_free=15.4, wall=29756
2023-09-01 04:23:16 | INFO | train_inner | epoch 023:    146 / 1826 loss=1.87, trans_loss=4.674, nll_loss=1.88, w2v_ctc_loss=0.672, task_loss=3.659, contrastive_loss=0, total=3974.32, n_correct=2776.64, ppl=3.68, accuracy=69.865, wps=13137.5, ups=1.65, wpb=7948.6, bsz=294.1, num_updates=40300, lr=7.0447e-05, gnorm=0.532, clip=0, loss_scale=8, train_wall=60, gb_free=15.3, wall=29817
2023-09-01 04:24:17 | INFO | train_inner | epoch 023:    246 / 1826 loss=1.873, trans_loss=4.668, nll_loss=1.871, w2v_ctc_loss=0.677, task_loss=3.789, contrastive_loss=0, total=3934.29, n_correct=2747.13, ppl=3.66, accuracy=69.825, wps=13029.7, ups=1.66, wpb=7868.6, bsz=282.4, num_updates=40400, lr=7.03598e-05, gnorm=0.546, clip=0, loss_scale=8, train_wall=60, gb_free=16.1, wall=29877
2023-09-01 04:25:17 | INFO | train_inner | epoch 023:    346 / 1826 loss=1.877, trans_loss=4.672, nll_loss=1.877, w2v_ctc_loss=0.678, task_loss=4.002, contrastive_loss=0, total=3906.92, n_correct=2724.6, ppl=3.67, accuracy=69.738, wps=12897.7, ups=1.65, wpb=7813.8, bsz=275, num_updates=40500, lr=7.02728e-05, gnorm=0.561, clip=0, loss_scale=8, train_wall=60, gb_free=14.4, wall=29938
2023-09-01 04:26:19 | INFO | train_inner | epoch 023:    446 / 1826 loss=1.866, trans_loss=4.668, nll_loss=1.871, w2v_ctc_loss=0.664, task_loss=3.579, contrastive_loss=0, total=4007.87, n_correct=2799.43, ppl=3.66, accuracy=69.848, wps=13071.5, ups=1.63, wpb=8015.7, bsz=301.9, num_updates=40600, lr=7.01862e-05, gnorm=0.546, clip=0, loss_scale=8, train_wall=61, gb_free=15.7, wall=29999
2023-09-01 04:27:20 | INFO | train_inner | epoch 023:    546 / 1826 loss=1.875, trans_loss=4.676, nll_loss=1.883, w2v_ctc_loss=0.678, task_loss=3.73, contrastive_loss=0, total=3952.3, n_correct=2755.65, ppl=3.69, accuracy=69.723, wps=12930.2, ups=1.64, wpb=7904.6, bsz=289.4, num_updates=40700, lr=7.01e-05, gnorm=0.55, clip=0, loss_scale=8, train_wall=60, gb_free=16.6, wall=30060
2023-09-01 04:28:21 | INFO | train_inner | epoch 023:    646 / 1826 loss=1.872, trans_loss=4.673, nll_loss=1.878, w2v_ctc_loss=0.671, task_loss=3.858, contrastive_loss=0, total=3963.31, n_correct=2766.48, ppl=3.68, accuracy=69.802, wps=12883.2, ups=1.63, wpb=7926.6, bsz=281.6, num_updates=40800, lr=7.0014e-05, gnorm=0.533, clip=0, loss_scale=8, train_wall=61, gb_free=12.3, wall=30122
2023-09-01 04:29:22 | INFO | train_inner | epoch 023:    746 / 1826 loss=1.874, trans_loss=4.673, nll_loss=1.878, w2v_ctc_loss=0.677, task_loss=3.861, contrastive_loss=0, total=3975.41, n_correct=2774.62, ppl=3.68, accuracy=69.795, wps=13040.3, ups=1.64, wpb=7950.8, bsz=281.8, num_updates=40900, lr=6.99284e-05, gnorm=0.547, clip=0, loss_scale=8, train_wall=60, gb_free=15.2, wall=30183
2023-09-01 04:30:23 | INFO | train_inner | epoch 023:    846 / 1826 loss=1.872, trans_loss=4.67, nll_loss=1.875, w2v_ctc_loss=0.676, task_loss=3.596, contrastive_loss=0, total=3993.74, n_correct=2787.28, ppl=3.67, accuracy=69.791, wps=13093.3, ups=1.64, wpb=7987.5, bsz=291.2, num_updates=41000, lr=6.9843e-05, gnorm=0.536, clip=0, loss_scale=8, train_wall=60, gb_free=15.9, wall=30244
2023-09-01 04:31:25 | INFO | train_inner | epoch 023:    946 / 1826 loss=1.869, trans_loss=4.666, nll_loss=1.871, w2v_ctc_loss=0.67, task_loss=3.718, contrastive_loss=0, total=3954.06, n_correct=2764.73, ppl=3.66, accuracy=69.921, wps=12899.7, ups=1.63, wpb=7908.1, bsz=285.9, num_updates=41100, lr=6.9758e-05, gnorm=0.546, clip=0, loss_scale=8, train_wall=61, gb_free=17.5, wall=30305
2023-09-01 04:31:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-01 04:32:26 | INFO | train_inner | epoch 023:   1047 / 1826 loss=1.874, trans_loss=4.67, nll_loss=1.874, w2v_ctc_loss=0.676, task_loss=3.981, contrastive_loss=0, total=3943.35, n_correct=2753.48, ppl=3.67, accuracy=69.826, wps=12776.5, ups=1.62, wpb=7886.7, bsz=276.6, num_updates=41200, lr=6.96733e-05, gnorm=0.563, clip=0, loss_scale=4, train_wall=61, gb_free=16.4, wall=30367
2023-09-01 04:33:28 | INFO | train_inner | epoch 023:   1147 / 1826 loss=1.877, trans_loss=4.673, nll_loss=1.88, w2v_ctc_loss=0.683, task_loss=3.722, contrastive_loss=0, total=3978.47, n_correct=2774.8, ppl=3.68, accuracy=69.745, wps=13002.7, ups=1.63, wpb=7956.9, bsz=292.2, num_updates=41300, lr=6.95889e-05, gnorm=0.544, clip=0, loss_scale=4, train_wall=61, gb_free=17, wall=30428
2023-09-01 04:34:28 | INFO | train_inner | epoch 023:   1247 / 1826 loss=1.869, trans_loss=4.664, nll_loss=1.868, w2v_ctc_loss=0.671, task_loss=3.797, contrastive_loss=0, total=3930.8, n_correct=2748.22, ppl=3.65, accuracy=69.915, wps=12963.6, ups=1.65, wpb=7861.6, bsz=283.6, num_updates=41400, lr=6.95048e-05, gnorm=0.556, clip=0, loss_scale=4, train_wall=60, gb_free=16.9, wall=30489
2023-09-01 04:35:30 | INFO | train_inner | epoch 023:   1347 / 1826 loss=1.888, trans_loss=4.686, nll_loss=1.896, w2v_ctc_loss=0.692, task_loss=4.048, contrastive_loss=0, total=3904.37, n_correct=2706.66, ppl=3.72, accuracy=69.324, wps=12681.2, ups=1.62, wpb=7808.7, bsz=271.4, num_updates=41500, lr=6.9421e-05, gnorm=0.562, clip=0, loss_scale=4, train_wall=61, gb_free=14.6, wall=30550
2023-09-01 04:36:31 | INFO | train_inner | epoch 023:   1447 / 1826 loss=1.88, trans_loss=4.683, nll_loss=1.892, w2v_ctc_loss=0.687, task_loss=3.658, contrastive_loss=0, total=3986.13, n_correct=2770.67, ppl=3.71, accuracy=69.508, wps=13017.6, ups=1.63, wpb=7972.3, bsz=294, num_updates=41600, lr=6.93375e-05, gnorm=0.563, clip=0, loss_scale=4, train_wall=61, gb_free=17, wall=30612
2023-09-01 04:37:32 | INFO | train_inner | epoch 023:   1547 / 1826 loss=1.875, trans_loss=4.674, nll_loss=1.88, w2v_ctc_loss=0.679, task_loss=3.772, contrastive_loss=0, total=3943.19, n_correct=2747.34, ppl=3.68, accuracy=69.673, wps=12913.7, ups=1.64, wpb=7886.4, bsz=286.6, num_updates=41700, lr=6.92543e-05, gnorm=0.553, clip=0, loss_scale=4, train_wall=60, gb_free=15.8, wall=30673
2023-09-01 04:38:33 | INFO | train_inner | epoch 023:   1647 / 1826 loss=1.876, trans_loss=4.675, nll_loss=1.882, w2v_ctc_loss=0.677, task_loss=3.623, contrastive_loss=0, total=3976.71, n_correct=2770.48, ppl=3.69, accuracy=69.668, wps=12989.6, ups=1.63, wpb=7953.4, bsz=290, num_updates=41800, lr=6.91714e-05, gnorm=0.57, clip=0, loss_scale=4, train_wall=60, gb_free=16, wall=30734
2023-09-01 04:39:35 | INFO | train_inner | epoch 023:   1747 / 1826 loss=1.886, trans_loss=4.684, nll_loss=1.893, w2v_ctc_loss=0.69, task_loss=3.864, contrastive_loss=0, total=3954.6, n_correct=2742.86, ppl=3.71, accuracy=69.359, wps=12796.8, ups=1.62, wpb=7909.2, bsz=280.1, num_updates=41900, lr=6.90889e-05, gnorm=0.598, clip=0, loss_scale=4, train_wall=61, gb_free=17.4, wall=30796
2023-09-01 04:40:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 04:41:03 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 3.805 | trans_loss 4.989 | nll_loss 2.236 | w2v_ctc_loss 1.426 | task_loss 13.636 | contrastive_loss 0 | total 3505.91 | n_correct 2430.36 | ppl 4.71 | accuracy 69.322 | uer 17.538 | wer 19.455 | raw_wer 19.455 | bleu 30.94 | wps 1202.6 | wpb 3505.9 | bsz 119.3 | num_updates 41979 | best_bleu 31.41
2023-09-01 04:41:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 41979 updates
2023-09-01 04:41:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_30.9401.pt
2023-09-01 04:41:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_30.9401.pt
2023-09-01 04:41:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_30.9401.pt (epoch 23 @ 41979 updates, score 30.94) (writing took 8.841308066999773 seconds)
2023-09-01 04:41:12 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-09-01 04:41:12 | INFO | train | epoch 023 | loss 1.875 | trans_loss 4.674 | nll_loss 1.879 | w2v_ctc_loss 0.677 | task_loss 3.797 | contrastive_loss 0 | total 3956.02 | n_correct 2758.21 | ppl 3.68 | accuracy 69.722 | wps 12316.7 | ups 1.56 | wpb 7912 | bsz 284.8 | num_updates 41979 | lr 6.90238e-05 | gnorm 0.553 | clip 0 | loss_scale 4 | train_wall 1103 | gb_free 16 | wall 30893
2023-09-01 04:41:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-09-01 04:41:12 | INFO | fairseq.trainer | begin training epoch 24
2023-09-01 04:41:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 04:41:33 | INFO | train_inner | epoch 024:     21 / 1826 loss=1.875, trans_loss=4.675, nll_loss=1.882, w2v_ctc_loss=0.667, task_loss=3.92, contrastive_loss=0, total=3955.35, n_correct=2754.26, ppl=3.69, accuracy=69.634, wps=6727.9, ups=0.85, wpb=7910.7, bsz=281.6, num_updates=42000, lr=6.90066e-05, gnorm=0.558, clip=0, loss_scale=4, train_wall=61, gb_free=16.9, wall=30913
2023-09-01 04:41:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 04:42:11 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.781 | trans_loss 4.987 | nll_loss 2.237 | w2v_ctc_loss 1.349 | task_loss 13.637 | contrastive_loss 0 | total 3505.91 | n_correct 2433.09 | ppl 4.71 | accuracy 69.4 | uer 17.323 | wer 19.252 | raw_wer 19.252 | bleu 30.84 | wps 1204 | wpb 3505.9 | bsz 119.3 | num_updates 42000 | best_bleu 31.41
2023-09-01 04:42:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 42000 updates
2023-09-01 04:42:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_24_42000.pt
2023-09-01 04:42:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_24_42000.pt
2023-09-01 04:42:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_24_42000.pt (epoch 24 @ 42000 updates, score 30.84) (writing took 7.882705230003921 seconds)
2023-09-01 04:43:20 | INFO | train_inner | epoch 024:    121 / 1826 loss=1.861, trans_loss=4.66, nll_loss=1.863, w2v_ctc_loss=0.664, task_loss=3.442, contrastive_loss=0, total=4042.13, n_correct=2831.52, ppl=3.64, accuracy=70.05, wps=7513, ups=0.93, wpb=8084.3, bsz=309.5, num_updates=42100, lr=6.89246e-05, gnorm=0.547, clip=0, loss_scale=4, train_wall=60, gb_free=15.8, wall=31021
2023-09-01 04:44:22 | INFO | train_inner | epoch 024:    221 / 1826 loss=1.859, trans_loss=4.667, nll_loss=1.871, w2v_ctc_loss=0.651, task_loss=3.357, contrastive_loss=0, total=4037.19, n_correct=2829.45, ppl=3.66, accuracy=70.085, wps=13061.5, ups=1.62, wpb=8074.4, bsz=312.2, num_updates=42200, lr=6.88428e-05, gnorm=0.54, clip=0, loss_scale=4, train_wall=61, gb_free=15.8, wall=31083
2023-09-01 04:45:24 | INFO | train_inner | epoch 024:    321 / 1826 loss=1.857, trans_loss=4.645, nll_loss=1.842, w2v_ctc_loss=0.658, task_loss=3.918, contrastive_loss=0, total=3913.82, n_correct=2751.37, ppl=3.59, accuracy=70.299, wps=12739.9, ups=1.63, wpb=7827.6, bsz=278.1, num_updates=42300, lr=6.87614e-05, gnorm=0.545, clip=0, loss_scale=4, train_wall=61, gb_free=15.9, wall=31144
2023-09-01 04:46:25 | INFO | train_inner | epoch 024:    421 / 1826 loss=1.857, trans_loss=4.645, nll_loss=1.843, w2v_ctc_loss=0.66, task_loss=3.88, contrastive_loss=0, total=3968.8, n_correct=2789.23, ppl=3.59, accuracy=70.279, wps=12927.2, ups=1.63, wpb=7937.6, bsz=281.2, num_updates=42400, lr=6.86803e-05, gnorm=0.543, clip=0, loss_scale=4, train_wall=61, gb_free=17.4, wall=31206
2023-09-01 04:47:26 | INFO | train_inner | epoch 024:    521 / 1826 loss=1.879, trans_loss=4.674, nll_loss=1.879, w2v_ctc_loss=0.681, task_loss=4.108, contrastive_loss=0, total=3896.74, n_correct=2717.1, ppl=3.68, accuracy=69.728, wps=12856.2, ups=1.65, wpb=7793.5, bsz=266, num_updates=42500, lr=6.85994e-05, gnorm=0.556, clip=0, loss_scale=4, train_wall=60, gb_free=15.9, wall=31266
2023-09-01 04:48:26 | INFO | train_inner | epoch 024:    621 / 1826 loss=1.858, trans_loss=4.658, nll_loss=1.86, w2v_ctc_loss=0.658, task_loss=3.539, contrastive_loss=0, total=4006.81, n_correct=2813.66, ppl=3.63, accuracy=70.222, wps=13193.9, ups=1.65, wpb=8013.6, bsz=295.8, num_updates=42600, lr=6.85189e-05, gnorm=0.54, clip=0, loss_scale=4, train_wall=60, gb_free=16.4, wall=31327
2023-09-01 04:49:28 | INFO | train_inner | epoch 024:    721 / 1826 loss=1.87, trans_loss=4.664, nll_loss=1.867, w2v_ctc_loss=0.672, task_loss=3.972, contrastive_loss=0, total=3924.23, n_correct=2742.78, ppl=3.65, accuracy=69.893, wps=12753.4, ups=1.62, wpb=7848.5, bsz=278.2, num_updates=42700, lr=6.84386e-05, gnorm=0.537, clip=0, loss_scale=4, train_wall=61, gb_free=16, wall=31389
2023-09-01 04:50:30 | INFO | train_inner | epoch 024:    821 / 1826 loss=1.871, trans_loss=4.67, nll_loss=1.874, w2v_ctc_loss=0.672, task_loss=3.802, contrastive_loss=0, total=3976.98, n_correct=2777.2, ppl=3.67, accuracy=69.832, wps=12850.1, ups=1.62, wpb=7954, bsz=289.8, num_updates=42800, lr=6.83586e-05, gnorm=0.536, clip=0, loss_scale=4, train_wall=61, gb_free=16.7, wall=31450
2023-09-01 04:51:31 | INFO | train_inner | epoch 024:    921 / 1826 loss=1.87, trans_loss=4.671, nll_loss=1.876, w2v_ctc_loss=0.669, task_loss=3.826, contrastive_loss=0, total=3915.33, n_correct=2734.95, ppl=3.67, accuracy=69.852, wps=12853.1, ups=1.64, wpb=7830.7, bsz=281.3, num_updates=42900, lr=6.82789e-05, gnorm=0.548, clip=0, loss_scale=4, train_wall=60, gb_free=16, wall=31511
2023-09-01 04:52:32 | INFO | train_inner | epoch 024:   1021 / 1826 loss=1.873, trans_loss=4.673, nll_loss=1.878, w2v_ctc_loss=0.67, task_loss=3.995, contrastive_loss=0, total=3931.56, n_correct=2743.77, ppl=3.68, accuracy=69.788, wps=12926.5, ups=1.64, wpb=7863.1, bsz=275.5, num_updates=43000, lr=6.81994e-05, gnorm=0.556, clip=0, loss_scale=4, train_wall=60, gb_free=14.7, wall=31572
2023-09-01 04:53:33 | INFO | train_inner | epoch 024:   1121 / 1826 loss=1.869, trans_loss=4.662, nll_loss=1.864, w2v_ctc_loss=0.673, task_loss=3.762, contrastive_loss=0, total=3998.21, n_correct=2794.4, ppl=3.64, accuracy=69.891, wps=13086.9, ups=1.64, wpb=7996.4, bsz=291.9, num_updates=43100, lr=6.81203e-05, gnorm=0.562, clip=0, loss_scale=4, train_wall=60, gb_free=16.2, wall=31633
2023-09-01 04:54:34 | INFO | train_inner | epoch 024:   1221 / 1826 loss=1.881, trans_loss=4.671, nll_loss=1.876, w2v_ctc_loss=0.688, task_loss=4.373, contrastive_loss=0, total=3888.24, n_correct=2711.24, ppl=3.67, accuracy=69.729, wps=12733.1, ups=1.64, wpb=7776.5, bsz=262.3, num_updates=43200, lr=6.80414e-05, gnorm=0.571, clip=0, loss_scale=8, train_wall=60, gb_free=15.9, wall=31694
2023-09-01 04:55:35 | INFO | train_inner | epoch 024:   1321 / 1826 loss=1.865, trans_loss=4.672, nll_loss=1.877, w2v_ctc_loss=0.659, task_loss=3.67, contrastive_loss=0, total=3953.29, n_correct=2760.92, ppl=3.67, accuracy=69.839, wps=12867.5, ups=1.63, wpb=7906.6, bsz=289.1, num_updates=43300, lr=6.79628e-05, gnorm=0.555, clip=0, loss_scale=8, train_wall=61, gb_free=16.8, wall=31756
2023-09-01 04:56:37 | INFO | train_inner | epoch 024:   1421 / 1826 loss=1.871, trans_loss=4.672, nll_loss=1.878, w2v_ctc_loss=0.67, task_loss=3.876, contrastive_loss=0, total=3998.91, n_correct=2792.18, ppl=3.67, accuracy=69.824, wps=12922.8, ups=1.62, wpb=7997.8, bsz=283.3, num_updates=43400, lr=6.78844e-05, gnorm=0.536, clip=0, loss_scale=8, train_wall=61, gb_free=16, wall=31818
2023-09-01 04:57:38 | INFO | train_inner | epoch 024:   1521 / 1826 loss=1.87, trans_loss=4.669, nll_loss=1.873, w2v_ctc_loss=0.676, task_loss=3.571, contrastive_loss=0, total=3985.88, n_correct=2784.47, ppl=3.66, accuracy=69.858, wps=13073, ups=1.64, wpb=7971.8, bsz=298.2, num_updates=43500, lr=6.78064e-05, gnorm=0.544, clip=0, loss_scale=8, train_wall=60, gb_free=15.9, wall=31879
2023-09-01 04:58:38 | INFO | train_inner | epoch 024:   1621 / 1826 loss=1.872, trans_loss=4.663, nll_loss=1.866, w2v_ctc_loss=0.674, task_loss=4.072, contrastive_loss=0, total=3870.79, n_correct=2705.48, ppl=3.64, accuracy=69.895, wps=12846.7, ups=1.66, wpb=7741.6, bsz=267.2, num_updates=43600, lr=6.77285e-05, gnorm=0.548, clip=0, loss_scale=8, train_wall=60, gb_free=14.9, wall=31939
2023-09-01 04:59:39 | INFO | train_inner | epoch 024:   1721 / 1826 loss=1.88, trans_loss=4.672, nll_loss=1.877, w2v_ctc_loss=0.691, task_loss=4.206, contrastive_loss=0, total=3920.38, n_correct=2733.7, ppl=3.67, accuracy=69.73, wps=12890.1, ups=1.64, wpb=7840.8, bsz=272.1, num_updates=43700, lr=6.7651e-05, gnorm=0.552, clip=0, loss_scale=8, train_wall=60, gb_free=16.4, wall=32000
2023-09-01 05:00:41 | INFO | train_inner | epoch 024:   1821 / 1826 loss=1.862, trans_loss=4.66, nll_loss=1.863, w2v_ctc_loss=0.666, task_loss=3.682, contrastive_loss=0, total=3990.53, n_correct=2794.04, ppl=3.64, accuracy=70.017, wps=12982.7, ups=1.63, wpb=7981.1, bsz=294.9, num_updates=43800, lr=6.75737e-05, gnorm=0.529, clip=0, loss_scale=8, train_wall=61, gb_free=16.5, wall=32061
2023-09-01 05:00:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 05:01:23 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.782 | trans_loss 4.994 | nll_loss 2.243 | w2v_ctc_loss 1.338 | task_loss 13.571 | contrastive_loss 0 | total 3505.91 | n_correct 2433.55 | ppl 4.73 | accuracy 69.413 | uer 17.522 | wer 19.388 | raw_wer 19.388 | bleu 30.86 | wps 1193.8 | wpb 3505.9 | bsz 119.3 | num_updates 43805 | best_bleu 31.41
2023-09-01 05:01:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 43805 updates
2023-09-01 05:01:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_last.pt
2023-09-01 05:01:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_last.pt
2023-09-01 05:01:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_last.pt (epoch 24 @ 43805 updates, score 30.86) (writing took 5.638356831012061 seconds)
2023-09-01 05:01:28 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-09-01 05:01:28 | INFO | train | epoch 024 | loss 1.868 | trans_loss 4.665 | nll_loss 1.868 | w2v_ctc_loss 0.669 | task_loss 3.824 | contrastive_loss 0 | total 3956.37 | n_correct 2766.69 | ppl 3.65 | accuracy 69.93 | wps 11880 | ups 1.5 | wpb 7912.7 | bsz 284.8 | num_updates 43805 | lr 6.75699e-05 | gnorm 0.547 | clip 0 | loss_scale 8 | train_wall 1105 | gb_free 17 | wall 32109
2023-09-01 05:01:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-09-01 05:01:29 | INFO | fairseq.trainer | begin training epoch 25
2023-09-01 05:01:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 05:02:34 | INFO | train_inner | epoch 025:     95 / 1826 loss=1.863, trans_loss=4.663, nll_loss=1.866, w2v_ctc_loss=0.662, task_loss=3.609, contrastive_loss=0, total=3970.23, n_correct=2779.95, ppl=3.64, accuracy=70.02, wps=7035.5, ups=0.89, wpb=7940.5, bsz=291, num_updates=43900, lr=6.74967e-05, gnorm=0.575, clip=0, loss_scale=8, train_wall=60, gb_free=12.1, wall=32174
2023-09-01 05:03:34 | INFO | train_inner | epoch 025:    195 / 1826 loss=1.855, trans_loss=4.651, nll_loss=1.851, w2v_ctc_loss=0.651, task_loss=3.567, contrastive_loss=0, total=3982.1, n_correct=2796.19, ppl=3.61, accuracy=70.219, wps=13128.7, ups=1.65, wpb=7964.2, bsz=294.3, num_updates=44000, lr=6.742e-05, gnorm=0.538, clip=0, loss_scale=8, train_wall=60, gb_free=15.4, wall=32235
2023-09-01 05:03:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 05:04:13 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.798 | trans_loss 4.992 | nll_loss 2.24 | w2v_ctc_loss 1.395 | task_loss 13.544 | contrastive_loss 0 | total 3505.91 | n_correct 2432.91 | ppl 4.72 | accuracy 69.395 | uer 17.586 | wer 19.391 | raw_wer 19.391 | bleu 31.19 | wps 1215.5 | wpb 3505.9 | bsz 119.3 | num_updates 44000 | best_bleu 31.41
2023-09-01 05:04:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 44000 updates
2023-09-01 05:04:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_25_44000.pt
2023-09-01 05:04:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_25_44000.pt
2023-09-01 05:04:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_25_44000.pt (epoch 25 @ 44000 updates, score 31.19) (writing took 7.986066252022283 seconds)
2023-09-01 05:05:23 | INFO | train_inner | epoch 025:    295 / 1826 loss=1.868, trans_loss=4.655, nll_loss=1.855, w2v_ctc_loss=0.674, task_loss=3.886, contrastive_loss=0, total=3966.94, n_correct=2778.67, ppl=3.62, accuracy=70.046, wps=7311.8, ups=0.92, wpb=7933.9, bsz=277.6, num_updates=44100, lr=6.73435e-05, gnorm=0.544, clip=0, loss_scale=8, train_wall=61, gb_free=14.5, wall=32343
2023-09-01 05:06:23 | INFO | train_inner | epoch 025:    395 / 1826 loss=1.861, trans_loss=4.654, nll_loss=1.853, w2v_ctc_loss=0.658, task_loss=3.832, contrastive_loss=0, total=3885.05, n_correct=2723.45, ppl=3.61, accuracy=70.101, wps=12848.3, ups=1.65, wpb=7770.1, bsz=268.2, num_updates=44200, lr=6.72673e-05, gnorm=0.539, clip=0, loss_scale=8, train_wall=60, gb_free=16.3, wall=32404
2023-09-01 05:07:25 | INFO | train_inner | epoch 025:    495 / 1826 loss=1.87, trans_loss=4.661, nll_loss=1.863, w2v_ctc_loss=0.67, task_loss=4.008, contrastive_loss=0, total=3898.44, n_correct=2730.13, ppl=3.64, accuracy=70.031, wps=12677.1, ups=1.63, wpb=7796.9, bsz=265.7, num_updates=44300, lr=6.71913e-05, gnorm=0.546, clip=0, loss_scale=8, train_wall=61, gb_free=16.8, wall=32465
2023-09-01 05:08:27 | INFO | train_inner | epoch 025:    595 / 1826 loss=1.864, trans_loss=4.658, nll_loss=1.858, w2v_ctc_loss=0.665, task_loss=3.727, contrastive_loss=0, total=3928.25, n_correct=2749.45, ppl=3.63, accuracy=69.992, wps=12700.6, ups=1.62, wpb=7856.5, bsz=282.2, num_updates=44400, lr=6.71156e-05, gnorm=0.533, clip=0, loss_scale=8, train_wall=61, gb_free=17.4, wall=32527
2023-09-01 05:09:28 | INFO | train_inner | epoch 025:    695 / 1826 loss=1.861, trans_loss=4.659, nll_loss=1.861, w2v_ctc_loss=0.662, task_loss=3.612, contrastive_loss=0, total=3959.17, n_correct=2778.04, ppl=3.63, accuracy=70.167, wps=12991.7, ups=1.64, wpb=7918.3, bsz=286.4, num_updates=44500, lr=6.70402e-05, gnorm=0.532, clip=0, loss_scale=8, train_wall=60, gb_free=13.6, wall=32588
2023-09-01 05:10:29 | INFO | train_inner | epoch 025:    795 / 1826 loss=1.865, trans_loss=4.662, nll_loss=1.865, w2v_ctc_loss=0.671, task_loss=3.467, contrastive_loss=0, total=3981.26, n_correct=2788.05, ppl=3.64, accuracy=70.029, wps=12985, ups=1.63, wpb=7962.5, bsz=298.5, num_updates=44600, lr=6.6965e-05, gnorm=0.535, clip=0, loss_scale=8, train_wall=61, gb_free=16.4, wall=32649
2023-09-01 05:11:31 | INFO | train_inner | epoch 025:    895 / 1826 loss=1.864, trans_loss=4.66, nll_loss=1.862, w2v_ctc_loss=0.659, task_loss=3.669, contrastive_loss=0, total=3998.11, n_correct=2800.54, ppl=3.64, accuracy=70.047, wps=12975.8, ups=1.62, wpb=7996.2, bsz=286.6, num_updates=44700, lr=6.689e-05, gnorm=0.543, clip=0, loss_scale=8, train_wall=61, gb_free=12.4, wall=32711
2023-09-01 05:12:32 | INFO | train_inner | epoch 025:    995 / 1826 loss=1.856, trans_loss=4.65, nll_loss=1.849, w2v_ctc_loss=0.655, task_loss=3.541, contrastive_loss=0, total=4040.68, n_correct=2839.89, ppl=3.6, accuracy=70.282, wps=13183.7, ups=1.63, wpb=8081.4, bsz=294.8, num_updates=44800, lr=6.68153e-05, gnorm=0.532, clip=0, loss_scale=8, train_wall=60, gb_free=16.4, wall=32772
2023-09-01 05:13:33 | INFO | train_inner | epoch 025:   1095 / 1826 loss=1.859, trans_loss=4.653, nll_loss=1.854, w2v_ctc_loss=0.661, task_loss=3.438, contrastive_loss=0, total=3961.2, n_correct=2781.55, ppl=3.61, accuracy=70.22, wps=12974.1, ups=1.64, wpb=7922.4, bsz=295.2, num_updates=44900, lr=6.67409e-05, gnorm=0.532, clip=0, loss_scale=8, train_wall=60, gb_free=12.2, wall=32833
2023-09-01 05:14:34 | INFO | train_inner | epoch 025:   1195 / 1826 loss=1.856, trans_loss=4.652, nll_loss=1.853, w2v_ctc_loss=0.655, task_loss=3.458, contrastive_loss=0, total=3998.37, n_correct=2809.33, ppl=3.61, accuracy=70.262, wps=13166.9, ups=1.65, wpb=7996.7, bsz=293.7, num_updates=45000, lr=6.66667e-05, gnorm=0.53, clip=0, loss_scale=8, train_wall=60, gb_free=16.5, wall=32894
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:0')
2023-09-01 05:15:35 | INFO | train_inner | epoch 025:   1295 / 1826 loss=1.863, trans_loss=4.656, nll_loss=1.857, w2v_ctc_loss=0.663, task_loss=3.669, contrastive_loss=0, total=3964.7, n_correct=2778.47, ppl=3.62, accuracy=70.08, wps=12892.4, ups=1.63, wpb=7929.4, bsz=288.9, num_updates=45100, lr=6.65927e-05, gnorm=0.538, clip=0, loss_scale=8, train_wall=61, gb_free=16.7, wall=32956
2023-09-01 05:16:36 | INFO | train_inner | epoch 025:   1395 / 1826 loss=1.863, trans_loss=4.649, nll_loss=1.848, w2v_ctc_loss=0.668, task_loss=3.778, contrastive_loss=0, total=3915.48, n_correct=2749.43, ppl=3.6, accuracy=70.219, wps=12876, ups=1.64, wpb=7831, bsz=273.1, num_updates=45200, lr=6.6519e-05, gnorm=0.542, clip=0, loss_scale=8, train_wall=60, gb_free=16.4, wall=33017
2023-09-01 05:17:38 | INFO | train_inner | epoch 025:   1495 / 1826 loss=1.868, trans_loss=4.661, nll_loss=1.863, w2v_ctc_loss=0.668, task_loss=3.856, contrastive_loss=0, total=3928.32, n_correct=2751.66, ppl=3.64, accuracy=70.047, wps=12754.5, ups=1.62, wpb=7856.6, bsz=272.8, num_updates=45300, lr=6.64455e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=61, gb_free=16.2, wall=33078
2023-09-01 05:18:38 | INFO | train_inner | epoch 025:   1595 / 1826 loss=1.862, trans_loss=4.657, nll_loss=1.858, w2v_ctc_loss=0.661, task_loss=3.799, contrastive_loss=0, total=3873.63, n_correct=2720.09, ppl=3.63, accuracy=70.221, wps=12771.8, ups=1.65, wpb=7747.3, bsz=271.8, num_updates=45400, lr=6.63723e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=60, gb_free=16.9, wall=33139
2023-09-01 05:19:40 | INFO | train_inner | epoch 025:   1695 / 1826 loss=1.864, trans_loss=4.66, nll_loss=1.862, w2v_ctc_loss=0.672, task_loss=3.603, contrastive_loss=0, total=3943.86, n_correct=2766.11, ppl=3.63, accuracy=70.137, wps=12870.7, ups=1.63, wpb=7887.7, bsz=287.6, num_updates=45500, lr=6.62994e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=61, gb_free=16.5, wall=33200
2023-09-01 05:20:41 | INFO | train_inner | epoch 025:   1795 / 1826 loss=1.865, trans_loss=4.668, nll_loss=1.873, w2v_ctc_loss=0.664, task_loss=3.489, contrastive_loss=0, total=3996.17, n_correct=2795.26, ppl=3.66, accuracy=69.948, wps=13088.5, ups=1.64, wpb=7992.3, bsz=297.3, num_updates=45600, lr=6.62266e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=60, gb_free=16.4, wall=33261
2023-09-01 05:21:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2325, device='cuda:5')
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 05:21:38 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.776 | trans_loss 4.984 | nll_loss 2.23 | w2v_ctc_loss 1.339 | task_loss 13.672 | contrastive_loss 0 | total 3505.91 | n_correct 2438.64 | ppl 4.69 | accuracy 69.558 | uer 17.229 | wer 19.147 | raw_wer 19.147 | bleu 31.22 | wps 1198.6 | wpb 3505.9 | bsz 119.3 | num_updates 45631 | best_bleu 31.41
2023-09-01 05:21:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 45631 updates
2023-09-01 05:21:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_31.2204.pt
2023-09-01 05:21:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_31.2204.pt
2023-09-01 05:21:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_31.2204.pt (epoch 25 @ 45631 updates, score 31.22) (writing took 7.64019425000879 seconds)
2023-09-01 05:21:46 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-09-01 05:21:46 | INFO | train | epoch 025 | loss 1.863 | trans_loss 4.657 | nll_loss 1.858 | w2v_ctc_loss 0.663 | task_loss 3.661 | contrastive_loss 0 | total 3956.37 | n_correct 2774.2 | ppl 3.62 | accuracy 70.12 | wps 11863.8 | ups 1.5 | wpb 7912.7 | bsz 284.8 | num_updates 45631 | lr 6.62041e-05 | gnorm 0.54 | clip 0 | loss_scale 16 | train_wall 1104 | gb_free 11.7 | wall 33327
2023-09-01 05:21:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-09-01 05:21:47 | INFO | fairseq.trainer | begin training epoch 26
2023-09-01 05:21:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 05:22:36 | INFO | train_inner | epoch 026:     69 / 1826 loss=1.856, trans_loss=4.637, nll_loss=1.832, w2v_ctc_loss=0.659, task_loss=3.96, contrastive_loss=0, total=3883.64, n_correct=2736.86, ppl=3.56, accuracy=70.472, wps=6709.6, ups=0.86, wpb=7767.3, bsz=266.8, num_updates=45700, lr=6.61541e-05, gnorm=0.555, clip=0, loss_scale=16, train_wall=61, gb_free=15.7, wall=33377
2023-09-01 05:23:37 | INFO | train_inner | epoch 026:    169 / 1826 loss=1.855, trans_loss=4.64, nll_loss=1.837, w2v_ctc_loss=0.655, task_loss=3.815, contrastive_loss=0, total=3922.68, n_correct=2761.54, ppl=3.57, accuracy=70.399, wps=12888.7, ups=1.64, wpb=7845.4, bsz=272.5, num_updates=45800, lr=6.60819e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=60, gb_free=10.4, wall=33438
2023-09-01 05:24:39 | INFO | train_inner | epoch 026:    269 / 1826 loss=1.854, trans_loss=4.646, nll_loss=1.844, w2v_ctc_loss=0.656, task_loss=3.591, contrastive_loss=0, total=3955.67, n_correct=2783.99, ppl=3.59, accuracy=70.38, wps=12915.6, ups=1.63, wpb=7911.3, bsz=290, num_updates=45900, lr=6.60098e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=61, gb_free=15.3, wall=33499
2023-09-01 05:25:40 | INFO | train_inner | epoch 026:    369 / 1826 loss=1.855, trans_loss=4.65, nll_loss=1.849, w2v_ctc_loss=0.655, task_loss=3.556, contrastive_loss=0, total=3975.9, n_correct=2794.31, ppl=3.6, accuracy=70.281, wps=12975.9, ups=1.63, wpb=7951.8, bsz=288.5, num_updates=46000, lr=6.5938e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=61, gb_free=15.7, wall=33560
2023-09-01 05:25:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 05:26:18 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.788 | trans_loss 4.994 | nll_loss 2.24 | w2v_ctc_loss 1.356 | task_loss 13.63 | contrastive_loss 0 | total 3505.91 | n_correct 2433.91 | ppl 4.72 | accuracy 69.423 | uer 17.28 | wer 19.2 | raw_wer 19.2 | bleu 31.46 | wps 1201.1 | wpb 3505.9 | bsz 119.3 | num_updates 46000 | best_bleu 31.46
2023-09-01 05:26:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 46000 updates
2023-09-01 05:26:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_26_46000.pt
2023-09-01 05:26:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_26_46000.pt
2023-09-01 05:26:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_26_46000.pt (epoch 26 @ 46000 updates, score 31.46) (writing took 13.022498675010866 seconds)
2023-09-01 05:27:33 | INFO | train_inner | epoch 026:    469 / 1826 loss=1.848, trans_loss=4.65, nll_loss=1.849, w2v_ctc_loss=0.638, task_loss=3.39, contrastive_loss=0, total=3986.08, n_correct=2803.65, ppl=3.6, accuracy=70.336, wps=7071.3, ups=0.89, wpb=7972.2, bsz=302.7, num_updates=46100, lr=6.58665e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=60, gb_free=17.5, wall=33673
2023-09-01 05:28:34 | INFO | train_inner | epoch 026:    569 / 1826 loss=1.852, trans_loss=4.648, nll_loss=1.846, w2v_ctc_loss=0.648, task_loss=3.404, contrastive_loss=0, total=4013.92, n_correct=2822.39, ppl=3.6, accuracy=70.315, wps=13060.3, ups=1.63, wpb=8027.8, bsz=304.9, num_updates=46200, lr=6.57952e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=61, gb_free=17.3, wall=33735
2023-09-01 05:29:35 | INFO | train_inner | epoch 026:    669 / 1826 loss=1.851, trans_loss=4.646, nll_loss=1.844, w2v_ctc_loss=0.647, task_loss=3.506, contrastive_loss=0, total=3979.41, n_correct=2801.14, ppl=3.59, accuracy=70.391, wps=13090.1, ups=1.64, wpb=7958.8, bsz=291.9, num_updates=46300, lr=6.57241e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=60, gb_free=15.7, wall=33795
2023-09-01 05:30:35 | INFO | train_inner | epoch 026:    769 / 1826 loss=1.862, trans_loss=4.658, nll_loss=1.858, w2v_ctc_loss=0.658, task_loss=3.826, contrastive_loss=0, total=3918.01, n_correct=2748.25, ppl=3.63, accuracy=70.144, wps=12939.2, ups=1.65, wpb=7836, bsz=271.5, num_updates=46400, lr=6.56532e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=60, gb_free=15.7, wall=33856
2023-09-01 05:31:37 | INFO | train_inner | epoch 026:    869 / 1826 loss=1.851, trans_loss=4.647, nll_loss=1.845, w2v_ctc_loss=0.647, task_loss=3.431, contrastive_loss=0, total=3983.54, n_correct=2806.85, ppl=3.59, accuracy=70.461, wps=12947.5, ups=1.63, wpb=7967.1, bsz=293.5, num_updates=46500, lr=6.55826e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=61, gb_free=15.9, wall=33917
2023-09-01 05:32:38 | INFO | train_inner | epoch 026:    969 / 1826 loss=1.861, trans_loss=4.652, nll_loss=1.851, w2v_ctc_loss=0.663, task_loss=3.676, contrastive_loss=0, total=3956.23, n_correct=2776.94, ppl=3.61, accuracy=70.192, wps=12851.6, ups=1.62, wpb=7912.5, bsz=282, num_updates=46600, lr=6.55122e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=61, gb_free=12.6, wall=33979
2023-09-01 05:33:39 | INFO | train_inner | epoch 026:   1069 / 1826 loss=1.855, trans_loss=4.643, nll_loss=1.84, w2v_ctc_loss=0.655, task_loss=3.706, contrastive_loss=0, total=3958.02, n_correct=2786.7, ppl=3.58, accuracy=70.406, wps=13006.8, ups=1.64, wpb=7916, bsz=281, num_updates=46700, lr=6.5442e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=60, gb_free=16.3, wall=34040
2023-09-01 05:34:40 | INFO | train_inner | epoch 026:   1169 / 1826 loss=1.854, trans_loss=4.653, nll_loss=1.853, w2v_ctc_loss=0.649, task_loss=3.502, contrastive_loss=0, total=4001.55, n_correct=2809.23, ppl=3.61, accuracy=70.204, wps=13213.8, ups=1.65, wpb=8003.1, bsz=290.8, num_updates=46800, lr=6.5372e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=60, gb_free=12.8, wall=34100
2023-09-01 05:35:42 | INFO | train_inner | epoch 026:   1269 / 1826 loss=1.857, trans_loss=4.65, nll_loss=1.849, w2v_ctc_loss=0.656, task_loss=3.622, contrastive_loss=0, total=3997.69, n_correct=2812.45, ppl=3.6, accuracy=70.352, wps=12976.6, ups=1.62, wpb=7995.4, bsz=289.2, num_updates=46900, lr=6.53023e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=61, gb_free=11.4, wall=34162
2023-09-01 05:36:44 | INFO | train_inner | epoch 026:   1369 / 1826 loss=1.863, trans_loss=4.649, nll_loss=1.848, w2v_ctc_loss=0.67, task_loss=3.84, contrastive_loss=0, total=3928.18, n_correct=2760.94, ppl=3.6, accuracy=70.285, wps=12680.4, ups=1.61, wpb=7856.4, bsz=275.9, num_updates=47000, lr=6.52328e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=61, gb_free=13.4, wall=34224
2023-09-01 05:37:45 | INFO | train_inner | epoch 026:   1469 / 1826 loss=1.861, trans_loss=4.649, nll_loss=1.848, w2v_ctc_loss=0.665, task_loss=3.855, contrastive_loss=0, total=3922.42, n_correct=2751.95, ppl=3.6, accuracy=70.159, wps=12745.1, ups=1.62, wpb=7844.8, bsz=278.3, num_updates=47100, lr=6.51635e-05, gnorm=0.557, clip=0, loss_scale=16, train_wall=61, gb_free=15.1, wall=34286
2023-09-01 05:38:46 | INFO | train_inner | epoch 026:   1569 / 1826 loss=1.861, trans_loss=4.646, nll_loss=1.843, w2v_ctc_loss=0.665, task_loss=4.03, contrastive_loss=0, total=3887.38, n_correct=2733.05, ppl=3.59, accuracy=70.306, wps=12741, ups=1.64, wpb=7774.8, bsz=264.3, num_updates=47200, lr=6.50945e-05, gnorm=0.553, clip=0, loss_scale=16, train_wall=60, gb_free=13.4, wall=34347
2023-09-01 05:39:48 | INFO | train_inner | epoch 026:   1669 / 1826 loss=1.854, trans_loss=4.647, nll_loss=1.845, w2v_ctc_loss=0.655, task_loss=3.721, contrastive_loss=0, total=3953.73, n_correct=2785.19, ppl=3.59, accuracy=70.445, wps=12866.9, ups=1.63, wpb=7907.5, bsz=283.7, num_updates=47300, lr=6.50256e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=61, gb_free=14, wall=34408
2023-09-01 05:40:49 | INFO | train_inner | epoch 026:   1769 / 1826 loss=1.858, trans_loss=4.655, nll_loss=1.857, w2v_ctc_loss=0.662, task_loss=3.474, contrastive_loss=0, total=4017.38, n_correct=2823.26, ppl=3.62, accuracy=70.276, wps=13103.6, ups=1.63, wpb=8034.8, bsz=298.5, num_updates=47400, lr=6.4957e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=61, gb_free=16.2, wall=34469
2023-09-01 05:41:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 05:42:02 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.806 | trans_loss 4.979 | nll_loss 2.225 | w2v_ctc_loss 1.453 | task_loss 13.695 | contrastive_loss 0 | total 3505.91 | n_correct 2435.64 | ppl 4.68 | accuracy 69.472 | uer 17.396 | wer 19.185 | raw_wer 19.185 | bleu 31.41 | wps 1188.3 | wpb 3505.9 | bsz 119.3 | num_updates 47457 | best_bleu 31.46
2023-09-01 05:42:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 47457 updates
2023-09-01 05:42:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_31.4103.pt
2023-09-01 05:42:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_31.4103.pt
2023-09-01 05:42:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint.best_bleu_31.4103.pt (epoch 26 @ 47457 updates, score 31.41) (writing took 7.879664448002586 seconds)
2023-09-01 05:42:10 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-09-01 05:42:10 | INFO | train | epoch 026 | loss 1.856 | trans_loss 4.648 | nll_loss 1.847 | w2v_ctc_loss 0.655 | task_loss 3.652 | contrastive_loss 0 | total 3956.37 | n_correct 2782.05 | ppl 3.6 | accuracy 70.318 | wps 11803.2 | ups 1.49 | wpb 7912.7 | bsz 284.8 | num_updates 47457 | lr 6.4918e-05 | gnorm 0.542 | clip 0 | loss_scale 32 | train_wall 1105 | gb_free 15.2 | wall 34551
2023-09-01 05:42:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-09-01 05:42:11 | INFO | fairseq.trainer | begin training epoch 27
2023-09-01 05:42:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 05:42:44 | INFO | train_inner | epoch 027:     43 / 1826 loss=1.853, trans_loss=4.645, nll_loss=1.844, w2v_ctc_loss=0.653, task_loss=3.664, contrastive_loss=0, total=3899.54, n_correct=2746.29, ppl=3.59, accuracy=70.426, wps=6751.7, ups=0.87, wpb=7799.1, bsz=282.4, num_updates=47500, lr=6.48886e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=34585
2023-09-01 05:43:45 | INFO | train_inner | epoch 027:    143 / 1826 loss=1.845, trans_loss=4.63, nll_loss=1.823, w2v_ctc_loss=0.644, task_loss=3.715, contrastive_loss=0, total=3939.29, n_correct=2788.59, ppl=3.54, accuracy=70.789, wps=12968.7, ups=1.65, wpb=7878.6, bsz=281.2, num_updates=47600, lr=6.48204e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=34646
2023-09-01 05:44:46 | INFO | train_inner | epoch 027:    243 / 1826 loss=1.85, trans_loss=4.637, nll_loss=1.833, w2v_ctc_loss=0.651, task_loss=3.713, contrastive_loss=0, total=3935.31, n_correct=2778.33, ppl=3.56, accuracy=70.6, wps=12908.4, ups=1.64, wpb=7870.6, bsz=282.4, num_updates=47700, lr=6.47524e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=34707
2023-09-01 05:45:47 | INFO | train_inner | epoch 027:    343 / 1826 loss=1.85, trans_loss=4.643, nll_loss=1.841, w2v_ctc_loss=0.654, task_loss=3.419, contrastive_loss=0, total=3977.26, n_correct=2805.32, ppl=3.58, accuracy=70.534, wps=13075.4, ups=1.64, wpb=7954.5, bsz=299.6, num_updates=47800, lr=6.46846e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=60, gb_free=15.1, wall=34767
2023-09-01 05:46:48 | INFO | train_inner | epoch 027:    443 / 1826 loss=1.842, trans_loss=4.627, nll_loss=1.82, w2v_ctc_loss=0.64, task_loss=3.81, contrastive_loss=0, total=3898.01, n_correct=2763.01, ppl=3.53, accuracy=70.883, wps=12714.2, ups=1.63, wpb=7796, bsz=275.4, num_updates=47900, lr=6.46171e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=61, gb_free=13.3, wall=34829
2023-09-01 05:47:50 | INFO | train_inner | epoch 027:    543 / 1826 loss=1.845, trans_loss=4.637, nll_loss=1.833, w2v_ctc_loss=0.647, task_loss=3.373, contrastive_loss=0, total=4050.41, n_correct=2859.5, ppl=3.56, accuracy=70.598, wps=13114.6, ups=1.62, wpb=8100.8, bsz=302.8, num_updates=48000, lr=6.45497e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=61, gb_free=12.6, wall=34891
2023-09-01 05:47:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 05:48:29 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.794 | trans_loss 4.986 | nll_loss 2.229 | w2v_ctc_loss 1.394 | task_loss 13.662 | contrastive_loss 0 | total 3505.91 | n_correct 2435.09 | ppl 4.69 | accuracy 69.457 | uer 17.315 | wer 19.136 | raw_wer 19.136 | bleu 31.35 | wps 1194.5 | wpb 3505.9 | bsz 119.3 | num_updates 48000 | best_bleu 31.46
2023-09-01 05:48:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 48000 updates
2023-09-01 05:48:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_27_48000.pt
2023-09-01 05:48:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_27_48000.pt
2023-09-01 05:48:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_27_48000.pt (epoch 27 @ 48000 updates, score 31.35) (writing took 7.129197926988127 seconds)
2023-09-01 05:49:37 | INFO | train_inner | epoch 027:    643 / 1826 loss=1.859, trans_loss=4.651, nll_loss=1.85, w2v_ctc_loss=0.656, task_loss=3.829, contrastive_loss=0, total=3878.27, n_correct=2723.05, ppl=3.61, accuracy=70.213, wps=7224.9, ups=0.93, wpb=7756.5, bsz=270.2, num_updates=48100, lr=6.44826e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=60, gb_free=12.4, wall=34998
2023-09-01 05:50:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-01 05:50:39 | INFO | train_inner | epoch 027:    744 / 1826 loss=1.849, trans_loss=4.636, nll_loss=1.831, w2v_ctc_loss=0.65, task_loss=3.689, contrastive_loss=0, total=3907.68, n_correct=2757.62, ppl=3.56, accuracy=70.569, wps=12644.1, ups=1.62, wpb=7815.4, bsz=283.3, num_updates=48200, lr=6.44157e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=61, gb_free=14.4, wall=35060
2023-09-01 05:51:41 | INFO | train_inner | epoch 027:    844 / 1826 loss=1.846, trans_loss=4.641, nll_loss=1.838, w2v_ctc_loss=0.64, task_loss=3.473, contrastive_loss=0, total=4057.35, n_correct=2858.88, ppl=3.58, accuracy=70.462, wps=13137.6, ups=1.62, wpb=8114.7, bsz=301.7, num_updates=48300, lr=6.43489e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=61, gb_free=14.8, wall=35122
2023-09-01 05:52:43 | INFO | train_inner | epoch 027:    944 / 1826 loss=1.856, trans_loss=4.647, nll_loss=1.845, w2v_ctc_loss=0.653, task_loss=3.837, contrastive_loss=0, total=3973.47, n_correct=2794.64, ppl=3.59, accuracy=70.332, wps=12865.8, ups=1.62, wpb=7946.9, bsz=278.7, num_updates=48400, lr=6.42824e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=61, gb_free=15.2, wall=35183
2023-09-01 05:53:44 | INFO | train_inner | epoch 027:   1044 / 1826 loss=1.852, trans_loss=4.641, nll_loss=1.838, w2v_ctc_loss=0.651, task_loss=3.77, contrastive_loss=0, total=3959.34, n_correct=2792.08, ppl=3.57, accuracy=70.519, wps=12995.8, ups=1.64, wpb=7918.7, bsz=277.2, num_updates=48500, lr=6.42161e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=60, gb_free=14.9, wall=35244
2023-09-01 05:54:45 | INFO | train_inner | epoch 027:   1144 / 1826 loss=1.856, trans_loss=4.647, nll_loss=1.846, w2v_ctc_loss=0.658, task_loss=3.682, contrastive_loss=0, total=3956.13, n_correct=2784.12, ppl=3.59, accuracy=70.375, wps=12977.9, ups=1.64, wpb=7912.3, bsz=281.5, num_updates=48600, lr=6.415e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=60, gb_free=13.5, wall=35305
2023-09-01 05:55:46 | INFO | train_inner | epoch 027:   1244 / 1826 loss=1.853, trans_loss=4.643, nll_loss=1.841, w2v_ctc_loss=0.653, task_loss=3.673, contrastive_loss=0, total=3954.01, n_correct=2786.59, ppl=3.58, accuracy=70.475, wps=12950.1, ups=1.64, wpb=7908, bsz=284.8, num_updates=48700, lr=6.40841e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=60, gb_free=15, wall=35366
2023-09-01 05:56:47 | INFO | train_inner | epoch 027:   1344 / 1826 loss=1.849, trans_loss=4.632, nll_loss=1.826, w2v_ctc_loss=0.653, task_loss=3.716, contrastive_loss=0, total=3965.92, n_correct=2800.75, ppl=3.54, accuracy=70.62, wps=13037.1, ups=1.64, wpb=7931.8, bsz=282.6, num_updates=48800, lr=6.40184e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=60, gb_free=11.7, wall=35427
2023-09-01 05:57:48 | INFO | train_inner | epoch 027:   1444 / 1826 loss=1.856, trans_loss=4.645, nll_loss=1.842, w2v_ctc_loss=0.657, task_loss=3.814, contrastive_loss=0, total=3966.23, n_correct=2789.6, ppl=3.59, accuracy=70.334, wps=12959.2, ups=1.63, wpb=7932.5, bsz=278.6, num_updates=48900, lr=6.39529e-05, gnorm=0.562, clip=0, loss_scale=16, train_wall=61, gb_free=16, wall=35488
2023-09-01 05:58:49 | INFO | train_inner | epoch 027:   1544 / 1826 loss=1.857, trans_loss=4.642, nll_loss=1.839, w2v_ctc_loss=0.662, task_loss=3.849, contrastive_loss=0, total=3892.39, n_correct=2739.94, ppl=3.58, accuracy=70.392, wps=12696.9, ups=1.63, wpb=7784.8, bsz=271.8, num_updates=49000, lr=6.38877e-05, gnorm=0.591, clip=0, loss_scale=16, train_wall=61, gb_free=15.3, wall=35550
2023-09-01 05:59:50 | INFO | train_inner | epoch 027:   1644 / 1826 loss=1.852, trans_loss=4.646, nll_loss=1.844, w2v_ctc_loss=0.646, task_loss=3.591, contrastive_loss=0, total=3958.49, n_correct=2785.7, ppl=3.59, accuracy=70.373, wps=12956.4, ups=1.64, wpb=7917, bsz=287.1, num_updates=49100, lr=6.38226e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=60, gb_free=15.9, wall=35611
2023-09-01 06:00:51 | INFO | train_inner | epoch 027:   1744 / 1826 loss=1.854, trans_loss=4.656, nll_loss=1.857, w2v_ctc_loss=0.649, task_loss=3.467, contrastive_loss=0, total=3996.35, n_correct=2809.95, ppl=3.62, accuracy=70.313, wps=13086.8, ups=1.64, wpb=7992.7, bsz=295.8, num_updates=49200, lr=6.37577e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=60, gb_free=16.8, wall=35672
2023-09-01 06:01:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 06:02:20 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.8 | trans_loss 4.983 | nll_loss 2.229 | w2v_ctc_loss 1.424 | task_loss 13.683 | contrastive_loss 0 | total 3505.91 | n_correct 2438 | ppl 4.69 | accuracy 69.54 | uer 17.468 | wer 19.324 | raw_wer 19.324 | bleu 31.65 | wps 1210.3 | wpb 3505.9 | bsz 119.3 | num_updates 49282 | best_bleu 31.65
2023-09-01 06:02:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 49282 updates
2023-09-01 06:02:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-09-01 06:02:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt
2023-09-01 06:02:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_best.pt (epoch 27 @ 49282 updates, score 31.65) (writing took 12.234808205015725 seconds)
2023-09-01 06:02:32 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-09-01 06:02:32 | INFO | train | epoch 027 | loss 1.851 | trans_loss 4.641 | nll_loss 1.838 | w2v_ctc_loss 0.651 | task_loss 3.652 | contrastive_loss 0 | total 3956.55 | n_correct 2789.42 | ppl 3.57 | accuracy 70.501 | wps 11819 | ups 1.49 | wpb 7913.1 | bsz 284.9 | num_updates 49282 | lr 6.37046e-05 | gnorm 0.548 | clip 0 | loss_scale 16 | train_wall 1105 | gb_free 16.8 | wall 35773
2023-09-01 06:02:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-09-01 06:02:33 | INFO | fairseq.trainer | begin training epoch 28
2023-09-01 06:02:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 06:02:51 | INFO | train_inner | epoch 028:     18 / 1826 loss=1.844, trans_loss=4.637, nll_loss=1.833, w2v_ctc_loss=0.646, task_loss=3.278, contrastive_loss=0, total=3975.26, n_correct=2810.5, ppl=3.56, accuracy=70.7, wps=6660.3, ups=0.84, wpb=7950.5, bsz=299.3, num_updates=49300, lr=6.3693e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=60, gb_free=16.1, wall=35791
2023-09-01 06:03:52 | INFO | train_inner | epoch 028:    118 / 1826 loss=1.841, trans_loss=4.625, nll_loss=1.817, w2v_ctc_loss=0.642, task_loss=3.668, contrastive_loss=0, total=3918.82, n_correct=2782.74, ppl=3.52, accuracy=71.01, wps=12829.6, ups=1.64, wpb=7837.6, bsz=280.7, num_updates=49400, lr=6.36285e-05, gnorm=0.578, clip=0, loss_scale=16, train_wall=61, gb_free=17.4, wall=35852
2023-09-01 06:04:54 | INFO | train_inner | epoch 028:    218 / 1826 loss=1.845, trans_loss=4.627, nll_loss=1.82, w2v_ctc_loss=0.646, task_loss=3.747, contrastive_loss=0, total=3979.35, n_correct=2815.6, ppl=3.53, accuracy=70.755, wps=12829.6, ups=1.61, wpb=7958.7, bsz=281.6, num_updates=49500, lr=6.35642e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=61, gb_free=17.2, wall=35914
2023-09-01 06:05:55 | INFO | train_inner | epoch 028:    318 / 1826 loss=1.844, trans_loss=4.632, nll_loss=1.825, w2v_ctc_loss=0.645, task_loss=3.59, contrastive_loss=0, total=3982.05, n_correct=2812.56, ppl=3.54, accuracy=70.631, wps=12998.1, ups=1.63, wpb=7964.1, bsz=290.7, num_updates=49600, lr=6.35001e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=61, gb_free=15.8, wall=35976
2023-09-01 06:06:56 | INFO | train_inner | epoch 028:    418 / 1826 loss=1.841, trans_loss=4.629, nll_loss=1.822, w2v_ctc_loss=0.644, task_loss=3.38, contrastive_loss=0, total=4004.2, n_correct=2836.45, ppl=3.54, accuracy=70.837, wps=13200.2, ups=1.65, wpb=8008.4, bsz=298.8, num_updates=49700, lr=6.34361e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=60, gb_free=15.5, wall=36036
2023-09-01 06:07:57 | INFO | train_inner | epoch 028:    518 / 1826 loss=1.856, trans_loss=4.643, nll_loss=1.84, w2v_ctc_loss=0.655, task_loss=3.809, contrastive_loss=0, total=3954.13, n_correct=2784.15, ppl=3.58, accuracy=70.411, wps=12967.6, ups=1.64, wpb=7908.3, bsz=278.1, num_updates=49800, lr=6.33724e-05, gnorm=0.615, clip=0, loss_scale=16, train_wall=60, gb_free=16.5, wall=36097
2023-09-01 06:08:58 | INFO | train_inner | epoch 028:    618 / 1826 loss=1.844, trans_loss=4.629, nll_loss=1.822, w2v_ctc_loss=0.643, task_loss=3.669, contrastive_loss=0, total=3934.8, n_correct=2780.42, ppl=3.53, accuracy=70.662, wps=12779, ups=1.62, wpb=7869.6, bsz=286.8, num_updates=49900, lr=6.33089e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=61, gb_free=15, wall=36159
2023-09-01 06:09:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-01 06:10:00 | INFO | train_inner | epoch 028:    719 / 1826 loss=1.853, trans_loss=4.644, nll_loss=1.842, w2v_ctc_loss=0.648, task_loss=3.757, contrastive_loss=0, total=3930.56, n_correct=2768.02, ppl=3.58, accuracy=70.423, wps=12797.3, ups=1.63, wpb=7861.1, bsz=278.2, num_updates=50000, lr=6.32456e-05, gnorm=0.593, clip=0, loss_scale=8, train_wall=61, gb_free=16.6, wall=36220
2023-09-01 06:10:00 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-09-01 06:10:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-09-01 06:10:41 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.778 | trans_loss 4.98 | nll_loss 2.223 | w2v_ctc_loss 1.356 | task_loss 13.638 | contrastive_loss 0 | total 3505.91 | n_correct 2440.27 | ppl 4.67 | accuracy 69.605 | uer 17.457 | wer 19.373 | raw_wer 19.373 | bleu 31.76 | wps 1143.7 | wpb 3505.9 | bsz 119.3 | num_updates 50000 | best_bleu 31.76
2023-09-01 06:10:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 50000 updates
2023-09-01 06:10:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_28_50000.pt
2023-09-01 06:10:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_28_50000.pt
2023-09-01 06:10:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd_turnid/checkpoint_28_50000.pt (epoch 28 @ 50000 updates, score 31.76) (writing took 13.99022765600239 seconds)
2023-09-01 06:10:56 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-09-01 06:10:56 | INFO | train | epoch 028 | loss 1.845 | trans_loss 4.632 | nll_loss 1.826 | w2v_ctc_loss 0.645 | task_loss 3.639 | contrastive_loss 0 | total 3958.3 | n_correct 2798.22 | ppl 3.55 | accuracy 70.693 | wps 11290.5 | ups 1.43 | wpb 7916.6 | bsz 285.8 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.565 | clip 0 | loss_scale 8 | train_wall 435 | gb_free 16.6 | wall 36276
2023-09-01 06:10:56 | INFO | fairseq_cli.train | done training in 36224.9 seconds
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    raise EOFError
EOFError
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    raise EOFError
EOFError
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1280 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
