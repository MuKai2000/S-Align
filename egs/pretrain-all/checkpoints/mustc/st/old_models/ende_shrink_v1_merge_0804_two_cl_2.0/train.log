2023-08-04 23:59:23 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:14716
2023-08-04 23:59:23 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:14716
2023-08-04 23:59:23 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:14716
2023-08-04 23:59:23 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:14716
2023-08-04 23:59:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-04 23:59:23 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:14716
2023-08-04 23:59:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-04 23:59:24 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:14716
2023-08-04 23:59:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-04 23:59:24 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:14716
2023-08-04 23:59:24 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:14716
2023-08-04 23:59:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-04 23:59:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-04 23:59:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-04 23:59:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-04 23:59:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-04 23:59:24 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 23:59:24 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-08-04 23:59:24 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 23:59:24 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-08-04 23:59:24 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 23:59:24 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 23:59:24 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 23:59:24 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-08-04 23:59:24 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-08-04 23:59:24 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 23:59:24 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-08-04 23:59:24 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-08-04 23:59:24 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 23:59:24 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 23:59:24 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-08-04 23:59:24 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-08-04 23:59:28 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:14716', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=2.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=True, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=2.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=True, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=2.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=True, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-04 23:59:28 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-04 23:59:28 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-04 23:59:28 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-04 23:59:28 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-04 23:59:28 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-04 23:59:33 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-04 23:59:33 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-04 23:59:33 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-04 23:59:35 | INFO | root | load pretrained hubert
2023-08-04 23:59:38 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-04 23:59:38 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-04 23:59:39 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-04 23:59:39 | INFO | root | share the sematic adapter and textual encoder
2023-08-04 23:59:39 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-04 23:59:39 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-04 23:59:39 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-04 23:59:39 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-04 23:59:39 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-08-04 23:59:39 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-04 23:59:39 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-04 23:59:39 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-04 23:59:39 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-04 23:59:39 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-04 23:59:45 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-04 23:59:46 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-04 23:59:46 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-04 23:59:47 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-04 23:59:47 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 23:59:47 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 23:59:47 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 23:59:47 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 23:59:47 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 23:59:47 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 23:59:47 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 23:59:47 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 23:59:47 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-04 23:59:47 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-04 23:59:47 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-04 23:59:47 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_last.pt
2023-08-04 23:59:47 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_last.pt
2023-08-04 23:59:47 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-04 23:59:47 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-04 23:59:47 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-04 23:59:47 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-04 23:59:49 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-04 23:59:50 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-05 00:00:39 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-05 00:00:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 00:00:39 | INFO | fairseq.trainer | begin training epoch 1
2023-08-05 00:00:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 00:01:54 | INFO | train_inner | epoch 001:    100 / 1474 loss=21.471, trans_loss=5.599, nll_loss=4.163, w2v_ctc_loss=23.052, task_loss=0, contrastive_loss=3.325, total=4207.04, n_correct=209.12, ppl=17.92, accuracy=4.971, wps=20433.4, ups=1.63, wpb=12551.1, bsz=471.4, num_updates=100, lr=4.098e-06, gnorm=0.985, clip=0, loss_scale=128, train_wall=66, gb_free=19.5, wall=127
2023-08-05 00:02:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-05 00:02:56 | INFO | train_inner | epoch 001:    201 / 1474 loss=19.322, trans_loss=5.469, nll_loss=4.053, w2v_ctc_loss=19.995, task_loss=0, contrastive_loss=3.285, total=4123.37, n_correct=224.33, ppl=16.6, accuracy=5.44, wps=19690.7, ups=1.6, wpb=12310.5, bsz=462.6, num_updates=200, lr=8.096e-06, gnorm=3.613, clip=0, loss_scale=64, train_wall=62, gb_free=19.2, wall=189
2023-08-05 00:03:57 | INFO | train_inner | epoch 001:    301 / 1474 loss=12.122, trans_loss=5.494, nll_loss=4.137, w2v_ctc_loss=9.022, task_loss=0, contrastive_loss=3.202, total=4079.62, n_correct=203.58, ppl=17.6, accuracy=4.99, wps=20001.2, ups=1.64, wpb=12186.7, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=4.754, clip=0, loss_scale=64, train_wall=60, gb_free=19.9, wall=250
2023-08-05 00:04:58 | INFO | train_inner | epoch 001:    401 / 1474 loss=10.845, trans_loss=5.519, nll_loss=4.193, w2v_ctc_loss=6.977, task_loss=0, contrastive_loss=3.233, total=4174.14, n_correct=195.09, ppl=18.28, accuracy=4.674, wps=20398.5, ups=1.64, wpb=12463.5, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=3.016, clip=0, loss_scale=64, train_wall=61, gb_free=18.9, wall=311
2023-08-05 00:06:00 | INFO | train_inner | epoch 001:    501 / 1474 loss=10.399, trans_loss=5.499, nll_loss=4.181, w2v_ctc_loss=6.338, task_loss=0, contrastive_loss=3.217, total=4176.18, n_correct=186.69, ppl=18.14, accuracy=4.47, wps=20375.8, ups=1.63, wpb=12479.7, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=1.496, clip=0, loss_scale=64, train_wall=61, gb_free=19.2, wall=372
2023-08-05 00:07:02 | INFO | train_inner | epoch 001:    601 / 1474 loss=10.099, trans_loss=5.521, nll_loss=4.209, w2v_ctc_loss=5.978, task_loss=0, contrastive_loss=3.257, total=4147.79, n_correct=193.24, ppl=18.49, accuracy=4.659, wps=19780.4, ups=1.6, wpb=12371.6, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.936, clip=0, loss_scale=64, train_wall=62, gb_free=19, wall=435
2023-08-05 00:08:03 | INFO | train_inner | epoch 001:    701 / 1474 loss=9.813, trans_loss=5.502, nll_loss=4.196, w2v_ctc_loss=5.873, task_loss=0, contrastive_loss=2.983, total=4152.1, n_correct=217.61, ppl=18.33, accuracy=5.241, wps=20437.4, ups=1.65, wpb=12395.5, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=1.096, clip=0, loss_scale=64, train_wall=60, gb_free=19.5, wall=496
2023-08-05 00:09:03 | INFO | train_inner | epoch 001:    801 / 1474 loss=9.505, trans_loss=5.446, nll_loss=4.139, w2v_ctc_loss=5.715, task_loss=0, contrastive_loss=2.897, total=4123.83, n_correct=255.34, ppl=17.62, accuracy=6.192, wps=20267.6, ups=1.65, wpb=12306.1, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=1.594, clip=0, loss_scale=64, train_wall=60, gb_free=19.2, wall=556
2023-08-05 00:10:04 | INFO | train_inner | epoch 001:    901 / 1474 loss=9.215, trans_loss=5.42, nll_loss=4.118, w2v_ctc_loss=5.621, task_loss=0, contrastive_loss=2.686, total=4163.61, n_correct=268.63, ppl=17.36, accuracy=6.452, wps=20511.3, ups=1.65, wpb=12433.9, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=2.452, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=617
2023-08-05 00:11:05 | INFO | train_inner | epoch 001:   1001 / 1474 loss=8.925, trans_loss=5.405, nll_loss=4.106, w2v_ctc_loss=5.482, task_loss=0, contrastive_loss=2.56, total=4135.34, n_correct=288.51, ppl=17.22, accuracy=6.977, wps=20212.6, ups=1.64, wpb=12353.2, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=2.648, clip=0, loss_scale=64, train_wall=61, gb_free=19, wall=678
2023-08-05 00:12:07 | INFO | train_inner | epoch 001:   1101 / 1474 loss=8.595, trans_loss=5.396, nll_loss=4.098, w2v_ctc_loss=5.338, task_loss=0, contrastive_loss=2.368, total=4147.38, n_correct=309.87, ppl=17.13, accuracy=7.471, wps=20137.7, ups=1.63, wpb=12367, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=3.056, clip=0, loss_scale=64, train_wall=61, gb_free=18.9, wall=740
2023-08-05 00:13:07 | INFO | train_inner | epoch 001:   1201 / 1474 loss=8.308, trans_loss=5.38, nll_loss=4.084, w2v_ctc_loss=5.216, task_loss=0, contrastive_loss=2.173, total=4139.9, n_correct=315.85, ppl=16.96, accuracy=7.629, wps=20351.1, ups=1.65, wpb=12366.5, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=3.178, clip=0, loss_scale=64, train_wall=60, gb_free=19, wall=800
2023-08-05 00:14:08 | INFO | train_inner | epoch 001:   1301 / 1474 loss=8.036, trans_loss=5.377, nll_loss=4.084, w2v_ctc_loss=5.048, task_loss=0, contrastive_loss=2.004, total=4046.58, n_correct=315.34, ppl=16.96, accuracy=7.793, wps=19911.9, ups=1.65, wpb=12081.6, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=3.332, clip=0, loss_scale=64, train_wall=60, gb_free=19.7, wall=861
2023-08-05 00:15:09 | INFO | train_inner | epoch 001:   1401 / 1474 loss=7.783, trans_loss=5.374, nll_loss=4.084, w2v_ctc_loss=4.856, task_loss=0, contrastive_loss=2.077, total=4133.18, n_correct=324.72, ppl=16.96, accuracy=7.856, wps=20356.5, ups=1.65, wpb=12350, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=3.261, clip=0, loss_scale=64, train_wall=60, gb_free=19.9, wall=922
2023-08-05 00:15:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 00:16:33 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 10.777 | trans_loss 11.005 | nll_loss 10.017 | w2v_ctc_loss 6.492 | task_loss 0 | contrastive_loss 2.513 | total 4003.4 | n_correct 362.8 | ppl 1035.98 | accuracy 9.062 | uer 79.335 | wer 78.849 | raw_wer 78.849 | bleu 0.03 | wps 1163.1 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-08-05 00:16:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-08-05 00:16:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 00:16:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 00:16:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.03) (writing took 5.895188096910715 seconds)
2023-08-05 00:16:39 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-05 00:16:39 | INFO | train | epoch 001 | loss 10.871 | trans_loss 5.453 | nll_loss 4.129 | w2v_ctc_loss 8.022 | task_loss 0 | contrastive_loss 2.767 | total 4138.5 | n_correct 254.517 | ppl 17.5 | accuracy 6.15 | wps 19227.2 | ups 1.56 | wpb 12355.3 | bsz 458.5 | num_updates 1473 | lr 5.89905e-05 | gnorm 2.552 | clip 0 | loss_scale 64 | train_wall 899 | gb_free 19.2 | wall 1012
2023-08-05 00:16:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 00:16:39 | INFO | fairseq.trainer | begin training epoch 2
2023-08-05 00:16:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 00:17:03 | INFO | train_inner | epoch 002:     27 / 1474 loss=7.53, trans_loss=5.366, nll_loss=4.07, w2v_ctc_loss=4.661, task_loss=0, contrastive_loss=1.922, total=4162.95, n_correct=331.3, ppl=16.79, accuracy=7.958, wps=10828.9, ups=0.87, wpb=12416.8, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=3.012, clip=0, loss_scale=64, train_wall=61, gb_free=19.7, wall=1036
2023-08-05 00:18:04 | INFO | train_inner | epoch 002:    127 / 1474 loss=7.252, trans_loss=5.366, nll_loss=4.068, w2v_ctc_loss=4.527, task_loss=0, contrastive_loss=1.71, total=4155.98, n_correct=331.3, ppl=16.77, accuracy=7.972, wps=20446.7, ups=1.65, wpb=12394.8, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=3.027, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=1097
2023-08-05 00:19:05 | INFO | train_inner | epoch 002:    227 / 1474 loss=7.055, trans_loss=5.348, nll_loss=4.051, w2v_ctc_loss=4.309, task_loss=0, contrastive_loss=1.731, total=4179.21, n_correct=337.07, ppl=16.57, accuracy=8.065, wps=20587.9, ups=1.65, wpb=12484.6, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=2.742, clip=0, loss_scale=64, train_wall=60, gb_free=19, wall=1158
2023-08-05 00:20:05 | INFO | train_inner | epoch 002:    327 / 1474 loss=6.751, trans_loss=5.351, nll_loss=4.051, w2v_ctc_loss=4.187, task_loss=0, contrastive_loss=1.435, total=4146.1, n_correct=337.99, ppl=16.58, accuracy=8.152, wps=20451.5, ups=1.65, wpb=12374.1, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=2.688, clip=0, loss_scale=64, train_wall=60, gb_free=18.8, wall=1218
2023-08-05 00:21:06 | INFO | train_inner | epoch 002:    427 / 1474 loss=6.496, trans_loss=5.347, nll_loss=4.051, w2v_ctc_loss=4.061, task_loss=0, contrastive_loss=1.24, total=4037.99, n_correct=330.65, ppl=16.57, accuracy=8.188, wps=19795.7, ups=1.64, wpb=12069.2, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=2.604, clip=0, loss_scale=64, train_wall=60, gb_free=19, wall=1279
2023-08-05 00:22:07 | INFO | train_inner | epoch 002:    527 / 1474 loss=6.373, trans_loss=5.333, nll_loss=4.029, w2v_ctc_loss=3.871, task_loss=0, contrastive_loss=1.33, total=4176.97, n_correct=351.1, ppl=16.32, accuracy=8.406, wps=20385.7, ups=1.64, wpb=12463.5, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=2.418, clip=0, loss_scale=64, train_wall=61, gb_free=19.6, wall=1340
2023-08-05 00:22:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 00:22:46 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 9.871 | trans_loss 10.894 | nll_loss 9.864 | w2v_ctc_loss 5.17 | task_loss 0 | contrastive_loss 1.682 | total 4003.4 | n_correct 389.9 | ppl 932.07 | accuracy 9.739 | uer 66.756 | wer 64.069 | raw_wer 64.069 | bleu 0.04 | wps 1201.6 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.04
2023-08-05 00:22:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-05 00:22:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_2_2000.pt
2023-08-05 00:22:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_2_2000.pt
2023-08-05 00:23:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.04) (writing took 24.98249721340835 seconds)
2023-08-05 00:24:12 | INFO | train_inner | epoch 002:    627 / 1474 loss=6.145, trans_loss=5.325, nll_loss=4.018, w2v_ctc_loss=3.733, task_loss=0, contrastive_loss=1.123, total=4126.49, n_correct=356.92, ppl=16.2, accuracy=8.649, wps=9891.1, ups=0.8, wpb=12314.9, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=2.075, clip=0, loss_scale=64, train_wall=60, gb_free=19.2, wall=1465
2023-08-05 00:25:12 | INFO | train_inner | epoch 002:    727 / 1474 loss=6.045, trans_loss=5.311, nll_loss=4.004, w2v_ctc_loss=3.615, task_loss=0, contrastive_loss=1.22, total=4149.06, n_correct=361.18, ppl=16.05, accuracy=8.705, wps=20617.5, ups=1.66, wpb=12386.4, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=2.017, clip=0, loss_scale=64, train_wall=60, gb_free=19.2, wall=1525
2023-08-05 00:26:13 | INFO | train_inner | epoch 002:    827 / 1474 loss=5.889, trans_loss=5.3, nll_loss=3.992, w2v_ctc_loss=3.519, task_loss=0, contrastive_loss=1.155, total=4175.4, n_correct=371.14, ppl=15.91, accuracy=8.889, wps=20490.6, ups=1.64, wpb=12471.9, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=1.724, clip=0, loss_scale=128, train_wall=60, gb_free=19.8, wall=1586
2023-08-05 00:26:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-05 00:27:15 | INFO | train_inner | epoch 002:    928 / 1474 loss=5.721, trans_loss=5.283, nll_loss=3.969, w2v_ctc_loss=3.399, task_loss=0, contrastive_loss=1.074, total=4087.96, n_correct=366.32, ppl=15.66, accuracy=8.961, wps=19694.9, ups=1.61, wpb=12205.3, bsz=439.8, num_updates=2400, lr=9.6052e-05, gnorm=1.716, clip=0, loss_scale=64, train_wall=61, gb_free=18.9, wall=1648
2023-08-05 00:28:15 | INFO | train_inner | epoch 002:   1028 / 1474 loss=5.6, trans_loss=5.272, nll_loss=3.956, w2v_ctc_loss=3.302, task_loss=0, contrastive_loss=0.982, total=4101.19, n_correct=376.41, ppl=15.52, accuracy=9.178, wps=20251.4, ups=1.65, wpb=12245.2, bsz=454.5, num_updates=2500, lr=0.00010005, gnorm=1.495, clip=0, loss_scale=64, train_wall=60, gb_free=19, wall=1708
2023-08-05 00:29:16 | INFO | train_inner | epoch 002:   1128 / 1474 loss=5.575, trans_loss=5.263, nll_loss=3.945, w2v_ctc_loss=3.199, task_loss=0, contrastive_loss=1.188, total=4192.73, n_correct=390.47, ppl=15.4, accuracy=9.313, wps=20602.4, ups=1.65, wpb=12513.6, bsz=488.9, num_updates=2600, lr=0.000104048, gnorm=1.43, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=1769
2023-08-05 00:30:17 | INFO | train_inner | epoch 002:   1228 / 1474 loss=5.478, trans_loss=5.252, nll_loss=3.93, w2v_ctc_loss=3.134, task_loss=0, contrastive_loss=1.108, total=4219.96, n_correct=403.19, ppl=15.24, accuracy=9.554, wps=20574.2, ups=1.63, wpb=12591.9, bsz=491.8, num_updates=2700, lr=0.000108046, gnorm=1.381, clip=0, loss_scale=64, train_wall=61, gb_free=18.9, wall=1830
2023-08-05 00:31:18 | INFO | train_inner | epoch 002:   1328 / 1474 loss=5.289, trans_loss=5.229, nll_loss=3.906, w2v_ctc_loss=3.081, task_loss=0, contrastive_loss=0.813, total=4163.26, n_correct=410.76, ppl=14.99, accuracy=9.866, wps=20415.6, ups=1.64, wpb=12441.6, bsz=463, num_updates=2800, lr=0.000112044, gnorm=1.237, clip=0, loss_scale=64, train_wall=60, gb_free=19, wall=1891
2023-08-05 00:32:19 | INFO | train_inner | epoch 002:   1428 / 1474 loss=5.223, trans_loss=5.237, nll_loss=3.915, w2v_ctc_loss=3.026, task_loss=0, contrastive_loss=0.897, total=4049.42, n_correct=393.73, ppl=15.09, accuracy=9.723, wps=19850.4, ups=1.64, wpb=12091.6, bsz=437.6, num_updates=2900, lr=0.000116042, gnorm=1.152, clip=0, loss_scale=64, train_wall=60, gb_free=19.2, wall=1952
2023-08-05 00:32:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 00:33:25 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.749 | trans_loss 10.309 | nll_loss 9.127 | w2v_ctc_loss 3.927 | task_loss 0 | contrastive_loss 0.971 | total 4003.4 | n_correct 492.8 | ppl 559.23 | accuracy 12.31 | uer 54.708 | wer 53.096 | raw_wer 53.096 | bleu 0.1 | wps 1210.7 | wpb 4003.4 | bsz 141.8 | num_updates 2946 | best_bleu 0.1
2023-08-05 00:33:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2946 updates
2023-08-05 00:33:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 00:33:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 00:33:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt (epoch 2 @ 2946 updates, score 0.1) (writing took 23.63793724961579 seconds)
2023-08-05 00:33:49 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-05 00:33:49 | INFO | train | epoch 002 | loss 6.063 | trans_loss 5.3 | nll_loss 3.991 | w2v_ctc_loss 3.638 | task_loss 0 | contrastive_loss 1.218 | total 4137.79 | n_correct 365.973 | ppl 15.9 | accuracy 8.845 | wps 17665.7 | ups 1.43 | wpb 12353.3 | bsz 458.1 | num_updates 2946 | lr 0.000117881 | gnorm 1.972 | clip 0 | loss_scale 64 | train_wall 887 | gb_free 19.3 | wall 2042
2023-08-05 00:33:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 00:33:49 | INFO | fairseq.trainer | begin training epoch 3
2023-08-05 00:33:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 00:34:30 | INFO | train_inner | epoch 003:     54 / 1474 loss=5.113, trans_loss=5.211, nll_loss=3.883, w2v_ctc_loss=2.953, task_loss=0, contrastive_loss=0.794, total=4067, n_correct=411.79, ppl=14.75, accuracy=10.125, wps=9297, ups=0.77, wpb=12142, bsz=441.4, num_updates=3000, lr=0.00012004, gnorm=1.12, clip=0, loss_scale=64, train_wall=60, gb_free=19.2, wall=2083
2023-08-05 00:34:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-05 00:34:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-05 00:34:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-05 00:34:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-05 00:35:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-05 00:35:52 | INFO | train_inner | epoch 003:    159 / 1474 loss=4.267, trans_loss=4.44, nll_loss=2.873, w2v_ctc_loss=2.612, task_loss=0, contrastive_loss=0.668, total=4133.12, n_correct=1102.24, ppl=7.32, accuracy=26.668, wps=15026, ups=1.22, wpb=12341.6, bsz=452.9, num_updates=3100, lr=0.000124038, gnorm=2.56, clip=2, loss_scale=2, train_wall=82, gb_free=16.7, wall=2165
2023-08-05 00:37:12 | INFO | train_inner | epoch 003:    259 / 1474 loss=3.731, trans_loss=4.177, nll_loss=2.531, w2v_ctc_loss=2.313, task_loss=0, contrastive_loss=0.577, total=4155.72, n_correct=1405.48, ppl=5.78, accuracy=33.82, wps=15500.8, ups=1.25, wpb=12415.9, bsz=465.5, num_updates=3200, lr=0.000128036, gnorm=1.674, clip=0, loss_scale=2, train_wall=80, gb_free=17.8, wall=2245
2023-08-05 00:38:31 | INFO | train_inner | epoch 003:    359 / 1474 loss=3.576, trans_loss=4.101, nll_loss=2.428, w2v_ctc_loss=2.196, task_loss=0, contrastive_loss=0.619, total=4154.07, n_correct=1514.38, ppl=5.38, accuracy=36.455, wps=15706.4, ups=1.27, wpb=12396.6, bsz=464.9, num_updates=3300, lr=0.000132034, gnorm=1.599, clip=0, loss_scale=2, train_wall=78, gb_free=15.9, wall=2324
2023-08-05 00:39:50 | INFO | train_inner | epoch 003:    459 / 1474 loss=3.399, trans_loss=4.048, nll_loss=2.358, w2v_ctc_loss=2.099, task_loss=0, contrastive_loss=0.454, total=4212.17, n_correct=1618.42, ppl=5.13, accuracy=38.422, wps=15881.4, ups=1.26, wpb=12572.6, bsz=473.8, num_updates=3400, lr=0.000136032, gnorm=1.368, clip=0, loss_scale=2, train_wall=79, gb_free=16, wall=2403
2023-08-05 00:41:09 | INFO | train_inner | epoch 003:    559 / 1474 loss=3.275, trans_loss=4.015, nll_loss=2.317, w2v_ctc_loss=2.012, task_loss=0, contrastive_loss=0.442, total=4081.04, n_correct=1613.79, ppl=4.98, accuracy=39.544, wps=15496.2, ups=1.27, wpb=12190.8, bsz=440.1, num_updates=3500, lr=0.00014003, gnorm=1.371, clip=0, loss_scale=2, train_wall=78, gb_free=16.7, wall=2482
2023-08-05 00:42:29 | INFO | train_inner | epoch 003:    659 / 1474 loss=3.227, trans_loss=3.977, nll_loss=2.262, w2v_ctc_loss=1.932, task_loss=0, contrastive_loss=0.55, total=4231.09, n_correct=1746.12, ppl=4.8, accuracy=41.269, wps=15752.6, ups=1.25, wpb=12615.6, bsz=484.4, num_updates=3600, lr=0.000144028, gnorm=1.266, clip=0, loss_scale=2, train_wall=80, gb_free=16.2, wall=2562
2023-08-05 00:43:47 | INFO | train_inner | epoch 003:    759 / 1474 loss=3.104, trans_loss=3.945, nll_loss=2.225, w2v_ctc_loss=1.899, task_loss=0, contrastive_loss=0.307, total=4160.74, n_correct=1757.57, ppl=4.67, accuracy=42.242, wps=15816.8, ups=1.27, wpb=12428.5, bsz=469.2, num_updates=3700, lr=0.000148026, gnorm=1.25, clip=0, loss_scale=2, train_wall=78, gb_free=17, wall=2640
2023-08-05 00:45:06 | INFO | train_inner | epoch 003:    859 / 1474 loss=3.05, trans_loss=3.934, nll_loss=2.208, w2v_ctc_loss=1.86, task_loss=0, contrastive_loss=0.285, total=4160.47, n_correct=1781.66, ppl=4.62, accuracy=42.824, wps=15779.4, ups=1.27, wpb=12423.6, bsz=455.4, num_updates=3800, lr=0.000152024, gnorm=1.307, clip=0, loss_scale=2, train_wall=78, gb_free=16.6, wall=2719
2023-08-05 00:46:25 | INFO | train_inner | epoch 003:    959 / 1474 loss=3.02, trans_loss=3.913, nll_loss=2.179, w2v_ctc_loss=1.829, task_loss=0, contrastive_loss=0.314, total=4162.26, n_correct=1829.06, ppl=4.53, accuracy=43.944, wps=15711.8, ups=1.27, wpb=12416.1, bsz=467.9, num_updates=3900, lr=0.000156022, gnorm=1.238, clip=0, loss_scale=2, train_wall=79, gb_free=17.9, wall=2798
2023-08-05 00:47:44 | INFO | train_inner | epoch 003:   1059 / 1474 loss=2.96, trans_loss=3.891, nll_loss=2.153, w2v_ctc_loss=1.805, task_loss=0, contrastive_loss=0.269, total=4062.67, n_correct=1806.87, ppl=4.45, accuracy=44.475, wps=15301, ups=1.26, wpb=12131.7, bsz=443.2, num_updates=4000, lr=0.00016002, gnorm=1.112, clip=0, loss_scale=2, train_wall=79, gb_free=15.9, wall=2877
2023-08-05 00:47:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 00:48:18 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.271 | trans_loss 6.412 | nll_loss 3.958 | w2v_ctc_loss 2.203 | task_loss 0 | contrastive_loss 0.386 | total 4003.4 | n_correct 1972.8 | ppl 15.54 | accuracy 49.278 | uer 30.709 | wer 31.267 | raw_wer 31.267 | bleu 11.58 | wps 1448.4 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 11.58
2023-08-05 00:48:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-05 00:48:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_3_4000.pt
2023-08-05 00:48:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_3_4000.pt
2023-08-05 00:48:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 11.58) (writing took 24.678547920659184 seconds)
2023-08-05 00:50:00 | INFO | train_inner | epoch 003:   1159 / 1474 loss=2.911, trans_loss=3.884, nll_loss=2.142, w2v_ctc_loss=1.76, task_loss=0, contrastive_loss=0.25, total=4046.76, n_correct=1822.51, ppl=4.41, accuracy=45.036, wps=8892.7, ups=0.74, wpb=12078.6, bsz=433.9, num_updates=4100, lr=0.000164018, gnorm=1.1, clip=0, loss_scale=2, train_wall=77, gb_free=16.5, wall=3013
2023-08-05 00:51:18 | INFO | train_inner | epoch 003:   1259 / 1474 loss=2.857, trans_loss=3.862, nll_loss=2.115, w2v_ctc_loss=1.721, task_loss=0, contrastive_loss=0.233, total=4064.26, n_correct=1865.5, ppl=4.33, accuracy=45.9, wps=15576.7, ups=1.28, wpb=12137.6, bsz=434, num_updates=4200, lr=0.000168016, gnorm=1.063, clip=0, loss_scale=2, train_wall=77, gb_free=16.9, wall=3091
2023-08-05 00:52:37 | INFO | train_inner | epoch 003:   1359 / 1474 loss=2.863, trans_loss=3.846, nll_loss=2.093, w2v_ctc_loss=1.687, task_loss=0, contrastive_loss=0.343, total=4137.36, n_correct=1920.12, ppl=4.27, accuracy=46.409, wps=15604.1, ups=1.26, wpb=12352.2, bsz=461.5, num_updates=4300, lr=0.000172014, gnorm=1.102, clip=0, loss_scale=2, train_wall=79, gb_free=16.5, wall=3170
2023-08-05 00:53:57 | INFO | train_inner | epoch 003:   1459 / 1474 loss=2.831, trans_loss=3.832, nll_loss=2.078, w2v_ctc_loss=1.665, task_loss=0, contrastive_loss=0.322, total=4207.75, n_correct=1983.26, ppl=4.22, accuracy=47.134, wps=15750.7, ups=1.25, wpb=12567.9, bsz=476.7, num_updates=4400, lr=0.000176012, gnorm=1.035, clip=0, loss_scale=2, train_wall=79, gb_free=17.5, wall=3250
2023-08-05 00:54:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 00:54:39 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.093 | trans_loss 6.273 | nll_loss 3.776 | w2v_ctc_loss 1.971 | task_loss 0 | contrastive_loss 0.358 | total 4003.4 | n_correct 2045.3 | ppl 13.7 | accuracy 51.089 | uer 29.347 | wer 29.827 | raw_wer 29.827 | bleu 12.84 | wps 1502.5 | wpb 4003.4 | bsz 141.8 | num_updates 4415 | best_bleu 12.84
2023-08-05 00:54:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4415 updates
2023-08-05 00:54:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 00:54:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 00:55:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt (epoch 3 @ 4415 updates, score 12.84) (writing took 24.641292601823807 seconds)
2023-08-05 00:55:04 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-05 00:55:04 | INFO | train | epoch 003 | loss 3.285 | trans_loss 4.034 | nll_loss 2.34 | w2v_ctc_loss 1.99 | task_loss 0 | contrastive_loss 0.419 | total 4138.49 | n_correct 1652.45 | ppl 5.06 | accuracy 39.929 | wps 14235.9 | ups 1.15 | wpb 12355.4 | bsz 458.3 | num_updates 4415 | lr 0.000176612 | gnorm 1.348 | clip 0.1 | loss_scale 2 | train_wall 1146 | gb_free 16.6 | wall 3317
2023-08-05 00:55:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 00:55:04 | INFO | fairseq.trainer | begin training epoch 4
2023-08-05 00:55:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 00:56:19 | INFO | train_inner | epoch 004:     85 / 1474 loss=2.718, trans_loss=3.804, nll_loss=2.036, w2v_ctc_loss=1.615, task_loss=0, contrastive_loss=0.181, total=4095.18, n_correct=1962.59, ppl=4.1, accuracy=47.924, wps=8620.1, ups=0.71, wpb=12222.9, bsz=437.8, num_updates=4500, lr=0.00018001, gnorm=0.976, clip=0, loss_scale=2, train_wall=78, gb_free=13, wall=3392
2023-08-05 00:57:37 | INFO | train_inner | epoch 004:    185 / 1474 loss=2.709, trans_loss=3.784, nll_loss=2.012, w2v_ctc_loss=1.598, task_loss=0, contrastive_loss=0.206, total=4178.83, n_correct=2033.15, ppl=4.03, accuracy=48.654, wps=15899.4, ups=1.27, wpb=12476.1, bsz=469.5, num_updates=4600, lr=0.000184008, gnorm=0.999, clip=0, loss_scale=2, train_wall=78, gb_free=14.9, wall=3470
2023-08-05 00:58:56 | INFO | train_inner | epoch 004:    285 / 1474 loss=2.736, trans_loss=3.787, nll_loss=2.019, w2v_ctc_loss=1.593, task_loss=0, contrastive_loss=0.33, total=4142.3, n_correct=2015.88, ppl=4.05, accuracy=48.666, wps=15700.5, ups=1.27, wpb=12373.8, bsz=460.7, num_updates=4700, lr=0.000188006, gnorm=0.994, clip=0, loss_scale=2, train_wall=78, gb_free=13.6, wall=3549
2023-08-05 01:00:16 | INFO | train_inner | epoch 004:    385 / 1474 loss=2.671, trans_loss=3.787, nll_loss=2.015, w2v_ctc_loss=1.57, task_loss=0, contrastive_loss=0.18, total=4124.92, n_correct=2014.47, ppl=4.04, accuracy=48.837, wps=15497.6, ups=1.26, wpb=12307.7, bsz=444.2, num_updates=4800, lr=0.000192004, gnorm=0.956, clip=0, loss_scale=2, train_wall=79, gb_free=12.8, wall=3629
2023-08-05 01:01:35 | INFO | train_inner | epoch 004:    485 / 1474 loss=2.769, trans_loss=3.768, nll_loss=1.993, w2v_ctc_loss=1.543, task_loss=0, contrastive_loss=0.571, total=4216.09, n_correct=2086.34, ppl=3.98, accuracy=49.485, wps=15889, ups=1.26, wpb=12585.8, bsz=497.6, num_updates=4900, lr=0.000196002, gnorm=1.009, clip=0, loss_scale=2, train_wall=78, gb_free=17, wall=3708
2023-08-05 01:02:54 | INFO | train_inner | epoch 004:    585 / 1474 loss=2.676, trans_loss=3.762, nll_loss=1.986, w2v_ctc_loss=1.556, task_loss=0, contrastive_loss=0.25, total=4231.12, n_correct=2113.15, ppl=3.96, accuracy=49.943, wps=15924.1, ups=1.26, wpb=12629.4, bsz=490.1, num_updates=5000, lr=0.0002, gnorm=0.969, clip=0, loss_scale=2, train_wall=79, gb_free=16.3, wall=3787
mt_weight tensor(0.5000)
asr_weight tensor(0.4513, device='cuda:0')
2023-08-05 01:04:14 | INFO | train_inner | epoch 004:    685 / 1474 loss=2.639, trans_loss=3.765, nll_loss=1.985, w2v_ctc_loss=1.516, task_loss=0, contrastive_loss=0.298, total=4176.95, n_correct=2092.95, ppl=3.96, accuracy=50.107, wps=15567.3, ups=1.25, wpb=12451, bsz=455.2, num_updates=5100, lr=0.00019803, gnorm=0.593, clip=0, loss_scale=4, train_wall=80, gb_free=15.3, wall=3867
2023-08-05 01:05:34 | INFO | train_inner | epoch 004:    785 / 1474 loss=2.606, trans_loss=3.757, nll_loss=1.979, w2v_ctc_loss=1.531, task_loss=0, contrastive_loss=0.171, total=4016.91, n_correct=2022.09, ppl=3.94, accuracy=50.339, wps=15076.6, ups=1.26, wpb=11995.1, bsz=418.7, num_updates=5200, lr=0.000196116, gnorm=0.611, clip=0, loss_scale=4, train_wall=79, gb_free=16.3, wall=3947
2023-08-05 01:06:53 | INFO | train_inner | epoch 004:    885 / 1474 loss=2.664, trans_loss=3.746, nll_loss=1.967, w2v_ctc_loss=1.532, task_loss=0, contrastive_loss=0.345, total=4183.4, n_correct=2112.61, ppl=3.91, accuracy=50.5, wps=15754.3, ups=1.26, wpb=12493.2, bsz=465.4, num_updates=5300, lr=0.000194257, gnorm=0.646, clip=0, loss_scale=4, train_wall=79, gb_free=15.7, wall=4026
2023-08-05 01:08:12 | INFO | train_inner | epoch 004:    985 / 1474 loss=2.596, trans_loss=3.734, nll_loss=1.951, w2v_ctc_loss=1.506, task_loss=0, contrastive_loss=0.214, total=4128.78, n_correct=2110.61, ppl=3.87, accuracy=51.119, wps=15572.4, ups=1.26, wpb=12332, bsz=456.8, num_updates=5400, lr=0.00019245, gnorm=0.602, clip=0, loss_scale=4, train_wall=79, gb_free=16.2, wall=4105
2023-08-05 01:09:31 | INFO | train_inner | epoch 004:   1085 / 1474 loss=2.595, trans_loss=3.743, nll_loss=1.962, w2v_ctc_loss=1.514, task_loss=0, contrastive_loss=0.194, total=4080.2, n_correct=2079.89, ppl=3.9, accuracy=50.975, wps=15360.7, ups=1.26, wpb=12179.1, bsz=437.7, num_updates=5500, lr=0.000190693, gnorm=0.615, clip=0, loss_scale=4, train_wall=79, gb_free=16.4, wall=4184
2023-08-05 01:10:51 | INFO | train_inner | epoch 004:   1185 / 1474 loss=2.625, trans_loss=3.731, nll_loss=1.949, w2v_ctc_loss=1.503, task_loss=0, contrastive_loss=0.305, total=4163.45, n_correct=2137.1, ppl=3.86, accuracy=51.33, wps=15707.4, ups=1.26, wpb=12436, bsz=485.6, num_updates=5600, lr=0.000188982, gnorm=0.611, clip=0, loss_scale=4, train_wall=79, gb_free=15.4, wall=4264
2023-08-05 01:12:09 | INFO | train_inner | epoch 004:   1285 / 1474 loss=2.592, trans_loss=3.721, nll_loss=1.935, w2v_ctc_loss=1.489, task_loss=0, contrastive_loss=0.268, total=4152.41, n_correct=2149.85, ppl=3.83, accuracy=51.774, wps=15814.8, ups=1.28, wpb=12401.3, bsz=471.4, num_updates=5700, lr=0.000187317, gnorm=0.622, clip=0, loss_scale=4, train_wall=78, gb_free=13.2, wall=4342
2023-08-05 01:13:27 | INFO | train_inner | epoch 004:   1385 / 1474 loss=2.531, trans_loss=3.718, nll_loss=1.931, w2v_ctc_loss=1.477, task_loss=0, contrastive_loss=0.15, total=4103.57, n_correct=2131.73, ppl=3.81, accuracy=51.948, wps=15780.1, ups=1.29, wpb=12255.2, bsz=437.9, num_updates=5800, lr=0.000185695, gnorm=0.568, clip=0, loss_scale=4, train_wall=77, gb_free=16.9, wall=4420
2023-08-05 01:14:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.4513, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.4513, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.4513, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.4513, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.4513, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.4513, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.4513, device='cuda:2')
2023-08-05 01:14:59 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.747 | trans_loss 5.944 | nll_loss 3.329 | w2v_ctc_loss 1.664 | task_loss 0 | contrastive_loss 0.298 | total 4003.4 | n_correct 2248.2 | ppl 10.05 | accuracy 56.157 | uer 24.829 | wer 26.375 | raw_wer 26.375 | bleu 16.22 | wps 2254.4 | wpb 4003.4 | bsz 141.8 | num_updates 5889 | best_bleu 16.22
2023-08-05 01:14:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5889 updates
2023-08-05 01:14:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 01:15:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 01:15:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt (epoch 4 @ 5889 updates, score 16.22) (writing took 24.008140852674842 seconds)
2023-08-05 01:15:23 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-05 01:15:23 | INFO | train | epoch 004 | loss 2.644 | trans_loss 3.754 | nll_loss 1.976 | w2v_ctc_loss 1.533 | task_loss 0 | contrastive_loss 0.261 | total 4138.65 | n_correct 2080.11 | ppl 3.93 | accuracy 50.261 | wps 14934.7 | ups 1.21 | wpb 12355.8 | bsz 458.5 | num_updates 5889 | lr 0.000184287 | gnorm 0.755 | clip 0 | loss_scale 4 | train_wall 1155 | gb_free 15.1 | wall 4536
2023-08-05 01:15:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 01:15:24 | INFO | fairseq.trainer | begin training epoch 5
2023-08-05 01:15:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 01:15:40 | INFO | train_inner | epoch 005:     11 / 1474 loss=2.513, trans_loss=3.708, nll_loss=1.918, w2v_ctc_loss=1.447, task_loss=0, contrastive_loss=0.166, total=4031.51, n_correct=2107.23, ppl=3.78, accuracy=52.269, wps=9039.5, ups=0.75, wpb=12037.5, bsz=436.7, num_updates=5900, lr=0.000184115, gnorm=0.57, clip=0, loss_scale=4, train_wall=77, gb_free=14.5, wall=4553
2023-08-05 01:17:00 | INFO | train_inner | epoch 005:    111 / 1474 loss=2.452, trans_loss=3.655, nll_loss=1.849, w2v_ctc_loss=1.374, task_loss=0, contrastive_loss=0.184, total=4256.63, n_correct=2299.38, ppl=3.6, accuracy=54.019, wps=15947.2, ups=1.25, wpb=12710, bsz=500.1, num_updates=6000, lr=0.000182574, gnorm=0.553, clip=0, loss_scale=4, train_wall=79, gb_free=16.4, wall=4633
2023-08-05 01:17:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 01:17:23 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.714 | trans_loss 5.914 | nll_loss 3.289 | w2v_ctc_loss 1.632 | task_loss 0 | contrastive_loss 0.289 | total 4003.4 | n_correct 2260.2 | ppl 9.77 | accuracy 56.457 | uer 23.884 | wer 25.327 | raw_wer 25.327 | bleu 16.35 | wps 2102 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 16.35
2023-08-05 01:17:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-08-05 01:17:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_5_6000.pt
2023-08-05 01:17:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_5_6000.pt
2023-08-05 01:17:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 16.35) (writing took 24.601954387500882 seconds)
2023-08-05 01:19:06 | INFO | train_inner | epoch 005:    211 / 1474 loss=2.51, trans_loss=3.666, nll_loss=1.861, w2v_ctc_loss=1.39, task_loss=0, contrastive_loss=0.382, total=4186.83, n_correct=2249.92, ppl=3.63, accuracy=53.738, wps=9888.4, ups=0.79, wpb=12492.2, bsz=485.3, num_updates=6100, lr=0.000181071, gnorm=0.563, clip=0, loss_scale=4, train_wall=77, gb_free=16.2, wall=4759
2023-08-05 01:20:24 | INFO | train_inner | epoch 005:    311 / 1474 loss=2.477, trans_loss=3.661, nll_loss=1.86, w2v_ctc_loss=1.408, task_loss=0, contrastive_loss=0.241, total=4094.07, n_correct=2194.48, ppl=3.63, accuracy=53.601, wps=15657.3, ups=1.28, wpb=12241.2, bsz=446, num_updates=6200, lr=0.000179605, gnorm=0.568, clip=0, loss_scale=4, train_wall=78, gb_free=16.4, wall=4837
2023-08-05 01:21:43 | INFO | train_inner | epoch 005:    411 / 1474 loss=2.491, trans_loss=3.655, nll_loss=1.853, w2v_ctc_loss=1.376, task_loss=0, contrastive_loss=0.328, total=4140.39, n_correct=2230.2, ppl=3.61, accuracy=53.864, wps=15634.4, ups=1.26, wpb=12372.8, bsz=467.9, num_updates=6300, lr=0.000178174, gnorm=0.587, clip=0, loss_scale=4, train_wall=78, gb_free=16.3, wall=4916
2023-08-05 01:23:02 | INFO | train_inner | epoch 005:    511 / 1474 loss=2.414, trans_loss=3.662, nll_loss=1.86, w2v_ctc_loss=1.379, task_loss=0, contrastive_loss=0.123, total=4026.21, n_correct=2162.2, ppl=3.63, accuracy=53.703, wps=15242.5, ups=1.27, wpb=12028.8, bsz=418.1, num_updates=6400, lr=0.000176777, gnorm=0.537, clip=0, loss_scale=4, train_wall=78, gb_free=17.2, wall=4995
2023-08-05 01:24:21 | INFO | train_inner | epoch 005:    611 / 1474 loss=2.468, trans_loss=3.67, nll_loss=1.867, w2v_ctc_loss=1.372, task_loss=0, contrastive_loss=0.295, total=4109.94, n_correct=2211.97, ppl=3.65, accuracy=53.82, wps=15583.4, ups=1.27, wpb=12260.2, bsz=449.8, num_updates=6500, lr=0.000175412, gnorm=0.578, clip=0, loss_scale=4, train_wall=78, gb_free=15.6, wall=5074
2023-08-05 01:25:40 | INFO | train_inner | epoch 005:    711 / 1474 loss=2.466, trans_loss=3.659, nll_loss=1.856, w2v_ctc_loss=1.367, task_loss=0, contrastive_loss=0.272, total=4176.83, n_correct=2264.66, ppl=3.62, accuracy=54.22, wps=15740.3, ups=1.26, wpb=12467.5, bsz=483.6, num_updates=6600, lr=0.000174078, gnorm=0.546, clip=0, loss_scale=4, train_wall=79, gb_free=17.2, wall=5153
2023-08-05 01:27:00 | INFO | train_inner | epoch 005:    811 / 1474 loss=2.426, trans_loss=3.66, nll_loss=1.857, w2v_ctc_loss=1.36, task_loss=0, contrastive_loss=0.196, total=4127.9, n_correct=2235.37, ppl=3.62, accuracy=54.153, wps=15458.3, ups=1.25, wpb=12321.2, bsz=447.5, num_updates=6700, lr=0.000172774, gnorm=0.535, clip=0, loss_scale=4, train_wall=79, gb_free=16, wall=5233
2023-08-05 01:28:19 | INFO | train_inner | epoch 005:    911 / 1474 loss=2.394, trans_loss=3.649, nll_loss=1.844, w2v_ctc_loss=1.344, task_loss=0, contrastive_loss=0.158, total=4101.19, n_correct=2236.35, ppl=3.59, accuracy=54.529, wps=15468.9, ups=1.26, wpb=12245.9, bsz=447.9, num_updates=6800, lr=0.000171499, gnorm=0.528, clip=0, loss_scale=4, train_wall=79, gb_free=17.4, wall=5312
2023-08-05 01:29:37 | INFO | train_inner | epoch 005:   1011 / 1474 loss=2.419, trans_loss=3.653, nll_loss=1.848, w2v_ctc_loss=1.348, task_loss=0, contrastive_loss=0.237, total=4164.27, n_correct=2266.89, ppl=3.6, accuracy=54.437, wps=15889.2, ups=1.28, wpb=12430.2, bsz=462, num_updates=6900, lr=0.000170251, gnorm=0.527, clip=0, loss_scale=4, train_wall=78, gb_free=15.2, wall=5390
2023-08-05 01:30:57 | INFO | train_inner | epoch 005:   1111 / 1474 loss=2.436, trans_loss=3.653, nll_loss=1.847, w2v_ctc_loss=1.356, task_loss=0, contrastive_loss=0.24, total=4168.94, n_correct=2275.83, ppl=3.6, accuracy=54.59, wps=15659.2, ups=1.26, wpb=12436.1, bsz=464.1, num_updates=7000, lr=0.000169031, gnorm=0.53, clip=0, loss_scale=4, train_wall=79, gb_free=16.8, wall=5470
2023-08-05 01:32:16 | INFO | train_inner | epoch 005:   1211 / 1474 loss=2.38, trans_loss=3.648, nll_loss=1.841, w2v_ctc_loss=1.33, task_loss=0, contrastive_loss=0.147, total=4171.16, n_correct=2284.88, ppl=3.58, accuracy=54.778, wps=15770.8, ups=1.27, wpb=12443.2, bsz=456.3, num_updates=7100, lr=0.000167836, gnorm=0.525, clip=0, loss_scale=4, train_wall=78, gb_free=16.1, wall=5548
2023-08-05 01:33:35 | INFO | train_inner | epoch 005:   1311 / 1474 loss=2.357, trans_loss=3.647, nll_loss=1.841, w2v_ctc_loss=1.318, task_loss=0, contrastive_loss=0.116, total=4126.97, n_correct=2261.3, ppl=3.58, accuracy=54.793, wps=15460.2, ups=1.26, wpb=12317.9, bsz=443.4, num_updates=7200, lr=0.000166667, gnorm=0.517, clip=0, loss_scale=8, train_wall=79, gb_free=15.7, wall=5628
2023-08-05 01:34:53 | INFO | train_inner | epoch 005:   1411 / 1474 loss=2.378, trans_loss=3.646, nll_loss=1.843, w2v_ctc_loss=1.315, task_loss=0, contrastive_loss=0.175, total=4138.54, n_correct=2271.9, ppl=3.59, accuracy=54.896, wps=15795.3, ups=1.28, wpb=12359.3, bsz=459, num_updates=7300, lr=0.000165521, gnorm=0.517, clip=0, loss_scale=8, train_wall=78, gb_free=17, wall=5706
2023-08-05 01:35:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 01:36:05 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.612 | trans_loss 5.831 | nll_loss 3.186 | w2v_ctc_loss 1.488 | task_loss 0 | contrastive_loss 0.289 | total 4003.4 | n_correct 2313.1 | ppl 9.1 | accuracy 57.778 | uer 21.952 | wer 23.59 | raw_wer 23.59 | bleu 16.97 | wps 2379.1 | wpb 4003.4 | bsz 141.8 | num_updates 7363 | best_bleu 16.97
2023-08-05 01:36:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7363 updates
2023-08-05 01:36:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 01:36:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 01:36:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt (epoch 5 @ 7363 updates, score 16.97) (writing took 25.294379513710737 seconds)
2023-08-05 01:36:31 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-05 01:36:31 | INFO | train | epoch 005 | loss 2.432 | trans_loss 3.655 | nll_loss 1.851 | w2v_ctc_loss 1.359 | task_loss 0 | contrastive_loss 0.221 | total 4138.65 | n_correct 2245.24 | ppl 3.61 | accuracy 54.251 | wps 14370.1 | ups 1.16 | wpb 12355.8 | bsz 458.5 | num_updates 7363 | lr 0.000164812 | gnorm 0.544 | clip 0 | loss_scale 8 | train_wall 1154 | gb_free 16.5 | wall 5804
2023-08-05 01:36:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 01:36:31 | INFO | fairseq.trainer | begin training epoch 6
2023-08-05 01:36:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 01:37:08 | INFO | train_inner | epoch 006:     37 / 1474 loss=2.362, trans_loss=3.622, nll_loss=1.809, w2v_ctc_loss=1.313, task_loss=0, contrastive_loss=0.172, total=4113.87, n_correct=2283.76, ppl=3.5, accuracy=55.514, wps=9151, ups=0.75, wpb=12276.7, bsz=447.4, num_updates=7400, lr=0.000164399, gnorm=0.534, clip=0, loss_scale=8, train_wall=78, gb_free=17.9, wall=5841
2023-08-05 01:38:27 | INFO | train_inner | epoch 006:    137 / 1474 loss=2.319, trans_loss=3.589, nll_loss=1.767, w2v_ctc_loss=1.258, task_loss=0, contrastive_loss=0.218, total=4161.2, n_correct=2344.52, ppl=3.4, accuracy=56.342, wps=15730.8, ups=1.27, wpb=12428.5, bsz=458.1, num_updates=7500, lr=0.000163299, gnorm=0.511, clip=0, loss_scale=8, train_wall=78, gb_free=17.1, wall=5920
2023-08-05 01:39:45 | INFO | train_inner | epoch 006:    237 / 1474 loss=2.316, trans_loss=3.603, nll_loss=1.786, w2v_ctc_loss=1.289, task_loss=0, contrastive_loss=0.127, total=4110.12, n_correct=2296.33, ppl=3.45, accuracy=55.87, wps=15582.6, ups=1.27, wpb=12279.2, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.51, clip=0, loss_scale=8, train_wall=78, gb_free=17.3, wall=5998
2023-08-05 01:41:05 | INFO | train_inner | epoch 006:    337 / 1474 loss=2.379, trans_loss=3.59, nll_loss=1.769, w2v_ctc_loss=1.24, task_loss=0, contrastive_loss=0.425, total=4170.52, n_correct=2351.85, ppl=3.41, accuracy=56.392, wps=15600.4, ups=1.25, wpb=12453.1, bsz=488.4, num_updates=7700, lr=0.000161165, gnorm=0.524, clip=0, loss_scale=8, train_wall=79, gb_free=15.9, wall=6078
2023-08-05 01:42:24 | INFO | train_inner | epoch 006:    437 / 1474 loss=2.292, trans_loss=3.593, nll_loss=1.773, w2v_ctc_loss=1.25, task_loss=0, contrastive_loss=0.14, total=4154.89, n_correct=2345.81, ppl=3.42, accuracy=56.459, wps=15736, ups=1.27, wpb=12405.6, bsz=470.4, num_updates=7800, lr=0.000160128, gnorm=0.514, clip=0, loss_scale=8, train_wall=78, gb_free=16.6, wall=6157
2023-08-05 01:43:43 | INFO | train_inner | epoch 006:    537 / 1474 loss=2.291, trans_loss=3.599, nll_loss=1.779, w2v_ctc_loss=1.258, task_loss=0, contrastive_loss=0.129, total=4174.46, n_correct=2356.87, ppl=3.43, accuracy=56.459, wps=15769, ups=1.27, wpb=12460.1, bsz=458.3, num_updates=7900, lr=0.000159111, gnorm=0.509, clip=0, loss_scale=8, train_wall=79, gb_free=17.3, wall=6236
2023-08-05 01:45:02 | INFO | train_inner | epoch 006:    637 / 1474 loss=2.307, trans_loss=3.6, nll_loss=1.782, w2v_ctc_loss=1.247, task_loss=0, contrastive_loss=0.189, total=4145.19, n_correct=2340.43, ppl=3.44, accuracy=56.461, wps=15656.6, ups=1.27, wpb=12372.7, bsz=470.9, num_updates=8000, lr=0.000158114, gnorm=0.538, clip=0, loss_scale=8, train_wall=79, gb_free=16, wall=6315
2023-08-05 01:45:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 01:45:26 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.596 | trans_loss 5.778 | nll_loss 3.115 | w2v_ctc_loss 1.572 | task_loss 0 | contrastive_loss 0.284 | total 4003.4 | n_correct 2346.7 | ppl 8.66 | accuracy 58.618 | uer 22.563 | wer 24.678 | raw_wer 24.678 | bleu 17.87 | wps 2130.2 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 17.87
2023-08-05 01:45:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-08-05 01:45:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_6_8000.pt
2023-08-05 01:45:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_6_8000.pt
2023-08-05 01:45:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 17.87) (writing took 25.373435217887163 seconds)
2023-08-05 01:47:10 | INFO | train_inner | epoch 006:    737 / 1474 loss=2.3, trans_loss=3.605, nll_loss=1.788, w2v_ctc_loss=1.262, task_loss=0, contrastive_loss=0.139, total=4151.01, n_correct=2338.42, ppl=3.45, accuracy=56.334, wps=9689.4, ups=0.78, wpb=12393.7, bsz=454.2, num_updates=8100, lr=0.000157135, gnorm=0.511, clip=0, loss_scale=8, train_wall=79, gb_free=13.3, wall=6443
2023-08-05 01:48:29 | INFO | train_inner | epoch 006:    837 / 1474 loss=2.286, trans_loss=3.611, nll_loss=1.796, w2v_ctc_loss=1.252, task_loss=0, contrastive_loss=0.121, total=4108.83, n_correct=2307.62, ppl=3.47, accuracy=56.162, wps=15594, ups=1.27, wpb=12267.1, bsz=439.4, num_updates=8200, lr=0.000156174, gnorm=0.509, clip=0, loss_scale=8, train_wall=78, gb_free=17.2, wall=6522
2023-08-05 01:49:48 | INFO | train_inner | epoch 006:    937 / 1474 loss=2.324, trans_loss=3.611, nll_loss=1.796, w2v_ctc_loss=1.257, task_loss=0, contrastive_loss=0.221, total=4076.46, n_correct=2289.71, ppl=3.47, accuracy=56.169, wps=15290.8, ups=1.26, wpb=12166, bsz=443, num_updates=8300, lr=0.00015523, gnorm=0.535, clip=0, loss_scale=8, train_wall=79, gb_free=12.9, wall=6601
2023-08-05 01:51:07 | INFO | train_inner | epoch 006:   1037 / 1474 loss=2.324, trans_loss=3.596, nll_loss=1.778, w2v_ctc_loss=1.235, task_loss=0, contrastive_loss=0.288, total=4175.9, n_correct=2363.45, ppl=3.43, accuracy=56.597, wps=15821.9, ups=1.27, wpb=12465, bsz=480.4, num_updates=8400, lr=0.000154303, gnorm=0.521, clip=0, loss_scale=8, train_wall=78, gb_free=14.4, wall=6680
2023-08-05 01:52:26 | INFO | train_inner | epoch 006:   1137 / 1474 loss=2.28, trans_loss=3.601, nll_loss=1.784, w2v_ctc_loss=1.246, task_loss=0, contrastive_loss=0.127, total=4077.2, n_correct=2300.65, ppl=3.44, accuracy=56.427, wps=15409.7, ups=1.27, wpb=12172.7, bsz=430.6, num_updates=8500, lr=0.000153393, gnorm=0.51, clip=0, loss_scale=8, train_wall=78, gb_free=16.5, wall=6759
2023-08-05 01:53:45 | INFO | train_inner | epoch 006:   1237 / 1474 loss=2.362, trans_loss=3.592, nll_loss=1.776, w2v_ctc_loss=1.233, task_loss=0, contrastive_loss=0.438, total=4133.46, n_correct=2338.63, ppl=3.42, accuracy=56.578, wps=15605.1, ups=1.26, wpb=12346.4, bsz=470.3, num_updates=8600, lr=0.000152499, gnorm=0.519, clip=0, loss_scale=8, train_wall=79, gb_free=12.7, wall=6838
2023-08-05 01:55:03 | INFO | train_inner | epoch 006:   1337 / 1474 loss=2.262, trans_loss=3.599, nll_loss=1.78, w2v_ctc_loss=1.232, task_loss=0, contrastive_loss=0.112, total=4127.77, n_correct=2341.79, ppl=3.43, accuracy=56.733, wps=15755, ups=1.28, wpb=12312.7, bsz=454.1, num_updates=8700, lr=0.00015162, gnorm=0.508, clip=0, loss_scale=8, train_wall=78, gb_free=17.2, wall=6916
2023-08-05 01:56:23 | INFO | train_inner | epoch 006:   1437 / 1474 loss=2.259, trans_loss=3.591, nll_loss=1.772, w2v_ctc_loss=1.228, task_loss=0, contrastive_loss=0.117, total=4190.32, n_correct=2386.78, ppl=3.41, accuracy=56.959, wps=15776.2, ups=1.26, wpb=12507.6, bsz=460.5, num_updates=8800, lr=0.000150756, gnorm=0.497, clip=0, loss_scale=8, train_wall=79, gb_free=17.1, wall=6996
2023-08-05 01:56:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 01:57:14 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.528 | trans_loss 5.734 | nll_loss 3.06 | w2v_ctc_loss 1.467 | task_loss 0 | contrastive_loss 0.263 | total 4003.4 | n_correct 2372.7 | ppl 8.34 | accuracy 59.267 | uer 20.582 | wer 22.549 | raw_wer 22.549 | bleu 18.35 | wps 2241.6 | wpb 4003.4 | bsz 141.8 | num_updates 8837 | best_bleu 18.35
2023-08-05 01:57:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8837 updates
2023-08-05 01:57:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 01:57:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 01:57:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt (epoch 6 @ 8837 updates, score 18.35) (writing took 24.00233026780188 seconds)
2023-08-05 01:57:39 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-05 01:57:39 | INFO | train | epoch 006 | loss 2.306 | trans_loss 3.598 | nll_loss 1.78 | w2v_ctc_loss 1.249 | task_loss 0 | contrastive_loss 0.198 | total 4138.65 | n_correct 2335.85 | ppl 3.43 | accuracy 56.44 | wps 14364.8 | ups 1.16 | wpb 12355.8 | bsz 458.5 | num_updates 8837 | lr 0.00015044 | gnorm 0.515 | clip 0 | loss_scale 8 | train_wall 1157 | gb_free 15.4 | wall 7072
2023-08-05 01:57:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 01:57:39 | INFO | fairseq.trainer | begin training epoch 7
2023-08-05 01:57:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 01:58:36 | INFO | train_inner | epoch 007:     63 / 1474 loss=2.229, trans_loss=3.569, nll_loss=1.744, w2v_ctc_loss=1.198, task_loss=0, contrastive_loss=0.132, total=4110.43, n_correct=2364.38, ppl=3.35, accuracy=57.521, wps=9179.9, ups=0.75, wpb=12272.9, bsz=462.8, num_updates=8900, lr=0.000149906, gnorm=0.507, clip=0, loss_scale=8, train_wall=78, gb_free=17.5, wall=7129
2023-08-05 01:59:54 | INFO | train_inner | epoch 007:    163 / 1474 loss=2.234, trans_loss=3.558, nll_loss=1.729, w2v_ctc_loss=1.183, task_loss=0, contrastive_loss=0.203, total=4109.53, n_correct=2371.62, ppl=3.31, accuracy=57.71, wps=15704.9, ups=1.28, wpb=12269.6, bsz=454.1, num_updates=9000, lr=0.000149071, gnorm=0.5, clip=0, loss_scale=8, train_wall=78, gb_free=13.9, wall=7207
2023-08-05 02:01:14 | INFO | train_inner | epoch 007:    263 / 1474 loss=2.208, trans_loss=3.553, nll_loss=1.721, w2v_ctc_loss=1.187, task_loss=0, contrastive_loss=0.113, total=4133.29, n_correct=2396.79, ppl=3.3, accuracy=57.987, wps=15556.8, ups=1.26, wpb=12335.8, bsz=455.5, num_updates=9100, lr=0.00014825, gnorm=0.501, clip=0, loss_scale=8, train_wall=79, gb_free=15.6, wall=7287
2023-08-05 02:02:33 | INFO | train_inner | epoch 007:    363 / 1474 loss=2.282, trans_loss=3.563, nll_loss=1.734, w2v_ctc_loss=1.179, task_loss=0, contrastive_loss=0.375, total=4194.76, n_correct=2420.46, ppl=3.33, accuracy=57.702, wps=15767.9, ups=1.26, wpb=12518.2, bsz=477.6, num_updates=9200, lr=0.000147442, gnorm=0.513, clip=0, loss_scale=16, train_wall=79, gb_free=13.3, wall=7366
2023-08-05 02:03:52 | INFO | train_inner | epoch 007:    463 / 1474 loss=2.257, trans_loss=3.561, nll_loss=1.735, w2v_ctc_loss=1.176, task_loss=0, contrastive_loss=0.295, total=4153.22, n_correct=2395.65, ppl=3.33, accuracy=57.682, wps=15746.1, ups=1.27, wpb=12403.3, bsz=463, num_updates=9300, lr=0.000146647, gnorm=0.517, clip=0, loss_scale=16, train_wall=78, gb_free=17, wall=7445
2023-08-05 02:05:10 | INFO | train_inner | epoch 007:    563 / 1474 loss=2.206, trans_loss=3.562, nll_loss=1.732, w2v_ctc_loss=1.178, task_loss=0, contrastive_loss=0.119, total=4168.14, n_correct=2416.66, ppl=3.32, accuracy=57.979, wps=15896.3, ups=1.28, wpb=12434.7, bsz=459.8, num_updates=9400, lr=0.000145865, gnorm=0.498, clip=0, loss_scale=16, train_wall=78, gb_free=17, wall=7523
2023-08-05 02:06:30 | INFO | train_inner | epoch 007:    663 / 1474 loss=2.194, trans_loss=3.559, nll_loss=1.729, w2v_ctc_loss=1.171, task_loss=0, contrastive_loss=0.108, total=4157.82, n_correct=2416.71, ppl=3.32, accuracy=58.124, wps=15630.1, ups=1.26, wpb=12406.4, bsz=455.4, num_updates=9500, lr=0.000145095, gnorm=0.491, clip=0, loss_scale=16, train_wall=79, gb_free=15.8, wall=7603
2023-08-05 02:07:49 | INFO | train_inner | epoch 007:    763 / 1474 loss=2.193, trans_loss=3.555, nll_loss=1.726, w2v_ctc_loss=1.171, task_loss=0, contrastive_loss=0.105, total=4122.1, n_correct=2388.76, ppl=3.31, accuracy=57.95, wps=15533.7, ups=1.26, wpb=12308.4, bsz=446.2, num_updates=9600, lr=0.000144338, gnorm=0.501, clip=0, loss_scale=16, train_wall=79, gb_free=15.8, wall=7682
2023-08-05 02:09:08 | INFO | train_inner | epoch 007:    863 / 1474 loss=2.201, trans_loss=3.564, nll_loss=1.737, w2v_ctc_loss=1.171, task_loss=0, contrastive_loss=0.122, total=4147.23, n_correct=2398.59, ppl=3.33, accuracy=57.836, wps=15704.6, ups=1.27, wpb=12377.6, bsz=460.9, num_updates=9700, lr=0.000143592, gnorm=0.501, clip=0, loss_scale=16, train_wall=78, gb_free=17.6, wall=7761
2023-08-05 02:10:26 | INFO | train_inner | epoch 007:    963 / 1474 loss=2.223, trans_loss=3.558, nll_loss=1.731, w2v_ctc_loss=1.158, task_loss=0, contrastive_loss=0.215, total=4140.14, n_correct=2404.5, ppl=3.32, accuracy=58.078, wps=15686, ups=1.27, wpb=12359.1, bsz=474.6, num_updates=9800, lr=0.000142857, gnorm=0.509, clip=0, loss_scale=16, train_wall=78, gb_free=16.2, wall=7839
2023-08-05 02:11:46 | INFO | train_inner | epoch 007:   1063 / 1474 loss=2.193, trans_loss=3.571, nll_loss=1.747, w2v_ctc_loss=1.176, task_loss=0, contrastive_loss=0.092, total=4103.51, n_correct=2366.86, ppl=3.36, accuracy=57.679, wps=15461.7, ups=1.26, wpb=12251.1, bsz=437.5, num_updates=9900, lr=0.000142134, gnorm=0.494, clip=0, loss_scale=16, train_wall=79, gb_free=17, wall=7919
2023-08-05 02:13:05 | INFO | train_inner | epoch 007:   1163 / 1474 loss=2.277, trans_loss=3.556, nll_loss=1.732, w2v_ctc_loss=1.165, task_loss=0, contrastive_loss=0.36, total=4137.04, n_correct=2399.28, ppl=3.32, accuracy=57.995, wps=15621, ups=1.26, wpb=12361.6, bsz=470.9, num_updates=10000, lr=0.000141421, gnorm=0.511, clip=0, loss_scale=16, train_wall=79, gb_free=16.2, wall=7998
2023-08-05 02:13:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 02:13:27 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.477 | trans_loss 5.686 | nll_loss 3.004 | w2v_ctc_loss 1.419 | task_loss 0 | contrastive_loss 0.259 | total 4003.4 | n_correct 2387.9 | ppl 8.02 | accuracy 59.647 | uer 19.452 | wer 21.353 | raw_wer 21.353 | bleu 18.31 | wps 2317.8 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 18.35
2023-08-05 02:13:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-08-05 02:13:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_7_10000.pt
2023-08-05 02:13:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_7_10000.pt
2023-08-05 02:14:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 18.31) (writing took 34.17387523688376 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:0')
2023-08-05 02:15:20 | INFO | train_inner | epoch 007:   1263 / 1474 loss=2.186, trans_loss=3.563, nll_loss=1.739, w2v_ctc_loss=1.158, task_loss=0, contrastive_loss=0.117, total=4129.52, n_correct=2395.41, ppl=3.34, accuracy=58.007, wps=9122.2, ups=0.74, wpb=12331.4, bsz=450.2, num_updates=10100, lr=0.00014072, gnorm=0.404, clip=0, loss_scale=16, train_wall=77, gb_free=16.9, wall=8133
2023-08-05 02:16:38 | INFO | train_inner | epoch 007:   1363 / 1474 loss=2.208, trans_loss=3.555, nll_loss=1.728, w2v_ctc_loss=1.169, task_loss=0, contrastive_loss=0.15, total=4172.87, n_correct=2431.96, ppl=3.31, accuracy=58.28, wps=15950.9, ups=1.28, wpb=12458.1, bsz=476.2, num_updates=10200, lr=0.000140028, gnorm=0.412, clip=0, loss_scale=16, train_wall=78, gb_free=17.3, wall=8211
2023-08-05 02:17:59 | INFO | train_inner | epoch 007:   1463 / 1474 loss=2.22, trans_loss=3.561, nll_loss=1.738, w2v_ctc_loss=1.166, task_loss=0, contrastive_loss=0.218, total=4109.42, n_correct=2377.93, ppl=3.34, accuracy=57.865, wps=15244, ups=1.24, wpb=12278.1, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.415, clip=0, loss_scale=16, train_wall=80, gb_free=16.7, wall=8292
2023-08-05 02:18:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:2')
2023-08-05 02:18:31 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.478 | trans_loss 5.691 | nll_loss 3.002 | w2v_ctc_loss 1.408 | task_loss 0 | contrastive_loss 0.261 | total 4003.4 | n_correct 2390.8 | ppl 8.01 | accuracy 59.719 | uer 19.807 | wer 21.67 | raw_wer 21.67 | bleu 18.52 | wps 2122.5 | wpb 4003.4 | bsz 141.8 | num_updates 10311 | best_bleu 18.52
2023-08-05 02:18:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10311 updates
2023-08-05 02:18:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 02:18:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 02:18:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt (epoch 7 @ 10311 updates, score 18.52) (writing took 23.744771998375654 seconds)
2023-08-05 02:18:55 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-05 02:18:55 | INFO | train | epoch 007 | loss 2.22 | trans_loss 3.56 | nll_loss 1.732 | w2v_ctc_loss 1.173 | task_loss 0 | contrastive_loss 0.183 | total 4138.65 | n_correct 2397.16 | ppl 3.32 | accuracy 57.921 | wps 14268 | ups 1.15 | wpb 12355.8 | bsz 458.5 | num_updates 10311 | lr 0.000139272 | gnorm 0.484 | clip 0 | loss_scale 16 | train_wall 1154 | gb_free 13.5 | wall 8348
2023-08-05 02:18:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 02:18:55 | INFO | fairseq.trainer | begin training epoch 8
2023-08-05 02:18:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 02:20:13 | INFO | train_inner | epoch 008:     89 / 1474 loss=2.149, trans_loss=3.537, nll_loss=1.7, w2v_ctc_loss=1.127, task_loss=0, contrastive_loss=0.11, total=4116.25, n_correct=2419.21, ppl=3.25, accuracy=58.772, wps=9122.1, ups=0.74, wpb=12273, bsz=443.3, num_updates=10400, lr=0.000138675, gnorm=0.409, clip=0, loss_scale=16, train_wall=78, gb_free=17.2, wall=8426
2023-08-05 02:21:31 | INFO | train_inner | epoch 008:    189 / 1474 loss=2.15, trans_loss=3.529, nll_loss=1.689, w2v_ctc_loss=1.122, task_loss=0, contrastive_loss=0.133, total=4037.23, n_correct=2382.62, ppl=3.22, accuracy=59.016, wps=15399.8, ups=1.28, wpb=12041.5, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.413, clip=0, loss_scale=16, train_wall=78, gb_free=13.1, wall=8504
2023-08-05 02:22:50 | INFO | train_inner | epoch 008:    289 / 1474 loss=2.154, trans_loss=3.523, nll_loss=1.684, w2v_ctc_loss=1.125, task_loss=0, contrastive_loss=0.127, total=4207.78, n_correct=2492.43, ppl=3.21, accuracy=59.234, wps=16034.3, ups=1.28, wpb=12556.5, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.412, clip=0, loss_scale=16, train_wall=78, gb_free=13.4, wall=8583
2023-08-05 02:24:10 | INFO | train_inner | epoch 008:    389 / 1474 loss=2.169, trans_loss=3.532, nll_loss=1.696, w2v_ctc_loss=1.14, task_loss=0, contrastive_loss=0.153, total=4127.24, n_correct=2428.31, ppl=3.24, accuracy=58.836, wps=15278.2, ups=1.24, wpb=12316.2, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=0.413, clip=0, loss_scale=16, train_wall=80, gb_free=12.2, wall=8663
2023-08-05 02:25:30 | INFO | train_inner | epoch 008:    489 / 1474 loss=2.251, trans_loss=3.527, nll_loss=1.692, w2v_ctc_loss=1.121, task_loss=0, contrastive_loss=0.409, total=4203.76, n_correct=2480.1, ppl=3.23, accuracy=58.997, wps=15761.6, ups=1.26, wpb=12548.2, bsz=504.5, num_updates=10800, lr=0.000136083, gnorm=0.425, clip=0, loss_scale=16, train_wall=79, gb_free=14.8, wall=8743
2023-08-05 02:26:48 | INFO | train_inner | epoch 008:    589 / 1474 loss=2.15, trans_loss=3.532, nll_loss=1.701, w2v_ctc_loss=1.141, task_loss=0, contrastive_loss=0.09, total=4062.5, n_correct=2382.18, ppl=3.25, accuracy=58.638, wps=15499.9, ups=1.28, wpb=12145.4, bsz=427.9, num_updates=10900, lr=0.000135457, gnorm=0.413, clip=0, loss_scale=16, train_wall=78, gb_free=11.7, wall=8821
2023-08-05 02:28:07 | INFO | train_inner | epoch 008:    689 / 1474 loss=2.14, trans_loss=3.523, nll_loss=1.686, w2v_ctc_loss=1.131, task_loss=0, contrastive_loss=0.099, total=4142.78, n_correct=2453.28, ppl=3.22, accuracy=59.218, wps=15628.9, ups=1.26, wpb=12364.4, bsz=448.6, num_updates=11000, lr=0.00013484, gnorm=0.404, clip=0, loss_scale=16, train_wall=79, gb_free=16, wall=8900
2023-08-05 02:29:27 | INFO | train_inner | epoch 008:    789 / 1474 loss=2.165, trans_loss=3.526, nll_loss=1.693, w2v_ctc_loss=1.126, task_loss=0, contrastive_loss=0.188, total=4118.9, n_correct=2428.77, ppl=3.23, accuracy=58.966, wps=15522.4, ups=1.26, wpb=12310.9, bsz=447.8, num_updates=11100, lr=0.000134231, gnorm=0.41, clip=0, loss_scale=16, train_wall=79, gb_free=15.4, wall=8980
2023-08-05 02:30:45 | INFO | train_inner | epoch 008:    889 / 1474 loss=2.169, trans_loss=3.527, nll_loss=1.695, w2v_ctc_loss=1.116, task_loss=0, contrastive_loss=0.198, total=4169.01, n_correct=2466.27, ppl=3.24, accuracy=59.157, wps=15836.3, ups=1.27, wpb=12452.5, bsz=473.7, num_updates=11200, lr=0.000133631, gnorm=0.418, clip=0, loss_scale=16, train_wall=78, gb_free=16.3, wall=9058
2023-08-05 02:32:04 | INFO | train_inner | epoch 008:    989 / 1474 loss=2.135, trans_loss=3.53, nll_loss=1.696, w2v_ctc_loss=1.117, task_loss=0, contrastive_loss=0.098, total=4154.69, n_correct=2457.73, ppl=3.24, accuracy=59.156, wps=15860.9, ups=1.28, wpb=12403.4, bsz=464.9, num_updates=11300, lr=0.000133038, gnorm=0.415, clip=0, loss_scale=32, train_wall=78, gb_free=17.9, wall=9137
2023-08-05 02:33:23 | INFO | train_inner | epoch 008:   1089 / 1474 loss=2.193, trans_loss=3.535, nll_loss=1.703, w2v_ctc_loss=1.115, task_loss=0, contrastive_loss=0.32, total=4199.1, n_correct=2472.18, ppl=3.26, accuracy=58.874, wps=15768.8, ups=1.26, wpb=12534.3, bsz=465.3, num_updates=11400, lr=0.000132453, gnorm=0.412, clip=0, loss_scale=32, train_wall=79, gb_free=13, wall=9216
2023-08-05 02:34:42 | INFO | train_inner | epoch 008:   1189 / 1474 loss=2.144, trans_loss=3.528, nll_loss=1.696, w2v_ctc_loss=1.12, task_loss=0, contrastive_loss=0.107, total=4177.31, n_correct=2468.91, ppl=3.24, accuracy=59.103, wps=15894, ups=1.27, wpb=12476.3, bsz=472.6, num_updates=11500, lr=0.000131876, gnorm=0.404, clip=0, loss_scale=32, train_wall=78, gb_free=15.2, wall=9294
2023-08-05 02:35:59 | INFO | train_inner | epoch 008:   1289 / 1474 loss=2.151, trans_loss=3.533, nll_loss=1.703, w2v_ctc_loss=1.128, task_loss=0, contrastive_loss=0.128, total=4063.85, n_correct=2392.95, ppl=3.26, accuracy=58.884, wps=15574.4, ups=1.28, wpb=12140.6, bsz=438.4, num_updates=11600, lr=0.000131306, gnorm=0.413, clip=0, loss_scale=32, train_wall=77, gb_free=17, wall=9372
2023-08-05 02:37:18 | INFO | train_inner | epoch 008:   1389 / 1474 loss=2.166, trans_loss=3.535, nll_loss=1.705, w2v_ctc_loss=1.121, task_loss=0, contrastive_loss=0.178, total=4141.5, n_correct=2444.98, ppl=3.26, accuracy=59.036, wps=15749, ups=1.27, wpb=12367.2, bsz=461.5, num_updates=11700, lr=0.000130744, gnorm=0.409, clip=0, loss_scale=32, train_wall=78, gb_free=16.6, wall=9451
2023-08-05 02:38:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-05 02:38:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 02:38:47 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.45 | trans_loss 5.652 | nll_loss 2.951 | w2v_ctc_loss 1.412 | task_loss 0 | contrastive_loss 0.251 | total 4003.4 | n_correct 2410.8 | ppl 7.73 | accuracy 60.219 | uer 18.807 | wer 20.491 | raw_wer 20.491 | bleu 19.28 | wps 2333.2 | wpb 4003.4 | bsz 141.8 | num_updates 11784 | best_bleu 19.28
2023-08-05 02:38:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11784 updates
2023-08-05 02:38:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 02:39:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 02:39:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt (epoch 8 @ 11784 updates, score 19.28) (writing took 24.886498039588332 seconds)
2023-08-05 02:39:12 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-05 02:39:12 | INFO | train | epoch 008 | loss 2.162 | trans_loss 3.53 | nll_loss 1.696 | w2v_ctc_loss 1.124 | task_loss 0 | contrastive_loss 0.168 | total 4138.01 | n_correct 2441.91 | ppl 3.24 | accuracy 59.012 | wps 14950.7 | ups 1.21 | wpb 12354 | bsz 458 | num_updates 11784 | lr 0.000130277 | gnorm 0.412 | clip 0 | loss_scale 16 | train_wall 1155 | gb_free 17.1 | wall 9565
2023-08-05 02:39:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 02:39:13 | INFO | fairseq.trainer | begin training epoch 9
2023-08-05 02:39:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 02:39:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-05 02:39:35 | INFO | train_inner | epoch 009:     17 / 1474 loss=2.135, trans_loss=3.527, nll_loss=1.692, w2v_ctc_loss=1.108, task_loss=0, contrastive_loss=0.129, total=4117.25, n_correct=2445.81, ppl=3.23, accuracy=59.404, wps=9001.5, ups=0.73, wpb=12287.9, bsz=458.8, num_updates=11800, lr=0.000130189, gnorm=0.413, clip=0, loss_scale=8, train_wall=80, gb_free=17.9, wall=9587
2023-08-05 02:40:54 | INFO | train_inner | epoch 009:    117 / 1474 loss=2.102, trans_loss=3.492, nll_loss=1.647, w2v_ctc_loss=1.078, task_loss=0, contrastive_loss=0.125, total=4192.68, n_correct=2526.38, ppl=3.13, accuracy=60.257, wps=15718.1, ups=1.26, wpb=12520.8, bsz=481.1, num_updates=11900, lr=0.000129641, gnorm=0.406, clip=0, loss_scale=8, train_wall=79, gb_free=16, wall=9667
2023-08-05 02:42:13 | INFO | train_inner | epoch 009:    217 / 1474 loss=2.086, trans_loss=3.498, nll_loss=1.654, w2v_ctc_loss=1.078, task_loss=0, contrastive_loss=0.084, total=4065.4, n_correct=2438.57, ppl=3.15, accuracy=59.984, wps=15427.2, ups=1.27, wpb=12138.7, bsz=429.9, num_updates=12000, lr=0.000129099, gnorm=0.409, clip=0, loss_scale=8, train_wall=78, gb_free=16.2, wall=9746
2023-08-05 02:42:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 02:42:34 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.445 | trans_loss 5.666 | nll_loss 2.964 | w2v_ctc_loss 1.36 | task_loss 0 | contrastive_loss 0.256 | total 4003.4 | n_correct 2410.7 | ppl 7.8 | accuracy 60.216 | uer 18.892 | wer 20.756 | raw_wer 20.756 | bleu 18.75 | wps 2483.1 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 19.28
2023-08-05 02:42:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-08-05 02:42:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_9_12000.pt
2023-08-05 02:42:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_9_12000.pt
2023-08-05 02:43:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.75) (writing took 34.211429208517075 seconds)
2023-08-05 02:44:27 | INFO | train_inner | epoch 009:    317 / 1474 loss=2.092, trans_loss=3.486, nll_loss=1.643, w2v_ctc_loss=1.064, task_loss=0, contrastive_loss=0.132, total=4152.87, n_correct=2509.49, ppl=3.12, accuracy=60.428, wps=9242, ups=0.74, wpb=12408.5, bsz=479.2, num_updates=12100, lr=0.000128565, gnorm=0.408, clip=0, loss_scale=8, train_wall=78, gb_free=16.9, wall=9880
2023-08-05 02:45:47 | INFO | train_inner | epoch 009:    417 / 1474 loss=2.092, trans_loss=3.504, nll_loss=1.663, w2v_ctc_loss=1.076, task_loss=0, contrastive_loss=0.099, total=4191.41, n_correct=2510.23, ppl=3.17, accuracy=59.89, wps=15725.5, ups=1.26, wpb=12514.6, bsz=464.1, num_updates=12200, lr=0.000128037, gnorm=0.401, clip=0, loss_scale=8, train_wall=79, gb_free=14.3, wall=9960
2023-08-05 02:47:06 | INFO | train_inner | epoch 009:    517 / 1474 loss=2.126, trans_loss=3.508, nll_loss=1.667, w2v_ctc_loss=1.099, task_loss=0, contrastive_loss=0.149, total=4119.12, n_correct=2460.31, ppl=3.18, accuracy=59.729, wps=15438.9, ups=1.26, wpb=12295.1, bsz=438.8, num_updates=12300, lr=0.000127515, gnorm=0.405, clip=0, loss_scale=8, train_wall=79, gb_free=16.9, wall=10039
2023-08-05 02:48:25 | INFO | train_inner | epoch 009:    617 / 1474 loss=2.118, trans_loss=3.499, nll_loss=1.66, w2v_ctc_loss=1.07, task_loss=0, contrastive_loss=0.201, total=4140.76, n_correct=2482.45, ppl=3.16, accuracy=59.952, wps=15710.7, ups=1.27, wpb=12374.8, bsz=463.2, num_updates=12400, lr=0.000127, gnorm=0.407, clip=0, loss_scale=8, train_wall=78, gb_free=15.8, wall=10118
2023-08-05 02:49:43 | INFO | train_inner | epoch 009:    717 / 1474 loss=2.102, trans_loss=3.508, nll_loss=1.671, w2v_ctc_loss=1.095, task_loss=0, contrastive_loss=0.096, total=4075.27, n_correct=2434.36, ppl=3.19, accuracy=59.735, wps=15654.9, ups=1.29, wpb=12176.3, bsz=443.7, num_updates=12500, lr=0.000126491, gnorm=0.414, clip=0, loss_scale=8, train_wall=77, gb_free=17.1, wall=10196
2023-08-05 02:51:02 | INFO | train_inner | epoch 009:    817 / 1474 loss=2.187, trans_loss=3.504, nll_loss=1.667, w2v_ctc_loss=1.088, task_loss=0, contrastive_loss=0.332, total=4215.48, n_correct=2523.03, ppl=3.18, accuracy=59.852, wps=15871, ups=1.26, wpb=12596.2, bsz=499.7, num_updates=12600, lr=0.000125988, gnorm=0.416, clip=0, loss_scale=8, train_wall=79, gb_free=17, wall=10275
2023-08-05 02:52:23 | INFO | train_inner | epoch 009:    917 / 1474 loss=2.151, trans_loss=3.509, nll_loss=1.667, w2v_ctc_loss=1.082, task_loss=0, contrastive_loss=0.318, total=4152.4, n_correct=2484.13, ppl=3.18, accuracy=59.824, wps=15415.4, ups=1.24, wpb=12388.2, bsz=450.8, num_updates=12700, lr=0.000125491, gnorm=0.41, clip=0, loss_scale=8, train_wall=80, gb_free=12.2, wall=10356
2023-08-05 02:53:41 | INFO | train_inner | epoch 009:   1017 / 1474 loss=2.103, trans_loss=3.518, nll_loss=1.68, w2v_ctc_loss=1.089, task_loss=0, contrastive_loss=0.1, total=4101.32, n_correct=2442.79, ppl=3.21, accuracy=59.561, wps=15651.8, ups=1.28, wpb=12242.4, bsz=424.9, num_updates=12800, lr=0.000125, gnorm=0.407, clip=0, loss_scale=8, train_wall=78, gb_free=16, wall=10434
2023-08-05 02:54:59 | INFO | train_inner | epoch 009:   1117 / 1474 loss=2.106, trans_loss=3.513, nll_loss=1.672, w2v_ctc_loss=1.08, task_loss=0, contrastive_loss=0.12, total=4172.83, n_correct=2501.08, ppl=3.19, accuracy=59.937, wps=15918.6, ups=1.28, wpb=12437.9, bsz=471.9, num_updates=12900, lr=0.000124515, gnorm=0.411, clip=0, loss_scale=8, train_wall=78, gb_free=16.7, wall=10512
2023-08-05 02:56:19 | INFO | train_inner | epoch 009:   1217 / 1474 loss=2.107, trans_loss=3.511, nll_loss=1.674, w2v_ctc_loss=1.095, task_loss=0, contrastive_loss=0.104, total=4138.15, n_correct=2473.19, ppl=3.19, accuracy=59.766, wps=15467.4, ups=1.25, wpb=12357.2, bsz=448.8, num_updates=13000, lr=0.000124035, gnorm=0.408, clip=0, loss_scale=8, train_wall=79, gb_free=16.3, wall=10592
2023-08-05 02:57:38 | INFO | train_inner | epoch 009:   1317 / 1474 loss=2.156, trans_loss=3.506, nll_loss=1.666, w2v_ctc_loss=1.075, task_loss=0, contrastive_loss=0.297, total=4205.27, n_correct=2526.37, ppl=3.17, accuracy=60.076, wps=15846.8, ups=1.26, wpb=12548.1, bsz=491.2, num_updates=13100, lr=0.00012356, gnorm=0.412, clip=0, loss_scale=8, train_wall=79, gb_free=16.8, wall=10671
2023-08-05 02:58:56 | INFO | train_inner | epoch 009:   1417 / 1474 loss=2.096, trans_loss=3.522, nll_loss=1.686, w2v_ctc_loss=1.087, task_loss=0, contrastive_loss=0.084, total=4071.37, n_correct=2429.32, ppl=3.22, accuracy=59.668, wps=15581.4, ups=1.28, wpb=12147.5, bsz=429, num_updates=13200, lr=0.000123091, gnorm=0.407, clip=0, loss_scale=8, train_wall=77, gb_free=15.1, wall=10749
2023-08-05 02:59:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 03:00:02 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.43 | trans_loss 5.643 | nll_loss 2.944 | w2v_ctc_loss 1.363 | task_loss 0 | contrastive_loss 0.262 | total 4003.4 | n_correct 2422 | ppl 7.7 | accuracy 60.499 | uer 18.746 | wer 20.618 | raw_wer 20.618 | bleu 18.82 | wps 2369.2 | wpb 4003.4 | bsz 141.8 | num_updates 13257 | best_bleu 19.28
2023-08-05 03:00:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13257 updates
2023-08-05 03:00:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_18.8206.pt
2023-08-05 03:00:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_18.8206.pt
2023-08-05 03:00:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_18.8206.pt (epoch 9 @ 13257 updates, score 18.82) (writing took 13.98416468128562 seconds)
2023-08-05 03:00:16 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-05 03:00:16 | INFO | train | epoch 009 | loss 2.116 | trans_loss 3.505 | nll_loss 1.666 | w2v_ctc_loss 1.083 | task_loss 0 | contrastive_loss 0.16 | total 4138.32 | n_correct 2479.51 | ppl 3.17 | accuracy 59.916 | wps 14396.8 | ups 1.17 | wpb 12355 | bsz 458.2 | num_updates 13257 | lr 0.000122827 | gnorm 0.409 | clip 0 | loss_scale 8 | train_wall 1154 | gb_free 12 | wall 10829
2023-08-05 03:00:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 03:00:17 | INFO | fairseq.trainer | begin training epoch 10
2023-08-05 03:00:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 03:00:58 | INFO | train_inner | epoch 010:     43 / 1474 loss=2.105, trans_loss=3.495, nll_loss=1.652, w2v_ctc_loss=1.06, task_loss=0, contrastive_loss=0.178, total=4113.02, n_correct=2488.98, ppl=3.14, accuracy=60.515, wps=10084.3, ups=0.82, wpb=12276.4, bsz=475.9, num_updates=13300, lr=0.000122628, gnorm=0.41, clip=0, loss_scale=8, train_wall=77, gb_free=16.6, wall=10871
2023-08-05 03:02:17 | INFO | train_inner | epoch 010:    143 / 1474 loss=2.048, trans_loss=3.471, nll_loss=1.621, w2v_ctc_loss=1.037, task_loss=0, contrastive_loss=0.1, total=4234.99, n_correct=2584.13, ppl=3.08, accuracy=61.019, wps=15981.7, ups=1.26, wpb=12647.2, bsz=473.2, num_updates=13400, lr=0.000122169, gnorm=0.398, clip=0, loss_scale=8, train_wall=79, gb_free=16.6, wall=10950
2023-08-05 03:03:36 | INFO | train_inner | epoch 010:    243 / 1474 loss=2.091, trans_loss=3.474, nll_loss=1.623, w2v_ctc_loss=1.045, task_loss=0, contrastive_loss=0.227, total=4131.11, n_correct=2521.11, ppl=3.08, accuracy=61.027, wps=15693.5, ups=1.27, wpb=12328.7, bsz=463.9, num_updates=13500, lr=0.000121716, gnorm=0.406, clip=0, loss_scale=8, train_wall=78, gb_free=16.3, wall=11028
2023-08-05 03:04:55 | INFO | train_inner | epoch 010:    343 / 1474 loss=2.061, trans_loss=3.473, nll_loss=1.628, w2v_ctc_loss=1.039, task_loss=0, contrastive_loss=0.139, total=4135.65, n_correct=2520.1, ppl=3.09, accuracy=60.936, wps=15632.2, ups=1.26, wpb=12362.4, bsz=454, num_updates=13600, lr=0.000121268, gnorm=0.406, clip=0, loss_scale=8, train_wall=78, gb_free=15.8, wall=11108
2023-08-05 03:06:14 | INFO | train_inner | epoch 010:    443 / 1474 loss=2.105, trans_loss=3.479, nll_loss=1.632, w2v_ctc_loss=1.031, task_loss=0, contrastive_loss=0.31, total=4199.14, n_correct=2553.75, ppl=3.1, accuracy=60.816, wps=15759.9, ups=1.26, wpb=12535.9, bsz=482.3, num_updates=13700, lr=0.000120824, gnorm=0.402, clip=0, loss_scale=8, train_wall=79, gb_free=17.1, wall=11187
2023-08-05 03:07:34 | INFO | train_inner | epoch 010:    543 / 1474 loss=2.069, trans_loss=3.494, nll_loss=1.647, w2v_ctc_loss=1.062, task_loss=0, contrastive_loss=0.091, total=4094.23, n_correct=2474.27, ppl=3.13, accuracy=60.433, wps=15339, ups=1.26, wpb=12209.6, bsz=433.2, num_updates=13800, lr=0.000120386, gnorm=0.413, clip=0, loss_scale=8, train_wall=79, gb_free=14.6, wall=11267
2023-08-05 03:08:53 | INFO | train_inner | epoch 010:    643 / 1474 loss=2.102, trans_loss=3.487, nll_loss=1.642, w2v_ctc_loss=1.053, task_loss=0, contrastive_loss=0.205, total=4182.84, n_correct=2536.41, ppl=3.12, accuracy=60.638, wps=15731.2, ups=1.26, wpb=12481.2, bsz=481.3, num_updates=13900, lr=0.000119952, gnorm=0.407, clip=0, loss_scale=16, train_wall=79, gb_free=16.8, wall=11346
2023-08-05 03:10:11 | INFO | train_inner | epoch 010:    743 / 1474 loss=2.073, trans_loss=3.489, nll_loss=1.645, w2v_ctc_loss=1.068, task_loss=0, contrastive_loss=0.089, total=4120.62, n_correct=2493.62, ppl=3.13, accuracy=60.516, wps=15711.3, ups=1.28, wpb=12301.2, bsz=451.7, num_updates=14000, lr=0.000119523, gnorm=0.41, clip=0, loss_scale=16, train_wall=78, gb_free=17.1, wall=11424
2023-08-05 03:10:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 03:10:34 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.439 | trans_loss 5.63 | nll_loss 2.92 | w2v_ctc_loss 1.421 | task_loss 0 | contrastive_loss 0.261 | total 4003.4 | n_correct 2431.2 | ppl 7.57 | accuracy 60.728 | uer 19.165 | wer 21.084 | raw_wer 21.084 | bleu 19.31 | wps 2358.6 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 19.31
2023-08-05 03:10:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-08-05 03:10:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_10_14000.pt
2023-08-05 03:10:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_10_14000.pt
2023-08-05 03:10:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 19.31) (writing took 24.374847412109375 seconds)
2023-08-05 03:12:18 | INFO | train_inner | epoch 010:    843 / 1474 loss=2.055, trans_loss=3.485, nll_loss=1.64, w2v_ctc_loss=1.043, task_loss=0, contrastive_loss=0.093, total=4132.62, n_correct=2506.46, ppl=3.12, accuracy=60.651, wps=9775.7, ups=0.79, wpb=12339.2, bsz=457.4, num_updates=14100, lr=0.000119098, gnorm=0.404, clip=0, loss_scale=16, train_wall=78, gb_free=16.8, wall=11551
2023-08-05 03:13:36 | INFO | train_inner | epoch 010:    943 / 1474 loss=2.078, trans_loss=3.487, nll_loss=1.641, w2v_ctc_loss=1.053, task_loss=0, contrastive_loss=0.13, total=4160.84, n_correct=2524.75, ppl=3.12, accuracy=60.679, wps=15786.9, ups=1.27, wpb=12411.3, bsz=467.9, num_updates=14200, lr=0.000118678, gnorm=0.411, clip=0, loss_scale=16, train_wall=78, gb_free=16, wall=11629
2023-08-05 03:14:55 | INFO | train_inner | epoch 010:   1043 / 1474 loss=2.065, trans_loss=3.491, nll_loss=1.647, w2v_ctc_loss=1.053, task_loss=0, contrastive_loss=0.104, total=4059.22, n_correct=2453.99, ppl=3.13, accuracy=60.455, wps=15380.6, ups=1.27, wpb=12120, bsz=431.2, num_updates=14300, lr=0.000118262, gnorm=0.412, clip=0, loss_scale=16, train_wall=78, gb_free=10, wall=11708
2023-08-05 03:16:13 | INFO | train_inner | epoch 010:   1143 / 1474 loss=2.071, trans_loss=3.499, nll_loss=1.658, w2v_ctc_loss=1.066, task_loss=0, contrastive_loss=0.088, total=4045.82, n_correct=2436.13, ppl=3.15, accuracy=60.214, wps=15525.2, ups=1.29, wpb=12079.3, bsz=422.8, num_updates=14400, lr=0.000117851, gnorm=0.413, clip=0, loss_scale=16, train_wall=77, gb_free=13.2, wall=11786
2023-08-05 03:17:31 | INFO | train_inner | epoch 010:   1243 / 1474 loss=2.063, trans_loss=3.485, nll_loss=1.645, w2v_ctc_loss=1.061, task_loss=0, contrastive_loss=0.084, total=4107.6, n_correct=2486.6, ppl=3.13, accuracy=60.537, wps=15668.8, ups=1.28, wpb=12284.6, bsz=446.5, num_updates=14500, lr=0.000117444, gnorm=0.408, clip=0, loss_scale=16, train_wall=78, gb_free=16.7, wall=11864
2023-08-05 03:18:51 | INFO | train_inner | epoch 010:   1343 / 1474 loss=2.064, trans_loss=3.492, nll_loss=1.651, w2v_ctc_loss=1.055, task_loss=0, contrastive_loss=0.096, total=4127.69, n_correct=2498.81, ppl=3.14, accuracy=60.538, wps=15498.9, ups=1.26, wpb=12326.4, bsz=452.2, num_updates=14600, lr=0.000117041, gnorm=0.408, clip=0, loss_scale=16, train_wall=79, gb_free=16.3, wall=11944
2023-08-05 03:20:10 | INFO | train_inner | epoch 010:   1443 / 1474 loss=2.146, trans_loss=3.496, nll_loss=1.655, w2v_ctc_loss=1.041, task_loss=0, contrastive_loss=0.34, total=4195.02, n_correct=2531.99, ppl=3.15, accuracy=60.357, wps=15802.6, ups=1.26, wpb=12514.1, bsz=483, num_updates=14700, lr=0.000116642, gnorm=0.413, clip=0, loss_scale=16, train_wall=79, gb_free=16.5, wall=12023
2023-08-05 03:20:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 03:20:56 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.414 | trans_loss 5.617 | nll_loss 2.908 | w2v_ctc_loss 1.382 | task_loss 0 | contrastive_loss 0.252 | total 4003.4 | n_correct 2431.6 | ppl 7.51 | accuracy 60.738 | uer 18.199 | wer 20.014 | raw_wer 20.014 | bleu 19.19 | wps 2360.3 | wpb 4003.4 | bsz 141.8 | num_updates 14731 | best_bleu 19.31
2023-08-05 03:20:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14731 updates
2023-08-05 03:20:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.1904.pt
2023-08-05 03:21:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.1904.pt
2023-08-05 03:21:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.1904.pt (epoch 10 @ 14731 updates, score 19.19) (writing took 16.90722419321537 seconds)
2023-08-05 03:21:13 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-05 03:21:14 | INFO | train | epoch 010 | loss 2.08 | trans_loss 3.485 | nll_loss 1.641 | w2v_ctc_loss 1.049 | task_loss 0 | contrastive_loss 0.161 | total 4138.65 | n_correct 2510.07 | ppl 3.12 | accuracy 60.65 | wps 14487.9 | ups 1.17 | wpb 12355.8 | bsz 458.5 | num_updates 14731 | lr 0.00011652 | gnorm 0.408 | clip 0 | loss_scale 16 | train_wall 1153 | gb_free 17.4 | wall 12086
2023-08-05 03:21:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 03:21:14 | INFO | fairseq.trainer | begin training epoch 11
2023-08-05 03:21:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 03:22:15 | INFO | train_inner | epoch 011:     69 / 1474 loss=2.051, trans_loss=3.461, nll_loss=1.609, w2v_ctc_loss=1.023, task_loss=0, contrastive_loss=0.171, total=4166, n_correct=2563.15, ppl=3.05, accuracy=61.525, wps=9965.1, ups=0.8, wpb=12436.1, bsz=475.7, num_updates=14800, lr=0.000116248, gnorm=0.401, clip=0, loss_scale=16, train_wall=77, gb_free=17.9, wall=12148
2023-08-05 03:23:34 | INFO | train_inner | epoch 011:    169 / 1474 loss=2.027, trans_loss=3.461, nll_loss=1.612, w2v_ctc_loss=1.022, task_loss=0, contrastive_loss=0.095, total=4100.74, n_correct=2517.6, ppl=3.06, accuracy=61.394, wps=15561.5, ups=1.27, wpb=12251.1, bsz=450.6, num_updates=14900, lr=0.000115857, gnorm=0.404, clip=0, loss_scale=16, train_wall=78, gb_free=14.7, wall=12226
2023-08-05 03:24:52 | INFO | train_inner | epoch 011:    269 / 1474 loss=2.015, trans_loss=3.461, nll_loss=1.61, w2v_ctc_loss=1.015, task_loss=0, contrastive_loss=0.08, total=4115.58, n_correct=2529.11, ppl=3.05, accuracy=61.452, wps=15590, ups=1.27, wpb=12290.6, bsz=444.2, num_updates=15000, lr=0.00011547, gnorm=0.401, clip=0, loss_scale=16, train_wall=78, gb_free=16.2, wall=12305
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:0')
2023-08-05 03:25:48 | INFO | train_inner | epoch 011:    369 / 1474 loss=2.183, trans_loss=5.148, nll_loss=2.398, w2v_ctc_loss=0.77, task_loss=0, contrastive_loss=0.068, total=4094.16, n_correct=2509.05, ppl=5.27, accuracy=61.284, wps=14746.2, ups=1.79, wpb=8227.1, bsz=296.5, num_updates=15100, lr=0.000115087, gnorm=0.545, clip=0, loss_scale=16, train_wall=55, gb_free=13.3, wall=12361
2023-08-05 03:26:44 | INFO | train_inner | epoch 011:    469 / 1474 loss=2.213, trans_loss=5.186, nll_loss=2.428, w2v_ctc_loss=0.773, task_loss=0, contrastive_loss=0.186, total=4112.8, n_correct=2507.36, ppl=5.38, accuracy=60.965, wps=14704.5, ups=1.79, wpb=8225.6, bsz=302.2, num_updates=15200, lr=0.000114708, gnorm=0.548, clip=0, loss_scale=16, train_wall=55, gb_free=17.4, wall=12417
2023-08-05 03:27:40 | INFO | train_inner | epoch 011:    569 / 1474 loss=2.21, trans_loss=5.183, nll_loss=2.425, w2v_ctc_loss=0.779, task_loss=0, contrastive_loss=0.182, total=4071.06, n_correct=2483.07, ppl=5.37, accuracy=60.993, wps=14469.3, ups=1.78, wpb=8142.1, bsz=292.6, num_updates=15300, lr=0.000114332, gnorm=0.548, clip=0, loss_scale=16, train_wall=56, gb_free=16.6, wall=12473
2023-08-05 03:28:38 | INFO | train_inner | epoch 011:    669 / 1474 loss=2.218, trans_loss=5.181, nll_loss=2.422, w2v_ctc_loss=0.773, task_loss=0, contrastive_loss=0.243, total=4156.4, n_correct=2540.09, ppl=5.36, accuracy=61.113, wps=14552.9, ups=1.75, wpb=8312.8, bsz=310.2, num_updates=15400, lr=0.000113961, gnorm=0.547, clip=0, loss_scale=16, train_wall=56, gb_free=16.4, wall=12530
2023-08-05 03:29:34 | INFO | train_inner | epoch 011:    769 / 1474 loss=2.197, trans_loss=5.188, nll_loss=2.432, w2v_ctc_loss=0.78, task_loss=0, contrastive_loss=0.067, total=4169.17, n_correct=2549.91, ppl=5.39, accuracy=61.161, wps=14810.7, ups=1.78, wpb=8338.3, bsz=304.8, num_updates=15500, lr=0.000113592, gnorm=0.537, clip=0, loss_scale=16, train_wall=56, gb_free=12.7, wall=12587
2023-08-05 03:30:29 | INFO | train_inner | epoch 011:    869 / 1474 loss=2.197, trans_loss=5.193, nll_loss=2.438, w2v_ctc_loss=0.778, task_loss=0, contrastive_loss=0.058, total=4120.01, n_correct=2508.37, ppl=5.42, accuracy=60.883, wps=14862.2, ups=1.8, wpb=8240, bsz=293.5, num_updates=15600, lr=0.000113228, gnorm=0.551, clip=0, loss_scale=16, train_wall=55, gb_free=13.9, wall=12642
2023-08-05 03:31:25 | INFO | train_inner | epoch 011:    969 / 1474 loss=2.199, trans_loss=5.192, nll_loss=2.437, w2v_ctc_loss=0.782, task_loss=0, contrastive_loss=0.07, total=4145.45, n_correct=2526.39, ppl=5.42, accuracy=60.944, wps=14759, ups=1.78, wpb=8290.9, bsz=303.7, num_updates=15700, lr=0.000112867, gnorm=0.545, clip=0, loss_scale=16, train_wall=55, gb_free=17.3, wall=12698
2023-08-05 03:32:22 | INFO | train_inner | epoch 011:   1069 / 1474 loss=2.201, trans_loss=5.188, nll_loss=2.433, w2v_ctc_loss=0.782, task_loss=0, contrastive_loss=0.086, total=4141.18, n_correct=2528.35, ppl=5.4, accuracy=61.054, wps=14600.9, ups=1.76, wpb=8282.4, bsz=309.4, num_updates=15800, lr=0.000112509, gnorm=0.543, clip=0, loss_scale=16, train_wall=56, gb_free=16.9, wall=12755
2023-08-05 03:33:18 | INFO | train_inner | epoch 011:   1169 / 1474 loss=2.202, trans_loss=5.194, nll_loss=2.441, w2v_ctc_loss=0.785, task_loss=0, contrastive_loss=0.074, total=4173.93, n_correct=2541.94, ppl=5.43, accuracy=60.9, wps=14899.6, ups=1.78, wpb=8347.9, bsz=307.2, num_updates=15900, lr=0.000112154, gnorm=0.537, clip=0, loss_scale=32, train_wall=55, gb_free=17.2, wall=12811
2023-08-05 03:34:14 | INFO | train_inner | epoch 011:   1269 / 1474 loss=2.211, trans_loss=5.187, nll_loss=2.433, w2v_ctc_loss=0.785, task_loss=0, contrastive_loss=0.14, total=4174.26, n_correct=2548.01, ppl=5.4, accuracy=61.041, wps=14943, ups=1.79, wpb=8348.5, bsz=314.4, num_updates=16000, lr=0.000111803, gnorm=0.55, clip=0, loss_scale=32, train_wall=55, gb_free=17.7, wall=12867
2023-08-05 03:34:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:6')
2023-08-05 03:34:37 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.419 | trans_loss 5.608 | nll_loss 2.899 | w2v_ctc_loss 1.415 | task_loss 0 | contrastive_loss 0.253 | total 4003.4 | n_correct 2443.3 | ppl 7.46 | accuracy 61.031 | uer 18.382 | wer 20.201 | raw_wer 20.201 | bleu 18.98 | wps 2213.4 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.31
2023-08-05 03:34:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-08-05 03:34:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_11_16000.pt
2023-08-05 03:34:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_11_16000.pt
2023-08-05 03:35:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 18.98) (writing took 25.918120194226503 seconds)
2023-08-05 03:36:01 | INFO | train_inner | epoch 011:   1369 / 1474 loss=2.228, trans_loss=5.187, nll_loss=2.434, w2v_ctc_loss=0.769, task_loss=0, contrastive_loss=0.301, total=4191.56, n_correct=2557.54, ppl=5.4, accuracy=61.016, wps=7827.6, ups=0.93, wpb=8383.1, bsz=327.7, num_updates=16100, lr=0.000111456, gnorm=0.549, clip=0, loss_scale=32, train_wall=56, gb_free=17.8, wall=12974
2023-08-05 03:36:58 | INFO | train_inner | epoch 011:   1469 / 1474 loss=2.197, trans_loss=5.192, nll_loss=2.44, w2v_ctc_loss=0.775, task_loss=0, contrastive_loss=0.078, total=4161.81, n_correct=2537.61, ppl=5.43, accuracy=60.974, wps=14732.7, ups=1.77, wpb=8323.6, bsz=313.2, num_updates=16200, lr=0.000111111, gnorm=0.555, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=13031
2023-08-05 03:37:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 03:37:22 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.391 | trans_loss 5.601 | nll_loss 2.89 | w2v_ctc_loss 1.341 | task_loss 0 | contrastive_loss 0.252 | total 4003.4 | n_correct 2447.7 | ppl 7.41 | accuracy 61.141 | uer 18.347 | wer 20.182 | raw_wer 20.182 | bleu 19.7 | wps 2421.7 | wpb 4003.4 | bsz 141.8 | num_updates 16205 | best_bleu 19.7
2023-08-05 03:37:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16205 updates
2023-08-05 03:37:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 03:37:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 03:37:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt (epoch 11 @ 16205 updates, score 19.7) (writing took 23.97138581611216 seconds)
2023-08-05 03:37:47 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-05 03:37:47 | INFO | train | epoch 011 | loss 2.159 | trans_loss 4.754 | nll_loss 2.225 | w2v_ctc_loss 0.838 | task_loss 0 | contrastive_loss 0.119 | total 4138.65 | n_correct 2529.36 | ppl 4.67 | accuracy 61.116 | wps 13391.8 | ups 1.48 | wpb 9023.7 | bsz 333.5 | num_updates 16205 | lr 0.000111094 | gnorm 0.52 | clip 0 | loss_scale 32 | train_wall 880 | gb_free 17.5 | wall 13080
2023-08-05 03:37:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 03:37:47 | INFO | fairseq.trainer | begin training epoch 12
2023-08-05 03:37:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 03:38:47 | INFO | train_inner | epoch 012:     95 / 1474 loss=2.176, trans_loss=5.135, nll_loss=2.363, w2v_ctc_loss=0.762, task_loss=0, contrastive_loss=0.109, total=4139.2, n_correct=2565.29, ppl=5.15, accuracy=61.976, wps=7580.1, ups=0.92, wpb=8278.4, bsz=312.5, num_updates=16300, lr=0.00011077, gnorm=0.548, clip=0, loss_scale=32, train_wall=55, gb_free=16.3, wall=13140
2023-08-05 03:39:42 | INFO | train_inner | epoch 012:    195 / 1474 loss=2.172, trans_loss=5.146, nll_loss=2.375, w2v_ctc_loss=0.767, task_loss=0, contrastive_loss=0.06, total=4126.87, n_correct=2548.16, ppl=5.19, accuracy=61.746, wps=14883.7, ups=1.8, wpb=8253.7, bsz=295.9, num_updates=16400, lr=0.000110432, gnorm=0.548, clip=0, loss_scale=32, train_wall=55, gb_free=16.7, wall=13195
2023-08-05 03:40:39 | INFO | train_inner | epoch 012:    295 / 1474 loss=2.171, trans_loss=5.141, nll_loss=2.372, w2v_ctc_loss=0.752, task_loss=0, contrastive_loss=0.089, total=4203.54, n_correct=2603.64, ppl=5.18, accuracy=61.939, wps=14919.8, ups=1.77, wpb=8407.1, bsz=321.1, num_updates=16500, lr=0.000110096, gnorm=0.546, clip=0, loss_scale=32, train_wall=56, gb_free=15, wall=13252
2023-08-05 03:41:35 | INFO | train_inner | epoch 012:    395 / 1474 loss=2.174, trans_loss=5.153, nll_loss=2.386, w2v_ctc_loss=0.76, task_loss=0, contrastive_loss=0.073, total=4149.28, n_correct=2564.95, ppl=5.23, accuracy=61.817, wps=14652.5, ups=1.77, wpb=8298.6, bsz=307.1, num_updates=16600, lr=0.000109764, gnorm=0.536, clip=0, loss_scale=32, train_wall=56, gb_free=15.4, wall=13308
2023-08-05 03:42:31 | INFO | train_inner | epoch 012:    495 / 1474 loss=2.185, trans_loss=5.165, nll_loss=2.403, w2v_ctc_loss=0.772, task_loss=0, contrastive_loss=0.082, total=4106.46, n_correct=2526.44, ppl=5.29, accuracy=61.524, wps=14749.2, ups=1.8, wpb=8212.9, bsz=301.2, num_updates=16700, lr=0.000109435, gnorm=0.542, clip=0, loss_scale=32, train_wall=55, gb_free=18.1, wall=13364
2023-08-05 03:43:27 | INFO | train_inner | epoch 012:    595 / 1474 loss=2.186, trans_loss=5.154, nll_loss=2.389, w2v_ctc_loss=0.762, task_loss=0, contrastive_loss=0.144, total=4190.91, n_correct=2588.41, ppl=5.24, accuracy=61.762, wps=14938, ups=1.78, wpb=8381.8, bsz=316.5, num_updates=16800, lr=0.000109109, gnorm=0.539, clip=0, loss_scale=32, train_wall=55, gb_free=16.2, wall=13420
2023-08-05 03:44:23 | INFO | train_inner | epoch 012:    695 / 1474 loss=2.191, trans_loss=5.152, nll_loss=2.387, w2v_ctc_loss=0.751, task_loss=0, contrastive_loss=0.234, total=4203.66, n_correct=2602.54, ppl=5.23, accuracy=61.911, wps=14982.8, ups=1.78, wpb=8407.3, bsz=324.4, num_updates=16900, lr=0.000108786, gnorm=0.54, clip=0, loss_scale=32, train_wall=55, gb_free=17.7, wall=13476
2023-08-05 03:45:20 | INFO | train_inner | epoch 012:    795 / 1474 loss=2.175, trans_loss=5.152, nll_loss=2.386, w2v_ctc_loss=0.768, task_loss=0, contrastive_loss=0.071, total=4095.72, n_correct=2530.15, ppl=5.23, accuracy=61.775, wps=14510.5, ups=1.77, wpb=8191.4, bsz=298.9, num_updates=17000, lr=0.000108465, gnorm=0.545, clip=0, loss_scale=32, train_wall=56, gb_free=17.5, wall=13533
2023-08-05 03:46:16 | INFO | train_inner | epoch 012:    895 / 1474 loss=2.188, trans_loss=5.163, nll_loss=2.401, w2v_ctc_loss=0.765, task_loss=0, contrastive_loss=0.121, total=4162.82, n_correct=2561.24, ppl=5.28, accuracy=61.527, wps=14892.4, ups=1.79, wpb=8325.6, bsz=305.4, num_updates=17100, lr=0.000108148, gnorm=0.545, clip=0, loss_scale=32, train_wall=55, gb_free=16.5, wall=13589
2023-08-05 03:47:11 | INFO | train_inner | epoch 012:    995 / 1474 loss=2.19, trans_loss=5.17, nll_loss=2.41, w2v_ctc_loss=0.768, task_loss=0, contrastive_loss=0.132, total=4117.63, n_correct=2531.17, ppl=5.32, accuracy=61.472, wps=14771.5, ups=1.79, wpb=8235.3, bsz=301.6, num_updates=17200, lr=0.000107833, gnorm=0.547, clip=0, loss_scale=32, train_wall=55, gb_free=17.1, wall=13644
2023-08-05 03:48:07 | INFO | train_inner | epoch 012:   1095 / 1474 loss=2.203, trans_loss=5.177, nll_loss=2.419, w2v_ctc_loss=0.775, task_loss=0, contrastive_loss=0.176, total=4046.48, n_correct=2481.01, ppl=5.35, accuracy=61.313, wps=14434.1, ups=1.78, wpb=8093, bsz=289.6, num_updates=17300, lr=0.000107521, gnorm=0.561, clip=0, loss_scale=32, train_wall=56, gb_free=16.3, wall=13700
2023-08-05 03:49:04 | INFO | train_inner | epoch 012:   1195 / 1474 loss=2.207, trans_loss=5.184, nll_loss=2.43, w2v_ctc_loss=0.784, task_loss=0, contrastive_loss=0.141, total=4201.13, n_correct=2568.35, ppl=5.39, accuracy=61.135, wps=14798.7, ups=1.76, wpb=8402.3, bsz=319.2, num_updates=17400, lr=0.000107211, gnorm=0.547, clip=0, loss_scale=32, train_wall=56, gb_free=17.5, wall=13757
2023-08-05 03:50:00 | INFO | train_inner | epoch 012:   1295 / 1474 loss=2.187, trans_loss=5.174, nll_loss=2.415, w2v_ctc_loss=0.782, task_loss=0, contrastive_loss=0.058, total=4070.27, n_correct=2496.94, ppl=5.34, accuracy=61.346, wps=14612.9, ups=1.8, wpb=8140.5, bsz=286.1, num_updates=17500, lr=0.000106904, gnorm=0.547, clip=0, loss_scale=32, train_wall=55, gb_free=16.2, wall=13813
2023-08-05 03:50:56 | INFO | train_inner | epoch 012:   1395 / 1474 loss=2.198, trans_loss=5.178, nll_loss=2.422, w2v_ctc_loss=0.768, task_loss=0, contrastive_loss=0.163, total=4139.63, n_correct=2534.84, ppl=5.36, accuracy=61.233, wps=14895.4, ups=1.8, wpb=8279.3, bsz=305.8, num_updates=17600, lr=0.0001066, gnorm=0.55, clip=0, loss_scale=32, train_wall=55, gb_free=17.3, wall=13869
2023-08-05 03:51:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 03:52:03 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.408 | trans_loss 5.593 | nll_loss 2.876 | w2v_ctc_loss 1.408 | task_loss 0 | contrastive_loss 0.261 | total 4003.4 | n_correct 2457.6 | ppl 7.34 | accuracy 61.388 | uer 18.358 | wer 20.171 | raw_wer 20.171 | bleu 19.63 | wps 2238.1 | wpb 4003.4 | bsz 141.8 | num_updates 17679 | best_bleu 19.7
2023-08-05 03:52:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17679 updates
2023-08-05 03:52:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.6304.pt
2023-08-05 03:52:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.6304.pt
2023-08-05 03:52:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.6304.pt (epoch 12 @ 17679 updates, score 19.63) (writing took 13.77167009562254 seconds)
2023-08-05 03:52:17 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-05 03:52:17 | INFO | train | epoch 012 | loss 2.186 | trans_loss 5.161 | nll_loss 2.398 | w2v_ctc_loss 0.767 | task_loss 0 | contrastive_loss 0.116 | total 4138.65 | n_correct 2549.33 | ppl 5.27 | accuracy 61.598 | wps 14015.7 | ups 1.69 | wpb 8277.3 | bsz 305.7 | num_updates 17679 | lr 0.000106362 | gnorm 0.546 | clip 0 | loss_scale 32 | train_wall 818 | gb_free 13.3 | wall 13950
2023-08-05 03:52:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 03:52:17 | INFO | fairseq.trainer | begin training epoch 13
2023-08-05 03:52:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 03:52:37 | INFO | train_inner | epoch 013:     21 / 1474 loss=2.187, trans_loss=5.175, nll_loss=2.417, w2v_ctc_loss=0.78, task_loss=0, contrastive_loss=0.066, total=4096.49, n_correct=2517.7, ppl=5.34, accuracy=61.46, wps=8095.1, ups=0.99, wpb=8193, bsz=295.4, num_updates=17700, lr=0.000106299, gnorm=0.557, clip=0, loss_scale=32, train_wall=56, gb_free=15, wall=13970
2023-08-05 03:53:33 | INFO | train_inner | epoch 013:    121 / 1474 loss=2.161, trans_loss=5.126, nll_loss=2.353, w2v_ctc_loss=0.753, task_loss=0, contrastive_loss=0.079, total=4160.97, n_correct=2591.39, ppl=5.11, accuracy=62.279, wps=14709.8, ups=1.77, wpb=8321.9, bsz=302.9, num_updates=17800, lr=0.000106, gnorm=0.543, clip=0, loss_scale=32, train_wall=56, gb_free=16.6, wall=14026
2023-08-05 03:54:30 | INFO | train_inner | epoch 013:    221 / 1474 loss=2.194, trans_loss=5.133, nll_loss=2.363, w2v_ctc_loss=0.752, task_loss=0, contrastive_loss=0.296, total=4212.08, n_correct=2617.59, ppl=5.14, accuracy=62.145, wps=14939.1, ups=1.77, wpb=8424.2, bsz=329.7, num_updates=17900, lr=0.000105703, gnorm=0.551, clip=0, loss_scale=32, train_wall=56, gb_free=15, wall=14083
2023-08-05 03:55:26 | INFO | train_inner | epoch 013:    321 / 1474 loss=2.156, trans_loss=5.127, nll_loss=2.353, w2v_ctc_loss=0.748, task_loss=0, contrastive_loss=0.063, total=4102.3, n_correct=2557.83, ppl=5.11, accuracy=62.351, wps=14699.2, ups=1.79, wpb=8204.6, bsz=294.1, num_updates=18000, lr=0.000105409, gnorm=0.542, clip=0, loss_scale=64, train_wall=55, gb_free=17.5, wall=14139
2023-08-05 03:55:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 03:55:50 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.402 | trans_loss 5.602 | nll_loss 2.887 | w2v_ctc_loss 1.369 | task_loss 0 | contrastive_loss 0.26 | total 4003.4 | n_correct 2454 | ppl 7.4 | accuracy 61.298 | uer 18.507 | wer 20.324 | raw_wer 20.324 | bleu 19.66 | wps 2117.7 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.7
2023-08-05 03:55:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-08-05 03:55:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_13_18000.pt
2023-08-05 03:55:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_13_18000.pt
2023-08-05 03:56:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.66) (writing took 32.95916715078056 seconds)
2023-08-05 03:57:19 | INFO | train_inner | epoch 013:    421 / 1474 loss=2.165, trans_loss=5.13, nll_loss=2.359, w2v_ctc_loss=0.748, task_loss=0, contrastive_loss=0.11, total=4177.29, n_correct=2604.64, ppl=5.13, accuracy=62.352, wps=7346.4, ups=0.88, wpb=8354.6, bsz=318.4, num_updates=18100, lr=0.000105118, gnorm=0.542, clip=0, loss_scale=64, train_wall=55, gb_free=17.8, wall=14252
2023-08-05 03:58:16 | INFO | train_inner | epoch 013:    521 / 1474 loss=2.177, trans_loss=5.142, nll_loss=2.373, w2v_ctc_loss=0.758, task_loss=0, contrastive_loss=0.146, total=4201.22, n_correct=2602.88, ppl=5.18, accuracy=61.955, wps=14823.5, ups=1.76, wpb=8402.4, bsz=319, num_updates=18200, lr=0.000104828, gnorm=0.543, clip=0, loss_scale=64, train_wall=56, gb_free=13.4, wall=14309
2023-08-05 03:59:12 | INFO | train_inner | epoch 013:    621 / 1474 loss=2.155, trans_loss=5.133, nll_loss=2.362, w2v_ctc_loss=0.746, task_loss=0, contrastive_loss=0.061, total=4161.98, n_correct=2592.42, ppl=5.14, accuracy=62.288, wps=14964.3, ups=1.8, wpb=8324, bsz=308.3, num_updates=18300, lr=0.000104542, gnorm=0.542, clip=0, loss_scale=64, train_wall=55, gb_free=16.2, wall=14365
2023-08-05 04:00:08 | INFO | train_inner | epoch 013:    721 / 1474 loss=2.17, trans_loss=5.147, nll_loss=2.38, w2v_ctc_loss=0.769, task_loss=0, contrastive_loss=0.06, total=4096.76, n_correct=2535.34, ppl=5.2, accuracy=61.886, wps=14642.2, ups=1.79, wpb=8193.5, bsz=284.6, num_updates=18400, lr=0.000104257, gnorm=0.548, clip=0, loss_scale=64, train_wall=55, gb_free=16.9, wall=14421
2023-08-05 04:01:04 | INFO | train_inner | epoch 013:    821 / 1474 loss=2.175, trans_loss=5.148, nll_loss=2.383, w2v_ctc_loss=0.755, task_loss=0, contrastive_loss=0.104, total=4121.73, n_correct=2553.23, ppl=5.22, accuracy=61.946, wps=14487.9, ups=1.76, wpb=8243.5, bsz=306.7, num_updates=18500, lr=0.000103975, gnorm=0.551, clip=0, loss_scale=64, train_wall=56, gb_free=15.2, wall=14477
2023-08-05 04:02:01 | INFO | train_inner | epoch 013:    921 / 1474 loss=2.163, trans_loss=5.146, nll_loss=2.38, w2v_ctc_loss=0.753, task_loss=0, contrastive_loss=0.069, total=4107.01, n_correct=2552.42, ppl=5.21, accuracy=62.148, wps=14653.5, ups=1.78, wpb=8214, bsz=296.5, num_updates=18600, lr=0.000103695, gnorm=0.543, clip=0, loss_scale=64, train_wall=56, gb_free=16.3, wall=14533
2023-08-05 04:02:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-05 04:02:57 | INFO | train_inner | epoch 013:   1022 / 1474 loss=2.181, trans_loss=5.151, nll_loss=2.387, w2v_ctc_loss=0.767, task_loss=0, contrastive_loss=0.119, total=4089.17, n_correct=2528.69, ppl=5.23, accuracy=61.839, wps=14601.4, ups=1.79, wpb=8178.3, bsz=294.7, num_updates=18700, lr=0.000103418, gnorm=0.545, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=14590
2023-08-05 04:03:53 | INFO | train_inner | epoch 013:   1122 / 1474 loss=2.165, trans_loss=5.14, nll_loss=2.372, w2v_ctc_loss=0.748, task_loss=0, contrastive_loss=0.102, total=4098.77, n_correct=2551.58, ppl=5.18, accuracy=62.252, wps=14634.8, ups=1.79, wpb=8197.5, bsz=304.8, num_updates=18800, lr=0.000103142, gnorm=0.547, clip=0, loss_scale=32, train_wall=55, gb_free=14.1, wall=14646
2023-08-05 04:04:49 | INFO | train_inner | epoch 013:   1222 / 1474 loss=2.17, trans_loss=5.154, nll_loss=2.391, w2v_ctc_loss=0.762, task_loss=0, contrastive_loss=0.062, total=4115.57, n_correct=2549.34, ppl=5.24, accuracy=61.944, wps=14695.6, ups=1.79, wpb=8231.1, bsz=295.9, num_updates=18900, lr=0.000102869, gnorm=0.546, clip=0, loss_scale=32, train_wall=55, gb_free=15.4, wall=14702
2023-08-05 04:05:45 | INFO | train_inner | epoch 013:   1322 / 1474 loss=2.179, trans_loss=5.143, nll_loss=2.378, w2v_ctc_loss=0.759, task_loss=0, contrastive_loss=0.16, total=4111.02, n_correct=2554.78, ppl=5.2, accuracy=62.145, wps=14544.9, ups=1.77, wpb=8222, bsz=307.8, num_updates=19000, lr=0.000102598, gnorm=0.549, clip=0, loss_scale=32, train_wall=56, gb_free=18.1, wall=14758
2023-08-05 04:06:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-05 04:06:42 | INFO | train_inner | epoch 013:   1423 / 1474 loss=2.167, trans_loss=5.155, nll_loss=2.393, w2v_ctc_loss=0.758, task_loss=0, contrastive_loss=0.057, total=4152, n_correct=2566.24, ppl=5.25, accuracy=61.807, wps=14721.9, ups=1.77, wpb=8304, bsz=303.4, num_updates=19100, lr=0.000102329, gnorm=0.54, clip=0, loss_scale=16, train_wall=56, gb_free=15.6, wall=14814
2023-08-05 04:07:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 04:07:33 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.389 | trans_loss 5.585 | nll_loss 2.869 | w2v_ctc_loss 1.375 | task_loss 0 | contrastive_loss 0.248 | total 4003.4 | n_correct 2454.3 | ppl 7.3 | accuracy 61.305 | uer 18.077 | wer 19.783 | raw_wer 19.783 | bleu 19.56 | wps 2171.6 | wpb 4003.4 | bsz 141.8 | num_updates 19151 | best_bleu 19.7
2023-08-05 04:07:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19151 updates
2023-08-05 04:07:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.5606.pt
2023-08-05 04:07:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.5606.pt
2023-08-05 04:07:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.5606.pt (epoch 13 @ 19151 updates, score 19.56) (writing took 19.08335868269205 seconds)
2023-08-05 04:07:53 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-05 04:07:53 | INFO | train | epoch 013 | loss 2.17 | trans_loss 5.141 | nll_loss 2.373 | w2v_ctc_loss 0.756 | task_loss 0 | contrastive_loss 0.107 | total 4137.69 | n_correct 2569.6 | ppl 5.18 | accuracy 62.102 | wps 13022 | ups 1.57 | wpb 8275.4 | bsz 305.2 | num_updates 19151 | lr 0.000102193 | gnorm 0.545 | clip 0 | loss_scale 16 | train_wall 819 | gb_free 17.9 | wall 14886
2023-08-05 04:07:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 04:07:53 | INFO | fairseq.trainer | begin training epoch 14
2023-08-05 04:07:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 04:08:28 | INFO | train_inner | epoch 014:     49 / 1474 loss=2.15, trans_loss=5.109, nll_loss=2.335, w2v_ctc_loss=0.747, task_loss=0, contrastive_loss=0.074, total=4182.69, n_correct=2623.74, ppl=5.05, accuracy=62.729, wps=7871.5, ups=0.94, wpb=8365.4, bsz=322.3, num_updates=19200, lr=0.000102062, gnorm=0.537, clip=0, loss_scale=16, train_wall=56, gb_free=16.3, wall=14921
2023-08-05 04:09:24 | INFO | train_inner | epoch 014:    149 / 1474 loss=2.137, trans_loss=5.097, nll_loss=2.317, w2v_ctc_loss=0.739, task_loss=0, contrastive_loss=0.056, total=4086.4, n_correct=2576.39, ppl=4.98, accuracy=63.048, wps=14652.3, ups=1.79, wpb=8172.8, bsz=301.5, num_updates=19300, lr=0.000101797, gnorm=0.54, clip=0, loss_scale=16, train_wall=55, gb_free=17.2, wall=14977
2023-08-05 04:10:20 | INFO | train_inner | epoch 014:    249 / 1474 loss=2.161, trans_loss=5.117, nll_loss=2.341, w2v_ctc_loss=0.744, task_loss=0, contrastive_loss=0.158, total=4103.37, n_correct=2567.03, ppl=5.07, accuracy=62.559, wps=14669.3, ups=1.79, wpb=8206.7, bsz=294, num_updates=19400, lr=0.000101535, gnorm=0.545, clip=0, loss_scale=16, train_wall=55, gb_free=17.5, wall=15032
2023-08-05 04:11:16 | INFO | train_inner | epoch 014:    349 / 1474 loss=2.15, trans_loss=5.112, nll_loss=2.337, w2v_ctc_loss=0.742, task_loss=0, contrastive_loss=0.091, total=4168.35, n_correct=2613.38, ppl=5.05, accuracy=62.696, wps=14849.9, ups=1.78, wpb=8336.7, bsz=318.7, num_updates=19500, lr=0.000101274, gnorm=0.549, clip=0, loss_scale=16, train_wall=56, gb_free=16.6, wall=15089
2023-08-05 04:12:12 | INFO | train_inner | epoch 014:    449 / 1474 loss=2.148, trans_loss=5.119, nll_loss=2.345, w2v_ctc_loss=0.739, task_loss=0, contrastive_loss=0.072, total=4155.83, n_correct=2599.97, ppl=5.08, accuracy=62.562, wps=14829.2, ups=1.78, wpb=8311.7, bsz=306.7, num_updates=19600, lr=0.000101015, gnorm=0.546, clip=0, loss_scale=16, train_wall=56, gb_free=16.2, wall=15145
2023-08-05 04:13:08 | INFO | train_inner | epoch 014:    549 / 1474 loss=2.159, trans_loss=5.125, nll_loss=2.352, w2v_ctc_loss=0.762, task_loss=0, contrastive_loss=0.067, total=4064.87, n_correct=2532.42, ppl=5.11, accuracy=62.3, wps=14407.4, ups=1.77, wpb=8129.7, bsz=288.5, num_updates=19700, lr=0.000100759, gnorm=0.545, clip=0, loss_scale=16, train_wall=56, gb_free=18.1, wall=15201
2023-08-05 04:14:05 | INFO | train_inner | epoch 014:    649 / 1474 loss=2.164, trans_loss=5.127, nll_loss=2.356, w2v_ctc_loss=0.746, task_loss=0, contrastive_loss=0.132, total=4167.34, n_correct=2598.17, ppl=5.12, accuracy=62.346, wps=14753.8, ups=1.77, wpb=8334.7, bsz=307.8, num_updates=19800, lr=0.000100504, gnorm=0.545, clip=0, loss_scale=16, train_wall=56, gb_free=17.4, wall=15258
2023-08-05 04:15:00 | INFO | train_inner | epoch 014:    749 / 1474 loss=2.152, trans_loss=5.118, nll_loss=2.345, w2v_ctc_loss=0.752, task_loss=0, contrastive_loss=0.064, total=4142.94, n_correct=2591.23, ppl=5.08, accuracy=62.546, wps=14893.1, ups=1.8, wpb=8285.9, bsz=308.6, num_updates=19900, lr=0.000100251, gnorm=0.543, clip=0, loss_scale=16, train_wall=55, gb_free=16.8, wall=15313
2023-08-05 04:15:57 | INFO | train_inner | epoch 014:    849 / 1474 loss=2.168, trans_loss=5.118, nll_loss=2.346, w2v_ctc_loss=0.744, task_loss=0, contrastive_loss=0.175, total=4173.06, n_correct=2610.88, ppl=5.08, accuracy=62.565, wps=14825.9, ups=1.78, wpb=8346.1, bsz=319.1, num_updates=20000, lr=0.0001, gnorm=0.573, clip=0, loss_scale=16, train_wall=56, gb_free=13.2, wall=15370
2023-08-05 04:15:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 04:16:18 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.396 | trans_loss 5.586 | nll_loss 2.867 | w2v_ctc_loss 1.396 | task_loss 0 | contrastive_loss 0.251 | total 4003.4 | n_correct 2449.6 | ppl 7.29 | accuracy 61.188 | uer 17.931 | wer 19.757 | raw_wer 19.757 | bleu 19.28 | wps 2318.1 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.7
2023-08-05 04:16:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-08-05 04:16:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_14_20000.pt
2023-08-05 04:16:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_14_20000.pt
2023-08-05 04:16:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.28) (writing took 32.7220803052187 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:0')
2023-08-05 04:17:48 | INFO | train_inner | epoch 014:    949 / 1474 loss=2.158, trans_loss=5.124, nll_loss=2.354, w2v_ctc_loss=0.743, task_loss=0, contrastive_loss=0.11, total=4166.71, n_correct=2600.9, ppl=5.11, accuracy=62.421, wps=7472.5, ups=0.9, wpb=8333.4, bsz=310.6, num_updates=20100, lr=9.97509e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=56, gb_free=16.7, wall=15481
2023-08-05 04:18:44 | INFO | train_inner | epoch 014:   1049 / 1474 loss=2.159, trans_loss=5.132, nll_loss=2.364, w2v_ctc_loss=0.748, task_loss=0, contrastive_loss=0.087, total=4145.57, n_correct=2585.57, ppl=5.15, accuracy=62.369, wps=14731.7, ups=1.78, wpb=8291.1, bsz=301.1, num_updates=20200, lr=9.95037e-05, gnorm=0.555, clip=0, loss_scale=16, train_wall=56, gb_free=17.7, wall=15537
2023-08-05 04:19:41 | INFO | train_inner | epoch 014:   1149 / 1474 loss=2.2, trans_loss=5.132, nll_loss=2.364, w2v_ctc_loss=0.755, task_loss=0, contrastive_loss=0.358, total=4219.9, n_correct=2625.21, ppl=5.15, accuracy=62.21, wps=14972, ups=1.77, wpb=8439.8, bsz=325.2, num_updates=20300, lr=9.92583e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=56, gb_free=16.7, wall=15594
2023-08-05 04:20:36 | INFO | train_inner | epoch 014:   1249 / 1474 loss=2.163, trans_loss=5.147, nll_loss=2.382, w2v_ctc_loss=0.764, task_loss=0, contrastive_loss=0.05, total=4032.06, n_correct=2503.55, ppl=5.21, accuracy=62.091, wps=14472, ups=1.79, wpb=8064.1, bsz=274.4, num_updates=20400, lr=9.90148e-05, gnorm=0.556, clip=0, loss_scale=16, train_wall=55, gb_free=17.9, wall=15649
2023-08-05 04:21:33 | INFO | train_inner | epoch 014:   1349 / 1474 loss=2.153, trans_loss=5.134, nll_loss=2.368, w2v_ctc_loss=0.742, task_loss=0, contrastive_loss=0.065, total=4205.07, n_correct=2626.6, ppl=5.16, accuracy=62.463, wps=14964.5, ups=1.78, wpb=8410.1, bsz=317.3, num_updates=20500, lr=9.8773e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=56, gb_free=16.9, wall=15706
2023-08-05 04:22:29 | INFO | train_inner | epoch 014:   1449 / 1474 loss=2.164, trans_loss=5.141, nll_loss=2.376, w2v_ctc_loss=0.747, task_loss=0, contrastive_loss=0.101, total=4126.44, n_correct=2568.55, ppl=5.19, accuracy=62.246, wps=14708, ups=1.78, wpb=8252.9, bsz=303.9, num_updates=20600, lr=9.85329e-05, gnorm=0.555, clip=0, loss_scale=16, train_wall=56, gb_free=16.4, wall=15762
2023-08-05 04:22:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:1')
2023-08-05 04:23:06 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.385 | trans_loss 5.573 | nll_loss 2.854 | w2v_ctc_loss 1.391 | task_loss 0 | contrastive_loss 0.246 | total 4003.4 | n_correct 2462.5 | ppl 7.23 | accuracy 61.51 | uer 18.297 | wer 20.23 | raw_wer 20.23 | bleu 19.59 | wps 2265.6 | wpb 4003.4 | bsz 141.8 | num_updates 20625 | best_bleu 19.7
2023-08-05 04:23:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20625 updates
2023-08-05 04:23:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.5905.pt
2023-08-05 04:23:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.5905.pt
2023-08-05 04:23:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.5905.pt (epoch 14 @ 20625 updates, score 19.59) (writing took 17.92524086870253 seconds)
2023-08-05 04:23:24 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-05 04:23:24 | INFO | train | epoch 014 | loss 2.159 | trans_loss 5.124 | nll_loss 2.352 | w2v_ctc_loss 0.748 | task_loss 0 | contrastive_loss 0.113 | total 4138.65 | n_correct 2585.45 | ppl 5.11 | accuracy 62.471 | wps 13102.8 | ups 1.58 | wpb 8277.3 | bsz 305.7 | num_updates 20625 | lr 9.84732e-05 | gnorm 0.549 | clip 0 | loss_scale 16 | train_wall 820 | gb_free 16.6 | wall 15817
2023-08-05 04:23:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 04:23:24 | INFO | fairseq.trainer | begin training epoch 15
2023-08-05 04:23:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 04:24:12 | INFO | train_inner | epoch 015:     75 / 1474 loss=2.151, trans_loss=5.107, nll_loss=2.331, w2v_ctc_loss=0.733, task_loss=0, contrastive_loss=0.152, total=4090.99, n_correct=2571.1, ppl=5.03, accuracy=62.848, wps=7891.2, ups=0.96, wpb=8182, bsz=300.8, num_updates=20700, lr=9.82946e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=55, gb_free=17.2, wall=15865
2023-08-05 04:25:08 | INFO | train_inner | epoch 015:    175 / 1474 loss=2.136, trans_loss=5.097, nll_loss=2.316, w2v_ctc_loss=0.738, task_loss=0, contrastive_loss=0.061, total=4115.56, n_correct=2596.44, ppl=4.98, accuracy=63.088, wps=14750.5, ups=1.79, wpb=8231.1, bsz=298.5, num_updates=20800, lr=9.80581e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=55, gb_free=17, wall=15921
2023-08-05 04:26:05 | INFO | train_inner | epoch 015:    275 / 1474 loss=2.131, trans_loss=5.097, nll_loss=2.317, w2v_ctc_loss=0.731, task_loss=0, contrastive_loss=0.054, total=4182.19, n_correct=2642.53, ppl=4.98, accuracy=63.185, wps=14813.3, ups=1.77, wpb=8364.4, bsz=310.5, num_updates=20900, lr=9.78232e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=56, gb_free=16.7, wall=15978
2023-08-05 04:27:01 | INFO | train_inner | epoch 015:    375 / 1474 loss=2.134, trans_loss=5.09, nll_loss=2.308, w2v_ctc_loss=0.729, task_loss=0, contrastive_loss=0.078, total=4172.52, n_correct=2630.97, ppl=4.95, accuracy=63.055, wps=14930.2, ups=1.79, wpb=8345, bsz=307.7, num_updates=21000, lr=9.759e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=55, gb_free=16.8, wall=16034
2023-08-05 04:27:57 | INFO | train_inner | epoch 015:    475 / 1474 loss=2.15, trans_loss=5.103, nll_loss=2.325, w2v_ctc_loss=0.726, task_loss=0, contrastive_loss=0.168, total=4076.84, n_correct=2564.87, ppl=5.01, accuracy=62.913, wps=14563.2, ups=1.79, wpb=8153.7, bsz=293.4, num_updates=21100, lr=9.73585e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=55, gb_free=17, wall=16090
2023-08-05 04:28:52 | INFO | train_inner | epoch 015:    575 / 1474 loss=2.143, trans_loss=5.103, nll_loss=2.325, w2v_ctc_loss=0.742, task_loss=0, contrastive_loss=0.08, total=4156.05, n_correct=2612.87, ppl=5.01, accuracy=62.869, wps=14909.2, ups=1.79, wpb=8312.1, bsz=302.8, num_updates=21200, lr=9.71286e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=55, gb_free=12.3, wall=16145
2023-08-05 04:29:49 | INFO | train_inner | epoch 015:    675 / 1474 loss=2.149, trans_loss=5.101, nll_loss=2.323, w2v_ctc_loss=0.738, task_loss=0, contrastive_loss=0.123, total=4118.87, n_correct=2592.64, ppl=5, accuracy=62.945, wps=14561.4, ups=1.77, wpb=8237.7, bsz=303, num_updates=21300, lr=9.69003e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=56, gb_free=17.2, wall=16202
2023-08-05 04:30:45 | INFO | train_inner | epoch 015:    775 / 1474 loss=2.142, trans_loss=5.111, nll_loss=2.336, w2v_ctc_loss=0.742, task_loss=0, contrastive_loss=0.063, total=4176.64, n_correct=2624.03, ppl=5.05, accuracy=62.826, wps=14944.8, ups=1.79, wpb=8353.3, bsz=305.3, num_updates=21400, lr=9.66736e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=55, gb_free=14.4, wall=16258
2023-08-05 04:31:41 | INFO | train_inner | epoch 015:    875 / 1474 loss=2.144, trans_loss=5.116, nll_loss=2.342, w2v_ctc_loss=0.742, task_loss=0, contrastive_loss=0.059, total=4056.99, n_correct=2543.02, ppl=5.07, accuracy=62.682, wps=14558.1, ups=1.79, wpb=8114, bsz=288, num_updates=21500, lr=9.64486e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=55, gb_free=17.5, wall=16314
2023-08-05 04:32:37 | INFO | train_inner | epoch 015:    975 / 1474 loss=2.15, trans_loss=5.113, nll_loss=2.339, w2v_ctc_loss=0.734, task_loss=0, contrastive_loss=0.143, total=4134.44, n_correct=2596.67, ppl=5.06, accuracy=62.806, wps=14797.7, ups=1.79, wpb=8268.9, bsz=304.8, num_updates=21600, lr=9.6225e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=55, gb_free=16.3, wall=16369
2023-08-05 04:33:33 | INFO | train_inner | epoch 015:   1075 / 1474 loss=2.178, trans_loss=5.116, nll_loss=2.345, w2v_ctc_loss=0.739, task_loss=0, contrastive_loss=0.298, total=4185.02, n_correct=2621.47, ppl=5.08, accuracy=62.639, wps=14705.6, ups=1.76, wpb=8370, bsz=324.2, num_updates=21700, lr=9.60031e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=56, gb_free=17, wall=16426
2023-08-05 04:34:29 | INFO | train_inner | epoch 015:   1175 / 1474 loss=2.139, trans_loss=5.105, nll_loss=2.332, w2v_ctc_loss=0.722, task_loss=0, contrastive_loss=0.106, total=4187.68, n_correct=2644.16, ppl=5.03, accuracy=63.141, wps=15073, ups=1.8, wpb=8375.4, bsz=329.7, num_updates=21800, lr=9.57826e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=16482
2023-08-05 04:35:25 | INFO | train_inner | epoch 015:   1275 / 1474 loss=2.149, trans_loss=5.118, nll_loss=2.345, w2v_ctc_loss=0.753, task_loss=0, contrastive_loss=0.062, total=4141.6, n_correct=2593.73, ppl=5.08, accuracy=62.626, wps=14804.5, ups=1.79, wpb=8283.2, bsz=301.1, num_updates=21900, lr=9.55637e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=55, gb_free=13.9, wall=16538
2023-08-05 04:36:21 | INFO | train_inner | epoch 015:   1375 / 1474 loss=2.142, trans_loss=5.118, nll_loss=2.346, w2v_ctc_loss=0.738, task_loss=0, contrastive_loss=0.051, total=4099.6, n_correct=2570.7, ppl=5.08, accuracy=62.706, wps=14657.6, ups=1.79, wpb=8199.2, bsz=293.2, num_updates=22000, lr=9.53463e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=55, gb_free=14.8, wall=16594
2023-08-05 04:36:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 04:36:43 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.376 | trans_loss 5.577 | nll_loss 2.853 | w2v_ctc_loss 1.354 | task_loss 0 | contrastive_loss 0.245 | total 4003.4 | n_correct 2467.2 | ppl 7.23 | accuracy 61.628 | uer 17.755 | wer 19.444 | raw_wer 19.444 | bleu 19.95 | wps 2283.6 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 19.95
2023-08-05 04:36:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-08-05 04:36:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_15_22000.pt
2023-08-05 04:36:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_15_22000.pt
2023-08-05 04:37:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.95) (writing took 24.92493148893118 seconds)
2023-08-05 04:38:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 04:38:30 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.389 | trans_loss 5.573 | nll_loss 2.85 | w2v_ctc_loss 1.401 | task_loss 0 | contrastive_loss 0.256 | total 4003.4 | n_correct 2463.2 | ppl 7.21 | accuracy 61.528 | uer 17.968 | wer 19.671 | raw_wer 19.671 | bleu 19.83 | wps 1978.9 | wpb 4003.4 | bsz 141.8 | num_updates 22099 | best_bleu 19.95
2023-08-05 04:38:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22099 updates
2023-08-05 04:38:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.8304.pt
2023-08-05 04:38:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.8304.pt
2023-08-05 04:38:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.8304.pt (epoch 15 @ 22099 updates, score 19.83) (writing took 13.686692271381617 seconds)
2023-08-05 04:38:44 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-05 04:38:44 | INFO | train | epoch 015 | loss 2.146 | trans_loss 5.107 | nll_loss 2.331 | w2v_ctc_loss 0.736 | task_loss 0 | contrastive_loss 0.11 | total 4138.65 | n_correct 2602.76 | ppl 5.03 | accuracy 62.889 | wps 13255 | ups 1.6 | wpb 8277.3 | bsz 305.7 | num_updates 22099 | lr 9.51325e-05 | gnorm 0.548 | clip 0 | loss_scale 32 | train_wall 818 | gb_free 17.1 | wall 16737
2023-08-05 04:38:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 04:38:45 | INFO | fairseq.trainer | begin training epoch 16
2023-08-05 04:38:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 04:38:53 | INFO | train_inner | epoch 016:      1 / 1474 loss=2.156, trans_loss=5.118, nll_loss=2.348, w2v_ctc_loss=0.738, task_loss=0, contrastive_loss=0.134, total=4149.9, n_correct=2604.82, ppl=5.09, accuracy=62.768, wps=5459.4, ups=0.66, wpb=8299.8, bsz=316.3, num_updates=22100, lr=9.51303e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=57, gb_free=17.8, wall=16746
2023-08-05 04:39:49 | INFO | train_inner | epoch 016:    101 / 1474 loss=2.124, trans_loss=5.075, nll_loss=2.289, w2v_ctc_loss=0.727, task_loss=0, contrastive_loss=0.078, total=4118.73, n_correct=2617.9, ppl=4.89, accuracy=63.561, wps=14772.4, ups=1.79, wpb=8237.5, bsz=314, num_updates=22200, lr=9.49158e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=55, gb_free=16.5, wall=16802
2023-08-05 04:40:44 | INFO | train_inner | epoch 016:    201 / 1474 loss=2.117, trans_loss=5.077, nll_loss=2.291, w2v_ctc_loss=0.717, task_loss=0, contrastive_loss=0.055, total=4106.45, n_correct=2609.46, ppl=4.89, accuracy=63.545, wps=14756.5, ups=1.8, wpb=8212.9, bsz=297.4, num_updates=22300, lr=9.47027e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=55, gb_free=16.8, wall=16857
2023-08-05 04:41:40 | INFO | train_inner | epoch 016:    301 / 1474 loss=2.138, trans_loss=5.085, nll_loss=2.303, w2v_ctc_loss=0.731, task_loss=0, contrastive_loss=0.128, total=4169.65, n_correct=2641.06, ppl=4.93, accuracy=63.34, wps=14958.8, ups=1.79, wpb=8339.3, bsz=309.9, num_updates=22400, lr=9.44911e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=55, gb_free=11.4, wall=16913
2023-08-05 04:42:37 | INFO | train_inner | epoch 016:    401 / 1474 loss=2.137, trans_loss=5.087, nll_loss=2.304, w2v_ctc_loss=0.73, task_loss=0, contrastive_loss=0.141, total=4063.79, n_correct=2570.92, ppl=4.94, accuracy=63.264, wps=14385.3, ups=1.77, wpb=8127.6, bsz=286.5, num_updates=22500, lr=9.42809e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=56, gb_free=13.2, wall=16970
2023-08-05 04:43:33 | INFO | train_inner | epoch 016:    501 / 1474 loss=2.126, trans_loss=5.08, nll_loss=2.297, w2v_ctc_loss=0.725, task_loss=0, contrastive_loss=0.083, total=4179.53, n_correct=2657.32, ppl=4.91, accuracy=63.579, wps=14802, ups=1.77, wpb=8359.1, bsz=319.5, num_updates=22600, lr=9.40721e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=56, gb_free=18, wall=17026
2023-08-05 04:44:29 | INFO | train_inner | epoch 016:    601 / 1474 loss=2.13, trans_loss=5.093, nll_loss=2.313, w2v_ctc_loss=0.734, task_loss=0, contrastive_loss=0.052, total=4121.37, n_correct=2603.75, ppl=4.97, accuracy=63.177, wps=14850.2, ups=1.8, wpb=8242.7, bsz=297.5, num_updates=22700, lr=9.38647e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=55, gb_free=18.1, wall=17082
2023-08-05 04:45:24 | INFO | train_inner | epoch 016:    701 / 1474 loss=2.129, trans_loss=5.095, nll_loss=2.315, w2v_ctc_loss=0.734, task_loss=0, contrastive_loss=0.053, total=4099.17, n_correct=2590.22, ppl=4.98, accuracy=63.189, wps=14814.2, ups=1.81, wpb=8198.3, bsz=297.5, num_updates=22800, lr=9.36586e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=55, gb_free=17, wall=17137
2023-08-05 04:46:20 | INFO | train_inner | epoch 016:    801 / 1474 loss=2.133, trans_loss=5.092, nll_loss=2.313, w2v_ctc_loss=0.718, task_loss=0, contrastive_loss=0.111, total=4184.53, n_correct=2645.85, ppl=4.97, accuracy=63.229, wps=14882, ups=1.78, wpb=8369.1, bsz=313, num_updates=22900, lr=9.34539e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=56, gb_free=13.9, wall=17193
2023-08-05 04:47:16 | INFO | train_inner | epoch 016:    901 / 1474 loss=2.133, trans_loss=5.092, nll_loss=2.313, w2v_ctc_loss=0.724, task_loss=0, contrastive_loss=0.103, total=4151.84, n_correct=2627.71, ppl=4.97, accuracy=63.29, wps=14812.1, ups=1.78, wpb=8303.7, bsz=307, num_updates=23000, lr=9.32505e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=56, gb_free=17.2, wall=17249
2023-08-05 04:48:13 | INFO | train_inner | epoch 016:   1001 / 1474 loss=2.146, trans_loss=5.105, nll_loss=2.329, w2v_ctc_loss=0.742, task_loss=0, contrastive_loss=0.103, total=4112.79, n_correct=2583.96, ppl=5.03, accuracy=62.827, wps=14614.7, ups=1.78, wpb=8225.6, bsz=299.5, num_updates=23100, lr=9.30484e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=56, gb_free=15.3, wall=17306
2023-08-05 04:49:08 | INFO | train_inner | epoch 016:   1101 / 1474 loss=2.141, trans_loss=5.108, nll_loss=2.334, w2v_ctc_loss=0.738, task_loss=0, contrastive_loss=0.077, total=4111.6, n_correct=2585, ppl=5.04, accuracy=62.871, wps=14736.1, ups=1.79, wpb=8223.2, bsz=295.6, num_updates=23200, lr=9.28477e-05, gnorm=0.543, clip=0, loss_scale=64, train_wall=55, gb_free=15.1, wall=17361
2023-08-05 04:49:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-05 04:50:06 | INFO | train_inner | epoch 016:   1202 / 1474 loss=2.126, trans_loss=5.1, nll_loss=2.323, w2v_ctc_loss=0.719, task_loss=0, contrastive_loss=0.061, total=4137.51, n_correct=2611.35, ppl=5, accuracy=63.114, wps=14381.2, ups=1.74, wpb=8275, bsz=299.7, num_updates=23300, lr=9.26482e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=57, gb_free=15.9, wall=17419
2023-08-05 04:51:02 | INFO | train_inner | epoch 016:   1302 / 1474 loss=2.149, trans_loss=5.104, nll_loss=2.328, w2v_ctc_loss=0.736, task_loss=0, contrastive_loss=0.153, total=4149.14, n_correct=2616.99, ppl=5.02, accuracy=63.073, wps=14675.7, ups=1.77, wpb=8298.3, bsz=311.9, num_updates=23400, lr=9.245e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=56, gb_free=11.9, wall=17475
2023-08-05 04:51:58 | INFO | train_inner | epoch 016:   1402 / 1474 loss=2.139, trans_loss=5.104, nll_loss=2.33, w2v_ctc_loss=0.734, task_loss=0, contrastive_loss=0.082, total=4200.01, n_correct=2648.39, ppl=5.03, accuracy=63.057, wps=15035.4, ups=1.79, wpb=8400, bsz=322.2, num_updates=23500, lr=9.22531e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=55, gb_free=17.2, wall=17531
2023-08-05 04:52:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 04:53:03 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.384 | trans_loss 5.572 | nll_loss 2.852 | w2v_ctc_loss 1.387 | task_loss 0 | contrastive_loss 0.252 | total 4003.4 | n_correct 2466.9 | ppl 7.22 | accuracy 61.62 | uer 17.893 | wer 19.645 | raw_wer 19.645 | bleu 20.04 | wps 1972.5 | wpb 4003.4 | bsz 141.8 | num_updates 23572 | best_bleu 20.04
2023-08-05 04:53:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23572 updates
2023-08-05 04:53:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 04:53:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 04:53:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt (epoch 16 @ 23572 updates, score 20.04) (writing took 23.63122466392815 seconds)
2023-08-05 04:53:28 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-05 04:53:28 | INFO | train | epoch 016 | loss 2.134 | trans_loss 5.093 | nll_loss 2.313 | w2v_ctc_loss 0.729 | task_loss 0 | contrastive_loss 0.101 | total 4137.02 | n_correct 2615.32 | ppl 4.97 | accuracy 63.217 | wps 13796.7 | ups 1.67 | wpb 8274 | bsz 305.1 | num_updates 23572 | lr 9.21121e-05 | gnorm 0.547 | clip 0 | loss_scale 32 | train_wall 819 | gb_free 15.8 | wall 17621
2023-08-05 04:53:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 04:53:28 | INFO | fairseq.trainer | begin training epoch 17
2023-08-05 04:53:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 04:53:51 | INFO | train_inner | epoch 017:     28 / 1474 loss=2.138, trans_loss=5.083, nll_loss=2.301, w2v_ctc_loss=0.713, task_loss=0, contrastive_loss=0.22, total=4141.79, n_correct=2624.97, ppl=4.93, accuracy=63.378, wps=7344.6, ups=0.89, wpb=8283.6, bsz=301.5, num_updates=23600, lr=9.20575e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=56, gb_free=16.4, wall=17644
2023-08-05 04:54:47 | INFO | train_inner | epoch 017:    128 / 1474 loss=2.112, trans_loss=5.062, nll_loss=2.273, w2v_ctc_loss=0.719, task_loss=0, contrastive_loss=0.056, total=4110.88, n_correct=2621.12, ppl=4.83, accuracy=63.761, wps=14636.5, ups=1.78, wpb=8221.8, bsz=295.4, num_updates=23700, lr=9.1863e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=56, gb_free=16.6, wall=17700
2023-08-05 04:55:43 | INFO | train_inner | epoch 017:    228 / 1474 loss=2.138, trans_loss=5.064, nll_loss=2.277, w2v_ctc_loss=0.712, task_loss=0, contrastive_loss=0.219, total=4171.95, n_correct=2659.27, ppl=4.85, accuracy=63.742, wps=14878.8, ups=1.78, wpb=8343.9, bsz=320.4, num_updates=23800, lr=9.16698e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=56, gb_free=16.3, wall=17756
2023-08-05 04:56:39 | INFO | train_inner | epoch 017:    328 / 1474 loss=2.134, trans_loss=5.071, nll_loss=2.285, w2v_ctc_loss=0.713, task_loss=0, contrastive_loss=0.226, total=4157.94, n_correct=2644.8, ppl=4.87, accuracy=63.608, wps=14924.5, ups=1.79, wpb=8315.9, bsz=305, num_updates=23900, lr=9.14779e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=55, gb_free=14.9, wall=17812
2023-08-05 04:57:35 | INFO | train_inner | epoch 017:    428 / 1474 loss=2.114, trans_loss=5.071, nll_loss=2.285, w2v_ctc_loss=0.718, task_loss=0, contrastive_loss=0.055, total=4141.8, n_correct=2641.74, ppl=4.87, accuracy=63.782, wps=14735.8, ups=1.78, wpb=8283.6, bsz=306.7, num_updates=24000, lr=9.12871e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=56, gb_free=17.6, wall=17868
2023-08-05 04:57:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 04:58:00 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.388 | trans_loss 5.573 | nll_loss 2.849 | w2v_ctc_loss 1.411 | task_loss 0 | contrastive_loss 0.24 | total 4003.4 | n_correct 2465.2 | ppl 7.21 | accuracy 61.578 | uer 17.729 | wer 19.503 | raw_wer 19.503 | bleu 19.64 | wps 2046.6 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 20.04
2023-08-05 04:58:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-08-05 04:58:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_17_24000.pt
2023-08-05 04:58:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_17_24000.pt
2023-08-05 04:58:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.64) (writing took 30.240749455988407 seconds)
2023-08-05 04:59:28 | INFO | train_inner | epoch 017:    528 / 1474 loss=2.122, trans_loss=5.075, nll_loss=2.291, w2v_ctc_loss=0.718, task_loss=0, contrastive_loss=0.098, total=4180.09, n_correct=2658.16, ppl=4.89, accuracy=63.591, wps=7404.7, ups=0.89, wpb=8360.2, bsz=307.5, num_updates=24100, lr=9.10975e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=57, gb_free=17.4, wall=17981
2023-08-05 05:00:24 | INFO | train_inner | epoch 017:    628 / 1474 loss=2.115, trans_loss=5.08, nll_loss=2.297, w2v_ctc_loss=0.716, task_loss=0, contrastive_loss=0.05, total=4166.6, n_correct=2651.33, ppl=4.91, accuracy=63.633, wps=15012, ups=1.8, wpb=8333.2, bsz=302.3, num_updates=24200, lr=9.09091e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=55, gb_free=16, wall=18037
2023-08-05 05:00:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-05 05:01:20 | INFO | train_inner | epoch 017:    729 / 1474 loss=2.133, trans_loss=5.084, nll_loss=2.303, w2v_ctc_loss=0.734, task_loss=0, contrastive_loss=0.095, total=4170.28, n_correct=2643.44, ppl=4.93, accuracy=63.388, wps=14806.3, ups=1.78, wpb=8340.6, bsz=308.8, num_updates=24300, lr=9.07218e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=56, gb_free=10.6, wall=18093
2023-08-05 05:02:16 | INFO | train_inner | epoch 017:    829 / 1474 loss=2.121, trans_loss=5.083, nll_loss=2.3, w2v_ctc_loss=0.722, task_loss=0, contrastive_loss=0.062, total=4092.64, n_correct=2596.78, ppl=4.92, accuracy=63.45, wps=14715.9, ups=1.8, wpb=8185.3, bsz=296.2, num_updates=24400, lr=9.05357e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=55, gb_free=16.1, wall=18149
2023-08-05 05:03:12 | INFO | train_inner | epoch 017:    929 / 1474 loss=2.118, trans_loss=5.082, nll_loss=2.301, w2v_ctc_loss=0.715, task_loss=0, contrastive_loss=0.06, total=4109.5, n_correct=2609.48, ppl=4.93, accuracy=63.499, wps=14694, ups=1.79, wpb=8219, bsz=305.4, num_updates=24500, lr=9.03508e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=55, gb_free=16.8, wall=18205
2023-08-05 05:04:07 | INFO | train_inner | epoch 017:   1029 / 1474 loss=2.122, trans_loss=5.083, nll_loss=2.302, w2v_ctc_loss=0.726, task_loss=0, contrastive_loss=0.063, total=4098.36, n_correct=2602.88, ppl=4.93, accuracy=63.51, wps=14779.6, ups=1.8, wpb=8196.7, bsz=301.7, num_updates=24600, lr=9.0167e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=55, gb_free=16, wall=18260
2023-08-05 05:05:03 | INFO | train_inner | epoch 017:   1129 / 1474 loss=2.116, trans_loss=5.082, nll_loss=2.3, w2v_ctc_loss=0.714, task_loss=0, contrastive_loss=0.055, total=4100.14, n_correct=2605.38, ppl=4.93, accuracy=63.544, wps=14693.9, ups=1.79, wpb=8200.3, bsz=299.3, num_updates=24700, lr=8.99843e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=55, gb_free=16.9, wall=18316
2023-08-05 05:05:59 | INFO | train_inner | epoch 017:   1229 / 1474 loss=2.168, trans_loss=5.093, nll_loss=2.317, w2v_ctc_loss=0.715, task_loss=0, contrastive_loss=0.35, total=4173.98, n_correct=2631.56, ppl=4.98, accuracy=63.047, wps=14798.6, ups=1.77, wpb=8348, bsz=325.9, num_updates=24800, lr=8.98027e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=56, gb_free=16.2, wall=18372
2023-08-05 05:06:55 | INFO | train_inner | epoch 017:   1329 / 1474 loss=2.119, trans_loss=5.088, nll_loss=2.309, w2v_ctc_loss=0.71, task_loss=0, contrastive_loss=0.065, total=4146.07, n_correct=2628.01, ppl=4.95, accuracy=63.386, wps=14853.4, ups=1.79, wpb=8292.1, bsz=303.2, num_updates=24900, lr=8.96221e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=55, gb_free=16.7, wall=18428
2023-08-05 05:07:51 | INFO | train_inner | epoch 017:   1429 / 1474 loss=2.119, trans_loss=5.088, nll_loss=2.309, w2v_ctc_loss=0.715, task_loss=0, contrastive_loss=0.058, total=4119.23, n_correct=2612.09, ppl=4.95, accuracy=63.412, wps=14773.6, ups=1.79, wpb=8238.5, bsz=303.4, num_updates=25000, lr=8.94427e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=55, gb_free=13.7, wall=18484
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:0')
2023-08-05 05:08:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:1')
2023-08-05 05:08:39 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.386 | trans_loss 5.568 | nll_loss 2.849 | w2v_ctc_loss 1.404 | task_loss 0 | contrastive_loss 0.252 | total 4003.4 | n_correct 2467.9 | ppl 7.2 | accuracy 61.645 | uer 17.835 | wer 19.537 | raw_wer 19.537 | bleu 19.35 | wps 2221.5 | wpb 4003.4 | bsz 141.8 | num_updates 25045 | best_bleu 20.04
2023-08-05 05:08:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25045 updates
2023-08-05 05:08:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.3501.pt
2023-08-05 05:08:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.3501.pt
2023-08-05 05:08:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.3501.pt (epoch 17 @ 25045 updates, score 19.35) (writing took 13.545483816415071 seconds)
2023-08-05 05:08:53 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-05 05:08:53 | INFO | train | epoch 017 | loss 2.125 | trans_loss 5.079 | nll_loss 2.296 | w2v_ctc_loss 0.718 | task_loss 0 | contrastive_loss 0.107 | total 4138.55 | n_correct 2629.35 | ppl 4.91 | accuracy 63.533 | wps 13176.7 | ups 1.59 | wpb 8277.1 | bsz 305.7 | num_updates 25045 | lr 8.93623e-05 | gnorm 0.547 | clip 0 | loss_scale 16 | train_wall 817 | gb_free 16.6 | wall 18546
2023-08-05 05:08:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 05:08:53 | INFO | fairseq.trainer | begin training epoch 18
2023-08-05 05:08:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 05:09:31 | INFO | train_inner | epoch 018:     55 / 1474 loss=2.117, trans_loss=5.074, nll_loss=2.29, w2v_ctc_loss=0.723, task_loss=0, contrastive_loss=0.063, total=4128.93, n_correct=2630.87, ppl=4.89, accuracy=63.718, wps=8214.6, ups=0.99, wpb=8257.9, bsz=301.7, num_updates=25100, lr=8.92644e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=56, gb_free=16.8, wall=18584
2023-08-05 05:10:27 | INFO | train_inner | epoch 018:    155 / 1474 loss=2.114, trans_loss=5.046, nll_loss=2.253, w2v_ctc_loss=0.69, task_loss=0, contrastive_loss=0.181, total=4158.38, n_correct=2672.74, ppl=4.77, accuracy=64.274, wps=14855, ups=1.79, wpb=8316.8, bsz=313.7, num_updates=25200, lr=8.90871e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=55, gb_free=16.9, wall=18640
2023-08-05 05:11:24 | INFO | train_inner | epoch 018:    255 / 1474 loss=2.099, trans_loss=5.046, nll_loss=2.253, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.056, total=4161.92, n_correct=2676.57, ppl=4.77, accuracy=64.311, wps=14824.1, ups=1.78, wpb=8323.8, bsz=312.8, num_updates=25300, lr=8.89108e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=56, gb_free=17, wall=18697
2023-08-05 05:12:20 | INFO | train_inner | epoch 018:    355 / 1474 loss=2.103, trans_loss=5.058, nll_loss=2.268, w2v_ctc_loss=0.702, task_loss=0, contrastive_loss=0.068, total=4167.42, n_correct=2667.62, ppl=4.82, accuracy=64.011, wps=14891.1, ups=1.79, wpb=8334.8, bsz=301.2, num_updates=25400, lr=8.87357e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=55, gb_free=15.6, wall=18753
2023-08-05 05:13:16 | INFO | train_inner | epoch 018:    455 / 1474 loss=2.122, trans_loss=5.065, nll_loss=2.277, w2v_ctc_loss=0.71, task_loss=0, contrastive_loss=0.16, total=4075.78, n_correct=2600.16, ppl=4.85, accuracy=63.795, wps=14540.8, ups=1.78, wpb=8151.6, bsz=294.2, num_updates=25500, lr=8.85615e-05, gnorm=0.561, clip=0, loss_scale=16, train_wall=55, gb_free=18.1, wall=18809
2023-08-05 05:14:12 | INFO | train_inner | epoch 018:    555 / 1474 loss=2.097, trans_loss=5.049, nll_loss=2.258, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.068, total=4218.07, n_correct=2711.72, ppl=4.78, accuracy=64.288, wps=14966.6, ups=1.77, wpb=8436.1, bsz=329.6, num_updates=25600, lr=8.83883e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=56, gb_free=16.2, wall=18865
2023-08-05 05:15:08 | INFO | train_inner | epoch 018:    655 / 1474 loss=2.128, trans_loss=5.08, nll_loss=2.298, w2v_ctc_loss=0.72, task_loss=0, contrastive_loss=0.136, total=4093.44, n_correct=2599.79, ppl=4.92, accuracy=63.511, wps=14667.6, ups=1.79, wpb=8186.9, bsz=298.5, num_updates=25700, lr=8.82162e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=55, gb_free=15.6, wall=18921
2023-08-05 05:16:04 | INFO | train_inner | epoch 018:    755 / 1474 loss=2.134, trans_loss=5.069, nll_loss=2.284, w2v_ctc_loss=0.716, task_loss=0, contrastive_loss=0.224, total=4202.99, n_correct=2681.68, ppl=4.87, accuracy=63.804, wps=15076.1, ups=1.79, wpb=8406, bsz=322.5, num_updates=25800, lr=8.80451e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=55, gb_free=17.9, wall=18977
2023-08-05 05:16:59 | INFO | train_inner | epoch 018:    855 / 1474 loss=2.11, trans_loss=5.072, nll_loss=2.288, w2v_ctc_loss=0.71, task_loss=0, contrastive_loss=0.054, total=4177.43, n_correct=2663.36, ppl=4.88, accuracy=63.756, wps=14957.2, ups=1.79, wpb=8354.9, bsz=304.8, num_updates=25900, lr=8.7875e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=55, gb_free=16.5, wall=19032
2023-08-05 05:17:55 | INFO | train_inner | epoch 018:    955 / 1474 loss=2.1, trans_loss=5.059, nll_loss=2.271, w2v_ctc_loss=0.695, task_loss=0, contrastive_loss=0.062, total=4138.23, n_correct=2651.44, ppl=4.83, accuracy=64.072, wps=14831.5, ups=1.79, wpb=8276.5, bsz=314.5, num_updates=26000, lr=8.77058e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=55, gb_free=16.8, wall=19088
2023-08-05 05:17:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 05:18:18 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.379 | trans_loss 5.567 | nll_loss 2.843 | w2v_ctc_loss 1.384 | task_loss 0 | contrastive_loss 0.251 | total 4003.4 | n_correct 2478.2 | ppl 7.17 | accuracy 61.902 | uer 18.103 | wer 19.962 | raw_wer 19.962 | bleu 19.56 | wps 2161.4 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 20.04
2023-08-05 05:18:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-08-05 05:18:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_18_26000.pt
2023-08-05 05:18:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_18_26000.pt
2023-08-05 05:19:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 19.56) (writing took 46.777288839221 seconds)
2023-08-05 05:20:02 | INFO | train_inner | epoch 018:   1055 / 1474 loss=2.107, trans_loss=5.071, nll_loss=2.287, w2v_ctc_loss=0.703, task_loss=0, contrastive_loss=0.056, total=4133.59, n_correct=2636.53, ppl=4.88, accuracy=63.783, wps=6524, ups=0.79, wpb=8267.2, bsz=298.7, num_updates=26100, lr=8.75376e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=56, gb_free=16.2, wall=19215
2023-08-05 05:20:58 | INFO | train_inner | epoch 018:   1155 / 1474 loss=2.122, trans_loss=5.062, nll_loss=2.275, w2v_ctc_loss=0.707, task_loss=0, contrastive_loss=0.162, total=4154.22, n_correct=2655.88, ppl=4.84, accuracy=63.932, wps=14858.3, ups=1.79, wpb=8308.4, bsz=315.1, num_updates=26200, lr=8.73704e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=55, gb_free=15.4, wall=19271
2023-08-05 05:21:54 | INFO | train_inner | epoch 018:   1255 / 1474 loss=2.109, trans_loss=5.081, nll_loss=2.299, w2v_ctc_loss=0.705, task_loss=0, contrastive_loss=0.051, total=4089.17, n_correct=2601.42, ppl=4.92, accuracy=63.617, wps=14673.9, ups=1.79, wpb=8178.3, bsz=287.6, num_updates=26300, lr=8.72041e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=55, gb_free=17, wall=19327
2023-08-05 05:22:50 | INFO | train_inner | epoch 018:   1355 / 1474 loss=2.127, trans_loss=5.088, nll_loss=2.309, w2v_ctc_loss=0.73, task_loss=0, contrastive_loss=0.075, total=4068.84, n_correct=2576.79, ppl=4.96, accuracy=63.33, wps=14499.6, ups=1.78, wpb=8137.7, bsz=291.4, num_updates=26400, lr=8.70388e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=56, gb_free=15.8, wall=19383
2023-08-05 05:23:46 | INFO | train_inner | epoch 018:   1455 / 1474 loss=2.119, trans_loss=5.083, nll_loss=2.303, w2v_ctc_loss=0.72, task_loss=0, contrastive_loss=0.061, total=4113.23, n_correct=2608.85, ppl=4.93, accuracy=63.426, wps=14694.7, ups=1.79, wpb=8226.5, bsz=297.2, num_updates=26500, lr=8.68744e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=19439
2023-08-05 05:23:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 05:24:20 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.389 | trans_loss 5.56 | nll_loss 2.836 | w2v_ctc_loss 1.437 | task_loss 0 | contrastive_loss 0.247 | total 4003.4 | n_correct 2480.6 | ppl 7.14 | accuracy 61.962 | uer 17.822 | wer 19.563 | raw_wer 19.563 | bleu 19.93 | wps 2083.6 | wpb 4003.4 | bsz 141.8 | num_updates 26519 | best_bleu 20.04
2023-08-05 05:24:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26519 updates
2023-08-05 05:24:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.9309.pt
2023-08-05 05:24:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.9309.pt
2023-08-05 05:24:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.9309.pt (epoch 18 @ 26519 updates, score 19.93) (writing took 14.186473175883293 seconds)
2023-08-05 05:24:35 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-05 05:24:35 | INFO | train | epoch 018 | loss 2.114 | trans_loss 5.066 | nll_loss 2.28 | w2v_ctc_loss 0.708 | task_loss 0 | contrastive_loss 0.104 | total 4138.65 | n_correct 2642.51 | ppl 4.86 | accuracy 63.85 | wps 12957 | ups 1.57 | wpb 8277.3 | bsz 305.7 | num_updates 26519 | lr 8.68433e-05 | gnorm 0.546 | clip 0 | loss_scale 32 | train_wall 818 | gb_free 16.2 | wall 19488
2023-08-05 05:24:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 05:24:35 | INFO | fairseq.trainer | begin training epoch 19
2023-08-05 05:24:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 05:25:27 | INFO | train_inner | epoch 019:     81 / 1474 loss=2.102, trans_loss=5.042, nll_loss=2.248, w2v_ctc_loss=0.699, task_loss=0, contrastive_loss=0.11, total=4107.26, n_correct=2636.25, ppl=4.75, accuracy=64.185, wps=8081.7, ups=0.98, wpb=8214.5, bsz=297.5, num_updates=26600, lr=8.6711e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=55, gb_free=13.2, wall=19540
2023-08-05 05:26:24 | INFO | train_inner | epoch 019:    181 / 1474 loss=2.105, trans_loss=5.037, nll_loss=2.243, w2v_ctc_loss=0.71, task_loss=0, contrastive_loss=0.098, total=4222.18, n_correct=2717.54, ppl=4.73, accuracy=64.363, wps=14980.9, ups=1.77, wpb=8444.4, bsz=324.4, num_updates=26700, lr=8.65485e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=56, gb_free=12.3, wall=19597
2023-08-05 05:27:20 | INFO | train_inner | epoch 019:    281 / 1474 loss=2.087, trans_loss=5.036, nll_loss=2.24, w2v_ctc_loss=0.695, task_loss=0, contrastive_loss=0.047, total=4187.37, n_correct=2702.52, ppl=4.72, accuracy=64.54, wps=14853.4, ups=1.77, wpb=8374.7, bsz=307, num_updates=26800, lr=8.63868e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=56, gb_free=17.8, wall=19653
2023-08-05 05:28:16 | INFO | train_inner | epoch 019:    381 / 1474 loss=2.107, trans_loss=5.04, nll_loss=2.247, w2v_ctc_loss=0.693, task_loss=0, contrastive_loss=0.153, total=4170.67, n_correct=2682.33, ppl=4.75, accuracy=64.314, wps=14872.5, ups=1.78, wpb=8341.3, bsz=310.5, num_updates=26900, lr=8.62261e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=55, gb_free=17.5, wall=19709
2023-08-05 05:29:12 | INFO | train_inner | epoch 019:    481 / 1474 loss=2.103, trans_loss=5.053, nll_loss=2.262, w2v_ctc_loss=0.71, task_loss=0, contrastive_loss=0.061, total=4115.22, n_correct=2641.5, ppl=4.8, accuracy=64.189, wps=14804.1, ups=1.8, wpb=8230.4, bsz=301.9, num_updates=27000, lr=8.60663e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=55, gb_free=15.4, wall=19765
2023-08-05 05:30:08 | INFO | train_inner | epoch 019:    581 / 1474 loss=2.102, trans_loss=5.046, nll_loss=2.254, w2v_ctc_loss=0.693, task_loss=0, contrastive_loss=0.128, total=4129.22, n_correct=2656.64, ppl=4.77, accuracy=64.338, wps=14754.8, ups=1.79, wpb=8258.4, bsz=306, num_updates=27100, lr=8.59074e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=55, gb_free=16.1, wall=19821
2023-08-05 05:31:05 | INFO | train_inner | epoch 019:    681 / 1474 loss=2.093, trans_loss=5.051, nll_loss=2.262, w2v_ctc_loss=0.688, task_loss=0, contrastive_loss=0.054, total=4197.2, n_correct=2697.47, ppl=4.8, accuracy=64.268, wps=14732.8, ups=1.76, wpb=8394.4, bsz=320.8, num_updates=27200, lr=8.57493e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=56, gb_free=15, wall=19878
2023-08-05 05:32:01 | INFO | train_inner | epoch 019:    781 / 1474 loss=2.099, trans_loss=5.051, nll_loss=2.261, w2v_ctc_loss=0.703, task_loss=0, contrastive_loss=0.065, total=4142.6, n_correct=2659.37, ppl=4.79, accuracy=64.196, wps=14833.7, ups=1.79, wpb=8285.2, bsz=305.1, num_updates=27300, lr=8.55921e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=55, gb_free=16.5, wall=19934
2023-08-05 05:32:56 | INFO | train_inner | epoch 019:    881 / 1474 loss=2.104, trans_loss=5.063, nll_loss=2.276, w2v_ctc_loss=0.707, task_loss=0, contrastive_loss=0.051, total=4153.47, n_correct=2653.44, ppl=4.84, accuracy=63.885, wps=14883.8, ups=1.79, wpb=8306.9, bsz=303.1, num_updates=27400, lr=8.54358e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=55, gb_free=16.5, wall=19989
2023-08-05 05:33:53 | INFO | train_inner | epoch 019:    981 / 1474 loss=2.133, trans_loss=5.068, nll_loss=2.284, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.283, total=4101.29, n_correct=2619, ppl=4.87, accuracy=63.858, wps=14428.2, ups=1.76, wpb=8202.6, bsz=309.9, num_updates=27500, lr=8.52803e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=20046
2023-08-05 05:34:50 | INFO | train_inner | epoch 019:   1081 / 1474 loss=2.11, trans_loss=5.072, nll_loss=2.288, w2v_ctc_loss=0.7, task_loss=0, contrastive_loss=0.092, total=4036.97, n_correct=2573.9, ppl=4.89, accuracy=63.758, wps=14342.3, ups=1.78, wpb=8073.9, bsz=291, num_updates=27600, lr=8.51257e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=56, gb_free=15.1, wall=20103
2023-08-05 05:35:46 | INFO | train_inner | epoch 019:   1181 / 1474 loss=2.127, trans_loss=5.071, nll_loss=2.287, w2v_ctc_loss=0.709, task_loss=0, contrastive_loss=0.172, total=4137.49, n_correct=2634.77, ppl=4.88, accuracy=63.68, wps=14786.8, ups=1.79, wpb=8275, bsz=307.7, num_updates=27700, lr=8.49719e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=55, gb_free=15.2, wall=20159
2023-08-05 05:36:42 | INFO | train_inner | epoch 019:   1281 / 1474 loss=2.107, trans_loss=5.071, nll_loss=2.288, w2v_ctc_loss=0.699, task_loss=0, contrastive_loss=0.073, total=4141.89, n_correct=2645.56, ppl=4.88, accuracy=63.873, wps=14806.9, ups=1.79, wpb=8283.8, bsz=300.1, num_updates=27800, lr=8.48189e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=55, gb_free=15.8, wall=20215
2023-08-05 05:37:38 | INFO | train_inner | epoch 019:   1381 / 1474 loss=2.105, trans_loss=5.067, nll_loss=2.282, w2v_ctc_loss=0.705, task_loss=0, contrastive_loss=0.06, total=4133.26, n_correct=2643.68, ppl=4.86, accuracy=63.961, wps=14773, ups=1.79, wpb=8266.5, bsz=301, num_updates=27900, lr=8.46668e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=55, gb_free=16.4, wall=20270
2023-08-05 05:38:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 05:38:53 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.378 | trans_loss 5.556 | nll_loss 2.83 | w2v_ctc_loss 1.411 | task_loss 0 | contrastive_loss 0.25 | total 4003.4 | n_correct 2480.3 | ppl 7.11 | accuracy 61.955 | uer 17.692 | wer 19.395 | raw_wer 19.395 | bleu 19.95 | wps 2268.4 | wpb 4003.4 | bsz 141.8 | num_updates 27993 | best_bleu 20.04
2023-08-05 05:38:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27993 updates
2023-08-05 05:38:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.9504.pt
2023-08-05 05:38:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.9504.pt
2023-08-05 05:39:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.9504.pt (epoch 19 @ 27993 updates, score 19.95) (writing took 18.935721227899194 seconds)
2023-08-05 05:39:12 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-05 05:39:12 | INFO | train | epoch 019 | loss 2.106 | trans_loss 5.055 | nll_loss 2.266 | w2v_ctc_loss 0.701 | task_loss 0 | contrastive_loss 0.103 | total 4138.65 | n_correct 2653.46 | ppl 4.81 | accuracy 64.114 | wps 13902.9 | ups 1.68 | wpb 8277.3 | bsz 305.7 | num_updates 27993 | lr 8.4526e-05 | gnorm 0.549 | clip 0 | loss_scale 32 | train_wall 820 | gb_free 17.7 | wall 20365
2023-08-05 05:39:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 05:39:13 | INFO | fairseq.trainer | begin training epoch 20
2023-08-05 05:39:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 05:39:24 | INFO | train_inner | epoch 020:      7 / 1474 loss=2.108, trans_loss=5.057, nll_loss=2.269, w2v_ctc_loss=0.696, task_loss=0, contrastive_loss=0.144, total=4119.08, n_correct=2643.85, ppl=4.82, accuracy=64.185, wps=7757.9, ups=0.94, wpb=8238.2, bsz=304.1, num_updates=28000, lr=8.45154e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=56, gb_free=16.4, wall=20377
2023-08-05 05:39:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 05:39:47 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.363 | trans_loss 5.555 | nll_loss 2.827 | w2v_ctc_loss 1.367 | task_loss 0 | contrastive_loss 0.246 | total 4003.4 | n_correct 2480.4 | ppl 7.1 | accuracy 61.957 | uer 17.487 | wer 19.28 | raw_wer 19.28 | bleu 20.03 | wps 2189.8 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.04
2023-08-05 05:39:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-08-05 05:39:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_20_28000.pt
2023-08-05 05:39:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_20_28000.pt
2023-08-05 05:40:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 20.03) (writing took 33.69632490724325 seconds)
2023-08-05 05:41:17 | INFO | train_inner | epoch 020:    107 / 1474 loss=2.078, trans_loss=5.018, nll_loss=2.218, w2v_ctc_loss=0.679, task_loss=0, contrastive_loss=0.066, total=4195.03, n_correct=2722.61, ppl=4.65, accuracy=64.901, wps=7382.5, ups=0.88, wpb=8390.1, bsz=313.7, num_updates=28100, lr=8.43649e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=56, gb_free=15.4, wall=20490
2023-08-05 05:42:13 | INFO | train_inner | epoch 020:    207 / 1474 loss=2.096, trans_loss=5.034, nll_loss=2.239, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.118, total=4154.14, n_correct=2677.48, ppl=4.72, accuracy=64.453, wps=14810.8, ups=1.78, wpb=8308.3, bsz=301, num_updates=28200, lr=8.42152e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=56, gb_free=17.5, wall=20546
2023-08-05 05:43:10 | INFO | train_inner | epoch 020:    307 / 1474 loss=2.079, trans_loss=5.023, nll_loss=2.226, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.056, total=4188.05, n_correct=2714.39, ppl=4.68, accuracy=64.813, wps=14939.5, ups=1.78, wpb=8376.1, bsz=326.2, num_updates=28300, lr=8.40663e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=56, gb_free=15.9, wall=20603
2023-08-05 05:44:05 | INFO | train_inner | epoch 020:    407 / 1474 loss=2.082, trans_loss=5.031, nll_loss=2.233, w2v_ctc_loss=0.686, task_loss=0, contrastive_loss=0.054, total=4115.16, n_correct=2658.53, ppl=4.7, accuracy=64.603, wps=14725.6, ups=1.79, wpb=8230.3, bsz=297, num_updates=28400, lr=8.39181e-05, gnorm=0.548, clip=0, loss_scale=64, train_wall=55, gb_free=15.8, wall=20658
2023-08-05 05:45:01 | INFO | train_inner | epoch 020:    507 / 1474 loss=2.099, trans_loss=5.044, nll_loss=2.252, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.144, total=4108.46, n_correct=2645.7, ppl=4.76, accuracy=64.396, wps=14755.2, ups=1.8, wpb=8216.9, bsz=300.4, num_updates=28500, lr=8.37708e-05, gnorm=0.549, clip=0, loss_scale=64, train_wall=55, gb_free=16.7, wall=20714
2023-08-05 05:45:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-05 05:45:58 | INFO | train_inner | epoch 020:    608 / 1474 loss=2.098, trans_loss=5.044, nll_loss=2.25, w2v_ctc_loss=0.693, task_loss=0, contrastive_loss=0.106, total=4071.2, n_correct=2618.82, ppl=4.76, accuracy=64.326, wps=14404, ups=1.77, wpb=8142.4, bsz=288.5, num_updates=28600, lr=8.36242e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=56, gb_free=17.9, wall=20771
2023-08-05 05:46:53 | INFO | train_inner | epoch 020:    708 / 1474 loss=2.092, trans_loss=5.045, nll_loss=2.253, w2v_ctc_loss=0.702, task_loss=0, contrastive_loss=0.049, total=4137.06, n_correct=2661.12, ppl=4.77, accuracy=64.324, wps=14874.3, ups=1.8, wpb=8274.1, bsz=300.5, num_updates=28700, lr=8.34784e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=55, gb_free=16.8, wall=20826
2023-08-05 05:47:49 | INFO | train_inner | epoch 020:    808 / 1474 loss=2.091, trans_loss=5.044, nll_loss=2.252, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.053, total=4146.78, n_correct=2667.4, ppl=4.76, accuracy=64.325, wps=14824.4, ups=1.79, wpb=8293.6, bsz=307.3, num_updates=28800, lr=8.33333e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=55, gb_free=15.6, wall=20882
2023-08-05 05:48:46 | INFO | train_inner | epoch 020:    908 / 1474 loss=2.138, trans_loss=5.053, nll_loss=2.265, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.341, total=4161, n_correct=2666.98, ppl=4.81, accuracy=64.095, wps=14730, ups=1.77, wpb=8322, bsz=323.2, num_updates=28900, lr=8.3189e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=56, gb_free=17.7, wall=20939
2023-08-05 05:49:42 | INFO | train_inner | epoch 020:   1008 / 1474 loss=2.088, trans_loss=5.047, nll_loss=2.256, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.057, total=4168.14, n_correct=2682.37, ppl=4.78, accuracy=64.354, wps=14797.1, ups=1.78, wpb=8336.3, bsz=307.3, num_updates=29000, lr=8.30455e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=56, gb_free=16.7, wall=20995
2023-08-05 05:50:38 | INFO | train_inner | epoch 020:   1108 / 1474 loss=2.116, trans_loss=5.054, nll_loss=2.266, w2v_ctc_loss=0.693, task_loss=0, contrastive_loss=0.191, total=4166.49, n_correct=2674.71, ppl=4.81, accuracy=64.196, wps=14807.7, ups=1.78, wpb=8333, bsz=315.4, num_updates=29100, lr=8.29027e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=56, gb_free=15.1, wall=21051
2023-08-05 05:51:34 | INFO | train_inner | epoch 020:   1208 / 1474 loss=2.095, trans_loss=5.05, nll_loss=2.26, w2v_ctc_loss=0.703, task_loss=0, contrastive_loss=0.048, total=4029.18, n_correct=2585.33, ppl=4.79, accuracy=64.165, wps=14385.2, ups=1.79, wpb=8058.4, bsz=284, num_updates=29200, lr=8.27606e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=56, gb_free=12.4, wall=21107
2023-08-05 05:52:30 | INFO | train_inner | epoch 020:   1308 / 1474 loss=2.096, trans_loss=5.058, nll_loss=2.272, w2v_ctc_loss=0.695, task_loss=0, contrastive_loss=0.05, total=4123.21, n_correct=2644.66, ppl=4.83, accuracy=64.141, wps=14781, ups=1.79, wpb=8246.4, bsz=297.1, num_updates=29300, lr=8.26192e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=55, gb_free=17.7, wall=21163
2023-08-05 05:53:26 | INFO | train_inner | epoch 020:   1408 / 1474 loss=2.096, trans_loss=5.057, nll_loss=2.269, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.051, total=4116.28, n_correct=2640.07, ppl=4.82, accuracy=64.137, wps=14645.7, ups=1.78, wpb=8232.6, bsz=295, num_updates=29400, lr=8.24786e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=56, gb_free=17.8, wall=21219
2023-08-05 05:54:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 05:54:26 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.36 | trans_loss 5.557 | nll_loss 2.831 | w2v_ctc_loss 1.35 | task_loss 0 | contrastive_loss 0.242 | total 4003.4 | n_correct 2476.2 | ppl 7.11 | accuracy 61.852 | uer 17.328 | wer 19.034 | raw_wer 19.034 | bleu 19.89 | wps 2212 | wpb 4003.4 | bsz 141.8 | num_updates 29466 | best_bleu 20.04
2023-08-05 05:54:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29466 updates
2023-08-05 05:54:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.8904.pt
2023-08-05 05:54:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.8904.pt
2023-08-05 05:54:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.8904.pt (epoch 20 @ 29466 updates, score 19.89) (writing took 23.950237467885017 seconds)
2023-08-05 05:54:50 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-05 05:54:50 | INFO | train | epoch 020 | loss 2.096 | trans_loss 5.043 | nll_loss 2.251 | w2v_ctc_loss 0.692 | task_loss 0 | contrastive_loss 0.1 | total 4137.26 | n_correct 2663.12 | ppl 4.76 | accuracy 64.369 | wps 12996.5 | ups 1.57 | wpb 8274.5 | bsz 305.2 | num_updates 29466 | lr 8.23862e-05 | gnorm 0.551 | clip 0 | loss_scale 32 | train_wall 818 | gb_free 16.4 | wall 21303
2023-08-05 05:54:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 05:54:50 | INFO | fairseq.trainer | begin training epoch 21
2023-08-05 05:54:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 05:55:18 | INFO | train_inner | epoch 021:     34 / 1474 loss=2.107, trans_loss=5.047, nll_loss=2.257, w2v_ctc_loss=0.688, task_loss=0, contrastive_loss=0.167, total=4152.26, n_correct=2670.06, ppl=4.78, accuracy=64.304, wps=7427.4, ups=0.89, wpb=8304.5, bsz=316.3, num_updates=29500, lr=8.23387e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=55, gb_free=16.7, wall=21331
2023-08-05 05:56:15 | INFO | train_inner | epoch 021:    134 / 1474 loss=2.091, trans_loss=5.013, nll_loss=2.212, w2v_ctc_loss=0.681, task_loss=0, contrastive_loss=0.161, total=4195.08, n_correct=2723.49, ppl=4.63, accuracy=64.921, wps=14868.2, ups=1.77, wpb=8390.2, bsz=319.6, num_updates=29600, lr=8.21995e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=56, gb_free=17.3, wall=21388
2023-08-05 05:57:10 | INFO | train_inner | epoch 021:    234 / 1474 loss=2.078, trans_loss=5.019, nll_loss=2.219, w2v_ctc_loss=0.671, task_loss=0, contrastive_loss=0.117, total=4155.31, n_correct=2699.49, ppl=4.65, accuracy=64.965, wps=14933.5, ups=1.8, wpb=8310.6, bsz=312.6, num_updates=29700, lr=8.2061e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=55, gb_free=17, wall=21443
2023-08-05 05:58:06 | INFO | train_inner | epoch 021:    334 / 1474 loss=2.092, trans_loss=5.025, nll_loss=2.227, w2v_ctc_loss=0.692, task_loss=0, contrastive_loss=0.119, total=4151.51, n_correct=2684.37, ppl=4.68, accuracy=64.66, wps=14830, ups=1.79, wpb=8303, bsz=310.8, num_updates=29800, lr=8.19232e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=56, gb_free=15.8, wall=21499
2023-08-05 05:59:03 | INFO | train_inner | epoch 021:    434 / 1474 loss=2.072, trans_loss=5.022, nll_loss=2.222, w2v_ctc_loss=0.675, task_loss=0, contrastive_loss=0.045, total=4180.85, n_correct=2714.23, ppl=4.67, accuracy=64.921, wps=14840.5, ups=1.77, wpb=8361.7, bsz=306.8, num_updates=29900, lr=8.17861e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=56, gb_free=16.1, wall=21556
2023-08-05 05:59:58 | INFO | train_inner | epoch 021:    534 / 1474 loss=2.075, trans_loss=5.021, nll_loss=2.222, w2v_ctc_loss=0.683, task_loss=0, contrastive_loss=0.044, total=4083.98, n_correct=2650.99, ppl=4.66, accuracy=64.912, wps=14657.4, ups=1.79, wpb=8168, bsz=295.1, num_updates=30000, lr=8.16497e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=55, gb_free=13.5, wall=21611
2023-08-05 05:59:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 06:00:22 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.387 | trans_loss 5.569 | nll_loss 2.842 | w2v_ctc_loss 1.408 | task_loss 0 | contrastive_loss 0.248 | total 4003.4 | n_correct 2476.4 | ppl 7.17 | accuracy 61.857 | uer 17.657 | wer 19.369 | raw_wer 19.369 | bleu 19.6 | wps 2195.8 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.04
2023-08-05 06:00:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-08-05 06:00:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_21_30000.pt
2023-08-05 06:00:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_21_30000.pt
2023-08-05 06:00:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 19.6) (writing took 13.094675982370973 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:0')
2023-08-05 06:01:31 | INFO | train_inner | epoch 021:    634 / 1474 loss=2.098, trans_loss=5.029, nll_loss=2.233, w2v_ctc_loss=0.677, task_loss=0, contrastive_loss=0.215, total=4215.41, n_correct=2727.08, ppl=4.7, accuracy=64.693, wps=9071, ups=1.08, wpb=8430.8, bsz=315.4, num_updates=30100, lr=8.15139e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=56, gb_free=11.9, wall=21704
2023-08-05 06:02:28 | INFO | train_inner | epoch 021:    734 / 1474 loss=2.086, trans_loss=5.037, nll_loss=2.243, w2v_ctc_loss=0.681, task_loss=0, contrastive_loss=0.074, total=4152.97, n_correct=2682.22, ppl=4.74, accuracy=64.586, wps=14777.3, ups=1.78, wpb=8305.9, bsz=309.3, num_updates=30200, lr=8.13788e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=56, gb_free=16.6, wall=21760
2023-08-05 06:03:24 | INFO | train_inner | epoch 021:    834 / 1474 loss=2.093, trans_loss=5.043, nll_loss=2.251, w2v_ctc_loss=0.689, task_loss=0, contrastive_loss=0.087, total=4066.93, n_correct=2620.32, ppl=4.76, accuracy=64.43, wps=14415.8, ups=1.77, wpb=8133.9, bsz=294.4, num_updates=30300, lr=8.12444e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=56, gb_free=17.3, wall=21817
2023-08-05 06:04:20 | INFO | train_inner | epoch 021:    934 / 1474 loss=2.082, trans_loss=5.033, nll_loss=2.238, w2v_ctc_loss=0.683, task_loss=0, contrastive_loss=0.06, total=4103.34, n_correct=2650.24, ppl=4.72, accuracy=64.587, wps=14696.3, ups=1.79, wpb=8206.7, bsz=301, num_updates=30400, lr=8.11107e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=55, gb_free=14.4, wall=21873
2023-08-05 06:05:15 | INFO | train_inner | epoch 021:   1034 / 1474 loss=2.088, trans_loss=5.047, nll_loss=2.257, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.058, total=4099.86, n_correct=2639.93, ppl=4.78, accuracy=64.391, wps=14760.1, ups=1.8, wpb=8199.7, bsz=298.8, num_updates=30500, lr=8.09776e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=55, gb_free=12, wall=21928
2023-08-05 06:06:11 | INFO | train_inner | epoch 021:   1134 / 1474 loss=2.087, trans_loss=5.04, nll_loss=2.246, w2v_ctc_loss=0.69, task_loss=0, contrastive_loss=0.062, total=4120.75, n_correct=2656.7, ppl=4.74, accuracy=64.471, wps=14702.6, ups=1.78, wpb=8241.5, bsz=293.5, num_updates=30600, lr=8.08452e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=56, gb_free=16.1, wall=21984
2023-08-05 06:07:07 | INFO | train_inner | epoch 021:   1234 / 1474 loss=2.093, trans_loss=5.039, nll_loss=2.247, w2v_ctc_loss=0.683, task_loss=0, contrastive_loss=0.111, total=4154.73, n_correct=2678.76, ppl=4.75, accuracy=64.475, wps=14852.1, ups=1.79, wpb=8309.5, bsz=311.6, num_updates=30700, lr=8.07134e-05, gnorm=0.562, clip=0, loss_scale=64, train_wall=56, gb_free=13.1, wall=22040
2023-08-05 06:08:03 | INFO | train_inner | epoch 021:   1334 / 1474 loss=2.087, trans_loss=5.039, nll_loss=2.248, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.072, total=4147.17, n_correct=2678.16, ppl=4.75, accuracy=64.578, wps=14786.1, ups=1.78, wpb=8294.3, bsz=311.9, num_updates=30800, lr=8.05823e-05, gnorm=0.545, clip=0, loss_scale=64, train_wall=56, gb_free=16.5, wall=22096
2023-08-05 06:09:00 | INFO | train_inner | epoch 021:   1434 / 1474 loss=2.109, trans_loss=5.052, nll_loss=2.263, w2v_ctc_loss=0.705, task_loss=0, contrastive_loss=0.121, total=4133.93, n_correct=2652.37, ppl=4.8, accuracy=64.161, wps=14651.9, ups=1.77, wpb=8267.9, bsz=304.5, num_updates=30900, lr=8.04518e-05, gnorm=0.576, clip=0, loss_scale=64, train_wall=56, gb_free=15.9, wall=22153
2023-08-05 06:09:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:4')
2023-08-05 06:09:44 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.355 | trans_loss 5.561 | nll_loss 2.837 | w2v_ctc_loss 1.321 | task_loss 0 | contrastive_loss 0.25 | total 4003.4 | n_correct 2481.2 | ppl 7.15 | accuracy 61.977 | uer 17.376 | wer 19.213 | raw_wer 19.213 | bleu 19.95 | wps 2447.3 | wpb 4003.4 | bsz 141.8 | num_updates 30940 | best_bleu 20.04
2023-08-05 06:09:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30940 updates
2023-08-05 06:09:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.9509.pt
2023-08-05 06:09:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.9509.pt
2023-08-05 06:10:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.9509.pt (epoch 21 @ 30940 updates, score 19.95) (writing took 17.09367959201336 seconds)
2023-08-05 06:10:02 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-05 06:10:02 | INFO | train | epoch 021 | loss 2.088 | trans_loss 5.033 | nll_loss 2.238 | w2v_ctc_loss 0.684 | task_loss 0 | contrastive_loss 0.101 | total 4138.65 | n_correct 2674.55 | ppl 4.72 | accuracy 64.624 | wps 13385.3 | ups 1.62 | wpb 8277.3 | bsz 305.7 | num_updates 30940 | lr 8.03998e-05 | gnorm 0.554 | clip 0 | loss_scale 64 | train_wall 820 | gb_free 15.7 | wall 22215
2023-08-05 06:10:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 06:10:02 | INFO | fairseq.trainer | begin training epoch 22
2023-08-05 06:10:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 06:10:43 | INFO | train_inner | epoch 022:     60 / 1474 loss=2.072, trans_loss=5.019, nll_loss=2.22, w2v_ctc_loss=0.68, task_loss=0, contrastive_loss=0.044, total=4128.84, n_correct=2681.75, ppl=4.66, accuracy=64.952, wps=7995.6, ups=0.97, wpb=8257.7, bsz=297.7, num_updates=31000, lr=8.03219e-05, gnorm=0.548, clip=0, loss_scale=64, train_wall=56, gb_free=14.6, wall=22256
2023-08-05 06:11:40 | INFO | train_inner | epoch 022:    160 / 1474 loss=2.083, trans_loss=5.009, nll_loss=2.207, w2v_ctc_loss=0.682, task_loss=0, contrastive_loss=0.124, total=4123.35, n_correct=2681.87, ppl=4.62, accuracy=65.041, wps=14470.7, ups=1.75, wpb=8246.7, bsz=310.3, num_updates=31100, lr=8.01927e-05, gnorm=0.554, clip=0, loss_scale=64, train_wall=57, gb_free=15.1, wall=22313
2023-08-05 06:12:36 | INFO | train_inner | epoch 022:    260 / 1474 loss=2.065, trans_loss=5.004, nll_loss=2.201, w2v_ctc_loss=0.666, task_loss=0, contrastive_loss=0.066, total=4267.16, n_correct=2787.21, ppl=4.6, accuracy=65.318, wps=15272.5, ups=1.79, wpb=8534.3, bsz=329.9, num_updates=31200, lr=8.00641e-05, gnorm=0.542, clip=0, loss_scale=64, train_wall=55, gb_free=16.9, wall=22369
2023-08-05 06:13:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-05 06:13:33 | INFO | train_inner | epoch 022:    361 / 1474 loss=2.092, trans_loss=5.02, nll_loss=2.221, w2v_ctc_loss=0.682, task_loss=0, contrastive_loss=0.163, total=4163.56, n_correct=2698.76, ppl=4.66, accuracy=64.819, wps=14532.1, ups=1.75, wpb=8327.1, bsz=304, num_updates=31300, lr=7.99361e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=57, gb_free=15.5, wall=22426
2023-08-05 06:14:30 | INFO | train_inner | epoch 022:    461 / 1474 loss=2.085, trans_loss=5.025, nll_loss=2.226, w2v_ctc_loss=0.681, task_loss=0, contrastive_loss=0.106, total=4132.96, n_correct=2679.22, ppl=4.68, accuracy=64.826, wps=14695.6, ups=1.78, wpb=8265.9, bsz=297.5, num_updates=31400, lr=7.98087e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=56, gb_free=17.3, wall=22483
2023-08-05 06:15:26 | INFO | train_inner | epoch 022:    561 / 1474 loss=2.07, trans_loss=5.015, nll_loss=2.214, w2v_ctc_loss=0.674, task_loss=0, contrastive_loss=0.054, total=4158.17, n_correct=2704.99, ppl=4.64, accuracy=65.052, wps=14665, ups=1.76, wpb=8316.3, bsz=307.8, num_updates=31500, lr=7.96819e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=22539
2023-08-05 06:16:22 | INFO | train_inner | epoch 022:    661 / 1474 loss=2.076, trans_loss=5.012, nll_loss=2.212, w2v_ctc_loss=0.664, task_loss=0, contrastive_loss=0.138, total=4139.66, n_correct=2693.18, ppl=4.63, accuracy=65.058, wps=14938, ups=1.8, wpb=8279.3, bsz=311.1, num_updates=31600, lr=7.95557e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=55, gb_free=16.4, wall=22595
2023-08-05 06:17:18 | INFO | train_inner | epoch 022:    761 / 1474 loss=2.074, trans_loss=5.02, nll_loss=2.222, w2v_ctc_loss=0.681, task_loss=0, contrastive_loss=0.055, total=4167.89, n_correct=2704.78, ppl=4.66, accuracy=64.896, wps=14832.2, ups=1.78, wpb=8335.8, bsz=303.9, num_updates=31700, lr=7.94301e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=56, gb_free=13.3, wall=22651
2023-08-05 06:18:14 | INFO | train_inner | epoch 022:    861 / 1474 loss=2.077, trans_loss=5.031, nll_loss=2.236, w2v_ctc_loss=0.681, task_loss=0, contrastive_loss=0.044, total=4075.79, n_correct=2634.99, ppl=4.71, accuracy=64.65, wps=14491.3, ups=1.78, wpb=8151.6, bsz=289, num_updates=31800, lr=7.93052e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=56, gb_free=16.6, wall=22707
2023-08-05 06:19:11 | INFO | train_inner | epoch 022:    961 / 1474 loss=2.074, trans_loss=5.026, nll_loss=2.23, w2v_ctc_loss=0.677, task_loss=0, contrastive_loss=0.046, total=4134.72, n_correct=2680.9, ppl=4.69, accuracy=64.839, wps=14645.9, ups=1.77, wpb=8269.4, bsz=303.2, num_updates=31900, lr=7.91808e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=56, gb_free=14.7, wall=22764
2023-08-05 06:20:07 | INFO | train_inner | epoch 022:   1061 / 1474 loss=2.09, trans_loss=5.021, nll_loss=2.223, w2v_ctc_loss=0.67, task_loss=0, contrastive_loss=0.214, total=4160.57, n_correct=2700.76, ppl=4.67, accuracy=64.913, wps=14896.8, ups=1.79, wpb=8321.1, bsz=315.5, num_updates=32000, lr=7.90569e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=55, gb_free=17.5, wall=22820
2023-08-05 06:20:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 06:20:30 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.373 | trans_loss 5.561 | nll_loss 2.836 | w2v_ctc_loss 1.382 | task_loss 0 | contrastive_loss 0.248 | total 4003.4 | n_correct 2485.2 | ppl 7.14 | accuracy 62.077 | uer 17.392 | wer 19.153 | raw_wer 19.153 | bleu 19.96 | wps 2090.7 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.04
2023-08-05 06:20:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-08-05 06:20:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_22_32000.pt
2023-08-05 06:20:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_22_32000.pt
2023-08-05 06:21:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 19.96) (writing took 31.19167044200003 seconds)
2023-08-05 06:21:58 | INFO | train_inner | epoch 022:   1161 / 1474 loss=2.091, trans_loss=5.043, nll_loss=2.253, w2v_ctc_loss=0.686, task_loss=0, contrastive_loss=0.094, total=4099.59, n_correct=2644.72, ppl=4.77, accuracy=64.512, wps=7350.2, ups=0.9, wpb=8199.2, bsz=296.2, num_updates=32100, lr=7.89337e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=56, gb_free=15.4, wall=22931
2023-08-05 06:22:54 | INFO | train_inner | epoch 022:   1261 / 1474 loss=2.089, trans_loss=5.039, nll_loss=2.247, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.085, total=4182.05, n_correct=2701.9, ppl=4.75, accuracy=64.607, wps=14949.8, ups=1.79, wpb=8364.1, bsz=323, num_updates=32200, lr=7.8811e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=56, gb_free=15.8, wall=22987
2023-08-05 06:23:50 | INFO | train_inner | epoch 022:   1361 / 1474 loss=2.081, trans_loss=5.028, nll_loss=2.233, w2v_ctc_loss=0.674, task_loss=0, contrastive_loss=0.114, total=4062.31, n_correct=2631.75, ppl=4.7, accuracy=64.785, wps=14475.4, ups=1.78, wpb=8124.6, bsz=299, num_updates=32300, lr=7.86889e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=56, gb_free=15.4, wall=23043
2023-08-05 06:24:46 | INFO | train_inner | epoch 022:   1461 / 1474 loss=2.086, trans_loss=5.045, nll_loss=2.254, w2v_ctc_loss=0.689, task_loss=0, contrastive_loss=0.059, total=4081.88, n_correct=2633.32, ppl=4.77, accuracy=64.512, wps=14673.7, ups=1.8, wpb=8163.8, bsz=288.9, num_updates=32400, lr=7.85674e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=55, gb_free=17.5, wall=23099
2023-08-05 06:24:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 06:25:17 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.363 | trans_loss 5.552 | nll_loss 2.824 | w2v_ctc_loss 1.37 | task_loss 0 | contrastive_loss 0.246 | total 4003.4 | n_correct 2483.5 | ppl 7.08 | accuracy 62.035 | uer 17.365 | wer 19.119 | raw_wer 19.119 | bleu 20.38 | wps 2095.7 | wpb 4003.4 | bsz 141.8 | num_updates 32413 | best_bleu 20.38
2023-08-05 06:25:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32413 updates
2023-08-05 06:25:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 06:25:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 06:25:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt (epoch 22 @ 32413 updates, score 20.38) (writing took 23.50544412061572 seconds)
2023-08-05 06:25:41 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-05 06:25:41 | INFO | train | epoch 022 | loss 2.081 | trans_loss 5.023 | nll_loss 2.226 | w2v_ctc_loss 0.678 | task_loss 0 | contrastive_loss 0.095 | total 4137.49 | n_correct 2683.55 | ppl 4.68 | accuracy 64.859 | wps 12973.4 | ups 1.57 | wpb 8275 | bsz 305.2 | num_updates 32413 | lr 7.85517e-05 | gnorm 0.553 | clip 0 | loss_scale 32 | train_wall 821 | gb_free 12.3 | wall 23154
2023-08-05 06:25:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 06:25:41 | INFO | fairseq.trainer | begin training epoch 23
2023-08-05 06:25:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 06:26:39 | INFO | train_inner | epoch 023:     87 / 1474 loss=2.064, trans_loss=4.999, nll_loss=2.194, w2v_ctc_loss=0.678, task_loss=0, contrastive_loss=0.05, total=4096.09, n_correct=2677.46, ppl=4.58, accuracy=65.366, wps=7254.6, ups=0.89, wpb=8192.2, bsz=301.2, num_updates=32500, lr=7.84465e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=56, gb_free=16.6, wall=23212
2023-08-05 06:27:35 | INFO | train_inner | epoch 023:    187 / 1474 loss=2.06, trans_loss=4.998, nll_loss=2.192, w2v_ctc_loss=0.668, task_loss=0, contrastive_loss=0.049, total=4107.77, n_correct=2687.89, ppl=4.57, accuracy=65.434, wps=14588.7, ups=1.78, wpb=8215.5, bsz=293.4, num_updates=32600, lr=7.8326e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=56, gb_free=16.7, wall=23268
2023-08-05 06:28:32 | INFO | train_inner | epoch 023:    287 / 1474 loss=2.072, trans_loss=5.006, nll_loss=2.203, w2v_ctc_loss=0.664, task_loss=0, contrastive_loss=0.124, total=4153.12, n_correct=2707.63, ppl=4.6, accuracy=65.195, wps=14575, ups=1.75, wpb=8306.2, bsz=306.4, num_updates=32700, lr=7.82062e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=56, gb_free=17.2, wall=23325
2023-08-05 06:29:28 | INFO | train_inner | epoch 023:    387 / 1474 loss=2.06, trans_loss=5.006, nll_loss=2.202, w2v_ctc_loss=0.666, task_loss=0, contrastive_loss=0.042, total=4116.7, n_correct=2686.82, ppl=4.6, accuracy=65.266, wps=14810.8, ups=1.8, wpb=8233.4, bsz=294, num_updates=32800, lr=7.80869e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=55, gb_free=15.7, wall=23381
2023-08-05 06:30:24 | INFO | train_inner | epoch 023:    487 / 1474 loss=2.071, trans_loss=5.007, nll_loss=2.205, w2v_ctc_loss=0.666, task_loss=0, contrastive_loss=0.097, total=4157.6, n_correct=2712.05, ppl=4.61, accuracy=65.231, wps=14709.1, ups=1.77, wpb=8315.2, bsz=313.5, num_updates=32900, lr=7.79681e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=56, gb_free=17.6, wall=23437
2023-08-05 06:31:20 | INFO | train_inner | epoch 023:    587 / 1474 loss=2.06, trans_loss=5.002, nll_loss=2.198, w2v_ctc_loss=0.666, task_loss=0, contrastive_loss=0.045, total=4173.42, n_correct=2730.72, ppl=4.59, accuracy=65.431, wps=15027.8, ups=1.8, wpb=8346.8, bsz=316, num_updates=33000, lr=7.78499e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=55, gb_free=13.1, wall=23493
2023-08-05 06:32:16 | INFO | train_inner | epoch 023:    687 / 1474 loss=2.071, trans_loss=5.008, nll_loss=2.205, w2v_ctc_loss=0.672, task_loss=0, contrastive_loss=0.085, total=4137.82, n_correct=2696.29, ppl=4.61, accuracy=65.162, wps=14631.3, ups=1.77, wpb=8275.6, bsz=302.5, num_updates=33100, lr=7.77322e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=56, gb_free=17.5, wall=23549
2023-08-05 06:33:12 | INFO | train_inner | epoch 023:    787 / 1474 loss=2.075, trans_loss=5.019, nll_loss=2.22, w2v_ctc_loss=0.678, task_loss=0, contrastive_loss=0.065, total=4150.99, n_correct=2698.29, ppl=4.66, accuracy=65.004, wps=14821, ups=1.79, wpb=8302, bsz=305.4, num_updates=33200, lr=7.76151e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=56, gb_free=16.5, wall=23605
2023-08-05 06:34:08 | INFO | train_inner | epoch 023:    887 / 1474 loss=2.077, trans_loss=5.009, nll_loss=2.208, w2v_ctc_loss=0.669, task_loss=0, contrastive_loss=0.14, total=4181.99, n_correct=2729.38, ppl=4.62, accuracy=65.265, wps=14897.9, ups=1.78, wpb=8364, bsz=324.7, num_updates=33300, lr=7.74984e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=56, gb_free=16.7, wall=23661
2023-08-05 06:34:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-05 06:35:05 | INFO | train_inner | epoch 023:    988 / 1474 loss=2.086, trans_loss=5.017, nll_loss=2.218, w2v_ctc_loss=0.668, task_loss=0, contrastive_loss=0.21, total=4148.97, n_correct=2696.88, ppl=4.65, accuracy=65.001, wps=14569.4, ups=1.76, wpb=8297.9, bsz=302.6, num_updates=33400, lr=7.73823e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=56, gb_free=18, wall=23718
2023-08-05 06:36:02 | INFO | train_inner | epoch 023:   1088 / 1474 loss=2.076, trans_loss=5.025, nll_loss=2.228, w2v_ctc_loss=0.683, task_loss=0, contrastive_loss=0.053, total=4092.37, n_correct=2654.34, ppl=4.69, accuracy=64.861, wps=14448.4, ups=1.77, wpb=8184.7, bsz=290.8, num_updates=33500, lr=7.72667e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=56, gb_free=17.7, wall=23775
2023-08-05 06:36:58 | INFO | train_inner | epoch 023:   1188 / 1474 loss=2.073, trans_loss=5.025, nll_loss=2.229, w2v_ctc_loss=0.679, task_loss=0, contrastive_loss=0.047, total=4164.9, n_correct=2702.86, ppl=4.69, accuracy=64.896, wps=14868.6, ups=1.78, wpb=8329.8, bsz=309.2, num_updates=33600, lr=7.71517e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=56, gb_free=14.2, wall=23831
2023-08-05 06:37:54 | INFO | train_inner | epoch 023:   1288 / 1474 loss=2.069, trans_loss=5.022, nll_loss=2.225, w2v_ctc_loss=0.667, task_loss=0, contrastive_loss=0.057, total=4136.96, n_correct=2691.08, ppl=4.67, accuracy=65.05, wps=14765.2, ups=1.78, wpb=8273.9, bsz=309.8, num_updates=33700, lr=7.70371e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=23887
2023-08-05 06:38:50 | INFO | train_inner | epoch 023:   1388 / 1474 loss=2.087, trans_loss=5.039, nll_loss=2.248, w2v_ctc_loss=0.674, task_loss=0, contrastive_loss=0.112, total=4142.84, n_correct=2677.3, ppl=4.75, accuracy=64.625, wps=14819, ups=1.79, wpb=8285.7, bsz=304.8, num_updates=33800, lr=7.69231e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=55, gb_free=16.4, wall=23943
2023-08-05 06:39:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 06:40:02 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.364 | trans_loss 5.553 | nll_loss 2.825 | w2v_ctc_loss 1.374 | task_loss 0 | contrastive_loss 0.246 | total 4003.4 | n_correct 2488.2 | ppl 7.09 | accuracy 62.152 | uer 17.137 | wer 18.873 | raw_wer 18.873 | bleu 20.16 | wps 2100.5 | wpb 4003.4 | bsz 141.8 | num_updates 33886 | best_bleu 20.38
2023-08-05 06:40:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33886 updates
2023-08-05 06:40:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_20.1603.pt
2023-08-05 06:40:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_20.1603.pt
2023-08-05 06:40:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_20.1603.pt (epoch 23 @ 33886 updates, score 20.16) (writing took 19.675130331888795 seconds)
2023-08-05 06:40:22 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-05 06:40:22 | INFO | train | epoch 023 | loss 2.073 | trans_loss 5.014 | nll_loss 2.214 | w2v_ctc_loss 0.671 | task_loss 0 | contrastive_loss 0.092 | total 4137.7 | n_correct 2693.62 | ppl 4.64 | accuracy 65.099 | wps 13839.4 | ups 1.67 | wpb 8275.4 | bsz 305.2 | num_updates 33886 | lr 7.68254e-05 | gnorm 0.558 | clip 0 | loss_scale 32 | train_wall 822 | gb_free 14.1 | wall 24035
2023-08-05 06:40:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 06:40:22 | INFO | fairseq.trainer | begin training epoch 24
2023-08-05 06:40:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 06:40:38 | INFO | train_inner | epoch 024:     14 / 1474 loss=2.096, trans_loss=5.031, nll_loss=2.237, w2v_ctc_loss=0.67, task_loss=0, contrastive_loss=0.188, total=4084.21, n_correct=2643.71, ppl=4.71, accuracy=64.73, wps=7537.8, ups=0.92, wpb=8168.4, bsz=303.7, num_updates=33900, lr=7.68095e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=56, gb_free=15.7, wall=24051
2023-08-05 06:41:35 | INFO | train_inner | epoch 024:    114 / 1474 loss=2.075, trans_loss=4.986, nll_loss=2.177, w2v_ctc_loss=0.656, task_loss=0, contrastive_loss=0.207, total=4168.61, n_correct=2734.89, ppl=4.52, accuracy=65.607, wps=14741.7, ups=1.77, wpb=8337.2, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=56, gb_free=12, wall=24108
2023-08-05 06:41:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 06:41:58 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.366 | trans_loss 5.556 | nll_loss 2.825 | w2v_ctc_loss 1.379 | task_loss 0 | contrastive_loss 0.233 | total 4003.4 | n_correct 2486.9 | ppl 7.08 | accuracy 62.12 | uer 17.023 | wer 18.732 | raw_wer 18.732 | bleu 19.99 | wps 2175.8 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.38
2023-08-05 06:41:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-08-05 06:41:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_24_34000.pt
2023-08-05 06:42:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_24_34000.pt
2023-08-05 06:42:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 19.99) (writing took 31.539311485365033 seconds)
2023-08-05 06:43:27 | INFO | train_inner | epoch 024:    214 / 1474 loss=2.081, trans_loss=4.988, nll_loss=2.182, w2v_ctc_loss=0.65, task_loss=0, contrastive_loss=0.259, total=4252.53, n_correct=2789.24, ppl=4.54, accuracy=65.59, wps=7597.5, ups=0.89, wpb=8505.1, bsz=341.3, num_updates=34100, lr=7.6584e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=56, gb_free=17.1, wall=24220
2023-08-05 06:44:23 | INFO | train_inner | epoch 024:    314 / 1474 loss=2.054, trans_loss=4.996, nll_loss=2.19, w2v_ctc_loss=0.662, task_loss=0, contrastive_loss=0.043, total=4138.44, n_correct=2712.49, ppl=4.56, accuracy=65.544, wps=14784.5, ups=1.79, wpb=8276.9, bsz=307.1, num_updates=34200, lr=7.64719e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=55, gb_free=15.8, wall=24276
2023-08-05 06:45:20 | INFO | train_inner | epoch 024:    414 / 1474 loss=2.085, trans_loss=5.002, nll_loss=2.197, w2v_ctc_loss=0.673, task_loss=0, contrastive_loss=0.182, total=4153.83, n_correct=2705.89, ppl=4.59, accuracy=65.142, wps=14682.1, ups=1.77, wpb=8307.7, bsz=298.4, num_updates=34300, lr=7.63604e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=56, gb_free=16.4, wall=24332
2023-08-05 06:46:16 | INFO | train_inner | epoch 024:    514 / 1474 loss=2.066, trans_loss=4.999, nll_loss=2.193, w2v_ctc_loss=0.666, task_loss=0, contrastive_loss=0.112, total=4141.88, n_correct=2710.64, ppl=4.57, accuracy=65.445, wps=14710.4, ups=1.78, wpb=8283.8, bsz=302.6, num_updates=34400, lr=7.62493e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=56, gb_free=15.5, wall=24389
2023-08-05 06:47:12 | INFO | train_inner | epoch 024:    614 / 1474 loss=2.059, trans_loss=4.999, nll_loss=2.195, w2v_ctc_loss=0.655, task_loss=0, contrastive_loss=0.073, total=4162.06, n_correct=2720.95, ppl=4.58, accuracy=65.375, wps=14870, ups=1.79, wpb=8324.1, bsz=308.1, num_updates=34500, lr=7.61387e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=55, gb_free=17, wall=24445
2023-08-05 06:48:08 | INFO | train_inner | epoch 024:    714 / 1474 loss=2.067, trans_loss=5.011, nll_loss=2.21, w2v_ctc_loss=0.664, task_loss=0, contrastive_loss=0.087, total=4097.35, n_correct=2676.02, ppl=4.63, accuracy=65.311, wps=14463.6, ups=1.76, wpb=8194.7, bsz=293.8, num_updates=34600, lr=7.60286e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=56, gb_free=17.6, wall=24501
2023-08-05 06:49:05 | INFO | train_inner | epoch 024:    814 / 1474 loss=2.066, trans_loss=5.013, nll_loss=2.214, w2v_ctc_loss=0.667, task_loss=0, contrastive_loss=0.062, total=4124.25, n_correct=2688.6, ppl=4.64, accuracy=65.19, wps=14666, ups=1.78, wpb=8248.5, bsz=308.2, num_updates=34700, lr=7.5919e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=56, gb_free=16.2, wall=24558
2023-08-05 06:50:01 | INFO | train_inner | epoch 024:    914 / 1474 loss=2.068, trans_loss=5.019, nll_loss=2.22, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.04, total=4041.44, n_correct=2622.27, ppl=4.66, accuracy=64.885, wps=14454, ups=1.79, wpb=8082.9, bsz=280.5, num_updates=34800, lr=7.58098e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=55, gb_free=16.4, wall=24614
2023-08-05 06:50:56 | INFO | train_inner | epoch 024:   1014 / 1474 loss=2.061, trans_loss=5.013, nll_loss=2.213, w2v_ctc_loss=0.663, task_loss=0, contrastive_loss=0.044, total=4128.8, n_correct=2692.11, ppl=4.64, accuracy=65.203, wps=14824.5, ups=1.8, wpb=8257.6, bsz=296.5, num_updates=34900, lr=7.57011e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=55, gb_free=15.4, wall=24669
2023-08-05 06:51:52 | INFO | train_inner | epoch 024:   1114 / 1474 loss=2.065, trans_loss=5, nll_loss=2.196, w2v_ctc_loss=0.669, task_loss=0, contrastive_loss=0.084, total=4130.49, n_correct=2700.55, ppl=4.58, accuracy=65.381, wps=14805.3, ups=1.79, wpb=8261, bsz=308.9, num_updates=35000, lr=7.55929e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=55, gb_free=16.3, wall=24725
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:0')
2023-08-05 06:52:48 | INFO | train_inner | epoch 024:   1214 / 1474 loss=2.066, trans_loss=5.012, nll_loss=2.212, w2v_ctc_loss=0.664, task_loss=0, contrastive_loss=0.073, total=4157.47, n_correct=2710.77, ppl=4.63, accuracy=65.202, wps=14795.6, ups=1.78, wpb=8314.9, bsz=311.2, num_updates=35100, lr=7.54851e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=56, gb_free=13.2, wall=24781
2023-08-05 06:52:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-05 06:53:45 | INFO | train_inner | epoch 024:   1315 / 1474 loss=2.071, trans_loss=5.021, nll_loss=2.224, w2v_ctc_loss=0.68, task_loss=0, contrastive_loss=0.048, total=4104.66, n_correct=2669.24, ppl=4.67, accuracy=65.03, wps=14424.1, ups=1.76, wpb=8209.3, bsz=294.5, num_updates=35200, lr=7.53778e-05, gnorm=0.559, clip=0, loss_scale=16, train_wall=56, gb_free=13.5, wall=24838
2023-08-05 06:54:41 | INFO | train_inner | epoch 024:   1415 / 1474 loss=2.069, trans_loss=5.024, nll_loss=2.227, w2v_ctc_loss=0.674, task_loss=0, contrastive_loss=0.046, total=4099.36, n_correct=2663.22, ppl=4.68, accuracy=64.967, wps=14788.4, ups=1.8, wpb=8198.7, bsz=294.7, num_updates=35300, lr=7.5271e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=55, gb_free=15.6, wall=24894
2023-08-05 06:55:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:3')
2023-08-05 06:55:37 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.347 | trans_loss 5.548 | nll_loss 2.819 | w2v_ctc_loss 1.33 | task_loss 0 | contrastive_loss 0.243 | total 4003.4 | n_correct 2491.4 | ppl 7.06 | accuracy 62.232 | uer 16.927 | wer 18.814 | raw_wer 18.814 | bleu 19.82 | wps 2244.2 | wpb 4003.4 | bsz 141.8 | num_updates 35359 | best_bleu 20.38
2023-08-05 06:55:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35359 updates
2023-08-05 06:55:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_last.pt
2023-08-05 06:55:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_last.pt
2023-08-05 06:55:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_last.pt (epoch 24 @ 35359 updates, score 19.82) (writing took 13.348712351173162 seconds)
2023-08-05 06:55:50 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-05 06:55:50 | INFO | train | epoch 024 | loss 2.068 | trans_loss 5.006 | nll_loss 2.204 | w2v_ctc_loss 0.665 | task_loss 0 | contrastive_loss 0.097 | total 4138.77 | n_correct 2702.02 | ppl 4.61 | accuracy 65.286 | wps 13138.1 | ups 1.59 | wpb 8277.5 | bsz 305.8 | num_updates 35359 | lr 7.52082e-05 | gnorm 0.554 | clip 0 | loss_scale 16 | train_wall 820 | gb_free 16.4 | wall 24963
2023-08-05 06:55:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 06:55:50 | INFO | fairseq.trainer | begin training epoch 25
2023-08-05 06:55:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 06:56:21 | INFO | train_inner | epoch 025:     41 / 1474 loss=2.054, trans_loss=4.996, nll_loss=2.192, w2v_ctc_loss=0.659, task_loss=0, contrastive_loss=0.052, total=4161.08, n_correct=2728.93, ppl=4.57, accuracy=65.582, wps=8323.6, ups=1, wpb=8322.2, bsz=309.6, num_updates=35400, lr=7.51646e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=55, gb_free=16.8, wall=24994
2023-08-05 06:57:17 | INFO | train_inner | epoch 025:    141 / 1474 loss=2.043, trans_loss=4.975, nll_loss=2.163, w2v_ctc_loss=0.651, task_loss=0, contrastive_loss=0.051, total=4139.23, n_correct=2730.73, ppl=4.48, accuracy=65.972, wps=14757.9, ups=1.78, wpb=8278.5, bsz=309.8, num_updates=35500, lr=7.50587e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=56, gb_free=16.7, wall=25050
2023-08-05 06:58:13 | INFO | train_inner | epoch 025:    241 / 1474 loss=2.049, trans_loss=4.982, nll_loss=2.173, w2v_ctc_loss=0.659, task_loss=0, contrastive_loss=0.055, total=4117.76, n_correct=2703.66, ppl=4.51, accuracy=65.659, wps=14627.5, ups=1.78, wpb=8235.5, bsz=302.9, num_updates=35600, lr=7.49532e-05, gnorm=0.558, clip=0, loss_scale=16, train_wall=56, gb_free=17.2, wall=25106
2023-08-05 06:59:09 | INFO | train_inner | epoch 025:    341 / 1474 loss=2.054, trans_loss=4.986, nll_loss=2.176, w2v_ctc_loss=0.655, task_loss=0, contrastive_loss=0.085, total=4142.17, n_correct=2717.72, ppl=4.52, accuracy=65.611, wps=14725.3, ups=1.78, wpb=8284.3, bsz=295.5, num_updates=35700, lr=7.48481e-05, gnorm=0.561, clip=0, loss_scale=16, train_wall=56, gb_free=16, wall=25162
2023-08-05 07:00:06 | INFO | train_inner | epoch 025:    441 / 1474 loss=2.078, trans_loss=4.995, nll_loss=2.189, w2v_ctc_loss=0.674, task_loss=0, contrastive_loss=0.163, total=4167.72, n_correct=2725.3, ppl=4.56, accuracy=65.391, wps=14781.6, ups=1.77, wpb=8335.4, bsz=296.8, num_updates=35800, lr=7.47435e-05, gnorm=0.567, clip=0, loss_scale=16, train_wall=56, gb_free=17.1, wall=25219
2023-08-05 07:01:02 | INFO | train_inner | epoch 025:    541 / 1474 loss=2.057, trans_loss=4.999, nll_loss=2.194, w2v_ctc_loss=0.66, task_loss=0, contrastive_loss=0.054, total=4154.79, n_correct=2718.89, ppl=4.58, accuracy=65.44, wps=14830.5, ups=1.78, wpb=8309.6, bsz=313.5, num_updates=35900, lr=7.46393e-05, gnorm=0.593, clip=0, loss_scale=16, train_wall=56, gb_free=17.9, wall=25275
2023-08-05 07:01:58 | INFO | train_inner | epoch 025:    641 / 1474 loss=2.064, trans_loss=4.992, nll_loss=2.187, w2v_ctc_loss=0.663, task_loss=0, contrastive_loss=0.121, total=4156.33, n_correct=2720.72, ppl=4.55, accuracy=65.46, wps=14822.9, ups=1.78, wpb=8312.7, bsz=309.3, num_updates=36000, lr=7.45356e-05, gnorm=0.558, clip=0, loss_scale=16, train_wall=56, gb_free=16.6, wall=25331
2023-08-05 07:01:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 07:02:23 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.367 | trans_loss 5.552 | nll_loss 2.822 | w2v_ctc_loss 1.388 | task_loss 0 | contrastive_loss 0.241 | total 4003.4 | n_correct 2489.8 | ppl 7.07 | accuracy 62.192 | uer 17.158 | wer 19.022 | raw_wer 19.022 | bleu 19.83 | wps 1965 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.38
2023-08-05 07:02:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-08-05 07:02:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_25_36000.pt
2023-08-05 07:02:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_25_36000.pt
2023-08-05 07:02:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 19.83) (writing took 18.48936048708856 seconds)
2023-08-05 07:03:38 | INFO | train_inner | epoch 025:    741 / 1474 loss=2.064, trans_loss=4.994, nll_loss=2.189, w2v_ctc_loss=0.659, task_loss=0, contrastive_loss=0.115, total=4133.94, n_correct=2707.33, ppl=4.56, accuracy=65.49, wps=8292.1, ups=1, wpb=8267.9, bsz=303.3, num_updates=36100, lr=7.44323e-05, gnorm=0.567, clip=0, loss_scale=16, train_wall=55, gb_free=15.4, wall=25431
2023-08-05 07:04:33 | INFO | train_inner | epoch 025:    841 / 1474 loss=2.057, trans_loss=4.998, nll_loss=2.195, w2v_ctc_loss=0.659, task_loss=0, contrastive_loss=0.062, total=4174.24, n_correct=2737.63, ppl=4.58, accuracy=65.584, wps=14955.1, ups=1.79, wpb=8348.5, bsz=324, num_updates=36200, lr=7.43294e-05, gnorm=0.557, clip=0, loss_scale=16, train_wall=55, gb_free=16.6, wall=25486
2023-08-05 07:05:30 | INFO | train_inner | epoch 025:    941 / 1474 loss=2.066, trans_loss=5.001, nll_loss=2.199, w2v_ctc_loss=0.662, task_loss=0, contrastive_loss=0.117, total=4154.13, n_correct=2719.97, ppl=4.59, accuracy=65.476, wps=14814.7, ups=1.78, wpb=8308.3, bsz=316.7, num_updates=36300, lr=7.4227e-05, gnorm=0.561, clip=0, loss_scale=16, train_wall=56, gb_free=11.6, wall=25542
2023-08-05 07:06:26 | INFO | train_inner | epoch 025:   1041 / 1474 loss=2.081, trans_loss=5.008, nll_loss=2.208, w2v_ctc_loss=0.655, task_loss=0, contrastive_loss=0.229, total=4178.3, n_correct=2728.1, ppl=4.62, accuracy=65.292, wps=14903.4, ups=1.78, wpb=8356.6, bsz=309.7, num_updates=36400, lr=7.41249e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=56, gb_free=17.2, wall=25599
2023-08-05 07:07:21 | INFO | train_inner | epoch 025:   1141 / 1474 loss=2.051, trans_loss=5.004, nll_loss=2.201, w2v_ctc_loss=0.652, task_loss=0, contrastive_loss=0.039, total=4042.33, n_correct=2644.53, ppl=4.6, accuracy=65.421, wps=14476.1, ups=1.79, wpb=8084.7, bsz=286.5, num_updates=36500, lr=7.40233e-05, gnorm=0.556, clip=0, loss_scale=16, train_wall=55, gb_free=18.1, wall=25654
2023-08-05 07:08:17 | INFO | train_inner | epoch 025:   1241 / 1474 loss=2.058, trans_loss=5.009, nll_loss=2.209, w2v_ctc_loss=0.66, task_loss=0, contrastive_loss=0.046, total=4087.78, n_correct=2668.43, ppl=4.62, accuracy=65.278, wps=14716.8, ups=1.8, wpb=8175.6, bsz=295.1, num_updates=36600, lr=7.39221e-05, gnorm=0.555, clip=0, loss_scale=16, train_wall=55, gb_free=18, wall=25710
2023-08-05 07:09:14 | INFO | train_inner | epoch 025:   1341 / 1474 loss=2.069, trans_loss=5.004, nll_loss=2.202, w2v_ctc_loss=0.659, task_loss=0, contrastive_loss=0.143, total=4166.64, n_correct=2723.54, ppl=4.6, accuracy=65.365, wps=14746, ups=1.77, wpb=8333.3, bsz=309.3, num_updates=36700, lr=7.38213e-05, gnorm=0.565, clip=0, loss_scale=16, train_wall=56, gb_free=16.8, wall=25766
2023-08-05 07:10:10 | INFO | train_inner | epoch 025:   1441 / 1474 loss=2.078, trans_loss=5.023, nll_loss=2.227, w2v_ctc_loss=0.669, task_loss=0, contrastive_loss=0.104, total=4114.64, n_correct=2671.94, ppl=4.68, accuracy=64.937, wps=14603.2, ups=1.77, wpb=8229.3, bsz=304.3, num_updates=36800, lr=7.3721e-05, gnorm=0.565, clip=0, loss_scale=16, train_wall=56, gb_free=16.7, wall=25823
2023-08-05 07:10:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 07:10:53 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.359 | trans_loss 5.548 | nll_loss 2.819 | w2v_ctc_loss 1.368 | task_loss 0 | contrastive_loss 0.249 | total 4003.4 | n_correct 2491.3 | ppl 7.06 | accuracy 62.23 | uer 17.158 | wer 19.119 | raw_wer 19.119 | bleu 19.95 | wps 2039.4 | wpb 4003.4 | bsz 141.8 | num_updates 36833 | best_bleu 20.38
2023-08-05 07:10:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36833 updates
2023-08-05 07:10:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.9506.pt
2023-08-05 07:10:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.9506.pt
2023-08-05 07:11:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_19.9506.pt (epoch 25 @ 36833 updates, score 19.95) (writing took 13.861041689291596 seconds)
2023-08-05 07:11:07 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-05 07:11:07 | INFO | train | epoch 025 | loss 2.062 | trans_loss 4.998 | nll_loss 2.193 | w2v_ctc_loss 0.66 | task_loss 0 | contrastive_loss 0.096 | total 4138.65 | n_correct 2709.33 | ppl 4.57 | accuracy 65.464 | wps 13307.9 | ups 1.61 | wpb 8277.3 | bsz 305.7 | num_updates 36833 | lr 7.36879e-05 | gnorm 0.561 | clip 0 | loss_scale 16 | train_wall 820 | gb_free 14.7 | wall 25880
2023-08-05 07:11:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 07:11:07 | INFO | fairseq.trainer | begin training epoch 26
2023-08-05 07:11:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 07:11:52 | INFO | train_inner | epoch 026:     67 / 1474 loss=2.044, trans_loss=4.973, nll_loss=2.162, w2v_ctc_loss=0.646, task_loss=0, contrastive_loss=0.071, total=4172.16, n_correct=2752.76, ppl=4.47, accuracy=65.979, wps=8138.6, ups=0.98, wpb=8344.3, bsz=316.9, num_updates=36900, lr=7.3621e-05, gnorm=0.558, clip=0, loss_scale=16, train_wall=56, gb_free=17.4, wall=25925
2023-08-05 07:12:49 | INFO | train_inner | epoch 026:    167 / 1474 loss=2.065, trans_loss=4.97, nll_loss=2.159, w2v_ctc_loss=0.638, task_loss=0, contrastive_loss=0.248, total=4265.22, n_correct=2820.5, ppl=4.46, accuracy=66.128, wps=15023.3, ups=1.76, wpb=8530.4, bsz=338.7, num_updates=37000, lr=7.35215e-05, gnorm=0.593, clip=0, loss_scale=16, train_wall=56, gb_free=15.8, wall=25982
2023-08-05 07:13:46 | INFO | train_inner | epoch 026:    267 / 1474 loss=2.059, trans_loss=4.978, nll_loss=2.168, w2v_ctc_loss=0.659, task_loss=0, contrastive_loss=0.132, total=4123.94, n_correct=2711.53, ppl=4.49, accuracy=65.751, wps=14608.6, ups=1.77, wpb=8247.9, bsz=306.6, num_updates=37100, lr=7.34223e-05, gnorm=0.56, clip=0, loss_scale=16, train_wall=56, gb_free=17.2, wall=26039
2023-08-05 07:14:41 | INFO | train_inner | epoch 026:    367 / 1474 loss=2.053, trans_loss=4.98, nll_loss=2.171, w2v_ctc_loss=0.654, task_loss=0, contrastive_loss=0.091, total=4168.11, n_correct=2741.6, ppl=4.5, accuracy=65.776, wps=15033.4, ups=1.8, wpb=8336.2, bsz=315.2, num_updates=37200, lr=7.33236e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=55, gb_free=17.6, wall=26094
2023-08-05 07:15:37 | INFO | train_inner | epoch 026:    467 / 1474 loss=2.055, trans_loss=4.973, nll_loss=2.161, w2v_ctc_loss=0.652, task_loss=0, contrastive_loss=0.138, total=4167.53, n_correct=2750.79, ppl=4.47, accuracy=66.005, wps=14869.1, ups=1.78, wpb=8335.1, bsz=314.6, num_updates=37300, lr=7.32252e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=56, gb_free=14.5, wall=26150
2023-08-05 07:16:34 | INFO | train_inner | epoch 026:    567 / 1474 loss=2.051, trans_loss=4.987, nll_loss=2.179, w2v_ctc_loss=0.662, task_loss=0, contrastive_loss=0.058, total=4158.48, n_correct=2733.03, ppl=4.53, accuracy=65.722, wps=14720.3, ups=1.77, wpb=8317, bsz=304.4, num_updates=37400, lr=7.31272e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=56, gb_free=13.3, wall=26207
2023-08-05 07:17:30 | INFO | train_inner | epoch 026:    667 / 1474 loss=2.044, trans_loss=4.987, nll_loss=2.18, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.044, total=4129.11, n_correct=2714.02, ppl=4.53, accuracy=65.729, wps=14697.4, ups=1.78, wpb=8258.2, bsz=297.7, num_updates=37500, lr=7.30297e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=56, gb_free=14.3, wall=26263
2023-08-05 07:18:26 | INFO | train_inner | epoch 026:    767 / 1474 loss=2.065, trans_loss=4.993, nll_loss=2.187, w2v_ctc_loss=0.651, task_loss=0, contrastive_loss=0.156, total=4096.84, n_correct=2683.23, ppl=4.55, accuracy=65.495, wps=14712.9, ups=1.8, wpb=8193.7, bsz=300.5, num_updates=37600, lr=7.29325e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=55, gb_free=16.8, wall=26319
2023-08-05 07:19:21 | INFO | train_inner | epoch 026:    867 / 1474 loss=2.052, trans_loss=4.99, nll_loss=2.183, w2v_ctc_loss=0.66, task_loss=0, contrastive_loss=0.058, total=4176.27, n_correct=2740.99, ppl=4.54, accuracy=65.632, wps=14945, ups=1.79, wpb=8352.5, bsz=306.4, num_updates=37700, lr=7.28357e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=55, gb_free=16.6, wall=26374
2023-08-05 07:20:18 | INFO | train_inner | epoch 026:    967 / 1474 loss=2.057, trans_loss=4.998, nll_loss=2.194, w2v_ctc_loss=0.645, task_loss=0, contrastive_loss=0.109, total=4141.01, n_correct=2712.17, ppl=4.58, accuracy=65.495, wps=14702.7, ups=1.78, wpb=8282, bsz=299.7, num_updates=37800, lr=7.27393e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=56, gb_free=15.8, wall=26431
2023-08-05 07:21:14 | INFO | train_inner | epoch 026:   1067 / 1474 loss=2.051, trans_loss=4.998, nll_loss=2.194, w2v_ctc_loss=0.656, task_loss=0, contrastive_loss=0.044, total=4113.69, n_correct=2698.16, ppl=4.58, accuracy=65.59, wps=14638.7, ups=1.78, wpb=8227.4, bsz=293, num_updates=37900, lr=7.26433e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=56, gb_free=15.8, wall=26487
2023-08-05 07:22:10 | INFO | train_inner | epoch 026:   1167 / 1474 loss=2.059, trans_loss=5.001, nll_loss=2.198, w2v_ctc_loss=0.657, task_loss=0, contrastive_loss=0.083, total=4116.78, n_correct=2691.33, ppl=4.59, accuracy=65.375, wps=14623.5, ups=1.78, wpb=8233.6, bsz=299, num_updates=38000, lr=7.25476e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=26543
2023-08-05 07:22:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 07:22:34 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.368 | trans_loss 5.557 | nll_loss 2.829 | w2v_ctc_loss 1.379 | task_loss 0 | contrastive_loss 0.241 | total 4003.4 | n_correct 2493.4 | ppl 7.11 | accuracy 62.282 | uer 17.288 | wer 19.194 | raw_wer 19.194 | bleu 19.98 | wps 2117.8 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.38
2023-08-05 07:22:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-08-05 07:22:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_26_38000.pt
2023-08-05 07:22:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_26_38000.pt
2023-08-05 07:23:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 19.98) (writing took 32.6246383190155 seconds)
2023-08-05 07:24:04 | INFO | train_inner | epoch 026:   1267 / 1474 loss=2.064, trans_loss=5.015, nll_loss=2.216, w2v_ctc_loss=0.673, task_loss=0, contrastive_loss=0.046, total=4001.06, n_correct=2603.5, ppl=4.64, accuracy=65.07, wps=7059.3, ups=0.88, wpb=8002.1, bsz=280.6, num_updates=38100, lr=7.24524e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=56, gb_free=16, wall=26657
2023-08-05 07:25:00 | INFO | train_inner | epoch 026:   1367 / 1474 loss=2.053, trans_loss=5.004, nll_loss=2.202, w2v_ctc_loss=0.648, task_loss=0, contrastive_loss=0.058, total=4157.69, n_correct=2724.44, ppl=4.6, accuracy=65.528, wps=14750.6, ups=1.77, wpb=8315.4, bsz=310.5, num_updates=38200, lr=7.23575e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=56, gb_free=16.4, wall=26713
2023-08-05 07:25:56 | INFO | train_inner | epoch 026:   1467 / 1474 loss=2.049, trans_loss=4.997, nll_loss=2.195, w2v_ctc_loss=0.648, task_loss=0, contrastive_loss=0.053, total=4158.47, n_correct=2729.07, ppl=4.58, accuracy=65.627, wps=14878, ups=1.79, wpb=8316.9, bsz=316.5, num_updates=38300, lr=7.22629e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=55, gb_free=17.6, wall=26769
2023-08-05 07:26:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 07:26:25 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.35 | trans_loss 5.549 | nll_loss 2.819 | w2v_ctc_loss 1.342 | task_loss 0 | contrastive_loss 0.242 | total 4003.4 | n_correct 2492.7 | ppl 7.06 | accuracy 62.265 | uer 17.243 | wer 19.045 | raw_wer 19.045 | bleu 20.26 | wps 2180.6 | wpb 4003.4 | bsz 141.8 | num_updates 38307 | best_bleu 20.38
2023-08-05 07:26:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38307 updates
2023-08-05 07:26:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_20.2600.pt
2023-08-05 07:26:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_20.2600.pt
2023-08-05 07:26:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_20.2600.pt (epoch 26 @ 38307 updates, score 20.26) (writing took 13.632641345262527 seconds)
2023-08-05 07:26:39 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-05 07:26:39 | INFO | train | epoch 026 | loss 2.055 | trans_loss 4.989 | nll_loss 2.182 | w2v_ctc_loss 0.653 | task_loss 0 | contrastive_loss 0.095 | total 4138.65 | n_correct 2717.69 | ppl 4.54 | accuracy 65.666 | wps 13091.2 | ups 1.58 | wpb 8277.3 | bsz 305.7 | num_updates 38307 | lr 7.22563e-05 | gnorm 0.562 | clip 0 | loss_scale 32 | train_wall 821 | gb_free 16.3 | wall 26812
2023-08-05 07:26:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 07:26:39 | INFO | fairseq.trainer | begin training epoch 27
2023-08-05 07:26:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 07:27:39 | INFO | train_inner | epoch 027:     93 / 1474 loss=2.024, trans_loss=4.953, nll_loss=2.133, w2v_ctc_loss=0.633, task_loss=0, contrastive_loss=0.035, total=4067.62, n_correct=2702.93, ppl=4.39, accuracy=66.45, wps=7909.3, ups=0.97, wpb=8135.2, bsz=284.4, num_updates=38400, lr=7.21688e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=55, gb_free=15.2, wall=26872
2023-08-05 07:28:35 | INFO | train_inner | epoch 027:    193 / 1474 loss=2.034, trans_loss=4.958, nll_loss=2.142, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.059, total=4185.52, n_correct=2776.27, ppl=4.41, accuracy=66.33, wps=14850.5, ups=1.77, wpb=8371, bsz=321.7, num_updates=38500, lr=7.2075e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=56, gb_free=17.9, wall=26928
2023-08-05 07:29:32 | INFO | train_inner | epoch 027:    293 / 1474 loss=2.038, trans_loss=4.971, nll_loss=2.159, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.046, total=4167.92, n_correct=2754.86, ppl=4.47, accuracy=66.097, wps=14749.4, ups=1.77, wpb=8335.8, bsz=306.8, num_updates=38600, lr=7.19816e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=56, gb_free=17.2, wall=26985
2023-08-05 07:30:28 | INFO | train_inner | epoch 027:    393 / 1474 loss=2.068, trans_loss=4.981, nll_loss=2.172, w2v_ctc_loss=0.648, task_loss=0, contrastive_loss=0.226, total=4075.21, n_correct=2678.82, ppl=4.51, accuracy=65.735, wps=14460.9, ups=1.77, wpb=8150.4, bsz=296, num_updates=38700, lr=7.18885e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=56, gb_free=18, wall=27041
2023-08-05 07:31:24 | INFO | train_inner | epoch 027:    493 / 1474 loss=2.061, trans_loss=4.982, nll_loss=2.174, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.162, total=4249.35, n_correct=2797.22, ppl=4.51, accuracy=65.827, wps=15142.1, ups=1.78, wpb=8498.7, bsz=331.9, num_updates=38800, lr=7.17958e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=56, gb_free=12.6, wall=27097
2023-08-05 07:32:20 | INFO | train_inner | epoch 027:    593 / 1474 loss=2.052, trans_loss=4.979, nll_loss=2.169, w2v_ctc_loss=0.651, task_loss=0, contrastive_loss=0.101, total=4133.39, n_correct=2722.09, ppl=4.5, accuracy=65.856, wps=14713.5, ups=1.78, wpb=8266.8, bsz=312, num_updates=38900, lr=7.17035e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=56, gb_free=12.7, wall=27153
2023-08-05 07:33:17 | INFO | train_inner | epoch 027:    693 / 1474 loss=2.049, trans_loss=4.984, nll_loss=2.176, w2v_ctc_loss=0.65, task_loss=0, contrastive_loss=0.079, total=4162.71, n_correct=2742.79, ppl=4.52, accuracy=65.89, wps=14725.3, ups=1.77, wpb=8325.4, bsz=305.4, num_updates=39000, lr=7.16115e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=56, gb_free=16.6, wall=27210
2023-08-05 07:34:13 | INFO | train_inner | epoch 027:    793 / 1474 loss=2.046, trans_loss=4.986, nll_loss=2.179, w2v_ctc_loss=0.655, task_loss=0, contrastive_loss=0.045, total=4103.81, n_correct=2694.73, ppl=4.53, accuracy=65.664, wps=14651.1, ups=1.79, wpb=8207.6, bsz=294.2, num_updates=39100, lr=7.15199e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=56, gb_free=16.5, wall=27266
2023-08-05 07:35:08 | INFO | train_inner | epoch 027:    893 / 1474 loss=2.041, trans_loss=4.992, nll_loss=2.186, w2v_ctc_loss=0.643, task_loss=0, contrastive_loss=0.039, total=4101.56, n_correct=2697.4, ppl=4.55, accuracy=65.765, wps=14805, ups=1.8, wpb=8203.1, bsz=292.1, num_updates=39200, lr=7.14286e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=55, gb_free=18, wall=27321
2023-08-05 07:36:05 | INFO | train_inner | epoch 027:    993 / 1474 loss=2.066, trans_loss=4.986, nll_loss=2.18, w2v_ctc_loss=0.646, task_loss=0, contrastive_loss=0.223, total=4199.56, n_correct=2763.51, ppl=4.53, accuracy=65.805, wps=14834.7, ups=1.77, wpb=8399.1, bsz=316.8, num_updates=39300, lr=7.13376e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=56, gb_free=12.2, wall=27378
2023-08-05 07:37:02 | INFO | train_inner | epoch 027:   1093 / 1474 loss=2.043, trans_loss=4.985, nll_loss=2.178, w2v_ctc_loss=0.644, task_loss=0, contrastive_loss=0.056, total=4150.97, n_correct=2732.57, ppl=4.52, accuracy=65.83, wps=14673.2, ups=1.77, wpb=8301.9, bsz=305, num_updates=39400, lr=7.1247e-05, gnorm=0.565, clip=0, loss_scale=64, train_wall=56, gb_free=12.6, wall=27435
2023-08-05 07:37:58 | INFO | train_inner | epoch 027:   1193 / 1474 loss=2.052, trans_loss=4.992, nll_loss=2.186, w2v_ctc_loss=0.656, task_loss=0, contrastive_loss=0.058, total=4103.06, n_correct=2694.91, ppl=4.55, accuracy=65.68, wps=14641.4, ups=1.78, wpb=8206.1, bsz=297.7, num_updates=39500, lr=7.11568e-05, gnorm=0.56, clip=0, loss_scale=64, train_wall=56, gb_free=16.8, wall=27491
2023-08-05 07:38:53 | INFO | train_inner | epoch 027:   1293 / 1474 loss=2.057, trans_loss=4.994, nll_loss=2.19, w2v_ctc_loss=0.649, task_loss=0, contrastive_loss=0.111, total=4062.52, n_correct=2661.55, ppl=4.56, accuracy=65.515, wps=14632.8, ups=1.8, wpb=8125, bsz=292.2, num_updates=39600, lr=7.10669e-05, gnorm=0.568, clip=0, loss_scale=64, train_wall=55, gb_free=16.9, wall=27546
2023-08-05 07:39:49 | INFO | train_inner | epoch 027:   1393 / 1474 loss=2.05, trans_loss=4.991, nll_loss=2.186, w2v_ctc_loss=0.643, task_loss=0, contrastive_loss=0.091, total=4152, n_correct=2728.9, ppl=4.55, accuracy=65.725, wps=14822.8, ups=1.79, wpb=8304, bsz=312.5, num_updates=39700, lr=7.09773e-05, gnorm=0.554, clip=0, loss_scale=64, train_wall=56, gb_free=16.9, wall=27602
2023-08-05 07:40:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 07:40:58 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.364 | trans_loss 5.546 | nll_loss 2.817 | w2v_ctc_loss 1.398 | task_loss 0 | contrastive_loss 0.239 | total 4003.4 | n_correct 2495.7 | ppl 7.05 | accuracy 62.34 | uer 17.102 | wer 19.015 | raw_wer 19.015 | bleu 20.11 | wps 2352 | wpb 4003.4 | bsz 141.8 | num_updates 39781 | best_bleu 20.38
2023-08-05 07:40:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39781 updates
2023-08-05 07:40:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_20.1101.pt
2023-08-05 07:41:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_20.1101.pt
2023-08-05 07:41:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_20.1101.pt (epoch 27 @ 39781 updates, score 20.11) (writing took 16.5471100397408 seconds)
2023-08-05 07:41:15 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-05 07:41:15 | INFO | train | epoch 027 | loss 2.048 | trans_loss 4.981 | nll_loss 2.172 | w2v_ctc_loss 0.646 | task_loss 0 | contrastive_loss 0.094 | total 4138.65 | n_correct 2726.4 | ppl 4.51 | accuracy 65.877 | wps 13925.7 | ups 1.68 | wpb 8277.3 | bsz 305.7 | num_updates 39781 | lr 7.0905e-05 | gnorm 0.559 | clip 0 | loss_scale 64 | train_wall 820 | gb_free 18.1 | wall 27688
2023-08-05 07:41:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 07:41:15 | INFO | fairseq.trainer | begin training epoch 28
2023-08-05 07:41:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 07:41:34 | INFO | train_inner | epoch 028:     19 / 1474 loss=2.038, trans_loss=4.983, nll_loss=2.175, w2v_ctc_loss=0.64, task_loss=0, contrastive_loss=0.047, total=4108.43, n_correct=2710.29, ppl=4.52, accuracy=65.969, wps=7865.5, ups=0.96, wpb=8216.9, bsz=305.1, num_updates=39800, lr=7.08881e-05, gnorm=0.562, clip=0, loss_scale=64, train_wall=55, gb_free=16.5, wall=27707
2023-08-05 07:42:29 | INFO | train_inner | epoch 028:    119 / 1474 loss=2.025, trans_loss=4.95, nll_loss=2.131, w2v_ctc_loss=0.636, task_loss=0, contrastive_loss=0.042, total=4113.41, n_correct=2733.43, ppl=4.38, accuracy=66.452, wps=14735.1, ups=1.79, wpb=8226.8, bsz=293.9, num_updates=39900, lr=7.07992e-05, gnorm=0.552, clip=0, loss_scale=64, train_wall=55, gb_free=17.1, wall=27762
2023-08-05 07:43:25 | INFO | train_inner | epoch 028:    219 / 1474 loss=2.029, trans_loss=4.96, nll_loss=2.144, w2v_ctc_loss=0.635, task_loss=0, contrastive_loss=0.049, total=4191.56, n_correct=2784.54, ppl=4.42, accuracy=66.432, wps=15036.6, ups=1.79, wpb=8383.1, bsz=315.2, num_updates=40000, lr=7.07107e-05, gnorm=0.559, clip=0, loss_scale=64, train_wall=55, gb_free=15.4, wall=27818
2023-08-05 07:43:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 07:43:48 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.37 | trans_loss 5.554 | nll_loss 2.826 | w2v_ctc_loss 1.401 | task_loss 0 | contrastive_loss 0.236 | total 4003.4 | n_correct 2492.3 | ppl 7.09 | accuracy 62.255 | uer 17.094 | wer 18.922 | raw_wer 18.922 | bleu 20.1 | wps 2185.3 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.38
2023-08-05 07:43:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-08-05 07:43:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_28_40000.pt
2023-08-05 07:43:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_28_40000.pt
2023-08-05 07:44:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 20.1) (writing took 18.78497476875782 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:0')
2023-08-05 07:45:04 | INFO | train_inner | epoch 028:    319 / 1474 loss=2.079, trans_loss=4.97, nll_loss=2.158, w2v_ctc_loss=0.633, task_loss=0, contrastive_loss=0.375, total=4145.32, n_correct=2734.66, ppl=4.46, accuracy=65.97, wps=8355.5, ups=1.01, wpb=8290.6, bsz=316.1, num_updates=40100, lr=7.06225e-05, gnorm=0.558, clip=0, loss_scale=64, train_wall=56, gb_free=16, wall=27917
2023-08-05 07:46:01 | INFO | train_inner | epoch 028:    419 / 1474 loss=2.035, trans_loss=4.968, nll_loss=2.155, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.038, total=4092.14, n_correct=2705.64, ppl=4.45, accuracy=66.118, wps=14544.8, ups=1.78, wpb=8184.3, bsz=295.7, num_updates=40200, lr=7.05346e-05, gnorm=0.565, clip=0, loss_scale=64, train_wall=56, gb_free=16.6, wall=27974
2023-08-05 07:46:57 | INFO | train_inner | epoch 028:    519 / 1474 loss=2.033, trans_loss=4.97, nll_loss=2.157, w2v_ctc_loss=0.638, task_loss=0, contrastive_loss=0.049, total=4096.35, n_correct=2707.13, ppl=4.46, accuracy=66.086, wps=14651.3, ups=1.79, wpb=8192.7, bsz=295.5, num_updates=40300, lr=7.0447e-05, gnorm=0.557, clip=0, loss_scale=64, train_wall=55, gb_free=16.3, wall=28030
2023-08-05 07:47:53 | INFO | train_inner | epoch 028:    619 / 1474 loss=2.041, trans_loss=4.981, nll_loss=2.171, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.05, total=4178.12, n_correct=2752.38, ppl=4.5, accuracy=65.876, wps=14929.8, ups=1.79, wpb=8356.2, bsz=305.3, num_updates=40400, lr=7.03598e-05, gnorm=0.554, clip=0, loss_scale=64, train_wall=56, gb_free=16.1, wall=28086
2023-08-05 07:48:49 | INFO | train_inner | epoch 028:    719 / 1474 loss=2.052, trans_loss=4.976, nll_loss=2.167, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.156, total=4185.82, n_correct=2766.95, ppl=4.49, accuracy=66.103, wps=14960.3, ups=1.79, wpb=8371.6, bsz=326.4, num_updates=40500, lr=7.02728e-05, gnorm=0.56, clip=0, loss_scale=64, train_wall=56, gb_free=16.3, wall=28142
2023-08-05 07:49:45 | INFO | train_inner | epoch 028:    819 / 1474 loss=2.032, trans_loss=4.973, nll_loss=2.162, w2v_ctc_loss=0.636, task_loss=0, contrastive_loss=0.042, total=4096.2, n_correct=2715.26, ppl=4.47, accuracy=66.287, wps=14644.7, ups=1.79, wpb=8192.4, bsz=307, num_updates=40600, lr=7.01862e-05, gnorm=0.555, clip=0, loss_scale=64, train_wall=55, gb_free=16.1, wall=28197
2023-08-05 07:50:41 | INFO | train_inner | epoch 028:    919 / 1474 loss=2.051, trans_loss=4.984, nll_loss=2.176, w2v_ctc_loss=0.649, task_loss=0, contrastive_loss=0.101, total=4120.27, n_correct=2710.94, ppl=4.52, accuracy=65.795, wps=14596.1, ups=1.77, wpb=8240.5, bsz=300.8, num_updates=40700, lr=7.01e-05, gnorm=0.557, clip=0, loss_scale=64, train_wall=56, gb_free=17.7, wall=28254
2023-08-05 07:51:37 | INFO | train_inner | epoch 028:   1019 / 1474 loss=2.058, trans_loss=4.981, nll_loss=2.173, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.151, total=4177.86, n_correct=2751.51, ppl=4.51, accuracy=65.859, wps=14935.7, ups=1.79, wpb=8355.7, bsz=311.1, num_updates=40800, lr=7.0014e-05, gnorm=0.564, clip=0, loss_scale=64, train_wall=55, gb_free=16.7, wall=28310
2023-08-05 07:52:33 | INFO | train_inner | epoch 028:   1119 / 1474 loss=2.038, trans_loss=4.973, nll_loss=2.163, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.059, total=4210.86, n_correct=2780.15, ppl=4.48, accuracy=66.023, wps=15060.6, ups=1.79, wpb=8421.7, bsz=318.9, num_updates=40900, lr=6.99284e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=55, gb_free=17.8, wall=28366
2023-08-05 07:53:29 | INFO | train_inner | epoch 028:   1219 / 1474 loss=2.037, trans_loss=4.982, nll_loss=2.174, w2v_ctc_loss=0.636, task_loss=0, contrastive_loss=0.048, total=4104.61, n_correct=2704.88, ppl=4.51, accuracy=65.899, wps=14686.6, ups=1.79, wpb=8209.2, bsz=305.6, num_updates=41000, lr=6.9843e-05, gnorm=0.565, clip=0, loss_scale=64, train_wall=55, gb_free=16.8, wall=28422
2023-08-05 07:54:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-05 07:54:26 | INFO | train_inner | epoch 028:   1320 / 1474 loss=2.04, trans_loss=4.984, nll_loss=2.176, w2v_ctc_loss=0.649, task_loss=0, contrastive_loss=0.041, total=4066.12, n_correct=2678.87, ppl=4.52, accuracy=65.883, wps=14329, ups=1.76, wpb=8132.2, bsz=279.9, num_updates=41100, lr=6.9758e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=56, gb_free=16.1, wall=28478
2023-08-05 07:55:22 | INFO | train_inner | epoch 028:   1420 / 1474 loss=2.046, trans_loss=4.985, nll_loss=2.177, w2v_ctc_loss=0.64, task_loss=0, contrastive_loss=0.085, total=4154.09, n_correct=2733.29, ppl=4.52, accuracy=65.798, wps=14774.7, ups=1.78, wpb=8308.2, bsz=299.3, num_updates=41200, lr=6.96733e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=56, gb_free=16.3, wall=28535
2023-08-05 07:55:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:3')
2023-08-05 07:56:16 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.349 | trans_loss 5.55 | nll_loss 2.82 | w2v_ctc_loss 1.335 | task_loss 0 | contrastive_loss 0.24 | total 4003.4 | n_correct 2495 | ppl 7.06 | accuracy 62.322 | uer 17.012 | wer 18.601 | raw_wer 18.601 | bleu 20.41 | wps 2053.9 | wpb 4003.4 | bsz 141.8 | num_updates 41254 | best_bleu 20.41
2023-08-05 07:56:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41254 updates
2023-08-05 07:56:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 07:56:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt
2023-08-05 07:56:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_best.pt (epoch 28 @ 41254 updates, score 20.41) (writing took 23.815903436392546 seconds)
2023-08-05 07:56:40 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-05 07:56:40 | INFO | train | epoch 028 | loss 2.042 | trans_loss 4.974 | nll_loss 2.163 | w2v_ctc_loss 0.641 | task_loss 0 | contrastive_loss 0.091 | total 4137.57 | n_correct 2732.72 | ppl 4.48 | accuracy 66.046 | wps 13172.6 | ups 1.59 | wpb 8275.1 | bsz 305.3 | num_updates 41254 | lr 6.96277e-05 | gnorm 0.559 | clip 0 | loss_scale 32 | train_wall 819 | gb_free 16.7 | wall 28613
2023-08-05 07:56:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 07:56:41 | INFO | fairseq.trainer | begin training epoch 29
2023-08-05 07:56:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 07:57:14 | INFO | train_inner | epoch 029:     46 / 1474 loss=2.033, trans_loss=4.959, nll_loss=2.144, w2v_ctc_loss=0.645, task_loss=0, contrastive_loss=0.058, total=4169.12, n_correct=2768.28, ppl=4.42, accuracy=66.4, wps=7413.3, ups=0.89, wpb=8338.2, bsz=316.4, num_updates=41300, lr=6.95889e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=56, gb_free=16.7, wall=28647
2023-08-05 07:57:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-05 07:58:11 | INFO | train_inner | epoch 029:    147 / 1474 loss=2.031, trans_loss=4.957, nll_loss=2.141, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.057, total=4101.12, n_correct=2722.67, ppl=4.41, accuracy=66.388, wps=14335.3, ups=1.75, wpb=8202.2, bsz=302.2, num_updates=41400, lr=6.95048e-05, gnorm=0.563, clip=0, loss_scale=16, train_wall=57, gb_free=16.8, wall=28704
2023-08-05 07:59:07 | INFO | train_inner | epoch 029:    247 / 1474 loss=2.038, trans_loss=4.949, nll_loss=2.131, w2v_ctc_loss=0.623, task_loss=0, contrastive_loss=0.157, total=4197.89, n_correct=2795.16, ppl=4.38, accuracy=66.585, wps=14980.4, ups=1.78, wpb=8395.8, bsz=329.5, num_updates=41500, lr=6.9421e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=56, gb_free=17.8, wall=28760
2023-08-05 08:00:04 | INFO | train_inner | epoch 029:    347 / 1474 loss=2.038, trans_loss=4.973, nll_loss=2.161, w2v_ctc_loss=0.649, task_loss=0, contrastive_loss=0.045, total=4094.4, n_correct=2705.98, ppl=4.47, accuracy=66.09, wps=14618.3, ups=1.79, wpb=8188.8, bsz=291.2, num_updates=41600, lr=6.93375e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=56, gb_free=16.7, wall=28816
2023-08-05 08:01:00 | INFO | train_inner | epoch 029:    447 / 1474 loss=2.016, trans_loss=4.944, nll_loss=2.124, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.039, total=4157.41, n_correct=2771.11, ppl=4.36, accuracy=66.655, wps=14825.6, ups=1.78, wpb=8314.8, bsz=308.5, num_updates=41700, lr=6.92543e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=56, gb_free=15.1, wall=28873
2023-08-05 08:01:56 | INFO | train_inner | epoch 029:    547 / 1474 loss=2.048, trans_loss=4.97, nll_loss=2.158, w2v_ctc_loss=0.64, task_loss=0, contrastive_loss=0.131, total=4149.27, n_correct=2740.63, ppl=4.46, accuracy=66.051, wps=14595.1, ups=1.76, wpb=8298.5, bsz=293.3, num_updates=41800, lr=6.91714e-05, gnorm=0.558, clip=0, loss_scale=16, train_wall=56, gb_free=15.7, wall=28929
2023-08-05 08:02:52 | INFO | train_inner | epoch 029:    647 / 1474 loss=2.046, trans_loss=4.958, nll_loss=2.144, w2v_ctc_loss=0.631, task_loss=0, contrastive_loss=0.201, total=4145.39, n_correct=2751.13, ppl=4.42, accuracy=66.366, wps=14823.6, ups=1.79, wpb=8290.8, bsz=319.3, num_updates=41900, lr=6.90889e-05, gnorm=0.553, clip=0, loss_scale=16, train_wall=55, gb_free=17.7, wall=28985
2023-08-05 08:03:49 | INFO | train_inner | epoch 029:    747 / 1474 loss=2.039, trans_loss=4.959, nll_loss=2.145, w2v_ctc_loss=0.632, task_loss=0, contrastive_loss=0.118, total=4242.46, n_correct=2810.77, ppl=4.42, accuracy=66.253, wps=15108.7, ups=1.78, wpb=8484.9, bsz=329.9, num_updates=42000, lr=6.90066e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=56, gb_free=16.8, wall=29042
2023-08-05 08:03:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 08:04:10 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.377 | trans_loss 5.552 | nll_loss 2.823 | w2v_ctc_loss 1.428 | task_loss 0 | contrastive_loss 0.235 | total 4003.4 | n_correct 2490.3 | ppl 7.08 | accuracy 62.205 | uer 17.174 | wer 18.832 | raw_wer 18.832 | bleu 20.14 | wps 2441.1 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.41
2023-08-05 08:04:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-08-05 08:04:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_29_42000.pt
2023-08-05 08:04:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_29_42000.pt
2023-08-05 08:04:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 20.14) (writing took 37.74779027700424 seconds)
2023-08-05 08:05:45 | INFO | train_inner | epoch 029:    847 / 1474 loss=2.033, trans_loss=4.98, nll_loss=2.17, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.038, total=4027.03, n_correct=2657.85, ppl=4.5, accuracy=66, wps=6932.5, ups=0.86, wpb=8054.1, bsz=280.3, num_updates=42100, lr=6.89246e-05, gnorm=0.575, clip=0, loss_scale=16, train_wall=55, gb_free=17.7, wall=29158
2023-08-05 08:06:41 | INFO | train_inner | epoch 029:    947 / 1474 loss=2.038, trans_loss=4.979, nll_loss=2.17, w2v_ctc_loss=0.644, task_loss=0, contrastive_loss=0.048, total=4086.72, n_correct=2697.76, ppl=4.5, accuracy=66.013, wps=14488.7, ups=1.77, wpb=8173.4, bsz=296.3, num_updates=42200, lr=6.88428e-05, gnorm=0.567, clip=0, loss_scale=16, train_wall=56, gb_free=15.8, wall=29214
2023-08-05 08:07:37 | INFO | train_inner | epoch 029:   1047 / 1474 loss=2.038, trans_loss=4.967, nll_loss=2.155, w2v_ctc_loss=0.632, task_loss=0, contrastive_loss=0.121, total=4139.4, n_correct=2744.32, ppl=4.45, accuracy=66.298, wps=14886, ups=1.8, wpb=8278.8, bsz=307.4, num_updates=42300, lr=6.87614e-05, gnorm=0.561, clip=0, loss_scale=16, train_wall=55, gb_free=15.8, wall=29270
2023-08-05 08:08:32 | INFO | train_inner | epoch 029:   1147 / 1474 loss=2.037, trans_loss=4.984, nll_loss=2.177, w2v_ctc_loss=0.646, task_loss=0, contrastive_loss=0.035, total=4072.33, n_correct=2687.12, ppl=4.52, accuracy=65.985, wps=14653.5, ups=1.8, wpb=8144.7, bsz=284.1, num_updates=42400, lr=6.86803e-05, gnorm=0.569, clip=0, loss_scale=16, train_wall=55, gb_free=17.2, wall=29325
2023-08-05 08:09:28 | INFO | train_inner | epoch 029:   1247 / 1474 loss=2.036, trans_loss=4.981, nll_loss=2.172, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.041, total=4160.52, n_correct=2745.67, ppl=4.51, accuracy=65.993, wps=14862, ups=1.79, wpb=8321, bsz=301.5, num_updates=42500, lr=6.85994e-05, gnorm=0.558, clip=0, loss_scale=16, train_wall=56, gb_free=16, wall=29381
2023-08-05 08:10:25 | INFO | train_inner | epoch 029:   1347 / 1474 loss=2.037, trans_loss=4.969, nll_loss=2.158, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.103, total=4168.02, n_correct=2761.67, ppl=4.46, accuracy=66.259, wps=14707.9, ups=1.76, wpb=8336, bsz=310.2, num_updates=42600, lr=6.85189e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=56, gb_free=16.8, wall=29438
2023-08-05 08:11:21 | INFO | train_inner | epoch 029:   1447 / 1474 loss=2.047, trans_loss=4.973, nll_loss=2.164, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.133, total=4166.06, n_correct=2749.22, ppl=4.48, accuracy=65.991, wps=14969.2, ups=1.8, wpb=8332.1, bsz=313.1, num_updates=42700, lr=6.84386e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=55, gb_free=17.1, wall=29494
2023-08-05 08:11:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 08:11:58 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.371 | trans_loss 5.551 | nll_loss 2.82 | w2v_ctc_loss 1.411 | task_loss 0 | contrastive_loss 0.233 | total 4003.4 | n_correct 2488.6 | ppl 7.06 | accuracy 62.162 | uer 17.129 | wer 18.888 | raw_wer 18.888 | bleu 19.95 | wps 2311.7 | wpb 4003.4 | bsz 141.8 | num_updates 42727 | best_bleu 20.41
2023-08-05 08:11:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42727 updates
2023-08-05 08:11:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_last.pt
2023-08-05 08:12:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_last.pt
2023-08-05 08:12:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_last.pt (epoch 29 @ 42727 updates, score 19.95) (writing took 14.246311331167817 seconds)
2023-08-05 08:12:12 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-05 08:12:12 | INFO | train | epoch 029 | loss 2.037 | trans_loss 4.967 | nll_loss 2.154 | w2v_ctc_loss 0.636 | task_loss 0 | contrastive_loss 0.091 | total 4138.09 | n_correct 2740.61 | ppl 4.45 | accuracy 66.229 | wps 13085.2 | ups 1.58 | wpb 8276.2 | bsz 305.5 | num_updates 42727 | lr 6.8417e-05 | gnorm 0.56 | clip 0 | loss_scale 16 | train_wall 820 | gb_free 16.3 | wall 29545
2023-08-05 08:12:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 08:12:12 | INFO | fairseq.trainer | begin training epoch 30
2023-08-05 08:12:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 08:13:01 | INFO | train_inner | epoch 030:     73 / 1474 loss=2.035, trans_loss=4.95, nll_loss=2.133, w2v_ctc_loss=0.622, task_loss=0, contrastive_loss=0.153, total=4175.11, n_correct=2774.74, ppl=4.38, accuracy=66.459, wps=8357.3, ups=1, wpb=8350.2, bsz=318.6, num_updates=42800, lr=6.83586e-05, gnorm=0.561, clip=0, loss_scale=16, train_wall=55, gb_free=17.3, wall=29594
2023-08-05 08:13:57 | INFO | train_inner | epoch 030:    173 / 1474 loss=2.021, trans_loss=4.933, nll_loss=2.11, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.081, total=4202.64, n_correct=2811.97, ppl=4.32, accuracy=66.91, wps=14997, ups=1.78, wpb=8405.3, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=56, gb_free=16.9, wall=29650
2023-08-05 08:14:53 | INFO | train_inner | epoch 030:    273 / 1474 loss=2.022, trans_loss=4.948, nll_loss=2.129, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.037, total=4120.21, n_correct=2742.9, ppl=4.37, accuracy=66.572, wps=14513, ups=1.76, wpb=8240.4, bsz=294.9, num_updates=43000, lr=6.81994e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=56, gb_free=15.6, wall=29706
2023-08-05 08:15:49 | INFO | train_inner | epoch 030:    373 / 1474 loss=2.015, trans_loss=4.943, nll_loss=2.123, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.041, total=4178.23, n_correct=2791.31, ppl=4.35, accuracy=66.806, wps=15009.1, ups=1.8, wpb=8356.5, bsz=307.5, num_updates=43100, lr=6.81203e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=55, gb_free=10.7, wall=29762
2023-08-05 08:16:45 | INFO | train_inner | epoch 030:    473 / 1474 loss=2.028, trans_loss=4.95, nll_loss=2.133, w2v_ctc_loss=0.622, task_loss=0, contrastive_loss=0.102, total=4124.47, n_correct=2742.38, ppl=4.39, accuracy=66.49, wps=14877.9, ups=1.8, wpb=8248.9, bsz=312.6, num_updates=43200, lr=6.80414e-05, gnorm=0.556, clip=0, loss_scale=16, train_wall=55, gb_free=17.8, wall=29818
2023-08-05 08:17:41 | INFO | train_inner | epoch 030:    573 / 1474 loss=2.03, trans_loss=4.96, nll_loss=2.146, w2v_ctc_loss=0.633, task_loss=0, contrastive_loss=0.065, total=4168.41, n_correct=2769.4, ppl=4.43, accuracy=66.438, wps=14905.6, ups=1.79, wpb=8336.8, bsz=312.4, num_updates=43300, lr=6.79628e-05, gnorm=0.561, clip=0, loss_scale=16, train_wall=55, gb_free=17.5, wall=29873
2023-08-05 08:18:37 | INFO | train_inner | epoch 030:    673 / 1474 loss=2.034, trans_loss=4.959, nll_loss=2.145, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.076, total=4187.95, n_correct=2779.8, ppl=4.42, accuracy=66.376, wps=14748.3, ups=1.76, wpb=8375.9, bsz=315, num_updates=43400, lr=6.78844e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=56, gb_free=16.2, wall=29930
2023-08-05 08:19:33 | INFO | train_inner | epoch 030:    773 / 1474 loss=2.052, trans_loss=4.971, nll_loss=2.16, w2v_ctc_loss=0.645, task_loss=0, contrastive_loss=0.156, total=4105.32, n_correct=2710.18, ppl=4.47, accuracy=66.016, wps=14685, ups=1.79, wpb=8210.6, bsz=302.6, num_updates=43500, lr=6.78064e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=55, gb_free=13.5, wall=29986
2023-08-05 08:20:29 | INFO | train_inner | epoch 030:    873 / 1474 loss=2.031, trans_loss=4.967, nll_loss=2.154, w2v_ctc_loss=0.636, task_loss=0, contrastive_loss=0.051, total=4102.11, n_correct=2717.65, ppl=4.45, accuracy=66.25, wps=14757.5, ups=1.8, wpb=8204.2, bsz=295.6, num_updates=43600, lr=6.77285e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=55, gb_free=17.7, wall=30042
2023-08-05 08:21:25 | INFO | train_inner | epoch 030:    973 / 1474 loss=2.036, trans_loss=4.973, nll_loss=2.162, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.052, total=4129.98, n_correct=2726.03, ppl=4.48, accuracy=66.006, wps=14782, ups=1.79, wpb=8260, bsz=300.4, num_updates=43700, lr=6.7651e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=55, gb_free=16.6, wall=30098
2023-08-05 08:22:21 | INFO | train_inner | epoch 030:   1073 / 1474 loss=2.045, trans_loss=4.978, nll_loss=2.167, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.131, total=4101.17, n_correct=2704.39, ppl=4.49, accuracy=65.942, wps=14472.6, ups=1.76, wpb=8202.3, bsz=282.3, num_updates=43800, lr=6.75737e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=56, gb_free=15.9, wall=30154
2023-08-05 08:23:17 | INFO | train_inner | epoch 030:   1173 / 1474 loss=2.031, trans_loss=4.963, nll_loss=2.151, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.109, total=4168.36, n_correct=2767.84, ppl=4.44, accuracy=66.401, wps=14928.8, ups=1.79, wpb=8336.7, bsz=314, num_updates=43900, lr=6.74967e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=55, gb_free=16.3, wall=30210
2023-08-05 08:23:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-05 08:24:14 | INFO | train_inner | epoch 030:   1274 / 1474 loss=2.036, trans_loss=4.975, nll_loss=2.164, w2v_ctc_loss=0.643, task_loss=0, contrastive_loss=0.045, total=4038.8, n_correct=2666.37, ppl=4.48, accuracy=66.019, wps=14297.8, ups=1.77, wpb=8077.6, bsz=284.7, num_updates=44000, lr=6.742e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=56, gb_free=15.3, wall=30267
2023-08-05 08:24:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 08:24:35 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.36 | trans_loss 5.547 | nll_loss 2.816 | w2v_ctc_loss 1.381 | task_loss 0 | contrastive_loss 0.239 | total 4003.4 | n_correct 2498.3 | ppl 7.04 | accuracy 62.404 | uer 16.93 | wer 18.676 | raw_wer 18.676 | bleu 19.94 | wps 2417.3 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.41
2023-08-05 08:24:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-08-05 08:24:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_30_44000.pt
2023-08-05 08:24:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_30_44000.pt
2023-08-05 08:24:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 19.94) (writing took 13.929623525589705 seconds)
2023-08-05 08:25:46 | INFO | train_inner | epoch 030:   1374 / 1474 loss=2.028, trans_loss=4.965, nll_loss=2.154, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.055, total=4167.64, n_correct=2766.53, ppl=4.45, accuracy=66.381, wps=9056.4, ups=1.09, wpb=8335.3, bsz=321.9, num_updates=44100, lr=6.73435e-05, gnorm=0.557, clip=0, loss_scale=16, train_wall=56, gb_free=16.9, wall=30359
2023-08-05 08:26:42 | INFO | train_inner | epoch 030:   1474 / 1474 loss=2.045, trans_loss=4.969, nll_loss=2.159, w2v_ctc_loss=0.621, task_loss=0, contrastive_loss=0.201, total=4117.91, n_correct=2728.04, ppl=4.47, accuracy=66.248, wps=14674, ups=1.78, wpb=8235.8, bsz=312.2, num_updates=44200, lr=6.72673e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=56, gb_free=17.4, wall=30415
2023-08-05 08:26:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 08:27:05 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.359 | trans_loss 5.55 | nll_loss 2.817 | w2v_ctc_loss 1.37 | task_loss 0 | contrastive_loss 0.239 | total 4003.4 | n_correct 2498.4 | ppl 7.05 | accuracy 62.407 | uer 16.986 | wer 18.732 | raw_wer 18.732 | bleu 20.3 | wps 2220.1 | wpb 4003.4 | bsz 141.8 | num_updates 44200 | best_bleu 20.41
2023-08-05 08:27:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44200 updates
2023-08-05 08:27:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_20.3009.pt
2023-08-05 08:27:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_20.3009.pt
2023-08-05 08:27:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_20.3009.pt (epoch 30 @ 44200 updates, score 20.3) (writing took 19.82213450782001 seconds)
2023-08-05 08:27:25 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-05 08:27:25 | INFO | train | epoch 030 | loss 2.033 | trans_loss 4.96 | nll_loss 2.146 | w2v_ctc_loss 0.632 | task_loss 0 | contrastive_loss 0.091 | total 4138.89 | n_correct 2746.45 | ppl 4.42 | accuracy 66.357 | wps 13357.8 | ups 1.61 | wpb 8277.8 | bsz 305.7 | num_updates 44200 | lr 6.72673e-05 | gnorm 0.561 | clip 0 | loss_scale 16 | train_wall 819 | gb_free 17.4 | wall 30458
2023-08-05 08:27:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 08:27:25 | INFO | fairseq.trainer | begin training epoch 31
2023-08-05 08:27:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 08:28:28 | INFO | train_inner | epoch 031:    100 / 1474 loss=2.016, trans_loss=4.941, nll_loss=2.118, w2v_ctc_loss=0.63, task_loss=0, contrastive_loss=0.047, total=4085.38, n_correct=2728.49, ppl=4.34, accuracy=66.787, wps=7687.1, ups=0.94, wpb=8170.8, bsz=293.4, num_updates=44300, lr=6.71913e-05, gnorm=0.559, clip=0, loss_scale=16, train_wall=55, gb_free=15.3, wall=30521
2023-08-05 08:29:24 | INFO | train_inner | epoch 031:    200 / 1474 loss=2.018, trans_loss=4.943, nll_loss=2.121, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.058, total=4139.51, n_correct=2763.3, ppl=4.35, accuracy=66.754, wps=14828.8, ups=1.79, wpb=8279, bsz=299.4, num_updates=44400, lr=6.71156e-05, gnorm=0.576, clip=0, loss_scale=16, train_wall=55, gb_free=12.5, wall=30577
2023-08-05 08:30:21 | INFO | train_inner | epoch 031:    300 / 1474 loss=2.025, trans_loss=4.943, nll_loss=2.123, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.104, total=4148.01, n_correct=2769.75, ppl=4.36, accuracy=66.773, wps=14632.4, ups=1.76, wpb=8296, bsz=301.1, num_updates=44500, lr=6.70402e-05, gnorm=0.559, clip=0, loss_scale=16, train_wall=56, gb_free=13.8, wall=30634
2023-08-05 08:31:17 | INFO | train_inner | epoch 031:    400 / 1474 loss=2.02, trans_loss=4.955, nll_loss=2.138, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.043, total=4095.42, n_correct=2723.38, ppl=4.4, accuracy=66.498, wps=14668.9, ups=1.79, wpb=8190.8, bsz=286.3, num_updates=44600, lr=6.6965e-05, gnorm=0.562, clip=0, loss_scale=16, train_wall=55, gb_free=13.9, wall=30690
2023-08-05 08:32:13 | INFO | train_inner | epoch 031:    500 / 1474 loss=2.021, trans_loss=4.948, nll_loss=2.129, w2v_ctc_loss=0.633, task_loss=0, contrastive_loss=0.05, total=4115.61, n_correct=2739.38, ppl=4.37, accuracy=66.561, wps=14718.1, ups=1.79, wpb=8231.2, bsz=300.6, num_updates=44700, lr=6.689e-05, gnorm=0.568, clip=0, loss_scale=16, train_wall=55, gb_free=16.6, wall=30745
2023-08-05 08:33:08 | INFO | train_inner | epoch 031:    600 / 1474 loss=2.019, trans_loss=4.952, nll_loss=2.134, w2v_ctc_loss=0.626, task_loss=0, contrastive_loss=0.041, total=4075.9, n_correct=2712.96, ppl=4.39, accuracy=66.561, wps=14598.8, ups=1.79, wpb=8151.8, bsz=293.3, num_updates=44800, lr=6.68153e-05, gnorm=0.558, clip=0, loss_scale=16, train_wall=55, gb_free=12.5, wall=30801
2023-08-05 08:34:05 | INFO | train_inner | epoch 031:    700 / 1474 loss=2.016, trans_loss=4.947, nll_loss=2.129, w2v_ctc_loss=0.621, task_loss=0, contrastive_loss=0.043, total=4208.99, n_correct=2807.81, ppl=4.37, accuracy=66.71, wps=14926.7, ups=1.77, wpb=8418, bsz=315.1, num_updates=44900, lr=6.67409e-05, gnorm=0.557, clip=0, loss_scale=16, train_wall=56, gb_free=18.1, wall=30858
2023-08-05 08:35:01 | INFO | train_inner | epoch 031:    800 / 1474 loss=2.035, trans_loss=4.962, nll_loss=2.147, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.11, total=4104.19, n_correct=2720.32, ppl=4.43, accuracy=66.282, wps=14574.3, ups=1.78, wpb=8208.4, bsz=297.4, num_updates=45000, lr=6.66667e-05, gnorm=0.568, clip=0, loss_scale=16, train_wall=56, gb_free=15.6, wall=30914
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:0')
2023-08-05 08:35:56 | INFO | train_inner | epoch 031:    900 / 1474 loss=2.023, trans_loss=4.952, nll_loss=2.135, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.057, total=4099.13, n_correct=2724.61, ppl=4.39, accuracy=66.468, wps=14814.5, ups=1.81, wpb=8198.3, bsz=294.3, num_updates=45100, lr=6.65927e-05, gnorm=0.569, clip=0, loss_scale=16, train_wall=55, gb_free=15.5, wall=30969
2023-08-05 08:36:53 | INFO | train_inner | epoch 031:   1000 / 1474 loss=2.036, trans_loss=4.962, nll_loss=2.149, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.138, total=4186.81, n_correct=2780.76, ppl=4.44, accuracy=66.417, wps=14917, ups=1.78, wpb=8373.6, bsz=320.9, num_updates=45200, lr=6.6519e-05, gnorm=0.559, clip=0, loss_scale=16, train_wall=56, gb_free=13.8, wall=31026
2023-08-05 08:37:49 | INFO | train_inner | epoch 031:   1100 / 1474 loss=2.029, trans_loss=4.957, nll_loss=2.143, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.085, total=4149.25, n_correct=2756.86, ppl=4.42, accuracy=66.442, wps=14713.5, ups=1.77, wpb=8298.5, bsz=315.2, num_updates=45300, lr=6.64455e-05, gnorm=0.577, clip=0, loss_scale=16, train_wall=56, gb_free=16.2, wall=31082
2023-08-05 08:38:45 | INFO | train_inner | epoch 031:   1200 / 1474 loss=2.041, trans_loss=4.959, nll_loss=2.146, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.202, total=4187.45, n_correct=2784.09, ppl=4.42, accuracy=66.487, wps=14931.4, ups=1.78, wpb=8374.9, bsz=320.3, num_updates=45400, lr=6.63723e-05, gnorm=0.559, clip=0, loss_scale=16, train_wall=56, gb_free=17.3, wall=31138
2023-08-05 08:39:41 | INFO | train_inner | epoch 031:   1300 / 1474 loss=2.026, trans_loss=4.964, nll_loss=2.152, w2v_ctc_loss=0.63, task_loss=0, contrastive_loss=0.048, total=4227.39, n_correct=2808.18, ppl=4.44, accuracy=66.428, wps=15148.6, ups=1.79, wpb=8454.8, bsz=326.7, num_updates=45500, lr=6.62994e-05, gnorm=0.558, clip=0, loss_scale=16, train_wall=55, gb_free=17.2, wall=31194
2023-08-05 08:40:37 | INFO | train_inner | epoch 031:   1400 / 1474 loss=2.059, trans_loss=4.962, nll_loss=2.15, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.255, total=4191.1, n_correct=2774.59, ppl=4.44, accuracy=66.202, wps=14991.4, ups=1.79, wpb=8382.2, bsz=327, num_updates=45600, lr=6.62266e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=55, gb_free=16.8, wall=31250
2023-08-05 08:41:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2314, device='cuda:7')
2023-08-05 08:41:42 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.362 | trans_loss 5.543 | nll_loss 2.81 | w2v_ctc_loss 1.4 | task_loss 0 | contrastive_loss 0.236 | total 4003.4 | n_correct 2504.5 | ppl 7.01 | accuracy 62.559 | uer 16.654 | wer 18.426 | raw_wer 18.426 | bleu 20.22 | wps 2088.5 | wpb 4003.4 | bsz 141.8 | num_updates 45674 | best_bleu 20.41
2023-08-05 08:41:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45674 updates
2023-08-05 08:41:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_20.2208.pt
2023-08-05 08:41:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_20.2208.pt
2023-08-05 08:41:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_20.2208.pt (epoch 31 @ 45674 updates, score 20.22) (writing took 17.089137388393283 seconds)
2023-08-05 08:41:59 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-05 08:41:59 | INFO | train | epoch 031 | loss 2.028 | trans_loss 4.954 | nll_loss 2.138 | w2v_ctc_loss 0.627 | task_loss 0 | contrastive_loss 0.091 | total 4138.65 | n_correct 2752.92 | ppl 4.4 | accuracy 66.517 | wps 13950.4 | ups 1.69 | wpb 8277.3 | bsz 305.7 | num_updates 45674 | lr 6.61729e-05 | gnorm 0.564 | clip 0 | loss_scale 16 | train_wall 819 | gb_free 12.6 | wall 31332
2023-08-05 08:42:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 08:42:00 | INFO | fairseq.trainer | begin training epoch 32
2023-08-05 08:42:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 08:42:23 | INFO | train_inner | epoch 032:     26 / 1474 loss=2.023, trans_loss=4.957, nll_loss=2.141, w2v_ctc_loss=0.633, task_loss=0, contrastive_loss=0.039, total=4040.88, n_correct=2687.52, ppl=4.41, accuracy=66.508, wps=7627.1, ups=0.94, wpb=8081.8, bsz=288.7, num_updates=45700, lr=6.61541e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=56, gb_free=15.9, wall=31356
2023-08-05 08:43:18 | INFO | train_inner | epoch 032:    126 / 1474 loss=1.999, trans_loss=4.918, nll_loss=2.091, w2v_ctc_loss=0.607, task_loss=0, contrastive_loss=0.047, total=4222.14, n_correct=2844.64, ppl=4.26, accuracy=67.374, wps=15163.5, ups=1.8, wpb=8444.3, bsz=322.6, num_updates=45800, lr=6.60819e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=55, gb_free=15.8, wall=31411
2023-08-05 08:44:15 | INFO | train_inner | epoch 032:    226 / 1474 loss=2.016, trans_loss=4.938, nll_loss=2.117, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.056, total=4159.77, n_correct=2782.55, ppl=4.34, accuracy=66.892, wps=14777.2, ups=1.78, wpb=8319.5, bsz=320.8, num_updates=45900, lr=6.60098e-05, gnorm=0.566, clip=0, loss_scale=16, train_wall=56, gb_free=16.5, wall=31468
2023-08-05 08:45:10 | INFO | train_inner | epoch 032:    326 / 1474 loss=2.005, trans_loss=4.927, nll_loss=2.103, w2v_ctc_loss=0.611, task_loss=0, contrastive_loss=0.05, total=4179.65, n_correct=2806.36, ppl=4.3, accuracy=67.143, wps=15001.9, ups=1.79, wpb=8359.3, bsz=313.8, num_updates=46000, lr=6.5938e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=55, gb_free=16.6, wall=31523
2023-08-05 08:45:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 08:45:32 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.37 | trans_loss 5.556 | nll_loss 2.827 | w2v_ctc_loss 1.393 | task_loss 0 | contrastive_loss 0.238 | total 4003.4 | n_correct 2497.3 | ppl 7.1 | accuracy 62.379 | uer 16.861 | wer 18.739 | raw_wer 18.739 | bleu 19.93 | wps 2386.3 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.41
2023-08-05 08:45:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-08-05 08:45:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_32_46000.pt
2023-08-05 08:45:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_32_46000.pt
2023-08-05 08:45:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 19.93) (writing took 17.784605484455824 seconds)
2023-08-05 08:46:48 | INFO | train_inner | epoch 032:    426 / 1474 loss=2.012, trans_loss=4.935, nll_loss=2.113, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.049, total=4172.34, n_correct=2793.41, ppl=4.33, accuracy=66.951, wps=8587.8, ups=1.03, wpb=8344.7, bsz=309.9, num_updates=46100, lr=6.58665e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=57, gb_free=17.4, wall=31621
2023-08-05 08:47:44 | INFO | train_inner | epoch 032:    526 / 1474 loss=2.03, trans_loss=4.947, nll_loss=2.129, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.126, total=4191.15, n_correct=2799.36, ppl=4.37, accuracy=66.792, wps=14938.4, ups=1.78, wpb=8382.3, bsz=315.1, num_updates=46200, lr=6.57952e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=55, gb_free=15.4, wall=31677
2023-08-05 08:48:40 | INFO | train_inner | epoch 032:    626 / 1474 loss=2.019, trans_loss=4.95, nll_loss=2.133, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.054, total=4138.05, n_correct=2757.87, ppl=4.38, accuracy=66.647, wps=14678.8, ups=1.77, wpb=8276.1, bsz=299.5, num_updates=46300, lr=6.57241e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=56, gb_free=13.8, wall=31733
2023-08-05 08:49:36 | INFO | train_inner | epoch 032:    726 / 1474 loss=2.018, trans_loss=4.949, nll_loss=2.131, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.04, total=4156.23, n_correct=2772.77, ppl=4.38, accuracy=66.714, wps=14800.8, ups=1.78, wpb=8312.5, bsz=303, num_updates=46400, lr=6.56532e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=31789
2023-08-05 08:50:33 | INFO | train_inner | epoch 032:    826 / 1474 loss=2.014, trans_loss=4.95, nll_loss=2.132, w2v_ctc_loss=0.621, task_loss=0, contrastive_loss=0.038, total=4112.3, n_correct=2741.04, ppl=4.38, accuracy=66.655, wps=14411.2, ups=1.75, wpb=8224.6, bsz=293.9, num_updates=46500, lr=6.55826e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=56, gb_free=16.2, wall=31846
2023-08-05 08:51:29 | INFO | train_inner | epoch 032:    926 / 1474 loss=2.013, trans_loss=4.95, nll_loss=2.133, w2v_ctc_loss=0.616, task_loss=0, contrastive_loss=0.037, total=4139.37, n_correct=2757.08, ppl=4.39, accuracy=66.606, wps=14861.8, ups=1.8, wpb=8278.7, bsz=298.6, num_updates=46600, lr=6.55122e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=55, gb_free=13.3, wall=31902
2023-08-05 08:52:25 | INFO | train_inner | epoch 032:   1026 / 1474 loss=2.031, trans_loss=4.958, nll_loss=2.143, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.129, total=4121.85, n_correct=2740.98, ppl=4.42, accuracy=66.499, wps=14874.3, ups=1.8, wpb=8243.7, bsz=306.1, num_updates=46700, lr=6.5442e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=55, gb_free=17.1, wall=31957
2023-08-05 08:53:21 | INFO | train_inner | epoch 032:   1126 / 1474 loss=2.026, trans_loss=4.962, nll_loss=2.147, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.073, total=4015.59, n_correct=2661.93, ppl=4.43, accuracy=66.29, wps=14311.1, ups=1.78, wpb=8031.2, bsz=270.1, num_updates=46800, lr=6.5372e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=55, gb_free=17.5, wall=32014
2023-08-05 08:54:17 | INFO | train_inner | epoch 032:   1226 / 1474 loss=2.046, trans_loss=4.966, nll_loss=2.154, w2v_ctc_loss=0.626, task_loss=0, contrastive_loss=0.176, total=4153.44, n_correct=2753.72, ppl=4.45, accuracy=66.3, wps=14642.4, ups=1.76, wpb=8306.9, bsz=310.8, num_updates=46900, lr=6.53023e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=56, gb_free=16.6, wall=32070
2023-08-05 08:55:13 | INFO | train_inner | epoch 032:   1326 / 1474 loss=2.022, trans_loss=4.959, nll_loss=2.145, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.037, total=4075.86, n_correct=2708.37, ppl=4.42, accuracy=66.449, wps=14756.1, ups=1.81, wpb=8151.7, bsz=295.4, num_updates=47000, lr=6.52328e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=55, gb_free=17.1, wall=32126
2023-08-05 08:56:09 | INFO | train_inner | epoch 032:   1426 / 1474 loss=2.058, trans_loss=4.964, nll_loss=2.151, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.27, total=4116.4, n_correct=2726.07, ppl=4.44, accuracy=66.225, wps=14732.3, ups=1.79, wpb=8232.8, bsz=307.6, num_updates=47100, lr=6.51635e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=55, gb_free=17, wall=32181
2023-08-05 08:56:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 08:56:57 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.361 | trans_loss 5.545 | nll_loss 2.818 | w2v_ctc_loss 1.391 | task_loss 0 | contrastive_loss 0.238 | total 4003.4 | n_correct 2485.7 | ppl 7.05 | accuracy 62.09 | uer 16.935 | wer 18.676 | raw_wer 18.676 | bleu 20.12 | wps 2330.1 | wpb 4003.4 | bsz 141.8 | num_updates 47148 | best_bleu 20.41
2023-08-05 08:56:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47148 updates
2023-08-05 08:56:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_20.1208.pt
2023-08-05 08:57:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_20.1208.pt
2023-08-05 08:57:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint.best_bleu_20.1208.pt (epoch 32 @ 47148 updates, score 20.12) (writing took 17.173823481425643 seconds)
2023-08-05 08:57:15 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-05 08:57:15 | INFO | train | epoch 032 | loss 2.023 | trans_loss 4.948 | nll_loss 2.13 | w2v_ctc_loss 0.622 | task_loss 0 | contrastive_loss 0.089 | total 4138.65 | n_correct 2759.87 | ppl 4.38 | accuracy 66.685 | wps 13331.1 | ups 1.61 | wpb 8277.3 | bsz 305.7 | num_updates 47148 | lr 6.51303e-05 | gnorm 0.562 | clip 0 | loss_scale 32 | train_wall 819 | gb_free 16.7 | wall 32248
2023-08-05 08:57:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 08:57:15 | INFO | fairseq.trainer | begin training epoch 33
2023-08-05 08:57:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 08:57:51 | INFO | train_inner | epoch 033:     52 / 1474 loss=2.027, trans_loss=4.942, nll_loss=2.124, w2v_ctc_loss=0.614, task_loss=0, contrastive_loss=0.139, total=4149.21, n_correct=2772.2, ppl=4.36, accuracy=66.813, wps=8083.3, ups=0.97, wpb=8298.4, bsz=320.5, num_updates=47200, lr=6.50945e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=55, gb_free=17.3, wall=32284
2023-08-05 08:58:48 | INFO | train_inner | epoch 033:    152 / 1474 loss=1.996, trans_loss=4.924, nll_loss=2.096, w2v_ctc_loss=0.601, task_loss=0, contrastive_loss=0.03, total=4073.9, n_correct=2737.1, ppl=4.28, accuracy=67.186, wps=14458.3, ups=1.77, wpb=8147.8, bsz=284.8, num_updates=47300, lr=6.50256e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=56, gb_free=15.6, wall=32341
2023-08-05 08:59:44 | INFO | train_inner | epoch 033:    252 / 1474 loss=2.03, trans_loss=4.923, nll_loss=2.1, w2v_ctc_loss=0.611, task_loss=0, contrastive_loss=0.194, total=4280.14, n_correct=2874.28, ppl=4.29, accuracy=67.154, wps=15295.9, ups=1.79, wpb=8560.3, bsz=346.5, num_updates=47400, lr=6.4957e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=55, gb_free=16.8, wall=32396
2023-08-05 09:00:39 | INFO | train_inner | epoch 033:    352 / 1474 loss=2.014, trans_loss=4.939, nll_loss=2.118, w2v_ctc_loss=0.622, task_loss=0, contrastive_loss=0.054, total=4120.27, n_correct=2752.57, ppl=4.34, accuracy=66.806, wps=14769.8, ups=1.79, wpb=8240.5, bsz=300.7, num_updates=47500, lr=6.48886e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=55, gb_free=17.6, wall=32452
2023-08-05 09:01:35 | INFO | train_inner | epoch 033:    452 / 1474 loss=1.997, trans_loss=4.923, nll_loss=2.096, w2v_ctc_loss=0.605, task_loss=0, contrastive_loss=0.038, total=4141.22, n_correct=2783.74, ppl=4.28, accuracy=67.22, wps=14863.1, ups=1.79, wpb=8282.4, bsz=310.8, num_updates=47600, lr=6.48204e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=55, gb_free=16.7, wall=32508
2023-08-05 09:02:32 | INFO | train_inner | epoch 033:    552 / 1474 loss=2.018, trans_loss=4.945, nll_loss=2.125, w2v_ctc_loss=0.623, task_loss=0, contrastive_loss=0.057, total=4133.59, n_correct=2753.1, ppl=4.36, accuracy=66.603, wps=14622, ups=1.77, wpb=8267.2, bsz=294, num_updates=47700, lr=6.47524e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=56, gb_free=15.6, wall=32565
2023-08-05 09:03:28 | INFO | train_inner | epoch 033:    652 / 1474 loss=2.021, trans_loss=4.952, nll_loss=2.135, w2v_ctc_loss=0.617, task_loss=0, contrastive_loss=0.09, total=4157.63, n_correct=2770.96, ppl=4.39, accuracy=66.648, wps=14817.8, ups=1.78, wpb=8315.3, bsz=301.6, num_updates=47800, lr=6.46846e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=56, gb_free=18, wall=32621
2023-08-05 09:04:24 | INFO | train_inner | epoch 033:    752 / 1474 loss=2.02, trans_loss=4.95, nll_loss=2.131, w2v_ctc_loss=0.635, task_loss=0, contrastive_loss=0.039, total=4070.75, n_correct=2710.69, ppl=4.38, accuracy=66.589, wps=14554.2, ups=1.79, wpb=8141.5, bsz=287.2, num_updates=47900, lr=6.46171e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=55, gb_free=16.7, wall=32677
2023-08-05 09:05:20 | INFO | train_inner | epoch 033:    852 / 1474 loss=2.012, trans_loss=4.937, nll_loss=2.116, w2v_ctc_loss=0.603, task_loss=0, contrastive_loss=0.106, total=4130.24, n_correct=2770.13, ppl=4.34, accuracy=67.069, wps=14692.3, ups=1.78, wpb=8260.5, bsz=316.3, num_updates=48000, lr=6.45497e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=32733
2023-08-05 09:05:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 09:05:43 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.369 | trans_loss 5.548 | nll_loss 2.817 | w2v_ctc_loss 1.408 | task_loss 0 | contrastive_loss 0.237 | total 4003.4 | n_correct 2501.7 | ppl 7.05 | accuracy 62.489 | uer 16.723 | wer 18.463 | raw_wer 18.463 | bleu 20.12 | wps 2165.7 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.41
2023-08-05 09:05:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-08-05 09:05:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_33_48000.pt
2023-08-05 09:05:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_33_48000.pt
2023-08-05 09:06:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 20.12) (writing took 20.71486477740109 seconds)
2023-08-05 09:07:01 | INFO | train_inner | epoch 033:    952 / 1474 loss=2.019, trans_loss=4.948, nll_loss=2.131, w2v_ctc_loss=0.628, task_loss=0, contrastive_loss=0.048, total=4151.18, n_correct=2771.12, ppl=4.38, accuracy=66.755, wps=8180.8, ups=0.99, wpb=8302.4, bsz=308.3, num_updates=48100, lr=6.44826e-05, gnorm=0.56, clip=0, loss_scale=64, train_wall=56, gb_free=11.9, wall=32834
2023-08-05 09:07:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-05 09:07:58 | INFO | train_inner | epoch 033:   1053 / 1474 loss=2.012, trans_loss=4.943, nll_loss=2.124, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.04, total=4120.84, n_correct=2752.36, ppl=4.36, accuracy=66.791, wps=14526.5, ups=1.76, wpb=8241.7, bsz=300, num_updates=48200, lr=6.44157e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=56, gb_free=16.1, wall=32891
2023-08-05 09:08:54 | INFO | train_inner | epoch 033:   1153 / 1474 loss=2.027, trans_loss=4.952, nll_loss=2.136, w2v_ctc_loss=0.612, task_loss=0, contrastive_loss=0.138, total=4181.58, n_correct=2787.49, ppl=4.39, accuracy=66.661, wps=14881.7, ups=1.78, wpb=8363.2, bsz=310, num_updates=48300, lr=6.43489e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=56, gb_free=15.5, wall=32947
2023-08-05 09:09:51 | INFO | train_inner | epoch 033:   1253 / 1474 loss=2.014, trans_loss=4.946, nll_loss=2.127, w2v_ctc_loss=0.622, task_loss=0, contrastive_loss=0.043, total=4115.76, n_correct=2750.07, ppl=4.37, accuracy=66.818, wps=14563.5, ups=1.77, wpb=8231.5, bsz=294.7, num_updates=48400, lr=6.42824e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=56, gb_free=17.1, wall=33004
2023-08-05 09:10:47 | INFO | train_inner | epoch 033:   1353 / 1474 loss=2.016, trans_loss=4.947, nll_loss=2.131, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.059, total=4120.69, n_correct=2752.68, ppl=4.38, accuracy=66.801, wps=14639.8, ups=1.78, wpb=8241.4, bsz=311.9, num_updates=48500, lr=6.42161e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=56, gb_free=17.1, wall=33060
2023-08-05 09:11:43 | INFO | train_inner | epoch 033:   1453 / 1474 loss=2.034, trans_loss=4.949, nll_loss=2.134, w2v_ctc_loss=0.616, task_loss=0, contrastive_loss=0.206, total=4125.28, n_correct=2748.5, ppl=4.39, accuracy=66.626, wps=14757.3, ups=1.79, wpb=8250.6, bsz=308.7, num_updates=48600, lr=6.415e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=55, gb_free=17.2, wall=33116
2023-08-05 09:11:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 09:12:18 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.364 | trans_loss 5.549 | nll_loss 2.815 | w2v_ctc_loss 1.393 | task_loss 0 | contrastive_loss 0.235 | total 4003.4 | n_correct 2498 | ppl 7.04 | accuracy 62.397 | uer 16.489 | wer 18.277 | raw_wer 18.277 | bleu 19.9 | wps 2139 | wpb 4003.4 | bsz 141.8 | num_updates 48621 | best_bleu 20.41
2023-08-05 09:12:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48621 updates
2023-08-05 09:12:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_last.pt
2023-08-05 09:12:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_last.pt
2023-08-05 09:12:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_last.pt (epoch 33 @ 48621 updates, score 19.9) (writing took 12.756425248458982 seconds)
2023-08-05 09:12:31 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-05 09:12:31 | INFO | train | epoch 033 | loss 2.016 | trans_loss 4.941 | nll_loss 2.121 | w2v_ctc_loss 0.617 | task_loss 0 | contrastive_loss 0.081 | total 4137.28 | n_correct 2765.64 | ppl 4.35 | accuracy 66.847 | wps 13303.9 | ups 1.61 | wpb 8274.6 | bsz 305.2 | num_updates 48621 | lr 6.41362e-05 | gnorm 0.562 | clip 0 | loss_scale 32 | train_wall 819 | gb_free 18.1 | wall 33164
2023-08-05 09:12:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 09:12:31 | INFO | fairseq.trainer | begin training epoch 34
2023-08-05 09:12:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 09:13:23 | INFO | train_inner | epoch 034:     79 / 1474 loss=2, trans_loss=4.921, nll_loss=2.094, w2v_ctc_loss=0.612, task_loss=0, contrastive_loss=0.043, total=4131.47, n_correct=2778.51, ppl=4.27, accuracy=67.252, wps=8237.8, ups=1, wpb=8262.9, bsz=301.7, num_updates=48700, lr=6.40841e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=55, gb_free=16.9, wall=33216
2023-08-05 09:14:19 | INFO | train_inner | epoch 034:    179 / 1474 loss=1.998, trans_loss=4.917, nll_loss=2.088, w2v_ctc_loss=0.609, task_loss=0, contrastive_loss=0.043, total=4065.88, n_correct=2736.85, ppl=4.25, accuracy=67.313, wps=14596.6, ups=1.8, wpb=8131.8, bsz=295.1, num_updates=48800, lr=6.40184e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=55, gb_free=16.3, wall=33272
2023-08-05 09:15:16 | INFO | train_inner | epoch 034:    279 / 1474 loss=2.038, trans_loss=4.935, nll_loss=2.114, w2v_ctc_loss=0.607, task_loss=0, contrastive_loss=0.247, total=4246.3, n_correct=2839.83, ppl=4.33, accuracy=66.878, wps=14986.7, ups=1.76, wpb=8492.6, bsz=328.7, num_updates=48900, lr=6.39529e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=56, gb_free=18, wall=33329
2023-08-05 09:16:12 | INFO | train_inner | epoch 034:    379 / 1474 loss=2.012, trans_loss=4.919, nll_loss=2.093, w2v_ctc_loss=0.606, task_loss=0, contrastive_loss=0.139, total=4156.17, n_correct=2797.51, ppl=4.27, accuracy=67.31, wps=14823.6, ups=1.78, wpb=8312.3, bsz=316.7, num_updates=49000, lr=6.38877e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=56, gb_free=18, wall=33385
2023-08-05 09:17:07 | INFO | train_inner | epoch 034:    479 / 1474 loss=2.01, trans_loss=4.937, nll_loss=2.115, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.038, total=4070.55, n_correct=2722.92, ppl=4.33, accuracy=66.893, wps=14631.3, ups=1.8, wpb=8141.1, bsz=284.6, num_updates=49100, lr=6.38226e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=55, gb_free=17.7, wall=33440
2023-08-05 09:18:03 | INFO | train_inner | epoch 034:    579 / 1474 loss=2, trans_loss=4.923, nll_loss=2.097, w2v_ctc_loss=0.608, task_loss=0, contrastive_loss=0.04, total=4119.38, n_correct=2769.44, ppl=4.28, accuracy=67.23, wps=14707.9, ups=1.79, wpb=8238.8, bsz=300.3, num_updates=49200, lr=6.37577e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=55, gb_free=13.6, wall=33496
2023-08-05 09:19:00 | INFO | train_inner | epoch 034:    679 / 1474 loss=2, trans_loss=4.929, nll_loss=2.106, w2v_ctc_loss=0.608, task_loss=0, contrastive_loss=0.036, total=4124.83, n_correct=2767.19, ppl=4.3, accuracy=67.086, wps=14591.9, ups=1.77, wpb=8249.7, bsz=300.2, num_updates=49300, lr=6.3693e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=56, gb_free=14.7, wall=33553
2023-08-05 09:19:56 | INFO | train_inner | epoch 034:    779 / 1474 loss=2.02, trans_loss=4.95, nll_loss=2.133, w2v_ctc_loss=0.612, task_loss=0, contrastive_loss=0.102, total=4082.07, n_correct=2723.63, ppl=4.39, accuracy=66.722, wps=14581.5, ups=1.79, wpb=8164.1, bsz=295, num_updates=49400, lr=6.36285e-05, gnorm=0.587, clip=0, loss_scale=32, train_wall=56, gb_free=16, wall=33609
2023-08-05 09:20:52 | INFO | train_inner | epoch 034:    879 / 1474 loss=2.015, trans_loss=4.943, nll_loss=2.124, w2v_ctc_loss=0.619, task_loss=0, contrastive_loss=0.06, total=4100.9, n_correct=2743.3, ppl=4.36, accuracy=66.895, wps=14544, ups=1.77, wpb=8201.8, bsz=296.6, num_updates=49500, lr=6.35642e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=56, gb_free=12.7, wall=33665
2023-08-05 09:21:48 | INFO | train_inner | epoch 034:    979 / 1474 loss=2.014, trans_loss=4.941, nll_loss=2.121, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.055, total=4168.39, n_correct=2788.26, ppl=4.35, accuracy=66.891, wps=14909, ups=1.79, wpb=8336.8, bsz=311.9, num_updates=49600, lr=6.35001e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=55, gb_free=16.1, wall=33721
2023-08-05 09:22:44 | INFO | train_inner | epoch 034:   1079 / 1474 loss=2.011, trans_loss=4.943, nll_loss=2.124, w2v_ctc_loss=0.621, task_loss=0, contrastive_loss=0.041, total=4150.57, n_correct=2774.01, ppl=4.36, accuracy=66.834, wps=14865.6, ups=1.79, wpb=8301.1, bsz=308.5, num_updates=49700, lr=6.34361e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=55, gb_free=17.1, wall=33777
2023-08-05 09:23:40 | INFO | train_inner | epoch 034:   1179 / 1474 loss=2.011, trans_loss=4.944, nll_loss=2.125, w2v_ctc_loss=0.615, task_loss=0, contrastive_loss=0.052, total=4098.77, n_correct=2738.56, ppl=4.36, accuracy=66.814, wps=14716, ups=1.8, wpb=8197.5, bsz=297.1, num_updates=49800, lr=6.33724e-05, gnorm=0.63, clip=0, loss_scale=32, train_wall=55, gb_free=17.2, wall=33833
2023-08-05 09:24:36 | INFO | train_inner | epoch 034:   1279 / 1474 loss=2.009, trans_loss=4.942, nll_loss=2.123, w2v_ctc_loss=0.617, task_loss=0, contrastive_loss=0.037, total=4150.54, n_correct=2774.6, ppl=4.36, accuracy=66.849, wps=14864, ups=1.79, wpb=8301.1, bsz=301, num_updates=49900, lr=6.33089e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=55, gb_free=17.5, wall=33889
2023-08-05 09:25:32 | INFO | train_inner | epoch 034:   1379 / 1474 loss=2.026, trans_loss=4.947, nll_loss=2.13, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.099, total=4196.91, n_correct=2798.41, ppl=4.38, accuracy=66.678, wps=14852.6, ups=1.77, wpb=8393.8, bsz=321.4, num_updates=50000, lr=6.32456e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=56, gb_free=16.3, wall=33945
2023-08-05 09:25:32 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-05 09:25:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 09:25:54 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.36 | trans_loss 5.541 | nll_loss 2.807 | w2v_ctc_loss 1.401 | task_loss 0 | contrastive_loss 0.233 | total 4003.4 | n_correct 2505.2 | ppl 7 | accuracy 62.577 | uer 16.755 | wer 18.72 | raw_wer 18.72 | bleu 20.12 | wps 2404.7 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.41
2023-08-05 09:25:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-08-05 09:25:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_34_50000.pt
2023-08-05 09:25:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_34_50000.pt
2023-08-05 09:26:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_two_cl_2.0/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 20.12) (writing took 22.28769677877426 seconds)
2023-08-05 09:26:17 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-05 09:26:17 | INFO | train | epoch 034 | loss 2.012 | trans_loss 4.935 | nll_loss 2.113 | w2v_ctc_loss 0.614 | task_loss 0 | contrastive_loss 0.076 | total 4133.04 | n_correct 2768.07 | ppl 4.33 | accuracy 66.974 | wps 13801 | ups 1.67 | wpb 8266.1 | bsz 304.2 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.572 | clip 0 | loss_scale 32 | train_wall 766 | gb_free 16.3 | wall 33990
2023-08-05 09:26:17 | INFO | fairseq_cli.train | done training in 33938.2 seconds
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    raise EOFError
EOFError
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
