2023-08-26 12:20:10 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:19912
2023-08-26 12:20:10 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:19912
2023-08-26 12:20:10 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:19912
2023-08-26 12:20:10 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:19912
2023-08-26 12:20:10 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:19912
2023-08-26 12:20:10 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:19912
2023-08-26 12:20:10 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-26 12:20:10 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:19912
2023-08-26 12:20:10 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:19912
2023-08-26 12:20:10 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-26 12:20:10 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-26 12:20:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-26 12:20:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-26 12:20:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-26 12:20:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-26 12:20:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-26 12:20:11 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-26 12:20:11 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-26 12:20:11 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-26 12:20:11 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-26 12:20:11 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-26 12:20:11 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-26 12:20:11 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-26 12:20:11 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-26 12:20:11 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-26 12:20:11 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-26 12:20:11 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-26 12:20:11 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-26 12:20:11 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-26 12:20:11 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-26 12:20:11 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-26 12:20:11 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-26 12:20:15 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19912', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-26 12:20:15 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,999
2023-08-26 12:20:15 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,999
2023-08-26 12:20:15 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-26 12:20:15 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-26 12:20:15 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline
2023-08-26 12:20:19 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-26 12:20:19 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-26 12:20:19 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-26 12:20:21 | INFO | root | load pretrained hubert
2023-08-26 12:20:28 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline
2023-08-26 12:20:32 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt
2023-08-26 12:20:38 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt
2023-08-26 12:20:38 | INFO | root | share the sematic adapter and textual encoder
2023-08-26 12:20:38 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9999, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9999, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9999, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9999, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-26 12:20:38 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-26 12:20:38 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-26 12:20:38 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-26 12:20:38 | INFO | fairseq_cli.train | num. shared model params: 147,043,968 (num. trained: 147,043,968)
2023-08-26 12:20:38 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-26 12:20:38 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-26 12:20:38 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-26 12:20:38 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-26 12:20:38 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-26 12:20:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-26 12:20:54 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-26 12:20:54 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-26 12:20:55 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-26 12:20:55 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-26 12:20:55 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-26 12:20:55 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-26 12:20:55 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-26 12:20:55 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-26 12:20:55 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-26 12:20:55 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-26 12:20:55 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-26 12:20:55 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-26 12:20:55 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-26 12:20:55 | INFO | fairseq_cli.train | max tokens per device = 11000 and max sentences per device = None
2023-08-26 12:20:55 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-26 12:20:55 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-26 12:20:55 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-26 12:20:55 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-26 12:20:55 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-26 12:20:55 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-26 12:20:57 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-26 12:20:59 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-26 12:21:59 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-26 12:21:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 12:21:59 | INFO | fairseq.trainer | begin training epoch 1
2023-08-26 12:21:59 | INFO | fairseq_cli.train | Start iterating over samples
True False
None None None
2023-08-26 12:22:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-26 12:22:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-26 12:22:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
True False
None None None
True False
None None None
True False
None None None
True False
None None None
2023-08-26 12:23:18 | INFO | train_inner | epoch 001:    103 / 1191 loss=19.962, trans_loss=6.388, nll_loss=5.161, w2v_ctc_loss=21.402, task_loss=2.983, contrastive_loss=3.61, total=6730.09, n_correct=202.16, ppl=35.77, accuracy=3.004, wps=27868.3, ups=1.43, wpb=19489.4, bsz=681.6, num_updates=100, lr=4.098e-06, gnorm=1.656, clip=0, loss_scale=16, train_wall=71, gb_free=17.9, wall=143
2023-08-26 12:24:25 | INFO | train_inner | epoch 001:    203 / 1191 loss=16.232, trans_loss=6.189, nll_loss=4.982, w2v_ctc_loss=15.889, task_loss=2.851, contrastive_loss=3.626, total=6694.99, n_correct=167.17, ppl=31.61, accuracy=2.497, wps=28748.7, ups=1.48, wpb=19404.5, bsz=683.1, num_updates=200, lr=8.096e-06, gnorm=6.151, clip=4, loss_scale=16, train_wall=67, gb_free=17.6, wall=211
2023-08-26 12:25:34 | INFO | train_inner | epoch 001:    303 / 1191 loss=11.213, trans_loss=6.173, nll_loss=5.04, w2v_ctc_loss=8.133, task_loss=2.39, contrastive_loss=3.656, total=6849.79, n_correct=125.85, ppl=32.89, accuracy=1.837, wps=28797.3, ups=1.45, wpb=19850.1, bsz=713.5, num_updates=300, lr=1.2094e-05, gnorm=1.633, clip=0, loss_scale=16, train_wall=68, gb_free=18, wall=280
2023-08-26 12:26:42 | INFO | train_inner | epoch 001:    403 / 1191 loss=10.735, trans_loss=6.28, nll_loss=5.207, w2v_ctc_loss=7.389, task_loss=2.529, contrastive_loss=3.538, total=6661.33, n_correct=64.66, ppl=36.93, accuracy=0.971, wps=28588.1, ups=1.48, wpb=19315.8, bsz=657.1, num_updates=400, lr=1.6092e-05, gnorm=0.863, clip=0, loss_scale=16, train_wall=67, gb_free=18.1, wall=347
2023-08-26 12:27:49 | INFO | train_inner | epoch 001:    503 / 1191 loss=10.609, trans_loss=6.39, nll_loss=5.35, w2v_ctc_loss=7.038, task_loss=2.233, contrastive_loss=3.59, total=6737.22, n_correct=41.4, ppl=40.79, accuracy=0.614, wps=29107.8, ups=1.49, wpb=19517.9, bsz=686.6, num_updates=500, lr=2.009e-05, gnorm=0.743, clip=0, loss_scale=16, train_wall=66, gb_free=18.4, wall=414
2023-08-26 12:28:56 | INFO | train_inner | epoch 001:    603 / 1191 loss=10.561, trans_loss=6.443, nll_loss=5.421, w2v_ctc_loss=6.903, task_loss=2.17, contrastive_loss=3.559, total=6775.38, n_correct=33.64, ppl=42.84, accuracy=0.497, wps=29182, ups=1.49, wpb=19631.7, bsz=689.3, num_updates=600, lr=2.4088e-05, gnorm=0.867, clip=0, loss_scale=16, train_wall=67, gb_free=18, wall=482
2023-08-26 12:30:03 | INFO | train_inner | epoch 001:    703 / 1191 loss=10.495, trans_loss=6.491, nll_loss=5.481, w2v_ctc_loss=6.792, task_loss=2.226, contrastive_loss=3.573, total=6625.64, n_correct=23.54, ppl=44.66, accuracy=0.355, wps=28734.4, ups=1.5, wpb=19188.7, bsz=672.7, num_updates=700, lr=2.8086e-05, gnorm=0.898, clip=0, loss_scale=16, train_wall=66, gb_free=18.1, wall=548
2023-08-26 12:31:10 | INFO | train_inner | epoch 001:    803 / 1191 loss=10.402, trans_loss=6.416, nll_loss=5.382, w2v_ctc_loss=6.757, task_loss=2.102, contrastive_loss=3.518, total=6750.05, n_correct=17.25, ppl=41.7, accuracy=0.256, wps=29226.7, ups=1.5, wpb=19548.7, bsz=688.8, num_updates=800, lr=3.2084e-05, gnorm=1.052, clip=0, loss_scale=16, train_wall=66, gb_free=18.3, wall=615
2023-08-26 12:32:19 | INFO | train_inner | epoch 001:    903 / 1191 loss=10.232, trans_loss=6.318, nll_loss=5.258, w2v_ctc_loss=6.719, task_loss=2.215, contrastive_loss=3.462, total=6706.37, n_correct=20.82, ppl=38.26, accuracy=0.31, wps=28185.7, ups=1.45, wpb=19433.6, bsz=675.8, num_updates=900, lr=3.6082e-05, gnorm=1.46, clip=0, loss_scale=16, train_wall=68, gb_free=17.6, wall=684
2023-08-26 12:32:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-26 12:33:26 | INFO | train_inner | epoch 001:   1004 / 1191 loss=10.164, trans_loss=6.291, nll_loss=5.219, w2v_ctc_loss=6.729, task_loss=2.285, contrastive_loss=3.402, total=6671, n_correct=24.27, ppl=37.24, accuracy=0.364, wps=28759.8, ups=1.49, wpb=19327.2, bsz=665.8, num_updates=1000, lr=4.008e-05, gnorm=1.761, clip=0, loss_scale=8, train_wall=67, gb_free=18.4, wall=752
2023-08-26 12:34:33 | INFO | train_inner | epoch 001:   1104 / 1191 loss=10.046, trans_loss=6.274, nll_loss=5.188, w2v_ctc_loss=6.653, task_loss=2.305, contrastive_loss=3.295, total=6572.24, n_correct=27.21, ppl=36.45, accuracy=0.414, wps=28724.9, ups=1.51, wpb=19034.3, bsz=644, num_updates=1100, lr=4.4078e-05, gnorm=1.776, clip=0, loss_scale=8, train_wall=66, gb_free=19.1, wall=818
2023-08-26 12:35:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-08-26 12:36:14 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 13.811 | trans_loss 13.852 | nll_loss 13.589 | w2v_ctc_loss 9.329 | task_loss 14.015 | contrastive_loss 4.853 | total 6138.43 | n_correct 21 | ppl 12322.1 | accuracy 0.342 | uer 91.718 | wer 98.974 | raw_wer 98.974 | bleu 0 | wps 1224.9 | wpb 6138.4 | bsz 201.1 | num_updates 1187
2023-08-26 12:36:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1187 updates
2023-08-26 12:36:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 12:36:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 12:36:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 1 @ 1187 updates, score 0.0) (writing took 4.12795984299737 seconds)
2023-08-26 12:36:18 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-26 12:36:18 | INFO | train | epoch 001 | loss 11.746 | trans_loss 6.327 | nll_loss 5.24 | w2v_ctc_loss 8.951 | task_loss 2.375 | contrastive_loss 3.519 | total 6702.39 | n_correct 65.2089 | ppl 37.78 | accuracy 0.973 | wps 27108 | ups 1.4 | wpb 19418.8 | bsz 678 | num_updates 1187 | lr 4.75563e-05 | gnorm 1.726 | clip 0.3 | loss_scale 8 | train_wall 797 | gb_free 18.5 | wall 924
2023-08-26 12:36:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 12:36:18 | INFO | fairseq.trainer | begin training epoch 2
2023-08-26 12:36:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 12:36:36 | INFO | train_inner | epoch 002:     13 / 1191 loss=10.001, trans_loss=6.265, nll_loss=5.181, w2v_ctc_loss=6.611, task_loss=2.163, contrastive_loss=3.361, total=6638.17, n_correct=29.97, ppl=36.27, accuracy=0.451, wps=15564, ups=0.81, wpb=19236.9, bsz=681, num_updates=1200, lr=4.8076e-05, gnorm=1.939, clip=0, loss_scale=8, train_wall=66, gb_free=17.6, wall=942
2023-08-26 12:37:43 | INFO | train_inner | epoch 002:    113 / 1191 loss=9.896, trans_loss=6.24, nll_loss=5.151, w2v_ctc_loss=6.609, task_loss=2.265, contrastive_loss=3.241, total=6607.17, n_correct=31.59, ppl=35.53, accuracy=0.478, wps=28776.7, ups=1.5, wpb=19135.7, bsz=660.8, num_updates=1300, lr=5.2074e-05, gnorm=2.205, clip=0, loss_scale=8, train_wall=66, gb_free=19, wall=1008
2023-08-26 12:38:50 | INFO | train_inner | epoch 002:    213 / 1191 loss=9.859, trans_loss=6.206, nll_loss=5.111, w2v_ctc_loss=6.611, task_loss=2.23, contrastive_loss=3.193, total=6717.78, n_correct=36.26, ppl=34.55, accuracy=0.54, wps=28877.9, ups=1.48, wpb=19457.9, bsz=673, num_updates=1400, lr=5.6072e-05, gnorm=2.373, clip=0, loss_scale=8, train_wall=67, gb_free=17.8, wall=1076
2023-08-26 12:39:58 | INFO | train_inner | epoch 002:    313 / 1191 loss=9.801, trans_loss=6.175, nll_loss=5.073, w2v_ctc_loss=6.553, task_loss=2.101, contrastive_loss=3.171, total=6783.61, n_correct=43.95, ppl=33.65, accuracy=0.648, wps=29088.4, ups=1.48, wpb=19657, bsz=692, num_updates=1500, lr=6.007e-05, gnorm=2.095, clip=0, loss_scale=8, train_wall=67, gb_free=17.6, wall=1143
2023-08-26 12:41:05 | INFO | train_inner | epoch 002:    413 / 1191 loss=9.428, trans_loss=6.162, nll_loss=5.053, w2v_ctc_loss=6.011, task_loss=2.154, contrastive_loss=3.199, total=6717.93, n_correct=45.85, ppl=33.19, accuracy=0.683, wps=29132, ups=1.5, wpb=19471.9, bsz=690.3, num_updates=1600, lr=6.4068e-05, gnorm=2.264, clip=0, loss_scale=8, train_wall=66, gb_free=18.2, wall=1210
2023-08-26 12:42:12 | INFO | train_inner | epoch 002:    513 / 1191 loss=8.677, trans_loss=6.154, nll_loss=5.045, w2v_ctc_loss=4.917, task_loss=2.22, contrastive_loss=3.179, total=6702.22, n_correct=47.75, ppl=33.01, accuracy=0.712, wps=28961.2, ups=1.49, wpb=19424.7, bsz=680.4, num_updates=1700, lr=6.8066e-05, gnorm=1.803, clip=0, loss_scale=8, train_wall=67, gb_free=18.4, wall=1277
2023-08-26 12:43:18 | INFO | train_inner | epoch 002:    613 / 1191 loss=8.383, trans_loss=6.158, nll_loss=5.046, w2v_ctc_loss=4.543, task_loss=2.275, contrastive_loss=3.102, total=6642.86, n_correct=45.69, ppl=33.04, accuracy=0.688, wps=28833.3, ups=1.5, wpb=19232.5, bsz=660, num_updates=1800, lr=7.2064e-05, gnorm=1.775, clip=0, loss_scale=8, train_wall=66, gb_free=17.7, wall=1344
2023-08-26 12:44:25 | INFO | train_inner | epoch 002:    713 / 1191 loss=8.19, trans_loss=6.167, nll_loss=5.057, w2v_ctc_loss=4.203, task_loss=2.092, contrastive_loss=3.115, total=6796.78, n_correct=48.61, ppl=33.29, accuracy=0.715, wps=29521, ups=1.5, wpb=19677.2, bsz=701.9, num_updates=1900, lr=7.6062e-05, gnorm=1.705, clip=0, loss_scale=8, train_wall=66, gb_free=19.1, wall=1410
2023-08-26 12:45:32 | INFO | train_inner | epoch 002:    813 / 1191 loss=7.961, trans_loss=6.158, nll_loss=5.043, w2v_ctc_loss=3.925, task_loss=2.133, contrastive_loss=3.004, total=6729.61, n_correct=51.69, ppl=32.97, accuracy=0.768, wps=29073.8, ups=1.49, wpb=19499, bsz=680.8, num_updates=2000, lr=8.006e-05, gnorm=1.694, clip=0, loss_scale=8, train_wall=67, gb_free=17.6, wall=1478
2023-08-26 12:45:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 12:46:16 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 12.218 | trans_loss 13.601 | nll_loss 13.186 | w2v_ctc_loss 5.094 | task_loss 14.015 | contrastive_loss 4.412 | total 6138.43 | n_correct 48.1429 | ppl 9318.34 | accuracy 0.784 | uer 70.305 | wer 67.776 | raw_wer 67.776 | bleu 0 | wps 1214.7 | wpb 6138.4 | bsz 201.1 | num_updates 2000 | best_bleu 0
2023-08-26 12:46:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-26 12:46:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_2_2000.pt
2023-08-26 12:46:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_2_2000.pt
2023-08-26 12:46:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 10.957043932998204 seconds)
2023-08-26 12:47:34 | INFO | train_inner | epoch 002:    913 / 1191 loss=7.772, trans_loss=6.159, nll_loss=5.044, w2v_ctc_loss=3.689, task_loss=2.11, contrastive_loss=3.04, total=6752.13, n_correct=55.48, ppl=32.99, accuracy=0.822, wps=16106.2, ups=0.82, wpb=19570.7, bsz=703.1, num_updates=2100, lr=8.4058e-05, gnorm=1.636, clip=0, loss_scale=8, train_wall=66, gb_free=17.9, wall=1599
2023-08-26 12:48:40 | INFO | train_inner | epoch 002:   1013 / 1191 loss=7.594, trans_loss=6.173, nll_loss=5.057, w2v_ctc_loss=3.518, task_loss=2.181, contrastive_loss=2.895, total=6765.53, n_correct=55.96, ppl=33.3, accuracy=0.827, wps=29340.3, ups=1.5, wpb=19614, bsz=684.2, num_updates=2200, lr=8.8056e-05, gnorm=1.814, clip=0, loss_scale=8, train_wall=66, gb_free=18.5, wall=1666
2023-08-26 12:49:47 | INFO | train_inner | epoch 002:   1113 / 1191 loss=7.438, trans_loss=6.174, nll_loss=5.061, w2v_ctc_loss=3.374, task_loss=2.297, contrastive_loss=2.808, total=6648.26, n_correct=57.07, ppl=33.37, accuracy=0.858, wps=28908.8, ups=1.5, wpb=19255.9, bsz=655, num_updates=2300, lr=9.2054e-05, gnorm=2.175, clip=0, loss_scale=8, train_wall=66, gb_free=18.5, wall=1732
2023-08-26 12:50:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 12:51:22 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 12.188 | trans_loss 14.092 | nll_loss 13.672 | w2v_ctc_loss 4.174 | task_loss 14.015 | contrastive_loss 4.16 | total 6138.43 | n_correct 55.2857 | ppl 13052.6 | accuracy 0.901 | uer 60.918 | wer 58.55 | raw_wer 58.55 | bleu 0 | wps 1224.7 | wpb 6138.4 | bsz 201.1 | num_updates 2378 | best_bleu 0
2023-08-26 12:51:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2378 updates
2023-08-26 12:51:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 12:51:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 12:51:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 2 @ 2378 updates, score 0.0) (writing took 10.419687394998618 seconds)
2023-08-26 12:51:33 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-26 12:51:33 | INFO | train | epoch 002 | loss 8.566 | trans_loss 6.175 | nll_loss 5.067 | w2v_ctc_loss 4.817 | task_loss 2.194 | contrastive_loss 3.073 | total 6703.69 | n_correct 47.8715 | ppl 33.52 | accuracy 0.714 | wps 25282.5 | ups 1.3 | wpb 19422.7 | bsz 678.2 | num_updates 2378 | lr 9.51724e-05 | gnorm 1.965 | clip 0 | loss_scale 8 | train_wall 790 | gb_free 17.7 | wall 1839
2023-08-26 12:51:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 12:51:33 | INFO | fairseq.trainer | begin training epoch 3
2023-08-26 12:51:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 12:51:55 | INFO | train_inner | epoch 003:     22 / 1191 loss=7.317, trans_loss=6.161, nll_loss=5.05, w2v_ctc_loss=3.266, task_loss=2.34, contrastive_loss=2.816, total=6597.75, n_correct=59.15, ppl=33.13, accuracy=0.897, wps=14958.4, ups=0.78, wpb=19123.8, bsz=654.9, num_updates=2400, lr=9.6052e-05, gnorm=1.883, clip=0, loss_scale=8, train_wall=66, gb_free=18.5, wall=1860
2023-08-26 12:53:02 | INFO | train_inner | epoch 003:    122 / 1191 loss=7.246, trans_loss=6.159, nll_loss=5.048, w2v_ctc_loss=3.15, task_loss=2.153, contrastive_loss=2.804, total=6689.99, n_correct=62.69, ppl=33.08, accuracy=0.937, wps=28989.6, ups=1.49, wpb=19400.5, bsz=686.9, num_updates=2500, lr=0.00010005, gnorm=2.093, clip=0, loss_scale=8, train_wall=66, gb_free=18.7, wall=1927
2023-08-26 12:54:10 | INFO | train_inner | epoch 003:    222 / 1191 loss=7.109, trans_loss=6.159, nll_loss=5.05, w2v_ctc_loss=3.036, task_loss=2.135, contrastive_loss=2.726, total=6716.3, n_correct=65.63, ppl=33.12, accuracy=0.977, wps=28677.9, ups=1.47, wpb=19462.8, bsz=684.5, num_updates=2600, lr=0.000104048, gnorm=1.885, clip=0, loss_scale=8, train_wall=67, gb_free=17.7, wall=1995
2023-08-26 12:55:16 | INFO | train_inner | epoch 003:    322 / 1191 loss=6.972, trans_loss=6.153, nll_loss=5.043, w2v_ctc_loss=2.99, task_loss=2.506, contrastive_loss=2.553, total=6578.84, n_correct=64.74, ppl=32.96, accuracy=0.984, wps=28590.8, ups=1.5, wpb=19052.5, bsz=625.2, num_updates=2700, lr=0.000108046, gnorm=2.112, clip=0, loss_scale=8, train_wall=66, gb_free=18.5, wall=2062
2023-08-26 12:56:23 | INFO | train_inner | epoch 003:    422 / 1191 loss=6.931, trans_loss=6.157, nll_loss=5.049, w2v_ctc_loss=2.881, task_loss=2.146, contrastive_loss=2.673, total=6697.81, n_correct=68.36, ppl=33.11, accuracy=1.021, wps=29322, ups=1.51, wpb=19404.2, bsz=690.4, num_updates=2800, lr=0.000112044, gnorm=1.77, clip=0, loss_scale=8, train_wall=66, gb_free=18.9, wall=2128
2023-08-26 12:57:29 | INFO | train_inner | epoch 003:    522 / 1191 loss=6.867, trans_loss=6.165, nll_loss=5.061, w2v_ctc_loss=2.845, task_loss=2.186, contrastive_loss=2.508, total=6747.27, n_correct=71, ppl=33.38, accuracy=1.052, wps=29277.4, ups=1.5, wpb=19551.8, bsz=674.2, num_updates=2900, lr=0.000116042, gnorm=2.138, clip=0, loss_scale=8, train_wall=66, gb_free=18.2, wall=2195
2023-08-26 12:58:36 | INFO | train_inner | epoch 003:    622 / 1191 loss=6.782, trans_loss=6.15, nll_loss=5.04, w2v_ctc_loss=2.786, task_loss=2.222, contrastive_loss=2.465, total=6746.29, n_correct=72.54, ppl=32.91, accuracy=1.075, wps=29332.4, ups=1.5, wpb=19552.3, bsz=665.2, num_updates=3000, lr=0.00012004, gnorm=1.937, clip=0, loss_scale=16, train_wall=66, gb_free=18.6, wall=2261
2023-08-26 12:58:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-26 12:58:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-26 12:58:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-26 12:58:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-08-26 13:00:25 | INFO | train_inner | epoch 003:    726 / 1191 loss=6.152, trans_loss=5.431, nll_loss=4.164, w2v_ctc_loss=2.526, task_loss=1.529, contrastive_loss=2.577, total=6742.35, n_correct=243.27, ppl=17.92, accuracy=3.608, wps=17856.8, ups=0.91, wpb=19541.9, bsz=701.5, num_updates=3100, lr=0.000124038, gnorm=3.349, clip=4, loss_scale=1, train_wall=109, gb_free=13, wall=2371
2023-08-26 13:02:09 | INFO | train_inner | epoch 003:    826 / 1191 loss=5.506, trans_loss=5.197, nll_loss=3.866, w2v_ctc_loss=2.188, task_loss=1.437, contrastive_loss=2.215, total=6780.63, n_correct=379.6, ppl=14.58, accuracy=5.598, wps=18945.9, ups=0.96, wpb=19654.7, bsz=710.8, num_updates=3200, lr=0.000128036, gnorm=2.178, clip=0, loss_scale=1, train_wall=103, gb_free=12, wall=2475
2023-08-26 13:03:52 | INFO | train_inner | epoch 003:    926 / 1191 loss=5.231, trans_loss=5.126, nll_loss=3.769, w2v_ctc_loss=2.033, task_loss=1.422, contrastive_loss=2.036, total=6793.28, n_correct=539.47, ppl=13.63, accuracy=7.941, wps=19058.9, ups=0.97, wpb=19676.5, bsz=709, num_updates=3300, lr=0.000132034, gnorm=2.106, clip=0, loss_scale=1, train_wall=103, gb_free=13.1, wall=2578
2023-08-26 13:05:37 | INFO | train_inner | epoch 003:   1026 / 1191 loss=4.937, trans_loss=4.993, nll_loss=3.592, w2v_ctc_loss=1.965, task_loss=1.796, contrastive_loss=1.835, total=6544.02, n_correct=812.24, ppl=12.06, accuracy=12.412, wps=18054, ups=0.95, wpb=18965.3, bsz=618.6, num_updates=3400, lr=0.000136032, gnorm=2.067, clip=0, loss_scale=1, train_wall=104, gb_free=13.8, wall=2683
2023-08-26 13:07:23 | INFO | train_inner | epoch 003:   1126 / 1191 loss=4.751, trans_loss=4.853, nll_loss=3.402, w2v_ctc_loss=1.848, task_loss=1.48, contrastive_loss=1.846, total=6773.24, n_correct=1023.65, ppl=10.57, accuracy=15.113, wps=18592.2, ups=0.95, wpb=19607.2, bsz=708.3, num_updates=3500, lr=0.00014003, gnorm=1.897, clip=0, loss_scale=1, train_wall=105, gb_free=14.6, wall=2788
2023-08-26 13:08:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 13:09:11 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 7.507 | trans_loss 8.987 | nll_loss 7.425 | w2v_ctc_loss 2.134 | task_loss 7.733 | contrastive_loss 2.402 | total 6138.43 | n_correct 1121.86 | ppl 171.87 | accuracy 18.276 | uer 34.397 | wer 34.288 | raw_wer 34.288 | bleu 0.12 | wps 1296 | wpb 6138.4 | bsz 201.1 | num_updates 3565 | best_bleu 0.12
2023-08-26 13:09:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 3565 updates
2023-08-26 13:09:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 13:09:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 13:09:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 3 @ 3565 updates, score 0.12) (writing took 10.369783499998448 seconds)
2023-08-26 13:09:21 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-26 13:09:21 | INFO | train | epoch 003 | loss 6.156 | trans_loss 5.646 | nll_loss 4.41 | w2v_ctc_loss 2.537 | task_loss 1.889 | contrastive_loss 2.359 | total 6704.62 | n_correct 346.231 | ppl 21.27 | accuracy 5.164 | wps 21582.6 | ups 1.11 | wpb 19425.5 | bsz 678.6 | num_updates 3565 | lr 0.000142629 | gnorm 2.115 | clip 0.3 | loss_scale 1 | train_wall 1003 | gb_free 15.1 | wall 2907
2023-08-26 13:09:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 13:09:22 | INFO | fairseq.trainer | begin training epoch 4
2023-08-26 13:09:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 13:10:06 | INFO | train_inner | epoch 004:     35 / 1191 loss=4.545, trans_loss=4.777, nll_loss=3.298, w2v_ctc_loss=1.786, task_loss=1.637, contrastive_loss=1.657, total=6566.26, n_correct=1080.37, ppl=9.83, accuracy=16.453, wps=11639.6, ups=0.61, wpb=19006.6, bsz=644.2, num_updates=3600, lr=0.000144028, gnorm=1.892, clip=0, loss_scale=1, train_wall=104, gb_free=13.3, wall=2952
2023-08-26 13:11:51 | INFO | train_inner | epoch 004:    135 / 1191 loss=4.393, trans_loss=4.702, nll_loss=3.199, w2v_ctc_loss=1.712, task_loss=1.588, contrastive_loss=1.55, total=6733.36, n_correct=1222.45, ppl=9.18, accuracy=18.155, wps=18586.8, ups=0.95, wpb=19503.2, bsz=659, num_updates=3700, lr=0.000148026, gnorm=1.689, clip=0, loss_scale=1, train_wall=104, gb_free=13.5, wall=3057
2023-08-26 13:13:35 | INFO | train_inner | epoch 004:    235 / 1191 loss=4.308, trans_loss=4.64, nll_loss=3.119, w2v_ctc_loss=1.666, task_loss=1.497, contrastive_loss=1.645, total=6747.52, n_correct=1329.34, ppl=8.69, accuracy=19.701, wps=18801.9, ups=0.96, wpb=19554.6, bsz=702.1, num_updates=3800, lr=0.000152024, gnorm=1.727, clip=0, loss_scale=1, train_wall=103, gb_free=14.2, wall=3161
2023-08-26 13:15:18 | INFO | train_inner | epoch 004:    335 / 1191 loss=4.153, trans_loss=4.585, nll_loss=3.045, w2v_ctc_loss=1.634, task_loss=1.552, contrastive_loss=1.411, total=6670.37, n_correct=1417.33, ppl=8.26, accuracy=21.248, wps=18704, ups=0.97, wpb=19329.7, bsz=662.9, num_updates=3900, lr=0.000156022, gnorm=1.558, clip=0, loss_scale=1, train_wall=103, gb_free=14.4, wall=3264
2023-08-26 13:17:04 | INFO | train_inner | epoch 004:    435 / 1191 loss=4.075, trans_loss=4.519, nll_loss=2.959, w2v_ctc_loss=1.614, task_loss=1.56, contrastive_loss=1.487, total=6715.16, n_correct=1548.34, ppl=7.78, accuracy=23.057, wps=18494.8, ups=0.95, wpb=19457, bsz=683.7, num_updates=4000, lr=0.00016002, gnorm=1.564, clip=0, loss_scale=1, train_wall=105, gb_free=11.7, wall=3369
2023-08-26 13:17:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 13:17:43 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 6.653 | trans_loss 8.097 | nll_loss 6.221 | w2v_ctc_loss 1.888 | task_loss 7.74 | contrastive_loss 1.867 | total 6138.43 | n_correct 1663.14 | ppl 74.6 | accuracy 27.094 | uer 30.88 | wer 30.959 | raw_wer 30.959 | bleu 1.54 | wps 1366.6 | wpb 6138.4 | bsz 201.1 | num_updates 4000 | best_bleu 1.54
2023-08-26 13:17:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 4000 updates
2023-08-26 13:17:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_4_4000.pt
2023-08-26 13:17:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_4_4000.pt
2023-08-26 13:17:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_4_4000.pt (epoch 4 @ 4000 updates, score 1.54) (writing took 13.013272869997309 seconds)
2023-08-26 13:19:40 | INFO | train_inner | epoch 004:    535 / 1191 loss=3.919, trans_loss=4.431, nll_loss=2.842, w2v_ctc_loss=1.582, task_loss=1.586, contrastive_loss=1.286, total=6673.82, n_correct=1706.49, ppl=7.17, accuracy=25.57, wps=12408.8, ups=0.64, wpb=19338.8, bsz=668.4, num_updates=4100, lr=0.000164018, gnorm=1.528, clip=0, loss_scale=1, train_wall=103, gb_free=12.2, wall=3525
2023-08-26 13:21:25 | INFO | train_inner | epoch 004:    635 / 1191 loss=3.803, trans_loss=4.333, nll_loss=2.714, w2v_ctc_loss=1.554, task_loss=1.492, contrastive_loss=1.309, total=6814.1, n_correct=1955.96, ppl=6.56, accuracy=28.705, wps=18746.3, ups=0.95, wpb=19748.2, bsz=705.7, num_updates=4200, lr=0.000168016, gnorm=1.459, clip=0, loss_scale=1, train_wall=105, gb_free=10.2, wall=3630
2023-08-26 13:23:08 | INFO | train_inner | epoch 004:    735 / 1191 loss=3.601, trans_loss=4.161, nll_loss=2.487, w2v_ctc_loss=1.52, task_loss=1.517, contrastive_loss=1.244, total=6700.29, n_correct=2287.2, ppl=5.61, accuracy=34.136, wps=18857, ups=0.97, wpb=19408.2, bsz=687.4, num_updates=4300, lr=0.000172014, gnorm=1.422, clip=0, loss_scale=1, train_wall=102, gb_free=13.8, wall=3733
2023-08-26 13:24:53 | INFO | train_inner | epoch 004:    835 / 1191 loss=3.426, trans_loss=4.002, nll_loss=2.283, w2v_ctc_loss=1.502, task_loss=1.443, contrastive_loss=1.173, total=6860.6, n_correct=2747.63, ppl=4.87, accuracy=40.049, wps=18856.7, ups=0.95, wpb=19871.7, bsz=724.3, num_updates=4400, lr=0.000176012, gnorm=1.304, clip=0, loss_scale=1, train_wall=105, gb_free=11.8, wall=3839
2023-08-26 13:26:37 | INFO | train_inner | epoch 004:    935 / 1191 loss=3.291, trans_loss=3.918, nll_loss=2.174, w2v_ctc_loss=1.481, task_loss=1.474, contrastive_loss=1.075, total=6733.51, n_correct=2923.14, ppl=4.51, accuracy=43.412, wps=18723.5, ups=0.96, wpb=19496.4, bsz=704.1, num_updates=4500, lr=0.00018001, gnorm=1.272, clip=0, loss_scale=1, train_wall=104, gb_free=13.3, wall=3943
2023-08-26 13:28:23 | INFO | train_inner | epoch 004:   1035 / 1191 loss=3.2, trans_loss=3.872, nll_loss=2.115, w2v_ctc_loss=1.485, task_loss=1.648, contrastive_loss=0.972, total=6645.98, n_correct=3005.12, ppl=4.33, accuracy=45.217, wps=18263.4, ups=0.95, wpb=19247.9, bsz=661.3, num_updates=4600, lr=0.000184008, gnorm=1.235, clip=0, loss_scale=1, train_wall=105, gb_free=12, wall=4048
2023-08-26 13:30:07 | INFO | train_inner | epoch 004:   1135 / 1191 loss=3.086, trans_loss=3.822, nll_loss=2.054, w2v_ctc_loss=1.466, task_loss=1.674, contrastive_loss=0.816, total=6563.35, n_correct=3096.3, ppl=4.15, accuracy=47.176, wps=18188.6, ups=0.96, wpb=19027.9, bsz=629.6, num_updates=4700, lr=0.000188006, gnorm=1.203, clip=0, loss_scale=1, train_wall=104, gb_free=9.1, wall=4153
2023-08-26 13:31:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 13:31:42 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.913 | trans_loss 6.009 | nll_loss 3.508 | w2v_ctc_loss 1.664 | task_loss 7.905 | contrastive_loss 1.109 | total 6138.43 | n_correct 3304.14 | ppl 11.38 | accuracy 53.827 | uer 27.315 | wer 27.769 | raw_wer 27.769 | bleu 12.02 | wps 1505.5 | wpb 6138.4 | bsz 201.1 | num_updates 4756 | best_bleu 12.02
2023-08-26 13:31:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 4756 updates
2023-08-26 13:31:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 13:31:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 13:31:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 4 @ 4756 updates, score 12.02) (writing took 12.811230555998918 seconds)
2023-08-26 13:31:54 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-26 13:31:54 | INFO | train | epoch 004 | loss 3.739 | trans_loss 4.263 | nll_loss 2.625 | w2v_ctc_loss 1.566 | task_loss 1.555 | contrastive_loss 1.26 | total 6703.69 | n_correct 2135.59 | ppl 6.17 | accuracy 31.857 | wps 17098.8 | ups 0.88 | wpb 19422.7 | bsz 678.2 | num_updates 4756 | lr 0.000190245 | gnorm 1.448 | clip 0 | loss_scale 1 | train_wall 1237 | gb_free 13.2 | wall 4260
2023-08-26 13:31:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 13:31:55 | INFO | fairseq.trainer | begin training epoch 5
2023-08-26 13:31:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 13:32:47 | INFO | train_inner | epoch 005:     44 / 1191 loss=3.023, trans_loss=3.769, nll_loss=1.985, w2v_ctc_loss=1.425, task_loss=1.455, contrastive_loss=0.882, total=6757.62, n_correct=3334, ppl=3.96, accuracy=49.337, wps=12294.9, ups=0.63, wpb=19585.7, bsz=710.1, num_updates=4800, lr=0.000192004, gnorm=1.108, clip=0, loss_scale=1, train_wall=102, gb_free=12.1, wall=4312
2023-08-26 13:34:32 | INFO | train_inner | epoch 005:    144 / 1191 loss=2.941, trans_loss=3.744, nll_loss=1.952, w2v_ctc_loss=1.396, task_loss=1.56, contrastive_loss=0.833, total=6720.77, n_correct=3396.07, ppl=3.87, accuracy=50.531, wps=18559.3, ups=0.95, wpb=19470.6, bsz=679.4, num_updates=4900, lr=0.000196002, gnorm=1.066, clip=0, loss_scale=1, train_wall=104, gb_free=12.1, wall=4417
2023-08-26 13:36:16 | INFO | train_inner | epoch 005:    244 / 1191 loss=2.887, trans_loss=3.713, nll_loss=1.912, w2v_ctc_loss=1.378, task_loss=1.421, contrastive_loss=0.785, total=6862.7, n_correct=3571.69, ppl=3.76, accuracy=52.045, wps=19065.4, ups=0.96, wpb=19879, bsz=728.1, num_updates=5000, lr=0.0002, gnorm=1.045, clip=0, loss_scale=1, train_wall=104, gb_free=12.4, wall=4521
mt_weight tensor(0.5000)
asr_weight tensor(0.5310, device='cuda:0')
2023-08-26 13:38:00 | INFO | train_inner | epoch 005:    344 / 1191 loss=2.821, trans_loss=3.687, nll_loss=1.88, w2v_ctc_loss=1.367, task_loss=1.615, contrastive_loss=0.733, total=6623.63, n_correct=3508.6, ppl=3.68, accuracy=52.971, wps=18438.3, ups=0.96, wpb=19190.6, bsz=663.6, num_updates=5100, lr=0.00019803, gnorm=0.713, clip=0, loss_scale=2, train_wall=103, gb_free=13.7, wall=4625
2023-08-26 13:39:45 | INFO | train_inner | epoch 005:    444 / 1191 loss=2.801, trans_loss=3.663, nll_loss=1.85, w2v_ctc_loss=1.37, task_loss=1.562, contrastive_loss=0.753, total=6678.98, n_correct=3592.18, ppl=3.61, accuracy=53.783, wps=18465.3, ups=0.95, wpb=19364, bsz=677.9, num_updates=5200, lr=0.000196116, gnorm=0.699, clip=0, loss_scale=2, train_wall=104, gb_free=14.2, wall=4730
2023-08-26 13:41:30 | INFO | train_inner | epoch 005:    544 / 1191 loss=2.765, trans_loss=3.646, nll_loss=1.825, w2v_ctc_loss=1.348, task_loss=1.574, contrastive_loss=0.765, total=6674.44, n_correct=3651, ppl=3.54, accuracy=54.701, wps=18432.9, ups=0.95, wpb=19332, bsz=676.1, num_updates=5300, lr=0.000194257, gnorm=0.691, clip=0, loss_scale=2, train_wall=104, gb_free=12.6, wall=4835
2023-08-26 13:43:13 | INFO | train_inner | epoch 005:    644 / 1191 loss=2.702, trans_loss=3.629, nll_loss=1.804, w2v_ctc_loss=1.34, task_loss=1.578, contrastive_loss=0.602, total=6701.47, n_correct=3727.08, ppl=3.49, accuracy=55.616, wps=18847.5, ups=0.97, wpb=19404.6, bsz=666.6, num_updates=5400, lr=0.00019245, gnorm=0.701, clip=0, loss_scale=2, train_wall=102, gb_free=13.4, wall=4938
2023-08-26 13:44:59 | INFO | train_inner | epoch 005:    744 / 1191 loss=2.697, trans_loss=3.607, nll_loss=1.778, w2v_ctc_loss=1.33, task_loss=1.553, contrastive_loss=0.699, total=6726.46, n_correct=3780.01, ppl=3.43, accuracy=56.196, wps=18387.1, ups=0.94, wpb=19494.9, bsz=687.1, num_updates=5500, lr=0.000190693, gnorm=0.645, clip=0, loss_scale=2, train_wall=105, gb_free=14.8, wall=5044
2023-08-26 13:46:43 | INFO | train_inner | epoch 005:    844 / 1191 loss=2.64, trans_loss=3.59, nll_loss=1.754, w2v_ctc_loss=1.306, task_loss=1.523, contrastive_loss=0.645, total=6755.92, n_correct=3847.42, ppl=3.37, accuracy=56.949, wps=18777.1, ups=0.96, wpb=19568, bsz=685.5, num_updates=5600, lr=0.000188982, gnorm=0.627, clip=0, loss_scale=2, train_wall=104, gb_free=14.2, wall=5148
2023-08-26 13:48:28 | INFO | train_inner | epoch 005:    944 / 1191 loss=2.62, trans_loss=3.584, nll_loss=1.75, w2v_ctc_loss=1.308, task_loss=1.625, contrastive_loss=0.615, total=6609, n_correct=3788.46, ppl=3.36, accuracy=57.323, wps=18245.8, ups=0.95, wpb=19153.5, bsz=658.3, num_updates=5700, lr=0.000187317, gnorm=0.62, clip=0, loss_scale=2, train_wall=104, gb_free=12.4, wall=5253
2023-08-26 13:50:13 | INFO | train_inner | epoch 005:   1044 / 1191 loss=2.587, trans_loss=3.572, nll_loss=1.732, w2v_ctc_loss=1.297, task_loss=1.664, contrastive_loss=0.568, total=6638.38, n_correct=3833.32, ppl=3.32, accuracy=57.745, wps=18333.7, ups=0.95, wpb=19232.6, bsz=646.6, num_updates=5800, lr=0.000185695, gnorm=0.616, clip=0, loss_scale=2, train_wall=104, gb_free=12.1, wall=5358
2023-08-26 13:51:56 | INFO | train_inner | epoch 005:   1144 / 1191 loss=2.579, trans_loss=3.561, nll_loss=1.719, w2v_ctc_loss=1.291, task_loss=1.578, contrastive_loss=0.591, total=6707.27, n_correct=3909.05, ppl=3.29, accuracy=58.281, wps=18743.1, ups=0.96, wpb=19433.4, bsz=672.3, num_updates=5900, lr=0.000184115, gnorm=0.611, clip=0, loss_scale=2, train_wall=103, gb_free=14, wall=5462
2023-08-26 13:52:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.5310, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.5310, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.5310, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.5310, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.5310, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.5310, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.5310, device='cuda:1')
2023-08-26 13:53:19 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.306 | trans_loss 5.398 | nll_loss 2.741 | w2v_ctc_loss 1.449 | task_loss 8.176 | contrastive_loss 0.718 | total 6138.43 | n_correct 3872.29 | ppl 6.68 | accuracy 63.083 | uer 23.927 | wer 24.968 | raw_wer 24.968 | bleu 20.89 | wps 1660.6 | wpb 6138.4 | bsz 201.1 | num_updates 5947 | best_bleu 20.89
2023-08-26 13:53:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 5947 updates
2023-08-26 13:53:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 13:53:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 13:53:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 5 @ 5947 updates, score 20.89) (writing took 11.025245288998121 seconds)
2023-08-26 13:53:30 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-26 13:53:30 | INFO | train | epoch 005 | loss 2.735 | trans_loss 3.637 | nll_loss 1.816 | w2v_ctc_loss 1.339 | task_loss 1.559 | contrastive_loss 0.697 | total 6703.69 | n_correct 3689.85 | ppl 3.52 | accuracy 55.042 | wps 17847.1 | ups 0.92 | wpb 19422.7 | bsz 678.2 | num_updates 5947 | lr 0.000183386 | gnorm 0.739 | clip 0 | loss_scale 2 | train_wall 1236 | gb_free 11.1 | wall 5556
2023-08-26 13:53:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 13:53:31 | INFO | fairseq.trainer | begin training epoch 6
2023-08-26 13:53:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 13:54:32 | INFO | train_inner | epoch 006:     53 / 1191 loss=2.529, trans_loss=3.534, nll_loss=1.685, w2v_ctc_loss=1.249, task_loss=1.583, contrastive_loss=0.612, total=6661.78, n_correct=3943.03, ppl=3.22, accuracy=59.189, wps=12381.9, ups=0.64, wpb=19302.8, bsz=664.4, num_updates=6000, lr=0.000182574, gnorm=0.635, clip=0, loss_scale=2, train_wall=103, gb_free=12.2, wall=5618
2023-08-26 13:54:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 13:55:07 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.297 | trans_loss 5.384 | nll_loss 2.721 | w2v_ctc_loss 1.479 | task_loss 8.207 | contrastive_loss 0.693 | total 6138.43 | n_correct 3883.86 | ppl 6.59 | accuracy 63.271 | uer 23.373 | wer 24.485 | raw_wer 24.485 | bleu 21.21 | wps 1540.7 | wpb 6138.4 | bsz 201.1 | num_updates 6000 | best_bleu 21.21
2023-08-26 13:55:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 6000 updates
2023-08-26 13:55:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_6_6000.pt
2023-08-26 13:55:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_6_6000.pt
2023-08-26 13:55:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_6_6000.pt (epoch 6 @ 6000 updates, score 21.21) (writing took 15.03789673600113 seconds)
2023-08-26 13:57:06 | INFO | train_inner | epoch 006:    153 / 1191 loss=2.481, trans_loss=3.527, nll_loss=1.673, w2v_ctc_loss=1.229, task_loss=1.589, contrastive_loss=0.531, total=6706.17, n_correct=3996.48, ppl=3.19, accuracy=59.594, wps=12609.1, ups=0.65, wpb=19417, bsz=672.3, num_updates=6100, lr=0.000181071, gnorm=0.628, clip=0, loss_scale=2, train_wall=103, gb_free=11.5, wall=5772
2023-08-26 13:58:51 | INFO | train_inner | epoch 006:    253 / 1191 loss=2.482, trans_loss=3.513, nll_loss=1.657, w2v_ctc_loss=1.217, task_loss=1.435, contrastive_loss=0.596, total=6846.28, n_correct=4107.19, ppl=3.15, accuracy=59.992, wps=18894, ups=0.95, wpb=19836, bsz=721.4, num_updates=6200, lr=0.000179605, gnorm=0.571, clip=0, loss_scale=2, train_wall=104, gb_free=13.6, wall=5877
2023-08-26 14:00:37 | INFO | train_inner | epoch 006:    353 / 1191 loss=2.453, trans_loss=3.513, nll_loss=1.657, w2v_ctc_loss=1.223, task_loss=1.58, contrastive_loss=0.483, total=6725.76, n_correct=4042.84, ppl=3.15, accuracy=60.11, wps=18406.3, ups=0.94, wpb=19477.6, bsz=674.9, num_updates=6300, lr=0.000178174, gnorm=0.579, clip=0, loss_scale=2, train_wall=105, gb_free=12.4, wall=5983
2023-08-26 14:02:21 | INFO | train_inner | epoch 006:    453 / 1191 loss=2.448, trans_loss=3.505, nll_loss=1.649, w2v_ctc_loss=1.225, task_loss=1.621, contrastive_loss=0.531, total=6576.12, n_correct=3962.06, ppl=3.14, accuracy=60.249, wps=18431.5, ups=0.97, wpb=19058.3, bsz=652.6, num_updates=6400, lr=0.000176777, gnorm=0.561, clip=0, loss_scale=2, train_wall=103, gb_free=13, wall=6086
2023-08-26 14:04:06 | INFO | train_inner | epoch 006:    553 / 1191 loss=2.41, trans_loss=3.493, nll_loss=1.634, w2v_ctc_loss=1.206, task_loss=1.608, contrastive_loss=0.452, total=6685.87, n_correct=4058.54, ppl=3.1, accuracy=60.703, wps=18408.4, ups=0.95, wpb=19382.5, bsz=660.9, num_updates=6500, lr=0.000175412, gnorm=0.564, clip=0, loss_scale=2, train_wall=105, gb_free=14.2, wall=6191
2023-08-26 14:05:51 | INFO | train_inner | epoch 006:    653 / 1191 loss=2.402, trans_loss=3.493, nll_loss=1.632, w2v_ctc_loss=1.192, task_loss=1.647, contrastive_loss=0.501, total=6675.16, n_correct=4065.8, ppl=3.1, accuracy=60.909, wps=18468.7, ups=0.96, wpb=19332.7, bsz=654.5, num_updates=6600, lr=0.000174078, gnorm=0.554, clip=0, loss_scale=2, train_wall=104, gb_free=14.4, wall=6296
2023-08-26 14:07:35 | INFO | train_inner | epoch 006:    753 / 1191 loss=2.424, trans_loss=3.482, nll_loss=1.618, w2v_ctc_loss=1.195, task_loss=1.459, contrastive_loss=0.588, total=6843.27, n_correct=4195.62, ppl=3.07, accuracy=61.31, wps=18951.9, ups=0.96, wpb=19825.5, bsz=722.5, num_updates=6700, lr=0.000172774, gnorm=0.555, clip=0, loss_scale=2, train_wall=104, gb_free=13.8, wall=6401
2023-08-26 14:09:20 | INFO | train_inner | epoch 006:    853 / 1191 loss=2.403, trans_loss=3.474, nll_loss=1.611, w2v_ctc_loss=1.197, task_loss=1.584, contrastive_loss=0.546, total=6628.09, n_correct=4074.84, ppl=3.06, accuracy=61.478, wps=18292.5, ups=0.95, wpb=19221.2, bsz=682.5, num_updates=6800, lr=0.000171499, gnorm=0.548, clip=0, loss_scale=2, train_wall=105, gb_free=14.4, wall=6506
2023-08-26 14:11:05 | INFO | train_inner | epoch 006:    953 / 1191 loss=2.381, trans_loss=3.479, nll_loss=1.615, w2v_ctc_loss=1.197, task_loss=1.732, contrastive_loss=0.466, total=6623.09, n_correct=4068.91, ppl=3.06, accuracy=61.435, wps=18239.2, ups=0.95, wpb=19184.2, bsz=632.5, num_updates=6900, lr=0.000170251, gnorm=0.537, clip=0, loss_scale=2, train_wall=105, gb_free=15.1, wall=6611
2023-08-26 14:12:50 | INFO | train_inner | epoch 006:   1053 / 1191 loss=2.363, trans_loss=3.465, nll_loss=1.598, w2v_ctc_loss=1.166, task_loss=1.566, contrastive_loss=0.528, total=6685.49, n_correct=4143.74, ppl=3.03, accuracy=61.981, wps=18531.2, ups=0.96, wpb=19375.2, bsz=672.3, num_updates=7000, lr=0.000169031, gnorm=0.553, clip=0, loss_scale=2, train_wall=104, gb_free=14, wall=6715
2023-08-26 14:14:33 | INFO | train_inner | epoch 006:   1153 / 1191 loss=2.326, trans_loss=3.455, nll_loss=1.586, w2v_ctc_loss=1.158, task_loss=1.439, contrastive_loss=0.406, total=6756.56, n_correct=4213.04, ppl=3, accuracy=62.355, wps=19029.3, ups=0.97, wpb=19583.8, bsz=710.5, num_updates=7100, lr=0.000167836, gnorm=0.538, clip=0, loss_scale=4, train_wall=102, gb_free=13.8, wall=6818
2023-08-26 14:15:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 14:15:45 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.089 | trans_loss 5.205 | nll_loss 2.502 | w2v_ctc_loss 1.33 | task_loss 8.363 | contrastive_loss 0.564 | total 6138.43 | n_correct 4036.29 | ppl 5.66 | accuracy 65.754 | uer 22.151 | wer 23.756 | raw_wer 23.756 | bleu 23.74 | wps 1697.5 | wpb 6138.4 | bsz 201.1 | num_updates 7138 | best_bleu 23.74
2023-08-26 14:15:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 7138 updates
2023-08-26 14:15:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 14:15:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 14:15:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 6 @ 7138 updates, score 23.74) (writing took 11.241049525997369 seconds)
2023-08-26 14:15:57 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-26 14:15:57 | INFO | train | epoch 006 | loss 2.417 | trans_loss 3.491 | nll_loss 1.631 | w2v_ctc_loss 1.2 | task_loss 1.562 | contrastive_loss 0.515 | total 6703.69 | n_correct 4082.95 | ppl 3.1 | accuracy 60.906 | wps 17184.5 | ups 0.88 | wpb 19422.7 | bsz 678.2 | num_updates 7138 | lr 0.000167389 | gnorm 0.566 | clip 0 | loss_scale 4 | train_wall 1237 | gb_free 13.5 | wall 6902
2023-08-26 14:15:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 14:15:57 | INFO | fairseq.trainer | begin training epoch 7
2023-08-26 14:15:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 14:17:09 | INFO | train_inner | epoch 007:     62 / 1191 loss=2.324, trans_loss=3.451, nll_loss=1.578, w2v_ctc_loss=1.144, task_loss=1.516, contrastive_loss=0.506, total=6721.95, n_correct=4200.62, ppl=2.99, accuracy=62.491, wps=12490.4, ups=0.64, wpb=19460.2, bsz=692.1, num_updates=7200, lr=0.000166667, gnorm=0.532, clip=0, loss_scale=4, train_wall=104, gb_free=15, wall=6974
2023-08-26 14:18:54 | INFO | train_inner | epoch 007:    162 / 1191 loss=2.297, trans_loss=3.435, nll_loss=1.562, w2v_ctc_loss=1.128, task_loss=1.597, contrastive_loss=0.483, total=6672.19, n_correct=4196.31, ppl=2.95, accuracy=62.893, wps=18345.4, ups=0.95, wpb=19352.6, bsz=674.7, num_updates=7300, lr=0.000165521, gnorm=0.527, clip=0, loss_scale=4, train_wall=105, gb_free=6.3, wall=7080
2023-08-26 14:20:38 | INFO | train_inner | epoch 007:    262 / 1191 loss=2.273, trans_loss=3.431, nll_loss=1.554, w2v_ctc_loss=1.126, task_loss=1.565, contrastive_loss=0.389, total=6687.13, n_correct=4221.82, ppl=2.94, accuracy=63.134, wps=18628.1, ups=0.96, wpb=19375.7, bsz=672.9, num_updates=7400, lr=0.000164399, gnorm=0.512, clip=0, loss_scale=4, train_wall=103, gb_free=10.8, wall=7184
2023-08-26 14:22:21 | INFO | train_inner | epoch 007:    362 / 1191 loss=2.241, trans_loss=3.417, nll_loss=1.537, w2v_ctc_loss=1.101, task_loss=1.51, contrastive_loss=0.366, total=6732.56, n_correct=4287.18, ppl=2.9, accuracy=63.678, wps=19013, ups=0.97, wpb=19514, bsz=689.7, num_updates=7500, lr=0.000163299, gnorm=0.51, clip=0, loss_scale=4, train_wall=102, gb_free=13.6, wall=7286
2023-08-26 14:24:04 | INFO | train_inner | epoch 007:    462 / 1191 loss=2.267, trans_loss=3.426, nll_loss=1.549, w2v_ctc_loss=1.109, task_loss=1.47, contrastive_loss=0.457, total=6781.49, n_correct=4303.6, ppl=2.93, accuracy=63.461, wps=18983.9, ups=0.97, wpb=19649.3, bsz=708.3, num_updates=7600, lr=0.000162221, gnorm=0.514, clip=0, loss_scale=4, train_wall=103, gb_free=12.1, wall=7390
2023-08-26 14:25:49 | INFO | train_inner | epoch 007:    562 / 1191 loss=2.251, trans_loss=3.422, nll_loss=1.543, w2v_ctc_loss=1.114, task_loss=1.599, contrastive_loss=0.383, total=6712.62, n_correct=4270.46, ppl=2.91, accuracy=63.618, wps=18516.9, ups=0.95, wpb=19444.9, bsz=672.4, num_updates=7700, lr=0.000161165, gnorm=0.516, clip=0, loss_scale=4, train_wall=104, gb_free=14.1, wall=7495
2023-08-26 14:27:36 | INFO | train_inner | epoch 007:    662 / 1191 loss=2.259, trans_loss=3.423, nll_loss=1.545, w2v_ctc_loss=1.103, task_loss=1.527, contrastive_loss=0.463, total=6755.47, n_correct=4292.35, ppl=2.92, accuracy=63.539, wps=18441, ups=0.94, wpb=19573.5, bsz=694.3, num_updates=7800, lr=0.000160128, gnorm=0.513, clip=0, loss_scale=4, train_wall=106, gb_free=13.5, wall=7601
2023-08-26 14:29:20 | INFO | train_inner | epoch 007:    762 / 1191 loss=2.226, trans_loss=3.414, nll_loss=1.533, w2v_ctc_loss=1.102, task_loss=1.599, contrastive_loss=0.362, total=6675.9, n_correct=4266.64, ppl=2.89, accuracy=63.911, wps=18510.7, ups=0.96, wpb=19333.2, bsz=669.4, num_updates=7900, lr=0.000159111, gnorm=0.506, clip=0, loss_scale=4, train_wall=104, gb_free=14.3, wall=7705
2023-08-26 14:31:04 | INFO | train_inner | epoch 007:    862 / 1191 loss=2.238, trans_loss=3.416, nll_loss=1.536, w2v_ctc_loss=1.092, task_loss=1.625, contrastive_loss=0.466, total=6653.07, n_correct=4249, ppl=2.9, accuracy=63.865, wps=18467.8, ups=0.96, wpb=19269.9, bsz=656.8, num_updates=8000, lr=0.000158114, gnorm=0.505, clip=0, loss_scale=4, train_wall=104, gb_free=14.6, wall=7810
2023-08-26 14:31:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 14:31:41 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.012 | trans_loss 5.122 | nll_loss 2.398 | w2v_ctc_loss 1.311 | task_loss 8.395 | contrastive_loss 0.522 | total 6138.43 | n_correct 4117.43 | ppl 5.27 | accuracy 67.076 | uer 20.86 | wer 22.242 | raw_wer 22.242 | bleu 24.71 | wps 1525.7 | wpb 6138.4 | bsz 201.1 | num_updates 8000 | best_bleu 24.71
2023-08-26 14:31:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 8000 updates
2023-08-26 14:31:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_7_8000.pt
2023-08-26 14:31:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_7_8000.pt
2023-08-26 14:31:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_7_8000.pt (epoch 7 @ 8000 updates, score 24.71) (writing took 11.272047639999073 seconds)
2023-08-26 14:33:37 | INFO | train_inner | epoch 007:    962 / 1191 loss=2.206, trans_loss=3.405, nll_loss=1.522, w2v_ctc_loss=1.093, task_loss=1.649, contrastive_loss=0.36, total=6647.82, n_correct=4270.25, ppl=2.87, accuracy=64.235, wps=12582.6, ups=0.65, wpb=19259.8, bsz=648.5, num_updates=8100, lr=0.000157135, gnorm=0.496, clip=0, loss_scale=4, train_wall=104, gb_free=13.8, wall=7963
2023-08-26 14:35:21 | INFO | train_inner | epoch 007:   1062 / 1191 loss=2.23, trans_loss=3.404, nll_loss=1.519, w2v_ctc_loss=1.091, task_loss=1.541, contrastive_loss=0.469, total=6668.15, n_correct=4290.82, ppl=2.87, accuracy=64.348, wps=18612.5, ups=0.96, wpb=19305.1, bsz=687.9, num_updates=8200, lr=0.000156174, gnorm=0.503, clip=0, loss_scale=4, train_wall=103, gb_free=6.6, wall=8067
2023-08-26 14:37:06 | INFO | train_inner | epoch 007:   1162 / 1191 loss=2.217, trans_loss=3.405, nll_loss=1.525, w2v_ctc_loss=1.087, task_loss=1.581, contrastive_loss=0.438, total=6725.89, n_correct=4322.21, ppl=2.88, accuracy=64.262, wps=18558.2, ups=0.95, wpb=19497.5, bsz=681, num_updates=8300, lr=0.00015523, gnorm=0.496, clip=0, loss_scale=4, train_wall=104, gb_free=11.7, wall=8172
2023-08-26 14:37:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 14:38:11 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 3.975 | trans_loss 5.098 | nll_loss 2.37 | w2v_ctc_loss 1.265 | task_loss 8.407 | contrastive_loss 0.5 | total 6138.43 | n_correct 4143.57 | ppl 5.17 | accuracy 67.502 | uer 20.646 | wer 21.971 | raw_wer 21.971 | bleu 25.4 | wps 1595.6 | wpb 6138.4 | bsz 201.1 | num_updates 8329 | best_bleu 25.4
2023-08-26 14:38:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 8329 updates
2023-08-26 14:38:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 14:38:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 14:38:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 7 @ 8329 updates, score 25.4) (writing took 11.576732460998755 seconds)
2023-08-26 14:38:23 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-26 14:38:23 | INFO | train | epoch 007 | loss 2.249 | trans_loss 3.419 | nll_loss 1.54 | w2v_ctc_loss 1.105 | task_loss 1.567 | contrastive_loss 0.427 | total 6703.69 | n_correct 4269.28 | ppl 2.91 | accuracy 63.686 | wps 17186.8 | ups 0.88 | wpb 19422.7 | bsz 678.2 | num_updates 8329 | lr 0.00015496 | gnorm 0.51 | clip 0 | loss_scale 4 | train_wall 1236 | gb_free 12.7 | wall 8248
2023-08-26 14:38:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 14:38:23 | INFO | fairseq.trainer | begin training epoch 8
2023-08-26 14:38:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 14:39:44 | INFO | train_inner | epoch 008:     71 / 1191 loss=2.155, trans_loss=3.385, nll_loss=1.495, w2v_ctc_loss=1.053, task_loss=1.567, contrastive_loss=0.317, total=6731.47, n_correct=4377.54, ppl=2.82, accuracy=65.031, wps=12357.7, ups=0.63, wpb=19491.5, bsz=668.5, num_updates=8400, lr=0.000154303, gnorm=0.488, clip=0, loss_scale=4, train_wall=103, gb_free=12.8, wall=8329
2023-08-26 14:41:29 | INFO | train_inner | epoch 008:    171 / 1191 loss=2.175, trans_loss=3.374, nll_loss=1.486, w2v_ctc_loss=1.045, task_loss=1.501, contrastive_loss=0.465, total=6745.22, n_correct=4393.11, ppl=2.8, accuracy=65.129, wps=18642.6, ups=0.95, wpb=19562.8, bsz=714.9, num_updates=8500, lr=0.000153393, gnorm=0.491, clip=0, loss_scale=4, train_wall=104, gb_free=13.6, wall=8434
2023-08-26 14:43:14 | INFO | train_inner | epoch 008:    271 / 1191 loss=2.156, trans_loss=3.379, nll_loss=1.489, w2v_ctc_loss=1.045, task_loss=1.552, contrastive_loss=0.385, total=6743.26, n_correct=4391.63, ppl=2.81, accuracy=65.126, wps=18519.7, ups=0.95, wpb=19534.2, bsz=692.4, num_updates=8600, lr=0.000152499, gnorm=0.494, clip=0, loss_scale=4, train_wall=105, gb_free=13.2, wall=8540
2023-08-26 14:45:00 | INFO | train_inner | epoch 008:    371 / 1191 loss=2.141, trans_loss=3.383, nll_loss=1.496, w2v_ctc_loss=1.057, task_loss=1.708, contrastive_loss=0.302, total=6640.26, n_correct=4311.15, ppl=2.82, accuracy=64.924, wps=18192.5, ups=0.95, wpb=19250.5, bsz=638.1, num_updates=8700, lr=0.00015162, gnorm=0.484, clip=0, loss_scale=4, train_wall=105, gb_free=14, wall=8646
2023-08-26 14:46:45 | INFO | train_inner | epoch 008:    471 / 1191 loss=2.153, trans_loss=3.375, nll_loss=1.485, w2v_ctc_loss=1.049, task_loss=1.598, contrastive_loss=0.376, total=6667.27, n_correct=4345.97, ppl=2.8, accuracy=65.184, wps=18363.6, ups=0.95, wpb=19324, bsz=666.9, num_updates=8800, lr=0.000150756, gnorm=0.487, clip=0, loss_scale=4, train_wall=105, gb_free=13.6, wall=8751
2023-08-26 14:48:30 | INFO | train_inner | epoch 008:    571 / 1191 loss=2.129, trans_loss=3.374, nll_loss=1.484, w2v_ctc_loss=1.032, task_loss=1.624, contrastive_loss=0.372, total=6679.79, n_correct=4362.25, ppl=2.8, accuracy=65.305, wps=18546.8, ups=0.96, wpb=19355.8, bsz=670.5, num_updates=8900, lr=0.000149906, gnorm=0.482, clip=0, loss_scale=4, train_wall=104, gb_free=5.9, wall=8855
2023-08-26 14:50:12 | INFO | train_inner | epoch 008:    671 / 1191 loss=2.12, trans_loss=3.374, nll_loss=1.484, w2v_ctc_loss=1.036, task_loss=1.528, contrastive_loss=0.301, total=6737.47, n_correct=4405.18, ppl=2.8, accuracy=65.383, wps=19041.6, ups=0.98, wpb=19517.5, bsz=681, num_updates=9000, lr=0.000149071, gnorm=0.479, clip=0, loss_scale=4, train_wall=102, gb_free=13.2, wall=8958
2023-08-26 14:51:56 | INFO | train_inner | epoch 008:    771 / 1191 loss=2.135, trans_loss=3.374, nll_loss=1.485, w2v_ctc_loss=1.042, task_loss=1.608, contrastive_loss=0.38, total=6673.31, n_correct=4361.49, ppl=2.8, accuracy=65.357, wps=18561.1, ups=0.96, wpb=19339.7, bsz=668.2, num_updates=9100, lr=0.00014825, gnorm=0.508, clip=0, loss_scale=4, train_wall=104, gb_free=14.4, wall=9062
2023-08-26 14:53:41 | INFO | train_inner | epoch 008:    871 / 1191 loss=2.124, trans_loss=3.364, nll_loss=1.472, w2v_ctc_loss=1.04, task_loss=1.474, contrastive_loss=0.328, total=6790.6, n_correct=4465.23, ppl=2.77, accuracy=65.756, wps=18848.4, ups=0.96, wpb=19678.3, bsz=702.2, num_updates=9200, lr=0.000147442, gnorm=0.478, clip=0, loss_scale=8, train_wall=104, gb_free=12.2, wall=9166
2023-08-26 14:55:25 | INFO | train_inner | epoch 008:    971 / 1191 loss=2.14, trans_loss=3.375, nll_loss=1.484, w2v_ctc_loss=1.036, task_loss=1.617, contrastive_loss=0.418, total=6661.79, n_correct=4357.39, ppl=2.8, accuracy=65.409, wps=18499.6, ups=0.96, wpb=19289.7, bsz=661.6, num_updates=9300, lr=0.000146647, gnorm=0.478, clip=0, loss_scale=8, train_wall=104, gb_free=13, wall=9271
2023-08-26 14:57:09 | INFO | train_inner | epoch 008:   1071 / 1191 loss=2.104, trans_loss=3.367, nll_loss=1.472, w2v_ctc_loss=1.033, task_loss=1.6, contrastive_loss=0.279, total=6694.64, n_correct=4400.99, ppl=2.77, accuracy=65.739, wps=18609.5, ups=0.96, wpb=19369.6, bsz=664.5, num_updates=9400, lr=0.000145865, gnorm=0.484, clip=0, loss_scale=8, train_wall=103, gb_free=13.5, wall=9375
2023-08-26 14:58:52 | INFO | train_inner | epoch 008:   1171 / 1191 loss=2.131, trans_loss=3.356, nll_loss=1.463, w2v_ctc_loss=1.015, task_loss=1.437, contrastive_loss=0.472, total=6735.36, n_correct=4442.54, ppl=2.76, accuracy=65.958, wps=18919.9, ups=0.97, wpb=19521, bsz=722.2, num_updates=9500, lr=0.000145095, gnorm=0.48, clip=0, loss_scale=8, train_wall=102, gb_free=14.1, wall=9478
2023-08-26 14:59:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 14:59:45 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 3.904 | trans_loss 5.036 | nll_loss 2.296 | w2v_ctc_loss 1.226 | task_loss 8.416 | contrastive_loss 0.451 | total 6138.43 | n_correct 4193.86 | ppl 4.91 | accuracy 68.321 | uer 19.351 | wer 20.826 | raw_wer 20.826 | bleu 26.41 | wps 1769.9 | wpb 6138.4 | bsz 201.1 | num_updates 9520 | best_bleu 26.41
2023-08-26 14:59:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 9520 updates
2023-08-26 14:59:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 14:59:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 14:59:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 8 @ 9520 updates, score 26.41) (writing took 12.33011917899421 seconds)
2023-08-26 14:59:58 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-26 14:59:58 | INFO | train | epoch 008 | loss 2.137 | trans_loss 3.373 | nll_loss 1.482 | w2v_ctc_loss 1.039 | task_loss 1.569 | contrastive_loss 0.371 | total 6703.69 | n_correct 4383.25 | ppl 2.79 | accuracy 65.386 | wps 17860.6 | ups 0.92 | wpb 19422.7 | bsz 678.2 | num_updates 9520 | lr 0.000144943 | gnorm 0.486 | clip 0 | loss_scale 8 | train_wall 1235 | gb_free 14 | wall 9543
2023-08-26 14:59:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 14:59:58 | INFO | fairseq.trainer | begin training epoch 9
2023-08-26 14:59:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 15:01:28 | INFO | train_inner | epoch 009:     80 / 1191 loss=2.081, trans_loss=3.345, nll_loss=1.446, w2v_ctc_loss=0.994, task_loss=1.585, contrastive_loss=0.374, total=6668.28, n_correct=4423.53, ppl=2.72, accuracy=66.337, wps=12420.6, ups=0.64, wpb=19318.2, bsz=673.6, num_updates=9600, lr=0.000144338, gnorm=0.473, clip=0, loss_scale=8, train_wall=103, gb_free=12.8, wall=9633
2023-08-26 15:03:13 | INFO | train_inner | epoch 009:    180 / 1191 loss=2.063, trans_loss=3.335, nll_loss=1.436, w2v_ctc_loss=0.986, task_loss=1.537, contrastive_loss=0.344, total=6753.46, n_correct=4495.01, ppl=2.71, accuracy=66.559, wps=18667.1, ups=0.95, wpb=19576.2, bsz=689.9, num_updates=9700, lr=0.000143592, gnorm=0.473, clip=0, loss_scale=8, train_wall=104, gb_free=13.5, wall=9738
2023-08-26 15:04:56 | INFO | train_inner | epoch 009:    280 / 1191 loss=2.072, trans_loss=3.348, nll_loss=1.448, w2v_ctc_loss=1.006, task_loss=1.49, contrastive_loss=0.293, total=6804.86, n_correct=4519.26, ppl=2.73, accuracy=66.412, wps=19099.4, ups=0.97, wpb=19697, bsz=703.1, num_updates=9800, lr=0.000142857, gnorm=0.466, clip=0, loss_scale=8, train_wall=102, gb_free=13.2, wall=9841
2023-08-26 15:06:43 | INFO | train_inner | epoch 009:    380 / 1191 loss=2.066, trans_loss=3.343, nll_loss=1.444, w2v_ctc_loss=0.988, task_loss=1.544, contrastive_loss=0.348, total=6768.72, n_correct=4497.29, ppl=2.72, accuracy=66.442, wps=18386.3, ups=0.94, wpb=19612.6, bsz=695, num_updates=9900, lr=0.000142134, gnorm=0.466, clip=0, loss_scale=8, train_wall=106, gb_free=13.1, wall=9948
2023-08-26 15:08:28 | INFO | train_inner | epoch 009:    480 / 1191 loss=2.085, trans_loss=3.343, nll_loss=1.446, w2v_ctc_loss=1.002, task_loss=1.549, contrastive_loss=0.371, total=6709.01, n_correct=4460.5, ppl=2.72, accuracy=66.485, wps=18414.3, ups=0.95, wpb=19445.3, bsz=689.9, num_updates=10000, lr=0.000141421, gnorm=0.482, clip=0, loss_scale=8, train_wall=105, gb_free=13.8, wall=10054
2023-08-26 15:08:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 15:09:02 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 3.905 | trans_loss 5.033 | nll_loss 2.292 | w2v_ctc_loss 1.243 | task_loss 8.468 | contrastive_loss 0.445 | total 6138.43 | n_correct 4199.14 | ppl 4.9 | accuracy 68.407 | uer 18.846 | wer 20.033 | raw_wer 20.033 | bleu 26.2 | wps 1674.7 | wpb 6138.4 | bsz 201.1 | num_updates 10000 | best_bleu 26.41
2023-08-26 15:09:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 10000 updates
2023-08-26 15:09:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_9_10000.pt
2023-08-26 15:09:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_9_10000.pt
2023-08-26 15:09:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_9_10000.pt (epoch 9 @ 10000 updates, score 26.2) (writing took 6.966043345993967 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:0')
2023-08-26 15:10:52 | INFO | train_inner | epoch 009:    580 / 1191 loss=2.045, trans_loss=3.337, nll_loss=1.436, w2v_ctc_loss=0.985, task_loss=1.606, contrastive_loss=0.285, total=6631.73, n_correct=4418.97, ppl=2.71, accuracy=66.634, wps=13365.9, ups=0.7, wpb=19212.5, bsz=663.9, num_updates=10100, lr=0.00014072, gnorm=0.365, clip=0, loss_scale=8, train_wall=103, gb_free=14.1, wall=10197
2023-08-26 15:12:36 | INFO | train_inner | epoch 009:    680 / 1191 loss=2.068, trans_loss=3.347, nll_loss=1.449, w2v_ctc_loss=0.997, task_loss=1.745, contrastive_loss=0.36, total=6557.22, n_correct=4348.02, ppl=2.73, accuracy=66.309, wps=18289.5, ups=0.96, wpb=18991.2, bsz=622.7, num_updates=10200, lr=0.000140028, gnorm=0.366, clip=0, loss_scale=8, train_wall=103, gb_free=13.8, wall=10301
2023-08-26 15:14:20 | INFO | train_inner | epoch 009:    780 / 1191 loss=2.078, trans_loss=3.342, nll_loss=1.445, w2v_ctc_loss=0.99, task_loss=1.55, contrastive_loss=0.389, total=6702.82, n_correct=4455.9, ppl=2.72, accuracy=66.478, wps=18645.8, ups=0.96, wpb=19425.6, bsz=689.1, num_updates=10300, lr=0.000139347, gnorm=0.369, clip=0, loss_scale=8, train_wall=103, gb_free=9.9, wall=10405
2023-08-26 15:14:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-26 15:16:05 | INFO | train_inner | epoch 009:    881 / 1191 loss=2.047, trans_loss=3.34, nll_loss=1.441, w2v_ctc_loss=0.991, task_loss=1.585, contrastive_loss=0.28, total=6721.18, n_correct=4476.17, ppl=2.72, accuracy=66.598, wps=18538.7, ups=0.95, wpb=19477.4, bsz=665.1, num_updates=10400, lr=0.000138675, gnorm=0.361, clip=0, loss_scale=4, train_wall=104, gb_free=11.2, wall=10511
2023-08-26 15:17:50 | INFO | train_inner | epoch 009:    981 / 1191 loss=2.06, trans_loss=3.337, nll_loss=1.437, w2v_ctc_loss=0.987, task_loss=1.554, contrastive_loss=0.348, total=6714.94, n_correct=4480, ppl=2.71, accuracy=66.717, wps=18470.4, ups=0.95, wpb=19450.9, bsz=685.3, num_updates=10500, lr=0.000138013, gnorm=0.369, clip=0, loss_scale=4, train_wall=105, gb_free=13.9, wall=10616
2023-08-26 15:19:35 | INFO | train_inner | epoch 009:   1081 / 1191 loss=2.067, trans_loss=3.336, nll_loss=1.437, w2v_ctc_loss=0.986, task_loss=1.546, contrastive_loss=0.402, total=6671.51, n_correct=4454.33, ppl=2.71, accuracy=66.766, wps=18520.6, ups=0.96, wpb=19335.8, bsz=678.8, num_updates=10600, lr=0.000137361, gnorm=0.363, clip=0, loss_scale=4, train_wall=104, gb_free=14.2, wall=10720
2023-08-26 15:21:19 | INFO | train_inner | epoch 009:   1181 / 1191 loss=2.054, trans_loss=3.336, nll_loss=1.437, w2v_ctc_loss=1.002, task_loss=1.646, contrastive_loss=0.273, total=6674.07, n_correct=4449.52, ppl=2.71, accuracy=66.669, wps=18529.8, ups=0.96, wpb=19339.3, bsz=655, num_updates=10700, lr=0.000136717, gnorm=0.362, clip=0, loss_scale=4, train_wall=104, gb_free=14.4, wall=10825
2023-08-26 15:21:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:4')
2023-08-26 15:22:02 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 3.872 | trans_loss 5.004 | nll_loss 2.25 | w2v_ctc_loss 1.216 | task_loss 8.432 | contrastive_loss 0.432 | total 6138.43 | n_correct 4233.14 | ppl 4.76 | accuracy 68.961 | uer 18.985 | wer 20.509 | raw_wer 20.509 | bleu 26.74 | wps 1767.3 | wpb 6138.4 | bsz 201.1 | num_updates 10710 | best_bleu 26.74
2023-08-26 15:22:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 10710 updates
2023-08-26 15:22:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 15:22:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 15:22:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 9 @ 10710 updates, score 26.74) (writing took 11.936129656998673 seconds)
2023-08-26 15:22:15 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-26 15:22:15 | INFO | train | epoch 009 | loss 2.064 | trans_loss 3.34 | nll_loss 1.441 | w2v_ctc_loss 0.992 | task_loss 1.568 | contrastive_loss 0.337 | total 6704.49 | n_correct 4462.09 | ppl 2.72 | accuracy 66.554 | wps 17291.5 | ups 0.89 | wpb 19425 | bsz 678.5 | num_updates 10710 | lr 0.000136653 | gnorm 0.408 | clip 0 | loss_scale 4 | train_wall 1235 | gb_free 14.3 | wall 10880
2023-08-26 15:22:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 15:22:15 | INFO | fairseq.trainer | begin training epoch 10
2023-08-26 15:22:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 15:23:55 | INFO | train_inner | epoch 010:     90 / 1191 loss=2.007, trans_loss=3.312, nll_loss=1.406, w2v_ctc_loss=0.954, task_loss=1.568, contrastive_loss=0.276, total=6665.56, n_correct=4497.08, ppl=2.65, accuracy=67.467, wps=12426.1, ups=0.64, wpb=19313.2, bsz=674, num_updates=10800, lr=0.000136083, gnorm=0.389, clip=0, loss_scale=4, train_wall=103, gb_free=14.1, wall=10980
2023-08-26 15:25:38 | INFO | train_inner | epoch 010:    190 / 1191 loss=2.022, trans_loss=3.323, nll_loss=1.42, w2v_ctc_loss=0.962, task_loss=1.581, contrastive_loss=0.312, total=6676.4, n_correct=4486.83, ppl=2.68, accuracy=67.204, wps=18673.2, ups=0.97, wpb=19344, bsz=679, num_updates=10900, lr=0.000135457, gnorm=0.361, clip=0, loss_scale=4, train_wall=103, gb_free=10.5, wall=11084
2023-08-26 15:27:23 | INFO | train_inner | epoch 010:    290 / 1191 loss=2.023, trans_loss=3.313, nll_loss=1.406, w2v_ctc_loss=0.954, task_loss=1.544, contrastive_loss=0.366, total=6758.29, n_correct=4557.98, ppl=2.65, accuracy=67.443, wps=18685.3, ups=0.95, wpb=19575, bsz=688, num_updates=11000, lr=0.00013484, gnorm=0.357, clip=0, loss_scale=4, train_wall=104, gb_free=13.9, wall=11188
2023-08-26 15:29:08 | INFO | train_inner | epoch 010:    390 / 1191 loss=2.055, trans_loss=3.319, nll_loss=1.415, w2v_ctc_loss=0.965, task_loss=1.446, contrastive_loss=0.442, total=6837.98, n_correct=4600.08, ppl=2.67, accuracy=67.272, wps=18853.6, ups=0.95, wpb=19812.8, bsz=733.7, num_updates=11100, lr=0.000134231, gnorm=0.361, clip=0, loss_scale=4, train_wall=104, gb_free=12.8, wall=11294
2023-08-26 15:30:53 | INFO | train_inner | epoch 010:    490 / 1191 loss=2.011, trans_loss=3.313, nll_loss=1.405, w2v_ctc_loss=0.972, task_loss=1.581, contrastive_loss=0.242, total=6733.09, n_correct=4544.13, ppl=2.65, accuracy=67.49, wps=18655.9, ups=0.96, wpb=19496.6, bsz=671.5, num_updates=11200, lr=0.000133631, gnorm=0.357, clip=0, loss_scale=4, train_wall=104, gb_free=13.4, wall=11398
2023-08-26 15:32:36 | INFO | train_inner | epoch 010:    590 / 1191 loss=2.018, trans_loss=3.32, nll_loss=1.415, w2v_ctc_loss=0.959, task_loss=1.583, contrastive_loss=0.323, total=6703.25, n_correct=4511.7, ppl=2.67, accuracy=67.306, wps=18848.9, ups=0.97, wpb=19415.2, bsz=668.5, num_updates=11300, lr=0.000133038, gnorm=0.357, clip=0, loss_scale=4, train_wall=102, gb_free=11.2, wall=11501
2023-08-26 15:34:21 | INFO | train_inner | epoch 010:    690 / 1191 loss=2.023, trans_loss=3.316, nll_loss=1.412, w2v_ctc_loss=0.964, task_loss=1.539, contrastive_loss=0.319, total=6753.28, n_correct=4550.3, ppl=2.66, accuracy=67.379, wps=18598.3, ups=0.95, wpb=19568.5, bsz=694.1, num_updates=11400, lr=0.000132453, gnorm=0.357, clip=0, loss_scale=4, train_wall=104, gb_free=12.4, wall=11606
2023-08-26 15:36:05 | INFO | train_inner | epoch 010:    790 / 1191 loss=1.993, trans_loss=3.313, nll_loss=1.408, w2v_ctc_loss=0.959, task_loss=1.661, contrastive_loss=0.232, total=6644.44, n_correct=4483.98, ppl=2.65, accuracy=67.485, wps=18448.5, ups=0.96, wpb=19257.5, bsz=653.5, num_updates=11500, lr=0.000131876, gnorm=0.357, clip=0, loss_scale=4, train_wall=104, gb_free=12.5, wall=11711
2023-08-26 15:37:51 | INFO | train_inner | epoch 010:    890 / 1191 loss=2.017, trans_loss=3.312, nll_loss=1.407, w2v_ctc_loss=0.966, task_loss=1.682, contrastive_loss=0.319, total=6555.79, n_correct=4420.88, ppl=2.65, accuracy=67.435, wps=17987.3, ups=0.95, wpb=18998.8, bsz=643.2, num_updates=11600, lr=0.000131306, gnorm=0.361, clip=0, loss_scale=4, train_wall=105, gb_free=14.3, wall=11816
2023-08-26 15:39:35 | INFO | train_inner | epoch 010:    990 / 1191 loss=1.999, trans_loss=3.308, nll_loss=1.402, w2v_ctc_loss=0.956, task_loss=1.513, contrastive_loss=0.266, total=6744.7, n_correct=4562.9, ppl=2.64, accuracy=67.652, wps=18847.3, ups=0.96, wpb=19542, bsz=685, num_updates=11700, lr=0.000130744, gnorm=0.353, clip=0, loss_scale=4, train_wall=103, gb_free=12.6, wall=11920
2023-08-26 15:41:19 | INFO | train_inner | epoch 010:   1090 / 1191 loss=2.006, trans_loss=3.306, nll_loss=1.401, w2v_ctc_loss=0.967, task_loss=1.574, contrastive_loss=0.26, total=6678.1, n_correct=4515.02, ppl=2.64, accuracy=67.609, wps=18554.2, ups=0.96, wpb=19361.2, bsz=671.9, num_updates=11800, lr=0.000130189, gnorm=0.356, clip=0, loss_scale=4, train_wall=104, gb_free=14.7, wall=12024
2023-08-26 15:43:04 | INFO | train_inner | epoch 010:   1190 / 1191 loss=2.032, trans_loss=3.312, nll_loss=1.406, w2v_ctc_loss=0.953, task_loss=1.54, contrastive_loss=0.442, total=6723, n_correct=4534.79, ppl=2.65, accuracy=67.452, wps=18592.5, ups=0.95, wpb=19474.7, bsz=687.8, num_updates=11900, lr=0.000129641, gnorm=0.36, clip=0, loss_scale=4, train_wall=104, gb_free=10.3, wall=12129
2023-08-26 15:43:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 15:43:38 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 3.825 | trans_loss 4.964 | nll_loss 2.204 | w2v_ctc_loss 1.17 | task_loss 8.523 | contrastive_loss 0.412 | total 6138.43 | n_correct 4267.29 | ppl 4.61 | accuracy 69.518 | uer 18.474 | wer 19.926 | raw_wer 19.926 | bleu 27.33 | wps 1659 | wpb 6138.4 | bsz 201.1 | num_updates 11901 | best_bleu 27.33
2023-08-26 15:43:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 11901 updates
2023-08-26 15:43:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 15:43:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 15:43:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 10 @ 11901 updates, score 27.33) (writing took 11.673018537003372 seconds)
2023-08-26 15:43:50 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-26 15:43:50 | INFO | train | epoch 010 | loss 2.017 | trans_loss 3.314 | nll_loss 1.409 | w2v_ctc_loss 0.961 | task_loss 1.569 | contrastive_loss 0.318 | total 6703.69 | n_correct 4520.46 | ppl 2.65 | accuracy 67.432 | wps 17851.6 | ups 0.92 | wpb 19422.7 | bsz 678.2 | num_updates 11901 | lr 0.000129635 | gnorm 0.361 | clip 0 | loss_scale 4 | train_wall 1234 | gb_free 12.1 | wall 12176
2023-08-26 15:43:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 15:43:51 | INFO | fairseq.trainer | begin training epoch 11
2023-08-26 15:43:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 15:45:42 | INFO | train_inner | epoch 011:     99 / 1191 loss=1.983, trans_loss=3.294, nll_loss=1.384, w2v_ctc_loss=0.943, task_loss=1.672, contrastive_loss=0.284, total=6625.08, n_correct=4505.09, ppl=2.61, accuracy=68.001, wps=12136.1, ups=0.63, wpb=19200.5, bsz=646.3, num_updates=12000, lr=0.000129099, gnorm=0.355, clip=0, loss_scale=4, train_wall=104, gb_free=12.1, wall=12287
2023-08-26 15:45:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 15:46:14 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 3.841 | trans_loss 4.971 | nll_loss 2.209 | w2v_ctc_loss 1.208 | task_loss 8.553 | contrastive_loss 0.416 | total 6138.43 | n_correct 4264.43 | ppl 4.62 | accuracy 69.471 | uer 18.503 | wer 19.963 | raw_wer 19.963 | bleu 27.25 | wps 1757.8 | wpb 6138.4 | bsz 201.1 | num_updates 12000 | best_bleu 27.33
2023-08-26 15:46:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 12000 updates
2023-08-26 15:46:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_11_12000.pt
2023-08-26 15:46:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_11_12000.pt
2023-08-26 15:46:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_11_12000.pt (epoch 11 @ 12000 updates, score 27.25) (writing took 7.0815002899980755 seconds)
2023-08-26 15:48:05 | INFO | train_inner | epoch 011:    199 / 1191 loss=1.978, trans_loss=3.296, nll_loss=1.385, w2v_ctc_loss=0.921, task_loss=1.532, contrastive_loss=0.344, total=6714.24, n_correct=4573.02, ppl=2.61, accuracy=68.109, wps=13561.8, ups=0.7, wpb=19444, bsz=690.5, num_updates=12100, lr=0.000128565, gnorm=0.349, clip=0, loss_scale=4, train_wall=103, gb_free=4.7, wall=12431
2023-08-26 15:49:49 | INFO | train_inner | epoch 011:    299 / 1191 loss=1.979, trans_loss=3.292, nll_loss=1.381, w2v_ctc_loss=0.929, task_loss=1.58, contrastive_loss=0.328, total=6621.56, n_correct=4511.11, ppl=2.6, accuracy=68.128, wps=18416.8, ups=0.96, wpb=19185.3, bsz=672.4, num_updates=12200, lr=0.000128037, gnorm=0.356, clip=0, loss_scale=4, train_wall=103, gb_free=10, wall=12535
2023-08-26 15:51:33 | INFO | train_inner | epoch 011:    399 / 1191 loss=1.978, trans_loss=3.291, nll_loss=1.381, w2v_ctc_loss=0.93, task_loss=1.637, contrastive_loss=0.335, total=6581.25, n_correct=4480.65, ppl=2.6, accuracy=68.082, wps=18373, ups=0.96, wpb=19076.8, bsz=656.9, num_updates=12300, lr=0.000127515, gnorm=0.351, clip=0, loss_scale=4, train_wall=103, gb_free=12, wall=12639
2023-08-26 15:53:18 | INFO | train_inner | epoch 011:    499 / 1191 loss=1.971, trans_loss=3.296, nll_loss=1.388, w2v_ctc_loss=0.942, task_loss=1.656, contrastive_loss=0.231, total=6670.13, n_correct=4538.34, ppl=2.62, accuracy=68.04, wps=18387.2, ups=0.95, wpb=19333.3, bsz=653.5, num_updates=12400, lr=0.000127, gnorm=0.349, clip=0, loss_scale=8, train_wall=104, gb_free=14.8, wall=12744
2023-08-26 15:55:02 | INFO | train_inner | epoch 011:    599 / 1191 loss=1.966, trans_loss=3.292, nll_loss=1.385, w2v_ctc_loss=0.94, task_loss=1.591, contrastive_loss=0.227, total=6647.53, n_correct=4519.56, ppl=2.61, accuracy=67.989, wps=18674.5, ups=0.97, wpb=19280.2, bsz=669, num_updates=12500, lr=0.000126491, gnorm=0.35, clip=0, loss_scale=8, train_wall=103, gb_free=12.2, wall=12847
2023-08-26 15:56:46 | INFO | train_inner | epoch 011:    699 / 1191 loss=1.968, trans_loss=3.289, nll_loss=1.379, w2v_ctc_loss=0.93, task_loss=1.655, contrastive_loss=0.272, total=6670.92, n_correct=4546.59, ppl=2.6, accuracy=68.155, wps=18456, ups=0.95, wpb=19341.9, bsz=658.6, num_updates=12600, lr=0.000125988, gnorm=0.354, clip=0, loss_scale=8, train_wall=104, gb_free=13.8, wall=12952
2023-08-26 15:58:31 | INFO | train_inner | epoch 011:    799 / 1191 loss=1.992, trans_loss=3.297, nll_loss=1.388, w2v_ctc_loss=0.944, task_loss=1.516, contrastive_loss=0.304, total=6805.86, n_correct=4627.4, ppl=2.62, accuracy=67.991, wps=18927.6, ups=0.96, wpb=19717.6, bsz=708.8, num_updates=12700, lr=0.000125491, gnorm=0.347, clip=0, loss_scale=8, train_wall=103, gb_free=14.2, wall=13056
2023-08-26 16:00:15 | INFO | train_inner | epoch 011:    899 / 1191 loss=1.967, trans_loss=3.298, nll_loss=1.387, w2v_ctc_loss=0.921, task_loss=1.551, contrastive_loss=0.281, total=6772.2, n_correct=4611.02, ppl=2.62, accuracy=68.087, wps=18715.8, ups=0.95, wpb=19604.9, bsz=678.5, num_updates=12800, lr=0.000125, gnorm=0.348, clip=0, loss_scale=8, train_wall=104, gb_free=12.5, wall=13161
2023-08-26 16:02:00 | INFO | train_inner | epoch 011:    999 / 1191 loss=1.975, trans_loss=3.291, nll_loss=1.378, w2v_ctc_loss=0.912, task_loss=1.472, contrastive_loss=0.363, total=6790.09, n_correct=4642.2, ppl=2.6, accuracy=68.367, wps=18775.5, ups=0.96, wpb=19658.4, bsz=709.9, num_updates=12900, lr=0.000124515, gnorm=0.347, clip=0, loss_scale=8, train_wall=104, gb_free=10.8, wall=13265
2023-08-26 16:03:44 | INFO | train_inner | epoch 011:   1099 / 1191 loss=1.987, trans_loss=3.29, nll_loss=1.379, w2v_ctc_loss=0.928, task_loss=1.491, contrastive_loss=0.38, total=6750.83, n_correct=4607.84, ppl=2.6, accuracy=68.256, wps=18815.4, ups=0.96, wpb=19560.1, bsz=699.2, num_updates=13000, lr=0.000124035, gnorm=0.349, clip=0, loss_scale=8, train_wall=103, gb_free=15.3, wall=13369
2023-08-26 16:05:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 16:05:53 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 3.825 | trans_loss 4.945 | nll_loss 2.178 | w2v_ctc_loss 1.226 | task_loss 8.558 | contrastive_loss 0.401 | total 6138.43 | n_correct 4288.71 | ppl 4.53 | accuracy 69.867 | uer 18.209 | wer 19.732 | raw_wer 19.732 | bleu 27.83 | wps 1670.4 | wpb 6138.4 | bsz 201.1 | num_updates 13092 | best_bleu 27.83
2023-08-26 16:05:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 13092 updates
2023-08-26 16:05:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 16:06:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 16:06:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 11 @ 13092 updates, score 27.83) (writing took 11.614662977997796 seconds)
2023-08-26 16:06:06 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-26 16:06:06 | INFO | train | epoch 011 | loss 1.976 | trans_loss 3.294 | nll_loss 1.383 | w2v_ctc_loss 0.931 | task_loss 1.57 | contrastive_loss 0.303 | total 6703.69 | n_correct 4566.26 | ppl 2.61 | accuracy 68.116 | wps 17324.5 | ups 0.89 | wpb 19422.7 | bsz 678.2 | num_updates 13092 | lr 0.000123598 | gnorm 0.35 | clip 0 | loss_scale 8 | train_wall 1234 | gb_free 13.2 | wall 13511
2023-08-26 16:06:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 16:06:06 | INFO | fairseq.trainer | begin training epoch 12
2023-08-26 16:06:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 16:06:22 | INFO | train_inner | epoch 012:      8 / 1191 loss=1.966, trans_loss=3.293, nll_loss=1.381, w2v_ctc_loss=0.924, task_loss=1.449, contrastive_loss=0.277, total=6828.68, n_correct=4663.27, ppl=2.6, accuracy=68.289, wps=12535.3, ups=0.63, wpb=19765.9, bsz=719.4, num_updates=13100, lr=0.00012356, gnorm=0.345, clip=0, loss_scale=8, train_wall=104, gb_free=13.2, wall=13527
2023-08-26 16:08:06 | INFO | train_inner | epoch 012:    108 / 1191 loss=1.922, trans_loss=3.271, nll_loss=1.354, w2v_ctc_loss=0.901, task_loss=1.603, contrastive_loss=0.221, total=6717.99, n_correct=4627.16, ppl=2.56, accuracy=68.877, wps=18641.6, ups=0.96, wpb=19465, bsz=662.1, num_updates=13200, lr=0.000123091, gnorm=0.343, clip=0, loss_scale=8, train_wall=104, gb_free=15, wall=13632
2023-08-26 16:09:50 | INFO | train_inner | epoch 012:    208 / 1191 loss=1.947, trans_loss=3.281, nll_loss=1.367, w2v_ctc_loss=0.907, task_loss=1.576, contrastive_loss=0.294, total=6735.23, n_correct=4617.81, ppl=2.58, accuracy=68.562, wps=18790.4, ups=0.96, wpb=19511.3, bsz=672.6, num_updates=13300, lr=0.000122628, gnorm=0.344, clip=0, loss_scale=8, train_wall=103, gb_free=10.1, wall=13735
2023-08-26 16:11:34 | INFO | train_inner | epoch 012:    308 / 1191 loss=1.957, trans_loss=3.278, nll_loss=1.364, w2v_ctc_loss=0.904, task_loss=1.532, contrastive_loss=0.354, total=6698.76, n_correct=4597.17, ppl=2.57, accuracy=68.627, wps=18583.1, ups=0.96, wpb=19416.8, bsz=689.3, num_updates=13400, lr=0.000122169, gnorm=0.341, clip=0, loss_scale=8, train_wall=104, gb_free=11.8, wall=13840
2023-08-26 16:13:19 | INFO | train_inner | epoch 012:    408 / 1191 loss=1.941, trans_loss=3.276, nll_loss=1.361, w2v_ctc_loss=0.892, task_loss=1.451, contrastive_loss=0.325, total=6779.09, n_correct=4657.28, ppl=2.57, accuracy=68.701, wps=18783.1, ups=0.96, wpb=19640, bsz=710.1, num_updates=13500, lr=0.000121716, gnorm=0.346, clip=0, loss_scale=8, train_wall=104, gb_free=14.8, wall=13944
2023-08-26 16:15:03 | INFO | train_inner | epoch 012:    508 / 1191 loss=1.925, trans_loss=3.275, nll_loss=1.36, w2v_ctc_loss=0.896, task_loss=1.528, contrastive_loss=0.228, total=6728.99, n_correct=4633.13, ppl=2.57, accuracy=68.853, wps=18828.7, ups=0.97, wpb=19492.1, bsz=684.5, num_updates=13600, lr=0.000121268, gnorm=0.348, clip=0, loss_scale=8, train_wall=103, gb_free=13.3, wall=14048
2023-08-26 16:16:47 | INFO | train_inner | epoch 012:    608 / 1191 loss=1.955, trans_loss=3.277, nll_loss=1.362, w2v_ctc_loss=0.911, task_loss=1.605, contrastive_loss=0.315, total=6729.55, n_correct=4617.7, ppl=2.57, accuracy=68.618, wps=18678, ups=0.96, wpb=19495.9, bsz=680.6, num_updates=13700, lr=0.000120824, gnorm=0.349, clip=0, loss_scale=8, train_wall=104, gb_free=13.6, wall=14152
2023-08-26 16:18:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-26 16:18:32 | INFO | train_inner | epoch 012:    709 / 1191 loss=1.954, trans_loss=3.267, nll_loss=1.353, w2v_ctc_loss=0.903, task_loss=1.518, contrastive_loss=0.373, total=6739.34, n_correct=4636.41, ppl=2.55, accuracy=68.796, wps=18523.3, ups=0.95, wpb=19546.5, bsz=690.4, num_updates=13800, lr=0.000120386, gnorm=0.345, clip=0, loss_scale=4, train_wall=105, gb_free=14.5, wall=14258
2023-08-26 16:20:17 | INFO | train_inner | epoch 012:    809 / 1191 loss=1.948, trans_loss=3.282, nll_loss=1.368, w2v_ctc_loss=0.913, task_loss=1.618, contrastive_loss=0.273, total=6657.26, n_correct=4566.6, ppl=2.58, accuracy=68.596, wps=18416.1, ups=0.96, wpb=19276.8, bsz=664.5, num_updates=13900, lr=0.000119952, gnorm=0.347, clip=0, loss_scale=4, train_wall=104, gb_free=12.8, wall=14363
2023-08-26 16:22:02 | INFO | train_inner | epoch 012:    909 / 1191 loss=1.952, trans_loss=3.284, nll_loss=1.371, w2v_ctc_loss=0.91, task_loss=1.647, contrastive_loss=0.302, total=6682.47, n_correct=4579.31, ppl=2.59, accuracy=68.527, wps=18421.4, ups=0.95, wpb=19355.4, bsz=664.6, num_updates=14000, lr=0.000119523, gnorm=0.343, clip=0, loss_scale=4, train_wall=104, gb_free=14.5, wall=14468
2023-08-26 16:22:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 16:22:35 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 3.812 | trans_loss 4.933 | nll_loss 2.163 | w2v_ctc_loss 1.215 | task_loss 8.507 | contrastive_loss 0.395 | total 6138.43 | n_correct 4296 | ppl 4.48 | accuracy 69.985 | uer 18.057 | wer 19.517 | raw_wer 19.517 | bleu 27.87 | wps 1711.3 | wpb 6138.4 | bsz 201.1 | num_updates 14000 | best_bleu 27.87
2023-08-26 16:22:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 14000 updates
2023-08-26 16:22:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_12_14000.pt
2023-08-26 16:22:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_12_14000.pt
2023-08-26 16:22:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_12_14000.pt (epoch 12 @ 14000 updates, score 27.87) (writing took 14.958056018003845 seconds)
2023-08-26 16:24:34 | INFO | train_inner | epoch 012:   1009 / 1191 loss=1.945, trans_loss=3.276, nll_loss=1.363, w2v_ctc_loss=0.918, task_loss=1.629, contrastive_loss=0.259, total=6594.83, n_correct=4526.39, ppl=2.57, accuracy=68.635, wps=12614.1, ups=0.66, wpb=19122.7, bsz=659.6, num_updates=14100, lr=0.000119098, gnorm=0.345, clip=0, loss_scale=4, train_wall=102, gb_free=11.2, wall=14619
2023-08-26 16:26:19 | INFO | train_inner | epoch 012:   1109 / 1191 loss=1.946, trans_loss=3.278, nll_loss=1.363, w2v_ctc_loss=0.904, task_loss=1.614, contrastive_loss=0.318, total=6645.96, n_correct=4565.93, ppl=2.57, accuracy=68.702, wps=18307.5, ups=0.95, wpb=19250.5, bsz=671.2, num_updates=14200, lr=0.000118678, gnorm=0.345, clip=0, loss_scale=4, train_wall=104, gb_free=14, wall=14724
2023-08-26 16:27:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 16:28:17 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 3.798 | trans_loss 4.928 | nll_loss 2.158 | w2v_ctc_loss 1.174 | task_loss 8.521 | contrastive_loss 0.401 | total 6138.43 | n_correct 4308.29 | ppl 4.46 | accuracy 70.185 | uer 17.977 | wer 19.498 | raw_wer 19.498 | bleu 27.76 | wps 1761.1 | wpb 6138.4 | bsz 201.1 | num_updates 14282 | best_bleu 27.87
2023-08-26 16:28:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 14282 updates
2023-08-26 16:28:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.7601.pt
2023-08-26 16:28:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.7601.pt
2023-08-26 16:28:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.7601.pt (epoch 12 @ 14282 updates, score 27.76) (writing took 6.854619466001168 seconds)
2023-08-26 16:28:24 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-26 16:28:24 | INFO | train | epoch 012 | loss 1.944 | trans_loss 3.277 | nll_loss 1.362 | w2v_ctc_loss 0.905 | task_loss 1.57 | contrastive_loss 0.292 | total 6703.08 | n_correct 4604.78 | ppl 2.57 | accuracy 68.696 | wps 17262.5 | ups 0.89 | wpb 19420.9 | bsz 678.2 | num_updates 14282 | lr 0.000118337 | gnorm 0.345 | clip 0 | loss_scale 4 | train_wall 1235 | gb_free 14.1 | wall 14850
2023-08-26 16:28:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 16:28:25 | INFO | fairseq.trainer | begin training epoch 13
2023-08-26 16:28:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 16:28:51 | INFO | train_inner | epoch 013:     18 / 1191 loss=1.929, trans_loss=3.273, nll_loss=1.356, w2v_ctc_loss=0.905, task_loss=1.588, contrastive_loss=0.234, total=6698, n_correct=4617.84, ppl=2.56, accuracy=68.944, wps=12743.1, ups=0.66, wpb=19397.3, bsz=670.3, num_updates=14300, lr=0.000118262, gnorm=0.343, clip=0, loss_scale=4, train_wall=104, gb_free=14.6, wall=14877
2023-08-26 16:30:36 | INFO | train_inner | epoch 013:    118 / 1191 loss=1.914, trans_loss=3.256, nll_loss=1.336, w2v_ctc_loss=0.881, task_loss=1.641, contrastive_loss=0.294, total=6709.65, n_correct=4649.55, ppl=2.52, accuracy=69.296, wps=18561.1, ups=0.95, wpb=19443.1, bsz=663.7, num_updates=14400, lr=0.000117851, gnorm=0.339, clip=0, loss_scale=4, train_wall=104, gb_free=13.7, wall=14981
2023-08-26 16:32:21 | INFO | train_inner | epoch 013:    218 / 1191 loss=1.92, trans_loss=3.265, nll_loss=1.346, w2v_ctc_loss=0.875, task_loss=1.562, contrastive_loss=0.328, total=6634.36, n_correct=4588.78, ppl=2.54, accuracy=69.167, wps=18292, ups=0.95, wpb=19219.2, bsz=685.4, num_updates=14500, lr=0.000117444, gnorm=0.339, clip=0, loss_scale=4, train_wall=104, gb_free=8.9, wall=15086
2023-08-26 16:34:05 | INFO | train_inner | epoch 013:    318 / 1191 loss=1.935, trans_loss=3.26, nll_loss=1.34, w2v_ctc_loss=0.863, task_loss=1.437, contrastive_loss=0.424, total=6756.89, n_correct=4681.7, ppl=2.53, accuracy=69.288, wps=18801, ups=0.96, wpb=19575.5, bsz=725.8, num_updates=14600, lr=0.000117041, gnorm=0.34, clip=0, loss_scale=4, train_wall=104, gb_free=14.3, wall=15191
2023-08-26 16:35:49 | INFO | train_inner | epoch 013:    418 / 1191 loss=1.904, trans_loss=3.264, nll_loss=1.347, w2v_ctc_loss=0.886, task_loss=1.584, contrastive_loss=0.206, total=6728.3, n_correct=4647.06, ppl=2.54, accuracy=69.067, wps=18733.4, ups=0.96, wpb=19499.4, bsz=668.6, num_updates=14700, lr=0.000116642, gnorm=0.341, clip=0, loss_scale=4, train_wall=103, gb_free=11.8, wall=15295
2023-08-26 16:37:34 | INFO | train_inner | epoch 013:    518 / 1191 loss=1.927, trans_loss=3.266, nll_loss=1.349, w2v_ctc_loss=0.887, task_loss=1.665, contrastive_loss=0.314, total=6643.94, n_correct=4582.98, ppl=2.55, accuracy=68.98, wps=18368.5, ups=0.95, wpb=19250.8, bsz=658.8, num_updates=14800, lr=0.000116248, gnorm=0.351, clip=0, loss_scale=4, train_wall=104, gb_free=13.7, wall=15399
2023-08-26 16:39:18 | INFO | train_inner | epoch 013:    618 / 1191 loss=1.917, trans_loss=3.266, nll_loss=1.348, w2v_ctc_loss=0.892, task_loss=1.609, contrastive_loss=0.258, total=6707.95, n_correct=4629.54, ppl=2.54, accuracy=69.016, wps=18653.4, ups=0.96, wpb=19431.4, bsz=655.6, num_updates=14900, lr=0.000115857, gnorm=0.341, clip=0, loss_scale=4, train_wall=104, gb_free=13.9, wall=15504
2023-08-26 16:41:03 | INFO | train_inner | epoch 013:    718 / 1191 loss=1.911, trans_loss=3.263, nll_loss=1.345, w2v_ctc_loss=0.885, task_loss=1.647, contrastive_loss=0.25, total=6637.65, n_correct=4592.33, ppl=2.54, accuracy=69.186, wps=18285.3, ups=0.95, wpb=19228.5, bsz=658.4, num_updates=15000, lr=0.00011547, gnorm=0.342, clip=0, loss_scale=4, train_wall=105, gb_free=11, wall=15609
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:0')
2023-08-26 16:42:17 | INFO | train_inner | epoch 013:    818 / 1191 loss=1.932, trans_loss=4.708, nll_loss=1.944, w2v_ctc_loss=0.642, task_loss=2.26, contrastive_loss=0.182, total=6769.34, n_correct=4671.83, ppl=3.85, accuracy=69.015, wps=18518.1, ups=1.36, wpb=13606, bsz=463.3, num_updates=15100, lr=0.000115087, gnorm=0.438, clip=0, loss_scale=4, train_wall=73, gb_free=13.6, wall=15682
2023-08-26 16:43:29 | INFO | train_inner | epoch 013:    918 / 1191 loss=1.942, trans_loss=4.731, nll_loss=1.953, w2v_ctc_loss=0.658, task_loss=2.613, contrastive_loss=0.184, total=6556.47, n_correct=4517.92, ppl=3.87, accuracy=68.908, wps=18225.6, ups=1.39, wpb=13112.9, bsz=420.7, num_updates=15200, lr=0.000114708, gnorm=0.454, clip=0, loss_scale=4, train_wall=71, gb_free=14.3, wall=15754
2023-08-26 16:44:42 | INFO | train_inner | epoch 013:   1018 / 1191 loss=1.924, trans_loss=4.723, nll_loss=1.943, w2v_ctc_loss=0.633, task_loss=2.241, contrastive_loss=0.167, total=6801.68, n_correct=4716.41, ppl=3.84, accuracy=69.342, wps=18680, ups=1.37, wpb=13603.4, bsz=469.2, num_updates=15300, lr=0.000114332, gnorm=0.437, clip=0, loss_scale=4, train_wall=72, gb_free=13.4, wall=15827
2023-08-26 16:45:54 | INFO | train_inner | epoch 013:   1118 / 1191 loss=1.935, trans_loss=4.727, nll_loss=1.948, w2v_ctc_loss=0.645, task_loss=2.299, contrastive_loss=0.23, total=6732.72, n_correct=4656.02, ppl=3.86, accuracy=69.155, wps=18631.7, ups=1.38, wpb=13465.4, bsz=461.9, num_updates=15400, lr=0.000113961, gnorm=0.442, clip=0, loss_scale=4, train_wall=72, gb_free=14.3, wall=15899
2023-08-26 16:46:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:7')
2023-08-26 16:47:22 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.785 | trans_loss 4.913 | nll_loss 2.138 | w2v_ctc_loss 1.182 | task_loss 8.549 | contrastive_loss 0.381 | total 6138.43 | n_correct 4318.57 | ppl 4.4 | accuracy 70.353 | uer 17.65 | wer 19.208 | raw_wer 19.208 | bleu 28.28 | wps 1645.3 | wpb 6138.4 | bsz 201.1 | num_updates 15473 | best_bleu 28.28
2023-08-26 16:47:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 15473 updates
2023-08-26 16:47:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 16:47:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 16:47:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 13 @ 15473 updates, score 28.28) (writing took 11.006712376998621 seconds)
2023-08-26 16:47:33 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-26 16:47:33 | INFO | train | epoch 013 | loss 1.923 | trans_loss 3.721 | nll_loss 1.534 | w2v_ctc_loss 0.806 | task_loss 1.812 | contrastive_loss 0.268 | total 6703.69 | n_correct 4634.49 | ppl 2.9 | accuracy 69.133 | wps 17661.2 | ups 1.04 | wpb 17033.5 | bsz 588.1 | num_updates 15473 | lr 0.000113691 | gnorm 0.382 | clip 0 | loss_scale 4 | train_wall 1088 | gb_free 9.5 | wall 15999
2023-08-26 16:47:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 16:47:33 | INFO | fairseq.trainer | begin training epoch 14
2023-08-26 16:47:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 16:47:59 | INFO | train_inner | epoch 014:     27 / 1191 loss=1.933, trans_loss=4.725, nll_loss=1.946, w2v_ctc_loss=0.641, task_loss=2.206, contrastive_loss=0.221, total=6742.3, n_correct=4668.02, ppl=3.85, accuracy=69.235, wps=10740, ups=0.8, wpb=13484.6, bsz=462.8, num_updates=15500, lr=0.000113592, gnorm=0.439, clip=0, loss_scale=4, train_wall=71, gb_free=12.4, wall=16025
2023-08-26 16:49:11 | INFO | train_inner | epoch 014:    127 / 1191 loss=1.921, trans_loss=4.705, nll_loss=1.92, w2v_ctc_loss=0.625, task_loss=2.275, contrastive_loss=0.239, total=6671.61, n_correct=4646.67, ppl=3.78, accuracy=69.648, wps=18543.3, ups=1.39, wpb=13343.2, bsz=454.8, num_updates=15600, lr=0.000113228, gnorm=0.439, clip=0, loss_scale=4, train_wall=71, gb_free=13.2, wall=16097
2023-08-26 16:50:24 | INFO | train_inner | epoch 014:    227 / 1191 loss=1.922, trans_loss=4.716, nll_loss=1.933, w2v_ctc_loss=0.632, task_loss=2.433, contrastive_loss=0.173, total=6627.34, n_correct=4595.1, ppl=3.82, accuracy=69.336, wps=18256.6, ups=1.38, wpb=13254.7, bsz=441.5, num_updates=15700, lr=0.000112867, gnorm=0.44, clip=0, loss_scale=4, train_wall=72, gb_free=10.9, wall=16169
2023-08-26 16:51:38 | INFO | train_inner | epoch 014:    327 / 1191 loss=1.926, trans_loss=4.71, nll_loss=1.927, w2v_ctc_loss=0.63, task_loss=2.403, contrastive_loss=0.24, total=6723.17, n_correct=4668.59, ppl=3.8, accuracy=69.44, wps=18289.2, ups=1.36, wpb=13446.3, bsz=449.2, num_updates=15800, lr=0.000112509, gnorm=0.438, clip=0, loss_scale=4, train_wall=73, gb_free=14.4, wall=16243
2023-08-26 16:52:50 | INFO | train_inner | epoch 014:    427 / 1191 loss=1.913, trans_loss=4.706, nll_loss=1.921, w2v_ctc_loss=0.623, task_loss=2.252, contrastive_loss=0.174, total=6814.56, n_correct=4744.39, ppl=3.79, accuracy=69.621, wps=18749.8, ups=1.38, wpb=13629.1, bsz=467.8, num_updates=15900, lr=0.000112154, gnorm=0.43, clip=0, loss_scale=8, train_wall=72, gb_free=14.5, wall=16316
2023-08-26 16:54:03 | INFO | train_inner | epoch 014:    527 / 1191 loss=1.928, trans_loss=4.706, nll_loss=1.921, w2v_ctc_loss=0.632, task_loss=2.322, contrastive_loss=0.264, total=6717.16, n_correct=4668.53, ppl=3.79, accuracy=69.502, wps=18393.8, ups=1.37, wpb=13434.3, bsz=457.8, num_updates=16000, lr=0.000111803, gnorm=0.436, clip=0, loss_scale=8, train_wall=72, gb_free=10.4, wall=16389
2023-08-26 16:54:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 16:54:36 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.795 | trans_loss 4.912 | nll_loss 2.141 | w2v_ctc_loss 1.206 | task_loss 8.558 | contrastive_loss 0.388 | total 6138.43 | n_correct 4323.43 | ppl 4.41 | accuracy 70.432 | uer 17.979 | wer 19.487 | raw_wer 19.487 | bleu 28.42 | wps 1760.6 | wpb 6138.4 | bsz 201.1 | num_updates 16000 | best_bleu 28.42
2023-08-26 16:54:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 16000 updates
2023-08-26 16:54:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_14_16000.pt
2023-08-26 16:54:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_14_16000.pt
2023-08-26 16:54:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_14_16000.pt (epoch 14 @ 16000 updates, score 28.42) (writing took 12.186343426990788 seconds)
2023-08-26 16:56:01 | INFO | train_inner | epoch 014:    627 / 1191 loss=1.919, trans_loss=4.708, nll_loss=1.924, w2v_ctc_loss=0.632, task_loss=2.28, contrastive_loss=0.194, total=6812.53, n_correct=4738.75, ppl=3.79, accuracy=69.559, wps=11602.3, ups=0.85, wpb=13625.1, bsz=465.6, num_updates=16100, lr=0.000111456, gnorm=0.432, clip=0, loss_scale=8, train_wall=72, gb_free=14.1, wall=16506
2023-08-26 16:57:13 | INFO | train_inner | epoch 014:    727 / 1191 loss=1.931, trans_loss=4.71, nll_loss=1.927, w2v_ctc_loss=0.638, task_loss=2.387, contrastive_loss=0.251, total=6684.49, n_correct=4641.64, ppl=3.8, accuracy=69.439, wps=18377.1, ups=1.37, wpb=13369, bsz=447.6, num_updates=16200, lr=0.000111111, gnorm=0.44, clip=0, loss_scale=8, train_wall=72, gb_free=12.9, wall=16579
2023-08-26 16:58:27 | INFO | train_inner | epoch 014:    827 / 1191 loss=1.931, trans_loss=4.715, nll_loss=1.933, w2v_ctc_loss=0.633, task_loss=2.372, contrastive_loss=0.287, total=6703.03, n_correct=4649.61, ppl=3.82, accuracy=69.366, wps=18214.8, ups=1.36, wpb=13406.1, bsz=460, num_updates=16300, lr=0.00011077, gnorm=0.437, clip=0, loss_scale=8, train_wall=73, gb_free=7.6, wall=16653
2023-08-26 16:59:40 | INFO | train_inner | epoch 014:    927 / 1191 loss=1.921, trans_loss=4.711, nll_loss=1.928, w2v_ctc_loss=0.636, task_loss=2.394, contrastive_loss=0.169, total=6648.37, n_correct=4621.99, ppl=3.8, accuracy=69.521, wps=18304.5, ups=1.38, wpb=13296.7, bsz=445.5, num_updates=16400, lr=0.000110432, gnorm=0.44, clip=0, loss_scale=8, train_wall=72, gb_free=9.9, wall=16725
2023-08-26 17:00:53 | INFO | train_inner | epoch 014:   1027 / 1191 loss=1.926, trans_loss=4.715, nll_loss=1.933, w2v_ctc_loss=0.646, task_loss=2.612, contrastive_loss=0.158, total=6579.07, n_correct=4564.29, ppl=3.82, accuracy=69.376, wps=17977.3, ups=1.37, wpb=13158.1, bsz=422.7, num_updates=16500, lr=0.000110096, gnorm=0.44, clip=0, loss_scale=8, train_wall=73, gb_free=13.8, wall=16798
2023-08-26 17:02:06 | INFO | train_inner | epoch 014:   1127 / 1191 loss=1.922, trans_loss=4.71, nll_loss=1.927, w2v_ctc_loss=0.634, task_loss=2.208, contrastive_loss=0.205, total=6782.82, n_correct=4720.82, ppl=3.8, accuracy=69.6, wps=18602.3, ups=1.37, wpb=13565.6, bsz=471, num_updates=16600, lr=0.000109764, gnorm=0.437, clip=0, loss_scale=8, train_wall=72, gb_free=6.2, wall=16871
2023-08-26 17:02:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 17:03:24 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.785 | trans_loss 4.9 | nll_loss 2.126 | w2v_ctc_loss 1.201 | task_loss 8.588 | contrastive_loss 0.392 | total 6138.43 | n_correct 4335 | ppl 4.36 | accuracy 70.621 | uer 17.781 | wer 19.342 | raw_wer 19.342 | bleu 28.54 | wps 1763.2 | wpb 6138.4 | bsz 201.1 | num_updates 16664 | best_bleu 28.54
2023-08-26 17:03:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 16664 updates
2023-08-26 17:03:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 17:03:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 17:03:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 14 @ 16664 updates, score 28.54) (writing took 11.761875135998707 seconds)
2023-08-26 17:03:36 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-26 17:03:36 | INFO | train | epoch 014 | loss 1.923 | trans_loss 4.71 | nll_loss 1.927 | w2v_ctc_loss 0.633 | task_loss 2.356 | contrastive_loss 0.212 | total 6703.69 | n_correct 4658.7 | ppl 3.8 | accuracy 69.495 | wps 16579 | ups 1.24 | wpb 13407.4 | bsz 452.1 | num_updates 16664 | lr 0.000109553 | gnorm 0.438 | clip 0 | loss_scale 8 | train_wall 859 | gb_free 14.4 | wall 16962
2023-08-26 17:03:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 17:03:36 | INFO | fairseq.trainer | begin training epoch 15
2023-08-26 17:03:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 17:04:10 | INFO | train_inner | epoch 015:     36 / 1191 loss=1.92, trans_loss=4.702, nll_loss=1.916, w2v_ctc_loss=0.629, task_loss=2.336, contrastive_loss=0.217, total=6697.04, n_correct=4666.92, ppl=3.77, accuracy=69.686, wps=10831.3, ups=0.81, wpb=13394.1, bsz=449.4, num_updates=16700, lr=0.000109435, gnorm=0.441, clip=0, loss_scale=8, train_wall=71, gb_free=11.7, wall=16995
2023-08-26 17:05:22 | INFO | train_inner | epoch 015:    136 / 1191 loss=1.912, trans_loss=4.693, nll_loss=1.906, w2v_ctc_loss=0.623, task_loss=2.287, contrastive_loss=0.212, total=6741.04, n_correct=4711.82, ppl=3.75, accuracy=69.898, wps=18638.9, ups=1.38, wpb=13482.1, bsz=458.9, num_updates=16800, lr=0.000109109, gnorm=0.433, clip=0, loss_scale=8, train_wall=72, gb_free=13.9, wall=17067
2023-08-26 17:06:34 | INFO | train_inner | epoch 015:    236 / 1191 loss=1.908, trans_loss=4.69, nll_loss=1.901, w2v_ctc_loss=0.621, task_loss=2.348, contrastive_loss=0.183, total=6693.64, n_correct=4680.24, ppl=3.73, accuracy=69.921, wps=18512.2, ups=1.38, wpb=13387.3, bsz=448.3, num_updates=16900, lr=0.000108786, gnorm=0.434, clip=0, loss_scale=8, train_wall=72, gb_free=8.3, wall=17140
2023-08-26 17:07:47 | INFO | train_inner | epoch 015:    336 / 1191 loss=1.902, trans_loss=4.684, nll_loss=1.894, w2v_ctc_loss=0.616, task_loss=2.373, contrastive_loss=0.175, total=6666.43, n_correct=4666.89, ppl=3.72, accuracy=70.006, wps=18323.4, ups=1.37, wpb=13332.9, bsz=446.4, num_updates=17000, lr=0.000108465, gnorm=0.435, clip=0, loss_scale=8, train_wall=72, gb_free=14.2, wall=17212
2023-08-26 17:09:00 | INFO | train_inner | epoch 015:    436 / 1191 loss=1.917, trans_loss=4.701, nll_loss=1.916, w2v_ctc_loss=0.63, task_loss=2.395, contrastive_loss=0.204, total=6715.85, n_correct=4679.82, ppl=3.77, accuracy=69.683, wps=18298.9, ups=1.36, wpb=13431.7, bsz=454.1, num_updates=17100, lr=0.000108148, gnorm=0.433, clip=0, loss_scale=8, train_wall=73, gb_free=11.3, wall=17286
2023-08-26 17:10:13 | INFO | train_inner | epoch 015:    536 / 1191 loss=1.918, trans_loss=4.696, nll_loss=1.909, w2v_ctc_loss=0.632, task_loss=2.311, contrastive_loss=0.217, total=6710.89, n_correct=4681.13, ppl=3.76, accuracy=69.754, wps=18487.4, ups=1.38, wpb=13421.8, bsz=461.7, num_updates=17200, lr=0.000107833, gnorm=0.438, clip=0, loss_scale=8, train_wall=72, gb_free=13.7, wall=17358
2023-08-26 17:11:26 | INFO | train_inner | epoch 015:    636 / 1191 loss=1.921, trans_loss=4.697, nll_loss=1.91, w2v_ctc_loss=0.639, task_loss=2.661, contrastive_loss=0.195, total=6602.28, n_correct=4595.32, ppl=3.76, accuracy=69.602, wps=18071.8, ups=1.37, wpb=13204.6, bsz=411, num_updates=17300, lr=0.000107521, gnorm=0.443, clip=0, loss_scale=8, train_wall=72, gb_free=14.4, wall=17432
2023-08-26 17:12:38 | INFO | train_inner | epoch 015:    736 / 1191 loss=1.923, trans_loss=4.696, nll_loss=1.909, w2v_ctc_loss=0.63, task_loss=2.383, contrastive_loss=0.288, total=6645.56, n_correct=4632.23, ppl=3.75, accuracy=69.704, wps=18367.6, ups=1.38, wpb=13291.1, bsz=454.2, num_updates=17400, lr=0.000107211, gnorm=0.444, clip=0, loss_scale=8, train_wall=72, gb_free=4.8, wall=17504
2023-08-26 17:13:51 | INFO | train_inner | epoch 015:    836 / 1191 loss=1.91, trans_loss=4.693, nll_loss=1.905, w2v_ctc_loss=0.633, task_loss=2.353, contrastive_loss=0.16, total=6714.02, n_correct=4694.04, ppl=3.75, accuracy=69.914, wps=18410.9, ups=1.37, wpb=13428, bsz=446.8, num_updates=17500, lr=0.000106904, gnorm=0.439, clip=0, loss_scale=8, train_wall=72, gb_free=13.7, wall=17577
2023-08-26 17:15:05 | INFO | train_inner | epoch 015:    936 / 1191 loss=1.908, trans_loss=4.689, nll_loss=1.901, w2v_ctc_loss=0.613, task_loss=2.228, contrastive_loss=0.261, total=6758.43, n_correct=4733.99, ppl=3.73, accuracy=70.046, wps=18445.9, ups=1.36, wpb=13516.9, bsz=474.5, num_updates=17600, lr=0.0001066, gnorm=0.429, clip=0, loss_scale=8, train_wall=73, gb_free=11.9, wall=17650
2023-08-26 17:16:18 | INFO | train_inner | epoch 015:   1036 / 1191 loss=1.91, trans_loss=4.694, nll_loss=1.907, w2v_ctc_loss=0.625, task_loss=2.344, contrastive_loss=0.183, total=6701.02, n_correct=4686.84, ppl=3.75, accuracy=69.942, wps=18367.9, ups=1.37, wpb=13402, bsz=454.7, num_updates=17700, lr=0.000106299, gnorm=0.438, clip=0, loss_scale=8, train_wall=72, gb_free=12.5, wall=17723
2023-08-26 17:17:31 | INFO | train_inner | epoch 015:   1136 / 1191 loss=1.917, trans_loss=4.699, nll_loss=1.913, w2v_ctc_loss=0.633, task_loss=2.397, contrastive_loss=0.196, total=6753.39, n_correct=4707.92, ppl=3.77, accuracy=69.712, wps=18457.7, ups=1.37, wpb=13506.8, bsz=445.3, num_updates=17800, lr=0.000106, gnorm=0.435, clip=0, loss_scale=8, train_wall=73, gb_free=13.3, wall=17796
2023-08-26 17:18:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 17:18:43 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.802 | trans_loss 4.897 | nll_loss 2.12 | w2v_ctc_loss 1.261 | task_loss 8.544 | contrastive_loss 0.396 | total 6138.43 | n_correct 4330.57 | ppl 4.35 | accuracy 70.549 | uer 18.035 | wer 19.583 | raw_wer 19.583 | bleu 28.28 | wps 1767 | wpb 6138.4 | bsz 201.1 | num_updates 17855 | best_bleu 28.54
2023-08-26 17:18:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 17855 updates
2023-08-26 17:18:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.2809.pt
2023-08-26 17:18:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.2809.pt
2023-08-26 17:18:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.2809.pt (epoch 15 @ 17855 updates, score 28.28) (writing took 7.34947410300083 seconds)
2023-08-26 17:18:51 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-26 17:18:51 | INFO | train | epoch 015 | loss 1.913 | trans_loss 4.694 | nll_loss 1.907 | w2v_ctc_loss 0.626 | task_loss 2.355 | contrastive_loss 0.211 | total 6703.69 | n_correct 4681.73 | ppl 3.75 | accuracy 69.838 | wps 17462.3 | ups 1.3 | wpb 13407.4 | bsz 452.1 | num_updates 17855 | lr 0.000105836 | gnorm 0.436 | clip 0 | loss_scale 8 | train_wall 860 | gb_free 11.6 | wall 17876
2023-08-26 17:18:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 17:18:51 | INFO | fairseq.trainer | begin training epoch 16
2023-08-26 17:18:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 17:19:30 | INFO | train_inner | epoch 016:     45 / 1191 loss=1.911, trans_loss=4.688, nll_loss=1.9, w2v_ctc_loss=0.613, task_loss=2.293, contrastive_loss=0.271, total=6677.12, n_correct=4673.93, ppl=3.73, accuracy=69.999, wps=11194.3, ups=0.84, wpb=13354.2, bsz=455.1, num_updates=17900, lr=0.000105703, gnorm=0.434, clip=0, loss_scale=16, train_wall=71, gb_free=13.9, wall=17916
2023-08-26 17:20:43 | INFO | train_inner | epoch 016:    145 / 1191 loss=1.902, trans_loss=4.679, nll_loss=1.888, w2v_ctc_loss=0.616, task_loss=2.416, contrastive_loss=0.191, total=6726.17, n_correct=4721.62, ppl=3.7, accuracy=70.198, wps=18396.1, ups=1.37, wpb=13452.3, bsz=445.6, num_updates=18000, lr=0.000105409, gnorm=0.433, clip=0, loss_scale=16, train_wall=73, gb_free=14.1, wall=17989
2023-08-26 17:20:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 17:21:15 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.786 | trans_loss 4.895 | nll_loss 2.116 | w2v_ctc_loss 1.215 | task_loss 8.588 | contrastive_loss 0.396 | total 6138.43 | n_correct 4335.57 | ppl 4.34 | accuracy 70.63 | uer 17.642 | wer 19.226 | raw_wer 19.226 | bleu 28.45 | wps 1771.6 | wpb 6138.4 | bsz 201.1 | num_updates 18000 | best_bleu 28.54
2023-08-26 17:21:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 18000 updates
2023-08-26 17:21:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_16_18000.pt
2023-08-26 17:21:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_16_18000.pt
2023-08-26 17:21:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_16_18000.pt (epoch 16 @ 18000 updates, score 28.45) (writing took 7.113723753005615 seconds)
2023-08-26 17:22:36 | INFO | train_inner | epoch 016:    245 / 1191 loss=1.904, trans_loss=4.679, nll_loss=1.887, w2v_ctc_loss=0.618, task_loss=2.434, contrastive_loss=0.207, total=6696.53, n_correct=4694.78, ppl=3.7, accuracy=70.108, wps=11917, ups=0.89, wpb=13393.1, bsz=441.3, num_updates=18100, lr=0.000105118, gnorm=0.432, clip=0, loss_scale=16, train_wall=72, gb_free=12.6, wall=18101
2023-08-26 17:23:48 | INFO | train_inner | epoch 016:    345 / 1191 loss=1.902, trans_loss=4.682, nll_loss=1.892, w2v_ctc_loss=0.614, task_loss=2.232, contrastive_loss=0.211, total=6778.29, n_correct=4759.08, ppl=3.71, accuracy=70.211, wps=18709.3, ups=1.38, wpb=13556.6, bsz=465, num_updates=18200, lr=0.000104828, gnorm=0.432, clip=0, loss_scale=16, train_wall=72, gb_free=15.1, wall=18174
2023-08-26 17:25:01 | INFO | train_inner | epoch 016:    445 / 1191 loss=1.901, trans_loss=4.681, nll_loss=1.891, w2v_ctc_loss=0.621, task_loss=2.367, contrastive_loss=0.159, total=6671.55, n_correct=4679.3, ppl=3.71, accuracy=70.138, wps=18423, ups=1.38, wpb=13343.1, bsz=446.5, num_updates=18300, lr=0.000104542, gnorm=0.432, clip=0, loss_scale=16, train_wall=72, gb_free=11.9, wall=18246
2023-08-26 17:26:13 | INFO | train_inner | epoch 016:    545 / 1191 loss=1.901, trans_loss=4.675, nll_loss=1.882, w2v_ctc_loss=0.614, task_loss=2.386, contrastive_loss=0.212, total=6683.11, n_correct=4693.25, ppl=3.69, accuracy=70.226, wps=18427.7, ups=1.38, wpb=13366.2, bsz=446.2, num_updates=18400, lr=0.000104257, gnorm=0.432, clip=0, loss_scale=16, train_wall=72, gb_free=14.7, wall=18319
2023-08-26 17:27:27 | INFO | train_inner | epoch 016:    645 / 1191 loss=1.906, trans_loss=4.679, nll_loss=1.888, w2v_ctc_loss=0.62, task_loss=2.341, contrastive_loss=0.229, total=6717.76, n_correct=4717.22, ppl=3.7, accuracy=70.22, wps=18288.5, ups=1.36, wpb=13435.5, bsz=458.3, num_updates=18500, lr=0.000103975, gnorm=0.433, clip=0, loss_scale=16, train_wall=73, gb_free=14.3, wall=18392
2023-08-26 17:28:40 | INFO | train_inner | epoch 016:    745 / 1191 loss=1.901, trans_loss=4.673, nll_loss=1.881, w2v_ctc_loss=0.621, task_loss=2.417, contrastive_loss=0.19, total=6644.93, n_correct=4669.73, ppl=3.68, accuracy=70.275, wps=18213, ups=1.37, wpb=13289.9, bsz=444.7, num_updates=18600, lr=0.000103695, gnorm=0.437, clip=0, loss_scale=16, train_wall=72, gb_free=13.2, wall=18465
2023-08-26 17:29:53 | INFO | train_inner | epoch 016:    845 / 1191 loss=1.906, trans_loss=4.684, nll_loss=1.894, w2v_ctc_loss=0.623, task_loss=2.438, contrastive_loss=0.197, total=6701.05, n_correct=4697.35, ppl=3.72, accuracy=70.099, wps=18320.9, ups=1.37, wpb=13402.1, bsz=443.1, num_updates=18700, lr=0.000103418, gnorm=0.435, clip=0, loss_scale=16, train_wall=73, gb_free=12.6, wall=18538
2023-08-26 17:31:06 | INFO | train_inner | epoch 016:    945 / 1191 loss=1.898, trans_loss=4.68, nll_loss=1.89, w2v_ctc_loss=0.612, task_loss=2.288, contrastive_loss=0.192, total=6724.13, n_correct=4720.62, ppl=3.71, accuracy=70.204, wps=18426.2, ups=1.37, wpb=13448.3, bsz=462.9, num_updates=18800, lr=0.000103142, gnorm=0.428, clip=0, loss_scale=16, train_wall=72, gb_free=12.3, wall=18611
2023-08-26 17:32:19 | INFO | train_inner | epoch 016:   1045 / 1191 loss=1.906, trans_loss=4.677, nll_loss=1.886, w2v_ctc_loss=0.623, task_loss=2.337, contrastive_loss=0.226, total=6686.75, n_correct=4692.16, ppl=3.7, accuracy=70.171, wps=18334.2, ups=1.37, wpb=13373.5, bsz=458.5, num_updates=18900, lr=0.000102869, gnorm=0.434, clip=0, loss_scale=16, train_wall=72, gb_free=14.4, wall=18684
2023-08-26 17:33:32 | INFO | train_inner | epoch 016:   1145 / 1191 loss=1.909, trans_loss=4.686, nll_loss=1.897, w2v_ctc_loss=0.623, task_loss=2.206, contrastive_loss=0.224, total=6796.66, n_correct=4760.16, ppl=3.73, accuracy=70.037, wps=18563.7, ups=1.37, wpb=13593.3, bsz=477.6, num_updates=19000, lr=0.000102598, gnorm=0.436, clip=0, loss_scale=16, train_wall=73, gb_free=13.1, wall=18757
2023-08-26 17:34:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 17:34:41 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.788 | trans_loss 4.898 | nll_loss 2.123 | w2v_ctc_loss 1.22 | task_loss 8.53 | contrastive_loss 0.39 | total 6138.43 | n_correct 4340.71 | ppl 4.36 | accuracy 70.714 | uer 18.225 | wer 19.825 | raw_wer 19.825 | bleu 28.67 | wps 1635.1 | wpb 6138.4 | bsz 201.1 | num_updates 19046 | best_bleu 28.67
2023-08-26 17:34:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 19046 updates
2023-08-26 17:34:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 17:34:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 17:34:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 16 @ 19046 updates, score 28.67) (writing took 11.575054984001326 seconds)
2023-08-26 17:34:53 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-26 17:34:53 | INFO | train | epoch 016 | loss 1.903 | trans_loss 4.679 | nll_loss 1.888 | w2v_ctc_loss 0.618 | task_loss 2.354 | contrastive_loss 0.208 | total 6703.69 | n_correct 4704.32 | ppl 3.7 | accuracy 70.175 | wps 16597.2 | ups 1.24 | wpb 13407.4 | bsz 452.1 | num_updates 19046 | lr 0.000102474 | gnorm 0.433 | clip 0 | loss_scale 16 | train_wall 859 | gb_free 13.6 | wall 18838
2023-08-26 17:34:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 17:34:53 | INFO | fairseq.trainer | begin training epoch 17
2023-08-26 17:34:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 17:35:40 | INFO | train_inner | epoch 017:     54 / 1191 loss=1.899, trans_loss=4.674, nll_loss=1.882, w2v_ctc_loss=0.607, task_loss=2.438, contrastive_loss=0.231, total=6598.23, n_correct=4632.5, ppl=3.68, accuracy=70.208, wps=10295.3, ups=0.78, wpb=13196.5, bsz=437.8, num_updates=19100, lr=0.000102329, gnorm=0.434, clip=0, loss_scale=16, train_wall=72, gb_free=13.7, wall=18885
2023-08-26 17:36:52 | INFO | train_inner | epoch 017:    154 / 1191 loss=1.893, trans_loss=4.664, nll_loss=1.868, w2v_ctc_loss=0.609, task_loss=2.386, contrastive_loss=0.213, total=6698.82, n_correct=4722.12, ppl=3.65, accuracy=70.492, wps=18534.2, ups=1.38, wpb=13397.6, bsz=450.9, num_updates=19200, lr=0.000102062, gnorm=0.433, clip=0, loss_scale=16, train_wall=72, gb_free=13.9, wall=18958
2023-08-26 17:38:05 | INFO | train_inner | epoch 017:    254 / 1191 loss=1.883, trans_loss=4.655, nll_loss=1.857, w2v_ctc_loss=0.606, task_loss=2.229, contrastive_loss=0.164, total=6821.43, n_correct=4827.21, ppl=3.62, accuracy=70.765, wps=18687.6, ups=1.37, wpb=13642.9, bsz=473.7, num_updates=19300, lr=0.000101797, gnorm=0.421, clip=0, loss_scale=16, train_wall=72, gb_free=10, wall=19031
2023-08-26 17:39:18 | INFO | train_inner | epoch 017:    354 / 1191 loss=1.894, trans_loss=4.67, nll_loss=1.877, w2v_ctc_loss=0.615, task_loss=2.4, contrastive_loss=0.166, total=6643.4, n_correct=4671.11, ppl=3.67, accuracy=70.312, wps=18321.6, ups=1.38, wpb=13286.8, bsz=444.5, num_updates=19400, lr=0.000101535, gnorm=0.434, clip=0, loss_scale=16, train_wall=72, gb_free=12.7, wall=19103
2023-08-26 17:40:30 | INFO | train_inner | epoch 017:    454 / 1191 loss=1.9, trans_loss=4.67, nll_loss=1.876, w2v_ctc_loss=0.615, task_loss=2.405, contrastive_loss=0.214, total=6705.47, n_correct=4715.89, ppl=3.67, accuracy=70.329, wps=18634, ups=1.39, wpb=13410.9, bsz=443.5, num_updates=19500, lr=0.000101274, gnorm=0.433, clip=0, loss_scale=16, train_wall=71, gb_free=13.4, wall=19175
2023-08-26 17:41:43 | INFO | train_inner | epoch 017:    554 / 1191 loss=1.903, trans_loss=4.675, nll_loss=1.882, w2v_ctc_loss=0.612, task_loss=2.401, contrastive_loss=0.245, total=6675.84, n_correct=4687.99, ppl=3.69, accuracy=70.223, wps=18214, ups=1.36, wpb=13351.7, bsz=440.8, num_updates=19600, lr=0.000101015, gnorm=0.433, clip=0, loss_scale=16, train_wall=73, gb_free=14, wall=19249
2023-08-26 17:42:55 | INFO | train_inner | epoch 017:    654 / 1191 loss=1.892, trans_loss=4.665, nll_loss=1.871, w2v_ctc_loss=0.61, task_loss=2.31, contrastive_loss=0.184, total=6687.04, n_correct=4708.51, ppl=3.66, accuracy=70.412, wps=18557.4, ups=1.39, wpb=13374.1, bsz=458.1, num_updates=19700, lr=0.000100759, gnorm=0.431, clip=0, loss_scale=16, train_wall=72, gb_free=13.7, wall=19321
2023-08-26 17:44:08 | INFO | train_inner | epoch 017:    754 / 1191 loss=1.896, trans_loss=4.673, nll_loss=1.88, w2v_ctc_loss=0.617, task_loss=2.444, contrastive_loss=0.154, total=6671.22, n_correct=4687.39, ppl=3.68, accuracy=70.263, wps=18289.3, ups=1.37, wpb=13342.4, bsz=434.6, num_updates=19800, lr=0.000100504, gnorm=0.432, clip=0, loss_scale=16, train_wall=72, gb_free=14.3, wall=19394
2023-08-26 17:45:22 | INFO | train_inner | epoch 017:    854 / 1191 loss=1.902, trans_loss=4.668, nll_loss=1.874, w2v_ctc_loss=0.615, task_loss=2.557, contrastive_loss=0.245, total=6600.69, n_correct=4647.64, ppl=3.66, accuracy=70.411, wps=17968.4, ups=1.36, wpb=13201.4, bsz=434.3, num_updates=19900, lr=0.000100251, gnorm=0.436, clip=0, loss_scale=16, train_wall=73, gb_free=13.6, wall=19467
2023-08-26 17:46:33 | INFO | train_inner | epoch 017:    954 / 1191 loss=1.892, trans_loss=4.661, nll_loss=1.865, w2v_ctc_loss=0.591, task_loss=2.051, contrastive_loss=0.306, total=6821.56, n_correct=4818.48, ppl=3.64, accuracy=70.636, wps=18996.8, ups=1.39, wpb=13643.1, bsz=498.7, num_updates=20000, lr=0.0001, gnorm=0.425, clip=0, loss_scale=32, train_wall=71, gb_free=14.3, wall=19539
2023-08-26 17:46:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 17:47:05 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.764 | trans_loss 4.882 | nll_loss 2.1 | w2v_ctc_loss 1.178 | task_loss 8.564 | contrastive_loss 0.386 | total 6138.43 | n_correct 4358.43 | ppl 4.29 | accuracy 71.002 | uer 17.078 | wer 18.739 | raw_wer 18.739 | bleu 28.55 | wps 1792.9 | wpb 6138.4 | bsz 201.1 | num_updates 20000 | best_bleu 28.67
2023-08-26 17:47:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 20000 updates
2023-08-26 17:47:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_17_20000.pt
2023-08-26 17:47:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_17_20000.pt
2023-08-26 17:47:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_17_20000.pt (epoch 17 @ 20000 updates, score 28.55) (writing took 7.280648405998363 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:0')
2023-08-26 17:48:26 | INFO | train_inner | epoch 017:   1054 / 1191 loss=1.889, trans_loss=4.661, nll_loss=1.865, w2v_ctc_loss=0.607, task_loss=2.415, contrastive_loss=0.194, total=6652.48, n_correct=4695.88, ppl=3.64, accuracy=70.588, wps=11843, ups=0.89, wpb=13305, bsz=441.9, num_updates=20100, lr=9.97509e-05, gnorm=0.43, clip=0, loss_scale=32, train_wall=72, gb_free=12.9, wall=19651
2023-08-26 17:49:39 | INFO | train_inner | epoch 017:   1154 / 1191 loss=1.89, trans_loss=4.661, nll_loss=1.866, w2v_ctc_loss=0.611, task_loss=2.355, contrastive_loss=0.183, total=6757.28, n_correct=4770.43, ppl=3.64, accuracy=70.597, wps=18495.3, ups=1.37, wpb=13514.6, bsz=451.7, num_updates=20200, lr=9.95037e-05, gnorm=0.429, clip=0, loss_scale=32, train_wall=73, gb_free=13.5, wall=19724
2023-08-26 17:50:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:5')
2023-08-26 17:50:38 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.76 | trans_loss 4.883 | nll_loss 2.103 | w2v_ctc_loss 1.159 | task_loss 8.596 | contrastive_loss 0.388 | total 6138.43 | n_correct 4354.71 | ppl 4.3 | accuracy 70.942 | uer 17.174 | wer 18.721 | raw_wer 18.721 | bleu 28.55 | wps 1762.6 | wpb 6138.4 | bsz 201.1 | num_updates 20237 | best_bleu 28.67
2023-08-26 17:50:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 20237 updates
2023-08-26 17:50:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.5508.pt
2023-08-26 17:50:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.5508.pt
2023-08-26 17:50:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.5508.pt (epoch 17 @ 20237 updates, score 28.55) (writing took 11.37875304899353 seconds)
2023-08-26 17:50:50 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-26 17:50:50 | INFO | train | epoch 017 | loss 1.894 | trans_loss 4.666 | nll_loss 1.871 | w2v_ctc_loss 0.609 | task_loss 2.355 | contrastive_loss 0.206 | total 6703.69 | n_correct 4723.11 | ppl 3.66 | accuracy 70.455 | wps 16678.5 | ups 1.24 | wpb 13407.4 | bsz 452.1 | num_updates 20237 | lr 9.94127e-05 | gnorm 0.431 | clip 0 | loss_scale 32 | train_wall 860 | gb_free 14 | wall 19796
2023-08-26 17:50:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 17:50:50 | INFO | fairseq.trainer | begin training epoch 18
2023-08-26 17:50:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 17:51:43 | INFO | train_inner | epoch 018:     63 / 1191 loss=1.877, trans_loss=4.648, nll_loss=1.848, w2v_ctc_loss=0.588, task_loss=2.25, contrastive_loss=0.196, total=6803.5, n_correct=4820.17, ppl=3.6, accuracy=70.848, wps=10927.3, ups=0.8, wpb=13607, bsz=464.9, num_updates=20300, lr=9.92583e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=72, gb_free=13.3, wall=19849
2023-08-26 17:52:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-26 17:52:57 | INFO | train_inner | epoch 018:    164 / 1191 loss=1.885, trans_loss=4.657, nll_loss=1.859, w2v_ctc_loss=0.605, task_loss=2.607, contrastive_loss=0.161, total=6637.78, n_correct=4690.35, ppl=3.63, accuracy=70.661, wps=17978.6, ups=1.35, wpb=13275.6, bsz=423.5, num_updates=20400, lr=9.90148e-05, gnorm=0.432, clip=0, loss_scale=16, train_wall=73, gb_free=13.9, wall=19923
2023-08-26 17:54:10 | INFO | train_inner | epoch 018:    264 / 1191 loss=1.893, trans_loss=4.657, nll_loss=1.86, w2v_ctc_loss=0.603, task_loss=2.386, contrastive_loss=0.268, total=6622.15, n_correct=4679.58, ppl=3.63, accuracy=70.666, wps=18263.1, ups=1.38, wpb=13244.3, bsz=447.2, num_updates=20500, lr=9.8773e-05, gnorm=0.432, clip=0, loss_scale=16, train_wall=72, gb_free=14.8, wall=19995
2023-08-26 17:55:23 | INFO | train_inner | epoch 018:    364 / 1191 loss=1.888, trans_loss=4.653, nll_loss=1.855, w2v_ctc_loss=0.605, task_loss=2.317, contrastive_loss=0.233, total=6736.36, n_correct=4769.3, ppl=3.62, accuracy=70.799, wps=18393.5, ups=1.37, wpb=13472.7, bsz=459.4, num_updates=20600, lr=9.85329e-05, gnorm=0.423, clip=0, loss_scale=16, train_wall=73, gb_free=13.1, wall=20068
2023-08-26 17:56:36 | INFO | train_inner | epoch 018:    464 / 1191 loss=1.881, trans_loss=4.654, nll_loss=1.856, w2v_ctc_loss=0.596, task_loss=2.337, contrastive_loss=0.18, total=6698.43, n_correct=4740.2, ppl=3.62, accuracy=70.766, wps=18435.1, ups=1.38, wpb=13396.9, bsz=454.4, num_updates=20700, lr=9.82946e-05, gnorm=0.43, clip=0, loss_scale=16, train_wall=72, gb_free=12.1, wall=20141
2023-08-26 17:57:48 | INFO | train_inner | epoch 018:    564 / 1191 loss=1.884, trans_loss=4.653, nll_loss=1.856, w2v_ctc_loss=0.602, task_loss=2.152, contrastive_loss=0.197, total=6847.61, n_correct=4845.42, ppl=3.62, accuracy=70.761, wps=18961.6, ups=1.38, wpb=13695.2, bsz=483.1, num_updates=20800, lr=9.80581e-05, gnorm=0.424, clip=0, loss_scale=16, train_wall=72, gb_free=11.7, wall=20213
2023-08-26 17:59:00 | INFO | train_inner | epoch 018:    664 / 1191 loss=1.884, trans_loss=4.651, nll_loss=1.852, w2v_ctc_loss=0.603, task_loss=2.53, contrastive_loss=0.177, total=6562.52, n_correct=4638.85, ppl=3.61, accuracy=70.687, wps=18240.3, ups=1.39, wpb=13125, bsz=426.3, num_updates=20900, lr=9.78232e-05, gnorm=0.434, clip=0, loss_scale=16, train_wall=71, gb_free=13.3, wall=20285
2023-08-26 18:00:13 | INFO | train_inner | epoch 018:    764 / 1191 loss=1.883, trans_loss=4.657, nll_loss=1.861, w2v_ctc_loss=0.603, task_loss=2.245, contrastive_loss=0.171, total=6829.65, n_correct=4827.26, ppl=3.63, accuracy=70.681, wps=18729.8, ups=1.37, wpb=13659.3, bsz=472.1, num_updates=21000, lr=9.759e-05, gnorm=0.453, clip=0, loss_scale=16, train_wall=72, gb_free=13.4, wall=20358
2023-08-26 18:01:26 | INFO | train_inner | epoch 018:    864 / 1191 loss=1.89, trans_loss=4.659, nll_loss=1.862, w2v_ctc_loss=0.606, task_loss=2.39, contrastive_loss=0.215, total=6699.72, n_correct=4725.98, ppl=3.64, accuracy=70.54, wps=18284.3, ups=1.36, wpb=13399.4, bsz=449, num_updates=21100, lr=9.73585e-05, gnorm=0.43, clip=0, loss_scale=16, train_wall=73, gb_free=13.5, wall=20432
2023-08-26 18:02:39 | INFO | train_inner | epoch 018:    964 / 1191 loss=1.878, trans_loss=4.648, nll_loss=1.849, w2v_ctc_loss=0.602, task_loss=2.26, contrastive_loss=0.164, total=6735.73, n_correct=4774.98, ppl=3.6, accuracy=70.89, wps=18506.2, ups=1.37, wpb=13471.5, bsz=459.4, num_updates=21200, lr=9.71286e-05, gnorm=0.42, clip=0, loss_scale=16, train_wall=72, gb_free=13.6, wall=20504
2023-08-26 18:03:51 | INFO | train_inner | epoch 018:   1064 / 1191 loss=1.892, trans_loss=4.658, nll_loss=1.861, w2v_ctc_loss=0.611, task_loss=2.5, contrastive_loss=0.211, total=6578.5, n_correct=4642.13, ppl=3.63, accuracy=70.565, wps=18289.8, ups=1.39, wpb=13157, bsz=432.2, num_updates=21300, lr=9.69003e-05, gnorm=0.434, clip=0, loss_scale=16, train_wall=71, gb_free=14.1, wall=20576
2023-08-26 18:05:04 | INFO | train_inner | epoch 018:   1164 / 1191 loss=1.889, trans_loss=4.654, nll_loss=1.856, w2v_ctc_loss=0.603, task_loss=2.322, contrastive_loss=0.232, total=6752.19, n_correct=4771.37, ppl=3.62, accuracy=70.664, wps=18351.5, ups=1.36, wpb=13504.4, bsz=463.4, num_updates=21400, lr=9.66736e-05, gnorm=0.43, clip=0, loss_scale=16, train_wall=73, gb_free=13.7, wall=20650
2023-08-26 18:05:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 18:05:56 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.769 | trans_loss 4.881 | nll_loss 2.103 | w2v_ctc_loss 1.193 | task_loss 8.558 | contrastive_loss 0.388 | total 6138.43 | n_correct 4352.43 | ppl 4.3 | accuracy 70.905 | uer 17.493 | wer 19.119 | raw_wer 19.119 | bleu 28.58 | wps 1725.7 | wpb 6138.4 | bsz 201.1 | num_updates 21427 | best_bleu 28.67
2023-08-26 18:05:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 21427 updates
2023-08-26 18:05:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.5804.pt
2023-08-26 18:05:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.5804.pt
2023-08-26 18:06:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.5804.pt (epoch 18 @ 21427 updates, score 28.58) (writing took 6.78072445098951 seconds)
2023-08-26 18:06:04 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-26 18:06:04 | INFO | train | epoch 018 | loss 1.885 | trans_loss 4.654 | nll_loss 1.856 | w2v_ctc_loss 0.602 | task_loss 2.354 | contrastive_loss 0.204 | total 6703.86 | n_correct 4741.22 | ppl 3.62 | accuracy 70.724 | wps 17465.9 | ups 1.3 | wpb 13407.7 | bsz 452.3 | num_updates 21427 | lr 9.66127e-05 | gnorm 0.43 | clip 0 | loss_scale 16 | train_wall 859 | gb_free 13.8 | wall 20709
2023-08-26 18:06:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 18:06:04 | INFO | fairseq.trainer | begin training epoch 19
2023-08-26 18:06:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 18:07:05 | INFO | train_inner | epoch 019:     73 / 1191 loss=1.88, trans_loss=4.644, nll_loss=1.843, w2v_ctc_loss=0.597, task_loss=2.494, contrastive_loss=0.207, total=6605.34, n_correct=4686.67, ppl=3.59, accuracy=70.953, wps=10996.9, ups=0.83, wpb=13210.7, bsz=428.3, num_updates=21500, lr=9.64486e-05, gnorm=0.429, clip=0, loss_scale=16, train_wall=72, gb_free=12.8, wall=20770
2023-08-26 18:08:16 | INFO | train_inner | epoch 019:    173 / 1191 loss=1.869, trans_loss=4.636, nll_loss=1.832, w2v_ctc_loss=0.591, task_loss=2.375, contrastive_loss=0.154, total=6678.53, n_correct=4752.53, ppl=3.56, accuracy=71.161, wps=18601.6, ups=1.39, wpb=13357.1, bsz=446.3, num_updates=21600, lr=9.6225e-05, gnorm=0.427, clip=0, loss_scale=16, train_wall=71, gb_free=14.3, wall=20842
2023-08-26 18:09:30 | INFO | train_inner | epoch 019:    273 / 1191 loss=1.872, trans_loss=4.633, nll_loss=1.829, w2v_ctc_loss=0.59, task_loss=2.267, contrastive_loss=0.208, total=6755.84, n_correct=4808.42, ppl=3.55, accuracy=71.174, wps=18391.3, ups=1.36, wpb=13511.7, bsz=461.2, num_updates=21700, lr=9.60031e-05, gnorm=0.426, clip=0, loss_scale=16, train_wall=73, gb_free=14.2, wall=20915
2023-08-26 18:10:42 | INFO | train_inner | epoch 019:    373 / 1191 loss=1.873, trans_loss=4.646, nll_loss=1.846, w2v_ctc_loss=0.593, task_loss=2.329, contrastive_loss=0.146, total=6694.87, n_correct=4749.17, ppl=3.59, accuracy=70.937, wps=18586.4, ups=1.39, wpb=13389.7, bsz=445.4, num_updates=21800, lr=9.57826e-05, gnorm=0.434, clip=0, loss_scale=16, train_wall=72, gb_free=11.8, wall=20987
2023-08-26 18:11:55 | INFO | train_inner | epoch 019:    473 / 1191 loss=1.881, trans_loss=4.643, nll_loss=1.843, w2v_ctc_loss=0.593, task_loss=2.192, contrastive_loss=0.252, total=6790.32, n_correct=4820.11, ppl=3.59, accuracy=70.985, wps=18615.4, ups=1.37, wpb=13580.6, bsz=478.7, num_updates=21900, lr=9.55637e-05, gnorm=0.429, clip=0, loss_scale=16, train_wall=72, gb_free=12, wall=21060
2023-08-26 18:13:08 | INFO | train_inner | epoch 019:    573 / 1191 loss=1.88, trans_loss=4.65, nll_loss=1.851, w2v_ctc_loss=0.603, task_loss=2.333, contrastive_loss=0.175, total=6753.74, n_correct=4785.74, ppl=3.61, accuracy=70.861, wps=18443.2, ups=1.37, wpb=13507.5, bsz=462.6, num_updates=22000, lr=9.53463e-05, gnorm=0.428, clip=0, loss_scale=16, train_wall=73, gb_free=11.5, wall=21134
2023-08-26 18:13:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 18:13:41 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.762 | trans_loss 4.881 | nll_loss 2.101 | w2v_ctc_loss 1.173 | task_loss 8.548 | contrastive_loss 0.382 | total 6138.43 | n_correct 4359.29 | ppl 4.29 | accuracy 71.016 | uer 17.169 | wer 18.814 | raw_wer 18.814 | bleu 28.93 | wps 1755.5 | wpb 6138.4 | bsz 201.1 | num_updates 22000 | best_bleu 28.93
2023-08-26 18:13:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 22000 updates
2023-08-26 18:13:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_19_22000.pt
2023-08-26 18:13:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_19_22000.pt
2023-08-26 18:13:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_19_22000.pt (epoch 19 @ 22000 updates, score 28.93) (writing took 11.656451681003091 seconds)
2023-08-26 18:15:05 | INFO | train_inner | epoch 019:    673 / 1191 loss=1.88, trans_loss=4.639, nll_loss=1.837, w2v_ctc_loss=0.591, task_loss=2.361, contrastive_loss=0.267, total=6649.95, n_correct=4725.36, ppl=3.57, accuracy=71.059, wps=11341.8, ups=0.85, wpb=13299.9, bsz=451.5, num_updates=22100, lr=9.51303e-05, gnorm=0.43, clip=0, loss_scale=16, train_wall=72, gb_free=13.8, wall=21251
2023-08-26 18:16:19 | INFO | train_inner | epoch 019:    773 / 1191 loss=1.879, trans_loss=4.642, nll_loss=1.841, w2v_ctc_loss=0.6, task_loss=2.313, contrastive_loss=0.184, total=6758.75, n_correct=4796.64, ppl=3.58, accuracy=70.969, wps=18453.1, ups=1.37, wpb=13517.5, bsz=461.1, num_updates=22200, lr=9.49158e-05, gnorm=0.43, clip=0, loss_scale=16, train_wall=73, gb_free=11.7, wall=21324
2023-08-26 18:17:31 | INFO | train_inner | epoch 019:    873 / 1191 loss=1.887, trans_loss=4.645, nll_loss=1.845, w2v_ctc_loss=0.602, task_loss=2.44, contrastive_loss=0.242, total=6623.8, n_correct=4692.93, ppl=3.59, accuracy=70.85, wps=18185.1, ups=1.37, wpb=13247.6, bsz=440.7, num_updates=22300, lr=9.47027e-05, gnorm=0.434, clip=0, loss_scale=16, train_wall=72, gb_free=14.3, wall=21397
2023-08-26 18:18:44 | INFO | train_inner | epoch 019:    973 / 1191 loss=1.878, trans_loss=4.64, nll_loss=1.838, w2v_ctc_loss=0.601, task_loss=2.523, contrastive_loss=0.182, total=6611.17, n_correct=4693.02, ppl=3.58, accuracy=70.986, wps=18297.3, ups=1.38, wpb=13222.3, bsz=434.3, num_updates=22400, lr=9.44911e-05, gnorm=0.432, clip=0, loss_scale=16, train_wall=72, gb_free=13.2, wall=21469
2023-08-26 18:19:56 | INFO | train_inner | epoch 019:   1073 / 1191 loss=1.879, trans_loss=4.643, nll_loss=1.842, w2v_ctc_loss=0.597, task_loss=2.292, contrastive_loss=0.204, total=6738.74, n_correct=4781.28, ppl=3.59, accuracy=70.952, wps=18674.6, ups=1.39, wpb=13477.5, bsz=455.1, num_updates=22500, lr=9.42809e-05, gnorm=0.427, clip=0, loss_scale=32, train_wall=72, gb_free=13.9, wall=21541
2023-08-26 18:21:09 | INFO | train_inner | epoch 019:   1173 / 1191 loss=1.884, trans_loss=4.653, nll_loss=1.855, w2v_ctc_loss=0.595, task_loss=2.34, contrastive_loss=0.227, total=6789.71, n_correct=4805.3, ppl=3.62, accuracy=70.773, wps=18496.6, ups=1.36, wpb=13579.4, bsz=457.9, num_updates=22600, lr=9.40721e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=73, gb_free=14.2, wall=21615
2023-08-26 18:21:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 18:21:55 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.774 | trans_loss 4.878 | nll_loss 2.097 | w2v_ctc_loss 1.217 | task_loss 8.482 | contrastive_loss 0.391 | total 6138.43 | n_correct 4351.86 | ppl 4.28 | accuracy 70.895 | uer 17.747 | wer 19.319 | raw_wer 19.319 | bleu 28.42 | wps 1751.2 | wpb 6138.4 | bsz 201.1 | num_updates 22618 | best_bleu 28.93
2023-08-26 18:21:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 22618 updates
2023-08-26 18:21:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.4203.pt
2023-08-26 18:21:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.4203.pt
2023-08-26 18:22:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.4203.pt (epoch 19 @ 22618 updates, score 28.42) (writing took 6.5995710589922965 seconds)
2023-08-26 18:22:02 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-26 18:22:02 | INFO | train | epoch 019 | loss 1.878 | trans_loss 4.643 | nll_loss 1.842 | w2v_ctc_loss 0.597 | task_loss 2.356 | contrastive_loss 0.202 | total 6703.69 | n_correct 4757.32 | ppl 3.59 | accuracy 70.966 | wps 16661.5 | ups 1.24 | wpb 13407.4 | bsz 452.1 | num_updates 22618 | lr 9.40346e-05 | gnorm 0.43 | clip 0 | loss_scale 32 | train_wall 859 | gb_free 14.3 | wall 21668
2023-08-26 18:22:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 18:22:02 | INFO | fairseq.trainer | begin training epoch 20
2023-08-26 18:22:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 18:23:10 | INFO | train_inner | epoch 020:     82 / 1191 loss=1.867, trans_loss=4.627, nll_loss=1.821, w2v_ctc_loss=0.587, task_loss=2.381, contrastive_loss=0.187, total=6693.71, n_correct=4771.34, ppl=3.53, accuracy=71.281, wps=11102.1, ups=0.83, wpb=13387.4, bsz=451.9, num_updates=22700, lr=9.38647e-05, gnorm=0.428, clip=0, loss_scale=32, train_wall=72, gb_free=13.5, wall=21735
2023-08-26 18:24:22 | INFO | train_inner | epoch 020:    182 / 1191 loss=1.868, trans_loss=4.627, nll_loss=1.821, w2v_ctc_loss=0.586, task_loss=2.451, contrastive_loss=0.203, total=6599.88, n_correct=4704.82, ppl=3.53, accuracy=71.286, wps=18365.9, ups=1.39, wpb=13199.8, bsz=438.3, num_updates=22800, lr=9.36586e-05, gnorm=0.43, clip=0, loss_scale=32, train_wall=71, gb_free=14.9, wall=21807
2023-08-26 18:25:35 | INFO | train_inner | epoch 020:    282 / 1191 loss=1.871, trans_loss=4.635, nll_loss=1.832, w2v_ctc_loss=0.585, task_loss=2.335, contrastive_loss=0.208, total=6767.67, n_correct=4817.76, ppl=3.56, accuracy=71.188, wps=18558.6, ups=1.37, wpb=13535.3, bsz=457.2, num_updates=22900, lr=9.34539e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=72, gb_free=12.6, wall=21880
2023-08-26 18:26:47 | INFO | train_inner | epoch 020:    382 / 1191 loss=1.868, trans_loss=4.635, nll_loss=1.832, w2v_ctc_loss=0.593, task_loss=2.224, contrastive_loss=0.158, total=6794.56, n_correct=4838.84, ppl=3.56, accuracy=71.216, wps=18752, ups=1.38, wpb=13589.1, bsz=468.7, num_updates=23000, lr=9.32505e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=72, gb_free=13.8, wall=21953
2023-08-26 18:28:00 | INFO | train_inner | epoch 020:    482 / 1191 loss=1.868, trans_loss=4.628, nll_loss=1.823, w2v_ctc_loss=0.588, task_loss=2.349, contrastive_loss=0.192, total=6694, n_correct=4767.06, ppl=3.54, accuracy=71.214, wps=18470.4, ups=1.38, wpb=13388, bsz=446.1, num_updates=23100, lr=9.30484e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=72, gb_free=11.6, wall=22025
2023-08-26 18:29:13 | INFO | train_inner | epoch 020:    582 / 1191 loss=1.883, trans_loss=4.634, nll_loss=1.831, w2v_ctc_loss=0.593, task_loss=2.429, contrastive_loss=0.301, total=6622.52, n_correct=4708.93, ppl=3.56, accuracy=71.105, wps=18050.8, ups=1.36, wpb=13245, bsz=442.4, num_updates=23200, lr=9.28477e-05, gnorm=0.43, clip=0, loss_scale=32, train_wall=73, gb_free=13, wall=22099
2023-08-26 18:30:25 | INFO | train_inner | epoch 020:    682 / 1191 loss=1.866, trans_loss=4.63, nll_loss=1.826, w2v_ctc_loss=0.576, task_loss=2.211, contrastive_loss=0.238, total=6711.24, n_correct=4787.03, ppl=3.54, accuracy=71.329, wps=18617.6, ups=1.39, wpb=13422.5, bsz=470.5, num_updates=23300, lr=9.26482e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=72, gb_free=13.4, wall=22171
2023-08-26 18:31:38 | INFO | train_inner | epoch 020:    782 / 1191 loss=1.872, trans_loss=4.634, nll_loss=1.831, w2v_ctc_loss=0.59, task_loss=2.252, contrastive_loss=0.202, total=6749.91, n_correct=4803.2, ppl=3.56, accuracy=71.159, wps=18488.1, ups=1.37, wpb=13499.8, bsz=458.6, num_updates=23400, lr=9.245e-05, gnorm=0.434, clip=0, loss_scale=32, train_wall=73, gb_free=13.6, wall=22244
2023-08-26 18:32:51 | INFO | train_inner | epoch 020:    882 / 1191 loss=1.87, trans_loss=4.633, nll_loss=1.829, w2v_ctc_loss=0.592, task_loss=2.42, contrastive_loss=0.164, total=6725.15, n_correct=4789.13, ppl=3.55, accuracy=71.212, wps=18420.5, ups=1.37, wpb=13450.3, bsz=447.2, num_updates=23500, lr=9.22531e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=72, gb_free=13.1, wall=22317
2023-08-26 18:34:05 | INFO | train_inner | epoch 020:    982 / 1191 loss=1.867, trans_loss=4.632, nll_loss=1.828, w2v_ctc_loss=0.588, task_loss=2.541, contrastive_loss=0.155, total=6666.28, n_correct=4745.83, ppl=3.55, accuracy=71.192, wps=18123.8, ups=1.36, wpb=13332.6, bsz=433.5, num_updates=23600, lr=9.20575e-05, gnorm=0.428, clip=0, loss_scale=32, train_wall=73, gb_free=13.1, wall=22390
2023-08-26 18:35:18 | INFO | train_inner | epoch 020:   1082 / 1191 loss=1.869, trans_loss=4.633, nll_loss=1.83, w2v_ctc_loss=0.597, task_loss=2.322, contrastive_loss=0.15, total=6748.86, n_correct=4801.33, ppl=3.56, accuracy=71.143, wps=18445.6, ups=1.37, wpb=13497.7, bsz=458, num_updates=23700, lr=9.1863e-05, gnorm=0.428, clip=0, loss_scale=32, train_wall=73, gb_free=13.1, wall=22463
2023-08-26 18:36:31 | INFO | train_inner | epoch 020:   1182 / 1191 loss=1.873, trans_loss=4.639, nll_loss=1.838, w2v_ctc_loss=0.591, task_loss=2.378, contrastive_loss=0.195, total=6683.47, n_correct=4751.02, ppl=3.58, accuracy=71.086, wps=18175, ups=1.36, wpb=13366.9, bsz=452.7, num_updates=23800, lr=9.16698e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=73, gb_free=13.9, wall=22537
2023-08-26 18:36:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 18:37:11 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.767 | trans_loss 4.877 | nll_loss 2.094 | w2v_ctc_loss 1.196 | task_loss 8.564 | contrastive_loss 0.392 | total 6138.43 | n_correct 4363.14 | ppl 4.27 | accuracy 71.079 | uer 17.303 | wer 18.94 | raw_wer 18.94 | bleu 28.52 | wps 1740.3 | wpb 6138.4 | bsz 201.1 | num_updates 23809 | best_bleu 28.93
2023-08-26 18:37:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 23809 updates
2023-08-26 18:37:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.5208.pt
2023-08-26 18:37:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.5208.pt
2023-08-26 18:37:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.5208.pt (epoch 20 @ 23809 updates, score 28.52) (writing took 6.8177950639947085 seconds)
2023-08-26 18:37:18 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-26 18:37:18 | INFO | train | epoch 020 | loss 1.871 | trans_loss 4.632 | nll_loss 1.828 | w2v_ctc_loss 0.589 | task_loss 2.355 | contrastive_loss 0.2 | total 6703.69 | n_correct 4773.15 | ppl 3.55 | accuracy 71.202 | wps 17436.1 | ups 1.3 | wpb 13407.4 | bsz 452.1 | num_updates 23809 | lr 9.16525e-05 | gnorm 0.427 | clip 0 | loss_scale 32 | train_wall 861 | gb_free 15.1 | wall 22583
2023-08-26 18:37:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 18:37:18 | INFO | fairseq.trainer | begin training epoch 21
2023-08-26 18:37:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 18:38:32 | INFO | train_inner | epoch 021:     91 / 1191 loss=1.869, trans_loss=4.62, nll_loss=1.813, w2v_ctc_loss=0.574, task_loss=2.207, contrastive_loss=0.314, total=6760.63, n_correct=4834.56, ppl=3.51, accuracy=71.51, wps=11234.5, ups=0.83, wpb=13521.3, bsz=474.7, num_updates=23900, lr=9.14779e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=72, gb_free=12.3, wall=22657
2023-08-26 18:39:44 | INFO | train_inner | epoch 021:    191 / 1191 loss=1.851, trans_loss=4.611, nll_loss=1.802, w2v_ctc_loss=0.571, task_loss=2.209, contrastive_loss=0.177, total=6783.08, n_correct=4865.93, ppl=3.49, accuracy=71.736, wps=18839.2, ups=1.39, wpb=13566.2, bsz=471.6, num_updates=24000, lr=9.12871e-05, gnorm=0.417, clip=0, loss_scale=32, train_wall=71, gb_free=14, wall=22729
2023-08-26 18:39:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 18:40:16 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.763 | trans_loss 4.877 | nll_loss 2.096 | w2v_ctc_loss 1.186 | task_loss 8.548 | contrastive_loss 0.382 | total 6138.43 | n_correct 4355.29 | ppl 4.28 | accuracy 70.951 | uer 17.239 | wer 18.907 | raw_wer 18.907 | bleu 28.68 | wps 1766.6 | wpb 6138.4 | bsz 201.1 | num_updates 24000 | best_bleu 28.93
2023-08-26 18:40:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 24000 updates
2023-08-26 18:40:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_21_24000.pt
2023-08-26 18:40:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_21_24000.pt
2023-08-26 18:40:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_21_24000.pt (epoch 21 @ 24000 updates, score 28.68) (writing took 7.112865882998449 seconds)
2023-08-26 18:41:36 | INFO | train_inner | epoch 021:    291 / 1191 loss=1.857, trans_loss=4.618, nll_loss=1.81, w2v_ctc_loss=0.584, task_loss=2.442, contrastive_loss=0.142, total=6641.78, n_correct=4748.49, ppl=3.51, accuracy=71.494, wps=11864, ups=0.89, wpb=13283.6, bsz=436, num_updates=24100, lr=9.10975e-05, gnorm=0.43, clip=0, loss_scale=32, train_wall=71, gb_free=15.2, wall=22841
2023-08-26 18:42:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-26 18:42:50 | INFO | train_inner | epoch 021:    392 / 1191 loss=1.86, trans_loss=4.624, nll_loss=1.818, w2v_ctc_loss=0.583, task_loss=2.371, contrastive_loss=0.164, total=6672.67, n_correct=4763.9, ppl=3.53, accuracy=71.394, wps=18085.5, ups=1.36, wpb=13345.3, bsz=450.9, num_updates=24200, lr=9.09091e-05, gnorm=0.424, clip=0, loss_scale=16, train_wall=73, gb_free=13.9, wall=22915
2023-08-26 18:44:02 | INFO | train_inner | epoch 021:    492 / 1191 loss=1.861, trans_loss=4.616, nll_loss=1.808, w2v_ctc_loss=0.582, task_loss=2.457, contrastive_loss=0.18, total=6689.7, n_correct=4783.64, ppl=3.5, accuracy=71.508, wps=18517.2, ups=1.38, wpb=13379.4, bsz=438.4, num_updates=24300, lr=9.07218e-05, gnorm=0.427, clip=0, loss_scale=16, train_wall=72, gb_free=13.6, wall=22987
2023-08-26 18:45:14 | INFO | train_inner | epoch 021:    592 / 1191 loss=1.866, trans_loss=4.625, nll_loss=1.819, w2v_ctc_loss=0.592, task_loss=2.53, contrastive_loss=0.143, total=6614.82, n_correct=4719.85, ppl=3.53, accuracy=71.353, wps=18271.8, ups=1.38, wpb=13229.6, bsz=423.7, num_updates=24400, lr=9.05357e-05, gnorm=0.424, clip=0, loss_scale=16, train_wall=72, gb_free=15, wall=23060
2023-08-26 18:46:28 | INFO | train_inner | epoch 021:    692 / 1191 loss=1.869, trans_loss=4.626, nll_loss=1.82, w2v_ctc_loss=0.587, task_loss=2.306, contrastive_loss=0.217, total=6722.88, n_correct=4793.65, ppl=3.53, accuracy=71.304, wps=18354.4, ups=1.37, wpb=13445.8, bsz=466.8, num_updates=24500, lr=9.03508e-05, gnorm=0.427, clip=0, loss_scale=16, train_wall=73, gb_free=12.5, wall=23133
2023-08-26 18:47:40 | INFO | train_inner | epoch 021:    792 / 1191 loss=1.872, trans_loss=4.625, nll_loss=1.82, w2v_ctc_loss=0.582, task_loss=2.449, contrastive_loss=0.262, total=6639.93, n_correct=4735.4, ppl=3.53, accuracy=71.317, wps=18247, ups=1.37, wpb=13279.9, bsz=443.4, num_updates=24600, lr=9.0167e-05, gnorm=0.426, clip=0, loss_scale=16, train_wall=72, gb_free=11.4, wall=23206
2023-08-26 18:48:53 | INFO | train_inner | epoch 021:    892 / 1191 loss=1.868, trans_loss=4.623, nll_loss=1.818, w2v_ctc_loss=0.588, task_loss=2.34, contrastive_loss=0.21, total=6729.37, n_correct=4803.28, ppl=3.53, accuracy=71.378, wps=18593.5, ups=1.38, wpb=13458.7, bsz=452, num_updates=24700, lr=8.99843e-05, gnorm=0.426, clip=0, loss_scale=16, train_wall=72, gb_free=12.2, wall=23278
2023-08-26 18:50:06 | INFO | train_inner | epoch 021:    992 / 1191 loss=1.866, trans_loss=4.63, nll_loss=1.826, w2v_ctc_loss=0.581, task_loss=2.245, contrastive_loss=0.208, total=6803.81, n_correct=4852.02, ppl=3.55, accuracy=71.313, wps=18563.3, ups=1.36, wpb=13607.6, bsz=465.2, num_updates=24800, lr=8.98027e-05, gnorm=0.416, clip=0, loss_scale=16, train_wall=73, gb_free=12.7, wall=23351
2023-08-26 18:51:19 | INFO | train_inner | epoch 021:   1092 / 1191 loss=1.863, trans_loss=4.625, nll_loss=1.82, w2v_ctc_loss=0.58, task_loss=2.288, contrastive_loss=0.189, total=6727.98, n_correct=4800.16, ppl=3.53, accuracy=71.346, wps=18465.5, ups=1.37, wpb=13456, bsz=457.5, num_updates=24900, lr=8.96221e-05, gnorm=0.423, clip=0, loss_scale=16, train_wall=72, gb_free=12.6, wall=23424
2023-08-26 18:52:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 18:53:04 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.751 | trans_loss 4.869 | nll_loss 2.083 | w2v_ctc_loss 1.166 | task_loss 8.556 | contrastive_loss 0.381 | total 6138.43 | n_correct 4371 | ppl 4.24 | accuracy 71.207 | uer 17.209 | wer 18.907 | raw_wer 18.907 | bleu 28.82 | wps 1762 | wpb 6138.4 | bsz 201.1 | num_updates 24999 | best_bleu 28.93
2023-08-26 18:53:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 24999 updates
2023-08-26 18:53:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.8201.pt
2023-08-26 18:53:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.8201.pt
2023-08-26 18:53:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.8201.pt (epoch 21 @ 24999 updates, score 28.82) (writing took 7.327292555986787 seconds)
2023-08-26 18:53:12 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-26 18:53:12 | INFO | train | epoch 021 | loss 1.864 | trans_loss 4.622 | nll_loss 1.816 | w2v_ctc_loss 0.582 | task_loss 2.353 | contrastive_loss 0.199 | total 6704.28 | n_correct 4788.11 | ppl 3.52 | accuracy 71.419 | wps 16729.9 | ups 1.25 | wpb 13408.6 | bsz 452.3 | num_updates 24999 | lr 8.94445e-05 | gnorm 0.424 | clip 0 | loss_scale 16 | train_wall 859 | gb_free 13.4 | wall 23537
2023-08-26 18:53:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 18:53:12 | INFO | fairseq.trainer | begin training epoch 22
2023-08-26 18:53:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 18:53:20 | INFO | train_inner | epoch 022:      1 / 1191 loss=1.869, trans_loss=4.626, nll_loss=1.821, w2v_ctc_loss=0.585, task_loss=2.386, contrastive_loss=0.215, total=6667.93, n_correct=4755.1, ppl=3.53, accuracy=71.313, wps=11031.4, ups=0.83, wpb=13335.9, bsz=453.9, num_updates=25000, lr=8.94427e-05, gnorm=0.43, clip=0, loss_scale=16, train_wall=72, gb_free=10.6, wall=23545
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:0')
2023-08-26 18:54:32 | INFO | train_inner | epoch 022:    101 / 1191 loss=1.846, trans_loss=4.606, nll_loss=1.795, w2v_ctc_loss=0.564, task_loss=2.309, contrastive_loss=0.161, total=6752.63, n_correct=4851.55, ppl=3.47, accuracy=71.847, wps=18624.3, ups=1.38, wpb=13505.3, bsz=456.3, num_updates=25100, lr=8.92644e-05, gnorm=0.422, clip=0, loss_scale=16, train_wall=72, gb_free=14.5, wall=23618
2023-08-26 18:55:45 | INFO | train_inner | epoch 022:    201 / 1191 loss=1.853, trans_loss=4.609, nll_loss=1.799, w2v_ctc_loss=0.571, task_loss=2.426, contrastive_loss=0.185, total=6655.06, n_correct=4768.93, ppl=3.48, accuracy=71.659, wps=18302, ups=1.38, wpb=13310.1, bsz=443.4, num_updates=25200, lr=8.90871e-05, gnorm=0.424, clip=0, loss_scale=16, train_wall=72, gb_free=12, wall=23690
2023-08-26 18:56:58 | INFO | train_inner | epoch 022:    301 / 1191 loss=1.858, trans_loss=4.612, nll_loss=1.803, w2v_ctc_loss=0.575, task_loss=2.267, contrastive_loss=0.225, total=6760.33, n_correct=4845.72, ppl=3.49, accuracy=71.679, wps=18560.3, ups=1.37, wpb=13520.7, bsz=469.7, num_updates=25300, lr=8.89108e-05, gnorm=0.424, clip=0, loss_scale=16, train_wall=72, gb_free=13.1, wall=23763
2023-08-26 18:58:11 | INFO | train_inner | epoch 022:    401 / 1191 loss=1.848, trans_loss=4.607, nll_loss=1.797, w2v_ctc_loss=0.572, task_loss=2.346, contrastive_loss=0.157, total=6660.25, n_correct=4782.96, ppl=3.48, accuracy=71.814, wps=18111.6, ups=1.36, wpb=13320.5, bsz=455.7, num_updates=25400, lr=8.87357e-05, gnorm=0.424, clip=0, loss_scale=16, train_wall=73, gb_free=15.1, wall=23837
2023-08-26 18:59:24 | INFO | train_inner | epoch 022:    501 / 1191 loss=1.864, trans_loss=4.617, nll_loss=1.809, w2v_ctc_loss=0.583, task_loss=2.349, contrastive_loss=0.219, total=6720.12, n_correct=4806.84, ppl=3.5, accuracy=71.529, wps=18616, ups=1.39, wpb=13440.2, bsz=457.6, num_updates=25500, lr=8.85615e-05, gnorm=0.424, clip=0, loss_scale=16, train_wall=72, gb_free=13.8, wall=23909
2023-08-26 19:00:36 | INFO | train_inner | epoch 022:    601 / 1191 loss=1.851, trans_loss=4.611, nll_loss=1.802, w2v_ctc_loss=0.574, task_loss=2.396, contrastive_loss=0.156, total=6704.25, n_correct=4806.37, ppl=3.49, accuracy=71.691, wps=18481.7, ups=1.38, wpb=13408.5, bsz=447.4, num_updates=25600, lr=8.83883e-05, gnorm=0.42, clip=0, loss_scale=16, train_wall=72, gb_free=10.3, wall=23982
2023-08-26 19:01:49 | INFO | train_inner | epoch 022:    701 / 1191 loss=1.856, trans_loss=4.612, nll_loss=1.803, w2v_ctc_loss=0.571, task_loss=2.289, contrastive_loss=0.221, total=6710.51, n_correct=4809.29, ppl=3.49, accuracy=71.668, wps=18478.8, ups=1.38, wpb=13421, bsz=454.9, num_updates=25700, lr=8.82162e-05, gnorm=0.423, clip=0, loss_scale=16, train_wall=72, gb_free=15, wall=24054
2023-08-26 19:03:01 | INFO | train_inner | epoch 022:    801 / 1191 loss=1.857, trans_loss=4.61, nll_loss=1.801, w2v_ctc_loss=0.576, task_loss=2.454, contrastive_loss=0.208, total=6572.69, n_correct=4710.59, ppl=3.48, accuracy=71.669, wps=18271.1, ups=1.39, wpb=13145.4, bsz=434.8, num_updates=25800, lr=8.80451e-05, gnorm=0.429, clip=0, loss_scale=16, train_wall=71, gb_free=11.6, wall=24126
2023-08-26 19:04:15 | INFO | train_inner | epoch 022:    901 / 1191 loss=1.872, trans_loss=4.621, nll_loss=1.815, w2v_ctc_loss=0.583, task_loss=2.386, contrastive_loss=0.278, total=6701.42, n_correct=4781.35, ppl=3.52, accuracy=71.348, wps=18017.6, ups=1.34, wpb=13402.8, bsz=452.1, num_updates=25900, lr=8.7875e-05, gnorm=0.429, clip=0, loss_scale=16, train_wall=74, gb_free=12.5, wall=24201
2023-08-26 19:05:28 | INFO | train_inner | epoch 022:   1001 / 1191 loss=1.856, trans_loss=4.613, nll_loss=1.804, w2v_ctc_loss=0.576, task_loss=2.237, contrastive_loss=0.182, total=6847.97, n_correct=4906.42, ppl=3.49, accuracy=71.648, wps=18805.2, ups=1.37, wpb=13695.9, bsz=468.2, num_updates=26000, lr=8.77058e-05, gnorm=0.418, clip=0, loss_scale=16, train_wall=72, gb_free=13.2, wall=24273
2023-08-26 19:05:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:6')
2023-08-26 19:06:00 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.753 | trans_loss 4.865 | nll_loss 2.081 | w2v_ctc_loss 1.171 | task_loss 8.53 | contrastive_loss 0.395 | total 6138.43 | n_correct 4369 | ppl 4.23 | accuracy 71.175 | uer 17.198 | wer 18.832 | raw_wer 18.832 | bleu 28.93 | wps 1762.6 | wpb 6138.4 | bsz 201.1 | num_updates 26000 | best_bleu 28.93
2023-08-26 19:06:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 26000 updates
2023-08-26 19:06:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_22_26000.pt
2023-08-26 19:06:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_22_26000.pt
2023-08-26 19:06:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_22_26000.pt (epoch 22 @ 26000 updates, score 28.93) (writing took 11.701975281001069 seconds)
2023-08-26 19:07:24 | INFO | train_inner | epoch 022:   1101 / 1191 loss=1.859, trans_loss=4.614, nll_loss=1.805, w2v_ctc_loss=0.581, task_loss=2.352, contrastive_loss=0.185, total=6699.81, n_correct=4792.76, ppl=3.49, accuracy=71.536, wps=11515.8, ups=0.86, wpb=13399.6, bsz=447.9, num_updates=26100, lr=8.75376e-05, gnorm=0.421, clip=0, loss_scale=16, train_wall=71, gb_free=12.9, wall=24390
2023-08-26 19:08:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 19:09:03 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.758 | trans_loss 4.869 | nll_loss 2.085 | w2v_ctc_loss 1.184 | task_loss 8.603 | contrastive_loss 0.388 | total 6138.43 | n_correct 4367.14 | ppl 4.24 | accuracy 71.144 | uer 16.918 | wer 18.62 | raw_wer 18.62 | bleu 28.78 | wps 1760.7 | wpb 6138.4 | bsz 201.1 | num_updates 26190 | best_bleu 28.93
2023-08-26 19:09:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 26190 updates
2023-08-26 19:09:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.7801.pt
2023-08-26 19:09:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.7801.pt
2023-08-26 19:09:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.7801.pt (epoch 22 @ 26190 updates, score 28.78) (writing took 6.588038697998854 seconds)
2023-08-26 19:09:10 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-26 19:09:10 | INFO | train | epoch 022 | loss 1.857 | trans_loss 4.612 | nll_loss 1.804 | w2v_ctc_loss 0.576 | task_loss 2.355 | contrastive_loss 0.197 | total 6703.69 | n_correct 4802.16 | ppl 3.49 | accuracy 71.635 | wps 16664.2 | ups 1.24 | wpb 13407.4 | bsz 452.1 | num_updates 26190 | lr 8.73871e-05 | gnorm 0.423 | clip 0 | loss_scale 16 | train_wall 859 | gb_free 13.5 | wall 24495
2023-08-26 19:09:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 19:09:10 | INFO | fairseq.trainer | begin training epoch 23
2023-08-26 19:09:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 19:09:25 | INFO | train_inner | epoch 023:     10 / 1191 loss=1.861, trans_loss=4.618, nll_loss=1.81, w2v_ctc_loss=0.58, task_loss=2.517, contrastive_loss=0.184, total=6653.96, n_correct=4760.56, ppl=3.51, accuracy=71.545, wps=11072.9, ups=0.83, wpb=13307.9, bsz=432.5, num_updates=26200, lr=8.73704e-05, gnorm=0.422, clip=0, loss_scale=16, train_wall=73, gb_free=13.9, wall=24510
2023-08-26 19:10:37 | INFO | train_inner | epoch 023:    110 / 1191 loss=1.85, trans_loss=4.599, nll_loss=1.786, w2v_ctc_loss=0.572, task_loss=2.461, contrastive_loss=0.176, total=6649.43, n_correct=4778.19, ppl=3.45, accuracy=71.859, wps=18319.6, ups=1.38, wpb=13298.9, bsz=438.7, num_updates=26300, lr=8.72041e-05, gnorm=0.427, clip=0, loss_scale=32, train_wall=72, gb_free=5.3, wall=24583
2023-08-26 19:11:51 | INFO | train_inner | epoch 023:    210 / 1191 loss=1.848, trans_loss=4.605, nll_loss=1.794, w2v_ctc_loss=0.57, task_loss=2.224, contrastive_loss=0.171, total=6807.79, n_correct=4886.26, ppl=3.47, accuracy=71.775, wps=18560.5, ups=1.36, wpb=13615.6, bsz=473.5, num_updates=26400, lr=8.70388e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=73, gb_free=13.7, wall=24656
2023-08-26 19:13:03 | INFO | train_inner | epoch 023:    310 / 1191 loss=1.838, trans_loss=4.596, nll_loss=1.782, w2v_ctc_loss=0.56, task_loss=2.247, contrastive_loss=0.14, total=6819.51, n_correct=4911.35, ppl=3.44, accuracy=72.019, wps=18791.9, ups=1.38, wpb=13639, bsz=464, num_updates=26500, lr=8.68744e-05, gnorm=0.417, clip=0, loss_scale=32, train_wall=72, gb_free=11.3, wall=24729
2023-08-26 19:14:16 | INFO | train_inner | epoch 023:    410 / 1191 loss=1.857, trans_loss=4.607, nll_loss=1.797, w2v_ctc_loss=0.567, task_loss=2.422, contrastive_loss=0.252, total=6727.48, n_correct=4823.2, ppl=3.47, accuracy=71.694, wps=18364.3, ups=1.36, wpb=13455, bsz=442.9, num_updates=26600, lr=8.6711e-05, gnorm=0.417, clip=0, loss_scale=32, train_wall=73, gb_free=12.2, wall=24802
2023-08-26 19:15:29 | INFO | train_inner | epoch 023:    510 / 1191 loss=1.85, trans_loss=4.603, nll_loss=1.792, w2v_ctc_loss=0.563, task_loss=2.341, contrastive_loss=0.209, total=6704.27, n_correct=4814.59, ppl=3.46, accuracy=71.814, wps=18550.7, ups=1.38, wpb=13408.5, bsz=451.1, num_updates=26700, lr=8.65485e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=72, gb_free=12.2, wall=24874
2023-08-26 19:16:41 | INFO | train_inner | epoch 023:    610 / 1191 loss=1.853, trans_loss=4.608, nll_loss=1.798, w2v_ctc_loss=0.571, task_loss=2.299, contrastive_loss=0.203, total=6683.43, n_correct=4795.86, ppl=3.48, accuracy=71.757, wps=18479.2, ups=1.38, wpb=13366.9, bsz=456.8, num_updates=26800, lr=8.63868e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=72, gb_free=13.5, wall=24946
2023-08-26 19:17:54 | INFO | train_inner | epoch 023:    710 / 1191 loss=1.858, trans_loss=4.608, nll_loss=1.797, w2v_ctc_loss=0.57, task_loss=2.454, contrastive_loss=0.254, total=6643.28, n_correct=4762.71, ppl=3.48, accuracy=71.692, wps=18187.1, ups=1.37, wpb=13286.6, bsz=439.6, num_updates=26900, lr=8.62261e-05, gnorm=0.429, clip=0, loss_scale=32, train_wall=72, gb_free=13.6, wall=25020
2023-08-26 19:19:07 | INFO | train_inner | epoch 023:    810 / 1191 loss=1.848, trans_loss=4.606, nll_loss=1.796, w2v_ctc_loss=0.569, task_loss=2.402, contrastive_loss=0.159, total=6723.07, n_correct=4822.25, ppl=3.47, accuracy=71.727, wps=18351.8, ups=1.36, wpb=13446.1, bsz=447.4, num_updates=27000, lr=8.60663e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=73, gb_free=14.2, wall=25093
2023-08-26 19:20:19 | INFO | train_inner | epoch 023:    910 / 1191 loss=1.845, trans_loss=4.597, nll_loss=1.785, w2v_ctc_loss=0.574, task_loss=2.263, contrastive_loss=0.153, total=6721.05, n_correct=4839.76, ppl=3.45, accuracy=72.009, wps=18668.8, ups=1.39, wpb=13442.1, bsz=465, num_updates=27100, lr=8.59074e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=72, gb_free=14.1, wall=25165
2023-08-26 19:21:31 | INFO | train_inner | epoch 023:   1010 / 1191 loss=1.85, trans_loss=4.603, nll_loss=1.793, w2v_ctc_loss=0.574, task_loss=2.248, contrastive_loss=0.2, total=6675.94, n_correct=4797.75, ppl=3.46, accuracy=71.866, wps=18520.8, ups=1.39, wpb=13351.9, bsz=465.9, num_updates=27200, lr=8.57493e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=72, gb_free=13.3, wall=25237
2023-08-26 19:22:44 | INFO | train_inner | epoch 023:   1110 / 1191 loss=1.855, trans_loss=4.609, nll_loss=1.8, w2v_ctc_loss=0.574, task_loss=2.471, contrastive_loss=0.195, total=6637.78, n_correct=4757.12, ppl=3.48, accuracy=71.667, wps=18355.6, ups=1.38, wpb=13275.6, bsz=440.1, num_updates=27300, lr=8.55921e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=72, gb_free=13.3, wall=25309
2023-08-26 19:23:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 19:24:15 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 3.738 | trans_loss 4.861 | nll_loss 2.077 | w2v_ctc_loss 1.146 | task_loss 8.576 | contrastive_loss 0.379 | total 6138.43 | n_correct 4375.43 | ppl 4.22 | accuracy 71.279 | uer 16.621 | wer 18.126 | raw_wer 18.126 | bleu 28.84 | wps 1754 | wpb 6138.4 | bsz 201.1 | num_updates 27381 | best_bleu 28.93
2023-08-26 19:24:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 27381 updates
2023-08-26 19:24:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.8407.pt
2023-08-26 19:24:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.8407.pt
2023-08-26 19:24:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.8407.pt (epoch 23 @ 27381 updates, score 28.84) (writing took 6.2236458609986585 seconds)
2023-08-26 19:24:22 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-26 19:24:22 | INFO | train | epoch 023 | loss 1.851 | trans_loss 4.604 | nll_loss 1.793 | w2v_ctc_loss 0.57 | task_loss 2.354 | contrastive_loss 0.195 | total 6703.69 | n_correct 4813.12 | ppl 3.47 | accuracy 71.798 | wps 17509.2 | ups 1.31 | wpb 13407.4 | bsz 452.1 | num_updates 27381 | lr 8.54654e-05 | gnorm 0.424 | clip 0 | loss_scale 32 | train_wall 859 | gb_free 14.5 | wall 25407
2023-08-26 19:24:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 19:24:22 | INFO | fairseq.trainer | begin training epoch 24
2023-08-26 19:24:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 19:24:44 | INFO | train_inner | epoch 024:     19 / 1191 loss=1.858, trans_loss=4.607, nll_loss=1.796, w2v_ctc_loss=0.574, task_loss=2.458, contrastive_loss=0.234, total=6654.8, n_correct=4772, ppl=3.47, accuracy=71.708, wps=11106.5, ups=0.83, wpb=13309.6, bsz=439.5, num_updates=27400, lr=8.54358e-05, gnorm=0.428, clip=0, loss_scale=32, train_wall=72, gb_free=11.6, wall=25429
2023-08-26 19:25:56 | INFO | train_inner | epoch 024:    119 / 1191 loss=1.84, trans_loss=4.595, nll_loss=1.781, w2v_ctc_loss=0.557, task_loss=2.208, contrastive_loss=0.195, total=6770.69, n_correct=4883.13, ppl=3.44, accuracy=72.122, wps=18725.6, ups=1.38, wpb=13541.4, bsz=478, num_updates=27500, lr=8.52803e-05, gnorm=0.417, clip=0, loss_scale=32, train_wall=72, gb_free=13.8, wall=25501
2023-08-26 19:27:08 | INFO | train_inner | epoch 024:    219 / 1191 loss=1.841, trans_loss=4.591, nll_loss=1.776, w2v_ctc_loss=0.549, task_loss=2.165, contrastive_loss=0.262, total=6808.43, n_correct=4915.69, ppl=3.42, accuracy=72.2, wps=18796.1, ups=1.38, wpb=13616.9, bsz=478.7, num_updates=27600, lr=8.51257e-05, gnorm=0.413, clip=0, loss_scale=32, train_wall=72, gb_free=14.6, wall=25574
2023-08-26 19:28:21 | INFO | train_inner | epoch 024:    319 / 1191 loss=1.846, trans_loss=4.598, nll_loss=1.785, w2v_ctc_loss=0.562, task_loss=2.357, contrastive_loss=0.203, total=6739.01, n_correct=4851, ppl=3.45, accuracy=71.984, wps=18583, ups=1.38, wpb=13478, bsz=450.4, num_updates=27700, lr=8.49719e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=72, gb_free=14.3, wall=25646
2023-08-26 19:29:34 | INFO | train_inner | epoch 024:    419 / 1191 loss=1.843, trans_loss=4.595, nll_loss=1.781, w2v_ctc_loss=0.564, task_loss=2.464, contrastive_loss=0.167, total=6663.22, n_correct=4793.82, ppl=3.44, accuracy=71.944, wps=18267.3, ups=1.37, wpb=13326.4, bsz=436.9, num_updates=27800, lr=8.48189e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=72, gb_free=13.6, wall=25719
2023-08-26 19:30:47 | INFO | train_inner | epoch 024:    519 / 1191 loss=1.854, trans_loss=4.6, nll_loss=1.788, w2v_ctc_loss=0.568, task_loss=2.433, contrastive_loss=0.26, total=6651.11, n_correct=4780.9, ppl=3.45, accuracy=71.881, wps=18215.3, ups=1.37, wpb=13302.2, bsz=454.4, num_updates=27900, lr=8.46668e-05, gnorm=0.429, clip=0, loss_scale=32, train_wall=73, gb_free=11.7, wall=25792
2023-08-26 19:31:59 | INFO | train_inner | epoch 024:    619 / 1191 loss=1.841, trans_loss=4.594, nll_loss=1.779, w2v_ctc_loss=0.567, task_loss=2.54, contrastive_loss=0.131, total=6545.91, n_correct=4713.67, ppl=3.43, accuracy=72.009, wps=18200.8, ups=1.39, wpb=13091.8, bsz=419.5, num_updates=28000, lr=8.45154e-05, gnorm=0.428, clip=0, loss_scale=32, train_wall=71, gb_free=14, wall=25864
2023-08-26 19:31:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 19:32:31 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.757 | trans_loss 4.868 | nll_loss 2.084 | w2v_ctc_loss 1.188 | task_loss 8.578 | contrastive_loss 0.384 | total 6138.43 | n_correct 4365.71 | ppl 4.24 | accuracy 71.121 | uer 16.754 | wer 18.237 | raw_wer 18.237 | bleu 29.02 | wps 1766.4 | wpb 6138.4 | bsz 201.1 | num_updates 28000 | best_bleu 29.02
2023-08-26 19:32:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 28000 updates
2023-08-26 19:32:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_24_28000.pt
2023-08-26 19:32:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_24_28000.pt
2023-08-26 19:32:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_24_28000.pt (epoch 24 @ 28000 updates, score 29.02) (writing took 13.926980124000693 seconds)
2023-08-26 19:33:58 | INFO | train_inner | epoch 024:    719 / 1191 loss=1.842, trans_loss=4.592, nll_loss=1.778, w2v_ctc_loss=0.562, task_loss=2.235, contrastive_loss=0.191, total=6744.37, n_correct=4864, ppl=3.43, accuracy=72.119, wps=11328.3, ups=0.84, wpb=13488.7, bsz=468, num_updates=28100, lr=8.43649e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=72, gb_free=14.1, wall=25983
2023-08-26 19:35:10 | INFO | train_inner | epoch 024:    819 / 1191 loss=1.837, trans_loss=4.589, nll_loss=1.775, w2v_ctc_loss=0.562, task_loss=2.334, contrastive_loss=0.153, total=6726.26, n_correct=4852.64, ppl=3.42, accuracy=72.145, wps=18716.4, ups=1.39, wpb=13452.5, bsz=450, num_updates=28200, lr=8.42152e-05, gnorm=0.418, clip=0, loss_scale=32, train_wall=71, gb_free=14, wall=26055
2023-08-26 19:36:23 | INFO | train_inner | epoch 024:    919 / 1191 loss=1.837, trans_loss=4.595, nll_loss=1.782, w2v_ctc_loss=0.558, task_loss=2.305, contrastive_loss=0.151, total=6729.03, n_correct=4854.71, ppl=3.44, accuracy=72.146, wps=18391.6, ups=1.37, wpb=13458.1, bsz=457.1, num_updates=28300, lr=8.40663e-05, gnorm=0.421, clip=0, loss_scale=64, train_wall=73, gb_free=14.2, wall=26128
2023-08-26 19:37:36 | INFO | train_inner | epoch 024:   1019 / 1191 loss=1.856, trans_loss=4.601, nll_loss=1.789, w2v_ctc_loss=0.57, task_loss=2.464, contrastive_loss=0.258, total=6600.79, n_correct=4741.55, ppl=3.46, accuracy=71.833, wps=18024.4, ups=1.37, wpb=13201.6, bsz=442.6, num_updates=28400, lr=8.39181e-05, gnorm=0.429, clip=0, loss_scale=64, train_wall=73, gb_free=8.3, wall=26202
2023-08-26 19:38:50 | INFO | train_inner | epoch 024:   1119 / 1191 loss=1.842, trans_loss=4.596, nll_loss=1.783, w2v_ctc_loss=0.563, task_loss=2.466, contrastive_loss=0.143, total=6701.65, n_correct=4827.58, ppl=3.44, accuracy=72.036, wps=18197.7, ups=1.36, wpb=13403.3, bsz=434.4, num_updates=28500, lr=8.37708e-05, gnorm=0.418, clip=0, loss_scale=64, train_wall=73, gb_free=10.3, wall=26275
2023-08-26 19:39:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-26 19:39:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 19:40:14 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.748 | trans_loss 4.863 | nll_loss 2.077 | w2v_ctc_loss 1.167 | task_loss 8.622 | contrastive_loss 0.389 | total 6138.43 | n_correct 4372.57 | ppl 4.22 | accuracy 71.233 | uer 16.947 | wer 18.442 | raw_wer 18.442 | bleu 28.88 | wps 1762.3 | wpb 6138.4 | bsz 201.1 | num_updates 28571 | best_bleu 29.02
2023-08-26 19:40:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 28571 updates
2023-08-26 19:40:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.8809.pt
2023-08-26 19:40:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.8809.pt
2023-08-26 19:40:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_28.8809.pt (epoch 24 @ 28571 updates, score 28.88) (writing took 7.169863745002658 seconds)
2023-08-26 19:40:22 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-26 19:40:22 | INFO | train | epoch 024 | loss 1.843 | trans_loss 4.595 | nll_loss 1.781 | w2v_ctc_loss 0.562 | task_loss 2.358 | contrastive_loss 0.19 | total 6702.89 | n_correct 4828.94 | ppl 3.44 | accuracy 72.043 | wps 16616.7 | ups 1.24 | wpb 13405.8 | bsz 451.7 | num_updates 28571 | lr 8.36666e-05 | gnorm 0.421 | clip 0 | loss_scale 32 | train_wall 859 | gb_free 14.9 | wall 26367
2023-08-26 19:40:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 19:40:22 | INFO | fairseq.trainer | begin training epoch 25
2023-08-26 19:40:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 19:40:50 | INFO | train_inner | epoch 025:     29 / 1191 loss=1.838, trans_loss=4.589, nll_loss=1.774, w2v_ctc_loss=0.562, task_loss=2.403, contrastive_loss=0.149, total=6700.45, n_correct=4837.89, ppl=3.42, accuracy=72.202, wps=11129.5, ups=0.83, wpb=13400.9, bsz=443.4, num_updates=28600, lr=8.36242e-05, gnorm=0.417, clip=0, loss_scale=32, train_wall=72, gb_free=13.8, wall=26396
2023-08-26 19:42:02 | INFO | train_inner | epoch 025:    129 / 1191 loss=1.839, trans_loss=4.577, nll_loss=1.758, w2v_ctc_loss=0.554, task_loss=2.493, contrastive_loss=0.241, total=6583.6, n_correct=4765.67, ppl=3.38, accuracy=72.387, wps=18256.3, ups=1.39, wpb=13167.2, bsz=436.5, num_updates=28700, lr=8.34784e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=71, gb_free=13.2, wall=26468
2023-08-26 19:43:15 | INFO | train_inner | epoch 025:    229 / 1191 loss=1.829, trans_loss=4.587, nll_loss=1.771, w2v_ctc_loss=0.549, task_loss=2.252, contrastive_loss=0.151, total=6780.64, n_correct=4899.62, ppl=3.41, accuracy=72.259, wps=18578.9, ups=1.37, wpb=13561.3, bsz=471, num_updates=28800, lr=8.33333e-05, gnorm=0.413, clip=0, loss_scale=32, train_wall=72, gb_free=14.1, wall=26541
2023-08-26 19:44:28 | INFO | train_inner | epoch 025:    329 / 1191 loss=1.84, trans_loss=4.585, nll_loss=1.768, w2v_ctc_loss=0.567, task_loss=2.478, contrastive_loss=0.165, total=6618.73, n_correct=4776, ppl=3.41, accuracy=72.159, wps=18133.8, ups=1.37, wpb=13237.5, bsz=431.7, num_updates=28900, lr=8.3189e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=72, gb_free=13.6, wall=26614
2023-08-26 19:45:42 | INFO | train_inner | epoch 025:    429 / 1191 loss=1.839, trans_loss=4.588, nll_loss=1.772, w2v_ctc_loss=0.562, task_loss=2.637, contrastive_loss=0.157, total=6559, n_correct=4733.41, ppl=3.42, accuracy=72.167, wps=17862.7, ups=1.36, wpb=13118, bsz=418.7, num_updates=29000, lr=8.30455e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=73, gb_free=13.4, wall=26687
2023-08-26 19:46:55 | INFO | train_inner | epoch 025:    529 / 1191 loss=1.831, trans_loss=4.585, nll_loss=1.768, w2v_ctc_loss=0.55, task_loss=2.137, contrastive_loss=0.173, total=6859.95, n_correct=4961.07, ppl=3.41, accuracy=72.319, wps=18871.5, ups=1.38, wpb=13719.9, bsz=486.8, num_updates=29100, lr=8.29027e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=72, gb_free=13, wall=26760
2023-08-26 19:48:07 | INFO | train_inner | epoch 025:    629 / 1191 loss=1.832, trans_loss=4.582, nll_loss=1.764, w2v_ctc_loss=0.553, task_loss=2.326, contrastive_loss=0.174, total=6758.81, n_correct=4893.3, ppl=3.4, accuracy=72.399, wps=18771.7, ups=1.39, wpb=13517.6, bsz=450.4, num_updates=29200, lr=8.27606e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=71, gb_free=14.3, wall=26832
2023-08-26 19:49:19 | INFO | train_inner | epoch 025:    729 / 1191 loss=1.848, trans_loss=4.591, nll_loss=1.777, w2v_ctc_loss=0.56, task_loss=2.382, contrastive_loss=0.267, total=6686.07, n_correct=4819.4, ppl=3.43, accuracy=72.081, wps=18417.5, ups=1.38, wpb=13372.1, bsz=450.8, num_updates=29300, lr=8.26192e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=72, gb_free=13.7, wall=26905
2023-08-26 19:50:32 | INFO | train_inner | epoch 025:    829 / 1191 loss=1.84, trans_loss=4.59, nll_loss=1.776, w2v_ctc_loss=0.558, task_loss=2.315, contrastive_loss=0.186, total=6724.86, n_correct=4850.07, ppl=3.42, accuracy=72.122, wps=18430, ups=1.37, wpb=13449.7, bsz=454.4, num_updates=29400, lr=8.24786e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=72, gb_free=12.2, wall=26978
2023-08-26 19:51:45 | INFO | train_inner | epoch 025:    929 / 1191 loss=1.834, trans_loss=4.585, nll_loss=1.769, w2v_ctc_loss=0.551, task_loss=2.207, contrastive_loss=0.18, total=6787.73, n_correct=4903.75, ppl=3.41, accuracy=72.244, wps=18620, ups=1.37, wpb=13575.5, bsz=474.6, num_updates=29500, lr=8.23387e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=72, gb_free=12.4, wall=27051
2023-08-26 19:52:57 | INFO | train_inner | epoch 025:   1029 / 1191 loss=1.843, trans_loss=4.598, nll_loss=1.785, w2v_ctc_loss=0.558, task_loss=2.338, contrastive_loss=0.197, total=6654.71, n_correct=4787.58, ppl=3.45, accuracy=71.943, wps=18589.9, ups=1.4, wpb=13309.4, bsz=451.1, num_updates=29600, lr=8.21995e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=71, gb_free=12.5, wall=27122
2023-08-26 19:54:09 | INFO | train_inner | epoch 025:   1129 / 1191 loss=1.84, trans_loss=4.586, nll_loss=1.77, w2v_ctc_loss=0.565, task_loss=2.439, contrastive_loss=0.182, total=6685.06, n_correct=4826.58, ppl=3.41, accuracy=72.2, wps=18361.9, ups=1.37, wpb=13370.1, bsz=444.3, num_updates=29700, lr=8.2061e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=72, gb_free=11.9, wall=27195
2023-08-26 19:54:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 19:55:27 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.751 | trans_loss 4.857 | nll_loss 2.069 | w2v_ctc_loss 1.199 | task_loss 8.572 | contrastive_loss 0.378 | total 6138.43 | n_correct 4376.43 | ppl 4.2 | accuracy 71.296 | uer 17.041 | wer 18.617 | raw_wer 18.617 | bleu 29.07 | wps 1752.4 | wpb 6138.4 | bsz 201.1 | num_updates 29762 | best_bleu 29.07
2023-08-26 19:55:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 29762 updates
2023-08-26 19:55:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 19:55:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 19:55:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 25 @ 29762 updates, score 29.07) (writing took 10.87488424500043 seconds)
2023-08-26 19:55:39 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-26 19:55:39 | INFO | train | epoch 025 | loss 1.838 | trans_loss 4.587 | nll_loss 1.772 | w2v_ctc_loss 0.557 | task_loss 2.355 | contrastive_loss 0.192 | total 6703.69 | n_correct 4839.86 | ppl 3.41 | accuracy 72.197 | wps 17420.2 | ups 1.3 | wpb 13407.4 | bsz 452.1 | num_updates 29762 | lr 8.19755e-05 | gnorm 0.421 | clip 0 | loss_scale 32 | train_wall 858 | gb_free 11.4 | wall 27284
2023-08-26 19:55:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 19:55:39 | INFO | fairseq.trainer | begin training epoch 26
2023-08-26 19:55:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 19:56:13 | INFO | train_inner | epoch 026:     38 / 1191 loss=1.842, trans_loss=4.59, nll_loss=1.776, w2v_ctc_loss=0.555, task_loss=2.245, contrastive_loss=0.225, total=6821.45, n_correct=4918.79, ppl=3.42, accuracy=72.108, wps=11011, ups=0.81, wpb=13642.9, bsz=465.1, num_updates=29800, lr=8.19232e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=72, gb_free=10.1, wall=27319
2023-08-26 19:57:27 | INFO | train_inner | epoch 026:    138 / 1191 loss=1.827, trans_loss=4.578, nll_loss=1.759, w2v_ctc_loss=0.546, task_loss=2.375, contrastive_loss=0.17, total=6715.27, n_correct=4863.68, ppl=3.39, accuracy=72.427, wps=18348.7, ups=1.37, wpb=13430.5, bsz=454.7, num_updates=29900, lr=8.17861e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=73, gb_free=12.9, wall=27392
2023-08-26 19:58:39 | INFO | train_inner | epoch 026:    238 / 1191 loss=1.828, trans_loss=4.571, nll_loss=1.751, w2v_ctc_loss=0.549, task_loss=2.355, contrastive_loss=0.197, total=6666.23, n_correct=4837.6, ppl=3.37, accuracy=72.569, wps=18443.5, ups=1.38, wpb=13332.5, bsz=450.1, num_updates=30000, lr=8.16497e-05, gnorm=0.418, clip=0, loss_scale=32, train_wall=72, gb_free=13.9, wall=27464
2023-08-26 19:58:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 19:59:11 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.76 | trans_loss 4.862 | nll_loss 2.076 | w2v_ctc_loss 1.217 | task_loss 8.624 | contrastive_loss 0.378 | total 6138.43 | n_correct 4375.29 | ppl 4.22 | accuracy 71.277 | uer 16.861 | wer 18.453 | raw_wer 18.453 | bleu 28.78 | wps 1769 | wpb 6138.4 | bsz 201.1 | num_updates 30000 | best_bleu 29.07
2023-08-26 19:59:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 30000 updates
2023-08-26 19:59:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_26_30000.pt
2023-08-26 19:59:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_26_30000.pt
2023-08-26 19:59:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_26_30000.pt (epoch 26 @ 30000 updates, score 28.78) (writing took 7.997757988006924 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:0')
2023-08-26 20:00:32 | INFO | train_inner | epoch 026:    338 / 1191 loss=1.831, trans_loss=4.579, nll_loss=1.761, w2v_ctc_loss=0.545, task_loss=2.034, contrastive_loss=0.237, total=6899.8, n_correct=4996.33, ppl=3.39, accuracy=72.413, wps=12201.1, ups=0.88, wpb=13799.6, bsz=500.6, num_updates=30100, lr=8.15139e-05, gnorm=0.416, clip=0, loss_scale=32, train_wall=72, gb_free=10.2, wall=27577
2023-08-26 20:01:45 | INFO | train_inner | epoch 026:    438 / 1191 loss=1.833, trans_loss=4.574, nll_loss=1.755, w2v_ctc_loss=0.554, task_loss=2.543, contrastive_loss=0.193, total=6569.02, n_correct=4758.04, ppl=3.37, accuracy=72.432, wps=18095.8, ups=1.38, wpb=13138, bsz=423, num_updates=30200, lr=8.13788e-05, gnorm=0.43, clip=0, loss_scale=32, train_wall=72, gb_free=14.6, wall=27650
2023-08-26 20:02:58 | INFO | train_inner | epoch 026:    538 / 1191 loss=1.835, trans_loss=4.578, nll_loss=1.759, w2v_ctc_loss=0.553, task_loss=2.374, contrastive_loss=0.209, total=6687.4, n_correct=4839.87, ppl=3.38, accuracy=72.373, wps=18261.5, ups=1.37, wpb=13374.8, bsz=452.8, num_updates=30300, lr=8.12444e-05, gnorm=0.423, clip=0, loss_scale=32, train_wall=73, gb_free=14.7, wall=27723
2023-08-26 20:04:11 | INFO | train_inner | epoch 026:    638 / 1191 loss=1.836, trans_loss=4.58, nll_loss=1.761, w2v_ctc_loss=0.555, task_loss=2.555, contrastive_loss=0.2, total=6600.22, n_correct=4772.64, ppl=3.39, accuracy=72.31, wps=18171.4, ups=1.38, wpb=13200.4, bsz=425.9, num_updates=30400, lr=8.11107e-05, gnorm=0.423, clip=0, loss_scale=32, train_wall=72, gb_free=10.8, wall=27796
2023-08-26 20:05:24 | INFO | train_inner | epoch 026:    738 / 1191 loss=1.833, trans_loss=4.583, nll_loss=1.766, w2v_ctc_loss=0.554, task_loss=2.379, contrastive_loss=0.155, total=6782.32, n_correct=4906.64, ppl=3.4, accuracy=72.345, wps=18537.4, ups=1.37, wpb=13564.6, bsz=446.6, num_updates=30500, lr=8.09776e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=73, gb_free=12.2, wall=27869
2023-08-26 20:06:36 | INFO | train_inner | epoch 026:    838 / 1191 loss=1.829, trans_loss=4.574, nll_loss=1.755, w2v_ctc_loss=0.546, task_loss=2.296, contrastive_loss=0.202, total=6691.89, n_correct=4849.42, ppl=3.38, accuracy=72.467, wps=18524.9, ups=1.38, wpb=13383.8, bsz=458.3, num_updates=30600, lr=8.08452e-05, gnorm=0.414, clip=0, loss_scale=32, train_wall=72, gb_free=13.1, wall=27941
2023-08-26 20:07:48 | INFO | train_inner | epoch 026:    938 / 1191 loss=1.843, trans_loss=4.587, nll_loss=1.771, w2v_ctc_loss=0.562, task_loss=2.423, contrastive_loss=0.219, total=6663.94, n_correct=4810.54, ppl=3.41, accuracy=72.188, wps=18420.7, ups=1.38, wpb=13327.9, bsz=443.6, num_updates=30700, lr=8.07134e-05, gnorm=0.426, clip=0, loss_scale=64, train_wall=72, gb_free=10.4, wall=28014
2023-08-26 20:09:01 | INFO | train_inner | epoch 026:   1038 / 1191 loss=1.837, trans_loss=4.586, nll_loss=1.77, w2v_ctc_loss=0.563, task_loss=2.394, contrastive_loss=0.154, total=6693.53, n_correct=4831.5, ppl=3.41, accuracy=72.182, wps=18309.5, ups=1.37, wpb=13387.1, bsz=446.3, num_updates=30800, lr=8.05823e-05, gnorm=0.424, clip=0, loss_scale=64, train_wall=73, gb_free=5.7, wall=28087
2023-08-26 20:10:15 | INFO | train_inner | epoch 026:   1138 / 1191 loss=1.834, trans_loss=4.587, nll_loss=1.771, w2v_ctc_loss=0.553, task_loss=2.235, contrastive_loss=0.185, total=6798.29, n_correct=4916.4, ppl=3.41, accuracy=72.318, wps=18530.8, ups=1.36, wpb=13596.6, bsz=478.7, num_updates=30900, lr=8.04518e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=73, gb_free=10.5, wall=28160
2023-08-26 20:10:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:3')
2023-08-26 20:11:26 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.746 | trans_loss 4.861 | nll_loss 2.075 | w2v_ctc_loss 1.166 | task_loss 8.556 | contrastive_loss 0.386 | total 6138.43 | n_correct 4379.43 | ppl 4.21 | accuracy 71.344 | uer 16.816 | wer 18.353 | raw_wer 18.353 | bleu 29.11 | wps 1768.5 | wpb 6138.4 | bsz 201.1 | num_updates 30953 | best_bleu 29.11
2023-08-26 20:11:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 30953 updates
2023-08-26 20:11:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 20:11:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 20:11:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 26 @ 30953 updates, score 29.11) (writing took 10.455008597011329 seconds)
2023-08-26 20:11:37 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-26 20:11:37 | INFO | train | epoch 026 | loss 1.833 | trans_loss 4.58 | nll_loss 1.762 | w2v_ctc_loss 0.552 | task_loss 2.357 | contrastive_loss 0.19 | total 6703.69 | n_correct 4850.74 | ppl 3.39 | accuracy 72.359 | wps 16669.8 | ups 1.24 | wpb 13407.4 | bsz 452.1 | num_updates 30953 | lr 8.03829e-05 | gnorm 0.421 | clip 0 | loss_scale 64 | train_wall 859 | gb_free 12.4 | wall 28242
2023-08-26 20:11:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 20:11:37 | INFO | fairseq.trainer | begin training epoch 27
2023-08-26 20:11:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 20:12:18 | INFO | train_inner | epoch 027:     47 / 1191 loss=1.83, trans_loss=4.578, nll_loss=1.76, w2v_ctc_loss=0.555, task_loss=2.417, contrastive_loss=0.147, total=6630.76, n_correct=4800.61, ppl=3.39, accuracy=72.399, wps=10761.5, ups=0.81, wpb=13261.5, bsz=438.4, num_updates=31000, lr=8.03219e-05, gnorm=0.426, clip=0, loss_scale=64, train_wall=72, gb_free=13.5, wall=28283
2023-08-26 20:13:31 | INFO | train_inner | epoch 027:    147 / 1191 loss=1.834, trans_loss=4.572, nll_loss=1.751, w2v_ctc_loss=0.549, task_loss=2.305, contrastive_loss=0.242, total=6722.36, n_correct=4871.26, ppl=3.37, accuracy=72.464, wps=18384.4, ups=1.37, wpb=13444.7, bsz=465.8, num_updates=31100, lr=8.01927e-05, gnorm=0.421, clip=0, loss_scale=64, train_wall=73, gb_free=11.6, wall=28357
2023-08-26 20:14:43 | INFO | train_inner | epoch 027:    247 / 1191 loss=1.822, trans_loss=4.567, nll_loss=1.746, w2v_ctc_loss=0.539, task_loss=2.174, contrastive_loss=0.205, total=6816.12, n_correct=4953.14, ppl=3.35, accuracy=72.668, wps=18865.6, ups=1.38, wpb=13632.2, bsz=481.5, num_updates=31200, lr=8.00641e-05, gnorm=0.413, clip=0, loss_scale=64, train_wall=72, gb_free=13, wall=28429
2023-08-26 20:14:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-26 20:15:57 | INFO | train_inner | epoch 027:    348 / 1191 loss=1.819, trans_loss=4.565, nll_loss=1.743, w2v_ctc_loss=0.537, task_loss=2.266, contrastive_loss=0.174, total=6720.19, n_correct=4889.48, ppl=3.35, accuracy=72.758, wps=18207.3, ups=1.35, wpb=13440.4, bsz=463.5, num_updates=31300, lr=7.99361e-05, gnorm=0.416, clip=0, loss_scale=32, train_wall=73, gb_free=12.5, wall=28503
2023-08-26 20:17:10 | INFO | train_inner | epoch 027:    448 / 1191 loss=1.835, trans_loss=4.581, nll_loss=1.763, w2v_ctc_loss=0.555, task_loss=2.502, contrastive_loss=0.189, total=6617.99, n_correct=4787.25, ppl=3.39, accuracy=72.337, wps=18139.7, ups=1.37, wpb=13236, bsz=437.6, num_updates=31400, lr=7.98087e-05, gnorm=0.43, clip=0, loss_scale=32, train_wall=72, gb_free=6.1, wall=28576
2023-08-26 20:18:23 | INFO | train_inner | epoch 027:    548 / 1191 loss=1.822, trans_loss=4.568, nll_loss=1.747, w2v_ctc_loss=0.544, task_loss=2.226, contrastive_loss=0.164, total=6786.76, n_correct=4928.86, ppl=3.36, accuracy=72.625, wps=18669.2, ups=1.38, wpb=13573.5, bsz=467.9, num_updates=31500, lr=7.96819e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=72, gb_free=13.3, wall=28648
2023-08-26 20:19:35 | INFO | train_inner | epoch 027:    648 / 1191 loss=1.834, trans_loss=4.574, nll_loss=1.754, w2v_ctc_loss=0.548, task_loss=2.405, contrastive_loss=0.236, total=6681.62, n_correct=4842.43, ppl=3.37, accuracy=72.474, wps=18462.5, ups=1.38, wpb=13363.2, bsz=444.4, num_updates=31600, lr=7.95557e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=72, gb_free=11.8, wall=28721
2023-08-26 20:20:48 | INFO | train_inner | epoch 027:    748 / 1191 loss=1.828, trans_loss=4.574, nll_loss=1.755, w2v_ctc_loss=0.551, task_loss=2.461, contrastive_loss=0.165, total=6672.74, n_correct=4839.45, ppl=3.37, accuracy=72.526, wps=18401.2, ups=1.38, wpb=13345.5, bsz=442.4, num_updates=31700, lr=7.94301e-05, gnorm=0.418, clip=0, loss_scale=32, train_wall=72, gb_free=12.7, wall=28793
2023-08-26 20:22:00 | INFO | train_inner | epoch 027:    848 / 1191 loss=1.827, trans_loss=4.573, nll_loss=1.753, w2v_ctc_loss=0.55, task_loss=2.483, contrastive_loss=0.157, total=6644.45, n_correct=4817.86, ppl=3.37, accuracy=72.51, wps=18339.1, ups=1.38, wpb=13288.9, bsz=439.2, num_updates=31800, lr=7.93052e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=72, gb_free=13, wall=28866
2023-08-26 20:23:13 | INFO | train_inner | epoch 027:    948 / 1191 loss=1.833, trans_loss=4.579, nll_loss=1.761, w2v_ctc_loss=0.552, task_loss=2.538, contrastive_loss=0.174, total=6643.34, n_correct=4810.26, ppl=3.39, accuracy=72.407, wps=18166.2, ups=1.37, wpb=13286.7, bsz=425.1, num_updates=31900, lr=7.91808e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=73, gb_free=10.6, wall=28939
2023-08-26 20:24:26 | INFO | train_inner | epoch 027:   1048 / 1191 loss=1.834, trans_loss=4.581, nll_loss=1.764, w2v_ctc_loss=0.548, task_loss=2.373, contrastive_loss=0.226, total=6650.56, n_correct=4814.67, ppl=3.4, accuracy=72.395, wps=18318.3, ups=1.38, wpb=13301.1, bsz=450.8, num_updates=32000, lr=7.90569e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=72, gb_free=13.2, wall=29012
2023-08-26 20:24:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 20:25:00 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.747 | trans_loss 4.855 | nll_loss 2.068 | w2v_ctc_loss 1.184 | task_loss 8.551 | contrastive_loss 0.383 | total 6138.43 | n_correct 4390.43 | ppl 4.19 | accuracy 71.524 | uer 16.762 | wer 18.416 | raw_wer 18.416 | bleu 28.65 | wps 1639 | wpb 6138.4 | bsz 201.1 | num_updates 32000 | best_bleu 29.11
2023-08-26 20:25:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 32000 updates
2023-08-26 20:25:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_27_32000.pt
2023-08-26 20:25:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_27_32000.pt
2023-08-26 20:25:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_27_32000.pt (epoch 27 @ 32000 updates, score 28.65) (writing took 5.9758642930100905 seconds)
2023-08-26 20:26:18 | INFO | train_inner | epoch 027:   1148 / 1191 loss=1.828, trans_loss=4.575, nll_loss=1.756, w2v_ctc_loss=0.544, task_loss=2.296, contrastive_loss=0.193, total=6756.52, n_correct=4898.27, ppl=3.38, accuracy=72.497, wps=12046.4, ups=0.89, wpb=13513, bsz=452.5, num_updates=32100, lr=7.89337e-05, gnorm=0.414, clip=0, loss_scale=32, train_wall=72, gb_free=14, wall=29124
2023-08-26 20:26:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 20:27:22 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.756 | trans_loss 4.855 | nll_loss 2.066 | w2v_ctc_loss 1.219 | task_loss 8.592 | contrastive_loss 0.378 | total 6138.43 | n_correct 4386.71 | ppl 4.19 | accuracy 71.463 | uer 16.573 | wer 18.211 | raw_wer 18.211 | bleu 29.2 | wps 1759.2 | wpb 6138.4 | bsz 201.1 | num_updates 32143 | best_bleu 29.2
2023-08-26 20:27:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 32143 updates
2023-08-26 20:27:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 20:27:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 20:27:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 27 @ 32143 updates, score 29.2) (writing took 12.831314968992956 seconds)
2023-08-26 20:27:35 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-26 20:27:35 | INFO | train | epoch 027 | loss 1.828 | trans_loss 4.572 | nll_loss 1.753 | w2v_ctc_loss 0.547 | task_loss 2.357 | contrastive_loss 0.189 | total 6702.87 | n_correct 4861.66 | ppl 3.37 | accuracy 72.531 | wps 16646.6 | ups 1.24 | wpb 13405.7 | bsz 451.9 | num_updates 32143 | lr 7.88809e-05 | gnorm 0.419 | clip 0 | loss_scale 32 | train_wall 859 | gb_free 13.3 | wall 29200
2023-08-26 20:27:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 20:27:35 | INFO | fairseq.trainer | begin training epoch 28
2023-08-26 20:27:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 20:28:24 | INFO | train_inner | epoch 028:     57 / 1191 loss=1.816, trans_loss=4.559, nll_loss=1.736, w2v_ctc_loss=0.536, task_loss=2.31, contrastive_loss=0.179, total=6701.35, n_correct=4877.8, ppl=3.33, accuracy=72.788, wps=10687.8, ups=0.8, wpb=13402.7, bsz=455.5, num_updates=32200, lr=7.8811e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=72, gb_free=6.4, wall=29249
2023-08-26 20:29:36 | INFO | train_inner | epoch 028:    157 / 1191 loss=1.826, trans_loss=4.568, nll_loss=1.746, w2v_ctc_loss=0.556, task_loss=2.484, contrastive_loss=0.133, total=6662.36, n_correct=4835.46, ppl=3.35, accuracy=72.579, wps=18437.6, ups=1.38, wpb=13324.7, bsz=429.7, num_updates=32300, lr=7.86889e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=72, gb_free=13.5, wall=29321
2023-08-26 20:30:49 | INFO | train_inner | epoch 028:    257 / 1191 loss=1.821, trans_loss=4.566, nll_loss=1.744, w2v_ctc_loss=0.542, task_loss=2.349, contrastive_loss=0.178, total=6695.94, n_correct=4864.4, ppl=3.35, accuracy=72.647, wps=18327, ups=1.37, wpb=13391.9, bsz=454.4, num_updates=32400, lr=7.85674e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=73, gb_free=13.4, wall=29394
2023-08-26 20:32:02 | INFO | train_inner | epoch 028:    357 / 1191 loss=1.815, trans_loss=4.56, nll_loss=1.737, w2v_ctc_loss=0.538, task_loss=2.33, contrastive_loss=0.149, total=6727.32, n_correct=4897.25, ppl=3.33, accuracy=72.796, wps=18372, ups=1.37, wpb=13454.6, bsz=459.2, num_updates=32500, lr=7.84465e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=73, gb_free=13.4, wall=29468
2023-08-26 20:33:15 | INFO | train_inner | epoch 028:    457 / 1191 loss=1.83, trans_loss=4.565, nll_loss=1.744, w2v_ctc_loss=0.54, task_loss=2.256, contrastive_loss=0.269, total=6777.32, n_correct=4924.23, ppl=3.35, accuracy=72.657, wps=18602.7, ups=1.37, wpb=13554.6, bsz=471.8, num_updates=32600, lr=7.8326e-05, gnorm=0.418, clip=0, loss_scale=32, train_wall=72, gb_free=12.8, wall=29541
2023-08-26 20:34:27 | INFO | train_inner | epoch 028:    557 / 1191 loss=1.812, trans_loss=4.563, nll_loss=1.74, w2v_ctc_loss=0.535, task_loss=2.328, contrastive_loss=0.133, total=6695.22, n_correct=4871.06, ppl=3.34, accuracy=72.754, wps=18746.9, ups=1.4, wpb=13390.4, bsz=451.6, num_updates=32700, lr=7.82062e-05, gnorm=0.413, clip=0, loss_scale=32, train_wall=71, gb_free=13.3, wall=29612
2023-08-26 20:35:38 | INFO | train_inner | epoch 028:    657 / 1191 loss=1.821, trans_loss=4.563, nll_loss=1.741, w2v_ctc_loss=0.539, task_loss=2.288, contrastive_loss=0.203, total=6769.44, n_correct=4926.34, ppl=3.34, accuracy=72.773, wps=18823.6, ups=1.39, wpb=13538.9, bsz=460.3, num_updates=32800, lr=7.80869e-05, gnorm=0.416, clip=0, loss_scale=32, train_wall=71, gb_free=13.5, wall=29684
2023-08-26 20:36:52 | INFO | train_inner | epoch 028:    757 / 1191 loss=1.821, trans_loss=4.566, nll_loss=1.744, w2v_ctc_loss=0.543, task_loss=2.348, contrastive_loss=0.165, total=6697.15, n_correct=4859.25, ppl=3.35, accuracy=72.557, wps=18271.6, ups=1.36, wpb=13394.3, bsz=455.2, num_updates=32900, lr=7.79681e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=73, gb_free=14, wall=29757
2023-08-26 20:38:04 | INFO | train_inner | epoch 028:    857 / 1191 loss=1.823, trans_loss=4.567, nll_loss=1.746, w2v_ctc_loss=0.544, task_loss=2.361, contrastive_loss=0.171, total=6642.02, n_correct=4824.51, ppl=3.35, accuracy=72.636, wps=18335.7, ups=1.38, wpb=13284, bsz=451.4, num_updates=33000, lr=7.78499e-05, gnorm=0.428, clip=0, loss_scale=32, train_wall=72, gb_free=13, wall=29830
2023-08-26 20:39:17 | INFO | train_inner | epoch 028:    957 / 1191 loss=1.832, trans_loss=4.572, nll_loss=1.752, w2v_ctc_loss=0.552, task_loss=2.471, contrastive_loss=0.204, total=6645.42, n_correct=4820.44, ppl=3.37, accuracy=72.538, wps=18334.6, ups=1.38, wpb=13290.8, bsz=437.2, num_updates=33100, lr=7.77322e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=72, gb_free=11.2, wall=29902
2023-08-26 20:40:30 | INFO | train_inner | epoch 028:   1057 / 1191 loss=1.83, trans_loss=4.572, nll_loss=1.752, w2v_ctc_loss=0.535, task_loss=2.457, contrastive_loss=0.259, total=6685.52, n_correct=4848.53, ppl=3.37, accuracy=72.523, wps=18314.3, ups=1.37, wpb=13371, bsz=440.5, num_updates=33200, lr=7.76151e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=72, gb_free=13.6, wall=29975
2023-08-26 20:41:43 | INFO | train_inner | epoch 028:   1157 / 1191 loss=1.824, trans_loss=4.568, nll_loss=1.747, w2v_ctc_loss=0.543, task_loss=2.439, contrastive_loss=0.172, total=6679.26, n_correct=4845.98, ppl=3.36, accuracy=72.553, wps=18334.8, ups=1.37, wpb=13358.5, bsz=444.1, num_updates=33300, lr=7.74984e-05, gnorm=0.425, clip=0, loss_scale=64, train_wall=72, gb_free=12.5, wall=30048
2023-08-26 20:42:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 20:42:40 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.754 | trans_loss 4.859 | nll_loss 2.07 | w2v_ctc_loss 1.202 | task_loss 8.587 | contrastive_loss 0.38 | total 6138.43 | n_correct 4382 | ppl 4.2 | accuracy 71.386 | uer 16.567 | wer 18.2 | raw_wer 18.2 | bleu 29.03 | wps 1775.1 | wpb 6138.4 | bsz 201.1 | num_updates 33334 | best_bleu 29.2
2023-08-26 20:42:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 33334 updates
2023-08-26 20:42:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.0300.pt
2023-08-26 20:42:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.0300.pt
2023-08-26 20:42:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.0300.pt (epoch 28 @ 33334 updates, score 29.03) (writing took 6.469418199005304 seconds)
2023-08-26 20:42:47 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-26 20:42:47 | INFO | train | epoch 028 | loss 1.823 | trans_loss 4.566 | nll_loss 1.744 | w2v_ctc_loss 0.542 | task_loss 2.357 | contrastive_loss 0.187 | total 6703.69 | n_correct 4870.43 | ppl 3.35 | accuracy 72.653 | wps 17507.7 | ups 1.31 | wpb 13407.4 | bsz 452.1 | num_updates 33334 | lr 7.74589e-05 | gnorm 0.42 | clip 0 | loss_scale 64 | train_wall 858 | gb_free 13 | wall 30112
2023-08-26 20:42:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 20:42:47 | INFO | fairseq.trainer | begin training epoch 29
2023-08-26 20:42:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 20:43:43 | INFO | train_inner | epoch 029:     66 / 1191 loss=1.811, trans_loss=4.55, nll_loss=1.725, w2v_ctc_loss=0.529, task_loss=2.152, contrastive_loss=0.185, total=6803.37, n_correct=4967.54, ppl=3.3, accuracy=73.016, wps=11336, ups=0.83, wpb=13606.7, bsz=476.6, num_updates=33400, lr=7.73823e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=72, gb_free=15.2, wall=30168
2023-08-26 20:44:55 | INFO | train_inner | epoch 029:    166 / 1191 loss=1.813, trans_loss=4.557, nll_loss=1.732, w2v_ctc_loss=0.536, task_loss=2.406, contrastive_loss=0.137, total=6680.35, n_correct=4864.8, ppl=3.32, accuracy=72.823, wps=18408.5, ups=1.38, wpb=13360.7, bsz=438.8, num_updates=33500, lr=7.72667e-05, gnorm=0.414, clip=0, loss_scale=64, train_wall=72, gb_free=12.9, wall=30241
2023-08-26 20:45:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-26 20:46:09 | INFO | train_inner | epoch 029:    267 / 1191 loss=1.822, trans_loss=4.559, nll_loss=1.735, w2v_ctc_loss=0.53, task_loss=2.392, contrastive_loss=0.249, total=6647.67, n_correct=4837.81, ppl=3.33, accuracy=72.775, wps=18037.8, ups=1.36, wpb=13295.3, bsz=447, num_updates=33600, lr=7.71517e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=73, gb_free=13.9, wall=30314
2023-08-26 20:47:22 | INFO | train_inner | epoch 029:    367 / 1191 loss=1.817, trans_loss=4.562, nll_loss=1.739, w2v_ctc_loss=0.544, task_loss=2.361, contrastive_loss=0.14, total=6747.17, n_correct=4906.2, ppl=3.34, accuracy=72.715, wps=18421.5, ups=1.37, wpb=13494.3, bsz=452, num_updates=33700, lr=7.70371e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=73, gb_free=14.3, wall=30388
2023-08-26 20:48:35 | INFO | train_inner | epoch 029:    467 / 1191 loss=1.817, trans_loss=4.56, nll_loss=1.737, w2v_ctc_loss=0.534, task_loss=2.275, contrastive_loss=0.191, total=6772.8, n_correct=4928.69, ppl=3.33, accuracy=72.772, wps=18551.5, ups=1.37, wpb=13545.6, bsz=464.8, num_updates=33800, lr=7.69231e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=73, gb_free=13.6, wall=30461
2023-08-26 20:49:48 | INFO | train_inner | epoch 029:    567 / 1191 loss=1.824, trans_loss=4.563, nll_loss=1.74, w2v_ctc_loss=0.55, task_loss=2.603, contrastive_loss=0.174, total=6577.57, n_correct=4778.49, ppl=3.34, accuracy=72.648, wps=17965.3, ups=1.37, wpb=13155.1, bsz=421.4, num_updates=33900, lr=7.68095e-05, gnorm=0.429, clip=0, loss_scale=32, train_wall=73, gb_free=14.3, wall=30534
2023-08-26 20:51:01 | INFO | train_inner | epoch 029:    667 / 1191 loss=1.814, trans_loss=4.553, nll_loss=1.728, w2v_ctc_loss=0.538, task_loss=2.219, contrastive_loss=0.173, total=6760.39, n_correct=4932.99, ppl=3.31, accuracy=72.969, wps=18598.7, ups=1.38, wpb=13520.8, bsz=469.3, num_updates=34000, lr=7.66965e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=72, gb_free=11.9, wall=30607
2023-08-26 20:51:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 20:51:34 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.737 | trans_loss 4.857 | nll_loss 2.07 | w2v_ctc_loss 1.149 | task_loss 8.64 | contrastive_loss 0.383 | total 6138.43 | n_correct 4387.29 | ppl 4.2 | accuracy 71.472 | uer 16.452 | wer 18.1 | raw_wer 18.1 | bleu 28.78 | wps 1752.1 | wpb 6138.4 | bsz 201.1 | num_updates 34000 | best_bleu 29.2
2023-08-26 20:51:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 34000 updates
2023-08-26 20:51:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_29_34000.pt
2023-08-26 20:51:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_29_34000.pt
2023-08-26 20:51:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_29_34000.pt (epoch 29 @ 34000 updates, score 28.78) (writing took 6.326101257989649 seconds)
2023-08-26 20:52:53 | INFO | train_inner | epoch 029:    767 / 1191 loss=1.812, trans_loss=4.555, nll_loss=1.73, w2v_ctc_loss=0.534, task_loss=2.369, contrastive_loss=0.166, total=6664.13, n_correct=4862.9, ppl=3.32, accuracy=72.971, wps=11953, ups=0.9, wpb=13328.3, bsz=450.3, num_updates=34100, lr=7.6584e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=72, gb_free=7.4, wall=30718
2023-08-26 20:54:05 | INFO | train_inner | epoch 029:    867 / 1191 loss=1.818, trans_loss=4.566, nll_loss=1.744, w2v_ctc_loss=0.542, task_loss=2.459, contrastive_loss=0.142, total=6659.43, n_correct=4838.32, ppl=3.35, accuracy=72.654, wps=18420.7, ups=1.38, wpb=13318.9, bsz=435.3, num_updates=34200, lr=7.64719e-05, gnorm=0.418, clip=0, loss_scale=32, train_wall=72, gb_free=10.8, wall=30790
2023-08-26 20:55:18 | INFO | train_inner | epoch 029:    967 / 1191 loss=1.833, trans_loss=4.566, nll_loss=1.744, w2v_ctc_loss=0.547, task_loss=2.335, contrastive_loss=0.264, total=6728.65, n_correct=4886.25, ppl=3.35, accuracy=72.619, wps=18403.6, ups=1.37, wpb=13457.3, bsz=461.6, num_updates=34300, lr=7.63604e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=72, gb_free=12.1, wall=30864
2023-08-26 20:56:31 | INFO | train_inner | epoch 029:   1067 / 1191 loss=1.82, trans_loss=4.559, nll_loss=1.736, w2v_ctc_loss=0.536, task_loss=2.343, contrastive_loss=0.211, total=6711.89, n_correct=4887.94, ppl=3.33, accuracy=72.825, wps=18524.1, ups=1.38, wpb=13423.8, bsz=456.2, num_updates=34400, lr=7.62493e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=72, gb_free=14.3, wall=30936
2023-08-26 20:57:44 | INFO | train_inner | epoch 029:   1167 / 1191 loss=1.812, trans_loss=4.56, nll_loss=1.737, w2v_ctc_loss=0.527, task_loss=2.287, contrastive_loss=0.179, total=6748.65, n_correct=4926.5, ppl=3.33, accuracy=73, wps=18448.9, ups=1.37, wpb=13497.3, bsz=461.5, num_updates=34500, lr=7.61387e-05, gnorm=0.412, clip=0, loss_scale=32, train_wall=73, gb_free=15.3, wall=31009
2023-08-26 20:58:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 20:58:34 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.738 | trans_loss 4.854 | nll_loss 2.068 | w2v_ctc_loss 1.163 | task_loss 8.626 | contrastive_loss 0.38 | total 6138.43 | n_correct 4385.43 | ppl 4.19 | accuracy 71.442 | uer 16.589 | wer 18.297 | raw_wer 18.297 | bleu 29.09 | wps 1736.2 | wpb 6138.4 | bsz 201.1 | num_updates 34524 | best_bleu 29.2
2023-08-26 20:58:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 34524 updates
2023-08-26 20:58:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.0903.pt
2023-08-26 20:58:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.0903.pt
2023-08-26 20:58:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.0903.pt (epoch 29 @ 34524 updates, score 29.09) (writing took 6.57603151499643 seconds)
2023-08-26 20:58:41 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-26 20:58:41 | INFO | train | epoch 029 | loss 1.818 | trans_loss 4.559 | nll_loss 1.736 | w2v_ctc_loss 0.537 | task_loss 2.358 | contrastive_loss 0.184 | total 6702.03 | n_correct 4880.07 | ppl 3.33 | accuracy 72.815 | wps 16724.6 | ups 1.25 | wpb 13404.1 | bsz 451.7 | num_updates 34524 | lr 7.61122e-05 | gnorm 0.42 | clip 0 | loss_scale 32 | train_wall 860 | gb_free 13.5 | wall 31066
2023-08-26 20:58:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 20:58:41 | INFO | fairseq.trainer | begin training epoch 30
2023-08-26 20:58:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 20:59:43 | INFO | train_inner | epoch 030:     76 / 1191 loss=1.804, trans_loss=4.548, nll_loss=1.722, w2v_ctc_loss=0.522, task_loss=2.097, contrastive_loss=0.176, total=6849.81, n_correct=5011.93, ppl=3.3, accuracy=73.169, wps=11500.9, ups=0.84, wpb=13699.6, bsz=486.1, num_updates=34600, lr=7.60286e-05, gnorm=0.406, clip=0, loss_scale=32, train_wall=71, gb_free=13.8, wall=31128
2023-08-26 21:00:54 | INFO | train_inner | epoch 030:    176 / 1191 loss=1.809, trans_loss=4.55, nll_loss=1.723, w2v_ctc_loss=0.526, task_loss=2.388, contrastive_loss=0.174, total=6657.78, n_correct=4862.02, ppl=3.3, accuracy=73.028, wps=18608.2, ups=1.4, wpb=13315.6, bsz=441, num_updates=34700, lr=7.5919e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=71, gb_free=14.5, wall=31200
2023-08-26 21:02:07 | INFO | train_inner | epoch 030:    276 / 1191 loss=1.809, trans_loss=4.544, nll_loss=1.717, w2v_ctc_loss=0.53, task_loss=2.254, contrastive_loss=0.184, total=6769.26, n_correct=4950.89, ppl=3.29, accuracy=73.138, wps=18668.5, ups=1.38, wpb=13538.5, bsz=465.3, num_updates=34800, lr=7.58098e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=72, gb_free=14.3, wall=31272
2023-08-26 21:03:20 | INFO | train_inner | epoch 030:    376 / 1191 loss=1.807, trans_loss=4.548, nll_loss=1.722, w2v_ctc_loss=0.525, task_loss=2.146, contrastive_loss=0.182, total=6850.27, n_correct=5007.19, ppl=3.3, accuracy=73.095, wps=18668.4, ups=1.36, wpb=13700.5, bsz=485.4, num_updates=34900, lr=7.57011e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=73, gb_free=13.7, wall=31346
2023-08-26 21:04:33 | INFO | train_inner | epoch 030:    476 / 1191 loss=1.814, trans_loss=4.553, nll_loss=1.728, w2v_ctc_loss=0.536, task_loss=2.455, contrastive_loss=0.173, total=6641.83, n_correct=4844.23, ppl=3.31, accuracy=72.935, wps=18262.3, ups=1.37, wpb=13283.7, bsz=444.7, num_updates=35000, lr=7.55929e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=72, gb_free=12.9, wall=31419
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:0')
2023-08-26 21:05:46 | INFO | train_inner | epoch 030:    576 / 1191 loss=1.82, trans_loss=4.557, nll_loss=1.733, w2v_ctc_loss=0.54, task_loss=2.4, contrastive_loss=0.193, total=6679.82, n_correct=4858.93, ppl=3.32, accuracy=72.74, wps=18262.2, ups=1.37, wpb=13359.6, bsz=445.4, num_updates=35100, lr=7.54851e-05, gnorm=0.43, clip=0, loss_scale=32, train_wall=72, gb_free=11.3, wall=31492
2023-08-26 21:06:59 | INFO | train_inner | epoch 030:    676 / 1191 loss=1.817, trans_loss=4.552, nll_loss=1.726, w2v_ctc_loss=0.544, task_loss=2.572, contrastive_loss=0.155, total=6572.86, n_correct=4790.55, ppl=3.31, accuracy=72.884, wps=18094.1, ups=1.38, wpb=13145.7, bsz=422.5, num_updates=35200, lr=7.53778e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=72, gb_free=13.8, wall=31564
2023-08-26 21:08:12 | INFO | train_inner | epoch 030:    776 / 1191 loss=1.826, trans_loss=4.555, nll_loss=1.73, w2v_ctc_loss=0.538, task_loss=2.479, contrastive_loss=0.254, total=6650.65, n_correct=4840.15, ppl=3.32, accuracy=72.777, wps=18161.8, ups=1.37, wpb=13301.3, bsz=438.1, num_updates=35300, lr=7.5271e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=73, gb_free=12.9, wall=31638
2023-08-26 21:09:25 | INFO | train_inner | epoch 030:    876 / 1191 loss=1.812, trans_loss=4.554, nll_loss=1.73, w2v_ctc_loss=0.527, task_loss=2.408, contrastive_loss=0.186, total=6686.47, n_correct=4878.1, ppl=3.32, accuracy=72.955, wps=18311.3, ups=1.37, wpb=13372.9, bsz=447.2, num_updates=35400, lr=7.51646e-05, gnorm=0.414, clip=0, loss_scale=32, train_wall=73, gb_free=15.6, wall=31711
2023-08-26 21:10:38 | INFO | train_inner | epoch 030:    976 / 1191 loss=1.822, trans_loss=4.558, nll_loss=1.735, w2v_ctc_loss=0.546, task_loss=2.461, contrastive_loss=0.19, total=6650.45, n_correct=4836.37, ppl=3.33, accuracy=72.722, wps=18170.6, ups=1.37, wpb=13300.9, bsz=445.3, num_updates=35500, lr=7.50587e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=73, gb_free=13, wall=31784
2023-08-26 21:11:51 | INFO | train_inner | epoch 030:   1076 / 1191 loss=1.812, trans_loss=4.556, nll_loss=1.733, w2v_ctc_loss=0.536, task_loss=2.308, contrastive_loss=0.142, total=6760.55, n_correct=4935.87, ppl=3.32, accuracy=73.01, wps=18528.8, ups=1.37, wpb=13521.1, bsz=455.7, num_updates=35600, lr=7.49532e-05, gnorm=0.417, clip=0, loss_scale=32, train_wall=72, gb_free=13, wall=31857
2023-08-26 21:13:04 | INFO | train_inner | epoch 030:   1176 / 1191 loss=1.817, trans_loss=4.563, nll_loss=1.741, w2v_ctc_loss=0.532, task_loss=2.338, contrastive_loss=0.199, total=6693.2, n_correct=4871.8, ppl=3.34, accuracy=72.787, wps=18315.1, ups=1.37, wpb=13386.4, bsz=453.9, num_updates=35700, lr=7.48481e-05, gnorm=0.414, clip=0, loss_scale=64, train_wall=73, gb_free=14.4, wall=31930
2023-08-26 21:13:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:4')
2023-08-26 21:13:47 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.748 | trans_loss 4.855 | nll_loss 2.068 | w2v_ctc_loss 1.196 | task_loss 8.62 | contrastive_loss 0.373 | total 6138.43 | n_correct 4386.14 | ppl 4.19 | accuracy 71.454 | uer 16.947 | wer 18.758 | raw_wer 18.758 | bleu 28.82 | wps 1769.7 | wpb 6138.4 | bsz 201.1 | num_updates 35715 | best_bleu 29.2
2023-08-26 21:13:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 35715 updates
2023-08-26 21:13:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-26 21:13:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-26 21:13:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt (epoch 30 @ 35715 updates, score 28.82) (writing took 5.97283010200772 seconds)
2023-08-26 21:13:53 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-26 21:13:53 | INFO | train | epoch 030 | loss 1.814 | trans_loss 4.553 | nll_loss 1.728 | w2v_ctc_loss 0.533 | task_loss 2.356 | contrastive_loss 0.184 | total 6703.69 | n_correct 4889.61 | ppl 3.31 | accuracy 72.939 | wps 17495.1 | ups 1.3 | wpb 13407.4 | bsz 452.1 | num_updates 35715 | lr 7.48324e-05 | gnorm 0.419 | clip 0 | loss_scale 64 | train_wall 860 | gb_free 14.3 | wall 31979
2023-08-26 21:13:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 21:13:54 | INFO | fairseq.trainer | begin training epoch 31
2023-08-26 21:13:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 21:15:03 | INFO | train_inner | epoch 031:     85 / 1191 loss=1.81, trans_loss=4.546, nll_loss=1.718, w2v_ctc_loss=0.532, task_loss=2.58, contrastive_loss=0.156, total=6595.99, n_correct=4824.55, ppl=3.29, accuracy=73.144, wps=11154.8, ups=0.85, wpb=13192, bsz=419.6, num_updates=35800, lr=7.47435e-05, gnorm=0.423, clip=0, loss_scale=64, train_wall=72, gb_free=6.1, wall=32048
2023-08-26 21:15:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-26 21:16:17 | INFO | train_inner | epoch 031:    186 / 1191 loss=1.804, trans_loss=4.545, nll_loss=1.717, w2v_ctc_loss=0.526, task_loss=2.319, contrastive_loss=0.156, total=6721.79, n_correct=4917.67, ppl=3.29, accuracy=73.16, wps=18209.1, ups=1.35, wpb=13443.6, bsz=456.9, num_updates=35900, lr=7.46393e-05, gnorm=0.418, clip=0, loss_scale=32, train_wall=73, gb_free=12.1, wall=32122
2023-08-26 21:17:30 | INFO | train_inner | epoch 031:    286 / 1191 loss=1.816, trans_loss=4.547, nll_loss=1.719, w2v_ctc_loss=0.538, task_loss=2.546, contrastive_loss=0.193, total=6560.21, n_correct=4788.54, ppl=3.29, accuracy=72.994, wps=17927, ups=1.37, wpb=13120.4, bsz=431.9, num_updates=36000, lr=7.45356e-05, gnorm=0.429, clip=0, loss_scale=32, train_wall=73, gb_free=12.8, wall=32195
2023-08-26 21:17:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 21:18:02 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 3.736 | trans_loss 4.852 | nll_loss 2.063 | w2v_ctc_loss 1.162 | task_loss 8.604 | contrastive_loss 0.37 | total 6138.43 | n_correct 4383.57 | ppl 4.18 | accuracy 71.412 | uer 16.645 | wer 18.323 | raw_wer 18.323 | bleu 29.08 | wps 1759.6 | wpb 6138.4 | bsz 201.1 | num_updates 36000 | best_bleu 29.2
2023-08-26 21:18:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 36000 updates
2023-08-26 21:18:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_31_36000.pt
2023-08-26 21:18:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_31_36000.pt
2023-08-26 21:18:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_31_36000.pt (epoch 31 @ 36000 updates, score 29.08) (writing took 7.511138017987832 seconds)
2023-08-26 21:19:22 | INFO | train_inner | epoch 031:    386 / 1191 loss=1.804, trans_loss=4.545, nll_loss=1.718, w2v_ctc_loss=0.529, task_loss=2.345, contrastive_loss=0.135, total=6740.71, n_correct=4930.43, ppl=3.29, accuracy=73.144, wps=12005.6, ups=0.89, wpb=13481.4, bsz=456.6, num_updates=36100, lr=7.44323e-05, gnorm=0.416, clip=0, loss_scale=32, train_wall=72, gb_free=15.1, wall=32307
2023-08-26 21:20:35 | INFO | train_inner | epoch 031:    486 / 1191 loss=1.815, trans_loss=4.557, nll_loss=1.732, w2v_ctc_loss=0.535, task_loss=2.566, contrastive_loss=0.157, total=6663.24, n_correct=4856.65, ppl=3.32, accuracy=72.887, wps=18327.8, ups=1.38, wpb=13326.5, bsz=427.4, num_updates=36200, lr=7.43294e-05, gnorm=0.423, clip=0, loss_scale=32, train_wall=72, gb_free=13.4, wall=32380
2023-08-26 21:21:47 | INFO | train_inner | epoch 031:    586 / 1191 loss=1.815, trans_loss=4.549, nll_loss=1.722, w2v_ctc_loss=0.531, task_loss=2.334, contrastive_loss=0.217, total=6690.15, n_correct=4882.38, ppl=3.3, accuracy=72.979, wps=18486.2, ups=1.38, wpb=13380.3, bsz=452.9, num_updates=36300, lr=7.4227e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=72, gb_free=12.5, wall=32453
2023-08-26 21:23:00 | INFO | train_inner | epoch 031:    686 / 1191 loss=1.812, trans_loss=4.546, nll_loss=1.72, w2v_ctc_loss=0.531, task_loss=2.181, contrastive_loss=0.209, total=6828.19, n_correct=4988.19, ppl=3.29, accuracy=73.053, wps=18738.2, ups=1.37, wpb=13656.4, bsz=475.7, num_updates=36400, lr=7.41249e-05, gnorm=0.417, clip=0, loss_scale=32, train_wall=72, gb_free=8.8, wall=32525
2023-08-26 21:24:13 | INFO | train_inner | epoch 031:    786 / 1191 loss=1.808, trans_loss=4.546, nll_loss=1.72, w2v_ctc_loss=0.529, task_loss=2.201, contrastive_loss=0.187, total=6799.81, n_correct=4974.26, ppl=3.29, accuracy=73.153, wps=18536.7, ups=1.36, wpb=13599.6, bsz=477.8, num_updates=36500, lr=7.40233e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=73, gb_free=12.8, wall=32599
2023-08-26 21:25:26 | INFO | train_inner | epoch 031:    886 / 1191 loss=1.812, trans_loss=4.551, nll_loss=1.725, w2v_ctc_loss=0.526, task_loss=2.412, contrastive_loss=0.211, total=6621.33, n_correct=4836.21, ppl=3.31, accuracy=73.04, wps=18192.5, ups=1.37, wpb=13242.7, bsz=446.7, num_updates=36600, lr=7.39221e-05, gnorm=0.423, clip=0, loss_scale=32, train_wall=72, gb_free=6.1, wall=32672
2023-08-26 21:26:39 | INFO | train_inner | epoch 031:    986 / 1191 loss=1.813, trans_loss=4.547, nll_loss=1.721, w2v_ctc_loss=0.532, task_loss=2.361, contrastive_loss=0.197, total=6696.19, n_correct=4889.36, ppl=3.3, accuracy=73.017, wps=18464.8, ups=1.38, wpb=13392.4, bsz=451.6, num_updates=36700, lr=7.38213e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=72, gb_free=10.1, wall=32744
2023-08-26 21:27:51 | INFO | train_inner | epoch 031:   1086 / 1191 loss=1.802, trans_loss=4.546, nll_loss=1.719, w2v_ctc_loss=0.521, task_loss=2.069, contrastive_loss=0.177, total=6891.63, n_correct=5043.49, ppl=3.29, accuracy=73.183, wps=18985.8, ups=1.38, wpb=13783.3, bsz=490.4, num_updates=36800, lr=7.3721e-05, gnorm=0.416, clip=0, loss_scale=32, train_wall=72, gb_free=4.2, wall=32817
2023-08-26 21:29:04 | INFO | train_inner | epoch 031:   1186 / 1191 loss=1.812, trans_loss=4.549, nll_loss=1.723, w2v_ctc_loss=0.531, task_loss=2.402, contrastive_loss=0.2, total=6644.22, n_correct=4849.28, ppl=3.3, accuracy=72.985, wps=18278.5, ups=1.38, wpb=13288.4, bsz=443.7, num_updates=36900, lr=7.3621e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=72, gb_free=14.5, wall=32889
2023-08-26 21:29:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 21:29:41 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 3.743 | trans_loss 4.853 | nll_loss 2.066 | w2v_ctc_loss 1.18 | task_loss 8.619 | contrastive_loss 0.38 | total 6138.43 | n_correct 4381.71 | ppl 4.19 | accuracy 71.382 | uer 16.468 | wer 18.211 | raw_wer 18.211 | bleu 29.07 | wps 1674.8 | wpb 6138.4 | bsz 201.1 | num_updates 36905 | best_bleu 29.2
2023-08-26 21:29:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 36905 updates
2023-08-26 21:29:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.0703.pt
2023-08-26 21:29:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.0703.pt
2023-08-26 21:29:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.0703.pt (epoch 31 @ 36905 updates, score 29.07) (writing took 7.585626557003707 seconds)
2023-08-26 21:29:49 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-26 21:29:49 | INFO | train | epoch 031 | loss 1.81 | trans_loss 4.548 | nll_loss 1.721 | w2v_ctc_loss 0.53 | task_loss 2.357 | contrastive_loss 0.183 | total 6703.32 | n_correct 4897.46 | ppl 3.3 | accuracy 73.06 | wps 16691.4 | ups 1.25 | wpb 13406.6 | bsz 452.1 | num_updates 36905 | lr 7.3616e-05 | gnorm 0.42 | clip 0 | loss_scale 32 | train_wall 860 | gb_free 10 | wall 32935
2023-08-26 21:29:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 21:29:49 | INFO | fairseq.trainer | begin training epoch 32
2023-08-26 21:29:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 21:31:05 | INFO | train_inner | epoch 032:     95 / 1191 loss=1.798, trans_loss=4.532, nll_loss=1.701, w2v_ctc_loss=0.52, task_loss=2.294, contrastive_loss=0.157, total=6699.21, n_correct=4916.82, ppl=3.25, accuracy=73.394, wps=11051.1, ups=0.82, wpb=13398.4, bsz=454.5, num_updates=37000, lr=7.35215e-05, gnorm=0.412, clip=0, loss_scale=32, train_wall=72, gb_free=11.6, wall=33011
2023-08-26 21:32:18 | INFO | train_inner | epoch 032:    195 / 1191 loss=1.809, trans_loss=4.539, nll_loss=1.71, w2v_ctc_loss=0.519, task_loss=2.26, contrastive_loss=0.258, total=6807.88, n_correct=4984.93, ppl=3.27, accuracy=73.223, wps=18625.5, ups=1.37, wpb=13615.8, bsz=467.3, num_updates=37100, lr=7.34223e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=73, gb_free=14.2, wall=33084
2023-08-26 21:33:31 | INFO | train_inner | epoch 032:    295 / 1191 loss=1.804, trans_loss=4.543, nll_loss=1.715, w2v_ctc_loss=0.527, task_loss=2.422, contrastive_loss=0.149, total=6684.79, n_correct=4888.71, ppl=3.28, accuracy=73.132, wps=18432.3, ups=1.38, wpb=13369.6, bsz=446.4, num_updates=37200, lr=7.33236e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=72, gb_free=12.9, wall=33156
2023-08-26 21:34:44 | INFO | train_inner | epoch 032:    395 / 1191 loss=1.795, trans_loss=4.529, nll_loss=1.698, w2v_ctc_loss=0.517, task_loss=2.284, contrastive_loss=0.152, total=6766.95, n_correct=4972.7, ppl=3.24, accuracy=73.485, wps=18624.1, ups=1.38, wpb=13533.9, bsz=460.3, num_updates=37300, lr=7.32252e-05, gnorm=0.418, clip=0, loss_scale=32, train_wall=72, gb_free=10.5, wall=33229
2023-08-26 21:35:57 | INFO | train_inner | epoch 032:    495 / 1191 loss=1.801, trans_loss=4.544, nll_loss=1.716, w2v_ctc_loss=0.522, task_loss=2.333, contrastive_loss=0.14, total=6728, n_correct=4922.75, ppl=3.28, accuracy=73.168, wps=18451.9, ups=1.37, wpb=13456, bsz=452.3, num_updates=37400, lr=7.31272e-05, gnorm=0.412, clip=0, loss_scale=32, train_wall=72, gb_free=14, wall=33302
2023-08-26 21:37:10 | INFO | train_inner | epoch 032:    595 / 1191 loss=1.803, trans_loss=4.541, nll_loss=1.713, w2v_ctc_loss=0.529, task_loss=2.406, contrastive_loss=0.136, total=6688.29, n_correct=4900.14, ppl=3.28, accuracy=73.264, wps=18191.3, ups=1.36, wpb=13376.6, bsz=443.7, num_updates=37500, lr=7.30297e-05, gnorm=0.417, clip=0, loss_scale=32, train_wall=73, gb_free=13.6, wall=33376
2023-08-26 21:38:24 | INFO | train_inner | epoch 032:    695 / 1191 loss=1.804, trans_loss=4.537, nll_loss=1.707, w2v_ctc_loss=0.522, task_loss=2.536, contrastive_loss=0.18, total=6660.06, n_correct=4879.59, ppl=3.27, accuracy=73.266, wps=18058.1, ups=1.36, wpb=13320.1, bsz=435.2, num_updates=37600, lr=7.29325e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=73, gb_free=8.4, wall=33449
2023-08-26 21:39:37 | INFO | train_inner | epoch 032:    795 / 1191 loss=1.814, trans_loss=4.543, nll_loss=1.716, w2v_ctc_loss=0.527, task_loss=2.276, contrastive_loss=0.241, total=6785.45, n_correct=4962.5, ppl=3.28, accuracy=73.134, wps=18523.9, ups=1.36, wpb=13570.9, bsz=469.8, num_updates=37700, lr=7.28357e-05, gnorm=0.416, clip=0, loss_scale=32, train_wall=73, gb_free=14.1, wall=33523
2023-08-26 21:40:50 | INFO | train_inner | epoch 032:    895 / 1191 loss=1.813, trans_loss=4.545, nll_loss=1.718, w2v_ctc_loss=0.532, task_loss=2.441, contrastive_loss=0.2, total=6681.76, n_correct=4880.2, ppl=3.29, accuracy=73.038, wps=18345, ups=1.37, wpb=13363.5, bsz=442.9, num_updates=37800, lr=7.27393e-05, gnorm=0.429, clip=0, loss_scale=32, train_wall=72, gb_free=14.3, wall=33595
2023-08-26 21:42:02 | INFO | train_inner | epoch 032:    995 / 1191 loss=1.806, trans_loss=4.543, nll_loss=1.716, w2v_ctc_loss=0.53, task_loss=2.402, contrastive_loss=0.163, total=6611.9, n_correct=4838.4, ppl=3.28, accuracy=73.177, wps=18250.1, ups=1.38, wpb=13223.8, bsz=442, num_updates=37900, lr=7.26433e-05, gnorm=0.423, clip=0, loss_scale=32, train_wall=72, gb_free=12.3, wall=33668
2023-08-26 21:43:15 | INFO | train_inner | epoch 032:   1095 / 1191 loss=1.805, trans_loss=4.547, nll_loss=1.72, w2v_ctc_loss=0.528, task_loss=2.489, contrastive_loss=0.13, total=6609.05, n_correct=4829.64, ppl=3.29, accuracy=73.076, wps=18244.5, ups=1.38, wpb=13218.1, bsz=430.6, num_updates=38000, lr=7.25476e-05, gnorm=0.425, clip=0, loss_scale=64, train_wall=72, gb_free=14.6, wall=33740
2023-08-26 21:43:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 21:43:47 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.75 | trans_loss 4.853 | nll_loss 2.065 | w2v_ctc_loss 1.209 | task_loss 8.62 | contrastive_loss 0.37 | total 6138.43 | n_correct 4387.71 | ppl 4.18 | accuracy 71.479 | uer 16.634 | wer 18.137 | raw_wer 18.137 | bleu 29.28 | wps 1773 | wpb 6138.4 | bsz 201.1 | num_updates 38000 | best_bleu 29.28
2023-08-26 21:43:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 38000 updates
2023-08-26 21:43:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_32_38000.pt
2023-08-26 21:43:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_32_38000.pt
2023-08-26 21:43:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_32_38000.pt (epoch 32 @ 38000 updates, score 29.28) (writing took 10.598305009989417 seconds)
2023-08-26 21:45:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 21:45:40 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.748 | trans_loss 4.855 | nll_loss 2.068 | w2v_ctc_loss 1.194 | task_loss 8.608 | contrastive_loss 0.38 | total 6138.43 | n_correct 4388.86 | ppl 4.19 | accuracy 71.498 | uer 16.693 | wer 18.297 | raw_wer 18.297 | bleu 29.29 | wps 1758.8 | wpb 6138.4 | bsz 201.1 | num_updates 38096 | best_bleu 29.29
2023-08-26 21:45:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 38096 updates
2023-08-26 21:45:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 21:45:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 21:45:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 32 @ 38096 updates, score 29.29) (writing took 12.317097573992214 seconds)
2023-08-26 21:45:53 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-26 21:45:53 | INFO | train | epoch 032 | loss 1.805 | trans_loss 4.541 | nll_loss 1.713 | w2v_ctc_loss 0.524 | task_loss 2.357 | contrastive_loss 0.182 | total 6703.69 | n_correct 4907.4 | ppl 3.28 | accuracy 73.205 | wps 16574.2 | ups 1.24 | wpb 13407.4 | bsz 452.1 | num_updates 38096 | lr 7.24562e-05 | gnorm 0.419 | clip 0 | loss_scale 64 | train_wall 860 | gb_free 11.4 | wall 33898
2023-08-26 21:45:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 21:45:53 | INFO | fairseq.trainer | begin training epoch 33
2023-08-26 21:45:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 21:46:03 | INFO | train_inner | epoch 033:      4 / 1191 loss=1.813, trans_loss=4.55, nll_loss=1.724, w2v_ctc_loss=0.519, task_loss=2.171, contrastive_loss=0.291, total=6715.16, n_correct=4905.88, ppl=3.3, accuracy=73.057, wps=7983.1, ups=0.59, wpb=13430.3, bsz=483.7, num_updates=38100, lr=7.24524e-05, gnorm=0.418, clip=0, loss_scale=64, train_wall=71, gb_free=15.1, wall=33909
2023-08-26 21:47:16 | INFO | train_inner | epoch 033:    104 / 1191 loss=1.791, trans_loss=4.53, nll_loss=1.699, w2v_ctc_loss=0.509, task_loss=2.273, contrastive_loss=0.146, total=6796.79, n_correct=4995.22, ppl=3.25, accuracy=73.494, wps=18523.7, ups=1.36, wpb=13593.6, bsz=466.2, num_updates=38200, lr=7.23575e-05, gnorm=0.415, clip=0, loss_scale=64, train_wall=73, gb_free=14.1, wall=33982
2023-08-26 21:48:28 | INFO | train_inner | epoch 033:    204 / 1191 loss=1.794, trans_loss=4.529, nll_loss=1.697, w2v_ctc_loss=0.514, task_loss=2.269, contrastive_loss=0.166, total=6774.25, n_correct=4978.92, ppl=3.24, accuracy=73.498, wps=18861.9, ups=1.39, wpb=13548.5, bsz=457.5, num_updates=38300, lr=7.22629e-05, gnorm=0.41, clip=0, loss_scale=64, train_wall=71, gb_free=14.6, wall=34054
2023-08-26 21:49:41 | INFO | train_inner | epoch 033:    304 / 1191 loss=1.806, trans_loss=4.536, nll_loss=1.705, w2v_ctc_loss=0.525, task_loss=2.546, contrastive_loss=0.198, total=6574.87, n_correct=4815.72, ppl=3.26, accuracy=73.244, wps=18090.3, ups=1.38, wpb=13149.7, bsz=429.3, num_updates=38400, lr=7.21688e-05, gnorm=0.424, clip=0, loss_scale=64, train_wall=72, gb_free=12, wall=34126
2023-08-26 21:50:53 | INFO | train_inner | epoch 033:    404 / 1191 loss=1.801, trans_loss=4.535, nll_loss=1.705, w2v_ctc_loss=0.521, task_loss=2.451, contrastive_loss=0.177, total=6600.59, n_correct=4842.95, ppl=3.26, accuracy=73.371, wps=18262.1, ups=1.38, wpb=13201.2, bsz=435.4, num_updates=38500, lr=7.2075e-05, gnorm=0.422, clip=0, loss_scale=64, train_wall=72, gb_free=14, wall=34199
2023-08-26 21:52:05 | INFO | train_inner | epoch 033:    504 / 1191 loss=1.799, trans_loss=4.535, nll_loss=1.705, w2v_ctc_loss=0.516, task_loss=2.287, contrastive_loss=0.178, total=6700.48, n_correct=4913.28, ppl=3.26, accuracy=73.327, wps=18734.3, ups=1.4, wpb=13401, bsz=457.5, num_updates=38600, lr=7.19816e-05, gnorm=0.41, clip=0, loss_scale=64, train_wall=71, gb_free=14.1, wall=34270
2023-08-26 21:53:18 | INFO | train_inner | epoch 033:    604 / 1191 loss=1.802, trans_loss=4.531, nll_loss=1.7, w2v_ctc_loss=0.529, task_loss=2.429, contrastive_loss=0.156, total=6668.81, n_correct=4889.73, ppl=3.25, accuracy=73.322, wps=18191.4, ups=1.36, wpb=13337.6, bsz=445.4, num_updates=38700, lr=7.18885e-05, gnorm=0.421, clip=0, loss_scale=64, train_wall=73, gb_free=14.2, wall=34344
2023-08-26 21:54:31 | INFO | train_inner | epoch 033:    704 / 1191 loss=1.8, trans_loss=4.536, nll_loss=1.706, w2v_ctc_loss=0.523, task_loss=2.396, contrastive_loss=0.161, total=6684.05, n_correct=4902.21, ppl=3.26, accuracy=73.342, wps=18311.6, ups=1.37, wpb=13368.1, bsz=444.9, num_updates=38800, lr=7.17958e-05, gnorm=0.421, clip=0, loss_scale=64, train_wall=72, gb_free=5.9, wall=34417
2023-08-26 21:55:43 | INFO | train_inner | epoch 033:    804 / 1191 loss=1.8, trans_loss=4.534, nll_loss=1.704, w2v_ctc_loss=0.513, task_loss=2.223, contrastive_loss=0.219, total=6798.01, n_correct=4992.35, ppl=3.26, accuracy=73.438, wps=18810.7, ups=1.38, wpb=13596, bsz=467.6, num_updates=38900, lr=7.17035e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=72, gb_free=14.4, wall=34489
2023-08-26 21:56:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-26 21:56:57 | INFO | train_inner | epoch 033:    905 / 1191 loss=1.803, trans_loss=4.54, nll_loss=1.711, w2v_ctc_loss=0.527, task_loss=2.291, contrastive_loss=0.16, total=6755.61, n_correct=4945.37, ppl=3.27, accuracy=73.204, wps=18306.8, ups=1.35, wpb=13511.2, bsz=463.5, num_updates=39000, lr=7.16115e-05, gnorm=0.417, clip=0, loss_scale=32, train_wall=73, gb_free=13.1, wall=34563
2023-08-26 21:58:11 | INFO | train_inner | epoch 033:   1005 / 1191 loss=1.806, trans_loss=4.545, nll_loss=1.718, w2v_ctc_loss=0.526, task_loss=2.484, contrastive_loss=0.159, total=6679.84, n_correct=4885.83, ppl=3.29, accuracy=73.143, wps=18095, ups=1.35, wpb=13359.7, bsz=440.5, num_updates=39100, lr=7.15199e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=73, gb_free=4.3, wall=34637
2023-08-26 21:59:24 | INFO | train_inner | epoch 033:   1105 / 1191 loss=1.808, trans_loss=4.541, nll_loss=1.712, w2v_ctc_loss=0.528, task_loss=2.308, contrastive_loss=0.207, total=6749.49, n_correct=4938.37, ppl=3.28, accuracy=73.167, wps=18539.8, ups=1.37, wpb=13499, bsz=463.2, num_updates=39200, lr=7.14286e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=72, gb_free=12.6, wall=34709
2023-08-26 22:00:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 22:00:59 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.748 | trans_loss 4.847 | nll_loss 2.059 | w2v_ctc_loss 1.217 | task_loss 8.613 | contrastive_loss 0.378 | total 6138.43 | n_correct 4399.29 | ppl 4.17 | accuracy 71.668 | uer 16.533 | wer 18.193 | raw_wer 18.193 | bleu 29.03 | wps 1749.7 | wpb 6138.4 | bsz 201.1 | num_updates 39286 | best_bleu 29.29
2023-08-26 22:00:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 39286 updates
2023-08-26 22:00:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.0302.pt
2023-08-26 22:01:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.0302.pt
2023-08-26 22:01:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.0302.pt (epoch 33 @ 39286 updates, score 29.03) (writing took 7.553986909988453 seconds)
2023-08-26 22:01:07 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-26 22:01:07 | INFO | train | epoch 033 | loss 1.801 | trans_loss 4.536 | nll_loss 1.706 | w2v_ctc_loss 0.521 | task_loss 2.355 | contrastive_loss 0.18 | total 6704.31 | n_correct 4915.55 | ppl 3.26 | accuracy 73.319 | wps 17442 | ups 1.3 | wpb 13408.6 | bsz 452.3 | num_updates 39286 | lr 7.13503e-05 | gnorm 0.419 | clip 0 | loss_scale 32 | train_wall 859 | gb_free 10.4 | wall 34813
2023-08-26 22:01:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 22:01:08 | INFO | fairseq.trainer | begin training epoch 34
2023-08-26 22:01:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 22:01:25 | INFO | train_inner | epoch 034:     14 / 1191 loss=1.804, trans_loss=4.535, nll_loss=1.705, w2v_ctc_loss=0.522, task_loss=2.264, contrastive_loss=0.234, total=6714.43, n_correct=4925.05, ppl=3.26, accuracy=73.35, wps=11084.7, ups=0.83, wpb=13428.9, bsz=468.7, num_updates=39300, lr=7.13376e-05, gnorm=0.417, clip=0, loss_scale=32, train_wall=72, gb_free=13.5, wall=34831
2023-08-26 22:02:38 | INFO | train_inner | epoch 034:    114 / 1191 loss=1.797, trans_loss=4.525, nll_loss=1.692, w2v_ctc_loss=0.506, task_loss=2.156, contrastive_loss=0.254, total=6812.86, n_correct=5014.76, ppl=3.23, accuracy=73.607, wps=18769.5, ups=1.38, wpb=13625.7, bsz=478.9, num_updates=39400, lr=7.1247e-05, gnorm=0.413, clip=0, loss_scale=32, train_wall=72, gb_free=14.3, wall=34903
2023-08-26 22:03:51 | INFO | train_inner | epoch 034:    214 / 1191 loss=1.799, trans_loss=4.528, nll_loss=1.695, w2v_ctc_loss=0.517, task_loss=2.437, contrastive_loss=0.194, total=6669.32, n_correct=4902.02, ppl=3.24, accuracy=73.501, wps=18293.5, ups=1.37, wpb=13338.6, bsz=448.9, num_updates=39500, lr=7.11568e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=72, gb_free=12.7, wall=34976
2023-08-26 22:05:04 | INFO | train_inner | epoch 034:    314 / 1191 loss=1.794, trans_loss=4.528, nll_loss=1.695, w2v_ctc_loss=0.52, task_loss=2.519, contrastive_loss=0.128, total=6597.66, n_correct=4844.5, ppl=3.24, accuracy=73.428, wps=18051.5, ups=1.37, wpb=13195.3, bsz=431.8, num_updates=39600, lr=7.10669e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=73, gb_free=13.5, wall=35049
2023-08-26 22:06:17 | INFO | train_inner | epoch 034:    414 / 1191 loss=1.796, trans_loss=4.531, nll_loss=1.699, w2v_ctc_loss=0.518, task_loss=2.491, contrastive_loss=0.14, total=6670.6, n_correct=4899.03, ppl=3.25, accuracy=73.442, wps=18180, ups=1.36, wpb=13341.2, bsz=433.1, num_updates=39700, lr=7.09773e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=73, gb_free=14.3, wall=35123
2023-08-26 22:07:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-26 22:07:31 | INFO | train_inner | epoch 034:    515 / 1191 loss=1.794, trans_loss=4.529, nll_loss=1.696, w2v_ctc_loss=0.513, task_loss=2.45, contrastive_loss=0.165, total=6685.25, n_correct=4918.21, ppl=3.24, accuracy=73.568, wps=18147.2, ups=1.36, wpb=13370.5, bsz=442, num_updates=39800, lr=7.08881e-05, gnorm=0.416, clip=0, loss_scale=16, train_wall=73, gb_free=13.8, wall=35196
2023-08-26 22:08:44 | INFO | train_inner | epoch 034:    615 / 1191 loss=1.802, trans_loss=4.533, nll_loss=1.703, w2v_ctc_loss=0.517, task_loss=2.283, contrastive_loss=0.208, total=6737.48, n_correct=4943.26, ppl=3.25, accuracy=73.37, wps=18524, ups=1.37, wpb=13475, bsz=465.8, num_updates=39900, lr=7.07992e-05, gnorm=0.425, clip=0, loss_scale=16, train_wall=72, gb_free=14.1, wall=35269
2023-08-26 22:09:56 | INFO | train_inner | epoch 034:    715 / 1191 loss=1.799, trans_loss=4.533, nll_loss=1.702, w2v_ctc_loss=0.519, task_loss=2.451, contrastive_loss=0.16, total=6608.91, n_correct=4846.31, ppl=3.25, accuracy=73.33, wps=18261.9, ups=1.38, wpb=13217.8, bsz=435.2, num_updates=40000, lr=7.07107e-05, gnorm=0.423, clip=0, loss_scale=16, train_wall=72, gb_free=12.5, wall=35341
2023-08-26 22:09:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 22:10:29 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.739 | trans_loss 4.845 | nll_loss 2.054 | w2v_ctc_loss 1.195 | task_loss 8.596 | contrastive_loss 0.365 | total 6138.43 | n_correct 4402.57 | ppl 4.15 | accuracy 71.721 | uer 16.484 | wer 18.163 | raw_wer 18.163 | bleu 29.19 | wps 1734.2 | wpb 6138.4 | bsz 201.1 | num_updates 40000 | best_bleu 29.29
2023-08-26 22:10:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 40000 updates
2023-08-26 22:10:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_34_40000.pt
2023-08-26 22:10:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_34_40000.pt
2023-08-26 22:10:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_34_40000.pt (epoch 34 @ 40000 updates, score 29.19) (writing took 6.593725575003191 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:0')
2023-08-26 22:11:49 | INFO | train_inner | epoch 034:    815 / 1191 loss=1.798, trans_loss=4.529, nll_loss=1.698, w2v_ctc_loss=0.525, task_loss=2.382, contrastive_loss=0.16, total=6668.41, n_correct=4898.19, ppl=3.24, accuracy=73.454, wps=11771.5, ups=0.88, wpb=13336.8, bsz=455.6, num_updates=40100, lr=7.06225e-05, gnorm=0.428, clip=0, loss_scale=16, train_wall=73, gb_free=13.3, wall=35455
2023-08-26 22:13:02 | INFO | train_inner | epoch 034:    915 / 1191 loss=1.799, trans_loss=4.529, nll_loss=1.697, w2v_ctc_loss=0.524, task_loss=2.513, contrastive_loss=0.149, total=6650.22, n_correct=4878.96, ppl=3.24, accuracy=73.365, wps=18381.3, ups=1.38, wpb=13300.4, bsz=427.8, num_updates=40200, lr=7.05346e-05, gnorm=0.427, clip=0, loss_scale=16, train_wall=72, gb_free=13.1, wall=35527
2023-08-26 22:14:15 | INFO | train_inner | epoch 034:   1015 / 1191 loss=1.796, trans_loss=4.535, nll_loss=1.705, w2v_ctc_loss=0.518, task_loss=2.388, contrastive_loss=0.138, total=6680.01, n_correct=4900.76, ppl=3.26, accuracy=73.365, wps=18277.4, ups=1.37, wpb=13360, bsz=442.6, num_updates=40300, lr=7.0447e-05, gnorm=0.42, clip=0, loss_scale=16, train_wall=73, gb_free=13.3, wall=35600
2023-08-26 22:15:27 | INFO | train_inner | epoch 034:   1115 / 1191 loss=1.792, trans_loss=4.529, nll_loss=1.698, w2v_ctc_loss=0.511, task_loss=2.183, contrastive_loss=0.172, total=6848.4, n_correct=5032.78, ppl=3.24, accuracy=73.488, wps=18928, ups=1.38, wpb=13696.8, bsz=477.6, num_updates=40400, lr=7.03598e-05, gnorm=0.409, clip=0, loss_scale=16, train_wall=72, gb_free=14, wall=35672
2023-08-26 22:16:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:5')
2023-08-26 22:16:55 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.745 | trans_loss 4.847 | nll_loss 2.058 | w2v_ctc_loss 1.214 | task_loss 8.612 | contrastive_loss 0.363 | total 6138.43 | n_correct 4393.43 | ppl 4.16 | accuracy 71.573 | uer 16.463 | wer 18.096 | raw_wer 18.096 | bleu 29.04 | wps 1778 | wpb 6138.4 | bsz 201.1 | num_updates 40476 | best_bleu 29.29
2023-08-26 22:16:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 40476 updates
2023-08-26 22:16:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.0402.pt
2023-08-26 22:16:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.0402.pt
2023-08-26 22:17:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.0402.pt (epoch 34 @ 40476 updates, score 29.04) (writing took 6.873576525002136 seconds)
2023-08-26 22:17:02 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-26 22:17:02 | INFO | train | epoch 034 | loss 1.797 | trans_loss 4.53 | nll_loss 1.698 | w2v_ctc_loss 0.516 | task_loss 2.359 | contrastive_loss 0.179 | total 6703.3 | n_correct 4924.24 | ppl 3.24 | accuracy 73.46 | wps 16708.9 | ups 1.25 | wpb 13406.6 | bsz 452.1 | num_updates 40476 | lr 7.02937e-05 | gnorm 0.419 | clip 0 | loss_scale 16 | train_wall 860 | gb_free 13.8 | wall 35768
2023-08-26 22:17:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 22:17:02 | INFO | fairseq.trainer | begin training epoch 35
2023-08-26 22:17:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 22:17:27 | INFO | train_inner | epoch 035:     24 / 1191 loss=1.798, trans_loss=4.528, nll_loss=1.696, w2v_ctc_loss=0.51, task_loss=2.212, contrastive_loss=0.239, total=6771.92, n_correct=4980.42, ppl=3.24, accuracy=73.545, wps=11257.5, ups=0.83, wpb=13543.8, bsz=471.7, num_updates=40500, lr=7.02728e-05, gnorm=0.408, clip=0, loss_scale=16, train_wall=72, gb_free=13.3, wall=35793
2023-08-26 22:18:40 | INFO | train_inner | epoch 035:    124 / 1191 loss=1.789, trans_loss=4.522, nll_loss=1.688, w2v_ctc_loss=0.515, task_loss=2.346, contrastive_loss=0.139, total=6711.06, n_correct=4945.35, ppl=3.22, accuracy=73.69, wps=18412.4, ups=1.37, wpb=13422.1, bsz=452.8, num_updates=40600, lr=7.01862e-05, gnorm=0.417, clip=0, loss_scale=16, train_wall=72, gb_free=11.5, wall=35866
2023-08-26 22:19:53 | INFO | train_inner | epoch 035:    224 / 1191 loss=1.795, trans_loss=4.519, nll_loss=1.684, w2v_ctc_loss=0.508, task_loss=2.453, contrastive_loss=0.252, total=6627.11, n_correct=4881.27, ppl=3.21, accuracy=73.656, wps=18323.2, ups=1.38, wpb=13254.2, bsz=444, num_updates=40700, lr=7.01e-05, gnorm=0.416, clip=0, loss_scale=16, train_wall=72, gb_free=14.9, wall=35938
2023-08-26 22:21:05 | INFO | train_inner | epoch 035:    324 / 1191 loss=1.786, trans_loss=4.516, nll_loss=1.68, w2v_ctc_loss=0.505, task_loss=2.261, contrastive_loss=0.189, total=6768.12, n_correct=4994.63, ppl=3.2, accuracy=73.796, wps=18695.1, ups=1.38, wpb=13536.2, bsz=463.6, num_updates=40800, lr=7.0014e-05, gnorm=0.415, clip=0, loss_scale=16, train_wall=72, gb_free=13.4, wall=36010
2023-08-26 22:22:18 | INFO | train_inner | epoch 035:    424 / 1191 loss=1.793, trans_loss=4.527, nll_loss=1.693, w2v_ctc_loss=0.52, task_loss=2.643, contrastive_loss=0.124, total=6573.32, n_correct=4831.45, ppl=3.23, accuracy=73.501, wps=18057.1, ups=1.37, wpb=13146.6, bsz=420.1, num_updates=40900, lr=6.99284e-05, gnorm=0.419, clip=0, loss_scale=16, train_wall=72, gb_free=13.5, wall=36083
2023-08-26 22:23:31 | INFO | train_inner | epoch 035:    524 / 1191 loss=1.788, trans_loss=4.518, nll_loss=1.683, w2v_ctc_loss=0.512, task_loss=2.357, contrastive_loss=0.155, total=6718.03, n_correct=4951.2, ppl=3.21, accuracy=73.7, wps=18446, ups=1.37, wpb=13436.1, bsz=456.1, num_updates=41000, lr=6.9843e-05, gnorm=0.418, clip=0, loss_scale=16, train_wall=72, gb_free=12.3, wall=36156
2023-08-26 22:24:44 | INFO | train_inner | epoch 035:    624 / 1191 loss=1.791, trans_loss=4.522, nll_loss=1.688, w2v_ctc_loss=0.514, task_loss=2.386, contrastive_loss=0.162, total=6702.8, n_correct=4930.6, ppl=3.22, accuracy=73.56, wps=18222.1, ups=1.36, wpb=13405.6, bsz=446.4, num_updates=41100, lr=6.9758e-05, gnorm=0.418, clip=0, loss_scale=16, train_wall=73, gb_free=9.4, wall=36230
2023-08-26 22:25:57 | INFO | train_inner | epoch 035:    724 / 1191 loss=1.798, trans_loss=4.529, nll_loss=1.697, w2v_ctc_loss=0.513, task_loss=2.357, contrastive_loss=0.203, total=6709.59, n_correct=4930.73, ppl=3.24, accuracy=73.488, wps=18485, ups=1.38, wpb=13419.2, bsz=453.6, num_updates=41200, lr=6.96733e-05, gnorm=0.42, clip=0, loss_scale=16, train_wall=72, gb_free=13, wall=36302
2023-08-26 22:27:10 | INFO | train_inner | epoch 035:    824 / 1191 loss=1.795, trans_loss=4.531, nll_loss=1.7, w2v_ctc_loss=0.509, task_loss=2.26, contrastive_loss=0.191, total=6756.65, n_correct=4961.4, ppl=3.25, accuracy=73.43, wps=18582.5, ups=1.38, wpb=13513.3, bsz=459.7, num_updates=41300, lr=6.95889e-05, gnorm=0.416, clip=0, loss_scale=16, train_wall=72, gb_free=14.1, wall=36375
2023-08-26 22:28:21 | INFO | train_inner | epoch 035:    924 / 1191 loss=1.792, trans_loss=4.524, nll_loss=1.692, w2v_ctc_loss=0.505, task_loss=2.162, contrastive_loss=0.213, total=6770.43, n_correct=4982.03, ppl=3.23, accuracy=73.585, wps=18833.3, ups=1.39, wpb=13540.9, bsz=473.1, num_updates=41400, lr=6.95048e-05, gnorm=0.413, clip=0, loss_scale=16, train_wall=71, gb_free=14.5, wall=36447
2023-08-26 22:29:34 | INFO | train_inner | epoch 035:   1024 / 1191 loss=1.793, trans_loss=4.522, nll_loss=1.688, w2v_ctc_loss=0.518, task_loss=2.384, contrastive_loss=0.142, total=6727.5, n_correct=4945.42, ppl=3.22, accuracy=73.511, wps=18599.2, ups=1.38, wpb=13455, bsz=442.9, num_updates=41500, lr=6.9421e-05, gnorm=0.415, clip=0, loss_scale=16, train_wall=72, gb_free=14, wall=36519
2023-08-26 22:30:47 | INFO | train_inner | epoch 035:   1124 / 1191 loss=1.794, trans_loss=4.531, nll_loss=1.699, w2v_ctc_loss=0.521, task_loss=2.431, contrastive_loss=0.138, total=6632.13, n_correct=4872.07, ppl=3.25, accuracy=73.462, wps=18082.4, ups=1.36, wpb=13264.3, bsz=443.4, num_updates=41600, lr=6.93375e-05, gnorm=0.419, clip=0, loss_scale=16, train_wall=73, gb_free=13.4, wall=36593
2023-08-26 22:31:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 22:32:08 | INFO | dev_st | epoch 035 | valid on 'dev_st' subset | loss 3.747 | trans_loss 4.846 | nll_loss 2.057 | w2v_ctc_loss 1.216 | task_loss 8.544 | contrastive_loss 0.368 | total 6138.43 | n_correct 4402.57 | ppl 4.16 | accuracy 71.721 | uer 16.819 | wer 18.423 | raw_wer 18.423 | bleu 29.28 | wps 1751 | wpb 6138.4 | bsz 201.1 | num_updates 41667 | best_bleu 29.29
2023-08-26 22:32:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 41667 updates
2023-08-26 22:32:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.2806.pt
2023-08-26 22:32:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.2806.pt
2023-08-26 22:32:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.2806.pt (epoch 35 @ 41667 updates, score 29.28) (writing took 7.392728024991811 seconds)
2023-08-26 22:32:17 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-08-26 22:32:17 | INFO | train | epoch 035 | loss 1.793 | trans_loss 4.524 | nll_loss 1.691 | w2v_ctc_loss 0.512 | task_loss 2.354 | contrastive_loss 0.177 | total 6703.69 | n_correct 4932.5 | ppl 3.23 | accuracy 73.579 | wps 17464.8 | ups 1.3 | wpb 13407.4 | bsz 452.1 | num_updates 41667 | lr 6.92818e-05 | gnorm 0.417 | clip 0 | loss_scale 16 | train_wall 859 | gb_free 14.1 | wall 36682
2023-08-26 22:32:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 22:32:17 | INFO | fairseq.trainer | begin training epoch 36
2023-08-26 22:32:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 22:32:48 | INFO | train_inner | epoch 036:     33 / 1191 loss=1.791, trans_loss=4.521, nll_loss=1.687, w2v_ctc_loss=0.503, task_loss=2.279, contrastive_loss=0.207, total=6723.84, n_correct=4957.86, ppl=3.22, accuracy=73.736, wps=11123.4, ups=0.83, wpb=13447.7, bsz=466.4, num_updates=41700, lr=6.92543e-05, gnorm=0.415, clip=0, loss_scale=16, train_wall=72, gb_free=14.4, wall=36713
2023-08-26 22:34:00 | INFO | train_inner | epoch 036:    133 / 1191 loss=1.79, trans_loss=4.512, nll_loss=1.674, w2v_ctc_loss=0.508, task_loss=2.428, contrastive_loss=0.22, total=6619.6, n_correct=4885.81, ppl=3.19, accuracy=73.808, wps=18391, ups=1.39, wpb=13239.2, bsz=440.5, num_updates=41800, lr=6.91714e-05, gnorm=0.421, clip=0, loss_scale=16, train_wall=71, gb_free=12.1, wall=36785
2023-08-26 22:35:12 | INFO | train_inner | epoch 036:    233 / 1191 loss=1.772, trans_loss=4.503, nll_loss=1.664, w2v_ctc_loss=0.497, task_loss=2.203, contrastive_loss=0.134, total=6746.42, n_correct=5000.22, ppl=3.17, accuracy=74.117, wps=18730.6, ups=1.39, wpb=13492.8, bsz=471.8, num_updates=41900, lr=6.90889e-05, gnorm=0.413, clip=0, loss_scale=32, train_wall=71, gb_free=14, wall=36858
2023-08-26 22:36:24 | INFO | train_inner | epoch 036:    333 / 1191 loss=1.781, trans_loss=4.516, nll_loss=1.68, w2v_ctc_loss=0.502, task_loss=2.247, contrastive_loss=0.14, total=6782.22, n_correct=5007.39, ppl=3.2, accuracy=73.831, wps=18775.5, ups=1.38, wpb=13564.4, bsz=465.7, num_updates=42000, lr=6.90066e-05, gnorm=0.412, clip=0, loss_scale=32, train_wall=71, gb_free=14.2, wall=36930
2023-08-26 22:36:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 22:36:56 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 3.749 | trans_loss 4.851 | nll_loss 2.061 | w2v_ctc_loss 1.212 | task_loss 8.56 | contrastive_loss 0.372 | total 6138.43 | n_correct 4393 | ppl 4.17 | accuracy 71.566 | uer 16.388 | wer 18.003 | raw_wer 18.003 | bleu 29.14 | wps 1779.9 | wpb 6138.4 | bsz 201.1 | num_updates 42000 | best_bleu 29.29
2023-08-26 22:36:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 42000 updates
2023-08-26 22:36:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_36_42000.pt
2023-08-26 22:36:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_36_42000.pt
2023-08-26 22:37:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_36_42000.pt (epoch 36 @ 42000 updates, score 29.14) (writing took 6.860056154997437 seconds)
2023-08-26 22:38:18 | INFO | train_inner | epoch 036:    433 / 1191 loss=1.786, trans_loss=4.518, nll_loss=1.683, w2v_ctc_loss=0.506, task_loss=2.222, contrastive_loss=0.175, total=6792.65, n_correct=5009.74, ppl=3.21, accuracy=73.752, wps=11979.1, ups=0.88, wpb=13585.3, bsz=471.5, num_updates=42100, lr=6.89246e-05, gnorm=0.411, clip=0, loss_scale=32, train_wall=73, gb_free=13.7, wall=37043
2023-08-26 22:39:31 | INFO | train_inner | epoch 036:    533 / 1191 loss=1.803, trans_loss=4.528, nll_loss=1.696, w2v_ctc_loss=0.512, task_loss=2.207, contrastive_loss=0.268, total=6799.2, n_correct=4994.79, ppl=3.24, accuracy=73.461, wps=18689.7, ups=1.37, wpb=13598.4, bsz=476.6, num_updates=42200, lr=6.88428e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=72, gb_free=13.7, wall=37116
2023-08-26 22:40:43 | INFO | train_inner | epoch 036:    633 / 1191 loss=1.785, trans_loss=4.515, nll_loss=1.68, w2v_ctc_loss=0.511, task_loss=2.416, contrastive_loss=0.13, total=6677.2, n_correct=4925.37, ppl=3.2, accuracy=73.764, wps=18353.6, ups=1.37, wpb=13354.4, bsz=440.8, num_updates=42300, lr=6.87614e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=72, gb_free=13.1, wall=37189
2023-08-26 22:41:56 | INFO | train_inner | epoch 036:    733 / 1191 loss=1.792, trans_loss=4.52, nll_loss=1.685, w2v_ctc_loss=0.51, task_loss=2.355, contrastive_loss=0.198, total=6721.98, n_correct=4951.2, ppl=3.22, accuracy=73.657, wps=18428.5, ups=1.37, wpb=13444, bsz=451.5, num_updates=42400, lr=6.86803e-05, gnorm=0.416, clip=0, loss_scale=32, train_wall=72, gb_free=13.7, wall=37262
2023-08-26 22:43:10 | INFO | train_inner | epoch 036:    833 / 1191 loss=1.789, trans_loss=4.527, nll_loss=1.695, w2v_ctc_loss=0.511, task_loss=2.456, contrastive_loss=0.134, total=6667.94, n_correct=4906.43, ppl=3.24, accuracy=73.582, wps=18134.3, ups=1.36, wpb=13335.9, bsz=443.4, num_updates=42500, lr=6.85994e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=73, gb_free=14.3, wall=37335
2023-08-26 22:44:23 | INFO | train_inner | epoch 036:    933 / 1191 loss=1.799, trans_loss=4.524, nll_loss=1.69, w2v_ctc_loss=0.514, task_loss=2.519, contrastive_loss=0.219, total=6687.67, n_correct=4916.65, ppl=3.23, accuracy=73.518, wps=18154.5, ups=1.36, wpb=13375.3, bsz=433.6, num_updates=42600, lr=6.85189e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=73, gb_free=13.8, wall=37409
2023-08-26 22:45:35 | INFO | train_inner | epoch 036:   1033 / 1191 loss=1.789, trans_loss=4.525, nll_loss=1.692, w2v_ctc_loss=0.51, task_loss=2.284, contrastive_loss=0.157, total=6704.37, n_correct=4932.81, ppl=3.23, accuracy=73.576, wps=18730.1, ups=1.4, wpb=13408.7, bsz=460.9, num_updates=42700, lr=6.84386e-05, gnorm=0.417, clip=0, loss_scale=32, train_wall=71, gb_free=14, wall=37480
2023-08-26 22:46:48 | INFO | train_inner | epoch 036:   1133 / 1191 loss=1.792, trans_loss=4.521, nll_loss=1.686, w2v_ctc_loss=0.522, task_loss=2.481, contrastive_loss=0.136, total=6606.86, n_correct=4859.69, ppl=3.22, accuracy=73.555, wps=18085.8, ups=1.37, wpb=13213.7, bsz=434.3, num_updates=42800, lr=6.83586e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=72, gb_free=14.8, wall=37554
2023-08-26 22:47:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-26 22:47:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 22:48:02 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 3.738 | trans_loss 4.847 | nll_loss 2.058 | w2v_ctc_loss 1.183 | task_loss 8.606 | contrastive_loss 0.371 | total 6138.43 | n_correct 4397.43 | ppl 4.16 | accuracy 71.638 | uer 16.436 | wer 17.984 | raw_wer 17.984 | bleu 29.42 | wps 1782.3 | wpb 6138.4 | bsz 201.1 | num_updates 42857 | best_bleu 29.42
2023-08-26 22:48:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 42857 updates
2023-08-26 22:48:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 22:48:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-26 22:48:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 36 @ 42857 updates, score 29.42) (writing took 12.041113507002592 seconds)
2023-08-26 22:48:15 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-08-26 22:48:15 | INFO | train | epoch 036 | loss 1.789 | trans_loss 4.519 | nll_loss 1.684 | w2v_ctc_loss 0.509 | task_loss 2.357 | contrastive_loss 0.174 | total 6702.6 | n_correct 4938.99 | ppl 3.21 | accuracy 73.688 | wps 16645.3 | ups 1.24 | wpb 13405.2 | bsz 451.7 | num_updates 42857 | lr 6.83131e-05 | gnorm 0.418 | clip 0 | loss_scale 16 | train_wall 859 | gb_free 12.7 | wall 37640
2023-08-26 22:48:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 22:48:15 | INFO | fairseq.trainer | begin training epoch 37
2023-08-26 22:48:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 22:48:54 | INFO | train_inner | epoch 037:     43 / 1191 loss=1.788, trans_loss=4.519, nll_loss=1.684, w2v_ctc_loss=0.508, task_loss=2.482, contrastive_loss=0.156, total=6665.32, n_correct=4910.75, ppl=3.21, accuracy=73.676, wps=10626.4, ups=0.8, wpb=13330.6, bsz=436.1, num_updates=42900, lr=6.82789e-05, gnorm=0.421, clip=0, loss_scale=16, train_wall=73, gb_free=15.1, wall=37679
2023-08-26 22:50:06 | INFO | train_inner | epoch 037:    143 / 1191 loss=1.793, trans_loss=4.515, nll_loss=1.679, w2v_ctc_loss=0.504, task_loss=2.238, contrastive_loss=0.254, total=6762.6, n_correct=4985.27, ppl=3.2, accuracy=73.718, wps=18604.8, ups=1.38, wpb=13525.2, bsz=464, num_updates=43000, lr=6.81994e-05, gnorm=0.416, clip=0, loss_scale=16, train_wall=72, gb_free=12.7, wall=37752
2023-08-26 22:51:19 | INFO | train_inner | epoch 037:    243 / 1191 loss=1.782, trans_loss=4.508, nll_loss=1.67, w2v_ctc_loss=0.503, task_loss=2.374, contrastive_loss=0.161, total=6696.92, n_correct=4947.84, ppl=3.18, accuracy=73.882, wps=18400.8, ups=1.37, wpb=13393.8, bsz=449.2, num_updates=43100, lr=6.81203e-05, gnorm=0.418, clip=0, loss_scale=16, train_wall=72, gb_free=11.6, wall=37825
2023-08-26 22:52:31 | INFO | train_inner | epoch 037:    343 / 1191 loss=1.786, trans_loss=4.514, nll_loss=1.678, w2v_ctc_loss=0.511, task_loss=2.414, contrastive_loss=0.154, total=6637.72, n_correct=4898.71, ppl=3.2, accuracy=73.801, wps=18470, ups=1.39, wpb=13275.4, bsz=440.5, num_updates=43200, lr=6.80414e-05, gnorm=0.429, clip=0, loss_scale=16, train_wall=71, gb_free=13.5, wall=37896
2023-08-26 22:53:44 | INFO | train_inner | epoch 037:    443 / 1191 loss=1.779, trans_loss=4.507, nll_loss=1.668, w2v_ctc_loss=0.501, task_loss=2.36, contrastive_loss=0.151, total=6703.75, n_correct=4960.36, ppl=3.18, accuracy=73.994, wps=18415.9, ups=1.37, wpb=13407.5, bsz=446.8, num_updates=43300, lr=6.79628e-05, gnorm=0.416, clip=0, loss_scale=16, train_wall=72, gb_free=14.4, wall=37969
2023-08-26 22:54:56 | INFO | train_inner | epoch 037:    543 / 1191 loss=1.783, trans_loss=4.511, nll_loss=1.674, w2v_ctc_loss=0.508, task_loss=2.412, contrastive_loss=0.168, total=6639.95, n_correct=4902.58, ppl=3.19, accuracy=73.835, wps=18254.4, ups=1.37, wpb=13279.9, bsz=449.3, num_updates=43400, lr=6.78844e-05, gnorm=0.418, clip=0, loss_scale=16, train_wall=72, gb_free=13.4, wall=38042
2023-08-26 22:56:09 | INFO | train_inner | epoch 037:    643 / 1191 loss=1.786, trans_loss=4.517, nll_loss=1.682, w2v_ctc_loss=0.502, task_loss=2.526, contrastive_loss=0.161, total=6631.82, n_correct=4891.6, ppl=3.21, accuracy=73.76, wps=18222.6, ups=1.37, wpb=13263.6, bsz=428.1, num_updates=43500, lr=6.78064e-05, gnorm=0.421, clip=0, loss_scale=16, train_wall=72, gb_free=12.2, wall=38115
2023-08-26 22:57:22 | INFO | train_inner | epoch 037:    743 / 1191 loss=1.787, trans_loss=4.513, nll_loss=1.677, w2v_ctc_loss=0.506, task_loss=2.343, contrastive_loss=0.181, total=6719.07, n_correct=4962.63, ppl=3.2, accuracy=73.859, wps=18394.5, ups=1.37, wpb=13438.1, bsz=451.8, num_updates=43600, lr=6.77285e-05, gnorm=0.415, clip=0, loss_scale=16, train_wall=72, gb_free=13.2, wall=38188
2023-08-26 22:58:36 | INFO | train_inner | epoch 037:    843 / 1191 loss=1.785, trans_loss=4.52, nll_loss=1.686, w2v_ctc_loss=0.504, task_loss=2.261, contrastive_loss=0.177, total=6808.88, n_correct=5021.69, ppl=3.22, accuracy=73.752, wps=18523.7, ups=1.36, wpb=13617.8, bsz=466.8, num_updates=43700, lr=6.7651e-05, gnorm=0.415, clip=0, loss_scale=16, train_wall=73, gb_free=14.2, wall=38261
2023-08-26 22:59:50 | INFO | train_inner | epoch 037:    943 / 1191 loss=1.783, trans_loss=4.514, nll_loss=1.678, w2v_ctc_loss=0.497, task_loss=2.064, contrastive_loss=0.213, total=6855.49, n_correct=5062.45, ppl=3.2, accuracy=73.845, wps=18603.3, ups=1.36, wpb=13711, bsz=499.9, num_updates=43800, lr=6.75737e-05, gnorm=0.415, clip=0, loss_scale=16, train_wall=73, gb_free=13, wall=38335
2023-08-26 23:01:02 | INFO | train_inner | epoch 037:   1043 / 1191 loss=1.781, trans_loss=4.512, nll_loss=1.675, w2v_ctc_loss=0.507, task_loss=2.46, contrastive_loss=0.126, total=6689.96, n_correct=4943.81, ppl=3.19, accuracy=73.899, wps=18371.5, ups=1.37, wpb=13379.9, bsz=441.4, num_updates=43900, lr=6.74967e-05, gnorm=0.422, clip=0, loss_scale=16, train_wall=72, gb_free=13.7, wall=38408
2023-08-26 23:02:15 | INFO | train_inner | epoch 037:   1143 / 1191 loss=1.796, trans_loss=4.523, nll_loss=1.69, w2v_ctc_loss=0.514, task_loss=2.437, contrastive_loss=0.2, total=6631.9, n_correct=4878.82, ppl=3.23, accuracy=73.566, wps=18217.8, ups=1.37, wpb=13263.8, bsz=443.6, num_updates=44000, lr=6.742e-05, gnorm=0.422, clip=0, loss_scale=16, train_wall=72, gb_free=14.4, wall=38481
2023-08-26 23:02:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 23:02:47 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 3.745 | trans_loss 4.85 | nll_loss 2.062 | w2v_ctc_loss 1.2 | task_loss 8.624 | contrastive_loss 0.376 | total 6138.43 | n_correct 4390.57 | ppl 4.17 | accuracy 71.526 | uer 16.597 | wer 18.144 | raw_wer 18.144 | bleu 29.2 | wps 1761 | wpb 6138.4 | bsz 201.1 | num_updates 44000 | best_bleu 29.42
2023-08-26 23:02:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 44000 updates
2023-08-26 23:02:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_37_44000.pt
2023-08-26 23:02:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_37_44000.pt
2023-08-26 23:02:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_37_44000.pt (epoch 37 @ 44000 updates, score 29.2) (writing took 6.900970949005568 seconds)
2023-08-26 23:03:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 23:04:02 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 3.742 | trans_loss 4.85 | nll_loss 2.061 | w2v_ctc_loss 1.195 | task_loss 8.562 | contrastive_loss 0.37 | total 6138.43 | n_correct 4392.71 | ppl 4.17 | accuracy 71.561 | uer 16.396 | wer 17.977 | raw_wer 17.977 | bleu 29.3 | wps 1759.9 | wpb 6138.4 | bsz 201.1 | num_updates 44048 | best_bleu 29.42
2023-08-26 23:04:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 44048 updates
2023-08-26 23:04:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.3007.pt
2023-08-26 23:04:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.3007.pt
2023-08-26 23:04:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.3007.pt (epoch 37 @ 44048 updates, score 29.3) (writing took 7.705592968995916 seconds)
2023-08-26 23:04:10 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-08-26 23:04:10 | INFO | train | epoch 037 | loss 1.785 | trans_loss 4.514 | nll_loss 1.678 | w2v_ctc_loss 0.505 | task_loss 2.355 | contrastive_loss 0.175 | total 6703.69 | n_correct 4948.05 | ppl 3.2 | accuracy 73.811 | wps 16721.7 | ups 1.25 | wpb 13407.4 | bsz 452.1 | num_updates 44048 | lr 6.73832e-05 | gnorm 0.419 | clip 0 | loss_scale 16 | train_wall 860 | gb_free 13.5 | wall 38595
2023-08-26 23:04:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 23:04:10 | INFO | fairseq.trainer | begin training epoch 38
2023-08-26 23:04:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 23:04:56 | INFO | train_inner | epoch 038:     52 / 1191 loss=1.784, trans_loss=4.518, nll_loss=1.682, w2v_ctc_loss=0.505, task_loss=2.479, contrastive_loss=0.132, total=6590.11, n_correct=4861.67, ppl=3.21, accuracy=73.772, wps=8222, ups=0.62, wpb=13180.2, bsz=432.1, num_updates=44100, lr=6.73435e-05, gnorm=0.42, clip=0, loss_scale=16, train_wall=72, gb_free=11.8, wall=38641
2023-08-26 23:06:08 | INFO | train_inner | epoch 038:    152 / 1191 loss=1.775, trans_loss=4.5, nll_loss=1.661, w2v_ctc_loss=0.497, task_loss=2.333, contrastive_loss=0.149, total=6707.39, n_correct=4972.15, ppl=3.16, accuracy=74.129, wps=18601.9, ups=1.39, wpb=13414.8, bsz=449.4, num_updates=44200, lr=6.72673e-05, gnorm=0.415, clip=0, loss_scale=16, train_wall=72, gb_free=8, wall=38713
2023-08-26 23:07:21 | INFO | train_inner | epoch 038:    252 / 1191 loss=1.79, trans_loss=4.509, nll_loss=1.671, w2v_ctc_loss=0.5, task_loss=2.345, contrastive_loss=0.266, total=6683.44, n_correct=4936.11, ppl=3.18, accuracy=73.856, wps=18322.4, ups=1.37, wpb=13366.9, bsz=456.5, num_updates=44300, lr=6.71913e-05, gnorm=0.42, clip=0, loss_scale=16, train_wall=72, gb_free=13.9, wall=38786
2023-08-26 23:08:33 | INFO | train_inner | epoch 038:    352 / 1191 loss=1.779, trans_loss=4.504, nll_loss=1.664, w2v_ctc_loss=0.506, task_loss=2.42, contrastive_loss=0.133, total=6695.6, n_correct=4953.87, ppl=3.17, accuracy=73.987, wps=18408.7, ups=1.37, wpb=13391.2, bsz=443, num_updates=44400, lr=6.71156e-05, gnorm=0.415, clip=0, loss_scale=16, train_wall=72, gb_free=13.1, wall=38859
2023-08-26 23:09:46 | INFO | train_inner | epoch 038:    452 / 1191 loss=1.779, trans_loss=4.509, nll_loss=1.671, w2v_ctc_loss=0.496, task_loss=2.222, contrastive_loss=0.195, total=6755.69, n_correct=4998.13, ppl=3.18, accuracy=73.984, wps=18590.5, ups=1.38, wpb=13511.4, bsz=476.3, num_updates=44500, lr=6.70402e-05, gnorm=0.413, clip=0, loss_scale=16, train_wall=72, gb_free=12.9, wall=38931
2023-08-26 23:11:00 | INFO | train_inner | epoch 038:    552 / 1191 loss=1.78, trans_loss=4.506, nll_loss=1.668, w2v_ctc_loss=0.497, task_loss=2.277, contrastive_loss=0.189, total=6799.96, n_correct=5032.26, ppl=3.18, accuracy=74.004, wps=18506.1, ups=1.36, wpb=13599.9, bsz=463.7, num_updates=44600, lr=6.6965e-05, gnorm=0.408, clip=0, loss_scale=16, train_wall=73, gb_free=11.7, wall=39005
2023-08-26 23:12:12 | INFO | train_inner | epoch 038:    652 / 1191 loss=1.788, trans_loss=4.518, nll_loss=1.684, w2v_ctc_loss=0.503, task_loss=2.168, contrastive_loss=0.201, total=6826.7, n_correct=5039.28, ppl=3.21, accuracy=73.817, wps=18751.1, ups=1.37, wpb=13653.4, bsz=474.6, num_updates=44700, lr=6.689e-05, gnorm=0.412, clip=0, loss_scale=16, train_wall=72, gb_free=11.9, wall=39078
2023-08-26 23:13:25 | INFO | train_inner | epoch 038:    752 / 1191 loss=1.78, trans_loss=4.509, nll_loss=1.672, w2v_ctc_loss=0.498, task_loss=2.298, contrastive_loss=0.188, total=6730.12, n_correct=4978.63, ppl=3.19, accuracy=73.975, wps=18593.4, ups=1.38, wpb=13460.2, bsz=464.2, num_updates=44800, lr=6.68153e-05, gnorm=0.412, clip=0, loss_scale=16, train_wall=72, gb_free=13.2, wall=39150
2023-08-26 23:14:38 | INFO | train_inner | epoch 038:    852 / 1191 loss=1.782, trans_loss=4.511, nll_loss=1.673, w2v_ctc_loss=0.508, task_loss=2.461, contrastive_loss=0.126, total=6687.39, n_correct=4932.99, ppl=3.19, accuracy=73.766, wps=18349.5, ups=1.37, wpb=13374.8, bsz=435.4, num_updates=44900, lr=6.67409e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=72, gb_free=11.5, wall=39223
2023-08-26 23:15:50 | INFO | train_inner | epoch 038:    952 / 1191 loss=1.782, trans_loss=4.512, nll_loss=1.675, w2v_ctc_loss=0.502, task_loss=2.378, contrastive_loss=0.152, total=6685.88, n_correct=4940.21, ppl=3.19, accuracy=73.89, wps=18357.8, ups=1.37, wpb=13371.8, bsz=446, num_updates=45000, lr=6.66667e-05, gnorm=0.417, clip=0, loss_scale=32, train_wall=72, gb_free=10.6, wall=39296
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:0')
2023-08-26 23:17:03 | INFO | train_inner | epoch 038:   1052 / 1191 loss=1.788, trans_loss=4.512, nll_loss=1.675, w2v_ctc_loss=0.507, task_loss=2.471, contrastive_loss=0.183, total=6622.97, n_correct=4886.5, ppl=3.19, accuracy=73.781, wps=18308.4, ups=1.38, wpb=13245.9, bsz=440.1, num_updates=45100, lr=6.65927e-05, gnorm=0.423, clip=0, loss_scale=32, train_wall=72, gb_free=12.2, wall=39368
2023-08-26 23:18:16 | INFO | train_inner | epoch 038:   1152 / 1191 loss=1.782, trans_loss=4.514, nll_loss=1.678, w2v_ctc_loss=0.504, task_loss=2.373, contrastive_loss=0.156, total=6688.64, n_correct=4937.16, ppl=3.2, accuracy=73.814, wps=18312.6, ups=1.37, wpb=13377.3, bsz=448.4, num_updates=45200, lr=6.6519e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=72, gb_free=13, wall=39441
2023-08-26 23:18:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2254, device='cuda:1')
2023-08-26 23:19:17 | INFO | dev_st | epoch 038 | valid on 'dev_st' subset | loss 3.742 | trans_loss 4.855 | nll_loss 2.067 | w2v_ctc_loss 1.181 | task_loss 8.596 | contrastive_loss 0.368 | total 6138.43 | n_correct 4388.43 | ppl 4.19 | accuracy 71.491 | uer 16.444 | wer 17.947 | raw_wer 17.947 | bleu 29.01 | wps 1762 | wpb 6138.4 | bsz 201.1 | num_updates 45239 | best_bleu 29.42
2023-08-26 23:19:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 45239 updates
2023-08-26 23:19:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-26 23:19:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-26 23:19:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt (epoch 38 @ 45239 updates, score 29.01) (writing took 5.66432463399542 seconds)
2023-08-26 23:19:22 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-08-26 23:19:22 | INFO | train | epoch 038 | loss 1.782 | trans_loss 4.51 | nll_loss 1.672 | w2v_ctc_loss 0.502 | task_loss 2.355 | contrastive_loss 0.174 | total 6703.69 | n_correct 4954.57 | ppl 3.19 | accuracy 73.908 | wps 17501.5 | ups 1.31 | wpb 13407.4 | bsz 452.1 | num_updates 45239 | lr 6.64903e-05 | gnorm 0.417 | clip 0 | loss_scale 32 | train_wall 860 | gb_free 13.8 | wall 39508
2023-08-26 23:19:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 23:19:23 | INFO | fairseq.trainer | begin training epoch 39
2023-08-26 23:19:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 23:20:14 | INFO | train_inner | epoch 039:     61 / 1191 loss=1.782, trans_loss=4.511, nll_loss=1.674, w2v_ctc_loss=0.506, task_loss=2.666, contrastive_loss=0.133, total=6527.07, n_correct=4823.52, ppl=3.19, accuracy=73.9, wps=11046.6, ups=0.85, wpb=13054.1, bsz=420.4, num_updates=45300, lr=6.64455e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=72, gb_free=10.1, wall=39560
2023-08-26 23:21:27 | INFO | train_inner | epoch 039:    161 / 1191 loss=1.77, trans_loss=4.495, nll_loss=1.653, w2v_ctc_loss=0.493, task_loss=2.395, contrastive_loss=0.132, total=6683.06, n_correct=4965.52, ppl=3.15, accuracy=74.3, wps=18373.9, ups=1.37, wpb=13366.1, bsz=440.5, num_updates=45400, lr=6.63723e-05, gnorm=0.416, clip=0, loss_scale=32, train_wall=72, gb_free=12.8, wall=39632
2023-08-26 23:22:40 | INFO | train_inner | epoch 039:    261 / 1191 loss=1.78, trans_loss=4.507, nll_loss=1.669, w2v_ctc_loss=0.498, task_loss=2.427, contrastive_loss=0.2, total=6673.47, n_correct=4938.82, ppl=3.18, accuracy=74.007, wps=18324.4, ups=1.37, wpb=13346.9, bsz=445, num_updates=45500, lr=6.62994e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=72, gb_free=13.6, wall=39705
2023-08-26 23:23:53 | INFO | train_inner | epoch 039:    361 / 1191 loss=1.78, trans_loss=4.505, nll_loss=1.666, w2v_ctc_loss=0.504, task_loss=2.564, contrastive_loss=0.151, total=6602.39, n_correct=4890.55, ppl=3.17, accuracy=74.072, wps=18037.3, ups=1.37, wpb=13204.8, bsz=427.5, num_updates=45600, lr=6.62266e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=73, gb_free=12.5, wall=39778
2023-08-26 23:25:06 | INFO | train_inner | epoch 039:    461 / 1191 loss=1.777, trans_loss=4.5, nll_loss=1.66, w2v_ctc_loss=0.491, task_loss=2.273, contrastive_loss=0.207, total=6752.25, n_correct=5003.16, ppl=3.16, accuracy=74.096, wps=18351.7, ups=1.36, wpb=13504.5, bsz=462.8, num_updates=45700, lr=6.61541e-05, gnorm=0.416, clip=0, loss_scale=32, train_wall=73, gb_free=14.2, wall=39852
2023-08-26 23:26:19 | INFO | train_inner | epoch 039:    561 / 1191 loss=1.777, trans_loss=4.502, nll_loss=1.663, w2v_ctc_loss=0.496, task_loss=2.364, contrastive_loss=0.162, total=6699.88, n_correct=4960.32, ppl=3.17, accuracy=74.036, wps=18354.5, ups=1.37, wpb=13399.8, bsz=450.3, num_updates=45800, lr=6.60819e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=73, gb_free=14, wall=39925
2023-08-26 23:26:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-26 23:27:33 | INFO | train_inner | epoch 039:    662 / 1191 loss=1.785, trans_loss=4.51, nll_loss=1.672, w2v_ctc_loss=0.503, task_loss=2.349, contrastive_loss=0.194, total=6704.76, n_correct=4947.65, ppl=3.19, accuracy=73.793, wps=18148.2, ups=1.35, wpb=13409.5, bsz=459.8, num_updates=45900, lr=6.60098e-05, gnorm=0.421, clip=0, loss_scale=16, train_wall=73, gb_free=6.1, wall=39999
2023-08-26 23:28:46 | INFO | train_inner | epoch 039:    762 / 1191 loss=1.78, trans_loss=4.508, nll_loss=1.67, w2v_ctc_loss=0.501, task_loss=2.34, contrastive_loss=0.177, total=6736.15, n_correct=4984.02, ppl=3.18, accuracy=73.989, wps=18494.6, ups=1.37, wpb=13472.3, bsz=455.3, num_updates=46000, lr=6.5938e-05, gnorm=0.413, clip=0, loss_scale=16, train_wall=72, gb_free=12.7, wall=40072
2023-08-26 23:28:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 23:29:19 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 3.747 | trans_loss 4.851 | nll_loss 2.062 | w2v_ctc_loss 1.21 | task_loss 8.643 | contrastive_loss 0.367 | total 6138.43 | n_correct 4389.57 | ppl 4.18 | accuracy 71.51 | uer 16.431 | wer 17.977 | raw_wer 17.977 | bleu 28.8 | wps 1767.9 | wpb 6138.4 | bsz 201.1 | num_updates 46000 | best_bleu 29.42
2023-08-26 23:29:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 46000 updates
2023-08-26 23:29:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_39_46000.pt
2023-08-26 23:29:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_39_46000.pt
2023-08-26 23:29:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_39_46000.pt (epoch 39 @ 46000 updates, score 28.8) (writing took 6.176393519010162 seconds)
2023-08-26 23:30:38 | INFO | train_inner | epoch 039:    862 / 1191 loss=1.776, trans_loss=4.508, nll_loss=1.67, w2v_ctc_loss=0.495, task_loss=2.242, contrastive_loss=0.167, total=6798.2, n_correct=5031.04, ppl=3.18, accuracy=74.005, wps=12214.2, ups=0.9, wpb=13596.4, bsz=472.1, num_updates=46100, lr=6.58665e-05, gnorm=0.414, clip=0, loss_scale=16, train_wall=72, gb_free=13.5, wall=40183
2023-08-26 23:31:51 | INFO | train_inner | epoch 039:    962 / 1191 loss=1.777, trans_loss=4.501, nll_loss=1.662, w2v_ctc_loss=0.494, task_loss=2.168, contrastive_loss=0.193, total=6835.31, n_correct=5062.07, ppl=3.16, accuracy=74.058, wps=18600.6, ups=1.36, wpb=13670.6, bsz=480.9, num_updates=46200, lr=6.57952e-05, gnorm=0.419, clip=0, loss_scale=16, train_wall=73, gb_free=13.6, wall=40256
2023-08-26 23:33:03 | INFO | train_inner | epoch 039:   1062 / 1191 loss=1.776, trans_loss=4.503, nll_loss=1.665, w2v_ctc_loss=0.491, task_loss=2.287, contrastive_loss=0.179, total=6757.98, n_correct=5008.85, ppl=3.17, accuracy=74.118, wps=18721.7, ups=1.39, wpb=13516, bsz=459.7, num_updates=46300, lr=6.57241e-05, gnorm=0.414, clip=0, loss_scale=16, train_wall=72, gb_free=14.3, wall=40329
2023-08-26 23:34:16 | INFO | train_inner | epoch 039:   1162 / 1191 loss=1.785, trans_loss=4.509, nll_loss=1.671, w2v_ctc_loss=0.509, task_loss=2.477, contrastive_loss=0.157, total=6582.59, n_correct=4861.61, ppl=3.18, accuracy=73.856, wps=18155.4, ups=1.38, wpb=13165.2, bsz=428.8, num_updates=46400, lr=6.56532e-05, gnorm=0.425, clip=0, loss_scale=16, train_wall=72, gb_free=14, wall=40401
2023-08-26 23:34:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 23:35:09 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 3.75 | trans_loss 4.853 | nll_loss 2.062 | w2v_ctc_loss 1.215 | task_loss 8.608 | contrastive_loss 0.371 | total 6138.43 | n_correct 4387.57 | ppl 4.18 | accuracy 71.477 | uer 16.153 | wer 17.824 | raw_wer 17.824 | bleu 29.13 | wps 1760.9 | wpb 6138.4 | bsz 201.1 | num_updates 46429 | best_bleu 29.42
2023-08-26 23:35:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 46429 updates
2023-08-26 23:35:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.1303.pt
2023-08-26 23:35:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.1303.pt
2023-08-26 23:35:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_29.1303.pt (epoch 39 @ 46429 updates, score 29.13) (writing took 7.224741398997139 seconds)
2023-08-26 23:35:17 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-08-26 23:35:17 | INFO | train | epoch 039 | loss 1.778 | trans_loss 4.504 | nll_loss 1.666 | w2v_ctc_loss 0.498 | task_loss 2.359 | contrastive_loss 0.172 | total 6703 | n_correct 4962.17 | ppl 3.17 | accuracy 74.029 | wps 16719.2 | ups 1.25 | wpb 13406 | bsz 451.9 | num_updates 46429 | lr 6.56327e-05 | gnorm 0.418 | clip 0 | loss_scale 16 | train_wall 861 | gb_free 13.1 | wall 40462
2023-08-26 23:35:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 23:35:17 | INFO | fairseq.trainer | begin training epoch 40
2023-08-26 23:35:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 23:36:16 | INFO | train_inner | epoch 040:     71 / 1191 loss=1.77, trans_loss=4.495, nll_loss=1.654, w2v_ctc_loss=0.491, task_loss=2.233, contrastive_loss=0.158, total=6767.38, n_correct=5019.67, ppl=3.15, accuracy=74.174, wps=11278, ups=0.83, wpb=13534.8, bsz=468.9, num_updates=46500, lr=6.55826e-05, gnorm=0.418, clip=0, loss_scale=16, train_wall=71, gb_free=13.2, wall=40521
2023-08-26 23:37:27 | INFO | train_inner | epoch 040:    171 / 1191 loss=1.768, trans_loss=4.494, nll_loss=1.653, w2v_ctc_loss=0.495, task_loss=2.343, contrastive_loss=0.12, total=6723.92, n_correct=4997.29, ppl=3.14, accuracy=74.321, wps=18777.3, ups=1.4, wpb=13447.8, bsz=450.2, num_updates=46600, lr=6.55122e-05, gnorm=0.415, clip=0, loss_scale=16, train_wall=71, gb_free=13.9, wall=40593
2023-08-26 23:38:41 | INFO | train_inner | epoch 040:    271 / 1191 loss=1.765, trans_loss=4.492, nll_loss=1.65, w2v_ctc_loss=0.484, task_loss=2.24, contrastive_loss=0.155, total=6753.31, n_correct=5020.76, ppl=3.14, accuracy=74.345, wps=18464.8, ups=1.37, wpb=13506.6, bsz=465.8, num_updates=46700, lr=6.5442e-05, gnorm=0.411, clip=0, loss_scale=16, train_wall=73, gb_free=14.8, wall=40666
2023-08-26 23:39:54 | INFO | train_inner | epoch 040:    371 / 1191 loss=1.78, trans_loss=4.499, nll_loss=1.658, w2v_ctc_loss=0.5, task_loss=2.511, contrastive_loss=0.186, total=6618.47, n_correct=4902.57, ppl=3.16, accuracy=74.074, wps=18042.8, ups=1.36, wpb=13236.9, bsz=438.2, num_updates=46800, lr=6.5372e-05, gnorm=0.426, clip=0, loss_scale=16, train_wall=73, gb_free=14.1, wall=40739
2023-08-26 23:41:06 | INFO | train_inner | epoch 040:    471 / 1191 loss=1.768, trans_loss=4.498, nll_loss=1.657, w2v_ctc_loss=0.494, task_loss=2.326, contrastive_loss=0.122, total=6719.05, n_correct=4990.86, ppl=3.15, accuracy=74.279, wps=18565.2, ups=1.38, wpb=13438.1, bsz=454.8, num_updates=46900, lr=6.53023e-05, gnorm=0.413, clip=0, loss_scale=16, train_wall=72, gb_free=13.8, wall=40812
2023-08-26 23:42:19 | INFO | train_inner | epoch 040:    571 / 1191 loss=1.777, trans_loss=4.5, nll_loss=1.66, w2v_ctc_loss=0.489, task_loss=2.303, contrastive_loss=0.229, total=6684.61, n_correct=4954.42, ppl=3.16, accuracy=74.117, wps=18472.5, ups=1.38, wpb=13369.2, bsz=455.8, num_updates=47000, lr=6.52328e-05, gnorm=0.419, clip=0, loss_scale=16, train_wall=72, gb_free=11.9, wall=40884
2023-08-26 23:43:32 | INFO | train_inner | epoch 040:    671 / 1191 loss=1.786, trans_loss=4.503, nll_loss=1.664, w2v_ctc_loss=0.5, task_loss=2.381, contrastive_loss=0.242, total=6699.46, n_correct=4960.33, ppl=3.17, accuracy=74.041, wps=18320.5, ups=1.37, wpb=13398.9, bsz=447.6, num_updates=47100, lr=6.51635e-05, gnorm=0.427, clip=0, loss_scale=16, train_wall=72, gb_free=7.6, wall=40957
2023-08-26 23:44:45 | INFO | train_inner | epoch 040:    771 / 1191 loss=1.775, trans_loss=4.501, nll_loss=1.662, w2v_ctc_loss=0.5, task_loss=2.423, contrastive_loss=0.138, total=6659.73, n_correct=4936.93, ppl=3.16, accuracy=74.131, wps=18258.1, ups=1.37, wpb=13319.5, bsz=443.6, num_updates=47200, lr=6.50945e-05, gnorm=0.422, clip=0, loss_scale=16, train_wall=72, gb_free=12.3, wall=41030
2023-08-26 23:45:58 | INFO | train_inner | epoch 040:    871 / 1191 loss=1.78, trans_loss=4.504, nll_loss=1.666, w2v_ctc_loss=0.5, task_loss=2.446, contrastive_loss=0.165, total=6696.57, n_correct=4954.43, ppl=3.17, accuracy=73.985, wps=18267.2, ups=1.36, wpb=13393.1, bsz=441.7, num_updates=47300, lr=6.50256e-05, gnorm=0.416, clip=0, loss_scale=16, train_wall=73, gb_free=14.2, wall=41104
2023-08-26 23:47:10 | INFO | train_inner | epoch 040:    971 / 1191 loss=1.78, trans_loss=4.506, nll_loss=1.668, w2v_ctc_loss=0.494, task_loss=2.313, contrastive_loss=0.203, total=6694.1, n_correct=4955.68, ppl=3.18, accuracy=74.031, wps=18536.2, ups=1.38, wpb=13388.2, bsz=455.1, num_updates=47400, lr=6.4957e-05, gnorm=0.424, clip=0, loss_scale=16, train_wall=72, gb_free=10.2, wall=41176
2023-08-26 23:48:24 | INFO | train_inner | epoch 040:   1071 / 1191 loss=1.776, trans_loss=4.501, nll_loss=1.662, w2v_ctc_loss=0.5, task_loss=2.353, contrastive_loss=0.156, total=6744.49, n_correct=4998.01, ppl=3.16, accuracy=74.105, wps=18408.3, ups=1.36, wpb=13489, bsz=455.8, num_updates=47500, lr=6.48886e-05, gnorm=0.419, clip=0, loss_scale=16, train_wall=73, gb_free=12.7, wall=41249
2023-08-26 23:49:36 | INFO | train_inner | epoch 040:   1171 / 1191 loss=1.775, trans_loss=4.502, nll_loss=1.663, w2v_ctc_loss=0.491, task_loss=2.285, contrastive_loss=0.187, total=6706.26, n_correct=4969.86, ppl=3.17, accuracy=74.108, wps=18473.6, ups=1.38, wpb=13412.5, bsz=463.1, num_updates=47600, lr=6.48204e-05, gnorm=0.416, clip=0, loss_scale=16, train_wall=72, gb_free=14.4, wall=41322
2023-08-26 23:49:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 23:50:23 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 3.741 | trans_loss 4.847 | nll_loss 2.056 | w2v_ctc_loss 1.204 | task_loss 8.588 | contrastive_loss 0.363 | total 6138.43 | n_correct 4396.14 | ppl 4.16 | accuracy 71.617 | uer 16.308 | wer 18.018 | raw_wer 18.018 | bleu 28.94 | wps 1769 | wpb 6138.4 | bsz 201.1 | num_updates 47620 | best_bleu 29.42
2023-08-26 23:50:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 47620 updates
2023-08-26 23:50:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-26 23:50:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-26 23:50:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt (epoch 40 @ 47620 updates, score 28.94) (writing took 6.860711012996035 seconds)
2023-08-26 23:50:30 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-08-26 23:50:30 | INFO | train | epoch 040 | loss 1.775 | trans_loss 4.5 | nll_loss 1.66 | w2v_ctc_loss 0.495 | task_loss 2.355 | contrastive_loss 0.172 | total 6703.69 | n_correct 4970.16 | ppl 3.16 | accuracy 74.141 | wps 17487.3 | ups 1.3 | wpb 13407.4 | bsz 452.1 | num_updates 47620 | lr 6.48068e-05 | gnorm 0.419 | clip 0 | loss_scale 16 | train_wall 859 | gb_free 11.9 | wall 41375
2023-08-26 23:50:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-26 23:50:30 | INFO | fairseq.trainer | begin training epoch 41
2023-08-26 23:50:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-26 23:51:36 | INFO | train_inner | epoch 041:     80 / 1191 loss=1.772, trans_loss=4.497, nll_loss=1.656, w2v_ctc_loss=0.489, task_loss=2.341, contrastive_loss=0.191, total=6708.43, n_correct=4979.5, ppl=3.15, accuracy=74.228, wps=11237.9, ups=0.84, wpb=13416.9, bsz=461.1, num_updates=47700, lr=6.47524e-05, gnorm=0.42, clip=0, loss_scale=16, train_wall=72, gb_free=13.6, wall=41441
2023-08-26 23:52:48 | INFO | train_inner | epoch 041:    180 / 1191 loss=1.78, trans_loss=4.496, nll_loss=1.654, w2v_ctc_loss=0.495, task_loss=2.4, contrastive_loss=0.223, total=6679.28, n_correct=4950.1, ppl=3.15, accuracy=74.111, wps=18407.1, ups=1.38, wpb=13358.6, bsz=446.1, num_updates=47800, lr=6.46846e-05, gnorm=0.424, clip=0, loss_scale=16, train_wall=72, gb_free=12.9, wall=41514
2023-08-26 23:54:01 | INFO | train_inner | epoch 041:    280 / 1191 loss=1.765, trans_loss=4.49, nll_loss=1.647, w2v_ctc_loss=0.481, task_loss=2.21, contrastive_loss=0.178, total=6799.31, n_correct=5060.79, ppl=3.13, accuracy=74.431, wps=18548.1, ups=1.36, wpb=13598.6, bsz=478, num_updates=47900, lr=6.46171e-05, gnorm=0.411, clip=0, loss_scale=32, train_wall=73, gb_free=13.6, wall=41587
2023-08-26 23:55:14 | INFO | train_inner | epoch 041:    380 / 1191 loss=1.764, trans_loss=4.493, nll_loss=1.651, w2v_ctc_loss=0.489, task_loss=2.264, contrastive_loss=0.125, total=6787.95, n_correct=5046.82, ppl=3.14, accuracy=74.35, wps=18649.2, ups=1.37, wpb=13575.9, bsz=460.8, num_updates=48000, lr=6.45497e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=72, gb_free=13.9, wall=41660
2023-08-26 23:55:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-26 23:55:47 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 3.751 | trans_loss 4.852 | nll_loss 2.062 | w2v_ctc_loss 1.226 | task_loss 8.638 | contrastive_loss 0.363 | total 6138.43 | n_correct 4395.14 | ppl 4.17 | accuracy 71.6 | uer 16.294 | wer 17.75 | raw_wer 17.75 | bleu 29.16 | wps 1746.8 | wpb 6138.4 | bsz 201.1 | num_updates 48000 | best_bleu 29.42
2023-08-26 23:55:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 48000 updates
2023-08-26 23:55:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_41_48000.pt
2023-08-26 23:55:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_41_48000.pt
2023-08-26 23:55:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_41_48000.pt (epoch 41 @ 48000 updates, score 29.16) (writing took 9.808092357998248 seconds)
2023-08-26 23:57:09 | INFO | train_inner | epoch 041:    480 / 1191 loss=1.768, trans_loss=4.494, nll_loss=1.653, w2v_ctc_loss=0.497, task_loss=2.293, contrastive_loss=0.12, total=6778.68, n_correct=5037.23, ppl=3.14, accuracy=74.31, wps=11768, ups=0.87, wpb=13557.4, bsz=458.9, num_updates=48100, lr=6.44826e-05, gnorm=0.414, clip=0, loss_scale=32, train_wall=72, gb_free=14.4, wall=41775
2023-08-26 23:58:22 | INFO | train_inner | epoch 041:    580 / 1191 loss=1.765, trans_loss=4.491, nll_loss=1.648, w2v_ctc_loss=0.484, task_loss=2.229, contrastive_loss=0.143, total=6784.72, n_correct=5044.91, ppl=3.13, accuracy=74.357, wps=18615.6, ups=1.37, wpb=13569.4, bsz=462, num_updates=48200, lr=6.44157e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=72, gb_free=13.7, wall=41848
2023-08-26 23:59:35 | INFO | train_inner | epoch 041:    680 / 1191 loss=1.771, trans_loss=4.495, nll_loss=1.653, w2v_ctc_loss=0.493, task_loss=2.366, contrastive_loss=0.165, total=6684.16, n_correct=4963.6, ppl=3.15, accuracy=74.259, wps=18510.6, ups=1.38, wpb=13368.3, bsz=449.7, num_updates=48300, lr=6.43489e-05, gnorm=0.417, clip=0, loss_scale=32, train_wall=72, gb_free=7.9, wall=41920
2023-08-27 00:00:47 | INFO | train_inner | epoch 041:    780 / 1191 loss=1.772, trans_loss=4.493, nll_loss=1.65, w2v_ctc_loss=0.494, task_loss=2.592, contrastive_loss=0.156, total=6538.9, n_correct=4853.12, ppl=3.14, accuracy=74.219, wps=17947.1, ups=1.37, wpb=13077.8, bsz=421.6, num_updates=48400, lr=6.42824e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=72, gb_free=14.1, wall=41993
2023-08-27 00:02:01 | INFO | train_inner | epoch 041:    880 / 1191 loss=1.774, trans_loss=4.494, nll_loss=1.651, w2v_ctc_loss=0.497, task_loss=2.532, contrastive_loss=0.16, total=6585.34, n_correct=4887.15, ppl=3.14, accuracy=74.213, wps=18032.9, ups=1.37, wpb=13170.7, bsz=427.6, num_updates=48500, lr=6.42161e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=73, gb_free=7.9, wall=42066
2023-08-27 00:03:14 | INFO | train_inner | epoch 041:    980 / 1191 loss=1.777, trans_loss=4.503, nll_loss=1.663, w2v_ctc_loss=0.495, task_loss=2.485, contrastive_loss=0.168, total=6665.41, n_correct=4930.03, ppl=3.17, accuracy=73.964, wps=18255.5, ups=1.37, wpb=13330.8, bsz=440.6, num_updates=48600, lr=6.415e-05, gnorm=0.423, clip=0, loss_scale=32, train_wall=72, gb_free=14.3, wall=42139
2023-08-27 00:04:27 | INFO | train_inner | epoch 041:   1080 / 1191 loss=1.774, trans_loss=4.5, nll_loss=1.661, w2v_ctc_loss=0.49, task_loss=2.186, contrastive_loss=0.202, total=6840.57, n_correct=5076.55, ppl=3.16, accuracy=74.212, wps=18745.1, ups=1.37, wpb=13681.1, bsz=479.5, num_updates=48700, lr=6.40841e-05, gnorm=0.412, clip=0, loss_scale=32, train_wall=72, gb_free=14.6, wall=42212
2023-08-27 00:05:39 | INFO | train_inner | epoch 041:   1180 / 1191 loss=1.779, trans_loss=4.501, nll_loss=1.661, w2v_ctc_loss=0.498, task_loss=2.481, contrastive_loss=0.2, total=6594.78, n_correct=4885.1, ppl=3.16, accuracy=74.075, wps=18209, ups=1.38, wpb=13189.6, bsz=431.4, num_updates=48800, lr=6.40184e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=72, gb_free=11.8, wall=42284
2023-08-27 00:05:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-27 00:06:19 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 3.732 | trans_loss 4.85 | nll_loss 2.061 | w2v_ctc_loss 1.167 | task_loss 8.603 | contrastive_loss 0.363 | total 6138.43 | n_correct 4393.57 | ppl 4.17 | accuracy 71.575 | uer 16.426 | wer 18.122 | raw_wer 18.122 | bleu 29.51 | wps 1773.5 | wpb 6138.4 | bsz 201.1 | num_updates 48811 | best_bleu 29.51
2023-08-27 00:06:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 48811 updates
2023-08-27 00:06:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-27 00:06:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-27 00:06:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 41 @ 48811 updates, score 29.51) (writing took 10.126140305001172 seconds)
2023-08-27 00:06:29 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-08-27 00:06:29 | INFO | train | epoch 041 | loss 1.772 | trans_loss 4.495 | nll_loss 1.654 | w2v_ctc_loss 0.492 | task_loss 2.355 | contrastive_loss 0.17 | total 6703.69 | n_correct 4976.55 | ppl 3.15 | accuracy 74.236 | wps 16637.4 | ups 1.24 | wpb 13407.4 | bsz 452.1 | num_updates 48811 | lr 6.40112e-05 | gnorm 0.418 | clip 0 | loss_scale 32 | train_wall 860 | gb_free 11.3 | wall 42335
2023-08-27 00:06:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-27 00:06:30 | INFO | fairseq.trainer | begin training epoch 42
2023-08-27 00:06:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-27 00:07:41 | INFO | train_inner | epoch 042:     89 / 1191 loss=1.76, trans_loss=4.483, nll_loss=1.639, w2v_ctc_loss=0.474, task_loss=2.097, contrastive_loss=0.19, total=6830.39, n_correct=5096.39, ppl=3.11, accuracy=74.613, wps=11179, ups=0.82, wpb=13660.8, bsz=486.2, num_updates=48900, lr=6.39529e-05, gnorm=0.404, clip=0, loss_scale=32, train_wall=71, gb_free=12.9, wall=42407
2023-08-27 00:08:54 | INFO | train_inner | epoch 042:    189 / 1191 loss=1.777, trans_loss=4.492, nll_loss=1.65, w2v_ctc_loss=0.487, task_loss=2.439, contrastive_loss=0.245, total=6676.16, n_correct=4953.78, ppl=3.14, accuracy=74.201, wps=18354.5, ups=1.37, wpb=13352.3, bsz=441.6, num_updates=49000, lr=6.38877e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=72, gb_free=8, wall=42479
2023-08-27 00:10:07 | INFO | train_inner | epoch 042:    289 / 1191 loss=1.771, trans_loss=4.486, nll_loss=1.642, w2v_ctc_loss=0.496, task_loss=2.422, contrastive_loss=0.172, total=6646.38, n_correct=4942.08, ppl=3.12, accuracy=74.357, wps=18248.2, ups=1.37, wpb=13292.8, bsz=444.2, num_updates=49100, lr=6.38226e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=72, gb_free=14.8, wall=42552
2023-08-27 00:11:19 | INFO | train_inner | epoch 042:    389 / 1191 loss=1.769, trans_loss=4.489, nll_loss=1.646, w2v_ctc_loss=0.492, task_loss=2.429, contrastive_loss=0.161, total=6624.92, n_correct=4927.91, ppl=3.13, accuracy=74.384, wps=18288.6, ups=1.38, wpb=13249.8, bsz=445.7, num_updates=49200, lr=6.37577e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=72, gb_free=13.3, wall=42625
2023-08-27 00:12:33 | INFO | train_inner | epoch 042:    489 / 1191 loss=1.767, trans_loss=4.493, nll_loss=1.65, w2v_ctc_loss=0.49, task_loss=2.622, contrastive_loss=0.116, total=6627.21, n_correct=4918.33, ppl=3.14, accuracy=74.214, wps=17954.4, ups=1.35, wpb=13254.4, bsz=421.1, num_updates=49300, lr=6.3693e-05, gnorm=0.416, clip=0, loss_scale=32, train_wall=73, gb_free=7.6, wall=42699
2023-08-27 00:13:46 | INFO | train_inner | epoch 042:    589 / 1191 loss=1.778, trans_loss=4.497, nll_loss=1.655, w2v_ctc_loss=0.498, task_loss=2.508, contrastive_loss=0.196, total=6612.24, n_correct=4899.96, ppl=3.15, accuracy=74.104, wps=18205.8, ups=1.38, wpb=13224.5, bsz=433.3, num_updates=49400, lr=6.36285e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=72, gb_free=10.9, wall=42771
2023-08-27 00:14:58 | INFO | train_inner | epoch 042:    689 / 1191 loss=1.764, trans_loss=4.49, nll_loss=1.648, w2v_ctc_loss=0.477, task_loss=2.165, contrastive_loss=0.18, total=6812.85, n_correct=5065.94, ppl=3.13, accuracy=74.359, wps=18741.3, ups=1.38, wpb=13625.7, bsz=478.7, num_updates=49500, lr=6.35642e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=72, gb_free=14.2, wall=42844
2023-08-27 00:16:11 | INFO | train_inner | epoch 042:    789 / 1191 loss=1.769, trans_loss=4.496, nll_loss=1.655, w2v_ctc_loss=0.488, task_loss=2.275, contrastive_loss=0.167, total=6711.61, n_correct=4986.5, ppl=3.15, accuracy=74.297, wps=18509.4, ups=1.38, wpb=13423.2, bsz=463.5, num_updates=49600, lr=6.35001e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=72, gb_free=13.9, wall=42916
2023-08-27 00:17:23 | INFO | train_inner | epoch 042:    889 / 1191 loss=1.762, trans_loss=4.487, nll_loss=1.644, w2v_ctc_loss=0.486, task_loss=2.427, contrastive_loss=0.126, total=6568.13, n_correct=4889.27, ppl=3.12, accuracy=74.439, wps=18130.6, ups=1.38, wpb=13136.3, bsz=440.1, num_updates=49700, lr=6.34361e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=72, gb_free=13.2, wall=42989
2023-08-27 00:18:36 | INFO | train_inner | epoch 042:    989 / 1191 loss=1.768, trans_loss=4.492, nll_loss=1.65, w2v_ctc_loss=0.482, task_loss=2.164, contrastive_loss=0.202, total=6810.28, n_correct=5062.12, ppl=3.14, accuracy=74.331, wps=18731.6, ups=1.38, wpb=13620.6, bsz=481, num_updates=49800, lr=6.33724e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=72, gb_free=11.5, wall=43062
2023-08-27 00:19:49 | INFO | train_inner | epoch 042:   1089 / 1191 loss=1.768, trans_loss=4.493, nll_loss=1.651, w2v_ctc_loss=0.492, task_loss=2.539, contrastive_loss=0.114, total=6679.66, n_correct=4959.16, ppl=3.14, accuracy=74.243, wps=18447.2, ups=1.38, wpb=13359.3, bsz=424.5, num_updates=49900, lr=6.33089e-05, gnorm=0.416, clip=0, loss_scale=32, train_wall=72, gb_free=14.4, wall=43134
2023-08-27 00:21:02 | INFO | train_inner | epoch 042:   1189 / 1191 loss=1.766, trans_loss=4.491, nll_loss=1.648, w2v_ctc_loss=0.488, task_loss=2.263, contrastive_loss=0.145, total=6829.88, n_correct=5079.44, ppl=3.14, accuracy=74.371, wps=18628.9, ups=1.36, wpb=13659.8, bsz=464.9, num_updates=50000, lr=6.32456e-05, gnorm=0.415, clip=0, loss_scale=64, train_wall=73, gb_free=12.2, wall=43207
2023-08-27 00:21:02 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-27 00:21:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-27 00:21:34 | INFO | dev_st | epoch 042 | valid on 'dev_st' subset | loss 3.729 | trans_loss 4.845 | nll_loss 2.055 | w2v_ctc_loss 1.169 | task_loss 8.572 | contrastive_loss 0.364 | total 6138.43 | n_correct 4394 | ppl 4.15 | accuracy 71.582 | uer 16.193 | wer 17.813 | raw_wer 17.813 | bleu 28.98 | wps 1759 | wpb 6138.4 | bsz 201.1 | num_updates 50000 | best_bleu 29.51
2023-08-27 00:21:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 50000 updates
2023-08-27 00:21:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_42_50000.pt
2023-08-27 00:21:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_42_50000.pt
2023-08-27 00:21:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0826_both_topCL_AT_sentence_mixup0109_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_42_50000.pt (epoch 42 @ 50000 updates, score 28.98) (writing took 6.18189612099377 seconds)
2023-08-27 00:21:41 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2023-08-27 00:21:41 | INFO | train | epoch 042 | loss 1.768 | trans_loss 4.491 | nll_loss 1.648 | w2v_ctc_loss 0.488 | task_loss 2.354 | contrastive_loss 0.169 | total 6705.77 | n_correct 4983.97 | ppl 3.13 | accuracy 74.324 | wps 17494.5 | ups 1.3 | wpb 13411.5 | bsz 452.3 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.417 | clip 0 | loss_scale 64 | train_wall 858 | gb_free 12.2 | wall 43246
2023-08-27 00:21:41 | INFO | fairseq_cli.train | done training in 43181.7 seconds
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    raise EOFError
EOFError
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    raise EOFError
EOFError
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1728 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
