2023-08-11 16:10:02 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:16152
2023-08-11 16:10:02 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:16152
2023-08-11 16:10:02 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:16152
2023-08-11 16:10:02 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:16152
2023-08-11 16:10:02 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:16152
2023-08-11 16:10:02 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-11 16:10:02 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:16152
2023-08-11 16:10:02 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:16152
2023-08-11 16:10:02 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:16152
2023-08-11 16:10:02 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-11 16:10:02 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-11 16:10:02 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-11 16:10:03 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-11 16:10:03 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-11 16:10:03 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-11 16:10:03 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-11 16:10:03 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-11 16:10:03 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-11 16:10:03 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-08-11 16:10:03 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-11 16:10:03 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-08-11 16:10:03 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-11 16:10:03 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-08-11 16:10:03 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-08-11 16:10:03 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-11 16:10:03 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-11 16:10:03 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-11 16:10:03 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-08-11 16:10:03 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-08-11 16:10:03 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-08-11 16:10:03 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-11 16:10:03 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-08-11 16:10:07 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16152', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-11 16:10:07 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-11 16:10:07 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-11 16:10:07 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-11 16:10:07 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-11 16:10:07 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-11 16:10:12 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-11 16:10:12 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-11 16:10:12 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-11 16:10:14 | INFO | root | load pretrained hubert
2023-08-11 16:10:17 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-11 16:10:18 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-11 16:10:21 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-11 16:10:22 | INFO | root | share the sematic adapter and textual encoder
2023-08-11 16:10:22 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-11 16:10:22 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-11 16:10:22 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-11 16:10:22 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-11 16:10:22 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-08-11 16:10:22 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-11 16:10:22 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-11 16:10:22 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-11 16:10:22 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-11 16:10:22 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-11 16:10:26 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-11 16:10:26 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-11 16:10:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-11 16:10:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-11 16:10:27 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-11 16:10:27 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-11 16:10:27 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-11 16:10:27 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-11 16:10:27 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-11 16:10:27 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-11 16:10:27 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-11 16:10:27 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-11 16:10:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-11 16:10:27 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-11 16:10:27 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-11 16:10:27 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-11 16:10:27 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-11 16:10:27 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-11 16:10:27 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-11 16:10:27 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-11 16:10:27 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-11 16:10:29 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-11 16:10:30 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-11 16:11:19 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-11 16:11:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 16:11:19 | INFO | fairseq.trainer | begin training epoch 1
2023-08-11 16:11:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 16:11:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-11 16:11:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-11 16:11:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-11 16:11:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-11 16:11:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-11 16:12:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-11 16:12:38 | INFO | train_inner | epoch 001:    106 / 1474 loss=20.517, trans_loss=5.877, nll_loss=4.686, w2v_ctc_loss=22.82, task_loss=0, contrastive_loss=3.281, total=4230.68, n_correct=124.36, ppl=25.74, accuracy=2.939, wps=19095.8, ups=1.52, wpb=12620.1, bsz=480, num_updates=100, lr=4.098e-06, gnorm=2.934, clip=0, loss_scale=2, train_wall=71, gb_free=18.7, wall=132
2023-08-11 16:13:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-08-11 16:13:42 | INFO | train_inner | epoch 001:    207 / 1474 loss=17.119, trans_loss=5.845, nll_loss=4.672, w2v_ctc_loss=17.71, task_loss=0, contrastive_loss=3.223, total=4095.82, n_correct=114.95, ppl=25.49, accuracy=2.807, wps=19183.5, ups=1.57, wpb=12231.5, bsz=453.2, num_updates=200, lr=8.096e-06, gnorm=7.477, clip=25, loss_scale=1, train_wall=63, gb_free=19.2, wall=195
2023-08-11 16:14:44 | INFO | train_inner | epoch 001:    307 / 1474 loss=10.185, trans_loss=5.828, nll_loss=4.689, w2v_ctc_loss=7.101, task_loss=0, contrastive_loss=3.184, total=4094.41, n_correct=112.3, ppl=25.79, accuracy=2.743, wps=19688.7, ups=1.61, wpb=12229.7, bsz=443.4, num_updates=300, lr=1.2094e-05, gnorm=2.475, clip=0, loss_scale=1, train_wall=62, gb_free=18.6, wall=257
2023-08-11 16:15:47 | INFO | train_inner | epoch 001:    407 / 1474 loss=9.642, trans_loss=5.788, nll_loss=4.673, w2v_ctc_loss=6.272, task_loss=0, contrastive_loss=3.204, total=4177.57, n_correct=101.7, ppl=25.5, accuracy=2.434, wps=19994.4, ups=1.6, wpb=12474.5, bsz=461.4, num_updates=400, lr=1.6092e-05, gnorm=1.325, clip=0, loss_scale=1, train_wall=62, gb_free=18.7, wall=320
2023-08-11 16:16:49 | INFO | train_inner | epoch 001:    507 / 1474 loss=9.464, trans_loss=5.756, nll_loss=4.652, w2v_ctc_loss=5.969, task_loss=0, contrastive_loss=3.303, total=4176.79, n_correct=94.56, ppl=25.14, accuracy=2.264, wps=19999.9, ups=1.6, wpb=12481.2, bsz=487, num_updates=500, lr=2.009e-05, gnorm=1.491, clip=1, loss_scale=1, train_wall=62, gb_free=19.2, wall=382
2023-08-11 16:17:53 | INFO | train_inner | epoch 001:    607 / 1474 loss=9.357, trans_loss=5.802, nll_loss=4.71, w2v_ctc_loss=5.81, task_loss=0, contrastive_loss=3.253, total=4146.02, n_correct=87.39, ppl=26.17, accuracy=2.108, wps=19433.5, ups=1.57, wpb=12362.3, bsz=474.7, num_updates=600, lr=2.4088e-05, gnorm=1.614, clip=1, loss_scale=1, train_wall=63, gb_free=19.2, wall=446
2023-08-11 16:18:55 | INFO | train_inner | epoch 001:    707 / 1474 loss=9.266, trans_loss=5.798, nll_loss=4.706, w2v_ctc_loss=5.76, task_loss=0, contrastive_loss=3.13, total=4136.69, n_correct=83.41, ppl=26.09, accuracy=2.016, wps=19965.4, ups=1.62, wpb=12353.2, bsz=453, num_updates=700, lr=2.8086e-05, gnorm=1.555, clip=0, loss_scale=1, train_wall=61, gb_free=19.4, wall=508
2023-08-11 16:19:57 | INFO | train_inner | epoch 001:    807 / 1474 loss=9.152, trans_loss=5.827, nll_loss=4.737, w2v_ctc_loss=5.594, task_loss=0, contrastive_loss=3.15, total=4132.5, n_correct=82.94, ppl=26.67, accuracy=2.007, wps=19900.4, ups=1.61, wpb=12330.1, bsz=464, num_updates=800, lr=3.2084e-05, gnorm=1.521, clip=0, loss_scale=1, train_wall=61, gb_free=18.9, wall=570
2023-08-11 16:20:58 | INFO | train_inner | epoch 001:    907 / 1474 loss=9.084, trans_loss=5.964, nll_loss=4.909, w2v_ctc_loss=5.416, task_loss=0, contrastive_loss=3.059, total=4165.04, n_correct=64.7, ppl=30.05, accuracy=1.553, wps=20114.8, ups=1.62, wpb=12438.6, bsz=458.3, num_updates=900, lr=3.6082e-05, gnorm=1.783, clip=0, loss_scale=1, train_wall=61, gb_free=18.8, wall=632
2023-08-11 16:22:01 | INFO | train_inner | epoch 001:   1007 / 1474 loss=8.936, trans_loss=6.007, nll_loss=4.962, w2v_ctc_loss=5.166, task_loss=0, contrastive_loss=3.06, total=4135.88, n_correct=65.68, ppl=31.17, accuracy=1.588, wps=19616.8, ups=1.59, wpb=12354.5, bsz=457.9, num_updates=1000, lr=4.008e-05, gnorm=1.962, clip=0, loss_scale=1, train_wall=62, gb_free=19.3, wall=695
2023-08-11 16:23:04 | INFO | train_inner | epoch 001:   1107 / 1474 loss=8.73, trans_loss=6.039, nll_loss=4.992, w2v_ctc_loss=4.935, task_loss=0, contrastive_loss=2.974, total=4152.66, n_correct=65.21, ppl=31.82, accuracy=1.57, wps=19788.7, ups=1.6, wpb=12385.6, bsz=454, num_updates=1100, lr=4.4078e-05, gnorm=2.166, clip=0, loss_scale=1, train_wall=62, gb_free=18.6, wall=757
2023-08-11 16:24:06 | INFO | train_inner | epoch 001:   1207 / 1474 loss=8.586, trans_loss=6.127, nll_loss=5.103, w2v_ctc_loss=4.75, task_loss=0, contrastive_loss=2.859, total=4122.37, n_correct=57.59, ppl=34.36, accuracy=1.397, wps=19868.5, ups=1.61, wpb=12314, bsz=436.2, num_updates=1200, lr=4.8076e-05, gnorm=2.19, clip=0, loss_scale=1, train_wall=61, gb_free=18.7, wall=819
2023-08-11 16:25:08 | INFO | train_inner | epoch 001:   1307 / 1474 loss=8.446, trans_loss=6.146, nll_loss=5.127, w2v_ctc_loss=4.553, task_loss=0, contrastive_loss=2.815, total=4071.58, n_correct=59.71, ppl=34.96, accuracy=1.467, wps=19721.7, ups=1.62, wpb=12154.5, bsz=447.9, num_updates=1300, lr=5.2074e-05, gnorm=2.389, clip=0, loss_scale=1, train_wall=61, gb_free=18.7, wall=881
2023-08-11 16:26:10 | INFO | train_inner | epoch 001:   1407 / 1474 loss=8.259, trans_loss=6.118, nll_loss=5.097, w2v_ctc_loss=4.378, task_loss=0, contrastive_loss=2.874, total=4117.88, n_correct=60.63, ppl=34.22, accuracy=1.472, wps=19830, ups=1.61, wpb=12305.9, bsz=449.1, num_updates=1400, lr=5.6072e-05, gnorm=2.462, clip=0, loss_scale=1, train_wall=61, gb_free=18.8, wall=943
2023-08-11 16:26:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 16:27:30 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 12.843 | trans_loss 13.732 | nll_loss 13.543 | w2v_ctc_loss 5.764 | task_loss 0 | contrastive_loss 4.074 | total 4003.4 | n_correct 47.4 | ppl 11939.6 | accuracy 1.184 | uer 70.846 | wer 68.771 | raw_wer 68.771 | bleu 0 | wps 1214.2 | wpb 4003.4 | bsz 141.8 | num_updates 1467
2023-08-11 16:27:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1467 updates
2023-08-11 16:27:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 16:27:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 16:27:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 1 @ 1467 updates, score 0.0) (writing took 6.714255025610328 seconds)
2023-08-11 16:27:37 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-11 16:27:37 | INFO | train | epoch 001 | loss 10.388 | trans_loss 5.932 | nll_loss 4.848 | w2v_ctc_loss 7.453 | task_loss 0 | contrastive_loss 3.089 | total 4139.43 | n_correct 82.9796 | ppl 28.8 | accuracy 2.005 | wps 18792.8 | ups 1.52 | wpb 12358.1 | bsz 458.9 | num_updates 1467 | lr 5.87507e-05 | gnorm 2.401 | clip 1.8 | loss_scale 1 | train_wall 917 | gb_free 18.9 | wall 1030
2023-08-11 16:27:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 16:27:37 | INFO | fairseq.trainer | begin training epoch 2
2023-08-11 16:27:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 16:28:06 | INFO | train_inner | epoch 002:     33 / 1474 loss=8.154, trans_loss=6.121, nll_loss=5.098, w2v_ctc_loss=4.222, task_loss=0, contrastive_loss=2.847, total=4166.55, n_correct=63.77, ppl=34.25, accuracy=1.531, wps=10700, ups=0.86, wpb=12424.8, bsz=469.9, num_updates=1500, lr=6.007e-05, gnorm=2.768, clip=0, loss_scale=1, train_wall=62, gb_free=18.9, wall=1059
2023-08-11 16:29:08 | INFO | train_inner | epoch 002:    133 / 1474 loss=8.017, trans_loss=6.13, nll_loss=5.112, w2v_ctc_loss=4.121, task_loss=0, contrastive_loss=2.71, total=4154.58, n_correct=59.35, ppl=34.59, accuracy=1.429, wps=19982.5, ups=1.61, wpb=12394, bsz=455, num_updates=1600, lr=6.4068e-05, gnorm=2.554, clip=0, loss_scale=1, train_wall=61, gb_free=18.7, wall=1121
2023-08-11 16:30:10 | INFO | train_inner | epoch 002:    233 / 1474 loss=7.945, trans_loss=6.123, nll_loss=5.108, w2v_ctc_loss=3.968, task_loss=0, contrastive_loss=2.775, total=4202.18, n_correct=63.13, ppl=34.49, accuracy=1.502, wps=20249.3, ups=1.61, wpb=12548.4, bsz=492.4, num_updates=1700, lr=6.8066e-05, gnorm=2.935, clip=0, loss_scale=1, train_wall=61, gb_free=18.8, wall=1183
2023-08-11 16:31:12 | INFO | train_inner | epoch 002:    333 / 1474 loss=7.723, trans_loss=6.09, nll_loss=5.066, w2v_ctc_loss=3.905, task_loss=0, contrastive_loss=2.544, total=4125.8, n_correct=65.62, ppl=33.5, accuracy=1.59, wps=19864.5, ups=1.61, wpb=12318.7, bsz=447, num_updates=1800, lr=7.2064e-05, gnorm=2.765, clip=0, loss_scale=1, train_wall=61, gb_free=19.6, wall=1245
2023-08-11 16:32:14 | INFO | train_inner | epoch 002:    433 / 1474 loss=7.562, trans_loss=6.091, nll_loss=5.07, w2v_ctc_loss=3.84, task_loss=0, contrastive_loss=2.347, total=4029.94, n_correct=61.67, ppl=33.58, accuracy=1.53, wps=19425.6, ups=1.61, wpb=12045.2, bsz=410.6, num_updates=1900, lr=7.6062e-05, gnorm=2.681, clip=0, loss_scale=1, train_wall=61, gb_free=18.9, wall=1307
2023-08-11 16:33:17 | INFO | train_inner | epoch 002:    533 / 1474 loss=7.518, trans_loss=6.076, nll_loss=5.049, w2v_ctc_loss=3.7, task_loss=0, contrastive_loss=2.505, total=4192.5, n_correct=71.52, ppl=33.11, accuracy=1.706, wps=19886.6, ups=1.59, wpb=12507.1, bsz=470.4, num_updates=2000, lr=8.006e-05, gnorm=2.573, clip=0, loss_scale=1, train_wall=62, gb_free=19.1, wall=1370
2023-08-11 16:33:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 16:33:55 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 12.058 | trans_loss 13.318 | nll_loss 13.027 | w2v_ctc_loss 4.858 | task_loss 0 | contrastive_loss 3.508 | total 4003.4 | n_correct 58 | ppl 8347.22 | accuracy 1.449 | uer 62.886 | wer 60.993 | raw_wer 60.993 | bleu 0 | wps 1217.9 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0
2023-08-11 16:33:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-11 16:33:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-08-11 16:33:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-08-11 16:34:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 50.11835369095206 seconds)
2023-08-11 16:35:47 | INFO | train_inner | epoch 002:    633 / 1474 loss=7.363, trans_loss=6.071, nll_loss=5.041, w2v_ctc_loss=3.601, task_loss=0, contrastive_loss=2.319, total=4121.32, n_correct=68.72, ppl=32.93, accuracy=1.667, wps=8192.5, ups=0.67, wpb=12299.3, bsz=449.2, num_updates=2100, lr=8.4058e-05, gnorm=2.553, clip=0, loss_scale=1, train_wall=61, gb_free=19.5, wall=1520
2023-08-11 16:36:48 | INFO | train_inner | epoch 002:    733 / 1474 loss=7.294, trans_loss=6.051, nll_loss=5.016, w2v_ctc_loss=3.535, task_loss=0, contrastive_loss=2.422, total=4155.52, n_correct=74.55, ppl=32.36, accuracy=1.794, wps=20173.6, ups=1.63, wpb=12404.1, bsz=466, num_updates=2200, lr=8.8056e-05, gnorm=2.464, clip=0, loss_scale=1, train_wall=61, gb_free=17.7, wall=1581
2023-08-11 16:37:50 | INFO | train_inner | epoch 002:    833 / 1474 loss=7.171, trans_loss=6.036, nll_loss=4.999, w2v_ctc_loss=3.472, task_loss=0, contrastive_loss=2.303, total=4157.05, n_correct=77.37, ppl=31.98, accuracy=1.861, wps=20150.1, ups=1.62, wpb=12420.1, bsz=457.6, num_updates=2300, lr=9.2054e-05, gnorm=2.436, clip=0, loss_scale=2, train_wall=61, gb_free=19.1, wall=1643
2023-08-11 16:38:53 | INFO | train_inner | epoch 002:    933 / 1474 loss=7.02, trans_loss=6.015, nll_loss=4.97, w2v_ctc_loss=3.375, task_loss=0, contrastive_loss=2.255, total=4105.43, n_correct=76.33, ppl=31.33, accuracy=1.859, wps=19474.3, ups=1.59, wpb=12253.9, bsz=443.6, num_updates=2400, lr=9.6052e-05, gnorm=2.39, clip=0, loss_scale=2, train_wall=62, gb_free=18.8, wall=1706
2023-08-11 16:39:55 | INFO | train_inner | epoch 002:   1033 / 1474 loss=6.932, trans_loss=6.013, nll_loss=4.966, w2v_ctc_loss=3.314, task_loss=0, contrastive_loss=2.144, total=4097.3, n_correct=75.4, ppl=31.25, accuracy=1.84, wps=19796.5, ups=1.62, wpb=12232.3, bsz=452.7, num_updates=2500, lr=0.00010005, gnorm=2.239, clip=0, loss_scale=2, train_wall=61, gb_free=18.7, wall=1768
2023-08-11 16:40:57 | INFO | train_inner | epoch 002:   1133 / 1474 loss=6.909, trans_loss=5.997, nll_loss=4.946, w2v_ctc_loss=3.218, task_loss=0, contrastive_loss=2.365, total=4213.49, n_correct=80.58, ppl=30.83, accuracy=1.912, wps=20185.9, ups=1.6, wpb=12579.3, bsz=498.9, num_updates=2600, lr=0.000104048, gnorm=2.206, clip=0, loss_scale=2, train_wall=62, gb_free=18.9, wall=1830
2023-08-11 16:41:59 | INFO | train_inner | epoch 002:   1233 / 1474 loss=6.798, trans_loss=5.989, nll_loss=4.935, w2v_ctc_loss=3.181, task_loss=0, contrastive_loss=2.172, total=4212.12, n_correct=81.45, ppl=30.58, accuracy=1.934, wps=20285, ups=1.61, wpb=12569.9, bsz=486.3, num_updates=2700, lr=0.000108046, gnorm=2.142, clip=0, loss_scale=2, train_wall=61, gb_free=19.1, wall=1892
2023-08-11 16:43:01 | INFO | train_inner | epoch 002:   1333 / 1474 loss=6.666, trans_loss=5.979, nll_loss=4.926, w2v_ctc_loss=3.137, task_loss=0, contrastive_loss=1.948, total=4139.37, n_correct=82.02, ppl=30.4, accuracy=1.981, wps=20002.6, ups=1.62, wpb=12372.6, bsz=455.1, num_updates=2800, lr=0.000112044, gnorm=2.117, clip=0, loss_scale=2, train_wall=61, gb_free=19.6, wall=1954
2023-08-11 16:44:03 | INFO | train_inner | epoch 002:   1433 / 1474 loss=6.57, trans_loss=5.979, nll_loss=4.924, w2v_ctc_loss=3.084, task_loss=0, contrastive_loss=1.999, total=4066.75, n_correct=77.82, ppl=30.35, accuracy=1.914, wps=19618.6, ups=1.62, wpb=12139.7, bsz=445.6, num_updates=2900, lr=0.000116042, gnorm=1.966, clip=0, loss_scale=2, train_wall=61, gb_free=19.2, wall=2016
2023-08-11 16:44:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 16:45:06 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 11.254 | trans_loss 13.054 | nll_loss 12.653 | w2v_ctc_loss 3.947 | task_loss 0 | contrastive_loss 2.664 | total 4003.4 | n_correct 84.9 | ppl 6442.52 | accuracy 2.121 | uer 53.572 | wer 52.806 | raw_wer 52.806 | bleu 0 | wps 1212.2 | wpb 4003.4 | bsz 141.8 | num_updates 2941 | best_bleu 0
2023-08-11 16:45:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2941 updates
2023-08-11 16:45:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 16:45:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 16:45:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 2 @ 2941 updates, score 0.0) (writing took 25.73609881848097 seconds)
2023-08-11 16:45:32 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-11 16:45:32 | INFO | train | epoch 002 | loss 7.249 | trans_loss 6.046 | nll_loss 5.009 | w2v_ctc_loss 3.534 | task_loss 0 | contrastive_loss 2.344 | total 4138.65 | n_correct 72.5516 | ppl 32.19 | accuracy 1.753 | wps 16946.4 | ups 1.37 | wpb 12355.8 | bsz 458.5 | num_updates 2941 | lr 0.000117681 | gnorm 2.419 | clip 0 | loss_scale 2 | train_wall 905 | gb_free 19 | wall 2105
2023-08-11 16:45:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 16:45:32 | INFO | fairseq.trainer | begin training epoch 3
2023-08-11 16:45:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 16:46:16 | INFO | train_inner | epoch 003:     59 / 1474 loss=6.464, trans_loss=5.968, nll_loss=4.908, w2v_ctc_loss=3.028, task_loss=0, contrastive_loss=1.853, total=4050.57, n_correct=79.13, ppl=30.03, accuracy=1.954, wps=9083.1, ups=0.75, wpb=12091.9, bsz=434.7, num_updates=3000, lr=0.00012004, gnorm=1.868, clip=0, loss_scale=2, train_wall=61, gb_free=19.3, wall=2149
2023-08-11 16:47:35 | INFO | train_inner | epoch 003:    159 / 1474 loss=5.768, trans_loss=5.261, nll_loss=4.009, w2v_ctc_loss=2.769, task_loss=0, contrastive_loss=1.806, total=4157.08, n_correct=321.29, ppl=16.1, accuracy=7.729, wps=15664.9, ups=1.26, wpb=12413.1, bsz=461.9, num_updates=3100, lr=0.000124038, gnorm=3.966, clip=4, loss_scale=2, train_wall=79, gb_free=16.4, wall=2228
2023-08-11 16:48:56 | INFO | train_inner | epoch 003:    259 / 1474 loss=4.777, trans_loss=4.454, nll_loss=2.939, w2v_ctc_loss=2.463, task_loss=0, contrastive_loss=1.592, total=4155.72, n_correct=959.81, ppl=7.67, accuracy=23.096, wps=15351.6, ups=1.24, wpb=12415.9, bsz=465.5, num_updates=3200, lr=0.000128036, gnorm=2.34, clip=0, loss_scale=2, train_wall=80, gb_free=17.5, wall=2309
2023-08-11 16:50:16 | INFO | train_inner | epoch 003:    359 / 1474 loss=4.435, trans_loss=4.254, nll_loss=2.678, w2v_ctc_loss=2.33, task_loss=0, contrastive_loss=1.5, total=4154.07, n_correct=1213, ppl=6.4, accuracy=29.2, wps=15461.8, ups=1.25, wpb=12396.6, bsz=464.9, num_updates=3300, lr=0.000132034, gnorm=2.197, clip=0, loss_scale=2, train_wall=80, gb_free=15.7, wall=2389
2023-08-11 16:51:37 | INFO | train_inner | epoch 003:    459 / 1474 loss=4.19, trans_loss=4.184, nll_loss=2.589, w2v_ctc_loss=2.211, task_loss=0, contrastive_loss=1.298, total=4212.17, n_correct=1337.47, ppl=6.02, accuracy=31.753, wps=15616.3, ups=1.24, wpb=12572.6, bsz=473.8, num_updates=3400, lr=0.000136032, gnorm=1.899, clip=0, loss_scale=2, train_wall=80, gb_free=15.8, wall=2470
2023-08-11 16:52:56 | INFO | train_inner | epoch 003:    559 / 1474 loss=3.99, trans_loss=4.15, nll_loss=2.549, w2v_ctc_loss=2.116, task_loss=0, contrastive_loss=1.166, total=4081.04, n_correct=1338.48, ppl=5.85, accuracy=32.798, wps=15280.6, ups=1.25, wpb=12190.8, bsz=440.1, num_updates=3500, lr=0.00014003, gnorm=1.814, clip=0, loss_scale=2, train_wall=79, gb_free=16.4, wall=2550
2023-08-11 16:54:18 | INFO | train_inner | epoch 003:    659 / 1474 loss=3.893, trans_loss=4.12, nll_loss=2.505, w2v_ctc_loss=2.029, task_loss=0, contrastive_loss=1.214, total=4231.09, n_correct=1449.21, ppl=5.68, accuracy=34.251, wps=15542.8, ups=1.23, wpb=12615.6, bsz=484.4, num_updates=3600, lr=0.000144028, gnorm=1.691, clip=0, loss_scale=2, train_wall=80, gb_free=15.9, wall=2631
2023-08-11 16:55:38 | INFO | train_inner | epoch 003:    759 / 1474 loss=3.723, trans_loss=4.08, nll_loss=2.459, w2v_ctc_loss=1.986, task_loss=0, contrastive_loss=0.92, total=4160.74, n_correct=1478.35, ppl=5.5, accuracy=35.531, wps=15500.5, ups=1.25, wpb=12428.5, bsz=469.2, num_updates=3700, lr=0.000148026, gnorm=1.568, clip=0, loss_scale=2, train_wall=80, gb_free=16.7, wall=2711
2023-08-11 16:56:58 | INFO | train_inner | epoch 003:    859 / 1474 loss=3.609, trans_loss=4.058, nll_loss=2.428, w2v_ctc_loss=1.94, task_loss=0, contrastive_loss=0.836, total=4160.47, n_correct=1520.87, ppl=5.38, accuracy=36.555, wps=15568.4, ups=1.25, wpb=12423.6, bsz=455.4, num_updates=3800, lr=0.000152024, gnorm=1.556, clip=0, loss_scale=2, train_wall=79, gb_free=16.3, wall=2791
2023-08-11 16:58:18 | INFO | train_inner | epoch 003:    959 / 1474 loss=3.531, trans_loss=4.026, nll_loss=2.385, w2v_ctc_loss=1.91, task_loss=0, contrastive_loss=0.819, total=4162.26, n_correct=1587.64, ppl=5.22, accuracy=38.144, wps=15489.6, ups=1.25, wpb=12416.1, bsz=467.9, num_updates=3900, lr=0.000156022, gnorm=1.601, clip=0, loss_scale=2, train_wall=79, gb_free=17.7, wall=2871
2023-08-11 16:59:38 | INFO | train_inner | epoch 003:   1059 / 1474 loss=3.444, trans_loss=3.996, nll_loss=2.348, w2v_ctc_loss=1.896, task_loss=0, contrastive_loss=0.73, total=4062.67, n_correct=1587.71, ppl=5.09, accuracy=39.08, wps=15167.3, ups=1.25, wpb=12131.7, bsz=443.2, num_updates=4000, lr=0.00016002, gnorm=1.555, clip=0, loss_scale=2, train_wall=79, gb_free=15.6, wall=2951
2023-08-11 16:59:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 17:00:11 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.783 | trans_loss 6.798 | nll_loss 4.518 | w2v_ctc_loss 2.327 | task_loss 0 | contrastive_loss 1.002 | total 4003.4 | n_correct 1721.4 | ppl 22.9 | accuracy 42.998 | uer 31.93 | wer 32.303 | raw_wer 32.303 | bleu 4.53 | wps 1413.5 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 4.53
2023-08-11 17:00:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-11 17:00:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-08-11 17:00:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-08-11 17:01:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 4.53) (writing took 51.651178574189544 seconds)
2023-08-11 17:02:22 | INFO | train_inner | epoch 003:   1159 / 1474 loss=3.355, trans_loss=3.976, nll_loss=2.32, w2v_ctc_loss=1.856, task_loss=0, contrastive_loss=0.67, total=4046.76, n_correct=1624.7, ppl=4.99, accuracy=40.148, wps=7342.3, ups=0.61, wpb=12078.6, bsz=433.9, num_updates=4100, lr=0.000164018, gnorm=1.492, clip=0, loss_scale=2, train_wall=79, gb_free=16.2, wall=3115
2023-08-11 17:03:42 | INFO | train_inner | epoch 003:   1259 / 1474 loss=3.27, trans_loss=3.939, nll_loss=2.274, w2v_ctc_loss=1.811, task_loss=0, contrastive_loss=0.619, total=4064.26, n_correct=1681.83, ppl=4.84, accuracy=41.381, wps=15319.3, ups=1.26, wpb=12137.6, bsz=434, num_updates=4200, lr=0.000168016, gnorm=1.376, clip=0, loss_scale=2, train_wall=79, gb_free=16.6, wall=3195
2023-08-11 17:05:02 | INFO | train_inner | epoch 003:   1359 / 1474 loss=3.247, trans_loss=3.913, nll_loss=2.239, w2v_ctc_loss=1.778, task_loss=0, contrastive_loss=0.711, total=4137.36, n_correct=1761.31, ppl=4.72, accuracy=42.571, wps=15294, ups=1.24, wpb=12352.2, bsz=461.5, num_updates=4300, lr=0.000172014, gnorm=1.408, clip=0, loss_scale=4, train_wall=80, gb_free=16.2, wall=3275
2023-08-11 17:06:23 | INFO | train_inner | epoch 003:   1459 / 1474 loss=3.181, trans_loss=3.887, nll_loss=2.207, w2v_ctc_loss=1.749, task_loss=0, contrastive_loss=0.666, total=4207.75, n_correct=1835.2, ppl=4.62, accuracy=43.615, wps=15590, ups=1.24, wpb=12567.9, bsz=476.7, num_updates=4400, lr=0.000176012, gnorm=1.289, clip=0, loss_scale=4, train_wall=80, gb_free=17.3, wall=3356
2023-08-11 17:06:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 17:07:05 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.317 | trans_loss 6.349 | nll_loss 3.933 | w2v_ctc_loss 2.082 | task_loss 0 | contrastive_loss 0.795 | total 4003.4 | n_correct 1966.4 | ppl 15.27 | accuracy 49.118 | uer 30.383 | wer 30.525 | raw_wer 30.525 | bleu 9.29 | wps 1540.1 | wpb 4003.4 | bsz 141.8 | num_updates 4415 | best_bleu 9.29
2023-08-11 17:07:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4415 updates
2023-08-11 17:07:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 17:07:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 17:07:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 3 @ 4415 updates, score 9.29) (writing took 28.795075561851263 seconds)
2023-08-11 17:07:34 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-11 17:07:34 | INFO | train | epoch 003 | loss 3.983 | trans_loss 4.234 | nll_loss 2.656 | w2v_ctc_loss 2.096 | task_loss 0 | contrastive_loss 1.073 | total 4138.65 | n_correct 1357.2 | ppl 6.3 | accuracy 32.793 | wps 13774.9 | ups 1.11 | wpb 12355.8 | bsz 458.5 | num_updates 4415 | lr 0.000176612 | gnorm 1.835 | clip 0.3 | loss_scale 4 | train_wall 1161 | gb_free 16.4 | wall 3427
2023-08-11 17:07:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 17:07:34 | INFO | fairseq.trainer | begin training epoch 4
2023-08-11 17:07:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 17:08:49 | INFO | train_inner | epoch 004:     85 / 1474 loss=3.055, trans_loss=3.855, nll_loss=2.163, w2v_ctc_loss=1.703, task_loss=0, contrastive_loss=0.494, total=4095.18, n_correct=1841.06, ppl=4.48, accuracy=44.957, wps=8352.5, ups=0.68, wpb=12222.9, bsz=437.8, num_updates=4500, lr=0.00018001, gnorm=1.245, clip=0, loss_scale=4, train_wall=79, gb_free=12.7, wall=3502
2023-08-11 17:10:09 | INFO | train_inner | epoch 004:    185 / 1474 loss=3.032, trans_loss=3.825, nll_loss=2.125, w2v_ctc_loss=1.689, task_loss=0, contrastive_loss=0.511, total=4178.83, n_correct=1925.3, ppl=4.36, accuracy=46.073, wps=15697.3, ups=1.26, wpb=12476.1, bsz=469.5, num_updates=4600, lr=0.000184008, gnorm=1.237, clip=0, loss_scale=4, train_wall=79, gb_free=14.7, wall=3582
2023-08-11 17:11:29 | INFO | train_inner | epoch 004:    285 / 1474 loss=3.03, trans_loss=3.821, nll_loss=2.121, w2v_ctc_loss=1.682, task_loss=0, contrastive_loss=0.617, total=4142.3, n_correct=1915.96, ppl=4.35, accuracy=46.254, wps=15404.9, ups=1.24, wpb=12373.8, bsz=460.7, num_updates=4700, lr=0.000188006, gnorm=1.271, clip=0, loss_scale=4, train_wall=80, gb_free=13.3, wall=3662
2023-08-11 17:12:50 | INFO | train_inner | epoch 004:    385 / 1474 loss=2.946, trans_loss=3.802, nll_loss=2.093, w2v_ctc_loss=1.654, task_loss=0, contrastive_loss=0.445, total=4124.92, n_correct=1944.59, ppl=4.27, accuracy=47.142, wps=15287.1, ups=1.24, wpb=12307.7, bsz=444.2, num_updates=4800, lr=0.000192004, gnorm=1.167, clip=0, loss_scale=4, train_wall=80, gb_free=12.5, wall=3743
2023-08-11 17:14:10 | INFO | train_inner | epoch 004:    485 / 1474 loss=2.994, trans_loss=3.777, nll_loss=2.064, w2v_ctc_loss=1.617, task_loss=0, contrastive_loss=0.826, total=4216.09, n_correct=2026.28, ppl=4.18, accuracy=48.061, wps=15603.8, ups=1.24, wpb=12585.8, bsz=497.6, num_updates=4900, lr=0.000196002, gnorm=1.182, clip=0, loss_scale=4, train_wall=80, gb_free=16.7, wall=3823
2023-08-11 17:15:30 | INFO | train_inner | epoch 004:    585 / 1474 loss=2.917, trans_loss=3.761, nll_loss=2.043, w2v_ctc_loss=1.63, task_loss=0, contrastive_loss=0.512, total=4231.12, n_correct=2065.88, ppl=4.12, accuracy=48.826, wps=15768.6, ups=1.25, wpb=12629.4, bsz=490.1, num_updates=5000, lr=0.0002, gnorm=1.144, clip=0, loss_scale=4, train_wall=80, gb_free=16.1, wall=3904
mt_weight tensor(0.5000)
asr_weight tensor(0.4998, device='cuda:0')
2023-08-11 17:16:52 | INFO | train_inner | epoch 004:    685 / 1474 loss=2.865, trans_loss=3.756, nll_loss=2.032, w2v_ctc_loss=1.594, task_loss=0, contrastive_loss=0.529, total=4176.95, n_correct=2055.35, ppl=4.09, accuracy=49.207, wps=15337.6, ups=1.23, wpb=12451, bsz=455.2, num_updates=5100, lr=0.00019803, gnorm=0.776, clip=0, loss_scale=4, train_wall=81, gb_free=15, wall=3985
2023-08-11 17:18:12 | INFO | train_inner | epoch 004:    785 / 1474 loss=2.825, trans_loss=3.737, nll_loss=2.014, w2v_ctc_loss=1.61, task_loss=0, contrastive_loss=0.396, total=4016.91, n_correct=2000.49, ppl=4.04, accuracy=49.802, wps=14911.8, ups=1.24, wpb=11995.1, bsz=418.7, num_updates=5200, lr=0.000196116, gnorm=0.78, clip=0, loss_scale=4, train_wall=80, gb_free=16.1, wall=4065
2023-08-11 17:19:32 | INFO | train_inner | epoch 004:    885 / 1474 loss=2.859, trans_loss=3.72, nll_loss=1.991, w2v_ctc_loss=1.598, task_loss=0, contrastive_loss=0.577, total=4183.4, n_correct=2106.08, ppl=3.98, accuracy=50.344, wps=15551.9, ups=1.24, wpb=12493.2, bsz=465.4, num_updates=5300, lr=0.000194257, gnorm=0.746, clip=0, loss_scale=4, train_wall=80, gb_free=15.4, wall=4145
2023-08-11 17:20:53 | INFO | train_inner | epoch 004:    985 / 1474 loss=2.795, trans_loss=3.705, nll_loss=1.972, w2v_ctc_loss=1.576, task_loss=0, contrastive_loss=0.439, total=4128.78, n_correct=2105.77, ppl=3.92, accuracy=51.002, wps=15280.1, ups=1.24, wpb=12332, bsz=456.8, num_updates=5400, lr=0.00019245, gnorm=0.735, clip=0, loss_scale=4, train_wall=80, gb_free=15.9, wall=4226
2023-08-11 17:22:13 | INFO | train_inner | epoch 004:   1085 / 1474 loss=2.776, trans_loss=3.703, nll_loss=1.969, w2v_ctc_loss=1.576, task_loss=0, contrastive_loss=0.404, total=4080.2, n_correct=2091.24, ppl=3.92, accuracy=51.253, wps=15192.3, ups=1.25, wpb=12179.1, bsz=437.7, num_updates=5500, lr=0.000190693, gnorm=0.722, clip=0, loss_scale=4, train_wall=80, gb_free=16.2, wall=4306
2023-08-11 17:23:34 | INFO | train_inner | epoch 004:   1185 / 1474 loss=2.787, trans_loss=3.69, nll_loss=1.954, w2v_ctc_loss=1.561, task_loss=0, contrastive_loss=0.514, total=4163.45, n_correct=2154.17, ppl=3.88, accuracy=51.74, wps=15449.4, ups=1.24, wpb=12436, bsz=485.6, num_updates=5600, lr=0.000188982, gnorm=0.743, clip=0, loss_scale=4, train_wall=80, gb_free=15.2, wall=4387
2023-08-11 17:24:53 | INFO | train_inner | epoch 004:   1285 / 1474 loss=2.755, trans_loss=3.675, nll_loss=1.935, w2v_ctc_loss=1.552, task_loss=0, contrastive_loss=0.469, total=4152.41, n_correct=2171.86, ppl=3.82, accuracy=52.304, wps=15610.5, ups=1.26, wpb=12401.3, bsz=471.4, num_updates=5700, lr=0.000187317, gnorm=0.727, clip=0, loss_scale=4, train_wall=79, gb_free=12.9, wall=4466
2023-08-11 17:26:12 | INFO | train_inner | epoch 004:   1385 / 1474 loss=2.687, trans_loss=3.662, nll_loss=1.918, w2v_ctc_loss=1.532, task_loss=0, contrastive_loss=0.337, total=4103.57, n_correct=2163.7, ppl=3.78, accuracy=52.727, wps=15545.1, ups=1.27, wpb=12255.2, bsz=437.9, num_updates=5800, lr=0.000185695, gnorm=0.68, clip=0, loss_scale=4, train_wall=78, gb_free=16.7, wall=4545
2023-08-11 17:27:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.4998, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.4998, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.4998, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.4998, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.4998, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.4998, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.4998, device='cuda:6')
2023-08-11 17:27:46 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.649 | trans_loss 5.684 | nll_loss 3.078 | w2v_ctc_loss 1.715 | task_loss 0 | contrastive_loss 0.518 | total 4003.4 | n_correct 2340.3 | ppl 8.45 | accuracy 58.458 | uer 25.058 | wer 26.554 | raw_wer 26.554 | bleu 16.17 | wps 2236.5 | wpb 4003.4 | bsz 141.8 | num_updates 5889 | best_bleu 16.17
2023-08-11 17:27:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5889 updates
2023-08-11 17:27:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 17:28:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 17:28:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 4 @ 5889 updates, score 16.17) (writing took 28.686812352389097 seconds)
2023-08-11 17:28:14 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-11 17:28:14 | INFO | train | epoch 004 | loss 2.866 | trans_loss 3.743 | nll_loss 2.02 | w2v_ctc_loss 1.605 | task_loss 0 | contrastive_loss 0.5 | total 4138.65 | n_correct 2049.6 | ppl 4.06 | accuracy 49.523 | wps 14682.3 | ups 1.19 | wpb 12355.8 | bsz 458.5 | num_updates 5889 | lr 0.000184287 | gnorm 0.921 | clip 0 | loss_scale 4 | train_wall 1173 | gb_free 14.8 | wall 4668
2023-08-11 17:28:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 17:28:15 | INFO | fairseq.trainer | begin training epoch 5
2023-08-11 17:28:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 17:28:31 | INFO | train_inner | epoch 005:     11 / 1474 loss=2.667, trans_loss=3.654, nll_loss=1.907, w2v_ctc_loss=1.506, task_loss=0, contrastive_loss=0.353, total=4031.51, n_correct=2137.9, ppl=3.75, accuracy=53.03, wps=8682.3, ups=0.72, wpb=12037.5, bsz=436.7, num_updates=5900, lr=0.000184115, gnorm=0.679, clip=0, loss_scale=4, train_wall=79, gb_free=14.3, wall=4684
2023-08-11 17:29:51 | INFO | train_inner | epoch 005:    111 / 1474 loss=2.608, trans_loss=3.615, nll_loss=1.857, w2v_ctc_loss=1.433, task_loss=0, contrastive_loss=0.373, total=4256.63, n_correct=2321.94, ppl=3.62, accuracy=54.549, wps=15800.7, ups=1.24, wpb=12710, bsz=500.1, num_updates=6000, lr=0.000182574, gnorm=0.65, clip=0, loss_scale=4, train_wall=80, gb_free=16.2, wall=4764
2023-08-11 17:29:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 17:30:15 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.619 | trans_loss 5.66 | nll_loss 3.045 | w2v_ctc_loss 1.687 | task_loss 0 | contrastive_loss 0.501 | total 4003.4 | n_correct 2359.4 | ppl 8.25 | accuracy 58.935 | uer 23.93 | wer 25.379 | raw_wer 25.379 | bleu 15.99 | wps 2168.1 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 16.17
2023-08-11 17:30:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-08-11 17:30:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-08-11 17:30:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-08-11 17:30:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 15.99) (writing took 39.877398354932666 seconds)
2023-08-11 17:32:14 | INFO | train_inner | epoch 005:    211 / 1474 loss=2.638, trans_loss=3.62, nll_loss=1.861, w2v_ctc_loss=1.444, task_loss=0, contrastive_loss=0.555, total=4186.83, n_correct=2281.56, ppl=3.63, accuracy=54.494, wps=8731, ups=0.7, wpb=12492.2, bsz=485.3, num_updates=6100, lr=0.000181071, gnorm=0.65, clip=0, loss_scale=4, train_wall=79, gb_free=16, wall=4907
2023-08-11 17:33:34 | INFO | train_inner | epoch 005:    311 / 1474 loss=2.61, trans_loss=3.608, nll_loss=1.852, w2v_ctc_loss=1.459, task_loss=0, contrastive_loss=0.412, total=4094.07, n_correct=2227.14, ppl=3.61, accuracy=54.399, wps=15400.4, ups=1.26, wpb=12241.2, bsz=446, num_updates=6200, lr=0.000179605, gnorm=0.665, clip=0, loss_scale=4, train_wall=79, gb_free=16.1, wall=4987
2023-08-11 17:34:54 | INFO | train_inner | epoch 005:    411 / 1474 loss=2.604, trans_loss=3.596, nll_loss=1.835, w2v_ctc_loss=1.426, task_loss=0, contrastive_loss=0.49, total=4140.39, n_correct=2280.91, ppl=3.57, accuracy=55.089, wps=15467.2, ups=1.25, wpb=12372.8, bsz=467.9, num_updates=6300, lr=0.000178174, gnorm=0.656, clip=0, loss_scale=4, train_wall=79, gb_free=16, wall=5067
2023-08-11 17:36:14 | INFO | train_inner | epoch 005:    511 / 1474 loss=2.542, trans_loss=3.598, nll_loss=1.836, w2v_ctc_loss=1.427, task_loss=0, contrastive_loss=0.282, total=4026.21, n_correct=2217.27, ppl=3.57, accuracy=55.071, wps=15022.7, ups=1.25, wpb=12028.8, bsz=418.1, num_updates=6400, lr=0.000176777, gnorm=0.626, clip=0, loss_scale=8, train_wall=79, gb_free=16.9, wall=5147
2023-08-11 17:36:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-11 17:37:35 | INFO | train_inner | epoch 005:    612 / 1474 loss=2.547, trans_loss=3.601, nll_loss=1.836, w2v_ctc_loss=1.419, task_loss=0, contrastive_loss=0.322, total=4103.52, n_correct=2267.99, ppl=3.57, accuracy=55.269, wps=15139.1, ups=1.24, wpb=12240.9, bsz=441.1, num_updates=6500, lr=0.000175412, gnorm=0.63, clip=0, loss_scale=4, train_wall=80, gb_free=16.5, wall=5228
2023-08-11 17:38:55 | INFO | train_inner | epoch 005:    712 / 1474 loss=2.577, trans_loss=3.595, nll_loss=1.832, w2v_ctc_loss=1.417, task_loss=0, contrastive_loss=0.438, total=4169.57, n_correct=2314.11, ppl=3.56, accuracy=55.5, wps=15523.1, ups=1.25, wpb=12447.3, bsz=482.2, num_updates=6600, lr=0.000174078, gnorm=0.652, clip=0, loss_scale=4, train_wall=79, gb_free=17, wall=5308
2023-08-11 17:40:15 | INFO | train_inner | epoch 005:    812 / 1474 loss=2.537, trans_loss=3.585, nll_loss=1.817, w2v_ctc_loss=1.408, task_loss=0, contrastive_loss=0.355, total=4123.32, n_correct=2297.74, ppl=3.52, accuracy=55.725, wps=15356.9, ups=1.25, wpb=12307, bsz=448.5, num_updates=6700, lr=0.000172774, gnorm=0.616, clip=0, loss_scale=4, train_wall=80, gb_free=17.6, wall=5388
2023-08-11 17:41:35 | INFO | train_inner | epoch 005:    912 / 1474 loss=2.499, trans_loss=3.574, nll_loss=1.804, w2v_ctc_loss=1.389, task_loss=0, contrastive_loss=0.309, total=4109.54, n_correct=2307.53, ppl=3.49, accuracy=56.151, wps=15263.6, ups=1.24, wpb=12270.4, bsz=449.3, num_updates=6800, lr=0.000171499, gnorm=0.609, clip=0, loss_scale=4, train_wall=80, gb_free=16.3, wall=5468
2023-08-11 17:42:55 | INFO | train_inner | epoch 005:   1012 / 1474 loss=2.519, trans_loss=3.579, nll_loss=1.811, w2v_ctc_loss=1.397, task_loss=0, contrastive_loss=0.382, total=4157.73, n_correct=2334.51, ppl=3.51, accuracy=56.149, wps=15564.2, ups=1.25, wpb=12411.9, bsz=458.8, num_updates=6900, lr=0.000170251, gnorm=0.632, clip=0, loss_scale=4, train_wall=79, gb_free=17.2, wall=5548
2023-08-11 17:44:15 | INFO | train_inner | epoch 005:   1112 / 1474 loss=2.532, trans_loss=3.573, nll_loss=1.802, w2v_ctc_loss=1.403, task_loss=0, contrastive_loss=0.392, total=4172.61, n_correct=2351.07, ppl=3.49, accuracy=56.345, wps=15485, ups=1.24, wpb=12446.4, bsz=466.7, num_updates=7000, lr=0.000169031, gnorm=0.616, clip=0, loss_scale=4, train_wall=80, gb_free=13.7, wall=5629
2023-08-11 17:45:35 | INFO | train_inner | epoch 005:   1212 / 1474 loss=2.476, trans_loss=3.566, nll_loss=1.792, w2v_ctc_loss=1.373, task_loss=0, contrastive_loss=0.289, total=4166.97, n_correct=2358.95, ppl=3.46, accuracy=56.611, wps=15596.4, ups=1.25, wpb=12430.2, bsz=454.5, num_updates=7100, lr=0.000167836, gnorm=0.606, clip=0, loss_scale=4, train_wall=79, gb_free=16.9, wall=5708
2023-08-11 17:46:56 | INFO | train_inner | epoch 005:   1312 / 1474 loss=2.45, trans_loss=3.56, nll_loss=1.786, w2v_ctc_loss=1.359, task_loss=0, contrastive_loss=0.253, total=4132.22, n_correct=2349.86, ppl=3.45, accuracy=56.867, wps=15251.8, ups=1.24, wpb=12332.7, bsz=445.1, num_updates=7200, lr=0.000166667, gnorm=0.59, clip=0, loss_scale=4, train_wall=80, gb_free=16.6, wall=5789
2023-08-11 17:48:16 | INFO | train_inner | epoch 005:   1412 / 1474 loss=2.459, trans_loss=3.558, nll_loss=1.786, w2v_ctc_loss=1.355, task_loss=0, contrastive_loss=0.312, total=4135.72, n_correct=2354.79, ppl=3.45, accuracy=56.938, wps=15530.3, ups=1.26, wpb=12352.5, bsz=457.5, num_updates=7300, lr=0.000165521, gnorm=0.595, clip=0, loss_scale=4, train_wall=79, gb_free=16.3, wall=5869
2023-08-11 17:49:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 17:49:27 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.438 | trans_loss 5.498 | nll_loss 2.849 | w2v_ctc_loss 1.519 | task_loss 0 | contrastive_loss 0.464 | total 4003.4 | n_correct 2448.1 | ppl 7.2 | accuracy 61.151 | uer 22.239 | wer 23.989 | raw_wer 23.989 | bleu 18.23 | wps 2369.6 | wpb 4003.4 | bsz 141.8 | num_updates 7362 | best_bleu 18.23
2023-08-11 17:49:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7362 updates
2023-08-11 17:49:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 17:49:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 17:49:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 5 @ 7362 updates, score 18.23) (writing took 29.3711293078959 seconds)
2023-08-11 17:49:56 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-11 17:49:56 | INFO | train | epoch 005 | loss 2.54 | trans_loss 3.587 | nll_loss 1.821 | w2v_ctc_loss 1.407 | task_loss 0 | contrastive_loss 0.369 | total 4137.68 | n_correct 2304.53 | ppl 3.53 | accuracy 55.696 | wps 13976 | ups 1.13 | wpb 12353 | bsz 457.8 | num_updates 7362 | lr 0.000164823 | gnorm 0.627 | clip 0 | loss_scale 4 | train_wall 1171 | gb_free 16.2 | wall 5970
2023-08-11 17:49:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 17:49:57 | INFO | fairseq.trainer | begin training epoch 6
2023-08-11 17:49:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 17:50:35 | INFO | train_inner | epoch 006:     38 / 1474 loss=2.445, trans_loss=3.543, nll_loss=1.764, w2v_ctc_loss=1.349, task_loss=0, contrastive_loss=0.309, total=4115.39, n_correct=2357.85, ppl=3.4, accuracy=57.293, wps=8830.9, ups=0.72, wpb=12279.5, bsz=446.7, num_updates=7400, lr=0.000164399, gnorm=0.596, clip=0, loss_scale=4, train_wall=79, gb_free=16.9, wall=6008
2023-08-11 17:51:55 | INFO | train_inner | epoch 006:    138 / 1474 loss=2.398, trans_loss=3.514, nll_loss=1.729, w2v_ctc_loss=1.296, task_loss=0, contrastive_loss=0.347, total=4157.06, n_correct=2416.74, ppl=3.32, accuracy=58.136, wps=15511.8, ups=1.25, wpb=12417.1, bsz=457.8, num_updates=7500, lr=0.000163299, gnorm=0.589, clip=0, loss_scale=4, train_wall=79, gb_free=17.6, wall=6088
2023-08-11 17:53:15 | INFO | train_inner | epoch 006:    238 / 1474 loss=2.404, trans_loss=3.525, nll_loss=1.744, w2v_ctc_loss=1.33, task_loss=0, contrastive_loss=0.259, total=4115.6, n_correct=2377.25, ppl=3.35, accuracy=57.762, wps=15352, ups=1.25, wpb=12295.8, bsz=440.7, num_updates=7600, lr=0.000162221, gnorm=0.581, clip=0, loss_scale=4, train_wall=79, gb_free=16.8, wall=6168
2023-08-11 17:54:36 | INFO | train_inner | epoch 006:    338 / 1474 loss=2.438, trans_loss=3.513, nll_loss=1.728, w2v_ctc_loss=1.281, task_loss=0, contrastive_loss=0.559, total=4163.86, n_correct=2426.02, ppl=3.31, accuracy=58.264, wps=15234.2, ups=1.23, wpb=12432.8, bsz=484.8, num_updates=7700, lr=0.000161165, gnorm=0.595, clip=0, loss_scale=4, train_wall=81, gb_free=16.1, wall=6250
2023-08-11 17:55:56 | INFO | train_inner | epoch 006:    438 / 1474 loss=2.366, trans_loss=3.51, nll_loss=1.723, w2v_ctc_loss=1.286, task_loss=0, contrastive_loss=0.266, total=4156.74, n_correct=2435.32, ppl=3.3, accuracy=58.587, wps=15675.8, ups=1.26, wpb=12410.9, bsz=471.8, num_updates=7800, lr=0.000160128, gnorm=0.576, clip=0, loss_scale=4, train_wall=79, gb_free=15.5, wall=6329
2023-08-11 17:57:15 | INFO | train_inner | epoch 006:    538 / 1474 loss=2.367, trans_loss=3.512, nll_loss=1.725, w2v_ctc_loss=1.298, task_loss=0, contrastive_loss=0.252, total=4173.1, n_correct=2445.71, ppl=3.31, accuracy=58.607, wps=15657.6, ups=1.26, wpb=12456.1, bsz=456.3, num_updates=7900, lr=0.000159111, gnorm=0.573, clip=0, loss_scale=4, train_wall=79, gb_free=15.8, wall=6408
2023-08-11 17:58:35 | INFO | train_inner | epoch 006:    638 / 1474 loss=2.368, trans_loss=3.512, nll_loss=1.726, w2v_ctc_loss=1.28, task_loss=0, contrastive_loss=0.302, total=4147.23, n_correct=2427.49, ppl=3.31, accuracy=58.533, wps=15530, ups=1.25, wpb=12379.1, bsz=471.9, num_updates=8000, lr=0.000158114, gnorm=0.573, clip=0, loss_scale=4, train_wall=79, gb_free=12.8, wall=6488
2023-08-11 17:58:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 17:59:00 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.38 | trans_loss 5.432 | nll_loss 2.767 | w2v_ctc_loss 1.54 | task_loss 0 | contrastive_loss 0.404 | total 4003.4 | n_correct 2483.8 | ppl 6.81 | accuracy 62.042 | uer 22.202 | wer 23.955 | raw_wer 23.955 | bleu 18.76 | wps 2027.1 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 18.76
2023-08-11 17:59:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-08-11 17:59:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-08-11 17:59:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-08-11 17:59:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 18.76) (writing took 48.48836720176041 seconds)
2023-08-11 18:01:09 | INFO | train_inner | epoch 006:    738 / 1474 loss=2.362, trans_loss=3.511, nll_loss=1.725, w2v_ctc_loss=1.295, task_loss=0, contrastive_loss=0.257, total=4147.61, n_correct=2431.87, ppl=3.31, accuracy=58.633, wps=8037.2, ups=0.65, wpb=12383.5, bsz=453.2, num_updates=8100, lr=0.000157135, gnorm=0.572, clip=0, loss_scale=4, train_wall=80, gb_free=16.2, wall=6642
2023-08-11 18:02:29 | INFO | train_inner | epoch 006:    838 / 1474 loss=2.351, trans_loss=3.515, nll_loss=1.729, w2v_ctc_loss=1.287, task_loss=0, contrastive_loss=0.238, total=4114.7, n_correct=2406.2, ppl=3.32, accuracy=58.478, wps=15314.5, ups=1.25, wpb=12284.9, bsz=442.6, num_updates=8200, lr=0.000156174, gnorm=0.568, clip=0, loss_scale=4, train_wall=80, gb_free=17.6, wall=6722
2023-08-11 18:03:49 | INFO | train_inner | epoch 006:    938 / 1474 loss=2.379, trans_loss=3.516, nll_loss=1.731, w2v_ctc_loss=1.292, task_loss=0, contrastive_loss=0.335, total=4082.44, n_correct=2386.22, ppl=3.32, accuracy=58.451, wps=15240.5, ups=1.25, wpb=12184.1, bsz=442.4, num_updates=8300, lr=0.00015523, gnorm=0.577, clip=0, loss_scale=4, train_wall=79, gb_free=16.2, wall=6802
2023-08-11 18:05:09 | INFO | train_inner | epoch 006:   1038 / 1474 loss=2.377, trans_loss=3.501, nll_loss=1.712, w2v_ctc_loss=1.269, task_loss=0, contrastive_loss=0.41, total=4168.55, n_correct=2456.89, ppl=3.28, accuracy=58.939, wps=15562, ups=1.25, wpb=12442.3, bsz=478.7, num_updates=8400, lr=0.000154303, gnorm=0.609, clip=0, loss_scale=4, train_wall=79, gb_free=15.6, wall=6882
2023-08-11 18:06:28 | INFO | train_inner | epoch 006:   1138 / 1474 loss=2.34, trans_loss=3.501, nll_loss=1.712, w2v_ctc_loss=1.281, task_loss=0, contrastive_loss=0.239, total=4075.88, n_correct=2398.28, ppl=3.28, accuracy=58.841, wps=15333, ups=1.26, wpb=12168.6, bsz=430.6, num_updates=8500, lr=0.000153393, gnorm=0.569, clip=0, loss_scale=8, train_wall=79, gb_free=14.1, wall=6962
2023-08-11 18:07:49 | INFO | train_inner | epoch 006:   1238 / 1474 loss=2.396, trans_loss=3.492, nll_loss=1.703, w2v_ctc_loss=1.266, task_loss=0, contrastive_loss=0.55, total=4136.41, n_correct=2443.21, ppl=3.26, accuracy=59.066, wps=15409.5, ups=1.25, wpb=12356.2, bsz=470.5, num_updates=8600, lr=0.000152499, gnorm=0.569, clip=0, loss_scale=8, train_wall=80, gb_free=15.3, wall=7042
2023-08-11 18:09:08 | INFO | train_inner | epoch 006:   1338 / 1474 loss=2.312, trans_loss=3.496, nll_loss=1.703, w2v_ctc_loss=1.259, task_loss=0, contrastive_loss=0.22, total=4123.87, n_correct=2451.12, ppl=3.26, accuracy=59.437, wps=15492, ups=1.26, wpb=12299.9, bsz=453.6, num_updates=8700, lr=0.00015162, gnorm=0.563, clip=0, loss_scale=8, train_wall=79, gb_free=16.3, wall=7121
2023-08-11 18:10:28 | INFO | train_inner | epoch 006:   1438 / 1474 loss=2.313, trans_loss=3.489, nll_loss=1.698, w2v_ctc_loss=1.26, task_loss=0, contrastive_loss=0.226, total=4197.44, n_correct=2495.27, ppl=3.24, accuracy=59.447, wps=15627.5, ups=1.25, wpb=12530.9, bsz=462.9, num_updates=8800, lr=0.000150756, gnorm=0.554, clip=0, loss_scale=8, train_wall=79, gb_free=16.4, wall=7201
2023-08-11 18:10:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 18:11:19 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.31 | trans_loss 5.372 | nll_loss 2.695 | w2v_ctc_loss 1.461 | task_loss 0 | contrastive_loss 0.397 | total 4003.4 | n_correct 2519.3 | ppl 6.47 | accuracy 62.929 | uer 20.694 | wer 22.3 | raw_wer 22.3 | bleu 19.36 | wps 2300.7 | wpb 4003.4 | bsz 141.8 | num_updates 8836 | best_bleu 19.36
2023-08-11 18:11:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8836 updates
2023-08-11 18:11:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 18:11:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 18:11:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 6 @ 8836 updates, score 19.36) (writing took 30.159667301923037 seconds)
2023-08-11 18:11:49 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-11 18:11:49 | INFO | train | epoch 006 | loss 2.368 | trans_loss 3.508 | nll_loss 1.721 | w2v_ctc_loss 1.284 | task_loss 0 | contrastive_loss 0.317 | total 4138.65 | n_correct 2427.77 | ppl 3.3 | accuracy 58.661 | wps 13871.6 | ups 1.12 | wpb 12355.8 | bsz 458.5 | num_updates 8836 | lr 0.000150448 | gnorm 0.576 | clip 0 | loss_scale 8 | train_wall 1169 | gb_free 15.1 | wall 7282
2023-08-11 18:11:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 18:11:50 | INFO | fairseq.trainer | begin training epoch 7
2023-08-11 18:11:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 18:12:49 | INFO | train_inner | epoch 007:     64 / 1474 loss=2.283, trans_loss=3.476, nll_loss=1.681, w2v_ctc_loss=1.229, task_loss=0, contrastive_loss=0.238, total=4105.94, n_correct=2459.21, ppl=3.21, accuracy=59.894, wps=8723.6, ups=0.71, wpb=12258, bsz=460.8, num_updates=8900, lr=0.000149906, gnorm=0.56, clip=0, loss_scale=8, train_wall=79, gb_free=14.9, wall=7342
2023-08-11 18:14:08 | INFO | train_inner | epoch 007:    164 / 1474 loss=2.281, trans_loss=3.467, nll_loss=1.668, w2v_ctc_loss=1.214, task_loss=0, contrastive_loss=0.311, total=4101.13, n_correct=2465.18, ppl=3.18, accuracy=60.11, wps=15466.5, ups=1.26, wpb=12245.3, bsz=452.9, num_updates=9000, lr=0.000149071, gnorm=0.559, clip=0, loss_scale=8, train_wall=79, gb_free=16.8, wall=7421
2023-08-11 18:15:27 | INFO | train_inner | epoch 007:    264 / 1474 loss=2.258, trans_loss=3.461, nll_loss=1.66, w2v_ctc_loss=1.216, task_loss=0, contrastive_loss=0.215, total=4143.65, n_correct=2498.54, ppl=3.16, accuracy=60.298, wps=15532.8, ups=1.26, wpb=12365.3, bsz=458, num_updates=9100, lr=0.00014825, gnorm=0.551, clip=0, loss_scale=8, train_wall=79, gb_free=16.2, wall=7501
2023-08-11 18:16:49 | INFO | train_inner | epoch 007:    364 / 1474 loss=2.308, trans_loss=3.466, nll_loss=1.667, w2v_ctc_loss=1.207, task_loss=0, contrastive_loss=0.472, total=4190.59, n_correct=2520.05, ppl=3.17, accuracy=60.136, wps=15381.2, ups=1.23, wpb=12506.9, bsz=477.2, num_updates=9200, lr=0.000147442, gnorm=0.552, clip=0, loss_scale=8, train_wall=81, gb_free=16.7, wall=7582
2023-08-11 18:18:09 | INFO | train_inner | epoch 007:    464 / 1474 loss=2.294, trans_loss=3.466, nll_loss=1.668, w2v_ctc_loss=1.206, task_loss=0, contrastive_loss=0.402, total=4154.13, n_correct=2499.22, ppl=3.18, accuracy=60.162, wps=15543.2, ups=1.25, wpb=12405.4, bsz=461.6, num_updates=9300, lr=0.000146647, gnorm=0.572, clip=0, loss_scale=8, train_wall=79, gb_free=16.3, wall=7662
2023-08-11 18:19:28 | INFO | train_inner | epoch 007:    564 / 1474 loss=2.25, trans_loss=3.462, nll_loss=1.661, w2v_ctc_loss=1.206, task_loss=0, contrastive_loss=0.221, total=4171.52, n_correct=2519.33, ppl=3.16, accuracy=60.394, wps=15705.1, ups=1.26, wpb=12446, bsz=461, num_updates=9400, lr=0.000145865, gnorm=0.545, clip=0, loss_scale=8, train_wall=79, gb_free=16.8, wall=7741
2023-08-11 18:20:48 | INFO | train_inner | epoch 007:    664 / 1474 loss=2.238, trans_loss=3.459, nll_loss=1.657, w2v_ctc_loss=1.198, task_loss=0, contrastive_loss=0.206, total=4151.13, n_correct=2515.15, ppl=3.15, accuracy=60.59, wps=15497.4, ups=1.25, wpb=12385.9, bsz=454, num_updates=9500, lr=0.000145095, gnorm=0.545, clip=0, loss_scale=8, train_wall=79, gb_free=12.7, wall=7821
2023-08-11 18:22:08 | INFO | train_inner | epoch 007:    764 / 1474 loss=2.237, trans_loss=3.453, nll_loss=1.651, w2v_ctc_loss=1.201, task_loss=0, contrastive_loss=0.2, total=4124.23, n_correct=2496.54, ppl=3.14, accuracy=60.533, wps=15336.2, ups=1.25, wpb=12314.5, bsz=446.8, num_updates=9600, lr=0.000144338, gnorm=0.547, clip=0, loss_scale=8, train_wall=80, gb_free=14.2, wall=7901
2023-08-11 18:23:28 | INFO | train_inner | epoch 007:    864 / 1474 loss=2.24, trans_loss=3.461, nll_loss=1.66, w2v_ctc_loss=1.198, task_loss=0, contrastive_loss=0.22, total=4148.43, n_correct=2506.51, ppl=3.16, accuracy=60.421, wps=15482.7, ups=1.25, wpb=12380.2, bsz=461.8, num_updates=9700, lr=0.000143592, gnorm=0.553, clip=0, loss_scale=8, train_wall=79, gb_free=16.4, wall=7981
2023-08-11 18:24:49 | INFO | train_inner | epoch 007:    964 / 1474 loss=2.254, trans_loss=3.453, nll_loss=1.652, w2v_ctc_loss=1.188, task_loss=0, contrastive_loss=0.314, total=4141.1, n_correct=2507.86, ppl=3.14, accuracy=60.56, wps=15356.4, ups=1.24, wpb=12362.4, bsz=473.7, num_updates=9800, lr=0.000142857, gnorm=0.555, clip=0, loss_scale=8, train_wall=80, gb_free=13.8, wall=8062
2023-08-11 18:26:09 | INFO | train_inner | epoch 007:   1064 / 1474 loss=2.228, trans_loss=3.461, nll_loss=1.661, w2v_ctc_loss=1.2, task_loss=0, contrastive_loss=0.185, total=4100.93, n_correct=2481.67, ppl=3.16, accuracy=60.515, wps=15297.5, ups=1.25, wpb=12243.4, bsz=437.6, num_updates=9900, lr=0.000142134, gnorm=0.545, clip=0, loss_scale=8, train_wall=79, gb_free=14.7, wall=8142
2023-08-11 18:27:30 | INFO | train_inner | epoch 007:   1164 / 1474 loss=2.282, trans_loss=3.446, nll_loss=1.645, w2v_ctc_loss=1.189, task_loss=0, contrastive_loss=0.44, total=4139.88, n_correct=2513.55, ppl=3.13, accuracy=60.716, wps=15287.3, ups=1.24, wpb=12369.6, bsz=471.4, num_updates=10000, lr=0.000141421, gnorm=0.552, clip=0, loss_scale=8, train_wall=80, gb_free=16.5, wall=8223
2023-08-11 18:27:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 18:27:54 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.248 | trans_loss 5.324 | nll_loss 2.635 | w2v_ctc_loss 1.389 | task_loss 0 | contrastive_loss 0.377 | total 4003.4 | n_correct 2551.6 | ppl 6.21 | accuracy 63.736 | uer 20.304 | wer 22.057 | raw_wer 22.057 | bleu 19.9 | wps 2094.9 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 19.9
2023-08-11 18:27:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-08-11 18:27:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-08-11 18:27:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-08-11 18:28:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 19.9) (writing took 50.085384948179126 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:0')
2023-08-11 18:30:04 | INFO | train_inner | epoch 007:   1264 / 1474 loss=2.218, trans_loss=3.45, nll_loss=1.648, w2v_ctc_loss=1.184, task_loss=0, contrastive_loss=0.21, total=4129.16, n_correct=2510.14, ppl=3.14, accuracy=60.791, wps=7999.9, ups=0.65, wpb=12331, bsz=448.9, num_updates=10100, lr=0.00014072, gnorm=0.436, clip=0, loss_scale=8, train_wall=79, gb_free=16.7, wall=8377
2023-08-11 18:31:23 | INFO | train_inner | epoch 007:   1364 / 1474 loss=2.237, trans_loss=3.443, nll_loss=1.64, w2v_ctc_loss=1.194, task_loss=0, contrastive_loss=0.245, total=4177.71, n_correct=2548.41, ppl=3.12, accuracy=61, wps=15698.1, ups=1.26, wpb=12473.7, bsz=478.6, num_updates=10200, lr=0.000140028, gnorm=0.436, clip=0, loss_scale=8, train_wall=79, gb_free=16.8, wall=8456
2023-08-11 18:32:45 | INFO | train_inner | epoch 007:   1464 / 1474 loss=2.241, trans_loss=3.447, nll_loss=1.646, w2v_ctc_loss=1.19, task_loss=0, contrastive_loss=0.305, total=4107.01, n_correct=2498.27, ppl=3.13, accuracy=60.829, wps=15018.1, ups=1.22, wpb=12270.2, bsz=442.8, num_updates=10300, lr=0.000139347, gnorm=0.443, clip=0, loss_scale=8, train_wall=81, gb_free=13.3, wall=8538
2023-08-11 18:32:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:3')
2023-08-11 18:33:15 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.238 | trans_loss 5.303 | nll_loss 2.607 | w2v_ctc_loss 1.423 | task_loss 0 | contrastive_loss 0.366 | total 4003.4 | n_correct 2565.6 | ppl 6.09 | accuracy 64.086 | uer 20.436 | wer 22.262 | raw_wer 22.262 | bleu 19.95 | wps 2212.3 | wpb 4003.4 | bsz 141.8 | num_updates 10310 | best_bleu 19.95
2023-08-11 18:33:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10310 updates
2023-08-11 18:33:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 18:33:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 18:33:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 7 @ 10310 updates, score 19.95) (writing took 27.335819670930505 seconds)
2023-08-11 18:33:43 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-11 18:33:43 | INFO | train | epoch 007 | loss 2.255 | trans_loss 3.457 | nll_loss 1.656 | w2v_ctc_loss 1.2 | task_loss 0 | contrastive_loss 0.28 | total 4138.65 | n_correct 2503.4 | ppl 3.15 | accuracy 60.488 | wps 13865 | ups 1.12 | wpb 12355.8 | bsz 458.5 | num_updates 10310 | lr 0.000139279 | gnorm 0.529 | clip 0 | loss_scale 8 | train_wall 1171 | gb_free 13.3 | wall 8596
2023-08-11 18:33:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 18:33:43 | INFO | fairseq.trainer | begin training epoch 8
2023-08-11 18:33:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 18:35:03 | INFO | train_inner | epoch 008:     90 / 1474 loss=2.185, trans_loss=3.437, nll_loss=1.627, w2v_ctc_loss=1.155, task_loss=0, contrastive_loss=0.201, total=4106.01, n_correct=2519.6, ppl=3.09, accuracy=61.364, wps=8874.9, ups=0.72, wpb=12242.2, bsz=440.9, num_updates=10400, lr=0.000138675, gnorm=0.437, clip=0, loss_scale=8, train_wall=79, gb_free=17, wall=8676
2023-08-11 18:36:22 | INFO | train_inner | epoch 008:    190 / 1474 loss=2.181, trans_loss=3.426, nll_loss=1.614, w2v_ctc_loss=1.149, task_loss=0, contrastive_loss=0.22, total=4043.12, n_correct=2493.51, ppl=3.06, accuracy=61.673, wps=15180.9, ups=1.26, wpb=12058.4, bsz=430, num_updates=10500, lr=0.000138013, gnorm=0.447, clip=0, loss_scale=16, train_wall=79, gb_free=13.3, wall=8755
2023-08-11 18:37:42 | INFO | train_inner | epoch 008:    290 / 1474 loss=2.184, trans_loss=3.422, nll_loss=1.61, w2v_ctc_loss=1.151, task_loss=0, contrastive_loss=0.217, total=4207.9, n_correct=2599.39, ppl=3.05, accuracy=61.774, wps=15781.4, ups=1.26, wpb=12558.3, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.441, clip=0, loss_scale=16, train_wall=79, gb_free=14.1, wall=8835
2023-08-11 18:39:03 | INFO | train_inner | epoch 008:    390 / 1474 loss=2.195, trans_loss=3.426, nll_loss=1.615, w2v_ctc_loss=1.162, task_loss=0, contrastive_loss=0.242, total=4134.6, n_correct=2541.19, ppl=3.06, accuracy=61.462, wps=15262.4, ups=1.24, wpb=12337.2, bsz=444.7, num_updates=10700, lr=0.000136717, gnorm=0.44, clip=0, loss_scale=16, train_wall=80, gb_free=17.2, wall=8916
2023-08-11 18:40:24 | INFO | train_inner | epoch 008:    490 / 1474 loss=2.253, trans_loss=3.424, nll_loss=1.615, w2v_ctc_loss=1.143, task_loss=0, contrastive_loss=0.498, total=4196.6, n_correct=2583.31, ppl=3.06, accuracy=61.557, wps=15452.2, ups=1.23, wpb=12528.1, bsz=501.4, num_updates=10800, lr=0.000136083, gnorm=0.443, clip=0, loss_scale=16, train_wall=80, gb_free=13, wall=8997
2023-08-11 18:41:43 | INFO | train_inner | epoch 008:    590 / 1474 loss=2.181, trans_loss=3.422, nll_loss=1.614, w2v_ctc_loss=1.165, task_loss=0, contrastive_loss=0.175, total=4065.55, n_correct=2499.55, ppl=3.06, accuracy=61.481, wps=15264.6, ups=1.26, wpb=12153.4, bsz=428.3, num_updates=10900, lr=0.000135457, gnorm=0.437, clip=0, loss_scale=16, train_wall=79, gb_free=16.1, wall=9077
2023-08-11 18:43:03 | INFO | train_inner | epoch 008:    690 / 1474 loss=2.171, trans_loss=3.417, nll_loss=1.605, w2v_ctc_loss=1.155, task_loss=0, contrastive_loss=0.186, total=4135.41, n_correct=2559.43, ppl=3.04, accuracy=61.891, wps=15524, ups=1.26, wpb=12343.8, bsz=447.2, num_updates=11000, lr=0.00013484, gnorm=0.434, clip=0, loss_scale=16, train_wall=79, gb_free=16, wall=9156
2023-08-11 18:44:23 | INFO | train_inner | epoch 008:    790 / 1474 loss=2.184, trans_loss=3.413, nll_loss=1.603, w2v_ctc_loss=1.147, task_loss=0, contrastive_loss=0.272, total=4128.86, n_correct=2557.64, ppl=3.04, accuracy=61.945, wps=15430.9, ups=1.25, wpb=12339, bsz=452.1, num_updates=11100, lr=0.000134231, gnorm=0.437, clip=0, loss_scale=16, train_wall=79, gb_free=16.2, wall=9236
2023-08-11 18:45:43 | INFO | train_inner | epoch 008:    890 / 1474 loss=2.184, trans_loss=3.417, nll_loss=1.607, w2v_ctc_loss=1.138, task_loss=0, contrastive_loss=0.281, total=4166.92, n_correct=2578.21, ppl=3.05, accuracy=61.873, wps=15504.3, ups=1.25, wpb=12446.8, bsz=471.5, num_updates=11200, lr=0.000133631, gnorm=0.444, clip=0, loss_scale=16, train_wall=80, gb_free=14.5, wall=9316
2023-08-11 18:47:03 | INFO | train_inner | epoch 008:    990 / 1474 loss=2.155, trans_loss=3.416, nll_loss=1.604, w2v_ctc_loss=1.14, task_loss=0, contrastive_loss=0.179, total=4150.39, n_correct=2577.45, ppl=3.04, accuracy=62.101, wps=15590.4, ups=1.26, wpb=12390.2, bsz=462.8, num_updates=11300, lr=0.000133038, gnorm=0.431, clip=0, loss_scale=16, train_wall=79, gb_free=17.2, wall=9396
2023-08-11 18:48:23 | INFO | train_inner | epoch 008:   1090 / 1474 loss=2.201, trans_loss=3.418, nll_loss=1.607, w2v_ctc_loss=1.136, task_loss=0, contrastive_loss=0.401, total=4197.39, n_correct=2593.59, ppl=3.05, accuracy=61.791, wps=15539.8, ups=1.24, wpb=12529.5, bsz=466.4, num_updates=11400, lr=0.000132453, gnorm=0.434, clip=0, loss_scale=16, train_wall=80, gb_free=16.7, wall=9476
2023-08-11 18:49:43 | INFO | train_inner | epoch 008:   1190 / 1474 loss=2.159, trans_loss=3.41, nll_loss=1.598, w2v_ctc_loss=1.139, task_loss=0, contrastive_loss=0.188, total=4180.55, n_correct=2595.95, ppl=3.03, accuracy=62.096, wps=15649.9, ups=1.25, wpb=12487.2, bsz=472.7, num_updates=11500, lr=0.000131876, gnorm=0.429, clip=0, loss_scale=16, train_wall=79, gb_free=17.2, wall=9556
2023-08-11 18:51:02 | INFO | train_inner | epoch 008:   1290 / 1474 loss=2.168, trans_loss=3.416, nll_loss=1.605, w2v_ctc_loss=1.149, task_loss=0, contrastive_loss=0.211, total=4062.6, n_correct=2512.57, ppl=3.04, accuracy=61.846, wps=15284.4, ups=1.26, wpb=12135.3, bsz=437.8, num_updates=11600, lr=0.000131306, gnorm=0.441, clip=0, loss_scale=16, train_wall=79, gb_free=13.1, wall=9636
2023-08-11 18:52:22 | INFO | train_inner | epoch 008:   1390 / 1474 loss=2.18, trans_loss=3.416, nll_loss=1.605, w2v_ctc_loss=1.136, task_loss=0, contrastive_loss=0.276, total=4159.11, n_correct=2583.24, ppl=3.04, accuracy=62.11, wps=15619.3, ups=1.26, wpb=12419, bsz=468.7, num_updates=11700, lr=0.000130744, gnorm=0.429, clip=0, loss_scale=16, train_wall=79, gb_free=13.3, wall=9715
2023-08-11 18:53:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 18:53:52 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.188 | trans_loss 5.254 | nll_loss 2.542 | w2v_ctc_loss 1.385 | task_loss 0 | contrastive_loss 0.35 | total 4003.4 | n_correct 2592.8 | ppl 5.82 | accuracy 64.765 | uer 19.645 | wer 21.617 | raw_wer 21.617 | bleu 20.31 | wps 2153.2 | wpb 4003.4 | bsz 141.8 | num_updates 11784 | best_bleu 20.31
2023-08-11 18:53:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11784 updates
2023-08-11 18:53:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 18:54:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 18:54:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 8 @ 11784 updates, score 20.31) (writing took 28.467860938981175 seconds)
2023-08-11 18:54:22 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-11 18:54:22 | INFO | train | epoch 008 | loss 2.184 | trans_loss 3.42 | nll_loss 1.609 | w2v_ctc_loss 1.146 | task_loss 0 | contrastive_loss 0.259 | total 4138.65 | n_correct 2557.96 | ppl 3.05 | accuracy 61.807 | wps 14704 | ups 1.19 | wpb 12355.8 | bsz 458.5 | num_updates 11784 | lr 0.000130277 | gnorm 0.437 | clip 0 | loss_scale 16 | train_wall 1168 | gb_free 16.9 | wall 9835
2023-08-11 18:54:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 18:54:22 | INFO | fairseq.trainer | begin training epoch 9
2023-08-11 18:54:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 18:54:43 | INFO | train_inner | epoch 009:     16 / 1474 loss=2.177, trans_loss=3.41, nll_loss=1.596, w2v_ctc_loss=1.121, task_loss=0, contrastive_loss=0.374, total=4121.25, n_correct=2565.75, ppl=3.02, accuracy=62.257, wps=8704, ups=0.71, wpb=12298.5, bsz=466, num_updates=11800, lr=0.000130189, gnorm=0.43, clip=0, loss_scale=16, train_wall=80, gb_free=17.6, wall=9856
2023-08-11 18:56:03 | INFO | train_inner | epoch 009:    116 / 1474 loss=2.118, trans_loss=3.384, nll_loss=1.564, w2v_ctc_loss=1.097, task_loss=0, contrastive_loss=0.204, total=4191.82, n_correct=2639.23, ppl=2.96, accuracy=62.961, wps=15708.6, ups=1.25, wpb=12518.2, bsz=479.9, num_updates=11900, lr=0.000129641, gnorm=0.427, clip=0, loss_scale=16, train_wall=79, gb_free=15.9, wall=9936
2023-08-11 18:57:23 | INFO | train_inner | epoch 009:    216 / 1474 loss=2.107, trans_loss=3.389, nll_loss=1.569, w2v_ctc_loss=1.099, task_loss=0, contrastive_loss=0.16, total=4061.27, n_correct=2553.1, ppl=2.97, accuracy=62.865, wps=15189, ups=1.25, wpb=12126.5, bsz=431.4, num_updates=12000, lr=0.000129099, gnorm=0.43, clip=0, loss_scale=16, train_wall=79, gb_free=17.5, wall=10016
2023-08-11 18:57:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 18:57:44 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.178 | trans_loss 5.257 | nll_loss 2.544 | w2v_ctc_loss 1.348 | task_loss 0 | contrastive_loss 0.349 | total 4003.4 | n_correct 2595.3 | ppl 5.83 | accuracy 64.827 | uer 19.401 | wer 21.297 | raw_wer 21.297 | bleu 20.89 | wps 2400.4 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 20.89
2023-08-11 18:57:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-08-11 18:57:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-08-11 18:57:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-08-11 18:58:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 20.89) (writing took 56.52529780752957 seconds)
2023-08-11 19:00:02 | INFO | train_inner | epoch 009:    316 / 1474 loss=2.108, trans_loss=3.378, nll_loss=1.558, w2v_ctc_loss=1.086, task_loss=0, contrastive_loss=0.21, total=4146.43, n_correct=2615.39, ppl=2.94, accuracy=63.076, wps=7805.7, ups=0.63, wpb=12389.9, bsz=474.6, num_updates=12100, lr=0.000128565, gnorm=0.432, clip=0, loss_scale=16, train_wall=79, gb_free=16.2, wall=10175
2023-08-11 19:01:22 | INFO | train_inner | epoch 009:    416 / 1474 loss=2.111, trans_loss=3.394, nll_loss=1.576, w2v_ctc_loss=1.096, task_loss=0, contrastive_loss=0.177, total=4194.84, n_correct=2630.08, ppl=2.98, accuracy=62.698, wps=15589.1, ups=1.24, wpb=12524.6, bsz=466.7, num_updates=12200, lr=0.000128037, gnorm=0.425, clip=0, loss_scale=16, train_wall=80, gb_free=16.1, wall=10255
2023-08-11 19:02:42 | INFO | train_inner | epoch 009:    516 / 1474 loss=2.138, trans_loss=3.394, nll_loss=1.575, w2v_ctc_loss=1.115, task_loss=0, contrastive_loss=0.228, total=4124.3, n_correct=2584.67, ppl=2.98, accuracy=62.669, wps=15411.2, ups=1.25, wpb=12310.3, bsz=439.5, num_updates=12300, lr=0.000127515, gnorm=0.428, clip=0, loss_scale=16, train_wall=79, gb_free=11.8, wall=10335
2023-08-11 19:04:01 | INFO | train_inner | epoch 009:    616 / 1474 loss=2.103, trans_loss=3.385, nll_loss=1.567, w2v_ctc_loss=1.091, task_loss=0, contrastive_loss=0.186, total=4120.96, n_correct=2590.95, ppl=2.96, accuracy=62.872, wps=15478.6, ups=1.26, wpb=12316.4, bsz=453.4, num_updates=12400, lr=0.000127, gnorm=0.425, clip=0, loss_scale=16, train_wall=79, gb_free=16.1, wall=10415
2023-08-11 19:05:20 | INFO | train_inner | epoch 009:    716 / 1474 loss=2.141, trans_loss=3.393, nll_loss=1.576, w2v_ctc_loss=1.115, task_loss=0, contrastive_loss=0.266, total=4088.53, n_correct=2562.75, ppl=2.98, accuracy=62.681, wps=15452.7, ups=1.27, wpb=12213.7, bsz=451.4, num_updates=12500, lr=0.000126491, gnorm=0.436, clip=0, loss_scale=16, train_wall=78, gb_free=16.9, wall=10494
2023-08-11 19:06:41 | INFO | train_inner | epoch 009:    816 / 1474 loss=2.177, trans_loss=3.387, nll_loss=1.57, w2v_ctc_loss=1.103, task_loss=0, contrastive_loss=0.407, total=4220.43, n_correct=2649.44, ppl=2.97, accuracy=62.777, wps=15704.1, ups=1.25, wpb=12611.1, bsz=501.1, num_updates=12600, lr=0.000125988, gnorm=0.435, clip=0, loss_scale=32, train_wall=80, gb_free=14.3, wall=10574
2023-08-11 19:08:02 | INFO | train_inner | epoch 009:    916 / 1474 loss=2.152, trans_loss=3.391, nll_loss=1.571, w2v_ctc_loss=1.102, task_loss=0, contrastive_loss=0.393, total=4146.05, n_correct=2600.63, ppl=2.97, accuracy=62.725, wps=15225.6, ups=1.23, wpb=12371.5, bsz=450.3, num_updates=12700, lr=0.000125491, gnorm=0.425, clip=0, loss_scale=32, train_wall=81, gb_free=17.7, wall=10655
2023-08-11 19:09:22 | INFO | train_inner | epoch 009:   1016 / 1474 loss=2.114, trans_loss=3.397, nll_loss=1.579, w2v_ctc_loss=1.106, task_loss=0, contrastive_loss=0.175, total=4101.48, n_correct=2568.88, ppl=2.99, accuracy=62.633, wps=15352.8, ups=1.25, wpb=12241.7, bsz=424.4, num_updates=12800, lr=0.000125, gnorm=0.426, clip=0, loss_scale=32, train_wall=79, gb_free=15.9, wall=10735
2023-08-11 19:10:41 | INFO | train_inner | epoch 009:   1116 / 1474 loss=2.118, trans_loss=3.395, nll_loss=1.573, w2v_ctc_loss=1.1, task_loss=0, contrastive_loss=0.196, total=4179.09, n_correct=2626.51, ppl=2.98, accuracy=62.849, wps=15647.7, ups=1.26, wpb=12457.7, bsz=474.7, num_updates=12900, lr=0.000124515, gnorm=0.426, clip=0, loss_scale=32, train_wall=79, gb_free=15.2, wall=10814
2023-08-11 19:12:01 | INFO | train_inner | epoch 009:   1216 / 1474 loss=2.119, trans_loss=3.392, nll_loss=1.574, w2v_ctc_loss=1.11, task_loss=0, contrastive_loss=0.181, total=4140.66, n_correct=2593.29, ppl=2.98, accuracy=62.63, wps=15452.8, ups=1.25, wpb=12363.4, bsz=448.1, num_updates=13000, lr=0.000124035, gnorm=0.429, clip=0, loss_scale=32, train_wall=79, gb_free=17, wall=10894
2023-08-11 19:13:21 | INFO | train_inner | epoch 009:   1316 / 1474 loss=2.148, trans_loss=3.387, nll_loss=1.566, w2v_ctc_loss=1.09, task_loss=0, contrastive_loss=0.368, total=4204.43, n_correct=2648.12, ppl=2.96, accuracy=62.984, wps=15697.6, ups=1.25, wpb=12544.9, bsz=492.5, num_updates=13100, lr=0.00012356, gnorm=0.421, clip=0, loss_scale=32, train_wall=79, gb_free=17.6, wall=10974
2023-08-11 19:14:40 | INFO | train_inner | epoch 009:   1416 / 1474 loss=2.108, trans_loss=3.397, nll_loss=1.58, w2v_ctc_loss=1.106, task_loss=0, contrastive_loss=0.157, total=4069.19, n_correct=2553.92, ppl=2.99, accuracy=62.762, wps=15330.7, ups=1.26, wpb=12143.2, bsz=427.7, num_updates=13200, lr=0.000123091, gnorm=0.428, clip=0, loss_scale=32, train_wall=79, gb_free=16.5, wall=11054
2023-08-11 19:15:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 19:15:50 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.166 | trans_loss 5.238 | nll_loss 2.528 | w2v_ctc_loss 1.36 | task_loss 0 | contrastive_loss 0.345 | total 4003.4 | n_correct 2604.9 | ppl 5.77 | accuracy 65.067 | uer 18.982 | wer 20.797 | raw_wer 20.797 | bleu 20.73 | wps 2046 | wpb 4003.4 | bsz 141.8 | num_updates 13258 | best_bleu 20.89
2023-08-11 19:15:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13258 updates
2023-08-11 19:15:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_20.7301.pt
2023-08-11 19:15:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_20.7301.pt
2023-08-11 19:16:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_20.7301.pt (epoch 9 @ 13258 updates, score 20.73) (writing took 20.431846177205443 seconds)
2023-08-11 19:16:11 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-11 19:16:11 | INFO | train | epoch 009 | loss 2.126 | trans_loss 3.39 | nll_loss 1.571 | w2v_ctc_loss 1.101 | task_loss 0 | contrastive_loss 0.242 | total 4138.65 | n_correct 2599.48 | ppl 2.97 | accuracy 62.81 | wps 13908.4 | ups 1.13 | wpb 12355.8 | bsz 458.5 | num_updates 13258 | lr 0.000122822 | gnorm 0.428 | clip 0 | loss_scale 32 | train_wall 1168 | gb_free 11.7 | wall 11144
2023-08-11 19:16:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 19:16:11 | INFO | fairseq.trainer | begin training epoch 10
2023-08-11 19:16:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 19:16:52 | INFO | train_inner | epoch 010:     42 / 1474 loss=2.108, trans_loss=3.38, nll_loss=1.558, w2v_ctc_loss=1.079, task_loss=0, contrastive_loss=0.25, total=4100.8, n_correct=2594.58, ppl=2.94, accuracy=63.27, wps=9277.5, ups=0.76, wpb=12238.2, bsz=469.4, num_updates=13300, lr=0.000122628, gnorm=0.426, clip=0, loss_scale=32, train_wall=78, gb_free=16.2, wall=11186
2023-08-11 19:18:12 | INFO | train_inner | epoch 010:    142 / 1474 loss=2.06, trans_loss=3.362, nll_loss=1.536, w2v_ctc_loss=1.049, task_loss=0, contrastive_loss=0.173, total=4247.35, n_correct=2708.34, ppl=2.9, accuracy=63.765, wps=15899.6, ups=1.25, wpb=12684.5, bsz=479.6, num_updates=13400, lr=0.000122169, gnorm=0.421, clip=0, loss_scale=32, train_wall=79, gb_free=11.9, wall=11265
2023-08-11 19:19:33 | INFO | train_inner | epoch 010:    242 / 1474 loss=2.092, trans_loss=3.361, nll_loss=1.533, w2v_ctc_loss=1.061, task_loss=0, contrastive_loss=0.295, total=4122.82, n_correct=2630.54, ppl=2.89, accuracy=63.804, wps=15298.7, ups=1.24, wpb=12303.3, bsz=461.4, num_updates=13500, lr=0.000121716, gnorm=0.424, clip=0, loss_scale=32, train_wall=80, gb_free=16.2, wall=11346
2023-08-11 19:20:52 | INFO | train_inner | epoch 010:    342 / 1474 loss=2.069, trans_loss=3.36, nll_loss=1.537, w2v_ctc_loss=1.055, task_loss=0, contrastive_loss=0.208, total=4138.27, n_correct=2634.18, ppl=2.9, accuracy=63.654, wps=15523.6, ups=1.25, wpb=12371, bsz=453.8, num_updates=13600, lr=0.000121268, gnorm=0.421, clip=0, loss_scale=32, train_wall=79, gb_free=16.3, wall=11425
2023-08-11 19:21:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-11 19:22:14 | INFO | train_inner | epoch 010:    443 / 1474 loss=2.058, trans_loss=3.366, nll_loss=1.54, w2v_ctc_loss=1.05, task_loss=0, contrastive_loss=0.166, total=4179.41, n_correct=2660.45, ppl=2.91, accuracy=63.656, wps=15289.6, ups=1.23, wpb=12477.2, bsz=468, num_updates=13700, lr=0.000120824, gnorm=0.422, clip=0, loss_scale=16, train_wall=81, gb_free=16.9, wall=11507
2023-08-11 19:23:34 | INFO | train_inner | epoch 010:    543 / 1474 loss=2.08, trans_loss=3.377, nll_loss=1.551, w2v_ctc_loss=1.079, task_loss=0, contrastive_loss=0.162, total=4094.23, n_correct=2591.91, ppl=2.93, accuracy=63.306, wps=15190.8, ups=1.24, wpb=12209.6, bsz=433.2, num_updates=13800, lr=0.000120386, gnorm=0.426, clip=0, loss_scale=16, train_wall=80, gb_free=14.4, wall=11587
2023-08-11 19:24:55 | INFO | train_inner | epoch 010:    643 / 1474 loss=2.1, trans_loss=3.371, nll_loss=1.546, w2v_ctc_loss=1.067, task_loss=0, contrastive_loss=0.277, total=4182.84, n_correct=2659.3, ppl=2.92, accuracy=63.576, wps=15546.3, ups=1.25, wpb=12481.2, bsz=481.3, num_updates=13900, lr=0.000119952, gnorm=0.428, clip=0, loss_scale=16, train_wall=80, gb_free=16.6, wall=11668
2023-08-11 19:26:14 | INFO | train_inner | epoch 010:    743 / 1474 loss=2.081, trans_loss=3.368, nll_loss=1.543, w2v_ctc_loss=1.083, task_loss=0, contrastive_loss=0.161, total=4120.62, n_correct=2618.47, ppl=2.91, accuracy=63.546, wps=15581.8, ups=1.27, wpb=12301.2, bsz=451.7, num_updates=14000, lr=0.000119523, gnorm=0.427, clip=0, loss_scale=16, train_wall=78, gb_free=16.9, wall=11747
2023-08-11 19:26:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 19:26:35 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.174 | trans_loss 5.221 | nll_loss 2.501 | w2v_ctc_loss 1.43 | task_loss 0 | contrastive_loss 0.342 | total 4003.4 | n_correct 2618.6 | ppl 5.66 | accuracy 65.409 | uer 19.253 | wer 21.11 | raw_wer 21.11 | bleu 21.22 | wps 2397.8 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 21.22
2023-08-11 19:26:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-08-11 19:26:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-08-11 19:26:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-08-11 19:27:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 21.22) (writing took 44.18874544091523 seconds)
2023-08-11 19:28:41 | INFO | train_inner | epoch 010:    843 / 1474 loss=2.06, trans_loss=3.366, nll_loss=1.542, w2v_ctc_loss=1.057, task_loss=0, contrastive_loss=0.163, total=4132.62, n_correct=2628.63, ppl=2.91, accuracy=63.607, wps=8376.2, ups=0.68, wpb=12339.2, bsz=457.4, num_updates=14100, lr=0.000119098, gnorm=0.414, clip=0, loss_scale=16, train_wall=80, gb_free=16.6, wall=11894
2023-08-11 19:30:00 | INFO | train_inner | epoch 010:    943 / 1474 loss=2.079, trans_loss=3.366, nll_loss=1.539, w2v_ctc_loss=1.066, task_loss=0, contrastive_loss=0.2, total=4160.84, n_correct=2649.02, ppl=2.91, accuracy=63.666, wps=15648.9, ups=1.26, wpb=12411.3, bsz=467.9, num_updates=14200, lr=0.000118678, gnorm=0.424, clip=0, loss_scale=16, train_wall=79, gb_free=15.8, wall=11973
2023-08-11 19:31:20 | INFO | train_inner | epoch 010:   1043 / 1474 loss=2.072, trans_loss=3.367, nll_loss=1.541, w2v_ctc_loss=1.069, task_loss=0, contrastive_loss=0.174, total=4059.22, n_correct=2578.14, ppl=2.91, accuracy=63.513, wps=15176.8, ups=1.25, wpb=12120, bsz=431.2, num_updates=14300, lr=0.000118262, gnorm=0.425, clip=0, loss_scale=16, train_wall=79, gb_free=9.8, wall=12053
2023-08-11 19:32:39 | INFO | train_inner | epoch 010:   1143 / 1474 loss=2.076, trans_loss=3.374, nll_loss=1.55, w2v_ctc_loss=1.08, task_loss=0, contrastive_loss=0.157, total=4045.82, n_correct=2561.46, ppl=2.93, accuracy=63.311, wps=15303.8, ups=1.27, wpb=12079.3, bsz=422.8, num_updates=14400, lr=0.000117851, gnorm=0.424, clip=0, loss_scale=16, train_wall=78, gb_free=12.9, wall=12132
2023-08-11 19:33:58 | INFO | train_inner | epoch 010:   1243 / 1474 loss=2.067, trans_loss=3.359, nll_loss=1.536, w2v_ctc_loss=1.075, task_loss=0, contrastive_loss=0.153, total=4107.6, n_correct=2614.46, ppl=2.9, accuracy=63.649, wps=15455.2, ups=1.26, wpb=12284.6, bsz=446.5, num_updates=14500, lr=0.000117444, gnorm=0.42, clip=0, loss_scale=16, train_wall=79, gb_free=16.5, wall=12212
2023-08-11 19:35:18 | INFO | train_inner | epoch 010:   1343 / 1474 loss=2.068, trans_loss=3.366, nll_loss=1.542, w2v_ctc_loss=1.07, task_loss=0, contrastive_loss=0.163, total=4127.69, n_correct=2630.23, ppl=2.91, accuracy=63.722, wps=15470.3, ups=1.26, wpb=12326.4, bsz=452.2, num_updates=14600, lr=0.000117041, gnorm=0.42, clip=0, loss_scale=16, train_wall=79, gb_free=16.1, wall=12291
2023-08-11 19:36:38 | INFO | train_inner | epoch 010:   1443 / 1474 loss=2.127, trans_loss=3.376, nll_loss=1.552, w2v_ctc_loss=1.052, task_loss=0, contrastive_loss=0.409, total=4195.02, n_correct=2658.84, ppl=2.93, accuracy=63.381, wps=15650.4, ups=1.25, wpb=12514.1, bsz=483, num_updates=14700, lr=0.000116642, gnorm=0.426, clip=0, loss_scale=16, train_wall=79, gb_free=16.3, wall=12371
2023-08-11 19:37:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 19:37:24 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.15 | trans_loss 5.213 | nll_loss 2.492 | w2v_ctc_loss 1.38 | task_loss 0 | contrastive_loss 0.33 | total 4003.4 | n_correct 2626.2 | ppl 5.63 | accuracy 65.599 | uer 18.692 | wer 20.518 | raw_wer 20.518 | bleu 21.45 | wps 2437.8 | wpb 4003.4 | bsz 141.8 | num_updates 14731 | best_bleu 21.45
2023-08-11 19:37:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14731 updates
2023-08-11 19:37:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 19:37:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 19:37:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 10 @ 14731 updates, score 21.45) (writing took 30.28615885414183 seconds)
2023-08-11 19:37:55 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-11 19:37:55 | INFO | train | epoch 010 | loss 2.079 | trans_loss 3.367 | nll_loss 1.542 | w2v_ctc_loss 1.064 | task_loss 0 | contrastive_loss 0.215 | total 4136.93 | n_correct 2630.7 | ppl 2.91 | accuracy 63.591 | wps 13951.2 | ups 1.13 | wpb 12350.7 | bsz 457.4 | num_updates 14731 | lr 0.00011652 | gnorm 0.423 | clip 0 | loss_scale 16 | train_wall 1168 | gb_free 17.1 | wall 12448
2023-08-11 19:37:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 19:37:55 | INFO | fairseq.trainer | begin training epoch 11
2023-08-11 19:37:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 19:38:57 | INFO | train_inner | epoch 011:     69 / 1474 loss=2.054, trans_loss=3.346, nll_loss=1.514, w2v_ctc_loss=1.037, task_loss=0, contrastive_loss=0.241, total=4166, n_correct=2676.74, ppl=2.86, accuracy=64.252, wps=8923.3, ups=0.72, wpb=12436.1, bsz=475.7, num_updates=14800, lr=0.000116248, gnorm=0.412, clip=0, loss_scale=16, train_wall=78, gb_free=17.7, wall=12511
2023-08-11 19:40:17 | INFO | train_inner | epoch 011:    169 / 1474 loss=2.035, trans_loss=3.347, nll_loss=1.517, w2v_ctc_loss=1.037, task_loss=0, contrastive_loss=0.161, total=4100.74, n_correct=2635.58, ppl=2.86, accuracy=64.271, wps=15321.9, ups=1.25, wpb=12251.1, bsz=450.6, num_updates=14900, lr=0.000115857, gnorm=0.422, clip=0, loss_scale=16, train_wall=79, gb_free=14.4, wall=12591
2023-08-11 19:41:37 | INFO | train_inner | epoch 011:    269 / 1474 loss=2.019, trans_loss=3.344, nll_loss=1.513, w2v_ctc_loss=1.025, task_loss=0, contrastive_loss=0.146, total=4115.58, n_correct=2645.14, ppl=2.85, accuracy=64.271, wps=15448.1, ups=1.26, wpb=12290.6, bsz=444.2, num_updates=15000, lr=0.00011547, gnorm=0.419, clip=0, loss_scale=16, train_wall=79, gb_free=16, wall=12670
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:0')
2023-08-11 19:42:34 | INFO | train_inner | epoch 011:    369 / 1474 loss=2.126, trans_loss=4.973, nll_loss=2.253, w2v_ctc_loss=0.778, task_loss=0, contrastive_loss=0.118, total=4094.16, n_correct=2629.3, ppl=4.77, accuracy=64.221, wps=14389.1, ups=1.75, wpb=8227.1, bsz=296.5, num_updates=15100, lr=0.000115087, gnorm=0.552, clip=0, loss_scale=16, train_wall=56, gb_free=13.1, wall=12727
2023-08-11 19:43:31 | INFO | train_inner | epoch 011:    469 / 1474 loss=2.152, trans_loss=5.008, nll_loss=2.278, w2v_ctc_loss=0.785, task_loss=0, contrastive_loss=0.237, total=4112.8, n_correct=2627.18, ppl=4.85, accuracy=63.878, wps=14360.7, ups=1.75, wpb=8225.6, bsz=302.2, num_updates=15200, lr=0.000114708, gnorm=0.559, clip=0, loss_scale=16, train_wall=57, gb_free=17.2, wall=12785
2023-08-11 19:44:29 | INFO | train_inner | epoch 011:    569 / 1474 loss=2.151, trans_loss=5.007, nll_loss=2.276, w2v_ctc_loss=0.791, task_loss=0, contrastive_loss=0.243, total=4071.06, n_correct=2598.96, ppl=4.84, accuracy=63.84, wps=14108.1, ups=1.73, wpb=8142.1, bsz=292.6, num_updates=15300, lr=0.000114332, gnorm=0.579, clip=0, loss_scale=16, train_wall=57, gb_free=16.4, wall=12842
2023-08-11 19:45:26 | INFO | train_inner | epoch 011:    669 / 1474 loss=2.152, trans_loss=4.996, nll_loss=2.263, w2v_ctc_loss=0.783, task_loss=0, contrastive_loss=0.299, total=4156.4, n_correct=2665.44, ppl=4.8, accuracy=64.129, wps=14502.9, ups=1.74, wpb=8312.8, bsz=310.2, num_updates=15400, lr=0.000113961, gnorm=0.554, clip=0, loss_scale=16, train_wall=57, gb_free=16.2, wall=12900
2023-08-11 19:46:24 | INFO | train_inner | epoch 011:    769 / 1474 loss=2.139, trans_loss=5.006, nll_loss=2.275, w2v_ctc_loss=0.794, task_loss=0, contrastive_loss=0.117, total=4169.17, n_correct=2674.99, ppl=4.84, accuracy=64.161, wps=14494.1, ups=1.74, wpb=8338.3, bsz=304.8, num_updates=15500, lr=0.000113592, gnorm=0.551, clip=0, loss_scale=16, train_wall=57, gb_free=12.4, wall=12957
2023-08-11 19:47:21 | INFO | train_inner | epoch 011:    869 / 1474 loss=2.138, trans_loss=5.008, nll_loss=2.278, w2v_ctc_loss=0.791, task_loss=0, contrastive_loss=0.108, total=4120.01, n_correct=2633.69, ppl=4.85, accuracy=63.924, wps=14538, ups=1.76, wpb=8240, bsz=293.5, num_updates=15600, lr=0.000113228, gnorm=0.551, clip=0, loss_scale=16, train_wall=56, gb_free=13.7, wall=13014
2023-08-11 19:48:18 | INFO | train_inner | epoch 011:    969 / 1474 loss=2.137, trans_loss=5.006, nll_loss=2.276, w2v_ctc_loss=0.79, task_loss=0, contrastive_loss=0.12, total=4145.45, n_correct=2653.39, ppl=4.84, accuracy=64.007, wps=14429.7, ups=1.74, wpb=8290.9, bsz=303.7, num_updates=15700, lr=0.000112867, gnorm=0.551, clip=0, loss_scale=32, train_wall=57, gb_free=17, wall=13071
2023-08-11 19:49:15 | INFO | train_inner | epoch 011:   1069 / 1474 loss=2.14, trans_loss=5.004, nll_loss=2.274, w2v_ctc_loss=0.793, task_loss=0, contrastive_loss=0.138, total=4141.18, n_correct=2654.5, ppl=4.84, accuracy=64.1, wps=14500.6, ups=1.75, wpb=8282.4, bsz=309.4, num_updates=15800, lr=0.000112509, gnorm=0.553, clip=0, loss_scale=32, train_wall=57, gb_free=16.6, wall=13128
2023-08-11 19:50:12 | INFO | train_inner | epoch 011:   1169 / 1474 loss=2.14, trans_loss=5.008, nll_loss=2.279, w2v_ctc_loss=0.796, task_loss=0, contrastive_loss=0.123, total=4173.93, n_correct=2667.14, ppl=4.85, accuracy=63.9, wps=14612.7, ups=1.75, wpb=8347.9, bsz=307.2, num_updates=15900, lr=0.000112154, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=16.9, wall=13186
2023-08-11 19:51:10 | INFO | train_inner | epoch 011:   1269 / 1474 loss=2.149, trans_loss=5.001, nll_loss=2.271, w2v_ctc_loss=0.797, task_loss=0, contrastive_loss=0.192, total=4174.26, n_correct=2672.48, ppl=4.83, accuracy=64.023, wps=14584.9, ups=1.75, wpb=8348.5, bsz=314.4, num_updates=16000, lr=0.000111803, gnorm=0.562, clip=0, loss_scale=32, train_wall=57, gb_free=17.5, wall=13243
2023-08-11 19:51:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:7')
2023-08-11 19:51:32 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.143 | trans_loss 5.206 | nll_loss 2.483 | w2v_ctc_loss 1.377 | task_loss 0 | contrastive_loss 0.33 | total 4003.4 | n_correct 2636.3 | ppl 5.59 | accuracy 65.852 | uer 18.493 | wer 20.38 | raw_wer 20.38 | bleu 21.39 | wps 2288.7 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 21.45
2023-08-11 19:51:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-08-11 19:51:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-08-11 19:51:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-08-11 19:52:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 21.39) (writing took 44.31678118184209 seconds)
2023-08-11 19:53:15 | INFO | train_inner | epoch 011:   1369 / 1474 loss=2.159, trans_loss=5, nll_loss=2.27, w2v_ctc_loss=0.781, task_loss=0, contrastive_loss=0.354, total=4191.56, n_correct=2683.21, ppl=4.82, accuracy=64.015, wps=6695.8, ups=0.8, wpb=8383.1, bsz=327.7, num_updates=16100, lr=0.000111456, gnorm=0.559, clip=0, loss_scale=32, train_wall=57, gb_free=17.5, wall=13368
2023-08-11 19:54:12 | INFO | train_inner | epoch 011:   1469 / 1474 loss=2.135, trans_loss=5.003, nll_loss=2.273, w2v_ctc_loss=0.785, task_loss=0, contrastive_loss=0.127, total=4161.81, n_correct=2668.34, ppl=4.83, accuracy=64.115, wps=14570.6, ups=1.75, wpb=8323.6, bsz=313.2, num_updates=16200, lr=0.000111111, gnorm=0.55, clip=0, loss_scale=32, train_wall=57, gb_free=16.7, wall=13425
2023-08-11 19:54:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 19:54:37 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.129 | trans_loss 5.204 | nll_loss 2.478 | w2v_ctc_loss 1.335 | task_loss 0 | contrastive_loss 0.328 | total 4003.4 | n_correct 2633.5 | ppl 5.57 | accuracy 65.782 | uer 18.461 | wer 20.298 | raw_wer 20.298 | bleu 21.88 | wps 2263.8 | wpb 4003.4 | bsz 141.8 | num_updates 16205 | best_bleu 21.88
2023-08-11 19:54:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16205 updates
2023-08-11 19:54:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 19:54:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 19:55:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 11 @ 16205 updates, score 21.88) (writing took 29.506149323657155 seconds)
2023-08-11 19:55:07 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-11 19:55:07 | INFO | train | epoch 011 | loss 2.115 | trans_loss 4.588 | nll_loss 2.083 | w2v_ctc_loss 0.85 | task_loss 0 | contrastive_loss 0.175 | total 4138.65 | n_correct 2651.9 | ppl 4.24 | accuracy 64.077 | wps 12883.1 | ups 1.43 | wpb 9023.7 | bsz 333.5 | num_updates 16205 | lr 0.000111094 | gnorm 0.531 | clip 0 | loss_scale 32 | train_wall 895 | gb_free 17.3 | wall 13481
2023-08-11 19:55:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 19:55:08 | INFO | fairseq.trainer | begin training epoch 12
2023-08-11 19:55:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 19:56:09 | INFO | train_inner | epoch 012:     95 / 1474 loss=2.118, trans_loss=4.965, nll_loss=2.222, w2v_ctc_loss=0.773, task_loss=0, contrastive_loss=0.157, total=4139.2, n_correct=2684.38, ppl=4.67, accuracy=64.853, wps=7085.5, ups=0.86, wpb=8278.4, bsz=312.5, num_updates=16300, lr=0.00011077, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=16, wall=13542
2023-08-11 19:57:06 | INFO | train_inner | epoch 012:    195 / 1474 loss=2.116, trans_loss=4.97, nll_loss=2.23, w2v_ctc_loss=0.774, task_loss=0, contrastive_loss=0.11, total=4126.87, n_correct=2666.61, ppl=4.69, accuracy=64.616, wps=14429.3, ups=1.75, wpb=8253.7, bsz=295.9, num_updates=16400, lr=0.000110432, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=16.5, wall=13599
2023-08-11 19:58:03 | INFO | train_inner | epoch 012:    295 / 1474 loss=2.113, trans_loss=4.967, nll_loss=2.226, w2v_ctc_loss=0.761, task_loss=0, contrastive_loss=0.138, total=4203.54, n_correct=2727.85, ppl=4.68, accuracy=64.894, wps=14649.5, ups=1.74, wpb=8407.1, bsz=321.1, num_updates=16500, lr=0.000110096, gnorm=0.543, clip=0, loss_scale=32, train_wall=57, gb_free=14.8, wall=13657
2023-08-11 19:59:02 | INFO | train_inner | epoch 012:    395 / 1474 loss=2.114, trans_loss=4.972, nll_loss=2.232, w2v_ctc_loss=0.769, task_loss=0, contrastive_loss=0.123, total=4149.28, n_correct=2684.02, ppl=4.7, accuracy=64.686, wps=14265.4, ups=1.72, wpb=8298.6, bsz=307.1, num_updates=16600, lr=0.000109764, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=15.2, wall=13715
2023-08-11 19:59:59 | INFO | train_inner | epoch 012:    495 / 1474 loss=2.127, trans_loss=4.988, nll_loss=2.253, w2v_ctc_loss=0.784, task_loss=0, contrastive_loss=0.131, total=4106.46, n_correct=2649.64, ppl=4.77, accuracy=64.524, wps=14377.5, ups=1.75, wpb=8212.9, bsz=301.2, num_updates=16700, lr=0.000109435, gnorm=0.551, clip=0, loss_scale=32, train_wall=56, gb_free=17.8, wall=13772
2023-08-11 20:00:57 | INFO | train_inner | epoch 012:    595 / 1474 loss=2.125, trans_loss=4.972, nll_loss=2.232, w2v_ctc_loss=0.774, task_loss=0, contrastive_loss=0.195, total=4190.91, n_correct=2711.65, ppl=4.7, accuracy=64.703, wps=14419.7, ups=1.72, wpb=8381.8, bsz=316.5, num_updates=16800, lr=0.000109109, gnorm=0.55, clip=0, loss_scale=32, train_wall=58, gb_free=15.9, wall=13830
2023-08-11 20:01:54 | INFO | train_inner | epoch 012:    695 / 1474 loss=2.125, trans_loss=4.969, nll_loss=2.23, w2v_ctc_loss=0.76, task_loss=0, contrastive_loss=0.281, total=4203.66, n_correct=2725.49, ppl=4.69, accuracy=64.836, wps=14734.9, ups=1.75, wpb=8407.3, bsz=324.4, num_updates=16900, lr=0.000108786, gnorm=0.547, clip=0, loss_scale=32, train_wall=57, gb_free=17.5, wall=13887
2023-08-11 20:02:52 | INFO | train_inner | epoch 012:    795 / 1474 loss=2.114, trans_loss=4.969, nll_loss=2.228, w2v_ctc_loss=0.775, task_loss=0, contrastive_loss=0.119, total=4095.72, n_correct=2653.08, ppl=4.69, accuracy=64.777, wps=14167.1, ups=1.73, wpb=8191.4, bsz=298.9, num_updates=17000, lr=0.000108465, gnorm=0.559, clip=0, loss_scale=32, train_wall=57, gb_free=17.3, wall=13945
2023-08-11 20:03:50 | INFO | train_inner | epoch 012:    895 / 1474 loss=2.125, trans_loss=4.975, nll_loss=2.236, w2v_ctc_loss=0.776, task_loss=0, contrastive_loss=0.171, total=4162.82, n_correct=2689.45, ppl=4.71, accuracy=64.606, wps=14283.1, ups=1.72, wpb=8325.6, bsz=305.4, num_updates=17100, lr=0.000108148, gnorm=0.552, clip=0, loss_scale=32, train_wall=58, gb_free=16.3, wall=14003
2023-08-11 20:04:48 | INFO | train_inner | epoch 012:    995 / 1474 loss=2.126, trans_loss=4.978, nll_loss=2.241, w2v_ctc_loss=0.78, task_loss=0, contrastive_loss=0.182, total=4117.63, n_correct=2658.71, ppl=4.73, accuracy=64.569, wps=14315.7, ups=1.74, wpb=8235.3, bsz=301.6, num_updates=17200, lr=0.000107833, gnorm=0.557, clip=0, loss_scale=32, train_wall=57, gb_free=16.9, wall=14061
2023-08-11 20:05:45 | INFO | train_inner | epoch 012:   1095 / 1474 loss=2.135, trans_loss=4.982, nll_loss=2.246, w2v_ctc_loss=0.784, task_loss=0, contrastive_loss=0.222, total=4046.48, n_correct=2610.6, ppl=4.74, accuracy=64.515, wps=14180.8, ups=1.75, wpb=8093, bsz=289.6, num_updates=17300, lr=0.000107521, gnorm=0.557, clip=0, loss_scale=32, train_wall=56, gb_free=16.1, wall=14118
2023-08-11 20:06:43 | INFO | train_inner | epoch 012:   1195 / 1474 loss=2.142, trans_loss=4.999, nll_loss=2.267, w2v_ctc_loss=0.793, task_loss=0, contrastive_loss=0.191, total=4201.13, n_correct=2696.54, ppl=4.81, accuracy=64.186, wps=14497.7, ups=1.73, wpb=8402.3, bsz=319.2, num_updates=17400, lr=0.000107211, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=17.3, wall=14176
2023-08-11 20:07:40 | INFO | train_inner | epoch 012:   1295 / 1474 loss=2.122, trans_loss=4.979, nll_loss=2.241, w2v_ctc_loss=0.792, task_loss=0, contrastive_loss=0.105, total=4070.27, n_correct=2623.65, ppl=4.73, accuracy=64.459, wps=14227.6, ups=1.75, wpb=8140.5, bsz=286.1, num_updates=17500, lr=0.000106904, gnorm=0.55, clip=0, loss_scale=32, train_wall=57, gb_free=16, wall=14233
2023-08-11 20:08:37 | INFO | train_inner | epoch 012:   1395 / 1474 loss=2.13, trans_loss=4.987, nll_loss=2.253, w2v_ctc_loss=0.776, task_loss=0, contrastive_loss=0.208, total=4139.63, n_correct=2665.76, ppl=4.77, accuracy=64.396, wps=14389.4, ups=1.74, wpb=8279.3, bsz=305.8, num_updates=17600, lr=0.0001066, gnorm=0.555, clip=0, loss_scale=32, train_wall=57, gb_free=17.1, wall=14291
2023-08-11 20:09:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 20:09:45 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.115 | trans_loss 5.187 | nll_loss 2.46 | w2v_ctc_loss 1.331 | task_loss 0 | contrastive_loss 0.331 | total 4003.4 | n_correct 2643.7 | ppl 5.5 | accuracy 66.036 | uer 18.443 | wer 20.253 | raw_wer 20.253 | bleu 21.7 | wps 2423.7 | wpb 4003.4 | bsz 141.8 | num_updates 17679 | best_bleu 21.88
2023-08-11 20:09:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17679 updates
2023-08-11 20:09:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.7004.pt
2023-08-11 20:09:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.7004.pt
2023-08-11 20:10:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.7004.pt (epoch 12 @ 17679 updates, score 21.7) (writing took 29.058943955227733 seconds)
2023-08-11 20:10:14 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-11 20:10:14 | INFO | train | epoch 012 | loss 2.124 | trans_loss 4.977 | nll_loss 2.239 | w2v_ctc_loss 0.777 | task_loss 0 | contrastive_loss 0.165 | total 4138.65 | n_correct 2673.79 | ppl 4.72 | accuracy 64.605 | wps 13460.4 | ups 1.63 | wpb 8277.3 | bsz 305.7 | num_updates 17679 | lr 0.000106362 | gnorm 0.551 | clip 0 | loss_scale 32 | train_wall 839 | gb_free 13.1 | wall 14387
2023-08-11 20:10:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 20:10:14 | INFO | fairseq.trainer | begin training epoch 13
2023-08-11 20:10:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 20:10:33 | INFO | train_inner | epoch 013:     21 / 1474 loss=2.125, trans_loss=4.986, nll_loss=2.25, w2v_ctc_loss=0.791, task_loss=0, contrastive_loss=0.115, total=4096.49, n_correct=2638.46, ppl=4.76, accuracy=64.408, wps=7060.1, ups=0.86, wpb=8193, bsz=295.4, num_updates=17700, lr=0.000106299, gnorm=0.558, clip=0, loss_scale=32, train_wall=57, gb_free=14.7, wall=14407
2023-08-11 20:11:31 | INFO | train_inner | epoch 013:    121 / 1474 loss=2.102, trans_loss=4.951, nll_loss=2.205, w2v_ctc_loss=0.759, task_loss=0, contrastive_loss=0.126, total=4160.97, n_correct=2709.96, ppl=4.61, accuracy=65.128, wps=14384.2, ups=1.73, wpb=8321.9, bsz=302.9, num_updates=17800, lr=0.000106, gnorm=0.541, clip=0, loss_scale=64, train_wall=57, gb_free=16.3, wall=14464
2023-08-11 20:12:29 | INFO | train_inner | epoch 013:    221 / 1474 loss=2.129, trans_loss=4.961, nll_loss=2.219, w2v_ctc_loss=0.759, task_loss=0, contrastive_loss=0.34, total=4212.08, n_correct=2735.94, ppl=4.65, accuracy=64.955, wps=14599.8, ups=1.73, wpb=8424.2, bsz=329.7, num_updates=17900, lr=0.000105703, gnorm=0.543, clip=0, loss_scale=64, train_wall=57, gb_free=14.8, wall=14522
2023-08-11 20:13:27 | INFO | train_inner | epoch 013:    321 / 1474 loss=2.094, trans_loss=4.943, nll_loss=2.195, w2v_ctc_loss=0.757, task_loss=0, contrastive_loss=0.109, total=4102.3, n_correct=2679.88, ppl=4.58, accuracy=65.326, wps=14173.5, ups=1.73, wpb=8204.6, bsz=294.1, num_updates=18000, lr=0.000105409, gnorm=0.544, clip=0, loss_scale=64, train_wall=57, gb_free=17.3, wall=14580
2023-08-11 20:13:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 20:13:51 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.128 | trans_loss 5.203 | nll_loss 2.478 | w2v_ctc_loss 1.337 | task_loss 0 | contrastive_loss 0.33 | total 4003.4 | n_correct 2638.1 | ppl 5.57 | accuracy 65.896 | uer 18.785 | wer 20.831 | raw_wer 20.831 | bleu 21.66 | wps 2057.8 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 21.88
2023-08-11 20:13:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-08-11 20:13:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-08-11 20:13:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-08-11 20:14:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 21.66) (writing took 39.09785548597574 seconds)
2023-08-11 20:15:28 | INFO | train_inner | epoch 013:    421 / 1474 loss=2.104, trans_loss=4.949, nll_loss=2.203, w2v_ctc_loss=0.759, task_loss=0, contrastive_loss=0.157, total=4177.29, n_correct=2728.53, ppl=4.6, accuracy=65.318, wps=6909.7, ups=0.83, wpb=8354.6, bsz=318.4, num_updates=18100, lr=0.000105118, gnorm=0.549, clip=0, loss_scale=64, train_wall=56, gb_free=17.5, wall=14701
2023-08-11 20:16:26 | INFO | train_inner | epoch 013:    521 / 1474 loss=2.113, trans_loss=4.957, nll_loss=2.213, w2v_ctc_loss=0.766, task_loss=0, contrastive_loss=0.193, total=4201.22, n_correct=2727.78, ppl=4.64, accuracy=64.928, wps=14389.7, ups=1.71, wpb=8402.4, bsz=319, num_updates=18200, lr=0.000104828, gnorm=0.548, clip=0, loss_scale=64, train_wall=58, gb_free=13.1, wall=14759
2023-08-11 20:17:23 | INFO | train_inner | epoch 013:    621 / 1474 loss=2.096, trans_loss=4.951, nll_loss=2.206, w2v_ctc_loss=0.757, task_loss=0, contrastive_loss=0.107, total=4161.98, n_correct=2716.8, ppl=4.61, accuracy=65.277, wps=14573.7, ups=1.75, wpb=8324, bsz=308.3, num_updates=18300, lr=0.000104542, gnorm=0.548, clip=0, loss_scale=64, train_wall=57, gb_free=16, wall=14816
2023-08-11 20:18:21 | INFO | train_inner | epoch 013:    721 / 1474 loss=2.109, trans_loss=4.959, nll_loss=2.215, w2v_ctc_loss=0.781, task_loss=0, contrastive_loss=0.107, total=4096.76, n_correct=2660.52, ppl=4.64, accuracy=64.942, wps=14201.3, ups=1.73, wpb=8193.5, bsz=284.6, num_updates=18400, lr=0.000104257, gnorm=0.554, clip=0, loss_scale=64, train_wall=57, gb_free=16.7, wall=14874
2023-08-11 20:19:19 | INFO | train_inner | epoch 013:    821 / 1474 loss=2.11, trans_loss=4.959, nll_loss=2.216, w2v_ctc_loss=0.764, task_loss=0, contrastive_loss=0.153, total=4121.73, n_correct=2677.34, ppl=4.65, accuracy=64.957, wps=14306, ups=1.74, wpb=8243.5, bsz=306.7, num_updates=18500, lr=0.000103975, gnorm=0.555, clip=0, loss_scale=64, train_wall=57, gb_free=14.9, wall=14932
2023-08-11 20:20:16 | INFO | train_inner | epoch 013:    921 / 1474 loss=2.101, trans_loss=4.956, nll_loss=2.212, w2v_ctc_loss=0.761, task_loss=0, contrastive_loss=0.116, total=4107.01, n_correct=2674.4, ppl=4.63, accuracy=65.118, wps=14329.2, ups=1.74, wpb=8214, bsz=296.5, num_updates=18600, lr=0.000103695, gnorm=0.543, clip=0, loss_scale=64, train_wall=57, gb_free=16.1, wall=14989
2023-08-11 20:21:13 | INFO | train_inner | epoch 013:   1021 / 1474 loss=2.118, trans_loss=4.964, nll_loss=2.222, w2v_ctc_loss=0.777, task_loss=0, contrastive_loss=0.167, total=4081.02, n_correct=2645.52, ppl=4.67, accuracy=64.825, wps=14345.1, ups=1.76, wpb=8162, bsz=293.4, num_updates=18700, lr=0.000103418, gnorm=0.558, clip=0, loss_scale=64, train_wall=56, gb_free=16.3, wall=15046
2023-08-11 20:22:10 | INFO | train_inner | epoch 013:   1121 / 1474 loss=2.1, trans_loss=4.949, nll_loss=2.203, w2v_ctc_loss=0.757, task_loss=0, contrastive_loss=0.147, total=4105.62, n_correct=2678.36, ppl=4.6, accuracy=65.236, wps=14352.3, ups=1.75, wpb=8211.2, bsz=305.9, num_updates=18800, lr=0.000103142, gnorm=0.546, clip=0, loss_scale=64, train_wall=57, gb_free=16.8, wall=15103
2023-08-11 20:23:08 | INFO | train_inner | epoch 013:   1221 / 1474 loss=2.108, trans_loss=4.962, nll_loss=2.22, w2v_ctc_loss=0.773, task_loss=0, contrastive_loss=0.109, total=4110.35, n_correct=2666.65, ppl=4.66, accuracy=64.876, wps=14309.5, ups=1.74, wpb=8220.7, bsz=295.1, num_updates=18900, lr=0.000102869, gnorm=0.557, clip=0, loss_scale=64, train_wall=57, gb_free=15, wall=15161
2023-08-11 20:24:05 | INFO | train_inner | epoch 013:   1321 / 1474 loss=2.112, trans_loss=4.951, nll_loss=2.207, w2v_ctc_loss=0.769, task_loss=0, contrastive_loss=0.204, total=4112.2, n_correct=2684.6, ppl=4.62, accuracy=65.284, wps=14252.8, ups=1.73, wpb=8224.4, bsz=308.2, num_updates=19000, lr=0.000102598, gnorm=0.557, clip=0, loss_scale=64, train_wall=57, gb_free=17.6, wall=15218
2023-08-11 20:25:02 | INFO | train_inner | epoch 013:   1421 / 1474 loss=2.116, trans_loss=4.96, nll_loss=2.218, w2v_ctc_loss=0.762, task_loss=0, contrastive_loss=0.214, total=4180.88, n_correct=2715.39, ppl=4.65, accuracy=64.948, wps=14707.9, ups=1.76, wpb=8361.8, bsz=312.2, num_updates=19100, lr=0.000102329, gnorm=0.546, clip=0, loss_scale=64, train_wall=56, gb_free=15.4, wall=15275
2023-08-11 20:25:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 20:25:56 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.132 | trans_loss 5.192 | nll_loss 2.463 | w2v_ctc_loss 1.379 | task_loss 0 | contrastive_loss 0.33 | total 4003.4 | n_correct 2637.7 | ppl 5.51 | accuracy 65.886 | uer 18.817 | wer 20.812 | raw_wer 20.812 | bleu 21.49 | wps 1958.4 | wpb 4003.4 | bsz 141.8 | num_updates 19153 | best_bleu 21.88
2023-08-11 20:25:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19153 updates
2023-08-11 20:25:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.4905.pt
2023-08-11 20:25:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.4905.pt
2023-08-11 20:26:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.4905.pt (epoch 13 @ 19153 updates, score 21.49) (writing took 21.668538227677345 seconds)
2023-08-11 20:26:18 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-11 20:26:18 | INFO | train | epoch 013 | loss 2.108 | trans_loss 4.955 | nll_loss 2.21 | w2v_ctc_loss 0.765 | task_loss 0 | contrastive_loss 0.161 | total 4138.65 | n_correct 2693.58 | ppl 4.63 | accuracy 65.083 | wps 12656.3 | ups 1.53 | wpb 8277.3 | bsz 305.7 | num_updates 19153 | lr 0.000102187 | gnorm 0.549 | clip 0 | loss_scale 64 | train_wall 839 | gb_free 17.7 | wall 15351
2023-08-11 20:26:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 20:26:18 | INFO | fairseq.trainer | begin training epoch 14
2023-08-11 20:26:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 20:26:53 | INFO | train_inner | epoch 014:     47 / 1474 loss=2.088, trans_loss=4.928, nll_loss=2.177, w2v_ctc_loss=0.754, task_loss=0, contrastive_loss=0.119, total=4176.2, n_correct=2741.13, ppl=4.52, accuracy=65.637, wps=7556.8, ups=0.9, wpb=8352.4, bsz=322.3, num_updates=19200, lr=0.000102062, gnorm=0.546, clip=0, loss_scale=64, train_wall=57, gb_free=11.1, wall=15386
2023-08-11 20:27:49 | INFO | train_inner | epoch 014:    147 / 1474 loss=2.081, trans_loss=4.919, nll_loss=2.164, w2v_ctc_loss=0.753, task_loss=0, contrastive_loss=0.101, total=4080.86, n_correct=2686.35, ppl=4.48, accuracy=65.828, wps=14363.1, ups=1.76, wpb=8161.7, bsz=299.6, num_updates=19300, lr=0.000101797, gnorm=0.546, clip=0, loss_scale=64, train_wall=56, gb_free=17, wall=15443
2023-08-11 20:28:47 | INFO | train_inner | epoch 014:    247 / 1474 loss=2.097, trans_loss=4.937, nll_loss=2.187, w2v_ctc_loss=0.752, task_loss=0, contrastive_loss=0.201, total=4106.97, n_correct=2687.34, ppl=4.55, accuracy=65.434, wps=14289.5, ups=1.74, wpb=8213.9, bsz=293.3, num_updates=19400, lr=0.000101535, gnorm=0.555, clip=0, loss_scale=64, train_wall=57, gb_free=12.7, wall=15500
2023-08-11 20:29:44 | INFO | train_inner | epoch 014:    347 / 1474 loss=2.089, trans_loss=4.932, nll_loss=2.182, w2v_ctc_loss=0.747, task_loss=0, contrastive_loss=0.137, total=4179.8, n_correct=2744.36, ppl=4.54, accuracy=65.658, wps=14653.3, ups=1.75, wpb=8359.6, bsz=322.5, num_updates=19500, lr=0.000101274, gnorm=0.547, clip=0, loss_scale=64, train_wall=57, gb_free=17.4, wall=15557
2023-08-11 20:30:41 | INFO | train_inner | epoch 014:    447 / 1474 loss=2.085, trans_loss=4.937, nll_loss=2.188, w2v_ctc_loss=0.748, task_loss=0, contrastive_loss=0.098, total=4120.38, n_correct=2700.31, ppl=4.56, accuracy=65.535, wps=14385.9, ups=1.75, wpb=8240.8, bsz=296.3, num_updates=19600, lr=0.000101015, gnorm=0.538, clip=0, loss_scale=64, train_wall=57, gb_free=17.2, wall=15614
2023-08-11 20:31:39 | INFO | train_inner | epoch 014:    547 / 1474 loss=2.102, trans_loss=4.94, nll_loss=2.191, w2v_ctc_loss=0.773, task_loss=0, contrastive_loss=0.133, total=4089.86, n_correct=2671.81, ppl=4.57, accuracy=65.328, wps=14147.2, ups=1.73, wpb=8179.7, bsz=295.5, num_updates=19700, lr=0.000100759, gnorm=0.554, clip=0, loss_scale=64, train_wall=57, gb_free=12.3, wall=15672
2023-08-11 20:32:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-11 20:32:37 | INFO | train_inner | epoch 014:    648 / 1474 loss=2.091, trans_loss=4.935, nll_loss=2.185, w2v_ctc_loss=0.759, task_loss=0, contrastive_loss=0.109, total=4147.33, n_correct=2713.99, ppl=4.55, accuracy=65.439, wps=14225.5, ups=1.72, wpb=8294.7, bsz=301.9, num_updates=19800, lr=0.000100504, gnorm=0.545, clip=0, loss_scale=64, train_wall=58, gb_free=17.3, wall=15731
2023-08-11 20:33:35 | INFO | train_inner | epoch 014:    748 / 1474 loss=2.09, trans_loss=4.929, nll_loss=2.177, w2v_ctc_loss=0.758, task_loss=0, contrastive_loss=0.11, total=4145.47, n_correct=2721.07, ppl=4.52, accuracy=65.64, wps=14440, ups=1.74, wpb=8290.9, bsz=309.6, num_updates=19900, lr=0.000100251, gnorm=0.547, clip=0, loss_scale=64, train_wall=57, gb_free=16.2, wall=15788
2023-08-11 20:34:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-11 20:34:33 | INFO | train_inner | epoch 014:    849 / 1474 loss=2.086, trans_loss=4.926, nll_loss=2.174, w2v_ctc_loss=0.755, task_loss=0, contrastive_loss=0.109, total=4153.2, n_correct=2726.86, ppl=4.51, accuracy=65.657, wps=14365.1, ups=1.73, wpb=8306.4, bsz=312, num_updates=20000, lr=0.0001, gnorm=0.547, clip=0, loss_scale=32, train_wall=57, gb_free=13, wall=15846
2023-08-11 20:34:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 20:34:56 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.133 | trans_loss 5.187 | nll_loss 2.455 | w2v_ctc_loss 1.402 | task_loss 0 | contrastive_loss 0.321 | total 4003.4 | n_correct 2643.3 | ppl 5.48 | accuracy 66.026 | uer 18.963 | wer 20.823 | raw_wer 20.823 | bleu 21.47 | wps 2247.7 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 21.88
2023-08-11 20:34:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-08-11 20:34:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-08-11 20:34:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-08-11 20:35:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 21.47) (writing took 26.537169985473156 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:0')
2023-08-11 20:36:21 | INFO | train_inner | epoch 014:    949 / 1474 loss=2.092, trans_loss=4.934, nll_loss=2.185, w2v_ctc_loss=0.751, task_loss=0, contrastive_loss=0.15, total=4166.71, n_correct=2729.23, ppl=4.55, accuracy=65.501, wps=7695.9, ups=0.92, wpb=8333.4, bsz=310.6, num_updates=20100, lr=9.97509e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=57, gb_free=16.5, wall=15954
2023-08-11 20:37:19 | INFO | train_inner | epoch 014:   1049 / 1474 loss=2.094, trans_loss=4.939, nll_loss=2.191, w2v_ctc_loss=0.755, task_loss=0, contrastive_loss=0.134, total=4145.57, n_correct=2712.72, ppl=4.57, accuracy=65.437, wps=14257.7, ups=1.72, wpb=8291.1, bsz=301.1, num_updates=20200, lr=9.95037e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=58, gb_free=17.4, wall=16012
2023-08-11 20:38:17 | INFO | train_inner | epoch 014:   1149 / 1474 loss=2.128, trans_loss=4.941, nll_loss=2.194, w2v_ctc_loss=0.764, task_loss=0, contrastive_loss=0.406, total=4219.9, n_correct=2756.06, ppl=4.57, accuracy=65.311, wps=14526.9, ups=1.72, wpb=8439.8, bsz=325.2, num_updates=20300, lr=9.92583e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=58, gb_free=16.5, wall=16070
2023-08-11 20:39:14 | INFO | train_inner | epoch 014:   1249 / 1474 loss=2.095, trans_loss=4.944, nll_loss=2.197, w2v_ctc_loss=0.77, task_loss=0, contrastive_loss=0.094, total=4032.06, n_correct=2633.68, ppl=4.58, accuracy=65.318, wps=14241.6, ups=1.77, wpb=8064.1, bsz=274.4, num_updates=20400, lr=9.90148e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=56, gb_free=17.7, wall=16127
2023-08-11 20:40:11 | INFO | train_inner | epoch 014:   1349 / 1474 loss=2.088, trans_loss=4.937, nll_loss=2.188, w2v_ctc_loss=0.752, task_loss=0, contrastive_loss=0.108, total=4205.07, n_correct=2755.71, ppl=4.56, accuracy=65.533, wps=14756, ups=1.75, wpb=8410.1, bsz=317.3, num_updates=20500, lr=9.8773e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=57, gb_free=16.7, wall=16184
2023-08-11 20:41:08 | INFO | train_inner | epoch 014:   1449 / 1474 loss=2.097, trans_loss=4.943, nll_loss=2.196, w2v_ctc_loss=0.754, task_loss=0, contrastive_loss=0.147, total=4126.44, n_correct=2695.69, ppl=4.58, accuracy=65.327, wps=14424.1, ups=1.75, wpb=8252.9, bsz=303.9, num_updates=20600, lr=9.85329e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=57, gb_free=16.2, wall=16241
2023-08-11 20:41:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:1')
2023-08-11 20:41:45 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.121 | trans_loss 5.181 | nll_loss 2.451 | w2v_ctc_loss 1.376 | task_loss 0 | contrastive_loss 0.322 | total 4003.4 | n_correct 2652.4 | ppl 5.47 | accuracy 66.254 | uer 18.91 | wer 20.902 | raw_wer 20.902 | bleu 21.93 | wps 2270.2 | wpb 4003.4 | bsz 141.8 | num_updates 20625 | best_bleu 21.93
2023-08-11 20:41:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20625 updates
2023-08-11 20:41:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 20:41:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 20:42:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 14 @ 20625 updates, score 21.93) (writing took 27.598151337355375 seconds)
2023-08-11 20:42:13 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-11 20:42:13 | INFO | train | epoch 014 | loss 2.094 | trans_loss 4.935 | nll_loss 2.185 | w2v_ctc_loss 0.756 | task_loss 0 | contrastive_loss 0.145 | total 4136.25 | n_correct 2709.42 | ppl 4.55 | accuracy 65.504 | wps 12748.3 | ups 1.54 | wpb 8272.5 | bsz 304.8 | num_updates 20625 | lr 9.84732e-05 | gnorm 0.548 | clip 0 | loss_scale 32 | train_wall 838 | gb_free 16.4 | wall 16306
2023-08-11 20:42:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 20:42:13 | INFO | fairseq.trainer | begin training epoch 15
2023-08-11 20:42:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 20:43:03 | INFO | train_inner | epoch 015:     75 / 1474 loss=2.088, trans_loss=4.923, nll_loss=2.17, w2v_ctc_loss=0.743, task_loss=0, contrastive_loss=0.195, total=4090.99, n_correct=2693.46, ppl=4.5, accuracy=65.839, wps=7092.7, ups=0.87, wpb=8182, bsz=300.8, num_updates=20700, lr=9.82946e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=16357
2023-08-11 20:44:00 | INFO | train_inner | epoch 015:    175 / 1474 loss=2.075, trans_loss=4.914, nll_loss=2.156, w2v_ctc_loss=0.745, task_loss=0, contrastive_loss=0.106, total=4115.56, n_correct=2717.11, ppl=4.46, accuracy=66.02, wps=14517, ups=1.76, wpb=8231.1, bsz=298.5, num_updates=20800, lr=9.80581e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=56, gb_free=16.8, wall=16413
2023-08-11 20:44:57 | INFO | train_inner | epoch 015:    275 / 1474 loss=2.073, trans_loss=4.916, nll_loss=2.16, w2v_ctc_loss=0.739, task_loss=0, contrastive_loss=0.098, total=4182.19, n_correct=2763.04, ppl=4.47, accuracy=66.067, wps=14668.9, ups=1.75, wpb=8364.4, bsz=310.5, num_updates=20900, lr=9.78232e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=56, gb_free=16.5, wall=16470
2023-08-11 20:45:54 | INFO | train_inner | epoch 015:    375 / 1474 loss=2.075, trans_loss=4.909, nll_loss=2.152, w2v_ctc_loss=0.738, task_loss=0, contrastive_loss=0.121, total=4172.52, n_correct=2751.4, ppl=4.44, accuracy=65.941, wps=14571.8, ups=1.75, wpb=8345, bsz=307.7, num_updates=21000, lr=9.759e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=16.6, wall=16528
2023-08-11 20:46:52 | INFO | train_inner | epoch 015:    475 / 1474 loss=2.085, trans_loss=4.917, nll_loss=2.162, w2v_ctc_loss=0.734, task_loss=0, contrastive_loss=0.211, total=4076.84, n_correct=2682.76, ppl=4.48, accuracy=65.805, wps=14201.1, ups=1.74, wpb=8153.7, bsz=293.4, num_updates=21100, lr=9.73585e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=57, gb_free=16.7, wall=16585
2023-08-11 20:47:49 | INFO | train_inner | epoch 015:    575 / 1474 loss=2.079, trans_loss=4.915, nll_loss=2.159, w2v_ctc_loss=0.749, task_loss=0, contrastive_loss=0.123, total=4156.05, n_correct=2736.88, ppl=4.47, accuracy=65.853, wps=14656.7, ups=1.76, wpb=8312.1, bsz=302.8, num_updates=21200, lr=9.71286e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=56, gb_free=12.1, wall=16642
2023-08-11 20:48:46 | INFO | train_inner | epoch 015:    675 / 1474 loss=2.083, trans_loss=4.912, nll_loss=2.155, w2v_ctc_loss=0.744, task_loss=0, contrastive_loss=0.165, total=4118.87, n_correct=2715.56, ppl=4.45, accuracy=65.93, wps=14405.6, ups=1.75, wpb=8237.7, bsz=303, num_updates=21300, lr=9.69003e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=57, gb_free=17, wall=16699
2023-08-11 20:49:43 | INFO | train_inner | epoch 015:    775 / 1474 loss=2.079, trans_loss=4.92, nll_loss=2.165, w2v_ctc_loss=0.75, task_loss=0, contrastive_loss=0.107, total=4176.64, n_correct=2750.07, ppl=4.48, accuracy=65.844, wps=14531.9, ups=1.74, wpb=8353.3, bsz=305.3, num_updates=21400, lr=9.66736e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=57, gb_free=14.2, wall=16756
2023-08-11 20:50:40 | INFO | train_inner | epoch 015:    875 / 1474 loss=2.079, trans_loss=4.922, nll_loss=2.169, w2v_ctc_loss=0.75, task_loss=0, contrastive_loss=0.1, total=4056.99, n_correct=2666.26, ppl=4.5, accuracy=65.72, wps=14202.7, ups=1.75, wpb=8114, bsz=288, num_updates=21500, lr=9.64486e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=57, gb_free=17.3, wall=16814
2023-08-11 20:51:37 | INFO | train_inner | epoch 015:    975 / 1474 loss=2.083, trans_loss=4.918, nll_loss=2.163, w2v_ctc_loss=0.741, task_loss=0, contrastive_loss=0.188, total=4134.44, n_correct=2726.05, ppl=4.48, accuracy=65.935, wps=14554.1, ups=1.76, wpb=8268.9, bsz=304.8, num_updates=21600, lr=9.6225e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=56, gb_free=16.1, wall=16870
2023-08-11 20:52:35 | INFO | train_inner | epoch 015:   1075 / 1474 loss=2.107, trans_loss=4.928, nll_loss=2.177, w2v_ctc_loss=0.745, task_loss=0, contrastive_loss=0.342, total=4185.02, n_correct=2745.3, ppl=4.52, accuracy=65.598, wps=14513.9, ups=1.73, wpb=8370, bsz=324.2, num_updates=21700, lr=9.60031e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=57, gb_free=16.8, wall=16928
2023-08-11 20:53:32 | INFO | train_inner | epoch 015:   1175 / 1474 loss=2.073, trans_loss=4.913, nll_loss=2.159, w2v_ctc_loss=0.728, task_loss=0, contrastive_loss=0.148, total=4187.68, n_correct=2769.95, ppl=4.47, accuracy=66.145, wps=14581.6, ups=1.74, wpb=8375.4, bsz=329.7, num_updates=21800, lr=9.57826e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=16.7, wall=16986
2023-08-11 20:54:30 | INFO | train_inner | epoch 015:   1275 / 1474 loss=2.083, trans_loss=4.918, nll_loss=2.163, w2v_ctc_loss=0.76, task_loss=0, contrastive_loss=0.106, total=4141.6, n_correct=2723.54, ppl=4.48, accuracy=65.761, wps=14468.5, ups=1.75, wpb=8283.2, bsz=301.1, num_updates=21900, lr=9.55637e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=57, gb_free=13.7, wall=17043
2023-08-11 20:55:27 | INFO | train_inner | epoch 015:   1375 / 1474 loss=2.075, trans_loss=4.917, nll_loss=2.162, w2v_ctc_loss=0.745, task_loss=0, contrastive_loss=0.093, total=4099.6, n_correct=2702.4, ppl=4.48, accuracy=65.919, wps=14356.7, ups=1.75, wpb=8199.2, bsz=293.2, num_updates=22000, lr=9.53463e-05, gnorm=0.546, clip=0, loss_scale=64, train_wall=57, gb_free=14.5, wall=17100
2023-08-11 20:55:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 20:55:50 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.096 | trans_loss 5.177 | nll_loss 2.445 | w2v_ctc_loss 1.305 | task_loss 0 | contrastive_loss 0.319 | total 4003.4 | n_correct 2651.1 | ppl 5.45 | accuracy 66.221 | uer 17.878 | wer 19.783 | raw_wer 19.783 | bleu 21.76 | wps 2176.6 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 21.93
2023-08-11 20:55:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-08-11 20:55:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-08-11 20:55:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-08-11 20:56:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 21.76) (writing took 37.47751856036484 seconds)
2023-08-11 20:57:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-11 20:57:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 20:57:48 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.105 | trans_loss 5.174 | nll_loss 2.442 | w2v_ctc_loss 1.336 | task_loss 0 | contrastive_loss 0.325 | total 4003.4 | n_correct 2647.5 | ppl 5.44 | accuracy 66.131 | uer 18.31 | wer 20.115 | raw_wer 20.115 | bleu 21.88 | wps 2379.4 | wpb 4003.4 | bsz 141.8 | num_updates 22098 | best_bleu 21.93
2023-08-11 20:57:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22098 updates
2023-08-11 20:57:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.8801.pt
2023-08-11 20:57:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.8801.pt
2023-08-11 20:58:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.8801.pt (epoch 15 @ 22098 updates, score 21.88) (writing took 37.77646870724857 seconds)
2023-08-11 20:58:29 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-11 20:58:29 | INFO | train | epoch 015 | loss 2.081 | trans_loss 4.917 | nll_loss 2.162 | w2v_ctc_loss 0.743 | task_loss 0 | contrastive_loss 0.15 | total 4138.19 | n_correct 2726.89 | ppl 4.48 | accuracy 65.896 | wps 12496.1 | ups 1.51 | wpb 8276.4 | bsz 305.4 | num_updates 22098 | lr 9.51346e-05 | gnorm 0.547 | clip 0 | loss_scale 32 | train_wall 835 | gb_free 16.9 | wall 17282
2023-08-11 20:58:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 20:58:29 | INFO | fairseq.trainer | begin training epoch 16
2023-08-11 20:58:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 20:58:38 | INFO | train_inner | epoch 016:      2 / 1474 loss=2.079, trans_loss=4.921, nll_loss=2.168, w2v_ctc_loss=0.745, task_loss=0, contrastive_loss=0.122, total=4148.18, n_correct=2733.45, ppl=4.49, accuracy=65.895, wps=4346.9, ups=0.52, wpb=8296.4, bsz=312.3, num_updates=22100, lr=9.51303e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=58, gb_free=16.7, wall=17291
2023-08-11 20:59:35 | INFO | train_inner | epoch 016:    102 / 1474 loss=2.066, trans_loss=4.898, nll_loss=2.137, w2v_ctc_loss=0.734, task_loss=0, contrastive_loss=0.12, total=4115.14, n_correct=2729.25, ppl=4.4, accuracy=66.322, wps=14448.9, ups=1.76, wpb=8230.3, bsz=313.9, num_updates=22200, lr=9.49158e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=56, gb_free=12.8, wall=17348
2023-08-11 21:00:32 | INFO | train_inner | epoch 016:    202 / 1474 loss=2.055, trans_loss=4.89, nll_loss=2.127, w2v_ctc_loss=0.722, task_loss=0, contrastive_loss=0.096, total=4109.58, n_correct=2731.66, ppl=4.37, accuracy=66.471, wps=14286, ups=1.74, wpb=8219.2, bsz=297.3, num_updates=22300, lr=9.47027e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=57, gb_free=15.1, wall=17405
2023-08-11 21:01:29 | INFO | train_inner | epoch 016:    302 / 1474 loss=2.074, trans_loss=4.9, nll_loss=2.14, w2v_ctc_loss=0.737, task_loss=0, contrastive_loss=0.17, total=4164.1, n_correct=2757.3, ppl=4.41, accuracy=66.216, wps=14561.7, ups=1.75, wpb=8328.2, bsz=308.6, num_updates=22400, lr=9.44911e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=57, gb_free=17.3, wall=17462
2023-08-11 21:02:27 | INFO | train_inner | epoch 016:    402 / 1474 loss=2.073, trans_loss=4.897, nll_loss=2.135, w2v_ctc_loss=0.739, task_loss=0, contrastive_loss=0.187, total=4065.22, n_correct=2691.65, ppl=4.39, accuracy=66.212, wps=14164.4, ups=1.74, wpb=8130.4, bsz=286.4, num_updates=22500, lr=9.42809e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=57, gb_free=16.4, wall=17520
2023-08-11 21:03:24 | INFO | train_inner | epoch 016:    502 / 1474 loss=2.067, trans_loss=4.9, nll_loss=2.141, w2v_ctc_loss=0.733, task_loss=0, contrastive_loss=0.127, total=4181.93, n_correct=2773.54, ppl=4.41, accuracy=66.322, wps=14567, ups=1.74, wpb=8363.9, bsz=320.3, num_updates=22600, lr=9.40721e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=15.8, wall=17577
2023-08-11 21:04:21 | INFO | train_inner | epoch 016:    602 / 1474 loss=2.066, trans_loss=4.903, nll_loss=2.143, w2v_ctc_loss=0.738, task_loss=0, contrastive_loss=0.094, total=4122.97, n_correct=2729.28, ppl=4.42, accuracy=66.197, wps=14473.9, ups=1.76, wpb=8245.9, bsz=299, num_updates=22700, lr=9.38647e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=56, gb_free=16.2, wall=17634
2023-08-11 21:05:18 | INFO | train_inner | epoch 016:    702 / 1474 loss=2.066, trans_loss=4.903, nll_loss=2.143, w2v_ctc_loss=0.738, task_loss=0, contrastive_loss=0.094, total=4093.15, n_correct=2707.53, ppl=4.42, accuracy=66.148, wps=14459.9, ups=1.77, wpb=8186.3, bsz=296.5, num_updates=22800, lr=9.36586e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=56, gb_free=17.9, wall=17691
2023-08-11 21:06:15 | INFO | train_inner | epoch 016:    802 / 1474 loss=2.067, trans_loss=4.898, nll_loss=2.137, w2v_ctc_loss=0.726, task_loss=0, contrastive_loss=0.157, total=4183.24, n_correct=2773.7, ppl=4.4, accuracy=66.305, wps=14536.9, ups=1.74, wpb=8366.5, bsz=312.1, num_updates=22900, lr=9.34539e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=57, gb_free=17.8, wall=17748
2023-08-11 21:07:12 | INFO | train_inner | epoch 016:    902 / 1474 loss=2.069, trans_loss=4.9, nll_loss=2.141, w2v_ctc_loss=0.733, task_loss=0, contrastive_loss=0.146, total=4150.23, n_correct=2749, ppl=4.41, accuracy=66.237, wps=14511, ups=1.75, wpb=8300.5, bsz=306.5, num_updates=23000, lr=9.32505e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=57, gb_free=12.4, wall=17806
2023-08-11 21:08:10 | INFO | train_inner | epoch 016:   1002 / 1474 loss=2.076, trans_loss=4.906, nll_loss=2.148, w2v_ctc_loss=0.744, task_loss=0, contrastive_loss=0.146, total=4116.59, n_correct=2719.25, ppl=4.43, accuracy=66.056, wps=14371.6, ups=1.75, wpb=8233.2, bsz=300.6, num_updates=23100, lr=9.30484e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=57, gb_free=16.9, wall=17863
2023-08-11 21:09:07 | INFO | train_inner | epoch 016:   1102 / 1474 loss=2.077, trans_loss=4.911, nll_loss=2.155, w2v_ctc_loss=0.748, task_loss=0, contrastive_loss=0.121, total=4112.71, n_correct=2712.37, ppl=4.45, accuracy=65.951, wps=14433.9, ups=1.75, wpb=8225.4, bsz=295.7, num_updates=23200, lr=9.28477e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=56, gb_free=12.5, wall=17920
2023-08-11 21:10:05 | INFO | train_inner | epoch 016:   1202 / 1474 loss=2.073, trans_loss=4.905, nll_loss=2.146, w2v_ctc_loss=0.72, task_loss=0, contrastive_loss=0.214, total=4161.11, n_correct=2752.32, ppl=4.43, accuracy=66.144, wps=14352, ups=1.72, wpb=8322.2, bsz=308.2, num_updates=23300, lr=9.26482e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=57, gb_free=15.7, wall=17978
2023-08-11 21:11:02 | INFO | train_inner | epoch 016:   1302 / 1474 loss=2.08, trans_loss=4.904, nll_loss=2.146, w2v_ctc_loss=0.742, task_loss=0, contrastive_loss=0.196, total=4149.14, n_correct=2746.74, ppl=4.43, accuracy=66.2, wps=14390.2, ups=1.73, wpb=8298.3, bsz=311.9, num_updates=23400, lr=9.245e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=11.7, wall=18036
2023-08-11 21:12:00 | INFO | train_inner | epoch 016:   1402 / 1474 loss=2.07, trans_loss=4.902, nll_loss=2.144, w2v_ctc_loss=0.739, task_loss=0, contrastive_loss=0.124, total=4200.01, n_correct=2782.93, ppl=4.42, accuracy=66.26, wps=14541.9, ups=1.73, wpb=8400, bsz=322.2, num_updates=23500, lr=9.22531e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=57, gb_free=17, wall=18093
2023-08-11 21:12:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-11 21:12:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 21:13:05 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.107 | trans_loss 5.173 | nll_loss 2.437 | w2v_ctc_loss 1.346 | task_loss 0 | contrastive_loss 0.326 | total 4003.4 | n_correct 2655.3 | ppl 5.42 | accuracy 66.326 | uer 18.162 | wer 19.869 | raw_wer 19.869 | bleu 21.85 | wps 2158.8 | wpb 4003.4 | bsz 141.8 | num_updates 23571 | best_bleu 21.93
2023-08-11 21:13:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23571 updates
2023-08-11 21:13:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.8502.pt
2023-08-11 21:13:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.8502.pt
2023-08-11 21:13:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.8502.pt (epoch 16 @ 23571 updates, score 21.85) (writing took 20.572659734636545 seconds)
2023-08-11 21:13:26 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-11 21:13:26 | INFO | train | epoch 016 | loss 2.069 | trans_loss 4.901 | nll_loss 2.142 | w2v_ctc_loss 0.735 | task_loss 0 | contrastive_loss 0.14 | total 4136.64 | n_correct 2739.26 | ppl 4.41 | accuracy 66.219 | wps 13586.6 | ups 1.64 | wpb 8273.3 | bsz 304.9 | num_updates 23571 | lr 9.21141e-05 | gnorm 0.547 | clip 0 | loss_scale 16 | train_wall 837 | gb_free 15.6 | wall 18179
2023-08-11 21:13:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 21:13:26 | INFO | fairseq.trainer | begin training epoch 17
2023-08-11 21:13:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 21:13:50 | INFO | train_inner | epoch 017:     29 / 1474 loss=2.055, trans_loss=4.89, nll_loss=2.126, w2v_ctc_loss=0.725, task_loss=0, contrastive_loss=0.09, total=4106.38, n_correct=2725.89, ppl=4.37, accuracy=66.382, wps=7475.3, ups=0.91, wpb=8212.8, bsz=288.8, num_updates=23600, lr=9.20575e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=57, gb_free=17.7, wall=18203
2023-08-11 21:14:48 | INFO | train_inner | epoch 017:    129 / 1474 loss=2.049, trans_loss=4.876, nll_loss=2.109, w2v_ctc_loss=0.723, task_loss=0, contrastive_loss=0.096, total=4110.37, n_correct=2742.59, ppl=4.31, accuracy=66.724, wps=14290.3, ups=1.74, wpb=8220.7, bsz=295.6, num_updates=23700, lr=9.1863e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=57, gb_free=16.6, wall=18261
2023-08-11 21:15:46 | INFO | train_inner | epoch 017:    229 / 1474 loss=2.069, trans_loss=4.879, nll_loss=2.112, w2v_ctc_loss=0.717, task_loss=0, contrastive_loss=0.258, total=4181.59, n_correct=2786.03, ppl=4.32, accuracy=66.626, wps=14355.5, ups=1.72, wpb=8363.2, bsz=322.2, num_updates=23800, lr=9.16698e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=58, gb_free=15.9, wall=18319
2023-08-11 21:16:43 | INFO | train_inner | epoch 017:    329 / 1474 loss=2.066, trans_loss=4.884, nll_loss=2.119, w2v_ctc_loss=0.719, task_loss=0, contrastive_loss=0.265, total=4157.97, n_correct=2765.36, ppl=4.34, accuracy=66.507, wps=14527.4, ups=1.75, wpb=8315.9, bsz=304, num_updates=23900, lr=9.14779e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=57, gb_free=16, wall=18376
2023-08-11 21:17:41 | INFO | train_inner | epoch 017:    429 / 1474 loss=2.053, trans_loss=4.884, nll_loss=2.119, w2v_ctc_loss=0.726, task_loss=0, contrastive_loss=0.094, total=4135.12, n_correct=2755.97, ppl=4.34, accuracy=66.648, wps=14337.7, ups=1.73, wpb=8270.2, bsz=306.1, num_updates=24000, lr=9.12871e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=57, gb_free=13, wall=18434
2023-08-11 21:17:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 21:18:04 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.116 | trans_loss 5.175 | nll_loss 2.44 | w2v_ctc_loss 1.376 | task_loss 0 | contrastive_loss 0.32 | total 4003.4 | n_correct 2654.1 | ppl 5.43 | accuracy 66.296 | uer 18.536 | wer 20.32 | raw_wer 20.32 | bleu 21.9 | wps 2271.9 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 21.93
2023-08-11 21:18:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-08-11 21:18:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-08-11 21:18:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-08-11 21:18:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 21.9) (writing took 41.799320328980684 seconds)
2023-08-11 21:19:45 | INFO | train_inner | epoch 017:    529 / 1474 loss=2.059, trans_loss=4.888, nll_loss=2.124, w2v_ctc_loss=0.725, task_loss=0, contrastive_loss=0.138, total=4185.81, n_correct=2782.45, ppl=4.36, accuracy=66.473, wps=6726.7, ups=0.8, wpb=8371.6, bsz=308.6, num_updates=24100, lr=9.10975e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=58, gb_free=16.1, wall=18558
2023-08-11 21:20:43 | INFO | train_inner | epoch 017:    629 / 1474 loss=2.05, trans_loss=4.885, nll_loss=2.121, w2v_ctc_loss=0.72, task_loss=0, contrastive_loss=0.091, total=4168.62, n_correct=2779.8, ppl=4.35, accuracy=66.684, wps=14500.4, ups=1.74, wpb=8337.2, bsz=303.2, num_updates=24200, lr=9.09091e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=57, gb_free=14.5, wall=18616
2023-08-11 21:21:40 | INFO | train_inner | epoch 017:    729 / 1474 loss=2.068, trans_loss=4.89, nll_loss=2.127, w2v_ctc_loss=0.743, task_loss=0, contrastive_loss=0.136, total=4167.34, n_correct=2768.9, ppl=4.37, accuracy=66.443, wps=14568.4, ups=1.75, wpb=8334.7, bsz=307.7, num_updates=24300, lr=9.07218e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=57, gb_free=10.4, wall=18673
2023-08-11 21:22:37 | INFO | train_inner | epoch 017:    829 / 1474 loss=2.056, trans_loss=4.889, nll_loss=2.125, w2v_ctc_loss=0.729, task_loss=0, contrastive_loss=0.103, total=4092.64, n_correct=2724.68, ppl=4.36, accuracy=66.575, wps=14314.7, ups=1.75, wpb=8185.3, bsz=296.2, num_updates=24400, lr=9.05357e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=57, gb_free=15.9, wall=18730
2023-08-11 21:23:34 | INFO | train_inner | epoch 017:    929 / 1474 loss=2.051, trans_loss=4.885, nll_loss=2.121, w2v_ctc_loss=0.722, task_loss=0, contrastive_loss=0.099, total=4109.5, n_correct=2737.83, ppl=4.35, accuracy=66.622, wps=14418.8, ups=1.75, wpb=8219, bsz=305.4, num_updates=24500, lr=9.03508e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=56, gb_free=16.6, wall=18787
2023-08-11 21:24:32 | INFO | train_inner | epoch 017:   1029 / 1474 loss=2.056, trans_loss=4.887, nll_loss=2.124, w2v_ctc_loss=0.731, task_loss=0, contrastive_loss=0.102, total=4098.36, n_correct=2727.17, ppl=4.36, accuracy=66.543, wps=14287.9, ups=1.74, wpb=8196.7, bsz=301.7, num_updates=24600, lr=9.0167e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=57, gb_free=15.8, wall=18845
2023-08-11 21:25:28 | INFO | train_inner | epoch 017:   1129 / 1474 loss=2.051, trans_loss=4.884, nll_loss=2.12, w2v_ctc_loss=0.721, task_loss=0, contrastive_loss=0.094, total=4100.14, n_correct=2730.01, ppl=4.35, accuracy=66.583, wps=14465.7, ups=1.76, wpb=8200.3, bsz=299.3, num_updates=24700, lr=8.99843e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=56, gb_free=16.7, wall=18901
2023-08-11 21:26:26 | INFO | train_inner | epoch 017:   1229 / 1474 loss=2.092, trans_loss=4.897, nll_loss=2.137, w2v_ctc_loss=0.718, task_loss=0, contrastive_loss=0.394, total=4173.98, n_correct=2765.68, ppl=4.4, accuracy=66.26, wps=14366.7, ups=1.72, wpb=8348, bsz=325.9, num_updates=24800, lr=8.98027e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=58, gb_free=16, wall=18960
2023-08-11 21:27:24 | INFO | train_inner | epoch 017:   1329 / 1474 loss=2.053, trans_loss=4.887, nll_loss=2.124, w2v_ctc_loss=0.716, task_loss=0, contrastive_loss=0.106, total=4146.07, n_correct=2761.18, ppl=4.36, accuracy=66.598, wps=14443.6, ups=1.74, wpb=8292.1, bsz=303.2, num_updates=24900, lr=8.96221e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=57, gb_free=16.5, wall=19017
2023-08-11 21:28:21 | INFO | train_inner | epoch 017:   1429 / 1474 loss=2.052, trans_loss=4.889, nll_loss=2.127, w2v_ctc_loss=0.72, task_loss=0, contrastive_loss=0.096, total=4119.23, n_correct=2742.14, ppl=4.37, accuracy=66.569, wps=14303.8, ups=1.74, wpb=8238.5, bsz=303.4, num_updates=25000, lr=8.94427e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=57, gb_free=13.4, wall=19075
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:0')
2023-08-11 21:28:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:4')
2023-08-11 21:29:09 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.115 | trans_loss 5.171 | nll_loss 2.438 | w2v_ctc_loss 1.382 | task_loss 0 | contrastive_loss 0.322 | total 4003.4 | n_correct 2659.7 | ppl 5.42 | accuracy 66.436 | uer 18.623 | wer 20.603 | raw_wer 20.603 | bleu 21.86 | wps 2333 | wpb 4003.4 | bsz 141.8 | num_updates 25045 | best_bleu 21.93
2023-08-11 21:29:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25045 updates
2023-08-11 21:29:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.8600.pt
2023-08-11 21:29:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.8600.pt
2023-08-11 21:29:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.8600.pt (epoch 17 @ 25045 updates, score 21.86) (writing took 23.29138968139887 seconds)
2023-08-11 21:29:33 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-11 21:29:33 | INFO | train | epoch 017 | loss 2.059 | trans_loss 4.886 | nll_loss 2.122 | w2v_ctc_loss 0.724 | task_loss 0 | contrastive_loss 0.147 | total 4138.65 | n_correct 2754.86 | ppl 4.35 | accuracy 66.564 | wps 12613.5 | ups 1.52 | wpb 8277.3 | bsz 305.7 | num_updates 25045 | lr 8.93623e-05 | gnorm 0.544 | clip 0 | loss_scale 16 | train_wall 839 | gb_free 16.4 | wall 19146
2023-08-11 21:29:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 21:29:33 | INFO | fairseq.trainer | begin training epoch 18
2023-08-11 21:29:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 21:30:13 | INFO | train_inner | epoch 018:     55 / 1474 loss=2.051, trans_loss=4.878, nll_loss=2.112, w2v_ctc_loss=0.728, task_loss=0, contrastive_loss=0.103, total=4128.93, n_correct=2754.12, ppl=4.32, accuracy=66.703, wps=7391.3, ups=0.9, wpb=8257.9, bsz=301.7, num_updates=25100, lr=8.92644e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=57, gb_free=16.6, wall=19186
2023-08-11 21:31:11 | INFO | train_inner | epoch 018:    155 / 1474 loss=2.047, trans_loss=4.86, nll_loss=2.088, w2v_ctc_loss=0.696, task_loss=0, contrastive_loss=0.223, total=4158.38, n_correct=2788.63, ppl=4.25, accuracy=67.06, wps=14441.5, ups=1.74, wpb=8316.8, bsz=313.7, num_updates=25200, lr=8.90871e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=57, gb_free=16.7, wall=19244
2023-08-11 21:32:08 | INFO | train_inner | epoch 018:    255 / 1474 loss=2.037, trans_loss=4.859, nll_loss=2.087, w2v_ctc_loss=0.71, task_loss=0, contrastive_loss=0.095, total=4161.92, n_correct=2795.32, ppl=4.25, accuracy=67.164, wps=14508.4, ups=1.74, wpb=8323.8, bsz=312.8, num_updates=25300, lr=8.89108e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=57, gb_free=16.7, wall=19301
2023-08-11 21:33:06 | INFO | train_inner | epoch 018:    355 / 1474 loss=2.042, trans_loss=4.87, nll_loss=2.101, w2v_ctc_loss=0.709, task_loss=0, contrastive_loss=0.108, total=4167.42, n_correct=2787.16, ppl=4.29, accuracy=66.88, wps=14446.8, ups=1.73, wpb=8334.8, bsz=301.2, num_updates=25400, lr=8.87357e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=57, gb_free=15.4, wall=19359
2023-08-11 21:34:03 | INFO | train_inner | epoch 018:    455 / 1474 loss=2.056, trans_loss=4.875, nll_loss=2.107, w2v_ctc_loss=0.716, task_loss=0, contrastive_loss=0.199, total=4075.78, n_correct=2720.2, ppl=4.31, accuracy=66.741, wps=14195, ups=1.74, wpb=8151.6, bsz=294.2, num_updates=25500, lr=8.85615e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=57, gb_free=17.9, wall=19416
2023-08-11 21:35:00 | INFO | train_inner | epoch 018:    555 / 1474 loss=2.034, trans_loss=4.857, nll_loss=2.085, w2v_ctc_loss=0.701, task_loss=0, contrastive_loss=0.107, total=4218.07, n_correct=2838.08, ppl=4.24, accuracy=67.284, wps=14773.5, ups=1.75, wpb=8436.1, bsz=329.6, num_updates=25600, lr=8.83883e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=57, gb_free=15.9, wall=19473
2023-08-11 21:35:57 | INFO | train_inner | epoch 018:    655 / 1474 loss=2.059, trans_loss=4.88, nll_loss=2.114, w2v_ctc_loss=0.727, task_loss=0, contrastive_loss=0.18, total=4093.44, n_correct=2729.3, ppl=4.33, accuracy=66.675, wps=14399.4, ups=1.76, wpb=8186.9, bsz=298.5, num_updates=25700, lr=8.82162e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=56, gb_free=15.3, wall=19530
2023-08-11 21:36:55 | INFO | train_inner | epoch 018:    755 / 1474 loss=2.064, trans_loss=4.875, nll_loss=2.108, w2v_ctc_loss=0.72, task_loss=0, contrastive_loss=0.267, total=4202.99, n_correct=2807.44, ppl=4.31, accuracy=66.796, wps=14493.2, ups=1.72, wpb=8406, bsz=322.5, num_updates=25800, lr=8.80451e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=57, gb_free=17.6, wall=19588
2023-08-11 21:37:52 | INFO | train_inner | epoch 018:    855 / 1474 loss=2.042, trans_loss=4.872, nll_loss=2.103, w2v_ctc_loss=0.714, task_loss=0, contrastive_loss=0.093, total=4177.43, n_correct=2793.47, ppl=4.3, accuracy=66.871, wps=14671.9, ups=1.76, wpb=8354.9, bsz=304.8, num_updates=25900, lr=8.7875e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=56, gb_free=16.3, wall=19645
2023-08-11 21:38:49 | INFO | train_inner | epoch 018:    955 / 1474 loss=2.036, trans_loss=4.865, nll_loss=2.096, w2v_ctc_loss=0.7, task_loss=0, contrastive_loss=0.101, total=4138.23, n_correct=2774.08, ppl=4.27, accuracy=67.035, wps=14501.5, ups=1.75, wpb=8276.5, bsz=314.5, num_updates=26000, lr=8.77058e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=16.6, wall=19702
2023-08-11 21:38:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 21:39:11 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.115 | trans_loss 5.171 | nll_loss 2.433 | w2v_ctc_loss 1.388 | task_loss 0 | contrastive_loss 0.314 | total 4003.4 | n_correct 2657.8 | ppl 5.4 | accuracy 66.389 | uer 18.172 | wer 20.029 | raw_wer 20.029 | bleu 22.19 | wps 2324.9 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 22.19
2023-08-11 21:39:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-08-11 21:39:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-08-11 21:39:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-08-11 21:40:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 22.19) (writing took 48.77243045903742 seconds)
2023-08-11 21:40:59 | INFO | train_inner | epoch 018:   1055 / 1474 loss=2.041, trans_loss=4.871, nll_loss=2.103, w2v_ctc_loss=0.709, task_loss=0, contrastive_loss=0.094, total=4133.59, n_correct=2764.71, ppl=4.3, accuracy=66.884, wps=6373.6, ups=0.77, wpb=8267.2, bsz=298.7, num_updates=26100, lr=8.75376e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=57, gb_free=15.9, wall=19832
2023-08-11 21:41:56 | INFO | train_inner | epoch 018:   1155 / 1474 loss=2.053, trans_loss=4.866, nll_loss=2.096, w2v_ctc_loss=0.714, task_loss=0, contrastive_loss=0.201, total=4154.22, n_correct=2780.57, ppl=4.28, accuracy=66.934, wps=14459.4, ups=1.74, wpb=8308.4, bsz=315.1, num_updates=26200, lr=8.73704e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=57, gb_free=15.1, wall=19890
2023-08-11 21:42:53 | INFO | train_inner | epoch 018:   1255 / 1474 loss=2.043, trans_loss=4.88, nll_loss=2.115, w2v_ctc_loss=0.713, task_loss=0, contrastive_loss=0.089, total=4089.17, n_correct=2727.61, ppl=4.33, accuracy=66.703, wps=14426.4, ups=1.76, wpb=8178.3, bsz=287.6, num_updates=26300, lr=8.72041e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=56, gb_free=16.8, wall=19946
2023-08-11 21:43:50 | INFO | train_inner | epoch 018:   1355 / 1474 loss=2.057, trans_loss=4.882, nll_loss=2.117, w2v_ctc_loss=0.734, task_loss=0, contrastive_loss=0.116, total=4068.84, n_correct=2709.01, ppl=4.34, accuracy=66.579, wps=14232, ups=1.75, wpb=8137.7, bsz=291.4, num_updates=26400, lr=8.70388e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=57, gb_free=15.5, wall=20003
2023-08-11 21:44:48 | INFO | train_inner | epoch 018:   1455 / 1474 loss=2.05, trans_loss=4.879, nll_loss=2.114, w2v_ctc_loss=0.725, task_loss=0, contrastive_loss=0.101, total=4113.23, n_correct=2742.28, ppl=4.33, accuracy=66.67, wps=14348.8, ups=1.74, wpb=8226.5, bsz=297.2, num_updates=26500, lr=8.68744e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=57, gb_free=16.6, wall=20061
2023-08-11 21:44:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 21:45:22 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.108 | trans_loss 5.163 | nll_loss 2.427 | w2v_ctc_loss 1.385 | task_loss 0 | contrastive_loss 0.314 | total 4003.4 | n_correct 2665.3 | ppl 5.38 | accuracy 66.576 | uer 17.888 | wer 19.835 | raw_wer 19.835 | bleu 22.07 | wps 2145.5 | wpb 4003.4 | bsz 141.8 | num_updates 26519 | best_bleu 22.19
2023-08-11 21:45:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26519 updates
2023-08-11 21:45:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.0706.pt
2023-08-11 21:45:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.0706.pt
2023-08-11 21:45:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.0706.pt (epoch 18 @ 26519 updates, score 22.07) (writing took 15.949496628716588 seconds)
2023-08-11 21:45:39 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-11 21:45:39 | INFO | train | epoch 018 | loss 2.048 | trans_loss 4.871 | nll_loss 2.102 | w2v_ctc_loss 0.713 | task_loss 0 | contrastive_loss 0.144 | total 4138.65 | n_correct 2767.57 | ppl 4.29 | accuracy 66.871 | wps 12634.6 | ups 1.53 | wpb 8277.3 | bsz 305.7 | num_updates 26519 | lr 8.68433e-05 | gnorm 0.545 | clip 0 | loss_scale 32 | train_wall 837 | gb_free 16 | wall 20112
2023-08-11 21:45:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 21:45:39 | INFO | fairseq.trainer | begin training epoch 19
2023-08-11 21:45:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 21:46:33 | INFO | train_inner | epoch 019:     81 / 1474 loss=2.038, trans_loss=4.854, nll_loss=2.081, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.151, total=4107.26, n_correct=2759.47, ppl=4.23, accuracy=67.185, wps=7784.7, ups=0.95, wpb=8214.5, bsz=297.5, num_updates=26600, lr=8.6711e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=57, gb_free=13, wall=20166
2023-08-11 21:47:31 | INFO | train_inner | epoch 019:    181 / 1474 loss=2.042, trans_loss=4.853, nll_loss=2.079, w2v_ctc_loss=0.715, task_loss=0, contrastive_loss=0.141, total=4222.18, n_correct=2838.21, ppl=4.23, accuracy=67.221, wps=14583.9, ups=1.73, wpb=8444.4, bsz=324.4, num_updates=26700, lr=8.65485e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=57, gb_free=12, wall=20224
2023-08-11 21:48:29 | INFO | train_inner | epoch 019:    281 / 1474 loss=2.027, trans_loss=4.848, nll_loss=2.073, w2v_ctc_loss=0.702, task_loss=0, contrastive_loss=0.086, total=4187.37, n_correct=2820.01, ppl=4.21, accuracy=67.346, wps=14551.8, ups=1.74, wpb=8374.7, bsz=307, num_updates=26800, lr=8.63868e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=57, gb_free=17.6, wall=20282
2023-08-11 21:49:26 | INFO | train_inner | epoch 019:    381 / 1474 loss=2.041, trans_loss=4.85, nll_loss=2.076, w2v_ctc_loss=0.7, task_loss=0, contrastive_loss=0.192, total=4170.67, n_correct=2802.62, ppl=4.22, accuracy=67.198, wps=14537.2, ups=1.74, wpb=8341.3, bsz=310.5, num_updates=26900, lr=8.62261e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=57, gb_free=17.3, wall=20339
2023-08-11 21:50:23 | INFO | train_inner | epoch 019:    481 / 1474 loss=2.04, trans_loss=4.86, nll_loss=2.088, w2v_ctc_loss=0.718, task_loss=0, contrastive_loss=0.102, total=4115.22, n_correct=2760.67, ppl=4.25, accuracy=67.084, wps=14420.1, ups=1.75, wpb=8230.4, bsz=301.9, num_updates=27000, lr=8.60663e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=57, gb_free=15.2, wall=20396
2023-08-11 21:51:20 | INFO | train_inner | epoch 019:    581 / 1474 loss=2.035, trans_loss=4.851, nll_loss=2.077, w2v_ctc_loss=0.699, task_loss=0, contrastive_loss=0.166, total=4129.22, n_correct=2778.82, ppl=4.22, accuracy=67.296, wps=14441.4, ups=1.75, wpb=8258.4, bsz=306, num_updates=27100, lr=8.59074e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=57, gb_free=15.9, wall=20453
2023-08-11 21:52:18 | INFO | train_inner | epoch 019:    681 / 1474 loss=2.028, trans_loss=4.859, nll_loss=2.087, w2v_ctc_loss=0.692, task_loss=0, contrastive_loss=0.092, total=4197.2, n_correct=2823.89, ppl=4.25, accuracy=67.28, wps=14644.3, ups=1.74, wpb=8394.4, bsz=320.8, num_updates=27200, lr=8.57493e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=57, gb_free=14.8, wall=20511
2023-08-11 21:53:15 | INFO | train_inner | epoch 019:    781 / 1474 loss=2.035, trans_loss=4.856, nll_loss=2.082, w2v_ctc_loss=0.709, task_loss=0, contrastive_loss=0.105, total=4142.6, n_correct=2779.38, ppl=4.24, accuracy=67.093, wps=14418.7, ups=1.74, wpb=8285.2, bsz=305.1, num_updates=27300, lr=8.55921e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=57, gb_free=16.3, wall=20568
2023-08-11 21:54:12 | INFO | train_inner | epoch 019:    881 / 1474 loss=2.038, trans_loss=4.864, nll_loss=2.093, w2v_ctc_loss=0.712, task_loss=0, contrastive_loss=0.09, total=4153.47, n_correct=2783.54, ppl=4.27, accuracy=67.017, wps=14496.1, ups=1.75, wpb=8306.9, bsz=303.1, num_updates=27400, lr=8.54358e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=57, gb_free=16.3, wall=20625
2023-08-11 21:55:10 | INFO | train_inner | epoch 019:    981 / 1474 loss=2.062, trans_loss=4.87, nll_loss=2.102, w2v_ctc_loss=0.705, task_loss=0, contrastive_loss=0.322, total=4101.29, n_correct=2746.08, ppl=4.29, accuracy=66.956, wps=14171.2, ups=1.73, wpb=8202.6, bsz=309.9, num_updates=27500, lr=8.52803e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=57, gb_free=16.7, wall=20683
2023-08-11 21:56:08 | INFO | train_inner | epoch 019:   1081 / 1474 loss=2.039, trans_loss=4.867, nll_loss=2.097, w2v_ctc_loss=0.703, task_loss=0, contrastive_loss=0.131, total=4036.97, n_correct=2704.86, ppl=4.28, accuracy=67.002, wps=14088.7, ups=1.74, wpb=8073.9, bsz=291, num_updates=27600, lr=8.51257e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=14.8, wall=20741
2023-08-11 21:57:06 | INFO | train_inner | epoch 019:   1181 / 1474 loss=2.055, trans_loss=4.868, nll_loss=2.098, w2v_ctc_loss=0.714, task_loss=0, contrastive_loss=0.213, total=4137.49, n_correct=2767.26, ppl=4.28, accuracy=66.883, wps=14216.9, ups=1.72, wpb=8275, bsz=307.7, num_updates=27700, lr=8.49719e-05, gnorm=0.55, clip=0, loss_scale=64, train_wall=58, gb_free=15, wall=20799
2023-08-11 21:58:03 | INFO | train_inner | epoch 019:   1281 / 1474 loss=2.039, trans_loss=4.865, nll_loss=2.096, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.113, total=4141.89, n_correct=2776.42, ppl=4.27, accuracy=67.033, wps=14535.9, ups=1.75, wpb=8283.8, bsz=300.1, num_updates=27800, lr=8.48189e-05, gnorm=0.546, clip=0, loss_scale=64, train_wall=56, gb_free=15.6, wall=20856
2023-08-11 21:59:00 | INFO | train_inner | epoch 019:   1381 / 1474 loss=2.036, trans_loss=4.861, nll_loss=2.09, w2v_ctc_loss=0.709, task_loss=0, contrastive_loss=0.099, total=4133.26, n_correct=2774.84, ppl=4.26, accuracy=67.134, wps=14488.7, ups=1.75, wpb=8266.5, bsz=301, num_updates=27900, lr=8.46668e-05, gnorm=0.544, clip=0, loss_scale=64, train_wall=57, gb_free=16.2, wall=20913
2023-08-11 21:59:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-11 21:59:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 22:00:17 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.091 | trans_loss 5.154 | nll_loss 2.411 | w2v_ctc_loss 1.353 | task_loss 0 | contrastive_loss 0.31 | total 4003.4 | n_correct 2670 | ppl 5.32 | accuracy 66.693 | uer 17.676 | wer 19.496 | raw_wer 19.496 | bleu 22.3 | wps 2134.5 | wpb 4003.4 | bsz 141.8 | num_updates 27992 | best_bleu 22.3
2023-08-11 22:00:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27992 updates
2023-08-11 22:00:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 22:00:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 22:00:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 19 @ 27992 updates, score 22.3) (writing took 28.19795322790742 seconds)
2023-08-11 22:00:46 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-11 22:00:46 | INFO | train | epoch 019 | loss 2.039 | trans_loss 4.858 | nll_loss 2.086 | w2v_ctc_loss 0.706 | task_loss 0 | contrastive_loss 0.142 | total 4138.78 | n_correct 2778.59 | ppl 4.25 | accuracy 67.135 | wps 13445.8 | ups 1.62 | wpb 8277.6 | bsz 305.7 | num_updates 27992 | lr 8.45275e-05 | gnorm 0.546 | clip 0 | loss_scale 32 | train_wall 838 | gb_free 17.4 | wall 21019
2023-08-11 22:00:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 22:00:46 | INFO | fairseq.trainer | begin training epoch 20
2023-08-11 22:00:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 22:00:58 | INFO | train_inner | epoch 020:      8 / 1474 loss=2.037, trans_loss=4.852, nll_loss=2.078, w2v_ctc_loss=0.7, task_loss=0, contrastive_loss=0.18, total=4119.75, n_correct=2770.01, ppl=4.22, accuracy=67.237, wps=6961.5, ups=0.84, wpb=8239.5, bsz=304.1, num_updates=28000, lr=8.45154e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=58, gb_free=17.4, wall=21031
2023-08-11 22:00:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 22:01:22 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.086 | trans_loss 5.159 | nll_loss 2.417 | w2v_ctc_loss 1.325 | task_loss 0 | contrastive_loss 0.31 | total 4003.4 | n_correct 2667.9 | ppl 5.34 | accuracy 66.641 | uer 17.87 | wer 19.858 | raw_wer 19.858 | bleu 22.02 | wps 2109.6 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 22.3
2023-08-11 22:01:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-08-11 22:01:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-08-11 22:01:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-08-11 22:01:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 22.02) (writing took 16.783832604065537 seconds)
2023-08-11 22:02:37 | INFO | train_inner | epoch 020:    108 / 1474 loss=2.016, trans_loss=4.833, nll_loss=2.053, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.103, total=4199.19, n_correct=2844.97, ppl=4.15, accuracy=67.75, wps=8466.5, ups=1.01, wpb=8398.4, bsz=314, num_updates=28100, lr=8.43649e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=57, gb_free=14.9, wall=21131
2023-08-11 22:03:35 | INFO | train_inner | epoch 020:    208 / 1474 loss=2.028, trans_loss=4.841, nll_loss=2.064, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.159, total=4148.29, n_correct=2798.6, ppl=4.18, accuracy=67.464, wps=14504.4, ups=1.75, wpb=8296.6, bsz=300.5, num_updates=28200, lr=8.42152e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=57, gb_free=15.7, wall=21188
2023-08-11 22:04:31 | INFO | train_inner | epoch 020:    308 / 1474 loss=2.019, trans_loss=4.836, nll_loss=2.058, w2v_ctc_loss=0.692, task_loss=0, contrastive_loss=0.093, total=4191.34, n_correct=2836.11, ppl=4.17, accuracy=67.666, wps=14749.3, ups=1.76, wpb=8382.7, bsz=326.2, num_updates=28300, lr=8.40663e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=56, gb_free=15.8, wall=21245
2023-08-11 22:05:29 | INFO | train_inner | epoch 020:    408 / 1474 loss=2.016, trans_loss=4.833, nll_loss=2.053, w2v_ctc_loss=0.688, task_loss=0, contrastive_loss=0.092, total=4114.19, n_correct=2786.24, ppl=4.15, accuracy=67.723, wps=14373.6, ups=1.75, wpb=8228.4, bsz=297.5, num_updates=28400, lr=8.39181e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=57, gb_free=15.4, wall=21302
2023-08-11 22:06:26 | INFO | train_inner | epoch 020:    508 / 1474 loss=2.03, trans_loss=4.847, nll_loss=2.071, w2v_ctc_loss=0.686, task_loss=0, contrastive_loss=0.18, total=4108.2, n_correct=2771.95, ppl=4.2, accuracy=67.474, wps=14246.3, ups=1.73, wpb=8216.4, bsz=299.5, num_updates=28500, lr=8.37708e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=57, gb_free=15.8, wall=21359
2023-08-11 22:07:23 | INFO | train_inner | epoch 020:    608 / 1474 loss=2.037, trans_loss=4.847, nll_loss=2.071, w2v_ctc_loss=0.7, task_loss=0, contrastive_loss=0.182, total=4092.44, n_correct=2756.05, ppl=4.2, accuracy=67.345, wps=14427, ups=1.76, wpb=8184.9, bsz=295.9, num_updates=28600, lr=8.36242e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=56, gb_free=17.6, wall=21416
2023-08-11 22:08:20 | INFO | train_inner | epoch 020:    708 / 1474 loss=2.028, trans_loss=4.849, nll_loss=2.074, w2v_ctc_loss=0.705, task_loss=0, contrastive_loss=0.087, total=4137.06, n_correct=2782.86, ppl=4.21, accuracy=67.267, wps=14559.3, ups=1.76, wpb=8274.1, bsz=300.5, num_updates=28700, lr=8.34784e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=56, gb_free=16.6, wall=21473
2023-08-11 22:09:17 | INFO | train_inner | epoch 020:    808 / 1474 loss=2.027, trans_loss=4.849, nll_loss=2.075, w2v_ctc_loss=0.702, task_loss=0, contrastive_loss=0.091, total=4146.78, n_correct=2792.85, ppl=4.21, accuracy=67.35, wps=14515.5, ups=1.75, wpb=8293.6, bsz=307.3, num_updates=28800, lr=8.33333e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=57, gb_free=15.4, wall=21530
2023-08-11 22:10:15 | INFO | train_inner | epoch 020:    908 / 1474 loss=2.062, trans_loss=4.854, nll_loss=2.082, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.382, total=4161, n_correct=2796.62, ppl=4.23, accuracy=67.21, wps=14272.8, ups=1.72, wpb=8322, bsz=323.2, num_updates=28900, lr=8.3189e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=58, gb_free=17.5, wall=21589
2023-08-11 22:11:12 | INFO | train_inner | epoch 020:   1008 / 1474 loss=2.022, trans_loss=4.847, nll_loss=2.071, w2v_ctc_loss=0.689, task_loss=0, contrastive_loss=0.096, total=4168.14, n_correct=2812.67, ppl=4.2, accuracy=67.48, wps=14647.9, ups=1.76, wpb=8336.3, bsz=307.3, num_updates=29000, lr=8.30455e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=56, gb_free=16.5, wall=21645
2023-08-11 22:12:10 | INFO | train_inner | epoch 020:   1108 / 1474 loss=2.044, trans_loss=4.849, nll_loss=2.075, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.233, total=4166.49, n_correct=2804.21, ppl=4.21, accuracy=67.304, wps=14520.3, ups=1.74, wpb=8333, bsz=315.4, num_updates=29100, lr=8.29027e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=57, gb_free=14.9, wall=21703
2023-08-11 22:13:07 | INFO | train_inner | epoch 020:   1208 / 1474 loss=2.024, trans_loss=4.839, nll_loss=2.061, w2v_ctc_loss=0.707, task_loss=0, contrastive_loss=0.084, total=4029.18, n_correct=2720.12, ppl=4.17, accuracy=67.511, wps=14070.2, ups=1.75, wpb=8058.4, bsz=284, num_updates=29200, lr=8.27606e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=57, gb_free=12.1, wall=21760
2023-08-11 22:14:04 | INFO | train_inner | epoch 020:   1308 / 1474 loss=2.026, trans_loss=4.85, nll_loss=2.075, w2v_ctc_loss=0.698, task_loss=0, contrastive_loss=0.09, total=4123.21, n_correct=2777.91, ppl=4.21, accuracy=67.373, wps=14358.1, ups=1.74, wpb=8246.4, bsz=297.1, num_updates=29300, lr=8.26192e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=57, gb_free=17.4, wall=21818
2023-08-11 22:15:01 | INFO | train_inner | epoch 020:   1408 / 1474 loss=2.029, trans_loss=4.852, nll_loss=2.079, w2v_ctc_loss=0.703, task_loss=0, contrastive_loss=0.088, total=4116.28, n_correct=2769.15, ppl=4.22, accuracy=67.273, wps=14456.7, ups=1.76, wpb=8232.6, bsz=295, num_updates=29400, lr=8.24786e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=56, gb_free=17.5, wall=21874
2023-08-11 22:15:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 22:16:03 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.086 | trans_loss 5.164 | nll_loss 2.424 | w2v_ctc_loss 1.311 | task_loss 0 | contrastive_loss 0.315 | total 4003.4 | n_correct 2669.4 | ppl 5.37 | accuracy 66.678 | uer 17.883 | wer 19.828 | raw_wer 19.828 | bleu 21.98 | wps 2091.1 | wpb 4003.4 | bsz 141.8 | num_updates 29466 | best_bleu 22.3
2023-08-11 22:16:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29466 updates
2023-08-11 22:16:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.9803.pt
2023-08-11 22:16:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.9803.pt
2023-08-11 22:16:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.9803.pt (epoch 20 @ 29466 updates, score 21.98) (writing took 35.45988668501377 seconds)
2023-08-11 22:16:39 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-11 22:16:39 | INFO | train | epoch 020 | loss 2.029 | trans_loss 4.845 | nll_loss 2.069 | w2v_ctc_loss 0.696 | task_loss 0 | contrastive_loss 0.141 | total 4138.65 | n_correct 2791.17 | ppl 4.2 | accuracy 67.442 | wps 12795.8 | ups 1.55 | wpb 8277.3 | bsz 305.7 | num_updates 29466 | lr 8.23862e-05 | gnorm 0.544 | clip 0 | loss_scale 32 | train_wall 836 | gb_free 16.2 | wall 21972
2023-08-11 22:16:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 22:16:39 | INFO | fairseq.trainer | begin training epoch 21
2023-08-11 22:16:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 22:17:07 | INFO | train_inner | epoch 021:     34 / 1474 loss=2.035, trans_loss=4.846, nll_loss=2.071, w2v_ctc_loss=0.692, task_loss=0, contrastive_loss=0.207, total=4152.26, n_correct=2798.37, ppl=4.2, accuracy=67.394, wps=6601, ups=0.79, wpb=8304.5, bsz=316.3, num_updates=29500, lr=8.23387e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=57, gb_free=16.5, wall=22000
2023-08-11 22:18:05 | INFO | train_inner | epoch 021:    134 / 1474 loss=2.023, trans_loss=4.824, nll_loss=2.042, w2v_ctc_loss=0.683, task_loss=0, contrastive_loss=0.197, total=4195.08, n_correct=2846.35, ppl=4.12, accuracy=67.85, wps=14517.1, ups=1.73, wpb=8390.2, bsz=319.6, num_updates=29600, lr=8.21995e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=57, gb_free=17, wall=22058
2023-08-11 22:19:03 | INFO | train_inner | epoch 021:    234 / 1474 loss=2.013, trans_loss=4.826, nll_loss=2.044, w2v_ctc_loss=0.675, task_loss=0, contrastive_loss=0.155, total=4155.31, n_correct=2820.56, ppl=4.12, accuracy=67.878, wps=14336.8, ups=1.73, wpb=8310.6, bsz=312.6, num_updates=29700, lr=8.2061e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=57, gb_free=16.8, wall=22116
2023-08-11 22:20:01 | INFO | train_inner | epoch 021:    334 / 1474 loss=2.027, trans_loss=4.835, nll_loss=2.056, w2v_ctc_loss=0.696, task_loss=0, contrastive_loss=0.156, total=4151.51, n_correct=2804.91, ppl=4.16, accuracy=67.564, wps=14265, ups=1.72, wpb=8303, bsz=310.8, num_updates=29800, lr=8.19232e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=58, gb_free=15.6, wall=22174
2023-08-11 22:20:58 | INFO | train_inner | epoch 021:    434 / 1474 loss=2.007, trans_loss=4.826, nll_loss=2.044, w2v_ctc_loss=0.68, task_loss=0, contrastive_loss=0.081, total=4180.85, n_correct=2840.21, ppl=4.12, accuracy=67.934, wps=14625.1, ups=1.75, wpb=8361.7, bsz=306.8, num_updates=29900, lr=8.17861e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=57, gb_free=15.8, wall=22231
2023-08-11 22:21:56 | INFO | train_inner | epoch 021:    534 / 1474 loss=2.01, trans_loss=4.823, nll_loss=2.04, w2v_ctc_loss=0.689, task_loss=0, contrastive_loss=0.08, total=4083.98, n_correct=2771.84, ppl=4.11, accuracy=67.871, wps=14223.7, ups=1.74, wpb=8168, bsz=295.1, num_updates=30000, lr=8.16497e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=13.3, wall=22289
2023-08-11 22:21:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 22:22:19 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.1 | trans_loss 5.167 | nll_loss 2.428 | w2v_ctc_loss 1.359 | task_loss 0 | contrastive_loss 0.306 | total 4003.4 | n_correct 2665.1 | ppl 5.38 | accuracy 66.571 | uer 17.798 | wer 19.735 | raw_wer 19.735 | bleu 22.05 | wps 2194.3 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 22.3
2023-08-11 22:22:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-08-11 22:22:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_21_30000.pt
2023-08-11 22:22:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_21_30000.pt
2023-08-11 22:22:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 22.05) (writing took 21.96423509530723 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:0')
2023-08-11 22:23:40 | INFO | train_inner | epoch 021:    634 / 1474 loss=2.028, trans_loss=4.829, nll_loss=2.048, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.251, total=4215.41, n_correct=2855.35, ppl=4.14, accuracy=67.736, wps=8104.2, ups=0.96, wpb=8430.8, bsz=315.4, num_updates=30100, lr=8.15139e-05, gnorm=0.543, clip=0, loss_scale=64, train_wall=57, gb_free=11.7, wall=22393
2023-08-11 22:24:37 | INFO | train_inner | epoch 021:    734 / 1474 loss=2.019, trans_loss=4.837, nll_loss=2.059, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.113, total=4152.97, n_correct=2808.65, ppl=4.17, accuracy=67.63, wps=14442.3, ups=1.74, wpb=8305.9, bsz=309.3, num_updates=30200, lr=8.13788e-05, gnorm=0.546, clip=0, loss_scale=64, train_wall=57, gb_free=16.4, wall=22450
2023-08-11 22:25:35 | INFO | train_inner | epoch 021:    834 / 1474 loss=2.027, trans_loss=4.844, nll_loss=2.068, w2v_ctc_loss=0.695, task_loss=0, contrastive_loss=0.125, total=4066.93, n_correct=2746.02, ppl=4.19, accuracy=67.521, wps=14118.2, ups=1.74, wpb=8133.9, bsz=294.4, num_updates=30300, lr=8.12444e-05, gnorm=0.56, clip=0, loss_scale=64, train_wall=57, gb_free=17, wall=22508
2023-08-11 22:26:32 | INFO | train_inner | epoch 021:    934 / 1474 loss=2.014, trans_loss=4.831, nll_loss=2.05, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.097, total=4103.34, n_correct=2776.46, ppl=4.14, accuracy=67.663, wps=14332.9, ups=1.75, wpb=8206.7, bsz=301, num_updates=30400, lr=8.11107e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=57, gb_free=14.2, wall=22565
2023-08-11 22:27:29 | INFO | train_inner | epoch 021:   1034 / 1474 loss=2.018, trans_loss=4.84, nll_loss=2.062, w2v_ctc_loss=0.689, task_loss=0, contrastive_loss=0.095, total=4099.86, n_correct=2772.87, ppl=4.18, accuracy=67.633, wps=14328.4, ups=1.75, wpb=8199.7, bsz=298.8, num_updates=30500, lr=8.09776e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=57, gb_free=11.7, wall=22623
2023-08-11 22:28:27 | INFO | train_inner | epoch 021:   1134 / 1474 loss=2.016, trans_loss=4.831, nll_loss=2.051, w2v_ctc_loss=0.692, task_loss=0, contrastive_loss=0.098, total=4120.75, n_correct=2790.8, ppl=4.14, accuracy=67.726, wps=14371.5, ups=1.74, wpb=8241.5, bsz=293.5, num_updates=30600, lr=8.08452e-05, gnorm=0.543, clip=0, loss_scale=64, train_wall=57, gb_free=15.9, wall=22680
2023-08-11 22:29:24 | INFO | train_inner | epoch 021:   1234 / 1474 loss=2.023, trans_loss=4.836, nll_loss=2.057, w2v_ctc_loss=0.688, task_loss=0, contrastive_loss=0.15, total=4154.73, n_correct=2807.87, ppl=4.16, accuracy=67.582, wps=14468.3, ups=1.74, wpb=8309.5, bsz=311.6, num_updates=30700, lr=8.07134e-05, gnorm=0.541, clip=0, loss_scale=64, train_wall=57, gb_free=12.9, wall=22737
2023-08-11 22:30:22 | INFO | train_inner | epoch 021:   1334 / 1474 loss=2.018, trans_loss=4.834, nll_loss=2.056, w2v_ctc_loss=0.686, task_loss=0, contrastive_loss=0.112, total=4147.17, n_correct=2808.48, ppl=4.16, accuracy=67.72, wps=14402.1, ups=1.74, wpb=8294.3, bsz=311.9, num_updates=30800, lr=8.05823e-05, gnorm=0.539, clip=0, loss_scale=64, train_wall=57, gb_free=16.3, wall=22795
2023-08-11 22:30:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-11 22:31:20 | INFO | train_inner | epoch 021:   1435 / 1474 loss=2.029, trans_loss=4.841, nll_loss=2.064, w2v_ctc_loss=0.709, task_loss=0, contrastive_loss=0.1, total=4115.08, n_correct=2773.11, ppl=4.18, accuracy=67.389, wps=14090.6, ups=1.71, wpb=8230.2, bsz=297.4, num_updates=30900, lr=8.04518e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=58, gb_free=16.6, wall=22853
2023-08-11 22:31:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:7')
2023-08-11 22:32:07 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.089 | trans_loss 5.164 | nll_loss 2.423 | w2v_ctc_loss 1.326 | task_loss 0 | contrastive_loss 0.312 | total 4003.4 | n_correct 2668.1 | ppl 5.36 | accuracy 66.646 | uer 17.689 | wer 19.492 | raw_wer 19.492 | bleu 22.13 | wps 2095.2 | wpb 4003.4 | bsz 141.8 | num_updates 30939 | best_bleu 22.3
2023-08-11 22:32:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30939 updates
2023-08-11 22:32:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.1306.pt
2023-08-11 22:32:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.1306.pt
2023-08-11 22:32:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.1306.pt (epoch 21 @ 30939 updates, score 22.13) (writing took 22.73980451747775 seconds)
2023-08-11 22:32:30 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-11 22:32:30 | INFO | train | epoch 021 | loss 2.02 | trans_loss 4.833 | nll_loss 2.053 | w2v_ctc_loss 0.688 | task_loss 0 | contrastive_loss 0.134 | total 4137.4 | n_correct 2800.59 | ppl 4.15 | accuracy 67.69 | wps 12821.6 | ups 1.55 | wpb 8274.8 | bsz 305.2 | num_updates 30939 | lr 8.04011e-05 | gnorm 0.545 | clip 0 | loss_scale 32 | train_wall 839 | gb_free 15.5 | wall 22923
2023-08-11 22:32:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 22:32:30 | INFO | fairseq.trainer | begin training epoch 22
2023-08-11 22:32:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 22:33:13 | INFO | train_inner | epoch 022:     61 / 1474 loss=2.008, trans_loss=4.82, nll_loss=2.038, w2v_ctc_loss=0.686, task_loss=0, contrastive_loss=0.082, total=4133.81, n_correct=2813.14, ppl=4.11, accuracy=68.052, wps=7345.8, ups=0.89, wpb=8267.6, bsz=300.5, num_updates=31000, lr=8.03219e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=56, gb_free=16.4, wall=22966
2023-08-11 22:34:11 | INFO | train_inner | epoch 022:    161 / 1474 loss=2.017, trans_loss=4.82, nll_loss=2.036, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.16, total=4116.11, n_correct=2795.85, ppl=4.1, accuracy=67.925, wps=14144.7, ups=1.72, wpb=8232.2, bsz=306.9, num_updates=31100, lr=8.01927e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=57, gb_free=16.8, wall=23024
2023-08-11 22:35:09 | INFO | train_inner | epoch 022:    261 / 1474 loss=2.001, trans_loss=4.811, nll_loss=2.025, w2v_ctc_loss=0.671, task_loss=0, contrastive_loss=0.103, total=4272.11, n_correct=2917.29, ppl=4.07, accuracy=68.287, wps=14796.4, ups=1.73, wpb=8544.2, bsz=331.4, num_updates=31200, lr=8.00641e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=57, gb_free=17.9, wall=23082
2023-08-11 22:36:06 | INFO | train_inner | epoch 022:    361 / 1474 loss=2.034, trans_loss=4.827, nll_loss=2.046, w2v_ctc_loss=0.688, task_loss=0, contrastive_loss=0.264, total=4178.4, n_correct=2830.65, ppl=4.13, accuracy=67.745, wps=14467.7, ups=1.73, wpb=8356.8, bsz=310, num_updates=31300, lr=7.99361e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=57, gb_free=15.3, wall=23140
2023-08-11 22:37:04 | INFO | train_inner | epoch 022:    461 / 1474 loss=2.017, trans_loss=4.824, nll_loss=2.042, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.144, total=4132.96, n_correct=2805.01, ppl=4.12, accuracy=67.869, wps=14348.7, ups=1.74, wpb=8265.9, bsz=297.5, num_updates=31400, lr=7.98087e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=17, wall=23197
2023-08-11 22:38:02 | INFO | train_inner | epoch 022:    561 / 1474 loss=2.004, trans_loss=4.816, nll_loss=2.031, w2v_ctc_loss=0.678, task_loss=0, contrastive_loss=0.091, total=4158.17, n_correct=2829.42, ppl=4.09, accuracy=68.045, wps=14345, ups=1.72, wpb=8316.3, bsz=307.8, num_updates=31500, lr=7.96819e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=57, gb_free=16.7, wall=23255
2023-08-11 22:39:00 | INFO | train_inner | epoch 022:    661 / 1474 loss=2.007, trans_loss=4.812, nll_loss=2.026, w2v_ctc_loss=0.668, task_loss=0, contrastive_loss=0.173, total=4139.66, n_correct=2821.91, ppl=4.07, accuracy=68.168, wps=14356.7, ups=1.73, wpb=8279.3, bsz=311.1, num_updates=31600, lr=7.95557e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=57, gb_free=16.2, wall=23313
2023-08-11 22:39:57 | INFO | train_inner | epoch 022:    761 / 1474 loss=2.007, trans_loss=4.817, nll_loss=2.033, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.093, total=4167.89, n_correct=2833.55, ppl=4.09, accuracy=67.985, wps=14550.2, ups=1.75, wpb=8335.8, bsz=303.9, num_updates=31700, lr=7.94301e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=13.1, wall=23370
2023-08-11 22:40:55 | INFO | train_inner | epoch 022:    861 / 1474 loss=2.01, trans_loss=4.828, nll_loss=2.047, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.08, total=4075.79, n_correct=2758.93, ppl=4.13, accuracy=67.691, wps=14135.2, ups=1.73, wpb=8151.6, bsz=289, num_updates=31800, lr=7.93052e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=57, gb_free=16.4, wall=23428
2023-08-11 22:41:52 | INFO | train_inner | epoch 022:    961 / 1474 loss=2.003, trans_loss=4.818, nll_loss=2.033, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.08, total=4134.72, n_correct=2813.22, ppl=4.09, accuracy=68.039, wps=14419.3, ups=1.74, wpb=8269.4, bsz=303.2, num_updates=31900, lr=7.91808e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=57, gb_free=14.4, wall=23485
2023-08-11 22:42:50 | INFO | train_inner | epoch 022:   1061 / 1474 loss=2.017, trans_loss=4.816, nll_loss=2.033, w2v_ctc_loss=0.67, task_loss=0, contrastive_loss=0.251, total=4160.57, n_correct=2830.79, ppl=4.09, accuracy=68.039, wps=14454.5, ups=1.74, wpb=8321.1, bsz=315.5, num_updates=32000, lr=7.90569e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=57, gb_free=17.3, wall=23543
2023-08-11 22:42:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 22:43:12 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.091 | trans_loss 5.163 | nll_loss 2.424 | w2v_ctc_loss 1.332 | task_loss 0 | contrastive_loss 0.312 | total 4003.4 | n_correct 2664.4 | ppl 5.37 | accuracy 66.553 | uer 17.936 | wer 20.014 | raw_wer 20.014 | bleu 21.97 | wps 2318.2 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 22.3
2023-08-11 22:43:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-08-11 22:43:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_22_32000.pt
2023-08-11 22:43:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_22_32000.pt
2023-08-11 22:43:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 21.97) (writing took 38.87873716838658 seconds)
2023-08-11 22:44:50 | INFO | train_inner | epoch 022:   1161 / 1474 loss=2.022, trans_loss=4.838, nll_loss=2.06, w2v_ctc_loss=0.689, task_loss=0, contrastive_loss=0.13, total=4099.59, n_correct=2773.48, ppl=4.17, accuracy=67.653, wps=6826, ups=0.83, wpb=8199.2, bsz=296.2, num_updates=32100, lr=7.89337e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=56, gb_free=15.1, wall=23663
2023-08-11 22:45:47 | INFO | train_inner | epoch 022:   1261 / 1474 loss=2.021, trans_loss=4.836, nll_loss=2.059, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.126, total=4182.05, n_correct=2829.62, ppl=4.17, accuracy=67.661, wps=14670.4, ups=1.75, wpb=8364.1, bsz=323, num_updates=32200, lr=7.8811e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=56, gb_free=15.6, wall=23720
2023-08-11 22:46:45 | INFO | train_inner | epoch 022:   1361 / 1474 loss=2.011, trans_loss=4.82, nll_loss=2.037, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.152, total=4062.31, n_correct=2759.78, ppl=4.1, accuracy=67.936, wps=14073.8, ups=1.73, wpb=8124.6, bsz=299, num_updates=32300, lr=7.86889e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=15.2, wall=23778
2023-08-11 22:47:42 | INFO | train_inner | epoch 022:   1461 / 1474 loss=2.016, trans_loss=4.835, nll_loss=2.056, w2v_ctc_loss=0.692, task_loss=0, contrastive_loss=0.096, total=4081.88, n_correct=2763.32, ppl=4.16, accuracy=67.697, wps=14263.5, ups=1.75, wpb=8163.8, bsz=288.9, num_updates=32400, lr=7.85674e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=57, gb_free=17.3, wall=23835
2023-08-11 22:47:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 22:48:11 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.085 | trans_loss 5.156 | nll_loss 2.414 | w2v_ctc_loss 1.333 | task_loss 0 | contrastive_loss 0.306 | total 4003.4 | n_correct 2673.9 | ppl 5.33 | accuracy 66.791 | uer 17.586 | wer 19.447 | raw_wer 19.447 | bleu 22.16 | wps 2371.3 | wpb 4003.4 | bsz 141.8 | num_updates 32413 | best_bleu 22.3
2023-08-11 22:48:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32413 updates
2023-08-11 22:48:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.1606.pt
2023-08-11 22:48:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.1606.pt
2023-08-11 22:48:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.1606.pt (epoch 22 @ 32413 updates, score 22.16) (writing took 37.06154450774193 seconds)
2023-08-11 22:48:52 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-11 22:48:52 | INFO | train | epoch 022 | loss 2.013 | trans_loss 4.822 | nll_loss 2.04 | w2v_ctc_loss 0.681 | task_loss 0 | contrastive_loss 0.137 | total 4138.65 | n_correct 2811.15 | ppl 4.11 | accuracy 67.924 | wps 12424.6 | ups 1.5 | wpb 8277.3 | bsz 305.7 | num_updates 32413 | lr 7.85517e-05 | gnorm 0.548 | clip 0 | loss_scale 32 | train_wall 839 | gb_free 12 | wall 23905
2023-08-11 22:48:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 22:48:52 | INFO | fairseq.trainer | begin training epoch 23
2023-08-11 22:48:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 22:49:50 | INFO | train_inner | epoch 023:     87 / 1474 loss=2, trans_loss=4.805, nll_loss=2.017, w2v_ctc_loss=0.681, task_loss=0, contrastive_loss=0.086, total=4096.09, n_correct=2795.94, ppl=4.05, accuracy=68.259, wps=6382.9, ups=0.78, wpb=8192.2, bsz=301.2, num_updates=32500, lr=7.84465e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=57, gb_free=16.4, wall=23963
2023-08-11 22:50:47 | INFO | train_inner | epoch 023:    187 / 1474 loss=1.994, trans_loss=4.8, nll_loss=2.01, w2v_ctc_loss=0.669, task_loss=0, contrastive_loss=0.084, total=4107.77, n_correct=2809.02, ppl=4.03, accuracy=68.383, wps=14393.9, ups=1.75, wpb=8215.5, bsz=293.4, num_updates=32600, lr=7.8326e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=57, gb_free=16.4, wall=24020
2023-08-11 22:51:45 | INFO | train_inner | epoch 023:    287 / 1474 loss=2.005, trans_loss=4.812, nll_loss=2.025, w2v_ctc_loss=0.664, task_loss=0, contrastive_loss=0.16, total=4153.12, n_correct=2830.37, ppl=4.07, accuracy=68.15, wps=14249.6, ups=1.72, wpb=8306.2, bsz=306.4, num_updates=32700, lr=7.82062e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=58, gb_free=17, wall=24079
2023-08-11 22:52:43 | INFO | train_inner | epoch 023:    387 / 1474 loss=1.993, trans_loss=4.802, nll_loss=2.012, w2v_ctc_loss=0.669, task_loss=0, contrastive_loss=0.076, total=4116.7, n_correct=2813.21, ppl=4.03, accuracy=68.337, wps=14345.6, ups=1.74, wpb=8233.4, bsz=294, num_updates=32800, lr=7.80869e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=57, gb_free=15.4, wall=24136
2023-08-11 22:53:40 | INFO | train_inner | epoch 023:    487 / 1474 loss=2.004, trans_loss=4.81, nll_loss=2.023, w2v_ctc_loss=0.669, task_loss=0, contrastive_loss=0.132, total=4157.6, n_correct=2835.33, ppl=4.07, accuracy=68.196, wps=14540.7, ups=1.75, wpb=8315.2, bsz=313.5, num_updates=32900, lr=7.79681e-05, gnorm=0.544, clip=0, loss_scale=64, train_wall=57, gb_free=17.3, wall=24193
2023-08-11 22:54:37 | INFO | train_inner | epoch 023:    587 / 1474 loss=1.994, trans_loss=4.801, nll_loss=2.012, w2v_ctc_loss=0.67, task_loss=0, contrastive_loss=0.081, total=4173.42, n_correct=2856.26, ppl=4.03, accuracy=68.439, wps=14706.5, ups=1.76, wpb=8346.8, bsz=316, num_updates=33000, lr=7.78499e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=56, gb_free=12.9, wall=24250
2023-08-11 22:55:34 | INFO | train_inner | epoch 023:    687 / 1474 loss=2.004, trans_loss=4.811, nll_loss=2.025, w2v_ctc_loss=0.674, task_loss=0, contrastive_loss=0.122, total=4137.82, n_correct=2820.68, ppl=4.07, accuracy=68.168, wps=14364.3, ups=1.74, wpb=8275.6, bsz=302.5, num_updates=33100, lr=7.77322e-05, gnorm=0.546, clip=0, loss_scale=64, train_wall=57, gb_free=17.2, wall=24308
2023-08-11 22:56:32 | INFO | train_inner | epoch 023:    787 / 1474 loss=2.005, trans_loss=4.814, nll_loss=2.029, w2v_ctc_loss=0.68, task_loss=0, contrastive_loss=0.101, total=4150.99, n_correct=2828.64, ppl=4.08, accuracy=68.144, wps=14481.7, ups=1.74, wpb=8302, bsz=305.4, num_updates=33200, lr=7.76151e-05, gnorm=0.544, clip=0, loss_scale=64, train_wall=57, gb_free=16.3, wall=24365
2023-08-11 22:57:29 | INFO | train_inner | epoch 023:    887 / 1474 loss=2.007, trans_loss=4.805, nll_loss=2.018, w2v_ctc_loss=0.671, task_loss=0, contrastive_loss=0.179, total=4181.99, n_correct=2855.62, ppl=4.05, accuracy=68.284, wps=14590.5, ups=1.74, wpb=8364, bsz=324.7, num_updates=33300, lr=7.74984e-05, gnorm=0.54, clip=0, loss_scale=64, train_wall=57, gb_free=16.5, wall=24422
2023-08-11 22:58:27 | INFO | train_inner | epoch 023:    987 / 1474 loss=2.021, trans_loss=4.81, nll_loss=2.024, w2v_ctc_loss=0.667, task_loss=0, contrastive_loss=0.334, total=4168.73, n_correct=2840.73, ppl=4.07, accuracy=68.144, wps=14479.3, ups=1.74, wpb=8337.5, bsz=310.5, num_updates=33400, lr=7.73823e-05, gnorm=0.543, clip=0, loss_scale=64, train_wall=57, gb_free=11.3, wall=24480
2023-08-11 22:59:24 | INFO | train_inner | epoch 023:   1087 / 1474 loss=2.006, trans_loss=4.817, nll_loss=2.032, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.089, total=4088.49, n_correct=2781.3, ppl=4.09, accuracy=68.028, wps=14165.4, ups=1.73, wpb=8177, bsz=290, num_updates=33500, lr=7.72667e-05, gnorm=0.552, clip=0, loss_scale=64, train_wall=57, gb_free=15.9, wall=24538
2023-08-11 23:00:22 | INFO | train_inner | epoch 023:   1187 / 1474 loss=2.004, trans_loss=4.819, nll_loss=2.036, w2v_ctc_loss=0.682, task_loss=0, contrastive_loss=0.081, total=4162.7, n_correct=2831.45, ppl=4.1, accuracy=68.02, wps=14443.4, ups=1.73, wpb=8325.4, bsz=309.3, num_updates=33600, lr=7.71517e-05, gnorm=0.543, clip=0, loss_scale=64, train_wall=57, gb_free=16.1, wall=24595
2023-08-11 23:01:19 | INFO | train_inner | epoch 023:   1287 / 1474 loss=1.998, trans_loss=4.811, nll_loss=2.025, w2v_ctc_loss=0.671, task_loss=0, contrastive_loss=0.092, total=4135.53, n_correct=2822.55, ppl=4.07, accuracy=68.251, wps=14502.7, ups=1.75, wpb=8271.1, bsz=308.9, num_updates=33700, lr=7.70371e-05, gnorm=0.546, clip=0, loss_scale=64, train_wall=56, gb_free=16.9, wall=24652
2023-08-11 23:01:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-11 23:02:17 | INFO | train_inner | epoch 023:   1388 / 1474 loss=2.004, trans_loss=4.82, nll_loss=2.037, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.091, total=4132.93, n_correct=2813.51, ppl=4.1, accuracy=68.075, wps=14245.6, ups=1.72, wpb=8265.9, bsz=300.1, num_updates=33800, lr=7.69231e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=16.2, wall=24710
2023-08-11 23:03:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 23:03:29 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.087 | trans_loss 5.154 | nll_loss 2.411 | w2v_ctc_loss 1.346 | task_loss 0 | contrastive_loss 0.311 | total 4003.4 | n_correct 2680.1 | ppl 5.32 | accuracy 66.946 | uer 17.57 | wer 19.399 | raw_wer 19.399 | bleu 22.73 | wps 2276.6 | wpb 4003.4 | bsz 141.8 | num_updates 33886 | best_bleu 22.73
2023-08-11 23:03:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33886 updates
2023-08-11 23:03:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 23:03:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 23:03:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 23 @ 33886 updates, score 22.73) (writing took 28.086654199287295 seconds)
2023-08-11 23:03:58 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-11 23:03:58 | INFO | train | epoch 023 | loss 2.004 | trans_loss 4.811 | nll_loss 2.024 | w2v_ctc_loss 0.673 | task_loss 0 | contrastive_loss 0.13 | total 4137.86 | n_correct 2821.51 | ppl 4.07 | accuracy 68.188 | wps 13450 | ups 1.63 | wpb 8275.7 | bsz 305.3 | num_updates 33886 | lr 7.68254e-05 | gnorm 0.543 | clip 0 | loss_scale 32 | train_wall 838 | gb_free 13.9 | wall 24811
2023-08-11 23:03:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 23:03:58 | INFO | fairseq.trainer | begin training epoch 24
2023-08-11 23:03:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 23:04:14 | INFO | train_inner | epoch 024:     14 / 1474 loss=2.02, trans_loss=4.821, nll_loss=2.038, w2v_ctc_loss=0.672, task_loss=0, contrastive_loss=0.226, total=4084.21, n_correct=2774.54, ppl=4.11, accuracy=67.933, wps=6993.2, ups=0.86, wpb=8168.4, bsz=303.7, num_updates=33900, lr=7.68095e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=57, gb_free=15.5, wall=24827
2023-08-11 23:05:12 | INFO | train_inner | epoch 024:    114 / 1474 loss=2.004, trans_loss=4.791, nll_loss=1.998, w2v_ctc_loss=0.656, task_loss=0, contrastive_loss=0.245, total=4168.61, n_correct=2859.07, ppl=4, accuracy=68.586, wps=14389.3, ups=1.73, wpb=8337.2, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=57, gb_free=11.8, wall=24885
2023-08-11 23:05:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 23:05:34 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.1 | trans_loss 5.159 | nll_loss 2.415 | w2v_ctc_loss 1.375 | task_loss 0 | contrastive_loss 0.311 | total 4003.4 | n_correct 2673.9 | ppl 5.33 | accuracy 66.791 | uer 17.779 | wer 19.731 | raw_wer 19.731 | bleu 22.39 | wps 2361 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 22.73
2023-08-11 23:05:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-08-11 23:05:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_24_34000.pt
2023-08-11 23:05:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_24_34000.pt
2023-08-11 23:05:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 22.39) (writing took 25.405185721814632 seconds)
2023-08-11 23:06:57 | INFO | train_inner | epoch 024:    214 / 1474 loss=2.011, trans_loss=4.797, nll_loss=2.007, w2v_ctc_loss=0.653, task_loss=0, contrastive_loss=0.3, total=4252.53, n_correct=2913.61, ppl=4.02, accuracy=68.515, wps=8066.7, ups=0.95, wpb=8505.1, bsz=341.3, num_updates=34100, lr=7.6584e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=57, gb_free=16.9, wall=24991
2023-08-11 23:07:54 | INFO | train_inner | epoch 024:    314 / 1474 loss=1.99, trans_loss=4.798, nll_loss=2.007, w2v_ctc_loss=0.665, task_loss=0, contrastive_loss=0.078, total=4138.44, n_correct=2833.39, ppl=4.02, accuracy=68.465, wps=14495.3, ups=1.75, wpb=8276.9, bsz=307.1, num_updates=34200, lr=7.64719e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=57, gb_free=15.6, wall=25048
2023-08-11 23:08:53 | INFO | train_inner | epoch 024:    414 / 1474 loss=2.013, trans_loss=4.798, nll_loss=2.008, w2v_ctc_loss=0.675, task_loss=0, contrastive_loss=0.221, total=4153.83, n_correct=2835.98, ppl=4.02, accuracy=68.274, wps=14296.8, ups=1.72, wpb=8307.7, bsz=298.4, num_updates=34300, lr=7.63604e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=57, gb_free=16.2, wall=25106
2023-08-11 23:09:50 | INFO | train_inner | epoch 024:    514 / 1474 loss=1.999, trans_loss=4.797, nll_loss=2.007, w2v_ctc_loss=0.67, task_loss=0, contrastive_loss=0.149, total=4141.88, n_correct=2834.25, ppl=4.02, accuracy=68.429, wps=14323.2, ups=1.73, wpb=8283.8, bsz=302.6, num_updates=34400, lr=7.62493e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=57, gb_free=15.3, wall=25164
2023-08-11 23:10:48 | INFO | train_inner | epoch 024:    614 / 1474 loss=1.993, trans_loss=4.8, nll_loss=2.011, w2v_ctc_loss=0.659, task_loss=0, contrastive_loss=0.108, total=4162.06, n_correct=2844.98, ppl=4.03, accuracy=68.355, wps=14572, ups=1.75, wpb=8324.1, bsz=308.1, num_updates=34500, lr=7.61387e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=56, gb_free=16.8, wall=25221
2023-08-11 23:11:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-11 23:11:45 | INFO | train_inner | epoch 024:    715 / 1474 loss=1.998, trans_loss=4.805, nll_loss=2.017, w2v_ctc_loss=0.667, task_loss=0, contrastive_loss=0.122, total=4097.9, n_correct=2795.13, ppl=4.05, accuracy=68.209, wps=14173.3, ups=1.73, wpb=8195.8, bsz=295.9, num_updates=34600, lr=7.60286e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=57, gb_free=15.8, wall=25279
2023-08-11 23:12:43 | INFO | train_inner | epoch 024:    815 / 1474 loss=1.997, trans_loss=4.808, nll_loss=2.022, w2v_ctc_loss=0.67, task_loss=0, contrastive_loss=0.098, total=4129.03, n_correct=2820.29, ppl=4.06, accuracy=68.304, wps=14279.1, ups=1.73, wpb=8258.1, bsz=307.8, num_updates=34700, lr=7.5919e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=57, gb_free=17.6, wall=25336
2023-08-11 23:13:40 | INFO | train_inner | epoch 024:    915 / 1474 loss=1.996, trans_loss=4.805, nll_loss=2.016, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.073, total=4035.8, n_correct=2749.96, ppl=4.04, accuracy=68.139, wps=14176.3, ups=1.76, wpb=8071.6, bsz=278.8, num_updates=34800, lr=7.58098e-05, gnorm=0.553, clip=0, loss_scale=16, train_wall=56, gb_free=12.6, wall=25393
2023-08-11 23:14:37 | INFO | train_inner | epoch 024:   1015 / 1474 loss=1.991, trans_loss=4.805, nll_loss=2.017, w2v_ctc_loss=0.664, task_loss=0, contrastive_loss=0.078, total=4124.2, n_correct=2819.49, ppl=4.05, accuracy=68.365, wps=14523.4, ups=1.76, wpb=8248.4, bsz=295.7, num_updates=34900, lr=7.57011e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=56, gb_free=13.5, wall=25450
2023-08-11 23:15:34 | INFO | train_inner | epoch 024:   1115 / 1474 loss=1.995, trans_loss=4.792, nll_loss=2.001, w2v_ctc_loss=0.672, task_loss=0, contrastive_loss=0.12, total=4133.96, n_correct=2832.6, ppl=4, accuracy=68.52, wps=14465.8, ups=1.75, wpb=8267.9, bsz=310.6, num_updates=35000, lr=7.55929e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=56, gb_free=16.5, wall=25507
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:0')
2023-08-11 23:16:32 | INFO | train_inner | epoch 024:   1215 / 1474 loss=1.996, trans_loss=4.803, nll_loss=2.015, w2v_ctc_loss=0.664, task_loss=0, contrastive_loss=0.107, total=4152.6, n_correct=2840.11, ppl=4.04, accuracy=68.394, wps=14323.5, ups=1.72, wpb=8305.2, bsz=310.7, num_updates=35100, lr=7.54851e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=57, gb_free=17.4, wall=25565
2023-08-11 23:17:30 | INFO | train_inner | epoch 024:   1315 / 1474 loss=2, trans_loss=4.808, nll_loss=2.021, w2v_ctc_loss=0.681, task_loss=0, contrastive_loss=0.082, total=4108.12, n_correct=2803.41, ppl=4.06, accuracy=68.241, wps=14291.7, ups=1.74, wpb=8216.2, bsz=293.3, num_updates=35200, lr=7.53778e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=57, gb_free=13.3, wall=25623
2023-08-11 23:18:26 | INFO | train_inner | epoch 024:   1415 / 1474 loss=1.998, trans_loss=4.809, nll_loss=2.023, w2v_ctc_loss=0.677, task_loss=0, contrastive_loss=0.08, total=4099.36, n_correct=2797.55, ppl=4.06, accuracy=68.244, wps=14444.7, ups=1.76, wpb=8198.7, bsz=294.7, num_updates=35300, lr=7.5271e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=56, gb_free=15.4, wall=25680
2023-08-11 23:19:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:5')
2023-08-11 23:19:22 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.069 | trans_loss 5.147 | nll_loss 2.402 | w2v_ctc_loss 1.306 | task_loss 0 | contrastive_loss 0.305 | total 4003.4 | n_correct 2683.8 | ppl 5.28 | accuracy 67.038 | uer 17.209 | wer 19.104 | raw_wer 19.104 | bleu 22.73 | wps 2324.6 | wpb 4003.4 | bsz 141.8 | num_updates 35359 | best_bleu 22.73
2023-08-11 23:19:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35359 updates
2023-08-11 23:19:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 23:19:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 23:19:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 24 @ 35359 updates, score 22.73) (writing took 27.262246983125806 seconds)
2023-08-11 23:19:50 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-11 23:19:50 | INFO | train | epoch 024 | loss 1.998 | trans_loss 4.801 | nll_loss 2.012 | w2v_ctc_loss 0.667 | task_loss 0 | contrastive_loss 0.133 | total 4138.57 | n_correct 2829.62 | ppl 4.03 | accuracy 68.372 | wps 12806.1 | ups 1.55 | wpb 8277.1 | bsz 305.7 | num_updates 35359 | lr 7.52082e-05 | gnorm 0.546 | clip 0 | loss_scale 16 | train_wall 837 | gb_free 16.2 | wall 25763
2023-08-11 23:19:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 23:19:50 | INFO | fairseq.trainer | begin training epoch 25
2023-08-11 23:19:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 23:20:21 | INFO | train_inner | epoch 025:     41 / 1474 loss=1.986, trans_loss=4.794, nll_loss=2.003, w2v_ctc_loss=0.661, task_loss=0, contrastive_loss=0.086, total=4161.08, n_correct=2857.65, ppl=4.01, accuracy=68.676, wps=7264.1, ups=0.87, wpb=8322.2, bsz=309.6, num_updates=35400, lr=7.51646e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=57, gb_free=16.6, wall=25794
2023-08-11 23:21:18 | INFO | train_inner | epoch 025:    141 / 1474 loss=1.977, trans_loss=4.779, nll_loss=1.984, w2v_ctc_loss=0.651, task_loss=0, contrastive_loss=0.085, total=4139.23, n_correct=2851.12, ppl=3.95, accuracy=68.88, wps=14411.5, ups=1.74, wpb=8278.5, bsz=309.8, num_updates=35500, lr=7.50587e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=57, gb_free=16.4, wall=25852
2023-08-11 23:22:16 | INFO | train_inner | epoch 025:    241 / 1474 loss=1.984, trans_loss=4.786, nll_loss=1.992, w2v_ctc_loss=0.66, task_loss=0, contrastive_loss=0.087, total=4117.76, n_correct=2827.94, ppl=3.98, accuracy=68.677, wps=14359.4, ups=1.74, wpb=8235.5, bsz=302.9, num_updates=35600, lr=7.49532e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=57, gb_free=17, wall=25909
2023-08-11 23:23:13 | INFO | train_inner | epoch 025:    341 / 1474 loss=1.986, trans_loss=4.786, nll_loss=1.992, w2v_ctc_loss=0.655, task_loss=0, contrastive_loss=0.119, total=4142.17, n_correct=2842.27, ppl=3.98, accuracy=68.618, wps=14491.5, ups=1.75, wpb=8284.3, bsz=295.5, num_updates=35700, lr=7.48481e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=56, gb_free=15.8, wall=25966
2023-08-11 23:24:11 | INFO | train_inner | epoch 025:    441 / 1474 loss=2.006, trans_loss=4.79, nll_loss=1.997, w2v_ctc_loss=0.677, task_loss=0, contrastive_loss=0.198, total=4167.72, n_correct=2853.54, ppl=3.99, accuracy=68.468, wps=14407.7, ups=1.73, wpb=8335.4, bsz=296.8, num_updates=35800, lr=7.47435e-05, gnorm=0.553, clip=0, loss_scale=16, train_wall=57, gb_free=16.9, wall=26024
2023-08-11 23:25:09 | INFO | train_inner | epoch 025:    541 / 1474 loss=1.989, trans_loss=4.797, nll_loss=2.006, w2v_ctc_loss=0.662, task_loss=0, contrastive_loss=0.088, total=4154.79, n_correct=2847.86, ppl=4.02, accuracy=68.544, wps=14359.3, ups=1.73, wpb=8309.6, bsz=313.5, num_updates=35900, lr=7.46393e-05, gnorm=0.553, clip=0, loss_scale=16, train_wall=57, gb_free=17.6, wall=26082
2023-08-11 23:26:06 | INFO | train_inner | epoch 025:    641 / 1474 loss=1.993, trans_loss=4.785, nll_loss=1.992, w2v_ctc_loss=0.666, task_loss=0, contrastive_loss=0.158, total=4156.33, n_correct=2851.14, ppl=3.98, accuracy=68.598, wps=14564, ups=1.75, wpb=8312.7, bsz=309.3, num_updates=36000, lr=7.45356e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=57, gb_free=16.4, wall=26139
2023-08-11 23:26:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 23:26:28 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.082 | trans_loss 5.155 | nll_loss 2.411 | w2v_ctc_loss 1.334 | task_loss 0 | contrastive_loss 0.298 | total 4003.4 | n_correct 2680.2 | ppl 5.32 | accuracy 66.948 | uer 17.124 | wer 19.063 | raw_wer 19.063 | bleu 22.43 | wps 2382.8 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 22.73
2023-08-11 23:26:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-08-11 23:26:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_25_36000.pt
2023-08-11 23:26:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_25_36000.pt
2023-08-11 23:27:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 22.43) (writing took 39.0195202101022 seconds)
2023-08-11 23:28:07 | INFO | train_inner | epoch 025:    741 / 1474 loss=1.994, trans_loss=4.787, nll_loss=1.995, w2v_ctc_loss=0.661, task_loss=0, contrastive_loss=0.151, total=4133.94, n_correct=2836.28, ppl=3.99, accuracy=68.61, wps=6809.7, ups=0.82, wpb=8267.9, bsz=303.3, num_updates=36100, lr=7.44323e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=57, gb_free=15.2, wall=26260
2023-08-11 23:29:05 | INFO | train_inner | epoch 025:    841 / 1474 loss=1.989, trans_loss=4.792, nll_loss=2, w2v_ctc_loss=0.663, task_loss=0, contrastive_loss=0.096, total=4174.24, n_correct=2864.41, ppl=4, accuracy=68.621, wps=14539.1, ups=1.74, wpb=8348.5, bsz=324, num_updates=36200, lr=7.43294e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=57, gb_free=16.4, wall=26318
2023-08-11 23:30:02 | INFO | train_inner | epoch 025:    941 / 1474 loss=1.994, trans_loss=4.792, nll_loss=2.002, w2v_ctc_loss=0.662, task_loss=0, contrastive_loss=0.155, total=4154.13, n_correct=2850.37, ppl=4, accuracy=68.615, wps=14346.5, ups=1.73, wpb=8308.3, bsz=316.7, num_updates=36300, lr=7.4227e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=57, gb_free=11.3, wall=26376
2023-08-11 23:31:00 | INFO | train_inner | epoch 025:   1041 / 1474 loss=2.006, trans_loss=4.8, nll_loss=2.011, w2v_ctc_loss=0.657, task_loss=0, contrastive_loss=0.265, total=4178.3, n_correct=2857, ppl=4.03, accuracy=68.377, wps=14559.5, ups=1.74, wpb=8356.6, bsz=309.7, num_updates=36400, lr=7.41249e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=57, gb_free=16.9, wall=26433
2023-08-11 23:31:56 | INFO | train_inner | epoch 025:   1141 / 1474 loss=1.982, trans_loss=4.792, nll_loss=2, w2v_ctc_loss=0.657, task_loss=0, contrastive_loss=0.071, total=4042.33, n_correct=2771.8, ppl=4, accuracy=68.569, wps=14286.1, ups=1.77, wpb=8084.7, bsz=286.5, num_updates=36500, lr=7.40233e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=56, gb_free=17.8, wall=26490
2023-08-11 23:32:54 | INFO | train_inner | epoch 025:   1241 / 1474 loss=1.988, trans_loss=4.8, nll_loss=2.011, w2v_ctc_loss=0.66, task_loss=0, contrastive_loss=0.082, total=4087.78, n_correct=2796.07, ppl=4.03, accuracy=68.401, wps=14291.9, ups=1.75, wpb=8175.6, bsz=295.1, num_updates=36600, lr=7.39221e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=57, gb_free=17.7, wall=26547
2023-08-11 23:33:52 | INFO | train_inner | epoch 025:   1341 / 1474 loss=1.995, trans_loss=4.792, nll_loss=2.001, w2v_ctc_loss=0.659, task_loss=0, contrastive_loss=0.174, total=4166.64, n_correct=2856.09, ppl=4, accuracy=68.547, wps=14399.1, ups=1.73, wpb=8333.3, bsz=309.3, num_updates=36700, lr=7.38213e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=57, gb_free=16.5, wall=26605
2023-08-11 23:34:49 | INFO | train_inner | epoch 025:   1441 / 1474 loss=2.004, trans_loss=4.808, nll_loss=2.022, w2v_ctc_loss=0.669, task_loss=0, contrastive_loss=0.14, total=4114.64, n_correct=2802.57, ppl=4.06, accuracy=68.112, wps=14361.3, ups=1.75, wpb=8229.3, bsz=304.3, num_updates=36800, lr=7.3721e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=57, gb_free=16.5, wall=26662
2023-08-11 23:35:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 23:35:30 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.078 | trans_loss 5.156 | nll_loss 2.414 | w2v_ctc_loss 1.315 | task_loss 0 | contrastive_loss 0.302 | total 4003.4 | n_correct 2680.1 | ppl 5.33 | accuracy 66.946 | uer 17.302 | wer 19.403 | raw_wer 19.403 | bleu 22.38 | wps 2365.9 | wpb 4003.4 | bsz 141.8 | num_updates 36833 | best_bleu 22.73
2023-08-11 23:35:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36833 updates
2023-08-11 23:35:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.3803.pt
2023-08-11 23:35:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.3803.pt
2023-08-11 23:36:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.3803.pt (epoch 25 @ 36833 updates, score 22.38) (writing took 37.53636967390776 seconds)
2023-08-11 23:36:10 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-11 23:36:10 | INFO | train | epoch 025 | loss 1.992 | trans_loss 4.792 | nll_loss 2 | w2v_ctc_loss 0.661 | task_loss 0 | contrastive_loss 0.131 | total 4138.65 | n_correct 2837.04 | ppl 4 | accuracy 68.55 | wps 12453.5 | ups 1.5 | wpb 8277.3 | bsz 305.7 | num_updates 36833 | lr 7.36879e-05 | gnorm 0.545 | clip 0 | loss_scale 32 | train_wall 838 | gb_free 14.5 | wall 26743
2023-08-11 23:36:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 23:36:10 | INFO | fairseq.trainer | begin training epoch 26
2023-08-11 23:36:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 23:36:56 | INFO | train_inner | epoch 026:     67 / 1474 loss=1.977, trans_loss=4.776, nll_loss=1.979, w2v_ctc_loss=0.648, task_loss=0, contrastive_loss=0.106, total=4172.16, n_correct=2875.75, ppl=3.94, accuracy=68.927, wps=6562.2, ups=0.79, wpb=8344.3, bsz=316.9, num_updates=36900, lr=7.3621e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=57, gb_free=17.1, wall=26789
2023-08-11 23:37:54 | INFO | train_inner | epoch 026:    167 / 1474 loss=1.993, trans_loss=4.777, nll_loss=1.982, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.281, total=4265.22, n_correct=2942.74, ppl=3.95, accuracy=68.994, wps=14727.3, ups=1.73, wpb=8530.4, bsz=338.7, num_updates=37000, lr=7.35215e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=57, gb_free=15.6, wall=26847
2023-08-11 23:38:52 | INFO | train_inner | epoch 026:    267 / 1474 loss=1.989, trans_loss=4.777, nll_loss=1.98, w2v_ctc_loss=0.658, task_loss=0, contrastive_loss=0.171, total=4123.94, n_correct=2836.15, ppl=3.95, accuracy=68.773, wps=14119.5, ups=1.71, wpb=8247.9, bsz=306.6, num_updates=37100, lr=7.34223e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=58, gb_free=16.9, wall=26906
2023-08-11 23:39:49 | INFO | train_inner | epoch 026:    367 / 1474 loss=1.985, trans_loss=4.781, nll_loss=1.986, w2v_ctc_loss=0.654, task_loss=0, contrastive_loss=0.126, total=4168.11, n_correct=2865.17, ppl=3.96, accuracy=68.74, wps=14628.2, ups=1.75, wpb=8336.2, bsz=315.2, num_updates=37200, lr=7.33236e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=56, gb_free=17.3, wall=26963
2023-08-11 23:40:46 | INFO | train_inner | epoch 026:    467 / 1474 loss=1.984, trans_loss=4.768, nll_loss=1.97, w2v_ctc_loss=0.654, task_loss=0, contrastive_loss=0.171, total=4167.53, n_correct=2877.39, ppl=3.92, accuracy=69.043, wps=14609.1, ups=1.75, wpb=8335.1, bsz=314.6, num_updates=37300, lr=7.32252e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=56, gb_free=14.3, wall=27020
2023-08-11 23:41:44 | INFO | train_inner | epoch 026:    567 / 1474 loss=1.985, trans_loss=4.781, nll_loss=1.986, w2v_ctc_loss=0.665, task_loss=0, contrastive_loss=0.093, total=4158.48, n_correct=2857.15, ppl=3.96, accuracy=68.707, wps=14430.5, ups=1.74, wpb=8317, bsz=304.4, num_updates=37400, lr=7.31272e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=13.1, wall=27077
2023-08-11 23:42:42 | INFO | train_inner | epoch 026:    667 / 1474 loss=1.976, trans_loss=4.78, nll_loss=1.984, w2v_ctc_loss=0.648, task_loss=0, contrastive_loss=0.078, total=4129.11, n_correct=2840.05, ppl=3.96, accuracy=68.781, wps=14282.7, ups=1.73, wpb=8258.2, bsz=297.7, num_updates=37500, lr=7.30297e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=57, gb_free=14.1, wall=27135
2023-08-11 23:43:39 | INFO | train_inner | epoch 026:    767 / 1474 loss=1.993, trans_loss=4.785, nll_loss=1.991, w2v_ctc_loss=0.654, task_loss=0, contrastive_loss=0.191, total=4096.84, n_correct=2813.81, ppl=3.97, accuracy=68.682, wps=14416.6, ups=1.76, wpb=8193.7, bsz=300.5, num_updates=37600, lr=7.29325e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=56, gb_free=16.6, wall=27192
2023-08-11 23:44:36 | INFO | train_inner | epoch 026:    867 / 1474 loss=1.984, trans_loss=4.782, nll_loss=1.986, w2v_ctc_loss=0.663, task_loss=0, contrastive_loss=0.092, total=4176.27, n_correct=2870.13, ppl=3.96, accuracy=68.725, wps=14603.3, ups=1.75, wpb=8352.5, bsz=306.4, num_updates=37700, lr=7.28357e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=57, gb_free=16.3, wall=27249
2023-08-11 23:45:34 | INFO | train_inner | epoch 026:    967 / 1474 loss=1.985, trans_loss=4.788, nll_loss=1.995, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.145, total=4141.01, n_correct=2841.55, ppl=3.99, accuracy=68.62, wps=14372.5, ups=1.74, wpb=8282, bsz=299.7, num_updates=37800, lr=7.27393e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=15.6, wall=27307
2023-08-11 23:46:32 | INFO | train_inner | epoch 026:   1067 / 1474 loss=1.979, trans_loss=4.782, nll_loss=1.987, w2v_ctc_loss=0.657, task_loss=0, contrastive_loss=0.078, total=4113.69, n_correct=2831.88, ppl=3.97, accuracy=68.84, wps=14181.5, ups=1.72, wpb=8227.4, bsz=293, num_updates=37900, lr=7.26433e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=57, gb_free=15.6, wall=27365
2023-08-11 23:47:29 | INFO | train_inner | epoch 026:   1167 / 1474 loss=1.988, trans_loss=4.792, nll_loss=2, w2v_ctc_loss=0.657, task_loss=0, contrastive_loss=0.117, total=4116.78, n_correct=2822.55, ppl=4, accuracy=68.562, wps=14395.8, ups=1.75, wpb=8233.6, bsz=299, num_updates=38000, lr=7.25476e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=57, gb_free=16.7, wall=27422
2023-08-11 23:47:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 23:47:51 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.081 | trans_loss 5.153 | nll_loss 2.408 | w2v_ctc_loss 1.34 | task_loss 0 | contrastive_loss 0.295 | total 4003.4 | n_correct 2681.4 | ppl 5.31 | accuracy 66.978 | uer 17.408 | wer 19.321 | raw_wer 19.321 | bleu 22.57 | wps 2294.7 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 22.73
2023-08-11 23:47:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-08-11 23:47:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_26_38000.pt
2023-08-11 23:47:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_26_38000.pt
2023-08-11 23:48:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 22.57) (writing took 41.93655335530639 seconds)
2023-08-11 23:49:32 | INFO | train_inner | epoch 026:   1267 / 1474 loss=1.991, trans_loss=4.799, nll_loss=2.008, w2v_ctc_loss=0.672, task_loss=0, contrastive_loss=0.08, total=4001.06, n_correct=2737.03, ppl=4.02, accuracy=68.408, wps=6488.8, ups=0.81, wpb=8002.1, bsz=280.6, num_updates=38100, lr=7.24524e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=57, gb_free=15.7, wall=27545
2023-08-11 23:50:30 | INFO | train_inner | epoch 026:   1367 / 1474 loss=1.983, trans_loss=4.792, nll_loss=2.001, w2v_ctc_loss=0.65, task_loss=0, contrastive_loss=0.091, total=4157.69, n_correct=2855.06, ppl=4, accuracy=68.669, wps=14302.8, ups=1.72, wpb=8315.4, bsz=310.5, num_updates=38200, lr=7.23575e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=58, gb_free=16.1, wall=27603
2023-08-11 23:51:28 | INFO | train_inner | epoch 026:   1467 / 1474 loss=1.978, trans_loss=4.784, nll_loss=1.991, w2v_ctc_loss=0.649, task_loss=0, contrastive_loss=0.086, total=4158.47, n_correct=2863.64, ppl=3.97, accuracy=68.863, wps=14447.7, ups=1.74, wpb=8316.9, bsz=316.5, num_updates=38300, lr=7.22629e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=57, gb_free=17.4, wall=27661
2023-08-11 23:51:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-11 23:51:55 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.083 | trans_loss 5.153 | nll_loss 2.41 | w2v_ctc_loss 1.343 | task_loss 0 | contrastive_loss 0.301 | total 4003.4 | n_correct 2680.8 | ppl 5.31 | accuracy 66.963 | uer 17.538 | wer 19.533 | raw_wer 19.533 | bleu 22.8 | wps 2175.2 | wpb 4003.4 | bsz 141.8 | num_updates 38307 | best_bleu 22.8
2023-08-11 23:51:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38307 updates
2023-08-11 23:51:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 23:52:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-11 23:52:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 26 @ 38307 updates, score 22.8) (writing took 28.08440009690821 seconds)
2023-08-11 23:52:24 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-11 23:52:24 | INFO | train | epoch 026 | loss 1.985 | trans_loss 4.782 | nll_loss 1.988 | w2v_ctc_loss 0.654 | task_loss 0 | contrastive_loss 0.129 | total 4138.65 | n_correct 2845.8 | ppl 3.97 | accuracy 68.761 | wps 12526.6 | ups 1.51 | wpb 8277.3 | bsz 305.7 | num_updates 38307 | lr 7.22563e-05 | gnorm 0.547 | clip 0 | loss_scale 32 | train_wall 839 | gb_free 16 | wall 27717
2023-08-11 23:52:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-11 23:52:24 | INFO | fairseq.trainer | begin training epoch 27
2023-08-11 23:52:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-11 23:53:25 | INFO | train_inner | epoch 027:     93 / 1474 loss=1.958, trans_loss=4.75, nll_loss=1.945, w2v_ctc_loss=0.636, task_loss=0, contrastive_loss=0.067, total=4067.62, n_correct=2822.49, ppl=3.85, accuracy=69.389, wps=6966.1, ups=0.86, wpb=8135.2, bsz=284.4, num_updates=38400, lr=7.21688e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=56, gb_free=15, wall=27778
2023-08-11 23:54:22 | INFO | train_inner | epoch 027:    193 / 1474 loss=1.969, trans_loss=4.763, nll_loss=1.963, w2v_ctc_loss=0.644, task_loss=0, contrastive_loss=0.093, total=4185.52, n_correct=2894.7, ppl=3.9, accuracy=69.16, wps=14608.4, ups=1.75, wpb=8371, bsz=321.7, num_updates=38500, lr=7.2075e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=57, gb_free=17.7, wall=27835
2023-08-11 23:55:20 | INFO | train_inner | epoch 027:    293 / 1474 loss=1.971, trans_loss=4.769, nll_loss=1.97, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.078, total=4167.92, n_correct=2883.88, ppl=3.92, accuracy=69.192, wps=14370.1, ups=1.72, wpb=8335.8, bsz=306.8, num_updates=38600, lr=7.19816e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=57, gb_free=16.9, wall=27893
2023-08-11 23:56:18 | INFO | train_inner | epoch 027:    393 / 1474 loss=1.993, trans_loss=4.775, nll_loss=1.978, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.262, total=4075.21, n_correct=2805.86, ppl=3.94, accuracy=68.852, wps=14089.4, ups=1.73, wpb=8150.4, bsz=296, num_updates=38700, lr=7.18885e-05, gnorm=0.548, clip=0, loss_scale=64, train_wall=57, gb_free=17.7, wall=27951
2023-08-11 23:57:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-11 23:57:16 | INFO | train_inner | epoch 027:    494 / 1474 loss=1.981, trans_loss=4.78, nll_loss=1.984, w2v_ctc_loss=0.65, task_loss=0, contrastive_loss=0.111, total=4228.43, n_correct=2912.48, ppl=3.96, accuracy=68.879, wps=14581.5, ups=1.72, wpb=8456.9, bsz=325.2, num_updates=38800, lr=7.17958e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=57, gb_free=16.9, wall=28009
2023-08-11 23:58:13 | INFO | train_inner | epoch 027:    594 / 1474 loss=1.982, trans_loss=4.771, nll_loss=1.974, w2v_ctc_loss=0.656, task_loss=0, contrastive_loss=0.135, total=4134.93, n_correct=2852.23, ppl=3.93, accuracy=68.979, wps=14387, ups=1.74, wpb=8269.9, bsz=312, num_updates=38900, lr=7.17035e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=17.6, wall=28066
2023-08-11 23:59:11 | INFO | train_inner | epoch 027:    694 / 1474 loss=1.979, trans_loss=4.774, nll_loss=1.977, w2v_ctc_loss=0.651, task_loss=0, contrastive_loss=0.114, total=4162.17, n_correct=2869.13, ppl=3.94, accuracy=68.934, wps=14429.7, ups=1.73, wpb=8324.3, bsz=305.1, num_updates=39000, lr=7.16115e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=57, gb_free=15.6, wall=28124
2023-08-12 00:00:08 | INFO | train_inner | epoch 027:    794 / 1474 loss=1.976, trans_loss=4.775, nll_loss=1.978, w2v_ctc_loss=0.656, task_loss=0, contrastive_loss=0.079, total=4107.17, n_correct=2828.15, ppl=3.94, accuracy=68.859, wps=14321.6, ups=1.74, wpb=8214.3, bsz=294.3, num_updates=39100, lr=7.15199e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=57, gb_free=11.9, wall=28181
2023-08-12 00:01:05 | INFO | train_inner | epoch 027:    894 / 1474 loss=1.972, trans_loss=4.78, nll_loss=1.984, w2v_ctc_loss=0.644, task_loss=0, contrastive_loss=0.071, total=4101.4, n_correct=2827.35, ppl=3.96, accuracy=68.936, wps=14456, ups=1.76, wpb=8202.8, bsz=292.8, num_updates=39200, lr=7.14286e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=56, gb_free=16.4, wall=28238
2023-08-12 00:02:03 | INFO | train_inner | epoch 027:    994 / 1474 loss=1.993, trans_loss=4.778, nll_loss=1.983, w2v_ctc_loss=0.648, task_loss=0, contrastive_loss=0.258, total=4195.5, n_correct=2886.35, ppl=3.95, accuracy=68.796, wps=14559.8, ups=1.74, wpb=8391, bsz=315.9, num_updates=39300, lr=7.13376e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=57, gb_free=16.8, wall=28296
2023-08-12 00:03:00 | INFO | train_inner | epoch 027:   1094 / 1474 loss=1.971, trans_loss=4.772, nll_loss=1.974, w2v_ctc_loss=0.645, task_loss=0, contrastive_loss=0.087, total=4147.99, n_correct=2861.18, ppl=3.93, accuracy=68.978, wps=14422.6, ups=1.74, wpb=8296, bsz=304.7, num_updates=39400, lr=7.1247e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=57, gb_free=16.2, wall=28353
2023-08-12 00:03:58 | INFO | train_inner | epoch 027:   1194 / 1474 loss=1.981, trans_loss=4.78, nll_loss=1.984, w2v_ctc_loss=0.659, task_loss=0, contrastive_loss=0.093, total=4104.84, n_correct=2823.91, ppl=3.96, accuracy=68.795, wps=14316.6, ups=1.74, wpb=8209.7, bsz=297.2, num_updates=39500, lr=7.11568e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=57, gb_free=12.6, wall=28411
2023-08-12 00:04:54 | INFO | train_inner | epoch 027:   1294 / 1474 loss=1.984, trans_loss=4.78, nll_loss=1.984, w2v_ctc_loss=0.651, task_loss=0, contrastive_loss=0.144, total=4062.86, n_correct=2795.1, ppl=3.96, accuracy=68.796, wps=14271, ups=1.76, wpb=8125.7, bsz=293.6, num_updates=39600, lr=7.10669e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=56, gb_free=16.6, wall=28468
2023-08-12 00:05:51 | INFO | train_inner | epoch 027:   1394 / 1474 loss=1.98, trans_loss=4.779, nll_loss=1.984, w2v_ctc_loss=0.646, task_loss=0, contrastive_loss=0.127, total=4157.6, n_correct=2861.84, ppl=3.96, accuracy=68.834, wps=14619.4, ups=1.76, wpb=8315.2, bsz=314, num_updates=39700, lr=7.09773e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=56, gb_free=17.7, wall=28525
2023-08-12 00:06:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-12 00:07:00 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.081 | trans_loss 5.156 | nll_loss 2.412 | w2v_ctc_loss 1.339 | task_loss 0 | contrastive_loss 0.29 | total 4003.4 | n_correct 2684.5 | ppl 5.32 | accuracy 67.056 | uer 17.386 | wer 19.295 | raw_wer 19.295 | bleu 22.65 | wps 2296.7 | wpb 4003.4 | bsz 141.8 | num_updates 39780 | best_bleu 22.8
2023-08-12 00:07:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39780 updates
2023-08-12 00:07:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.6503.pt
2023-08-12 00:07:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.6503.pt
2023-08-12 00:07:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.6503.pt (epoch 27 @ 39780 updates, score 22.65) (writing took 37.55133216455579 seconds)
2023-08-12 00:07:41 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-12 00:07:41 | INFO | train | epoch 027 | loss 1.977 | trans_loss 4.773 | nll_loss 1.976 | w2v_ctc_loss 0.648 | task_loss 0 | contrastive_loss 0.121 | total 4137.23 | n_correct 2853.22 | ppl 3.93 | accuracy 68.964 | wps 13294.7 | ups 1.61 | wpb 8274.5 | bsz 305.2 | num_updates 39780 | lr 7.09059e-05 | gnorm 0.546 | clip 0 | loss_scale 32 | train_wall 838 | gb_free 17.8 | wall 28634
2023-08-12 00:07:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-12 00:07:41 | INFO | fairseq.trainer | begin training epoch 28
2023-08-12 00:07:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-12 00:08:00 | INFO | train_inner | epoch 028:     20 / 1474 loss=1.966, trans_loss=4.769, nll_loss=1.97, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.078, total=4107.3, n_correct=2839.56, ppl=3.92, accuracy=69.134, wps=6392.7, ups=0.78, wpb=8214.6, bsz=304.5, num_updates=39800, lr=7.08881e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=57, gb_free=17.3, wall=28653
2023-08-12 00:08:57 | INFO | train_inner | epoch 028:    120 / 1474 loss=1.959, trans_loss=4.748, nll_loss=1.942, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.073, total=4112.44, n_correct=2859.45, ppl=3.84, accuracy=69.532, wps=14404.3, ups=1.75, wpb=8224.9, bsz=292.7, num_updates=39900, lr=7.07992e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=57, gb_free=14, wall=28710
2023-08-12 00:09:54 | INFO | train_inner | epoch 028:    220 / 1474 loss=1.961, trans_loss=4.758, nll_loss=1.956, w2v_ctc_loss=0.634, task_loss=0, contrastive_loss=0.083, total=4193.3, n_correct=2908.55, ppl=3.88, accuracy=69.362, wps=14645.2, ups=1.75, wpb=8386.6, bsz=316.4, num_updates=40000, lr=7.07107e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=57, gb_free=17, wall=28767
2023-08-12 00:09:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-12 00:10:17 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.082 | trans_loss 5.159 | nll_loss 2.415 | w2v_ctc_loss 1.332 | task_loss 0 | contrastive_loss 0.29 | total 4003.4 | n_correct 2683.8 | ppl 5.33 | accuracy 67.038 | uer 17.238 | wer 19.227 | raw_wer 19.227 | bleu 22.52 | wps 2202.4 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 22.8
2023-08-12 00:10:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-08-12 00:10:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_28_40000.pt
2023-08-12 00:10:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_28_40000.pt
2023-08-12 00:11:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 22.52) (writing took 46.10312690027058 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:0')
2023-08-12 00:12:05 | INFO | train_inner | epoch 028:    320 / 1474 loss=2.001, trans_loss=4.767, nll_loss=1.968, w2v_ctc_loss=0.633, task_loss=0, contrastive_loss=0.411, total=4138.69, n_correct=2855.59, ppl=3.91, accuracy=68.997, wps=6327, ups=0.76, wpb=8277.4, bsz=314.4, num_updates=40100, lr=7.06225e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=57, gb_free=13.5, wall=28898
2023-08-12 00:13:02 | INFO | train_inner | epoch 028:    420 / 1474 loss=1.966, trans_loss=4.759, nll_loss=1.957, w2v_ctc_loss=0.648, task_loss=0, contrastive_loss=0.07, total=4089.84, n_correct=2833.31, ppl=3.88, accuracy=69.277, wps=14332.6, ups=1.75, wpb=8179.7, bsz=295.7, num_updates=40200, lr=7.05346e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=57, gb_free=16.6, wall=28955
2023-08-12 00:13:59 | INFO | train_inner | epoch 028:    520 / 1474 loss=1.963, trans_loss=4.759, nll_loss=1.957, w2v_ctc_loss=0.638, task_loss=0, contrastive_loss=0.081, total=4098.92, n_correct=2835.92, ppl=3.88, accuracy=69.187, wps=14430, ups=1.76, wpb=8197.8, bsz=295.7, num_updates=40300, lr=7.0447e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=56, gb_free=17, wall=29012
2023-08-12 00:14:56 | INFO | train_inner | epoch 028:    620 / 1474 loss=1.97, trans_loss=4.771, nll_loss=1.972, w2v_ctc_loss=0.645, task_loss=0, contrastive_loss=0.082, total=4180.1, n_correct=2887.53, ppl=3.92, accuracy=69.078, wps=14653, ups=1.75, wpb=8360.2, bsz=305.3, num_updates=40400, lr=7.03598e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=57, gb_free=16.6, wall=29069
2023-08-12 00:15:54 | INFO | train_inner | epoch 028:    720 / 1474 loss=1.981, trans_loss=4.772, nll_loss=1.974, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.19, total=4191.62, n_correct=2896.18, ppl=3.93, accuracy=69.095, wps=14479.2, ups=1.73, wpb=8383.2, bsz=329.2, num_updates=40500, lr=7.02728e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=57, gb_free=17.1, wall=29127
2023-08-12 00:16:51 | INFO | train_inner | epoch 028:    820 / 1474 loss=1.963, trans_loss=4.763, nll_loss=1.963, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.072, total=4088.91, n_correct=2833.4, ppl=3.9, accuracy=69.295, wps=14315.5, ups=1.75, wpb=8177.8, bsz=304.3, num_updates=40600, lr=7.01862e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=57, gb_free=17.1, wall=29184
2023-08-12 00:17:49 | INFO | train_inner | epoch 028:    920 / 1474 loss=1.981, trans_loss=4.772, nll_loss=1.974, w2v_ctc_loss=0.651, task_loss=0, contrastive_loss=0.136, total=4117.01, n_correct=2833.8, ppl=3.93, accuracy=68.832, wps=14249.7, ups=1.73, wpb=8234, bsz=299.7, num_updates=40700, lr=7.01e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=57, gb_free=15.4, wall=29242
2023-08-12 00:18:47 | INFO | train_inner | epoch 028:   1020 / 1474 loss=1.987, trans_loss=4.771, nll_loss=1.972, w2v_ctc_loss=0.652, task_loss=0, contrastive_loss=0.186, total=4182.85, n_correct=2886.02, ppl=3.92, accuracy=68.996, wps=14450.1, ups=1.73, wpb=8365.7, bsz=312, num_updates=40800, lr=7.0014e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=57, gb_free=16.4, wall=29300
2023-08-12 00:19:45 | INFO | train_inner | epoch 028:   1120 / 1474 loss=1.968, trans_loss=4.763, nll_loss=1.963, w2v_ctc_loss=0.64, task_loss=0, contrastive_loss=0.093, total=4220.16, n_correct=2917.31, ppl=3.9, accuracy=69.128, wps=14571.1, ups=1.73, wpb=8440.3, bsz=321, num_updates=40900, lr=6.99284e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=57, gb_free=16, wall=29358
2023-08-12 00:20:42 | INFO | train_inner | epoch 028:   1220 / 1474 loss=1.966, trans_loss=4.768, nll_loss=1.969, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.081, total=4092.46, n_correct=2828.06, ppl=3.92, accuracy=69.104, wps=14244.1, ups=1.74, wpb=8184.9, bsz=303.1, num_updates=41000, lr=6.9843e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=57, gb_free=17.7, wall=29415
2023-08-12 00:21:40 | INFO | train_inner | epoch 028:   1320 / 1474 loss=1.973, trans_loss=4.769, nll_loss=1.969, w2v_ctc_loss=0.651, task_loss=0, contrastive_loss=0.096, total=4084.55, n_correct=2818.16, ppl=3.92, accuracy=68.996, wps=14190.8, ups=1.74, wpb=8169.1, bsz=285.1, num_updates=41100, lr=6.9758e-05, gnorm=0.553, clip=0, loss_scale=64, train_wall=57, gb_free=15.8, wall=29473
2023-08-12 00:22:37 | INFO | train_inner | epoch 028:   1420 / 1474 loss=1.972, trans_loss=4.767, nll_loss=1.967, w2v_ctc_loss=0.64, task_loss=0, contrastive_loss=0.118, total=4154.09, n_correct=2869.02, ppl=3.91, accuracy=69.065, wps=14464.2, ups=1.74, wpb=8308.2, bsz=299.3, num_updates=41200, lr=6.96733e-05, gnorm=0.541, clip=0, loss_scale=64, train_wall=57, gb_free=16.1, wall=29530
2023-08-12 00:23:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-12 00:23:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:3')
2023-08-12 00:23:30 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.072 | trans_loss 5.149 | nll_loss 2.403 | w2v_ctc_loss 1.323 | task_loss 0 | contrastive_loss 0.29 | total 4003.4 | n_correct 2681.1 | ppl 5.29 | accuracy 66.971 | uer 17.185 | wer 19.071 | raw_wer 19.071 | bleu 22.51 | wps 2310.5 | wpb 4003.4 | bsz 141.8 | num_updates 41253 | best_bleu 22.8
2023-08-12 00:23:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41253 updates
2023-08-12 00:23:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.5109.pt
2023-08-12 00:23:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.5109.pt
2023-08-12 00:24:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.5109.pt (epoch 28 @ 41253 updates, score 22.51) (writing took 37.208522368222475 seconds)
2023-08-12 00:24:09 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-12 00:24:09 | INFO | train | epoch 028 | loss 1.972 | trans_loss 4.765 | nll_loss 1.964 | w2v_ctc_loss 0.642 | task_loss 0 | contrastive_loss 0.126 | total 4138.64 | n_correct 2861.51 | ppl 3.9 | accuracy 69.141 | wps 12333.4 | ups 1.49 | wpb 8277.3 | bsz 305.7 | num_updates 41253 | lr 6.96285e-05 | gnorm 0.547 | clip 0 | loss_scale 32 | train_wall 839 | gb_free 16.5 | wall 29623
2023-08-12 00:24:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-12 00:24:10 | INFO | fairseq.trainer | begin training epoch 29
2023-08-12 00:24:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-12 00:24:45 | INFO | train_inner | epoch 029:     47 / 1474 loss=1.965, trans_loss=4.756, nll_loss=1.954, w2v_ctc_loss=0.644, task_loss=0, contrastive_loss=0.091, total=4168.33, n_correct=2890.36, ppl=3.87, accuracy=69.341, wps=6530.4, ups=0.78, wpb=8336.7, bsz=315.9, num_updates=41300, lr=6.95889e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=58, gb_free=16.1, wall=29658
2023-08-12 00:25:42 | INFO | train_inner | epoch 029:    147 / 1474 loss=1.97, trans_loss=4.758, nll_loss=1.956, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.109, total=4110.03, n_correct=2847.51, ppl=3.88, accuracy=69.282, wps=14313.9, ups=1.74, wpb=8220.1, bsz=305.5, num_updates=41400, lr=6.95048e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=57, gb_free=16.6, wall=29715
2023-08-12 00:26:40 | INFO | train_inner | epoch 029:    247 / 1474 loss=1.967, trans_loss=4.747, nll_loss=1.943, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.188, total=4197.89, n_correct=2917.29, ppl=3.84, accuracy=69.494, wps=14606.3, ups=1.74, wpb=8395.8, bsz=329.5, num_updates=41500, lr=6.9421e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=57, gb_free=17.5, wall=29773
2023-08-12 00:27:37 | INFO | train_inner | epoch 029:    347 / 1474 loss=1.968, trans_loss=4.764, nll_loss=1.963, w2v_ctc_loss=0.649, task_loss=0, contrastive_loss=0.077, total=4094.4, n_correct=2832.97, ppl=3.9, accuracy=69.191, wps=14331.9, ups=1.75, wpb=8188.8, bsz=291.2, num_updates=41600, lr=6.93375e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=57, gb_free=16.5, wall=29830
2023-08-12 00:28:34 | INFO | train_inner | epoch 029:    447 / 1474 loss=1.948, trans_loss=4.736, nll_loss=1.928, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.07, total=4157.41, n_correct=2901.61, ppl=3.81, accuracy=69.794, wps=14447.8, ups=1.74, wpb=8314.8, bsz=308.5, num_updates=41700, lr=6.92543e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=57, gb_free=14.9, wall=29888
2023-08-12 00:29:32 | INFO | train_inner | epoch 029:    547 / 1474 loss=1.976, trans_loss=4.764, nll_loss=1.963, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.166, total=4149.27, n_correct=2864.79, ppl=3.9, accuracy=69.043, wps=14437.5, ups=1.74, wpb=8298.5, bsz=293.3, num_updates=41800, lr=6.91714e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=57, gb_free=15.5, wall=29945
2023-08-12 00:30:29 | INFO | train_inner | epoch 029:    647 / 1474 loss=1.974, trans_loss=4.752, nll_loss=1.949, w2v_ctc_loss=0.634, task_loss=0, contrastive_loss=0.234, total=4145.39, n_correct=2876.65, ppl=3.86, accuracy=69.394, wps=14513.1, ups=1.75, wpb=8290.8, bsz=319.3, num_updates=41900, lr=6.90889e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=57, gb_free=17.5, wall=30002
2023-08-12 00:31:27 | INFO | train_inner | epoch 029:    747 / 1474 loss=1.967, trans_loss=4.752, nll_loss=1.948, w2v_ctc_loss=0.634, task_loss=0, contrastive_loss=0.151, total=4242.46, n_correct=2945.81, ppl=3.86, accuracy=69.436, wps=14770.7, ups=1.74, wpb=8484.9, bsz=329.9, num_updates=42000, lr=6.90066e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=57, gb_free=16.6, wall=30060
2023-08-12 00:31:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-12 00:31:51 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.095 | trans_loss 5.164 | nll_loss 2.421 | w2v_ctc_loss 1.365 | task_loss 0 | contrastive_loss 0.292 | total 4003.4 | n_correct 2677.4 | ppl 5.36 | accuracy 66.878 | uer 17.463 | wer 19.224 | raw_wer 19.224 | bleu 22.58 | wps 2311.5 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 22.8
2023-08-12 00:31:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-08-12 00:31:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_29_42000.pt
2023-08-12 00:31:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_29_42000.pt
2023-08-12 00:32:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 22.58) (writing took 42.03064119629562 seconds)
2023-08-12 00:33:31 | INFO | train_inner | epoch 029:    847 / 1474 loss=1.964, trans_loss=4.768, nll_loss=1.968, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.07, total=4027.03, n_correct=2781.27, ppl=3.91, accuracy=69.065, wps=6471.2, ups=0.8, wpb=8054.1, bsz=280.3, num_updates=42100, lr=6.89246e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=57, gb_free=17.4, wall=30184
2023-08-12 00:34:28 | INFO | train_inner | epoch 029:    947 / 1474 loss=1.967, trans_loss=4.763, nll_loss=1.962, w2v_ctc_loss=0.645, task_loss=0, contrastive_loss=0.08, total=4086.72, n_correct=2832.13, ppl=3.9, accuracy=69.301, wps=14342.6, ups=1.75, wpb=8173.4, bsz=296.3, num_updates=42200, lr=6.88428e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=56, gb_free=15.5, wall=30241
2023-08-12 00:35:25 | INFO | train_inner | epoch 029:   1047 / 1474 loss=1.966, trans_loss=4.754, nll_loss=1.951, w2v_ctc_loss=0.632, task_loss=0, contrastive_loss=0.155, total=4139.4, n_correct=2872.7, ppl=3.87, accuracy=69.399, wps=14507, ups=1.75, wpb=8278.8, bsz=307.4, num_updates=42300, lr=6.87614e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=57, gb_free=15.6, wall=30298
2023-08-12 00:36:22 | INFO | train_inner | epoch 029:   1147 / 1474 loss=1.966, trans_loss=4.768, nll_loss=1.968, w2v_ctc_loss=0.645, task_loss=0, contrastive_loss=0.068, total=4072.33, n_correct=2815.69, ppl=3.91, accuracy=69.142, wps=14284, ups=1.75, wpb=8144.7, bsz=284.1, num_updates=42400, lr=6.86803e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=30355
2023-08-12 00:37:20 | INFO | train_inner | epoch 029:   1247 / 1474 loss=1.966, trans_loss=4.765, nll_loss=1.965, w2v_ctc_loss=0.644, task_loss=0, contrastive_loss=0.075, total=4160.52, n_correct=2876.55, ppl=3.9, accuracy=69.139, wps=14453.9, ups=1.74, wpb=8321, bsz=301.5, num_updates=42500, lr=6.85994e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=57, gb_free=15.7, wall=30413
2023-08-12 00:38:17 | INFO | train_inner | epoch 029:   1347 / 1474 loss=1.962, trans_loss=4.751, nll_loss=1.947, w2v_ctc_loss=0.628, task_loss=0, contrastive_loss=0.135, total=4168.02, n_correct=2893.99, ppl=3.86, accuracy=69.433, wps=14534.5, ups=1.74, wpb=8336, bsz=310.2, num_updates=42600, lr=6.85189e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=57, gb_free=16.6, wall=30470
2023-08-12 00:39:14 | INFO | train_inner | epoch 029:   1447 / 1474 loss=1.972, trans_loss=4.756, nll_loss=1.954, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.166, total=4166.06, n_correct=2886.83, ppl=3.87, accuracy=69.294, wps=14561.2, ups=1.75, wpb=8332.1, bsz=313.1, num_updates=42700, lr=6.84386e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=57, gb_free=16.9, wall=30527
2023-08-12 00:39:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-12 00:39:52 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.09 | trans_loss 5.155 | nll_loss 2.409 | w2v_ctc_loss 1.367 | task_loss 0 | contrastive_loss 0.296 | total 4003.4 | n_correct 2683 | ppl 5.31 | accuracy 67.018 | uer 17.315 | wer 19.19 | raw_wer 19.19 | bleu 22.7 | wps 2331.2 | wpb 4003.4 | bsz 141.8 | num_updates 42727 | best_bleu 22.8
2023-08-12 00:39:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42727 updates
2023-08-12 00:39:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.7001.pt
2023-08-12 00:39:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.7001.pt
2023-08-12 00:40:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.7001.pt (epoch 29 @ 42727 updates, score 22.7) (writing took 20.167314464226365 seconds)
2023-08-12 00:40:12 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-12 00:40:12 | INFO | train | epoch 029 | loss 1.966 | trans_loss 4.756 | nll_loss 1.954 | w2v_ctc_loss 0.637 | task_loss 0 | contrastive_loss 0.124 | total 4138.65 | n_correct 2869.37 | ppl 3.87 | accuracy 69.331 | wps 12670.3 | ups 1.53 | wpb 8277.3 | bsz 305.7 | num_updates 42727 | lr 6.8417e-05 | gnorm 0.549 | clip 0 | loss_scale 32 | train_wall 837 | gb_free 16.1 | wall 30585
2023-08-12 00:40:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-12 00:40:13 | INFO | fairseq.trainer | begin training epoch 30
2023-08-12 00:40:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-12 00:41:03 | INFO | train_inner | epoch 030:     73 / 1474 loss=1.963, trans_loss=4.744, nll_loss=1.938, w2v_ctc_loss=0.623, task_loss=0, contrastive_loss=0.184, total=4175.11, n_correct=2906.58, ppl=3.83, accuracy=69.617, wps=7668.1, ups=0.92, wpb=8350.2, bsz=318.6, num_updates=42800, lr=6.83586e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=57, gb_free=17.1, wall=30636
2023-08-12 00:42:01 | INFO | train_inner | epoch 030:    173 / 1474 loss=1.954, trans_loss=4.731, nll_loss=1.921, w2v_ctc_loss=0.63, task_loss=0, contrastive_loss=0.115, total=4202.64, n_correct=2937.54, ppl=3.79, accuracy=69.897, wps=14617.7, ups=1.74, wpb=8405.3, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=57, gb_free=16.7, wall=30694
2023-08-12 00:42:57 | INFO | train_inner | epoch 030:    273 / 1474 loss=1.957, trans_loss=4.749, nll_loss=1.943, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.07, total=4120.21, n_correct=2865.99, ppl=3.85, accuracy=69.559, wps=14488.5, ups=1.76, wpb=8240.4, bsz=294.9, num_updates=43000, lr=6.81994e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=56, gb_free=15.4, wall=30751
2023-08-12 00:43:55 | INFO | train_inner | epoch 030:    373 / 1474 loss=1.947, trans_loss=4.736, nll_loss=1.927, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.072, total=4178.23, n_correct=2919.43, ppl=3.8, accuracy=69.872, wps=14542, ups=1.74, wpb=8356.5, bsz=307.5, num_updates=43100, lr=6.81203e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=57, gb_free=10.5, wall=30808
2023-08-12 00:44:52 | INFO | train_inner | epoch 030:    473 / 1474 loss=1.956, trans_loss=4.743, nll_loss=1.937, w2v_ctc_loss=0.623, task_loss=0, contrastive_loss=0.134, total=4124.47, n_correct=2874.88, ppl=3.83, accuracy=69.703, wps=14483.7, ups=1.76, wpb=8248.9, bsz=312.6, num_updates=43200, lr=6.80414e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=56, gb_free=17.6, wall=30865
2023-08-12 00:45:50 | INFO | train_inner | epoch 030:    573 / 1474 loss=1.96, trans_loss=4.749, nll_loss=1.944, w2v_ctc_loss=0.635, task_loss=0, contrastive_loss=0.097, total=4168.41, n_correct=2896.33, ppl=3.85, accuracy=69.483, wps=14409.8, ups=1.73, wpb=8336.8, bsz=312.4, num_updates=43300, lr=6.79628e-05, gnorm=0.55, clip=0, loss_scale=64, train_wall=57, gb_free=17.3, wall=30923
2023-08-12 00:46:47 | INFO | train_inner | epoch 030:    673 / 1474 loss=1.966, trans_loss=4.751, nll_loss=1.946, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.11, total=4187.95, n_correct=2902.92, ppl=3.85, accuracy=69.316, wps=14615.1, ups=1.74, wpb=8375.9, bsz=315, num_updates=43400, lr=6.78844e-05, gnorm=0.555, clip=0, loss_scale=64, train_wall=57, gb_free=15.9, wall=30980
2023-08-12 00:47:44 | INFO | train_inner | epoch 030:    773 / 1474 loss=1.977, trans_loss=4.756, nll_loss=1.952, w2v_ctc_loss=0.643, task_loss=0, contrastive_loss=0.189, total=4105.32, n_correct=2844.24, ppl=3.87, accuracy=69.282, wps=14357, ups=1.75, wpb=8210.6, bsz=302.6, num_updates=43500, lr=6.78064e-05, gnorm=0.553, clip=0, loss_scale=64, train_wall=57, gb_free=13.2, wall=31037
2023-08-12 00:48:42 | INFO | train_inner | epoch 030:    873 / 1474 loss=1.962, trans_loss=4.754, nll_loss=1.951, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.084, total=4102.11, n_correct=2848.15, ppl=3.87, accuracy=69.431, wps=14321.4, ups=1.75, wpb=8204.2, bsz=295.6, num_updates=43600, lr=6.77285e-05, gnorm=0.556, clip=0, loss_scale=64, train_wall=57, gb_free=17.5, wall=31095
2023-08-12 00:49:39 | INFO | train_inner | epoch 030:    973 / 1474 loss=1.963, trans_loss=4.755, nll_loss=1.952, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.085, total=4129.98, n_correct=2863.77, ppl=3.87, accuracy=69.341, wps=14389.8, ups=1.74, wpb=8260, bsz=300.4, num_updates=43700, lr=6.7651e-05, gnorm=0.549, clip=0, loss_scale=64, train_wall=57, gb_free=16.4, wall=31152
2023-08-12 00:50:36 | INFO | train_inner | epoch 030:   1073 / 1474 loss=1.969, trans_loss=4.757, nll_loss=1.953, w2v_ctc_loss=0.636, task_loss=0, contrastive_loss=0.163, total=4101.17, n_correct=2840.27, ppl=3.87, accuracy=69.255, wps=14265.2, ups=1.74, wpb=8202.3, bsz=282.3, num_updates=43800, lr=6.75737e-05, gnorm=0.546, clip=0, loss_scale=64, train_wall=57, gb_free=15.7, wall=31210
2023-08-12 00:51:34 | INFO | train_inner | epoch 030:   1173 / 1474 loss=1.96, trans_loss=4.748, nll_loss=1.943, w2v_ctc_loss=0.623, task_loss=0, contrastive_loss=0.143, total=4168.36, n_correct=2897.53, ppl=3.85, accuracy=69.512, wps=14561.2, ups=1.75, wpb=8336.7, bsz=314, num_updates=43900, lr=6.74967e-05, gnorm=0.546, clip=0, loss_scale=64, train_wall=57, gb_free=16, wall=31267
2023-08-12 00:52:31 | INFO | train_inner | epoch 030:   1273 / 1474 loss=1.963, trans_loss=4.755, nll_loss=1.951, w2v_ctc_loss=0.643, task_loss=0, contrastive_loss=0.077, total=4036.17, n_correct=2795.52, ppl=3.87, accuracy=69.262, wps=14023.9, ups=1.74, wpb=8072.3, bsz=284.3, num_updates=44000, lr=6.742e-05, gnorm=0.552, clip=0, loss_scale=64, train_wall=57, gb_free=15.8, wall=31325
2023-08-12 00:52:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-12 00:52:53 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.081 | trans_loss 5.155 | nll_loss 2.411 | w2v_ctc_loss 1.334 | task_loss 0 | contrastive_loss 0.298 | total 4003.4 | n_correct 2687.8 | ppl 5.32 | accuracy 67.138 | uer 17.413 | wer 19.216 | raw_wer 19.216 | bleu 22.54 | wps 2405.7 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 22.8
2023-08-12 00:52:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-08-12 00:52:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_30_44000.pt
2023-08-12 00:52:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_30_44000.pt
2023-08-12 00:53:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 22.54) (writing took 40.07976042293012 seconds)
2023-08-12 00:54:35 | INFO | train_inner | epoch 030:   1373 / 1474 loss=1.957, trans_loss=4.75, nll_loss=1.947, w2v_ctc_loss=0.631, task_loss=0, contrastive_loss=0.086, total=4165.07, n_correct=2896.98, ppl=3.85, accuracy=69.554, wps=6748.8, ups=0.81, wpb=8330.1, bsz=321.6, num_updates=44100, lr=6.73435e-05, gnorm=0.549, clip=0, loss_scale=64, train_wall=57, gb_free=16.7, wall=31448
2023-08-12 00:55:32 | INFO | train_inner | epoch 030:   1473 / 1474 loss=1.967, trans_loss=4.752, nll_loss=1.948, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.233, total=4141.76, n_correct=2876.29, ppl=3.86, accuracy=69.446, wps=14450.2, ups=1.74, wpb=8283.5, bsz=314.3, num_updates=44200, lr=6.72673e-05, gnorm=0.548, clip=0, loss_scale=64, train_wall=57, gb_free=16.4, wall=31505
2023-08-12 00:55:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-12 00:55:55 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.08 | trans_loss 5.155 | nll_loss 2.41 | w2v_ctc_loss 1.332 | task_loss 0 | contrastive_loss 0.295 | total 4003.4 | n_correct 2682 | ppl 5.32 | accuracy 66.993 | uer 17.386 | wer 19.324 | raw_wer 19.324 | bleu 22.44 | wps 2368.1 | wpb 4003.4 | bsz 141.8 | num_updates 44201 | best_bleu 22.8
2023-08-12 00:55:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44201 updates
2023-08-12 00:55:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-12 00:56:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-12 00:56:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_last.pt (epoch 30 @ 44201 updates, score 22.44) (writing took 14.11964270286262 seconds)
2023-08-12 00:56:09 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-12 00:56:09 | INFO | train | epoch 030 | loss 1.961 | trans_loss 4.749 | nll_loss 1.944 | w2v_ctc_loss 0.633 | task_loss 0 | contrastive_loss 0.124 | total 4138.65 | n_correct 2876.42 | ppl 3.85 | accuracy 69.501 | wps 12757.5 | ups 1.54 | wpb 8277.3 | bsz 305.7 | num_updates 44201 | lr 6.72665e-05 | gnorm 0.548 | clip 0 | loss_scale 64 | train_wall 837 | gb_free 17.2 | wall 31542
2023-08-12 00:56:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-12 00:56:09 | INFO | fairseq.trainer | begin training epoch 31
2023-08-12 00:56:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-12 00:57:14 | INFO | train_inner | epoch 031:     99 / 1474 loss=1.95, trans_loss=4.737, nll_loss=1.928, w2v_ctc_loss=0.63, task_loss=0, contrastive_loss=0.071, total=4054.44, n_correct=2827.55, ppl=3.81, accuracy=69.74, wps=7970.8, ups=0.98, wpb=8108.9, bsz=288.2, num_updates=44300, lr=6.71913e-05, gnorm=0.553, clip=0, loss_scale=64, train_wall=57, gb_free=16.5, wall=31607
2023-08-12 00:57:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-12 00:58:12 | INFO | train_inner | epoch 031:    200 / 1474 loss=1.946, trans_loss=4.735, nll_loss=1.926, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.077, total=4137.96, n_correct=2888.28, ppl=3.8, accuracy=69.8, wps=14251.4, ups=1.72, wpb=8275.9, bsz=299.1, num_updates=44400, lr=6.71156e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=57, gb_free=12.2, wall=31665
2023-08-12 00:59:10 | INFO | train_inner | epoch 031:    300 / 1474 loss=1.955, trans_loss=4.734, nll_loss=1.924, w2v_ctc_loss=0.626, task_loss=0, contrastive_loss=0.136, total=4148.01, n_correct=2894.34, ppl=3.8, accuracy=69.777, wps=14379.1, ups=1.73, wpb=8296, bsz=301.1, num_updates=44500, lr=6.70402e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=57, gb_free=13.6, wall=31723
2023-08-12 01:00:07 | INFO | train_inner | epoch 031:    400 / 1474 loss=1.95, trans_loss=4.745, nll_loss=1.938, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.076, total=4095.42, n_correct=2850.42, ppl=3.83, accuracy=69.6, wps=14242.2, ups=1.74, wpb=8190.8, bsz=286.3, num_updates=44600, lr=6.6965e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=57, gb_free=13.6, wall=31780
2023-08-12 01:01:04 | INFO | train_inner | epoch 031:    500 / 1474 loss=1.953, trans_loss=4.738, nll_loss=1.929, w2v_ctc_loss=0.635, task_loss=0, contrastive_loss=0.083, total=4115.61, n_correct=2866.85, ppl=3.81, accuracy=69.658, wps=14400.7, ups=1.75, wpb=8231.2, bsz=300.6, num_updates=44700, lr=6.689e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=56, gb_free=16.4, wall=31837
2023-08-12 01:02:02 | INFO | train_inner | epoch 031:    600 / 1474 loss=1.951, trans_loss=4.74, nll_loss=1.932, w2v_ctc_loss=0.628, task_loss=0, contrastive_loss=0.072, total=4075.9, n_correct=2840.18, ppl=3.81, accuracy=69.682, wps=14192.3, ups=1.74, wpb=8151.8, bsz=293.3, num_updates=44800, lr=6.68153e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=57, gb_free=12.2, wall=31895
2023-08-12 01:02:59 | INFO | train_inner | epoch 031:    700 / 1474 loss=1.946, trans_loss=4.735, nll_loss=1.926, w2v_ctc_loss=0.621, task_loss=0, contrastive_loss=0.075, total=4208.99, n_correct=2939.22, ppl=3.8, accuracy=69.832, wps=14594.1, ups=1.73, wpb=8418, bsz=315.1, num_updates=44900, lr=6.67409e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=57, gb_free=17.8, wall=31953
2023-08-12 01:03:57 | INFO | train_inner | epoch 031:    800 / 1474 loss=1.962, trans_loss=4.746, nll_loss=1.94, w2v_ctc_loss=0.628, task_loss=0, contrastive_loss=0.144, total=4104.19, n_correct=2850.27, ppl=3.84, accuracy=69.448, wps=14177.3, ups=1.73, wpb=8208.4, bsz=297.4, num_updates=45000, lr=6.66667e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=57, gb_free=15.4, wall=32010
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:0')
2023-08-12 01:04:55 | INFO | train_inner | epoch 031:    900 / 1474 loss=1.95, trans_loss=4.733, nll_loss=1.923, w2v_ctc_loss=0.63, task_loss=0, contrastive_loss=0.09, total=4099.13, n_correct=2861.74, ppl=3.79, accuracy=69.813, wps=14233.7, ups=1.74, wpb=8198.3, bsz=294.3, num_updates=45100, lr=6.65927e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=57, gb_free=15.3, wall=32068
2023-08-12 01:05:52 | INFO | train_inner | epoch 031:   1000 / 1474 loss=1.963, trans_loss=4.746, nll_loss=1.941, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.171, total=4186.81, n_correct=2914.6, ppl=3.84, accuracy=69.614, wps=14615.8, ups=1.75, wpb=8373.6, bsz=320.9, num_updates=45200, lr=6.6519e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=13.6, wall=32125
2023-08-12 01:06:50 | INFO | train_inner | epoch 031:   1100 / 1474 loss=1.958, trans_loss=4.742, nll_loss=1.935, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.119, total=4149.25, n_correct=2890.69, ppl=3.82, accuracy=69.668, wps=14409.5, ups=1.74, wpb=8298.5, bsz=315.2, num_updates=45300, lr=6.64455e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=57, gb_free=16, wall=32183
2023-08-12 01:07:47 | INFO | train_inner | epoch 031:   1200 / 1474 loss=1.965, trans_loss=4.743, nll_loss=1.937, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.238, total=4187.45, n_correct=2915.94, ppl=3.83, accuracy=69.635, wps=14573.3, ups=1.74, wpb=8374.9, bsz=320.3, num_updates=45400, lr=6.63723e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=57, gb_free=17.1, wall=32240
2023-08-12 01:08:44 | INFO | train_inner | epoch 031:   1300 / 1474 loss=1.957, trans_loss=4.75, nll_loss=1.947, w2v_ctc_loss=0.631, task_loss=0, contrastive_loss=0.08, total=4227.39, n_correct=2939.6, ppl=3.86, accuracy=69.537, wps=14821.7, ups=1.75, wpb=8454.8, bsz=326.7, num_updates=45500, lr=6.62994e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=56, gb_free=17, wall=32298
2023-08-12 01:09:43 | INFO | train_inner | epoch 031:   1400 / 1474 loss=1.979, trans_loss=4.745, nll_loss=1.94, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.288, total=4191.1, n_correct=2915.22, ppl=3.84, accuracy=69.557, wps=14406.3, ups=1.72, wpb=8382.2, bsz=327, num_updates=45600, lr=6.62266e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=58, gb_free=16.6, wall=32356
2023-08-12 01:10:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2554, device='cuda:6')
2023-08-12 01:10:48 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.085 | trans_loss 5.154 | nll_loss 2.408 | w2v_ctc_loss 1.357 | task_loss 0 | contrastive_loss 0.293 | total 4003.4 | n_correct 2683.7 | ppl 5.31 | accuracy 67.036 | uer 16.994 | wer 18.888 | raw_wer 18.888 | bleu 22.64 | wps 2260.3 | wpb 4003.4 | bsz 141.8 | num_updates 45674 | best_bleu 22.8
2023-08-12 01:10:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45674 updates
2023-08-12 01:10:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.6407.pt
2023-08-12 01:10:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.6407.pt
2023-08-12 01:11:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_22.6407.pt (epoch 31 @ 45674 updates, score 22.64) (writing took 37.80249509960413 seconds)
2023-08-12 01:11:26 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-12 01:11:26 | INFO | train | epoch 031 | loss 1.956 | trans_loss 4.741 | nll_loss 1.933 | w2v_ctc_loss 0.627 | task_loss 0 | contrastive_loss 0.122 | total 4137.95 | n_correct 2882.79 | ppl 3.82 | accuracy 69.667 | wps 13289 | ups 1.61 | wpb 8275.9 | bsz 305.4 | num_updates 45674 | lr 6.61729e-05 | gnorm 0.55 | clip 0 | loss_scale 32 | train_wall 838 | gb_free 12.4 | wall 32459
2023-08-12 01:11:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-12 01:11:26 | INFO | fairseq.trainer | begin training epoch 32
2023-08-12 01:11:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-12 01:11:49 | INFO | train_inner | epoch 032:     26 / 1474 loss=1.949, trans_loss=4.737, nll_loss=1.928, w2v_ctc_loss=0.631, task_loss=0, contrastive_loss=0.07, total=4040.88, n_correct=2819.15, ppl=3.81, accuracy=69.766, wps=6402, ups=0.79, wpb=8081.8, bsz=288.7, num_updates=45700, lr=6.61541e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=57, gb_free=15.7, wall=32482
2023-08-12 01:12:46 | INFO | train_inner | epoch 032:    126 / 1474 loss=1.934, trans_loss=4.716, nll_loss=1.902, w2v_ctc_loss=0.607, task_loss=0, contrastive_loss=0.079, total=4222.14, n_correct=2963.63, ppl=3.74, accuracy=70.193, wps=14720, ups=1.74, wpb=8444.3, bsz=322.6, num_updates=45800, lr=6.60819e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=57, gb_free=15.6, wall=32539
2023-08-12 01:13:44 | INFO | train_inner | epoch 032:    226 / 1474 loss=1.947, trans_loss=4.734, nll_loss=1.924, w2v_ctc_loss=0.623, task_loss=0, contrastive_loss=0.087, total=4159.77, n_correct=2904.58, ppl=3.8, accuracy=69.825, wps=14410.5, ups=1.73, wpb=8319.5, bsz=320.8, num_updates=45900, lr=6.60098e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=16.3, wall=32597
2023-08-12 01:14:41 | INFO | train_inner | epoch 032:    326 / 1474 loss=1.938, trans_loss=4.72, nll_loss=1.907, w2v_ctc_loss=0.612, task_loss=0, contrastive_loss=0.082, total=4179.65, n_correct=2930.49, ppl=3.75, accuracy=70.113, wps=14535.4, ups=1.74, wpb=8359.3, bsz=313.8, num_updates=46000, lr=6.5938e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=57, gb_free=16.4, wall=32655
2023-08-12 01:14:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-12 01:15:04 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.096 | trans_loss 5.163 | nll_loss 2.419 | w2v_ctc_loss 1.369 | task_loss 0 | contrastive_loss 0.296 | total 4003.4 | n_correct 2678.7 | ppl 5.35 | accuracy 66.911 | uer 17.14 | wer 19.034 | raw_wer 19.034 | bleu 22.8 | wps 2264.6 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 22.8
2023-08-12 01:15:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-08-12 01:15:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_32_46000.pt
2023-08-12 01:15:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_32_46000.pt
2023-08-12 01:15:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 22.8) (writing took 43.606300530955195 seconds)
2023-08-12 01:16:46 | INFO | train_inner | epoch 032:    426 / 1474 loss=1.943, trans_loss=4.724, nll_loss=1.912, w2v_ctc_loss=0.622, task_loss=0, contrastive_loss=0.08, total=4172.34, n_correct=2920.23, ppl=3.76, accuracy=69.99, wps=6709.4, ups=0.8, wpb=8344.7, bsz=309.9, num_updates=46100, lr=6.58665e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=57, gb_free=17.2, wall=32779
2023-08-12 01:17:44 | INFO | train_inner | epoch 032:    526 / 1474 loss=1.959, trans_loss=4.737, nll_loss=1.928, w2v_ctc_loss=0.626, task_loss=0, contrastive_loss=0.16, total=4191.15, n_correct=2923.57, ppl=3.81, accuracy=69.756, wps=14485, ups=1.73, wpb=8382.3, bsz=315.1, num_updates=46200, lr=6.57952e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=57, gb_free=15.1, wall=32837
2023-08-12 01:18:42 | INFO | train_inner | epoch 032:    626 / 1474 loss=1.947, trans_loss=4.735, nll_loss=1.925, w2v_ctc_loss=0.623, task_loss=0, contrastive_loss=0.085, total=4138.05, n_correct=2887.74, ppl=3.8, accuracy=69.785, wps=14283.6, ups=1.73, wpb=8276.1, bsz=299.5, num_updates=46300, lr=6.57241e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=57, gb_free=13.6, wall=32895
2023-08-12 01:19:39 | INFO | train_inner | epoch 032:    726 / 1474 loss=1.948, trans_loss=4.736, nll_loss=1.926, w2v_ctc_loss=0.63, task_loss=0, contrastive_loss=0.071, total=4156.23, n_correct=2902.55, ppl=3.8, accuracy=69.836, wps=14414.8, ups=1.73, wpb=8312.5, bsz=303, num_updates=46400, lr=6.56532e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=57, gb_free=16.6, wall=32952
2023-08-12 01:20:36 | INFO | train_inner | epoch 032:    826 / 1474 loss=1.944, trans_loss=4.734, nll_loss=1.924, w2v_ctc_loss=0.621, task_loss=0, contrastive_loss=0.069, total=4112.3, n_correct=2870.07, ppl=3.79, accuracy=69.792, wps=14459.4, ups=1.76, wpb=8224.6, bsz=293.9, num_updates=46500, lr=6.55826e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=56, gb_free=16, wall=33009
2023-08-12 01:21:34 | INFO | train_inner | epoch 032:    926 / 1474 loss=1.942, trans_loss=4.733, nll_loss=1.924, w2v_ctc_loss=0.616, task_loss=0, contrastive_loss=0.067, total=4139.37, n_correct=2890.56, ppl=3.79, accuracy=69.831, wps=14426, ups=1.74, wpb=8278.7, bsz=298.6, num_updates=46600, lr=6.55122e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=57, gb_free=13.1, wall=33067
2023-08-12 01:22:31 | INFO | train_inner | epoch 032:   1026 / 1474 loss=1.958, trans_loss=4.738, nll_loss=1.93, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.161, total=4121.85, n_correct=2873.65, ppl=3.81, accuracy=69.717, wps=14395.2, ups=1.75, wpb=8243.7, bsz=306.1, num_updates=46700, lr=6.5442e-05, gnorm=0.546, clip=0, loss_scale=64, train_wall=57, gb_free=16.8, wall=33124
2023-08-12 01:23:29 | INFO | train_inner | epoch 032:   1126 / 1474 loss=1.951, trans_loss=4.738, nll_loss=1.928, w2v_ctc_loss=0.626, task_loss=0, contrastive_loss=0.104, total=4015.59, n_correct=2795.26, ppl=3.81, accuracy=69.61, wps=13915.3, ups=1.73, wpb=8031.2, bsz=270.1, num_updates=46800, lr=6.5372e-05, gnorm=0.561, clip=0, loss_scale=64, train_wall=57, gb_free=17.3, wall=33182
2023-08-12 01:24:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-12 01:24:26 | INFO | train_inner | epoch 032:   1227 / 1474 loss=1.968, trans_loss=4.746, nll_loss=1.941, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.209, total=4152.19, n_correct=2888.3, ppl=3.84, accuracy=69.561, wps=14348.8, ups=1.73, wpb=8304.4, bsz=310, num_updates=46900, lr=6.53023e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=57, gb_free=16.1, wall=33240
2023-08-12 01:25:23 | INFO | train_inner | epoch 032:   1327 / 1474 loss=1.947, trans_loss=4.735, nll_loss=1.926, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.068, total=4079.56, n_correct=2842.55, ppl=3.8, accuracy=69.678, wps=14339.3, ups=1.76, wpb=8159.1, bsz=297.9, num_updates=47000, lr=6.52328e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=56, gb_free=17.2, wall=33296
2023-08-12 01:26:20 | INFO | train_inner | epoch 032:   1427 / 1474 loss=1.978, trans_loss=4.742, nll_loss=1.935, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.307, total=4107.37, n_correct=2855.8, ppl=3.82, accuracy=69.529, wps=14373.1, ups=1.75, wpb=8214.7, bsz=304.2, num_updates=47100, lr=6.51635e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=57, gb_free=17.4, wall=33354
2023-08-12 01:26:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-12 01:27:10 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.088 | trans_loss 5.157 | nll_loss 2.413 | w2v_ctc_loss 1.357 | task_loss 0 | contrastive_loss 0.298 | total 4003.4 | n_correct 2680.8 | ppl 5.33 | accuracy 66.963 | uer 17.028 | wer 18.858 | raw_wer 18.858 | bleu 22.99 | wps 2268.6 | wpb 4003.4 | bsz 141.8 | num_updates 47147 | best_bleu 22.99
2023-08-12 01:27:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47147 updates
2023-08-12 01:27:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-12 01:27:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-12 01:27:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 32 @ 47147 updates, score 22.99) (writing took 28.626727713271976 seconds)
2023-08-12 01:27:39 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-12 01:27:39 | INFO | train | epoch 032 | loss 1.951 | trans_loss 4.733 | nll_loss 1.924 | w2v_ctc_loss 0.622 | task_loss 0 | contrastive_loss 0.121 | total 4138.54 | n_correct 2889.15 | ppl 3.79 | accuracy 69.811 | wps 12525.6 | ups 1.51 | wpb 8277.1 | bsz 305.6 | num_updates 47147 | lr 6.5131e-05 | gnorm 0.55 | clip 0 | loss_scale 32 | train_wall 837 | gb_free 16.5 | wall 33433
2023-08-12 01:27:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-12 01:27:40 | INFO | fairseq.trainer | begin training epoch 33
2023-08-12 01:27:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-12 01:28:19 | INFO | train_inner | epoch 033:     53 / 1474 loss=1.954, trans_loss=4.731, nll_loss=1.921, w2v_ctc_loss=0.614, task_loss=0, contrastive_loss=0.171, total=4146.91, n_correct=2901.58, ppl=3.79, accuracy=69.97, wps=7024.5, ups=0.85, wpb=8293.8, bsz=319.7, num_updates=47200, lr=6.50945e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=16.2, wall=33472
2023-08-12 01:29:16 | INFO | train_inner | epoch 033:    153 / 1474 loss=1.929, trans_loss=4.715, nll_loss=1.899, w2v_ctc_loss=0.603, task_loss=0, contrastive_loss=0.06, total=4073.36, n_correct=2860.37, ppl=3.73, accuracy=70.221, wps=14262.8, ups=1.75, wpb=8146.7, bsz=285.1, num_updates=47300, lr=6.50256e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=16.7, wall=33529
2023-08-12 01:30:14 | INFO | train_inner | epoch 033:    253 / 1474 loss=1.96, trans_loss=4.72, nll_loss=1.907, w2v_ctc_loss=0.613, task_loss=0, contrastive_loss=0.233, total=4283.64, n_correct=3002.19, ppl=3.75, accuracy=70.085, wps=14801.4, ups=1.73, wpb=8567.3, bsz=347.6, num_updates=47400, lr=6.4957e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=57, gb_free=16.4, wall=33587
2023-08-12 01:31:11 | INFO | train_inner | epoch 033:    353 / 1474 loss=1.943, trans_loss=4.725, nll_loss=1.913, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.086, total=4131.27, n_correct=2891.53, ppl=3.77, accuracy=69.991, wps=14373.6, ups=1.74, wpb=8262.5, bsz=302.3, num_updates=47500, lr=6.48886e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=57, gb_free=16.2, wall=33644
2023-08-12 01:32:08 | INFO | train_inner | epoch 033:    453 / 1474 loss=1.928, trans_loss=4.711, nll_loss=1.895, w2v_ctc_loss=0.604, task_loss=0, contrastive_loss=0.066, total=4135.1, n_correct=2908.53, ppl=3.72, accuracy=70.338, wps=14492.7, ups=1.75, wpb=8270.2, bsz=309.7, num_updates=47600, lr=6.48204e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=56, gb_free=15.7, wall=33701
2023-08-12 01:33:05 | INFO | train_inner | epoch 033:    553 / 1474 loss=1.945, trans_loss=4.727, nll_loss=1.915, w2v_ctc_loss=0.623, task_loss=0, contrastive_loss=0.089, total=4132.78, n_correct=2887.31, ppl=3.77, accuracy=69.864, wps=14477.5, ups=1.75, wpb=8265.6, bsz=294.2, num_updates=47700, lr=6.47524e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=57, gb_free=17.8, wall=33758
2023-08-12 01:34:03 | INFO | train_inner | epoch 033:    653 / 1474 loss=1.95, trans_loss=4.738, nll_loss=1.929, w2v_ctc_loss=0.618, task_loss=0, contrastive_loss=0.12, total=4156.26, n_correct=2900.93, ppl=3.81, accuracy=69.797, wps=14462.8, ups=1.74, wpb=8312.5, bsz=300.7, num_updates=47800, lr=6.46846e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=57, gb_free=16.2, wall=33816
2023-08-12 01:35:00 | INFO | train_inner | epoch 033:    753 / 1474 loss=1.949, trans_loss=4.732, nll_loss=1.922, w2v_ctc_loss=0.634, task_loss=0, contrastive_loss=0.069, total=4074.99, n_correct=2844.24, ppl=3.79, accuracy=69.797, wps=14213.4, ups=1.74, wpb=8150, bsz=288.2, num_updates=47900, lr=6.46171e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=57, gb_free=16.3, wall=33873
2023-08-12 01:35:57 | INFO | train_inner | epoch 033:    853 / 1474 loss=1.937, trans_loss=4.721, nll_loss=1.908, w2v_ctc_loss=0.601, task_loss=0, contrastive_loss=0.139, total=4127.6, n_correct=2898.69, ppl=3.75, accuracy=70.227, wps=14383.5, ups=1.74, wpb=8255.2, bsz=315.3, num_updates=48000, lr=6.45497e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=57, gb_free=16.2, wall=33931
2023-08-12 01:35:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-12 01:36:19 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.09 | trans_loss 5.163 | nll_loss 2.42 | w2v_ctc_loss 1.352 | task_loss 0 | contrastive_loss 0.289 | total 4003.4 | n_correct 2678.3 | ppl 5.35 | accuracy 66.901 | uer 17.105 | wer 18.959 | raw_wer 18.959 | bleu 22.23 | wps 2409.5 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 22.99
2023-08-12 01:36:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-08-12 01:36:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_33_48000.pt
2023-08-12 01:36:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_33_48000.pt
2023-08-12 01:36:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 22.23) (writing took 20.69256930798292 seconds)
2023-08-12 01:37:38 | INFO | train_inner | epoch 033:    953 / 1474 loss=1.946, trans_loss=4.728, nll_loss=1.917, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.08, total=4157.37, n_correct=2906.07, ppl=3.78, accuracy=69.902, wps=8288.1, ups=1, wpb=8314.7, bsz=310.1, num_updates=48100, lr=6.44826e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=57, gb_free=17.5, wall=34031
2023-08-12 01:38:35 | INFO | train_inner | epoch 033:   1053 / 1474 loss=1.954, trans_loss=4.726, nll_loss=1.914, w2v_ctc_loss=0.619, task_loss=0, contrastive_loss=0.181, total=4134.8, n_correct=2891.19, ppl=3.77, accuracy=69.923, wps=14324.9, ups=1.73, wpb=8269.6, bsz=306, num_updates=48200, lr=6.44157e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=57, gb_free=15.8, wall=34089
2023-08-12 01:39:33 | INFO | train_inner | epoch 033:   1153 / 1474 loss=1.952, trans_loss=4.735, nll_loss=1.925, w2v_ctc_loss=0.611, task_loss=0, contrastive_loss=0.171, total=4181.58, n_correct=2920.52, ppl=3.8, accuracy=69.842, wps=14484.5, ups=1.73, wpb=8363.2, bsz=310, num_updates=48300, lr=6.43489e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=57, gb_free=15.3, wall=34146
2023-08-12 01:40:31 | INFO | train_inner | epoch 033:   1253 / 1474 loss=1.94, trans_loss=4.724, nll_loss=1.912, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.072, total=4115.76, n_correct=2882.47, ppl=3.76, accuracy=70.035, wps=14260.8, ups=1.73, wpb=8231.5, bsz=294.7, num_updates=48400, lr=6.42824e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=57, gb_free=16.8, wall=34204
2023-08-12 01:41:29 | INFO | train_inner | epoch 033:   1353 / 1474 loss=1.945, trans_loss=4.73, nll_loss=1.92, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.09, total=4120.69, n_correct=2883.46, ppl=3.78, accuracy=69.975, wps=14290.2, ups=1.73, wpb=8241.4, bsz=311.9, num_updates=48500, lr=6.42161e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=57, gb_free=16.9, wall=34262
2023-08-12 01:42:26 | INFO | train_inner | epoch 033:   1453 / 1474 loss=1.958, trans_loss=4.731, nll_loss=1.921, w2v_ctc_loss=0.617, task_loss=0, contrastive_loss=0.238, total=4125.28, n_correct=2877.84, ppl=3.79, accuracy=69.761, wps=14406.3, ups=1.75, wpb=8250.6, bsz=308.7, num_updates=48600, lr=6.415e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=17, wall=34319
2023-08-12 01:42:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-12 01:43:00 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.101 | trans_loss 5.162 | nll_loss 2.416 | w2v_ctc_loss 1.388 | task_loss 0 | contrastive_loss 0.294 | total 4003.4 | n_correct 2677.1 | ppl 5.34 | accuracy 66.871 | uer 17.413 | wer 19.306 | raw_wer 19.306 | bleu 22.47 | wps 2282.2 | wpb 4003.4 | bsz 141.8 | num_updates 48621 | best_bleu 22.99
2023-08-12 01:43:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48621 updates
2023-08-12 01:43:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-12 01:43:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-12 01:43:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_last.pt (epoch 33 @ 48621 updates, score 22.47) (writing took 15.119503354653716 seconds)
2023-08-12 01:43:15 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-12 01:43:15 | INFO | train | epoch 033 | loss 1.945 | trans_loss 4.726 | nll_loss 1.914 | w2v_ctc_loss 0.616 | task_loss 0 | contrastive_loss 0.12 | total 4138.65 | n_correct 2896.6 | ppl 3.77 | accuracy 69.989 | wps 13034.9 | ups 1.57 | wpb 8277.3 | bsz 305.7 | num_updates 48621 | lr 6.41362e-05 | gnorm 0.551 | clip 0 | loss_scale 32 | train_wall 838 | gb_free 17.9 | wall 34369
2023-08-12 01:43:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-12 01:43:16 | INFO | fairseq.trainer | begin training epoch 34
2023-08-12 01:43:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-12 01:44:08 | INFO | train_inner | epoch 034:     79 / 1474 loss=1.932, trans_loss=4.712, nll_loss=1.896, w2v_ctc_loss=0.611, task_loss=0, contrastive_loss=0.073, total=4131.47, n_correct=2900.55, ppl=3.72, accuracy=70.206, wps=8086.7, ups=0.98, wpb=8262.9, bsz=301.7, num_updates=48700, lr=6.40841e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=57, gb_free=16.7, wall=34421
2023-08-12 01:45:06 | INFO | train_inner | epoch 034:    179 / 1474 loss=1.929, trans_loss=4.705, nll_loss=1.887, w2v_ctc_loss=0.61, task_loss=0, contrastive_loss=0.074, total=4065.88, n_correct=2863.68, ppl=3.7, accuracy=70.432, wps=14156.9, ups=1.74, wpb=8131.8, bsz=295.1, num_updates=48800, lr=6.40184e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=57, gb_free=16, wall=34479
2023-08-12 01:46:03 | INFO | train_inner | epoch 034:    279 / 1474 loss=1.962, trans_loss=4.725, nll_loss=1.913, w2v_ctc_loss=0.607, task_loss=0, contrastive_loss=0.28, total=4246.3, n_correct=2970.95, ppl=3.77, accuracy=69.966, wps=14718.7, ups=1.73, wpb=8492.6, bsz=328.7, num_updates=48900, lr=6.39529e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=57, gb_free=17.8, wall=34536
2023-08-12 01:47:01 | INFO | train_inner | epoch 034:    379 / 1474 loss=1.939, trans_loss=4.706, nll_loss=1.889, w2v_ctc_loss=0.604, task_loss=0, contrastive_loss=0.174, total=4156.17, n_correct=2924.14, ppl=3.7, accuracy=70.357, wps=14462.3, ups=1.74, wpb=8312.3, bsz=316.7, num_updates=49000, lr=6.38877e-05, gnorm=0.545, clip=0, loss_scale=64, train_wall=57, gb_free=17.8, wall=34594
2023-08-12 01:47:58 | INFO | train_inner | epoch 034:    479 / 1474 loss=1.94, trans_loss=4.721, nll_loss=1.907, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.068, total=4070.55, n_correct=2850.12, ppl=3.75, accuracy=70.018, wps=14220.7, ups=1.75, wpb=8141.1, bsz=284.6, num_updates=49100, lr=6.38226e-05, gnorm=0.557, clip=0, loss_scale=64, train_wall=57, gb_free=17.5, wall=34651
2023-08-12 01:48:55 | INFO | train_inner | epoch 034:    579 / 1474 loss=1.931, trans_loss=4.709, nll_loss=1.892, w2v_ctc_loss=0.609, task_loss=0, contrastive_loss=0.071, total=4119.38, n_correct=2897.71, ppl=3.71, accuracy=70.343, wps=14446, ups=1.75, wpb=8238.8, bsz=300.3, num_updates=49200, lr=6.37577e-05, gnorm=0.55, clip=0, loss_scale=64, train_wall=56, gb_free=13.4, wall=34708
2023-08-12 01:49:52 | INFO | train_inner | epoch 034:    679 / 1474 loss=1.93, trans_loss=4.715, nll_loss=1.9, w2v_ctc_loss=0.607, task_loss=0, contrastive_loss=0.064, total=4124.83, n_correct=2897.96, ppl=3.73, accuracy=70.256, wps=14532, ups=1.76, wpb=8249.7, bsz=300.2, num_updates=49300, lr=6.3693e-05, gnorm=0.553, clip=0, loss_scale=64, train_wall=56, gb_free=14.4, wall=34765
2023-08-12 01:50:49 | INFO | train_inner | epoch 034:    779 / 1474 loss=1.948, trans_loss=4.737, nll_loss=1.928, w2v_ctc_loss=0.61, task_loss=0, contrastive_loss=0.134, total=4082.07, n_correct=2850.15, ppl=3.81, accuracy=69.821, wps=14211.5, ups=1.74, wpb=8164.1, bsz=295, num_updates=49400, lr=6.36285e-05, gnorm=0.56, clip=0, loss_scale=64, train_wall=57, gb_free=15.7, wall=34822
2023-08-12 01:51:47 | INFO | train_inner | epoch 034:    879 / 1474 loss=1.943, trans_loss=4.725, nll_loss=1.913, w2v_ctc_loss=0.619, task_loss=0, contrastive_loss=0.093, total=4100.9, n_correct=2872.67, ppl=3.76, accuracy=70.05, wps=14314.4, ups=1.75, wpb=8201.8, bsz=296.6, num_updates=49500, lr=6.35642e-05, gnorm=0.559, clip=0, loss_scale=64, train_wall=57, gb_free=12.5, wall=34880
2023-08-12 01:52:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-12 01:52:44 | INFO | train_inner | epoch 034:    980 / 1474 loss=1.945, trans_loss=4.723, nll_loss=1.91, w2v_ctc_loss=0.626, task_loss=0, contrastive_loss=0.087, total=4155.92, n_correct=2908.54, ppl=3.76, accuracy=69.985, wps=14393, ups=1.73, wpb=8311.8, bsz=307.9, num_updates=49600, lr=6.35001e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=57, gb_free=14, wall=34937
2023-08-12 01:53:41 | INFO | train_inner | epoch 034:   1080 / 1474 loss=1.938, trans_loss=4.721, nll_loss=1.908, w2v_ctc_loss=0.619, task_loss=0, contrastive_loss=0.072, total=4152.17, n_correct=2916.83, ppl=3.75, accuracy=70.248, wps=14652, ups=1.76, wpb=8304.3, bsz=309, num_updates=49700, lr=6.34361e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=56, gb_free=14.7, wall=34994
2023-08-12 01:54:38 | INFO | train_inner | epoch 034:   1180 / 1474 loss=1.938, trans_loss=4.723, nll_loss=1.91, w2v_ctc_loss=0.614, task_loss=0, contrastive_loss=0.083, total=4101.68, n_correct=2872.92, ppl=3.76, accuracy=70.043, wps=14379.1, ups=1.75, wpb=8203.4, bsz=298, num_updates=49800, lr=6.33724e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=57, gb_free=16.3, wall=35051
2023-08-12 01:55:35 | INFO | train_inner | epoch 034:   1280 / 1474 loss=1.936, trans_loss=4.718, nll_loss=1.903, w2v_ctc_loss=0.616, task_loss=0, contrastive_loss=0.068, total=4146.01, n_correct=2909.14, ppl=3.74, accuracy=70.167, wps=14516.9, ups=1.75, wpb=8292, bsz=300.6, num_updates=49900, lr=6.33089e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=57, gb_free=17.3, wall=35108
2023-08-12 01:56:33 | INFO | train_inner | epoch 034:   1380 / 1474 loss=1.953, trans_loss=4.728, nll_loss=1.918, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.131, total=4197.99, n_correct=2934.18, ppl=3.78, accuracy=69.895, wps=14559.6, ups=1.73, wpb=8396, bsz=321.1, num_updates=50000, lr=6.32456e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=57, gb_free=17.3, wall=35166
2023-08-12 01:56:33 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-12 01:56:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-12 01:56:55 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.092 | trans_loss 5.159 | nll_loss 2.411 | w2v_ctc_loss 1.364 | task_loss 0 | contrastive_loss 0.3 | total 4003.4 | n_correct 2684.2 | ppl 5.32 | accuracy 67.048 | uer 17.195 | wer 19.164 | raw_wer 19.164 | bleu 22.69 | wps 2341.6 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 22.99
2023-08-12 01:56:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-08-12 01:56:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_34_50000.pt
2023-08-12 01:56:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_34_50000.pt
2023-08-12 01:57:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0811_baseline_alpha1.5_mt0.5/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 22.69) (writing took 40.430821569636464 seconds)
2023-08-12 01:57:38 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-12 01:57:38 | INFO | train | epoch 034 | loss 1.94 | trans_loss 4.719 | nll_loss 1.905 | w2v_ctc_loss 0.614 | task_loss 0 | contrastive_loss 0.107 | total 4132.21 | n_correct 2897.73 | ppl 3.75 | accuracy 70.125 | wps 13209.2 | ups 1.6 | wpb 8264.4 | bsz 304 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.553 | clip 0 | loss_scale 32 | train_wall 783 | gb_free 17.3 | wall 35231
2023-08-12 01:57:38 | INFO | fairseq_cli.train | done training in 35179.5 seconds
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    raise EOFError
EOFError
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
