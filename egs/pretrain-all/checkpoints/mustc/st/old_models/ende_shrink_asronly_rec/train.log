2023-07-06 10:57:21 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:17122
2023-07-06 10:57:21 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:17122
2023-07-06 10:57:21 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:17122
2023-07-06 10:57:21 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:17122
2023-07-06 10:57:21 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:17122
2023-07-06 10:57:21 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:17122
2023-07-06 10:57:21 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:17122
2023-07-06 10:57:21 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:17122
2023-07-06 10:57:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-06 10:57:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-06 10:57:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-06 10:57:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-06 10:57:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-06 10:57:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-06 10:57:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-06 10:57:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-06 10:57:22 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-06 10:57:22 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-06 10:57:22 | INFO | fairseq.distributed.utils | initialized host capios as rank 2
2023-07-06 10:57:22 | INFO | fairseq.distributed.utils | initialized host capios as rank 0
2023-07-06 10:57:22 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-06 10:57:22 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-06 10:57:22 | INFO | fairseq.distributed.utils | initialized host capios as rank 1
2023-07-06 10:57:22 | INFO | fairseq.distributed.utils | initialized host capios as rank 6
2023-07-06 10:57:22 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-06 10:57:22 | INFO | fairseq.distributed.utils | initialized host capios as rank 7
2023-07-06 10:57:22 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-06 10:57:22 | INFO | fairseq.distributed.utils | initialized host capios as rank 5
2023-07-06 10:57:22 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-06 10:57:22 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-06 10:57:22 | INFO | fairseq.distributed.utils | initialized host capios as rank 4
2023-07-06 10:57:22 | INFO | fairseq.distributed.utils | initialized host capios as rank 3
2023-07-06 10:57:24 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_asronly_rec', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:17122', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_asr,train_rec_st', 'valid_subset': 'dev_rec_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_asronly_rec', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_asronly_rec', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_asronly_rec', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_asr,train_rec_st', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_rec_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=100000, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_asronly_rec', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_asronly_rec', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_asr,train_rec_st', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_rec_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=100000, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_asronly_rec', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_asronly_rec', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_asr,train_rec_st', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_rec_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=100000, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-06 10:57:24 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-06 10:57:24 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-06 10:57:24 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-06 10:57:24 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-06 10:57:26 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-06 10:57:26 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-06 10:57:26 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-06 10:57:28 | INFO | root | load pretrained hubert
2023-07-06 10:57:32 | INFO | root | share the sematic adapter and textual encoder
2023-07-06 10:57:32 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-06 10:57:32 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-06 10:57:32 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-06 10:57:32 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJoint
2023-07-06 10:57:32 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-07-06 10:57:33 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-06 10:57:33 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-06 10:57:33 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-06 10:57:33 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-06 10:57:33 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_rec_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-06 10:57:39 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-06 10:57:39 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-06 10:57:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-06 10:57:40 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-06 10:57:40 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-06 10:57:40 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-06 10:57:40 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-06 10:57:40 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-06 10:57:40 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-06 10:57:40 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-06 10:57:40 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-06 10:57:40 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-06 10:57:40 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-06 10:57:40 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-06 10:57:40 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-06 10:57:40 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_last.pt
2023-07-06 10:57:40 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_last.pt
2023-07-06 10:57:40 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-06 10:57:40 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-06 10:57:40 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-06 10:57:40 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-06 10:57:41 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-06 10:57:43 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_rec_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-06 10:58:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 10:58:25 | INFO | fairseq.trainer | begin training epoch 1
2023-07-06 10:58:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 10:59:15 | INFO | train_inner | epoch 001:    100 / 1474 loss=27.868, trans_loss=7.319, nll_loss=7.317, w2v_ctc_loss=34.992, contrastive_loss=0, total=4137.01, n_correct=5.17, ppl=159.43, accuracy=0.125, wps=20103.6, ups=2.43, wpb=8274, bsz=314.3, num_updates=100, lr=4.098e-06, gnorm=0.856, clip=0, loss_scale=128, train_wall=42, gb_free=19.3, wall=95
2023-07-06 10:59:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-06 10:59:56 | INFO | train_inner | epoch 001:    201 / 1474 loss=25.43, trans_loss=7.332, nll_loss=7.332, w2v_ctc_loss=31.225, contrastive_loss=0, total=4062.79, n_correct=5.16, ppl=161.13, accuracy=0.127, wps=19737.9, ups=2.43, wpb=8125.6, bsz=307.6, num_updates=200, lr=8.096e-06, gnorm=4.746, clip=9, loss_scale=64, train_wall=41, gb_free=19, wall=136
2023-07-06 11:00:36 | INFO | train_inner | epoch 001:    301 / 1474 loss=14.235, trans_loss=7.36, nll_loss=7.357, w2v_ctc_loss=13.973, contrastive_loss=0, total=4022.25, n_correct=4.5, ppl=163.97, accuracy=0.112, wps=19837.5, ups=2.47, wpb=8044.5, bsz=290.2, num_updates=300, lr=1.2094e-05, gnorm=3.917, clip=18, loss_scale=64, train_wall=40, gb_free=19.7, wall=177
2023-07-06 11:01:17 | INFO | train_inner | epoch 001:    401 / 1474 loss=12.709, trans_loss=7.327, nll_loss=7.316, w2v_ctc_loss=11.663, contrastive_loss=0, total=4115.21, n_correct=4.87, ppl=159.32, accuracy=0.118, wps=20273.1, ups=2.46, wpb=8230.4, bsz=307, num_updates=400, lr=1.6092e-05, gnorm=1.197, clip=0, loss_scale=64, train_wall=40, gb_free=18.7, wall=217
2023-07-06 11:01:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-06 11:01:58 | INFO | train_inner | epoch 001:    502 / 1474 loss=11.532, trans_loss=7.298, nll_loss=7.277, w2v_ctc_loss=9.881, contrastive_loss=0, total=4153.15, n_correct=5.48, ppl=155.05, accuracy=0.132, wps=20195.5, ups=2.43, wpb=8306.3, bsz=327.2, num_updates=500, lr=2.009e-05, gnorm=1.121, clip=0, loss_scale=32, train_wall=41, gb_free=17.7, wall=258
2023-07-06 11:02:39 | INFO | train_inner | epoch 001:    602 / 1474 loss=10.96, trans_loss=7.272, nll_loss=7.246, w2v_ctc_loss=9.031, contrastive_loss=0, total=4052.03, n_correct=4.93, ppl=151.78, accuracy=0.122, wps=20012.3, ups=2.47, wpb=8104.1, bsz=314, num_updates=600, lr=2.4088e-05, gnorm=0.689, clip=0, loss_scale=32, train_wall=40, gb_free=18.9, wall=299
2023-07-06 11:03:19 | INFO | train_inner | epoch 001:    702 / 1474 loss=10.806, trans_loss=7.278, nll_loss=7.251, w2v_ctc_loss=8.786, contrastive_loss=0, total=4087.3, n_correct=4.75, ppl=152.35, accuracy=0.116, wps=20358.8, ups=2.49, wpb=8174.6, bsz=303.5, num_updates=700, lr=2.8086e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=40, gb_free=19.2, wall=339
2023-07-06 11:03:59 | INFO | train_inner | epoch 001:    802 / 1474 loss=10.694, trans_loss=7.295, nll_loss=7.271, w2v_ctc_loss=8.596, contrastive_loss=0, total=4056.82, n_correct=5.16, ppl=154.46, accuracy=0.127, wps=20166.9, ups=2.49, wpb=8113.6, bsz=309.3, num_updates=800, lr=3.2084e-05, gnorm=0.61, clip=0, loss_scale=32, train_wall=40, gb_free=19.2, wall=379
2023-07-06 11:04:39 | INFO | train_inner | epoch 001:    902 / 1474 loss=10.564, trans_loss=7.316, nll_loss=7.292, w2v_ctc_loss=8.373, contrastive_loss=0, total=4110.67, n_correct=4.85, ppl=156.73, accuracy=0.118, wps=20447, ups=2.49, wpb=8221.3, bsz=305, num_updates=900, lr=3.6082e-05, gnorm=0.678, clip=0, loss_scale=32, train_wall=40, gb_free=19.1, wall=420
2023-07-06 11:05:20 | INFO | train_inner | epoch 001:   1002 / 1474 loss=10.352, trans_loss=7.352, nll_loss=7.327, w2v_ctc_loss=8.01, contrastive_loss=0, total=4081.84, n_correct=4.85, ppl=160.54, accuracy=0.119, wps=20142.9, ups=2.47, wpb=8163.7, bsz=305.9, num_updates=1000, lr=4.008e-05, gnorm=0.803, clip=0, loss_scale=32, train_wall=40, gb_free=19.3, wall=460
2023-07-06 11:06:01 | INFO | train_inner | epoch 001:   1102 / 1474 loss=10.178, trans_loss=7.384, nll_loss=7.358, w2v_ctc_loss=7.705, contrastive_loss=0, total=4075.05, n_correct=4.62, ppl=164.09, accuracy=0.113, wps=19890.1, ups=2.44, wpb=8150.1, bsz=302.3, num_updates=1100, lr=4.4078e-05, gnorm=0.817, clip=0, loss_scale=32, train_wall=41, gb_free=18.7, wall=501
2023-07-06 11:06:42 | INFO | train_inner | epoch 001:   1202 / 1474 loss=9.971, trans_loss=7.424, nll_loss=7.394, w2v_ctc_loss=7.344, contrastive_loss=0, total=4081.46, n_correct=4.52, ppl=168.23, accuracy=0.111, wps=19982.1, ups=2.45, wpb=8162.9, bsz=292.3, num_updates=1200, lr=4.8076e-05, gnorm=0.876, clip=0, loss_scale=32, train_wall=40, gb_free=19.4, wall=542
2023-07-06 11:07:21 | INFO | train_inner | epoch 001:   1302 / 1474 loss=9.77, trans_loss=7.485, nll_loss=7.451, w2v_ctc_loss=6.969, contrastive_loss=0, total=3996.6, n_correct=5.31, ppl=174.95, accuracy=0.133, wps=20048.1, ups=2.51, wpb=7993.2, bsz=295.2, num_updates=1300, lr=5.2074e-05, gnorm=0.972, clip=0, loss_scale=32, train_wall=39, gb_free=19.1, wall=582
2023-07-06 11:08:02 | INFO | train_inner | epoch 001:   1402 / 1474 loss=9.567, trans_loss=7.563, nll_loss=7.526, w2v_ctc_loss=6.572, contrastive_loss=0, total=4081.33, n_correct=4.96, ppl=184.31, accuracy=0.122, wps=20244, ups=2.48, wpb=8162.7, bsz=303, num_updates=1400, lr=5.6072e-05, gnorm=1.211, clip=0, loss_scale=32, train_wall=40, gb_free=18.6, wall=622
2023-07-06 11:08:30 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-07-06 11:08:47 | INFO | dev_rec_st | epoch 001 | valid on 'dev_rec_st' subset | loss 12.552 | trans_loss 15.462 | nll_loss 15.364 | w2v_ctc_loss 5.762 | contrastive_loss 0 | total 3909.1 | n_correct 5.6 | ppl 42169.8 | accuracy 0.143 | uer 68.203 | wer 66.351 | raw_wer 66.351 | bleu 0.24 | wps 3974.4 | wpb 3909.1 | bsz 141.8 | num_updates 1472
2023-07-06 11:08:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1472 updates
2023-07-06 11:08:47 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 11:08:49 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 11:08:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt (epoch 1 @ 1472 updates, score 0.24) (writing took 5.147840916004498 seconds)
2023-07-06 11:08:52 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-07-06 11:08:52 | INFO | train | epoch 001 | loss 13.017 | trans_loss 7.369 | nll_loss 7.348 | w2v_ctc_loss 12.09 | contrastive_loss 0 | total 4078.27 | n_correct 4.92459 | ppl 162.88 | accuracy 0.121 | wps 19410 | ups 2.38 | wpb 8156.5 | bsz 305.6 | num_updates 1472 | lr 5.89506e-05 | gnorm 1.369 | clip 1.8 | loss_scale 32 | train_wall 593 | gb_free 19 | wall 672
2023-07-06 11:08:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 11:08:52 | INFO | fairseq.trainer | begin training epoch 2
2023-07-06 11:08:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 11:09:10 | INFO | train_inner | epoch 002:     28 / 1474 loss=9.388, trans_loss=7.616, nll_loss=7.573, w2v_ctc_loss=6.241, contrastive_loss=0, total=4093.09, n_correct=4.79, ppl=190.38, accuracy=0.117, wps=11949.4, ups=1.46, wpb=8186.2, bsz=314.7, num_updates=1500, lr=6.007e-05, gnorm=1.438, clip=0, loss_scale=32, train_wall=40, gb_free=18.7, wall=691
2023-07-06 11:09:51 | INFO | train_inner | epoch 002:    128 / 1474 loss=9.266, trans_loss=7.672, nll_loss=7.625, w2v_ctc_loss=5.992, contrastive_loss=0, total=4079.78, n_correct=4.76, ppl=197.36, accuracy=0.117, wps=20271.2, ups=2.48, wpb=8159.6, bsz=300.4, num_updates=1600, lr=6.4068e-05, gnorm=1.478, clip=0, loss_scale=32, train_wall=40, gb_free=19.6, wall=731
2023-07-06 11:10:31 | INFO | train_inner | epoch 002:    228 / 1474 loss=9.069, trans_loss=7.731, nll_loss=7.685, w2v_ctc_loss=5.627, contrastive_loss=0, total=4142.3, n_correct=4.94, ppl=205.73, accuracy=0.119, wps=20713.2, ups=2.5, wpb=8284.6, bsz=330.2, num_updates=1700, lr=6.8066e-05, gnorm=1.418, clip=0, loss_scale=32, train_wall=40, gb_free=19.1, wall=771
2023-07-06 11:11:11 | INFO | train_inner | epoch 002:    328 / 1474 loss=9.006, trans_loss=7.791, nll_loss=7.74, w2v_ctc_loss=5.465, contrastive_loss=0, total=4070.82, n_correct=4.77, ppl=213.73, accuracy=0.117, wps=20206.9, ups=2.48, wpb=8141.6, bsz=295.5, num_updates=1800, lr=7.2064e-05, gnorm=1.403, clip=0, loss_scale=32, train_wall=40, gb_free=19.2, wall=811
2023-07-06 11:11:51 | INFO | train_inner | epoch 002:    428 / 1474 loss=8.907, trans_loss=7.827, nll_loss=7.769, w2v_ctc_loss=5.276, contrastive_loss=0, total=3992.95, n_correct=4.89, ppl=218.12, accuracy=0.122, wps=19968.5, ups=2.5, wpb=7985.9, bsz=277.2, num_updates=1900, lr=7.6062e-05, gnorm=1.612, clip=0, loss_scale=32, train_wall=40, gb_free=19.7, wall=851
2023-07-06 11:12:31 | INFO | train_inner | epoch 002:    528 / 1474 loss=8.784, trans_loss=7.859, nll_loss=7.801, w2v_ctc_loss=5.048, contrastive_loss=0, total=4114.65, n_correct=4.4, ppl=223, accuracy=0.107, wps=20466.4, ups=2.49, wpb=8229.3, bsz=313.5, num_updates=2000, lr=8.006e-05, gnorm=1.362, clip=0, loss_scale=32, train_wall=40, gb_free=18.8, wall=891
2023-07-06 11:12:31 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 11:12:47 | INFO | dev_rec_st | epoch 002 | valid on 'dev_rec_st' subset | loss 12.601 | trans_loss 16.089 | nll_loss 15.964 | w2v_ctc_loss 4.462 | contrastive_loss 0 | total 3909.1 | n_correct 5.6 | ppl 63906.7 | accuracy 0.143 | uer 58.185 | wer 56.202 | raw_wer 56.202 | bleu 0.39 | wps 3947.2 | wpb 3909.1 | bsz 141.8 | num_updates 2000 | best_bleu 0.39
2023-07-06 11:12:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-07-06 11:12:47 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_2_2000.pt
2023-07-06 11:12:50 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_2_2000.pt
2023-07-06 11:12:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.39) (writing took 9.78792988198984 seconds)
2023-07-06 11:13:37 | INFO | train_inner | epoch 002:    628 / 1474 loss=8.698, trans_loss=7.88, nll_loss=7.822, w2v_ctc_loss=4.894, contrastive_loss=0, total=4063.09, n_correct=5.3, ppl=226.36, accuracy=0.13, wps=12293.8, ups=1.51, wpb=8126.2, bsz=297.8, num_updates=2100, lr=8.4058e-05, gnorm=2.12, clip=0, loss_scale=32, train_wall=40, gb_free=19.1, wall=957
2023-07-06 11:14:17 | INFO | train_inner | epoch 002:    728 / 1474 loss=8.631, trans_loss=7.897, nll_loss=7.836, w2v_ctc_loss=4.775, contrastive_loss=0, total=4086.78, n_correct=5.05, ppl=228.57, accuracy=0.124, wps=20473.4, ups=2.5, wpb=8173.6, bsz=308.6, num_updates=2200, lr=8.8056e-05, gnorm=1.661, clip=0, loss_scale=32, train_wall=40, gb_free=19.5, wall=997
2023-07-06 11:14:57 | INFO | train_inner | epoch 002:    828 / 1474 loss=8.583, trans_loss=7.915, nll_loss=7.854, w2v_ctc_loss=4.676, contrastive_loss=0, total=4110.32, n_correct=4.94, ppl=231.29, accuracy=0.12, wps=20427.2, ups=2.48, wpb=8220.6, bsz=306.2, num_updates=2300, lr=9.2054e-05, gnorm=1.352, clip=0, loss_scale=32, train_wall=40, gb_free=19.3, wall=1038
2023-07-06 11:15:37 | INFO | train_inner | epoch 002:    928 / 1474 loss=8.513, trans_loss=7.93, nll_loss=7.868, w2v_ctc_loss=4.553, contrastive_loss=0, total=4050.89, n_correct=5.17, ppl=233.63, accuracy=0.128, wps=20238.2, ups=2.5, wpb=8101.8, bsz=298.6, num_updates=2400, lr=9.6052e-05, gnorm=1.621, clip=0, loss_scale=32, train_wall=40, gb_free=18.7, wall=1078
2023-07-06 11:16:17 | INFO | train_inner | epoch 002:   1028 / 1474 loss=8.457, trans_loss=7.934, nll_loss=7.869, w2v_ctc_loss=4.469, contrastive_loss=0, total=4042.8, n_correct=4.86, ppl=233.71, accuracy=0.12, wps=20336.1, ups=2.52, wpb=8085.6, bsz=303, num_updates=2500, lr=0.00010005, gnorm=1.643, clip=0, loss_scale=32, train_wall=39, gb_free=18.8, wall=1117
2023-07-06 11:16:58 | INFO | train_inner | epoch 002:   1128 / 1474 loss=8.386, trans_loss=7.914, nll_loss=7.848, w2v_ctc_loss=4.374, contrastive_loss=0, total=4122.96, n_correct=5.27, ppl=230.34, accuracy=0.128, wps=20329.7, ups=2.47, wpb=8245.9, bsz=324, num_updates=2600, lr=0.000104048, gnorm=1.517, clip=0, loss_scale=64, train_wall=40, gb_free=18.7, wall=1158
2023-07-06 11:17:38 | INFO | train_inner | epoch 002:   1228 / 1474 loss=8.357, trans_loss=7.932, nll_loss=7.865, w2v_ctc_loss=4.314, contrastive_loss=0, total=4152.02, n_correct=4.87, ppl=233.1, accuracy=0.117, wps=20407.9, ups=2.46, wpb=8304, bsz=327.9, num_updates=2700, lr=0.000108046, gnorm=1.452, clip=0, loss_scale=64, train_wall=40, gb_free=18.7, wall=1199
2023-07-06 11:18:19 | INFO | train_inner | epoch 002:   1328 / 1474 loss=8.297, trans_loss=7.919, nll_loss=7.85, w2v_ctc_loss=4.238, contrastive_loss=0, total=4115.07, n_correct=4.87, ppl=230.74, accuracy=0.118, wps=20511.5, ups=2.49, wpb=8230.1, bsz=308.7, num_updates=2800, lr=0.000112044, gnorm=1.222, clip=0, loss_scale=64, train_wall=40, gb_free=18.8, wall=1239
2023-07-06 11:18:58 | INFO | train_inner | epoch 002:   1428 / 1474 loss=8.281, trans_loss=7.922, nll_loss=7.854, w2v_ctc_loss=4.207, contrastive_loss=0, total=3992.79, n_correct=4.89, ppl=231.39, accuracy=0.122, wps=19984.4, ups=2.5, wpb=7985.6, bsz=291.7, num_updates=2900, lr=0.000116042, gnorm=1.315, clip=0, loss_scale=64, train_wall=40, gb_free=19, wall=1279
2023-07-06 11:19:17 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 11:19:33 | INFO | dev_rec_st | epoch 002 | valid on 'dev_rec_st' subset | loss 12.445 | trans_loss 16.214 | nll_loss 16.053 | w2v_ctc_loss 3.652 | contrastive_loss 0 | total 3909.1 | n_correct 5.6 | ppl 67965.4 | accuracy 0.143 | uer 49.837 | wer 49.003 | raw_wer 49.003 | bleu 0.55 | wps 3953.4 | wpb 3909.1 | bsz 141.8 | num_updates 2946 | best_bleu 0.55
2023-07-06 11:19:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2946 updates
2023-07-06 11:19:33 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 11:19:38 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 11:19:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt (epoch 2 @ 2946 updates, score 0.55) (writing took 8.920565512002213 seconds)
2023-07-06 11:19:42 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-07-06 11:19:42 | INFO | train | epoch 002 | loss 8.66 | trans_loss 7.862 | nll_loss 7.802 | w2v_ctc_loss 4.854 | contrastive_loss 0 | total 4078.54 | n_correct 4.9213 | ppl 223.24 | accuracy 0.121 | wps 18494.7 | ups 2.27 | wpb 8157.1 | bsz 305.7 | num_updates 2946 | lr 0.000117881 | gnorm 1.509 | clip 0 | loss_scale 64 | train_wall 586 | gb_free 19.1 | wall 1322
2023-07-06 11:19:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 11:19:42 | INFO | fairseq.trainer | begin training epoch 3
2023-07-06 11:19:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 11:20:11 | INFO | train_inner | epoch 003:     54 / 1474 loss=8.22, trans_loss=7.908, nll_loss=7.835, w2v_ctc_loss=4.127, contrastive_loss=0, total=4008.78, n_correct=4.63, ppl=228.29, accuracy=0.115, wps=11045.8, ups=1.38, wpb=8017.6, bsz=294.6, num_updates=3000, lr=0.00012004, gnorm=1.548, clip=0, loss_scale=64, train_wall=40, gb_free=19, wall=1351
2023-07-06 11:20:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-06 11:20:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-06 11:20:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-06 11:21:10 | INFO | train_inner | epoch 003:    157 / 1474 loss=7.98, trans_loss=5.086, nll_loss=4.481, w2v_ctc_loss=6.802, contrastive_loss=0, total=4084.28, n_correct=385.95, ppl=22.33, accuracy=9.45, wps=13781.1, ups=1.69, wpb=8168.6, bsz=304.8, num_updates=3100, lr=0.000124038, gnorm=2.673, clip=6, loss_scale=8, train_wall=59, gb_free=16.8, wall=1411
2023-07-06 11:22:09 | INFO | train_inner | epoch 003:    257 / 1474 loss=7.28, trans_loss=4.66, nll_loss=3.943, w2v_ctc_loss=6.181, contrastive_loss=0, total=4097.72, n_correct=718.46, ppl=15.38, accuracy=17.533, wps=13912.6, ups=1.7, wpb=8195.4, bsz=307.8, num_updates=3200, lr=0.000128036, gnorm=1.876, clip=0, loss_scale=8, train_wall=58, gb_free=15.1, wall=1470
2023-07-06 11:23:08 | INFO | train_inner | epoch 003:    357 / 1474 loss=7.24, trans_loss=4.458, nll_loss=3.678, w2v_ctc_loss=6.332, contrastive_loss=0, total=4105.51, n_correct=899.67, ppl=12.8, accuracy=21.914, wps=14081.1, ups=1.71, wpb=8211, bsz=312.1, num_updates=3300, lr=0.000132034, gnorm=2.18, clip=0, loss_scale=8, train_wall=58, gb_free=17.4, wall=1528
2023-07-06 11:24:06 | INFO | train_inner | epoch 003:    457 / 1474 loss=6.995, trans_loss=4.225, nll_loss=3.372, w2v_ctc_loss=6.212, contrastive_loss=0, total=4136.26, n_correct=1103.33, ppl=10.35, accuracy=26.675, wps=14068.8, ups=1.7, wpb=8272.5, bsz=316.9, num_updates=3400, lr=0.000136032, gnorm=2.055, clip=0, loss_scale=8, train_wall=58, gb_free=12.5, wall=1587
2023-07-06 11:25:04 | INFO | train_inner | epoch 003:    557 / 1474 loss=6.663, trans_loss=4.043, nll_loss=3.131, w2v_ctc_loss=5.897, contrastive_loss=0, total=4037.25, n_correct=1239.19, ppl=8.76, accuracy=30.694, wps=13906.5, ups=1.72, wpb=8074.5, bsz=291.5, num_updates=3500, lr=0.00014003, gnorm=1.895, clip=0, loss_scale=8, train_wall=58, gb_free=17.4, wall=1645
2023-07-06 11:26:04 | INFO | train_inner | epoch 003:    657 / 1474 loss=6.56, trans_loss=3.91, nll_loss=2.955, w2v_ctc_loss=5.888, contrastive_loss=0, total=4150.37, n_correct=1392.88, ppl=7.75, accuracy=33.56, wps=13993.4, ups=1.69, wpb=8300.7, bsz=324, num_updates=3600, lr=0.000144028, gnorm=2.491, clip=0, loss_scale=8, train_wall=59, gb_free=16.8, wall=1704
2023-07-06 11:27:02 | INFO | train_inner | epoch 003:    757 / 1474 loss=6.606, trans_loss=3.874, nll_loss=2.906, w2v_ctc_loss=5.989, contrastive_loss=0, total=4109.4, n_correct=1394.72, ppl=7.5, accuracy=33.94, wps=14123.7, ups=1.72, wpb=8218.8, bsz=313.7, num_updates=3700, lr=0.000148026, gnorm=3.241, clip=0, loss_scale=8, train_wall=58, gb_free=16.7, wall=1762
2023-07-06 11:28:00 | INFO | train_inner | epoch 003:    857 / 1474 loss=6.452, trans_loss=3.799, nll_loss=2.807, w2v_ctc_loss=5.827, contrastive_loss=0, total=4106.53, n_correct=1458.04, ppl=7, accuracy=35.505, wps=14078.8, ups=1.71, wpb=8213.1, bsz=305.1, num_updates=3800, lr=0.000152024, gnorm=3.158, clip=0, loss_scale=8, train_wall=58, gb_free=14.6, wall=1821
2023-07-06 11:28:59 | INFO | train_inner | epoch 003:    957 / 1474 loss=6.249, trans_loss=3.727, nll_loss=2.71, w2v_ctc_loss=5.601, contrastive_loss=0, total=4089.87, n_correct=1534.97, ppl=6.54, accuracy=37.531, wps=13961.1, ups=1.71, wpb=8179.7, bsz=311.4, num_updates=3900, lr=0.000156022, gnorm=3.084, clip=0, loss_scale=8, train_wall=58, gb_free=16.9, wall=1879
2023-07-06 11:29:57 | INFO | train_inner | epoch 003:   1057 / 1474 loss=6.133, trans_loss=3.666, nll_loss=2.63, w2v_ctc_loss=5.474, contrastive_loss=0, total=4004.15, n_correct=1560.71, ppl=6.19, accuracy=38.977, wps=13804.1, ups=1.72, wpb=8008.3, bsz=292.3, num_updates=4000, lr=0.00016002, gnorm=2.793, clip=0, loss_scale=8, train_wall=58, gb_free=17.2, wall=1937
2023-07-06 11:29:57 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 11:30:13 | INFO | dev_rec_st | epoch 003 | valid on 'dev_rec_st' subset | loss 5.247 | trans_loss 7.327 | nll_loss 5.179 | w2v_ctc_loss 0.392 | contrastive_loss 0 | total 3909.1 | n_correct 1619.5 | ppl 36.23 | accuracy 41.429 | uer 72.251 | wer 72.261 | raw_wer 72.261 | bleu 0.3 | wps 3943 | wpb 3909.1 | bsz 141.8 | num_updates 4000 | best_bleu 0.55
2023-07-06 11:30:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-07-06 11:30:13 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_3_4000.pt
2023-07-06 11:30:16 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_3_4000.pt
2023-07-06 11:30:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 0.3) (writing took 6.811418102006428 seconds)
2023-07-06 11:31:18 | INFO | train_inner | epoch 003:   1157 / 1474 loss=5.893, trans_loss=3.564, nll_loss=2.495, w2v_ctc_loss=5.229, contrastive_loss=0, total=3985.49, n_correct=1658.16, ppl=5.64, accuracy=41.605, wps=9833.2, ups=1.23, wpb=7971, bsz=291.3, num_updates=4100, lr=0.000164018, gnorm=2.674, clip=0, loss_scale=8, train_wall=58, gb_free=16.6, wall=2018
2023-07-06 11:32:16 | INFO | train_inner | epoch 003:   1257 / 1474 loss=5.854, trans_loss=3.51, nll_loss=2.421, w2v_ctc_loss=5.224, contrastive_loss=0, total=4008.03, n_correct=1724.77, ppl=5.36, accuracy=43.033, wps=13860.7, ups=1.73, wpb=8016.1, bsz=289.1, num_updates=4200, lr=0.000168016, gnorm=3.406, clip=0, loss_scale=8, train_wall=57, gb_free=13.5, wall=2076
2023-07-06 11:33:15 | INFO | train_inner | epoch 003:   1357 / 1474 loss=5.54, trans_loss=3.429, nll_loss=2.313, w2v_ctc_loss=4.833, contrastive_loss=0, total=4082.18, n_correct=1855.12, ppl=4.97, accuracy=45.444, wps=13822.6, ups=1.69, wpb=8164.4, bsz=308.9, num_updates=4300, lr=0.000172014, gnorm=2.973, clip=0, loss_scale=8, train_wall=59, gb_free=17.1, wall=2135
2023-07-06 11:34:14 | INFO | train_inner | epoch 003:   1457 / 1474 loss=5.388, trans_loss=3.332, nll_loss=2.184, w2v_ctc_loss=4.702, contrastive_loss=0, total=4156.14, n_correct=2003.28, ppl=4.54, accuracy=48.2, wps=14104.6, ups=1.7, wpb=8312.3, bsz=318.8, num_updates=4400, lr=0.000176012, gnorm=2.827, clip=0, loss_scale=8, train_wall=59, gb_free=16.6, wall=2194
2023-07-06 11:34:24 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 11:34:40 | INFO | dev_rec_st | epoch 003 | valid on 'dev_rec_st' subset | loss 5.014 | trans_loss 6.557 | nll_loss 4.178 | w2v_ctc_loss 1.413 | contrastive_loss 0 | total 3909.1 | n_correct 2028.7 | ppl 18.11 | accuracy 51.897 | uer 67.778 | wer 67.503 | raw_wer 67.503 | bleu 0.4 | wps 3891.9 | wpb 3909.1 | bsz 141.8 | num_updates 4417 | best_bleu 0.55
2023-07-06 11:34:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4417 updates
2023-07-06 11:34:40 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.4008.pt
2023-07-06 11:34:43 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.4008.pt
2023-07-06 11:34:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.4008.pt (epoch 3 @ 4417 updates, score 0.4) (writing took 5.6554501069913385 seconds)
2023-07-06 11:34:46 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-07-06 11:34:46 | INFO | train | epoch 003 | loss 6.542 | trans_loss 4.089 | nll_loss 3.172 | w2v_ctc_loss 5.66 | contrastive_loss 0 | total 4079.56 | n_correct 1308.21 | ppl 9.01 | accuracy 32.067 | wps 13279.4 | ups 1.63 | wpb 8159.1 | bsz 305.9 | num_updates 4417 | lr 0.000176692 | gnorm 2.642 | clip 0.4 | loss_scale 8 | train_wall 845 | gb_free 16.8 | wall 2226
2023-07-06 11:34:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 11:34:46 | INFO | fairseq.trainer | begin training epoch 4
2023-07-06 11:34:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 11:35:41 | INFO | train_inner | epoch 004:     83 / 1474 loss=5.448, trans_loss=3.304, nll_loss=2.144, w2v_ctc_loss=4.835, contrastive_loss=0, total=4027.26, n_correct=1959.9, ppl=4.42, accuracy=48.666, wps=9220.4, ups=1.14, wpb=8054.5, bsz=291.4, num_updates=4500, lr=0.00018001, gnorm=3.236, clip=0, loss_scale=8, train_wall=57, gb_free=16.2, wall=2281
2023-07-06 11:36:39 | INFO | train_inner | epoch 004:    183 / 1474 loss=5.243, trans_loss=3.202, nll_loss=2.009, w2v_ctc_loss=4.614, contrastive_loss=0, total=4122.56, n_correct=2140.52, ppl=4.02, accuracy=51.922, wps=14236.7, ups=1.73, wpb=8245.1, bsz=313.1, num_updates=4600, lr=0.000184008, gnorm=3.399, clip=0, loss_scale=8, train_wall=58, gb_free=16.5, wall=2339
2023-07-06 11:37:38 | INFO | train_inner | epoch 004:    283 / 1474 loss=5.303, trans_loss=3.205, nll_loss=2.011, w2v_ctc_loss=4.705, contrastive_loss=0, total=4091.21, n_correct=2118.26, ppl=4.03, accuracy=51.776, wps=13998.6, ups=1.71, wpb=8182.4, bsz=309.2, num_updates=4700, lr=0.000188006, gnorm=3.115, clip=0, loss_scale=8, train_wall=58, gb_free=13.2, wall=2398
2023-07-06 11:38:36 | INFO | train_inner | epoch 004:    383 / 1474 loss=5.173, trans_loss=3.133, nll_loss=1.915, w2v_ctc_loss=4.585, contrastive_loss=0, total=4062.44, n_correct=2184.97, ppl=3.77, accuracy=53.785, wps=13982.8, ups=1.72, wpb=8124.9, bsz=295.7, num_updates=4800, lr=0.000192004, gnorm=3.009, clip=0, loss_scale=8, train_wall=58, gb_free=14.6, wall=2456
2023-07-06 11:39:34 | INFO | train_inner | epoch 004:    483 / 1474 loss=5.003, trans_loss=3.084, nll_loss=1.849, w2v_ctc_loss=4.374, contrastive_loss=0, total=4147.95, n_correct=2296.14, ppl=3.6, accuracy=55.356, wps=14178.6, ups=1.71, wpb=8295.9, bsz=330.7, num_updates=4900, lr=0.000196002, gnorm=3.096, clip=0, loss_scale=8, train_wall=58, gb_free=16.9, wall=2514
2023-07-06 11:40:33 | INFO | train_inner | epoch 004:    583 / 1474 loss=4.949, trans_loss=3.056, nll_loss=1.811, w2v_ctc_loss=4.325, contrastive_loss=0, total=4159.98, n_correct=2332.28, ppl=3.51, accuracy=56.065, wps=14253.7, ups=1.71, wpb=8320, bsz=325.9, num_updates=5000, lr=0.0002, gnorm=2.896, clip=0, loss_scale=8, train_wall=58, gb_free=12.2, wall=2573
2023-07-06 11:41:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-06 11:41:33 | INFO | train_inner | epoch 004:    684 / 1474 loss=5.015, trans_loss=3.036, nll_loss=1.783, w2v_ctc_loss=4.44, contrastive_loss=0, total=4089.62, n_correct=2316, ppl=3.44, accuracy=56.631, wps=13637.8, ups=1.67, wpb=8179.2, bsz=301.7, num_updates=5100, lr=0.00019803, gnorm=3.043, clip=0, loss_scale=8, train_wall=60, gb_free=17, wall=2633
2023-07-06 11:42:31 | INFO | train_inner | epoch 004:    784 / 1474 loss=4.893, trans_loss=2.989, nll_loss=1.721, w2v_ctc_loss=4.314, contrastive_loss=0, total=3971.78, n_correct=2305.43, ppl=3.3, accuracy=58.045, wps=13641, ups=1.72, wpb=7943.6, bsz=280.4, num_updates=5200, lr=0.000196116, gnorm=2.937, clip=0, loss_scale=8, train_wall=58, gb_free=13.2, wall=2691
2023-07-06 11:43:29 | INFO | train_inner | epoch 004:    884 / 1474 loss=4.763, trans_loss=2.95, nll_loss=1.67, w2v_ctc_loss=4.146, contrastive_loss=0, total=4129.29, n_correct=2446.94, ppl=3.18, accuracy=59.258, wps=14069.3, ups=1.7, wpb=8258.6, bsz=310.9, num_updates=5300, lr=0.000194257, gnorm=2.726, clip=0, loss_scale=8, train_wall=58, gb_free=17.6, wall=2750
2023-07-06 11:44:28 | INFO | train_inner | epoch 004:    984 / 1474 loss=4.684, trans_loss=2.91, nll_loss=1.616, w2v_ctc_loss=4.07, contrastive_loss=0, total=4070.95, n_correct=2461.65, ppl=3.07, accuracy=60.469, wps=13896.1, ups=1.71, wpb=8141.9, bsz=304.7, num_updates=5400, lr=0.00019245, gnorm=3.054, clip=0, loss_scale=8, train_wall=58, gb_free=12.8, wall=2808
2023-07-06 11:45:27 | INFO | train_inner | epoch 004:   1084 / 1474 loss=4.616, trans_loss=2.886, nll_loss=1.585, w2v_ctc_loss=3.997, contrastive_loss=0, total=4012.23, n_correct=2454.38, ppl=3, accuracy=61.172, wps=13695.3, ups=1.71, wpb=8024.5, bsz=290.5, num_updates=5500, lr=0.000190693, gnorm=2.919, clip=0, loss_scale=8, train_wall=58, gb_free=16, wall=2867
2023-07-06 11:46:25 | INFO | train_inner | epoch 004:   1184 / 1474 loss=4.503, trans_loss=2.841, nll_loss=1.527, w2v_ctc_loss=3.868, contrastive_loss=0, total=4109.45, n_correct=2570.69, ppl=2.88, accuracy=62.556, wps=14109.7, ups=1.72, wpb=8218.9, bsz=322.3, num_updates=5600, lr=0.000188982, gnorm=2.862, clip=0, loss_scale=8, train_wall=58, gb_free=16.7, wall=2925
2023-07-06 11:47:23 | INFO | train_inner | epoch 004:   1284 / 1474 loss=4.426, trans_loss=2.817, nll_loss=1.495, w2v_ctc_loss=3.784, contrastive_loss=0, total=4098.38, n_correct=2595.4, ppl=2.82, accuracy=63.327, wps=14062.2, ups=1.72, wpb=8196.8, bsz=315.1, num_updates=5700, lr=0.000187317, gnorm=2.762, clip=0, loss_scale=8, train_wall=58, gb_free=16.1, wall=2984
2023-07-06 11:48:21 | INFO | train_inner | epoch 004:   1384 / 1474 loss=4.461, trans_loss=2.797, nll_loss=1.469, w2v_ctc_loss=3.851, contrastive_loss=0, total=4046.51, n_correct=2586.55, ppl=2.77, accuracy=63.921, wps=14040.5, ups=1.73, wpb=8093, bsz=291.7, num_updates=5800, lr=0.000185695, gnorm=2.751, clip=0, loss_scale=8, train_wall=57, gb_free=15.6, wall=3041
2023-07-06 11:49:13 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 11:49:30 | INFO | dev_rec_st | epoch 004 | valid on 'dev_rec_st' subset | loss 4.295 | trans_loss 5.244 | nll_loss 2.428 | w2v_ctc_loss 2.081 | contrastive_loss 0 | total 3909.1 | n_correct 2744.3 | ppl 5.38 | accuracy 70.203 | uer 48.945 | wer 50.274 | raw_wer 50.274 | bleu 0.53 | wps 3973.4 | wpb 3909.1 | bsz 141.8 | num_updates 5890 | best_bleu 0.55
2023-07-06 11:49:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5890 updates
2023-07-06 11:49:30 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.5301.pt
2023-07-06 11:49:32 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.5301.pt
2023-07-06 11:49:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.5301.pt (epoch 4 @ 5890 updates, score 0.53) (writing took 5.674155098997289 seconds)
2023-07-06 11:49:35 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-07-06 11:49:35 | INFO | train | epoch 004 | loss 4.859 | trans_loss 2.998 | nll_loss 1.735 | w2v_ctc_loss 4.247 | contrastive_loss 0 | total 4078.39 | n_correct 2359.28 | ppl 3.33 | accuracy 57.848 | wps 13509.5 | ups 1.66 | wpb 8156.8 | bsz 305.7 | num_updates 5890 | lr 0.000184271 | gnorm 2.98 | clip 0 | loss_scale 8 | train_wall 854 | gb_free 14.8 | wall 3116
2023-07-06 11:49:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 11:49:36 | INFO | fairseq.trainer | begin training epoch 5
2023-07-06 11:49:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 11:49:48 | INFO | train_inner | epoch 005:     10 / 1474 loss=4.447, trans_loss=2.785, nll_loss=1.454, w2v_ctc_loss=3.833, contrastive_loss=0, total=3980.51, n_correct=2552.76, ppl=2.74, accuracy=64.131, wps=9098.7, ups=1.14, wpb=7961, bsz=292.9, num_updates=5900, lr=0.000184115, gnorm=3.049, clip=0, loss_scale=8, train_wall=58, gb_free=16.8, wall=3129
2023-07-06 11:49:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-07-06 11:50:48 | INFO | train_inner | epoch 005:    111 / 1474 loss=4.174, trans_loss=2.711, nll_loss=1.359, w2v_ctc_loss=3.505, contrastive_loss=0, total=4192.65, n_correct=2791.94, ppl=2.56, accuracy=66.591, wps=14042.9, ups=1.67, wpb=8385.3, bsz=333.3, num_updates=6000, lr=0.000182574, gnorm=2.704, clip=0, loss_scale=4, train_wall=59, gb_free=16.3, wall=3188
2023-07-06 11:50:48 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 11:51:05 | INFO | dev_rec_st | epoch 005 | valid on 'dev_rec_st' subset | loss 4.26 | trans_loss 5.145 | nll_loss 2.294 | w2v_ctc_loss 2.195 | contrastive_loss 0 | total 3909.1 | n_correct 2820.7 | ppl 4.91 | accuracy 72.157 | uer 47.477 | wer 48.701 | raw_wer 48.701 | bleu 0.53 | wps 3981.6 | wpb 3909.1 | bsz 141.8 | num_updates 6000 | best_bleu 0.55
2023-07-06 11:51:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-07-06 11:51:05 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_5_6000.pt
2023-07-06 11:51:07 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_5_6000.pt
2023-07-06 11:51:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 0.53) (writing took 6.697190730003058 seconds)
2023-07-06 11:52:09 | INFO | train_inner | epoch 005:    211 / 1474 loss=4.195, trans_loss=2.716, nll_loss=1.365, w2v_ctc_loss=3.53, contrastive_loss=0, total=4122.99, n_correct=2732, ppl=2.58, accuracy=66.263, wps=10176.3, ups=1.23, wpb=8246, bsz=325.1, num_updates=6100, lr=0.000181071, gnorm=2.847, clip=0, loss_scale=4, train_wall=57, gb_free=16, wall=3269
2023-07-06 11:53:07 | INFO | train_inner | epoch 005:    311 / 1474 loss=4.186, trans_loss=2.708, nll_loss=1.355, w2v_ctc_loss=3.528, contrastive_loss=0, total=4053.11, n_correct=2694.23, ppl=2.56, accuracy=66.473, wps=13972.1, ups=1.72, wpb=8106.2, bsz=297.3, num_updates=6200, lr=0.000179605, gnorm=2.605, clip=0, loss_scale=4, train_wall=58, gb_free=16.1, wall=3327
2023-07-06 11:54:06 | INFO | train_inner | epoch 005:    411 / 1474 loss=4.119, trans_loss=2.69, nll_loss=1.332, w2v_ctc_loss=3.442, contrastive_loss=0, total=4092.06, n_correct=2740.98, ppl=2.52, accuracy=66.983, wps=14000.3, ups=1.71, wpb=8184.1, bsz=311.9, num_updates=6300, lr=0.000178174, gnorm=2.847, clip=0, loss_scale=4, train_wall=58, gb_free=16, wall=3386
2023-07-06 11:55:04 | INFO | train_inner | epoch 005:    511 / 1474 loss=4.11, trans_loss=2.679, nll_loss=1.317, w2v_ctc_loss=3.436, contrastive_loss=0, total=3976.38, n_correct=2678.53, ppl=2.49, accuracy=67.361, wps=13724.6, ups=1.73, wpb=7952.8, bsz=278.7, num_updates=6400, lr=0.000176777, gnorm=2.534, clip=0, loss_scale=4, train_wall=58, gb_free=16.9, wall=3444
2023-07-06 11:56:02 | INFO | train_inner | epoch 005:    611 / 1474 loss=4.144, trans_loss=2.677, nll_loss=1.314, w2v_ctc_loss=3.486, contrastive_loss=0, total=4035.2, n_correct=2718.97, ppl=2.49, accuracy=67.381, wps=13850.4, ups=1.72, wpb=8070.4, bsz=297.9, num_updates=6500, lr=0.000175412, gnorm=2.95, clip=0, loss_scale=4, train_wall=58, gb_free=15.3, wall=3502
2023-07-06 11:57:00 | INFO | train_inner | epoch 005:    711 / 1474 loss=4.071, trans_loss=2.653, nll_loss=1.287, w2v_ctc_loss=3.411, contrastive_loss=0, total=4113.81, n_correct=2806.77, ppl=2.44, accuracy=68.228, wps=14068.7, ups=1.71, wpb=8227.6, bsz=322.4, num_updates=6600, lr=0.000174078, gnorm=2.693, clip=0, loss_scale=4, train_wall=58, gb_free=16.9, wall=3561
2023-07-06 11:57:59 | INFO | train_inner | epoch 005:    811 / 1474 loss=4.049, trans_loss=2.644, nll_loss=1.274, w2v_ctc_loss=3.378, contrastive_loss=0, total=4065.38, n_correct=2785.39, ppl=2.42, accuracy=68.515, wps=13806.7, ups=1.7, wpb=8130.8, bsz=298.3, num_updates=6700, lr=0.000172774, gnorm=2.577, clip=0, loss_scale=4, train_wall=58, gb_free=15.7, wall=3619
2023-07-06 11:58:57 | INFO | train_inner | epoch 005:    911 / 1474 loss=4.003, trans_loss=2.623, nll_loss=1.247, w2v_ctc_loss=3.33, contrastive_loss=0, total=4043.56, n_correct=2793.95, ppl=2.37, accuracy=69.096, wps=13870.7, ups=1.72, wpb=8087.1, bsz=298.6, num_updates=6800, lr=0.000171499, gnorm=2.66, clip=0, loss_scale=4, train_wall=58, gb_free=17.1, wall=3678
2023-07-06 11:59:55 | INFO | train_inner | epoch 005:   1011 / 1474 loss=3.984, trans_loss=2.618, nll_loss=1.242, w2v_ctc_loss=3.312, contrastive_loss=0, total=4102.44, n_correct=2841.7, ppl=2.36, accuracy=69.269, wps=14142.5, ups=1.72, wpb=8204.9, bsz=308.3, num_updates=6900, lr=0.000170251, gnorm=2.746, clip=0, loss_scale=4, train_wall=58, gb_free=14.9, wall=3736
2023-07-06 12:00:54 | INFO | train_inner | epoch 005:   1111 / 1474 loss=3.968, trans_loss=2.617, nll_loss=1.242, w2v_ctc_loss=3.284, contrastive_loss=0, total=4098.21, n_correct=2841.27, ppl=2.36, accuracy=69.33, wps=13898.2, ups=1.7, wpb=8196.4, bsz=309.4, num_updates=7000, lr=0.000169031, gnorm=2.379, clip=0, loss_scale=4, train_wall=59, gb_free=16.5, wall=3795
2023-07-06 12:01:53 | INFO | train_inner | epoch 005:   1211 / 1474 loss=3.962, trans_loss=2.596, nll_loss=1.215, w2v_ctc_loss=3.294, contrastive_loss=0, total=4100.89, n_correct=2864.08, ppl=2.32, accuracy=69.84, wps=14028.6, ups=1.71, wpb=8201.8, bsz=304.2, num_updates=7100, lr=0.000167836, gnorm=2.778, clip=0, loss_scale=4, train_wall=58, gb_free=15.8, wall=3853
2023-07-06 12:02:52 | INFO | train_inner | epoch 005:   1311 / 1474 loss=3.92, trans_loss=2.577, nll_loss=1.191, w2v_ctc_loss=3.252, contrastive_loss=0, total=4063.92, n_correct=2864.12, ppl=2.28, accuracy=70.477, wps=13849.4, ups=1.7, wpb=8127.8, bsz=295.6, num_updates=7200, lr=0.000166667, gnorm=2.619, clip=0, loss_scale=4, train_wall=58, gb_free=15.5, wall=3912
2023-07-06 12:03:50 | INFO | train_inner | epoch 005:   1411 / 1474 loss=3.85, trans_loss=2.566, nll_loss=1.178, w2v_ctc_loss=3.153, contrastive_loss=0, total=4082.18, n_correct=2891.98, ppl=2.26, accuracy=70.844, wps=14045.1, ups=1.72, wpb=8164.4, bsz=306, num_updates=7300, lr=0.000165521, gnorm=2.45, clip=0, loss_scale=4, train_wall=58, gb_free=16.8, wall=3970
2023-07-06 12:04:27 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 12:04:44 | INFO | dev_rec_st | epoch 005 | valid on 'dev_rec_st' subset | loss 4.236 | trans_loss 4.754 | nll_loss 1.8 | w2v_ctc_loss 3.028 | contrastive_loss 0 | total 3909.1 | n_correct 3052.3 | ppl 3.48 | accuracy 78.082 | uer 42.248 | wer 43.951 | raw_wer 43.951 | bleu 0.67 | wps 3634 | wpb 3909.1 | bsz 141.8 | num_updates 7363 | best_bleu 0.67
2023-07-06 12:04:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7363 updates
2023-07-06 12:04:44 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 12:04:49 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 12:04:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt (epoch 5 @ 7363 updates, score 0.67) (writing took 9.037622763993568 seconds)
2023-07-06 12:04:53 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-07-06 12:04:53 | INFO | train | epoch 005 | loss 4.048 | trans_loss 2.646 | nll_loss 1.277 | w2v_ctc_loss 3.377 | contrastive_loss 0 | total 4078.54 | n_correct 2789.8 | ppl 2.42 | accuracy 68.402 | wps 13091.4 | ups 1.6 | wpb 8157.1 | bsz 305.7 | num_updates 7363 | lr 0.000164812 | gnorm 2.669 | clip 0 | loss_scale 4 | train_wall 854 | gb_free 16.2 | wall 4033
2023-07-06 12:04:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 12:04:53 | INFO | fairseq.trainer | begin training epoch 6
2023-07-06 12:04:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 12:05:22 | INFO | train_inner | epoch 006:     37 / 1474 loss=3.887, trans_loss=2.568, nll_loss=1.181, w2v_ctc_loss=3.219, contrastive_loss=0, total=4048.98, n_correct=2863.06, ppl=2.27, accuracy=70.711, wps=8752.7, ups=1.08, wpb=8098, bsz=298.2, num_updates=7400, lr=0.000164399, gnorm=2.64, clip=0, loss_scale=4, train_wall=58, gb_free=17.7, wall=4063
2023-07-06 12:06:21 | INFO | train_inner | epoch 006:    137 / 1474 loss=3.729, trans_loss=2.521, nll_loss=1.121, w2v_ctc_loss=3.022, contrastive_loss=0, total=4106.14, n_correct=2966.36, ppl=2.17, accuracy=72.242, wps=14014, ups=1.71, wpb=8212.3, bsz=305.4, num_updates=7500, lr=0.000163299, gnorm=2.445, clip=0, loss_scale=4, train_wall=58, gb_free=16.8, wall=4121
2023-07-06 12:07:19 | INFO | train_inner | epoch 006:    237 / 1474 loss=3.781, trans_loss=2.542, nll_loss=1.148, w2v_ctc_loss=3.078, contrastive_loss=0, total=4058.98, n_correct=2906.09, ppl=2.22, accuracy=71.597, wps=13946.4, ups=1.72, wpb=8118, bsz=291.5, num_updates=7600, lr=0.000162221, gnorm=2.387, clip=0, loss_scale=4, train_wall=58, gb_free=17, wall=4179
2023-07-06 12:08:18 | INFO | train_inner | epoch 006:    337 / 1474 loss=3.704, trans_loss=2.521, nll_loss=1.123, w2v_ctc_loss=2.982, contrastive_loss=0, total=4112.87, n_correct=2973.97, ppl=2.18, accuracy=72.309, wps=13920.8, ups=1.69, wpb=8225.7, bsz=325.9, num_updates=7700, lr=0.000161165, gnorm=2.591, clip=0, loss_scale=4, train_wall=59, gb_free=15.6, wall=4239
2023-07-06 12:09:16 | INFO | train_inner | epoch 006:    437 / 1474 loss=3.665, trans_loss=2.503, nll_loss=1.1, w2v_ctc_loss=2.948, contrastive_loss=0, total=4095.85, n_correct=2979, ppl=2.14, accuracy=72.732, wps=14098.3, ups=1.72, wpb=8191.7, bsz=313.6, num_updates=7800, lr=0.000160128, gnorm=2.535, clip=0, loss_scale=4, train_wall=58, gb_free=16.3, wall=4297
2023-07-06 12:10:15 | INFO | train_inner | epoch 006:    537 / 1474 loss=3.717, trans_loss=2.508, nll_loss=1.106, w2v_ctc_loss=3.013, contrastive_loss=0, total=4111.13, n_correct=2983.37, ppl=2.15, accuracy=72.568, wps=14063, ups=1.71, wpb=8222.3, bsz=305.5, num_updates=7900, lr=0.000159111, gnorm=2.663, clip=0, loss_scale=4, train_wall=58, gb_free=17.1, wall=4355
2023-07-06 12:11:13 | INFO | train_inner | epoch 006:    637 / 1474 loss=3.619, trans_loss=2.489, nll_loss=1.083, w2v_ctc_loss=2.889, contrastive_loss=0, total=4082.3, n_correct=2988.11, ppl=2.12, accuracy=73.197, wps=14053.8, ups=1.72, wpb=8164.6, bsz=313.9, num_updates=8000, lr=0.000158114, gnorm=2.255, clip=0, loss_scale=8, train_wall=58, gb_free=15.8, wall=4413
2023-07-06 12:11:13 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 12:11:30 | INFO | dev_rec_st | epoch 006 | valid on 'dev_rec_st' subset | loss 4.401 | trans_loss 4.636 | nll_loss 1.68 | w2v_ctc_loss 3.852 | contrastive_loss 0 | total 3909.1 | n_correct 3120.8 | ppl 3.2 | accuracy 79.834 | uer 36.668 | wer 38.433 | raw_wer 38.433 | bleu 0.69 | wps 3949.6 | wpb 3909.1 | bsz 141.8 | num_updates 8000 | best_bleu 0.69
2023-07-06 12:11:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-07-06 12:11:30 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_6_8000.pt
2023-07-06 12:11:32 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_6_8000.pt
2023-07-06 12:11:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 0.69) (writing took 9.90469902100449 seconds)
2023-07-06 12:12:38 | INFO | train_inner | epoch 006:    737 / 1474 loss=3.695, trans_loss=2.496, nll_loss=1.092, w2v_ctc_loss=2.996, contrastive_loss=0, total=4091.69, n_correct=2982.87, ppl=2.13, accuracy=72.901, wps=9579.9, ups=1.17, wpb=8183.4, bsz=302.8, num_updates=8100, lr=0.000157135, gnorm=2.662, clip=0, loss_scale=8, train_wall=58, gb_free=13, wall=4499
2023-07-06 12:13:37 | INFO | train_inner | epoch 006:    837 / 1474 loss=3.694, trans_loss=2.498, nll_loss=1.094, w2v_ctc_loss=2.992, contrastive_loss=0, total=4049.48, n_correct=2948.18, ppl=2.14, accuracy=72.804, wps=13831, ups=1.71, wpb=8099, bsz=293, num_updates=8200, lr=0.000156174, gnorm=2.677, clip=0, loss_scale=8, train_wall=58, gb_free=17, wall=4557
2023-07-06 12:14:35 | INFO | train_inner | epoch 006:    937 / 1474 loss=3.685, trans_loss=2.499, nll_loss=1.098, w2v_ctc_loss=2.976, contrastive_loss=0, total=4013.04, n_correct=2920.74, ppl=2.14, accuracy=72.781, wps=13752.5, ups=1.71, wpb=8026.1, bsz=295.3, num_updates=8300, lr=0.00015523, gnorm=2.566, clip=0, loss_scale=8, train_wall=58, gb_free=12.7, wall=4616
2023-07-06 12:15:33 | INFO | train_inner | epoch 006:   1037 / 1474 loss=3.606, trans_loss=2.478, nll_loss=1.072, w2v_ctc_loss=2.872, contrastive_loss=0, total=4107.98, n_correct=3020.08, ppl=2.1, accuracy=73.517, wps=14150.2, ups=1.72, wpb=8216, bsz=318.3, num_updates=8400, lr=0.000154303, gnorm=2.307, clip=0, loss_scale=8, train_wall=58, gb_free=14.2, wall=4674
2023-07-06 12:16:32 | INFO | train_inner | epoch 006:   1137 / 1474 loss=3.677, trans_loss=2.489, nll_loss=1.085, w2v_ctc_loss=2.979, contrastive_loss=0, total=4018.28, n_correct=2935.35, ppl=2.12, accuracy=73.05, wps=13788.2, ups=1.72, wpb=8036.6, bsz=287.1, num_updates=8500, lr=0.000153393, gnorm=2.757, clip=0, loss_scale=8, train_wall=58, gb_free=16.2, wall=4732
2023-07-06 12:17:30 | INFO | train_inner | epoch 006:   1237 / 1474 loss=3.612, trans_loss=2.477, nll_loss=1.072, w2v_ctc_loss=2.891, contrastive_loss=0, total=4083.88, n_correct=2999.86, ppl=2.1, accuracy=73.456, wps=13863.8, ups=1.7, wpb=8167.8, bsz=315.1, num_updates=8600, lr=0.000152499, gnorm=2.602, clip=0, loss_scale=8, train_wall=58, gb_free=12.4, wall=4791
2023-07-06 12:18:28 | INFO | train_inner | epoch 006:   1337 / 1474 loss=3.574, trans_loss=2.454, nll_loss=1.042, w2v_ctc_loss=2.858, contrastive_loss=0, total=4057.15, n_correct=3012.09, ppl=2.06, accuracy=74.242, wps=14062.8, ups=1.73, wpb=8114.3, bsz=302.7, num_updates=8700, lr=0.00015162, gnorm=2.514, clip=0, loss_scale=8, train_wall=57, gb_free=16.9, wall=4849
2023-07-06 12:19:27 | INFO | train_inner | epoch 006:   1437 / 1474 loss=3.64, trans_loss=2.463, nll_loss=1.054, w2v_ctc_loss=2.945, contrastive_loss=0, total=4127.01, n_correct=3048.73, ppl=2.08, accuracy=73.873, wps=14069.3, ups=1.7, wpb=8254, bsz=307, num_updates=8800, lr=0.000150756, gnorm=2.74, clip=0, loss_scale=8, train_wall=58, gb_free=16.9, wall=4907
2023-07-06 12:19:48 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 12:20:05 | INFO | dev_rec_st | epoch 006 | valid on 'dev_rec_st' subset | loss 4.031 | trans_loss 4.55 | nll_loss 1.577 | w2v_ctc_loss 2.82 | contrastive_loss 0 | total 3909.1 | n_correct 3168.5 | ppl 2.98 | accuracy 81.054 | uer 37.204 | wer 39.529 | raw_wer 39.529 | bleu 0.68 | wps 3815.3 | wpb 3909.1 | bsz 141.8 | num_updates 8837 | best_bleu 0.69
2023-07-06 12:20:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8837 updates
2023-07-06 12:20:05 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.6801.pt
2023-07-06 12:20:08 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.6801.pt
2023-07-06 12:20:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.6801.pt (epoch 6 @ 8837 updates, score 0.68) (writing took 5.764387725997949 seconds)
2023-07-06 12:20:11 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-07-06 12:20:11 | INFO | train | epoch 006 | loss 3.671 | trans_loss 2.495 | nll_loss 1.092 | w2v_ctc_loss 2.961 | contrastive_loss 0 | total 4078.54 | n_correct 2975.54 | ppl 2.13 | accuracy 72.956 | wps 13100.6 | ups 1.61 | wpb 8157.1 | bsz 305.7 | num_updates 8837 | lr 0.00015044 | gnorm 2.547 | clip 0 | loss_scale 8 | train_wall 855 | gb_free 15.1 | wall 4951
2023-07-06 12:20:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 12:20:11 | INFO | fairseq.trainer | begin training epoch 7
2023-07-06 12:20:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 12:20:56 | INFO | train_inner | epoch 007:     63 / 1474 loss=3.511, trans_loss=2.439, nll_loss=1.024, w2v_ctc_loss=2.777, contrastive_loss=0, total=4052.03, n_correct=3026.08, ppl=2.03, accuracy=74.681, wps=9140.4, ups=1.13, wpb=8104.1, bsz=308.5, num_updates=8900, lr=0.000149906, gnorm=2.522, clip=0, loss_scale=8, train_wall=58, gb_free=17.2, wall=4996
2023-07-06 12:21:54 | INFO | train_inner | epoch 007:    163 / 1474 loss=3.539, trans_loss=2.438, nll_loss=1.023, w2v_ctc_loss=2.82, contrastive_loss=0, total=4051.29, n_correct=3022.52, ppl=2.03, accuracy=74.606, wps=13867.3, ups=1.71, wpb=8102.6, bsz=303.1, num_updates=9000, lr=0.000149071, gnorm=2.707, clip=0, loss_scale=8, train_wall=58, gb_free=13.6, wall=5054
2023-07-06 12:22:52 | INFO | train_inner | epoch 007:    263 / 1474 loss=3.508, trans_loss=2.426, nll_loss=1.008, w2v_ctc_loss=2.778, contrastive_loss=0, total=4069.23, n_correct=3055.15, ppl=2.01, accuracy=75.079, wps=14026, ups=1.72, wpb=8138.5, bsz=303.6, num_updates=9100, lr=0.00014825, gnorm=2.511, clip=0, loss_scale=8, train_wall=58, gb_free=15.3, wall=5112
2023-07-06 12:23:51 | INFO | train_inner | epoch 007:    363 / 1474 loss=3.475, trans_loss=2.429, nll_loss=1.013, w2v_ctc_loss=2.737, contrastive_loss=0, total=4133.09, n_correct=3097.97, ppl=2.02, accuracy=74.955, wps=14042.6, ups=1.7, wpb=8266.2, bsz=320, num_updates=9200, lr=0.000147442, gnorm=2.419, clip=0, loss_scale=8, train_wall=58, gb_free=13, wall=5171
2023-07-06 12:24:49 | INFO | train_inner | epoch 007:    463 / 1474 loss=3.456, trans_loss=2.425, nll_loss=1.008, w2v_ctc_loss=2.706, contrastive_loss=0, total=4091.71, n_correct=3071.74, ppl=2.01, accuracy=75.072, wps=14082, ups=1.72, wpb=8183.4, bsz=306.8, num_updates=9300, lr=0.000146647, gnorm=2.433, clip=0, loss_scale=8, train_wall=58, gb_free=16.8, wall=5229
2023-07-06 12:25:47 | INFO | train_inner | epoch 007:    563 / 1474 loss=3.464, trans_loss=2.414, nll_loss=0.995, w2v_ctc_loss=2.733, contrastive_loss=0, total=4098.42, n_correct=3085.77, ppl=1.99, accuracy=75.292, wps=14170.5, ups=1.73, wpb=8196.8, bsz=306.5, num_updates=9400, lr=0.000145865, gnorm=2.41, clip=0, loss_scale=8, train_wall=57, gb_free=16.8, wall=5287
2023-07-06 12:26:45 | INFO | train_inner | epoch 007:    663 / 1474 loss=3.478, trans_loss=2.408, nll_loss=0.986, w2v_ctc_loss=2.754, contrastive_loss=0, total=4090.71, n_correct=3092.96, ppl=1.98, accuracy=75.609, wps=13967.9, ups=1.71, wpb=8181.4, bsz=303.6, num_updates=9500, lr=0.000145095, gnorm=2.502, clip=0, loss_scale=8, train_wall=58, gb_free=15.5, wall=5346
2023-07-06 12:27:44 | INFO | train_inner | epoch 007:    763 / 1474 loss=3.474, trans_loss=2.417, nll_loss=0.999, w2v_ctc_loss=2.742, contrastive_loss=0, total=4064.23, n_correct=3057.29, ppl=2, accuracy=75.224, wps=13879.7, ups=1.71, wpb=8128.5, bsz=297.5, num_updates=9600, lr=0.000144338, gnorm=2.506, clip=0, loss_scale=8, train_wall=58, gb_free=15.5, wall=5404
2023-07-06 12:28:43 | INFO | train_inner | epoch 007:    863 / 1474 loss=3.445, trans_loss=2.402, nll_loss=0.981, w2v_ctc_loss=2.708, contrastive_loss=0, total=4083.18, n_correct=3094.56, ppl=1.97, accuracy=75.788, wps=13946.7, ups=1.71, wpb=8166.4, bsz=307.2, num_updates=9700, lr=0.000143592, gnorm=2.423, clip=0, loss_scale=8, train_wall=58, gb_free=17.4, wall=5463
2023-07-06 12:29:41 | INFO | train_inner | epoch 007:    963 / 1474 loss=3.381, trans_loss=2.395, nll_loss=0.973, w2v_ctc_loss=2.619, contrastive_loss=0, total=4078.87, n_correct=3100.02, ppl=1.96, accuracy=76.002, wps=13957.2, ups=1.71, wpb=8157.7, bsz=316.4, num_updates=9800, lr=0.000142857, gnorm=2.251, clip=0, loss_scale=8, train_wall=58, gb_free=15.8, wall=5521
2023-07-06 12:30:39 | INFO | train_inner | epoch 007:   1063 / 1474 loss=3.417, trans_loss=2.401, nll_loss=0.979, w2v_ctc_loss=2.67, contrastive_loss=0, total=4044.09, n_correct=3064.52, ppl=1.97, accuracy=75.778, wps=13842.3, ups=1.71, wpb=8088.2, bsz=291.7, num_updates=9900, lr=0.000142134, gnorm=2.439, clip=0, loss_scale=8, train_wall=58, gb_free=16.8, wall=5580
2023-07-06 12:31:38 | INFO | train_inner | epoch 007:   1163 / 1474 loss=3.4, trans_loss=2.402, nll_loss=0.983, w2v_ctc_loss=2.656, contrastive_loss=0, total=4087.56, n_correct=3094.44, ppl=1.98, accuracy=75.704, wps=14025.7, ups=1.72, wpb=8175.1, bsz=313.9, num_updates=10000, lr=0.000141421, gnorm=2.595, clip=0, loss_scale=8, train_wall=58, gb_free=16.1, wall=5638
2023-07-06 12:31:38 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 12:31:55 | INFO | dev_rec_st | epoch 007 | valid on 'dev_rec_st' subset | loss 4.056 | trans_loss 4.495 | nll_loss 1.492 | w2v_ctc_loss 3.03 | contrastive_loss 0 | total 3909.1 | n_correct 3220.4 | ppl 2.81 | accuracy 82.382 | uer 34.9 | wer 37.049 | raw_wer 37.049 | bleu 0.71 | wps 3819.2 | wpb 3909.1 | bsz 141.8 | num_updates 10000 | best_bleu 0.71
2023-07-06 12:31:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-07-06 12:31:55 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_7_10000.pt
2023-07-06 12:31:57 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_7_10000.pt
2023-07-06 12:32:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 0.71) (writing took 9.951256507993094 seconds)
2023-07-06 12:32:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-06 12:33:04 | INFO | train_inner | epoch 007:   1264 / 1474 loss=3.381, trans_loss=2.386, nll_loss=0.963, w2v_ctc_loss=2.63, contrastive_loss=0, total=4073.24, n_correct=3104.11, ppl=1.95, accuracy=76.207, wps=9479.1, ups=1.16, wpb=8146.5, bsz=299.6, num_updates=10100, lr=0.00014072, gnorm=2.453, clip=0, loss_scale=8, train_wall=58, gb_free=16.7, wall=5724
2023-07-06 12:33:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-07-06 12:34:02 | INFO | train_inner | epoch 007:   1365 / 1474 loss=3.379, trans_loss=2.388, nll_loss=0.965, w2v_ctc_loss=2.63, contrastive_loss=0, total=4111.24, n_correct=3134.35, ppl=1.95, accuracy=76.239, wps=14051.9, ups=1.71, wpb=8222.5, bsz=316.2, num_updates=10200, lr=0.000140028, gnorm=2.393, clip=0, loss_scale=4, train_wall=58, gb_free=16.9, wall=5782
2023-07-06 12:35:01 | INFO | train_inner | epoch 007:   1465 / 1474 loss=3.426, trans_loss=2.404, nll_loss=0.985, w2v_ctc_loss=2.689, contrastive_loss=0, total=4062.88, n_correct=3070.89, ppl=1.98, accuracy=75.584, wps=13733.1, ups=1.69, wpb=8125.8, bsz=298, num_updates=10300, lr=0.000139347, gnorm=2.69, clip=0, loss_scale=4, train_wall=59, gb_free=16.6, wall=5842
2023-07-06 12:35:06 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 12:35:24 | INFO | dev_rec_st | epoch 007 | valid on 'dev_rec_st' subset | loss 3.999 | trans_loss 4.464 | nll_loss 1.486 | w2v_ctc_loss 2.915 | contrastive_loss 0 | total 3909.1 | n_correct 3228 | ppl 2.8 | accuracy 82.577 | uer 34.218 | wer 36.833 | raw_wer 36.833 | bleu 0.7 | wps 3812.1 | wpb 3909.1 | bsz 141.8 | num_updates 10309 | best_bleu 0.71
2023-07-06 12:35:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10309 updates
2023-07-06 12:35:24 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.7006.pt
2023-07-06 12:35:26 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.7006.pt
2023-07-06 12:35:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.7006.pt (epoch 7 @ 10309 updates, score 0.7) (writing took 5.801391532004345 seconds)
2023-07-06 12:35:30 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-07-06 12:35:30 | INFO | train | epoch 007 | loss 3.449 | trans_loss 2.411 | nll_loss 0.992 | w2v_ctc_loss 2.71 | contrastive_loss 0 | total 4078.24 | n_correct 3077.77 | ppl 1.99 | accuracy 75.468 | wps 13067 | ups 1.6 | wpb 8156.5 | bsz 305.5 | num_updates 10309 | lr 0.000139286 | gnorm 2.49 | clip 0 | loss_scale 4 | train_wall 854 | gb_free 13.3 | wall 5870
2023-07-06 12:35:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 12:35:30 | INFO | fairseq.trainer | begin training epoch 8
2023-07-06 12:35:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 12:36:30 | INFO | train_inner | epoch 008:     91 / 1474 loss=3.393, trans_loss=2.374, nll_loss=0.947, w2v_ctc_loss=2.657, contrastive_loss=0, total=4021.33, n_correct=3078.57, ppl=1.93, accuracy=76.556, wps=9027.4, ups=1.12, wpb=8042.7, bsz=290.4, num_updates=10400, lr=0.000138675, gnorm=2.537, clip=0, loss_scale=4, train_wall=58, gb_free=17.7, wall=5931
2023-07-06 12:37:29 | INFO | train_inner | epoch 008:    191 / 1474 loss=3.372, trans_loss=2.366, nll_loss=0.938, w2v_ctc_loss=2.638, contrastive_loss=0, total=3968.87, n_correct=3048.35, ppl=1.92, accuracy=76.806, wps=13521.7, ups=1.7, wpb=7937.7, bsz=286, num_updates=10500, lr=0.000138013, gnorm=2.534, clip=0, loss_scale=4, train_wall=58, gb_free=16, wall=5989
2023-07-06 12:38:27 | INFO | train_inner | epoch 008:    291 / 1474 loss=3.305, trans_loss=2.359, nll_loss=0.93, w2v_ctc_loss=2.542, contrastive_loss=0, total=4150.18, n_correct=3196.21, ppl=1.91, accuracy=77.014, wps=14222.1, ups=1.71, wpb=8300.4, bsz=326.4, num_updates=10600, lr=0.000137361, gnorm=2.344, clip=0, loss_scale=4, train_wall=58, gb_free=16, wall=6048
2023-07-06 12:39:27 | INFO | train_inner | epoch 008:    391 / 1474 loss=3.342, trans_loss=2.363, nll_loss=0.935, w2v_ctc_loss=2.6, contrastive_loss=0, total=4067.63, n_correct=3128.74, ppl=1.91, accuracy=76.918, wps=13783.6, ups=1.69, wpb=8135.3, bsz=297.4, num_updates=10700, lr=0.000136717, gnorm=2.537, clip=0, loss_scale=4, train_wall=59, gb_free=16.5, wall=6107
2023-07-06 12:40:25 | INFO | train_inner | epoch 008:    491 / 1474 loss=3.323, trans_loss=2.373, nll_loss=0.949, w2v_ctc_loss=2.557, contrastive_loss=0, total=4128.61, n_correct=3162.65, ppl=1.93, accuracy=76.603, wps=14084.2, ups=1.71, wpb=8257.2, bsz=331.9, num_updates=10800, lr=0.000136083, gnorm=2.507, clip=0, loss_scale=4, train_wall=58, gb_free=17.6, wall=6165
2023-07-06 12:41:24 | INFO | train_inner | epoch 008:    591 / 1474 loss=3.333, trans_loss=2.359, nll_loss=0.93, w2v_ctc_loss=2.591, contrastive_loss=0, total=4020.6, n_correct=3092.96, ppl=1.9, accuracy=76.928, wps=13751.6, ups=1.71, wpb=8041.2, bsz=284.5, num_updates=10900, lr=0.000135457, gnorm=2.486, clip=0, loss_scale=4, train_wall=58, gb_free=12.6, wall=6224
2023-07-06 12:42:22 | INFO | train_inner | epoch 008:    691 / 1474 loss=3.358, trans_loss=2.359, nll_loss=0.931, w2v_ctc_loss=2.623, contrastive_loss=0, total=4076.99, n_correct=3140.84, ppl=1.91, accuracy=77.038, wps=13935.4, ups=1.71, wpb=8154, bsz=300.3, num_updates=11000, lr=0.00013484, gnorm=2.528, clip=0, loss_scale=4, train_wall=58, gb_free=16.5, wall=6282
2023-07-06 12:43:20 | INFO | train_inner | epoch 008:    791 / 1474 loss=3.321, trans_loss=2.357, nll_loss=0.928, w2v_ctc_loss=2.569, contrastive_loss=0, total=4075.28, n_correct=3141.73, ppl=1.9, accuracy=77.092, wps=14003.7, ups=1.72, wpb=8150.6, bsz=299.3, num_updates=11100, lr=0.000134231, gnorm=2.676, clip=0, loss_scale=4, train_wall=58, gb_free=17.3, wall=6341
2023-07-06 12:44:19 | INFO | train_inner | epoch 008:    891 / 1474 loss=3.292, trans_loss=2.354, nll_loss=0.925, w2v_ctc_loss=2.529, contrastive_loss=0, total=4123.56, n_correct=3184.36, ppl=1.9, accuracy=77.224, wps=14164.6, ups=1.72, wpb=8247.1, bsz=318, num_updates=11200, lr=0.000133631, gnorm=2.522, clip=0, loss_scale=4, train_wall=58, gb_free=16.6, wall=6399
2023-07-06 12:45:16 | INFO | train_inner | epoch 008:    991 / 1474 loss=3.272, trans_loss=2.334, nll_loss=0.9, w2v_ctc_loss=2.523, contrastive_loss=0, total=4086.69, n_correct=3180.03, ppl=1.87, accuracy=77.814, wps=14113.7, ups=1.73, wpb=8173.4, bsz=306.9, num_updates=11300, lr=0.000133038, gnorm=2.343, clip=0, loss_scale=4, train_wall=57, gb_free=16.4, wall=6457
2023-07-06 12:46:15 | INFO | train_inner | epoch 008:   1091 / 1474 loss=3.289, trans_loss=2.351, nll_loss=0.922, w2v_ctc_loss=2.532, contrastive_loss=0, total=4132.82, n_correct=3187.94, ppl=1.9, accuracy=77.137, wps=14015.7, ups=1.7, wpb=8265.6, bsz=311.5, num_updates=11400, lr=0.000132453, gnorm=2.386, clip=0, loss_scale=4, train_wall=59, gb_free=17.5, wall=6516
2023-07-06 12:47:13 | INFO | train_inner | epoch 008:   1191 / 1474 loss=3.267, trans_loss=2.342, nll_loss=0.912, w2v_ctc_loss=2.508, contrastive_loss=0, total=4131.9, n_correct=3205.13, ppl=1.88, accuracy=77.57, wps=14259.3, ups=1.73, wpb=8263.8, bsz=316, num_updates=11500, lr=0.000131876, gnorm=2.466, clip=0, loss_scale=4, train_wall=58, gb_free=13.3, wall=6574
2023-07-06 12:48:12 | INFO | train_inner | epoch 008:   1291 / 1474 loss=3.309, trans_loss=2.349, nll_loss=0.92, w2v_ctc_loss=2.558, contrastive_loss=0, total=4002.04, n_correct=3092.68, ppl=1.89, accuracy=77.278, wps=13752.6, ups=1.72, wpb=8004.1, bsz=289.8, num_updates=11600, lr=0.000131306, gnorm=2.629, clip=0, loss_scale=4, train_wall=58, gb_free=16.4, wall=6632
2023-07-06 12:49:09 | INFO | train_inner | epoch 008:   1391 / 1474 loss=3.255, trans_loss=2.335, nll_loss=0.902, w2v_ctc_loss=2.49, contrastive_loss=0, total=4107.57, n_correct=3195.13, ppl=1.87, accuracy=77.786, wps=14235.8, ups=1.73, wpb=8215.1, bsz=314.5, num_updates=11700, lr=0.000130744, gnorm=2.307, clip=0, loss_scale=4, train_wall=57, gb_free=16.9, wall=6690
2023-07-06 12:49:57 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 12:50:14 | INFO | dev_rec_st | epoch 008 | valid on 'dev_rec_st' subset | loss 3.97 | trans_loss 4.355 | nll_loss 1.335 | w2v_ctc_loss 3.07 | contrastive_loss 0 | total 3909.1 | n_correct 3286.6 | ppl 2.52 | accuracy 84.076 | uer 32.509 | wer 34.611 | raw_wer 34.611 | bleu 0.76 | wps 3973 | wpb 3909.1 | bsz 141.8 | num_updates 11783 | best_bleu 0.76
2023-07-06 12:50:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11783 updates
2023-07-06 12:50:14 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 12:50:19 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 12:50:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt (epoch 8 @ 11783 updates, score 0.76) (writing took 9.10064105699712 seconds)
2023-07-06 12:50:24 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-07-06 12:50:24 | INFO | train | epoch 008 | loss 3.311 | trans_loss 2.354 | nll_loss 0.924 | w2v_ctc_loss 2.558 | contrastive_loss 0 | total 4078.54 | n_correct 3147.74 | ppl 1.9 | accuracy 77.178 | wps 13451.6 | ups 1.65 | wpb 8157.1 | bsz 305.7 | num_updates 11783 | lr 0.000130283 | gnorm 2.48 | clip 0 | loss_scale 4 | train_wall 854 | gb_free 16.9 | wall 6764
2023-07-06 12:50:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 12:50:24 | INFO | fairseq.trainer | begin training epoch 9
2023-07-06 12:50:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 12:50:41 | INFO | train_inner | epoch 009:     17 / 1474 loss=3.237, trans_loss=2.331, nll_loss=0.898, w2v_ctc_loss=2.472, contrastive_loss=0, total=4050.71, n_correct=3155.3, ppl=1.86, accuracy=77.895, wps=8843.1, ups=1.09, wpb=8101.4, bsz=309.5, num_updates=11800, lr=0.000130189, gnorm=2.438, clip=0, loss_scale=4, train_wall=58, gb_free=17.6, wall=6781
2023-07-06 12:51:39 | INFO | train_inner | epoch 009:    117 / 1474 loss=3.211, trans_loss=2.312, nll_loss=0.874, w2v_ctc_loss=2.452, contrastive_loss=0, total=4135.39, n_correct=3249.08, ppl=1.83, accuracy=78.568, wps=14276.3, ups=1.73, wpb=8270.8, bsz=320.8, num_updates=11900, lr=0.000129641, gnorm=2.51, clip=0, loss_scale=4, train_wall=58, gb_free=15.8, wall=6839
2023-07-06 12:52:38 | INFO | train_inner | epoch 009:    217 / 1474 loss=3.238, trans_loss=2.315, nll_loss=0.878, w2v_ctc_loss=2.482, contrastive_loss=0, total=4007.94, n_correct=3139.06, ppl=1.84, accuracy=78.321, wps=13618.1, ups=1.7, wpb=8015.9, bsz=286.6, num_updates=12000, lr=0.000129099, gnorm=2.551, clip=0, loss_scale=4, train_wall=58, gb_free=15.9, wall=6898
2023-07-06 12:52:38 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 12:52:55 | INFO | dev_rec_st | epoch 009 | valid on 'dev_rec_st' subset | loss 3.803 | trans_loss 4.396 | nll_loss 1.388 | w2v_ctc_loss 2.422 | contrastive_loss 0 | total 3909.1 | n_correct 3263.4 | ppl 2.62 | accuracy 83.482 | uer 35.837 | wer 38.205 | raw_wer 38.205 | bleu 0.75 | wps 3864.8 | wpb 3909.1 | bsz 141.8 | num_updates 12000 | best_bleu 0.76
2023-07-06 12:52:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-07-06 12:52:55 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_9_12000.pt
2023-07-06 12:52:57 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_9_12000.pt
2023-07-06 12:53:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 0.75) (writing took 6.7760745999985375 seconds)
2023-07-06 12:54:00 | INFO | train_inner | epoch 009:    317 / 1474 loss=3.143, trans_loss=2.304, nll_loss=0.865, w2v_ctc_loss=2.361, contrastive_loss=0, total=4102.74, n_correct=3230, ppl=1.82, accuracy=78.728, wps=9998.5, ups=1.22, wpb=8205.5, bsz=319.5, num_updates=12100, lr=0.000128565, gnorm=2.341, clip=0, loss_scale=4, train_wall=57, gb_free=16.7, wall=6980
2023-07-06 12:54:59 | INFO | train_inner | epoch 009:    417 / 1474 loss=3.218, trans_loss=2.317, nll_loss=0.882, w2v_ctc_loss=2.458, contrastive_loss=0, total=4131.75, n_correct=3233.03, ppl=1.84, accuracy=78.248, wps=14040, ups=1.7, wpb=8263.5, bsz=309.4, num_updates=12200, lr=0.000128037, gnorm=2.552, clip=0, loss_scale=8, train_wall=58, gb_free=14, wall=7039
2023-07-06 12:55:57 | INFO | train_inner | epoch 009:    517 / 1474 loss=3.217, trans_loss=2.32, nll_loss=0.885, w2v_ctc_loss=2.454, contrastive_loss=0, total=4056.83, n_correct=3171.18, ppl=1.85, accuracy=78.169, wps=13978.9, ups=1.72, wpb=8113.7, bsz=292.5, num_updates=12300, lr=0.000127515, gnorm=2.443, clip=0, loss_scale=8, train_wall=58, gb_free=16.6, wall=7097
2023-07-06 12:56:55 | INFO | train_inner | epoch 009:    617 / 1474 loss=3.154, trans_loss=2.313, nll_loss=0.876, w2v_ctc_loss=2.367, contrastive_loss=0, total=4093.25, n_correct=3208.93, ppl=1.84, accuracy=78.396, wps=14089, ups=1.72, wpb=8186.5, bsz=308.8, num_updates=12400, lr=0.000127, gnorm=2.423, clip=0, loss_scale=8, train_wall=58, gb_free=15.5, wall=7155
2023-07-06 12:57:52 | INFO | train_inner | epoch 009:    717 / 1474 loss=3.232, trans_loss=2.311, nll_loss=0.874, w2v_ctc_loss=2.486, contrastive_loss=0, total=4025.78, n_correct=3157.22, ppl=1.83, accuracy=78.425, wps=13991.2, ups=1.74, wpb=8051.6, bsz=295.8, num_updates=12500, lr=0.000126491, gnorm=2.571, clip=0, loss_scale=8, train_wall=57, gb_free=16.9, wall=7213
2023-07-06 12:58:51 | INFO | train_inner | epoch 009:    817 / 1474 loss=3.179, trans_loss=2.32, nll_loss=0.888, w2v_ctc_loss=2.395, contrastive_loss=0, total=4165.22, n_correct=3259.96, ppl=1.85, accuracy=78.266, wps=14163.1, ups=1.7, wpb=8330.4, bsz=333.1, num_updates=12600, lr=0.000125988, gnorm=2.422, clip=0, loss_scale=8, train_wall=58, gb_free=16.7, wall=7272
2023-07-06 12:59:50 | INFO | train_inner | epoch 009:    917 / 1474 loss=3.202, trans_loss=2.316, nll_loss=0.881, w2v_ctc_loss=2.436, contrastive_loss=0, total=4087.8, n_correct=3200.32, ppl=1.84, accuracy=78.29, wps=13829, ups=1.69, wpb=8175.6, bsz=302.1, num_updates=12700, lr=0.000125491, gnorm=2.576, clip=0, loss_scale=8, train_wall=59, gb_free=12, wall=7331
2023-07-06 13:00:49 | INFO | train_inner | epoch 009:   1017 / 1474 loss=3.249, trans_loss=2.31, nll_loss=0.874, w2v_ctc_loss=2.506, contrastive_loss=0, total=4039.73, n_correct=3167.91, ppl=1.83, accuracy=78.419, wps=13818.9, ups=1.71, wpb=8079.5, bsz=283.2, num_updates=12800, lr=0.000125, gnorm=2.691, clip=0, loss_scale=8, train_wall=58, gb_free=15.9, wall=7389
2023-07-06 13:01:47 | INFO | train_inner | epoch 009:   1117 / 1474 loss=3.139, trans_loss=2.295, nll_loss=0.856, w2v_ctc_loss=2.359, contrastive_loss=0, total=4092.22, n_correct=3234.47, ppl=1.81, accuracy=79.039, wps=14115.6, ups=1.72, wpb=8184.4, bsz=314.6, num_updates=12900, lr=0.000124515, gnorm=2.407, clip=0, loss_scale=8, train_wall=58, gb_free=16.4, wall=7447
2023-07-06 13:02:46 | INFO | train_inner | epoch 009:   1217 / 1474 loss=3.203, trans_loss=2.311, nll_loss=0.876, w2v_ctc_loss=2.444, contrastive_loss=0, total=4080.91, n_correct=3201.08, ppl=1.84, accuracy=78.44, wps=13846.4, ups=1.7, wpb=8161.8, bsz=299.2, num_updates=13000, lr=0.000124035, gnorm=2.448, clip=0, loss_scale=8, train_wall=59, gb_free=16.3, wall=7506
2023-07-06 13:03:44 | INFO | train_inner | epoch 009:   1317 / 1474 loss=3.152, trans_loss=2.301, nll_loss=0.864, w2v_ctc_loss=2.372, contrastive_loss=0, total=4132.39, n_correct=3258.34, ppl=1.82, accuracy=78.849, wps=14175.9, ups=1.72, wpb=8264.8, bsz=325.6, num_updates=13100, lr=0.00012356, gnorm=2.412, clip=0, loss_scale=8, train_wall=58, gb_free=16.5, wall=7564
2023-07-06 13:04:42 | INFO | train_inner | epoch 009:   1417 / 1474 loss=3.193, trans_loss=2.302, nll_loss=0.865, w2v_ctc_loss=2.43, contrastive_loss=0, total=4004.72, n_correct=3151.23, ppl=1.82, accuracy=78.688, wps=13826.4, ups=1.73, wpb=8009.4, bsz=286, num_updates=13200, lr=0.000123091, gnorm=2.512, clip=0, loss_scale=8, train_wall=58, gb_free=14.8, wall=7622
2023-07-06 13:05:15 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 13:05:31 | INFO | dev_rec_st | epoch 009 | valid on 'dev_rec_st' subset | loss 3.881 | trans_loss 4.351 | nll_loss 1.342 | w2v_ctc_loss 2.786 | contrastive_loss 0 | total 3909.1 | n_correct 3292 | ppl 2.54 | accuracy 84.214 | uer 33.531 | wer 36.031 | raw_wer 36.031 | bleu 0.75 | wps 3927.2 | wpb 3909.1 | bsz 141.8 | num_updates 13257 | best_bleu 0.76
2023-07-06 13:05:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13257 updates
2023-07-06 13:05:31 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.7505.pt
2023-07-06 13:05:34 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.7505.pt
2023-07-06 13:05:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.7505.pt (epoch 9 @ 13257 updates, score 0.75) (writing took 5.710390483000083 seconds)
2023-07-06 13:05:37 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-07-06 13:05:37 | INFO | train | epoch 009 | loss 3.195 | trans_loss 2.31 | nll_loss 0.874 | w2v_ctc_loss 2.429 | contrastive_loss 0 | total 4078.54 | n_correct 3202.09 | ppl 1.83 | accuracy 78.511 | wps 13157.9 | ups 1.61 | wpb 8157.1 | bsz 305.7 | num_updates 13257 | lr 0.000122827 | gnorm 2.492 | clip 0 | loss_scale 8 | train_wall 854 | gb_free 11.8 | wall 7678
2023-07-06 13:05:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 13:05:38 | INFO | fairseq.trainer | begin training epoch 10
2023-07-06 13:05:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 13:06:10 | INFO | train_inner | epoch 010:     43 / 1474 loss=3.148, trans_loss=2.29, nll_loss=0.851, w2v_ctc_loss=2.376, contrastive_loss=0, total=4050.4, n_correct=3207.28, ppl=1.8, accuracy=79.184, wps=9231.6, ups=1.14, wpb=8100.8, bsz=317.3, num_updates=13300, lr=0.000122628, gnorm=2.589, clip=0, loss_scale=8, train_wall=57, gb_free=16.3, wall=7710
2023-07-06 13:07:08 | INFO | train_inner | epoch 010:    143 / 1474 loss=3.119, trans_loss=2.274, nll_loss=0.83, w2v_ctc_loss=2.35, contrastive_loss=0, total=4177.21, n_correct=3328.19, ppl=1.78, accuracy=79.675, wps=14321.7, ups=1.71, wpb=8354.4, bsz=315.5, num_updates=13400, lr=0.000122169, gnorm=2.577, clip=0, loss_scale=8, train_wall=58, gb_free=16.4, wall=7768
2023-07-06 13:08:06 | INFO | train_inner | epoch 010:    243 / 1474 loss=3.098, trans_loss=2.274, nll_loss=0.831, w2v_ctc_loss=2.318, contrastive_loss=0, total=4061.28, n_correct=3234.3, ppl=1.78, accuracy=79.637, wps=14037.4, ups=1.73, wpb=8122.6, bsz=307.4, num_updates=13500, lr=0.000121716, gnorm=2.446, clip=0, loss_scale=8, train_wall=57, gb_free=16.2, wall=7826
2023-07-06 13:09:05 | INFO | train_inner | epoch 010:    343 / 1474 loss=3.125, trans_loss=2.279, nll_loss=0.838, w2v_ctc_loss=2.355, contrastive_loss=0, total=4091.08, n_correct=3251.33, ppl=1.79, accuracy=79.474, wps=13918.4, ups=1.7, wpb=8182.2, bsz=302.7, num_updates=13600, lr=0.000121268, gnorm=2.501, clip=0, loss_scale=8, train_wall=58, gb_free=15.5, wall=7885
2023-07-06 13:10:04 | INFO | train_inner | epoch 010:    443 / 1474 loss=3.097, trans_loss=2.286, nll_loss=0.846, w2v_ctc_loss=2.31, contrastive_loss=0, total=4142.02, n_correct=3277.99, ppl=1.8, accuracy=79.14, wps=13948.1, ups=1.68, wpb=8284, bsz=323.1, num_updates=13700, lr=0.000120824, gnorm=2.444, clip=0, loss_scale=8, train_wall=59, gb_free=17, wall=7944
2023-07-06 13:11:03 | INFO | train_inner | epoch 010:    543 / 1474 loss=3.149, trans_loss=2.284, nll_loss=0.843, w2v_ctc_loss=2.382, contrastive_loss=0, total=4021.09, n_correct=3189.97, ppl=1.79, accuracy=79.331, wps=13770.1, ups=1.71, wpb=8042.2, bsz=288.8, num_updates=13800, lr=0.000120386, gnorm=2.407, clip=0, loss_scale=8, train_wall=58, gb_free=14.3, wall=8003
2023-07-06 13:12:01 | INFO | train_inner | epoch 010:    643 / 1474 loss=3.116, trans_loss=2.28, nll_loss=0.839, w2v_ctc_loss=2.336, contrastive_loss=0, total=4115.51, n_correct=3268.47, ppl=1.79, accuracy=79.418, wps=14146.7, ups=1.72, wpb=8231, bsz=320.9, num_updates=13900, lr=0.000119952, gnorm=2.578, clip=0, loss_scale=8, train_wall=58, gb_free=16.6, wall=8061
2023-07-06 13:12:59 | INFO | train_inner | epoch 010:    743 / 1474 loss=3.13, trans_loss=2.28, nll_loss=0.839, w2v_ctc_loss=2.36, contrastive_loss=0, total=4059.96, n_correct=3227.92, ppl=1.79, accuracy=79.506, wps=14048.9, ups=1.73, wpb=8119.9, bsz=301.1, num_updates=14000, lr=0.000119523, gnorm=2.52, clip=0, loss_scale=8, train_wall=57, gb_free=16.9, wall=8119
2023-07-06 13:12:59 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 13:13:16 | INFO | dev_rec_st | epoch 010 | valid on 'dev_rec_st' subset | loss 3.861 | trans_loss 4.305 | nll_loss 1.286 | w2v_ctc_loss 2.825 | contrastive_loss 0 | total 3909.1 | n_correct 3323.9 | ppl 2.44 | accuracy 85.03 | uer 29.929 | wer 32.672 | raw_wer 32.672 | bleu 0.75 | wps 3911.3 | wpb 3909.1 | bsz 141.8 | num_updates 14000 | best_bleu 0.76
2023-07-06 13:13:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-07-06 13:13:16 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_10_14000.pt
2023-07-06 13:13:18 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_10_14000.pt
2023-07-06 13:13:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 0.75) (writing took 6.782604267995339 seconds)
2023-07-06 13:14:21 | INFO | train_inner | epoch 010:    843 / 1474 loss=3.104, trans_loss=2.269, nll_loss=0.825, w2v_ctc_loss=2.328, contrastive_loss=0, total=4073.94, n_correct=3250.34, ppl=1.77, accuracy=79.784, wps=9840.4, ups=1.21, wpb=8147.9, bsz=304.9, num_updates=14100, lr=0.000119098, gnorm=2.482, clip=0, loss_scale=8, train_wall=58, gb_free=16.7, wall=8202
2023-07-06 13:15:19 | INFO | train_inner | epoch 010:    943 / 1474 loss=3.095, trans_loss=2.27, nll_loss=0.827, w2v_ctc_loss=2.316, contrastive_loss=0, total=4089.6, n_correct=3261.39, ppl=1.77, accuracy=79.748, wps=14270.6, ups=1.74, wpb=8179.2, bsz=312, num_updates=14200, lr=0.000118678, gnorm=2.345, clip=0, loss_scale=8, train_wall=57, gb_free=15.7, wall=8259
2023-07-06 13:15:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-06 13:16:18 | INFO | train_inner | epoch 010:   1044 / 1474 loss=3.139, trans_loss=2.281, nll_loss=0.841, w2v_ctc_loss=2.371, contrastive_loss=0, total=4006.55, n_correct=3177.9, ppl=1.79, accuracy=79.318, wps=13558.3, ups=1.69, wpb=8013.1, bsz=290, num_updates=14300, lr=0.000118262, gnorm=2.603, clip=0, loss_scale=8, train_wall=59, gb_free=16, wall=8318
2023-07-06 13:17:16 | INFO | train_inner | epoch 010:   1144 / 1474 loss=3.141, trans_loss=2.281, nll_loss=0.841, w2v_ctc_loss=2.375, contrastive_loss=0, total=3976.56, n_correct=3150.81, ppl=1.79, accuracy=79.235, wps=13761.1, ups=1.73, wpb=7953.1, bsz=278.8, num_updates=14400, lr=0.000117851, gnorm=2.487, clip=0, loss_scale=8, train_wall=57, gb_free=15.5, wall=8376
2023-07-06 13:18:14 | INFO | train_inner | epoch 010:   1244 / 1474 loss=3.098, trans_loss=2.266, nll_loss=0.823, w2v_ctc_loss=2.332, contrastive_loss=0, total=4069.29, n_correct=3248.49, ppl=1.77, accuracy=79.829, wps=13987.2, ups=1.72, wpb=8138.6, bsz=297.6, num_updates=14500, lr=0.000117444, gnorm=2.37, clip=0, loss_scale=8, train_wall=58, gb_free=15.1, wall=8434
2023-07-06 13:19:12 | INFO | train_inner | epoch 010:   1344 / 1474 loss=3.089, trans_loss=2.261, nll_loss=0.816, w2v_ctc_loss=2.314, contrastive_loss=0, total=4085.85, n_correct=3268.45, ppl=1.76, accuracy=79.994, wps=14027.1, ups=1.72, wpb=8171.7, bsz=304.7, num_updates=14600, lr=0.000117041, gnorm=2.331, clip=0, loss_scale=8, train_wall=58, gb_free=16.8, wall=8492
2023-07-06 13:20:11 | INFO | train_inner | epoch 010:   1444 / 1474 loss=3.098, trans_loss=2.277, nll_loss=0.838, w2v_ctc_loss=2.316, contrastive_loss=0, total=4112.45, n_correct=3269.69, ppl=1.79, accuracy=79.507, wps=14051.8, ups=1.71, wpb=8224.9, bsz=320.5, num_updates=14700, lr=0.000116642, gnorm=2.435, clip=0, loss_scale=8, train_wall=58, gb_free=13.3, wall=8551
2023-07-06 13:20:28 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 13:20:45 | INFO | dev_rec_st | epoch 010 | valid on 'dev_rec_st' subset | loss 3.84 | trans_loss 4.297 | nll_loss 1.289 | w2v_ctc_loss 2.772 | contrastive_loss 0 | total 3909.1 | n_correct 3325.6 | ppl 2.44 | accuracy 85.073 | uer 29.509 | wer 32.288 | raw_wer 32.288 | bleu 0.78 | wps 3977.9 | wpb 3909.1 | bsz 141.8 | num_updates 14730 | best_bleu 0.78
2023-07-06 13:20:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14730 updates
2023-07-06 13:20:45 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 13:20:49 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 13:20:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt (epoch 10 @ 14730 updates, score 0.78) (writing took 8.747201101999963 seconds)
2023-07-06 13:20:54 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-07-06 13:20:54 | INFO | train | epoch 010 | loss 3.113 | trans_loss 2.276 | nll_loss 0.834 | w2v_ctc_loss 2.338 | contrastive_loss 0 | total 4078.53 | n_correct 3243.71 | ppl 1.78 | accuracy 79.531 | wps 13113.1 | ups 1.61 | wpb 8157.1 | bsz 305.7 | num_updates 14730 | lr 0.000116524 | gnorm 2.473 | clip 0 | loss_scale 8 | train_wall 853 | gb_free 17.1 | wall 8594
2023-07-06 13:20:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 13:20:54 | INFO | fairseq.trainer | begin training epoch 11
2023-07-06 13:20:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 13:21:41 | INFO | train_inner | epoch 011:     70 / 1474 loss=3.039, trans_loss=2.25, nll_loss=0.803, w2v_ctc_loss=2.247, contrastive_loss=0, total=4101.85, n_correct=3298.34, ppl=1.74, accuracy=80.411, wps=9063.4, ups=1.1, wpb=8203.7, bsz=316.5, num_updates=14800, lr=0.000116248, gnorm=2.418, clip=0, loss_scale=8, train_wall=57, gb_free=16.4, wall=8641
2023-07-06 13:22:40 | INFO | train_inner | epoch 011:    170 / 1474 loss=3.074, trans_loss=2.257, nll_loss=0.811, w2v_ctc_loss=2.304, contrastive_loss=0, total=4053.84, n_correct=3245.23, ppl=1.75, accuracy=80.053, wps=13785.7, ups=1.7, wpb=8107.7, bsz=300.3, num_updates=14900, lr=0.000115857, gnorm=2.479, clip=0, loss_scale=8, train_wall=58, gb_free=16.7, wall=8700
2023-07-06 13:23:38 | INFO | train_inner | epoch 011:    270 / 1474 loss=3.057, trans_loss=2.246, nll_loss=0.798, w2v_ctc_loss=2.283, contrastive_loss=0, total=4059.14, n_correct=3266.96, ppl=1.74, accuracy=80.484, wps=13936.3, ups=1.72, wpb=8118.3, bsz=295.4, num_updates=15000, lr=0.00011547, gnorm=2.42, clip=0, loss_scale=8, train_wall=58, gb_free=15.6, wall=8758
2023-07-06 13:24:36 | INFO | train_inner | epoch 011:    370 / 1474 loss=3.042, trans_loss=2.245, nll_loss=0.797, w2v_ctc_loss=2.254, contrastive_loss=0, total=4024.32, n_correct=3242.98, ppl=1.74, accuracy=80.585, wps=13985.9, ups=1.74, wpb=8048.6, bsz=296.2, num_updates=15100, lr=0.000115087, gnorm=2.392, clip=0, loss_scale=8, train_wall=57, gb_free=12.3, wall=8816
2023-07-06 13:25:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-07-06 13:25:35 | INFO | train_inner | epoch 011:    471 / 1474 loss=3.089, trans_loss=2.262, nll_loss=0.819, w2v_ctc_loss=2.313, contrastive_loss=0, total=4041.01, n_correct=3230.51, ppl=1.76, accuracy=79.943, wps=13560.6, ups=1.68, wpb=8082, bsz=302.7, num_updates=15200, lr=0.000114708, gnorm=2.526, clip=0, loss_scale=4, train_wall=59, gb_free=16.5, wall=8876
2023-07-06 13:26:34 | INFO | train_inner | epoch 011:    571 / 1474 loss=3.081, trans_loss=2.255, nll_loss=0.81, w2v_ctc_loss=2.305, contrastive_loss=0, total=4017.73, n_correct=3219.21, ppl=1.75, accuracy=80.125, wps=13742.9, ups=1.71, wpb=8035.5, bsz=290.9, num_updates=15300, lr=0.000114332, gnorm=2.614, clip=0, loss_scale=4, train_wall=58, gb_free=13.3, wall=8934
2023-07-06 13:27:32 | INFO | train_inner | epoch 011:    671 / 1474 loss=3.054, trans_loss=2.258, nll_loss=0.815, w2v_ctc_loss=2.269, contrastive_loss=0, total=4095.21, n_correct=3280.13, ppl=1.76, accuracy=80.097, wps=14075.5, ups=1.72, wpb=8190.4, bsz=312.1, num_updates=15400, lr=0.000113961, gnorm=2.455, clip=0, loss_scale=4, train_wall=58, gb_free=17, wall=8992
2023-07-06 13:28:30 | INFO | train_inner | epoch 011:    771 / 1474 loss=3.048, trans_loss=2.252, nll_loss=0.807, w2v_ctc_loss=2.273, contrastive_loss=0, total=4089.37, n_correct=3278.39, ppl=1.75, accuracy=80.169, wps=13985.3, ups=1.71, wpb=8178.7, bsz=301, num_updates=15500, lr=0.000113592, gnorm=2.417, clip=0, loss_scale=4, train_wall=58, gb_free=15.8, wall=9051
2023-07-06 13:29:29 | INFO | train_inner | epoch 011:    871 / 1474 loss=3.033, trans_loss=2.242, nll_loss=0.794, w2v_ctc_loss=2.248, contrastive_loss=0, total=4068.23, n_correct=3277.75, ppl=1.73, accuracy=80.569, wps=13953.2, ups=1.71, wpb=8136.5, bsz=294.6, num_updates=15600, lr=0.000113228, gnorm=2.405, clip=0, loss_scale=4, train_wall=58, gb_free=16.6, wall=9109
2023-07-06 13:30:27 | INFO | train_inner | epoch 011:    971 / 1474 loss=3.045, trans_loss=2.248, nll_loss=0.801, w2v_ctc_loss=2.265, contrastive_loss=0, total=4082.53, n_correct=3282.82, ppl=1.74, accuracy=80.411, wps=14043.8, ups=1.72, wpb=8165.1, bsz=304.5, num_updates=15700, lr=0.000112867, gnorm=2.567, clip=0, loss_scale=4, train_wall=58, gb_free=17.7, wall=9167
2023-07-06 13:31:25 | INFO | train_inner | epoch 011:   1071 / 1474 loss=3.052, trans_loss=2.248, nll_loss=0.803, w2v_ctc_loss=2.276, contrastive_loss=0, total=4097.51, n_correct=3294.61, ppl=1.74, accuracy=80.405, wps=14144.8, ups=1.73, wpb=8195, bsz=310.5, num_updates=15800, lr=0.000112509, gnorm=2.512, clip=0, loss_scale=4, train_wall=58, gb_free=15.9, wall=9225
2023-07-06 13:32:23 | INFO | train_inner | epoch 011:   1171 / 1474 loss=3.062, trans_loss=2.251, nll_loss=0.806, w2v_ctc_loss=2.29, contrastive_loss=0, total=4122.45, n_correct=3310.05, ppl=1.75, accuracy=80.293, wps=14070.2, ups=1.71, wpb=8244.9, bsz=311.7, num_updates=15900, lr=0.000112154, gnorm=2.646, clip=0, loss_scale=4, train_wall=58, gb_free=16.9, wall=9284
2023-07-06 13:33:22 | INFO | train_inner | epoch 011:   1271 / 1474 loss=3.065, trans_loss=2.255, nll_loss=0.811, w2v_ctc_loss=2.289, contrastive_loss=0, total=4093.44, n_correct=3283.07, ppl=1.75, accuracy=80.203, wps=14007.6, ups=1.71, wpb=8186.9, bsz=307.4, num_updates=16000, lr=0.000111803, gnorm=2.6, clip=0, loss_scale=4, train_wall=58, gb_free=16.8, wall=9342
2023-07-06 13:33:22 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 13:33:39 | INFO | dev_rec_st | epoch 011 | valid on 'dev_rec_st' subset | loss 3.897 | trans_loss 4.26 | nll_loss 1.238 | w2v_ctc_loss 3.051 | contrastive_loss 0 | total 3909.1 | n_correct 3349 | ppl 2.36 | accuracy 85.672 | uer 28.065 | wer 29.794 | raw_wer 29.794 | bleu 0.8 | wps 3970.2 | wpb 3909.1 | bsz 141.8 | num_updates 16000 | best_bleu 0.8
2023-07-06 13:33:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-07-06 13:33:39 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_11_16000.pt
2023-07-06 13:33:41 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_11_16000.pt
2023-07-06 13:33:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 0.8) (writing took 9.96560827200301 seconds)
2023-07-06 13:34:48 | INFO | train_inner | epoch 011:   1371 / 1474 loss=2.994, trans_loss=2.246, nll_loss=0.801, w2v_ctc_loss=2.187, contrastive_loss=0, total=4130.2, n_correct=3325.26, ppl=1.74, accuracy=80.511, wps=9576.7, ups=1.16, wpb=8260.4, bsz=328.4, num_updates=16100, lr=0.000111456, gnorm=2.314, clip=0, loss_scale=4, train_wall=58, gb_free=15.6, wall=9428
2023-07-06 13:35:46 | INFO | train_inner | epoch 011:   1471 / 1474 loss=3.021, trans_loss=2.238, nll_loss=0.791, w2v_ctc_loss=2.237, contrastive_loss=0, total=4113.38, n_correct=3323.45, ppl=1.73, accuracy=80.796, wps=14093.1, ups=1.71, wpb=8226.8, bsz=315.6, num_updates=16200, lr=0.000111111, gnorm=2.51, clip=0, loss_scale=4, train_wall=58, gb_free=16.4, wall=9487
2023-07-06 13:35:48 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 13:36:06 | INFO | dev_rec_st | epoch 011 | valid on 'dev_rec_st' subset | loss 3.868 | trans_loss 4.229 | nll_loss 1.196 | w2v_ctc_loss 3.025 | contrastive_loss 0 | total 3909.1 | n_correct 3367.7 | ppl 2.29 | accuracy 86.15 | uer 28.02 | wer 29.771 | raw_wer 29.771 | bleu 0.82 | wps 3759.8 | wpb 3909.1 | bsz 141.8 | num_updates 16203 | best_bleu 0.82
2023-07-06 13:36:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16203 updates
2023-07-06 13:36:06 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 13:36:10 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 13:36:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt (epoch 11 @ 16203 updates, score 0.82) (writing took 8.911463968004682 seconds)
2023-07-06 13:36:15 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-07-06 13:36:15 | INFO | train | epoch 011 | loss 3.05 | trans_loss 2.25 | nll_loss 0.804 | w2v_ctc_loss 2.269 | contrastive_loss 0 | total 4078.42 | n_correct 3277.1 | ppl 1.75 | accuracy 80.352 | wps 13044.5 | ups 1.6 | wpb 8156.8 | bsz 305.7 | num_updates 16203 | lr 0.000111101 | gnorm 2.485 | clip 0 | loss_scale 4 | train_wall 854 | gb_free 17 | wall 9515
2023-07-06 13:36:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 13:36:15 | INFO | fairseq.trainer | begin training epoch 12
2023-07-06 13:36:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 13:37:19 | INFO | train_inner | epoch 012:     97 / 1474 loss=2.972, trans_loss=2.228, nll_loss=0.778, w2v_ctc_loss=2.172, contrastive_loss=0, total=4073.64, n_correct=3302.52, ppl=1.71, accuracy=81.07, wps=8830.2, ups=1.08, wpb=8147.3, bsz=312.6, num_updates=16300, lr=0.00011077, gnorm=2.427, clip=0, loss_scale=4, train_wall=58, gb_free=16.8, wall=9579
2023-07-06 13:38:17 | INFO | train_inner | epoch 012:    197 / 1474 loss=2.999, trans_loss=2.229, nll_loss=0.779, w2v_ctc_loss=2.207, contrastive_loss=0, total=4081.16, n_correct=3306.15, ppl=1.72, accuracy=81.01, wps=13935.5, ups=1.71, wpb=8162.3, bsz=296.6, num_updates=16400, lr=0.000110432, gnorm=2.58, clip=0, loss_scale=4, train_wall=58, gb_free=16.5, wall=9638
2023-07-06 13:39:16 | INFO | train_inner | epoch 012:    297 / 1474 loss=2.979, trans_loss=2.226, nll_loss=0.776, w2v_ctc_loss=2.184, contrastive_loss=0, total=4166.29, n_correct=3380.54, ppl=1.71, accuracy=81.14, wps=14198.5, ups=1.7, wpb=8332.6, bsz=326, num_updates=16500, lr=0.000110096, gnorm=2.514, clip=0, loss_scale=4, train_wall=58, gb_free=16.4, wall=9696
2023-07-06 13:40:14 | INFO | train_inner | epoch 012:    397 / 1474 loss=2.981, trans_loss=2.225, nll_loss=0.774, w2v_ctc_loss=2.192, contrastive_loss=0, total=4079.3, n_correct=3310.22, ppl=1.71, accuracy=81.147, wps=13965.6, ups=1.71, wpb=8158.6, bsz=301.9, num_updates=16600, lr=0.000109764, gnorm=2.394, clip=0, loss_scale=4, train_wall=58, gb_free=15.7, wall=9755
2023-07-06 13:41:13 | INFO | train_inner | epoch 012:    497 / 1474 loss=2.994, trans_loss=2.231, nll_loss=0.782, w2v_ctc_loss=2.203, contrastive_loss=0, total=4002.02, n_correct=3239.34, ppl=1.72, accuracy=80.943, wps=13711.9, ups=1.71, wpb=8004, bsz=297.7, num_updates=16700, lr=0.000109435, gnorm=2.544, clip=0, loss_scale=4, train_wall=58, gb_free=17.3, wall=9813
2023-07-06 13:42:12 | INFO | train_inner | epoch 012:    597 / 1474 loss=2.976, trans_loss=2.227, nll_loss=0.778, w2v_ctc_loss=2.185, contrastive_loss=0, total=4167.4, n_correct=3378.43, ppl=1.71, accuracy=81.068, wps=14125.8, ups=1.69, wpb=8334.8, bsz=320.8, num_updates=16800, lr=0.000109109, gnorm=2.422, clip=0, loss_scale=4, train_wall=59, gb_free=15.9, wall=9872
2023-07-06 13:43:10 | INFO | train_inner | epoch 012:    697 / 1474 loss=2.956, trans_loss=2.222, nll_loss=0.771, w2v_ctc_loss=2.155, contrastive_loss=0, total=4124.3, n_correct=3350.11, ppl=1.71, accuracy=81.229, wps=14210.5, ups=1.72, wpb=8248.6, bsz=325.2, num_updates=16900, lr=0.000108786, gnorm=2.461, clip=0, loss_scale=4, train_wall=58, gb_free=15.4, wall=9930
2023-07-06 13:44:08 | INFO | train_inner | epoch 012:    797 / 1474 loss=2.996, trans_loss=2.228, nll_loss=0.778, w2v_ctc_loss=2.213, contrastive_loss=0, total=4021.98, n_correct=3260.55, ppl=1.71, accuracy=81.068, wps=13798.9, ups=1.72, wpb=8044, bsz=296.3, num_updates=17000, lr=0.000108465, gnorm=2.539, clip=0, loss_scale=4, train_wall=58, gb_free=12.9, wall=9988
2023-07-06 13:45:07 | INFO | train_inner | epoch 012:    897 / 1474 loss=2.993, trans_loss=2.224, nll_loss=0.774, w2v_ctc_loss=2.203, contrastive_loss=0, total=4113.15, n_correct=3334.88, ppl=1.71, accuracy=81.078, wps=14100.6, ups=1.71, wpb=8226.3, bsz=306.2, num_updates=17100, lr=0.000108148, gnorm=2.444, clip=0, loss_scale=4, train_wall=58, gb_free=15.5, wall=10047
2023-07-06 13:46:05 | INFO | train_inner | epoch 012:    997 / 1474 loss=3.001, trans_loss=2.228, nll_loss=0.779, w2v_ctc_loss=2.214, contrastive_loss=0, total=4058.38, n_correct=3286.27, ppl=1.72, accuracy=80.975, wps=13940.5, ups=1.72, wpb=8116.8, bsz=301.8, num_updates=17200, lr=0.000107833, gnorm=2.658, clip=0, loss_scale=8, train_wall=58, gb_free=16.3, wall=10105
2023-07-06 13:47:03 | INFO | train_inner | epoch 012:   1097 / 1474 loss=2.976, trans_loss=2.23, nll_loss=0.782, w2v_ctc_loss=2.182, contrastive_loss=0, total=3994.46, n_correct=3230.63, ppl=1.72, accuracy=80.878, wps=13737.4, ups=1.72, wpb=7988.9, bsz=291.2, num_updates=17300, lr=0.000107521, gnorm=2.451, clip=0, loss_scale=8, train_wall=58, gb_free=12.3, wall=10163
2023-07-06 13:48:01 | INFO | train_inner | epoch 012:   1197 / 1474 loss=3.013, trans_loss=2.239, nll_loss=0.794, w2v_ctc_loss=2.222, contrastive_loss=0, total=4134, n_correct=3333.16, ppl=1.73, accuracy=80.628, wps=14178.3, ups=1.71, wpb=8268, bsz=317.5, num_updates=17400, lr=0.000107211, gnorm=2.481, clip=0, loss_scale=8, train_wall=58, gb_free=15.8, wall=10222
2023-07-06 13:49:00 | INFO | train_inner | epoch 012:   1297 / 1474 loss=3.011, trans_loss=2.228, nll_loss=0.78, w2v_ctc_loss=2.236, contrastive_loss=0, total=4024.56, n_correct=3255.62, ppl=1.72, accuracy=80.894, wps=13763.7, ups=1.71, wpb=8049.1, bsz=287, num_updates=17500, lr=0.000106904, gnorm=2.541, clip=0, loss_scale=8, train_wall=58, gb_free=17, wall=10280
2023-07-06 13:49:58 | INFO | train_inner | epoch 012:   1397 / 1474 loss=2.977, trans_loss=2.227, nll_loss=0.778, w2v_ctc_loss=2.182, contrastive_loss=0, total=4064.89, n_correct=3291.72, ppl=1.71, accuracy=80.979, wps=13958.6, ups=1.72, wpb=8129.8, bsz=303.7, num_updates=17600, lr=0.0001066, gnorm=2.531, clip=0, loss_scale=8, train_wall=58, gb_free=17, wall=10338
2023-07-06 13:50:43 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 13:51:00 | INFO | dev_rec_st | epoch 012 | valid on 'dev_rec_st' subset | loss 3.796 | trans_loss 4.222 | nll_loss 1.201 | w2v_ctc_loss 2.802 | contrastive_loss 0 | total 3909.1 | n_correct 3365 | ppl 2.3 | accuracy 86.081 | uer 27.609 | wer 29.764 | raw_wer 29.764 | bleu 0.81 | wps 3908.3 | wpb 3909.1 | bsz 141.8 | num_updates 17677 | best_bleu 0.82
2023-07-06 13:51:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17677 updates
2023-07-06 13:51:00 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8105.pt
2023-07-06 13:51:02 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8105.pt
2023-07-06 13:51:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8105.pt (epoch 12 @ 17677 updates, score 0.81) (writing took 5.766665719987941 seconds)
2023-07-06 13:51:06 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-07-06 13:51:06 | INFO | train | epoch 012 | loss 2.989 | trans_loss 2.228 | nll_loss 0.779 | w2v_ctc_loss 2.198 | contrastive_loss 0 | total 4078.54 | n_correct 3303.81 | ppl 1.72 | accuracy 81.005 | wps 13497.4 | ups 1.65 | wpb 8157.1 | bsz 305.7 | num_updates 17677 | lr 0.000106368 | gnorm 2.499 | clip 0 | loss_scale 8 | train_wall 854 | gb_free 12.9 | wall 10406
2023-07-06 13:51:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 13:51:06 | INFO | fairseq.trainer | begin training epoch 13
2023-07-06 13:51:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 13:51:26 | INFO | train_inner | epoch 013:     23 / 1474 loss=3.01, trans_loss=2.225, nll_loss=0.776, w2v_ctc_loss=2.234, contrastive_loss=0, total=4038.78, n_correct=3270.48, ppl=1.71, accuracy=80.977, wps=9155.6, ups=1.13, wpb=8077.6, bsz=296.2, num_updates=17700, lr=0.000106299, gnorm=2.468, clip=0, loss_scale=8, train_wall=58, gb_free=16.3, wall=10426
2023-07-06 13:52:25 | INFO | train_inner | epoch 013:    123 / 1474 loss=2.92, trans_loss=2.202, nll_loss=0.746, w2v_ctc_loss=2.122, contrastive_loss=0, total=4118.87, n_correct=3372.42, ppl=1.68, accuracy=81.877, wps=14111.1, ups=1.71, wpb=8237.7, bsz=304, num_updates=17800, lr=0.000106, gnorm=2.365, clip=0, loss_scale=8, train_wall=58, gb_free=16.8, wall=10485
2023-07-06 13:53:24 | INFO | train_inner | epoch 013:    223 / 1474 loss=2.929, trans_loss=2.215, nll_loss=0.764, w2v_ctc_loss=2.122, contrastive_loss=0, total=4125.29, n_correct=3357.13, ppl=1.7, accuracy=81.379, wps=13988.6, ups=1.7, wpb=8250.6, bsz=328.1, num_updates=17900, lr=0.000105703, gnorm=2.418, clip=0, loss_scale=8, train_wall=59, gb_free=14.5, wall=10544
2023-07-06 13:54:22 | INFO | train_inner | epoch 013:    323 / 1474 loss=2.945, trans_loss=2.203, nll_loss=0.748, w2v_ctc_loss=2.157, contrastive_loss=0, total=4031.37, n_correct=3299.13, ppl=1.68, accuracy=81.836, wps=13725, ups=1.7, wpb=8062.7, bsz=293.4, num_updates=18000, lr=0.000105409, gnorm=2.524, clip=0, loss_scale=8, train_wall=58, gb_free=17.6, wall=10603
2023-07-06 13:54:22 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 13:54:39 | INFO | dev_rec_st | epoch 013 | valid on 'dev_rec_st' subset | loss 3.836 | trans_loss 4.225 | nll_loss 1.196 | w2v_ctc_loss 2.928 | contrastive_loss 0 | total 3909.1 | n_correct 3367.3 | ppl 2.29 | accuracy 86.14 | uer 28.259 | wer 31.255 | raw_wer 31.255 | bleu 0.77 | wps 3935.9 | wpb 3909.1 | bsz 141.8 | num_updates 18000 | best_bleu 0.82
2023-07-06 13:54:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-07-06 13:54:39 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_13_18000.pt
2023-07-06 13:54:42 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_13_18000.pt
2023-07-06 13:54:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 0.77) (writing took 6.705779185998836 seconds)
2023-07-06 13:55:44 | INFO | train_inner | epoch 013:    423 / 1474 loss=2.921, trans_loss=2.21, nll_loss=0.758, w2v_ctc_loss=2.114, contrastive_loss=0, total=4137.97, n_correct=3375.57, ppl=1.69, accuracy=81.576, wps=10086.1, ups=1.22, wpb=8275.9, bsz=323.5, num_updates=18100, lr=0.000105118, gnorm=2.57, clip=0, loss_scale=8, train_wall=57, gb_free=16.8, wall=10685
2023-07-06 13:56:43 | INFO | train_inner | epoch 013:    523 / 1474 loss=2.941, trans_loss=2.211, nll_loss=0.759, w2v_ctc_loss=2.141, contrastive_loss=0, total=4120.28, n_correct=3360.3, ppl=1.69, accuracy=81.555, wps=14047.2, ups=1.7, wpb=8240.6, bsz=317, num_updates=18200, lr=0.000104828, gnorm=2.414, clip=0, loss_scale=8, train_wall=58, gb_free=17, wall=10743
2023-07-06 13:57:42 | INFO | train_inner | epoch 013:    623 / 1474 loss=2.924, trans_loss=2.201, nll_loss=0.747, w2v_ctc_loss=2.13, contrastive_loss=0, total=4099.3, n_correct=3356.56, ppl=1.68, accuracy=81.881, wps=14002.4, ups=1.71, wpb=8198.6, bsz=306.4, num_updates=18300, lr=0.000104542, gnorm=2.423, clip=0, loss_scale=8, train_wall=58, gb_free=17.2, wall=10802
2023-07-06 13:58:40 | INFO | train_inner | epoch 013:    723 / 1474 loss=2.972, trans_loss=2.213, nll_loss=0.761, w2v_ctc_loss=2.191, contrastive_loss=0, total=4040.93, n_correct=3289.04, ppl=1.69, accuracy=81.393, wps=13850.2, ups=1.71, wpb=8081.9, bsz=286.3, num_updates=18400, lr=0.000104257, gnorm=2.358, clip=0, loss_scale=8, train_wall=58, gb_free=16, wall=10860
2023-07-06 13:59:39 | INFO | train_inner | epoch 013:    823 / 1474 loss=2.96, trans_loss=2.207, nll_loss=0.755, w2v_ctc_loss=2.176, contrastive_loss=0, total=4065.99, n_correct=3320.38, ppl=1.69, accuracy=81.662, wps=13779.6, ups=1.69, wpb=8132, bsz=305.7, num_updates=18500, lr=0.000103975, gnorm=2.493, clip=0, loss_scale=8, train_wall=59, gb_free=17, wall=10919
2023-07-06 14:00:37 | INFO | train_inner | epoch 013:    923 / 1474 loss=2.927, trans_loss=2.201, nll_loss=0.746, w2v_ctc_loss=2.134, contrastive_loss=0, total=4042.58, n_correct=3306.78, ppl=1.68, accuracy=81.799, wps=13915.6, ups=1.72, wpb=8085.2, bsz=296.8, num_updates=18600, lr=0.000103695, gnorm=2.344, clip=0, loss_scale=8, train_wall=58, gb_free=15.9, wall=10977
2023-07-06 14:01:35 | INFO | train_inner | epoch 013:   1023 / 1474 loss=2.966, trans_loss=2.211, nll_loss=0.76, w2v_ctc_loss=2.182, contrastive_loss=0, total=4040.88, n_correct=3293.32, ppl=1.69, accuracy=81.5, wps=13853.3, ups=1.71, wpb=8081.8, bsz=292.3, num_updates=18700, lr=0.000103418, gnorm=2.506, clip=0, loss_scale=8, train_wall=58, gb_free=17.3, wall=11036
2023-07-06 14:02:33 | INFO | train_inner | epoch 013:   1123 / 1474 loss=2.933, trans_loss=2.205, nll_loss=0.752, w2v_ctc_loss=2.142, contrastive_loss=0, total=4043.17, n_correct=3307.11, ppl=1.68, accuracy=81.795, wps=13996, ups=1.73, wpb=8086.3, bsz=305.6, num_updates=18800, lr=0.000103142, gnorm=2.512, clip=0, loss_scale=8, train_wall=57, gb_free=17.5, wall=11093
2023-07-06 14:03:32 | INFO | train_inner | epoch 013:   1223 / 1474 loss=2.953, trans_loss=2.207, nll_loss=0.755, w2v_ctc_loss=2.166, contrastive_loss=0, total=4064.42, n_correct=3316.92, ppl=1.69, accuracy=81.609, wps=13926.7, ups=1.71, wpb=8128.8, bsz=296.7, num_updates=18900, lr=0.000102869, gnorm=2.472, clip=0, loss_scale=8, train_wall=58, gb_free=17.6, wall=11152
2023-07-06 14:04:30 | INFO | train_inner | epoch 013:   1323 / 1474 loss=2.931, trans_loss=2.206, nll_loss=0.754, w2v_ctc_loss=2.139, contrastive_loss=0, total=4050.12, n_correct=3309.27, ppl=1.69, accuracy=81.708, wps=13910, ups=1.72, wpb=8100.2, bsz=306.5, num_updates=19000, lr=0.000102598, gnorm=2.479, clip=0, loss_scale=8, train_wall=58, gb_free=16.5, wall=11210
2023-07-06 14:05:28 | INFO | train_inner | epoch 013:   1423 / 1474 loss=2.927, trans_loss=2.208, nll_loss=0.757, w2v_ctc_loss=2.131, contrastive_loss=0, total=4102.1, n_correct=3346.41, ppl=1.69, accuracy=81.578, wps=14055.8, ups=1.71, wpb=8204.2, bsz=310.5, num_updates=19100, lr=0.000102329, gnorm=2.384, clip=0, loss_scale=8, train_wall=58, gb_free=15.2, wall=11268
2023-07-06 14:05:58 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 14:06:15 | INFO | dev_rec_st | epoch 013 | valid on 'dev_rec_st' subset | loss 3.726 | trans_loss 4.154 | nll_loss 1.127 | w2v_ctc_loss 2.728 | contrastive_loss 0 | total 3909.1 | n_correct 3407.7 | ppl 2.18 | accuracy 87.174 | uer 25.875 | wer 27.974 | raw_wer 27.974 | bleu 0.84 | wps 3792.9 | wpb 3909.1 | bsz 141.8 | num_updates 19151 | best_bleu 0.84
2023-07-06 14:06:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19151 updates
2023-07-06 14:06:15 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 14:06:20 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 14:06:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt (epoch 13 @ 19151 updates, score 0.84) (writing took 9.06691823300207 seconds)
2023-07-06 14:06:24 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-07-06 14:06:24 | INFO | train | epoch 013 | loss 2.938 | trans_loss 2.207 | nll_loss 0.754 | w2v_ctc_loss 2.145 | contrastive_loss 0 | total 4078.54 | n_correct 3330.77 | ppl 1.69 | accuracy 81.666 | wps 13088.7 | ups 1.6 | wpb 8157.1 | bsz 305.7 | num_updates 19151 | lr 0.000102193 | gnorm 2.443 | clip 0 | loss_scale 8 | train_wall 854 | gb_free 17.5 | wall 11325
2023-07-06 14:06:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 14:06:25 | INFO | fairseq.trainer | begin training epoch 14
2023-07-06 14:06:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 14:07:00 | INFO | train_inner | epoch 014:     49 / 1474 loss=2.886, trans_loss=2.187, nll_loss=0.731, w2v_ctc_loss=2.084, contrastive_loss=0, total=4127.5, n_correct=3398.2, ppl=1.66, accuracy=82.331, wps=8967.6, ups=1.09, wpb=8255, bsz=322.3, num_updates=19200, lr=0.000102062, gnorm=2.45, clip=0, loss_scale=8, train_wall=58, gb_free=15.9, wall=11361
2023-07-06 14:07:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-06 14:07:59 | INFO | train_inner | epoch 014:    150 / 1474 loss=2.896, trans_loss=2.188, nll_loss=0.731, w2v_ctc_loss=2.101, contrastive_loss=0, total=4042.08, n_correct=3327.96, ppl=1.66, accuracy=82.333, wps=13835.6, ups=1.71, wpb=8084.2, bsz=303.5, num_updates=19300, lr=0.000101797, gnorm=2.503, clip=0, loss_scale=8, train_wall=58, gb_free=16.6, wall=11419
2023-07-06 14:08:56 | INFO | train_inner | epoch 014:    250 / 1474 loss=2.894, trans_loss=2.187, nll_loss=0.73, w2v_ctc_loss=2.093, contrastive_loss=0, total=4018.66, n_correct=3307.26, ppl=1.66, accuracy=82.298, wps=13890.8, ups=1.73, wpb=8037.3, bsz=292.6, num_updates=19400, lr=0.000101535, gnorm=2.397, clip=0, loss_scale=8, train_wall=57, gb_free=16.6, wall=11477
2023-07-06 14:09:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-07-06 14:09:55 | INFO | train_inner | epoch 014:    351 / 1474 loss=2.873, trans_loss=2.185, nll_loss=0.728, w2v_ctc_loss=2.07, contrastive_loss=0, total=4109.14, n_correct=3388.59, ppl=1.66, accuracy=82.465, wps=13939.6, ups=1.7, wpb=8218.3, bsz=316.2, num_updates=19500, lr=0.000101274, gnorm=2.499, clip=0, loss_scale=4, train_wall=59, gb_free=17.1, wall=11536
2023-07-06 14:10:54 | INFO | train_inner | epoch 014:    451 / 1474 loss=2.9, trans_loss=2.189, nll_loss=0.732, w2v_ctc_loss=2.11, contrastive_loss=0, total=4096.5, n_correct=3367.27, ppl=1.66, accuracy=82.199, wps=14061.9, ups=1.72, wpb=8193, bsz=308.5, num_updates=19600, lr=0.000101015, gnorm=2.435, clip=0, loss_scale=4, train_wall=58, gb_free=15.7, wall=11594
2023-07-06 14:11:52 | INFO | train_inner | epoch 014:    551 / 1474 loss=2.941, trans_loss=2.2, nll_loss=0.746, w2v_ctc_loss=2.16, contrastive_loss=0, total=4017.89, n_correct=3287.77, ppl=1.68, accuracy=81.828, wps=13723.2, ups=1.71, wpb=8035.8, bsz=285.9, num_updates=19700, lr=0.000100759, gnorm=2.596, clip=0, loss_scale=4, train_wall=58, gb_free=11.8, wall=11653
2023-07-06 14:12:51 | INFO | train_inner | epoch 014:    651 / 1474 loss=2.899, trans_loss=2.194, nll_loss=0.74, w2v_ctc_loss=2.103, contrastive_loss=0, total=4107.83, n_correct=3369.69, ppl=1.67, accuracy=82.031, wps=14076.2, ups=1.71, wpb=8215.7, bsz=310.7, num_updates=19800, lr=0.000100504, gnorm=2.48, clip=0, loss_scale=4, train_wall=58, gb_free=15.6, wall=11711
2023-07-06 14:13:49 | INFO | train_inner | epoch 014:    751 / 1474 loss=2.893, trans_loss=2.189, nll_loss=0.733, w2v_ctc_loss=2.091, contrastive_loss=0, total=4065.79, n_correct=3343.33, ppl=1.66, accuracy=82.231, wps=13994.3, ups=1.72, wpb=8131.6, bsz=304.4, num_updates=19900, lr=0.000100251, gnorm=2.392, clip=0, loss_scale=4, train_wall=58, gb_free=16.4, wall=11769
2023-07-06 14:14:47 | INFO | train_inner | epoch 014:    851 / 1474 loss=2.893, trans_loss=2.192, nll_loss=0.737, w2v_ctc_loss=2.094, contrastive_loss=0, total=4145.43, n_correct=3408.27, ppl=1.67, accuracy=82.218, wps=14171.7, ups=1.71, wpb=8290.9, bsz=322.6, num_updates=20000, lr=0.0001, gnorm=2.491, clip=0, loss_scale=4, train_wall=58, gb_free=14.7, wall=11828
2023-07-06 14:14:47 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 14:15:05 | INFO | dev_rec_st | epoch 014 | valid on 'dev_rec_st' subset | loss 3.71 | trans_loss 4.173 | nll_loss 1.147 | w2v_ctc_loss 2.63 | contrastive_loss 0 | total 3909.1 | n_correct 3401.4 | ppl 2.22 | accuracy 87.012 | uer 26.212 | wer 28.791 | raw_wer 28.791 | bleu 0.81 | wps 3876.1 | wpb 3909.1 | bsz 141.8 | num_updates 20000 | best_bleu 0.84
2023-07-06 14:15:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-07-06 14:15:05 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_14_20000.pt
2023-07-06 14:15:07 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_14_20000.pt
2023-07-06 14:15:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 0.81) (writing took 6.704418383000302 seconds)
2023-07-06 14:16:11 | INFO | train_inner | epoch 014:    951 / 1474 loss=2.894, trans_loss=2.195, nll_loss=0.741, w2v_ctc_loss=2.09, contrastive_loss=0, total=4111.97, n_correct=3371.31, ppl=1.67, accuracy=81.988, wps=9870.8, ups=1.2, wpb=8223.9, bsz=309.5, num_updates=20100, lr=9.97509e-05, gnorm=2.439, clip=0, loss_scale=4, train_wall=58, gb_free=16.9, wall=11911
2023-07-06 14:17:10 | INFO | train_inner | epoch 014:   1051 / 1474 loss=2.891, trans_loss=2.188, nll_loss=0.732, w2v_ctc_loss=2.088, contrastive_loss=0, total=4072.9, n_correct=3351.67, ppl=1.66, accuracy=82.292, wps=13769.7, ups=1.69, wpb=8145.8, bsz=300.7, num_updates=20200, lr=9.95037e-05, gnorm=2.453, clip=0, loss_scale=4, train_wall=59, gb_free=15.7, wall=11970
2023-07-06 14:18:08 | INFO | train_inner | epoch 014:   1151 / 1474 loss=2.89, trans_loss=2.202, nll_loss=0.751, w2v_ctc_loss=2.072, contrastive_loss=0, total=4160.82, n_correct=3406.08, ppl=1.68, accuracy=81.861, wps=14183.3, ups=1.7, wpb=8321.6, bsz=328.4, num_updates=20300, lr=9.92583e-05, gnorm=2.339, clip=0, loss_scale=4, train_wall=58, gb_free=17, wall=12029
2023-07-06 14:19:07 | INFO | train_inner | epoch 014:   1251 / 1474 loss=2.917, trans_loss=2.193, nll_loss=0.738, w2v_ctc_loss=2.123, contrastive_loss=0, total=3964.06, n_correct=3250.72, ppl=1.67, accuracy=82.005, wps=13647.2, ups=1.72, wpb=7928.1, bsz=274.5, num_updates=20400, lr=9.90148e-05, gnorm=2.434, clip=0, loss_scale=4, train_wall=58, gb_free=15.7, wall=12087
2023-07-06 14:20:05 | INFO | train_inner | epoch 014:   1351 / 1474 loss=2.864, trans_loss=2.179, nll_loss=0.721, w2v_ctc_loss=2.056, contrastive_loss=0, total=4128.3, n_correct=3407.79, ppl=1.65, accuracy=82.547, wps=14167.3, ups=1.72, wpb=8256.6, bsz=315.4, num_updates=20500, lr=9.8773e-05, gnorm=2.37, clip=0, loss_scale=4, train_wall=58, gb_free=17, wall=12145
2023-07-06 14:21:03 | INFO | train_inner | epoch 014:   1451 / 1474 loss=2.894, trans_loss=2.187, nll_loss=0.732, w2v_ctc_loss=2.096, contrastive_loss=0, total=4067.45, n_correct=3346.03, ppl=1.66, accuracy=82.264, wps=14029.5, ups=1.72, wpb=8134.9, bsz=304.1, num_updates=20600, lr=9.85329e-05, gnorm=2.546, clip=0, loss_scale=4, train_wall=58, gb_free=16.5, wall=12203
2023-07-06 14:21:16 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 14:21:33 | INFO | dev_rec_st | epoch 014 | valid on 'dev_rec_st' subset | loss 3.665 | trans_loss 4.162 | nll_loss 1.135 | w2v_ctc_loss 2.506 | contrastive_loss 0 | total 3909.1 | n_correct 3403.4 | ppl 2.2 | accuracy 87.064 | uer 25.498 | wer 27.814 | raw_wer 27.814 | bleu 0.82 | wps 3936.2 | wpb 3909.1 | bsz 141.8 | num_updates 20623 | best_bleu 0.84
2023-07-06 14:21:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20623 updates
2023-07-06 14:21:33 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8208.pt
2023-07-06 14:21:36 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8208.pt
2023-07-06 14:21:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8208.pt (epoch 14 @ 20623 updates, score 0.82) (writing took 5.66165526000259 seconds)
2023-07-06 14:21:39 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-07-06 14:21:39 | INFO | train | epoch 014 | loss 2.897 | trans_loss 2.19 | nll_loss 0.735 | w2v_ctc_loss 2.098 | contrastive_loss 0 | total 4078.92 | n_correct 3352.19 | ppl 1.66 | accuracy 82.183 | wps 13128.5 | ups 1.61 | wpb 8157.8 | bsz 305.8 | num_updates 20623 | lr 9.8478e-05 | gnorm 2.462 | clip 0 | loss_scale 4 | train_wall 854 | gb_free 16.3 | wall 12239
2023-07-06 14:21:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 14:21:39 | INFO | fairseq.trainer | begin training epoch 15
2023-07-06 14:21:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 14:22:31 | INFO | train_inner | epoch 015:     77 / 1474 loss=2.879, trans_loss=2.179, nll_loss=0.721, w2v_ctc_loss=2.084, contrastive_loss=0, total=4038.45, n_correct=3332.37, ppl=1.65, accuracy=82.516, wps=9177.4, ups=1.14, wpb=8076.9, bsz=300.1, num_updates=20700, lr=9.82946e-05, gnorm=2.55, clip=0, loss_scale=4, train_wall=57, gb_free=16.3, wall=12291
2023-07-06 14:23:29 | INFO | train_inner | epoch 015:    177 / 1474 loss=2.87, trans_loss=2.177, nll_loss=0.718, w2v_ctc_loss=2.07, contrastive_loss=0, total=4050.98, n_correct=3347.28, ppl=1.65, accuracy=82.629, wps=13839, ups=1.71, wpb=8102, bsz=298, num_updates=20800, lr=9.80581e-05, gnorm=2.521, clip=0, loss_scale=4, train_wall=58, gb_free=15.9, wall=12350
2023-07-06 14:24:28 | INFO | train_inner | epoch 015:    277 / 1474 loss=2.843, trans_loss=2.171, nll_loss=0.712, w2v_ctc_loss=2.036, contrastive_loss=0, total=4136.1, n_correct=3424.38, ppl=1.64, accuracy=82.792, wps=14191.4, ups=1.72, wpb=8272.2, bsz=311, num_updates=20900, lr=9.78232e-05, gnorm=2.537, clip=0, loss_scale=4, train_wall=58, gb_free=13.3, wall=12408
2023-07-06 14:25:26 | INFO | train_inner | epoch 015:    377 / 1474 loss=2.859, trans_loss=2.176, nll_loss=0.718, w2v_ctc_loss=2.058, contrastive_loss=0, total=4097.41, n_correct=3386.88, ppl=1.64, accuracy=82.659, wps=14039.6, ups=1.71, wpb=8194.8, bsz=307.4, num_updates=21000, lr=9.759e-05, gnorm=2.608, clip=0, loss_scale=4, train_wall=58, gb_free=14.9, wall=12466
2023-07-06 14:26:24 | INFO | train_inner | epoch 015:    477 / 1474 loss=2.849, trans_loss=2.18, nll_loss=0.723, w2v_ctc_loss=2.029, contrastive_loss=0, total=4023.93, n_correct=3318.89, ppl=1.65, accuracy=82.479, wps=13810.5, ups=1.72, wpb=8047.9, bsz=294.4, num_updates=21100, lr=9.73585e-05, gnorm=2.475, clip=0, loss_scale=4, train_wall=58, gb_free=16.7, wall=12525
2023-07-06 14:27:23 | INFO | train_inner | epoch 015:    577 / 1474 loss=2.863, trans_loss=2.176, nll_loss=0.719, w2v_ctc_loss=2.058, contrastive_loss=0, total=4085.45, n_correct=3376.38, ppl=1.65, accuracy=82.644, wps=14015.2, ups=1.72, wpb=8170.9, bsz=300.4, num_updates=21200, lr=9.71286e-05, gnorm=2.46, clip=0, loss_scale=4, train_wall=58, gb_free=16.9, wall=12583
2023-07-06 14:28:21 | INFO | train_inner | epoch 015:    677 / 1474 loss=2.872, trans_loss=2.181, nll_loss=0.724, w2v_ctc_loss=2.072, contrastive_loss=0, total=4067.1, n_correct=3356.02, ppl=1.65, accuracy=82.516, wps=13999.2, ups=1.72, wpb=8134.2, bsz=304.9, num_updates=21300, lr=9.69003e-05, gnorm=2.386, clip=0, loss_scale=4, train_wall=58, gb_free=16.8, wall=12641
2023-07-06 14:29:19 | INFO | train_inner | epoch 015:    777 / 1474 loss=2.865, trans_loss=2.175, nll_loss=0.718, w2v_ctc_loss=2.064, contrastive_loss=0, total=4103.26, n_correct=3391.3, ppl=1.64, accuracy=82.649, wps=14011.4, ups=1.71, wpb=8206.5, bsz=306.5, num_updates=21400, lr=9.66736e-05, gnorm=2.352, clip=0, loss_scale=4, train_wall=58, gb_free=13.1, wall=12700
2023-07-06 14:30:17 | INFO | train_inner | epoch 015:    877 / 1474 loss=2.869, trans_loss=2.174, nll_loss=0.716, w2v_ctc_loss=2.076, contrastive_loss=0, total=4002.66, n_correct=3306.46, ppl=1.64, accuracy=82.607, wps=13835.6, ups=1.73, wpb=8005.3, bsz=286.2, num_updates=21500, lr=9.64486e-05, gnorm=2.611, clip=0, loss_scale=4, train_wall=57, gb_free=15.1, wall=12757
2023-07-06 14:31:15 | INFO | train_inner | epoch 015:    977 / 1474 loss=2.852, trans_loss=2.176, nll_loss=0.718, w2v_ctc_loss=2.048, contrastive_loss=0, total=4074.47, n_correct=3364.23, ppl=1.65, accuracy=82.569, wps=14075.7, ups=1.73, wpb=8148.9, bsz=305.1, num_updates=21600, lr=9.6225e-05, gnorm=2.391, clip=0, loss_scale=8, train_wall=57, gb_free=15.4, wall=12815
2023-07-06 14:32:14 | INFO | train_inner | epoch 015:   1077 / 1474 loss=2.838, trans_loss=2.18, nll_loss=0.725, w2v_ctc_loss=2.015, contrastive_loss=0, total=4123.2, n_correct=3399.15, ppl=1.65, accuracy=82.44, wps=14008.9, ups=1.7, wpb=8246.4, bsz=326.6, num_updates=21700, lr=9.60031e-05, gnorm=2.375, clip=0, loss_scale=8, train_wall=58, gb_free=13.3, wall=12874
2023-07-06 14:33:12 | INFO | train_inner | epoch 015:   1177 / 1474 loss=2.807, trans_loss=2.166, nll_loss=0.707, w2v_ctc_loss=1.992, contrastive_loss=0, total=4131.89, n_correct=3432.35, ppl=1.63, accuracy=83.07, wps=14183, ups=1.72, wpb=8263.8, bsz=329.1, num_updates=21800, lr=9.57826e-05, gnorm=2.392, clip=0, loss_scale=8, train_wall=58, gb_free=16.9, wall=12932
2023-07-06 14:34:11 | INFO | train_inner | epoch 015:   1277 / 1474 loss=2.86, trans_loss=2.177, nll_loss=0.72, w2v_ctc_loss=2.056, contrastive_loss=0, total=4074.62, n_correct=3365.48, ppl=1.65, accuracy=82.596, wps=13923.6, ups=1.71, wpb=8149.2, bsz=300.6, num_updates=21900, lr=9.55637e-05, gnorm=2.52, clip=0, loss_scale=8, train_wall=58, gb_free=12.4, wall=12991
2023-07-06 14:35:09 | INFO | train_inner | epoch 015:   1377 / 1474 loss=2.854, trans_loss=2.168, nll_loss=0.709, w2v_ctc_loss=2.051, contrastive_loss=0, total=4039.23, n_correct=3348.7, ppl=1.63, accuracy=82.904, wps=13865.7, ups=1.72, wpb=8078.5, bsz=294.1, num_updates=22000, lr=9.53463e-05, gnorm=2.439, clip=0, loss_scale=8, train_wall=58, gb_free=16.3, wall=13049
2023-07-06 14:35:09 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 14:35:26 | INFO | dev_rec_st | epoch 015 | valid on 'dev_rec_st' subset | loss 3.646 | trans_loss 4.128 | nll_loss 1.099 | w2v_ctc_loss 2.52 | contrastive_loss 0 | total 3909.1 | n_correct 3421.4 | ppl 2.14 | accuracy 87.524 | uer 24.861 | wer 26.852 | raw_wer 26.852 | bleu 0.83 | wps 3921.3 | wpb 3909.1 | bsz 141.8 | num_updates 22000 | best_bleu 0.84
2023-07-06 14:35:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-07-06 14:35:26 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_15_22000.pt
2023-07-06 14:35:28 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_15_22000.pt
2023-07-06 14:35:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 0.83) (writing took 6.724877970002126 seconds)
2023-07-06 14:36:31 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 14:36:48 | INFO | dev_rec_st | epoch 015 | valid on 'dev_rec_st' subset | loss 3.71 | trans_loss 4.162 | nll_loss 1.133 | w2v_ctc_loss 2.657 | contrastive_loss 0 | total 3909.1 | n_correct 3404.9 | ppl 2.19 | accuracy 87.102 | uer 25.92 | wer 28.347 | raw_wer 28.347 | bleu 0.83 | wps 3925.4 | wpb 3909.1 | bsz 141.8 | num_updates 22097 | best_bleu 0.84
2023-07-06 14:36:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22097 updates
2023-07-06 14:36:48 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8308.pt
2023-07-06 14:36:50 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8308.pt
2023-07-06 14:36:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8308.pt (epoch 15 @ 22097 updates, score 0.83) (writing took 5.762479703000281 seconds)
2023-07-06 14:36:54 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-07-06 14:36:54 | INFO | train | epoch 015 | loss 2.852 | trans_loss 2.175 | nll_loss 0.717 | w2v_ctc_loss 2.046 | contrastive_loss 0 | total 4078.54 | n_correct 3371.34 | ppl 1.64 | accuracy 82.661 | wps 13145.1 | ups 1.61 | wpb 8157.1 | bsz 305.7 | num_updates 22097 | lr 9.51368e-05 | gnorm 2.467 | clip 0 | loss_scale 8 | train_wall 853 | gb_free 17 | wall 13154
2023-07-06 14:36:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 14:36:54 | INFO | fairseq.trainer | begin training epoch 16
2023-07-06 14:36:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 14:37:03 | INFO | train_inner | epoch 016:      3 / 1474 loss=2.836, trans_loss=2.176, nll_loss=0.72, w2v_ctc_loss=2.027, contrastive_loss=0, total=4107.92, n_correct=3394.57, ppl=1.65, accuracy=82.635, wps=7230, ups=0.88, wpb=8215.8, bsz=316.5, num_updates=22100, lr=9.51303e-05, gnorm=2.446, clip=0, loss_scale=8, train_wall=59, gb_free=16.7, wall=13163
2023-07-06 14:38:00 | INFO | train_inner | epoch 016:    103 / 1474 loss=2.797, trans_loss=2.153, nll_loss=0.69, w2v_ctc_loss=1.983, contrastive_loss=0, total=4063.19, n_correct=3389.7, ppl=1.61, accuracy=83.425, wps=14161.1, ups=1.74, wpb=8126.4, bsz=314.3, num_updates=22200, lr=9.49158e-05, gnorm=2.409, clip=0, loss_scale=8, train_wall=57, gb_free=16.9, wall=13220
2023-07-06 14:38:58 | INFO | train_inner | epoch 016:    203 / 1474 loss=2.787, trans_loss=2.153, nll_loss=0.69, w2v_ctc_loss=1.965, contrastive_loss=0, total=4059.38, n_correct=3387.01, ppl=1.61, accuracy=83.437, wps=13902.5, ups=1.71, wpb=8118.8, bsz=297.4, num_updates=22300, lr=9.47027e-05, gnorm=2.415, clip=0, loss_scale=8, train_wall=58, gb_free=16.8, wall=13279
2023-07-06 14:39:57 | INFO | train_inner | epoch 016:    303 / 1474 loss=2.844, trans_loss=2.167, nll_loss=0.708, w2v_ctc_loss=2.041, contrastive_loss=0, total=4097.36, n_correct=3396.99, ppl=1.63, accuracy=82.907, wps=13993.6, ups=1.71, wpb=8194.7, bsz=308.1, num_updates=22400, lr=9.44911e-05, gnorm=2.578, clip=0, loss_scale=8, train_wall=58, gb_free=16.9, wall=13337
2023-07-06 14:40:55 | INFO | train_inner | epoch 016:    403 / 1474 loss=2.818, trans_loss=2.164, nll_loss=0.703, w2v_ctc_loss=2.004, contrastive_loss=0, total=4003, n_correct=3320.45, ppl=1.63, accuracy=82.949, wps=13837.8, ups=1.73, wpb=8006, bsz=287.3, num_updates=22500, lr=9.42809e-05, gnorm=2.465, clip=0, loss_scale=8, train_wall=57, gb_free=14.8, wall=13395
2023-07-06 14:41:53 | INFO | train_inner | epoch 016:    503 / 1474 loss=2.827, trans_loss=2.165, nll_loss=0.706, w2v_ctc_loss=2.019, contrastive_loss=0, total=4102.48, n_correct=3405.32, ppl=1.63, accuracy=83.006, wps=13989.5, ups=1.71, wpb=8205, bsz=318.4, num_updates=22600, lr=9.40721e-05, gnorm=2.501, clip=0, loss_scale=8, train_wall=58, gb_free=16.3, wall=13454
2023-07-06 14:42:51 | INFO | train_inner | epoch 016:    603 / 1474 loss=2.828, trans_loss=2.156, nll_loss=0.694, w2v_ctc_loss=2.025, contrastive_loss=0, total=4062.21, n_correct=3382.29, ppl=1.62, accuracy=83.262, wps=14089.4, ups=1.73, wpb=8124.4, bsz=300.3, num_updates=22700, lr=9.38647e-05, gnorm=2.505, clip=0, loss_scale=8, train_wall=57, gb_free=16.1, wall=13511
2023-07-06 14:43:49 | INFO | train_inner | epoch 016:    703 / 1474 loss=2.837, trans_loss=2.16, nll_loss=0.699, w2v_ctc_loss=2.036, contrastive_loss=0, total=4041.94, n_correct=3365.11, ppl=1.62, accuracy=83.255, wps=14028.1, ups=1.74, wpb=8083.9, bsz=298.1, num_updates=22800, lr=9.36586e-05, gnorm=2.482, clip=0, loss_scale=8, train_wall=57, gb_free=16.3, wall=13569
2023-07-06 14:44:47 | INFO | train_inner | epoch 016:    803 / 1474 loss=2.808, trans_loss=2.16, nll_loss=0.699, w2v_ctc_loss=1.997, contrastive_loss=0, total=4121.19, n_correct=3424.71, ppl=1.62, accuracy=83.1, wps=14127.2, ups=1.71, wpb=8242.4, bsz=311.3, num_updates=22900, lr=9.34539e-05, gnorm=2.515, clip=0, loss_scale=8, train_wall=58, gb_free=17, wall=13627
2023-07-06 14:45:45 | INFO | train_inner | epoch 016:    903 / 1474 loss=2.81, trans_loss=2.162, nll_loss=0.702, w2v_ctc_loss=1.994, contrastive_loss=0, total=4091.82, n_correct=3398, ppl=1.63, accuracy=83.044, wps=14101.4, ups=1.72, wpb=8183.6, bsz=305.8, num_updates=23000, lr=9.32505e-05, gnorm=2.641, clip=0, loss_scale=8, train_wall=58, gb_free=11.9, wall=13685
2023-07-06 14:46:44 | INFO | train_inner | epoch 016:   1003 / 1474 loss=2.822, trans_loss=2.168, nll_loss=0.71, w2v_ctc_loss=2.004, contrastive_loss=0, total=4065.6, n_correct=3370.56, ppl=1.64, accuracy=82.904, wps=13894.7, ups=1.71, wpb=8131.2, bsz=301.7, num_updates=23100, lr=9.30484e-05, gnorm=2.411, clip=0, loss_scale=8, train_wall=58, gb_free=16.4, wall=13744
2023-07-06 14:47:42 | INFO | train_inner | epoch 016:   1103 / 1474 loss=2.849, trans_loss=2.172, nll_loss=0.715, w2v_ctc_loss=2.042, contrastive_loss=0, total=4059.99, n_correct=3355.93, ppl=1.64, accuracy=82.659, wps=13893.6, ups=1.71, wpb=8120, bsz=296.2, num_updates=23200, lr=9.28477e-05, gnorm=2.499, clip=0, loss_scale=8, train_wall=58, gb_free=16.9, wall=13802
2023-07-06 14:48:41 | INFO | train_inner | epoch 016:   1203 / 1474 loss=2.793, trans_loss=2.165, nll_loss=0.706, w2v_ctc_loss=1.968, contrastive_loss=0, total=4094.48, n_correct=3396.06, ppl=1.63, accuracy=82.942, wps=13870.8, ups=1.69, wpb=8189, bsz=306.3, num_updates=23300, lr=9.26482e-05, gnorm=2.442, clip=0, loss_scale=8, train_wall=59, gb_free=16.4, wall=13861
2023-07-06 14:49:40 | INFO | train_inner | epoch 016:   1303 / 1474 loss=2.824, trans_loss=2.167, nll_loss=0.709, w2v_ctc_loss=2.007, contrastive_loss=0, total=4089.52, n_correct=3390.83, ppl=1.64, accuracy=82.915, wps=13965, ups=1.71, wpb=8179, bsz=310.4, num_updates=23400, lr=9.245e-05, gnorm=2.46, clip=0, loss_scale=8, train_wall=58, gb_free=12.9, wall=13920
2023-07-06 14:50:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-07-06 14:50:39 | INFO | train_inner | epoch 016:   1404 / 1474 loss=2.802, trans_loss=2.158, nll_loss=0.698, w2v_ctc_loss=1.987, contrastive_loss=0, total=4145.96, n_correct=3448.1, ppl=1.62, accuracy=83.168, wps=13961.8, ups=1.68, wpb=8291.9, bsz=324.8, num_updates=23500, lr=9.22531e-05, gnorm=2.334, clip=0, loss_scale=4, train_wall=59, gb_free=16.8, wall=13979
2023-07-06 14:51:20 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 14:51:38 | INFO | dev_rec_st | epoch 016 | valid on 'dev_rec_st' subset | loss 3.703 | trans_loss 4.119 | nll_loss 1.085 | w2v_ctc_loss 2.733 | contrastive_loss 0 | total 3909.1 | n_correct 3427.7 | ppl 2.12 | accuracy 87.685 | uer 24.344 | wer 26.151 | raw_wer 26.151 | bleu 0.84 | wps 3807.5 | wpb 3909.1 | bsz 141.8 | num_updates 23570 | best_bleu 0.84
2023-07-06 14:51:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23570 updates
2023-07-06 14:51:38 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 14:51:42 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 14:51:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt (epoch 16 @ 23570 updates, score 0.84) (writing took 9.145782813997357 seconds)
2023-07-06 14:51:47 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-07-06 14:51:47 | INFO | train | epoch 016 | loss 2.818 | trans_loss 2.162 | nll_loss 0.702 | w2v_ctc_loss 2.006 | contrastive_loss 0 | total 4079.23 | n_correct 3388.27 | ppl 1.63 | accuracy 83.061 | wps 13451.7 | ups 1.65 | wpb 8158.5 | bsz 305.8 | num_updates 23570 | lr 9.2116e-05 | gnorm 2.476 | clip 0 | loss_scale 4 | train_wall 853 | gb_free 15.4 | wall 14047
2023-07-06 14:51:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 14:51:47 | INFO | fairseq.trainer | begin training epoch 17
2023-07-06 14:51:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 14:52:12 | INFO | train_inner | epoch 017:     30 / 1474 loss=2.811, trans_loss=2.162, nll_loss=0.703, w2v_ctc_loss=1.995, contrastive_loss=0, total=4077.4, n_correct=3388.68, ppl=1.63, accuracy=83.109, wps=8776.5, ups=1.08, wpb=8154.8, bsz=302.7, num_updates=23600, lr=9.20575e-05, gnorm=2.49, clip=0, loss_scale=4, train_wall=58, gb_free=15.9, wall=14072
2023-07-06 14:53:10 | INFO | train_inner | epoch 017:    130 / 1474 loss=2.794, trans_loss=2.151, nll_loss=0.689, w2v_ctc_loss=1.981, contrastive_loss=0, total=4042.86, n_correct=3371.93, ppl=1.61, accuracy=83.405, wps=13880.2, ups=1.72, wpb=8085.7, bsz=296.9, num_updates=23700, lr=9.1863e-05, gnorm=2.415, clip=0, loss_scale=4, train_wall=58, gb_free=16.7, wall=14131
2023-07-06 14:54:08 | INFO | train_inner | epoch 017:    230 / 1474 loss=2.769, trans_loss=2.156, nll_loss=0.696, w2v_ctc_loss=1.943, contrastive_loss=0, total=4118.25, n_correct=3430.76, ppl=1.62, accuracy=83.306, wps=14188.6, ups=1.72, wpb=8236.5, bsz=319.3, num_updates=23800, lr=9.16698e-05, gnorm=2.419, clip=0, loss_scale=4, train_wall=58, gb_free=17.2, wall=14189
2023-07-06 14:55:07 | INFO | train_inner | epoch 017:    330 / 1474 loss=2.785, trans_loss=2.156, nll_loss=0.695, w2v_ctc_loss=1.966, contrastive_loss=0, total=4096.53, n_correct=3411.22, ppl=1.62, accuracy=83.271, wps=14010.4, ups=1.71, wpb=8193.1, bsz=307.6, num_updates=23900, lr=9.14779e-05, gnorm=2.379, clip=0, loss_scale=4, train_wall=58, gb_free=16.8, wall=14247
2023-07-06 14:56:06 | INFO | train_inner | epoch 017:    430 / 1474 loss=2.779, trans_loss=2.149, nll_loss=0.685, w2v_ctc_loss=1.961, contrastive_loss=0, total=4089.04, n_correct=3416.12, ppl=1.61, accuracy=83.543, wps=13935.6, ups=1.7, wpb=8178.1, bsz=305.3, num_updates=24000, lr=9.12871e-05, gnorm=2.474, clip=0, loss_scale=4, train_wall=58, gb_free=16.4, wall=14306
2023-07-06 14:56:06 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 14:56:23 | INFO | dev_rec_st | epoch 017 | valid on 'dev_rec_st' subset | loss 3.631 | trans_loss 4.124 | nll_loss 1.09 | w2v_ctc_loss 2.481 | contrastive_loss 0 | total 3909.1 | n_correct 3426.1 | ppl 2.13 | accuracy 87.644 | uer 25.806 | wer 27.982 | raw_wer 27.982 | bleu 0.83 | wps 3591.7 | wpb 3909.1 | bsz 141.8 | num_updates 24000 | best_bleu 0.84
2023-07-06 14:56:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-07-06 14:56:23 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_17_24000.pt
2023-07-06 14:56:26 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_17_24000.pt
2023-07-06 14:56:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 0.83) (writing took 6.90463711299526 seconds)
2023-07-06 14:57:30 | INFO | train_inner | epoch 017:    530 / 1474 loss=2.817, trans_loss=2.157, nll_loss=0.696, w2v_ctc_loss=2.014, contrastive_loss=0, total=4114.04, n_correct=3424.06, ppl=1.62, accuracy=83.229, wps=9691.7, ups=1.18, wpb=8228.1, bsz=309.7, num_updates=24100, lr=9.10975e-05, gnorm=2.471, clip=0, loss_scale=4, train_wall=59, gb_free=16.6, wall=14391
2023-07-06 14:58:29 | INFO | train_inner | epoch 017:    630 / 1474 loss=2.79, trans_loss=2.148, nll_loss=0.685, w2v_ctc_loss=1.978, contrastive_loss=0, total=4093.58, n_correct=3420.72, ppl=1.61, accuracy=83.563, wps=14033.1, ups=1.71, wpb=8187.2, bsz=300.1, num_updates=24200, lr=9.09091e-05, gnorm=2.466, clip=0, loss_scale=4, train_wall=58, gb_free=15.3, wall=14449
2023-07-06 14:59:28 | INFO | train_inner | epoch 017:    730 / 1474 loss=2.8, trans_loss=2.158, nll_loss=0.698, w2v_ctc_loss=1.987, contrastive_loss=0, total=4114.39, n_correct=3421.4, ppl=1.62, accuracy=83.157, wps=14000.6, ups=1.7, wpb=8228.8, bsz=310.5, num_updates=24300, lr=9.07218e-05, gnorm=2.434, clip=0, loss_scale=4, train_wall=58, gb_free=11.9, wall=14508
2023-07-06 15:00:25 | INFO | train_inner | epoch 017:    830 / 1474 loss=2.812, trans_loss=2.15, nll_loss=0.687, w2v_ctc_loss=2.012, contrastive_loss=0, total=4020.22, n_correct=3353.54, ppl=1.61, accuracy=83.417, wps=13986.2, ups=1.74, wpb=8040.4, bsz=294.5, num_updates=24400, lr=9.05357e-05, gnorm=2.505, clip=0, loss_scale=4, train_wall=57, gb_free=16.9, wall=14565
2023-07-06 15:01:22 | INFO | train_inner | epoch 017:    930 / 1474 loss=2.768, trans_loss=2.145, nll_loss=0.682, w2v_ctc_loss=1.952, contrastive_loss=0, total=4058.54, n_correct=3392.93, ppl=1.6, accuracy=83.6, wps=14254.6, ups=1.76, wpb=8117.1, bsz=307.5, num_updates=24500, lr=9.03508e-05, gnorm=2.388, clip=0, loss_scale=4, train_wall=56, gb_free=17.6, wall=14622
2023-07-06 15:02:20 | INFO | train_inner | epoch 017:   1030 / 1474 loss=2.781, trans_loss=2.149, nll_loss=0.687, w2v_ctc_loss=1.968, contrastive_loss=0, total=4041.37, n_correct=3371.01, ppl=1.61, accuracy=83.413, wps=13927.5, ups=1.72, wpb=8082.7, bsz=298.8, num_updates=24600, lr=9.0167e-05, gnorm=2.525, clip=0, loss_scale=4, train_wall=58, gb_free=15.6, wall=14680
2023-07-06 15:03:18 | INFO | train_inner | epoch 017:   1130 / 1474 loss=2.761, trans_loss=2.145, nll_loss=0.682, w2v_ctc_loss=1.933, contrastive_loss=0, total=4047.82, n_correct=3384.27, ppl=1.6, accuracy=83.607, wps=14046, ups=1.74, wpb=8095.6, bsz=301.7, num_updates=24700, lr=8.99843e-05, gnorm=2.37, clip=0, loss_scale=4, train_wall=57, gb_free=15.7, wall=14738
2023-07-06 15:04:16 | INFO | train_inner | epoch 017:   1230 / 1474 loss=2.798, trans_loss=2.168, nll_loss=0.711, w2v_ctc_loss=1.972, contrastive_loss=0, total=4110.37, n_correct=3405.73, ppl=1.64, accuracy=82.857, wps=13984.6, ups=1.7, wpb=8220.7, bsz=323.6, num_updates=24800, lr=8.98027e-05, gnorm=2.438, clip=0, loss_scale=4, train_wall=58, gb_free=16.4, wall=14797
2023-07-06 15:05:14 | INFO | train_inner | epoch 017:   1330 / 1474 loss=2.776, trans_loss=2.148, nll_loss=0.685, w2v_ctc_loss=1.962, contrastive_loss=0, total=4078.72, n_correct=3404.98, ppl=1.61, accuracy=83.482, wps=14069.1, ups=1.72, wpb=8157.4, bsz=301.4, num_updates=24900, lr=8.96221e-05, gnorm=2.456, clip=0, loss_scale=4, train_wall=58, gb_free=15.8, wall=14855
2023-07-06 15:06:13 | INFO | train_inner | epoch 017:   1430 / 1474 loss=2.771, trans_loss=2.145, nll_loss=0.682, w2v_ctc_loss=1.95, contrastive_loss=0, total=4071, n_correct=3407.66, ppl=1.6, accuracy=83.706, wps=13914.6, ups=1.71, wpb=8142, bsz=303.9, num_updates=25000, lr=8.94427e-05, gnorm=2.464, clip=0, loss_scale=4, train_wall=58, gb_free=16.1, wall=14913
2023-07-06 15:06:39 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 15:06:56 | INFO | dev_rec_st | epoch 017 | valid on 'dev_rec_st' subset | loss 3.691 | trans_loss 4.114 | nll_loss 1.08 | w2v_ctc_loss 2.706 | contrastive_loss 0 | total 3909.1 | n_correct 3432.8 | ppl 2.11 | accuracy 87.816 | uer 24.007 | wer 25.991 | raw_wer 25.991 | bleu 0.84 | wps 3909.4 | wpb 3909.1 | bsz 141.8 | num_updates 25044 | best_bleu 0.84
2023-07-06 15:06:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25044 updates
2023-07-06 15:06:56 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 15:07:00 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 15:07:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt (epoch 17 @ 25044 updates, score 0.84) (writing took 9.033043089992134 seconds)
2023-07-06 15:07:05 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-07-06 15:07:05 | INFO | train | epoch 017 | loss 2.787 | trans_loss 2.152 | nll_loss 0.69 | w2v_ctc_loss 1.972 | contrastive_loss 0 | total 4078.54 | n_correct 3401.35 | ppl 1.61 | accuracy 83.396 | wps 13095.9 | ups 1.61 | wpb 8157.1 | bsz 305.7 | num_updates 25044 | lr 8.93641e-05 | gnorm 2.45 | clip 0 | loss_scale 4 | train_wall 853 | gb_free 16.4 | wall 14965
2023-07-06 15:07:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 15:07:05 | INFO | fairseq.trainer | begin training epoch 18
2023-07-06 15:07:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 15:07:46 | INFO | train_inner | epoch 018:     56 / 1474 loss=2.803, trans_loss=2.147, nll_loss=0.684, w2v_ctc_loss=1.999, contrastive_loss=0, total=4070.6, n_correct=3401.33, ppl=1.61, accuracy=83.558, wps=8767.2, ups=1.08, wpb=8141.2, bsz=301.5, num_updates=25100, lr=8.92644e-05, gnorm=2.577, clip=0, loss_scale=4, train_wall=59, gb_free=16.8, wall=15006
2023-07-06 15:08:44 | INFO | train_inner | epoch 018:    156 / 1474 loss=2.733, trans_loss=2.14, nll_loss=0.675, w2v_ctc_loss=1.899, contrastive_loss=0, total=4096.87, n_correct=3435.24, ppl=1.6, accuracy=83.85, wps=14146.7, ups=1.73, wpb=8193.7, bsz=315, num_updates=25200, lr=8.90871e-05, gnorm=2.45, clip=0, loss_scale=4, train_wall=57, gb_free=16.7, wall=15064
2023-07-06 15:09:42 | INFO | train_inner | epoch 018:    256 / 1474 loss=2.755, trans_loss=2.136, nll_loss=0.671, w2v_ctc_loss=1.941, contrastive_loss=0, total=4092.73, n_correct=3437.3, ppl=1.59, accuracy=83.986, wps=13981.3, ups=1.71, wpb=8185.5, bsz=311.2, num_updates=25300, lr=8.89108e-05, gnorm=2.487, clip=0, loss_scale=4, train_wall=58, gb_free=16.8, wall=15123
2023-07-06 15:10:41 | INFO | train_inner | epoch 018:    356 / 1474 loss=2.77, trans_loss=2.137, nll_loss=0.672, w2v_ctc_loss=1.957, contrastive_loss=0, total=4109.72, n_correct=3447.93, ppl=1.59, accuracy=83.897, wps=14030.1, ups=1.71, wpb=8219.4, bsz=302.1, num_updates=25400, lr=8.87357e-05, gnorm=2.692, clip=0, loss_scale=4, train_wall=58, gb_free=16.6, wall=15181
2023-07-06 15:11:40 | INFO | train_inner | epoch 018:    456 / 1474 loss=2.771, trans_loss=2.147, nll_loss=0.685, w2v_ctc_loss=1.953, contrastive_loss=0, total=4013.4, n_correct=3353.15, ppl=1.61, accuracy=83.549, wps=13621.7, ups=1.7, wpb=8026.8, bsz=291.7, num_updates=25500, lr=8.85615e-05, gnorm=2.419, clip=0, loss_scale=8, train_wall=58, gb_free=15.5, wall=15240
2023-07-06 15:12:38 | INFO | train_inner | epoch 018:    556 / 1474 loss=2.726, trans_loss=2.132, nll_loss=0.666, w2v_ctc_loss=1.9, contrastive_loss=0, total=4174.27, n_correct=3513.36, ppl=1.59, accuracy=84.167, wps=14337.6, ups=1.72, wpb=8348.5, bsz=330.4, num_updates=25600, lr=8.83883e-05, gnorm=2.373, clip=0, loss_scale=8, train_wall=58, gb_free=16.8, wall=15298
2023-07-06 15:13:36 | INFO | train_inner | epoch 018:    656 / 1474 loss=2.775, trans_loss=2.147, nll_loss=0.685, w2v_ctc_loss=1.957, contrastive_loss=0, total=4025.11, n_correct=3363.8, ppl=1.61, accuracy=83.57, wps=13877.8, ups=1.72, wpb=8050.2, bsz=298.4, num_updates=25700, lr=8.82162e-05, gnorm=2.47, clip=0, loss_scale=8, train_wall=58, gb_free=16.5, wall=15356
2023-07-06 15:14:35 | INFO | train_inner | epoch 018:    756 / 1474 loss=2.765, trans_loss=2.147, nll_loss=0.685, w2v_ctc_loss=1.933, contrastive_loss=0, total=4147.28, n_correct=3462.33, ppl=1.61, accuracy=83.484, wps=14125.4, ups=1.7, wpb=8294.6, bsz=324.5, num_updates=25800, lr=8.80451e-05, gnorm=2.481, clip=0, loss_scale=8, train_wall=58, gb_free=17.7, wall=15415
2023-07-06 15:15:33 | INFO | train_inner | epoch 018:    856 / 1474 loss=2.751, trans_loss=2.137, nll_loss=0.673, w2v_ctc_loss=1.931, contrastive_loss=0, total=4119.28, n_correct=3456.47, ppl=1.59, accuracy=83.91, wps=14144.4, ups=1.72, wpb=8238.6, bsz=306.1, num_updates=25900, lr=8.7875e-05, gnorm=2.431, clip=0, loss_scale=8, train_wall=58, gb_free=15.7, wall=15473
2023-07-06 15:16:31 | INFO | train_inner | epoch 018:    956 / 1474 loss=2.722, trans_loss=2.132, nll_loss=0.666, w2v_ctc_loss=1.889, contrastive_loss=0, total=4070.93, n_correct=3423.07, ppl=1.59, accuracy=84.086, wps=14135, ups=1.74, wpb=8141.9, bsz=312.7, num_updates=26000, lr=8.77058e-05, gnorm=2.5, clip=0, loss_scale=8, train_wall=57, gb_free=14.6, wall=15531
2023-07-06 15:16:31 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 15:16:48 | INFO | dev_rec_st | epoch 018 | valid on 'dev_rec_st' subset | loss 3.677 | trans_loss 4.107 | nll_loss 1.07 | w2v_ctc_loss 2.673 | contrastive_loss 0 | total 3909.1 | n_correct 3434.9 | ppl 2.1 | accuracy 87.869 | uer 23.853 | wer 25.573 | raw_wer 25.573 | bleu 0.85 | wps 3921 | wpb 3909.1 | bsz 141.8 | num_updates 26000 | best_bleu 0.85
2023-07-06 15:16:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-07-06 15:16:48 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_18_26000.pt
2023-07-06 15:16:50 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_18_26000.pt
2023-07-06 15:16:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 0.85) (writing took 10.130033802008256 seconds)
2023-07-06 15:17:57 | INFO | train_inner | epoch 018:   1056 / 1474 loss=2.769, trans_loss=2.138, nll_loss=0.673, w2v_ctc_loss=1.956, contrastive_loss=0, total=4078.83, n_correct=3419.78, ppl=1.59, accuracy=83.842, wps=9428.7, ups=1.16, wpb=8157.7, bsz=298.3, num_updates=26100, lr=8.75376e-05, gnorm=2.5, clip=0, loss_scale=8, train_wall=58, gb_free=16.8, wall=15617
2023-07-06 15:18:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-07-06 15:18:56 | INFO | train_inner | epoch 018:   1157 / 1474 loss=2.752, trans_loss=2.141, nll_loss=0.678, w2v_ctc_loss=1.927, contrastive_loss=0, total=4100.47, n_correct=3435.05, ppl=1.6, accuracy=83.772, wps=13930.3, ups=1.7, wpb=8200.9, bsz=317.1, num_updates=26200, lr=8.73704e-05, gnorm=2.595, clip=0, loss_scale=4, train_wall=58, gb_free=16.5, wall=15676
2023-07-06 15:19:54 | INFO | train_inner | epoch 018:   1257 / 1474 loss=2.761, trans_loss=2.136, nll_loss=0.671, w2v_ctc_loss=1.947, contrastive_loss=0, total=4034.15, n_correct=3382.06, ppl=1.59, accuracy=83.836, wps=13855.5, ups=1.72, wpb=8068.3, bsz=290.1, num_updates=26300, lr=8.72041e-05, gnorm=2.509, clip=0, loss_scale=4, train_wall=58, gb_free=16.5, wall=15735
2023-07-06 15:20:52 | INFO | train_inner | epoch 018:   1357 / 1474 loss=2.794, trans_loss=2.147, nll_loss=0.686, w2v_ctc_loss=1.988, contrastive_loss=0, total=3994.92, n_correct=3332.49, ppl=1.61, accuracy=83.418, wps=13803.6, ups=1.73, wpb=7989.8, bsz=285.4, num_updates=26400, lr=8.70388e-05, gnorm=2.456, clip=0, loss_scale=4, train_wall=57, gb_free=17.7, wall=15792
2023-07-06 15:21:50 | INFO | train_inner | epoch 018:   1457 / 1474 loss=2.762, trans_loss=2.143, nll_loss=0.681, w2v_ctc_loss=1.942, contrastive_loss=0, total=4073.74, n_correct=3407.4, ppl=1.6, accuracy=83.643, wps=13974.6, ups=1.72, wpb=8147.5, bsz=300.5, num_updates=26500, lr=8.68744e-05, gnorm=2.399, clip=0, loss_scale=4, train_wall=58, gb_free=10.9, wall=15851
2023-07-06 15:22:00 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 15:22:17 | INFO | dev_rec_st | epoch 018 | valid on 'dev_rec_st' subset | loss 3.661 | trans_loss 4.135 | nll_loss 1.121 | w2v_ctc_loss 2.553 | contrastive_loss 0 | total 3909.1 | n_correct 3419.8 | ppl 2.18 | accuracy 87.483 | uer 23.731 | wer 25.823 | raw_wer 25.823 | bleu 0.83 | wps 3796.1 | wpb 3909.1 | bsz 141.8 | num_updates 26517 | best_bleu 0.85
2023-07-06 15:22:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26517 updates
2023-07-06 15:22:17 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8306.pt
2023-07-06 15:22:20 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8306.pt
2023-07-06 15:22:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8306.pt (epoch 18 @ 26517 updates, score 0.83) (writing took 5.637928696000017 seconds)
2023-07-06 15:22:23 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-07-06 15:22:23 | INFO | train | epoch 018 | loss 2.757 | trans_loss 2.14 | nll_loss 0.676 | w2v_ctc_loss 1.937 | contrastive_loss 0 | total 4078.83 | n_correct 3417.71 | ppl 1.6 | accuracy 83.791 | wps 13086.2 | ups 1.6 | wpb 8157.7 | bsz 305.8 | num_updates 26517 | lr 8.68466e-05 | gnorm 2.485 | clip 0 | loss_scale 4 | train_wall 853 | gb_free 15.9 | wall 15884
2023-07-06 15:22:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 15:22:24 | INFO | fairseq.trainer | begin training epoch 19
2023-07-06 15:22:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 15:23:19 | INFO | train_inner | epoch 019:     83 / 1474 loss=2.738, trans_loss=2.133, nll_loss=0.668, w2v_ctc_loss=1.921, contrastive_loss=0, total=4037.03, n_correct=3391.09, ppl=1.59, accuracy=84, wps=9122.7, ups=1.13, wpb=8074.1, bsz=297.1, num_updates=26600, lr=8.6711e-05, gnorm=2.494, clip=0, loss_scale=4, train_wall=57, gb_free=16.7, wall=15939
2023-07-06 15:24:18 | INFO | train_inner | epoch 019:    183 / 1474 loss=2.717, trans_loss=2.128, nll_loss=0.662, w2v_ctc_loss=1.884, contrastive_loss=0, total=4167.56, n_correct=3510.24, ppl=1.58, accuracy=84.228, wps=14128.2, ups=1.7, wpb=8335.1, bsz=323.2, num_updates=26700, lr=8.65485e-05, gnorm=2.336, clip=0, loss_scale=4, train_wall=59, gb_free=12.9, wall=15998
2023-07-06 15:25:16 | INFO | train_inner | epoch 019:    283 / 1474 loss=2.733, trans_loss=2.126, nll_loss=0.658, w2v_ctc_loss=1.914, contrastive_loss=0, total=4130.77, n_correct=3481.08, ppl=1.58, accuracy=84.272, wps=14182.7, ups=1.72, wpb=8261.5, bsz=308.2, num_updates=26800, lr=8.63868e-05, gnorm=2.476, clip=0, loss_scale=4, train_wall=58, gb_free=16, wall=16057
2023-07-06 15:26:15 | INFO | train_inner | epoch 019:    383 / 1474 loss=2.706, trans_loss=2.132, nll_loss=0.667, w2v_ctc_loss=1.871, contrastive_loss=0, total=4106.55, n_correct=3454.24, ppl=1.59, accuracy=84.115, wps=14095.3, ups=1.72, wpb=8213.1, bsz=312.3, num_updates=26900, lr=8.62261e-05, gnorm=2.452, clip=0, loss_scale=4, train_wall=58, gb_free=14.4, wall=16115
2023-07-06 15:27:12 | INFO | train_inner | epoch 019:    483 / 1474 loss=2.744, trans_loss=2.131, nll_loss=0.666, w2v_ctc_loss=1.923, contrastive_loss=0, total=4035.76, n_correct=3397.38, ppl=1.59, accuracy=84.182, wps=13938.4, ups=1.73, wpb=8071.5, bsz=298.5, num_updates=27000, lr=8.60663e-05, gnorm=2.413, clip=0, loss_scale=4, train_wall=57, gb_free=14.2, wall=16173
2023-07-06 15:28:10 | INFO | train_inner | epoch 019:    583 / 1474 loss=2.723, trans_loss=2.127, nll_loss=0.66, w2v_ctc_loss=1.9, contrastive_loss=0, total=4080.41, n_correct=3435.18, ppl=1.58, accuracy=84.187, wps=14110.6, ups=1.73, wpb=8160.8, bsz=306.8, num_updates=27100, lr=8.59074e-05, gnorm=2.465, clip=0, loss_scale=4, train_wall=57, gb_free=16.7, wall=16231
2023-07-06 15:29:08 | INFO | train_inner | epoch 019:    683 / 1474 loss=2.701, trans_loss=2.12, nll_loss=0.652, w2v_ctc_loss=1.873, contrastive_loss=0, total=4138.95, n_correct=3497.44, ppl=1.57, accuracy=84.501, wps=14288.9, ups=1.73, wpb=8277.9, bsz=321.9, num_updates=27200, lr=8.57493e-05, gnorm=2.407, clip=0, loss_scale=4, train_wall=58, gb_free=17, wall=16288
2023-07-06 15:30:07 | INFO | train_inner | epoch 019:    783 / 1474 loss=2.739, trans_loss=2.133, nll_loss=0.668, w2v_ctc_loss=1.92, contrastive_loss=0, total=4093.52, n_correct=3436.41, ppl=1.59, accuracy=83.948, wps=14033.4, ups=1.71, wpb=8187, bsz=305.6, num_updates=27300, lr=8.55921e-05, gnorm=2.464, clip=0, loss_scale=4, train_wall=58, gb_free=12.4, wall=16347
2023-07-06 15:31:05 | INFO | train_inner | epoch 019:    883 / 1474 loss=2.749, trans_loss=2.132, nll_loss=0.667, w2v_ctc_loss=1.935, contrastive_loss=0, total=4085.82, n_correct=3433.01, ppl=1.59, accuracy=84.023, wps=13980.6, ups=1.71, wpb=8171.6, bsz=303.2, num_updates=27400, lr=8.54358e-05, gnorm=2.512, clip=0, loss_scale=4, train_wall=58, gb_free=16.1, wall=16405
2023-07-06 15:32:04 | INFO | train_inner | epoch 019:    983 / 1474 loss=2.725, trans_loss=2.138, nll_loss=0.675, w2v_ctc_loss=1.887, contrastive_loss=0, total=4040.77, n_correct=3384.44, ppl=1.6, accuracy=83.757, wps=13667.3, ups=1.69, wpb=8081.5, bsz=309.1, num_updates=27500, lr=8.52803e-05, gnorm=2.421, clip=0, loss_scale=4, train_wall=59, gb_free=14.3, wall=16464
2023-07-06 15:33:02 | INFO | train_inner | epoch 019:   1083 / 1474 loss=2.729, trans_loss=2.13, nll_loss=0.665, w2v_ctc_loss=1.905, contrastive_loss=0, total=3990.59, n_correct=3356.96, ppl=1.59, accuracy=84.122, wps=13709.3, ups=1.72, wpb=7981.2, bsz=293.6, num_updates=27600, lr=8.51257e-05, gnorm=2.455, clip=0, loss_scale=4, train_wall=58, gb_free=16.7, wall=16523
2023-07-06 15:34:01 | INFO | train_inner | epoch 019:   1183 / 1474 loss=2.77, trans_loss=2.141, nll_loss=0.679, w2v_ctc_loss=1.956, contrastive_loss=0, total=4074.63, n_correct=3410.36, ppl=1.6, accuracy=83.697, wps=13799.8, ups=1.69, wpb=8149.3, bsz=305.9, num_updates=27700, lr=8.49719e-05, gnorm=2.624, clip=0, loss_scale=4, train_wall=59, gb_free=16.5, wall=16582
2023-07-06 15:34:59 | INFO | train_inner | epoch 019:   1283 / 1474 loss=2.733, trans_loss=2.131, nll_loss=0.666, w2v_ctc_loss=1.91, contrastive_loss=0, total=4078.11, n_correct=3428.4, ppl=1.59, accuracy=84.068, wps=14043.8, ups=1.72, wpb=8156.2, bsz=301.4, num_updates=27800, lr=8.48189e-05, gnorm=2.412, clip=0, loss_scale=4, train_wall=58, gb_free=16.4, wall=16640
2023-07-06 15:35:58 | INFO | train_inner | epoch 019:   1383 / 1474 loss=2.733, trans_loss=2.129, nll_loss=0.663, w2v_ctc_loss=1.911, contrastive_loss=0, total=4053.95, n_correct=3412.76, ppl=1.58, accuracy=84.184, wps=13962.3, ups=1.72, wpb=8107.9, bsz=300.7, num_updates=27900, lr=8.46668e-05, gnorm=2.469, clip=0, loss_scale=4, train_wall=58, gb_free=15.5, wall=16698
2023-07-06 15:36:51 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 15:37:08 | INFO | dev_rec_st | epoch 019 | valid on 'dev_rec_st' subset | loss 3.602 | trans_loss 4.108 | nll_loss 1.075 | w2v_ctc_loss 2.42 | contrastive_loss 0 | total 3909.1 | n_correct 3429.4 | ppl 2.11 | accuracy 87.729 | uer 24.559 | wer 27.072 | raw_wer 27.072 | bleu 0.82 | wps 3819 | wpb 3909.1 | bsz 141.8 | num_updates 27991 | best_bleu 0.85
2023-07-06 15:37:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27991 updates
2023-07-06 15:37:08 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_last.pt
2023-07-06 15:37:12 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_last.pt
2023-07-06 15:37:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_last.pt (epoch 19 @ 27991 updates, score 0.82) (writing took 4.438528883998515 seconds)
2023-07-06 15:37:13 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-07-06 15:37:13 | INFO | train | epoch 019 | loss 2.732 | trans_loss 2.131 | nll_loss 0.665 | w2v_ctc_loss 1.908 | contrastive_loss 0 | total 4078.54 | n_correct 3429.52 | ppl 1.59 | accuracy 84.087 | wps 13522 | ups 1.66 | wpb 8157.1 | bsz 305.7 | num_updates 27991 | lr 8.4529e-05 | gnorm 2.462 | clip 0 | loss_scale 4 | train_wall 853 | gb_free 17.2 | wall 16773
2023-07-06 15:37:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 15:37:13 | INFO | fairseq.trainer | begin training epoch 20
2023-07-06 15:37:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 15:37:26 | INFO | train_inner | epoch 020:      9 / 1474 loss=2.729, trans_loss=2.129, nll_loss=0.664, w2v_ctc_loss=1.899, contrastive_loss=0, total=4062.44, n_correct=3415.81, ppl=1.58, accuracy=84.083, wps=9229.7, ups=1.14, wpb=8124.9, bsz=301.4, num_updates=28000, lr=8.45154e-05, gnorm=2.511, clip=0, loss_scale=4, train_wall=58, gb_free=16.9, wall=16786
2023-07-06 15:37:26 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 15:37:43 | INFO | dev_rec_st | epoch 020 | valid on 'dev_rec_st' subset | loss 3.658 | trans_loss 4.129 | nll_loss 1.111 | w2v_ctc_loss 2.56 | contrastive_loss 0 | total 3909.1 | n_correct 3421.7 | ppl 2.16 | accuracy 87.532 | uer 25.076 | wer 27.911 | raw_wer 27.911 | bleu 0.84 | wps 3884.2 | wpb 3909.1 | bsz 141.8 | num_updates 28000 | best_bleu 0.85
2023-07-06 15:37:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-07-06 15:37:43 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_20_28000.pt
2023-07-06 15:37:45 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_20_28000.pt
2023-07-06 15:37:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 0.84) (writing took 6.995242684002733 seconds)
2023-07-06 15:38:49 | INFO | train_inner | epoch 020:    109 / 1474 loss=2.674, trans_loss=2.115, nll_loss=0.645, w2v_ctc_loss=1.838, contrastive_loss=0, total=4151.08, n_correct=3517.36, ppl=1.56, accuracy=84.734, wps=9984.3, ups=1.2, wpb=8302.2, bsz=314, num_updates=28100, lr=8.43649e-05, gnorm=2.348, clip=0, loss_scale=4, train_wall=58, gb_free=15.3, wall=16869
2023-07-06 15:39:48 | INFO | train_inner | epoch 020:    209 / 1474 loss=2.696, trans_loss=2.121, nll_loss=0.654, w2v_ctc_loss=1.865, contrastive_loss=0, total=4099.05, n_correct=3460.44, ppl=1.57, accuracy=84.421, wps=13936.9, ups=1.7, wpb=8198.1, bsz=302.9, num_updates=28200, lr=8.42152e-05, gnorm=2.486, clip=0, loss_scale=4, train_wall=58, gb_free=15.6, wall=16928
2023-07-06 15:40:46 | INFO | train_inner | epoch 020:    309 / 1474 loss=2.667, trans_loss=2.112, nll_loss=0.642, w2v_ctc_loss=1.829, contrastive_loss=0, total=4125.22, n_correct=3497.81, ppl=1.56, accuracy=84.791, wps=14062.9, ups=1.7, wpb=8250.4, bsz=324.3, num_updates=28300, lr=8.40663e-05, gnorm=2.469, clip=0, loss_scale=8, train_wall=58, gb_free=15.9, wall=16987
2023-07-06 15:41:44 | INFO | train_inner | epoch 020:    409 / 1474 loss=2.696, trans_loss=2.116, nll_loss=0.647, w2v_ctc_loss=1.869, contrastive_loss=0, total=4044.52, n_correct=3420.9, ppl=1.57, accuracy=84.581, wps=13917.7, ups=1.72, wpb=8089, bsz=296.7, num_updates=28400, lr=8.39181e-05, gnorm=2.527, clip=0, loss_scale=8, train_wall=58, gb_free=15.9, wall=17045
2023-07-06 15:42:43 | INFO | train_inner | epoch 020:    509 / 1474 loss=2.691, trans_loss=2.124, nll_loss=0.658, w2v_ctc_loss=1.857, contrastive_loss=0, total=4036.82, n_correct=3404.05, ppl=1.58, accuracy=84.325, wps=13876.9, ups=1.72, wpb=8073.6, bsz=300.4, num_updates=28500, lr=8.37708e-05, gnorm=2.402, clip=0, loss_scale=8, train_wall=58, gb_free=16, wall=17103
2023-07-06 15:43:40 | INFO | train_inner | epoch 020:    609 / 1474 loss=2.714, trans_loss=2.128, nll_loss=0.663, w2v_ctc_loss=1.888, contrastive_loss=0, total=4030.43, n_correct=3391.66, ppl=1.58, accuracy=84.151, wps=13938.3, ups=1.73, wpb=8060.9, bsz=294.6, num_updates=28600, lr=8.36242e-05, gnorm=2.419, clip=0, loss_scale=8, train_wall=57, gb_free=12.4, wall=17161
2023-07-06 15:44:38 | INFO | train_inner | epoch 020:    709 / 1474 loss=2.708, trans_loss=2.117, nll_loss=0.649, w2v_ctc_loss=1.881, contrastive_loss=0, total=4076.12, n_correct=3445.1, ppl=1.57, accuracy=84.519, wps=14150.3, ups=1.74, wpb=8152.2, bsz=300.5, num_updates=28700, lr=8.34784e-05, gnorm=2.411, clip=0, loss_scale=8, train_wall=57, gb_free=14.2, wall=17218
2023-07-06 15:45:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-07-06 15:45:37 | INFO | train_inner | epoch 020:    810 / 1474 loss=2.715, trans_loss=2.119, nll_loss=0.651, w2v_ctc_loss=1.892, contrastive_loss=0, total=4098.05, n_correct=3464.73, ppl=1.57, accuracy=84.546, wps=13993.3, ups=1.71, wpb=8196.1, bsz=310.1, num_updates=28800, lr=8.33333e-05, gnorm=2.469, clip=0, loss_scale=4, train_wall=58, gb_free=13.3, wall=17277
2023-07-06 15:46:36 | INFO | train_inner | epoch 020:    910 / 1474 loss=2.731, trans_loss=2.141, nll_loss=0.679, w2v_ctc_loss=1.894, contrastive_loss=0, total=4079.66, n_correct=3415.91, ppl=1.6, accuracy=83.73, wps=13809.6, ups=1.69, wpb=8159.3, bsz=324.1, num_updates=28900, lr=8.3189e-05, gnorm=2.48, clip=0, loss_scale=4, train_wall=59, gb_free=17.2, wall=17336
2023-07-06 15:47:35 | INFO | train_inner | epoch 020:   1010 / 1474 loss=2.699, trans_loss=2.12, nll_loss=0.653, w2v_ctc_loss=1.866, contrastive_loss=0, total=4105.12, n_correct=3465.69, ppl=1.57, accuracy=84.424, wps=13941, ups=1.7, wpb=8210.2, bsz=311.8, num_updates=29000, lr=8.30455e-05, gnorm=2.48, clip=0, loss_scale=4, train_wall=58, gb_free=15.5, wall=17395
2023-07-06 15:48:33 | INFO | train_inner | epoch 020:   1110 / 1474 loss=2.711, trans_loss=2.126, nll_loss=0.66, w2v_ctc_loss=1.884, contrastive_loss=0, total=4093.02, n_correct=3447.19, ppl=1.58, accuracy=84.221, wps=14124.8, ups=1.73, wpb=8186, bsz=308.6, num_updates=29100, lr=8.29027e-05, gnorm=2.371, clip=0, loss_scale=4, train_wall=58, gb_free=16.2, wall=17453
2023-07-06 15:49:31 | INFO | train_inner | epoch 020:   1210 / 1474 loss=2.737, trans_loss=2.125, nll_loss=0.658, w2v_ctc_loss=1.925, contrastive_loss=0, total=3982.83, n_correct=3355.99, ppl=1.58, accuracy=84.261, wps=13708.3, ups=1.72, wpb=7965.7, bsz=282.7, num_updates=29200, lr=8.27606e-05, gnorm=2.602, clip=0, loss_scale=4, train_wall=58, gb_free=16.3, wall=17511
2023-07-06 15:50:29 | INFO | train_inner | epoch 020:   1310 / 1474 loss=2.707, trans_loss=2.121, nll_loss=0.655, w2v_ctc_loss=1.88, contrastive_loss=0, total=4092.47, n_correct=3451.81, ppl=1.57, accuracy=84.345, wps=13921.2, ups=1.7, wpb=8184.9, bsz=300.8, num_updates=29300, lr=8.26192e-05, gnorm=2.456, clip=0, loss_scale=4, train_wall=58, gb_free=16.7, wall=17570
2023-07-06 15:51:28 | INFO | train_inner | epoch 020:   1410 / 1474 loss=2.712, trans_loss=2.123, nll_loss=0.656, w2v_ctc_loss=1.888, contrastive_loss=0, total=4060.52, n_correct=3421.01, ppl=1.58, accuracy=84.251, wps=13873.6, ups=1.71, wpb=8121, bsz=294.5, num_updates=29400, lr=8.24786e-05, gnorm=2.447, clip=0, loss_scale=4, train_wall=58, gb_free=16.5, wall=17628
2023-07-06 15:52:05 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 15:52:22 | INFO | dev_rec_st | epoch 020 | valid on 'dev_rec_st' subset | loss 3.68 | trans_loss 4.118 | nll_loss 1.099 | w2v_ctc_loss 2.656 | contrastive_loss 0 | total 3909.1 | n_correct 3431.3 | ppl 2.14 | accuracy 87.777 | uer 23.996 | wer 26.196 | raw_wer 26.196 | bleu 0.86 | wps 3881.8 | wpb 3909.1 | bsz 141.8 | num_updates 29464 | best_bleu 0.86
2023-07-06 15:52:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29464 updates
2023-07-06 15:52:22 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 15:52:26 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 15:52:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt (epoch 20 @ 29464 updates, score 0.86) (writing took 8.869341105004423 seconds)
2023-07-06 15:52:31 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-07-06 15:52:31 | INFO | train | epoch 020 | loss 2.702 | trans_loss 2.121 | nll_loss 0.655 | w2v_ctc_loss 1.873 | contrastive_loss 0 | total 4078.79 | n_correct 3442.33 | ppl 1.57 | accuracy 84.396 | wps 13083.6 | ups 1.6 | wpb 8157.6 | bsz 305.8 | num_updates 29464 | lr 8.2389e-05 | gnorm 2.455 | clip 0 | loss_scale 4 | train_wall 853 | gb_free 16.7 | wall 17691
2023-07-06 15:52:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 15:52:31 | INFO | fairseq.trainer | begin training epoch 21
2023-07-06 15:52:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 15:52:59 | INFO | train_inner | epoch 021:     36 / 1474 loss=2.685, trans_loss=2.116, nll_loss=0.648, w2v_ctc_loss=1.852, contrastive_loss=0, total=4075.56, n_correct=3446.77, ppl=1.57, accuracy=84.572, wps=8928.6, ups=1.1, wpb=8151.1, bsz=313, num_updates=29500, lr=8.23387e-05, gnorm=2.505, clip=0, loss_scale=4, train_wall=57, gb_free=15.5, wall=17720
2023-07-06 15:53:58 | INFO | train_inner | epoch 021:    136 / 1474 loss=2.654, trans_loss=2.113, nll_loss=0.644, w2v_ctc_loss=1.806, contrastive_loss=0, total=4136.84, n_correct=3504.52, ppl=1.56, accuracy=84.715, wps=14176.1, ups=1.71, wpb=8273.7, bsz=319.8, num_updates=29600, lr=8.21995e-05, gnorm=2.386, clip=0, loss_scale=4, train_wall=58, gb_free=16.5, wall=17778
2023-07-06 15:54:55 | INFO | train_inner | epoch 021:    236 / 1474 loss=2.649, trans_loss=2.104, nll_loss=0.633, w2v_ctc_loss=1.81, contrastive_loss=0, total=4096.5, n_correct=3481.89, ppl=1.55, accuracy=84.997, wps=14174.2, ups=1.73, wpb=8193, bsz=311.7, num_updates=29700, lr=8.2061e-05, gnorm=2.402, clip=0, loss_scale=4, train_wall=57, gb_free=12.6, wall=17836
2023-07-06 15:55:54 | INFO | train_inner | epoch 021:    336 / 1474 loss=2.681, trans_loss=2.111, nll_loss=0.642, w2v_ctc_loss=1.851, contrastive_loss=0, total=4107.46, n_correct=3480.37, ppl=1.56, accuracy=84.733, wps=14020.1, ups=1.71, wpb=8214.9, bsz=312.6, num_updates=29800, lr=8.19232e-05, gnorm=2.429, clip=0, loss_scale=4, train_wall=58, gb_free=14.9, wall=17894
2023-07-06 15:56:52 | INFO | train_inner | epoch 021:    436 / 1474 loss=2.663, trans_loss=2.1, nll_loss=0.627, w2v_ctc_loss=1.837, contrastive_loss=0, total=4096.45, n_correct=3486.35, ppl=1.54, accuracy=85.107, wps=14145.8, ups=1.73, wpb=8192.9, bsz=306.1, num_updates=29900, lr=8.17861e-05, gnorm=2.494, clip=0, loss_scale=4, train_wall=57, gb_free=16.5, wall=17952
2023-07-06 15:57:50 | INFO | train_inner | epoch 021:    536 / 1474 loss=2.68, trans_loss=2.112, nll_loss=0.643, w2v_ctc_loss=1.854, contrastive_loss=0, total=4044.23, n_correct=3423.26, ppl=1.56, accuracy=84.646, wps=13925.2, ups=1.72, wpb=8088.5, bsz=295.4, num_updates=30000, lr=8.16497e-05, gnorm=2.448, clip=0, loss_scale=4, train_wall=58, gb_free=13.1, wall=18010
2023-07-06 15:57:50 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 15:58:08 | INFO | dev_rec_st | epoch 021 | valid on 'dev_rec_st' subset | loss 3.567 | trans_loss 4.1 | nll_loss 1.07 | w2v_ctc_loss 2.323 | contrastive_loss 0 | total 3909.1 | n_correct 3437.8 | ppl 2.1 | accuracy 87.944 | uer 23.391 | wer 25.659 | raw_wer 25.659 | bleu 0.86 | wps 3739.6 | wpb 3909.1 | bsz 141.8 | num_updates 30000 | best_bleu 0.86
2023-07-06 15:58:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-07-06 15:58:08 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_21_30000.pt
2023-07-06 15:58:10 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_21_30000.pt
2023-07-06 15:58:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 0.86) (writing took 9.773147874002461 seconds)
2023-07-06 15:58:54 | INFO | train_inner | epoch 021:    636 / 1474 loss=3.499, trans_loss=4.192, nll_loss=1.286, w2v_ctc_loss=1.841, contrastive_loss=0, total=4153.87, n_correct=3511.02, ppl=2.44, accuracy=84.524, wps=6509.7, ups=1.55, wpb=4195.4, bsz=160.8, num_updates=30100, lr=8.15139e-05, gnorm=1.668, clip=0, loss_scale=4, train_wall=36, gb_free=17.2, wall=18075
2023-07-06 15:59:31 | INFO | train_inner | epoch 021:    736 / 1474 loss=3.501, trans_loss=4.216, nll_loss=1.277, w2v_ctc_loss=1.833, contrastive_loss=0, total=4087.12, n_correct=3467.31, ppl=2.42, accuracy=84.835, wps=11177.3, ups=2.73, wpb=4087.1, bsz=153.7, num_updates=30200, lr=8.13788e-05, gnorm=1.646, clip=0, loss_scale=4, train_wall=36, gb_free=15.3, wall=18111
2023-07-06 16:00:08 | INFO | train_inner | epoch 021:    836 / 1474 loss=3.524, trans_loss=4.233, nll_loss=1.299, w2v_ctc_loss=1.868, contrastive_loss=0, total=4020.12, n_correct=3396.84, ppl=2.46, accuracy=84.496, wps=10978.4, ups=2.73, wpb=4020.1, bsz=148.1, num_updates=30300, lr=8.12444e-05, gnorm=1.702, clip=0, loss_scale=4, train_wall=36, gb_free=16.9, wall=18148
2023-07-06 16:00:44 | INFO | train_inner | epoch 021:    936 / 1474 loss=3.519, trans_loss=4.222, nll_loss=1.285, w2v_ctc_loss=1.881, contrastive_loss=0, total=4030.92, n_correct=3415.43, ppl=2.44, accuracy=84.731, wps=11102.2, ups=2.75, wpb=4030.9, bsz=150.3, num_updates=30400, lr=8.11107e-05, gnorm=1.632, clip=0, loss_scale=4, train_wall=36, gb_free=16.8, wall=18184
2023-07-06 16:01:20 | INFO | train_inner | epoch 021:   1036 / 1474 loss=3.519, trans_loss=4.226, nll_loss=1.291, w2v_ctc_loss=1.869, contrastive_loss=0, total=4044.76, n_correct=3422.7, ppl=2.45, accuracy=84.621, wps=11093.3, ups=2.74, wpb=4044.8, bsz=149.2, num_updates=30500, lr=8.09776e-05, gnorm=1.647, clip=0, loss_scale=4, train_wall=36, gb_free=16.3, wall=18221
2023-07-06 16:01:57 | INFO | train_inner | epoch 021:   1136 / 1474 loss=3.528, trans_loss=4.229, nll_loss=1.294, w2v_ctc_loss=1.891, contrastive_loss=0, total=4038.28, n_correct=3415.52, ppl=2.45, accuracy=84.579, wps=11089.8, ups=2.75, wpb=4038.3, bsz=146.8, num_updates=30600, lr=8.08452e-05, gnorm=1.69, clip=0, loss_scale=4, train_wall=36, gb_free=16.9, wall=18257
2023-07-06 16:02:33 | INFO | train_inner | epoch 021:   1236 / 1474 loss=3.515, trans_loss=4.224, nll_loss=1.289, w2v_ctc_loss=1.862, contrastive_loss=0, total=4091.98, n_correct=3464.87, ppl=2.44, accuracy=84.675, wps=11284.3, ups=2.76, wpb=4092, bsz=155.8, num_updates=30700, lr=8.07134e-05, gnorm=1.614, clip=0, loss_scale=4, train_wall=36, gb_free=17, wall=18293
2023-07-06 16:03:10 | INFO | train_inner | epoch 021:   1336 / 1474 loss=3.506, trans_loss=4.219, nll_loss=1.284, w2v_ctc_loss=1.844, contrastive_loss=0, total=4094.56, n_correct=3466.74, ppl=2.43, accuracy=84.667, wps=11164.2, ups=2.73, wpb=4094.6, bsz=155, num_updates=30800, lr=8.05823e-05, gnorm=1.6, clip=0, loss_scale=4, train_wall=36, gb_free=16.6, wall=18330
2023-07-06 16:03:47 | INFO | train_inner | epoch 021:   1436 / 1474 loss=3.539, trans_loss=4.247, nll_loss=1.319, w2v_ctc_loss=1.886, contrastive_loss=0, total=4081.18, n_correct=3439.48, ppl=2.49, accuracy=84.277, wps=11114, ups=2.72, wpb=4081.2, bsz=152.5, num_updates=30900, lr=8.04518e-05, gnorm=1.688, clip=0, loss_scale=8, train_wall=36, gb_free=16.8, wall=18367
2023-07-06 16:04:00 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 16:04:18 | INFO | dev_rec_st | epoch 021 | valid on 'dev_rec_st' subset | loss 3.653 | trans_loss 4.065 | nll_loss 1.028 | w2v_ctc_loss 2.691 | contrastive_loss 0 | total 3909.1 | n_correct 3457.1 | ppl 2.04 | accuracy 88.437 | uer 23.032 | wer 25.107 | raw_wer 25.107 | bleu 0.84 | wps 3848.2 | wpb 3909.1 | bsz 141.8 | num_updates 30938 | best_bleu 0.86
2023-07-06 16:04:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30938 updates
2023-07-06 16:04:18 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8406.pt
2023-07-06 16:04:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8406.pt
2023-07-06 16:04:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8406.pt (epoch 21 @ 30938 updates, score 0.84) (writing took 8.05220236799505 seconds)
2023-07-06 16:04:26 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-07-06 16:04:26 | INFO | train | epoch 021 | loss 3.062 | trans_loss 3.093 | nll_loss 0.942 | w2v_ctc_loss 1.847 | contrastive_loss 0 | total 4078.54 | n_correct 3453.93 | ppl 1.92 | accuracy 84.686 | wps 11483.6 | ups 2.06 | wpb 5568.9 | bsz 208.9 | num_updates 30938 | lr 8.04024e-05 | gnorm 1.939 | clip 0 | loss_scale 8 | train_wall 648 | gb_free 15.6 | wall 18406
2023-07-06 16:04:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 16:04:26 | INFO | fairseq.trainer | begin training epoch 22
2023-07-06 16:04:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 16:04:56 | INFO | train_inner | epoch 022:     62 / 1474 loss=3.496, trans_loss=4.207, nll_loss=1.267, w2v_ctc_loss=1.839, contrastive_loss=0, total=4077.13, n_correct=3464.48, ppl=2.41, accuracy=84.973, wps=5882.4, ups=1.44, wpb=4077.1, bsz=150.2, num_updates=31000, lr=8.03219e-05, gnorm=1.604, clip=0, loss_scale=8, train_wall=36, gb_free=12.8, wall=18436
2023-07-06 16:05:32 | INFO | train_inner | epoch 022:    162 / 1474 loss=3.502, trans_loss=4.21, nll_loss=1.272, w2v_ctc_loss=1.849, contrastive_loss=0, total=4055.35, n_correct=3443.34, ppl=2.42, accuracy=84.909, wps=11093.5, ups=2.74, wpb=4055.3, bsz=153.5, num_updates=31100, lr=8.01927e-05, gnorm=1.732, clip=0, loss_scale=8, train_wall=36, gb_free=17.7, wall=18473
2023-07-06 16:06:09 | INFO | train_inner | epoch 022:    262 / 1474 loss=3.468, trans_loss=4.179, nll_loss=1.233, w2v_ctc_loss=1.808, contrastive_loss=0, total=4213.04, n_correct=3599, ppl=2.35, accuracy=85.425, wps=11398.4, ups=2.71, wpb=4213, bsz=165.3, num_updates=31200, lr=8.00641e-05, gnorm=1.629, clip=0, loss_scale=8, train_wall=36, gb_free=14.5, wall=18510
2023-07-06 16:06:47 | INFO | train_inner | epoch 022:    362 / 1474 loss=3.512, trans_loss=4.228, nll_loss=1.296, w2v_ctc_loss=1.842, contrastive_loss=0, total=4126.07, n_correct=3488.59, ppl=2.46, accuracy=84.55, wps=11060.8, ups=2.68, wpb=4126.1, bsz=155.2, num_updates=31300, lr=7.99361e-05, gnorm=1.725, clip=0, loss_scale=8, train_wall=37, gb_free=17.8, wall=18547
2023-07-06 16:07:23 | INFO | train_inner | epoch 022:    462 / 1474 loss=3.518, trans_loss=4.22, nll_loss=1.285, w2v_ctc_loss=1.881, contrastive_loss=0, total=4072.07, n_correct=3448.14, ppl=2.44, accuracy=84.678, wps=11126.8, ups=2.73, wpb=4072.1, bsz=150.3, num_updates=31400, lr=7.98087e-05, gnorm=1.707, clip=0, loss_scale=8, train_wall=36, gb_free=15.9, wall=18584
2023-07-06 16:08:00 | INFO | train_inner | epoch 022:    562 / 1474 loss=3.495, trans_loss=4.203, nll_loss=1.264, w2v_ctc_loss=1.844, contrastive_loss=0, total=4072.09, n_correct=3460.18, ppl=2.4, accuracy=84.973, wps=11047.8, ups=2.71, wpb=4072.1, bsz=152.2, num_updates=31500, lr=7.96819e-05, gnorm=1.657, clip=0, loss_scale=8, train_wall=36, gb_free=16.7, wall=18620
2023-07-06 16:08:36 | INFO | train_inner | epoch 022:    662 / 1474 loss=3.474, trans_loss=4.188, nll_loss=1.245, w2v_ctc_loss=1.809, contrastive_loss=0, total=4083.23, n_correct=3480.23, ppl=2.37, accuracy=85.232, wps=11352.4, ups=2.78, wpb=4083.2, bsz=155, num_updates=31600, lr=7.95557e-05, gnorm=1.601, clip=0, loss_scale=8, train_wall=36, gb_free=13.5, wall=18656
2023-07-06 16:09:13 | INFO | train_inner | epoch 022:    762 / 1474 loss=3.495, trans_loss=4.201, nll_loss=1.262, w2v_ctc_loss=1.847, contrastive_loss=0, total=4109.11, n_correct=3493.54, ppl=2.4, accuracy=85.019, wps=11249.8, ups=2.74, wpb=4109.1, bsz=151.9, num_updates=31700, lr=7.94301e-05, gnorm=1.709, clip=0, loss_scale=8, train_wall=36, gb_free=12.2, wall=18693
2023-07-06 16:09:49 | INFO | train_inner | epoch 022:    862 / 1474 loss=3.501, trans_loss=4.202, nll_loss=1.264, w2v_ctc_loss=1.865, contrastive_loss=0, total=4016.15, n_correct=3411.68, ppl=2.4, accuracy=84.949, wps=11003.6, ups=2.74, wpb=4016.2, bsz=145.3, num_updates=31800, lr=7.93052e-05, gnorm=1.671, clip=0, loss_scale=8, train_wall=36, gb_free=17.1, wall=18729
2023-07-06 16:10:26 | INFO | train_inner | epoch 022:    962 / 1474 loss=3.491, trans_loss=4.196, nll_loss=1.256, w2v_ctc_loss=1.845, contrastive_loss=0, total=4082.6, n_correct=3475.72, ppl=2.39, accuracy=85.135, wps=11110.4, ups=2.72, wpb=4082.6, bsz=152.3, num_updates=31900, lr=7.91808e-05, gnorm=1.713, clip=0, loss_scale=8, train_wall=36, gb_free=14.9, wall=18766
2023-07-06 16:11:02 | INFO | train_inner | epoch 022:   1062 / 1474 loss=3.485, trans_loss=4.199, nll_loss=1.26, w2v_ctc_loss=1.819, contrastive_loss=0, total=4091.9, n_correct=3479.28, ppl=2.4, accuracy=85.028, wps=11280.9, ups=2.76, wpb=4091.9, bsz=157.7, num_updates=32000, lr=7.90569e-05, gnorm=1.611, clip=0, loss_scale=8, train_wall=36, gb_free=16.6, wall=18802
2023-07-06 16:11:02 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 16:11:20 | INFO | dev_rec_st | epoch 022 | valid on 'dev_rec_st' subset | loss 3.683 | trans_loss 4.077 | nll_loss 1.053 | w2v_ctc_loss 2.762 | contrastive_loss 0 | total 3909.1 | n_correct 3455.4 | ppl 2.07 | accuracy 88.394 | uer 22.995 | wer 24.548 | raw_wer 24.548 | bleu 0.84 | wps 3804.1 | wpb 3909.1 | bsz 141.8 | num_updates 32000 | best_bleu 0.86
2023-07-06 16:11:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-07-06 16:11:20 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_22_32000.pt
2023-07-06 16:11:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_22_32000.pt
2023-07-06 16:11:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 0.84) (writing took 8.94455268800084 seconds)
2023-07-06 16:12:05 | INFO | train_inner | epoch 022:   1162 / 1474 loss=3.507, trans_loss=4.212, nll_loss=1.277, w2v_ctc_loss=1.863, contrastive_loss=0, total=4041.69, n_correct=3427.05, ppl=2.42, accuracy=84.793, wps=6444.4, ups=1.59, wpb=4041.7, bsz=148.1, num_updates=32100, lr=7.89337e-05, gnorm=1.636, clip=0, loss_scale=8, train_wall=36, gb_free=16.9, wall=18865
2023-07-06 16:12:41 | INFO | train_inner | epoch 022:   1262 / 1474 loss=3.487, trans_loss=4.202, nll_loss=1.266, w2v_ctc_loss=1.818, contrastive_loss=0, total=4112.74, n_correct=3495.37, ppl=2.4, accuracy=84.989, wps=11289.5, ups=2.75, wpb=4112.7, bsz=160.8, num_updates=32200, lr=7.8811e-05, gnorm=1.63, clip=0, loss_scale=8, train_wall=36, gb_free=17.2, wall=18902
2023-07-06 16:13:17 | INFO | train_inner | epoch 022:   1362 / 1474 loss=3.482, trans_loss=4.19, nll_loss=1.249, w2v_ctc_loss=1.831, contrastive_loss=0, total=4014.25, n_correct=3418.77, ppl=2.38, accuracy=85.166, wps=11123.6, ups=2.77, wpb=4014.2, bsz=149.7, num_updates=32300, lr=7.86889e-05, gnorm=1.645, clip=0, loss_scale=8, train_wall=36, gb_free=17.2, wall=18938
2023-07-06 16:13:54 | INFO | train_inner | epoch 022:   1462 / 1474 loss=3.5, trans_loss=4.201, nll_loss=1.264, w2v_ctc_loss=1.864, contrastive_loss=0, total=4026.66, n_correct=3421.91, ppl=2.4, accuracy=84.981, wps=10914.5, ups=2.71, wpb=4026.7, bsz=144.7, num_updates=32400, lr=7.85674e-05, gnorm=1.67, clip=0, loss_scale=8, train_wall=36, gb_free=16.6, wall=18975
2023-07-06 16:13:59 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 16:14:16 | INFO | dev_rec_st | epoch 022 | valid on 'dev_rec_st' subset | loss 3.653 | trans_loss 4.082 | nll_loss 1.053 | w2v_ctc_loss 2.65 | contrastive_loss 0 | total 3909.1 | n_correct 3447.7 | ppl 2.08 | accuracy 88.197 | uer 23.37 | wer 25.133 | raw_wer 25.133 | bleu 0.86 | wps 3902.6 | wpb 3909.1 | bsz 141.8 | num_updates 32412 | best_bleu 0.86
2023-07-06 16:14:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32412 updates
2023-07-06 16:14:16 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 16:14:21 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 16:14:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt (epoch 22 @ 32412 updates, score 0.86) (writing took 9.193847232003463 seconds)
2023-07-06 16:14:26 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-07-06 16:14:26 | INFO | train | epoch 022 | loss 3.494 | trans_loss 4.202 | nll_loss 1.264 | w2v_ctc_loss 1.842 | contrastive_loss 0 | total 4078.54 | n_correct 3466.33 | ppl 2.4 | accuracy 84.99 | wps 10022.9 | ups 2.46 | wpb 4078.5 | bsz 152.8 | num_updates 32412 | lr 7.85529e-05 | gnorm 1.665 | clip 0 | loss_scale 8 | train_wall 532 | gb_free 12.1 | wall 19006
2023-07-06 16:14:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 16:14:26 | INFO | fairseq.trainer | begin training epoch 23
2023-07-06 16:14:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 16:15:05 | INFO | train_inner | epoch 023:     88 / 1474 loss=3.477, trans_loss=4.18, nll_loss=1.237, w2v_ctc_loss=1.837, contrastive_loss=0, total=4041.87, n_correct=3452.49, ppl=2.36, accuracy=85.418, wps=5719.3, ups=1.42, wpb=4041.9, bsz=150.6, num_updates=32500, lr=7.84465e-05, gnorm=1.723, clip=0, loss_scale=8, train_wall=36, gb_free=16.5, wall=19045
2023-07-06 16:15:42 | INFO | train_inner | epoch 023:    188 / 1474 loss=3.464, trans_loss=4.176, nll_loss=1.232, w2v_ctc_loss=1.804, contrastive_loss=0, total=4044.08, n_correct=3455.12, ppl=2.35, accuracy=85.436, wps=10994.9, ups=2.72, wpb=4044.1, bsz=147.2, num_updates=32600, lr=7.8326e-05, gnorm=1.626, clip=0, loss_scale=8, train_wall=36, gb_free=17.1, wall=19082
2023-07-06 16:16:19 | INFO | train_inner | epoch 023:    288 / 1474 loss=3.466, trans_loss=4.177, nll_loss=1.234, w2v_ctc_loss=1.805, contrastive_loss=0, total=4082.53, n_correct=3488.27, ppl=2.35, accuracy=85.444, wps=11107.1, ups=2.72, wpb=4082.5, bsz=152.9, num_updates=32700, lr=7.82062e-05, gnorm=1.666, clip=0, loss_scale=8, train_wall=36, gb_free=17.5, wall=19119
2023-07-06 16:16:55 | INFO | train_inner | epoch 023:    388 / 1474 loss=3.487, trans_loss=4.18, nll_loss=1.236, w2v_ctc_loss=1.87, contrastive_loss=0, total=4058.47, n_correct=3465.44, ppl=2.36, accuracy=85.388, wps=11073.7, ups=2.73, wpb=4058.5, bsz=147, num_updates=32800, lr=7.80869e-05, gnorm=1.75, clip=0, loss_scale=8, train_wall=36, gb_free=16.1, wall=19156
2023-07-06 16:17:32 | INFO | train_inner | epoch 023:    488 / 1474 loss=3.481, trans_loss=4.188, nll_loss=1.248, w2v_ctc_loss=1.83, contrastive_loss=0, total=4084.88, n_correct=3481.93, ppl=2.38, accuracy=85.239, wps=11185.5, ups=2.74, wpb=4084.9, bsz=156.1, num_updates=32900, lr=7.79681e-05, gnorm=1.646, clip=0, loss_scale=16, train_wall=36, gb_free=17.4, wall=19192
2023-07-06 16:18:08 | INFO | train_inner | epoch 023:    588 / 1474 loss=3.468, trans_loss=4.17, nll_loss=1.225, w2v_ctc_loss=1.829, contrastive_loss=0, total=4129.45, n_correct=3532.77, ppl=2.34, accuracy=85.551, wps=11389.3, ups=2.76, wpb=4129.4, bsz=158.1, num_updates=33000, lr=7.78499e-05, gnorm=1.68, clip=0, loss_scale=16, train_wall=36, gb_free=17.4, wall=19228
2023-07-06 16:18:45 | INFO | train_inner | epoch 023:    688 / 1474 loss=3.467, trans_loss=4.178, nll_loss=1.235, w2v_ctc_loss=1.807, contrastive_loss=0, total=4080.25, n_correct=3482.78, ppl=2.35, accuracy=85.357, wps=11157.3, ups=2.73, wpb=4080.2, bsz=151.1, num_updates=33100, lr=7.77322e-05, gnorm=1.629, clip=0, loss_scale=16, train_wall=36, gb_free=16.8, wall=19265
2023-07-06 16:19:21 | INFO | train_inner | epoch 023:    788 / 1474 loss=3.476, trans_loss=4.183, nll_loss=1.242, w2v_ctc_loss=1.828, contrastive_loss=0, total=4082.93, n_correct=3484, ppl=2.37, accuracy=85.331, wps=11304.8, ups=2.77, wpb=4082.9, bsz=152.9, num_updates=33200, lr=7.76151e-05, gnorm=1.638, clip=0, loss_scale=16, train_wall=36, gb_free=17.1, wall=19301
2023-07-06 16:19:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-06 16:19:57 | INFO | train_inner | epoch 023:    889 / 1474 loss=3.474, trans_loss=4.184, nll_loss=1.245, w2v_ctc_loss=1.816, contrastive_loss=0, total=4124.15, n_correct=3519.18, ppl=2.37, accuracy=85.331, wps=11282, ups=2.74, wpb=4124.1, bsz=161.6, num_updates=33300, lr=7.74984e-05, gnorm=1.65, clip=0, loss_scale=8, train_wall=36, gb_free=16.6, wall=19338
2023-07-06 16:20:34 | INFO | train_inner | epoch 023:    989 / 1474 loss=3.495, trans_loss=4.2, nll_loss=1.264, w2v_ctc_loss=1.85, contrastive_loss=0, total=4096.49, n_correct=3478.69, ppl=2.4, accuracy=84.919, wps=11107.1, ups=2.71, wpb=4096.5, bsz=154.5, num_updates=33400, lr=7.73823e-05, gnorm=1.68, clip=0, loss_scale=8, train_wall=36, gb_free=12.1, wall=19374
2023-07-06 16:21:11 | INFO | train_inner | epoch 023:   1089 / 1474 loss=3.491, trans_loss=4.191, nll_loss=1.253, w2v_ctc_loss=1.858, contrastive_loss=0, total=4031.59, n_correct=3433.53, ppl=2.38, accuracy=85.166, wps=10983.7, ups=2.72, wpb=4031.6, bsz=145.7, num_updates=33500, lr=7.72667e-05, gnorm=1.665, clip=0, loss_scale=8, train_wall=36, gb_free=17.5, wall=19411
2023-07-06 16:21:47 | INFO | train_inner | epoch 023:   1189 / 1474 loss=3.473, trans_loss=4.184, nll_loss=1.244, w2v_ctc_loss=1.815, contrastive_loss=0, total=4105.05, n_correct=3501.14, ppl=2.37, accuracy=85.289, wps=11214.3, ups=2.73, wpb=4105.1, bsz=154.6, num_updates=33600, lr=7.71517e-05, gnorm=1.652, clip=0, loss_scale=8, train_wall=36, gb_free=17.1, wall=19448
2023-07-06 16:22:24 | INFO | train_inner | epoch 023:   1289 / 1474 loss=3.458, trans_loss=4.169, nll_loss=1.226, w2v_ctc_loss=1.799, contrastive_loss=0, total=4074.34, n_correct=3484.7, ppl=2.34, accuracy=85.528, wps=11182.1, ups=2.74, wpb=4074.3, bsz=154.7, num_updates=33700, lr=7.70371e-05, gnorm=1.665, clip=0, loss_scale=8, train_wall=36, gb_free=16.8, wall=19484
2023-07-06 16:23:01 | INFO | train_inner | epoch 023:   1389 / 1474 loss=3.503, trans_loss=4.203, nll_loss=1.269, w2v_ctc_loss=1.868, contrastive_loss=0, total=4103.63, n_correct=3485.65, ppl=2.41, accuracy=84.941, wps=11203, ups=2.73, wpb=4103.6, bsz=154.4, num_updates=33800, lr=7.69231e-05, gnorm=1.682, clip=0, loss_scale=8, train_wall=36, gb_free=11.2, wall=19521
2023-07-06 16:23:32 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 16:23:49 | INFO | dev_rec_st | epoch 023 | valid on 'dev_rec_st' subset | loss 3.593 | trans_loss 4.074 | nll_loss 1.045 | w2v_ctc_loss 2.47 | contrastive_loss 0 | total 3909.1 | n_correct 3454.1 | ppl 2.06 | accuracy 88.36 | uer 22.865 | wer 25.2 | raw_wer 25.2 | bleu 0.85 | wps 3767.9 | wpb 3909.1 | bsz 141.8 | num_updates 33885 | best_bleu 0.86
2023-07-06 16:23:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33885 updates
2023-07-06 16:23:49 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8500.pt
2023-07-06 16:23:51 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8500.pt
2023-07-06 16:23:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8500.pt (epoch 23 @ 33885 updates, score 0.85) (writing took 5.843095625998103 seconds)
2023-07-06 16:23:55 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-07-06 16:23:55 | INFO | train | epoch 023 | loss 3.477 | trans_loss 4.184 | nll_loss 1.243 | w2v_ctc_loss 1.829 | contrastive_loss 0 | total 4078.32 | n_correct 3478.79 | ppl 2.37 | accuracy 85.3 | wps 10548.9 | ups 2.59 | wpb 4078.3 | bsz 152.8 | num_updates 33885 | lr 7.68265e-05 | gnorm 1.669 | clip 0 | loss_scale 8 | train_wall 532 | gb_free 14 | wall 19575
2023-07-06 16:23:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 16:23:55 | INFO | fairseq.trainer | begin training epoch 24
2023-07-06 16:23:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 16:24:08 | INFO | train_inner | epoch 024:     15 / 1474 loss=3.474, trans_loss=4.193, nll_loss=1.257, w2v_ctc_loss=1.797, contrastive_loss=0, total=4048.99, n_correct=3446.98, ppl=2.39, accuracy=85.132, wps=5987.9, ups=1.48, wpb=4049, bsz=154.3, num_updates=33900, lr=7.68095e-05, gnorm=1.675, clip=0, loss_scale=8, train_wall=36, gb_free=17.1, wall=19588
2023-07-06 16:24:45 | INFO | train_inner | epoch 024:    115 / 1474 loss=3.44, trans_loss=4.155, nll_loss=1.207, w2v_ctc_loss=1.772, contrastive_loss=0, total=4094.12, n_correct=3512.83, ppl=2.31, accuracy=85.802, wps=11201.3, ups=2.74, wpb=4094.1, bsz=157.9, num_updates=34000, lr=7.66965e-05, gnorm=1.654, clip=0, loss_scale=8, train_wall=36, gb_free=16, wall=19625
2023-07-06 16:24:45 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 16:25:02 | INFO | dev_rec_st | epoch 024 | valid on 'dev_rec_st' subset | loss 3.611 | trans_loss 4.081 | nll_loss 1.07 | w2v_ctc_loss 2.515 | contrastive_loss 0 | total 3909.1 | n_correct 3446.3 | ppl 2.1 | accuracy 88.161 | uer 22.87 | wer 25.107 | raw_wer 25.107 | bleu 0.83 | wps 3874.3 | wpb 3909.1 | bsz 141.8 | num_updates 34000 | best_bleu 0.86
2023-07-06 16:25:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-07-06 16:25:02 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_24_34000.pt
2023-07-06 16:25:04 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_24_34000.pt
2023-07-06 16:25:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 0.83) (writing took 5.643262223005877 seconds)
2023-07-06 16:25:45 | INFO | train_inner | epoch 024:    215 / 1474 loss=3.446, trans_loss=4.164, nll_loss=1.221, w2v_ctc_loss=1.769, contrastive_loss=0, total=4179.32, n_correct=3581.62, ppl=2.33, accuracy=85.699, wps=6984.1, ups=1.67, wpb=4179.3, bsz=170.8, num_updates=34100, lr=7.6584e-05, gnorm=1.584, clip=0, loss_scale=8, train_wall=36, gb_free=15.7, wall=19685
2023-07-06 16:26:21 | INFO | train_inner | epoch 024:    315 / 1474 loss=3.445, trans_loss=4.153, nll_loss=1.206, w2v_ctc_loss=1.795, contrastive_loss=0, total=4081.4, n_correct=3501.84, ppl=2.31, accuracy=85.8, wps=11188.4, ups=2.74, wpb=4081.4, bsz=154.6, num_updates=34200, lr=7.64719e-05, gnorm=1.635, clip=0, loss_scale=8, train_wall=36, gb_free=16.8, wall=19721
2023-07-06 16:26:58 | INFO | train_inner | epoch 024:    415 / 1474 loss=3.494, trans_loss=4.197, nll_loss=1.261, w2v_ctc_loss=1.853, contrastive_loss=0, total=4082.6, n_correct=3472.81, ppl=2.4, accuracy=85.064, wps=11154.5, ups=2.73, wpb=4082.6, bsz=148.6, num_updates=34300, lr=7.63604e-05, gnorm=1.642, clip=0, loss_scale=8, train_wall=36, gb_free=11.2, wall=19758
2023-07-06 16:27:34 | INFO | train_inner | epoch 024:    515 / 1474 loss=3.479, trans_loss=4.179, nll_loss=1.238, w2v_ctc_loss=1.846, contrastive_loss=0, total=4080.61, n_correct=3485.65, ppl=2.36, accuracy=85.42, wps=11188.6, ups=2.74, wpb=4080.6, bsz=150.6, num_updates=34400, lr=7.62493e-05, gnorm=1.704, clip=0, loss_scale=8, train_wall=36, gb_free=16.5, wall=19794
2023-07-06 16:28:11 | INFO | train_inner | epoch 024:    615 / 1474 loss=3.461, trans_loss=4.165, nll_loss=1.222, w2v_ctc_loss=1.82, contrastive_loss=0, total=4099.18, n_correct=3509.99, ppl=2.33, accuracy=85.627, wps=11177.2, ups=2.73, wpb=4099.2, bsz=154.6, num_updates=34500, lr=7.61387e-05, gnorm=1.681, clip=0, loss_scale=8, train_wall=36, gb_free=16.8, wall=19831
2023-07-06 16:28:47 | INFO | train_inner | epoch 024:    715 / 1474 loss=3.471, trans_loss=4.171, nll_loss=1.229, w2v_ctc_loss=1.838, contrastive_loss=0, total=4035, n_correct=3447.48, ppl=2.34, accuracy=85.439, wps=11046.5, ups=2.74, wpb=4035, bsz=147.7, num_updates=34600, lr=7.60286e-05, gnorm=1.626, clip=0, loss_scale=8, train_wall=36, gb_free=15.8, wall=19868
2023-07-06 16:29:24 | INFO | train_inner | epoch 024:    815 / 1474 loss=3.454, trans_loss=4.165, nll_loss=1.221, w2v_ctc_loss=1.796, contrastive_loss=0, total=4063.61, n_correct=3479.9, ppl=2.33, accuracy=85.636, wps=11070.1, ups=2.72, wpb=4063.6, bsz=153.9, num_updates=34700, lr=7.5919e-05, gnorm=1.618, clip=0, loss_scale=8, train_wall=36, gb_free=17.6, wall=19904
2023-07-06 16:30:00 | INFO | train_inner | epoch 024:    915 / 1474 loss=3.476, trans_loss=4.175, nll_loss=1.234, w2v_ctc_loss=1.844, contrastive_loss=0, total=3993.65, n_correct=3408.87, ppl=2.35, accuracy=85.357, wps=10984.4, ups=2.75, wpb=3993.7, bsz=139.4, num_updates=34800, lr=7.58098e-05, gnorm=1.621, clip=0, loss_scale=8, train_wall=36, gb_free=12.6, wall=19941
2023-07-06 16:30:37 | INFO | train_inner | epoch 024:   1015 / 1474 loss=3.457, trans_loss=4.158, nll_loss=1.213, w2v_ctc_loss=1.821, contrastive_loss=0, total=4062.32, n_correct=3479.53, ppl=2.32, accuracy=85.654, wps=11164.7, ups=2.75, wpb=4062.3, bsz=147.8, num_updates=34900, lr=7.57011e-05, gnorm=1.66, clip=0, loss_scale=8, train_wall=36, gb_free=13.5, wall=19977
2023-07-06 16:31:13 | INFO | train_inner | epoch 024:   1115 / 1474 loss=3.455, trans_loss=4.167, nll_loss=1.226, w2v_ctc_loss=1.791, contrastive_loss=0, total=4081.94, n_correct=3493.45, ppl=2.34, accuracy=85.583, wps=11257.7, ups=2.76, wpb=4081.9, bsz=155.3, num_updates=35000, lr=7.55929e-05, gnorm=1.605, clip=0, loss_scale=8, train_wall=36, gb_free=16.5, wall=20013
2023-07-06 16:31:50 | INFO | train_inner | epoch 024:   1215 / 1474 loss=3.462, trans_loss=4.169, nll_loss=1.227, w2v_ctc_loss=1.812, contrastive_loss=0, total=4098.64, n_correct=3502.64, ppl=2.34, accuracy=85.459, wps=11207, ups=2.73, wpb=4098.6, bsz=155.4, num_updates=35100, lr=7.54851e-05, gnorm=1.705, clip=0, loss_scale=8, train_wall=36, gb_free=17.4, wall=20050
2023-07-06 16:32:26 | INFO | train_inner | epoch 024:   1315 / 1474 loss=3.478, trans_loss=4.177, nll_loss=1.236, w2v_ctc_loss=1.847, contrastive_loss=0, total=4042.56, n_correct=3449.34, ppl=2.36, accuracy=85.326, wps=11016.9, ups=2.73, wpb=4042.6, bsz=146.7, num_updates=35200, lr=7.53778e-05, gnorm=1.675, clip=0, loss_scale=8, train_wall=36, gb_free=13.3, wall=20087
2023-07-06 16:33:03 | INFO | train_inner | epoch 024:   1415 / 1474 loss=3.462, trans_loss=4.167, nll_loss=1.224, w2v_ctc_loss=1.819, contrastive_loss=0, total=4040.17, n_correct=3455.6, ppl=2.34, accuracy=85.531, wps=11040.7, ups=2.73, wpb=4040.2, bsz=147.3, num_updates=35300, lr=7.5271e-05, gnorm=1.669, clip=0, loss_scale=16, train_wall=36, gb_free=15.4, wall=20123
2023-07-06 16:33:24 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 16:33:41 | INFO | dev_rec_st | epoch 024 | valid on 'dev_rec_st' subset | loss 3.633 | trans_loss 4.085 | nll_loss 1.062 | w2v_ctc_loss 2.576 | contrastive_loss 0 | total 3909.1 | n_correct 3445.5 | ppl 2.09 | accuracy 88.14 | uer 22.794 | wer 25.111 | raw_wer 25.111 | bleu 0.84 | wps 3861.7 | wpb 3909.1 | bsz 141.8 | num_updates 35359 | best_bleu 0.86
2023-07-06 16:33:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35359 updates
2023-07-06 16:33:41 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8409.pt
2023-07-06 16:33:44 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8409.pt
2023-07-06 16:33:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8409.pt (epoch 24 @ 35359 updates, score 0.84) (writing took 5.762871714003268 seconds)
2023-07-06 16:33:47 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-07-06 16:33:47 | INFO | train | epoch 024 | loss 3.462 | trans_loss 4.168 | nll_loss 1.226 | w2v_ctc_loss 1.814 | contrastive_loss 0 | total 4078.54 | n_correct 3488.64 | ppl 2.34 | accuracy 85.537 | wps 10147.6 | ups 2.49 | wpb 4078.5 | bsz 152.8 | num_updates 35359 | lr 7.52082e-05 | gnorm 1.646 | clip 0 | loss_scale 16 | train_wall 532 | gb_free 16.2 | wall 20168
2023-07-06 16:33:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 16:33:48 | INFO | fairseq.trainer | begin training epoch 25
2023-07-06 16:33:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 16:34:10 | INFO | train_inner | epoch 025:     41 / 1474 loss=3.444, trans_loss=4.151, nll_loss=1.205, w2v_ctc_loss=1.795, contrastive_loss=0, total=4100.16, n_correct=3519.25, ppl=2.31, accuracy=85.832, wps=6124.5, ups=1.49, wpb=4100.2, bsz=154.8, num_updates=35400, lr=7.51646e-05, gnorm=1.622, clip=0, loss_scale=16, train_wall=36, gb_free=16.8, wall=20190
2023-07-06 16:34:46 | INFO | train_inner | epoch 025:    141 / 1474 loss=3.418, trans_loss=4.132, nll_loss=1.18, w2v_ctc_loss=1.754, contrastive_loss=0, total=4082.77, n_correct=3519.42, ppl=2.27, accuracy=86.202, wps=11294.3, ups=2.77, wpb=4082.8, bsz=154.9, num_updates=35500, lr=7.50587e-05, gnorm=1.647, clip=0, loss_scale=16, train_wall=36, gb_free=16.4, wall=20226
2023-07-06 16:35:23 | INFO | train_inner | epoch 025:    241 / 1474 loss=3.44, trans_loss=4.145, nll_loss=1.197, w2v_ctc_loss=1.796, contrastive_loss=0, total=4066.24, n_correct=3493.54, ppl=2.29, accuracy=85.916, wps=11084.9, ups=2.73, wpb=4066.2, bsz=151.5, num_updates=35600, lr=7.49532e-05, gnorm=1.695, clip=0, loss_scale=16, train_wall=36, gb_free=17, wall=20263
2023-07-06 16:35:59 | INFO | train_inner | epoch 025:    341 / 1474 loss=3.456, trans_loss=4.161, nll_loss=1.217, w2v_ctc_loss=1.812, contrastive_loss=0, total=4068.14, n_correct=3484.66, ppl=2.33, accuracy=85.657, wps=11097.2, ups=2.73, wpb=4068.1, bsz=147.7, num_updates=35700, lr=7.48481e-05, gnorm=1.67, clip=0, loss_scale=16, train_wall=36, gb_free=15.8, wall=20300
2023-07-06 16:36:36 | INFO | train_inner | epoch 025:    441 / 1474 loss=3.482, trans_loss=4.179, nll_loss=1.241, w2v_ctc_loss=1.853, contrastive_loss=0, total=4095.67, n_correct=3494.73, ppl=2.36, accuracy=85.327, wps=11122.1, ups=2.72, wpb=4095.7, bsz=148.4, num_updates=35800, lr=7.47435e-05, gnorm=1.684, clip=0, loss_scale=16, train_wall=36, gb_free=16.9, wall=20336
2023-07-06 16:37:13 | INFO | train_inner | epoch 025:    541 / 1474 loss=3.447, trans_loss=4.155, nll_loss=1.21, w2v_ctc_loss=1.795, contrastive_loss=0, total=4096.33, n_correct=3512.9, ppl=2.31, accuracy=85.757, wps=11233, ups=2.74, wpb=4096.3, bsz=156.7, num_updates=35900, lr=7.46393e-05, gnorm=1.677, clip=0, loss_scale=16, train_wall=36, gb_free=17.7, wall=20373
2023-07-06 16:37:49 | INFO | train_inner | epoch 025:    641 / 1474 loss=3.44, trans_loss=4.151, nll_loss=1.206, w2v_ctc_loss=1.781, contrastive_loss=0, total=4102.25, n_correct=3520.84, ppl=2.31, accuracy=85.827, wps=11320.3, ups=2.76, wpb=4102.2, bsz=154.8, num_updates=36000, lr=7.45356e-05, gnorm=1.581, clip=0, loss_scale=16, train_wall=36, gb_free=16.5, wall=20409
2023-07-06 16:37:49 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 16:38:06 | INFO | dev_rec_st | epoch 025 | valid on 'dev_rec_st' subset | loss 3.542 | trans_loss 4.048 | nll_loss 1.015 | w2v_ctc_loss 2.362 | contrastive_loss 0 | total 3909.1 | n_correct 3467.8 | ppl 2.02 | accuracy 88.711 | uer 22.172 | wer 24.537 | raw_wer 24.537 | bleu 0.85 | wps 3807.9 | wpb 3909.1 | bsz 141.8 | num_updates 36000 | best_bleu 0.86
2023-07-06 16:38:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-07-06 16:38:06 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_25_36000.pt
2023-07-06 16:38:09 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_25_36000.pt
2023-07-06 16:38:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 0.85) (writing took 6.80830354099453 seconds)
2023-07-06 16:38:50 | INFO | train_inner | epoch 025:    741 / 1474 loss=3.452, trans_loss=4.158, nll_loss=1.214, w2v_ctc_loss=1.806, contrastive_loss=0, total=4077.19, n_correct=3496.13, ppl=2.32, accuracy=85.749, wps=6669.4, ups=1.64, wpb=4077.2, bsz=151.6, num_updates=36100, lr=7.44323e-05, gnorm=1.671, clip=0, loss_scale=16, train_wall=36, gb_free=15.2, wall=20470
2023-07-06 16:39:26 | INFO | train_inner | epoch 025:    841 / 1474 loss=3.442, trans_loss=4.147, nll_loss=1.202, w2v_ctc_loss=1.796, contrastive_loss=0, total=4110.88, n_correct=3532.49, ppl=2.3, accuracy=85.93, wps=11296.6, ups=2.75, wpb=4110.9, bsz=162, num_updates=36200, lr=7.43294e-05, gnorm=1.673, clip=0, loss_scale=16, train_wall=36, gb_free=16.5, wall=20507
2023-07-06 16:40:03 | INFO | train_inner | epoch 025:    941 / 1474 loss=3.437, trans_loss=4.151, nll_loss=1.206, w2v_ctc_loss=1.772, contrastive_loss=0, total=4094.17, n_correct=3512.61, ppl=2.31, accuracy=85.795, wps=11059.7, ups=2.7, wpb=4094.2, bsz=158.4, num_updates=36300, lr=7.4227e-05, gnorm=1.588, clip=0, loss_scale=16, train_wall=37, gb_free=11.3, wall=20544
2023-07-06 16:40:40 | INFO | train_inner | epoch 025:   1041 / 1474 loss=3.452, trans_loss=4.161, nll_loss=1.219, w2v_ctc_loss=1.797, contrastive_loss=0, total=4115.81, n_correct=3526.66, ppl=2.33, accuracy=85.686, wps=11226.9, ups=2.73, wpb=4115.8, bsz=155.7, num_updates=36400, lr=7.41249e-05, gnorm=1.678, clip=0, loss_scale=16, train_wall=36, gb_free=17, wall=20580
2023-07-06 16:41:16 | INFO | train_inner | epoch 025:   1141 / 1474 loss=3.44, trans_loss=4.144, nll_loss=1.197, w2v_ctc_loss=1.797, contrastive_loss=0, total=3983.65, n_correct=3420.39, ppl=2.29, accuracy=85.861, wps=10985.6, ups=2.76, wpb=3983.7, bsz=143.2, num_updates=36500, lr=7.40233e-05, gnorm=1.68, clip=0, loss_scale=16, train_wall=36, gb_free=17.8, wall=20617
2023-07-06 16:41:52 | INFO | train_inner | epoch 025:   1241 / 1474 loss=3.435, trans_loss=4.143, nll_loss=1.197, w2v_ctc_loss=1.782, contrastive_loss=0, total=4031.16, n_correct=3465.47, ppl=2.29, accuracy=85.967, wps=11192.4, ups=2.78, wpb=4031.2, bsz=147.6, num_updates=36600, lr=7.39221e-05, gnorm=1.599, clip=0, loss_scale=16, train_wall=36, gb_free=17.8, wall=20653
2023-07-06 16:42:29 | INFO | train_inner | epoch 025:   1341 / 1474 loss=3.441, trans_loss=4.148, nll_loss=1.202, w2v_ctc_loss=1.793, contrastive_loss=0, total=4101.18, n_correct=3521.97, ppl=2.3, accuracy=85.877, wps=11252.9, ups=2.74, wpb=4101.2, bsz=153.7, num_updates=36700, lr=7.38213e-05, gnorm=1.671, clip=0, loss_scale=16, train_wall=36, gb_free=16.6, wall=20689
2023-07-06 16:43:06 | INFO | train_inner | epoch 025:   1441 / 1474 loss=3.455, trans_loss=4.164, nll_loss=1.224, w2v_ctc_loss=1.799, contrastive_loss=0, total=4054.57, n_correct=3468.09, ppl=2.34, accuracy=85.535, wps=11040, ups=2.72, wpb=4054.6, bsz=152.2, num_updates=36800, lr=7.3721e-05, gnorm=1.68, clip=0, loss_scale=16, train_wall=36, gb_free=16.7, wall=20726
2023-07-06 16:43:18 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 16:43:35 | INFO | dev_rec_st | epoch 025 | valid on 'dev_rec_st' subset | loss 3.602 | trans_loss 4.049 | nll_loss 1.023 | w2v_ctc_loss 2.559 | contrastive_loss 0 | total 3909.1 | n_correct 3467.1 | ppl 2.03 | accuracy 88.693 | uer 22.329 | wer 24.645 | raw_wer 24.645 | bleu 0.83 | wps 3831.9 | wpb 3909.1 | bsz 141.8 | num_updates 36833 | best_bleu 0.86
2023-07-06 16:43:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36833 updates
2023-07-06 16:43:35 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_last.pt
2023-07-06 16:43:40 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_last.pt
2023-07-06 16:43:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_last.pt (epoch 25 @ 36833 updates, score 0.83) (writing took 4.691983818993322 seconds)
2023-07-06 16:43:40 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-07-06 16:43:40 | INFO | train | epoch 025 | loss 3.445 | trans_loss 4.152 | nll_loss 1.207 | w2v_ctc_loss 1.795 | contrastive_loss 0 | total 4078.54 | n_correct 3499.47 | ppl 2.31 | accuracy 85.802 | wps 10146.7 | ups 2.49 | wpb 4078.5 | bsz 152.8 | num_updates 36833 | lr 7.36879e-05 | gnorm 1.654 | clip 0 | loss_scale 16 | train_wall 532 | gb_free 14.5 | wall 20760
2023-07-06 16:43:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 16:43:40 | INFO | fairseq.trainer | begin training epoch 26
2023-07-06 16:43:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 16:44:12 | INFO | train_inner | epoch 026:     67 / 1474 loss=3.428, trans_loss=4.134, nll_loss=1.185, w2v_ctc_loss=1.781, contrastive_loss=0, total=4110.6, n_correct=3540.84, ppl=2.27, accuracy=86.139, wps=6189.5, ups=1.51, wpb=4110.6, bsz=158.4, num_updates=36900, lr=7.3621e-05, gnorm=1.619, clip=0, loss_scale=16, train_wall=36, gb_free=17.1, wall=20792
2023-07-06 16:44:49 | INFO | train_inner | epoch 026:    167 / 1474 loss=3.41, trans_loss=4.133, nll_loss=1.185, w2v_ctc_loss=1.722, contrastive_loss=0, total=4206.73, n_correct=3624.44, ppl=2.27, accuracy=86.158, wps=11464.8, ups=2.73, wpb=4206.7, bsz=170.2, num_updates=37000, lr=7.35215e-05, gnorm=1.569, clip=0, loss_scale=16, train_wall=36, gb_free=15.6, wall=20829
2023-07-06 16:45:25 | INFO | train_inner | epoch 026:    267 / 1474 loss=3.432, trans_loss=4.146, nll_loss=1.2, w2v_ctc_loss=1.765, contrastive_loss=0, total=4072.51, n_correct=3498.29, ppl=2.3, accuracy=85.9, wps=11124.6, ups=2.73, wpb=4072.5, bsz=153.4, num_updates=37100, lr=7.34223e-05, gnorm=1.627, clip=0, loss_scale=16, train_wall=36, gb_free=17.2, wall=20866
2023-07-06 16:46:02 | INFO | train_inner | epoch 026:    367 / 1474 loss=3.418, trans_loss=4.134, nll_loss=1.186, w2v_ctc_loss=1.748, contrastive_loss=0, total=4106.22, n_correct=3538.65, ppl=2.28, accuracy=86.178, wps=11280.3, ups=2.75, wpb=4106.2, bsz=157.6, num_updates=37200, lr=7.33236e-05, gnorm=1.621, clip=0, loss_scale=16, train_wall=36, gb_free=17.3, wall=20902
2023-07-06 16:46:38 | INFO | train_inner | epoch 026:    467 / 1474 loss=3.432, trans_loss=4.137, nll_loss=1.189, w2v_ctc_loss=1.787, contrastive_loss=0, total=4099.27, n_correct=3528.26, ppl=2.28, accuracy=86.07, wps=11271.3, ups=2.75, wpb=4099.3, bsz=156.3, num_updates=37300, lr=7.32252e-05, gnorm=1.651, clip=0, loss_scale=16, train_wall=36, gb_free=14.3, wall=20938
2023-07-06 16:47:15 | INFO | train_inner | epoch 026:    567 / 1474 loss=3.436, trans_loss=4.138, nll_loss=1.19, w2v_ctc_loss=1.799, contrastive_loss=0, total=4116.15, n_correct=3541.89, ppl=2.28, accuracy=86.049, wps=11247.2, ups=2.73, wpb=4116.1, bsz=152.2, num_updates=37400, lr=7.31272e-05, gnorm=1.63, clip=0, loss_scale=32, train_wall=36, gb_free=13.1, wall=20975
2023-07-06 16:47:51 | INFO | train_inner | epoch 026:    667 / 1474 loss=3.426, trans_loss=4.136, nll_loss=1.188, w2v_ctc_loss=1.769, contrastive_loss=0, total=4066.84, n_correct=3498.52, ppl=2.28, accuracy=86.026, wps=11073.8, ups=2.72, wpb=4066.8, bsz=148.8, num_updates=37500, lr=7.30297e-05, gnorm=1.602, clip=0, loss_scale=32, train_wall=36, gb_free=14.1, wall=21012
2023-07-06 16:48:28 | INFO | train_inner | epoch 026:    767 / 1474 loss=3.432, trans_loss=4.147, nll_loss=1.202, w2v_ctc_loss=1.764, contrastive_loss=0, total=4044.2, n_correct=3473.69, ppl=2.3, accuracy=85.893, wps=11084.9, ups=2.74, wpb=4044.2, bsz=150.3, num_updates=37600, lr=7.29325e-05, gnorm=1.628, clip=0, loss_scale=32, train_wall=36, gb_free=16.9, wall=21048
2023-07-06 16:49:04 | INFO | train_inner | epoch 026:    867 / 1474 loss=3.433, trans_loss=4.14, nll_loss=1.193, w2v_ctc_loss=1.786, contrastive_loss=0, total=4108.77, n_correct=3532.87, ppl=2.29, accuracy=85.984, wps=11294.9, ups=2.75, wpb=4108.8, bsz=153.2, num_updates=37700, lr=7.28357e-05, gnorm=1.696, clip=0, loss_scale=32, train_wall=36, gb_free=16.4, wall=21085
2023-07-06 16:49:41 | INFO | train_inner | epoch 026:    967 / 1474 loss=3.424, trans_loss=4.138, nll_loss=1.19, w2v_ctc_loss=1.758, contrastive_loss=0, total=4076.94, n_correct=3506.5, ppl=2.28, accuracy=86.008, wps=11189.6, ups=2.74, wpb=4076.9, bsz=149.8, num_updates=37800, lr=7.27393e-05, gnorm=1.611, clip=0, loss_scale=32, train_wall=36, gb_free=15.7, wall=21121
2023-07-06 16:50:17 | INFO | train_inner | epoch 026:   1067 / 1474 loss=3.427, trans_loss=4.134, nll_loss=1.185, w2v_ctc_loss=1.779, contrastive_loss=0, total=4064.36, n_correct=3497.86, ppl=2.27, accuracy=86.062, wps=11188.9, ups=2.75, wpb=4064.4, bsz=146.5, num_updates=37900, lr=7.26433e-05, gnorm=1.655, clip=0, loss_scale=32, train_wall=36, gb_free=15.7, wall=21157
2023-07-06 16:50:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-06 16:50:54 | INFO | train_inner | epoch 026:   1168 / 1474 loss=3.434, trans_loss=4.142, nll_loss=1.197, w2v_ctc_loss=1.781, contrastive_loss=0, total=4047.66, n_correct=3478.67, ppl=2.29, accuracy=85.943, wps=10926.1, ups=2.7, wpb=4047.7, bsz=149.2, num_updates=38000, lr=7.25476e-05, gnorm=1.629, clip=0, loss_scale=16, train_wall=37, gb_free=16.9, wall=21194
2023-07-06 16:50:54 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 16:51:11 | INFO | dev_rec_st | epoch 026 | valid on 'dev_rec_st' subset | loss 3.588 | trans_loss 4.047 | nll_loss 1.015 | w2v_ctc_loss 2.517 | contrastive_loss 0 | total 3909.1 | n_correct 3469.3 | ppl 2.02 | accuracy 88.749 | uer 21.918 | wer 23.996 | raw_wer 23.996 | bleu 0.85 | wps 3871.7 | wpb 3909.1 | bsz 141.8 | num_updates 38000 | best_bleu 0.86
2023-07-06 16:51:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-07-06 16:51:11 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_26_38000.pt
2023-07-06 16:51:14 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_26_38000.pt
2023-07-06 16:51:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 0.85) (writing took 8.816691875006654 seconds)
2023-07-06 16:51:57 | INFO | train_inner | epoch 026:   1268 / 1474 loss=3.453, trans_loss=4.153, nll_loss=1.209, w2v_ctc_loss=1.819, contrastive_loss=0, total=3950.54, n_correct=3384.38, ppl=2.31, accuracy=85.669, wps=6270.5, ups=1.59, wpb=3950.5, bsz=140.2, num_updates=38100, lr=7.24524e-05, gnorm=1.63, clip=0, loss_scale=16, train_wall=36, gb_free=17.1, wall=21257
2023-07-06 16:52:34 | INFO | train_inner | epoch 026:   1368 / 1474 loss=3.432, trans_loss=4.141, nll_loss=1.196, w2v_ctc_loss=1.777, contrastive_loss=0, total=4083.96, n_correct=3511.48, ppl=2.29, accuracy=85.982, wps=11049.5, ups=2.71, wpb=4084, bsz=155.6, num_updates=38200, lr=7.23575e-05, gnorm=1.644, clip=0, loss_scale=16, train_wall=37, gb_free=14, wall=21294
2023-07-06 16:53:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-06 16:53:11 | INFO | train_inner | epoch 026:   1469 / 1474 loss=3.407, trans_loss=4.124, nll_loss=1.174, w2v_ctc_loss=1.733, contrastive_loss=0, total=4082.72, n_correct=3522.08, ppl=2.26, accuracy=86.268, wps=11059.8, ups=2.71, wpb=4082.7, bsz=157.5, num_updates=38300, lr=7.22629e-05, gnorm=1.609, clip=0, loss_scale=8, train_wall=37, gb_free=16.5, wall=21331
2023-07-06 16:53:13 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 16:53:30 | INFO | dev_rec_st | epoch 026 | valid on 'dev_rec_st' subset | loss 3.59 | trans_loss 4.049 | nll_loss 1.024 | w2v_ctc_loss 2.52 | contrastive_loss 0 | total 3909.1 | n_correct 3465 | ppl 2.03 | accuracy 88.639 | uer 22.159 | wer 24.265 | raw_wer 24.265 | bleu 0.84 | wps 3916.7 | wpb 3909.1 | bsz 141.8 | num_updates 38305 | best_bleu 0.86
2023-07-06 16:53:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38305 updates
2023-07-06 16:53:30 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_last.pt
2023-07-06 16:53:35 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_last.pt
2023-07-06 16:53:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_last.pt (epoch 26 @ 38305 updates, score 0.84) (writing took 4.615396023000358 seconds)
2023-07-06 16:53:35 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-07-06 16:53:35 | INFO | train | epoch 026 | loss 3.428 | trans_loss 4.138 | nll_loss 1.191 | w2v_ctc_loss 1.771 | contrastive_loss 0 | total 4078.53 | n_correct 3508.4 | ppl 2.28 | accuracy 86.021 | wps 10093.2 | ups 2.47 | wpb 4078.5 | bsz 152.8 | num_updates 38305 | lr 7.22582e-05 | gnorm 1.629 | clip 0 | loss_scale 8 | train_wall 532 | gb_free 16.3 | wall 21355
2023-07-06 16:53:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 16:53:35 | INFO | fairseq.trainer | begin training epoch 27
2023-07-06 16:53:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 16:54:17 | INFO | train_inner | epoch 027:     95 / 1474 loss=3.411, trans_loss=4.114, nll_loss=1.16, w2v_ctc_loss=1.772, contrastive_loss=0, total=3997.14, n_correct=3455.39, ppl=2.23, accuracy=86.447, wps=6080, ups=1.52, wpb=3997.1, bsz=142.2, num_updates=38400, lr=7.21688e-05, gnorm=1.651, clip=0, loss_scale=8, train_wall=36, gb_free=17, wall=21397
2023-07-06 16:54:53 | INFO | train_inner | epoch 027:    195 / 1474 loss=3.401, trans_loss=4.114, nll_loss=1.161, w2v_ctc_loss=1.739, contrastive_loss=0, total=4140.23, n_correct=3578.67, ppl=2.24, accuracy=86.437, wps=11349.1, ups=2.74, wpb=4140.2, bsz=161.8, num_updates=38500, lr=7.2075e-05, gnorm=1.644, clip=0, loss_scale=8, train_wall=36, gb_free=17, wall=21433
2023-07-06 16:55:30 | INFO | train_inner | epoch 027:    295 / 1474 loss=3.409, trans_loss=4.118, nll_loss=1.167, w2v_ctc_loss=1.753, contrastive_loss=0, total=4110.95, n_correct=3550.85, ppl=2.24, accuracy=86.375, wps=11161.8, ups=2.72, wpb=4110.9, bsz=153.1, num_updates=38600, lr=7.19816e-05, gnorm=1.681, clip=0, loss_scale=8, train_wall=36, gb_free=17.4, wall=21470
2023-07-06 16:56:07 | INFO | train_inner | epoch 027:    395 / 1474 loss=3.428, trans_loss=4.144, nll_loss=1.199, w2v_ctc_loss=1.757, contrastive_loss=0, total=4012.64, n_correct=3448.83, ppl=2.3, accuracy=85.949, wps=10894, ups=2.71, wpb=4012.6, bsz=149.7, num_updates=38700, lr=7.18885e-05, gnorm=1.647, clip=0, loss_scale=8, train_wall=36, gb_free=17.1, wall=21507
2023-07-06 16:56:44 | INFO | train_inner | epoch 027:    495 / 1474 loss=3.412, trans_loss=4.125, nll_loss=1.177, w2v_ctc_loss=1.747, contrastive_loss=0, total=4172.2, n_correct=3600.03, ppl=2.26, accuracy=86.286, wps=11327.5, ups=2.71, wpb=4172.2, bsz=163.5, num_updates=38800, lr=7.17958e-05, gnorm=1.605, clip=0, loss_scale=8, train_wall=36, gb_free=17, wall=21544
2023-07-06 16:57:20 | INFO | train_inner | epoch 027:    595 / 1474 loss=3.425, trans_loss=4.131, nll_loss=1.183, w2v_ctc_loss=1.777, contrastive_loss=0, total=4076.79, n_correct=3513.31, ppl=2.27, accuracy=86.178, wps=11214.3, ups=2.75, wpb=4076.8, bsz=156, num_updates=38900, lr=7.17035e-05, gnorm=1.652, clip=0, loss_scale=8, train_wall=36, gb_free=15.1, wall=21580
2023-07-06 16:57:56 | INFO | train_inner | epoch 027:    695 / 1474 loss=3.421, trans_loss=4.129, nll_loss=1.181, w2v_ctc_loss=1.767, contrastive_loss=0, total=4114.3, n_correct=3544.28, ppl=2.27, accuracy=86.145, wps=11308.9, ups=2.75, wpb=4114.3, bsz=153.4, num_updates=39000, lr=7.16115e-05, gnorm=1.664, clip=0, loss_scale=8, train_wall=36, gb_free=17.9, wall=21617
2023-07-06 16:58:33 | INFO | train_inner | epoch 027:    795 / 1474 loss=3.422, trans_loss=4.126, nll_loss=1.177, w2v_ctc_loss=1.778, contrastive_loss=0, total=4044, n_correct=3487.03, ppl=2.26, accuracy=86.227, wps=11052.9, ups=2.73, wpb=4044, bsz=146.8, num_updates=39100, lr=7.15199e-05, gnorm=1.718, clip=0, loss_scale=8, train_wall=36, gb_free=17.7, wall=21653
2023-07-06 16:59:09 | INFO | train_inner | epoch 027:    895 / 1474 loss=3.401, trans_loss=4.111, nll_loss=1.158, w2v_ctc_loss=1.743, contrastive_loss=0, total=4034.76, n_correct=3490.72, ppl=2.23, accuracy=86.516, wps=11093.1, ups=2.75, wpb=4034.8, bsz=146.7, num_updates=39200, lr=7.14286e-05, gnorm=1.673, clip=0, loss_scale=8, train_wall=36, gb_free=16.7, wall=21690
2023-07-06 16:59:46 | INFO | train_inner | epoch 027:    995 / 1474 loss=3.427, trans_loss=4.137, nll_loss=1.192, w2v_ctc_loss=1.77, contrastive_loss=0, total=4132.22, n_correct=3554.17, ppl=2.28, accuracy=86.011, wps=11202.4, ups=2.71, wpb=4132.2, bsz=157.6, num_updates=39300, lr=7.13376e-05, gnorm=1.663, clip=0, loss_scale=8, train_wall=36, gb_free=17, wall=21727
2023-07-06 17:00:23 | INFO | train_inner | epoch 027:   1095 / 1474 loss=3.41, trans_loss=4.119, nll_loss=1.169, w2v_ctc_loss=1.756, contrastive_loss=0, total=4109.11, n_correct=3549.62, ppl=2.25, accuracy=86.384, wps=11297.2, ups=2.75, wpb=4109.1, bsz=153.9, num_updates=39400, lr=7.1247e-05, gnorm=1.668, clip=0, loss_scale=8, train_wall=36, gb_free=15.9, wall=21763
2023-07-06 17:00:59 | INFO | train_inner | epoch 027:   1195 / 1474 loss=3.417, trans_loss=4.128, nll_loss=1.18, w2v_ctc_loss=1.757, contrastive_loss=0, total=4032.86, n_correct=3473.03, ppl=2.27, accuracy=86.118, wps=10983.6, ups=2.72, wpb=4032.9, bsz=147.1, num_updates=39500, lr=7.11568e-05, gnorm=1.626, clip=0, loss_scale=8, train_wall=36, gb_free=12.7, wall=21800
2023-07-06 17:01:36 | INFO | train_inner | epoch 027:   1295 / 1474 loss=3.425, trans_loss=4.133, nll_loss=1.187, w2v_ctc_loss=1.774, contrastive_loss=0, total=4009.72, n_correct=3450.76, ppl=2.28, accuracy=86.06, wps=11088.8, ups=2.77, wpb=4009.7, bsz=147.2, num_updates=39600, lr=7.10669e-05, gnorm=1.705, clip=0, loss_scale=8, train_wall=36, gb_free=16.7, wall=21836
2023-07-06 17:02:12 | INFO | train_inner | epoch 027:   1395 / 1474 loss=3.409, trans_loss=4.123, nll_loss=1.175, w2v_ctc_loss=1.744, contrastive_loss=0, total=4093.69, n_correct=3531.55, ppl=2.26, accuracy=86.268, wps=11382.9, ups=2.78, wpb=4093.7, bsz=156.5, num_updates=39700, lr=7.09773e-05, gnorm=1.647, clip=0, loss_scale=8, train_wall=36, gb_free=17.8, wall=21872
2023-07-06 17:02:40 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 17:02:57 | INFO | dev_rec_st | epoch 027 | valid on 'dev_rec_st' subset | loss 3.612 | trans_loss 4.053 | nll_loss 1.028 | w2v_ctc_loss 2.583 | contrastive_loss 0 | total 3909.1 | n_correct 3460.2 | ppl 2.04 | accuracy 88.517 | uer 22.178 | wer 24.246 | raw_wer 24.246 | bleu 0.84 | wps 3853.8 | wpb 3909.1 | bsz 141.8 | num_updates 39779 | best_bleu 0.86
2023-07-06 17:02:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39779 updates
2023-07-06 17:02:57 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_last.pt
2023-07-06 17:03:02 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_last.pt
2023-07-06 17:03:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_last.pt (epoch 27 @ 39779 updates, score 0.84) (writing took 4.700034911002149 seconds)
2023-07-06 17:03:02 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-07-06 17:03:02 | INFO | train | epoch 027 | loss 3.415 | trans_loss 4.125 | nll_loss 1.175 | w2v_ctc_loss 1.76 | contrastive_loss 0 | total 4078.54 | n_correct 3517.87 | ppl 2.26 | accuracy 86.253 | wps 10596.5 | ups 2.6 | wpb 4078.5 | bsz 152.8 | num_updates 39779 | lr 7.09068e-05 | gnorm 1.657 | clip 0 | loss_scale 8 | train_wall 532 | gb_free 17.8 | wall 21922
2023-07-06 17:03:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 17:03:03 | INFO | fairseq.trainer | begin training epoch 28
2023-07-06 17:03:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 17:03:17 | INFO | train_inner | epoch 028:     21 / 1474 loss=3.405, trans_loss=4.109, nll_loss=1.156, w2v_ctc_loss=1.762, contrastive_loss=0, total=4055.98, n_correct=3507.74, ppl=2.23, accuracy=86.483, wps=6152.4, ups=1.52, wpb=4056, bsz=153.8, num_updates=39800, lr=7.08881e-05, gnorm=1.607, clip=0, loss_scale=8, train_wall=36, gb_free=15.7, wall=21938
2023-07-06 17:03:54 | INFO | train_inner | epoch 028:    121 / 1474 loss=3.399, trans_loss=4.107, nll_loss=1.152, w2v_ctc_loss=1.749, contrastive_loss=0, total=4038.91, n_correct=3496.06, ppl=2.22, accuracy=86.559, wps=11119.3, ups=2.75, wpb=4038.9, bsz=145.5, num_updates=39900, lr=7.07992e-05, gnorm=1.626, clip=0, loss_scale=8, train_wall=36, gb_free=16.6, wall=21974
2023-07-06 17:04:30 | INFO | train_inner | epoch 028:    221 / 1474 loss=3.394, trans_loss=4.099, nll_loss=1.144, w2v_ctc_loss=1.747, contrastive_loss=0, total=4132.49, n_correct=3584, ppl=2.21, accuracy=86.727, wps=11316.2, ups=2.74, wpb=4132.5, bsz=158.1, num_updates=40000, lr=7.07107e-05, gnorm=1.624, clip=0, loss_scale=8, train_wall=36, gb_free=17, wall=22011
2023-07-06 17:04:30 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 17:04:49 | INFO | dev_rec_st | epoch 028 | valid on 'dev_rec_st' subset | loss 3.526 | trans_loss 4.039 | nll_loss 1.014 | w2v_ctc_loss 2.329 | contrastive_loss 0 | total 3909.1 | n_correct 3476.2 | ppl 2.02 | accuracy 88.926 | uer 21.864 | wer 24.071 | raw_wer 24.071 | bleu 0.88 | wps 3379.3 | wpb 3909.1 | bsz 141.8 | num_updates 40000 | best_bleu 0.88
2023-07-06 17:04:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-07-06 17:04:49 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_28_40000.pt
2023-07-06 17:04:51 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_28_40000.pt
2023-07-06 17:04:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 0.88) (writing took 9.797653992995038 seconds)
2023-07-06 17:05:36 | INFO | train_inner | epoch 028:    321 / 1474 loss=3.421, trans_loss=4.137, nll_loss=1.193, w2v_ctc_loss=1.749, contrastive_loss=0, total=4070.09, n_correct=3500.27, ppl=2.29, accuracy=86, wps=6205.2, ups=1.52, wpb=4070.1, bsz=157.7, num_updates=40100, lr=7.06225e-05, gnorm=1.731, clip=0, loss_scale=8, train_wall=36, gb_free=16.9, wall=22076
2023-07-06 17:06:12 | INFO | train_inner | epoch 028:    421 / 1474 loss=3.411, trans_loss=4.114, nll_loss=1.162, w2v_ctc_loss=1.77, contrastive_loss=0, total=4038.06, n_correct=3491.02, ppl=2.24, accuracy=86.453, wps=11085.4, ups=2.75, wpb=4038.1, bsz=148.3, num_updates=40200, lr=7.05346e-05, gnorm=1.636, clip=0, loss_scale=8, train_wall=36, gb_free=17.7, wall=22113
2023-07-06 17:06:48 | INFO | train_inner | epoch 028:    521 / 1474 loss=3.393, trans_loss=4.106, nll_loss=1.152, w2v_ctc_loss=1.731, contrastive_loss=0, total=4055.41, n_correct=3507.64, ppl=2.22, accuracy=86.493, wps=11223, ups=2.77, wpb=4055.4, bsz=149.3, num_updates=40300, lr=7.0447e-05, gnorm=1.65, clip=0, loss_scale=8, train_wall=36, gb_free=15.1, wall=22149
2023-07-06 17:07:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-06 17:07:25 | INFO | train_inner | epoch 028:    622 / 1474 loss=3.404, trans_loss=4.112, nll_loss=1.161, w2v_ctc_loss=1.75, contrastive_loss=0, total=4119.94, n_correct=3559.43, ppl=2.24, accuracy=86.395, wps=11222, ups=2.72, wpb=4119.9, bsz=152.9, num_updates=40400, lr=7.03598e-05, gnorm=1.648, clip=0, loss_scale=8, train_wall=36, gb_free=16.7, wall=22185
2023-07-06 17:08:02 | INFO | train_inner | epoch 028:    722 / 1474 loss=3.399, trans_loss=4.117, nll_loss=1.167, w2v_ctc_loss=1.725, contrastive_loss=0, total=4114.85, n_correct=3555.61, ppl=2.25, accuracy=86.409, wps=11294.3, ups=2.74, wpb=4114.9, bsz=162.4, num_updates=40500, lr=7.02728e-05, gnorm=1.654, clip=0, loss_scale=8, train_wall=36, gb_free=16.7, wall=22222
2023-07-06 17:08:38 | INFO | train_inner | epoch 028:    822 / 1474 loss=3.393, trans_loss=4.103, nll_loss=1.148, w2v_ctc_loss=1.738, contrastive_loss=0, total=4027.59, n_correct=3489.34, ppl=2.22, accuracy=86.636, wps=11075.4, ups=2.75, wpb=4027.6, bsz=151.9, num_updates=40600, lr=7.01862e-05, gnorm=1.65, clip=0, loss_scale=8, train_wall=36, gb_free=16.9, wall=22258
2023-07-06 17:09:15 | INFO | train_inner | epoch 028:    922 / 1474 loss=3.414, trans_loss=4.123, nll_loss=1.175, w2v_ctc_loss=1.758, contrastive_loss=0, total=4075.94, n_correct=3517.09, ppl=2.26, accuracy=86.289, wps=11004.8, ups=2.7, wpb=4075.9, bsz=150.8, num_updates=40700, lr=7.01e-05, gnorm=1.703, clip=0, loss_scale=8, train_wall=37, gb_free=16.7, wall=22295
2023-07-06 17:09:52 | INFO | train_inner | epoch 028:   1022 / 1474 loss=3.42, trans_loss=4.125, nll_loss=1.177, w2v_ctc_loss=1.773, contrastive_loss=0, total=4112.72, n_correct=3544.39, ppl=2.26, accuracy=86.181, wps=11273.2, ups=2.74, wpb=4112.7, bsz=155, num_updates=40800, lr=7.0014e-05, gnorm=1.693, clip=0, loss_scale=8, train_wall=36, gb_free=17, wall=22332
2023-07-06 17:10:28 | INFO | train_inner | epoch 028:   1122 / 1474 loss=3.398, trans_loss=4.11, nll_loss=1.159, w2v_ctc_loss=1.738, contrastive_loss=0, total=4163.36, n_correct=3600.08, ppl=2.23, accuracy=86.471, wps=11362.7, ups=2.73, wpb=4163.4, bsz=160.3, num_updates=40900, lr=6.99284e-05, gnorm=1.61, clip=0, loss_scale=8, train_wall=36, gb_free=17.8, wall=22368
2023-07-06 17:11:05 | INFO | train_inner | epoch 028:   1222 / 1474 loss=3.384, trans_loss=4.101, nll_loss=1.148, w2v_ctc_loss=1.71, contrastive_loss=0, total=4052.64, n_correct=3510.7, ppl=2.22, accuracy=86.627, wps=11078.2, ups=2.73, wpb=4052.6, bsz=153.5, num_updates=41000, lr=6.9843e-05, gnorm=1.623, clip=0, loss_scale=8, train_wall=36, gb_free=12.9, wall=22405
2023-07-06 17:11:42 | INFO | train_inner | epoch 028:   1322 / 1474 loss=3.435, trans_loss=4.137, nll_loss=1.192, w2v_ctc_loss=1.798, contrastive_loss=0, total=4016.25, n_correct=3451.83, ppl=2.28, accuracy=85.947, wps=10922.7, ups=2.72, wpb=4016.2, bsz=140.9, num_updates=41100, lr=6.9758e-05, gnorm=1.707, clip=0, loss_scale=8, train_wall=36, gb_free=17.2, wall=22442
2023-07-06 17:12:18 | INFO | train_inner | epoch 028:   1422 / 1474 loss=3.426, trans_loss=4.131, nll_loss=1.185, w2v_ctc_loss=1.781, contrastive_loss=0, total=4086.37, n_correct=3514.87, ppl=2.27, accuracy=86.014, wps=11139.9, ups=2.73, wpb=4086.4, bsz=150.2, num_updates=41200, lr=6.96733e-05, gnorm=1.671, clip=0, loss_scale=8, train_wall=36, gb_free=16.3, wall=22478
2023-07-06 17:12:37 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 17:12:54 | INFO | dev_rec_st | epoch 028 | valid on 'dev_rec_st' subset | loss 3.562 | trans_loss 4.063 | nll_loss 1.038 | w2v_ctc_loss 2.394 | contrastive_loss 0 | total 3909.1 | n_correct 3457.6 | ppl 2.05 | accuracy 88.45 | uer 21.984 | wer 23.679 | raw_wer 23.679 | bleu 0.87 | wps 3793.6 | wpb 3909.1 | bsz 141.8 | num_updates 41252 | best_bleu 0.88
2023-07-06 17:12:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41252 updates
2023-07-06 17:12:54 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8700.pt
2023-07-06 17:12:57 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8700.pt
2023-07-06 17:13:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8700.pt (epoch 28 @ 41252 updates, score 0.87) (writing took 5.648960097998497 seconds)
2023-07-06 17:13:00 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-07-06 17:13:00 | INFO | train | epoch 028 | loss 3.406 | trans_loss 4.116 | nll_loss 1.165 | w2v_ctc_loss 1.75 | contrastive_loss 0 | total 4079.07 | n_correct 3523.52 | ppl 2.24 | accuracy 86.381 | wps 10044.4 | ups 2.46 | wpb 4079.1 | bsz 152.9 | num_updates 41252 | lr 6.96294e-05 | gnorm 1.66 | clip 0 | loss_scale 8 | train_wall 532 | gb_free 16.7 | wall 22521
2023-07-06 17:13:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 17:13:01 | INFO | fairseq.trainer | begin training epoch 29
2023-07-06 17:13:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 17:13:25 | INFO | train_inner | epoch 029:     48 / 1474 loss=3.396, trans_loss=4.107, nll_loss=1.155, w2v_ctc_loss=1.737, contrastive_loss=0, total=4099.02, n_correct=3550.39, ppl=2.23, accuracy=86.616, wps=6100.6, ups=1.49, wpb=4099, bsz=157.5, num_updates=41300, lr=6.95889e-05, gnorm=1.696, clip=0, loss_scale=8, train_wall=36, gb_free=17, wall=22546
2023-07-06 17:14:02 | INFO | train_inner | epoch 029:    148 / 1474 loss=3.395, trans_loss=4.101, nll_loss=1.147, w2v_ctc_loss=1.748, contrastive_loss=0, total=4070.12, n_correct=3524.15, ppl=2.21, accuracy=86.586, wps=11059.4, ups=2.72, wpb=4070.1, bsz=154, num_updates=41400, lr=6.95048e-05, gnorm=1.676, clip=0, loss_scale=8, train_wall=36, gb_free=16.8, wall=22582
2023-07-06 17:14:39 | INFO | train_inner | epoch 029:    248 / 1474 loss=3.382, trans_loss=4.1, nll_loss=1.146, w2v_ctc_loss=1.709, contrastive_loss=0, total=4122.82, n_correct=3575.32, ppl=2.21, accuracy=86.72, wps=11084.6, ups=2.69, wpb=4122.8, bsz=164.1, num_updates=41500, lr=6.9421e-05, gnorm=1.625, clip=0, loss_scale=8, train_wall=37, gb_free=16.4, wall=22620
2023-07-06 17:15:16 | INFO | train_inner | epoch 029:    348 / 1474 loss=3.41, trans_loss=4.109, nll_loss=1.157, w2v_ctc_loss=1.78, contrastive_loss=0, total=4034.71, n_correct=3489.35, ppl=2.23, accuracy=86.483, wps=11028.1, ups=2.73, wpb=4034.7, bsz=145.6, num_updates=41600, lr=6.93375e-05, gnorm=1.73, clip=0, loss_scale=8, train_wall=36, gb_free=17.1, wall=22656
2023-07-06 17:15:52 | INFO | train_inner | epoch 029:    448 / 1474 loss=3.38, trans_loss=4.089, nll_loss=1.131, w2v_ctc_loss=1.727, contrastive_loss=0, total=4098.61, n_correct=3561.69, ppl=2.19, accuracy=86.9, wps=11283.8, ups=2.75, wpb=4098.6, bsz=153.9, num_updates=41700, lr=6.92543e-05, gnorm=1.615, clip=0, loss_scale=8, train_wall=36, gb_free=15, wall=22693
2023-07-06 17:16:29 | INFO | train_inner | epoch 029:    548 / 1474 loss=3.405, trans_loss=4.118, nll_loss=1.169, w2v_ctc_loss=1.742, contrastive_loss=0, total=4095.16, n_correct=3534.75, ppl=2.25, accuracy=86.315, wps=11174.9, ups=2.73, wpb=4095.2, bsz=147.6, num_updates=41800, lr=6.91714e-05, gnorm=1.618, clip=0, loss_scale=8, train_wall=36, gb_free=16.9, wall=22729
2023-07-06 17:17:05 | INFO | train_inner | epoch 029:    648 / 1474 loss=3.398, trans_loss=4.112, nll_loss=1.161, w2v_ctc_loss=1.732, contrastive_loss=0, total=4097.38, n_correct=3541.99, ppl=2.24, accuracy=86.445, wps=11217, ups=2.74, wpb=4097.4, bsz=160.2, num_updates=41900, lr=6.90889e-05, gnorm=1.65, clip=0, loss_scale=8, train_wall=36, gb_free=16.3, wall=22766
2023-07-06 17:17:42 | INFO | train_inner | epoch 029:    748 / 1474 loss=3.393, trans_loss=4.105, nll_loss=1.153, w2v_ctc_loss=1.731, contrastive_loss=0, total=4179.78, n_correct=3621.14, ppl=2.22, accuracy=86.635, wps=11329.5, ups=2.71, wpb=4179.8, bsz=164.3, num_updates=42000, lr=6.90066e-05, gnorm=1.639, clip=0, loss_scale=8, train_wall=36, gb_free=15.9, wall=22803
2023-07-06 17:17:42 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 17:18:00 | INFO | dev_rec_st | epoch 029 | valid on 'dev_rec_st' subset | loss 3.559 | trans_loss 4.048 | nll_loss 1.014 | w2v_ctc_loss 2.417 | contrastive_loss 0 | total 3909.1 | n_correct 3469.3 | ppl 2.02 | accuracy 88.749 | uer 21.761 | wer 24.052 | raw_wer 24.052 | bleu 0.84 | wps 3835.2 | wpb 3909.1 | bsz 141.8 | num_updates 42000 | best_bleu 0.88
2023-07-06 17:18:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-07-06 17:18:00 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_29_42000.pt
2023-07-06 17:18:02 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_29_42000.pt
2023-07-06 17:18:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 0.84) (writing took 5.49936970800627 seconds)
2023-07-06 17:18:42 | INFO | train_inner | epoch 029:    848 / 1474 loss=3.399, trans_loss=4.101, nll_loss=1.148, w2v_ctc_loss=1.76, contrastive_loss=0, total=3970.79, n_correct=3437.08, ppl=2.22, accuracy=86.559, wps=6694.5, ups=1.69, wpb=3970.8, bsz=141.5, num_updates=42100, lr=6.89246e-05, gnorm=1.673, clip=0, loss_scale=8, train_wall=36, gb_free=16.7, wall=22862
2023-07-06 17:19:18 | INFO | train_inner | epoch 029:    948 / 1474 loss=3.398, trans_loss=4.103, nll_loss=1.149, w2v_ctc_loss=1.754, contrastive_loss=0, total=4027.01, n_correct=3485.42, ppl=2.22, accuracy=86.551, wps=11132, ups=2.76, wpb=4027, bsz=146.7, num_updates=42200, lr=6.88428e-05, gnorm=1.645, clip=0, loss_scale=8, train_wall=36, gb_free=16.4, wall=22898
2023-07-06 17:19:54 | INFO | train_inner | epoch 029:   1048 / 1474 loss=3.382, trans_loss=4.099, nll_loss=1.146, w2v_ctc_loss=1.707, contrastive_loss=0, total=4068.08, n_correct=3526.71, ppl=2.21, accuracy=86.692, wps=11198.1, ups=2.75, wpb=4068.1, bsz=154, num_updates=42300, lr=6.87614e-05, gnorm=1.625, clip=0, loss_scale=8, train_wall=36, gb_free=17.2, wall=22935
2023-07-06 17:20:31 | INFO | train_inner | epoch 029:   1148 / 1474 loss=3.408, trans_loss=4.111, nll_loss=1.161, w2v_ctc_loss=1.768, contrastive_loss=0, total=4026.44, n_correct=3479.52, ppl=2.24, accuracy=86.417, wps=11070.7, ups=2.75, wpb=4026.4, bsz=142.6, num_updates=42400, lr=6.86803e-05, gnorm=1.708, clip=0, loss_scale=16, train_wall=36, gb_free=12.4, wall=22971
2023-07-06 17:21:07 | INFO | train_inner | epoch 029:   1248 / 1474 loss=3.397, trans_loss=4.103, nll_loss=1.15, w2v_ctc_loss=1.751, contrastive_loss=0, total=4101.8, n_correct=3550.12, ppl=2.22, accuracy=86.55, wps=11275.8, ups=2.75, wpb=4101.8, bsz=150.8, num_updates=42500, lr=6.85994e-05, gnorm=1.644, clip=0, loss_scale=16, train_wall=36, gb_free=16.8, wall=23007
2023-07-06 17:21:44 | INFO | train_inner | epoch 029:   1348 / 1474 loss=3.394, trans_loss=4.107, nll_loss=1.155, w2v_ctc_loss=1.73, contrastive_loss=0, total=4090.79, n_correct=3539.61, ppl=2.23, accuracy=86.526, wps=11141.3, ups=2.72, wpb=4090.8, bsz=154.3, num_updates=42600, lr=6.85189e-05, gnorm=1.669, clip=0, loss_scale=16, train_wall=36, gb_free=16.7, wall=23044
2023-07-06 17:22:20 | INFO | train_inner | epoch 029:   1448 / 1474 loss=3.397, trans_loss=4.11, nll_loss=1.16, w2v_ctc_loss=1.733, contrastive_loss=0, total=4097.85, n_correct=3542.51, ppl=2.24, accuracy=86.448, wps=11348, ups=2.77, wpb=4097.9, bsz=156.2, num_updates=42700, lr=6.84386e-05, gnorm=1.658, clip=0, loss_scale=16, train_wall=36, gb_free=17.9, wall=23080
2023-07-06 17:22:29 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 17:22:47 | INFO | dev_rec_st | epoch 029 | valid on 'dev_rec_st' subset | loss 3.54 | trans_loss 4.046 | nll_loss 1.032 | w2v_ctc_loss 2.357 | contrastive_loss 0 | total 3909.1 | n_correct 3468.9 | ppl 2.04 | accuracy 88.739 | uer 21.721 | wer 23.858 | raw_wer 23.858 | bleu 0.86 | wps 3717.1 | wpb 3909.1 | bsz 141.8 | num_updates 42726 | best_bleu 0.88
2023-07-06 17:22:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42726 updates
2023-07-06 17:22:47 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8602.pt
2023-07-06 17:22:50 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8602.pt
2023-07-06 17:22:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8602.pt (epoch 29 @ 42726 updates, score 0.86) (writing took 5.948887871985789 seconds)
2023-07-06 17:22:53 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-07-06 17:22:53 | INFO | train | epoch 029 | loss 3.395 | trans_loss 4.104 | nll_loss 1.152 | w2v_ctc_loss 1.74 | contrastive_loss 0 | total 4078.54 | n_correct 3530.86 | ppl 2.22 | accuracy 86.572 | wps 10137.8 | ups 2.49 | wpb 4078.5 | bsz 152.8 | num_updates 42726 | lr 6.84178e-05 | gnorm 1.655 | clip 0 | loss_scale 16 | train_wall 532 | gb_free 16.4 | wall 23114
2023-07-06 17:22:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 17:22:54 | INFO | fairseq.trainer | begin training epoch 30
2023-07-06 17:22:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 17:23:29 | INFO | train_inner | epoch 030:     74 / 1474 loss=3.378, trans_loss=4.095, nll_loss=1.14, w2v_ctc_loss=1.707, contrastive_loss=0, total=4113.86, n_correct=3568.83, ppl=2.2, accuracy=86.751, wps=5972.4, ups=1.45, wpb=4113.9, bsz=158.7, num_updates=42800, lr=6.83586e-05, gnorm=1.608, clip=0, loss_scale=16, train_wall=36, gb_free=16, wall=23149
2023-07-06 17:24:05 | INFO | train_inner | epoch 030:    174 / 1474 loss=3.373, trans_loss=4.086, nll_loss=1.13, w2v_ctc_loss=1.708, contrastive_loss=0, total=4150.65, n_correct=3609.77, ppl=2.19, accuracy=86.969, wps=11396.5, ups=2.75, wpb=4150.6, bsz=160.2, num_updates=42900, lr=6.82789e-05, gnorm=1.631, clip=0, loss_scale=16, train_wall=36, gb_free=17.1, wall=23185
2023-07-06 17:24:41 | INFO | train_inner | epoch 030:    274 / 1474 loss=3.378, trans_loss=4.087, nll_loss=1.13, w2v_ctc_loss=1.726, contrastive_loss=0, total=4052.44, n_correct=3523.39, ppl=2.19, accuracy=86.945, wps=11164.2, ups=2.75, wpb=4052.4, bsz=146.6, num_updates=43000, lr=6.81994e-05, gnorm=1.649, clip=0, loss_scale=16, train_wall=36, gb_free=15.9, wall=23222
2023-07-06 17:25:18 | INFO | train_inner | epoch 030:    374 / 1474 loss=3.373, trans_loss=4.08, nll_loss=1.121, w2v_ctc_loss=1.725, contrastive_loss=0, total=4129.21, n_correct=3593.13, ppl=2.18, accuracy=87.017, wps=11294.1, ups=2.74, wpb=4129.2, bsz=154.6, num_updates=43100, lr=6.81203e-05, gnorm=1.661, clip=0, loss_scale=16, train_wall=36, gb_free=17.3, wall=23258
2023-07-06 17:25:54 | INFO | train_inner | epoch 030:    474 / 1474 loss=3.379, trans_loss=4.093, nll_loss=1.138, w2v_ctc_loss=1.714, contrastive_loss=0, total=4062.12, n_correct=3525.31, ppl=2.2, accuracy=86.785, wps=11247.2, ups=2.77, wpb=4062.1, bsz=155.6, num_updates=43200, lr=6.80414e-05, gnorm=1.671, clip=0, loss_scale=16, train_wall=36, gb_free=15.1, wall=23294
2023-07-06 17:26:30 | INFO | train_inner | epoch 030:    574 / 1474 loss=3.367, trans_loss=4.085, nll_loss=1.128, w2v_ctc_loss=1.694, contrastive_loss=0, total=4104.76, n_correct=3567.31, ppl=2.18, accuracy=86.907, wps=11277.8, ups=2.75, wpb=4104.8, bsz=156.1, num_updates=43300, lr=6.79628e-05, gnorm=1.58, clip=0, loss_scale=16, train_wall=36, gb_free=15.4, wall=23331
2023-07-06 17:27:07 | INFO | train_inner | epoch 030:    674 / 1474 loss=3.381, trans_loss=4.093, nll_loss=1.138, w2v_ctc_loss=1.72, contrastive_loss=0, total=4137.18, n_correct=3589.29, ppl=2.2, accuracy=86.757, wps=11249.8, ups=2.72, wpb=4137.2, bsz=157.6, num_updates=43400, lr=6.78844e-05, gnorm=1.583, clip=0, loss_scale=16, train_wall=36, gb_free=15.8, wall=23368
2023-07-06 17:27:44 | INFO | train_inner | epoch 030:    774 / 1474 loss=3.389, trans_loss=4.105, nll_loss=1.154, w2v_ctc_loss=1.718, contrastive_loss=0, total=4042.93, n_correct=3499.46, ppl=2.23, accuracy=86.558, wps=11092.8, ups=2.74, wpb=4042.9, bsz=151.3, num_updates=43500, lr=6.78064e-05, gnorm=1.619, clip=0, loss_scale=16, train_wall=36, gb_free=16.4, wall=23404
2023-07-06 17:28:20 | INFO | train_inner | epoch 030:    874 / 1474 loss=3.375, trans_loss=4.088, nll_loss=1.132, w2v_ctc_loss=1.71, contrastive_loss=0, total=4043.78, n_correct=3513.84, ppl=2.19, accuracy=86.895, wps=11092.7, ups=2.74, wpb=4043.8, bsz=148.9, num_updates=43600, lr=6.77285e-05, gnorm=1.674, clip=0, loss_scale=16, train_wall=36, gb_free=16.4, wall=23440
2023-07-06 17:28:57 | INFO | train_inner | epoch 030:    974 / 1474 loss=3.389, trans_loss=4.098, nll_loss=1.146, w2v_ctc_loss=1.735, contrastive_loss=0, total=4059.8, n_correct=3517.45, ppl=2.21, accuracy=86.641, wps=11009.2, ups=2.71, wpb=4059.8, bsz=149.4, num_updates=43700, lr=6.7651e-05, gnorm=1.655, clip=0, loss_scale=16, train_wall=36, gb_free=16.7, wall=23477
2023-07-06 17:29:34 | INFO | train_inner | epoch 030:   1074 / 1474 loss=3.4, trans_loss=4.106, nll_loss=1.154, w2v_ctc_loss=1.754, contrastive_loss=0, total=4023.47, n_correct=3480.69, ppl=2.23, accuracy=86.51, wps=10945.6, ups=2.72, wpb=4023.5, bsz=139.8, num_updates=43800, lr=6.75737e-05, gnorm=1.714, clip=0, loss_scale=16, train_wall=36, gb_free=16.4, wall=23514
2023-07-06 17:30:10 | INFO | train_inner | epoch 030:   1174 / 1474 loss=3.375, trans_loss=4.091, nll_loss=1.137, w2v_ctc_loss=1.705, contrastive_loss=0, total=4109.75, n_correct=3566.86, ppl=2.2, accuracy=86.79, wps=11278.9, ups=2.74, wpb=4109.8, bsz=157.4, num_updates=43900, lr=6.74967e-05, gnorm=1.634, clip=0, loss_scale=16, train_wall=36, gb_free=17.7, wall=23551
2023-07-06 17:30:47 | INFO | train_inner | epoch 030:   1274 / 1474 loss=3.395, trans_loss=4.102, nll_loss=1.15, w2v_ctc_loss=1.745, contrastive_loss=0, total=3980.72, n_correct=3444.42, ppl=2.22, accuracy=86.528, wps=10841.5, ups=2.72, wpb=3980.7, bsz=142.1, num_updates=44000, lr=6.742e-05, gnorm=1.668, clip=0, loss_scale=16, train_wall=36, gb_free=15.1, wall=23587
2023-07-06 17:30:47 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 17:31:04 | INFO | dev_rec_st | epoch 030 | valid on 'dev_rec_st' subset | loss 3.558 | trans_loss 4.026 | nll_loss 1.001 | w2v_ctc_loss 2.466 | contrastive_loss 0 | total 3909.1 | n_correct 3480 | ppl 2 | accuracy 89.023 | uer 21.262 | wer 23.135 | raw_wer 23.135 | bleu 0.86 | wps 3926.4 | wpb 3909.1 | bsz 141.8 | num_updates 44000 | best_bleu 0.88
2023-07-06 17:31:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-07-06 17:31:04 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_30_44000.pt
2023-07-06 17:31:07 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_30_44000.pt
2023-07-06 17:31:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 0.86) (writing took 7.343959907011595 seconds)
2023-07-06 17:31:48 | INFO | train_inner | epoch 030:   1374 / 1474 loss=3.362, trans_loss=4.083, nll_loss=1.127, w2v_ctc_loss=1.68, contrastive_loss=0, total=4119.12, n_correct=3579.13, ppl=2.18, accuracy=86.891, wps=6732, ups=1.63, wpb=4119.1, bsz=161, num_updates=44100, lr=6.73435e-05, gnorm=1.639, clip=0, loss_scale=16, train_wall=36, gb_free=16.8, wall=23648
2023-07-06 17:32:25 | INFO | train_inner | epoch 030:   1474 / 1474 loss=3.368, trans_loss=4.095, nll_loss=1.142, w2v_ctc_loss=1.674, contrastive_loss=0, total=4061.01, n_correct=3522.57, ppl=2.21, accuracy=86.741, wps=11112.1, ups=2.74, wpb=4061, bsz=156.9, num_updates=44200, lr=6.72673e-05, gnorm=1.569, clip=0, loss_scale=16, train_wall=36, gb_free=17.2, wall=23685
2023-07-06 17:32:25 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 17:32:42 | INFO | dev_rec_st | epoch 030 | valid on 'dev_rec_st' subset | loss 3.55 | trans_loss 4.015 | nll_loss 0.984 | w2v_ctc_loss 2.464 | contrastive_loss 0 | total 3909.1 | n_correct 3484.1 | ppl 1.98 | accuracy 89.128 | uer 21.75 | wer 23.489 | raw_wer 23.489 | bleu 0.87 | wps 3756.8 | wpb 3909.1 | bsz 141.8 | num_updates 44200 | best_bleu 0.88
2023-07-06 17:32:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44200 updates
2023-07-06 17:32:42 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8708.pt
2023-07-06 17:32:45 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8708.pt
2023-07-06 17:32:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8708.pt (epoch 30 @ 44200 updates, score 0.87) (writing took 5.82540400500875 seconds)
2023-07-06 17:32:48 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-07-06 17:32:48 | INFO | train | epoch 030 | loss 3.379 | trans_loss 4.092 | nll_loss 1.138 | w2v_ctc_loss 1.714 | contrastive_loss 0 | total 4078.54 | n_correct 3539.37 | ppl 2.2 | accuracy 86.78 | wps 10103.3 | ups 2.48 | wpb 4078.5 | bsz 152.8 | num_updates 44200 | lr 6.72673e-05 | gnorm 1.638 | clip 0 | loss_scale 16 | train_wall 532 | gb_free 17.2 | wall 23709
2023-07-06 17:32:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 17:32:49 | INFO | fairseq.trainer | begin training epoch 31
2023-07-06 17:32:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 17:33:33 | INFO | train_inner | epoch 031:    100 / 1474 loss=3.371, trans_loss=4.076, nll_loss=1.118, w2v_ctc_loss=1.724, contrastive_loss=0, total=4031.3, n_correct=3510.29, ppl=2.17, accuracy=87.076, wps=5946, ups=1.47, wpb=4031.3, bsz=146.7, num_updates=44300, lr=6.71913e-05, gnorm=1.666, clip=0, loss_scale=16, train_wall=36, gb_free=15.1, wall=23753
2023-07-06 17:34:09 | INFO | train_inner | epoch 031:    200 / 1474 loss=3.364, trans_loss=4.075, nll_loss=1.115, w2v_ctc_loss=1.705, contrastive_loss=0, total=4079.26, n_correct=3552.65, ppl=2.17, accuracy=87.091, wps=11102.3, ups=2.72, wpb=4079.3, bsz=149.7, num_updates=44400, lr=6.71156e-05, gnorm=1.654, clip=0, loss_scale=16, train_wall=36, gb_free=12.2, wall=23790
2023-07-06 17:34:46 | INFO | train_inner | epoch 031:    300 / 1474 loss=3.376, trans_loss=4.086, nll_loss=1.13, w2v_ctc_loss=1.72, contrastive_loss=0, total=4085.87, n_correct=3549.11, ppl=2.19, accuracy=86.863, wps=11154.5, ups=2.73, wpb=4085.9, bsz=150.6, num_updates=44500, lr=6.70402e-05, gnorm=1.668, clip=0, loss_scale=32, train_wall=36, gb_free=13.6, wall=23826
2023-07-06 17:35:22 | INFO | train_inner | epoch 031:    400 / 1474 loss=3.381, trans_loss=4.085, nll_loss=1.129, w2v_ctc_loss=1.737, contrastive_loss=0, total=4022.54, n_correct=3495.73, ppl=2.19, accuracy=86.904, wps=11035.7, ups=2.74, wpb=4022.5, bsz=143.1, num_updates=44600, lr=6.6965e-05, gnorm=1.666, clip=0, loss_scale=32, train_wall=36, gb_free=13.7, wall=23863
2023-07-06 17:35:59 | INFO | train_inner | epoch 031:    500 / 1474 loss=3.364, trans_loss=4.081, nll_loss=1.124, w2v_ctc_loss=1.693, contrastive_loss=0, total=4064.95, n_correct=3535.56, ppl=2.18, accuracy=86.977, wps=11124.3, ups=2.74, wpb=4065, bsz=150.3, num_updates=44700, lr=6.689e-05, gnorm=1.605, clip=0, loss_scale=32, train_wall=36, gb_free=16.5, wall=23899
2023-07-06 17:36:35 | INFO | train_inner | epoch 031:    600 / 1474 loss=3.367, trans_loss=4.078, nll_loss=1.119, w2v_ctc_loss=1.709, contrastive_loss=0, total=4022.65, n_correct=3499.82, ppl=2.17, accuracy=87.003, wps=11011.8, ups=2.74, wpb=4022.7, bsz=146.7, num_updates=44800, lr=6.68153e-05, gnorm=1.717, clip=0, loss_scale=32, train_wall=36, gb_free=12.2, wall=23936
2023-07-06 17:37:12 | INFO | train_inner | epoch 031:    700 / 1474 loss=3.352, trans_loss=4.069, nll_loss=1.109, w2v_ctc_loss=1.679, contrastive_loss=0, total=4141.74, n_correct=3613.83, ppl=2.16, accuracy=87.254, wps=11388.2, ups=2.75, wpb=4141.7, bsz=157.5, num_updates=44900, lr=6.67409e-05, gnorm=1.653, clip=0, loss_scale=32, train_wall=36, gb_free=17.9, wall=23972
2023-07-06 17:37:48 | INFO | train_inner | epoch 031:    800 / 1474 loss=3.369, trans_loss=4.09, nll_loss=1.135, w2v_ctc_loss=1.686, contrastive_loss=0, total=4065.46, n_correct=3529.3, ppl=2.2, accuracy=86.812, wps=11136.9, ups=2.74, wpb=4065.5, bsz=148.7, num_updates=45000, lr=6.66667e-05, gnorm=1.62, clip=0, loss_scale=32, train_wall=36, gb_free=15.5, wall=24009
2023-07-06 17:38:25 | INFO | train_inner | epoch 031:    900 / 1474 loss=3.366, trans_loss=4.082, nll_loss=1.125, w2v_ctc_loss=1.694, contrastive_loss=0, total=4036, n_correct=3509.16, ppl=2.18, accuracy=86.946, wps=10991.1, ups=2.72, wpb=4036, bsz=147.2, num_updates=45100, lr=6.65927e-05, gnorm=1.641, clip=0, loss_scale=32, train_wall=36, gb_free=15.3, wall=24045
2023-07-06 17:39:01 | INFO | train_inner | epoch 031:   1000 / 1474 loss=3.372, trans_loss=4.087, nll_loss=1.133, w2v_ctc_loss=1.704, contrastive_loss=0, total=4108.2, n_correct=3568.96, ppl=2.19, accuracy=86.874, wps=11332.5, ups=2.76, wpb=4108.2, bsz=159.5, num_updates=45200, lr=6.6519e-05, gnorm=1.632, clip=0, loss_scale=32, train_wall=36, gb_free=13.5, wall=24082
2023-07-06 17:39:38 | INFO | train_inner | epoch 031:   1100 / 1474 loss=3.361, trans_loss=4.079, nll_loss=1.122, w2v_ctc_loss=1.686, contrastive_loss=0, total=4078.74, n_correct=3549.46, ppl=2.18, accuracy=87.023, wps=11189.3, ups=2.74, wpb=4078.7, bsz=157.6, num_updates=45300, lr=6.64455e-05, gnorm=1.635, clip=0, loss_scale=32, train_wall=36, gb_free=16.1, wall=24118
2023-07-06 17:40:14 | INFO | train_inner | epoch 031:   1200 / 1474 loss=3.38, trans_loss=4.092, nll_loss=1.138, w2v_ctc_loss=1.72, contrastive_loss=0, total=4127.96, n_correct=3582, ppl=2.2, accuracy=86.774, wps=11412.2, ups=2.76, wpb=4128, bsz=160.9, num_updates=45400, lr=6.63723e-05, gnorm=1.695, clip=0, loss_scale=32, train_wall=36, gb_free=17.1, wall=24154
2023-07-06 17:40:50 | INFO | train_inner | epoch 031:   1300 / 1474 loss=3.365, trans_loss=4.079, nll_loss=1.123, w2v_ctc_loss=1.698, contrastive_loss=0, total=4175.51, n_correct=3633.77, ppl=2.18, accuracy=87.026, wps=11531.4, ups=2.76, wpb=4175.5, bsz=163.4, num_updates=45500, lr=6.62994e-05, gnorm=1.596, clip=0, loss_scale=32, train_wall=36, gb_free=17.1, wall=24190
2023-07-06 17:41:27 | INFO | train_inner | epoch 031:   1400 / 1474 loss=3.376, trans_loss=4.103, nll_loss=1.153, w2v_ctc_loss=1.679, contrastive_loss=0, total=4133.82, n_correct=3580.41, ppl=2.22, accuracy=86.613, wps=11297.2, ups=2.73, wpb=4133.8, bsz=163.7, num_updates=45600, lr=6.62266e-05, gnorm=1.621, clip=0, loss_scale=32, train_wall=36, gb_free=16.6, wall=24227
2023-07-06 17:41:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-06 17:41:53 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 17:42:11 | INFO | dev_rec_st | epoch 031 | valid on 'dev_rec_st' subset | loss 3.512 | trans_loss 4.033 | nll_loss 1.006 | w2v_ctc_loss 2.295 | contrastive_loss 0 | total 3909.1 | n_correct 3476.8 | ppl 2.01 | accuracy 88.941 | uer 21.684 | wer 23.881 | raw_wer 23.881 | bleu 0.85 | wps 3874 | wpb 3909.1 | bsz 141.8 | num_updates 45673 | best_bleu 0.88
2023-07-06 17:42:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45673 updates
2023-07-06 17:42:11 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_last.pt
2023-07-06 17:42:15 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_last.pt
2023-07-06 17:42:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_last.pt (epoch 31 @ 45673 updates, score 0.85) (writing took 4.52294488500047 seconds)
2023-07-06 17:42:15 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-07-06 17:42:15 | INFO | train | epoch 031 | loss 3.368 | trans_loss 4.083 | nll_loss 1.126 | w2v_ctc_loss 1.702 | contrastive_loss 0 | total 4078.03 | n_correct 3545.89 | ppl 2.18 | accuracy 86.951 | wps 10595.2 | ups 2.6 | wpb 4078 | bsz 152.8 | num_updates 45673 | lr 6.61737e-05 | gnorm 1.647 | clip 0 | loss_scale 16 | train_wall 531 | gb_free 12.4 | wall 24276
2023-07-06 17:42:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 17:42:16 | INFO | fairseq.trainer | begin training epoch 32
2023-07-06 17:42:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 17:42:33 | INFO | train_inner | epoch 032:     27 / 1474 loss=3.359, trans_loss=4.073, nll_loss=1.114, w2v_ctc_loss=1.695, contrastive_loss=0, total=3990.72, n_correct=3477.41, ppl=2.16, accuracy=87.137, wps=6038.5, ups=1.51, wpb=3990.7, bsz=145.5, num_updates=45700, lr=6.61541e-05, gnorm=1.678, clip=0, loss_scale=16, train_wall=36, gb_free=16.7, wall=24293
2023-07-06 17:43:10 | INFO | train_inner | epoch 032:    127 / 1474 loss=3.337, trans_loss=4.056, nll_loss=1.093, w2v_ctc_loss=1.658, contrastive_loss=0, total=4146, n_correct=3627.19, ppl=2.13, accuracy=87.486, wps=11277.3, ups=2.72, wpb=4146, bsz=159.5, num_updates=45800, lr=6.60819e-05, gnorm=1.648, clip=0, loss_scale=16, train_wall=36, gb_free=11.9, wall=24330
2023-07-06 17:43:46 | INFO | train_inner | epoch 032:    227 / 1474 loss=3.342, trans_loss=4.061, nll_loss=1.1, w2v_ctc_loss=1.665, contrastive_loss=0, total=4098.73, n_correct=3580.67, ppl=2.14, accuracy=87.36, wps=11176.7, ups=2.73, wpb=4098.7, bsz=160.2, num_updates=45900, lr=6.60098e-05, gnorm=1.672, clip=0, loss_scale=16, train_wall=36, gb_free=14.6, wall=24367
2023-07-06 17:44:23 | INFO | train_inner | epoch 032:    327 / 1474 loss=3.338, trans_loss=4.054, nll_loss=1.091, w2v_ctc_loss=1.667, contrastive_loss=0, total=4111.63, n_correct=3596.56, ppl=2.13, accuracy=87.473, wps=11301.8, ups=2.75, wpb=4111.6, bsz=156.7, num_updates=46000, lr=6.5938e-05, gnorm=1.561, clip=0, loss_scale=16, train_wall=36, gb_free=17.2, wall=24403
2023-07-06 17:44:23 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 17:44:40 | INFO | dev_rec_st | epoch 032 | valid on 'dev_rec_st' subset | loss 3.554 | trans_loss 4.018 | nll_loss 0.981 | w2v_ctc_loss 2.473 | contrastive_loss 0 | total 3909.1 | n_correct 3489.9 | ppl 1.97 | accuracy 89.276 | uer 21.519 | wer 23.381 | raw_wer 23.381 | bleu 0.87 | wps 3818 | wpb 3909.1 | bsz 141.8 | num_updates 46000 | best_bleu 0.88
2023-07-06 17:44:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-07-06 17:44:40 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_32_46000.pt
2023-07-06 17:44:43 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_32_46000.pt
2023-07-06 17:44:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 0.87) (writing took 6.95222405999084 seconds)
2023-07-06 17:45:24 | INFO | train_inner | epoch 032:    427 / 1474 loss=3.344, trans_loss=4.06, nll_loss=1.098, w2v_ctc_loss=1.675, contrastive_loss=0, total=4133.6, n_correct=3611.8, ppl=2.14, accuracy=87.377, wps=6730.6, ups=1.63, wpb=4133.6, bsz=156.1, num_updates=46100, lr=6.58665e-05, gnorm=1.635, clip=0, loss_scale=16, train_wall=36, gb_free=17.9, wall=24464
2023-07-06 17:46:01 | INFO | train_inner | epoch 032:    527 / 1474 loss=3.377, trans_loss=4.084, nll_loss=1.128, w2v_ctc_loss=1.727, contrastive_loss=0, total=4140.12, n_correct=3597.01, ppl=2.19, accuracy=86.882, wps=11271.7, ups=2.72, wpb=4140.1, bsz=157, num_updates=46200, lr=6.57952e-05, gnorm=1.675, clip=0, loss_scale=16, train_wall=36, gb_free=13.1, wall=24501
2023-07-06 17:46:38 | INFO | train_inner | epoch 032:    627 / 1474 loss=3.36, trans_loss=4.071, nll_loss=1.111, w2v_ctc_loss=1.701, contrastive_loss=0, total=4071.81, n_correct=3547.87, ppl=2.16, accuracy=87.133, wps=11052.8, ups=2.71, wpb=4071.8, bsz=149.4, num_updates=46300, lr=6.57241e-05, gnorm=1.688, clip=0, loss_scale=16, train_wall=36, gb_free=17.3, wall=24538
2023-07-06 17:47:14 | INFO | train_inner | epoch 032:    727 / 1474 loss=3.361, trans_loss=4.07, nll_loss=1.111, w2v_ctc_loss=1.706, contrastive_loss=0, total=4105.48, n_correct=3579.51, ppl=2.16, accuracy=87.189, wps=11156.2, ups=2.72, wpb=4105.5, bsz=152.2, num_updates=46400, lr=6.56532e-05, gnorm=1.654, clip=0, loss_scale=16, train_wall=36, gb_free=16, wall=24575
2023-07-06 17:47:51 | INFO | train_inner | epoch 032:    827 / 1474 loss=3.353, trans_loss=4.068, nll_loss=1.109, w2v_ctc_loss=1.683, contrastive_loss=0, total=4043.07, n_correct=3525, ppl=2.16, accuracy=87.186, wps=11149.4, ups=2.76, wpb=4043.1, bsz=146.3, num_updates=46500, lr=6.55826e-05, gnorm=1.63, clip=0, loss_scale=16, train_wall=36, gb_free=16, wall=24611
2023-07-06 17:48:27 | INFO | train_inner | epoch 032:    927 / 1474 loss=3.355, trans_loss=4.068, nll_loss=1.108, w2v_ctc_loss=1.692, contrastive_loss=0, total=4071.63, n_correct=3547.97, ppl=2.16, accuracy=87.139, wps=11143.1, ups=2.74, wpb=4071.6, bsz=150.2, num_updates=46600, lr=6.55122e-05, gnorm=1.68, clip=0, loss_scale=16, train_wall=36, gb_free=17.1, wall=24648
2023-07-06 17:49:04 | INFO | train_inner | epoch 032:   1027 / 1474 loss=3.36, trans_loss=4.073, nll_loss=1.116, w2v_ctc_loss=1.695, contrastive_loss=0, total=4049.39, n_correct=3529.08, ppl=2.17, accuracy=87.151, wps=11139.7, ups=2.75, wpb=4049.4, bsz=151.2, num_updates=46700, lr=6.5442e-05, gnorm=1.702, clip=0, loss_scale=16, train_wall=36, gb_free=17.3, wall=24684
2023-07-06 17:49:40 | INFO | train_inner | epoch 032:   1127 / 1474 loss=3.37, trans_loss=4.083, nll_loss=1.126, w2v_ctc_loss=1.708, contrastive_loss=0, total=3951.83, n_correct=3435.08, ppl=2.18, accuracy=86.924, wps=10809.2, ups=2.74, wpb=3951.8, bsz=134.9, num_updates=46800, lr=6.5372e-05, gnorm=1.727, clip=0, loss_scale=16, train_wall=36, gb_free=14.6, wall=24720
2023-07-06 17:50:17 | INFO | train_inner | epoch 032:   1227 / 1474 loss=3.368, trans_loss=4.086, nll_loss=1.133, w2v_ctc_loss=1.691, contrastive_loss=0, total=4103.44, n_correct=3565.38, ppl=2.19, accuracy=86.888, wps=11263.9, ups=2.74, wpb=4103.4, bsz=156.1, num_updates=46900, lr=6.53023e-05, gnorm=1.652, clip=0, loss_scale=16, train_wall=36, gb_free=16.3, wall=24757
2023-07-06 17:50:53 | INFO | train_inner | epoch 032:   1327 / 1474 loss=3.361, trans_loss=4.073, nll_loss=1.115, w2v_ctc_loss=1.699, contrastive_loss=0, total=4011, n_correct=3491.98, ppl=2.17, accuracy=87.06, wps=11079.9, ups=2.76, wpb=4011, bsz=149, num_updates=47000, lr=6.52328e-05, gnorm=1.702, clip=0, loss_scale=16, train_wall=36, gb_free=17.2, wall=24793
2023-07-06 17:51:29 | INFO | train_inner | epoch 032:   1427 / 1474 loss=3.375, trans_loss=4.091, nll_loss=1.138, w2v_ctc_loss=1.706, contrastive_loss=0, total=4052.29, n_correct=3518.77, ppl=2.2, accuracy=86.834, wps=11209.3, ups=2.77, wpb=4052.3, bsz=153.1, num_updates=47100, lr=6.51635e-05, gnorm=1.678, clip=0, loss_scale=16, train_wall=36, gb_free=17.4, wall=24829
2023-07-06 17:51:46 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 17:52:03 | INFO | dev_rec_st | epoch 032 | valid on 'dev_rec_st' subset | loss 3.491 | trans_loss 4.012 | nll_loss 0.981 | w2v_ctc_loss 2.276 | contrastive_loss 0 | total 3909.1 | n_correct 3486.5 | ppl 1.97 | accuracy 89.189 | uer 20.962 | wer 23.023 | raw_wer 23.023 | bleu 0.87 | wps 3846.7 | wpb 3909.1 | bsz 141.8 | num_updates 47147 | best_bleu 0.88
2023-07-06 17:52:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47147 updates
2023-07-06 17:52:03 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8705.pt
2023-07-06 17:52:06 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8705.pt
2023-07-06 17:52:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8705.pt (epoch 32 @ 47147 updates, score 0.87) (writing took 5.761129781007185 seconds)
2023-07-06 17:52:09 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-07-06 17:52:09 | INFO | train | epoch 032 | loss 3.357 | trans_loss 4.072 | nll_loss 1.113 | w2v_ctc_loss 1.689 | contrastive_loss 0 | total 4078.54 | n_correct 3554.09 | ppl 2.16 | accuracy 87.141 | wps 10122.5 | ups 2.48 | wpb 4078.5 | bsz 152.8 | num_updates 47147 | lr 6.5131e-05 | gnorm 1.664 | clip 0 | loss_scale 16 | train_wall 532 | gb_free 16.8 | wall 24870
2023-07-06 17:52:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 17:52:09 | INFO | fairseq.trainer | begin training epoch 33
2023-07-06 17:52:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 17:52:36 | INFO | train_inner | epoch 033:     53 / 1474 loss=3.36, trans_loss=4.082, nll_loss=1.127, w2v_ctc_loss=1.676, contrastive_loss=0, total=4084.85, n_correct=3552.49, ppl=2.18, accuracy=86.967, wps=6062.1, ups=1.48, wpb=4084.8, bsz=159.9, num_updates=47200, lr=6.50945e-05, gnorm=1.66, clip=0, loss_scale=16, train_wall=36, gb_free=16.2, wall=24897
2023-07-06 17:53:13 | INFO | train_inner | epoch 033:    153 / 1474 loss=3.337, trans_loss=4.05, nll_loss=1.086, w2v_ctc_loss=1.672, contrastive_loss=0, total=4009.88, n_correct=3508.87, ppl=2.12, accuracy=87.506, wps=11035.3, ups=2.75, wpb=4009.9, bsz=142.6, num_updates=47300, lr=6.50256e-05, gnorm=1.693, clip=0, loss_scale=16, train_wall=36, gb_free=16.8, wall=24933
2023-07-06 17:53:49 | INFO | train_inner | epoch 033:    253 / 1474 loss=3.341, trans_loss=4.066, nll_loss=1.108, w2v_ctc_loss=1.648, contrastive_loss=0, total=4225.44, n_correct=3686.33, ppl=2.16, accuracy=87.241, wps=11573.3, ups=2.74, wpb=4225.4, bsz=173.8, num_updates=47400, lr=6.4957e-05, gnorm=1.64, clip=0, loss_scale=16, train_wall=36, gb_free=16.5, wall=24970
2023-07-06 17:54:26 | INFO | train_inner | epoch 033:    353 / 1474 loss=3.352, trans_loss=4.064, nll_loss=1.103, w2v_ctc_loss=1.692, contrastive_loss=0, total=4056.38, n_correct=3537.95, ppl=2.15, accuracy=87.219, wps=11139.4, ups=2.75, wpb=4056.4, bsz=151.1, num_updates=47500, lr=6.48886e-05, gnorm=1.66, clip=0, loss_scale=16, train_wall=36, gb_free=16.4, wall=25006
2023-07-06 17:55:01 | INFO | train_inner | epoch 033:    453 / 1474 loss=3.318, trans_loss=4.037, nll_loss=1.069, w2v_ctc_loss=1.64, contrastive_loss=0, total=4091.46, n_correct=3589.62, ppl=2.1, accuracy=87.734, wps=11412.4, ups=2.79, wpb=4091.5, bsz=154.8, num_updates=47600, lr=6.48204e-05, gnorm=1.654, clip=0, loss_scale=16, train_wall=35, gb_free=15.7, wall=25042
2023-07-06 17:55:38 | INFO | train_inner | epoch 033:    553 / 1474 loss=3.349, trans_loss=4.063, nll_loss=1.103, w2v_ctc_loss=1.682, contrastive_loss=0, total=4065.6, n_correct=3547.17, ppl=2.15, accuracy=87.248, wps=11167.8, ups=2.75, wpb=4065.6, bsz=147.1, num_updates=47700, lr=6.47524e-05, gnorm=1.664, clip=0, loss_scale=16, train_wall=36, gb_free=17.8, wall=25078
2023-07-06 17:56:15 | INFO | train_inner | epoch 033:    653 / 1474 loss=3.351, trans_loss=4.069, nll_loss=1.11, w2v_ctc_loss=1.676, contrastive_loss=0, total=4092.56, n_correct=3566.96, ppl=2.16, accuracy=87.157, wps=11160.5, ups=2.73, wpb=4092.6, bsz=150.4, num_updates=47800, lr=6.46846e-05, gnorm=1.68, clip=0, loss_scale=32, train_wall=36, gb_free=16.2, wall=25115
2023-07-06 17:56:51 | INFO | train_inner | epoch 033:    753 / 1474 loss=3.362, trans_loss=4.07, nll_loss=1.112, w2v_ctc_loss=1.708, contrastive_loss=0, total=4008.37, n_correct=3493.94, ppl=2.16, accuracy=87.166, wps=11019, ups=2.75, wpb=4008.4, bsz=144.1, num_updates=47900, lr=6.46171e-05, gnorm=1.667, clip=0, loss_scale=32, train_wall=36, gb_free=16.4, wall=25151
2023-07-06 17:57:27 | INFO | train_inner | epoch 033:    853 / 1474 loss=3.326, trans_loss=4.052, nll_loss=1.09, w2v_ctc_loss=1.632, contrastive_loss=0, total=4057.29, n_correct=3550.76, ppl=2.13, accuracy=87.516, wps=11173.3, ups=2.75, wpb=4057.3, bsz=157.8, num_updates=48000, lr=6.45497e-05, gnorm=1.604, clip=0, loss_scale=32, train_wall=36, gb_free=16.3, wall=25188
2023-07-06 17:57:27 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 17:57:45 | INFO | dev_rec_st | epoch 033 | valid on 'dev_rec_st' subset | loss 3.554 | trans_loss 4.015 | nll_loss 0.98 | w2v_ctc_loss 2.478 | contrastive_loss 0 | total 3909.1 | n_correct 3487.3 | ppl 1.97 | accuracy 89.21 | uer 21.124 | wer 22.915 | raw_wer 22.915 | bleu 0.9 | wps 3871.1 | wpb 3909.1 | bsz 141.8 | num_updates 48000 | best_bleu 0.9
2023-07-06 17:57:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-07-06 17:57:45 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_33_48000.pt
2023-07-06 17:57:47 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_33_48000.pt
2023-07-06 17:57:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 0.9) (writing took 10.169274463012698 seconds)
2023-07-06 17:58:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-06 17:58:32 | INFO | train_inner | epoch 033:    954 / 1474 loss=3.358, trans_loss=4.067, nll_loss=1.108, w2v_ctc_loss=1.702, contrastive_loss=0, total=4105.4, n_correct=3580.45, ppl=2.16, accuracy=87.213, wps=6322.9, ups=1.54, wpb=4105.4, bsz=155.8, num_updates=48100, lr=6.44826e-05, gnorm=1.674, clip=0, loss_scale=16, train_wall=37, gb_free=16.2, wall=25252
2023-07-06 17:59:09 | INFO | train_inner | epoch 033:   1054 / 1474 loss=3.361, trans_loss=4.076, nll_loss=1.12, w2v_ctc_loss=1.693, contrastive_loss=0, total=4078.95, n_correct=3550.26, ppl=2.17, accuracy=87.039, wps=11072.6, ups=2.71, wpb=4079, bsz=152.4, num_updates=48200, lr=6.44157e-05, gnorm=1.676, clip=0, loss_scale=16, train_wall=36, gb_free=16.9, wall=25289
2023-07-06 17:59:46 | INFO | train_inner | epoch 033:   1154 / 1474 loss=3.344, trans_loss=4.062, nll_loss=1.102, w2v_ctc_loss=1.668, contrastive_loss=0, total=4114.07, n_correct=3590.43, ppl=2.15, accuracy=87.272, wps=11269.7, ups=2.74, wpb=4114.1, bsz=153.8, num_updates=48300, lr=6.43489e-05, gnorm=1.643, clip=0, loss_scale=16, train_wall=36, gb_free=16.6, wall=25326
2023-07-06 18:00:22 | INFO | train_inner | epoch 033:   1254 / 1474 loss=3.356, trans_loss=4.069, nll_loss=1.11, w2v_ctc_loss=1.693, contrastive_loss=0, total=4055.36, n_correct=3532.25, ppl=2.16, accuracy=87.101, wps=11074.2, ups=2.73, wpb=4055.4, bsz=147.2, num_updates=48400, lr=6.42824e-05, gnorm=1.73, clip=0, loss_scale=16, train_wall=36, gb_free=16.4, wall=25362
2023-07-06 18:00:59 | INFO | train_inner | epoch 033:   1354 / 1474 loss=3.347, trans_loss=4.064, nll_loss=1.105, w2v_ctc_loss=1.677, contrastive_loss=0, total=4075.69, n_correct=3554.7, ppl=2.15, accuracy=87.217, wps=11191.8, ups=2.75, wpb=4075.7, bsz=155.8, num_updates=48500, lr=6.42161e-05, gnorm=1.631, clip=0, loss_scale=16, train_wall=36, gb_free=15.6, wall=25399
2023-07-06 18:01:35 | INFO | train_inner | epoch 033:   1454 / 1474 loss=3.348, trans_loss=4.067, nll_loss=1.109, w2v_ctc_loss=1.671, contrastive_loss=0, total=4079.12, n_correct=3555.91, ppl=2.16, accuracy=87.173, wps=11175.6, ups=2.74, wpb=4079.1, bsz=155.8, num_updates=48600, lr=6.415e-05, gnorm=1.712, clip=0, loss_scale=16, train_wall=36, gb_free=17.2, wall=25435
2023-07-06 18:01:42 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 18:02:00 | INFO | dev_rec_st | epoch 033 | valid on 'dev_rec_st' subset | loss 3.559 | trans_loss 4.012 | nll_loss 0.979 | w2v_ctc_loss 2.501 | contrastive_loss 0 | total 3909.1 | n_correct 3488.9 | ppl 1.97 | accuracy 89.251 | uer 21.148 | wer 22.907 | raw_wer 22.907 | bleu 0.9 | wps 3814.6 | wpb 3909.1 | bsz 141.8 | num_updates 48620 | best_bleu 0.9
2023-07-06 18:02:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48620 updates
2023-07-06 18:02:00 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 18:02:04 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 18:02:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt (epoch 33 @ 48620 updates, score 0.9) (writing took 9.221279717996367 seconds)
2023-07-06 18:02:09 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-07-06 18:02:09 | INFO | train | epoch 033 | loss 3.347 | trans_loss 4.063 | nll_loss 1.103 | w2v_ctc_loss 1.676 | contrastive_loss 0 | total 4078.31 | n_correct 3559.04 | ppl 2.15 | accuracy 87.267 | wps 10014.3 | ups 2.46 | wpb 4078.3 | bsz 152.8 | num_updates 48620 | lr 6.41368e-05 | gnorm 1.668 | clip 0 | loss_scale 16 | train_wall 531 | gb_free 17.9 | wall 25469
2023-07-06 18:02:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 18:02:09 | INFO | fairseq.trainer | begin training epoch 34
2023-07-06 18:02:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 18:02:46 | INFO | train_inner | epoch 034:     80 / 1474 loss=3.326, trans_loss=4.04, nll_loss=1.074, w2v_ctc_loss=1.659, contrastive_loss=0, total=4062.68, n_correct=3563.5, ppl=2.11, accuracy=87.713, wps=5727.5, ups=1.41, wpb=4062.7, bsz=150.3, num_updates=48700, lr=6.40841e-05, gnorm=1.597, clip=0, loss_scale=16, train_wall=36, gb_free=16.2, wall=25506
2023-07-06 18:03:23 | INFO | train_inner | epoch 034:    180 / 1474 loss=3.328, trans_loss=4.047, nll_loss=1.083, w2v_ctc_loss=1.649, contrastive_loss=0, total=4011.21, n_correct=3511.78, ppl=2.12, accuracy=87.549, wps=10938, ups=2.73, wpb=4011.2, bsz=147.6, num_updates=48800, lr=6.40184e-05, gnorm=1.648, clip=0, loss_scale=16, train_wall=36, gb_free=16.8, wall=25543
2023-07-06 18:03:59 | INFO | train_inner | epoch 034:    280 / 1474 loss=3.342, trans_loss=4.069, nll_loss=1.112, w2v_ctc_loss=1.644, contrastive_loss=0, total=4167.45, n_correct=3633.63, ppl=2.16, accuracy=87.191, wps=11408.6, ups=2.74, wpb=4167.4, bsz=163.8, num_updates=48900, lr=6.39529e-05, gnorm=1.722, clip=0, loss_scale=16, train_wall=36, gb_free=16.7, wall=25580
2023-07-06 18:04:36 | INFO | train_inner | epoch 034:    380 / 1474 loss=3.325, trans_loss=4.047, nll_loss=1.083, w2v_ctc_loss=1.64, contrastive_loss=0, total=4097.48, n_correct=3589, ppl=2.12, accuracy=87.59, wps=11238.3, ups=2.74, wpb=4097.5, bsz=158.2, num_updates=49000, lr=6.38877e-05, gnorm=1.606, clip=0, loss_scale=16, train_wall=36, gb_free=16.1, wall=25616
2023-07-06 18:05:12 | INFO | train_inner | epoch 034:    480 / 1474 loss=3.348, trans_loss=4.054, nll_loss=1.091, w2v_ctc_loss=1.7, contrastive_loss=0, total=4016.6, n_correct=3511.36, ppl=2.13, accuracy=87.421, wps=11027.5, ups=2.75, wpb=4016.6, bsz=143.3, num_updates=49100, lr=6.38226e-05, gnorm=1.711, clip=0, loss_scale=16, train_wall=36, gb_free=15.8, wall=25652
2023-07-06 18:05:48 | INFO | train_inner | epoch 034:    580 / 1474 loss=3.34, trans_loss=4.049, nll_loss=1.086, w2v_ctc_loss=1.684, contrastive_loss=0, total=4057.59, n_correct=3552.66, ppl=2.12, accuracy=87.556, wps=11191.9, ups=2.76, wpb=4057.6, bsz=150.1, num_updates=49200, lr=6.37577e-05, gnorm=1.662, clip=0, loss_scale=16, train_wall=36, gb_free=16.3, wall=25689
2023-07-06 18:06:25 | INFO | train_inner | epoch 034:    680 / 1474 loss=3.331, trans_loss=4.044, nll_loss=1.079, w2v_ctc_loss=1.667, contrastive_loss=0, total=4058.32, n_correct=3557.2, ppl=2.11, accuracy=87.652, wps=11105.7, ups=2.74, wpb=4058.3, bsz=148.6, num_updates=49300, lr=6.3693e-05, gnorm=1.704, clip=0, loss_scale=16, train_wall=36, gb_free=16.4, wall=25725
2023-07-06 18:07:01 | INFO | train_inner | epoch 034:    780 / 1474 loss=3.336, trans_loss=4.053, nll_loss=1.091, w2v_ctc_loss=1.662, contrastive_loss=0, total=4015.92, n_correct=3512.9, ppl=2.13, accuracy=87.474, wps=10993.8, ups=2.74, wpb=4015.9, bsz=148.7, num_updates=49400, lr=6.36285e-05, gnorm=1.654, clip=0, loss_scale=16, train_wall=36, gb_free=16.2, wall=25762
2023-07-06 18:07:38 | INFO | train_inner | epoch 034:    880 / 1474 loss=3.343, trans_loss=4.058, nll_loss=1.097, w2v_ctc_loss=1.673, contrastive_loss=0, total=4035.89, n_correct=3525.01, ppl=2.14, accuracy=87.342, wps=11033.4, ups=2.73, wpb=4035.9, bsz=147.1, num_updates=49500, lr=6.35642e-05, gnorm=1.722, clip=0, loss_scale=16, train_wall=36, gb_free=15, wall=25798
2023-07-06 18:08:15 | INFO | train_inner | epoch 034:    980 / 1474 loss=3.343, trans_loss=4.061, nll_loss=1.101, w2v_ctc_loss=1.669, contrastive_loss=0, total=4121.23, n_correct=3596.34, ppl=2.15, accuracy=87.264, wps=11241.1, ups=2.73, wpb=4121.2, bsz=156.3, num_updates=49600, lr=6.35001e-05, gnorm=1.62, clip=0, loss_scale=16, train_wall=36, gb_free=14, wall=25835
2023-07-06 18:08:51 | INFO | train_inner | epoch 034:   1080 / 1474 loss=3.346, trans_loss=4.058, nll_loss=1.098, w2v_ctc_loss=1.685, contrastive_loss=0, total=4084.91, n_correct=3567.7, ppl=2.14, accuracy=87.339, wps=11284.8, ups=2.76, wpb=4084.9, bsz=154.5, num_updates=49700, lr=6.34361e-05, gnorm=1.632, clip=0, loss_scale=16, train_wall=36, gb_free=14.7, wall=25871
2023-07-06 18:09:28 | INFO | train_inner | epoch 034:   1180 / 1474 loss=3.345, trans_loss=4.06, nll_loss=1.101, w2v_ctc_loss=1.677, contrastive_loss=0, total=4042.67, n_correct=3530.92, ppl=2.14, accuracy=87.341, wps=10968.5, ups=2.71, wpb=4042.7, bsz=149, num_updates=49800, lr=6.33724e-05, gnorm=1.618, clip=0, loss_scale=16, train_wall=36, gb_free=16.3, wall=25908
2023-07-06 18:10:04 | INFO | train_inner | epoch 034:   1280 / 1474 loss=3.335, trans_loss=4.049, nll_loss=1.086, w2v_ctc_loss=1.668, contrastive_loss=0, total=4084.02, n_correct=3574.21, ppl=2.12, accuracy=87.517, wps=11205, ups=2.74, wpb=4084, bsz=150.3, num_updates=49900, lr=6.33089e-05, gnorm=1.648, clip=0, loss_scale=16, train_wall=36, gb_free=17.4, wall=25945
2023-07-06 18:10:41 | INFO | train_inner | epoch 034:   1380 / 1474 loss=3.341, trans_loss=4.06, nll_loss=1.1, w2v_ctc_loss=1.662, contrastive_loss=0, total=4156.44, n_correct=3631.3, ppl=2.14, accuracy=87.366, wps=11291.5, ups=2.72, wpb=4156.4, bsz=160.6, num_updates=50000, lr=6.32456e-05, gnorm=1.618, clip=0, loss_scale=16, train_wall=36, gb_free=17.3, wall=25981
2023-07-06 18:10:41 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 18:10:58 | INFO | dev_rec_st | epoch 034 | valid on 'dev_rec_st' subset | loss 3.529 | trans_loss 4.014 | nll_loss 0.985 | w2v_ctc_loss 2.396 | contrastive_loss 0 | total 3909.1 | n_correct 3485.3 | ppl 1.98 | accuracy 89.159 | uer 21.129 | wer 23.112 | raw_wer 23.112 | bleu 0.88 | wps 3915 | wpb 3909.1 | bsz 141.8 | num_updates 50000 | best_bleu 0.9
2023-07-06 18:10:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-07-06 18:10:58 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_34_50000.pt
2023-07-06 18:11:01 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_34_50000.pt
2023-07-06 18:11:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 0.88) (writing took 6.820385429993621 seconds)
2023-07-06 18:11:40 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 18:11:57 | INFO | dev_rec_st | epoch 034 | valid on 'dev_rec_st' subset | loss 3.571 | trans_loss 4.03 | nll_loss 1 | w2v_ctc_loss 2.498 | contrastive_loss 0 | total 3909.1 | n_correct 3478.3 | ppl 2 | accuracy 88.98 | uer 21.565 | wer 23.869 | raw_wer 23.869 | bleu 0.88 | wps 3810.2 | wpb 3909.1 | bsz 141.8 | num_updates 50094 | best_bleu 0.9
2023-07-06 18:11:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50094 updates
2023-07-06 18:11:57 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8803.pt
2023-07-06 18:12:02 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8803.pt
2023-07-06 18:12:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8803.pt (epoch 34 @ 50094 updates, score 0.88) (writing took 7.7870032289938536 seconds)
2023-07-06 18:12:05 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-07-06 18:12:05 | INFO | train | epoch 034 | loss 3.338 | trans_loss 4.055 | nll_loss 1.093 | w2v_ctc_loss 1.666 | contrastive_loss 0 | total 4078.54 | n_correct 3566.03 | ppl 2.13 | accuracy 87.434 | wps 10087.6 | ups 2.47 | wpb 4078.5 | bsz 152.8 | num_updates 50094 | lr 6.31862e-05 | gnorm 1.654 | clip 0 | loss_scale 16 | train_wall 533 | gb_free 17.4 | wall 26065
2023-07-06 18:12:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 18:12:05 | INFO | fairseq.trainer | begin training epoch 35
2023-07-06 18:12:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 18:12:14 | INFO | train_inner | epoch 035:      6 / 1474 loss=3.339, trans_loss=4.064, nll_loss=1.105, w2v_ctc_loss=1.648, contrastive_loss=0, total=4146.69, n_correct=3618.89, ppl=2.15, accuracy=87.272, wps=4438.8, ups=1.07, wpb=4146.7, bsz=163.2, num_updates=50100, lr=6.31824e-05, gnorm=1.638, clip=0, loss_scale=32, train_wall=36, gb_free=17.9, wall=26075
2023-07-06 18:12:51 | INFO | train_inner | epoch 035:    106 / 1474 loss=3.321, trans_loss=4.042, nll_loss=1.077, w2v_ctc_loss=1.64, contrastive_loss=0, total=4108.69, n_correct=3602.82, ppl=2.11, accuracy=87.688, wps=11230.5, ups=2.73, wpb=4108.7, bsz=155.8, num_updates=50200, lr=6.31194e-05, gnorm=1.627, clip=0, loss_scale=32, train_wall=36, gb_free=15.9, wall=26111
2023-07-06 18:13:28 | INFO | train_inner | epoch 035:    206 / 1474 loss=3.312, trans_loss=4.028, nll_loss=1.061, w2v_ctc_loss=1.64, contrastive_loss=0, total=4121.84, n_correct=3623.86, ppl=2.09, accuracy=87.919, wps=11293, ups=2.74, wpb=4121.8, bsz=158, num_updates=50300, lr=6.30567e-05, gnorm=1.657, clip=0, loss_scale=32, train_wall=36, gb_free=13.8, wall=26148
2023-07-06 18:14:04 | INFO | train_inner | epoch 035:    306 / 1474 loss=3.334, trans_loss=4.055, nll_loss=1.094, w2v_ctc_loss=1.652, contrastive_loss=0, total=4073.6, n_correct=3561.17, ppl=2.14, accuracy=87.421, wps=11035.1, ups=2.71, wpb=4073.6, bsz=150.8, num_updates=50400, lr=6.29941e-05, gnorm=1.656, clip=0, loss_scale=32, train_wall=37, gb_free=12.7, wall=26185
2023-07-06 18:14:41 | INFO | train_inner | epoch 035:    406 / 1474 loss=3.345, trans_loss=4.051, nll_loss=1.088, w2v_ctc_loss=1.698, contrastive_loss=0, total=4012.1, n_correct=3507.81, ppl=2.13, accuracy=87.431, wps=11008.1, ups=2.74, wpb=4012.1, bsz=141.8, num_updates=50500, lr=6.29317e-05, gnorm=1.698, clip=0, loss_scale=32, train_wall=36, gb_free=16.9, wall=26221
2023-07-06 18:15:18 | INFO | train_inner | epoch 035:    506 / 1474 loss=3.331, trans_loss=4.048, nll_loss=1.085, w2v_ctc_loss=1.657, contrastive_loss=0, total=4086.98, n_correct=3576.9, ppl=2.12, accuracy=87.519, wps=11154.1, ups=2.73, wpb=4087, bsz=152.5, num_updates=50600, lr=6.28695e-05, gnorm=1.654, clip=0, loss_scale=32, train_wall=36, gb_free=16.4, wall=26258
2023-07-06 18:15:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-06 18:15:54 | INFO | train_inner | epoch 035:    607 / 1474 loss=3.32, trans_loss=4.046, nll_loss=1.083, w2v_ctc_loss=1.627, contrastive_loss=0, total=4105.83, n_correct=3596.26, ppl=2.12, accuracy=87.589, wps=11229.1, ups=2.73, wpb=4105.8, bsz=155.6, num_updates=50700, lr=6.28074e-05, gnorm=1.619, clip=0, loss_scale=16, train_wall=36, gb_free=16.7, wall=26294
2023-07-06 18:16:30 | INFO | train_inner | epoch 035:    707 / 1474 loss=3.346, trans_loss=4.054, nll_loss=1.092, w2v_ctc_loss=1.695, contrastive_loss=0, total=4011.94, n_correct=3509.41, ppl=2.13, accuracy=87.474, wps=11038.2, ups=2.75, wpb=4011.9, bsz=147, num_updates=50800, lr=6.27456e-05, gnorm=1.708, clip=0, loss_scale=16, train_wall=36, gb_free=16.5, wall=26331
2023-07-06 18:17:07 | INFO | train_inner | epoch 035:    807 / 1474 loss=3.324, trans_loss=4.045, nll_loss=1.081, w2v_ctc_loss=1.642, contrastive_loss=0, total=4097.19, n_correct=3590.88, ppl=2.12, accuracy=87.643, wps=11140.1, ups=2.72, wpb=4097.2, bsz=155.4, num_updates=50900, lr=6.26839e-05, gnorm=1.571, clip=0, loss_scale=16, train_wall=36, gb_free=16.5, wall=26368
2023-07-06 18:17:44 | INFO | train_inner | epoch 035:    907 / 1474 loss=3.338, trans_loss=4.048, nll_loss=1.084, w2v_ctc_loss=1.684, contrastive_loss=0, total=4028.76, n_correct=3526.21, ppl=2.12, accuracy=87.526, wps=11001.7, ups=2.73, wpb=4028.8, bsz=146.2, num_updates=51000, lr=6.26224e-05, gnorm=1.652, clip=0, loss_scale=16, train_wall=36, gb_free=17, wall=26404
2023-07-06 18:18:21 | INFO | train_inner | epoch 035:   1007 / 1474 loss=3.345, trans_loss=4.06, nll_loss=1.101, w2v_ctc_loss=1.676, contrastive_loss=0, total=4079.39, n_correct=3563.07, ppl=2.15, accuracy=87.343, wps=10970, ups=2.69, wpb=4079.4, bsz=153.2, num_updates=51100, lr=6.25611e-05, gnorm=1.63, clip=0, loss_scale=16, train_wall=37, gb_free=17.6, wall=26441
2023-07-06 18:18:57 | INFO | train_inner | epoch 035:   1107 / 1474 loss=3.32, trans_loss=4.039, nll_loss=1.074, w2v_ctc_loss=1.643, contrastive_loss=0, total=4125.54, n_correct=3620.41, ppl=2.11, accuracy=87.756, wps=11356.5, ups=2.75, wpb=4125.5, bsz=156.2, num_updates=51200, lr=6.25e-05, gnorm=1.6, clip=0, loss_scale=16, train_wall=36, gb_free=17.2, wall=26478
2023-07-06 18:19:34 | INFO | train_inner | epoch 035:   1207 / 1474 loss=3.318, trans_loss=4.045, nll_loss=1.082, w2v_ctc_loss=1.622, contrastive_loss=0, total=4148.46, n_correct=3634.7, ppl=2.12, accuracy=87.616, wps=11422.3, ups=2.75, wpb=4148.5, bsz=161.4, num_updates=51300, lr=6.24391e-05, gnorm=1.576, clip=0, loss_scale=16, train_wall=36, gb_free=17.1, wall=26514
2023-07-06 18:20:10 | INFO | train_inner | epoch 035:   1307 / 1474 loss=3.324, trans_loss=4.043, nll_loss=1.08, w2v_ctc_loss=1.645, contrastive_loss=0, total=4077.05, n_correct=3572.91, ppl=2.11, accuracy=87.635, wps=11265.1, ups=2.76, wpb=4077.1, bsz=155.8, num_updates=51400, lr=6.23783e-05, gnorm=1.708, clip=0, loss_scale=16, train_wall=36, gb_free=15.3, wall=26550
2023-07-06 18:20:46 | INFO | train_inner | epoch 035:   1407 / 1474 loss=3.337, trans_loss=4.048, nll_loss=1.085, w2v_ctc_loss=1.678, contrastive_loss=0, total=4003.56, n_correct=3504.53, ppl=2.12, accuracy=87.535, wps=11039.3, ups=2.76, wpb=4003.6, bsz=144.4, num_updates=51500, lr=6.23177e-05, gnorm=1.663, clip=0, loss_scale=16, train_wall=36, gb_free=16.9, wall=26586
2023-07-06 18:21:11 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 18:21:28 | INFO | dev_rec_st | epoch 035 | valid on 'dev_rec_st' subset | loss 3.526 | trans_loss 4.009 | nll_loss 0.979 | w2v_ctc_loss 2.398 | contrastive_loss 0 | total 3909.1 | n_correct 3492.7 | ppl 1.97 | accuracy 89.348 | uer 20.896 | wer 22.591 | raw_wer 22.591 | bleu 0.9 | wps 3768.6 | wpb 3909.1 | bsz 141.8 | num_updates 51567 | best_bleu 0.9
2023-07-06 18:21:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 51567 updates
2023-07-06 18:21:28 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 18:21:33 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 18:21:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt (epoch 35 @ 51567 updates, score 0.9) (writing took 9.014283041004092 seconds)
2023-07-06 18:21:37 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-07-06 18:21:37 | INFO | train | epoch 035 | loss 3.329 | trans_loss 4.046 | nll_loss 1.083 | w2v_ctc_loss 1.656 | contrastive_loss 0 | total 4078.48 | n_correct 3571.92 | ppl 2.12 | accuracy 87.58 | wps 10495.3 | ups 2.57 | wpb 4078.5 | bsz 152.9 | num_updates 51567 | lr 6.22772e-05 | gnorm 1.643 | clip 0 | loss_scale 16 | train_wall 532 | gb_free 17.3 | wall 26638
2023-07-06 18:21:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 18:21:38 | INFO | fairseq.trainer | begin training epoch 36
2023-07-06 18:21:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 18:21:56 | INFO | train_inner | epoch 036:     33 / 1474 loss=3.328, trans_loss=4.044, nll_loss=1.08, w2v_ctc_loss=1.657, contrastive_loss=0, total=4046.88, n_correct=3544.78, ppl=2.11, accuracy=87.593, wps=5755.8, ups=1.42, wpb=4046.9, bsz=152.8, num_updates=51600, lr=6.22573e-05, gnorm=1.628, clip=0, loss_scale=16, train_wall=36, gb_free=17.1, wall=26657
2023-07-06 18:22:33 | INFO | train_inner | epoch 036:    133 / 1474 loss=3.315, trans_loss=4.031, nll_loss=1.064, w2v_ctc_loss=1.645, contrastive_loss=0, total=4035.08, n_correct=3545.77, ppl=2.09, accuracy=87.874, wps=11063.2, ups=2.74, wpb=4035.1, bsz=149.6, num_updates=51700, lr=6.2197e-05, gnorm=1.768, clip=0, loss_scale=16, train_wall=36, gb_free=12.5, wall=26693
2023-07-06 18:23:10 | INFO | train_inner | epoch 036:    233 / 1474 loss=3.313, trans_loss=4.027, nll_loss=1.059, w2v_ctc_loss=1.647, contrastive_loss=0, total=4084.49, n_correct=3592.29, ppl=2.08, accuracy=87.95, wps=11109.5, ups=2.72, wpb=4084.5, bsz=152.7, num_updates=51800, lr=6.2137e-05, gnorm=1.72, clip=0, loss_scale=16, train_wall=36, gb_free=12.1, wall=26730
2023-07-06 18:23:46 | INFO | train_inner | epoch 036:    333 / 1474 loss=3.287, trans_loss=4.013, nll_loss=1.042, w2v_ctc_loss=1.592, contrastive_loss=0, total=4092.4, n_correct=3609.92, ppl=2.06, accuracy=88.21, wps=11360.2, ups=2.78, wpb=4092.4, bsz=154, num_updates=51900, lr=6.20771e-05, gnorm=1.59, clip=0, loss_scale=16, train_wall=36, gb_free=17.9, wall=26766
2023-07-06 18:24:22 | INFO | train_inner | epoch 036:    433 / 1474 loss=3.299, trans_loss=4.034, nll_loss=1.069, w2v_ctc_loss=1.585, contrastive_loss=0, total=4170.92, n_correct=3662.87, ppl=2.1, accuracy=87.819, wps=11518.1, ups=2.76, wpb=4170.9, bsz=166.6, num_updates=52000, lr=6.20174e-05, gnorm=1.603, clip=0, loss_scale=16, train_wall=36, gb_free=16, wall=26802
2023-07-06 18:24:22 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 18:24:39 | INFO | dev_rec_st | epoch 036 | valid on 'dev_rec_st' subset | loss 3.457 | trans_loss 4.005 | nll_loss 0.969 | w2v_ctc_loss 2.176 | contrastive_loss 0 | total 3909.1 | n_correct 3492.4 | ppl 1.96 | accuracy 89.34 | uer 20.843 | wer 23.004 | raw_wer 23.004 | bleu 0.89 | wps 3836.8 | wpb 3909.1 | bsz 141.8 | num_updates 52000 | best_bleu 0.9
2023-07-06 18:24:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 52000 updates
2023-07-06 18:24:39 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_36_52000.pt
2023-07-06 18:24:42 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_36_52000.pt
2023-07-06 18:24:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_36_52000.pt (epoch 36 @ 52000 updates, score 0.89) (writing took 7.232689404001576 seconds)
2023-07-06 18:25:24 | INFO | train_inner | epoch 036:    533 / 1474 loss=3.33, trans_loss=4.052, nll_loss=1.092, w2v_ctc_loss=1.645, contrastive_loss=0, total=4091.97, n_correct=3580.72, ppl=2.13, accuracy=87.506, wps=6607.9, ups=1.61, wpb=4092, bsz=156.9, num_updates=52100, lr=6.19578e-05, gnorm=1.678, clip=0, loss_scale=16, train_wall=36, gb_free=15.5, wall=26864
2023-07-06 18:26:00 | INFO | train_inner | epoch 036:    633 / 1474 loss=3.322, trans_loss=4.043, nll_loss=1.08, w2v_ctc_loss=1.641, contrastive_loss=0, total=4117.89, n_correct=3608.12, ppl=2.11, accuracy=87.621, wps=11291.1, ups=2.74, wpb=4117.9, bsz=158.3, num_updates=52200, lr=6.18984e-05, gnorm=1.651, clip=0, loss_scale=16, train_wall=36, gb_free=16.1, wall=26901
2023-07-06 18:26:37 | INFO | train_inner | epoch 036:    733 / 1474 loss=3.329, trans_loss=4.044, nll_loss=1.081, w2v_ctc_loss=1.661, contrastive_loss=0, total=4119.98, n_correct=3611.2, ppl=2.12, accuracy=87.651, wps=11274, ups=2.74, wpb=4120, bsz=157.6, num_updates=52300, lr=6.18392e-05, gnorm=1.628, clip=0, loss_scale=16, train_wall=36, gb_free=16.7, wall=26937
2023-07-06 18:27:14 | INFO | train_inner | epoch 036:    833 / 1474 loss=3.336, trans_loss=4.063, nll_loss=1.106, w2v_ctc_loss=1.639, contrastive_loss=0, total=4115.33, n_correct=3593.79, ppl=2.15, accuracy=87.327, wps=11159.5, ups=2.71, wpb=4115.3, bsz=161.7, num_updates=52400, lr=6.17802e-05, gnorm=1.601, clip=0, loss_scale=16, train_wall=36, gb_free=15.1, wall=26974
2023-07-06 18:27:51 | INFO | train_inner | epoch 036:    933 / 1474 loss=3.32, trans_loss=4.035, nll_loss=1.069, w2v_ctc_loss=1.651, contrastive_loss=0, total=4108.03, n_correct=3606.32, ppl=2.1, accuracy=87.787, wps=11010.9, ups=2.68, wpb=4108, bsz=151.4, num_updates=52500, lr=6.17213e-05, gnorm=1.589, clip=0, loss_scale=16, train_wall=37, gb_free=17.2, wall=27011
2023-07-06 18:28:28 | INFO | train_inner | epoch 036:   1033 / 1474 loss=3.318, trans_loss=4.033, nll_loss=1.068, w2v_ctc_loss=1.651, contrastive_loss=0, total=4134.17, n_correct=3630.69, ppl=2.1, accuracy=87.821, wps=11344.3, ups=2.74, wpb=4134.2, bsz=151.7, num_updates=52600, lr=6.16626e-05, gnorm=1.645, clip=0, loss_scale=16, train_wall=36, gb_free=12.8, wall=27048
2023-07-06 18:29:04 | INFO | train_inner | epoch 036:   1133 / 1474 loss=3.324, trans_loss=4.039, nll_loss=1.075, w2v_ctc_loss=1.654, contrastive_loss=0, total=4070.48, n_correct=3567.84, ppl=2.11, accuracy=87.652, wps=11200.8, ups=2.75, wpb=4070.5, bsz=152.4, num_updates=52700, lr=6.16041e-05, gnorm=1.604, clip=0, loss_scale=32, train_wall=36, gb_free=16.8, wall=27084
2023-07-06 18:29:40 | INFO | train_inner | epoch 036:   1233 / 1474 loss=3.327, trans_loss=4.042, nll_loss=1.078, w2v_ctc_loss=1.657, contrastive_loss=0, total=4000.41, n_correct=3503.25, ppl=2.11, accuracy=87.572, wps=10977.9, ups=2.74, wpb=4000.4, bsz=140, num_updates=52800, lr=6.15457e-05, gnorm=1.637, clip=0, loss_scale=32, train_wall=36, gb_free=16.8, wall=27121
2023-07-06 18:30:16 | INFO | train_inner | epoch 036:   1333 / 1474 loss=3.319, trans_loss=4.036, nll_loss=1.071, w2v_ctc_loss=1.645, contrastive_loss=0, total=4052.13, n_correct=3554.96, ppl=2.1, accuracy=87.731, wps=11244.1, ups=2.77, wpb=4052.1, bsz=153.2, num_updates=52900, lr=6.14875e-05, gnorm=1.635, clip=0, loss_scale=32, train_wall=36, gb_free=16.5, wall=27157
2023-07-06 18:30:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-06 18:30:53 | INFO | train_inner | epoch 036:   1434 / 1474 loss=3.342, trans_loss=4.058, nll_loss=1.099, w2v_ctc_loss=1.67, contrastive_loss=0, total=3998.2, n_correct=3490.88, ppl=2.14, accuracy=87.311, wps=10855.2, ups=2.72, wpb=3998.2, bsz=139.1, num_updates=53000, lr=6.14295e-05, gnorm=1.653, clip=0, loss_scale=16, train_wall=36, gb_free=17.9, wall=27194
2023-07-06 18:31:07 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 18:31:25 | INFO | dev_rec_st | epoch 036 | valid on 'dev_rec_st' subset | loss 3.57 | trans_loss 4.032 | nll_loss 1.004 | w2v_ctc_loss 2.494 | contrastive_loss 0 | total 3909.1 | n_correct 3482 | ppl 2.01 | accuracy 89.074 | uer 21.148 | wer 23.452 | raw_wer 23.452 | bleu 0.88 | wps 3807.1 | wpb 3909.1 | bsz 141.8 | num_updates 53040 | best_bleu 0.9
2023-07-06 18:31:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 53040 updates
2023-07-06 18:31:25 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8803.pt
2023-07-06 18:31:30 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8803.pt
2023-07-06 18:31:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.8803.pt (epoch 36 @ 53040 updates, score 0.88) (writing took 8.029133642994566 seconds)
2023-07-06 18:31:33 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-07-06 18:31:33 | INFO | train | epoch 036 | loss 3.319 | trans_loss 4.039 | nll_loss 1.074 | w2v_ctc_loss 1.641 | contrastive_loss 0 | total 4078.82 | n_correct 3577.78 | ppl 2.11 | accuracy 87.716 | wps 10083.9 | ups 2.47 | wpb 4078.8 | bsz 152.9 | num_updates 53040 | lr 6.14063e-05 | gnorm 1.643 | clip 0 | loss_scale 16 | train_wall 532 | gb_free 17 | wall 27234
2023-07-06 18:31:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 18:31:33 | INFO | fairseq.trainer | begin training epoch 37
2023-07-06 18:31:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 18:32:02 | INFO | train_inner | epoch 037:     60 / 1474 loss=3.301, trans_loss=4.021, nll_loss=1.052, w2v_ctc_loss=1.621, contrastive_loss=0, total=4036.08, n_correct=3552.93, ppl=2.07, accuracy=88.029, wps=5828.2, ups=1.44, wpb=4036.1, bsz=149.9, num_updates=53100, lr=6.13716e-05, gnorm=1.698, clip=0, loss_scale=16, train_wall=36, gb_free=10.6, wall=27263
2023-07-06 18:32:39 | INFO | train_inner | epoch 037:    160 / 1474 loss=3.312, trans_loss=4.03, nll_loss=1.063, w2v_ctc_loss=1.636, contrastive_loss=0, total=4066.17, n_correct=3573.95, ppl=2.09, accuracy=87.895, wps=11117.2, ups=2.73, wpb=4066.2, bsz=153.3, num_updates=53200, lr=6.13139e-05, gnorm=1.781, clip=0, loss_scale=16, train_wall=36, gb_free=13.4, wall=27299
2023-07-06 18:33:16 | INFO | train_inner | epoch 037:    260 / 1474 loss=3.285, trans_loss=4.011, nll_loss=1.04, w2v_ctc_loss=1.59, contrastive_loss=0, total=4139.62, n_correct=3651.29, ppl=2.06, accuracy=88.204, wps=11312.6, ups=2.73, wpb=4139.6, bsz=161.6, num_updates=53300, lr=6.12564e-05, gnorm=1.551, clip=0, loss_scale=16, train_wall=36, gb_free=16.6, wall=27336
2023-07-06 18:33:52 | INFO | train_inner | epoch 037:    360 / 1474 loss=3.32, trans_loss=4.031, nll_loss=1.065, w2v_ctc_loss=1.66, contrastive_loss=0, total=4096.82, n_correct=3600.43, ppl=2.09, accuracy=87.884, wps=11246.5, ups=2.75, wpb=4096.8, bsz=153.3, num_updates=53400, lr=6.1199e-05, gnorm=1.692, clip=0, loss_scale=16, train_wall=36, gb_free=16.7, wall=27372
2023-07-06 18:34:29 | INFO | train_inner | epoch 037:    460 / 1474 loss=3.325, trans_loss=4.05, nll_loss=1.088, w2v_ctc_loss=1.634, contrastive_loss=0, total=4100.72, n_correct=3587.32, ppl=2.13, accuracy=87.48, wps=11152.4, ups=2.72, wpb=4100.7, bsz=157.1, num_updates=53500, lr=6.11418e-05, gnorm=1.677, clip=0, loss_scale=16, train_wall=36, gb_free=16.6, wall=27409
2023-07-06 18:35:05 | INFO | train_inner | epoch 037:    560 / 1474 loss=3.316, trans_loss=4.032, nll_loss=1.065, w2v_ctc_loss=1.645, contrastive_loss=0, total=4044.18, n_correct=3553.25, ppl=2.09, accuracy=87.861, wps=11086.4, ups=2.74, wpb=4044.2, bsz=150.3, num_updates=53600, lr=6.10847e-05, gnorm=1.673, clip=0, loss_scale=16, train_wall=36, gb_free=16.5, wall=27446
2023-07-06 18:35:42 | INFO | train_inner | epoch 037:    660 / 1474 loss=3.318, trans_loss=4.036, nll_loss=1.071, w2v_ctc_loss=1.644, contrastive_loss=0, total=4047.47, n_correct=3550.38, ppl=2.1, accuracy=87.719, wps=11105.1, ups=2.74, wpb=4047.5, bsz=145.5, num_updates=53700, lr=6.10278e-05, gnorm=1.662, clip=0, loss_scale=16, train_wall=36, gb_free=16.7, wall=27482
2023-07-06 18:36:18 | INFO | train_inner | epoch 037:    760 / 1474 loss=3.308, trans_loss=4.028, nll_loss=1.061, w2v_ctc_loss=1.627, contrastive_loss=0, total=4068.82, n_correct=3576.39, ppl=2.09, accuracy=87.897, wps=11219.4, ups=2.76, wpb=4068.8, bsz=153.2, num_updates=53800, lr=6.09711e-05, gnorm=1.623, clip=0, loss_scale=16, train_wall=36, gb_free=16.3, wall=27518
2023-07-06 18:36:54 | INFO | train_inner | epoch 037:    860 / 1474 loss=3.296, trans_loss=4.019, nll_loss=1.05, w2v_ctc_loss=1.608, contrastive_loss=0, total=4096.2, n_correct=3607.07, ppl=2.07, accuracy=88.059, wps=11287.3, ups=2.76, wpb=4096.2, bsz=157.6, num_updates=53900, lr=6.09145e-05, gnorm=1.64, clip=0, loss_scale=16, train_wall=36, gb_free=16.6, wall=27555
2023-07-06 18:37:31 | INFO | train_inner | epoch 037:    960 / 1474 loss=3.334, trans_loss=4.044, nll_loss=1.08, w2v_ctc_loss=1.679, contrastive_loss=0, total=4039.7, n_correct=3536.41, ppl=2.11, accuracy=87.541, wps=10930.7, ups=2.71, wpb=4039.7, bsz=145.9, num_updates=54000, lr=6.08581e-05, gnorm=1.755, clip=0, loss_scale=16, train_wall=37, gb_free=16.4, wall=27592
2023-07-06 18:37:31 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 18:37:50 | INFO | dev_rec_st | epoch 037 | valid on 'dev_rec_st' subset | loss 3.568 | trans_loss 4.023 | nll_loss 1.009 | w2v_ctc_loss 2.508 | contrastive_loss 0 | total 3909.1 | n_correct 3480.8 | ppl 2.01 | accuracy 89.044 | uer 21.18 | wer 22.855 | raw_wer 22.855 | bleu 0.9 | wps 3469.1 | wpb 3909.1 | bsz 141.8 | num_updates 54000 | best_bleu 0.9
2023-07-06 18:37:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54000 updates
2023-07-06 18:37:50 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_37_54000.pt
2023-07-06 18:37:52 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_37_54000.pt
2023-07-06 18:38:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_37_54000.pt (epoch 37 @ 54000 updates, score 0.9) (writing took 10.114427085994976 seconds)
2023-07-06 18:38:36 | INFO | train_inner | epoch 037:   1060 / 1474 loss=3.311, trans_loss=4.035, nll_loss=1.07, w2v_ctc_loss=1.621, contrastive_loss=0, total=4112.41, n_correct=3611.04, ppl=2.1, accuracy=87.808, wps=6313.8, ups=1.54, wpb=4112.4, bsz=160.4, num_updates=54100, lr=6.08018e-05, gnorm=1.682, clip=0, loss_scale=16, train_wall=36, gb_free=15.6, wall=27657
2023-07-06 18:39:13 | INFO | train_inner | epoch 037:   1160 / 1474 loss=3.32, trans_loss=4.039, nll_loss=1.075, w2v_ctc_loss=1.642, contrastive_loss=0, total=4109.76, n_correct=3602.17, ppl=2.11, accuracy=87.649, wps=11250.5, ups=2.74, wpb=4109.8, bsz=155.8, num_updates=54200, lr=6.07457e-05, gnorm=1.645, clip=0, loss_scale=16, train_wall=36, gb_free=16.8, wall=27693
2023-07-06 18:39:49 | INFO | train_inner | epoch 037:   1260 / 1474 loss=3.305, trans_loss=4.028, nll_loss=1.062, w2v_ctc_loss=1.619, contrastive_loss=0, total=4112.51, n_correct=3614.66, ppl=2.09, accuracy=87.894, wps=11266.4, ups=2.74, wpb=4112.5, bsz=156.9, num_updates=54300, lr=6.06897e-05, gnorm=1.642, clip=0, loss_scale=16, train_wall=36, gb_free=15.4, wall=27730
2023-07-06 18:40:26 | INFO | train_inner | epoch 037:   1360 / 1474 loss=3.328, trans_loss=4.04, nll_loss=1.076, w2v_ctc_loss=1.668, contrastive_loss=0, total=4013, n_correct=3516.28, ppl=2.11, accuracy=87.622, wps=10980.2, ups=2.74, wpb=4013, bsz=142.3, num_updates=54400, lr=6.06339e-05, gnorm=1.786, clip=0, loss_scale=16, train_wall=36, gb_free=13.8, wall=27766
2023-07-06 18:41:02 | INFO | train_inner | epoch 037:   1460 / 1474 loss=3.313, trans_loss=4.035, nll_loss=1.07, w2v_ctc_loss=1.629, contrastive_loss=0, total=4097.97, n_correct=3598.38, ppl=2.1, accuracy=87.809, wps=11297.1, ups=2.76, wpb=4098, bsz=152, num_updates=54500, lr=6.05783e-05, gnorm=1.657, clip=0, loss_scale=16, train_wall=36, gb_free=16.1, wall=27803
2023-07-06 18:41:07 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 18:41:25 | INFO | dev_rec_st | epoch 037 | valid on 'dev_rec_st' subset | loss 3.597 | trans_loss 4.04 | nll_loss 1.025 | w2v_ctc_loss 2.564 | contrastive_loss 0 | total 3909.1 | n_correct 3473.2 | ppl 2.03 | accuracy 88.849 | uer 21.724 | wer 23.91 | raw_wer 23.91 | bleu 0.86 | wps 3655.9 | wpb 3909.1 | bsz 141.8 | num_updates 54514 | best_bleu 0.9
2023-07-06 18:41:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54514 updates
2023-07-06 18:41:25 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_last.pt
2023-07-06 18:41:30 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_last.pt
2023-07-06 18:41:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_last.pt (epoch 37 @ 54514 updates, score 0.86) (writing took 4.72175074799452 seconds)
2023-07-06 18:41:30 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-07-06 18:41:30 | INFO | train | epoch 037 | loss 3.314 | trans_loss 4.032 | nll_loss 1.067 | w2v_ctc_loss 1.636 | contrastive_loss 0 | total 4078.54 | n_correct 3581.43 | ppl 2.09 | accuracy 87.812 | wps 10073.5 | ups 2.47 | wpb 4078.5 | bsz 152.8 | num_updates 54514 | lr 6.05705e-05 | gnorm 1.679 | clip 0 | loss_scale 16 | train_wall 532 | gb_free 13.2 | wall 27830
2023-07-06 18:41:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 18:41:30 | INFO | fairseq.trainer | begin training epoch 38
2023-07-06 18:41:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 18:42:09 | INFO | train_inner | epoch 038:     86 / 1474 loss=3.309, trans_loss=4.02, nll_loss=1.051, w2v_ctc_loss=1.649, contrastive_loss=0, total=4022.9, n_correct=3542.55, ppl=2.07, accuracy=88.06, wps=6017.9, ups=1.5, wpb=4022.9, bsz=148.2, num_updates=54600, lr=6.05228e-05, gnorm=1.662, clip=0, loss_scale=16, train_wall=36, gb_free=13.3, wall=27869
2023-07-06 18:42:46 | INFO | train_inner | epoch 038:    186 / 1474 loss=3.298, trans_loss=4.016, nll_loss=1.045, w2v_ctc_loss=1.622, contrastive_loss=0, total=4022.11, n_correct=3542.76, ppl=2.06, accuracy=88.082, wps=11062.6, ups=2.75, wpb=4022.1, bsz=145.1, num_updates=54700, lr=6.04674e-05, gnorm=1.686, clip=0, loss_scale=16, train_wall=36, gb_free=17, wall=27906
2023-07-06 18:43:22 | INFO | train_inner | epoch 038:    286 / 1474 loss=3.303, trans_loss=4.02, nll_loss=1.051, w2v_ctc_loss=1.632, contrastive_loss=0, total=4016.52, n_correct=3537.91, ppl=2.07, accuracy=88.084, wps=11055.5, ups=2.75, wpb=4016.5, bsz=148, num_updates=54800, lr=6.04122e-05, gnorm=1.71, clip=0, loss_scale=16, train_wall=36, gb_free=16.8, wall=27942
2023-07-06 18:43:58 | INFO | train_inner | epoch 038:    386 / 1474 loss=3.298, trans_loss=4.02, nll_loss=1.051, w2v_ctc_loss=1.615, contrastive_loss=0, total=4105.29, n_correct=3616.76, ppl=2.07, accuracy=88.1, wps=11228.8, ups=2.74, wpb=4105.3, bsz=153.6, num_updates=54900, lr=6.03572e-05, gnorm=1.681, clip=0, loss_scale=16, train_wall=36, gb_free=13.2, wall=27979
2023-07-06 18:44:35 | INFO | train_inner | epoch 038:    486 / 1474 loss=3.294, trans_loss=4.015, nll_loss=1.045, w2v_ctc_loss=1.613, contrastive_loss=0, total=4126.77, n_correct=3637.69, ppl=2.06, accuracy=88.149, wps=11394.1, ups=2.76, wpb=4126.8, bsz=156.5, num_updates=55000, lr=6.03023e-05, gnorm=1.713, clip=0, loss_scale=32, train_wall=36, gb_free=16.5, wall=28015
2023-07-06 18:45:12 | INFO | train_inner | epoch 038:    586 / 1474 loss=3.311, trans_loss=4.036, nll_loss=1.072, w2v_ctc_loss=1.618, contrastive_loss=0, total=4108.43, n_correct=3603.56, ppl=2.1, accuracy=87.711, wps=11119.3, ups=2.71, wpb=4108.4, bsz=154.2, num_updates=55100, lr=6.02475e-05, gnorm=1.677, clip=0, loss_scale=32, train_wall=36, gb_free=15.1, wall=28052
2023-07-06 18:45:48 | INFO | train_inner | epoch 038:    686 / 1474 loss=3.297, trans_loss=4.025, nll_loss=1.059, w2v_ctc_loss=1.596, contrastive_loss=0, total=4119.14, n_correct=3623.23, ppl=2.08, accuracy=87.961, wps=11260.4, ups=2.73, wpb=4119.1, bsz=161.7, num_updates=55200, lr=6.01929e-05, gnorm=1.659, clip=0, loss_scale=32, train_wall=36, gb_free=17.1, wall=28088
2023-07-06 18:46:25 | INFO | train_inner | epoch 038:    786 / 1474 loss=3.288, trans_loss=4.018, nll_loss=1.049, w2v_ctc_loss=1.585, contrastive_loss=0, total=4120.48, n_correct=3630.12, ppl=2.07, accuracy=88.099, wps=11274.1, ups=2.74, wpb=4120.5, bsz=162.6, num_updates=55300, lr=6.01385e-05, gnorm=1.642, clip=0, loss_scale=32, train_wall=36, gb_free=17, wall=28125
2023-07-06 18:47:01 | INFO | train_inner | epoch 038:    886 / 1474 loss=3.293, trans_loss=4.015, nll_loss=1.046, w2v_ctc_loss=1.608, contrastive_loss=0, total=4086.46, n_correct=3601.38, ppl=2.06, accuracy=88.13, wps=11167.3, ups=2.73, wpb=4086.5, bsz=155.8, num_updates=55400, lr=6.00842e-05, gnorm=1.643, clip=0, loss_scale=32, train_wall=36, gb_free=13.6, wall=28162
2023-07-06 18:47:38 | INFO | train_inner | epoch 038:    986 / 1474 loss=3.309, trans_loss=4.028, nll_loss=1.062, w2v_ctc_loss=1.633, contrastive_loss=0, total=4054.83, n_correct=3564.58, ppl=2.09, accuracy=87.909, wps=11129.7, ups=2.74, wpb=4054.8, bsz=150.3, num_updates=55500, lr=6.003e-05, gnorm=1.641, clip=0, loss_scale=32, train_wall=36, gb_free=16.9, wall=28198
2023-07-06 18:48:14 | INFO | train_inner | epoch 038:   1086 / 1474 loss=3.303, trans_loss=4.027, nll_loss=1.061, w2v_ctc_loss=1.613, contrastive_loss=0, total=4183.46, n_correct=3677.14, ppl=2.09, accuracy=87.897, wps=11430.6, ups=2.73, wpb=4183.5, bsz=164.7, num_updates=55600, lr=5.9976e-05, gnorm=1.607, clip=0, loss_scale=32, train_wall=36, gb_free=15.8, wall=28235
2023-07-06 18:48:51 | INFO | train_inner | epoch 038:   1186 / 1474 loss=3.322, trans_loss=4.036, nll_loss=1.071, w2v_ctc_loss=1.656, contrastive_loss=0, total=4032.48, n_correct=3537.2, ppl=2.1, accuracy=87.718, wps=10954.4, ups=2.72, wpb=4032.5, bsz=145.1, num_updates=55700, lr=5.99222e-05, gnorm=1.696, clip=0, loss_scale=32, train_wall=36, gb_free=16.3, wall=28271
2023-07-06 18:49:28 | INFO | train_inner | epoch 038:   1286 / 1474 loss=3.315, trans_loss=4.031, nll_loss=1.066, w2v_ctc_loss=1.645, contrastive_loss=0, total=4066.46, n_correct=3569.86, ppl=2.09, accuracy=87.788, wps=11077.4, ups=2.72, wpb=4066.5, bsz=147.2, num_updates=55800, lr=5.98684e-05, gnorm=1.703, clip=0, loss_scale=32, train_wall=36, gb_free=15.7, wall=28308
2023-07-06 18:50:04 | INFO | train_inner | epoch 038:   1386 / 1474 loss=3.317, trans_loss=4.036, nll_loss=1.072, w2v_ctc_loss=1.639, contrastive_loss=0, total=4085.5, n_correct=3583.79, ppl=2.1, accuracy=87.72, wps=11276.8, ups=2.76, wpb=4085.5, bsz=154.2, num_updates=55900, lr=5.98149e-05, gnorm=1.662, clip=0, loss_scale=32, train_wall=36, gb_free=15.9, wall=28344
2023-07-06 18:50:36 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 18:50:54 | INFO | dev_rec_st | epoch 038 | valid on 'dev_rec_st' subset | loss 3.532 | trans_loss 4.01 | nll_loss 0.985 | w2v_ctc_loss 2.417 | contrastive_loss 0 | total 3909.1 | n_correct 3489.9 | ppl 1.98 | accuracy 89.276 | uer 20.612 | wer 22.673 | raw_wer 22.673 | bleu 0.91 | wps 3915.7 | wpb 3909.1 | bsz 141.8 | num_updates 55988 | best_bleu 0.91
2023-07-06 18:50:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 55988 updates
2023-07-06 18:50:54 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 18:50:58 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt
2023-07-06 18:51:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_best.pt (epoch 38 @ 55988 updates, score 0.91) (writing took 9.185306127998047 seconds)
2023-07-06 18:51:03 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-07-06 18:51:03 | INFO | train | epoch 038 | loss 3.305 | trans_loss 4.025 | nll_loss 1.058 | w2v_ctc_loss 1.624 | contrastive_loss 0 | total 4078.54 | n_correct 3587.09 | ppl 2.08 | accuracy 87.951 | wps 10493.5 | ups 2.57 | wpb 4078.5 | bsz 152.8 | num_updates 55988 | lr 5.97678e-05 | gnorm 1.67 | clip 0 | loss_scale 32 | train_wall 531 | gb_free 16.8 | wall 28403
2023-07-06 18:51:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 18:51:03 | INFO | fairseq.trainer | begin training epoch 39
2023-07-06 18:51:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 18:51:15 | INFO | train_inner | epoch 039:     12 / 1474 loss=3.315, trans_loss=4.032, nll_loss=1.066, w2v_ctc_loss=1.644, contrastive_loss=0, total=3983.05, n_correct=3497.69, ppl=2.09, accuracy=87.814, wps=5598.8, ups=1.41, wpb=3983.1, bsz=143.8, num_updates=56000, lr=5.97614e-05, gnorm=1.667, clip=0, loss_scale=32, train_wall=36, gb_free=16.2, wall=28416
2023-07-06 18:51:15 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 18:51:33 | INFO | dev_rec_st | epoch 039 | valid on 'dev_rec_st' subset | loss 3.483 | trans_loss 4.009 | nll_loss 0.98 | w2v_ctc_loss 2.255 | contrastive_loss 0 | total 3909.1 | n_correct 3491 | ppl 1.97 | accuracy 89.304 | uer 20.858 | wer 22.956 | raw_wer 22.956 | bleu 0.88 | wps 3879 | wpb 3909.1 | bsz 141.8 | num_updates 56000 | best_bleu 0.91
2023-07-06 18:51:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 56000 updates
2023-07-06 18:51:33 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_39_56000.pt
2023-07-06 18:51:35 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_39_56000.pt
2023-07-06 18:51:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_39_56000.pt (epoch 39 @ 56000 updates, score 0.88) (writing took 8.824806770993746 seconds)
2023-07-06 18:52:18 | INFO | train_inner | epoch 039:    112 / 1474 loss=3.292, trans_loss=4.014, nll_loss=1.044, w2v_ctc_loss=1.608, contrastive_loss=0, total=3992.76, n_correct=3520.45, ppl=2.06, accuracy=88.171, wps=6360.7, ups=1.59, wpb=3992.8, bsz=143, num_updates=56100, lr=5.97081e-05, gnorm=1.658, clip=0, loss_scale=32, train_wall=36, gb_free=15.9, wall=28478
2023-07-06 18:52:55 | INFO | train_inner | epoch 039:    212 / 1474 loss=3.296, trans_loss=4.01, nll_loss=1.039, w2v_ctc_loss=1.629, contrastive_loss=0, total=4077.66, n_correct=3598.48, ppl=2.05, accuracy=88.249, wps=11127.8, ups=2.73, wpb=4077.7, bsz=150.3, num_updates=56200, lr=5.9655e-05, gnorm=1.658, clip=0, loss_scale=32, train_wall=36, gb_free=16.6, wall=28515
2023-07-06 18:53:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-06 18:53:31 | INFO | train_inner | epoch 039:    313 / 1474 loss=3.287, trans_loss=4.007, nll_loss=1.035, w2v_ctc_loss=1.607, contrastive_loss=0, total=4087.4, n_correct=3608.11, ppl=2.05, accuracy=88.274, wps=11143.2, ups=2.73, wpb=4087.4, bsz=149.9, num_updates=56300, lr=5.9602e-05, gnorm=1.632, clip=0, loss_scale=16, train_wall=36, gb_free=16.7, wall=28552
2023-07-06 18:54:08 | INFO | train_inner | epoch 039:    413 / 1474 loss=3.293, trans_loss=4.023, nll_loss=1.056, w2v_ctc_loss=1.589, contrastive_loss=0, total=4063.52, n_correct=3577.38, ppl=2.08, accuracy=88.036, wps=11096, ups=2.73, wpb=4063.5, bsz=156.6, num_updates=56400, lr=5.95491e-05, gnorm=1.626, clip=0, loss_scale=16, train_wall=36, gb_free=15.9, wall=28588
2023-07-06 18:54:45 | INFO | train_inner | epoch 039:    513 / 1474 loss=3.297, trans_loss=4.026, nll_loss=1.059, w2v_ctc_loss=1.598, contrastive_loss=0, total=4095.23, n_correct=3600.89, ppl=2.08, accuracy=87.929, wps=11119.7, ups=2.72, wpb=4095.2, bsz=155.5, num_updates=56500, lr=5.94964e-05, gnorm=1.66, clip=0, loss_scale=16, train_wall=36, gb_free=13.4, wall=28625
2023-07-06 18:55:21 | INFO | train_inner | epoch 039:    613 / 1474 loss=3.297, trans_loss=4.02, nll_loss=1.051, w2v_ctc_loss=1.609, contrastive_loss=0, total=4072.27, n_correct=3585.46, ppl=2.07, accuracy=88.046, wps=11155.1, ups=2.74, wpb=4072.3, bsz=153, num_updates=56600, lr=5.94438e-05, gnorm=1.68, clip=0, loss_scale=16, train_wall=36, gb_free=17, wall=28662
2023-07-06 18:55:57 | INFO | train_inner | epoch 039:    713 / 1474 loss=3.291, trans_loss=4.015, nll_loss=1.045, w2v_ctc_loss=1.604, contrastive_loss=0, total=4076.65, n_correct=3592.34, ppl=2.06, accuracy=88.12, wps=11315.2, ups=2.78, wpb=4076.7, bsz=151.8, num_updates=56700, lr=5.93914e-05, gnorm=1.62, clip=0, loss_scale=16, train_wall=36, gb_free=17.3, wall=28698
2023-07-06 18:56:34 | INFO | train_inner | epoch 039:    813 / 1474 loss=3.301, trans_loss=4.021, nll_loss=1.054, w2v_ctc_loss=1.621, contrastive_loss=0, total=4103.7, n_correct=3612.31, ppl=2.08, accuracy=88.026, wps=11084.6, ups=2.7, wpb=4103.7, bsz=153.8, num_updates=56800, lr=5.93391e-05, gnorm=1.627, clip=0, loss_scale=16, train_wall=37, gb_free=17.4, wall=28735
2023-07-06 18:57:11 | INFO | train_inner | epoch 039:    913 / 1474 loss=3.293, trans_loss=4.012, nll_loss=1.042, w2v_ctc_loss=1.616, contrastive_loss=0, total=4068.68, n_correct=3587.29, ppl=2.06, accuracy=88.168, wps=11076.8, ups=2.72, wpb=4068.7, bsz=150.2, num_updates=56900, lr=5.92869e-05, gnorm=1.659, clip=0, loss_scale=16, train_wall=36, gb_free=16.7, wall=28771
2023-07-06 18:57:48 | INFO | train_inner | epoch 039:   1013 / 1474 loss=3.3, trans_loss=4.032, nll_loss=1.068, w2v_ctc_loss=1.592, contrastive_loss=0, total=4132.28, n_correct=3630.16, ppl=2.1, accuracy=87.849, wps=11182.5, ups=2.71, wpb=4132.3, bsz=159.6, num_updates=57000, lr=5.92349e-05, gnorm=1.654, clip=0, loss_scale=16, train_wall=36, gb_free=14.1, wall=28808
2023-07-06 18:58:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-06 18:58:25 | INFO | train_inner | epoch 039:   1114 / 1474 loss=3.294, trans_loss=4.018, nll_loss=1.05, w2v_ctc_loss=1.604, contrastive_loss=0, total=4115.18, n_correct=3624.82, ppl=2.07, accuracy=88.084, wps=11189.4, ups=2.72, wpb=4115.2, bsz=159.9, num_updates=57100, lr=5.9183e-05, gnorm=1.599, clip=0, loss_scale=8, train_wall=36, gb_free=16.2, wall=28845
2023-07-06 18:59:01 | INFO | train_inner | epoch 039:   1214 / 1474 loss=3.297, trans_loss=4.02, nll_loss=1.052, w2v_ctc_loss=1.612, contrastive_loss=0, total=4086.61, n_correct=3597.78, ppl=2.07, accuracy=88.038, wps=11219.1, ups=2.75, wpb=4086.6, bsz=154.3, num_updates=57200, lr=5.91312e-05, gnorm=1.646, clip=0, loss_scale=8, train_wall=36, gb_free=17.1, wall=28882
2023-07-06 18:59:38 | INFO | train_inner | epoch 039:   1314 / 1474 loss=3.294, trans_loss=4.018, nll_loss=1.05, w2v_ctc_loss=1.605, contrastive_loss=0, total=4109.71, n_correct=3621.07, ppl=2.07, accuracy=88.11, wps=11304.3, ups=2.75, wpb=4109.7, bsz=157.4, num_updates=57300, lr=5.90796e-05, gnorm=1.625, clip=0, loss_scale=8, train_wall=36, gb_free=17, wall=28918
2023-07-06 19:00:14 | INFO | train_inner | epoch 039:   1414 / 1474 loss=3.293, trans_loss=4.012, nll_loss=1.041, w2v_ctc_loss=1.616, contrastive_loss=0, total=3997.14, n_correct=3523.19, ppl=2.06, accuracy=88.143, wps=11051.6, ups=2.76, wpb=3997.1, bsz=140.6, num_updates=57400, lr=5.90281e-05, gnorm=1.638, clip=0, loss_scale=8, train_wall=36, gb_free=16.6, wall=28954
2023-07-06 19:00:36 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 19:00:53 | INFO | dev_rec_st | epoch 039 | valid on 'dev_rec_st' subset | loss 3.466 | trans_loss 4.002 | nll_loss 0.968 | w2v_ctc_loss 2.215 | contrastive_loss 0 | total 3909.1 | n_correct 3500.8 | ppl 1.96 | accuracy 89.555 | uer 20.67 | wer 22.948 | raw_wer 22.948 | bleu 0.9 | wps 3912.4 | wpb 3909.1 | bsz 141.8 | num_updates 57460 | best_bleu 0.91
2023-07-06 19:00:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 57460 updates
2023-07-06 19:00:53 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.9000.pt
2023-07-06 19:00:56 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.9000.pt
2023-07-06 19:00:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint.best_bleu_0.9000.pt (epoch 39 @ 57460 updates, score 0.9) (writing took 5.890972111999872 seconds)
2023-07-06 19:00:59 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-07-06 19:00:59 | INFO | train | epoch 039 | loss 3.295 | trans_loss 4.018 | nll_loss 1.049 | w2v_ctc_loss 1.607 | contrastive_loss 0 | total 4078.1 | n_correct 3592.38 | ppl 2.07 | accuracy 88.089 | wps 10065.6 | ups 2.47 | wpb 4078.1 | bsz 152.8 | num_updates 57460 | lr 5.89973e-05 | gnorm 1.642 | clip 0 | loss_scale 8 | train_wall 532 | gb_free 15.6 | wall 29000
2023-07-06 19:01:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 19:01:00 | INFO | fairseq.trainer | begin training epoch 40
2023-07-06 19:01:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 19:01:22 | INFO | train_inner | epoch 040:     40 / 1474 loss=3.284, trans_loss=4.009, nll_loss=1.038, w2v_ctc_loss=1.594, contrastive_loss=0, total=4084.84, n_correct=3602.59, ppl=2.05, accuracy=88.194, wps=5999.5, ups=1.47, wpb=4084.8, bsz=154.6, num_updates=57500, lr=5.89768e-05, gnorm=1.655, clip=0, loss_scale=8, train_wall=36, gb_free=17.6, wall=29022
2023-07-06 19:01:59 | INFO | train_inner | epoch 040:    140 / 1474 loss=3.27, trans_loss=3.996, nll_loss=1.022, w2v_ctc_loss=1.577, contrastive_loss=0, total=4101.84, n_correct=3628.24, ppl=2.03, accuracy=88.454, wps=11200.2, ups=2.73, wpb=4101.8, bsz=154.3, num_updates=57600, lr=5.89256e-05, gnorm=1.651, clip=0, loss_scale=8, train_wall=36, gb_free=14.8, wall=29059
2023-07-06 19:02:35 | INFO | train_inner | epoch 040:    240 / 1474 loss=3.285, trans_loss=4.007, nll_loss=1.036, w2v_ctc_loss=1.599, contrastive_loss=0, total=4039.43, n_correct=3565.63, ppl=2.05, accuracy=88.271, wps=11155.1, ups=2.76, wpb=4039.4, bsz=149, num_updates=57700, lr=5.88745e-05, gnorm=1.725, clip=0, loss_scale=8, train_wall=36, gb_free=16.5, wall=29095
2023-07-06 19:03:11 | INFO | train_inner | epoch 040:    340 / 1474 loss=3.27, trans_loss=3.991, nll_loss=1.016, w2v_ctc_loss=1.586, contrastive_loss=0, total=4115.38, n_correct=3643.18, ppl=2.02, accuracy=88.526, wps=11301.7, ups=2.75, wpb=4115.4, bsz=160.1, num_updates=57800, lr=5.88235e-05, gnorm=1.653, clip=0, loss_scale=8, train_wall=36, gb_free=17, wall=29131
2023-07-06 19:03:48 | INFO | train_inner | epoch 040:    440 / 1474 loss=3.29, trans_loss=4.013, nll_loss=1.044, w2v_ctc_loss=1.6, contrastive_loss=0, total=4077.36, n_correct=3594.96, ppl=2.06, accuracy=88.169, wps=11174.5, ups=2.74, wpb=4077.4, bsz=155, num_updates=57900, lr=5.87727e-05, gnorm=1.674, clip=0, loss_scale=8, train_wall=36, gb_free=16.7, wall=29168
2023-07-06 19:04:24 | INFO | train_inner | epoch 040:    540 / 1474 loss=3.275, trans_loss=4.007, nll_loss=1.036, w2v_ctc_loss=1.567, contrastive_loss=0, total=4110.94, n_correct=3627.04, ppl=2.05, accuracy=88.229, wps=11276, ups=2.74, wpb=4110.9, bsz=157.2, num_updates=58000, lr=5.8722e-05, gnorm=1.651, clip=0, loss_scale=8, train_wall=36, gb_free=16.6, wall=29204
2023-07-06 19:04:24 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 19:04:41 | INFO | dev_rec_st | epoch 040 | valid on 'dev_rec_st' subset | loss 3.607 | trans_loss 4.018 | nll_loss 0.994 | w2v_ctc_loss 2.649 | contrastive_loss 0 | total 3909.1 | n_correct 3489.2 | ppl 1.99 | accuracy 89.258 | uer 20.906 | wer 22.71 | raw_wer 22.71 | bleu 0.9 | wps 3876.8 | wpb 3909.1 | bsz 141.8 | num_updates 58000 | best_bleu 0.91
2023-07-06 19:04:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58000 updates
2023-07-06 19:04:41 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_40_58000.pt
2023-07-06 19:04:44 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_40_58000.pt
2023-07-06 19:04:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_40_58000.pt (epoch 40 @ 58000 updates, score 0.9) (writing took 8.891711595992092 seconds)
2023-07-06 19:05:27 | INFO | train_inner | epoch 040:    640 / 1474 loss=3.298, trans_loss=4.018, nll_loss=1.05, w2v_ctc_loss=1.617, contrastive_loss=0, total=4062.71, n_correct=3577.47, ppl=2.07, accuracy=88.056, wps=6463.8, ups=1.59, wpb=4062.7, bsz=148.9, num_updates=58100, lr=5.86715e-05, gnorm=1.698, clip=0, loss_scale=8, train_wall=36, gb_free=12.7, wall=29267
2023-07-06 19:06:03 | INFO | train_inner | epoch 040:    740 / 1474 loss=3.277, trans_loss=4.002, nll_loss=1.029, w2v_ctc_loss=1.585, contrastive_loss=0, total=4073.11, n_correct=3601.71, ppl=2.04, accuracy=88.427, wps=11232.4, ups=2.76, wpb=4073.1, bsz=155.3, num_updates=58200, lr=5.8621e-05, gnorm=1.583, clip=0, loss_scale=8, train_wall=36, gb_free=12.6, wall=29304
2023-07-06 19:06:40 | INFO | train_inner | epoch 040:    840 / 1474 loss=3.286, trans_loss=4.016, nll_loss=1.048, w2v_ctc_loss=1.582, contrastive_loss=0, total=4156.72, n_correct=3662.42, ppl=2.07, accuracy=88.108, wps=11179.3, ups=2.69, wpb=4156.7, bsz=164.5, num_updates=58300, lr=5.85707e-05, gnorm=1.616, clip=0, loss_scale=8, train_wall=37, gb_free=16.6, wall=29341
2023-07-06 19:07:17 | INFO | train_inner | epoch 040:    940 / 1474 loss=3.305, trans_loss=4.022, nll_loss=1.055, w2v_ctc_loss=1.631, contrastive_loss=0, total=4033.07, n_correct=3549.4, ppl=2.08, accuracy=88.007, wps=11055.6, ups=2.74, wpb=4033.1, bsz=146.8, num_updates=58400, lr=5.85206e-05, gnorm=1.677, clip=0, loss_scale=8, train_wall=36, gb_free=17.2, wall=29377
2023-07-06 19:07:54 | INFO | train_inner | epoch 040:   1040 / 1474 loss=3.31, trans_loss=4.024, nll_loss=1.057, w2v_ctc_loss=1.645, contrastive_loss=0, total=4056.14, n_correct=3567.46, ppl=2.08, accuracy=87.952, wps=10915.1, ups=2.69, wpb=4056.1, bsz=143.7, num_updates=58500, lr=5.84705e-05, gnorm=1.649, clip=0, loss_scale=8, train_wall=37, gb_free=17.1, wall=29414
2023-07-06 19:08:31 | INFO | train_inner | epoch 040:   1140 / 1474 loss=3.305, trans_loss=4.018, nll_loss=1.049, w2v_ctc_loss=1.64, contrastive_loss=0, total=4075.8, n_correct=3587.96, ppl=2.07, accuracy=88.031, wps=11172, ups=2.74, wpb=4075.8, bsz=149.9, num_updates=58600, lr=5.84206e-05, gnorm=1.709, clip=0, loss_scale=8, train_wall=36, gb_free=16.3, wall=29451
2023-07-06 19:09:07 | INFO | train_inner | epoch 040:   1240 / 1474 loss=3.29, trans_loss=4.014, nll_loss=1.046, w2v_ctc_loss=1.599, contrastive_loss=0, total=4113.39, n_correct=3627.51, ppl=2.06, accuracy=88.188, wps=11213, ups=2.73, wpb=4113.4, bsz=154.7, num_updates=58700, lr=5.83708e-05, gnorm=1.627, clip=0, loss_scale=8, train_wall=36, gb_free=17.1, wall=29488
2023-07-06 19:09:44 | INFO | train_inner | epoch 040:   1340 / 1474 loss=3.292, trans_loss=4.018, nll_loss=1.051, w2v_ctc_loss=1.596, contrastive_loss=0, total=4061.96, n_correct=3575.88, ppl=2.07, accuracy=88.033, wps=11098.3, ups=2.73, wpb=4062, bsz=152.9, num_updates=58800, lr=5.83212e-05, gnorm=1.701, clip=0, loss_scale=8, train_wall=36, gb_free=17.5, wall=29524
2023-07-06 19:10:20 | INFO | train_inner | epoch 040:   1440 / 1474 loss=3.282, trans_loss=4.009, nll_loss=1.039, w2v_ctc_loss=1.585, contrastive_loss=0, total=4073.32, n_correct=3594.56, ppl=2.05, accuracy=88.246, wps=11136.1, ups=2.73, wpb=4073.3, bsz=153.1, num_updates=58900, lr=5.82717e-05, gnorm=1.691, clip=0, loss_scale=8, train_wall=36, gb_free=14.1, wall=29561
2023-07-06 19:10:33 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 19:10:50 | INFO | dev_rec_st | epoch 040 | valid on 'dev_rec_st' subset | loss 3.526 | trans_loss 4.022 | nll_loss 0.996 | w2v_ctc_loss 2.367 | contrastive_loss 0 | total 3909.1 | n_correct 3485.4 | ppl 1.99 | accuracy 89.161 | uer 20.845 | wer 23.094 | raw_wer 23.094 | bleu 0.87 | wps 3850 | wpb 3909.1 | bsz 141.8 | num_updates 58934 | best_bleu 0.91
2023-07-06 19:10:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58934 updates
2023-07-06 19:10:50 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_last.pt
2023-07-06 19:10:55 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_last.pt
2023-07-06 19:10:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_last.pt (epoch 40 @ 58934 updates, score 0.87) (writing took 4.609798759993282 seconds)
2023-07-06 19:10:55 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-07-06 19:10:55 | INFO | train | epoch 040 | loss 3.287 | trans_loss 4.01 | nll_loss 1.04 | w2v_ctc_loss 1.599 | contrastive_loss 0 | total 4078.54 | n_correct 3597.48 | ppl 2.06 | accuracy 88.205 | wps 10099.2 | ups 2.48 | wpb 4078.5 | bsz 152.8 | num_updates 58934 | lr 5.82548e-05 | gnorm 1.663 | clip 0 | loss_scale 8 | train_wall 532 | gb_free 15.9 | wall 29595
2023-07-06 19:10:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-06 19:10:55 | INFO | fairseq.trainer | begin training epoch 41
2023-07-06 19:10:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-06 19:11:26 | INFO | train_inner | epoch 041:     66 / 1474 loss=3.263, trans_loss=3.99, nll_loss=1.014, w2v_ctc_loss=1.566, contrastive_loss=0, total=4042.1, n_correct=3580.28, ppl=2.02, accuracy=88.575, wps=6134.5, ups=1.52, wpb=4042.1, bsz=149.2, num_updates=59000, lr=5.82223e-05, gnorm=1.643, clip=0, loss_scale=8, train_wall=36, gb_free=16.3, wall=29627
2023-07-06 19:12:03 | INFO | train_inner | epoch 041:    166 / 1474 loss=3.264, trans_loss=3.989, nll_loss=1.013, w2v_ctc_loss=1.574, contrastive_loss=0, total=4080.88, n_correct=3617.89, ppl=2.02, accuracy=88.655, wps=11193.5, ups=2.74, wpb=4080.9, bsz=153.6, num_updates=59100, lr=5.8173e-05, gnorm=1.639, clip=0, loss_scale=8, train_wall=36, gb_free=17.1, wall=29663
2023-07-06 19:12:39 | INFO | train_inner | epoch 041:    266 / 1474 loss=3.262, trans_loss=3.996, nll_loss=1.022, w2v_ctc_loss=1.551, contrastive_loss=0, total=4109.86, n_correct=3637.96, ppl=2.03, accuracy=88.518, wps=11383.8, ups=2.77, wpb=4109.9, bsz=159.4, num_updates=59200, lr=5.81238e-05, gnorm=1.621, clip=0, loss_scale=16, train_wall=36, gb_free=17.2, wall=29699
2023-07-06 19:13:15 | INFO | train_inner | epoch 041:    366 / 1474 loss=3.284, trans_loss=4.005, nll_loss=1.035, w2v_ctc_loss=1.6, contrastive_loss=0, total=4092.01, n_correct=3614.75, ppl=2.05, accuracy=88.337, wps=11186.1, ups=2.73, wpb=4092, bsz=153.6, num_updates=59300, lr=5.80748e-05, gnorm=1.719, clip=0, loss_scale=16, train_wall=36, gb_free=16.8, wall=29736
2023-07-06 19:13:52 | INFO | train_inner | epoch 041:    466 / 1474 loss=3.277, trans_loss=4, nll_loss=1.026, w2v_ctc_loss=1.592, contrastive_loss=0, total=4083.79, n_correct=3613.16, ppl=2.04, accuracy=88.476, wps=11199.4, ups=2.74, wpb=4083.8, bsz=151.7, num_updates=59400, lr=5.80259e-05, gnorm=1.687, clip=0, loss_scale=16, train_wall=36, gb_free=16.8, wall=29772
2023-07-06 19:14:28 | INFO | train_inner | epoch 041:    566 / 1474 loss=3.281, trans_loss=4.003, nll_loss=1.03, w2v_ctc_loss=1.596, contrastive_loss=0, total=4093.44, n_correct=3617.95, ppl=2.04, accuracy=88.384, wps=11217.8, ups=2.74, wpb=4093.4, bsz=153.5, num_updates=59500, lr=5.79771e-05, gnorm=1.65, clip=0, loss_scale=16, train_wall=36, gb_free=15.6, wall=29809
2023-07-06 19:15:05 | INFO | train_inner | epoch 041:    666 / 1474 loss=3.272, trans_loss=3.995, nll_loss=1.021, w2v_ctc_loss=1.584, contrastive_loss=0, total=4127.54, n_correct=3652.98, ppl=2.03, accuracy=88.503, wps=11364.8, ups=2.75, wpb=4127.5, bsz=158.5, num_updates=59600, lr=5.79284e-05, gnorm=1.675, clip=0, loss_scale=16, train_wall=36, gb_free=17, wall=29845
2023-07-06 19:15:41 | INFO | train_inner | epoch 041:    766 / 1474 loss=3.281, trans_loss=3.999, nll_loss=1.027, w2v_ctc_loss=1.606, contrastive_loss=0, total=4085.06, n_correct=3610.9, ppl=2.04, accuracy=88.393, wps=11216.3, ups=2.75, wpb=4085.1, bsz=150.1, num_updates=59700, lr=5.78799e-05, gnorm=1.7, clip=0, loss_scale=16, train_wall=36, gb_free=14.9, wall=29882
2023-07-06 19:16:18 | INFO | train_inner | epoch 041:    866 / 1474 loss=3.284, trans_loss=4.002, nll_loss=1.03, w2v_ctc_loss=1.609, contrastive_loss=0, total=4047.81, n_correct=3576.5, ppl=2.04, accuracy=88.356, wps=11105.6, ups=2.74, wpb=4047.8, bsz=148.1, num_updates=59800, lr=5.78315e-05, gnorm=1.677, clip=0, loss_scale=16, train_wall=36, gb_free=16.1, wall=29918
2023-07-06 19:16:55 | INFO | train_inner | epoch 041:    966 / 1474 loss=3.297, trans_loss=4.017, nll_loss=1.049, w2v_ctc_loss=1.618, contrastive_loss=0, total=4059.57, n_correct=3576.8, ppl=2.07, accuracy=88.108, wps=11001.8, ups=2.71, wpb=4059.6, bsz=149.2, num_updates=59900, lr=5.77832e-05, gnorm=1.665, clip=0, loss_scale=16, train_wall=36, gb_free=15.8, wall=29955
2023-07-06 19:17:31 | INFO | train_inner | epoch 041:   1066 / 1474 loss=3.29, trans_loss=4.006, nll_loss=1.036, w2v_ctc_loss=1.618, contrastive_loss=0, total=4072.54, n_correct=3594.93, ppl=2.05, accuracy=88.272, wps=11184.6, ups=2.75, wpb=4072.5, bsz=151.5, num_updates=60000, lr=5.7735e-05, gnorm=1.668, clip=0, loss_scale=16, train_wall=36, gb_free=15.4, wall=29991
2023-07-06 19:17:31 | INFO | fairseq_cli.train | Stopping training due to num_updates: 60000 >= max_update: 60000
2023-07-06 19:17:31 | INFO | fairseq_cli.train | begin validation on "dev_rec_st" subset
2023-07-06 19:17:48 | INFO | dev_rec_st | epoch 041 | valid on 'dev_rec_st' subset | loss 3.491 | trans_loss 4.003 | nll_loss 0.972 | w2v_ctc_loss 2.297 | contrastive_loss 0 | total 3909.1 | n_correct 3496.9 | ppl 1.96 | accuracy 89.455 | uer 20.747 | wer 23.042 | raw_wer 23.042 | bleu 0.91 | wps 3807 | wpb 3909.1 | bsz 141.8 | num_updates 60000 | best_bleu 0.91
2023-07-06 19:17:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 60000 updates
2023-07-06 19:17:48 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_41_60000.pt
2023-07-06 19:17:51 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_41_60000.pt
2023-07-06 19:17:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_asronly_rec/checkpoint_41_60000.pt (epoch 41 @ 60000 updates, score 0.91) (writing took 9.74231281100947 seconds)
2023-07-06 19:17:59 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-07-06 19:17:59 | INFO | train | epoch 041 | loss 3.278 | trans_loss 4 | nll_loss 1.028 | w2v_ctc_loss 1.593 | contrastive_loss 0 | total 4084.5 | n_correct 3611.28 | ppl 2.04 | accuracy 88.414 | wps 10271.4 | ups 2.51 | wpb 4084.5 | bsz 152.9 | num_updates 60000 | lr 5.7735e-05 | gnorm 1.67 | clip 0 | loss_scale 16 | train_wall 384 | gb_free 15.4 | wall 30019
2023-07-06 19:17:59 | INFO | fairseq_cli.train | done training in 29973.3 seconds
/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1776 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
