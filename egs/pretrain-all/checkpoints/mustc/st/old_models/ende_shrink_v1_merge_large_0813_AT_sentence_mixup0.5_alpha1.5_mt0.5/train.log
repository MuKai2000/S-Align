2023-08-13 12:47:24 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:19246
2023-08-13 12:47:24 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:19246
2023-08-13 12:47:24 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:19246
2023-08-13 12:47:24 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:19246
2023-08-13 12:47:24 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:19246
2023-08-13 12:47:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-13 12:47:24 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:19246
2023-08-13 12:47:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-13 12:47:24 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:19246
2023-08-13 12:47:24 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:19246
2023-08-13 12:47:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-13 12:47:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-13 12:47:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-13 12:47:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-13 12:47:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-13 12:47:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-13 12:47:25 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-13 12:47:25 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-08-13 12:47:25 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-13 12:47:25 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-08-13 12:47:25 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-13 12:47:25 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-13 12:47:25 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-13 12:47:25 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-13 12:47:25 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-13 12:47:25 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-08-13 12:47:25 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-08-13 12:47:25 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-08-13 12:47:25 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-08-13 12:47:25 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-08-13 12:47:25 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-13 12:47:25 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-08-13 12:47:30 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19246', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.5, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.5, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.5, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-13 12:47:30 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-13 12:47:30 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-13 12:47:30 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-13 12:47:30 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-13 12:47:30 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-13 12:47:34 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-13 12:47:34 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-13 12:47:34 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-13 12:47:36 | INFO | root | load pretrained hubert
2023-08-13 12:47:39 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-13 12:47:40 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-13 12:47:43 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-13 12:47:43 | INFO | root | share the sematic adapter and textual encoder
2023-08-13 12:47:43 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-13 12:47:43 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-13 12:47:43 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-13 12:47:43 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-13 12:47:43 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-08-13 12:47:43 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-13 12:47:43 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-13 12:47:43 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-13 12:47:43 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-13 12:47:43 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-13 12:47:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-13 12:47:50 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-13 12:47:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-13 12:47:50 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-13 12:47:50 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-13 12:47:50 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-13 12:47:50 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-13 12:47:50 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-13 12:47:50 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-13 12:47:50 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-13 12:47:50 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-13 12:47:50 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-13 12:47:50 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-13 12:47:50 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-13 12:47:50 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-13 12:47:50 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-13 12:47:50 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-13 12:47:50 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-13 12:47:50 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-13 12:47:50 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-13 12:47:50 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-13 12:47:52 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-13 12:47:53 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-13 12:48:41 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-13 12:48:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 12:48:41 | INFO | fairseq.trainer | begin training epoch 1
2023-08-13 12:48:41 | INFO | fairseq_cli.train | Start iterating over samples
None None None
2023-08-13 12:48:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
None None None
2023-08-13 12:48:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
None None None
2023-08-13 12:49:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-13 12:49:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
None None None
None None None
None None None
2023-08-13 12:50:04 | INFO | train_inner | epoch 001:    104 / 1474 loss=20.042, trans_loss=5.873, nll_loss=4.682, w2v_ctc_loss=22.314, task_loss=1.757, contrastive_loss=3.276, total=4227.88, n_correct=124.03, ppl=25.67, accuracy=2.934, wps=18487.5, ups=1.47, wpb=12612.8, bsz=477.6, num_updates=100, lr=4.098e-06, gnorm=2.838, clip=0, loss_scale=8, train_wall=73, gb_free=18.6, wall=134
2023-08-13 12:50:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-13 12:51:10 | INFO | train_inner | epoch 001:    205 / 1474 loss=16.535, trans_loss=5.85, nll_loss=4.678, w2v_ctc_loss=17.005, task_loss=1.709, contrastive_loss=3.233, total=4114.31, n_correct=115.8, ppl=25.6, accuracy=2.815, wps=18519, ups=1.51, wpb=12284.9, bsz=458.2, num_updates=200, lr=8.096e-06, gnorm=7.22, clip=17, loss_scale=4, train_wall=66, gb_free=19.4, wall=200
2023-08-13 12:52:15 | INFO | train_inner | epoch 001:    305 / 1474 loss=9.907, trans_loss=5.838, nll_loss=4.702, w2v_ctc_loss=6.876, task_loss=1.654, contrastive_loss=3.175, total=4080.91, n_correct=111.18, ppl=26.02, accuracy=2.724, wps=18887.1, ups=1.55, wpb=12190.4, bsz=439.4, num_updates=300, lr=1.2094e-05, gnorm=2.219, clip=0, loss_scale=4, train_wall=64, gb_free=18.6, wall=264
2023-08-13 12:53:20 | INFO | train_inner | epoch 001:    405 / 1474 loss=9.413, trans_loss=5.802, nll_loss=4.69, w2v_ctc_loss=6.113, task_loss=1.416, contrastive_loss=3.207, total=4176.41, n_correct=102.94, ppl=25.82, accuracy=2.465, wps=19180.8, ups=1.54, wpb=12470, bsz=461.3, num_updates=400, lr=1.6092e-05, gnorm=1.562, clip=0, loss_scale=4, train_wall=65, gb_free=19.5, wall=329
2023-08-13 12:54:25 | INFO | train_inner | epoch 001:    505 / 1474 loss=9.205, trans_loss=5.717, nll_loss=4.599, w2v_ctc_loss=5.821, task_loss=1.272, contrastive_loss=3.305, total=4192.13, n_correct=103.36, ppl=24.24, accuracy=2.466, wps=19248.7, ups=1.54, wpb=12526, bsz=489.2, num_updates=500, lr=2.009e-05, gnorm=1.494, clip=1, loss_scale=4, train_wall=65, gb_free=19.1, wall=395
2023-08-13 12:55:30 | INFO | train_inner | epoch 001:    605 / 1474 loss=9.078, trans_loss=5.737, nll_loss=4.624, w2v_ctc_loss=5.663, task_loss=1.248, contrastive_loss=3.254, total=4131.49, n_correct=97.55, ppl=24.66, accuracy=2.361, wps=18841, ups=1.53, wpb=12320.8, bsz=473.5, num_updates=600, lr=2.4088e-05, gnorm=1.243, clip=0, loss_scale=4, train_wall=65, gb_free=18.9, wall=460
2023-08-13 12:56:34 | INFO | train_inner | epoch 001:    705 / 1474 loss=9, trans_loss=5.751, nll_loss=4.644, w2v_ctc_loss=5.597, task_loss=1.303, contrastive_loss=3.135, total=4147.85, n_correct=89.29, ppl=25.01, accuracy=2.153, wps=19361.4, ups=1.56, wpb=12387.4, bsz=455.8, num_updates=700, lr=2.8086e-05, gnorm=1.391, clip=0, loss_scale=4, train_wall=64, gb_free=19.3, wall=524
2023-08-13 12:57:39 | INFO | train_inner | epoch 001:    805 / 1474 loss=8.944, trans_loss=5.897, nll_loss=4.828, w2v_ctc_loss=5.417, task_loss=1.277, contrastive_loss=3.146, total=4128.17, n_correct=73.82, ppl=28.4, accuracy=1.788, wps=18978.8, ups=1.54, wpb=12316.6, bsz=462.9, num_updates=800, lr=3.2084e-05, gnorm=1.61, clip=0, loss_scale=4, train_wall=64, gb_free=18.6, wall=589
2023-08-13 12:58:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-13 12:58:44 | INFO | train_inner | epoch 001:    906 / 1474 loss=8.795, trans_loss=5.899, nll_loss=4.825, w2v_ctc_loss=5.245, task_loss=1.29, contrastive_loss=3.058, total=4167.86, n_correct=72.61, ppl=28.34, accuracy=1.742, wps=19053.3, ups=1.53, wpb=12445.5, bsz=458.8, num_updates=900, lr=3.6082e-05, gnorm=1.953, clip=0, loss_scale=2, train_wall=65, gb_free=18.6, wall=654
2023-08-13 12:59:50 | INFO | train_inner | epoch 001:   1006 / 1474 loss=8.724, trans_loss=6.053, nll_loss=5.017, w2v_ctc_loss=5.013, task_loss=1.292, contrastive_loss=3.052, total=4137.5, n_correct=49.92, ppl=32.39, accuracy=1.207, wps=18922.7, ups=1.53, wpb=12361.1, bsz=459.1, num_updates=1000, lr=4.008e-05, gnorm=1.973, clip=0, loss_scale=2, train_wall=65, gb_free=19.3, wall=719
2023-08-13 13:00:54 | INFO | train_inner | epoch 001:   1106 / 1474 loss=8.525, trans_loss=6.09, nll_loss=5.052, w2v_ctc_loss=4.788, task_loss=1.327, contrastive_loss=2.961, total=4151.84, n_correct=48.43, ppl=33.18, accuracy=1.166, wps=19088.5, ups=1.54, wpb=12382.4, bsz=452.7, num_updates=1100, lr=4.4078e-05, gnorm=1.82, clip=0, loss_scale=2, train_wall=64, gb_free=18.8, wall=784
2023-08-13 13:01:59 | INFO | train_inner | epoch 001:   1206 / 1474 loss=8.367, trans_loss=6.155, nll_loss=5.138, w2v_ctc_loss=4.591, task_loss=1.383, contrastive_loss=2.85, total=4123.25, n_correct=40.14, ppl=35.22, accuracy=0.974, wps=19150, ups=1.55, wpb=12316.7, bsz=437.7, num_updates=1200, lr=4.8076e-05, gnorm=2.079, clip=0, loss_scale=2, train_wall=64, gb_free=19.6, wall=849
2023-08-13 13:03:03 | INFO | train_inner | epoch 001:   1306 / 1474 loss=8.204, trans_loss=6.148, nll_loss=5.13, w2v_ctc_loss=4.399, task_loss=1.302, contrastive_loss=2.804, total=4066.16, n_correct=50.13, ppl=35.01, accuracy=1.233, wps=18969.3, ups=1.56, wpb=12138.7, bsz=445.8, num_updates=1300, lr=5.2074e-05, gnorm=2.556, clip=0, loss_scale=2, train_wall=64, gb_free=18.8, wall=913
2023-08-13 13:04:07 | INFO | train_inner | epoch 001:   1406 / 1474 loss=8.066, trans_loss=6.17, nll_loss=5.163, w2v_ctc_loss=4.232, task_loss=1.324, contrastive_loss=2.865, total=4119.98, n_correct=47.02, ppl=35.82, accuracy=1.141, wps=19054.6, ups=1.55, wpb=12311.1, bsz=449.5, num_updates=1400, lr=5.6072e-05, gnorm=2.202, clip=0, loss_scale=2, train_wall=64, gb_free=18.6, wall=977
2023-08-13 13:04:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
2023-08-13 13:05:33 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 12.49 | trans_loss 13.904 | nll_loss 13.765 | w2v_ctc_loss 5.472 | task_loss 7.545 | contrastive_loss 4.081 | total 4003.4 | n_correct 27.2 | ppl 13918.2 | accuracy 0.679 | uer 69.676 | wer 68.01 | raw_wer 68.01 | bleu 0 | wps 1106.5 | wpb 4003.4 | bsz 141.8 | num_updates 1468
2023-08-13 13:05:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1468 updates
2023-08-13 13:05:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 13:05:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 13:05:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 1 @ 1468 updates, score 0.0) (writing took 7.50948085449636 seconds)
2023-08-13 13:05:41 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-13 13:05:41 | INFO | train | epoch 001 | loss 10.11 | trans_loss 5.937 | nll_loss 4.854 | w2v_ctc_loss 7.232 | task_loss 1.39 | contrastive_loss 3.085 | total 4140.12 | n_correct 79.0347 | ppl 28.92 | accuracy 1.909 | wps 18053.1 | ups 1.46 | wpb 12360.2 | bsz 459 | num_updates 1468 | lr 5.87906e-05 | gnorm 2.3 | clip 1.2 | loss_scale 2 | train_wall 955 | gb_free 18.9 | wall 1070
2023-08-13 13:05:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 13:05:41 | INFO | fairseq.trainer | begin training epoch 2
2023-08-13 13:05:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 13:06:09 | INFO | train_inner | epoch 002:     32 / 1474 loss=7.927, trans_loss=6.154, nll_loss=5.14, w2v_ctc_loss=4.067, task_loss=1.253, contrastive_loss=2.833, total=4165.61, n_correct=50.58, ppl=35.26, accuracy=1.214, wps=10183.6, ups=0.82, wpb=12422.6, bsz=470.4, num_updates=1500, lr=6.007e-05, gnorm=2.479, clip=0, loss_scale=2, train_wall=65, gb_free=18.7, wall=1099
2023-08-13 13:07:14 | INFO | train_inner | epoch 002:    132 / 1474 loss=7.778, trans_loss=6.129, nll_loss=5.11, w2v_ctc_loss=3.976, task_loss=1.31, contrastive_loss=2.685, total=4153.7, n_correct=53.46, ppl=34.54, accuracy=1.287, wps=19242.2, ups=1.55, wpb=12391.2, bsz=453.7, num_updates=1600, lr=6.4068e-05, gnorm=2.427, clip=0, loss_scale=2, train_wall=64, gb_free=19.2, wall=1164
2023-08-13 13:08:18 | INFO | train_inner | epoch 002:    232 / 1474 loss=7.696, trans_loss=6.132, nll_loss=5.118, w2v_ctc_loss=3.822, task_loss=1.144, contrastive_loss=2.751, total=4201.44, n_correct=53.4, ppl=34.73, accuracy=1.271, wps=19534.8, ups=1.56, wpb=12547.2, bsz=493.6, num_updates=1700, lr=6.8066e-05, gnorm=2.549, clip=0, loss_scale=2, train_wall=64, gb_free=18.9, wall=1228
2023-08-13 13:09:23 | INFO | train_inner | epoch 002:    332 / 1474 loss=7.518, trans_loss=6.131, nll_loss=5.116, w2v_ctc_loss=3.77, task_loss=1.337, contrastive_loss=2.516, total=4130.13, n_correct=54.35, ppl=34.67, accuracy=1.316, wps=19086.7, ups=1.55, wpb=12330.1, bsz=445.5, num_updates=1800, lr=7.2064e-05, gnorm=2.66, clip=0, loss_scale=2, train_wall=64, gb_free=18.7, wall=1292
2023-08-13 13:10:28 | INFO | train_inner | epoch 002:    432 / 1474 loss=7.365, trans_loss=6.105, nll_loss=5.087, w2v_ctc_loss=3.71, task_loss=1.468, contrastive_loss=2.333, total=4035.12, n_correct=55.23, ppl=33.98, accuracy=1.369, wps=18517, ups=1.54, wpb=12062.7, bsz=413.5, num_updates=1900, lr=7.6062e-05, gnorm=2.618, clip=0, loss_scale=2, train_wall=65, gb_free=19, wall=1358
2023-08-13 13:11:32 | INFO | train_inner | epoch 002:    532 / 1474 loss=7.305, trans_loss=6.101, nll_loss=5.077, w2v_ctc_loss=3.571, task_loss=1.268, contrastive_loss=2.481, total=4183.09, n_correct=62.76, ppl=33.76, accuracy=1.5, wps=19521.3, ups=1.56, wpb=12479, bsz=468.4, num_updates=2000, lr=8.006e-05, gnorm=2.488, clip=0, loss_scale=2, train_wall=63, gb_free=18.5, wall=1422
2023-08-13 13:11:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 13:12:11 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 11.707 | trans_loss 13.429 | nll_loss 13.157 | w2v_ctc_loss 4.633 | task_loss 7.545 | contrastive_loss 3.521 | total 4003.4 | n_correct 52.5 | ppl 9133.45 | accuracy 1.311 | uer 62.031 | wer 60.419 | raw_wer 60.419 | bleu 0 | wps 1156.4 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0
2023-08-13 13:12:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-13 13:12:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-08-13 13:12:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-08-13 13:13:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 51.967683928087354 seconds)
2023-08-13 13:14:07 | INFO | train_inner | epoch 002:    632 / 1474 loss=7.156, trans_loss=6.089, nll_loss=5.062, w2v_ctc_loss=3.479, task_loss=1.301, contrastive_loss=2.293, total=4123.85, n_correct=59.05, ppl=33.41, accuracy=1.432, wps=7933.4, ups=0.64, wpb=12306.4, bsz=448.7, num_updates=2100, lr=8.4058e-05, gnorm=2.436, clip=0, loss_scale=2, train_wall=63, gb_free=18.6, wall=1577
2023-08-13 13:15:11 | INFO | train_inner | epoch 002:    732 / 1474 loss=7.081, trans_loss=6.077, nll_loss=5.046, w2v_ctc_loss=3.416, task_loss=1.288, contrastive_loss=2.364, total=4148.13, n_correct=65.03, ppl=33.03, accuracy=1.568, wps=19296.9, ups=1.56, wpb=12381, bsz=462.1, num_updates=2200, lr=8.8056e-05, gnorm=2.432, clip=0, loss_scale=2, train_wall=64, gb_free=18.6, wall=1641
2023-08-13 13:16:16 | INFO | train_inner | epoch 002:    832 / 1474 loss=6.984, trans_loss=6.065, nll_loss=5.032, w2v_ctc_loss=3.362, task_loss=1.301, contrastive_loss=2.308, total=4172.27, n_correct=66.66, ppl=32.73, accuracy=1.598, wps=19188.9, ups=1.54, wpb=12465.7, bsz=464.5, num_updates=2300, lr=9.2054e-05, gnorm=2.259, clip=0, loss_scale=2, train_wall=64, gb_free=18.8, wall=1706
2023-08-13 13:17:21 | INFO | train_inner | epoch 002:    932 / 1474 loss=6.838, trans_loss=6.046, nll_loss=5.006, w2v_ctc_loss=3.275, task_loss=1.362, contrastive_loss=2.228, total=4101.67, n_correct=67.63, ppl=32.14, accuracy=1.649, wps=18901.9, ups=1.54, wpb=12242.5, bsz=441.6, num_updates=2400, lr=9.6052e-05, gnorm=2.389, clip=0, loss_scale=2, train_wall=64, gb_free=18.9, wall=1771
2023-08-13 13:18:25 | INFO | train_inner | epoch 002:   1032 / 1474 loss=6.748, trans_loss=6.043, nll_loss=5.003, w2v_ctc_loss=3.211, task_loss=1.324, contrastive_loss=2.115, total=4091.09, n_correct=65.87, ppl=32.06, accuracy=1.61, wps=19128.7, ups=1.57, wpb=12214.8, bsz=451.5, num_updates=2500, lr=0.00010005, gnorm=2.115, clip=0, loss_scale=2, train_wall=63, gb_free=19.2, wall=1834
2023-08-13 13:19:29 | INFO | train_inner | epoch 002:   1132 / 1474 loss=6.716, trans_loss=6.028, nll_loss=4.984, w2v_ctc_loss=3.113, task_loss=1.149, contrastive_loss=2.34, total=4219.19, n_correct=69.01, ppl=31.64, accuracy=1.636, wps=19423.4, ups=1.54, wpb=12595.1, bsz=500.6, num_updates=2600, lr=0.000104048, gnorm=2.195, clip=0, loss_scale=2, train_wall=64, gb_free=19, wall=1899
2023-08-13 13:20:34 | INFO | train_inner | epoch 002:   1232 / 1474 loss=6.609, trans_loss=6.017, nll_loss=4.968, w2v_ctc_loss=3.081, task_loss=1.21, contrastive_loss=2.145, total=4212.91, n_correct=70.42, ppl=31.3, accuracy=1.672, wps=19372.3, ups=1.54, wpb=12571.7, bsz=486.8, num_updates=2700, lr=0.000108046, gnorm=2.056, clip=0, loss_scale=2, train_wall=64, gb_free=19.1, wall=1964
2023-08-13 13:21:39 | INFO | train_inner | epoch 002:   1332 / 1474 loss=6.499, trans_loss=6.009, nll_loss=4.962, w2v_ctc_loss=3.045, task_loss=1.271, contrastive_loss=1.926, total=4142.48, n_correct=70.72, ppl=31.16, accuracy=1.707, wps=19158.8, ups=1.55, wpb=12381.2, bsz=456.3, num_updates=2800, lr=0.000112044, gnorm=2.041, clip=0, loss_scale=2, train_wall=64, gb_free=18.9, wall=2029
2023-08-13 13:22:44 | INFO | train_inner | epoch 002:   1432 / 1474 loss=6.404, trans_loss=6.002, nll_loss=4.95, w2v_ctc_loss=2.996, task_loss=1.386, contrastive_loss=1.985, total=4063.28, n_correct=68.64, ppl=30.92, accuracy=1.689, wps=18789.6, ups=1.55, wpb=12131.5, bsz=444.3, num_updates=2900, lr=0.000116042, gnorm=1.99, clip=0, loss_scale=4, train_wall=64, gb_free=19.6, wall=2093
2023-08-13 13:23:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 13:23:51 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 10.849 | trans_loss 13.035 | nll_loss 12.638 | w2v_ctc_loss 3.8 | task_loss 7.545 | contrastive_loss 2.648 | total 4003.4 | n_correct 85 | ppl 6375.17 | accuracy 2.123 | uer 53.33 | wer 52.593 | raw_wer 52.593 | bleu 0 | wps 1131.7 | wpb 4003.4 | bsz 141.8 | num_updates 2942 | best_bleu 0
2023-08-13 13:23:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2942 updates
2023-08-13 13:23:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 13:24:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 13:24:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 2 @ 2942 updates, score 0.0) (writing took 27.25502640940249 seconds)
2023-08-13 13:24:18 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-13 13:24:18 | INFO | train | epoch 002 | loss 7.049 | trans_loss 6.069 | nll_loss 5.037 | w2v_ctc_loss 3.417 | task_loss 1.292 | contrastive_loss 2.319 | total 4138.65 | n_correct 63.0197 | ppl 32.83 | accuracy 1.523 | wps 16295.1 | ups 1.32 | wpb 12355.8 | bsz 458.5 | num_updates 2942 | lr 0.000117721 | gnorm 2.328 | clip 0 | loss_scale 4 | train_wall 943 | gb_free 19 | wall 2188
2023-08-13 13:24:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 13:24:19 | INFO | fairseq.trainer | begin training epoch 3
2023-08-13 13:24:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 13:25:04 | INFO | train_inner | epoch 003:     58 / 1474 loss=6.308, trans_loss=5.989, nll_loss=4.934, w2v_ctc_loss=2.945, task_loss=1.362, contrastive_loss=1.837, total=4048.67, n_correct=71.29, ppl=30.57, accuracy=1.761, wps=8615.5, ups=0.71, wpb=12085.6, bsz=433.9, num_updates=3000, lr=0.00012004, gnorm=1.854, clip=0, loss_scale=4, train_wall=64, gb_free=18.8, wall=2234
2023-08-13 13:25:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-13 13:26:36 | INFO | train_inner | epoch 003:    159 / 1474 loss=5.676, trans_loss=5.363, nll_loss=4.144, w2v_ctc_loss=2.701, task_loss=0.902, contrastive_loss=1.779, total=4154.39, n_correct=236.95, ppl=17.68, accuracy=5.704, wps=13390.6, ups=1.08, wpb=12405.5, bsz=462.5, num_updates=3100, lr=0.000124038, gnorm=3.94, clip=6, loss_scale=2, train_wall=92, gb_free=16.2, wall=2326
2023-08-13 13:28:10 | INFO | train_inner | epoch 003:    259 / 1474 loss=5.035, trans_loss=5.084, nll_loss=3.784, w2v_ctc_loss=2.388, task_loss=0.927, contrastive_loss=1.528, total=4155.72, n_correct=416.21, ppl=13.78, accuracy=10.015, wps=13294, ups=1.07, wpb=12415.9, bsz=465.5, num_updates=3200, lr=0.000128036, gnorm=2.3, clip=0, loss_scale=2, train_wall=93, gb_free=17.4, wall=2420
2023-08-13 13:29:43 | INFO | train_inner | epoch 003:    359 / 1474 loss=4.762, trans_loss=4.951, nll_loss=3.603, w2v_ctc_loss=2.263, task_loss=0.917, contrastive_loss=1.459, total=4154.07, n_correct=518.81, ppl=12.15, accuracy=12.489, wps=13350, ups=1.08, wpb=12396.6, bsz=464.9, num_updates=3300, lr=0.000132034, gnorm=2.114, clip=0, loss_scale=2, train_wall=92, gb_free=15.3, wall=2513
2023-08-13 13:31:16 | INFO | train_inner | epoch 003:    459 / 1474 loss=4.499, trans_loss=4.823, nll_loss=3.432, w2v_ctc_loss=2.15, task_loss=0.901, contrastive_loss=1.27, total=4212.17, n_correct=625.33, ppl=10.79, accuracy=14.846, wps=13540.3, ups=1.08, wpb=12572.6, bsz=473.8, num_updates=3400, lr=0.000136032, gnorm=1.937, clip=0, loss_scale=2, train_wall=92, gb_free=15.4, wall=2605
2023-08-13 13:32:48 | INFO | train_inner | epoch 003:    559 / 1474 loss=4.284, trans_loss=4.725, nll_loss=3.303, w2v_ctc_loss=2.07, task_loss=0.985, contrastive_loss=1.153, total=4081.04, n_correct=688.93, ppl=9.87, accuracy=16.881, wps=13175.6, ups=1.08, wpb=12190.8, bsz=440.1, num_updates=3500, lr=0.00014003, gnorm=1.888, clip=0, loss_scale=2, train_wall=92, gb_free=16.1, wall=2698
2023-08-13 13:34:22 | INFO | train_inner | epoch 003:    659 / 1474 loss=4.14, trans_loss=4.625, nll_loss=3.164, w2v_ctc_loss=1.988, task_loss=0.876, contrastive_loss=1.202, total=4231.09, n_correct=830.77, ppl=8.96, accuracy=19.635, wps=13416, ups=1.06, wpb=12615.6, bsz=484.4, num_updates=3600, lr=0.000144028, gnorm=1.738, clip=0, loss_scale=2, train_wall=94, gb_free=15.7, wall=2792
2023-08-13 13:34:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-08-13 13:35:56 | INFO | train_inner | epoch 003:    760 / 1474 loss=3.952, trans_loss=4.515, nll_loss=3.022, w2v_ctc_loss=1.969, task_loss=0.891, contrastive_loss=0.926, total=4155.42, n_correct=931.84, ppl=8.12, accuracy=22.425, wps=13301.4, ups=1.07, wpb=12414.2, bsz=468, num_updates=3700, lr=0.000148026, gnorm=1.883, clip=1, loss_scale=1, train_wall=93, gb_free=11.1, wall=2885
2023-08-13 13:37:28 | INFO | train_inner | epoch 003:    860 / 1474 loss=3.775, trans_loss=4.407, nll_loss=2.877, w2v_ctc_loss=1.914, task_loss=0.927, contrastive_loss=0.84, total=4172.27, n_correct=1067.86, ppl=7.35, accuracy=25.594, wps=13500.1, ups=1.08, wpb=12457.6, bsz=458.8, num_updates=3800, lr=0.000152024, gnorm=1.713, clip=0, loss_scale=1, train_wall=92, gb_free=16.2, wall=2978
2023-08-13 13:39:01 | INFO | train_inner | epoch 003:    960 / 1474 loss=3.601, trans_loss=4.248, nll_loss=2.665, w2v_ctc_loss=1.876, task_loss=0.886, contrastive_loss=0.828, total=4171.53, n_correct=1276.61, ppl=6.34, accuracy=30.603, wps=13357.6, ups=1.07, wpb=12442.2, bsz=473.5, num_updates=3900, lr=0.000156022, gnorm=1.569, clip=0, loss_scale=1, train_wall=93, gb_free=15.9, wall=3071
2023-08-13 13:40:33 | INFO | train_inner | epoch 003:   1060 / 1474 loss=3.427, trans_loss=4.106, nll_loss=2.483, w2v_ctc_loss=1.866, task_loss=1.001, contrastive_loss=0.698, total=4051.14, n_correct=1423.81, ppl=5.59, accuracy=35.146, wps=13078, ups=1.08, wpb=12099.4, bsz=436.8, num_updates=4000, lr=0.00016002, gnorm=1.452, clip=0, loss_scale=1, train_wall=92, gb_free=16.5, wall=3163
2023-08-13 13:40:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 13:41:00 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.516 | trans_loss 6.744 | nll_loss 4.408 | w2v_ctc_loss 2.202 | task_loss 4.208 | contrastive_loss 0.943 | total 4003.4 | n_correct 1752.1 | ppl 21.23 | accuracy 43.765 | uer 32.089 | wer 32.426 | raw_wer 32.426 | bleu 6.57 | wps 1845.3 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 6.57
2023-08-13 13:41:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-13 13:41:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-08-13 13:41:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-08-13 13:41:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 6.57) (writing took 30.817441184073687 seconds)
2023-08-13 13:43:02 | INFO | train_inner | epoch 003:   1160 / 1474 loss=3.293, trans_loss=4.029, nll_loss=2.384, w2v_ctc_loss=1.813, task_loss=0.987, contrastive_loss=0.648, total=4050.25, n_correct=1556.41, ppl=5.22, accuracy=38.428, wps=8120.8, ups=0.67, wpb=12088.6, bsz=435.7, num_updates=4100, lr=0.000164018, gnorm=1.356, clip=0, loss_scale=1, train_wall=91, gb_free=15.9, wall=3312
2023-08-13 13:44:34 | INFO | train_inner | epoch 003:   1260 / 1474 loss=3.19, trans_loss=3.967, nll_loss=2.306, w2v_ctc_loss=1.773, task_loss=0.988, contrastive_loss=0.59, total=4058.28, n_correct=1645.53, ppl=4.95, accuracy=40.547, wps=13211.2, ups=1.09, wpb=12119.7, bsz=431.2, num_updates=4200, lr=0.000168016, gnorm=1.334, clip=0, loss_scale=1, train_wall=91, gb_free=16.1, wall=3404
2023-08-13 13:46:08 | INFO | train_inner | epoch 003:   1360 / 1474 loss=3.142, trans_loss=3.924, nll_loss=2.251, w2v_ctc_loss=1.731, task_loss=0.933, contrastive_loss=0.674, total=4134.29, n_correct=1749.84, ppl=4.76, accuracy=42.325, wps=13188.9, ups=1.07, wpb=12343, bsz=460.8, num_updates=4300, lr=0.000172014, gnorm=1.278, clip=0, loss_scale=1, train_wall=93, gb_free=16.4, wall=3497
2023-08-13 13:47:42 | INFO | train_inner | epoch 003:   1460 / 1474 loss=3.077, trans_loss=3.89, nll_loss=2.209, w2v_ctc_loss=1.704, task_loss=0.881, contrastive_loss=0.632, total=4206.08, n_correct=1834.74, ppl=4.62, accuracy=43.621, wps=13388.4, ups=1.07, wpb=12563.6, bsz=476.5, num_updates=4400, lr=0.000176012, gnorm=1.218, clip=0, loss_scale=1, train_wall=93, gb_free=14.1, wall=3591
2023-08-13 13:47:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 13:48:20 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.033 | trans_loss 6.252 | nll_loss 3.787 | w2v_ctc_loss 1.954 | task_loss 4.209 | contrastive_loss 0.727 | total 4003.4 | n_correct 2010.6 | ppl 13.8 | accuracy 50.222 | uer 30.045 | wer 30.472 | raw_wer 30.472 | bleu 10.06 | wps 1846.6 | wpb 4003.4 | bsz 141.8 | num_updates 4414 | best_bleu 10.06
2023-08-13 13:48:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4414 updates
2023-08-13 13:48:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 13:48:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 13:48:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 3 @ 4414 updates, score 10.06) (writing took 29.389935152605176 seconds)
2023-08-13 13:48:50 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-13 13:48:50 | INFO | train | epoch 003 | loss 4.074 | trans_loss 4.531 | nll_loss 3.045 | w2v_ctc_loss 2.048 | task_loss 0.944 | contrastive_loss 1.05 | total 4138.72 | n_correct 1025.31 | ppl 8.26 | accuracy 24.773 | wps 12358.4 | ups 1 | wpb 12356.1 | bsz 458.7 | num_updates 4414 | lr 0.000176572 | gnorm 1.831 | clip 0.5 | loss_scale 1 | train_wall 1344 | gb_free 16.2 | wall 3660
2023-08-13 13:48:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 13:48:50 | INFO | fairseq.trainer | begin training epoch 4
2023-08-13 13:48:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 13:50:16 | INFO | train_inner | epoch 004:     86 / 1474 loss=2.953, trans_loss=3.856, nll_loss=2.162, w2v_ctc_loss=1.657, task_loss=0.964, contrastive_loss=0.456, total=4096.88, n_correct=1844.45, ppl=4.48, accuracy=45.021, wps=7911.6, ups=0.65, wpb=12226.6, bsz=438.5, num_updates=4500, lr=0.00018001, gnorm=1.169, clip=0, loss_scale=1, train_wall=91, gb_free=13.8, wall=3746
2023-08-13 13:51:48 | INFO | train_inner | epoch 004:    186 / 1474 loss=2.914, trans_loss=3.819, nll_loss=2.116, w2v_ctc_loss=1.639, task_loss=0.884, contrastive_loss=0.47, total=4177.87, n_correct=1939.31, ppl=4.34, accuracy=46.419, wps=13604.5, ups=1.09, wpb=12473.8, bsz=469, num_updates=4600, lr=0.000184008, gnorm=1.139, clip=0, loss_scale=1, train_wall=91, gb_free=15.2, wall=3838
2023-08-13 13:53:21 | INFO | train_inner | epoch 004:    286 / 1474 loss=2.909, trans_loss=3.809, nll_loss=2.105, w2v_ctc_loss=1.624, task_loss=0.929, contrastive_loss=0.583, total=4147.79, n_correct=1939.14, ppl=4.3, accuracy=46.751, wps=13232.1, ups=1.07, wpb=12391.1, bsz=464.6, num_updates=4700, lr=0.000188006, gnorm=1.136, clip=0, loss_scale=1, train_wall=93, gb_free=15.8, wall=3931
2023-08-13 13:54:54 | INFO | train_inner | epoch 004:    386 / 1474 loss=2.832, trans_loss=3.795, nll_loss=2.084, w2v_ctc_loss=1.604, task_loss=0.973, contrastive_loss=0.401, total=4120.11, n_correct=1956.82, ppl=4.24, accuracy=47.494, wps=13316.9, ups=1.08, wpb=12293.6, bsz=440.8, num_updates=4800, lr=0.000192004, gnorm=1.092, clip=0, loss_scale=1, train_wall=92, gb_free=17.2, wall=4024
2023-08-13 13:56:27 | INFO | train_inner | epoch 004:    486 / 1474 loss=2.871, trans_loss=3.769, nll_loss=2.052, w2v_ctc_loss=1.563, task_loss=0.833, contrastive_loss=0.789, total=4223.31, n_correct=2047.76, ppl=4.15, accuracy=48.487, wps=13495.8, ups=1.07, wpb=12605.5, bsz=500.9, num_updates=4900, lr=0.000196002, gnorm=1.086, clip=0, loss_scale=1, train_wall=93, gb_free=15.8, wall=4117
2023-08-13 13:57:59 | INFO | train_inner | epoch 004:    586 / 1474 loss=2.796, trans_loss=3.752, nll_loss=2.032, w2v_ctc_loss=1.577, task_loss=0.866, contrastive_loss=0.468, total=4228.66, n_correct=2081.53, ppl=4.09, accuracy=49.224, wps=13675.9, ups=1.08, wpb=12623.9, bsz=488.4, num_updates=5000, lr=0.0002, gnorm=1.091, clip=0, loss_scale=1, train_wall=92, gb_free=15.2, wall=4209
mt_weight tensor(0.5000)
asr_weight tensor(0.5437, device='cuda:0')
2023-08-13 13:59:34 | INFO | train_inner | epoch 004:    686 / 1474 loss=2.746, trans_loss=3.745, nll_loss=2.017, w2v_ctc_loss=1.545, task_loss=0.969, contrastive_loss=0.488, total=4172.53, n_correct=2075.77, ppl=4.05, accuracy=49.748, wps=13108.4, ups=1.05, wpb=12437.1, bsz=453.2, num_updates=5100, lr=0.00019803, gnorm=0.727, clip=0, loss_scale=1, train_wall=94, gb_free=16.9, wall=4304
2023-08-13 14:01:07 | INFO | train_inner | epoch 004:    786 / 1474 loss=2.707, trans_loss=3.725, nll_loss=1.997, w2v_ctc_loss=1.553, task_loss=1.026, contrastive_loss=0.355, total=4019.56, n_correct=2020.41, ppl=3.99, accuracy=50.264, wps=12988.4, ups=1.08, wpb=12004.8, bsz=419.9, num_updates=5200, lr=0.000196116, gnorm=0.729, clip=0, loss_scale=1, train_wall=92, gb_free=14.6, wall=4397
2023-08-13 14:02:40 | INFO | train_inner | epoch 004:    886 / 1474 loss=2.729, trans_loss=3.708, nll_loss=1.976, w2v_ctc_loss=1.538, task_loss=0.934, contrastive_loss=0.523, total=4183.92, n_correct=2127.12, ppl=3.93, accuracy=50.84, wps=13469.4, ups=1.08, wpb=12492.9, bsz=465.6, num_updates=5300, lr=0.000194257, gnorm=0.715, clip=0, loss_scale=1, train_wall=92, gb_free=17.4, wall=4489
2023-08-13 14:04:13 | INFO | train_inner | epoch 004:    986 / 1474 loss=2.667, trans_loss=3.691, nll_loss=1.955, w2v_ctc_loss=1.517, task_loss=0.95, contrastive_loss=0.391, total=4126.25, n_correct=2124.59, ppl=3.88, accuracy=51.49, wps=13223, ups=1.07, wpb=12324.7, bsz=455.9, num_updates=5400, lr=0.00019245, gnorm=0.695, clip=0, loss_scale=1, train_wall=93, gb_free=14.3, wall=4583
2023-08-13 14:05:46 | INFO | train_inner | epoch 004:   1086 / 1474 loss=2.652, trans_loss=3.69, nll_loss=1.952, w2v_ctc_loss=1.517, task_loss=0.985, contrastive_loss=0.363, total=4084.57, n_correct=2113.03, ppl=3.87, accuracy=51.732, wps=13093.1, ups=1.07, wpb=12192, bsz=441.2, num_updates=5500, lr=0.000190693, gnorm=0.692, clip=0, loss_scale=1, train_wall=93, gb_free=16.2, wall=4676
2023-08-13 14:07:19 | INFO | train_inner | epoch 004:   1186 / 1474 loss=2.658, trans_loss=3.68, nll_loss=1.941, w2v_ctc_loss=1.503, task_loss=0.873, contrastive_loss=0.463, total=4162.44, n_correct=2171.54, ppl=3.84, accuracy=52.17, wps=13372.9, ups=1.08, wpb=12433, bsz=482.7, num_updates=5600, lr=0.000188982, gnorm=0.685, clip=0, loss_scale=1, train_wall=92, gb_free=16.6, wall=4769
2023-08-13 14:08:51 | INFO | train_inner | epoch 004:   1286 / 1474 loss=2.621, trans_loss=3.661, nll_loss=1.917, w2v_ctc_loss=1.488, task_loss=0.895, contrastive_loss=0.419, total=4144.75, n_correct=2187.31, ppl=3.78, accuracy=52.773, wps=13450.7, ups=1.09, wpb=12378.7, bsz=470, num_updates=5700, lr=0.000187317, gnorm=0.674, clip=0, loss_scale=2, train_wall=91, gb_free=16.3, wall=4861
2023-08-13 14:10:22 | INFO | train_inner | epoch 004:   1386 / 1474 loss=2.569, trans_loss=3.651, nll_loss=1.904, w2v_ctc_loss=1.477, task_loss=0.954, contrastive_loss=0.295, total=4107.86, n_correct=2182.52, ppl=3.74, accuracy=53.13, wps=13439.5, ups=1.1, wpb=12268.5, bsz=439.2, num_updates=5800, lr=0.000185695, gnorm=0.654, clip=0, loss_scale=2, train_wall=91, gb_free=16.9, wall=4952
2023-08-13 14:11:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.5437, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.5437, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.5437, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.5437, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.5437, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.5437, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.5437, device='cuda:1')
2023-08-13 14:12:09 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.429 | trans_loss 5.642 | nll_loss 3.024 | w2v_ctc_loss 1.623 | task_loss 4.427 | contrastive_loss 0.46 | total 4003.4 | n_correct 2364.7 | ppl 8.14 | accuracy 59.067 | uer 24.694 | wer 26.192 | raw_wer 26.192 | bleu 16.14 | wps 1929 | wpb 4003.4 | bsz 141.8 | num_updates 5888 | best_bleu 16.14
2023-08-13 14:12:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5888 updates
2023-08-13 14:12:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 14:12:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 14:12:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 4 @ 5888 updates, score 16.14) (writing took 28.549359418451786 seconds)
2023-08-13 14:12:37 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-13 14:12:37 | INFO | train | epoch 004 | loss 2.745 | trans_loss 3.733 | nll_loss 2.007 | w2v_ctc_loss 1.55 | task_loss 0.931 | contrastive_loss 0.457 | total 4138.65 | n_correct 2066.62 | ppl 4.02 | accuracy 49.935 | wps 12760.8 | ups 1.03 | wpb 12355.8 | bsz 458.5 | num_updates 5888 | lr 0.000184302 | gnorm 0.862 | clip 0 | loss_scale 2 | train_wall 1358 | gb_free 14.5 | wall 5087
2023-08-13 14:12:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 14:12:38 | INFO | fairseq.trainer | begin training epoch 5
2023-08-13 14:12:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 14:12:56 | INFO | train_inner | epoch 005:     12 / 1474 loss=2.548, trans_loss=3.644, nll_loss=1.893, w2v_ctc_loss=1.45, task_loss=0.976, contrastive_loss=0.308, total=4036.09, n_correct=2158.64, ppl=3.71, accuracy=53.483, wps=7808.7, ups=0.65, wpb=12049.9, bsz=436.9, num_updates=5900, lr=0.000184115, gnorm=0.664, clip=0, loss_scale=2, train_wall=91, gb_free=11.3, wall=5106
2023-08-13 14:14:29 | INFO | train_inner | epoch 005:    112 / 1474 loss=2.478, trans_loss=3.605, nll_loss=1.843, w2v_ctc_loss=1.372, task_loss=0.832, contrastive_loss=0.323, total=4256.69, n_correct=2339.2, ppl=3.59, accuracy=54.953, wps=13690.9, ups=1.08, wpb=12710.6, bsz=500.9, num_updates=6000, lr=0.000182574, gnorm=0.619, clip=0, loss_scale=2, train_wall=92, gb_free=17.1, wall=5199
2023-08-13 14:14:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 14:14:53 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.409 | trans_loss 5.621 | nll_loss 2.994 | w2v_ctc_loss 1.613 | task_loss 4.452 | contrastive_loss 0.448 | total 4003.4 | n_correct 2376.6 | ppl 7.97 | accuracy 59.365 | uer 24.394 | wer 25.823 | raw_wer 25.823 | bleu 16.65 | wps 2188.2 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 16.65
2023-08-13 14:14:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-08-13 14:14:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-08-13 14:14:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-08-13 14:15:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 16.65) (writing took 56.27874310873449 seconds)
2023-08-13 14:17:22 | INFO | train_inner | epoch 005:    212 / 1474 loss=2.516, trans_loss=3.61, nll_loss=1.848, w2v_ctc_loss=1.387, task_loss=0.868, contrastive_loss=0.515, total=4186.1, n_correct=2296.5, ppl=3.6, accuracy=54.86, wps=7222.8, ups=0.58, wpb=12490.5, bsz=484.8, num_updates=6100, lr=0.000181071, gnorm=0.628, clip=0, loss_scale=2, train_wall=92, gb_free=14.4, wall=5372
2023-08-13 14:18:54 | INFO | train_inner | epoch 005:    312 / 1474 loss=2.488, trans_loss=3.598, nll_loss=1.838, w2v_ctc_loss=1.398, task_loss=0.95, contrastive_loss=0.369, total=4098.24, n_correct=2243.97, ppl=3.58, accuracy=54.754, wps=13388, ups=1.09, wpb=12253.4, bsz=447.9, num_updates=6200, lr=0.000179605, gnorm=0.632, clip=0, loss_scale=2, train_wall=91, gb_free=16, wall=5464
2023-08-13 14:20:27 | INFO | train_inner | epoch 005:    412 / 1474 loss=2.481, trans_loss=3.588, nll_loss=1.825, w2v_ctc_loss=1.368, task_loss=0.918, contrastive_loss=0.446, total=4138.6, n_correct=2290.86, ppl=3.54, accuracy=55.354, wps=13223.2, ups=1.07, wpb=12367.6, bsz=466.6, num_updates=6300, lr=0.000178174, gnorm=0.627, clip=0, loss_scale=2, train_wall=93, gb_free=12.6, wall=5557
2023-08-13 14:22:00 | INFO | train_inner | epoch 005:    512 / 1474 loss=2.427, trans_loss=3.592, nll_loss=1.828, w2v_ctc_loss=1.372, task_loss=1.041, contrastive_loss=0.24, total=4018.65, n_correct=2222.04, ppl=3.55, accuracy=55.293, wps=12982, ups=1.08, wpb=12005.2, bsz=417.4, num_updates=6400, lr=0.000176777, gnorm=0.614, clip=0, loss_scale=2, train_wall=92, gb_free=16.4, wall=5650
2023-08-13 14:23:32 | INFO | train_inner | epoch 005:    612 / 1474 loss=2.455, trans_loss=3.596, nll_loss=1.83, w2v_ctc_loss=1.359, task_loss=0.958, contrastive_loss=0.406, total=4121.58, n_correct=2282.96, ppl=3.56, accuracy=55.39, wps=13279.9, ups=1.08, wpb=12295, bsz=451, num_updates=6500, lr=0.000175412, gnorm=0.632, clip=0, loss_scale=2, train_wall=92, gb_free=16.2, wall=5742
2023-08-13 14:25:05 | INFO | train_inner | epoch 005:    712 / 1474 loss=2.47, trans_loss=3.594, nll_loss=1.83, w2v_ctc_loss=1.374, task_loss=0.88, contrastive_loss=0.389, total=4169.57, n_correct=2315.93, ppl=3.56, accuracy=55.544, wps=13368.8, ups=1.07, wpb=12447.3, bsz=482.2, num_updates=6600, lr=0.000174078, gnorm=0.755, clip=0, loss_scale=2, train_wall=93, gb_free=16.8, wall=5835
2023-08-13 14:26:39 | INFO | train_inner | epoch 005:    812 / 1474 loss=2.422, trans_loss=3.579, nll_loss=1.81, w2v_ctc_loss=1.352, task_loss=0.96, contrastive_loss=0.311, total=4123.32, n_correct=2304.93, ppl=3.51, accuracy=55.9, wps=13184.4, ups=1.07, wpb=12307, bsz=448.5, num_updates=6700, lr=0.000172774, gnorm=0.606, clip=0, loss_scale=2, train_wall=93, gb_free=17.4, wall=5929
2023-08-13 14:28:11 | INFO | train_inner | epoch 005:    912 / 1474 loss=2.391, trans_loss=3.568, nll_loss=1.797, w2v_ctc_loss=1.338, task_loss=0.956, contrastive_loss=0.27, total=4109.54, n_correct=2317.13, ppl=3.48, accuracy=56.384, wps=13247.4, ups=1.08, wpb=12270.4, bsz=449.3, num_updates=6800, lr=0.000171499, gnorm=0.606, clip=0, loss_scale=2, train_wall=92, gb_free=16.1, wall=6021
2023-08-13 14:29:43 | INFO | train_inner | epoch 005:   1012 / 1474 loss=2.408, trans_loss=3.575, nll_loss=1.805, w2v_ctc_loss=1.343, task_loss=0.933, contrastive_loss=0.344, total=4157.73, n_correct=2337.84, ppl=3.5, accuracy=56.229, wps=13514.3, ups=1.09, wpb=12411.9, bsz=458.8, num_updates=6900, lr=0.000170251, gnorm=0.595, clip=0, loss_scale=2, train_wall=91, gb_free=17.1, wall=6113
2023-08-13 14:31:17 | INFO | train_inner | epoch 005:   1112 / 1474 loss=2.422, trans_loss=3.569, nll_loss=1.796, w2v_ctc_loss=1.351, task_loss=0.924, contrastive_loss=0.351, total=4172.61, n_correct=2357.76, ppl=3.47, accuracy=56.506, wps=13277.1, ups=1.07, wpb=12446.4, bsz=466.7, num_updates=7000, lr=0.000169031, gnorm=0.604, clip=0, loss_scale=2, train_wall=93, gb_free=13.2, wall=6207
2023-08-13 14:32:51 | INFO | train_inner | epoch 005:   1212 / 1474 loss=2.37, trans_loss=3.562, nll_loss=1.787, w2v_ctc_loss=1.324, task_loss=0.949, contrastive_loss=0.25, total=4166.97, n_correct=2365.01, ppl=3.45, accuracy=56.756, wps=13298.1, ups=1.07, wpb=12430.2, bsz=454.5, num_updates=7100, lr=0.000167836, gnorm=0.606, clip=0, loss_scale=2, train_wall=93, gb_free=16.7, wall=6300
2023-08-13 14:34:24 | INFO | train_inner | epoch 005:   1312 / 1474 loss=2.346, trans_loss=3.558, nll_loss=1.783, w2v_ctc_loss=1.31, task_loss=0.95, contrastive_loss=0.216, total=4132.22, n_correct=2351.3, ppl=3.44, accuracy=56.902, wps=13237.7, ups=1.07, wpb=12332.7, bsz=445.1, num_updates=7200, lr=0.000166667, gnorm=0.58, clip=0, loss_scale=2, train_wall=93, gb_free=16.3, wall=6394
2023-08-13 14:35:57 | INFO | train_inner | epoch 005:   1412 / 1474 loss=2.358, trans_loss=3.555, nll_loss=1.782, w2v_ctc_loss=1.307, task_loss=0.944, contrastive_loss=0.277, total=4135.72, n_correct=2360.15, ppl=3.44, accuracy=57.067, wps=13308.6, ups=1.08, wpb=12352.5, bsz=457.5, num_updates=7300, lr=0.000165521, gnorm=0.589, clip=0, loss_scale=2, train_wall=92, gb_free=15.9, wall=6486
2023-08-13 14:36:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 14:37:17 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.264 | trans_loss 5.468 | nll_loss 2.81 | w2v_ctc_loss 1.531 | task_loss 4.465 | contrastive_loss 0.413 | total 4003.4 | n_correct 2471.1 | ppl 7.01 | accuracy 61.725 | uer 23.062 | wer 24.727 | raw_wer 24.727 | bleu 18.2 | wps 2210.4 | wpb 4003.4 | bsz 141.8 | num_updates 7362 | best_bleu 18.2
2023-08-13 14:37:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7362 updates
2023-08-13 14:37:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 14:37:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 14:37:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 5 @ 7362 updates, score 18.2) (writing took 29.82232093438506 seconds)
2023-08-13 14:37:47 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-13 14:37:47 | INFO | train | epoch 005 | loss 2.429 | trans_loss 3.581 | nll_loss 1.813 | w2v_ctc_loss 1.353 | task_loss 0.932 | contrastive_loss 0.336 | total 4138.65 | n_correct 2313.2 | ppl 3.51 | accuracy 55.893 | wps 12064.3 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 7362 | lr 0.000164823 | gnorm 0.621 | clip 0 | loss_scale 2 | train_wall 1360 | gb_free 16 | wall 6597
2023-08-13 14:37:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 14:37:47 | INFO | fairseq.trainer | begin training epoch 6
2023-08-13 14:37:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 14:38:30 | INFO | train_inner | epoch 006:     38 / 1474 loss=2.344, trans_loss=3.54, nll_loss=1.76, w2v_ctc_loss=1.302, task_loss=0.96, contrastive_loss=0.272, total=4115.39, n_correct=2363.41, ppl=3.39, accuracy=57.429, wps=7977.6, ups=0.65, wpb=12279.5, bsz=446.7, num_updates=7400, lr=0.000164399, gnorm=0.596, clip=0, loss_scale=2, train_wall=92, gb_free=16.6, wall=6640
2023-08-13 14:40:03 | INFO | train_inner | epoch 006:    138 / 1474 loss=2.294, trans_loss=3.512, nll_loss=1.726, w2v_ctc_loss=1.244, task_loss=0.924, contrastive_loss=0.311, total=4157.06, n_correct=2418.28, ppl=3.31, accuracy=58.173, wps=13443.5, ups=1.08, wpb=12417.1, bsz=457.8, num_updates=7500, lr=0.000163299, gnorm=0.577, clip=0, loss_scale=2, train_wall=92, gb_free=17.5, wall=6733
2023-08-13 14:41:35 | INFO | train_inner | epoch 006:    238 / 1474 loss=2.303, trans_loss=3.524, nll_loss=1.742, w2v_ctc_loss=1.282, task_loss=0.991, contrastive_loss=0.222, total=4115.6, n_correct=2380.46, ppl=3.35, accuracy=57.84, wps=13298.8, ups=1.08, wpb=12295.8, bsz=440.7, num_updates=7600, lr=0.000162221, gnorm=0.577, clip=0, loss_scale=2, train_wall=92, gb_free=16.6, wall=6825
2023-08-13 14:43:09 | INFO | train_inner | epoch 006:    338 / 1474 loss=2.331, trans_loss=3.513, nll_loss=1.727, w2v_ctc_loss=1.23, task_loss=0.885, contrastive_loss=0.519, total=4163.86, n_correct=2424.38, ppl=3.31, accuracy=58.224, wps=13238.6, ups=1.06, wpb=12432.8, bsz=484.8, num_updates=7700, lr=0.000161165, gnorm=0.584, clip=0, loss_scale=2, train_wall=93, gb_free=15.8, wall=6919
2023-08-13 14:44:41 | INFO | train_inner | epoch 006:    438 / 1474 loss=2.265, trans_loss=3.508, nll_loss=1.721, w2v_ctc_loss=1.238, task_loss=0.89, contrastive_loss=0.23, total=4156.74, n_correct=2436.14, ppl=3.3, accuracy=58.607, wps=13525.1, ups=1.09, wpb=12410.9, bsz=471.8, num_updates=7800, lr=0.000160128, gnorm=0.572, clip=0, loss_scale=4, train_wall=91, gb_free=15.1, wall=7011
2023-08-13 14:46:14 | INFO | train_inner | epoch 006:    538 / 1474 loss=2.271, trans_loss=3.512, nll_loss=1.725, w2v_ctc_loss=1.252, task_loss=0.938, contrastive_loss=0.22, total=4173.1, n_correct=2444.79, ppl=3.31, accuracy=58.585, wps=13407.7, ups=1.08, wpb=12456.1, bsz=456.3, num_updates=7900, lr=0.000159111, gnorm=0.575, clip=0, loss_scale=4, train_wall=92, gb_free=15.6, wall=7104
2023-08-13 14:47:46 | INFO | train_inner | epoch 006:    638 / 1474 loss=2.272, trans_loss=3.512, nll_loss=1.726, w2v_ctc_loss=1.233, task_loss=0.886, contrastive_loss=0.276, total=4147.23, n_correct=2425, ppl=3.31, accuracy=58.473, wps=13466.4, ups=1.09, wpb=12379.1, bsz=471.9, num_updates=8000, lr=0.000158114, gnorm=0.604, clip=0, loss_scale=4, train_wall=91, gb_free=12.2, wall=7196
2023-08-13 14:47:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 14:48:09 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.208 | trans_loss 5.421 | nll_loss 2.75 | w2v_ctc_loss 1.48 | task_loss 4.523 | contrastive_loss 0.382 | total 4003.4 | n_correct 2489.9 | ppl 6.73 | accuracy 62.195 | uer 22.462 | wer 24.224 | raw_wer 24.224 | bleu 18.59 | wps 2190.6 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 18.59
2023-08-13 14:48:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-08-13 14:48:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-08-13 14:48:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-08-13 14:49:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 18.59) (writing took 54.40269006974995 seconds)
2023-08-13 14:49:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-13 14:50:38 | INFO | train_inner | epoch 006:    739 / 1474 loss=2.279, trans_loss=3.519, nll_loss=1.735, w2v_ctc_loss=1.255, task_loss=0.959, contrastive_loss=0.231, total=4139.56, n_correct=2412.9, ppl=3.33, accuracy=58.289, wps=7162.5, ups=0.58, wpb=12359, bsz=450.9, num_updates=8100, lr=0.000157135, gnorm=0.634, clip=0, loss_scale=2, train_wall=94, gb_free=16.5, wall=7368
2023-08-13 14:52:11 | INFO | train_inner | epoch 006:    839 / 1474 loss=2.256, trans_loss=3.512, nll_loss=1.726, w2v_ctc_loss=1.24, task_loss=0.964, contrastive_loss=0.206, total=4134.7, n_correct=2420.95, ppl=3.31, accuracy=58.552, wps=13377.3, ups=1.08, wpb=12344.1, bsz=447.8, num_updates=8200, lr=0.000156174, gnorm=0.568, clip=0, loss_scale=2, train_wall=92, gb_free=14.4, wall=7460
2023-08-13 14:53:44 | INFO | train_inner | epoch 006:    939 / 1474 loss=2.287, trans_loss=3.516, nll_loss=1.73, w2v_ctc_loss=1.251, task_loss=0.995, contrastive_loss=0.304, total=4074.92, n_correct=2381.95, ppl=3.32, accuracy=58.454, wps=13030, ups=1.07, wpb=12163, bsz=439.9, num_updates=8300, lr=0.00015523, gnorm=0.577, clip=0, loss_scale=2, train_wall=93, gb_free=16.3, wall=7554
2023-08-13 14:55:16 | INFO | train_inner | epoch 006:   1039 / 1474 loss=2.279, trans_loss=3.502, nll_loss=1.713, w2v_ctc_loss=1.224, task_loss=0.878, contrastive_loss=0.375, total=4167.38, n_correct=2455.41, ppl=3.28, accuracy=58.92, wps=13484.3, ups=1.08, wpb=12438.7, bsz=478.3, num_updates=8400, lr=0.000154303, gnorm=0.58, clip=0, loss_scale=2, train_wall=92, gb_free=16, wall=7646
2023-08-13 14:56:49 | INFO | train_inner | epoch 006:   1139 / 1474 loss=2.248, trans_loss=3.5, nll_loss=1.711, w2v_ctc_loss=1.237, task_loss=1.035, contrastive_loss=0.207, total=4066.48, n_correct=2393.96, ppl=3.27, accuracy=58.871, wps=13106, ups=1.08, wpb=12140, bsz=428.3, num_updates=8500, lr=0.000153393, gnorm=0.571, clip=0, loss_scale=2, train_wall=92, gb_free=15.6, wall=7739
2023-08-13 14:58:22 | INFO | train_inner | epoch 006:   1239 / 1474 loss=2.3, trans_loss=3.493, nll_loss=1.705, w2v_ctc_loss=1.218, task_loss=0.915, contrastive_loss=0.522, total=4143.59, n_correct=2445.65, ppl=3.26, accuracy=59.022, wps=13265.5, ups=1.07, wpb=12377.1, bsz=471.5, num_updates=8600, lr=0.000152499, gnorm=0.581, clip=0, loss_scale=2, train_wall=93, gb_free=16.9, wall=7832
2023-08-13 14:59:54 | INFO | train_inner | epoch 006:   1339 / 1474 loss=2.221, trans_loss=3.495, nll_loss=1.703, w2v_ctc_loss=1.217, task_loss=0.923, contrastive_loss=0.189, total=4125.75, n_correct=2448.45, ppl=3.26, accuracy=59.346, wps=13359.4, ups=1.09, wpb=12308.4, bsz=454.4, num_updates=8700, lr=0.00015162, gnorm=0.563, clip=0, loss_scale=2, train_wall=92, gb_free=15.9, wall=7924
2023-08-13 15:01:27 | INFO | train_inner | epoch 006:   1439 / 1474 loss=2.22, trans_loss=3.489, nll_loss=1.697, w2v_ctc_loss=1.215, task_loss=0.933, contrastive_loss=0.195, total=4194.06, n_correct=2492.61, ppl=3.24, accuracy=59.432, wps=13494.9, ups=1.08, wpb=12518.6, bsz=462, num_updates=8800, lr=0.000150756, gnorm=0.553, clip=0, loss_scale=2, train_wall=92, gb_free=16, wall=8017
2023-08-13 15:01:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 15:02:23 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.148 | trans_loss 5.366 | nll_loss 2.686 | w2v_ctc_loss 1.416 | task_loss 4.55 | contrastive_loss 0.372 | total 4003.4 | n_correct 2521.6 | ppl 6.44 | accuracy 62.986 | uer 21.315 | wer 23.075 | raw_wer 23.075 | bleu 19.37 | wps 2166.5 | wpb 4003.4 | bsz 141.8 | num_updates 8835 | best_bleu 19.37
2023-08-13 15:02:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8835 updates
2023-08-13 15:02:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 15:02:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 15:02:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 6 @ 8835 updates, score 19.37) (writing took 30.758768199011683 seconds)
2023-08-13 15:02:54 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-13 15:02:54 | INFO | train | epoch 006 | loss 2.272 | trans_loss 3.508 | nll_loss 1.72 | w2v_ctc_loss 1.238 | task_loss 0.934 | contrastive_loss 0.285 | total 4138.69 | n_correct 2426.83 | ppl 3.3 | accuracy 58.638 | wps 12078.5 | ups 0.98 | wpb 12356 | bsz 458.5 | num_updates 8835 | lr 0.000150457 | gnorm 0.579 | clip 0 | loss_scale 2 | train_wall 1359 | gb_free 14.7 | wall 8104
2023-08-13 15:02:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 15:02:54 | INFO | fairseq.trainer | begin training epoch 7
2023-08-13 15:02:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 15:04:02 | INFO | train_inner | epoch 007:     65 / 1474 loss=2.192, trans_loss=3.476, nll_loss=1.68, w2v_ctc_loss=1.186, task_loss=0.915, contrastive_loss=0.208, total=4103.49, n_correct=2456.69, ppl=3.2, accuracy=59.868, wps=7913.8, ups=0.65, wpb=12251.2, bsz=461.5, num_updates=8900, lr=0.000149906, gnorm=0.558, clip=0, loss_scale=2, train_wall=92, gb_free=16.7, wall=8172
2023-08-13 15:05:34 | INFO | train_inner | epoch 007:    165 / 1474 loss=2.194, trans_loss=3.468, nll_loss=1.67, w2v_ctc_loss=1.172, task_loss=0.945, contrastive_loss=0.282, total=4110.42, n_correct=2468.58, ppl=3.18, accuracy=60.057, wps=13334.2, ups=1.09, wpb=12272.5, bsz=455.4, num_updates=9000, lr=0.000149071, gnorm=0.555, clip=0, loss_scale=2, train_wall=92, gb_free=16.1, wall=8264
2023-08-13 15:07:06 | INFO | train_inner | epoch 007:    265 / 1474 loss=2.173, trans_loss=3.464, nll_loss=1.664, w2v_ctc_loss=1.175, task_loss=0.939, contrastive_loss=0.187, total=4130.95, n_correct=2485.11, ppl=3.17, accuracy=60.158, wps=13355.9, ups=1.08, wpb=12328.4, bsz=454.4, num_updates=9100, lr=0.00014825, gnorm=0.583, clip=0, loss_scale=2, train_wall=92, gb_free=17.3, wall=8356
2023-08-13 15:08:39 | INFO | train_inner | epoch 007:    365 / 1474 loss=2.224, trans_loss=3.469, nll_loss=1.67, w2v_ctc_loss=1.168, task_loss=0.899, contrastive_loss=0.446, total=4204.16, n_correct=2523.39, ppl=3.18, accuracy=60.021, wps=13508.5, ups=1.08, wpb=12547.1, bsz=481.5, num_updates=9200, lr=0.000147442, gnorm=0.564, clip=0, loss_scale=2, train_wall=92, gb_free=16.8, wall=8449
2023-08-13 15:10:11 | INFO | train_inner | epoch 007:    465 / 1474 loss=2.2, trans_loss=3.467, nll_loss=1.669, w2v_ctc_loss=1.16, task_loss=0.933, contrastive_loss=0.367, total=4147.32, n_correct=2492.13, ppl=3.18, accuracy=60.09, wps=13419.6, ups=1.08, wpb=12384.6, bsz=458.5, num_updates=9300, lr=0.000146647, gnorm=0.556, clip=0, loss_scale=2, train_wall=92, gb_free=17.6, wall=8541
2023-08-13 15:11:43 | INFO | train_inner | epoch 007:    565 / 1474 loss=2.166, trans_loss=3.464, nll_loss=1.662, w2v_ctc_loss=1.166, task_loss=0.914, contrastive_loss=0.194, total=4171.72, n_correct=2519.33, ppl=3.16, accuracy=60.391, wps=13525.5, ups=1.09, wpb=12445.8, bsz=460.5, num_updates=9400, lr=0.000145865, gnorm=0.548, clip=0, loss_scale=2, train_wall=92, gb_free=15.5, wall=8633
2023-08-13 15:13:16 | INFO | train_inner | epoch 007:    665 / 1474 loss=2.154, trans_loss=3.46, nll_loss=1.659, w2v_ctc_loss=1.157, task_loss=0.931, contrastive_loss=0.18, total=4150.49, n_correct=2513.44, ppl=3.16, accuracy=60.558, wps=13340.8, ups=1.08, wpb=12385.7, bsz=454.7, num_updates=9500, lr=0.000145095, gnorm=0.546, clip=0, loss_scale=2, train_wall=92, gb_free=16.1, wall=8726
2023-08-13 15:14:49 | INFO | train_inner | epoch 007:    765 / 1474 loss=2.152, trans_loss=3.453, nll_loss=1.651, w2v_ctc_loss=1.159, task_loss=0.968, contrastive_loss=0.176, total=4132.17, n_correct=2500.16, ppl=3.14, accuracy=60.505, wps=13318.7, ups=1.08, wpb=12338.5, bsz=450.8, num_updates=9600, lr=0.000144338, gnorm=0.545, clip=0, loss_scale=2, train_wall=92, gb_free=15.9, wall=8819
2023-08-13 15:16:22 | INFO | train_inner | epoch 007:    865 / 1474 loss=2.157, trans_loss=3.464, nll_loss=1.663, w2v_ctc_loss=1.157, task_loss=0.946, contrastive_loss=0.193, total=4140.18, n_correct=2499.82, ppl=3.17, accuracy=60.38, wps=13349, ups=1.08, wpb=12352.6, bsz=457.8, num_updates=9700, lr=0.000143592, gnorm=0.552, clip=0, loss_scale=2, train_wall=92, gb_free=15.3, wall=8911
2023-08-13 15:17:54 | INFO | train_inner | epoch 007:    965 / 1474 loss=2.167, trans_loss=3.453, nll_loss=1.651, w2v_ctc_loss=1.145, task_loss=0.893, contrastive_loss=0.288, total=4144.65, n_correct=2512.97, ppl=3.14, accuracy=60.632, wps=13346.6, ups=1.08, wpb=12374.9, bsz=475.4, num_updates=9800, lr=0.000142857, gnorm=0.556, clip=0, loss_scale=2, train_wall=92, gb_free=14.8, wall=9004
2023-08-13 15:19:27 | INFO | train_inner | epoch 007:   1065 / 1474 loss=2.148, trans_loss=3.463, nll_loss=1.665, w2v_ctc_loss=1.161, task_loss=0.981, contrastive_loss=0.16, total=4097.24, n_correct=2475.48, ppl=3.17, accuracy=60.418, wps=13184.6, ups=1.08, wpb=12232.2, bsz=435.9, num_updates=9900, lr=0.000142134, gnorm=0.549, clip=0, loss_scale=2, train_wall=92, gb_free=15.7, wall=9097
2023-08-13 15:21:00 | INFO | train_inner | epoch 007:   1165 / 1474 loss=2.202, trans_loss=3.449, nll_loss=1.648, w2v_ctc_loss=1.148, task_loss=0.909, contrastive_loss=0.428, total=4142.16, n_correct=2511.82, ppl=3.13, accuracy=60.64, wps=13371.3, ups=1.08, wpb=12377.5, bsz=471.9, num_updates=10000, lr=0.000141421, gnorm=0.566, clip=0, loss_scale=2, train_wall=92, gb_free=15, wall=9189
2023-08-13 15:21:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 15:21:24 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.082 | trans_loss 5.316 | nll_loss 2.623 | w2v_ctc_loss 1.33 | task_loss 4.597 | contrastive_loss 0.355 | total 4003.4 | n_correct 2558.2 | ppl 6.16 | accuracy 63.901 | uer 19.481 | wer 21.312 | raw_wer 21.312 | bleu 19.72 | wps 2141.2 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 19.72
2023-08-13 15:21:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-08-13 15:21:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-08-13 15:21:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-08-13 15:22:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 19.72) (writing took 49.122920570895076 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:0')
2023-08-13 15:23:45 | INFO | train_inner | epoch 007:   1265 / 1474 loss=2.138, trans_loss=3.451, nll_loss=1.65, w2v_ctc_loss=1.145, task_loss=0.957, contrastive_loss=0.186, total=4119.52, n_correct=2502.59, ppl=3.14, accuracy=60.75, wps=7430.4, ups=0.6, wpb=12302.1, bsz=446.6, num_updates=10100, lr=0.00014072, gnorm=0.431, clip=0, loss_scale=4, train_wall=91, gb_free=13.5, wall=9355
2023-08-13 15:25:17 | INFO | train_inner | epoch 007:   1365 / 1474 loss=2.152, trans_loss=3.446, nll_loss=1.643, w2v_ctc_loss=1.15, task_loss=0.868, contrastive_loss=0.223, total=4185.65, n_correct=2549.55, ppl=3.12, accuracy=60.912, wps=13594.9, ups=1.09, wpb=12496.2, bsz=480.7, num_updates=10200, lr=0.000140028, gnorm=0.431, clip=0, loss_scale=4, train_wall=91, gb_free=16.6, wall=9447
2023-08-13 15:26:52 | INFO | train_inner | epoch 007:   1465 / 1474 loss=2.165, trans_loss=3.45, nll_loss=1.65, w2v_ctc_loss=1.151, task_loss=0.998, contrastive_loss=0.288, total=4113.9, n_correct=2495.29, ppl=3.14, accuracy=60.655, wps=12990.3, ups=1.06, wpb=12290.7, bsz=446.9, num_updates=10300, lr=0.000139347, gnorm=0.436, clip=0, loss_scale=4, train_wall=94, gb_free=16.2, wall=9542
2023-08-13 15:27:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:2')
2023-08-13 15:27:23 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.095 | trans_loss 5.305 | nll_loss 2.606 | w2v_ctc_loss 1.405 | task_loss 4.585 | contrastive_loss 0.347 | total 4003.4 | n_correct 2568.3 | ppl 6.09 | accuracy 64.153 | uer 20.596 | wer 22.497 | raw_wer 22.497 | bleu 20.35 | wps 2154.3 | wpb 4003.4 | bsz 141.8 | num_updates 10309 | best_bleu 20.35
2023-08-13 15:27:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10309 updates
2023-08-13 15:27:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 15:27:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 15:27:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 7 @ 10309 updates, score 20.35) (writing took 31.33151752129197 seconds)
2023-08-13 15:27:55 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-13 15:27:55 | INFO | train | epoch 007 | loss 2.171 | trans_loss 3.459 | nll_loss 1.659 | w2v_ctc_loss 1.159 | task_loss 0.935 | contrastive_loss 0.255 | total 4138.65 | n_correct 2500.61 | ppl 3.16 | accuracy 60.421 | wps 12133.8 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 10309 | lr 0.000139286 | gnorm 0.53 | clip 0 | loss_scale 4 | train_wall 1357 | gb_free 12.8 | wall 9605
2023-08-13 15:27:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 15:27:55 | INFO | fairseq.trainer | begin training epoch 8
2023-08-13 15:27:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 15:29:27 | INFO | train_inner | epoch 008:     91 / 1474 loss=2.109, trans_loss=3.439, nll_loss=1.63, w2v_ctc_loss=1.118, task_loss=1.007, contrastive_loss=0.178, total=4095.89, n_correct=2510.69, ppl=3.1, accuracy=61.298, wps=7863.5, ups=0.64, wpb=12213.1, bsz=435.6, num_updates=10400, lr=0.000138675, gnorm=0.429, clip=0, loss_scale=4, train_wall=92, gb_free=17.5, wall=9697
2023-08-13 15:30:59 | INFO | train_inner | epoch 008:    191 / 1474 loss=2.106, trans_loss=3.43, nll_loss=1.618, w2v_ctc_loss=1.11, task_loss=1.015, contrastive_loss=0.202, total=4040.13, n_correct=2484.8, ppl=3.07, accuracy=61.503, wps=13126, ups=1.09, wpb=12049.1, bsz=429, num_updates=10500, lr=0.000138013, gnorm=0.435, clip=0, loss_scale=4, train_wall=91, gb_free=15.8, wall=9789
2023-08-13 15:32:31 | INFO | train_inner | epoch 008:    291 / 1474 loss=2.103, trans_loss=3.424, nll_loss=1.613, w2v_ctc_loss=1.11, task_loss=0.875, contrastive_loss=0.197, total=4216.54, n_correct=2596.46, ppl=3.06, accuracy=61.578, wps=13648.8, ups=1.08, wpb=12583.3, bsz=489.6, num_updates=10600, lr=0.000137361, gnorm=0.429, clip=0, loss_scale=4, train_wall=92, gb_free=15.7, wall=9881
2023-08-13 15:34:04 | INFO | train_inner | epoch 008:    391 / 1474 loss=2.116, trans_loss=3.428, nll_loss=1.617, w2v_ctc_loss=1.12, task_loss=0.979, contrastive_loss=0.22, total=4134.8, n_correct=2541.21, ppl=3.07, accuracy=61.459, wps=13229.8, ups=1.07, wpb=12337.2, bsz=446.1, num_updates=10700, lr=0.000136717, gnorm=0.429, clip=0, loss_scale=4, train_wall=93, gb_free=16.1, wall=9974
2023-08-13 15:35:37 | INFO | train_inner | epoch 008:    491 / 1474 loss=2.17, trans_loss=3.426, nll_loss=1.617, w2v_ctc_loss=1.102, task_loss=0.846, contrastive_loss=0.482, total=4193.98, n_correct=2578.29, ppl=3.07, accuracy=61.476, wps=13469.7, ups=1.08, wpb=12521.7, bsz=500.7, num_updates=10800, lr=0.000136083, gnorm=0.43, clip=0, loss_scale=4, train_wall=92, gb_free=17.4, wall=10067
2023-08-13 15:37:10 | INFO | train_inner | epoch 008:    591 / 1474 loss=2.106, trans_loss=3.425, nll_loss=1.618, w2v_ctc_loss=1.128, task_loss=1.023, contrastive_loss=0.155, total=4063.58, n_correct=2494.75, ppl=3.07, accuracy=61.393, wps=13135.5, ups=1.08, wpb=12147.8, bsz=426.8, num_updates=10900, lr=0.000135457, gnorm=0.429, clip=0, loss_scale=4, train_wall=92, gb_free=12.1, wall=10160
2023-08-13 15:38:43 | INFO | train_inner | epoch 008:    691 / 1474 loss=2.096, trans_loss=3.42, nll_loss=1.609, w2v_ctc_loss=1.117, task_loss=0.956, contrastive_loss=0.166, total=4138.77, n_correct=2558.56, ppl=3.05, accuracy=61.819, wps=13303.2, ups=1.08, wpb=12354.5, bsz=450.4, num_updates=11000, lr=0.00013484, gnorm=0.424, clip=0, loss_scale=4, train_wall=92, gb_free=16.2, wall=10252
2023-08-13 15:40:15 | INFO | train_inner | epoch 008:    791 / 1474 loss=2.105, trans_loss=3.415, nll_loss=1.606, w2v_ctc_loss=1.109, task_loss=0.957, contrastive_loss=0.249, total=4122.32, n_correct=2545.27, ppl=3.04, accuracy=61.744, wps=13335.7, ups=1.08, wpb=12319.9, bsz=449, num_updates=11100, lr=0.000134231, gnorm=0.426, clip=0, loss_scale=4, train_wall=92, gb_free=17.1, wall=10345
2023-08-13 15:41:47 | INFO | train_inner | epoch 008:    891 / 1474 loss=2.104, trans_loss=3.421, nll_loss=1.612, w2v_ctc_loss=1.094, task_loss=0.89, contrastive_loss=0.258, total=4180.85, n_correct=2584.42, ppl=3.06, accuracy=61.816, wps=13530.5, ups=1.08, wpb=12485.3, bsz=477, num_updates=11200, lr=0.000133631, gnorm=0.422, clip=0, loss_scale=4, train_wall=92, gb_free=15.3, wall=10437
2023-08-13 15:43:19 | INFO | train_inner | epoch 008:    991 / 1474 loss=2.078, trans_loss=3.419, nll_loss=1.608, w2v_ctc_loss=1.099, task_loss=0.906, contrastive_loss=0.158, total=4145.35, n_correct=2567.34, ppl=3.05, accuracy=61.933, wps=13448.1, ups=1.09, wpb=12377.4, bsz=460.4, num_updates=11300, lr=0.000133038, gnorm=0.417, clip=0, loss_scale=4, train_wall=92, gb_free=16.2, wall=10529
2023-08-13 15:44:52 | INFO | train_inner | epoch 008:   1091 / 1474 loss=2.124, trans_loss=3.42, nll_loss=1.609, w2v_ctc_loss=1.098, task_loss=0.931, contrastive_loss=0.382, total=4191.42, n_correct=2589.13, ppl=3.05, accuracy=61.772, wps=13465.7, ups=1.08, wpb=12511.3, bsz=464.9, num_updates=11400, lr=0.000132453, gnorm=0.426, clip=0, loss_scale=4, train_wall=92, gb_free=17.3, wall=10622
2023-08-13 15:46:25 | INFO | train_inner | epoch 008:   1191 / 1474 loss=2.086, trans_loss=3.414, nll_loss=1.604, w2v_ctc_loss=1.103, task_loss=0.886, contrastive_loss=0.171, total=4187.13, n_correct=2593.63, ppl=3.04, accuracy=61.943, wps=13496.5, ups=1.08, wpb=12506.2, bsz=474, num_updates=11500, lr=0.000131876, gnorm=0.419, clip=0, loss_scale=4, train_wall=92, gb_free=12.7, wall=10715
2023-08-13 15:47:57 | INFO | train_inner | epoch 008:   1291 / 1474 loss=2.095, trans_loss=3.419, nll_loss=1.609, w2v_ctc_loss=1.112, task_loss=0.985, contrastive_loss=0.191, total=4055.06, n_correct=2500.23, ppl=3.05, accuracy=61.657, wps=13153.1, ups=1.09, wpb=12112.2, bsz=434.6, num_updates=11600, lr=0.000131306, gnorm=0.434, clip=0, loss_scale=4, train_wall=92, gb_free=16.2, wall=10807
2023-08-13 15:49:29 | INFO | train_inner | epoch 008:   1391 / 1474 loss=2.104, trans_loss=3.42, nll_loss=1.611, w2v_ctc_loss=1.098, task_loss=0.898, contrastive_loss=0.257, total=4166, n_correct=2578.74, ppl=3.05, accuracy=61.9, wps=13568.2, ups=1.09, wpb=12439.6, bsz=471.7, num_updates=11700, lr=0.000130744, gnorm=0.42, clip=0, loss_scale=4, train_wall=91, gb_free=16.5, wall=10898
2023-08-13 15:50:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 15:51:08 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.051 | trans_loss 5.258 | nll_loss 2.543 | w2v_ctc_loss 1.379 | task_loss 4.642 | contrastive_loss 0.334 | total 4003.4 | n_correct 2598.1 | ppl 5.83 | accuracy 64.897 | uer 19.319 | wer 21.095 | raw_wer 21.095 | bleu 20.81 | wps 2204.1 | wpb 4003.4 | bsz 141.8 | num_updates 11783 | best_bleu 20.81
2023-08-13 15:51:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11783 updates
2023-08-13 15:51:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 15:51:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 15:51:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 8 @ 11783 updates, score 20.81) (writing took 29.266442151740193 seconds)
2023-08-13 15:51:38 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-13 15:51:38 | INFO | train | epoch 008 | loss 2.107 | trans_loss 3.423 | nll_loss 1.613 | w2v_ctc_loss 1.107 | task_loss 0.935 | contrastive_loss 0.239 | total 4138.65 | n_correct 2552.92 | ppl 3.06 | accuracy 61.685 | wps 12799.2 | ups 1.04 | wpb 12355.8 | bsz 458.5 | num_updates 11783 | lr 0.000130283 | gnorm 0.426 | clip 0 | loss_scale 4 | train_wall 1355 | gb_free 16.5 | wall 11028
2023-08-13 15:51:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 15:51:38 | INFO | fairseq.trainer | begin training epoch 9
2023-08-13 15:51:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 15:52:02 | INFO | train_inner | epoch 009:     17 / 1474 loss=2.103, trans_loss=3.415, nll_loss=1.602, w2v_ctc_loss=1.085, task_loss=0.922, contrastive_loss=0.353, total=4113.19, n_correct=2552.55, ppl=3.04, accuracy=62.058, wps=8018.3, ups=0.65, wpb=12275.6, bsz=463.4, num_updates=11800, lr=0.000130189, gnorm=0.416, clip=0, loss_scale=4, train_wall=92, gb_free=17.5, wall=11052
2023-08-13 15:53:34 | INFO | train_inner | epoch 009:    117 / 1474 loss=2.043, trans_loss=3.39, nll_loss=1.571, w2v_ctc_loss=1.059, task_loss=0.877, contrastive_loss=0.186, total=4192.68, n_correct=2632.02, ppl=2.97, accuracy=62.777, wps=13525.5, ups=1.08, wpb=12520.8, bsz=481.1, num_updates=11900, lr=0.000129641, gnorm=0.419, clip=0, loss_scale=4, train_wall=92, gb_free=15.5, wall=11144
2023-08-13 15:55:07 | INFO | train_inner | epoch 009:    217 / 1474 loss=2.034, trans_loss=3.393, nll_loss=1.574, w2v_ctc_loss=1.06, task_loss=1.013, contrastive_loss=0.143, total=4065.4, n_correct=2549, ppl=2.98, accuracy=62.7, wps=13107.6, ups=1.08, wpb=12138.7, bsz=429.9, num_updates=12000, lr=0.000129099, gnorm=0.42, clip=0, loss_scale=4, train_wall=92, gb_free=15.5, wall=11237
2023-08-13 15:55:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 15:55:30 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.048 | trans_loss 5.264 | nll_loss 2.552 | w2v_ctc_loss 1.355 | task_loss 4.595 | contrastive_loss 0.341 | total 4003.4 | n_correct 2590.8 | ppl 5.86 | accuracy 64.715 | uer 20.001 | wer 22.001 | raw_wer 22.001 | bleu 20.81 | wps 2256.7 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 20.81
2023-08-13 15:55:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-08-13 15:55:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-08-13 15:55:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-08-13 15:56:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 20.81) (writing took 51.10896583274007 seconds)
2023-08-13 15:57:54 | INFO | train_inner | epoch 009:    317 / 1474 loss=2.033, trans_loss=3.382, nll_loss=1.563, w2v_ctc_loss=1.047, task_loss=0.873, contrastive_loss=0.195, total=4152.87, n_correct=2617.58, ppl=2.96, accuracy=63.031, wps=7445.6, ups=0.6, wpb=12408.5, bsz=479.2, num_updates=12100, lr=0.000128565, gnorm=0.416, clip=0, loss_scale=4, train_wall=91, gb_free=16.5, wall=11403
2023-08-13 15:59:27 | INFO | train_inner | epoch 009:    417 / 1474 loss=2.039, trans_loss=3.397, nll_loss=1.58, w2v_ctc_loss=1.06, task_loss=0.926, contrastive_loss=0.158, total=4191.41, n_correct=2621.27, ppl=2.99, accuracy=62.539, wps=13378.7, ups=1.07, wpb=12514.6, bsz=464.1, num_updates=12200, lr=0.000128037, gnorm=0.414, clip=0, loss_scale=8, train_wall=93, gb_free=13.7, wall=11497
2023-08-13 16:01:00 | INFO | train_inner | epoch 009:    517 / 1474 loss=2.067, trans_loss=3.396, nll_loss=1.578, w2v_ctc_loss=1.083, task_loss=0.982, contrastive_loss=0.21, total=4119.12, n_correct=2577.26, ppl=2.99, accuracy=62.568, wps=13230.7, ups=1.08, wpb=12295.1, bsz=438.8, num_updates=12300, lr=0.000127515, gnorm=0.417, clip=0, loss_scale=8, train_wall=92, gb_free=16.3, wall=11590
2023-08-13 16:02:34 | INFO | train_inner | epoch 009:    617 / 1474 loss=2.053, trans_loss=3.389, nll_loss=1.573, w2v_ctc_loss=1.052, task_loss=0.937, contrastive_loss=0.263, total=4140.76, n_correct=2598.08, ppl=2.98, accuracy=62.744, wps=13200, ups=1.07, wpb=12374.8, bsz=463.2, num_updates=12400, lr=0.000127, gnorm=0.421, clip=0, loss_scale=8, train_wall=93, gb_free=15.2, wall=11684
2023-08-13 16:04:06 | INFO | train_inner | epoch 009:    717 / 1474 loss=2.045, trans_loss=3.395, nll_loss=1.579, w2v_ctc_loss=1.077, task_loss=0.968, contrastive_loss=0.154, total=4075.27, n_correct=2549.67, ppl=2.99, accuracy=62.564, wps=13275.9, ups=1.09, wpb=12176.3, bsz=443.7, num_updates=12500, lr=0.000126491, gnorm=0.422, clip=0, loss_scale=8, train_wall=91, gb_free=16.7, wall=11775
2023-08-13 16:05:39 | INFO | train_inner | epoch 009:    817 / 1474 loss=2.101, trans_loss=3.39, nll_loss=1.574, w2v_ctc_loss=1.066, task_loss=0.848, contrastive_loss=0.391, total=4215.48, n_correct=2643.27, ppl=2.98, accuracy=62.704, wps=13434.7, ups=1.07, wpb=12596.2, bsz=499.7, num_updates=12600, lr=0.000125988, gnorm=0.425, clip=0, loss_scale=8, train_wall=93, gb_free=16.6, wall=11869
2023-08-13 16:07:13 | INFO | train_inner | epoch 009:    917 / 1474 loss=2.078, trans_loss=3.395, nll_loss=1.575, w2v_ctc_loss=1.064, task_loss=0.963, contrastive_loss=0.374, total=4152.4, n_correct=2601.06, ppl=2.98, accuracy=62.64, wps=13270.7, ups=1.07, wpb=12388.2, bsz=450.8, num_updates=12700, lr=0.000125491, gnorm=0.412, clip=0, loss_scale=8, train_wall=93, gb_free=11.4, wall=11962
2023-08-13 16:08:45 | INFO | train_inner | epoch 009:   1017 / 1474 loss=2.043, trans_loss=3.4, nll_loss=1.583, w2v_ctc_loss=1.07, task_loss=1.044, contrastive_loss=0.158, total=4101.32, n_correct=2562.88, ppl=3, accuracy=62.489, wps=13259.7, ups=1.08, wpb=12242.4, bsz=424.9, num_updates=12800, lr=0.000125, gnorm=0.417, clip=0, loss_scale=8, train_wall=92, gb_free=15.5, wall=12055
2023-08-13 16:10:17 | INFO | train_inner | epoch 009:   1117 / 1474 loss=2.041, trans_loss=3.398, nll_loss=1.578, w2v_ctc_loss=1.06, task_loss=0.887, contrastive_loss=0.176, total=4172.83, n_correct=2621.69, ppl=2.99, accuracy=62.828, wps=13570.6, ups=1.09, wpb=12437.9, bsz=471.9, num_updates=12900, lr=0.000124515, gnorm=0.418, clip=0, loss_scale=8, train_wall=91, gb_free=16, wall=12146
2023-08-13 16:11:50 | INFO | train_inner | epoch 009:   1217 / 1474 loss=2.047, trans_loss=3.394, nll_loss=1.577, w2v_ctc_loss=1.077, task_loss=0.986, contrastive_loss=0.162, total=4138.15, n_correct=2591.27, ppl=2.98, accuracy=62.619, wps=13231.3, ups=1.07, wpb=12357.2, bsz=448.8, num_updates=13000, lr=0.000124035, gnorm=0.417, clip=0, loss_scale=8, train_wall=93, gb_free=15.8, wall=12240
2023-08-13 16:13:23 | INFO | train_inner | epoch 009:   1317 / 1474 loss=2.071, trans_loss=3.389, nll_loss=1.569, w2v_ctc_loss=1.053, task_loss=0.856, contrastive_loss=0.348, total=4205.27, n_correct=2644.7, ppl=2.97, accuracy=62.89, wps=13572.6, ups=1.08, wpb=12548.1, bsz=491.2, num_updates=13100, lr=0.00012356, gnorm=0.414, clip=0, loss_scale=8, train_wall=92, gb_free=16.3, wall=12332
2023-08-13 16:14:54 | INFO | train_inner | epoch 009:   1417 / 1474 loss=2.038, trans_loss=3.402, nll_loss=1.585, w2v_ctc_loss=1.07, task_loss=1.006, contrastive_loss=0.139, total=4071.37, n_correct=2546.35, ppl=3, accuracy=62.543, wps=13262.8, ups=1.09, wpb=12147.5, bsz=429, num_updates=13200, lr=0.000123091, gnorm=0.419, clip=0, loss_scale=8, train_wall=91, gb_free=14.5, wall=12424
2023-08-13 16:15:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 16:16:09 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.014 | trans_loss 5.234 | nll_loss 2.521 | w2v_ctc_loss 1.319 | task_loss 4.657 | contrastive_loss 0.325 | total 4003.4 | n_correct 2609.3 | ppl 5.74 | accuracy 65.177 | uer 19.032 | wer 20.842 | raw_wer 20.842 | bleu 20.94 | wps 2150.8 | wpb 4003.4 | bsz 141.8 | num_updates 13257 | best_bleu 20.94
2023-08-13 16:16:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13257 updates
2023-08-13 16:16:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 16:16:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 16:16:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 9 @ 13257 updates, score 20.94) (writing took 28.74768898077309 seconds)
2023-08-13 16:16:39 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-13 16:16:39 | INFO | train | epoch 009 | loss 2.053 | trans_loss 3.394 | nll_loss 1.576 | w2v_ctc_loss 1.064 | task_loss 0.936 | contrastive_loss 0.224 | total 4138.65 | n_correct 2594.74 | ppl 2.98 | accuracy 62.695 | wps 12133.7 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 13257 | lr 0.000122827 | gnorm 0.418 | clip 0 | loss_scale 8 | train_wall 1358 | gb_free 11.1 | wall 12529
2023-08-13 16:16:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 16:16:39 | INFO | fairseq.trainer | begin training epoch 10
2023-08-13 16:16:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 16:17:26 | INFO | train_inner | epoch 010:     43 / 1474 loss=2.034, trans_loss=3.383, nll_loss=1.562, w2v_ctc_loss=1.041, task_loss=0.876, contrastive_loss=0.233, total=4113.02, n_correct=2597.62, ppl=2.95, accuracy=63.156, wps=8073.8, ups=0.66, wpb=12276.4, bsz=475.9, num_updates=13300, lr=0.000122628, gnorm=0.418, clip=0, loss_scale=8, train_wall=91, gb_free=16, wall=12576
2023-08-13 16:18:59 | INFO | train_inner | epoch 010:    143 / 1474 loss=1.99, trans_loss=3.366, nll_loss=1.541, w2v_ctc_loss=1.017, task_loss=0.902, contrastive_loss=0.156, total=4234.99, n_correct=2694.35, ppl=2.91, accuracy=63.621, wps=13646.5, ups=1.08, wpb=12647.2, bsz=473.2, num_updates=13400, lr=0.000122169, gnorm=0.41, clip=0, loss_scale=8, train_wall=92, gb_free=16.1, wall=12669
2023-08-13 16:20:31 | INFO | train_inner | epoch 010:    243 / 1474 loss=2.019, trans_loss=3.364, nll_loss=1.536, w2v_ctc_loss=1.025, task_loss=0.917, contrastive_loss=0.276, total=4131.11, n_correct=2628.31, ppl=2.9, accuracy=63.622, wps=13378.4, ups=1.09, wpb=12328.7, bsz=463.9, num_updates=13500, lr=0.000121716, gnorm=0.416, clip=0, loss_scale=8, train_wall=92, gb_free=15.8, wall=12761
2023-08-13 16:22:04 | INFO | train_inner | epoch 010:    343 / 1474 loss=1.999, trans_loss=3.364, nll_loss=1.542, w2v_ctc_loss=1.02, task_loss=0.947, contrastive_loss=0.193, total=4135.65, n_correct=2626.71, ppl=2.91, accuracy=63.514, wps=13315.3, ups=1.08, wpb=12362.4, bsz=454, num_updates=13600, lr=0.000121268, gnorm=0.414, clip=0, loss_scale=8, train_wall=92, gb_free=15.4, wall=12854
2023-08-13 16:23:38 | INFO | train_inner | epoch 010:    443 / 1474 loss=2.026, trans_loss=3.369, nll_loss=1.544, w2v_ctc_loss=1.01, task_loss=0.897, contrastive_loss=0.361, total=4199.14, n_correct=2667.59, ppl=2.92, accuracy=63.527, wps=13360.1, ups=1.07, wpb=12535.9, bsz=482.3, num_updates=13700, lr=0.000120824, gnorm=0.413, clip=0, loss_scale=8, train_wall=93, gb_free=16.5, wall=12948
2023-08-13 16:25:10 | INFO | train_inner | epoch 010:    543 / 1474 loss=2.011, trans_loss=3.381, nll_loss=1.556, w2v_ctc_loss=1.045, task_loss=1.019, contrastive_loss=0.145, total=4094.23, n_correct=2587.32, ppl=2.94, accuracy=63.194, wps=13234.6, ups=1.08, wpb=12209.6, bsz=433.2, num_updates=13800, lr=0.000120386, gnorm=0.416, clip=0, loss_scale=8, train_wall=92, gb_free=14, wall=13040
2023-08-13 16:26:43 | INFO | train_inner | epoch 010:    643 / 1474 loss=2.026, trans_loss=3.374, nll_loss=1.549, w2v_ctc_loss=1.029, task_loss=0.879, contrastive_loss=0.26, total=4182.84, n_correct=2656.75, ppl=2.93, accuracy=63.515, wps=13442.3, ups=1.08, wpb=12481.2, bsz=481.3, num_updates=13900, lr=0.000119952, gnorm=0.414, clip=0, loss_scale=8, train_wall=92, gb_free=16.3, wall=13133
2023-08-13 16:28:15 | INFO | train_inner | epoch 010:    743 / 1474 loss=2.011, trans_loss=3.373, nll_loss=1.549, w2v_ctc_loss=1.048, task_loss=0.943, contrastive_loss=0.143, total=4120.62, n_correct=2611.35, ppl=2.93, accuracy=63.373, wps=13370.5, ups=1.09, wpb=12301.2, bsz=451.7, num_updates=14000, lr=0.000119523, gnorm=0.416, clip=0, loss_scale=8, train_wall=91, gb_free=16.4, wall=13225
2023-08-13 16:28:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 16:28:38 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.023 | trans_loss 5.226 | nll_loss 2.505 | w2v_ctc_loss 1.37 | task_loss 4.641 | contrastive_loss 0.33 | total 4003.4 | n_correct 2623.9 | ppl 5.68 | accuracy 65.542 | uer 19.667 | wer 21.517 | raw_wer 21.517 | bleu 21.24 | wps 2148.5 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 21.24
2023-08-13 16:28:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-08-13 16:28:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-08-13 16:28:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-08-13 16:29:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 21.24) (writing took 52.86716715618968 seconds)
2023-08-13 16:31:05 | INFO | train_inner | epoch 010:    843 / 1474 loss=1.99, trans_loss=3.371, nll_loss=1.547, w2v_ctc_loss=1.022, task_loss=0.925, contrastive_loss=0.146, total=4132.62, n_correct=2622.94, ppl=2.92, accuracy=63.469, wps=7260.3, ups=0.59, wpb=12339.2, bsz=457.4, num_updates=14100, lr=0.000119098, gnorm=0.409, clip=0, loss_scale=8, train_wall=92, gb_free=16.4, wall=13395
2023-08-13 16:32:37 | INFO | train_inner | epoch 010:    943 / 1474 loss=2.006, trans_loss=3.369, nll_loss=1.542, w2v_ctc_loss=1.031, task_loss=0.9, contrastive_loss=0.183, total=4160.84, n_correct=2644.52, ppl=2.91, accuracy=63.557, wps=13476.4, ups=1.09, wpb=12411.3, bsz=467.9, num_updates=14200, lr=0.000118678, gnorm=0.415, clip=0, loss_scale=16, train_wall=92, gb_free=15.5, wall=13487
2023-08-13 16:34:10 | INFO | train_inner | epoch 010:   1043 / 1474 loss=2.003, trans_loss=3.37, nll_loss=1.545, w2v_ctc_loss=1.035, task_loss=1.024, contrastive_loss=0.158, total=4059.22, n_correct=2572.94, ppl=2.92, accuracy=63.385, wps=13058.2, ups=1.08, wpb=12120, bsz=431.2, num_updates=14300, lr=0.000118262, gnorm=0.42, clip=0, loss_scale=16, train_wall=92, gb_free=9, wall=13580
2023-08-13 16:35:42 | INFO | train_inner | epoch 010:   1143 / 1474 loss=2.009, trans_loss=3.378, nll_loss=1.556, w2v_ctc_loss=1.046, task_loss=1.039, contrastive_loss=0.142, total=4045.82, n_correct=2558.42, ppl=2.94, accuracy=63.236, wps=13147, ups=1.09, wpb=12079.3, bsz=422.8, num_updates=14400, lr=0.000117851, gnorm=0.418, clip=0, loss_scale=16, train_wall=91, gb_free=12.5, wall=13671
2023-08-13 16:37:13 | INFO | train_inner | epoch 010:   1243 / 1474 loss=1.998, trans_loss=3.362, nll_loss=1.54, w2v_ctc_loss=1.04, task_loss=0.955, contrastive_loss=0.137, total=4107.6, n_correct=2604.96, ppl=2.91, accuracy=63.418, wps=13390.1, ups=1.09, wpb=12284.6, bsz=446.5, num_updates=14500, lr=0.000117444, gnorm=0.416, clip=0, loss_scale=16, train_wall=91, gb_free=16.3, wall=13763
2023-08-13 16:38:46 | INFO | train_inner | epoch 010:   1343 / 1474 loss=1.997, trans_loss=3.37, nll_loss=1.547, w2v_ctc_loss=1.034, task_loss=0.956, contrastive_loss=0.146, total=4127.69, n_correct=2622.95, ppl=2.92, accuracy=63.545, wps=13299.8, ups=1.08, wpb=12326.4, bsz=452.2, num_updates=14600, lr=0.000117041, gnorm=0.412, clip=0, loss_scale=16, train_wall=92, gb_free=15.7, wall=13856
2023-08-13 16:40:19 | INFO | train_inner | epoch 010:   1443 / 1474 loss=2.056, trans_loss=3.379, nll_loss=1.555, w2v_ctc_loss=1.019, task_loss=0.881, contrastive_loss=0.397, total=4195.02, n_correct=2654.52, ppl=2.94, accuracy=63.278, wps=13493.5, ups=1.08, wpb=12514.1, bsz=483, num_updates=14700, lr=0.000116642, gnorm=0.424, clip=0, loss_scale=16, train_wall=92, gb_free=16.1, wall=13949
2023-08-13 16:40:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 16:41:10 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.001 | trans_loss 5.209 | nll_loss 2.486 | w2v_ctc_loss 1.341 | task_loss 4.64 | contrastive_loss 0.323 | total 4003.4 | n_correct 2628.6 | ppl 5.6 | accuracy 65.659 | uer 18.419 | wer 20.182 | raw_wer 20.182 | bleu 21.57 | wps 2272.6 | wpb 4003.4 | bsz 141.8 | num_updates 14731 | best_bleu 21.57
2023-08-13 16:41:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14731 updates
2023-08-13 16:41:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 16:41:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 16:41:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 10 @ 14731 updates, score 21.57) (writing took 33.144516130909324 seconds)
2023-08-13 16:41:43 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-13 16:41:43 | INFO | train | epoch 010 | loss 2.011 | trans_loss 3.37 | nll_loss 1.546 | w2v_ctc_loss 1.028 | task_loss 0.936 | contrastive_loss 0.214 | total 4138.65 | n_correct 2626.34 | ppl 2.92 | accuracy 63.459 | wps 12103.6 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 14731 | lr 0.00011652 | gnorm 0.415 | clip 0 | loss_scale 16 | train_wall 1356 | gb_free 17 | wall 14033
2023-08-13 16:41:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 16:41:44 | INFO | fairseq.trainer | begin training epoch 11
2023-08-13 16:41:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 16:42:55 | INFO | train_inner | epoch 011:     69 / 1474 loss=1.98, trans_loss=3.35, nll_loss=1.519, w2v_ctc_loss=1, task_loss=0.876, contrastive_loss=0.221, total=4166, n_correct=2674.36, ppl=2.87, accuracy=64.195, wps=7961, ups=0.64, wpb=12436.1, bsz=475.7, num_updates=14800, lr=0.000116248, gnorm=0.405, clip=0, loss_scale=16, train_wall=91, gb_free=17.6, wall=14105
2023-08-13 16:44:27 | INFO | train_inner | epoch 011:    169 / 1474 loss=1.966, trans_loss=3.351, nll_loss=1.522, w2v_ctc_loss=1.001, task_loss=0.959, contrastive_loss=0.146, total=4100.74, n_correct=2627.33, ppl=2.87, accuracy=64.07, wps=13260.8, ups=1.08, wpb=12251.1, bsz=450.6, num_updates=14900, lr=0.000115857, gnorm=0.414, clip=0, loss_scale=16, train_wall=92, gb_free=14.1, wall=14197
2023-08-13 16:46:00 | INFO | train_inner | epoch 011:    269 / 1474 loss=1.953, trans_loss=3.348, nll_loss=1.518, w2v_ctc_loss=0.994, task_loss=0.968, contrastive_loss=0.13, total=4115.58, n_correct=2641.47, ppl=2.86, accuracy=64.182, wps=13291.1, ups=1.08, wpb=12290.6, bsz=444.2, num_updates=15000, lr=0.00011547, gnorm=0.41, clip=0, loss_scale=16, train_wall=92, gb_free=15.7, wall=14290
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:0')
2023-08-13 16:47:09 | INFO | train_inner | epoch 011:    369 / 1474 loss=2.048, trans_loss=4.978, nll_loss=2.259, w2v_ctc_loss=0.745, task_loss=1.441, contrastive_loss=0.106, total=4094.16, n_correct=2622.9, ppl=4.79, accuracy=64.064, wps=11963.7, ups=1.45, wpb=8227.1, bsz=296.5, num_updates=15100, lr=0.000115087, gnorm=0.53, clip=0, loss_scale=16, train_wall=68, gb_free=12.3, wall=14358
2023-08-13 16:48:18 | INFO | train_inner | epoch 011:    469 / 1474 loss=2.071, trans_loss=5.014, nll_loss=2.285, w2v_ctc_loss=0.749, task_loss=1.452, contrastive_loss=0.226, total=4112.8, n_correct=2619.12, ppl=4.87, accuracy=63.682, wps=11791.3, ups=1.43, wpb=8225.6, bsz=302.2, num_updates=15200, lr=0.000114708, gnorm=0.536, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=14428
2023-08-13 16:49:28 | INFO | train_inner | epoch 011:    569 / 1474 loss=2.07, trans_loss=5.011, nll_loss=2.281, w2v_ctc_loss=0.755, task_loss=1.513, contrastive_loss=0.222, total=4071.06, n_correct=2597.97, ppl=4.86, accuracy=63.816, wps=11673.2, ups=1.43, wpb=8142.1, bsz=292.6, num_updates=15300, lr=0.000114332, gnorm=0.541, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=14498
2023-08-13 16:50:38 | INFO | train_inner | epoch 011:    669 / 1474 loss=2.069, trans_loss=5, nll_loss=2.268, w2v_ctc_loss=0.749, task_loss=1.374, contrastive_loss=0.283, total=4156.4, n_correct=2661.57, ppl=4.82, accuracy=64.035, wps=11970.4, ups=1.44, wpb=8312.8, bsz=310.2, num_updates=15400, lr=0.000113961, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=14567
2023-08-13 16:51:47 | INFO | train_inner | epoch 011:    769 / 1474 loss=2.059, trans_loss=5.012, nll_loss=2.283, w2v_ctc_loss=0.76, task_loss=1.423, contrastive_loss=0.106, total=4169.17, n_correct=2667.49, ppl=4.87, accuracy=63.981, wps=12005.3, ups=1.44, wpb=8338.3, bsz=304.8, num_updates=15500, lr=0.000113592, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=11.7, wall=14637
2023-08-13 16:52:56 | INFO | train_inner | epoch 011:    869 / 1474 loss=2.059, trans_loss=5.012, nll_loss=2.283, w2v_ctc_loss=0.756, task_loss=1.471, contrastive_loss=0.097, total=4120.01, n_correct=2628.3, ppl=4.87, accuracy=63.794, wps=11914.4, ups=1.45, wpb=8240, bsz=293.5, num_updates=15600, lr=0.000113228, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=13, wall=14706
2023-08-13 16:54:05 | INFO | train_inner | epoch 011:    969 / 1474 loss=2.057, trans_loss=5.01, nll_loss=2.281, w2v_ctc_loss=0.755, task_loss=1.42, contrastive_loss=0.108, total=4145.45, n_correct=2646.54, ppl=4.86, accuracy=63.842, wps=11967, ups=1.44, wpb=8290.9, bsz=303.7, num_updates=15700, lr=0.000112867, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=14775
2023-08-13 16:55:15 | INFO | train_inner | epoch 011:   1069 / 1474 loss=2.058, trans_loss=5.007, nll_loss=2.278, w2v_ctc_loss=0.757, task_loss=1.38, contrastive_loss=0.126, total=4141.18, n_correct=2646.41, ppl=4.85, accuracy=63.905, wps=11960.9, ups=1.44, wpb=8282.4, bsz=309.4, num_updates=15800, lr=0.000112509, gnorm=0.533, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=14845
2023-08-13 16:56:24 | INFO | train_inner | epoch 011:   1169 / 1474 loss=2.061, trans_loss=5.015, nll_loss=2.288, w2v_ctc_loss=0.762, task_loss=1.407, contrastive_loss=0.112, total=4173.93, n_correct=2662.18, ppl=4.88, accuracy=63.781, wps=12041.5, ups=1.44, wpb=8347.9, bsz=307.2, num_updates=15900, lr=0.000112154, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=14914
2023-08-13 16:57:34 | INFO | train_inner | epoch 011:   1269 / 1474 loss=2.067, trans_loss=5.007, nll_loss=2.278, w2v_ctc_loss=0.761, task_loss=1.35, contrastive_loss=0.182, total=4174.26, n_correct=2667.6, ppl=4.85, accuracy=63.906, wps=12009.2, ups=1.44, wpb=8348.5, bsz=314.4, num_updates=16000, lr=0.000111803, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=17.1, wall=14983
2023-08-13 16:57:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:1')
2023-08-13 16:57:57 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.003 | trans_loss 5.207 | nll_loss 2.482 | w2v_ctc_loss 1.349 | task_loss 4.63 | contrastive_loss 0.325 | total 4003.4 | n_correct 2637.1 | ppl 5.59 | accuracy 65.872 | uer 18.369 | wer 20.298 | raw_wer 20.298 | bleu 21.18 | wps 2203.6 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 21.57
2023-08-13 16:57:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-08-13 16:57:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-08-13 16:58:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-08-13 16:58:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 21.18) (writing took 26.90457625500858 seconds)
2023-08-13 16:59:34 | INFO | train_inner | epoch 011:   1369 / 1474 loss=2.073, trans_loss=5.004, nll_loss=2.275, w2v_ctc_loss=0.745, task_loss=1.298, contrastive_loss=0.339, total=4191.56, n_correct=2680.67, ppl=4.84, accuracy=63.954, wps=6934.9, ups=0.83, wpb=8383.1, bsz=327.7, num_updates=16100, lr=0.000111456, gnorm=0.542, clip=0, loss_scale=16, train_wall=70, gb_free=17.2, wall=15104
2023-08-13 17:00:44 | INFO | train_inner | epoch 011:   1469 / 1474 loss=2.055, trans_loss=5.01, nll_loss=2.282, w2v_ctc_loss=0.753, task_loss=1.346, contrastive_loss=0.117, total=4161.81, n_correct=2661.39, ppl=4.86, accuracy=63.948, wps=11967.2, ups=1.44, wpb=8323.6, bsz=313.2, num_updates=16200, lr=0.000111111, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=15174
2023-08-13 17:00:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 17:01:12 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 3.98 | trans_loss 5.205 | nll_loss 2.48 | w2v_ctc_loss 1.278 | task_loss 4.652 | contrastive_loss 0.321 | total 4003.4 | n_correct 2632.5 | ppl 5.58 | accuracy 65.757 | uer 18.586 | wer 20.473 | raw_wer 20.473 | bleu 21.14 | wps 2052.5 | wpb 4003.4 | bsz 141.8 | num_updates 16205 | best_bleu 21.57
2023-08-13 17:01:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16205 updates
2023-08-13 17:01:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.1403.pt
2023-08-13 17:01:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.1403.pt
2023-08-13 17:01:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.1403.pt (epoch 11 @ 16205 updates, score 21.14) (writing took 39.303486816585064 seconds)
2023-08-13 17:01:51 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-13 17:01:51 | INFO | train | epoch 011 | loss 2.037 | trans_loss 4.593 | nll_loss 2.089 | w2v_ctc_loss 0.814 | task_loss 1.287 | contrastive_loss 0.161 | total 4138.65 | n_correct 2646.41 | ppl 4.25 | accuracy 63.944 | wps 11011.4 | ups 1.22 | wpb 9023.7 | bsz 333.5 | num_updates 16205 | lr 0.000111094 | gnorm 0.51 | clip 0 | loss_scale 16 | train_wall 1078 | gb_free 16.9 | wall 15241
2023-08-13 17:01:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 17:01:52 | INFO | fairseq.trainer | begin training epoch 12
2023-08-13 17:01:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 17:03:06 | INFO | train_inner | epoch 012:     95 / 1474 loss=2.037, trans_loss=4.97, nll_loss=2.23, w2v_ctc_loss=0.737, task_loss=1.354, contrastive_loss=0.146, total=4139.2, n_correct=2677.7, ppl=4.69, accuracy=64.691, wps=5835.4, ups=0.7, wpb=8278.4, bsz=312.5, num_updates=16300, lr=0.00011077, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=15316
2023-08-13 17:04:15 | INFO | train_inner | epoch 012:    195 / 1474 loss=2.039, trans_loss=4.975, nll_loss=2.234, w2v_ctc_loss=0.743, task_loss=1.442, contrastive_loss=0.099, total=4126.87, n_correct=2661.68, ppl=4.71, accuracy=64.496, wps=11975.2, ups=1.45, wpb=8253.7, bsz=295.9, num_updates=16400, lr=0.000110432, gnorm=0.528, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=15385
2023-08-13 17:05:25 | INFO | train_inner | epoch 012:    295 / 1474 loss=2.034, trans_loss=4.974, nll_loss=2.235, w2v_ctc_loss=0.729, task_loss=1.312, contrastive_loss=0.128, total=4203.54, n_correct=2718.86, ppl=4.71, accuracy=64.68, wps=11995.4, ups=1.43, wpb=8407.1, bsz=321.1, num_updates=16500, lr=0.000110096, gnorm=0.526, clip=0, loss_scale=32, train_wall=70, gb_free=14.2, wall=15455
2023-08-13 17:06:34 | INFO | train_inner | epoch 012:    395 / 1474 loss=2.037, trans_loss=4.979, nll_loss=2.24, w2v_ctc_loss=0.738, task_loss=1.376, contrastive_loss=0.113, total=4149.28, n_correct=2679.31, ppl=4.73, accuracy=64.573, wps=11963.7, ups=1.44, wpb=8298.6, bsz=307.1, num_updates=16600, lr=0.000109764, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=14.8, wall=15524
2023-08-13 17:07:44 | INFO | train_inner | epoch 012:    495 / 1474 loss=2.048, trans_loss=4.992, nll_loss=2.258, w2v_ctc_loss=0.749, task_loss=1.417, contrastive_loss=0.121, total=4106.46, n_correct=2645.18, ppl=4.78, accuracy=64.415, wps=11856.7, ups=1.44, wpb=8212.9, bsz=301.2, num_updates=16700, lr=0.000109435, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=17.5, wall=15593
2023-08-13 17:08:53 | INFO | train_inner | epoch 012:    595 / 1474 loss=2.046, trans_loss=4.98, nll_loss=2.242, w2v_ctc_loss=0.742, task_loss=1.342, contrastive_loss=0.184, total=4190.91, n_correct=2703.32, ppl=4.73, accuracy=64.504, wps=12028.3, ups=1.44, wpb=8381.8, bsz=316.5, num_updates=16800, lr=0.000109109, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=15663
2023-08-13 17:10:03 | INFO | train_inner | epoch 012:    695 / 1474 loss=2.043, trans_loss=4.976, nll_loss=2.238, w2v_ctc_loss=0.726, task_loss=1.294, contrastive_loss=0.27, total=4203.66, n_correct=2718.44, ppl=4.72, accuracy=64.668, wps=12015.7, ups=1.43, wpb=8407.3, bsz=324.4, num_updates=16900, lr=0.000108786, gnorm=0.523, clip=0, loss_scale=32, train_wall=70, gb_free=17.1, wall=15733
2023-08-13 17:11:12 | INFO | train_inner | epoch 012:    795 / 1474 loss=2.037, trans_loss=4.975, nll_loss=2.236, w2v_ctc_loss=0.743, task_loss=1.423, contrastive_loss=0.11, total=4095.72, n_correct=2645.68, ppl=4.71, accuracy=64.596, wps=11838.7, ups=1.45, wpb=8191.4, bsz=298.9, num_updates=17000, lr=0.000108465, gnorm=0.537, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=15802
2023-08-13 17:12:22 | INFO | train_inner | epoch 012:    895 / 1474 loss=2.044, trans_loss=4.979, nll_loss=2.241, w2v_ctc_loss=0.741, task_loss=1.441, contrastive_loss=0.16, total=4162.82, n_correct=2685.17, ppl=4.73, accuracy=64.504, wps=11963.9, ups=1.44, wpb=8325.6, bsz=305.4, num_updates=17100, lr=0.000108148, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=15.8, wall=15872
2023-08-13 17:13:31 | INFO | train_inner | epoch 012:    995 / 1474 loss=2.047, trans_loss=4.983, nll_loss=2.247, w2v_ctc_loss=0.744, task_loss=1.43, contrastive_loss=0.168, total=4117.63, n_correct=2653.35, ppl=4.75, accuracy=64.439, wps=11925.1, ups=1.45, wpb=8235.3, bsz=301.6, num_updates=17200, lr=0.000107833, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=15941
2023-08-13 17:14:41 | INFO | train_inner | epoch 012:   1095 / 1474 loss=2.058, trans_loss=4.988, nll_loss=2.253, w2v_ctc_loss=0.75, task_loss=1.475, contrastive_loss=0.213, total=4046.48, n_correct=2604.26, ppl=4.77, accuracy=64.359, wps=11604, ups=1.43, wpb=8093, bsz=289.6, num_updates=17300, lr=0.000107521, gnorm=0.54, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=16011
2023-08-13 17:15:50 | INFO | train_inner | epoch 012:   1195 / 1474 loss=2.06, trans_loss=5.004, nll_loss=2.274, w2v_ctc_loss=0.758, task_loss=1.371, contrastive_loss=0.181, total=4201.13, n_correct=2691.15, ppl=4.84, accuracy=64.058, wps=12094.4, ups=1.44, wpb=8402.3, bsz=319.2, num_updates=17400, lr=0.000107211, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=16080
2023-08-13 17:17:00 | INFO | train_inner | epoch 012:   1295 / 1474 loss=2.047, trans_loss=4.984, nll_loss=2.248, w2v_ctc_loss=0.758, task_loss=1.564, contrastive_loss=0.096, total=4070.27, n_correct=2619.65, ppl=4.75, accuracy=64.361, wps=11699.9, ups=1.44, wpb=8140.5, bsz=286.1, num_updates=17500, lr=0.000106904, gnorm=0.536, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=16150
2023-08-13 17:18:09 | INFO | train_inner | epoch 012:   1395 / 1474 loss=2.05, trans_loss=4.991, nll_loss=2.257, w2v_ctc_loss=0.741, task_loss=1.415, contrastive_loss=0.198, total=4139.63, n_correct=2663.21, ppl=4.78, accuracy=64.334, wps=11976.3, ups=1.45, wpb=8279.3, bsz=305.8, num_updates=17600, lr=0.0001066, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=16219
2023-08-13 17:19:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 17:19:27 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 3.999 | trans_loss 5.195 | nll_loss 2.468 | w2v_ctc_loss 1.367 | task_loss 4.643 | contrastive_loss 0.321 | total 4003.4 | n_correct 2634.2 | ppl 5.53 | accuracy 65.799 | uer 18.74 | wer 20.644 | raw_wer 20.644 | bleu 21.78 | wps 2261.2 | wpb 4003.4 | bsz 141.8 | num_updates 17679 | best_bleu 21.78
2023-08-13 17:19:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17679 updates
2023-08-13 17:19:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 17:19:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 17:19:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 12 @ 17679 updates, score 21.78) (writing took 32.668465454131365 seconds)
2023-08-13 17:20:00 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-13 17:20:00 | INFO | train | epoch 012 | loss 2.045 | trans_loss 4.982 | nll_loss 2.246 | w2v_ctc_loss 0.743 | task_loss 1.404 | contrastive_loss 0.154 | total 4138.65 | n_correct 2668.35 | ppl 4.74 | accuracy 64.474 | wps 11205.9 | ups 1.35 | wpb 8277.3 | bsz 305.7 | num_updates 17679 | lr 0.000106362 | gnorm 0.529 | clip 0 | loss_scale 32 | train_wall 1017 | gb_free 12.5 | wall 16330
2023-08-13 17:20:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 17:20:00 | INFO | fairseq.trainer | begin training epoch 13
2023-08-13 17:20:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 17:20:24 | INFO | train_inner | epoch 013:     21 / 1474 loss=2.046, trans_loss=4.99, nll_loss=2.256, w2v_ctc_loss=0.755, task_loss=1.46, contrastive_loss=0.104, total=4096.49, n_correct=2636.77, ppl=4.78, accuracy=64.367, wps=6089.4, ups=0.74, wpb=8193, bsz=295.4, num_updates=17700, lr=0.000106299, gnorm=0.53, clip=0, loss_scale=32, train_wall=70, gb_free=14.2, wall=16353
2023-08-13 17:21:33 | INFO | train_inner | epoch 013:    121 / 1474 loss=2.026, trans_loss=4.957, nll_loss=2.212, w2v_ctc_loss=0.728, task_loss=1.41, contrastive_loss=0.117, total=4160.97, n_correct=2700.77, ppl=4.63, accuracy=64.907, wps=11969.7, ups=1.44, wpb=8321.9, bsz=302.9, num_updates=17800, lr=0.000106, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=16423
2023-08-13 17:22:43 | INFO | train_inner | epoch 013:    221 / 1474 loss=2.044, trans_loss=4.966, nll_loss=2.225, w2v_ctc_loss=0.725, task_loss=1.297, contrastive_loss=0.326, total=4212.08, n_correct=2733, ppl=4.68, accuracy=64.885, wps=12018.1, ups=1.43, wpb=8424.2, bsz=329.7, num_updates=17900, lr=0.000105703, gnorm=0.521, clip=0, loss_scale=32, train_wall=70, gb_free=14.3, wall=16493
2023-08-13 17:23:53 | INFO | train_inner | epoch 013:    321 / 1474 loss=2.019, trans_loss=4.949, nll_loss=2.203, w2v_ctc_loss=0.724, task_loss=1.456, contrastive_loss=0.099, total=4102.3, n_correct=2676.02, ppl=4.6, accuracy=65.232, wps=11766.1, ups=1.43, wpb=8204.6, bsz=294.1, num_updates=18000, lr=0.000105409, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=16.9, wall=16563
2023-08-13 17:23:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 17:24:16 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.987 | trans_loss 5.198 | nll_loss 2.471 | w2v_ctc_loss 1.318 | task_loss 4.642 | contrastive_loss 0.32 | total 4003.4 | n_correct 2638 | ppl 5.55 | accuracy 65.894 | uer 18.6 | wer 20.544 | raw_wer 20.544 | bleu 22.01 | wps 2184.2 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 22.01
2023-08-13 17:24:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-08-13 17:24:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-08-13 17:24:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-08-13 17:25:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 22.01) (writing took 54.28837365284562 seconds)
2023-08-13 17:26:21 | INFO | train_inner | epoch 013:    421 / 1474 loss=2.024, trans_loss=4.956, nll_loss=2.211, w2v_ctc_loss=0.725, task_loss=1.318, contrastive_loss=0.147, total=4177.29, n_correct=2720.48, ppl=4.63, accuracy=65.125, wps=5648.2, ups=0.68, wpb=8354.6, bsz=318.4, num_updates=18100, lr=0.000105118, gnorm=0.518, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=16711
2023-08-13 17:27:31 | INFO | train_inner | epoch 013:    521 / 1474 loss=2.034, trans_loss=4.965, nll_loss=2.223, w2v_ctc_loss=0.734, task_loss=1.361, contrastive_loss=0.183, total=4201.22, n_correct=2720.71, ppl=4.67, accuracy=64.76, wps=12035.2, ups=1.43, wpb=8402.4, bsz=319, num_updates=18200, lr=0.000104828, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=12.6, wall=16781
2023-08-13 17:28:40 | INFO | train_inner | epoch 013:    621 / 1474 loss=2.017, trans_loss=4.956, nll_loss=2.211, w2v_ctc_loss=0.724, task_loss=1.364, contrastive_loss=0.096, total=4161.98, n_correct=2713.5, ppl=4.63, accuracy=65.197, wps=12013.9, ups=1.44, wpb=8324, bsz=308.3, num_updates=18300, lr=0.000104542, gnorm=0.524, clip=0, loss_scale=64, train_wall=69, gb_free=15.5, wall=16850
2023-08-13 17:29:50 | INFO | train_inner | epoch 013:    721 / 1474 loss=2.035, trans_loss=4.964, nll_loss=2.221, w2v_ctc_loss=0.749, task_loss=1.565, contrastive_loss=0.097, total=4096.76, n_correct=2654.98, ppl=4.66, accuracy=64.807, wps=11723.4, ups=1.43, wpb=8193.5, bsz=284.6, num_updates=18400, lr=0.000104257, gnorm=0.53, clip=0, loss_scale=64, train_wall=69, gb_free=16.4, wall=16920
2023-08-13 17:31:00 | INFO | train_inner | epoch 013:    821 / 1474 loss=2.032, trans_loss=4.965, nll_loss=2.224, w2v_ctc_loss=0.73, task_loss=1.421, contrastive_loss=0.144, total=4121.73, n_correct=2669.55, ppl=4.67, accuracy=64.768, wps=11732.8, ups=1.42, wpb=8243.5, bsz=306.7, num_updates=18500, lr=0.000103975, gnorm=0.532, clip=0, loss_scale=64, train_wall=70, gb_free=14.5, wall=16990
2023-08-13 17:32:09 | INFO | train_inner | epoch 013:    921 / 1474 loss=2.025, trans_loss=4.961, nll_loss=2.219, w2v_ctc_loss=0.729, task_loss=1.435, contrastive_loss=0.106, total=4107.01, n_correct=2670.11, ppl=4.66, accuracy=65.013, wps=11863.2, ups=1.44, wpb=8214, bsz=296.5, num_updates=18600, lr=0.000103695, gnorm=0.529, clip=0, loss_scale=64, train_wall=69, gb_free=15.6, wall=17059
2023-08-13 17:33:19 | INFO | train_inner | epoch 013:   1021 / 1474 loss=2.041, trans_loss=4.97, nll_loss=2.229, w2v_ctc_loss=0.743, task_loss=1.485, contrastive_loss=0.156, total=4081.02, n_correct=2640.92, ppl=4.69, accuracy=64.712, wps=11789.5, ups=1.44, wpb=8162, bsz=293.4, num_updates=18700, lr=0.000103418, gnorm=0.53, clip=0, loss_scale=64, train_wall=69, gb_free=15.9, wall=17128
2023-08-13 17:34:28 | INFO | train_inner | epoch 013:   1121 / 1474 loss=2.021, trans_loss=4.953, nll_loss=2.209, w2v_ctc_loss=0.722, task_loss=1.385, contrastive_loss=0.137, total=4105.62, n_correct=2674.09, ppl=4.62, accuracy=65.132, wps=11853.8, ups=1.44, wpb=8211.2, bsz=305.9, num_updates=18800, lr=0.000103142, gnorm=0.525, clip=0, loss_scale=64, train_wall=69, gb_free=16.4, wall=17198
2023-08-13 17:35:38 | INFO | train_inner | epoch 013:   1221 / 1474 loss=2.031, trans_loss=4.966, nll_loss=2.225, w2v_ctc_loss=0.739, task_loss=1.497, contrastive_loss=0.098, total=4110.35, n_correct=2664.07, ppl=4.68, accuracy=64.814, wps=11757.7, ups=1.43, wpb=8220.7, bsz=295.1, num_updates=18900, lr=0.000102869, gnorm=0.526, clip=0, loss_scale=64, train_wall=69, gb_free=14.6, wall=17268
2023-08-13 17:36:48 | INFO | train_inner | epoch 013:   1321 / 1474 loss=2.033, trans_loss=4.957, nll_loss=2.214, w2v_ctc_loss=0.734, task_loss=1.386, contrastive_loss=0.194, total=4112.2, n_correct=2677.41, ppl=4.64, accuracy=65.109, wps=11790.4, ups=1.43, wpb=8224.4, bsz=308.2, num_updates=19000, lr=0.000102598, gnorm=0.528, clip=0, loss_scale=64, train_wall=69, gb_free=17.3, wall=17337
2023-08-13 17:37:57 | INFO | train_inner | epoch 013:   1421 / 1474 loss=2.036, trans_loss=4.965, nll_loss=2.225, w2v_ctc_loss=0.728, task_loss=1.38, contrastive_loss=0.204, total=4180.88, n_correct=2711.32, ppl=4.67, accuracy=64.85, wps=12067.1, ups=1.44, wpb=8361.8, bsz=312.2, num_updates=19100, lr=0.000102329, gnorm=0.526, clip=0, loss_scale=64, train_wall=69, gb_free=14.9, wall=17407
2023-08-13 17:38:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 17:38:57 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.99 | trans_loss 5.192 | nll_loss 2.461 | w2v_ctc_loss 1.345 | task_loss 4.622 | contrastive_loss 0.321 | total 4003.4 | n_correct 2636.4 | ppl 5.5 | accuracy 65.854 | uer 18.825 | wer 20.864 | raw_wer 20.864 | bleu 21.52 | wps 2251.2 | wpb 4003.4 | bsz 141.8 | num_updates 19153 | best_bleu 22.01
2023-08-13 17:38:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19153 updates
2023-08-13 17:38:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.5207.pt
2023-08-13 17:39:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.5207.pt
2023-08-13 17:39:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.5207.pt (epoch 13 @ 19153 updates, score 21.52) (writing took 17.25167341902852 seconds)
2023-08-13 17:39:17 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-13 17:39:17 | INFO | train | epoch 013 | loss 2.03 | trans_loss 4.96 | nll_loss 2.217 | w2v_ctc_loss 0.731 | task_loss 1.406 | contrastive_loss 0.151 | total 4138.65 | n_correct 2688.2 | ppl 4.65 | accuracy 64.953 | wps 10548 | ups 1.27 | wpb 8277.3 | bsz 305.7 | num_updates 19153 | lr 0.000102187 | gnorm 0.526 | clip 0 | loss_scale 64 | train_wall 1020 | gb_free 17.4 | wall 17487
2023-08-13 17:39:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 17:39:17 | INFO | fairseq.trainer | begin training epoch 14
2023-08-13 17:39:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 17:39:57 | INFO | train_inner | epoch 014:     47 / 1474 loss=2.009, trans_loss=4.934, nll_loss=2.185, w2v_ctc_loss=0.72, task_loss=1.286, contrastive_loss=0.111, total=4176.2, n_correct=2733.34, ppl=4.55, accuracy=65.45, wps=6944, ups=0.83, wpb=8352.4, bsz=322.3, num_updates=19200, lr=0.000102062, gnorm=0.52, clip=0, loss_scale=64, train_wall=69, gb_free=10.2, wall=17527
2023-08-13 17:41:06 | INFO | train_inner | epoch 014:    147 / 1474 loss=2.005, trans_loss=4.925, nll_loss=2.172, w2v_ctc_loss=0.721, task_loss=1.418, contrastive_loss=0.092, total=4080.86, n_correct=2681.7, ppl=4.5, accuracy=65.714, wps=11829, ups=1.45, wpb=8161.7, bsz=299.6, num_updates=19300, lr=0.000101797, gnorm=0.521, clip=0, loss_scale=64, train_wall=69, gb_free=16.7, wall=17596
2023-08-13 17:42:15 | INFO | train_inner | epoch 014:    247 / 1474 loss=2.023, trans_loss=4.944, nll_loss=2.196, w2v_ctc_loss=0.721, task_loss=1.478, contrastive_loss=0.192, total=4106.97, n_correct=2679.4, ppl=4.58, accuracy=65.24, wps=11855.7, ups=1.44, wpb=8213.9, bsz=293.3, num_updates=19400, lr=0.000101535, gnorm=0.53, clip=0, loss_scale=64, train_wall=69, gb_free=11.9, wall=17665
2023-08-13 17:43:25 | INFO | train_inner | epoch 014:    347 / 1474 loss=2.009, trans_loss=4.939, nll_loss=2.19, w2v_ctc_loss=0.713, task_loss=1.29, contrastive_loss=0.128, total=4179.8, n_correct=2738.14, ppl=4.56, accuracy=65.509, wps=12078.2, ups=1.44, wpb=8359.6, bsz=322.5, num_updates=19500, lr=0.000101274, gnorm=0.523, clip=0, loss_scale=64, train_wall=69, gb_free=17, wall=17734
2023-08-13 17:44:34 | INFO | train_inner | epoch 014:    447 / 1474 loss=2.01, trans_loss=4.945, nll_loss=2.197, w2v_ctc_loss=0.716, task_loss=1.447, contrastive_loss=0.088, total=4120.38, n_correct=2691.75, ppl=4.59, accuracy=65.328, wps=11844.9, ups=1.44, wpb=8240.8, bsz=296.3, num_updates=19600, lr=0.000101015, gnorm=0.521, clip=0, loss_scale=64, train_wall=69, gb_free=16.8, wall=17804
2023-08-13 17:45:44 | INFO | train_inner | epoch 014:    547 / 1474 loss=2.025, trans_loss=4.945, nll_loss=2.197, w2v_ctc_loss=0.74, task_loss=1.487, contrastive_loss=0.124, total=4089.86, n_correct=2666.98, ppl=4.58, accuracy=65.21, wps=11671.1, ups=1.43, wpb=8179.7, bsz=295.5, num_updates=19700, lr=0.000100759, gnorm=0.534, clip=0, loss_scale=64, train_wall=70, gb_free=11.6, wall=17874
2023-08-13 17:46:54 | INFO | train_inner | epoch 014:    647 / 1474 loss=2.023, trans_loss=4.945, nll_loss=2.197, w2v_ctc_loss=0.727, task_loss=1.406, contrastive_loss=0.169, total=4158.94, n_correct=2714.29, ppl=4.59, accuracy=65.264, wps=11913.5, ups=1.43, wpb=8317.9, bsz=306.7, num_updates=19800, lr=0.000100504, gnorm=0.529, clip=0, loss_scale=64, train_wall=69, gb_free=15.8, wall=17944
2023-08-13 17:48:03 | INFO | train_inner | epoch 014:    747 / 1474 loss=2.01, trans_loss=4.933, nll_loss=2.183, w2v_ctc_loss=0.725, task_loss=1.361, contrastive_loss=0.101, total=4150.03, n_correct=2720.51, ppl=4.54, accuracy=65.554, wps=11994.2, ups=1.45, wpb=8300.1, bsz=310.4, num_updates=19900, lr=0.000100251, gnorm=0.523, clip=0, loss_scale=64, train_wall=69, gb_free=15.3, wall=18013
2023-08-13 17:49:13 | INFO | train_inner | epoch 014:    847 / 1474 loss=2.021, trans_loss=4.935, nll_loss=2.186, w2v_ctc_loss=0.721, task_loss=1.343, contrastive_loss=0.21, total=4162.8, n_correct=2724.95, ppl=4.55, accuracy=65.46, wps=11947.6, ups=1.44, wpb=8325.6, bsz=317.2, num_updates=20000, lr=0.0001, gnorm=0.527, clip=0, loss_scale=64, train_wall=69, gb_free=16.8, wall=18083
2023-08-13 17:49:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 17:49:37 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.996 | trans_loss 5.186 | nll_loss 2.454 | w2v_ctc_loss 1.385 | task_loss 4.651 | contrastive_loss 0.312 | total 4003.4 | n_correct 2648.1 | ppl 5.48 | accuracy 66.146 | uer 18.528 | wer 20.376 | raw_wer 20.376 | bleu 22.03 | wps 2159.9 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 22.03
2023-08-13 17:49:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-08-13 17:49:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-08-13 17:49:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-08-13 17:50:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 22.03) (writing took 54.171739814803004 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:0')
2023-08-13 17:51:42 | INFO | train_inner | epoch 014:    947 / 1474 loss=2.011, trans_loss=4.939, nll_loss=2.19, w2v_ctc_loss=0.721, task_loss=1.425, contrastive_loss=0.101, total=4159.46, n_correct=2719.25, ppl=4.56, accuracy=65.375, wps=5581.1, ups=0.67, wpb=8318.9, bsz=306.7, num_updates=20100, lr=9.97509e-05, gnorm=0.521, clip=0, loss_scale=64, train_wall=70, gb_free=15, wall=18232
2023-08-13 17:52:52 | INFO | train_inner | epoch 014:   1047 / 1474 loss=2.021, trans_loss=4.944, nll_loss=2.198, w2v_ctc_loss=0.72, task_loss=1.4, contrastive_loss=0.168, total=4155.93, n_correct=2715.89, ppl=4.59, accuracy=65.35, wps=11870.7, ups=1.43, wpb=8311.9, bsz=305.9, num_updates=20200, lr=9.95037e-05, gnorm=0.521, clip=0, loss_scale=64, train_wall=70, gb_free=16, wall=18302
2023-08-13 17:54:02 | INFO | train_inner | epoch 014:   1147 / 1474 loss=2.044, trans_loss=4.944, nll_loss=2.198, w2v_ctc_loss=0.731, task_loss=1.321, contrastive_loss=0.39, total=4228.09, n_correct=2757.96, ppl=4.59, accuracy=65.229, wps=12049.9, ups=1.42, wpb=8456.2, bsz=326.3, num_updates=20300, lr=9.92583e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=70, gb_free=17.3, wall=18372
2023-08-13 17:54:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-13 17:55:12 | INFO | train_inner | epoch 014:   1248 / 1474 loss=2.024, trans_loss=4.95, nll_loss=2.204, w2v_ctc_loss=0.741, task_loss=1.644, contrastive_loss=0.084, total=4022.3, n_correct=2623.77, ppl=4.61, accuracy=65.231, wps=11459.5, ups=1.42, wpb=8044.6, bsz=272.4, num_updates=20400, lr=9.90148e-05, gnorm=0.536, clip=0, loss_scale=64, train_wall=70, gb_free=16, wall=18442
2023-08-13 17:56:22 | INFO | train_inner | epoch 014:   1348 / 1474 loss=2.008, trans_loss=4.943, nll_loss=2.196, w2v_ctc_loss=0.716, task_loss=1.324, contrastive_loss=0.1, total=4213.9, n_correct=2756.23, ppl=4.58, accuracy=65.408, wps=12157.4, ups=1.44, wpb=8427.8, bsz=319.4, num_updates=20500, lr=9.8773e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=69, gb_free=15.8, wall=18512
2023-08-13 17:56:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-13 17:57:32 | INFO | train_inner | epoch 014:   1449 / 1474 loss=2.014, trans_loss=4.947, nll_loss=2.201, w2v_ctc_loss=0.722, task_loss=1.433, contrastive_loss=0.097, total=4111.36, n_correct=2686.46, ppl=4.6, accuracy=65.342, wps=11744.8, ups=1.43, wpb=8222.7, bsz=298.5, num_updates=20600, lr=9.85329e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=70, gb_free=15.8, wall=18582
2023-08-13 17:57:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:7')
2023-08-13 17:58:13 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.971 | trans_loss 5.181 | nll_loss 2.448 | w2v_ctc_loss 1.317 | task_loss 4.636 | contrastive_loss 0.309 | total 4003.4 | n_correct 2651.4 | ppl 5.46 | accuracy 66.229 | uer 18.517 | wer 20.51 | raw_wer 20.51 | bleu 21.88 | wps 2161.7 | wpb 4003.4 | bsz 141.8 | num_updates 20625 | best_bleu 22.03
2023-08-13 17:58:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20625 updates
2023-08-13 17:58:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.8801.pt
2023-08-13 17:58:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.8801.pt
2023-08-13 17:58:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.8801.pt (epoch 14 @ 20625 updates, score 21.88) (writing took 17.031099155545235 seconds)
2023-08-13 17:58:31 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-13 17:58:31 | INFO | train | epoch 014 | loss 2.017 | trans_loss 4.941 | nll_loss 2.193 | w2v_ctc_loss 0.724 | task_loss 1.407 | contrastive_loss 0.145 | total 4137.68 | n_correct 2705.11 | ppl 4.57 | accuracy 65.377 | wps 10558.7 | ups 1.28 | wpb 8275.4 | bsz 305.3 | num_updates 20625 | lr 9.84732e-05 | gnorm 0.526 | clip 0 | loss_scale 32 | train_wall 1019 | gb_free 16 | wall 18640
2023-08-13 17:58:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 17:58:31 | INFO | fairseq.trainer | begin training epoch 15
2023-08-13 17:58:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 17:59:30 | INFO | train_inner | epoch 015:     75 / 1474 loss=2.011, trans_loss=4.93, nll_loss=2.179, w2v_ctc_loss=0.71, task_loss=1.411, contrastive_loss=0.186, total=4090.99, n_correct=2686.39, ppl=4.53, accuracy=65.666, wps=6916.1, ups=0.85, wpb=8182, bsz=300.8, num_updates=20700, lr=9.82946e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=18700
2023-08-13 18:00:40 | INFO | train_inner | epoch 015:    175 / 1474 loss=2, trans_loss=4.92, nll_loss=2.164, w2v_ctc_loss=0.714, task_loss=1.456, contrastive_loss=0.097, total=4115.56, n_correct=2713, ppl=4.48, accuracy=65.921, wps=11865.2, ups=1.44, wpb=8231.1, bsz=298.5, num_updates=20800, lr=9.80581e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=18769
2023-08-13 18:01:49 | INFO | train_inner | epoch 015:    275 / 1474 loss=1.995, trans_loss=4.921, nll_loss=2.166, w2v_ctc_loss=0.706, task_loss=1.367, contrastive_loss=0.089, total=4182.19, n_correct=2758.96, ppl=4.49, accuracy=65.969, wps=12041.3, ups=1.44, wpb=8364.4, bsz=310.5, num_updates=20900, lr=9.78232e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=18839
2023-08-13 18:02:59 | INFO | train_inner | epoch 015:    375 / 1474 loss=1.997, trans_loss=4.914, nll_loss=2.157, w2v_ctc_loss=0.707, task_loss=1.402, contrastive_loss=0.113, total=4172.52, n_correct=2751.01, ppl=4.46, accuracy=65.932, wps=11954.2, ups=1.43, wpb=8345, bsz=307.7, num_updates=21000, lr=9.759e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=18909
2023-08-13 18:04:08 | INFO | train_inner | epoch 015:    475 / 1474 loss=2.009, trans_loss=4.921, nll_loss=2.166, w2v_ctc_loss=0.703, task_loss=1.473, contrastive_loss=0.2, total=4076.84, n_correct=2678.83, ppl=4.49, accuracy=65.708, wps=11770.1, ups=1.44, wpb=8153.7, bsz=293.4, num_updates=21100, lr=9.73585e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=18978
2023-08-13 18:05:17 | INFO | train_inner | epoch 015:    575 / 1474 loss=2.005, trans_loss=4.923, nll_loss=2.169, w2v_ctc_loss=0.719, task_loss=1.435, contrastive_loss=0.115, total=4156.05, n_correct=2729.56, ppl=4.5, accuracy=65.677, wps=11975.4, ups=1.44, wpb=8312.1, bsz=302.8, num_updates=21200, lr=9.71286e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=11.3, wall=19047
2023-08-13 18:06:27 | INFO | train_inner | epoch 015:    675 / 1474 loss=2.007, trans_loss=4.916, nll_loss=2.161, w2v_ctc_loss=0.714, task_loss=1.44, contrastive_loss=0.159, total=4118.87, n_correct=2709.59, ppl=4.47, accuracy=65.785, wps=11830.5, ups=1.44, wpb=8237.7, bsz=303, num_updates=21300, lr=9.69003e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=19117
2023-08-13 18:07:37 | INFO | train_inner | epoch 015:    775 / 1474 loss=2.002, trans_loss=4.925, nll_loss=2.172, w2v_ctc_loss=0.715, task_loss=1.414, contrastive_loss=0.098, total=4176.64, n_correct=2743.74, ppl=4.51, accuracy=65.693, wps=11969.3, ups=1.43, wpb=8353.3, bsz=305.3, num_updates=21400, lr=9.66736e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=69, gb_free=13.7, wall=19187
2023-08-13 18:08:45 | INFO | train_inner | epoch 015:    875 / 1474 loss=2.005, trans_loss=4.928, nll_loss=2.176, w2v_ctc_loss=0.718, task_loss=1.519, contrastive_loss=0.092, total=4056.99, n_correct=2661.31, ppl=4.52, accuracy=65.598, wps=11857.8, ups=1.46, wpb=8114, bsz=288, num_updates=21500, lr=9.64486e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=19255
2023-08-13 18:09:55 | INFO | train_inner | epoch 015:    975 / 1474 loss=2.005, trans_loss=4.922, nll_loss=2.168, w2v_ctc_loss=0.708, task_loss=1.399, contrastive_loss=0.177, total=4134.44, n_correct=2721.9, ppl=4.5, accuracy=65.835, wps=11951.1, ups=1.45, wpb=8268.9, bsz=304.8, num_updates=21600, lr=9.6225e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=15.8, wall=19324
2023-08-13 18:11:05 | INFO | train_inner | epoch 015:   1075 / 1474 loss=2.026, trans_loss=4.934, nll_loss=2.184, w2v_ctc_loss=0.713, task_loss=1.325, contrastive_loss=0.333, total=4185.02, n_correct=2741.36, ppl=4.54, accuracy=65.504, wps=11946.3, ups=1.43, wpb=8370, bsz=324.2, num_updates=21700, lr=9.60031e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=70, gb_free=16.4, wall=19394
2023-08-13 18:12:14 | INFO | train_inner | epoch 015:   1175 / 1474 loss=1.992, trans_loss=4.919, nll_loss=2.166, w2v_ctc_loss=0.695, task_loss=1.257, contrastive_loss=0.14, total=4187.68, n_correct=2764.21, ppl=4.49, accuracy=66.008, wps=12028.2, ups=1.44, wpb=8375.4, bsz=329.7, num_updates=21800, lr=9.57826e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=19464
2023-08-13 18:13:23 | INFO | train_inner | epoch 015:   1275 / 1474 loss=2.008, trans_loss=4.922, nll_loss=2.168, w2v_ctc_loss=0.729, task_loss=1.449, contrastive_loss=0.097, total=4141.6, n_correct=2719.18, ppl=4.49, accuracy=65.655, wps=11972.5, ups=1.45, wpb=8283.2, bsz=301.1, num_updates=21900, lr=9.55637e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=13, wall=19533
2023-08-13 18:14:33 | INFO | train_inner | epoch 015:   1375 / 1474 loss=1.998, trans_loss=4.921, nll_loss=2.166, w2v_ctc_loss=0.712, task_loss=1.452, contrastive_loss=0.084, total=4099.6, n_correct=2698.16, ppl=4.49, accuracy=65.815, wps=11788.3, ups=1.44, wpb=8199.2, bsz=293.2, num_updates=22000, lr=9.53463e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=14, wall=19603
2023-08-13 18:14:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 18:14:56 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.95 | trans_loss 5.174 | nll_loss 2.437 | w2v_ctc_loss 1.267 | task_loss 4.631 | contrastive_loss 0.302 | total 4003.4 | n_correct 2655.4 | ppl 5.42 | accuracy 66.329 | uer 17.976 | wer 19.846 | raw_wer 19.846 | bleu 22.17 | wps 2188.3 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 22.17
2023-08-13 18:14:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-08-13 18:14:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-08-13 18:15:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-08-13 18:15:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 22.17) (writing took 53.61084824241698 seconds)
2023-08-13 18:17:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 18:17:25 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.961 | trans_loss 5.173 | nll_loss 2.44 | w2v_ctc_loss 1.3 | task_loss 4.648 | contrastive_loss 0.318 | total 4003.4 | n_correct 2655.2 | ppl 5.43 | accuracy 66.324 | uer 18.191 | wer 20.26 | raw_wer 20.26 | bleu 21.88 | wps 2072.9 | wpb 4003.4 | bsz 141.8 | num_updates 22099 | best_bleu 22.17
2023-08-13 18:17:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22099 updates
2023-08-13 18:17:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.8801.pt
2023-08-13 18:17:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.8801.pt
2023-08-13 18:17:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.8801.pt (epoch 15 @ 22099 updates, score 21.88) (writing took 27.261710591614246 seconds)
2023-08-13 18:17:53 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-13 18:17:53 | INFO | train | epoch 015 | loss 2.004 | trans_loss 4.922 | nll_loss 2.169 | w2v_ctc_loss 0.711 | task_loss 1.405 | contrastive_loss 0.145 | total 4138.65 | n_correct 2722.28 | ppl 4.5 | accuracy 65.777 | wps 10498.9 | ups 1.27 | wpb 8277.3 | bsz 305.7 | num_updates 22099 | lr 9.51325e-05 | gnorm 0.525 | clip 0 | loss_scale 32 | train_wall 1018 | gb_free 16.7 | wall 19803
2023-08-13 18:17:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 18:17:53 | INFO | fairseq.trainer | begin training epoch 16
2023-08-13 18:17:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 18:18:01 | INFO | train_inner | epoch 016:      1 / 1474 loss=2.009, trans_loss=4.929, nll_loss=2.179, w2v_ctc_loss=0.712, task_loss=1.342, contrastive_loss=0.172, total=4149.9, n_correct=2726.25, ppl=4.53, accuracy=65.694, wps=3986.5, ups=0.48, wpb=8299.8, bsz=316.3, num_updates=22100, lr=9.51303e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=70, gb_free=17.1, wall=19811
2023-08-13 18:19:10 | INFO | train_inner | epoch 016:    101 / 1474 loss=1.987, trans_loss=4.904, nll_loss=2.146, w2v_ctc_loss=0.7, task_loss=1.35, contrastive_loss=0.112, total=4118.73, n_correct=2724.92, ppl=4.42, accuracy=66.159, wps=11951.8, ups=1.45, wpb=8237.5, bsz=314, num_updates=22200, lr=9.49158e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=19880
2023-08-13 18:20:19 | INFO | train_inner | epoch 016:    201 / 1474 loss=1.982, trans_loss=4.897, nll_loss=2.136, w2v_ctc_loss=0.693, task_loss=1.442, contrastive_loss=0.089, total=4106.45, n_correct=2722.32, ppl=4.39, accuracy=66.294, wps=11869.8, ups=1.45, wpb=8212.9, bsz=297.4, num_updates=22300, lr=9.47027e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=19949
2023-08-13 18:21:29 | INFO | train_inner | epoch 016:    301 / 1474 loss=1.997, trans_loss=4.905, nll_loss=2.146, w2v_ctc_loss=0.705, task_loss=1.389, contrastive_loss=0.162, total=4169.65, n_correct=2757.9, ppl=4.43, accuracy=66.142, wps=11912.4, ups=1.43, wpb=8339.3, bsz=309.9, num_updates=22400, lr=9.44911e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=70, gb_free=10.4, wall=20019
2023-08-13 18:22:39 | INFO | train_inner | epoch 016:    401 / 1474 loss=1.999, trans_loss=4.902, nll_loss=2.141, w2v_ctc_loss=0.708, task_loss=1.509, contrastive_loss=0.176, total=4063.79, n_correct=2686.02, ppl=4.41, accuracy=66.096, wps=11749, ups=1.45, wpb=8127.6, bsz=286.5, num_updates=22500, lr=9.42809e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=12.2, wall=20088
2023-08-13 18:23:48 | INFO | train_inner | epoch 016:    501 / 1474 loss=1.989, trans_loss=4.906, nll_loss=2.148, w2v_ctc_loss=0.7, task_loss=1.351, contrastive_loss=0.119, total=4179.53, n_correct=2771.13, ppl=4.43, accuracy=66.302, wps=11979.2, ups=1.43, wpb=8359.1, bsz=319.5, num_updates=22600, lr=9.40721e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=69, gb_free=17.5, wall=20158
2023-08-13 18:24:57 | INFO | train_inner | epoch 016:    601 / 1474 loss=1.994, trans_loss=4.911, nll_loss=2.154, w2v_ctc_loss=0.71, task_loss=1.415, contrastive_loss=0.085, total=4121.37, n_correct=2720.52, ppl=4.45, accuracy=66.01, wps=11978.3, ups=1.45, wpb=8242.7, bsz=297.5, num_updates=22700, lr=9.38647e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=68, gb_free=17.6, wall=20227
2023-08-13 18:26:06 | INFO | train_inner | epoch 016:    701 / 1474 loss=1.99, trans_loss=4.908, nll_loss=2.149, w2v_ctc_loss=0.709, task_loss=1.436, contrastive_loss=0.086, total=4099.17, n_correct=2710.08, ppl=4.44, accuracy=66.113, wps=11880.4, ups=1.45, wpb=8198.3, bsz=297.5, num_updates=22800, lr=9.36586e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=69, gb_free=16.5, wall=20296
2023-08-13 18:27:16 | INFO | train_inner | epoch 016:    801 / 1474 loss=1.988, trans_loss=4.901, nll_loss=2.142, w2v_ctc_loss=0.693, task_loss=1.342, contrastive_loss=0.148, total=4184.53, n_correct=2771.3, ppl=4.41, accuracy=66.227, wps=12033.2, ups=1.44, wpb=8369.1, bsz=313, num_updates=22900, lr=9.34539e-05, gnorm=0.519, clip=0, loss_scale=64, train_wall=69, gb_free=13.1, wall=20365
2023-08-13 18:28:25 | INFO | train_inner | epoch 016:    901 / 1474 loss=1.993, trans_loss=4.906, nll_loss=2.148, w2v_ctc_loss=0.7, task_loss=1.379, contrastive_loss=0.139, total=4151.84, n_correct=2744.84, ppl=4.43, accuracy=66.111, wps=11995.5, ups=1.44, wpb=8303.7, bsz=307, num_updates=23000, lr=9.32505e-05, gnorm=0.52, clip=0, loss_scale=64, train_wall=69, gb_free=16.5, wall=20435
2023-08-13 18:29:34 | INFO | train_inner | epoch 016:   1001 / 1474 loss=2.002, trans_loss=4.912, nll_loss=2.155, w2v_ctc_loss=0.715, task_loss=1.457, contrastive_loss=0.138, total=4112.79, n_correct=2709.76, ppl=4.45, accuracy=65.886, wps=11832, ups=1.44, wpb=8225.6, bsz=299.5, num_updates=23100, lr=9.30484e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=69, gb_free=14.5, wall=20504
2023-08-13 18:30:44 | INFO | train_inner | epoch 016:   1101 / 1474 loss=2, trans_loss=4.916, nll_loss=2.161, w2v_ctc_loss=0.712, task_loss=1.495, contrastive_loss=0.113, total=4111.6, n_correct=2707.07, ppl=4.47, accuracy=65.84, wps=11766.1, ups=1.43, wpb=8223.2, bsz=295.6, num_updates=23200, lr=9.28477e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=69, gb_free=14.4, wall=20574
2023-08-13 18:31:54 | INFO | train_inner | epoch 016:   1201 / 1474 loss=2, trans_loss=4.912, nll_loss=2.156, w2v_ctc_loss=0.693, task_loss=1.429, contrastive_loss=0.206, total=4157.51, n_correct=2742.16, ppl=4.46, accuracy=65.957, wps=11904.6, ups=1.43, wpb=8315, bsz=306.6, num_updates=23300, lr=9.26482e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=69, gb_free=14.5, wall=20644
2023-08-13 18:33:04 | INFO | train_inner | epoch 016:   1301 / 1474 loss=2, trans_loss=4.907, nll_loss=2.15, w2v_ctc_loss=0.708, task_loss=1.366, contrastive_loss=0.186, total=4151.03, n_correct=2745.72, ppl=4.44, accuracy=66.146, wps=11923.8, ups=1.44, wpb=8302.1, bsz=314.5, num_updates=23400, lr=9.245e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=69, gb_free=15.8, wall=20714
2023-08-13 18:34:14 | INFO | train_inner | epoch 016:   1401 / 1474 loss=1.991, trans_loss=4.907, nll_loss=2.149, w2v_ctc_loss=0.706, task_loss=1.342, contrastive_loss=0.116, total=4201.47, n_correct=2778.15, ppl=4.44, accuracy=66.123, wps=12035.2, ups=1.43, wpb=8402.9, bsz=320.7, num_updates=23500, lr=9.22531e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=69, gb_free=15.6, wall=20783
2023-08-13 18:35:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 18:35:29 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.948 | trans_loss 5.165 | nll_loss 2.425 | w2v_ctc_loss 1.282 | task_loss 4.672 | contrastive_loss 0.303 | total 4003.4 | n_correct 2665.3 | ppl 5.37 | accuracy 66.576 | uer 17.824 | wer 19.727 | raw_wer 19.727 | bleu 22.09 | wps 2074.8 | wpb 4003.4 | bsz 141.8 | num_updates 23573 | best_bleu 22.17
2023-08-13 18:35:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23573 updates
2023-08-13 18:35:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.0907.pt
2023-08-13 18:35:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.0907.pt
2023-08-13 18:35:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.0907.pt (epoch 16 @ 23573 updates, score 22.09) (writing took 24.917477330192924 seconds)
2023-08-13 18:35:54 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-13 18:35:54 | INFO | train | epoch 016 | loss 1.994 | trans_loss 4.907 | nll_loss 2.149 | w2v_ctc_loss 0.703 | task_loss 1.405 | contrastive_loss 0.143 | total 4138.65 | n_correct 2735.75 | ppl 4.43 | accuracy 66.102 | wps 11282.4 | ups 1.36 | wpb 8277.3 | bsz 305.7 | num_updates 23573 | lr 9.21102e-05 | gnorm 0.525 | clip 0 | loss_scale 64 | train_wall 1017 | gb_free 15.1 | wall 20884
2023-08-13 18:35:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 18:35:54 | INFO | fairseq.trainer | begin training epoch 17
2023-08-13 18:35:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 18:36:21 | INFO | train_inner | epoch 017:     27 / 1474 loss=1.994, trans_loss=4.895, nll_loss=2.134, w2v_ctc_loss=0.69, task_loss=1.436, contrastive_loss=0.25, total=4145.04, n_correct=2749.18, ppl=4.39, accuracy=66.325, wps=6526, ups=0.79, wpb=8290.1, bsz=302.4, num_updates=23600, lr=9.20575e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=69, gb_free=15.3, wall=20910
2023-08-13 18:37:30 | INFO | train_inner | epoch 017:    127 / 1474 loss=1.977, trans_loss=4.883, nll_loss=2.117, w2v_ctc_loss=0.694, task_loss=1.445, contrastive_loss=0.088, total=4117.27, n_correct=2739.43, ppl=4.34, accuracy=66.535, wps=11923.5, ups=1.45, wpb=8234.5, bsz=296.2, num_updates=23700, lr=9.1863e-05, gnorm=0.52, clip=0, loss_scale=64, train_wall=69, gb_free=17.5, wall=20980
2023-08-13 18:38:39 | INFO | train_inner | epoch 017:    227 / 1474 loss=1.992, trans_loss=4.884, nll_loss=2.119, w2v_ctc_loss=0.688, task_loss=1.33, contrastive_loss=0.252, total=4159.6, n_correct=2767.69, ppl=4.34, accuracy=66.537, wps=11980.2, ups=1.44, wpb=8319.2, bsz=317.6, num_updates=23800, lr=9.16698e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=69, gb_free=16.5, wall=21049
2023-08-13 18:39:48 | INFO | train_inner | epoch 017:    327 / 1474 loss=1.991, trans_loss=4.889, nll_loss=2.126, w2v_ctc_loss=0.689, task_loss=1.399, contrastive_loss=0.257, total=4156.91, n_correct=2761.88, ppl=4.36, accuracy=66.441, wps=12020.8, ups=1.45, wpb=8313.8, bsz=305.7, num_updates=23900, lr=9.14779e-05, gnorm=0.519, clip=0, loss_scale=64, train_wall=69, gb_free=17.2, wall=21118
2023-08-13 18:40:58 | INFO | train_inner | epoch 017:    427 / 1474 loss=1.976, trans_loss=4.889, nll_loss=2.125, w2v_ctc_loss=0.693, task_loss=1.398, contrastive_loss=0.087, total=4146.43, n_correct=2761.02, ppl=4.36, accuracy=66.588, wps=11856.7, ups=1.43, wpb=8292.9, bsz=308, num_updates=24000, lr=9.12871e-05, gnorm=0.519, clip=0, loss_scale=64, train_wall=69, gb_free=15.9, wall=21188
2023-08-13 18:40:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 18:41:23 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.969 | trans_loss 5.169 | nll_loss 2.429 | w2v_ctc_loss 1.345 | task_loss 4.671 | contrastive_loss 0.3 | total 4003.4 | n_correct 2657.4 | ppl 5.39 | accuracy 66.379 | uer 17.97 | wer 19.846 | raw_wer 19.846 | bleu 22.34 | wps 2055.3 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 22.34
2023-08-13 18:41:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-08-13 18:41:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-08-13 18:41:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-08-13 18:42:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 22.34) (writing took 49.410809924826026 seconds)
2023-08-13 18:43:24 | INFO | train_inner | epoch 017:    527 / 1474 loss=1.984, trans_loss=4.893, nll_loss=2.131, w2v_ctc_loss=0.695, task_loss=1.459, contrastive_loss=0.131, total=4182.1, n_correct=2773.44, ppl=4.38, accuracy=66.317, wps=5736.2, ups=0.69, wpb=8364.2, bsz=307.9, num_updates=24100, lr=9.10975e-05, gnorm=0.518, clip=0, loss_scale=64, train_wall=70, gb_free=16.5, wall=21334
2023-08-13 18:44:33 | INFO | train_inner | epoch 017:    627 / 1474 loss=1.975, trans_loss=4.891, nll_loss=2.128, w2v_ctc_loss=0.688, task_loss=1.417, contrastive_loss=0.083, total=4167.27, n_correct=2771.5, ppl=4.37, accuracy=66.506, wps=12042.7, ups=1.44, wpb=8334.5, bsz=302.2, num_updates=24200, lr=9.09091e-05, gnorm=0.512, clip=0, loss_scale=64, train_wall=69, gb_free=10.3, wall=21403
2023-08-13 18:45:43 | INFO | train_inner | epoch 017:    727 / 1474 loss=1.994, trans_loss=4.897, nll_loss=2.136, w2v_ctc_loss=0.713, task_loss=1.393, contrastive_loss=0.132, total=4166.12, n_correct=2758.55, ppl=4.39, accuracy=66.214, wps=11979.7, ups=1.44, wpb=8332.2, bsz=308.1, num_updates=24300, lr=9.07218e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=69, gb_free=16, wall=21473
2023-08-13 18:46:52 | INFO | train_inner | epoch 017:    827 / 1474 loss=1.981, trans_loss=4.891, nll_loss=2.128, w2v_ctc_loss=0.699, task_loss=1.426, contrastive_loss=0.095, total=4091.64, n_correct=2719.87, ppl=4.37, accuracy=66.474, wps=11863.2, ups=1.45, wpb=8183.3, bsz=295.3, num_updates=24400, lr=9.05357e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=68, gb_free=17, wall=21542
2023-08-13 18:48:00 | INFO | train_inner | epoch 017:    927 / 1474 loss=1.978, trans_loss=4.893, nll_loss=2.131, w2v_ctc_loss=0.693, task_loss=1.389, contrastive_loss=0.093, total=4106.83, n_correct=2726.37, ppl=4.38, accuracy=66.386, wps=11975.1, ups=1.46, wpb=8213.7, bsz=304.6, num_updates=24500, lr=9.03508e-05, gnorm=0.516, clip=0, loss_scale=64, train_wall=68, gb_free=15.5, wall=21610
2023-08-13 18:49:10 | INFO | train_inner | epoch 017:   1027 / 1474 loss=1.979, trans_loss=4.891, nll_loss=2.13, w2v_ctc_loss=0.696, task_loss=1.39, contrastive_loss=0.096, total=4115.49, n_correct=2732.26, ppl=4.38, accuracy=66.39, wps=11896.8, ups=1.45, wpb=8231, bsz=305.8, num_updates=24600, lr=9.0167e-05, gnorm=0.529, clip=0, loss_scale=64, train_wall=69, gb_free=16.4, wall=21679
2023-08-13 18:50:19 | INFO | train_inner | epoch 017:   1127 / 1474 loss=1.975, trans_loss=4.89, nll_loss=2.127, w2v_ctc_loss=0.687, task_loss=1.462, contrastive_loss=0.083, total=4078.39, n_correct=2713.8, ppl=4.37, accuracy=66.541, wps=11788.9, ups=1.45, wpb=8156.8, bsz=293.7, num_updates=24700, lr=8.99843e-05, gnorm=0.525, clip=0, loss_scale=128, train_wall=69, gb_free=15.2, wall=21749
2023-08-13 18:50:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-13 18:51:30 | INFO | train_inner | epoch 017:   1228 / 1474 loss=2, trans_loss=4.901, nll_loss=2.141, w2v_ctc_loss=0.694, task_loss=1.404, contrastive_loss=0.273, total=4148.2, n_correct=2745.38, ppl=4.41, accuracy=66.182, wps=11673.7, ups=1.41, wpb=8296.4, bsz=315.7, num_updates=24800, lr=8.98027e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=71, gb_free=15.7, wall=21820
2023-08-13 18:52:39 | INFO | train_inner | epoch 017:   1328 / 1474 loss=1.987, trans_loss=4.896, nll_loss=2.136, w2v_ctc_loss=0.686, task_loss=1.399, contrastive_loss=0.168, total=4149.03, n_correct=2752.29, ppl=4.39, accuracy=66.336, wps=11959, ups=1.44, wpb=8298.1, bsz=306.7, num_updates=24900, lr=8.96221e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=69, gb_free=16.6, wall=21889
2023-08-13 18:53:49 | INFO | train_inner | epoch 017:   1428 / 1474 loss=1.977, trans_loss=4.895, nll_loss=2.133, w2v_ctc_loss=0.69, task_loss=1.411, contrastive_loss=0.088, total=4117.13, n_correct=2735.39, ppl=4.39, accuracy=66.439, wps=11834.7, ups=1.44, wpb=8234.3, bsz=303.7, num_updates=25000, lr=8.94427e-05, gnorm=0.519, clip=0, loss_scale=64, train_wall=69, gb_free=17.2, wall=21959
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:0')
2023-08-13 18:54:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-13 18:54:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:3')
2023-08-13 18:54:44 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.962 | trans_loss 5.172 | nll_loss 2.436 | w2v_ctc_loss 1.311 | task_loss 4.672 | contrastive_loss 0.305 | total 4003.4 | n_correct 2658.1 | ppl 5.41 | accuracy 66.396 | uer 17.904 | wer 19.809 | raw_wer 19.809 | bleu 22.05 | wps 2195.3 | wpb 4003.4 | bsz 141.8 | num_updates 25045 | best_bleu 22.34
2023-08-13 18:54:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25045 updates
2023-08-13 18:54:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.0503.pt
2023-08-13 18:54:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.0503.pt
2023-08-13 18:55:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.0503.pt (epoch 17 @ 25045 updates, score 22.05) (writing took 22.283577861264348 seconds)
2023-08-13 18:55:07 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-13 18:55:07 | INFO | train | epoch 017 | loss 1.983 | trans_loss 4.891 | nll_loss 2.129 | w2v_ctc_loss 0.693 | task_loss 1.409 | contrastive_loss 0.136 | total 4136.6 | n_correct 2748.14 | ppl 4.37 | accuracy 66.435 | wps 10565.7 | ups 1.28 | wpb 8273.2 | bsz 305.1 | num_updates 25045 | lr 8.93623e-05 | gnorm 0.522 | clip 0 | loss_scale 32 | train_wall 1017 | gb_free 16.1 | wall 22037
2023-08-13 18:55:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 18:55:07 | INFO | fairseq.trainer | begin training epoch 18
2023-08-13 18:55:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 18:55:53 | INFO | train_inner | epoch 018:     55 / 1474 loss=1.975, trans_loss=4.883, nll_loss=2.118, w2v_ctc_loss=0.695, task_loss=1.44, contrastive_loss=0.098, total=4134.79, n_correct=2758.7, ppl=4.34, accuracy=66.719, wps=6639, ups=0.8, wpb=8269.6, bsz=302.5, num_updates=25100, lr=8.92644e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=70, gb_free=16.3, wall=22083
2023-08-13 18:57:03 | INFO | train_inner | epoch 018:    155 / 1474 loss=1.97, trans_loss=4.865, nll_loss=2.094, w2v_ctc_loss=0.664, task_loss=1.333, contrastive_loss=0.217, total=4158.38, n_correct=2783.8, ppl=4.27, accuracy=66.944, wps=11972.5, ups=1.44, wpb=8316.8, bsz=313.7, num_updates=25200, lr=8.90871e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=22153
2023-08-13 18:58:13 | INFO | train_inner | epoch 018:    255 / 1474 loss=1.961, trans_loss=4.866, nll_loss=2.095, w2v_ctc_loss=0.679, task_loss=1.364, contrastive_loss=0.089, total=4161.92, n_correct=2790.51, ppl=4.27, accuracy=67.049, wps=11926.6, ups=1.43, wpb=8323.8, bsz=312.8, num_updates=25300, lr=8.89108e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=22223
2023-08-13 18:59:22 | INFO | train_inner | epoch 018:    355 / 1474 loss=1.967, trans_loss=4.875, nll_loss=2.107, w2v_ctc_loss=0.677, task_loss=1.433, contrastive_loss=0.101, total=4167.42, n_correct=2782.58, ppl=4.31, accuracy=66.77, wps=12010.1, ups=1.44, wpb=8334.8, bsz=301.2, num_updates=25400, lr=8.87357e-05, gnorm=0.513, clip=0, loss_scale=32, train_wall=69, gb_free=15.1, wall=22292
2023-08-13 19:00:32 | INFO | train_inner | epoch 018:    455 / 1474 loss=1.982, trans_loss=4.879, nll_loss=2.113, w2v_ctc_loss=0.685, task_loss=1.506, contrastive_loss=0.193, total=4075.78, n_correct=2715.99, ppl=4.33, accuracy=66.637, wps=11585.4, ups=1.42, wpb=8151.6, bsz=294.2, num_updates=25500, lr=8.85615e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=70, gb_free=17.6, wall=22362
2023-08-13 19:01:42 | INFO | train_inner | epoch 018:    555 / 1474 loss=1.955, trans_loss=4.863, nll_loss=2.092, w2v_ctc_loss=0.668, task_loss=1.256, contrastive_loss=0.101, total=4218.07, n_correct=2832.52, ppl=4.26, accuracy=67.152, wps=12085, ups=1.43, wpb=8436.1, bsz=329.6, num_updates=25600, lr=8.83883e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=22432
2023-08-13 19:02:52 | INFO | train_inner | epoch 018:    655 / 1474 loss=1.986, trans_loss=4.887, nll_loss=2.124, w2v_ctc_loss=0.697, task_loss=1.454, contrastive_loss=0.17, total=4093.44, n_correct=2723.06, ppl=4.36, accuracy=66.523, wps=11783.9, ups=1.44, wpb=8186.9, bsz=298.5, num_updates=25700, lr=8.82162e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=14.9, wall=22502
2023-08-13 19:04:01 | INFO | train_inner | epoch 018:    755 / 1474 loss=1.988, trans_loss=4.881, nll_loss=2.116, w2v_ctc_loss=0.691, task_loss=1.339, contrastive_loss=0.258, total=4202.99, n_correct=2800.34, ppl=4.33, accuracy=66.627, wps=12127.9, ups=1.44, wpb=8406, bsz=322.5, num_updates=25800, lr=8.80451e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=17.3, wall=22571
2023-08-13 19:05:11 | INFO | train_inner | epoch 018:    855 / 1474 loss=1.968, trans_loss=4.876, nll_loss=2.109, w2v_ctc_loss=0.684, task_loss=1.417, contrastive_loss=0.087, total=4177.43, n_correct=2788.2, ppl=4.31, accuracy=66.744, wps=12029.5, ups=1.44, wpb=8354.9, bsz=304.8, num_updates=25900, lr=8.7875e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=15.8, wall=22640
2023-08-13 19:06:19 | INFO | train_inner | epoch 018:    955 / 1474 loss=1.958, trans_loss=4.869, nll_loss=2.101, w2v_ctc_loss=0.668, task_loss=1.308, contrastive_loss=0.094, total=4138.23, n_correct=2770.38, ppl=4.29, accuracy=66.946, wps=12031.9, ups=1.45, wpb=8276.5, bsz=314.5, num_updates=26000, lr=8.77058e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=22709
2023-08-13 19:06:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 19:06:43 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.957 | trans_loss 5.169 | nll_loss 2.428 | w2v_ctc_loss 1.307 | task_loss 4.627 | contrastive_loss 0.301 | total 4003.4 | n_correct 2657.5 | ppl 5.38 | accuracy 66.381 | uer 17.689 | wer 19.597 | raw_wer 19.597 | bleu 22.3 | wps 2113.9 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 22.34
2023-08-13 19:06:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-08-13 19:06:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-08-13 19:06:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-08-13 19:07:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 22.3) (writing took 37.09318558871746 seconds)
2023-08-13 19:08:31 | INFO | train_inner | epoch 018:   1055 / 1474 loss=1.968, trans_loss=4.877, nll_loss=2.111, w2v_ctc_loss=0.679, task_loss=1.478, contrastive_loss=0.088, total=4133.59, n_correct=2758.21, ppl=4.32, accuracy=66.727, wps=6292.4, ups=0.76, wpb=8267.2, bsz=298.7, num_updates=26100, lr=8.75376e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=22841
2023-08-13 19:09:40 | INFO | train_inner | epoch 018:   1155 / 1474 loss=1.974, trans_loss=4.87, nll_loss=2.102, w2v_ctc_loss=0.68, task_loss=1.328, contrastive_loss=0.192, total=4154.22, n_correct=2779.18, ppl=4.29, accuracy=66.9, wps=12023.6, ups=1.45, wpb=8308.4, bsz=315.1, num_updates=26200, lr=8.73704e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=69, gb_free=14.7, wall=22910
2023-08-13 19:10:49 | INFO | train_inner | epoch 018:   1255 / 1474 loss=1.971, trans_loss=4.884, nll_loss=2.12, w2v_ctc_loss=0.684, task_loss=1.51, contrastive_loss=0.083, total=4089.17, n_correct=2725.6, ppl=4.35, accuracy=66.654, wps=11867.8, ups=1.45, wpb=8178.3, bsz=287.6, num_updates=26300, lr=8.72041e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=22979
2023-08-13 19:11:58 | INFO | train_inner | epoch 018:   1355 / 1474 loss=1.985, trans_loss=4.887, nll_loss=2.124, w2v_ctc_loss=0.704, task_loss=1.501, contrastive_loss=0.11, total=4068.84, n_correct=2704.98, ppl=4.36, accuracy=66.48, wps=11796.7, ups=1.45, wpb=8137.7, bsz=291.4, num_updates=26400, lr=8.70388e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=15.1, wall=23048
2023-08-13 19:13:07 | INFO | train_inner | epoch 018:   1455 / 1474 loss=1.978, trans_loss=4.884, nll_loss=2.119, w2v_ctc_loss=0.697, task_loss=1.489, contrastive_loss=0.095, total=4113.23, n_correct=2740.66, ppl=4.35, accuracy=66.63, wps=11823.4, ups=1.44, wpb=8226.5, bsz=297.2, num_updates=26500, lr=8.68744e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=23117
2023-08-13 19:13:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 19:13:47 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.958 | trans_loss 5.162 | nll_loss 2.423 | w2v_ctc_loss 1.325 | task_loss 4.652 | contrastive_loss 0.299 | total 4003.4 | n_correct 2667.2 | ppl 5.36 | accuracy 66.623 | uer 17.551 | wer 19.44 | raw_wer 19.44 | bleu 22.42 | wps 1816.2 | wpb 4003.4 | bsz 141.8 | num_updates 26519 | best_bleu 22.42
2023-08-13 19:13:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26519 updates
2023-08-13 19:13:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 19:14:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 19:14:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 18 @ 26519 updates, score 22.42) (writing took 29.226533375680447 seconds)
2023-08-13 19:14:17 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-13 19:14:17 | INFO | train | epoch 018 | loss 1.972 | trans_loss 4.876 | nll_loss 2.109 | w2v_ctc_loss 0.683 | task_loss 1.406 | contrastive_loss 0.137 | total 4138.65 | n_correct 2763.29 | ppl 4.31 | accuracy 66.768 | wps 10606.2 | ups 1.28 | wpb 8277.3 | bsz 305.7 | num_updates 26519 | lr 8.68433e-05 | gnorm 0.523 | clip 0 | loss_scale 32 | train_wall 1018 | gb_free 15.7 | wall 23187
2023-08-13 19:14:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 19:14:17 | INFO | fairseq.trainer | begin training epoch 19
2023-08-13 19:14:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 19:15:20 | INFO | train_inner | epoch 019:     81 / 1474 loss=1.964, trans_loss=4.859, nll_loss=2.087, w2v_ctc_loss=0.674, task_loss=1.397, contrastive_loss=0.145, total=4107.26, n_correct=2754.93, ppl=4.25, accuracy=67.075, wps=6172.3, ups=0.75, wpb=8214.5, bsz=297.5, num_updates=26600, lr=8.6711e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=12.3, wall=23250
2023-08-13 19:16:31 | INFO | train_inner | epoch 019:    181 / 1474 loss=1.966, trans_loss=4.859, nll_loss=2.086, w2v_ctc_loss=0.684, task_loss=1.31, contrastive_loss=0.136, total=4222.18, n_correct=2835.6, ppl=4.25, accuracy=67.16, wps=12024.4, ups=1.42, wpb=8444.4, bsz=324.4, num_updates=26700, lr=8.65485e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=70, gb_free=11.3, wall=23320
2023-08-13 19:17:40 | INFO | train_inner | epoch 019:    281 / 1474 loss=1.952, trans_loss=4.852, nll_loss=2.078, w2v_ctc_loss=0.672, task_loss=1.379, contrastive_loss=0.079, total=4187.37, n_correct=2817.45, ppl=4.22, accuracy=67.284, wps=12136, ups=1.45, wpb=8374.7, bsz=307, num_updates=26800, lr=8.63868e-05, gnorm=0.514, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=23389
2023-08-13 19:18:49 | INFO | train_inner | epoch 019:    381 / 1474 loss=1.965, trans_loss=4.856, nll_loss=2.083, w2v_ctc_loss=0.669, task_loss=1.387, contrastive_loss=0.184, total=4170.67, n_correct=2798.54, ppl=4.24, accuracy=67.1, wps=12083.6, ups=1.45, wpb=8341.3, bsz=310.5, num_updates=26900, lr=8.62261e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=23458
2023-08-13 19:19:58 | INFO | train_inner | epoch 019:    481 / 1474 loss=1.965, trans_loss=4.864, nll_loss=2.093, w2v_ctc_loss=0.686, task_loss=1.442, contrastive_loss=0.095, total=4115.22, n_correct=2755.62, ppl=4.27, accuracy=66.962, wps=11957.7, ups=1.45, wpb=8230.4, bsz=301.9, num_updates=27000, lr=8.60663e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=68, gb_free=14.8, wall=23527
2023-08-13 19:21:07 | INFO | train_inner | epoch 019:    581 / 1474 loss=1.96, trans_loss=4.857, nll_loss=2.084, w2v_ctc_loss=0.67, task_loss=1.379, contrastive_loss=0.158, total=4129.22, n_correct=2774.24, ppl=4.24, accuracy=67.186, wps=11962.1, ups=1.45, wpb=8258.4, bsz=306, num_updates=27100, lr=8.59074e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=69, gb_free=15.6, wall=23596
2023-08-13 19:22:16 | INFO | train_inner | epoch 019:    681 / 1474 loss=1.951, trans_loss=4.863, nll_loss=2.093, w2v_ctc_loss=0.661, task_loss=1.283, contrastive_loss=0.086, total=4197.2, n_correct=2818.57, ppl=4.27, accuracy=67.154, wps=12130.5, ups=1.45, wpb=8394.4, bsz=320.8, num_updates=27200, lr=8.57493e-05, gnorm=0.51, clip=0, loss_scale=64, train_wall=69, gb_free=14.3, wall=23666
2023-08-13 19:23:25 | INFO | train_inner | epoch 019:    781 / 1474 loss=1.962, trans_loss=4.862, nll_loss=2.09, w2v_ctc_loss=0.679, task_loss=1.414, contrastive_loss=0.099, total=4142.6, n_correct=2776.1, ppl=4.26, accuracy=67.013, wps=11898.7, ups=1.44, wpb=8285.2, bsz=305.1, num_updates=27300, lr=8.55921e-05, gnorm=0.52, clip=0, loss_scale=64, train_wall=69, gb_free=15.9, wall=23735
2023-08-13 19:24:34 | INFO | train_inner | epoch 019:    881 / 1474 loss=1.964, trans_loss=4.869, nll_loss=2.1, w2v_ctc_loss=0.683, task_loss=1.437, contrastive_loss=0.083, total=4153.47, n_correct=2780.04, ppl=4.29, accuracy=66.933, wps=12044, ups=1.45, wpb=8306.9, bsz=303.1, num_updates=27400, lr=8.54358e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=69, gb_free=15.9, wall=23804
2023-08-13 19:25:45 | INFO | train_inner | epoch 019:    981 / 1474 loss=1.985, trans_loss=4.875, nll_loss=2.108, w2v_ctc_loss=0.675, task_loss=1.403, contrastive_loss=0.316, total=4101.29, n_correct=2739.19, ppl=4.31, accuracy=66.788, wps=11641.8, ups=1.42, wpb=8202.6, bsz=309.9, num_updates=27500, lr=8.52803e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=70, gb_free=16.4, wall=23875
2023-08-13 19:26:54 | INFO | train_inner | epoch 019:   1081 / 1474 loss=1.967, trans_loss=4.873, nll_loss=2.105, w2v_ctc_loss=0.674, task_loss=1.503, contrastive_loss=0.126, total=4036.97, n_correct=2698.63, ppl=4.3, accuracy=66.848, wps=11668.5, ups=1.45, wpb=8073.9, bsz=291, num_updates=27600, lr=8.51257e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=69, gb_free=14.3, wall=23944
2023-08-13 19:28:04 | INFO | train_inner | epoch 019:   1181 / 1474 loss=1.979, trans_loss=4.872, nll_loss=2.103, w2v_ctc_loss=0.684, task_loss=1.43, contrastive_loss=0.208, total=4137.49, n_correct=2764.26, ppl=4.3, accuracy=66.81, wps=11842.1, ups=1.43, wpb=8275, bsz=307.7, num_updates=27700, lr=8.49719e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=69, gb_free=14.4, wall=24014
2023-08-13 19:29:13 | INFO | train_inner | epoch 019:   1281 / 1474 loss=1.966, trans_loss=4.871, nll_loss=2.103, w2v_ctc_loss=0.674, task_loss=1.426, contrastive_loss=0.107, total=4141.89, n_correct=2769.91, ppl=4.3, accuracy=66.876, wps=12047.6, ups=1.45, wpb=8283.8, bsz=300.1, num_updates=27800, lr=8.48189e-05, gnorm=0.52, clip=0, loss_scale=64, train_wall=68, gb_free=15.3, wall=24082
2023-08-13 19:30:22 | INFO | train_inner | epoch 019:   1381 / 1474 loss=1.963, trans_loss=4.867, nll_loss=2.097, w2v_ctc_loss=0.678, task_loss=1.435, contrastive_loss=0.093, total=4133.26, n_correct=2767.68, ppl=4.28, accuracy=66.961, wps=11960.3, ups=1.45, wpb=8266.5, bsz=301, num_updates=27900, lr=8.46668e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=69, gb_free=15.9, wall=24152
2023-08-13 19:31:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 19:31:50 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.947 | trans_loss 5.158 | nll_loss 2.415 | w2v_ctc_loss 1.294 | task_loss 4.657 | contrastive_loss 0.308 | total 4003.4 | n_correct 2672.1 | ppl 5.33 | accuracy 66.746 | uer 17.785 | wer 19.831 | raw_wer 19.831 | bleu 22.57 | wps 2157.6 | wpb 4003.4 | bsz 141.8 | num_updates 27993 | best_bleu 22.57
2023-08-13 19:31:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27993 updates
2023-08-13 19:31:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 19:32:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 19:32:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 19 @ 27993 updates, score 22.57) (writing took 28.245958663523197 seconds)
2023-08-13 19:32:19 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-13 19:32:19 | INFO | train | epoch 019 | loss 1.965 | trans_loss 4.863 | nll_loss 2.093 | w2v_ctc_loss 0.676 | task_loss 1.405 | contrastive_loss 0.136 | total 4138.65 | n_correct 2773.87 | ppl 4.27 | accuracy 67.024 | wps 11277.8 | ups 1.36 | wpb 8277.3 | bsz 305.7 | num_updates 27993 | lr 8.4526e-05 | gnorm 0.523 | clip 0 | loss_scale 64 | train_wall 1015 | gb_free 17.1 | wall 24269
2023-08-13 19:32:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 19:32:19 | INFO | fairseq.trainer | begin training epoch 20
2023-08-13 19:32:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 19:32:31 | INFO | train_inner | epoch 020:      7 / 1474 loss=1.963, trans_loss=4.857, nll_loss=2.085, w2v_ctc_loss=0.671, task_loss=1.417, contrastive_loss=0.174, total=4119.08, n_correct=2764.56, ppl=4.24, accuracy=67.116, wps=6381.8, ups=0.77, wpb=8238.2, bsz=304.1, num_updates=28000, lr=8.45154e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=69, gb_free=15.9, wall=24281
2023-08-13 19:32:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 19:32:55 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.95 | trans_loss 5.157 | nll_loss 2.414 | w2v_ctc_loss 1.312 | task_loss 4.669 | contrastive_loss 0.302 | total 4003.4 | n_correct 2676.1 | ppl 5.33 | accuracy 66.846 | uer 17.705 | wer 19.69 | raw_wer 19.69 | bleu 22.45 | wps 2077 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 22.57
2023-08-13 19:32:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-08-13 19:32:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-08-13 19:32:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-08-13 19:33:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 22.45) (writing took 16.981874594464898 seconds)
2023-08-13 19:34:23 | INFO | train_inner | epoch 020:    107 / 1474 loss=1.942, trans_loss=4.837, nll_loss=2.058, w2v_ctc_loss=0.656, task_loss=1.361, contrastive_loss=0.099, total=4195.03, n_correct=2836.36, ppl=4.16, accuracy=67.612, wps=7487.5, ups=0.89, wpb=8390.1, bsz=313.7, num_updates=28100, lr=8.43649e-05, gnorm=0.516, clip=0, loss_scale=64, train_wall=69, gb_free=14.7, wall=24393
2023-08-13 19:35:33 | INFO | train_inner | epoch 020:    207 / 1474 loss=1.956, trans_loss=4.848, nll_loss=2.072, w2v_ctc_loss=0.668, task_loss=1.46, contrastive_loss=0.151, total=4154.14, n_correct=2798.82, ppl=4.21, accuracy=67.374, wps=11804.9, ups=1.42, wpb=8308.3, bsz=301, num_updates=28200, lr=8.42152e-05, gnorm=0.517, clip=0, loss_scale=64, train_wall=70, gb_free=16.9, wall=24463
2023-08-13 19:36:42 | INFO | train_inner | epoch 020:    307 / 1474 loss=1.942, trans_loss=4.842, nll_loss=2.065, w2v_ctc_loss=0.661, task_loss=1.269, contrastive_loss=0.088, total=4188.05, n_correct=2829.48, ppl=4.19, accuracy=67.561, wps=12114.7, ups=1.45, wpb=8376.1, bsz=326.2, num_updates=28300, lr=8.40663e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=69, gb_free=15.3, wall=24532
2023-08-13 19:37:52 | INFO | train_inner | epoch 020:    407 / 1474 loss=1.945, trans_loss=4.84, nll_loss=2.061, w2v_ctc_loss=0.662, task_loss=1.426, contrastive_loss=0.086, total=4115.16, n_correct=2779.79, ppl=4.17, accuracy=67.55, wps=11916.8, ups=1.45, wpb=8230.3, bsz=297, num_updates=28400, lr=8.39181e-05, gnorm=0.518, clip=0, loss_scale=64, train_wall=69, gb_free=15.2, wall=24601
2023-08-13 19:39:01 | INFO | train_inner | epoch 020:    507 / 1474 loss=1.957, trans_loss=4.852, nll_loss=2.078, w2v_ctc_loss=0.659, task_loss=1.438, contrastive_loss=0.173, total=4108.46, n_correct=2765.11, ppl=4.22, accuracy=67.303, wps=11862.6, ups=1.44, wpb=8216.9, bsz=300.4, num_updates=28500, lr=8.37708e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=69, gb_free=16.1, wall=24671
2023-08-13 19:40:10 | INFO | train_inner | epoch 020:    607 / 1474 loss=1.963, trans_loss=4.852, nll_loss=2.077, w2v_ctc_loss=0.669, task_loss=1.477, contrastive_loss=0.176, total=4094.9, n_correct=2751.33, ppl=4.22, accuracy=67.189, wps=11851.2, ups=1.45, wpb=8189.8, bsz=296.1, num_updates=28600, lr=8.36242e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=69, gb_free=11.5, wall=24740
2023-08-13 19:41:19 | INFO | train_inner | epoch 020:    707 / 1474 loss=1.954, trans_loss=4.854, nll_loss=2.08, w2v_ctc_loss=0.675, task_loss=1.407, contrastive_loss=0.081, total=4140.23, n_correct=2782.8, ppl=4.23, accuracy=67.214, wps=11949.9, ups=1.44, wpb=8280.5, bsz=300.6, num_updates=28700, lr=8.34784e-05, gnorm=0.519, clip=0, loss_scale=64, train_wall=69, gb_free=15.9, wall=24809
2023-08-13 19:42:28 | INFO | train_inner | epoch 020:    807 / 1474 loss=1.952, trans_loss=4.854, nll_loss=2.081, w2v_ctc_loss=0.672, task_loss=1.394, contrastive_loss=0.082, total=4140.66, n_correct=2784.26, ppl=4.23, accuracy=67.242, wps=11997.2, ups=1.45, wpb=8281.3, bsz=305.6, num_updates=28800, lr=8.33333e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=69, gb_free=17.3, wall=24878
2023-08-13 19:42:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-13 19:43:39 | INFO | train_inner | epoch 020:    908 / 1474 loss=1.971, trans_loss=4.858, nll_loss=2.086, w2v_ctc_loss=0.67, task_loss=1.374, contrastive_loss=0.269, total=4136.06, n_correct=2774.33, ppl=4.25, accuracy=67.077, wps=11701.1, ups=1.41, wpb=8272.1, bsz=315.6, num_updates=28900, lr=8.3189e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=70, gb_free=17.2, wall=24949
2023-08-13 19:44:49 | INFO | train_inner | epoch 020:   1008 / 1474 loss=1.948, trans_loss=4.852, nll_loss=2.078, w2v_ctc_loss=0.66, task_loss=1.401, contrastive_loss=0.089, total=4168.14, n_correct=2806.54, ppl=4.22, accuracy=67.333, wps=11870.8, ups=1.42, wpb=8336.3, bsz=307.3, num_updates=29000, lr=8.30455e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=70, gb_free=16.1, wall=25019
2023-08-13 19:45:58 | INFO | train_inner | epoch 020:   1108 / 1474 loss=1.969, trans_loss=4.856, nll_loss=2.084, w2v_ctc_loss=0.668, task_loss=1.355, contrastive_loss=0.227, total=4166.49, n_correct=2799.16, ppl=4.24, accuracy=67.183, wps=12043.5, ups=1.45, wpb=8333, bsz=315.4, num_updates=29100, lr=8.29027e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=14.5, wall=25088
2023-08-13 19:47:08 | INFO | train_inner | epoch 020:   1208 / 1474 loss=1.955, trans_loss=4.846, nll_loss=2.07, w2v_ctc_loss=0.68, task_loss=1.552, contrastive_loss=0.078, total=4029.18, n_correct=2711.08, ppl=4.2, accuracy=67.286, wps=11608, ups=1.44, wpb=8058.4, bsz=284, num_updates=29200, lr=8.27606e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=11.4, wall=25158
2023-08-13 19:48:18 | INFO | train_inner | epoch 020:   1308 / 1474 loss=1.954, trans_loss=4.856, nll_loss=2.083, w2v_ctc_loss=0.669, task_loss=1.481, contrastive_loss=0.084, total=4123.21, n_correct=2771.33, ppl=4.24, accuracy=67.213, wps=11822.9, ups=1.43, wpb=8246.4, bsz=297.1, num_updates=29300, lr=8.26192e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=17.1, wall=25227
2023-08-13 19:49:27 | INFO | train_inner | epoch 020:   1408 / 1474 loss=1.956, trans_loss=4.855, nll_loss=2.082, w2v_ctc_loss=0.673, task_loss=1.482, contrastive_loss=0.082, total=4116.28, n_correct=2765, ppl=4.23, accuracy=67.172, wps=11850.7, ups=1.44, wpb=8232.6, bsz=295, num_updates=29400, lr=8.24786e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=25297
2023-08-13 19:50:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 19:50:37 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.955 | trans_loss 5.16 | nll_loss 2.417 | w2v_ctc_loss 1.32 | task_loss 4.633 | contrastive_loss 0.298 | total 4003.4 | n_correct 2668.5 | ppl 5.34 | accuracy 66.656 | uer 17.49 | wer 19.332 | raw_wer 19.332 | bleu 22.33 | wps 2022.6 | wpb 4003.4 | bsz 141.8 | num_updates 29466 | best_bleu 22.57
2023-08-13 19:50:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29466 updates
2023-08-13 19:50:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.3303.pt
2023-08-13 19:50:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.3303.pt
2023-08-13 19:50:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.3303.pt (epoch 20 @ 29466 updates, score 22.33) (writing took 22.080322172492743 seconds)
2023-08-13 19:50:59 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-13 19:50:59 | INFO | train | epoch 020 | loss 1.954 | trans_loss 4.85 | nll_loss 2.076 | w2v_ctc_loss 0.667 | task_loss 1.409 | contrastive_loss 0.127 | total 4136.98 | n_correct 2784.58 | ppl 4.22 | accuracy 67.309 | wps 10878.4 | ups 1.31 | wpb 8274 | bsz 305.1 | num_updates 29466 | lr 8.23862e-05 | gnorm 0.522 | clip 0 | loss_scale 32 | train_wall 1017 | gb_free 15.9 | wall 25389
2023-08-13 19:51:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 19:51:00 | INFO | fairseq.trainer | begin training epoch 21
2023-08-13 19:51:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 19:51:31 | INFO | train_inner | epoch 021:     34 / 1474 loss=1.959, trans_loss=4.851, nll_loss=2.078, w2v_ctc_loss=0.66, task_loss=1.336, contrastive_loss=0.201, total=4152.26, n_correct=2796.32, ppl=4.22, accuracy=67.345, wps=6687.1, ups=0.81, wpb=8304.5, bsz=316.3, num_updates=29500, lr=8.23387e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=25421
2023-08-13 19:52:41 | INFO | train_inner | epoch 021:    134 / 1474 loss=1.948, trans_loss=4.83, nll_loss=2.05, w2v_ctc_loss=0.655, task_loss=1.313, contrastive_loss=0.191, total=4195.08, n_correct=2840.94, ppl=4.14, accuracy=67.721, wps=12059.5, ups=1.44, wpb=8390.2, bsz=319.6, num_updates=29600, lr=8.21995e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=25491
2023-08-13 19:53:50 | INFO | train_inner | epoch 021:    234 / 1474 loss=1.939, trans_loss=4.833, nll_loss=2.053, w2v_ctc_loss=0.647, task_loss=1.34, contrastive_loss=0.146, total=4155.31, n_correct=2814.12, ppl=4.15, accuracy=67.723, wps=11999.7, ups=1.44, wpb=8310.6, bsz=312.6, num_updates=29700, lr=8.2061e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=25560
2023-08-13 19:55:01 | INFO | train_inner | epoch 021:    334 / 1474 loss=1.951, trans_loss=4.839, nll_loss=2.061, w2v_ctc_loss=0.664, task_loss=1.389, contrastive_loss=0.15, total=4151.51, n_correct=2800.67, ppl=4.17, accuracy=67.461, wps=11785.2, ups=1.42, wpb=8303, bsz=310.8, num_updates=29800, lr=8.19232e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=70, gb_free=15.3, wall=25630
2023-08-13 19:56:09 | INFO | train_inner | epoch 021:    434 / 1474 loss=1.936, trans_loss=4.833, nll_loss=2.053, w2v_ctc_loss=0.651, task_loss=1.358, contrastive_loss=0.075, total=4180.85, n_correct=2832.53, ppl=4.15, accuracy=67.75, wps=12204.9, ups=1.46, wpb=8361.7, bsz=306.8, num_updates=29900, lr=8.17861e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=68, gb_free=15.4, wall=25699
2023-08-13 19:57:18 | INFO | train_inner | epoch 021:    534 / 1474 loss=1.939, trans_loss=4.829, nll_loss=2.048, w2v_ctc_loss=0.661, task_loss=1.465, contrastive_loss=0.075, total=4083.98, n_correct=2765.91, ppl=4.13, accuracy=67.726, wps=11843, ups=1.45, wpb=8168, bsz=295.1, num_updates=30000, lr=8.16497e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=12.7, wall=25768
2023-08-13 19:57:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 19:57:42 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.955 | trans_loss 5.16 | nll_loss 2.418 | w2v_ctc_loss 1.323 | task_loss 4.685 | contrastive_loss 0.302 | total 4003.4 | n_correct 2671.1 | ppl 5.35 | accuracy 66.721 | uer 17.578 | wer 19.664 | raw_wer 19.664 | bleu 22.04 | wps 2160.9 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 22.57
2023-08-13 19:57:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-08-13 19:57:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_21_30000.pt
2023-08-13 19:57:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_21_30000.pt
2023-08-13 19:58:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 22.04) (writing took 42.55782449617982 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:0')
2023-08-13 19:59:35 | INFO | train_inner | epoch 021:    634 / 1474 loss=1.953, trans_loss=4.834, nll_loss=2.055, w2v_ctc_loss=0.653, task_loss=1.392, contrastive_loss=0.244, total=4215.41, n_correct=2851.62, ppl=4.15, accuracy=67.648, wps=6159.8, ups=0.73, wpb=8430.8, bsz=315.4, num_updates=30100, lr=8.15139e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=10.8, wall=25905
2023-08-13 20:00:44 | INFO | train_inner | epoch 021:    734 / 1474 loss=1.946, trans_loss=4.843, nll_loss=2.067, w2v_ctc_loss=0.656, task_loss=1.401, contrastive_loss=0.107, total=4152.97, n_correct=2801.89, ppl=4.19, accuracy=67.467, wps=11986.8, ups=1.44, wpb=8305.9, bsz=309.3, num_updates=30200, lr=8.13788e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=25974
2023-08-13 20:01:54 | INFO | train_inner | epoch 021:    834 / 1474 loss=1.955, trans_loss=4.85, nll_loss=2.075, w2v_ctc_loss=0.665, task_loss=1.486, contrastive_loss=0.12, total=4066.93, n_correct=2738.74, ppl=4.21, accuracy=67.342, wps=11577.9, ups=1.42, wpb=8133.9, bsz=294.4, num_updates=30300, lr=8.12444e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=70, gb_free=16.7, wall=26044
2023-08-13 20:03:03 | INFO | train_inner | epoch 021:    934 / 1474 loss=1.941, trans_loss=4.836, nll_loss=2.058, w2v_ctc_loss=0.659, task_loss=1.407, contrastive_loss=0.092, total=4103.34, n_correct=2772.21, ppl=4.16, accuracy=67.56, wps=11928.4, ups=1.45, wpb=8206.7, bsz=301, num_updates=30400, lr=8.11107e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=13.7, wall=26113
2023-08-13 20:04:12 | INFO | train_inner | epoch 021:   1034 / 1474 loss=1.947, trans_loss=4.847, nll_loss=2.072, w2v_ctc_loss=0.662, task_loss=1.433, contrastive_loss=0.09, total=4099.86, n_correct=2765.85, ppl=4.2, accuracy=67.462, wps=11893.1, ups=1.45, wpb=8199.7, bsz=298.8, num_updates=30500, lr=8.09776e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=11, wall=26182
2023-08-13 20:05:22 | INFO | train_inner | epoch 021:   1134 / 1474 loss=1.947, trans_loss=4.838, nll_loss=2.059, w2v_ctc_loss=0.664, task_loss=1.51, contrastive_loss=0.093, total=4120.75, n_correct=2783.43, ppl=4.17, accuracy=67.547, wps=11861.2, ups=1.44, wpb=8241.5, bsz=293.5, num_updates=30600, lr=8.08452e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=69, gb_free=15.4, wall=26251
2023-08-13 20:06:31 | INFO | train_inner | epoch 021:   1234 / 1474 loss=1.949, trans_loss=4.841, nll_loss=2.064, w2v_ctc_loss=0.658, task_loss=1.333, contrastive_loss=0.146, total=4154.73, n_correct=2804.73, ppl=4.18, accuracy=67.507, wps=12013.3, ups=1.45, wpb=8309.5, bsz=311.6, num_updates=30700, lr=8.07134e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=12.3, wall=26321
2023-08-13 20:07:40 | INFO | train_inner | epoch 021:   1334 / 1474 loss=1.944, trans_loss=4.84, nll_loss=2.063, w2v_ctc_loss=0.658, task_loss=1.363, contrastive_loss=0.107, total=4147.17, n_correct=2804.55, ppl=4.18, accuracy=67.626, wps=11936.9, ups=1.44, wpb=8294.3, bsz=311.9, num_updates=30800, lr=8.05823e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=26390
2023-08-13 20:08:50 | INFO | train_inner | epoch 021:   1434 / 1474 loss=1.964, trans_loss=4.85, nll_loss=2.076, w2v_ctc_loss=0.68, task_loss=1.47, contrastive_loss=0.155, total=4133.93, n_correct=2777.63, ppl=4.22, accuracy=67.191, wps=11805.5, ups=1.43, wpb=8267.9, bsz=304.5, num_updates=30900, lr=8.04518e-05, gnorm=0.537, clip=0, loss_scale=64, train_wall=70, gb_free=15.2, wall=26460
2023-08-13 20:09:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:6')
2023-08-13 20:09:43 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.948 | trans_loss 5.161 | nll_loss 2.419 | w2v_ctc_loss 1.292 | task_loss 4.673 | contrastive_loss 0.306 | total 4003.4 | n_correct 2670.5 | ppl 5.35 | accuracy 66.706 | uer 17.633 | wer 19.667 | raw_wer 19.667 | bleu 22.16 | wps 2060.3 | wpb 4003.4 | bsz 141.8 | num_updates 30940 | best_bleu 22.57
2023-08-13 20:09:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30940 updates
2023-08-13 20:09:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.1602.pt
2023-08-13 20:09:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.1602.pt
2023-08-13 20:10:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.1602.pt (epoch 21 @ 30940 updates, score 22.16) (writing took 21.912174563854933 seconds)
2023-08-13 20:10:05 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-13 20:10:05 | INFO | train | epoch 021 | loss 1.947 | trans_loss 4.839 | nll_loss 2.061 | w2v_ctc_loss 0.659 | task_loss 1.405 | contrastive_loss 0.132 | total 4138.65 | n_correct 2795.91 | ppl 4.17 | accuracy 67.556 | wps 10646.8 | ups 1.29 | wpb 8277.3 | bsz 305.7 | num_updates 30940 | lr 8.03998e-05 | gnorm 0.525 | clip 0 | loss_scale 64 | train_wall 1017 | gb_free 15.1 | wall 26535
2023-08-13 20:10:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 20:10:06 | INFO | fairseq.trainer | begin training epoch 22
2023-08-13 20:10:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 20:10:54 | INFO | train_inner | epoch 022:     60 / 1474 loss=1.936, trans_loss=4.825, nll_loss=2.043, w2v_ctc_loss=0.657, task_loss=1.431, contrastive_loss=0.075, total=4128.84, n_correct=2804.41, ppl=4.12, accuracy=67.922, wps=6665.1, ups=0.81, wpb=8257.7, bsz=297.7, num_updates=31000, lr=8.03219e-05, gnorm=0.517, clip=0, loss_scale=64, train_wall=69, gb_free=13.8, wall=26584
2023-08-13 20:12:04 | INFO | train_inner | epoch 022:    160 / 1474 loss=1.942, trans_loss=4.823, nll_loss=2.041, w2v_ctc_loss=0.656, task_loss=1.414, contrastive_loss=0.156, total=4123.35, n_correct=2796.96, ppl=4.11, accuracy=67.832, wps=11828.7, ups=1.43, wpb=8246.7, bsz=310.3, num_updates=31100, lr=8.01927e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=69, gb_free=14.4, wall=26654
2023-08-13 20:13:14 | INFO | train_inner | epoch 022:    260 / 1474 loss=1.925, trans_loss=4.817, nll_loss=2.033, w2v_ctc_loss=0.641, task_loss=1.241, contrastive_loss=0.098, total=4267.16, n_correct=2907.32, ppl=4.09, accuracy=68.132, wps=12242.5, ups=1.43, wpb=8534.3, bsz=329.9, num_updates=31200, lr=8.00641e-05, gnorm=0.509, clip=0, loss_scale=64, train_wall=69, gb_free=16.4, wall=26724
2023-08-13 20:13:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-13 20:14:25 | INFO | train_inner | epoch 022:    361 / 1474 loss=1.945, trans_loss=4.829, nll_loss=2.047, w2v_ctc_loss=0.659, task_loss=1.464, contrastive_loss=0.141, total=4154.17, n_correct=2816.01, ppl=4.13, accuracy=67.788, wps=11606, ups=1.4, wpb=8308.3, bsz=302.4, num_updates=31300, lr=7.99361e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=71, gb_free=15.1, wall=26795
2023-08-13 20:15:35 | INFO | train_inner | epoch 022:    461 / 1474 loss=1.945, trans_loss=4.829, nll_loss=2.047, w2v_ctc_loss=0.654, task_loss=1.474, contrastive_loss=0.139, total=4132.96, n_correct=2801.28, ppl=4.13, accuracy=67.779, wps=11919, ups=1.44, wpb=8265.9, bsz=297.5, num_updates=31400, lr=7.98087e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=26864
2023-08-13 20:16:45 | INFO | train_inner | epoch 022:    561 / 1474 loss=1.931, trans_loss=4.822, nll_loss=2.039, w2v_ctc_loss=0.648, task_loss=1.407, contrastive_loss=0.086, total=4158.17, n_correct=2824.03, ppl=4.11, accuracy=67.915, wps=11882.2, ups=1.43, wpb=8316.3, bsz=307.8, num_updates=31500, lr=7.96819e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=70, gb_free=16.4, wall=26934
2023-08-13 20:17:53 | INFO | train_inner | epoch 022:    661 / 1474 loss=1.932, trans_loss=4.815, nll_loss=2.031, w2v_ctc_loss=0.639, task_loss=1.341, contrastive_loss=0.168, total=4139.66, n_correct=2820.3, ppl=4.09, accuracy=68.129, wps=12057.2, ups=1.46, wpb=8279.3, bsz=311.1, num_updates=31600, lr=7.95557e-05, gnorm=0.511, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=27003
2023-08-13 20:19:03 | INFO | train_inner | epoch 022:    761 / 1474 loss=1.936, trans_loss=4.824, nll_loss=2.041, w2v_ctc_loss=0.656, task_loss=1.442, contrastive_loss=0.087, total=4167.89, n_correct=2825.48, ppl=4.11, accuracy=67.792, wps=11896, ups=1.43, wpb=8335.8, bsz=303.9, num_updates=31700, lr=7.94301e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=70, gb_free=12.4, wall=27073
2023-08-13 20:20:13 | INFO | train_inner | epoch 022:    861 / 1474 loss=1.941, trans_loss=4.834, nll_loss=2.055, w2v_ctc_loss=0.659, task_loss=1.522, contrastive_loss=0.075, total=4075.79, n_correct=2753.11, ppl=4.16, accuracy=67.548, wps=11677.6, ups=1.43, wpb=8151.6, bsz=289, num_updates=31800, lr=7.93052e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=27143
2023-08-13 20:21:23 | INFO | train_inner | epoch 022:    961 / 1474 loss=1.931, trans_loss=4.824, nll_loss=2.042, w2v_ctc_loss=0.649, task_loss=1.416, contrastive_loss=0.075, total=4134.72, n_correct=2805.28, ppl=4.12, accuracy=67.847, wps=11845.8, ups=1.43, wpb=8269.4, bsz=303.2, num_updates=31900, lr=7.91808e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=13.8, wall=27213
2023-08-13 20:22:33 | INFO | train_inner | epoch 022:   1061 / 1474 loss=1.943, trans_loss=4.821, nll_loss=2.039, w2v_ctc_loss=0.642, task_loss=1.342, contrastive_loss=0.244, total=4160.57, n_correct=2826.93, ppl=4.11, accuracy=67.946, wps=11947.2, ups=1.44, wpb=8321.1, bsz=315.5, num_updates=32000, lr=7.90569e-05, gnorm=0.515, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=27282
2023-08-13 20:22:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 20:22:56 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.952 | trans_loss 5.16 | nll_loss 2.42 | w2v_ctc_loss 1.307 | task_loss 4.642 | contrastive_loss 0.308 | total 4003.4 | n_correct 2668.8 | ppl 5.35 | accuracy 66.663 | uer 17.67 | wer 19.6 | raw_wer 19.6 | bleu 22.25 | wps 1933.6 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 22.57
2023-08-13 20:22:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-08-13 20:22:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_22_32000.pt
2023-08-13 20:23:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_22_32000.pt
2023-08-13 20:23:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 22.25) (writing took 39.61051505431533 seconds)
2023-08-13 20:24:49 | INFO | train_inner | epoch 022:   1161 / 1474 loss=1.95, trans_loss=4.843, nll_loss=2.067, w2v_ctc_loss=0.66, task_loss=1.45, contrastive_loss=0.128, total=4099.59, n_correct=2771.36, ppl=4.19, accuracy=67.601, wps=6031.5, ups=0.74, wpb=8199.2, bsz=296.2, num_updates=32100, lr=7.89337e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=68, gb_free=14.6, wall=27418
2023-08-13 20:25:58 | INFO | train_inner | epoch 022:   1261 / 1474 loss=1.945, trans_loss=4.842, nll_loss=2.065, w2v_ctc_loss=0.657, task_loss=1.299, contrastive_loss=0.122, total=4182.05, n_correct=2826.68, ppl=4.19, accuracy=67.591, wps=12072.6, ups=1.44, wpb=8364.1, bsz=323, num_updates=32200, lr=7.8811e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=15.2, wall=27488
2023-08-13 20:27:07 | INFO | train_inner | epoch 022:   1361 / 1474 loss=1.938, trans_loss=4.825, nll_loss=2.044, w2v_ctc_loss=0.646, task_loss=1.404, contrastive_loss=0.143, total=4062.31, n_correct=2757.53, ppl=4.12, accuracy=67.881, wps=11743.6, ups=1.45, wpb=8124.6, bsz=299, num_updates=32300, lr=7.86889e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=14.7, wall=27557
2023-08-13 20:28:16 | INFO | train_inner | epoch 022:   1461 / 1474 loss=1.947, trans_loss=4.841, nll_loss=2.064, w2v_ctc_loss=0.665, task_loss=1.502, contrastive_loss=0.091, total=4081.88, n_correct=2756.93, ppl=4.18, accuracy=67.541, wps=11772.4, ups=1.44, wpb=8163.8, bsz=288.9, num_updates=32400, lr=7.85674e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=27626
2023-08-13 20:28:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 20:28:48 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.932 | trans_loss 5.152 | nll_loss 2.409 | w2v_ctc_loss 1.269 | task_loss 4.612 | contrastive_loss 0.294 | total 4003.4 | n_correct 2678.1 | ppl 5.31 | accuracy 66.896 | uer 17.495 | wer 19.57 | raw_wer 19.57 | bleu 22.5 | wps 2248.9 | wpb 4003.4 | bsz 141.8 | num_updates 32413 | best_bleu 22.57
2023-08-13 20:28:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32413 updates
2023-08-13 20:28:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.5008.pt
2023-08-13 20:28:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.5008.pt
2023-08-13 20:29:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.5008.pt (epoch 22 @ 32413 updates, score 22.5) (writing took 39.096189660951495 seconds)
2023-08-13 20:29:28 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-13 20:29:28 | INFO | train | epoch 022 | loss 1.939 | trans_loss 4.827 | nll_loss 2.046 | w2v_ctc_loss 0.653 | task_loss 1.408 | contrastive_loss 0.123 | total 4136.85 | n_correct 2805.59 | ppl 4.13 | accuracy 67.819 | wps 10483.5 | ups 1.27 | wpb 8273.7 | bsz 305.1 | num_updates 32413 | lr 7.85517e-05 | gnorm 0.522 | clip 0 | loss_scale 32 | train_wall 1018 | gb_free 11.3 | wall 27698
2023-08-13 20:29:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 20:29:28 | INFO | fairseq.trainer | begin training epoch 23
2023-08-13 20:29:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 20:30:35 | INFO | train_inner | epoch 023:     87 / 1474 loss=1.927, trans_loss=4.809, nll_loss=2.023, w2v_ctc_loss=0.652, task_loss=1.434, contrastive_loss=0.081, total=4096.09, n_correct=2792.36, ppl=4.06, accuracy=68.171, wps=5896.4, ups=0.72, wpb=8192.2, bsz=301.2, num_updates=32500, lr=7.84465e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=27765
2023-08-13 20:31:45 | INFO | train_inner | epoch 023:    187 / 1474 loss=1.923, trans_loss=4.803, nll_loss=2.014, w2v_ctc_loss=0.641, task_loss=1.495, contrastive_loss=0.08, total=4107.77, n_correct=2802.41, ppl=4.04, accuracy=68.222, wps=11808.1, ups=1.44, wpb=8215.5, bsz=293.4, num_updates=32600, lr=7.8326e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=27835
2023-08-13 20:32:55 | INFO | train_inner | epoch 023:    287 / 1474 loss=1.933, trans_loss=4.817, nll_loss=2.032, w2v_ctc_loss=0.638, task_loss=1.405, contrastive_loss=0.156, total=4153.12, n_correct=2825.91, ppl=4.09, accuracy=68.043, wps=11861.3, ups=1.43, wpb=8306.2, bsz=306.4, num_updates=32700, lr=7.82062e-05, gnorm=0.515, clip=0, loss_scale=32, train_wall=70, gb_free=16.7, wall=27905
2023-08-13 20:34:04 | INFO | train_inner | epoch 023:    387 / 1474 loss=1.922, trans_loss=4.806, nll_loss=2.018, w2v_ctc_loss=0.642, task_loss=1.458, contrastive_loss=0.071, total=4116.7, n_correct=2808.45, ppl=4.05, accuracy=68.221, wps=11978.8, ups=1.45, wpb=8233.4, bsz=294, num_updates=32800, lr=7.80869e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=68, gb_free=15, wall=27974
2023-08-13 20:35:13 | INFO | train_inner | epoch 023:    487 / 1474 loss=1.929, trans_loss=4.815, nll_loss=2.03, w2v_ctc_loss=0.639, task_loss=1.367, contrastive_loss=0.127, total=4157.6, n_correct=2831.29, ppl=4.08, accuracy=68.099, wps=12027.3, ups=1.45, wpb=8315.2, bsz=313.5, num_updates=32900, lr=7.79681e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=28043
2023-08-13 20:36:22 | INFO | train_inner | epoch 023:    587 / 1474 loss=1.921, trans_loss=4.809, nll_loss=2.022, w2v_ctc_loss=0.641, task_loss=1.329, contrastive_loss=0.076, total=4173.42, n_correct=2846.52, ppl=4.06, accuracy=68.206, wps=12084.2, ups=1.45, wpb=8346.8, bsz=316, num_updates=33000, lr=7.78499e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=69, gb_free=12.2, wall=28112
2023-08-13 20:37:31 | INFO | train_inner | epoch 023:    687 / 1474 loss=1.933, trans_loss=4.818, nll_loss=2.034, w2v_ctc_loss=0.647, task_loss=1.406, contrastive_loss=0.117, total=4137.82, n_correct=2813.34, ppl=4.1, accuracy=67.991, wps=11971.8, ups=1.45, wpb=8275.6, bsz=302.5, num_updates=33100, lr=7.77322e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=16.9, wall=28181
2023-08-13 20:38:40 | INFO | train_inner | epoch 023:    787 / 1474 loss=1.932, trans_loss=4.819, nll_loss=2.036, w2v_ctc_loss=0.65, task_loss=1.419, contrastive_loss=0.097, total=4150.99, n_correct=2825.7, ppl=4.1, accuracy=68.073, wps=12050.1, ups=1.45, wpb=8302, bsz=305.4, num_updates=33200, lr=7.76151e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=28250
2023-08-13 20:39:49 | INFO | train_inner | epoch 023:    887 / 1474 loss=1.932, trans_loss=4.812, nll_loss=2.026, w2v_ctc_loss=0.643, task_loss=1.287, contrastive_loss=0.173, total=4181.99, n_correct=2850.2, ppl=4.07, accuracy=68.154, wps=12109.2, ups=1.45, wpb=8364, bsz=324.7, num_updates=33300, lr=7.74984e-05, gnorm=0.52, clip=0, loss_scale=64, train_wall=69, gb_free=16.1, wall=28319
2023-08-13 20:40:59 | INFO | train_inner | epoch 023:    987 / 1474 loss=1.949, trans_loss=4.817, nll_loss=2.032, w2v_ctc_loss=0.64, task_loss=1.399, contrastive_loss=0.33, total=4168.73, n_correct=2832.78, ppl=4.09, accuracy=67.953, wps=11880.5, ups=1.42, wpb=8337.5, bsz=310.5, num_updates=33400, lr=7.73823e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=70, gb_free=10.5, wall=28389
2023-08-13 20:42:09 | INFO | train_inner | epoch 023:   1087 / 1474 loss=1.937, trans_loss=4.823, nll_loss=2.04, w2v_ctc_loss=0.658, task_loss=1.5, contrastive_loss=0.084, total=4088.49, n_correct=2774.26, ppl=4.11, accuracy=67.855, wps=11718.8, ups=1.43, wpb=8177, bsz=290, num_updates=33500, lr=7.72667e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=69, gb_free=15.5, wall=28459
2023-08-13 20:43:19 | INFO | train_inner | epoch 023:   1187 / 1474 loss=1.93, trans_loss=4.823, nll_loss=2.041, w2v_ctc_loss=0.652, task_loss=1.397, contrastive_loss=0.076, total=4162.7, n_correct=2829.43, ppl=4.12, accuracy=67.971, wps=11888, ups=1.43, wpb=8325.4, bsz=309.3, num_updates=33600, lr=7.71517e-05, gnorm=0.521, clip=0, loss_scale=64, train_wall=70, gb_free=15.8, wall=28529
2023-08-13 20:44:28 | INFO | train_inner | epoch 023:   1287 / 1474 loss=1.925, trans_loss=4.817, nll_loss=2.032, w2v_ctc_loss=0.642, task_loss=1.366, contrastive_loss=0.088, total=4135.53, n_correct=2815.08, ppl=4.09, accuracy=68.071, wps=11948.2, ups=1.44, wpb=8271.1, bsz=308.9, num_updates=33700, lr=7.70371e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=69, gb_free=16.5, wall=28598
2023-08-13 20:45:38 | INFO | train_inner | epoch 023:   1387 / 1474 loss=1.941, trans_loss=4.83, nll_loss=2.049, w2v_ctc_loss=0.648, task_loss=1.419, contrastive_loss=0.145, total=4143.98, n_correct=2812.21, ppl=4.14, accuracy=67.863, wps=11828.8, ups=1.43, wpb=8288, bsz=305.2, num_updates=33800, lr=7.69231e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=70, gb_free=15.5, wall=28668
2023-08-13 20:46:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-13 20:46:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 20:47:03 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 3.943 | trans_loss 5.155 | nll_loss 2.412 | w2v_ctc_loss 1.295 | task_loss 4.652 | contrastive_loss 0.299 | total 4003.4 | n_correct 2676.8 | ppl 5.32 | accuracy 66.863 | uer 17.339 | wer 19.235 | raw_wer 19.235 | bleu 22.23 | wps 2125.5 | wpb 4003.4 | bsz 141.8 | num_updates 33886 | best_bleu 22.57
2023-08-13 20:47:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33886 updates
2023-08-13 20:47:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.2305.pt
2023-08-13 20:47:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.2305.pt
2023-08-13 20:47:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.2305.pt (epoch 23 @ 33886 updates, score 22.23) (writing took 16.655372058972716 seconds)
2023-08-13 20:47:20 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-13 20:47:20 | INFO | train | epoch 023 | loss 1.931 | trans_loss 4.816 | nll_loss 2.032 | w2v_ctc_loss 0.645 | task_loss 1.409 | contrastive_loss 0.122 | total 4136.71 | n_correct 2815.12 | ppl 4.09 | accuracy 68.052 | wps 11367.7 | ups 1.37 | wpb 8273.4 | bsz 305 | num_updates 33886 | lr 7.68254e-05 | gnorm 0.522 | clip 0 | loss_scale 32 | train_wall 1017 | gb_free 13.4 | wall 28770
2023-08-13 20:47:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 20:47:20 | INFO | fairseq.trainer | begin training epoch 24
2023-08-13 20:47:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 20:47:38 | INFO | train_inner | epoch 024:     14 / 1474 loss=1.935, trans_loss=4.823, nll_loss=2.041, w2v_ctc_loss=0.648, task_loss=1.474, contrastive_loss=0.107, total=4056.29, n_correct=2753.34, ppl=4.11, accuracy=67.878, wps=6798.8, ups=0.84, wpb=8112.6, bsz=293.8, num_updates=33900, lr=7.68095e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=70, gb_free=15.1, wall=28787
2023-08-13 20:48:47 | INFO | train_inner | epoch 024:    114 / 1474 loss=1.928, trans_loss=4.798, nll_loss=2.007, w2v_ctc_loss=0.628, task_loss=1.297, contrastive_loss=0.237, total=4168.61, n_correct=2851.05, ppl=4.02, accuracy=68.393, wps=11957.4, ups=1.43, wpb=8337.2, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=10.9, wall=28857
2023-08-13 20:48:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 20:49:12 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.953 | trans_loss 5.16 | nll_loss 2.414 | w2v_ctc_loss 1.32 | task_loss 4.682 | contrastive_loss 0.292 | total 4003.4 | n_correct 2672.5 | ppl 5.33 | accuracy 66.756 | uer 17.408 | wer 19.358 | raw_wer 19.358 | bleu 22.13 | wps 2013.7 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 22.57
2023-08-13 20:49:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-08-13 20:49:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_24_34000.pt
2023-08-13 20:49:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_24_34000.pt
2023-08-13 20:49:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 22.13) (writing took 19.250155080109835 seconds)
2023-08-13 20:50:42 | INFO | train_inner | epoch 024:    214 / 1474 loss=1.931, trans_loss=4.803, nll_loss=2.015, w2v_ctc_loss=0.623, task_loss=1.226, contrastive_loss=0.291, total=4252.53, n_correct=2911.31, ppl=4.04, accuracy=68.461, wps=7438.2, ups=0.87, wpb=8505.1, bsz=341.3, num_updates=34100, lr=7.6584e-05, gnorm=0.513, clip=0, loss_scale=32, train_wall=70, gb_free=16.5, wall=28972
2023-08-13 20:51:51 | INFO | train_inner | epoch 024:    314 / 1474 loss=1.917, trans_loss=4.803, nll_loss=2.013, w2v_ctc_loss=0.638, task_loss=1.369, contrastive_loss=0.073, total=4138.44, n_correct=2828.78, ppl=4.04, accuracy=68.354, wps=11994.9, ups=1.45, wpb=8276.9, bsz=307.1, num_updates=34200, lr=7.64719e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=15.3, wall=29041
2023-08-13 20:53:00 | INFO | train_inner | epoch 024:    414 / 1474 loss=1.943, trans_loss=4.804, nll_loss=2.015, w2v_ctc_loss=0.649, task_loss=1.486, contrastive_loss=0.216, total=4153.83, n_correct=2826.88, ppl=4.04, accuracy=68.055, wps=11948.6, ups=1.44, wpb=8307.7, bsz=298.4, num_updates=34300, lr=7.63604e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=29110
2023-08-13 20:54:10 | INFO | train_inner | epoch 024:    514 / 1474 loss=1.927, trans_loss=4.803, nll_loss=2.014, w2v_ctc_loss=0.643, task_loss=1.435, contrastive_loss=0.141, total=4141.88, n_correct=2830.62, ppl=4.04, accuracy=68.341, wps=11856.9, ups=1.43, wpb=8283.8, bsz=302.6, num_updates=34400, lr=7.62493e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=14.8, wall=29180
2023-08-13 20:55:20 | INFO | train_inner | epoch 024:    614 / 1474 loss=1.921, trans_loss=4.804, nll_loss=2.015, w2v_ctc_loss=0.633, task_loss=1.412, contrastive_loss=0.104, total=4162.06, n_correct=2841.48, ppl=4.04, accuracy=68.271, wps=11955.6, ups=1.44, wpb=8324.1, bsz=308.1, num_updates=34500, lr=7.61387e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=29250
2023-08-13 20:56:29 | INFO | train_inner | epoch 024:    714 / 1474 loss=1.928, trans_loss=4.812, nll_loss=2.025, w2v_ctc_loss=0.638, task_loss=1.451, contrastive_loss=0.117, total=4097.35, n_correct=2791.26, ppl=4.07, accuracy=68.124, wps=11800.2, ups=1.44, wpb=8194.7, bsz=293.8, num_updates=34600, lr=7.60286e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=29319
2023-08-13 20:57:39 | INFO | train_inner | epoch 024:    814 / 1474 loss=1.925, trans_loss=4.814, nll_loss=2.03, w2v_ctc_loss=0.643, task_loss=1.401, contrastive_loss=0.094, total=4124.25, n_correct=2810.3, ppl=4.08, accuracy=68.141, wps=11900.1, ups=1.44, wpb=8248.5, bsz=308.2, num_updates=34700, lr=7.5919e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=15.8, wall=29388
2023-08-13 20:58:47 | INFO | train_inner | epoch 024:    914 / 1474 loss=1.929, trans_loss=4.811, nll_loss=2.024, w2v_ctc_loss=0.65, task_loss=1.561, contrastive_loss=0.069, total=4041.44, n_correct=2749.14, ppl=4.07, accuracy=68.024, wps=11736.4, ups=1.45, wpb=8082.9, bsz=280.5, num_updates=34800, lr=7.58098e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=29457
2023-08-13 20:59:57 | INFO | train_inner | epoch 024:   1014 / 1474 loss=1.921, trans_loss=4.81, nll_loss=2.023, w2v_ctc_loss=0.637, task_loss=1.466, contrastive_loss=0.073, total=4128.8, n_correct=2818.55, ppl=4.06, accuracy=68.266, wps=11893, ups=1.44, wpb=8257.6, bsz=296.5, num_updates=34900, lr=7.57011e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=14.7, wall=29527
2023-08-13 21:01:06 | INFO | train_inner | epoch 024:   1114 / 1474 loss=1.923, trans_loss=4.799, nll_loss=2.01, w2v_ctc_loss=0.644, task_loss=1.355, contrastive_loss=0.116, total=4130.49, n_correct=2821.57, ppl=4.03, accuracy=68.311, wps=11878.5, ups=1.44, wpb=8261, bsz=308.9, num_updates=35000, lr=7.55929e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=29596
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:0')
2023-08-13 21:02:16 | INFO | train_inner | epoch 024:   1214 / 1474 loss=1.923, trans_loss=4.809, nll_loss=2.022, w2v_ctc_loss=0.637, task_loss=1.391, contrastive_loss=0.105, total=4157.47, n_correct=2839.35, ppl=4.06, accuracy=68.295, wps=11953.2, ups=1.44, wpb=8314.9, bsz=311.2, num_updates=35100, lr=7.54851e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=12.4, wall=29666
2023-08-13 21:03:25 | INFO | train_inner | epoch 024:   1314 / 1474 loss=1.931, trans_loss=4.815, nll_loss=2.03, w2v_ctc_loss=0.656, task_loss=1.492, contrastive_loss=0.078, total=4107.23, n_correct=2796.53, ppl=4.08, accuracy=68.088, wps=11838.8, ups=1.44, wpb=8214.5, bsz=294.3, num_updates=35200, lr=7.53778e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=29735
2023-08-13 21:04:35 | INFO | train_inner | epoch 024:   1414 / 1474 loss=1.928, trans_loss=4.814, nll_loss=2.029, w2v_ctc_loss=0.651, task_loss=1.469, contrastive_loss=0.076, total=4094.39, n_correct=2790.22, ppl=4.08, accuracy=68.147, wps=11828, ups=1.44, wpb=8188.8, bsz=292.9, num_updates=35300, lr=7.5271e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=15.8, wall=29804
2023-08-13 21:05:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:2')
2023-08-13 21:05:40 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.941 | trans_loss 5.157 | nll_loss 2.414 | w2v_ctc_loss 1.282 | task_loss 4.669 | contrastive_loss 0.301 | total 4003.4 | n_correct 2680 | ppl 5.33 | accuracy 66.943 | uer 17.344 | wer 19.291 | raw_wer 19.291 | bleu 22.23 | wps 2045.1 | wpb 4003.4 | bsz 141.8 | num_updates 35360 | best_bleu 22.57
2023-08-13 21:05:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35360 updates
2023-08-13 21:05:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.2303.pt
2023-08-13 21:05:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.2303.pt
2023-08-13 21:06:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.2303.pt (epoch 24 @ 35360 updates, score 22.23) (writing took 21.149692591279745 seconds)
2023-08-13 21:06:02 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-13 21:06:02 | INFO | train | epoch 024 | loss 1.926 | trans_loss 4.807 | nll_loss 2.019 | w2v_ctc_loss 0.64 | task_loss 1.406 | contrastive_loss 0.128 | total 4138.65 | n_correct 2824.25 | ppl 4.05 | accuracy 68.241 | wps 10873.4 | ups 1.31 | wpb 8277.3 | bsz 305.7 | num_updates 35360 | lr 7.52071e-05 | gnorm 0.526 | clip 0 | loss_scale 32 | train_wall 1017 | gb_free 15.8 | wall 29892
2023-08-13 21:06:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 21:06:02 | INFO | fairseq.trainer | begin training epoch 25
2023-08-13 21:06:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 21:06:38 | INFO | train_inner | epoch 025:     40 / 1474 loss=1.913, trans_loss=4.799, nll_loss=2.01, w2v_ctc_loss=0.632, task_loss=1.353, contrastive_loss=0.083, total=4165.57, n_correct=2854.73, ppl=4.03, accuracy=68.532, wps=6755.7, ups=0.81, wpb=8331.1, bsz=311.2, num_updates=35400, lr=7.51646e-05, gnorm=0.513, clip=0, loss_scale=32, train_wall=69, gb_free=12.8, wall=29928
2023-08-13 21:07:47 | INFO | train_inner | epoch 025:    140 / 1474 loss=1.905, trans_loss=4.785, nll_loss=1.991, w2v_ctc_loss=0.625, task_loss=1.362, contrastive_loss=0.081, total=4135.43, n_correct=2842.4, ppl=3.97, accuracy=68.733, wps=11986, ups=1.45, wpb=8270.9, bsz=308.9, num_updates=35500, lr=7.50587e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=69, gb_free=17.5, wall=29997
2023-08-13 21:08:57 | INFO | train_inner | epoch 025:    240 / 1474 loss=1.914, trans_loss=4.791, nll_loss=1.999, w2v_ctc_loss=0.634, task_loss=1.444, contrastive_loss=0.085, total=4116.13, n_correct=2822.62, ppl=4, accuracy=68.575, wps=11769.3, ups=1.43, wpb=8232.3, bsz=303, num_updates=35600, lr=7.49532e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=30067
2023-08-13 21:10:06 | INFO | train_inner | epoch 025:    340 / 1474 loss=1.919, trans_loss=4.794, nll_loss=2.001, w2v_ctc_loss=0.631, task_loss=1.498, contrastive_loss=0.115, total=4141.49, n_correct=2835.83, ppl=4, accuracy=68.474, wps=11920.3, ups=1.44, wpb=8283, bsz=294.2, num_updates=35700, lr=7.48481e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=14.9, wall=30136
2023-08-13 21:11:16 | INFO | train_inner | epoch 025:    440 / 1474 loss=1.934, trans_loss=4.793, nll_loss=2.001, w2v_ctc_loss=0.648, task_loss=1.467, contrastive_loss=0.193, total=4167.4, n_correct=2849.57, ppl=4, accuracy=68.378, wps=11899.9, ups=1.43, wpb=8334.8, bsz=297.7, num_updates=35800, lr=7.47435e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=70, gb_free=15.5, wall=30206
2023-08-13 21:12:26 | INFO | train_inner | epoch 025:    540 / 1474 loss=1.918, trans_loss=4.804, nll_loss=2.015, w2v_ctc_loss=0.634, task_loss=1.369, contrastive_loss=0.086, total=4160.61, n_correct=2845.08, ppl=4.04, accuracy=68.381, wps=11935, ups=1.43, wpb=8321.2, bsz=313.9, num_updates=35900, lr=7.46393e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=69, gb_free=17.3, wall=30276
2023-08-13 21:13:36 | INFO | train_inner | epoch 025:    640 / 1474 loss=1.921, trans_loss=4.791, nll_loss=1.999, w2v_ctc_loss=0.637, task_loss=1.391, contrastive_loss=0.151, total=4153.68, n_correct=2845.62, ppl=4, accuracy=68.508, wps=11974.8, ups=1.44, wpb=8307.4, bsz=309.6, num_updates=36000, lr=7.45356e-05, gnorm=0.529, clip=0, loss_scale=64, train_wall=69, gb_free=16.1, wall=30345
2023-08-13 21:13:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 21:13:58 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.953 | trans_loss 5.161 | nll_loss 2.419 | w2v_ctc_loss 1.311 | task_loss 4.654 | contrastive_loss 0.302 | total 4003.4 | n_correct 2674.2 | ppl 5.35 | accuracy 66.798 | uer 17.413 | wer 19.272 | raw_wer 19.272 | bleu 22.18 | wps 2242.5 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 22.57
2023-08-13 21:13:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-08-13 21:13:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_25_36000.pt
2023-08-13 21:14:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_25_36000.pt
2023-08-13 21:14:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 22.18) (writing took 19.760285640135407 seconds)
2023-08-13 21:14:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-13 21:15:29 | INFO | train_inner | epoch 025:    741 / 1474 loss=1.916, trans_loss=4.79, nll_loss=1.997, w2v_ctc_loss=0.636, task_loss=1.444, contrastive_loss=0.087, total=4122.55, n_correct=2827.71, ppl=3.99, accuracy=68.591, wps=7271.1, ups=0.88, wpb=8245.1, bsz=298, num_updates=36100, lr=7.44323e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=70, gb_free=14.8, wall=30459
2023-08-13 21:16:38 | INFO | train_inner | epoch 025:    841 / 1474 loss=1.913, trans_loss=4.797, nll_loss=2.007, w2v_ctc_loss=0.633, task_loss=1.303, contrastive_loss=0.091, total=4174.24, n_correct=2861.61, ppl=4.02, accuracy=68.554, wps=12020.8, ups=1.44, wpb=8348.5, bsz=324, num_updates=36200, lr=7.43294e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=30528
2023-08-13 21:17:48 | INFO | train_inner | epoch 025:    941 / 1474 loss=1.922, trans_loss=4.8, nll_loss=2.011, w2v_ctc_loss=0.635, task_loss=1.334, contrastive_loss=0.151, total=4154.13, n_correct=2841.45, ppl=4.03, accuracy=68.401, wps=11947.8, ups=1.44, wpb=8308.3, bsz=316.7, num_updates=36300, lr=7.4227e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=10.4, wall=30598
2023-08-13 21:18:58 | INFO | train_inner | epoch 025:   1041 / 1474 loss=1.934, trans_loss=4.806, nll_loss=2.019, w2v_ctc_loss=0.63, task_loss=1.396, contrastive_loss=0.259, total=4178.3, n_correct=2850.64, ppl=4.05, accuracy=68.225, wps=12000.8, ups=1.44, wpb=8356.6, bsz=309.7, num_updates=36400, lr=7.41249e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=30667
2023-08-13 21:20:06 | INFO | train_inner | epoch 025:   1141 / 1474 loss=1.913, trans_loss=4.798, nll_loss=2.008, w2v_ctc_loss=0.629, task_loss=1.509, contrastive_loss=0.067, total=4042.33, n_correct=2764.33, ppl=4.02, accuracy=68.385, wps=11762.1, ups=1.45, wpb=8084.7, bsz=286.5, num_updates=36500, lr=7.40233e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=17.5, wall=30736
2023-08-13 21:21:15 | INFO | train_inner | epoch 025:   1241 / 1474 loss=1.92, trans_loss=4.807, nll_loss=2.02, w2v_ctc_loss=0.636, task_loss=1.428, contrastive_loss=0.077, total=4087.78, n_correct=2790.68, ppl=4.06, accuracy=68.269, wps=11878.1, ups=1.45, wpb=8175.6, bsz=295.1, num_updates=36600, lr=7.39221e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=68, gb_free=17.4, wall=30805
2023-08-13 21:22:25 | INFO | train_inner | epoch 025:   1341 / 1474 loss=1.924, trans_loss=4.799, nll_loss=2.01, w2v_ctc_loss=0.634, task_loss=1.374, contrastive_loss=0.17, total=4166.64, n_correct=2851.24, ppl=4.03, accuracy=68.43, wps=11951.2, ups=1.43, wpb=8333.3, bsz=309.3, num_updates=36700, lr=7.38213e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=30875
2023-08-13 21:23:35 | INFO | train_inner | epoch 025:   1441 / 1474 loss=1.933, trans_loss=4.816, nll_loss=2.031, w2v_ctc_loss=0.642, task_loss=1.432, contrastive_loss=0.138, total=4114.64, n_correct=2798.64, ppl=4.09, accuracy=68.017, wps=11754.3, ups=1.43, wpb=8229.3, bsz=304.3, num_updates=36800, lr=7.3721e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=70, gb_free=16.2, wall=30945
2023-08-13 21:23:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 21:24:21 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.943 | trans_loss 5.153 | nll_loss 2.407 | w2v_ctc_loss 1.296 | task_loss 4.649 | contrastive_loss 0.305 | total 4003.4 | n_correct 2679.4 | ppl 5.3 | accuracy 66.928 | uer 17.198 | wer 19.242 | raw_wer 19.242 | bleu 22.4 | wps 2130.4 | wpb 4003.4 | bsz 141.8 | num_updates 36833 | best_bleu 22.57
2023-08-13 21:24:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36833 updates
2023-08-13 21:24:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4001.pt
2023-08-13 21:24:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4001.pt
2023-08-13 21:24:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4001.pt (epoch 25 @ 36833 updates, score 22.4) (writing took 36.15843275003135 seconds)
2023-08-13 21:24:58 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-13 21:24:58 | INFO | train | epoch 025 | loss 1.92 | trans_loss 4.798 | nll_loss 2.008 | w2v_ctc_loss 0.634 | task_loss 1.406 | contrastive_loss 0.123 | total 4137.91 | n_correct 2831.47 | ppl 4.02 | accuracy 68.428 | wps 10736 | ups 1.3 | wpb 8275.8 | bsz 305.3 | num_updates 36833 | lr 7.36879e-05 | gnorm 0.526 | clip 0 | loss_scale 32 | train_wall 1017 | gb_free 14 | wall 31027
2023-08-13 21:24:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 21:24:58 | INFO | fairseq.trainer | begin training epoch 26
2023-08-13 21:24:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 21:25:52 | INFO | train_inner | epoch 026:     67 / 1474 loss=1.904, trans_loss=4.781, nll_loss=1.985, w2v_ctc_loss=0.619, task_loss=1.331, contrastive_loss=0.103, total=4172.16, n_correct=2870.03, ppl=3.96, accuracy=68.79, wps=6099, ups=0.73, wpb=8344.3, bsz=316.9, num_updates=36900, lr=7.3621e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=31082
2023-08-13 21:27:01 | INFO | train_inner | epoch 026:    167 / 1474 loss=1.917, trans_loss=4.781, nll_loss=1.987, w2v_ctc_loss=0.613, task_loss=1.239, contrastive_loss=0.278, total=4265.22, n_correct=2939.8, ppl=3.96, accuracy=68.925, wps=12250, ups=1.44, wpb=8530.4, bsz=338.7, num_updates=37000, lr=7.35215e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=69, gb_free=15.1, wall=31151
2023-08-13 21:28:11 | INFO | train_inner | epoch 026:    267 / 1474 loss=1.918, trans_loss=4.783, nll_loss=1.988, w2v_ctc_loss=0.633, task_loss=1.395, contrastive_loss=0.164, total=4123.94, n_correct=2832.73, ppl=3.97, accuracy=68.69, wps=11880.5, ups=1.44, wpb=8247.9, bsz=306.6, num_updates=37100, lr=7.34223e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=31221
2023-08-13 21:29:20 | INFO | train_inner | epoch 026:    367 / 1474 loss=1.913, trans_loss=4.787, nll_loss=1.993, w2v_ctc_loss=0.628, task_loss=1.343, contrastive_loss=0.122, total=4168.11, n_correct=2859.07, ppl=3.98, accuracy=68.594, wps=12070.4, ups=1.45, wpb=8336.2, bsz=315.2, num_updates=37200, lr=7.33236e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=31290
2023-08-13 21:30:29 | INFO | train_inner | epoch 026:    467 / 1474 loss=1.913, trans_loss=4.776, nll_loss=1.979, w2v_ctc_loss=0.628, task_loss=1.35, contrastive_loss=0.168, total=4167.53, n_correct=2870.92, ppl=3.94, accuracy=68.888, wps=12096.8, ups=1.45, wpb=8335.1, bsz=314.6, num_updates=37300, lr=7.32252e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=13.7, wall=31359
2023-08-13 21:31:38 | INFO | train_inner | epoch 026:    567 / 1474 loss=1.913, trans_loss=4.786, nll_loss=1.992, w2v_ctc_loss=0.636, task_loss=1.414, contrastive_loss=0.089, total=4158.48, n_correct=2853.41, ppl=3.98, accuracy=68.617, wps=11939.7, ups=1.44, wpb=8317, bsz=304.4, num_updates=37400, lr=7.31272e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=12.4, wall=31428
2023-08-13 21:32:48 | INFO | train_inner | epoch 026:    667 / 1474 loss=1.906, trans_loss=4.785, nll_loss=1.991, w2v_ctc_loss=0.621, task_loss=1.441, contrastive_loss=0.075, total=4129.11, n_correct=2836.04, ppl=3.97, accuracy=68.684, wps=11948.9, ups=1.45, wpb=8258.2, bsz=297.7, num_updates=37500, lr=7.30297e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=13.5, wall=31497
2023-08-13 21:33:57 | INFO | train_inner | epoch 026:    767 / 1474 loss=1.921, trans_loss=4.791, nll_loss=1.998, w2v_ctc_loss=0.625, task_loss=1.419, contrastive_loss=0.186, total=4096.84, n_correct=2810.17, ppl=3.99, accuracy=68.594, wps=11851.2, ups=1.45, wpb=8193.7, bsz=300.5, num_updates=37600, lr=7.29325e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=31566
2023-08-13 21:35:06 | INFO | train_inner | epoch 026:    867 / 1474 loss=1.913, trans_loss=4.787, nll_loss=1.994, w2v_ctc_loss=0.634, task_loss=1.402, contrastive_loss=0.089, total=4176.27, n_correct=2865.21, ppl=3.98, accuracy=68.607, wps=12073.3, ups=1.45, wpb=8352.5, bsz=306.4, num_updates=37700, lr=7.28357e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=31636
2023-08-13 21:36:15 | INFO | train_inner | epoch 026:    967 / 1474 loss=1.914, trans_loss=4.792, nll_loss=2, w2v_ctc_loss=0.62, task_loss=1.448, contrastive_loss=0.139, total=4141.01, n_correct=2835.38, ppl=4, accuracy=68.471, wps=11912, ups=1.44, wpb=8282, bsz=299.7, num_updates=37800, lr=7.27393e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=15.1, wall=31705
2023-08-13 21:37:24 | INFO | train_inner | epoch 026:   1067 / 1474 loss=1.909, trans_loss=4.788, nll_loss=1.994, w2v_ctc_loss=0.629, task_loss=1.483, contrastive_loss=0.074, total=4113.69, n_correct=2825.88, ppl=3.98, accuracy=68.695, wps=11930.7, ups=1.45, wpb=8227.4, bsz=293, num_updates=37900, lr=7.26433e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=69, gb_free=15.3, wall=31774
2023-08-13 21:38:34 | INFO | train_inner | epoch 026:   1167 / 1474 loss=1.917, trans_loss=4.797, nll_loss=2.006, w2v_ctc_loss=0.629, task_loss=1.465, contrastive_loss=0.113, total=4116.78, n_correct=2819.37, ppl=4.02, accuracy=68.485, wps=11826.9, ups=1.44, wpb=8233.6, bsz=299, num_updates=38000, lr=7.25476e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=31844
2023-08-13 21:38:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 21:38:57 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.948 | trans_loss 5.156 | nll_loss 2.413 | w2v_ctc_loss 1.314 | task_loss 4.655 | contrastive_loss 0.294 | total 4003.4 | n_correct 2672.2 | ppl 5.32 | accuracy 66.748 | uer 17.312 | wer 19.365 | raw_wer 19.365 | bleu 22.15 | wps 2218.2 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 22.57
2023-08-13 21:38:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-08-13 21:38:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_26_38000.pt
2023-08-13 21:39:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_26_38000.pt
2023-08-13 21:39:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 22.15) (writing took 19.32089651376009 seconds)
2023-08-13 21:40:26 | INFO | train_inner | epoch 026:   1267 / 1474 loss=1.924, trans_loss=4.806, nll_loss=2.017, w2v_ctc_loss=0.645, task_loss=1.556, contrastive_loss=0.076, total=4001.06, n_correct=2731.25, ppl=4.05, accuracy=68.263, wps=7123.2, ups=0.89, wpb=8002.1, bsz=280.6, num_updates=38100, lr=7.24524e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=69, gb_free=15.4, wall=31956
2023-08-13 21:41:36 | INFO | train_inner | epoch 026:   1367 / 1474 loss=1.91, trans_loss=4.797, nll_loss=2.007, w2v_ctc_loss=0.621, task_loss=1.405, contrastive_loss=0.088, total=4157.69, n_correct=2852.21, ppl=4.02, accuracy=68.601, wps=11881.1, ups=1.43, wpb=8315.4, bsz=310.5, num_updates=38200, lr=7.23575e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=70, gb_free=15.8, wall=32026
2023-08-13 21:42:45 | INFO | train_inner | epoch 026:   1467 / 1474 loss=1.905, trans_loss=4.79, nll_loss=1.998, w2v_ctc_loss=0.62, task_loss=1.335, contrastive_loss=0.082, total=4158.47, n_correct=2855.11, ppl=3.99, accuracy=68.658, wps=12032.1, ups=1.45, wpb=8316.9, bsz=316.5, num_updates=38300, lr=7.22629e-05, gnorm=0.517, clip=0, loss_scale=64, train_wall=69, gb_free=17, wall=32095
2023-08-13 21:42:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 21:43:14 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.929 | trans_loss 5.148 | nll_loss 2.403 | w2v_ctc_loss 1.27 | task_loss 4.65 | contrastive_loss 0.292 | total 4003.4 | n_correct 2679 | ppl 5.29 | accuracy 66.918 | uer 17.097 | wer 19.112 | raw_wer 19.112 | bleu 22.25 | wps 2122.5 | wpb 4003.4 | bsz 141.8 | num_updates 38307 | best_bleu 22.57
2023-08-13 21:43:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38307 updates
2023-08-13 21:43:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.2508.pt
2023-08-13 21:43:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.2508.pt
2023-08-13 21:43:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.2508.pt (epoch 26 @ 38307 updates, score 22.25) (writing took 26.978060692548752 seconds)
2023-08-13 21:43:41 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-13 21:43:41 | INFO | train | epoch 026 | loss 1.913 | trans_loss 4.788 | nll_loss 1.995 | w2v_ctc_loss 0.627 | task_loss 1.405 | contrastive_loss 0.125 | total 4138.65 | n_correct 2840.98 | ppl 3.99 | accuracy 68.645 | wps 10861.8 | ups 1.31 | wpb 8277.3 | bsz 305.7 | num_updates 38307 | lr 7.22563e-05 | gnorm 0.524 | clip 0 | loss_scale 64 | train_wall 1015 | gb_free 15.7 | wall 32151
2023-08-13 21:43:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 21:43:41 | INFO | fairseq.trainer | begin training epoch 27
2023-08-13 21:43:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 21:44:52 | INFO | train_inner | epoch 027:     93 / 1474 loss=1.89, trans_loss=4.755, nll_loss=1.951, w2v_ctc_loss=0.61, task_loss=1.502, contrastive_loss=0.064, total=4067.62, n_correct=2819.53, ppl=3.87, accuracy=69.316, wps=6408, ups=0.79, wpb=8135.2, bsz=284.4, num_updates=38400, lr=7.21688e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=68, gb_free=14.6, wall=32222
2023-08-13 21:46:02 | INFO | train_inner | epoch 027:    193 / 1474 loss=1.895, trans_loss=4.768, nll_loss=1.969, w2v_ctc_loss=0.615, task_loss=1.341, contrastive_loss=0.09, total=4185.52, n_correct=2892.85, ppl=3.92, accuracy=69.116, wps=12041.8, ups=1.44, wpb=8371, bsz=321.7, num_updates=38500, lr=7.2075e-05, gnorm=0.521, clip=0, loss_scale=64, train_wall=69, gb_free=17.4, wall=32292
2023-08-13 21:47:11 | INFO | train_inner | epoch 027:    293 / 1474 loss=1.901, trans_loss=4.774, nll_loss=1.976, w2v_ctc_loss=0.621, task_loss=1.4, contrastive_loss=0.076, total=4167.92, n_correct=2877.46, ppl=3.94, accuracy=69.038, wps=12015.4, ups=1.44, wpb=8335.8, bsz=306.8, num_updates=38600, lr=7.19816e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=69, gb_free=16.5, wall=32361
2023-08-13 21:47:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-13 21:48:22 | INFO | train_inner | epoch 027:    394 / 1474 loss=1.91, trans_loss=4.777, nll_loss=1.98, w2v_ctc_loss=0.624, task_loss=1.515, contrastive_loss=0.142, total=4054.47, n_correct=2794.27, ppl=3.95, accuracy=68.918, wps=11445, ups=1.41, wpb=8108.9, bsz=288.6, num_updates=38700, lr=7.18885e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=70, gb_free=16, wall=32432
2023-08-13 21:49:32 | INFO | train_inner | epoch 027:    494 / 1474 loss=1.913, trans_loss=4.786, nll_loss=1.993, w2v_ctc_loss=0.617, task_loss=1.288, contrastive_loss=0.191, total=4245.37, n_correct=2919.58, ppl=3.98, accuracy=68.771, wps=12114.1, ups=1.43, wpb=8490.7, bsz=331.5, num_updates=38800, lr=7.17958e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=70, gb_free=16.6, wall=32502
2023-08-13 21:50:42 | INFO | train_inner | epoch 027:    594 / 1474 loss=1.911, trans_loss=4.777, nll_loss=1.981, w2v_ctc_loss=0.628, task_loss=1.38, contrastive_loss=0.133, total=4134.93, n_correct=2847.16, ppl=3.95, accuracy=68.856, wps=11882.5, ups=1.44, wpb=8269.9, bsz=312, num_updates=38900, lr=7.17035e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=17.3, wall=32572
2023-08-13 21:51:51 | INFO | train_inner | epoch 027:    694 / 1474 loss=1.909, trans_loss=4.78, nll_loss=1.984, w2v_ctc_loss=0.626, task_loss=1.407, contrastive_loss=0.112, total=4162.17, n_correct=2861.7, ppl=3.96, accuracy=68.755, wps=12053.5, ups=1.45, wpb=8324.3, bsz=305.1, num_updates=39000, lr=7.16115e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=15.1, wall=32641
2023-08-13 21:53:00 | INFO | train_inner | epoch 027:    794 / 1474 loss=1.907, trans_loss=4.78, nll_loss=1.984, w2v_ctc_loss=0.629, task_loss=1.475, contrastive_loss=0.075, total=4107.17, n_correct=2822.42, ppl=3.96, accuracy=68.719, wps=11908.3, ups=1.45, wpb=8214.3, bsz=294.3, num_updates=39100, lr=7.15199e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=11.2, wall=32710
2023-08-13 21:54:09 | INFO | train_inner | epoch 027:    894 / 1474 loss=1.903, trans_loss=4.785, nll_loss=1.991, w2v_ctc_loss=0.617, task_loss=1.457, contrastive_loss=0.067, total=4101.4, n_correct=2823.28, ppl=3.97, accuracy=68.837, wps=11845.7, ups=1.44, wpb=8202.8, bsz=292.8, num_updates=39200, lr=7.14286e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=32779
2023-08-13 21:55:19 | INFO | train_inner | epoch 027:    994 / 1474 loss=1.919, trans_loss=4.782, nll_loss=1.988, w2v_ctc_loss=0.619, task_loss=1.362, contrastive_loss=0.251, total=4195.5, n_correct=2886.64, ppl=3.97, accuracy=68.803, wps=11932.8, ups=1.42, wpb=8391, bsz=315.9, num_updates=39300, lr=7.13376e-05, gnorm=0.515, clip=0, loss_scale=32, train_wall=70, gb_free=16.5, wall=32849
2023-08-13 21:56:28 | INFO | train_inner | epoch 027:   1094 / 1474 loss=1.901, trans_loss=4.777, nll_loss=1.981, w2v_ctc_loss=0.619, task_loss=1.413, contrastive_loss=0.085, total=4147.99, n_correct=2857.04, ppl=3.95, accuracy=68.878, wps=12064.4, ups=1.45, wpb=8296, bsz=304.7, num_updates=39400, lr=7.1247e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=32918
2023-08-13 21:57:38 | INFO | train_inner | epoch 027:   1194 / 1474 loss=1.91, trans_loss=4.784, nll_loss=1.99, w2v_ctc_loss=0.63, task_loss=1.471, contrastive_loss=0.089, total=4104.84, n_correct=2821.17, ppl=3.97, accuracy=68.728, wps=11836.3, ups=1.44, wpb=8209.7, bsz=297.2, num_updates=39500, lr=7.11568e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=11.9, wall=32987
2023-08-13 21:58:47 | INFO | train_inner | epoch 027:   1294 / 1474 loss=1.914, trans_loss=4.785, nll_loss=1.991, w2v_ctc_loss=0.623, task_loss=1.486, contrastive_loss=0.14, total=4062.86, n_correct=2793.36, ppl=3.97, accuracy=68.754, wps=11761.7, ups=1.45, wpb=8125.7, bsz=293.6, num_updates=39600, lr=7.10669e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=33056
2023-08-13 21:59:56 | INFO | train_inner | epoch 027:   1394 / 1474 loss=1.907, trans_loss=4.784, nll_loss=1.991, w2v_ctc_loss=0.619, task_loss=1.323, contrastive_loss=0.124, total=4157.6, n_correct=2857.78, ppl=3.97, accuracy=68.736, wps=12039.2, ups=1.45, wpb=8315.2, bsz=314, num_updates=39700, lr=7.09773e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=69, gb_free=17.4, wall=33126
2023-08-13 22:00:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 22:01:15 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.955 | trans_loss 5.155 | nll_loss 2.411 | w2v_ctc_loss 1.341 | task_loss 4.635 | contrastive_loss 0.292 | total 4003.4 | n_correct 2675 | ppl 5.32 | accuracy 66.818 | uer 17.339 | wer 19.324 | raw_wer 19.324 | bleu 22.5 | wps 2160 | wpb 4003.4 | bsz 141.8 | num_updates 39780 | best_bleu 22.57
2023-08-13 22:01:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39780 updates
2023-08-13 22:01:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.5005.pt
2023-08-13 22:01:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.5005.pt
2023-08-13 22:01:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.5005.pt (epoch 27 @ 39780 updates, score 22.5) (writing took 22.264813078567386 seconds)
2023-08-13 22:01:37 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-13 22:01:37 | INFO | train | epoch 027 | loss 1.906 | trans_loss 4.778 | nll_loss 1.982 | w2v_ctc_loss 0.621 | task_loss 1.407 | contrastive_loss 0.116 | total 4136.97 | n_correct 2849.52 | ppl 3.95 | accuracy 68.879 | wps 11321.6 | ups 1.37 | wpb 8273.9 | bsz 305.1 | num_updates 39780 | lr 7.09059e-05 | gnorm 0.524 | clip 0 | loss_scale 32 | train_wall 1015 | gb_free 17.5 | wall 33227
2023-08-13 22:01:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 22:01:38 | INFO | fairseq.trainer | begin training epoch 28
2023-08-13 22:01:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 22:01:59 | INFO | train_inner | epoch 028:     20 / 1474 loss=1.895, trans_loss=4.774, nll_loss=1.977, w2v_ctc_loss=0.613, task_loss=1.364, contrastive_loss=0.074, total=4107.3, n_correct=2836.51, ppl=3.94, accuracy=69.06, wps=6667.2, ups=0.81, wpb=8214.6, bsz=304.5, num_updates=39800, lr=7.08881e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=33249
2023-08-13 22:03:08 | INFO | train_inner | epoch 028:    120 / 1474 loss=1.892, trans_loss=4.754, nll_loss=1.95, w2v_ctc_loss=0.617, task_loss=1.469, contrastive_loss=0.069, total=4112.44, n_correct=2854.62, ppl=3.86, accuracy=69.414, wps=11943, ups=1.45, wpb=8224.9, bsz=292.7, num_updates=39900, lr=7.07992e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=68, gb_free=13.5, wall=33318
2023-08-13 22:04:17 | INFO | train_inner | epoch 028:    220 / 1474 loss=1.889, trans_loss=4.764, nll_loss=1.963, w2v_ctc_loss=0.606, task_loss=1.327, contrastive_loss=0.079, total=4193.3, n_correct=2905.31, ppl=3.9, accuracy=69.285, wps=12137.4, ups=1.45, wpb=8386.6, bsz=316.4, num_updates=40000, lr=7.07107e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=33387
2023-08-13 22:04:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 22:04:42 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.947 | trans_loss 5.159 | nll_loss 2.414 | w2v_ctc_loss 1.31 | task_loss 4.666 | contrastive_loss 0.285 | total 4003.4 | n_correct 2674.4 | ppl 5.33 | accuracy 66.803 | uer 17.28 | wer 19.254 | raw_wer 19.254 | bleu 22.45 | wps 1963.7 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 22.57
2023-08-13 22:04:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-08-13 22:04:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_28_40000.pt
2023-08-13 22:04:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_28_40000.pt
2023-08-13 22:05:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 22.45) (writing took 45.554916203022 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:0')
2023-08-13 22:06:39 | INFO | train_inner | epoch 028:    320 / 1474 loss=1.928, trans_loss=4.773, nll_loss=1.976, w2v_ctc_loss=0.608, task_loss=1.406, contrastive_loss=0.404, total=4138.69, n_correct=2850.37, ppl=3.93, accuracy=68.871, wps=5829.3, ups=0.7, wpb=8277.4, bsz=314.4, num_updates=40100, lr=7.06225e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=70, gb_free=12.9, wall=33529
2023-08-13 22:07:48 | INFO | train_inner | epoch 028:    420 / 1474 loss=1.898, trans_loss=4.766, nll_loss=1.966, w2v_ctc_loss=0.622, task_loss=1.451, contrastive_loss=0.068, total=4089.84, n_correct=2828.21, ppl=3.91, accuracy=69.152, wps=11818.1, ups=1.44, wpb=8179.7, bsz=295.7, num_updates=40200, lr=7.05346e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=33598
2023-08-13 22:08:58 | INFO | train_inner | epoch 028:    520 / 1474 loss=1.894, trans_loss=4.765, nll_loss=1.965, w2v_ctc_loss=0.611, task_loss=1.464, contrastive_loss=0.079, total=4098.92, n_correct=2833.46, ppl=3.9, accuracy=69.127, wps=11815.8, ups=1.44, wpb=8197.8, bsz=295.7, num_updates=40300, lr=7.0447e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=33667
2023-08-13 22:10:07 | INFO | train_inner | epoch 028:    620 / 1474 loss=1.901, trans_loss=4.778, nll_loss=1.981, w2v_ctc_loss=0.619, task_loss=1.415, contrastive_loss=0.08, total=4180.1, n_correct=2883.59, ppl=3.95, accuracy=68.984, wps=12092.4, ups=1.45, wpb=8360.2, bsz=305.3, num_updates=40400, lr=7.03598e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=33736
2023-08-13 22:11:17 | INFO | train_inner | epoch 028:    720 / 1474 loss=1.906, trans_loss=4.778, nll_loss=1.982, w2v_ctc_loss=0.609, task_loss=1.269, contrastive_loss=0.187, total=4191.62, n_correct=2892.48, ppl=3.95, accuracy=69.006, wps=11958, ups=1.43, wpb=8383.2, bsz=329.2, num_updates=40500, lr=7.02728e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=70, gb_free=16.7, wall=33807
2023-08-13 22:12:26 | INFO | train_inner | epoch 028:    820 / 1474 loss=1.891, trans_loss=4.768, nll_loss=1.969, w2v_ctc_loss=0.61, task_loss=1.392, contrastive_loss=0.069, total=4088.91, n_correct=2828.23, ppl=3.91, accuracy=69.168, wps=11896.6, ups=1.45, wpb=8177.8, bsz=304.3, num_updates=40600, lr=7.01862e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=33875
2023-08-13 22:13:36 | INFO | train_inner | epoch 028:    920 / 1474 loss=1.909, trans_loss=4.776, nll_loss=1.979, w2v_ctc_loss=0.622, task_loss=1.454, contrastive_loss=0.132, total=4117.01, n_correct=2831.32, ppl=3.94, accuracy=68.771, wps=11766.4, ups=1.43, wpb=8234, bsz=299.7, num_updates=40700, lr=7.01e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=69, gb_free=15, wall=33945
2023-08-13 22:14:45 | INFO | train_inner | epoch 028:   1020 / 1474 loss=1.914, trans_loss=4.775, nll_loss=1.978, w2v_ctc_loss=0.624, task_loss=1.369, contrastive_loss=0.184, total=4182.85, n_correct=2880.42, ppl=3.94, accuracy=68.863, wps=12074, ups=1.44, wpb=8365.7, bsz=312, num_updates=40800, lr=7.0014e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=69, gb_free=16.1, wall=34015
2023-08-13 22:15:55 | INFO | train_inner | epoch 028:   1120 / 1474 loss=1.894, trans_loss=4.767, nll_loss=1.969, w2v_ctc_loss=0.612, task_loss=1.348, contrastive_loss=0.09, total=4220.16, n_correct=2914.57, ppl=3.91, accuracy=69.063, wps=12019.1, ups=1.42, wpb=8440.3, bsz=321, num_updates=40900, lr=6.99284e-05, gnorm=0.517, clip=0, loss_scale=64, train_wall=70, gb_free=15.7, wall=34085
2023-08-13 22:17:04 | INFO | train_inner | epoch 028:   1220 / 1474 loss=1.895, trans_loss=4.774, nll_loss=1.976, w2v_ctc_loss=0.61, task_loss=1.396, contrastive_loss=0.077, total=4092.46, n_correct=2822, ppl=3.93, accuracy=68.956, wps=11891, ups=1.45, wpb=8184.9, bsz=303.1, num_updates=41000, lr=6.9843e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=68, gb_free=17.4, wall=34154
2023-08-13 22:18:13 | INFO | train_inner | epoch 028:   1320 / 1474 loss=1.906, trans_loss=4.774, nll_loss=1.976, w2v_ctc_loss=0.625, task_loss=1.54, contrastive_loss=0.093, total=4084.55, n_correct=2813.77, ppl=3.93, accuracy=68.888, wps=11781.8, ups=1.44, wpb=8169.1, bsz=285.1, num_updates=41100, lr=6.9758e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=69, gb_free=15.5, wall=34223
2023-08-13 22:19:23 | INFO | train_inner | epoch 028:   1420 / 1474 loss=1.903, trans_loss=4.773, nll_loss=1.974, w2v_ctc_loss=0.615, task_loss=1.466, contrastive_loss=0.115, total=4154.09, n_correct=2863.13, ppl=3.93, accuracy=68.923, wps=11965.2, ups=1.44, wpb=8308.2, bsz=299.3, num_updates=41200, lr=6.96733e-05, gnorm=0.518, clip=0, loss_scale=64, train_wall=69, gb_free=15.6, wall=34292
2023-08-13 22:20:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:2')
2023-08-13 22:20:24 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.941 | trans_loss 5.16 | nll_loss 2.416 | w2v_ctc_loss 1.278 | task_loss 4.646 | contrastive_loss 0.296 | total 4003.4 | n_correct 2676.1 | ppl 5.34 | accuracy 66.846 | uer 17.315 | wer 19.213 | raw_wer 19.213 | bleu 22.41 | wps 2194 | wpb 4003.4 | bsz 141.8 | num_updates 41254 | best_bleu 22.57
2023-08-13 22:20:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41254 updates
2023-08-13 22:20:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4105.pt
2023-08-13 22:20:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4105.pt
2023-08-13 22:21:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4105.pt (epoch 28 @ 41254 updates, score 22.41) (writing took 37.536024417728186 seconds)
2023-08-13 22:21:04 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-13 22:21:04 | INFO | train | epoch 028 | loss 1.901 | trans_loss 4.77 | nll_loss 1.971 | w2v_ctc_loss 0.615 | task_loss 1.405 | contrastive_loss 0.122 | total 4138.65 | n_correct 2857.48 | ppl 3.92 | accuracy 69.044 | wps 10461.4 | ups 1.26 | wpb 8277.3 | bsz 305.7 | num_updates 41254 | lr 6.96277e-05 | gnorm 0.525 | clip 0 | loss_scale 64 | train_wall 1016 | gb_free 16.2 | wall 34393
2023-08-13 22:21:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 22:21:04 | INFO | fairseq.trainer | begin training epoch 29
2023-08-13 22:21:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 22:21:43 | INFO | train_inner | epoch 029:     46 / 1474 loss=1.895, trans_loss=4.763, nll_loss=1.963, w2v_ctc_loss=0.618, task_loss=1.349, contrastive_loss=0.089, total=4169.12, n_correct=2886.91, ppl=3.9, accuracy=69.245, wps=5934.8, ups=0.71, wpb=8338.2, bsz=316.4, num_updates=41300, lr=6.95889e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=69, gb_free=16.1, wall=34433
2023-08-13 22:22:52 | INFO | train_inner | epoch 029:    146 / 1474 loss=1.896, trans_loss=4.762, nll_loss=1.96, w2v_ctc_loss=0.614, task_loss=1.399, contrastive_loss=0.106, total=4105.72, n_correct=2843.69, ppl=3.89, accuracy=69.262, wps=11848.9, ups=1.44, wpb=8211.4, bsz=304.1, num_updates=41400, lr=6.95048e-05, gnorm=0.531, clip=0, loss_scale=64, train_wall=69, gb_free=15.7, wall=34502
2023-08-13 22:23:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-13 22:24:03 | INFO | train_inner | epoch 029:    247 / 1474 loss=1.881, trans_loss=4.75, nll_loss=1.947, w2v_ctc_loss=0.601, task_loss=1.31, contrastive_loss=0.086, total=4173.39, n_correct=2901.7, ppl=3.85, accuracy=69.529, wps=11802.2, ups=1.41, wpb=8346.8, bsz=322.4, num_updates=41500, lr=6.9421e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=70, gb_free=17.2, wall=34573
2023-08-13 22:25:12 | INFO | train_inner | epoch 029:    347 / 1474 loss=1.9, trans_loss=4.769, nll_loss=1.969, w2v_ctc_loss=0.623, task_loss=1.507, contrastive_loss=0.074, total=4094.4, n_correct=2828.44, ppl=3.91, accuracy=69.081, wps=11851.4, ups=1.45, wpb=8188.8, bsz=291.2, num_updates=41600, lr=6.93375e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=34642
2023-08-13 22:26:22 | INFO | train_inner | epoch 029:    447 / 1474 loss=1.878, trans_loss=4.741, nll_loss=1.934, w2v_ctc_loss=0.599, task_loss=1.346, contrastive_loss=0.067, total=4157.41, n_correct=2897.67, ppl=3.82, accuracy=69.699, wps=11980.3, ups=1.44, wpb=8314.8, bsz=308.5, num_updates=41700, lr=6.92543e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=69, gb_free=14.4, wall=34712
2023-08-13 22:27:31 | INFO | train_inner | epoch 029:    547 / 1474 loss=1.908, trans_loss=4.768, nll_loss=1.969, w2v_ctc_loss=0.615, task_loss=1.506, contrastive_loss=0.163, total=4149.27, n_correct=2862.3, ppl=3.91, accuracy=68.983, wps=11942.5, ups=1.44, wpb=8298.5, bsz=293.3, num_updates=41800, lr=6.91714e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=15.1, wall=34781
2023-08-13 22:28:40 | INFO | train_inner | epoch 029:    647 / 1474 loss=1.901, trans_loss=4.758, nll_loss=1.957, w2v_ctc_loss=0.606, task_loss=1.326, contrastive_loss=0.231, total=4145.39, n_correct=2872.77, ppl=3.88, accuracy=69.3, wps=11977.1, ups=1.44, wpb=8290.8, bsz=319.3, num_updates=41900, lr=6.90889e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=34850
2023-08-13 22:29:50 | INFO | train_inner | epoch 029:    747 / 1474 loss=1.894, trans_loss=4.757, nll_loss=1.955, w2v_ctc_loss=0.606, task_loss=1.294, contrastive_loss=0.149, total=4242.46, n_correct=2941.16, ppl=3.88, accuracy=69.327, wps=12153, ups=1.43, wpb=8484.9, bsz=329.9, num_updates=42000, lr=6.90066e-05, gnorm=0.515, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=34920
2023-08-13 22:29:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 22:30:13 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.956 | trans_loss 5.152 | nll_loss 2.405 | w2v_ctc_loss 1.349 | task_loss 4.641 | contrastive_loss 0.295 | total 4003.4 | n_correct 2681.1 | ppl 5.3 | accuracy 66.971 | uer 17.596 | wer 19.503 | raw_wer 19.503 | bleu 22.09 | wps 2216.6 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 22.57
2023-08-13 22:30:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-08-13 22:30:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_29_42000.pt
2023-08-13 22:30:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_29_42000.pt
2023-08-13 22:30:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 22.09) (writing took 21.964314188808203 seconds)
2023-08-13 22:31:45 | INFO | train_inner | epoch 029:    847 / 1474 loss=1.898, trans_loss=4.772, nll_loss=1.974, w2v_ctc_loss=0.613, task_loss=1.559, contrastive_loss=0.067, total=4027.03, n_correct=2777.49, ppl=3.93, accuracy=68.971, wps=7025.7, ups=0.87, wpb=8054.1, bsz=280.3, num_updates=42100, lr=6.89246e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=17.1, wall=35035
2023-08-13 22:32:54 | INFO | train_inner | epoch 029:    947 / 1474 loss=1.896, trans_loss=4.767, nll_loss=1.967, w2v_ctc_loss=0.617, task_loss=1.437, contrastive_loss=0.077, total=4086.72, n_correct=2826.27, ppl=3.91, accuracy=69.157, wps=11891, ups=1.45, wpb=8173.4, bsz=296.3, num_updates=42200, lr=6.88428e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=68, gb_free=15.1, wall=35103
2023-08-13 22:34:03 | INFO | train_inner | epoch 029:   1047 / 1474 loss=1.896, trans_loss=4.76, nll_loss=1.958, w2v_ctc_loss=0.607, task_loss=1.404, contrastive_loss=0.149, total=4139.4, n_correct=2868.63, ppl=3.89, accuracy=69.301, wps=11895.7, ups=1.44, wpb=8278.8, bsz=307.4, num_updates=42300, lr=6.87614e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=15.3, wall=35173
2023-08-13 22:35:12 | INFO | train_inner | epoch 029:   1147 / 1474 loss=1.9, trans_loss=4.774, nll_loss=1.976, w2v_ctc_loss=0.619, task_loss=1.534, contrastive_loss=0.064, total=4072.33, n_correct=2806.72, ppl=3.93, accuracy=68.922, wps=11771.2, ups=1.45, wpb=8144.7, bsz=284.1, num_updates=42400, lr=6.86803e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=35242
2023-08-13 22:36:22 | INFO | train_inner | epoch 029:   1247 / 1474 loss=1.897, trans_loss=4.77, nll_loss=1.972, w2v_ctc_loss=0.616, task_loss=1.423, contrastive_loss=0.072, total=4160.52, n_correct=2874.3, ppl=3.92, accuracy=69.085, wps=11964.4, ups=1.44, wpb=8321, bsz=301.5, num_updates=42500, lr=6.85994e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=15.2, wall=35312
2023-08-13 22:37:32 | INFO | train_inner | epoch 029:   1347 / 1474 loss=1.891, trans_loss=4.756, nll_loss=1.954, w2v_ctc_loss=0.599, task_loss=1.384, contrastive_loss=0.135, total=4168.02, n_correct=2889.82, ppl=3.87, accuracy=69.333, wps=11981.3, ups=1.44, wpb=8336, bsz=310.2, num_updates=42600, lr=6.85189e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=35381
2023-08-13 22:38:41 | INFO | train_inner | epoch 029:   1447 / 1474 loss=1.901, trans_loss=4.762, nll_loss=1.961, w2v_ctc_loss=0.616, task_loss=1.369, contrastive_loss=0.164, total=4166.06, n_correct=2878.85, ppl=3.89, accuracy=69.102, wps=12018.5, ups=1.44, wpb=8332.1, bsz=313.1, num_updates=42700, lr=6.84386e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=35451
2023-08-13 22:38:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 22:39:23 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.948 | trans_loss 5.152 | nll_loss 2.404 | w2v_ctc_loss 1.322 | task_loss 4.67 | contrastive_loss 0.299 | total 4003.4 | n_correct 2680.6 | ppl 5.29 | accuracy 66.958 | uer 17.084 | wer 19.049 | raw_wer 19.049 | bleu 22.23 | wps 2194.1 | wpb 4003.4 | bsz 141.8 | num_updates 42727 | best_bleu 22.57
2023-08-13 22:39:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42727 updates
2023-08-13 22:39:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-13 22:39:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-13 22:39:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_last.pt (epoch 29 @ 42727 updates, score 22.23) (writing took 15.540238251909614 seconds)
2023-08-13 22:39:38 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-13 22:39:38 | INFO | train | epoch 029 | loss 1.895 | trans_loss 4.762 | nll_loss 1.96 | w2v_ctc_loss 0.61 | task_loss 1.407 | contrastive_loss 0.114 | total 4136.74 | n_correct 2863.78 | ppl 3.89 | accuracy 69.228 | wps 10933.8 | ups 1.32 | wpb 8273.5 | bsz 305.1 | num_updates 42727 | lr 6.8417e-05 | gnorm 0.525 | clip 0 | loss_scale 32 | train_wall 1016 | gb_free 15.8 | wall 35508
2023-08-13 22:39:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 22:39:38 | INFO | fairseq.trainer | begin training epoch 30
2023-08-13 22:39:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 22:40:39 | INFO | train_inner | epoch 030:     73 / 1474 loss=1.89, trans_loss=4.75, nll_loss=1.945, w2v_ctc_loss=0.596, task_loss=1.337, contrastive_loss=0.178, total=4175.11, n_correct=2900.49, ppl=3.85, accuracy=69.471, wps=7086.6, ups=0.85, wpb=8350.2, bsz=318.6, num_updates=42800, lr=6.83586e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=70, gb_free=16.8, wall=35569
2023-08-13 22:41:48 | INFO | train_inner | epoch 030:    173 / 1474 loss=1.882, trans_loss=4.737, nll_loss=1.929, w2v_ctc_loss=0.603, task_loss=1.316, contrastive_loss=0.111, total=4202.64, n_correct=2931.65, ppl=3.81, accuracy=69.757, wps=12177.9, ups=1.45, wpb=8405.3, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=35638
2023-08-13 22:42:57 | INFO | train_inner | epoch 030:    273 / 1474 loss=1.889, trans_loss=4.754, nll_loss=1.95, w2v_ctc_loss=0.614, task_loss=1.45, contrastive_loss=0.067, total=4120.21, n_correct=2861.54, ppl=3.86, accuracy=69.451, wps=11957.2, ups=1.45, wpb=8240.4, bsz=294.9, num_updates=43000, lr=6.81994e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=68, gb_free=14.9, wall=35706
2023-08-13 22:44:06 | INFO | train_inner | epoch 030:    373 / 1474 loss=1.878, trans_loss=4.742, nll_loss=1.935, w2v_ctc_loss=0.599, task_loss=1.4, contrastive_loss=0.069, total=4178.23, n_correct=2914.17, ppl=3.82, accuracy=69.747, wps=11986.1, ups=1.43, wpb=8356.5, bsz=307.5, num_updates=43100, lr=6.81203e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=69, gb_free=9.6, wall=35776
2023-08-13 22:45:15 | INFO | train_inner | epoch 030:    473 / 1474 loss=1.884, trans_loss=4.748, nll_loss=1.943, w2v_ctc_loss=0.594, task_loss=1.347, contrastive_loss=0.132, total=4124.47, n_correct=2869.19, ppl=3.84, accuracy=69.565, wps=11951.5, ups=1.45, wpb=8248.9, bsz=312.6, num_updates=43200, lr=6.80414e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=35845
2023-08-13 22:46:25 | INFO | train_inner | epoch 030:    573 / 1474 loss=1.888, trans_loss=4.754, nll_loss=1.95, w2v_ctc_loss=0.607, task_loss=1.366, contrastive_loss=0.093, total=4168.41, n_correct=2892.96, ppl=3.86, accuracy=69.402, wps=12063.5, ups=1.45, wpb=8336.8, bsz=312.4, num_updates=43300, lr=6.79628e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=35914
2023-08-13 22:47:35 | INFO | train_inner | epoch 030:    673 / 1474 loss=1.894, trans_loss=4.755, nll_loss=1.952, w2v_ctc_loss=0.614, task_loss=1.39, contrastive_loss=0.107, total=4187.95, n_correct=2898.81, ppl=3.87, accuracy=69.218, wps=11908.5, ups=1.42, wpb=8375.9, bsz=315, num_updates=43400, lr=6.78844e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=70, gb_free=15.4, wall=35985
2023-08-13 22:48:44 | INFO | train_inner | epoch 030:    773 / 1474 loss=1.906, trans_loss=4.761, nll_loss=1.959, w2v_ctc_loss=0.617, task_loss=1.436, contrastive_loss=0.188, total=4105.32, n_correct=2838.84, ppl=3.89, accuracy=69.15, wps=11793.7, ups=1.44, wpb=8210.6, bsz=302.6, num_updates=43500, lr=6.78064e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=69, gb_free=12.6, wall=36054
2023-08-13 22:49:54 | INFO | train_inner | epoch 030:    873 / 1474 loss=1.893, trans_loss=4.761, nll_loss=1.959, w2v_ctc_loss=0.609, task_loss=1.449, contrastive_loss=0.081, total=4102.11, n_correct=2839.24, ppl=3.89, accuracy=69.214, wps=11832.9, ups=1.44, wpb=8204.2, bsz=295.6, num_updates=43600, lr=6.77285e-05, gnorm=0.537, clip=0, loss_scale=64, train_wall=69, gb_free=17.1, wall=36124
2023-08-13 22:51:03 | INFO | train_inner | epoch 030:    973 / 1474 loss=1.894, trans_loss=4.762, nll_loss=1.96, w2v_ctc_loss=0.614, task_loss=1.44, contrastive_loss=0.081, total=4129.98, n_correct=2856.05, ppl=3.89, accuracy=69.154, wps=11931.2, ups=1.44, wpb=8260, bsz=300.4, num_updates=43700, lr=6.7651e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=69, gb_free=16.1, wall=36193
2023-08-13 22:52:13 | INFO | train_inner | epoch 030:   1073 / 1474 loss=1.903, trans_loss=4.761, nll_loss=1.959, w2v_ctc_loss=0.612, task_loss=1.57, contrastive_loss=0.161, total=4101.17, n_correct=2838.95, ppl=3.89, accuracy=69.223, wps=11694.4, ups=1.43, wpb=8202.3, bsz=282.3, num_updates=43800, lr=6.75737e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=70, gb_free=15.4, wall=36263
2023-08-13 22:53:23 | INFO | train_inner | epoch 030:   1173 / 1474 loss=1.888, trans_loss=4.754, nll_loss=1.952, w2v_ctc_loss=0.596, task_loss=1.355, contrastive_loss=0.139, total=4168.36, n_correct=2892.14, ppl=3.87, accuracy=69.383, wps=11982.6, ups=1.44, wpb=8336.7, bsz=314, num_updates=43900, lr=6.74967e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=69, gb_free=15.7, wall=36333
2023-08-13 22:54:32 | INFO | train_inner | epoch 030:   1273 / 1474 loss=1.895, trans_loss=4.761, nll_loss=1.96, w2v_ctc_loss=0.616, task_loss=1.55, contrastive_loss=0.074, total=4036.17, n_correct=2789.8, ppl=3.89, accuracy=69.12, wps=11599.6, ups=1.44, wpb=8072.3, bsz=284.3, num_updates=44000, lr=6.742e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=69, gb_free=15.5, wall=36402
2023-08-13 22:54:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 22:54:55 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.936 | trans_loss 5.152 | nll_loss 2.404 | w2v_ctc_loss 1.283 | task_loss 4.631 | contrastive_loss 0.295 | total 4003.4 | n_correct 2680.8 | ppl 5.29 | accuracy 66.963 | uer 16.975 | wer 18.806 | raw_wer 18.806 | bleu 22.73 | wps 2290.9 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 22.73
2023-08-13 22:54:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-08-13 22:54:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_30_44000.pt
2023-08-13 22:54:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_30_44000.pt
2023-08-13 22:55:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 22.73) (writing took 41.06613954901695 seconds)
2023-08-13 22:56:45 | INFO | train_inner | epoch 030:   1373 / 1474 loss=1.885, trans_loss=4.758, nll_loss=1.956, w2v_ctc_loss=0.602, task_loss=1.325, contrastive_loss=0.084, total=4165.07, n_correct=2888.26, ppl=3.88, accuracy=69.345, wps=6262.6, ups=0.75, wpb=8330.1, bsz=321.6, num_updates=44100, lr=6.73435e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=68, gb_free=16.4, wall=36535
2023-08-13 22:57:55 | INFO | train_inner | epoch 030:   1473 / 1474 loss=1.896, trans_loss=4.758, nll_loss=1.957, w2v_ctc_loss=0.594, task_loss=1.319, contrastive_loss=0.229, total=4141.76, n_correct=2871.13, ppl=3.88, accuracy=69.321, wps=11983.6, ups=1.45, wpb=8283.5, bsz=314.3, num_updates=44200, lr=6.72673e-05, gnorm=0.529, clip=0, loss_scale=64, train_wall=69, gb_free=16, wall=36604
2023-08-13 22:57:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 22:58:18 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.943 | trans_loss 5.154 | nll_loss 2.408 | w2v_ctc_loss 1.305 | task_loss 4.672 | contrastive_loss 0.289 | total 4003.4 | n_correct 2680.5 | ppl 5.31 | accuracy 66.956 | uer 17.092 | wer 19.101 | raw_wer 19.101 | bleu 22.43 | wps 2209.4 | wpb 4003.4 | bsz 141.8 | num_updates 44201 | best_bleu 22.73
2023-08-13 22:58:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44201 updates
2023-08-13 22:58:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4308.pt
2023-08-13 22:58:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4308.pt
2023-08-13 22:58:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4308.pt (epoch 30 @ 44201 updates, score 22.43) (writing took 39.526029355823994 seconds)
2023-08-13 22:58:58 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-13 22:58:58 | INFO | train | epoch 030 | loss 1.891 | trans_loss 4.754 | nll_loss 1.951 | w2v_ctc_loss 0.606 | task_loss 1.404 | contrastive_loss 0.121 | total 4138.65 | n_correct 2870.92 | ppl 3.87 | accuracy 69.369 | wps 10516.1 | ups 1.27 | wpb 8277.3 | bsz 305.7 | num_updates 44201 | lr 6.72665e-05 | gnorm 0.528 | clip 0 | loss_scale 64 | train_wall 1017 | gb_free 16.8 | wall 36668
2023-08-13 22:58:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 22:58:59 | INFO | fairseq.trainer | begin training epoch 31
2023-08-13 22:58:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 23:00:16 | INFO | train_inner | epoch 031:     99 / 1474 loss=1.883, trans_loss=4.743, nll_loss=1.935, w2v_ctc_loss=0.605, task_loss=1.504, contrastive_loss=0.068, total=4054.44, n_correct=2824.87, ppl=3.82, accuracy=69.673, wps=5749.2, ups=0.71, wpb=8108.9, bsz=288.2, num_updates=44300, lr=6.71913e-05, gnorm=0.531, clip=0, loss_scale=64, train_wall=69, gb_free=16.2, wall=36745
2023-08-13 23:01:25 | INFO | train_inner | epoch 031:    199 / 1474 loss=1.884, trans_loss=4.745, nll_loss=1.938, w2v_ctc_loss=0.602, task_loss=1.437, contrastive_loss=0.097, total=4147.4, n_correct=2886.73, ppl=3.83, accuracy=69.603, wps=11907.8, ups=1.44, wpb=8294.8, bsz=302.2, num_updates=44400, lr=6.71156e-05, gnorm=0.531, clip=0, loss_scale=64, train_wall=69, gb_free=16.5, wall=36815
2023-08-13 23:02:35 | INFO | train_inner | epoch 031:    299 / 1474 loss=1.887, trans_loss=4.741, nll_loss=1.933, w2v_ctc_loss=0.6, task_loss=1.436, contrastive_loss=0.135, total=4149.21, n_correct=2889.52, ppl=3.82, accuracy=69.64, wps=11903.8, ups=1.43, wpb=8298.4, bsz=301.6, num_updates=44500, lr=6.70402e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=69, gb_free=15.8, wall=36885
2023-08-13 23:03:45 | INFO | train_inner | epoch 031:    399 / 1474 loss=1.885, trans_loss=4.751, nll_loss=1.946, w2v_ctc_loss=0.6, task_loss=1.535, contrastive_loss=0.073, total=4092.62, n_correct=2844.4, ppl=3.85, accuracy=69.501, wps=11743.4, ups=1.43, wpb=8185.2, bsz=285.6, num_updates=44600, lr=6.6965e-05, gnorm=0.529, clip=0, loss_scale=64, train_wall=69, gb_free=16.9, wall=36954
2023-08-13 23:04:54 | INFO | train_inner | epoch 031:    499 / 1474 loss=1.884, trans_loss=4.745, nll_loss=1.938, w2v_ctc_loss=0.608, task_loss=1.47, contrastive_loss=0.08, total=4111.85, n_correct=2860.63, ppl=3.83, accuracy=69.57, wps=11794.4, ups=1.43, wpb=8223.7, bsz=300.3, num_updates=44700, lr=6.689e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=69, gb_free=10.6, wall=37024
2023-08-13 23:06:04 | INFO | train_inner | epoch 031:    599 / 1474 loss=1.88, trans_loss=4.743, nll_loss=1.936, w2v_ctc_loss=0.6, task_loss=1.468, contrastive_loss=0.069, total=4083.44, n_correct=2842.91, ppl=3.83, accuracy=69.62, wps=11709.9, ups=1.43, wpb=8166.9, bsz=294.5, num_updates=44800, lr=6.68153e-05, gnorm=0.531, clip=0, loss_scale=64, train_wall=69, gb_free=16.5, wall=37094
2023-08-13 23:07:13 | INFO | train_inner | epoch 031:    699 / 1474 loss=1.876, trans_loss=4.742, nll_loss=1.935, w2v_ctc_loss=0.593, task_loss=1.337, contrastive_loss=0.072, total=4213.98, n_correct=2937.26, ppl=3.82, accuracy=69.703, wps=12218.3, ups=1.45, wpb=8428, bsz=315.7, num_updates=44900, lr=6.67409e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=69, gb_free=15.9, wall=37163
2023-08-13 23:08:23 | INFO | train_inner | epoch 031:    799 / 1474 loss=1.894, trans_loss=4.751, nll_loss=1.946, w2v_ctc_loss=0.605, task_loss=1.47, contrastive_loss=0.141, total=4097.37, n_correct=2841.33, ppl=3.85, accuracy=69.345, wps=11666.1, ups=1.42, wpb=8194.7, bsz=295.8, num_updates=45000, lr=6.66667e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=70, gb_free=12.5, wall=37233
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:0')
2023-08-13 23:09:33 | INFO | train_inner | epoch 031:    899 / 1474 loss=1.881, trans_loss=4.737, nll_loss=1.928, w2v_ctc_loss=0.601, task_loss=1.461, contrastive_loss=0.086, total=4096.72, n_correct=2851.86, ppl=3.81, accuracy=69.613, wps=11831.6, ups=1.44, wpb=8193.4, bsz=296.1, num_updates=45100, lr=6.65927e-05, gnorm=0.534, clip=0, loss_scale=64, train_wall=69, gb_free=17, wall=37302
2023-08-13 23:10:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-13 23:10:43 | INFO | train_inner | epoch 031:   1000 / 1474 loss=1.89, trans_loss=4.753, nll_loss=1.949, w2v_ctc_loss=0.599, task_loss=1.312, contrastive_loss=0.167, total=4187.93, n_correct=2909.67, ppl=3.86, accuracy=69.478, wps=11918.9, ups=1.42, wpb=8375.9, bsz=320.6, num_updates=45200, lr=6.6519e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=70, gb_free=13, wall=37373
2023-08-13 23:11:52 | INFO | train_inner | epoch 031:   1100 / 1474 loss=1.887, trans_loss=4.749, nll_loss=1.945, w2v_ctc_loss=0.601, task_loss=1.371, contrastive_loss=0.116, total=4149.25, n_correct=2884.15, ppl=3.85, accuracy=69.51, wps=12022.6, ups=1.45, wpb=8298.5, bsz=315.2, num_updates=45300, lr=6.64455e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=37442
2023-08-13 23:13:01 | INFO | train_inner | epoch 031:   1200 / 1474 loss=1.891, trans_loss=4.748, nll_loss=1.943, w2v_ctc_loss=0.592, task_loss=1.321, contrastive_loss=0.231, total=4187.45, n_correct=2913.45, ppl=3.84, accuracy=69.576, wps=12052.7, ups=1.44, wpb=8374.9, bsz=320.3, num_updates=45400, lr=6.63723e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=37511
2023-08-13 23:14:10 | INFO | train_inner | epoch 031:   1300 / 1474 loss=1.883, trans_loss=4.756, nll_loss=1.953, w2v_ctc_loss=0.603, task_loss=1.261, contrastive_loss=0.076, total=4227.39, n_correct=2934.51, ppl=3.87, accuracy=69.417, wps=12258.6, ups=1.45, wpb=8454.8, bsz=326.7, num_updates=45500, lr=6.62994e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=37580
2023-08-13 23:15:21 | INFO | train_inner | epoch 031:   1400 / 1474 loss=1.903, trans_loss=4.75, nll_loss=1.947, w2v_ctc_loss=0.6, task_loss=1.286, contrastive_loss=0.279, total=4191.1, n_correct=2909.43, ppl=3.85, accuracy=69.419, wps=11914.8, ups=1.42, wpb=8382.2, bsz=327, num_updates=45600, lr=6.62266e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=70, gb_free=16.3, wall=37651
2023-08-13 23:16:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2675, device='cuda:2')
2023-08-13 23:16:35 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 3.948 | trans_loss 5.153 | nll_loss 2.405 | w2v_ctc_loss 1.327 | task_loss 4.681 | contrastive_loss 0.291 | total 4003.4 | n_correct 2678.8 | ppl 5.29 | accuracy 66.913 | uer 17.278 | wer 19.313 | raw_wer 19.313 | bleu 22.49 | wps 2150.4 | wpb 4003.4 | bsz 141.8 | num_updates 45674 | best_bleu 22.73
2023-08-13 23:16:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45674 updates
2023-08-13 23:16:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4902.pt
2023-08-13 23:16:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4902.pt
2023-08-13 23:16:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.4902.pt (epoch 31 @ 45674 updates, score 22.49) (writing took 21.020835993811488 seconds)
2023-08-13 23:16:57 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-13 23:16:57 | INFO | train | epoch 031 | loss 1.886 | trans_loss 4.747 | nll_loss 1.941 | w2v_ctc_loss 0.601 | task_loss 1.404 | contrastive_loss 0.12 | total 4138.52 | n_correct 2878.15 | ppl 3.84 | accuracy 69.545 | wps 11304.8 | ups 1.37 | wpb 8277 | bsz 305.7 | num_updates 45674 | lr 6.61729e-05 | gnorm 0.529 | clip 0 | loss_scale 32 | train_wall 1018 | gb_free 11.7 | wall 37747
2023-08-13 23:16:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 23:16:57 | INFO | fairseq.trainer | begin training epoch 32
2023-08-13 23:16:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 23:17:23 | INFO | train_inner | epoch 032:     26 / 1474 loss=1.882, trans_loss=4.742, nll_loss=1.936, w2v_ctc_loss=0.606, task_loss=1.484, contrastive_loss=0.067, total=4040.88, n_correct=2814.1, ppl=3.83, accuracy=69.641, wps=6602.8, ups=0.82, wpb=8081.8, bsz=288.7, num_updates=45700, lr=6.61541e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=15.2, wall=37773
2023-08-13 23:18:33 | INFO | train_inner | epoch 032:    126 / 1474 loss=1.862, trans_loss=4.722, nll_loss=1.909, w2v_ctc_loss=0.581, task_loss=1.299, contrastive_loss=0.076, total=4222.14, n_correct=2958.73, ppl=3.75, accuracy=70.077, wps=12077.3, ups=1.43, wpb=8444.3, bsz=322.6, num_updates=45800, lr=6.60819e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=69, gb_free=15.2, wall=37843
2023-08-13 23:19:43 | INFO | train_inner | epoch 032:    226 / 1474 loss=1.875, trans_loss=4.739, nll_loss=1.931, w2v_ctc_loss=0.597, task_loss=1.337, contrastive_loss=0.085, total=4159.77, n_correct=2900.32, ppl=3.81, accuracy=69.723, wps=11962.3, ups=1.44, wpb=8319.5, bsz=320.8, num_updates=45900, lr=6.60098e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=37912
2023-08-13 23:20:52 | INFO | train_inner | epoch 032:    326 / 1474 loss=1.868, trans_loss=4.725, nll_loss=1.914, w2v_ctc_loss=0.586, task_loss=1.332, contrastive_loss=0.08, total=4179.65, n_correct=2926.69, ppl=3.77, accuracy=70.022, wps=12049.2, ups=1.44, wpb=8359.3, bsz=313.8, num_updates=46000, lr=6.5938e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=37982
2023-08-13 23:20:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 23:21:16 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.959 | trans_loss 5.159 | nll_loss 2.411 | w2v_ctc_loss 1.347 | task_loss 4.661 | contrastive_loss 0.295 | total 4003.4 | n_correct 2681.6 | ppl 5.32 | accuracy 66.983 | uer 17.1 | wer 18.989 | raw_wer 18.989 | bleu 22.01 | wps 2172.7 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 22.73
2023-08-13 23:21:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-08-13 23:21:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_32_46000.pt
2023-08-13 23:21:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_32_46000.pt
2023-08-13 23:21:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 22.01) (writing took 22.77452701702714 seconds)
2023-08-13 23:22:49 | INFO | train_inner | epoch 032:    426 / 1474 loss=1.873, trans_loss=4.729, nll_loss=1.919, w2v_ctc_loss=0.598, task_loss=1.374, contrastive_loss=0.078, total=4172.34, n_correct=2916.13, ppl=3.78, accuracy=69.892, wps=7151.9, ups=0.86, wpb=8344.7, bsz=309.9, num_updates=46100, lr=6.58665e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=16.9, wall=38098
2023-08-13 23:23:59 | INFO | train_inner | epoch 032:    526 / 1474 loss=1.888, trans_loss=4.743, nll_loss=1.936, w2v_ctc_loss=0.599, task_loss=1.37, contrastive_loss=0.158, total=4191.15, n_correct=2918.12, ppl=3.83, accuracy=69.626, wps=11883.6, ups=1.42, wpb=8382.3, bsz=315.1, num_updates=46200, lr=6.57952e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=70, gb_free=14.7, wall=38169
2023-08-13 23:25:09 | INFO | train_inner | epoch 032:    626 / 1474 loss=1.879, trans_loss=4.741, nll_loss=1.933, w2v_ctc_loss=0.597, task_loss=1.469, contrastive_loss=0.083, total=4138.05, n_correct=2882.26, ppl=3.82, accuracy=69.653, wps=11863.1, ups=1.43, wpb=8276.1, bsz=299.5, num_updates=46300, lr=6.57241e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=13, wall=38239
2023-08-13 23:26:19 | INFO | train_inner | epoch 032:    726 / 1474 loss=1.879, trans_loss=4.741, nll_loss=1.933, w2v_ctc_loss=0.603, task_loss=1.422, contrastive_loss=0.069, total=4156.23, n_correct=2897.63, ppl=3.82, accuracy=69.718, wps=11880.7, ups=1.43, wpb=8312.5, bsz=303, num_updates=46400, lr=6.56532e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=38309
2023-08-13 23:27:28 | INFO | train_inner | epoch 032:    826 / 1474 loss=1.876, trans_loss=4.739, nll_loss=1.93, w2v_ctc_loss=0.595, task_loss=1.453, contrastive_loss=0.066, total=4112.3, n_correct=2864.83, ppl=3.81, accuracy=69.665, wps=11890.7, ups=1.45, wpb=8224.6, bsz=293.9, num_updates=46500, lr=6.55826e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=38378
2023-08-13 23:28:38 | INFO | train_inner | epoch 032:    926 / 1474 loss=1.875, trans_loss=4.739, nll_loss=1.931, w2v_ctc_loss=0.592, task_loss=1.451, contrastive_loss=0.064, total=4139.37, n_correct=2886.89, ppl=3.81, accuracy=69.742, wps=11845.6, ups=1.43, wpb=8278.7, bsz=298.6, num_updates=46600, lr=6.55122e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=12.4, wall=38448
2023-08-13 23:29:47 | INFO | train_inner | epoch 032:   1026 / 1474 loss=1.886, trans_loss=4.744, nll_loss=1.938, w2v_ctc_loss=0.596, task_loss=1.382, contrastive_loss=0.158, total=4121.85, n_correct=2867.48, ppl=3.83, accuracy=69.568, wps=11979.2, ups=1.45, wpb=8243.7, bsz=306.1, num_updates=46700, lr=6.5442e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=38517
2023-08-13 23:30:57 | INFO | train_inner | epoch 032:   1126 / 1474 loss=1.886, trans_loss=4.742, nll_loss=1.934, w2v_ctc_loss=0.6, task_loss=1.664, contrastive_loss=0.101, total=4015.59, n_correct=2791.97, ppl=3.82, accuracy=69.528, wps=11484.1, ups=1.43, wpb=8031.2, bsz=270.1, num_updates=46800, lr=6.5372e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=69, gb_free=16.9, wall=38587
2023-08-13 23:32:07 | INFO | train_inner | epoch 032:   1226 / 1474 loss=1.897, trans_loss=4.752, nll_loss=1.948, w2v_ctc_loss=0.599, task_loss=1.385, contrastive_loss=0.205, total=4153.44, n_correct=2882.54, ppl=3.86, accuracy=69.401, wps=11883, ups=1.43, wpb=8306.9, bsz=310.8, num_updates=46900, lr=6.53023e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=38657
2023-08-13 23:33:16 | INFO | train_inner | epoch 032:   1326 / 1474 loss=1.878, trans_loss=4.741, nll_loss=1.933, w2v_ctc_loss=0.599, task_loss=1.445, contrastive_loss=0.065, total=4075.86, n_correct=2836.6, ppl=3.82, accuracy=69.595, wps=11804.2, ups=1.45, wpb=8151.7, bsz=295.4, num_updates=47000, lr=6.52328e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=38726
2023-08-13 23:34:25 | INFO | train_inner | epoch 032:   1426 / 1474 loss=1.904, trans_loss=4.745, nll_loss=1.938, w2v_ctc_loss=0.609, task_loss=1.401, contrastive_loss=0.294, total=4116.4, n_correct=2860.88, ppl=3.83, accuracy=69.5, wps=11945.2, ups=1.45, wpb=8232.8, bsz=307.6, num_updates=47100, lr=6.51635e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=38794
2023-08-13 23:34:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 23:35:21 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.944 | trans_loss 5.151 | nll_loss 2.404 | w2v_ctc_loss 1.316 | task_loss 4.663 | contrastive_loss 0.293 | total 4003.4 | n_correct 2683.3 | ppl 5.29 | accuracy 67.026 | uer 16.951 | wer 18.918 | raw_wer 18.918 | bleu 22.61 | wps 2145.3 | wpb 4003.4 | bsz 141.8 | num_updates 47148 | best_bleu 22.73
2023-08-13 23:35:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47148 updates
2023-08-13 23:35:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.6104.pt
2023-08-13 23:35:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.6104.pt
2023-08-13 23:35:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.6104.pt (epoch 32 @ 47148 updates, score 22.61) (writing took 22.595780098810792 seconds)
2023-08-13 23:35:44 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-13 23:35:44 | INFO | train | epoch 032 | loss 1.881 | trans_loss 4.739 | nll_loss 1.93 | w2v_ctc_loss 0.596 | task_loss 1.404 | contrastive_loss 0.118 | total 4138.65 | n_correct 2884.67 | ppl 3.81 | accuracy 69.701 | wps 10824.6 | ups 1.31 | wpb 8277.3 | bsz 305.7 | num_updates 47148 | lr 6.51303e-05 | gnorm 0.527 | clip 0 | loss_scale 32 | train_wall 1019 | gb_free 16.1 | wall 38874
2023-08-13 23:35:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 23:35:44 | INFO | fairseq.trainer | begin training epoch 33
2023-08-13 23:35:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 23:36:29 | INFO | train_inner | epoch 033:     52 / 1474 loss=1.881, trans_loss=4.737, nll_loss=1.928, w2v_ctc_loss=0.588, task_loss=1.326, contrastive_loss=0.168, total=4149.21, n_correct=2897.82, ppl=3.81, accuracy=69.84, wps=6676.7, ups=0.8, wpb=8298.4, bsz=320.5, num_updates=47200, lr=6.50945e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=38919
2023-08-13 23:37:38 | INFO | train_inner | epoch 033:    152 / 1474 loss=1.862, trans_loss=4.719, nll_loss=1.904, w2v_ctc_loss=0.578, task_loss=1.509, contrastive_loss=0.058, total=4073.9, n_correct=2855.82, ppl=3.74, accuracy=70.1, wps=11770.1, ups=1.44, wpb=8147.8, bsz=284.8, num_updates=47300, lr=6.50256e-05, gnorm=0.534, clip=0, loss_scale=64, train_wall=69, gb_free=14.9, wall=38988
2023-08-13 23:38:48 | INFO | train_inner | epoch 033:    252 / 1474 loss=1.885, trans_loss=4.726, nll_loss=1.915, w2v_ctc_loss=0.587, task_loss=1.197, contrastive_loss=0.233, total=4280.14, n_correct=2996.45, ppl=3.77, accuracy=70.008, wps=12301.8, ups=1.44, wpb=8560.3, bsz=346.5, num_updates=47400, lr=6.4957e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=69, gb_free=16.2, wall=39058
2023-08-13 23:39:57 | INFO | train_inner | epoch 033:    352 / 1474 loss=1.875, trans_loss=4.731, nll_loss=1.921, w2v_ctc_loss=0.595, task_loss=1.437, contrastive_loss=0.084, total=4120.27, n_correct=2880.66, ppl=3.79, accuracy=69.914, wps=11905.2, ups=1.44, wpb=8240.5, bsz=300.7, num_updates=47500, lr=6.48886e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=69, gb_free=17, wall=39127
2023-08-13 23:41:06 | INFO | train_inner | epoch 033:    452 / 1474 loss=1.858, trans_loss=4.718, nll_loss=1.903, w2v_ctc_loss=0.578, task_loss=1.333, contrastive_loss=0.064, total=4141.22, n_correct=2909.71, ppl=3.74, accuracy=70.262, wps=12019.1, ups=1.45, wpb=8282.4, bsz=310.8, num_updates=47600, lr=6.48204e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=68, gb_free=16.1, wall=39196
2023-08-13 23:42:15 | INFO | train_inner | epoch 033:    552 / 1474 loss=1.879, trans_loss=4.733, nll_loss=1.923, w2v_ctc_loss=0.598, task_loss=1.462, contrastive_loss=0.087, total=4133.59, n_correct=2884.5, ppl=3.79, accuracy=69.782, wps=11926.5, ups=1.44, wpb=8267.2, bsz=294, num_updates=47700, lr=6.47524e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=69, gb_free=14.9, wall=39265
2023-08-13 23:43:25 | INFO | train_inner | epoch 033:    652 / 1474 loss=1.882, trans_loss=4.744, nll_loss=1.936, w2v_ctc_loss=0.592, task_loss=1.435, contrastive_loss=0.119, total=4157.63, n_correct=2896.37, ppl=3.83, accuracy=69.664, wps=11979.7, ups=1.44, wpb=8315.3, bsz=301.6, num_updates=47800, lr=6.46846e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=69, gb_free=17.5, wall=39334
2023-08-13 23:44:34 | INFO | train_inner | epoch 033:    752 / 1474 loss=1.883, trans_loss=4.738, nll_loss=1.929, w2v_ctc_loss=0.609, task_loss=1.524, contrastive_loss=0.067, total=4070.75, n_correct=2837.86, ppl=3.81, accuracy=69.713, wps=11749, ups=1.44, wpb=8141.5, bsz=287.2, num_updates=47900, lr=6.46171e-05, gnorm=0.539, clip=0, loss_scale=64, train_wall=69, gb_free=16, wall=39404
2023-08-13 23:45:43 | INFO | train_inner | epoch 033:    852 / 1474 loss=1.865, trans_loss=4.725, nll_loss=1.913, w2v_ctc_loss=0.575, task_loss=1.336, contrastive_loss=0.132, total=4130.24, n_correct=2896.38, ppl=3.77, accuracy=70.126, wps=11962.8, ups=1.45, wpb=8260.5, bsz=316.3, num_updates=48000, lr=6.45497e-05, gnorm=0.521, clip=0, loss_scale=64, train_wall=69, gb_free=16.3, wall=39473
2023-08-13 23:45:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 23:46:07 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.96 | trans_loss 5.157 | nll_loss 2.41 | w2v_ctc_loss 1.366 | task_loss 4.655 | contrastive_loss 0.28 | total 4003.4 | n_correct 2679.1 | ppl 5.31 | accuracy 66.921 | uer 16.802 | wer 18.705 | raw_wer 18.705 | bleu 22.2 | wps 2212.2 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 22.73
2023-08-13 23:46:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-08-13 23:46:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_33_48000.pt
2023-08-13 23:46:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_33_48000.pt
2023-08-13 23:46:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 22.2) (writing took 23.080495670437813 seconds)
2023-08-13 23:47:40 | INFO | train_inner | epoch 033:    952 / 1474 loss=1.876, trans_loss=4.734, nll_loss=1.924, w2v_ctc_loss=0.601, task_loss=1.403, contrastive_loss=0.076, total=4151.18, n_correct=2898.71, ppl=3.79, accuracy=69.829, wps=7106.2, ups=0.86, wpb=8302.4, bsz=308.3, num_updates=48100, lr=6.44826e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=69, gb_free=10.9, wall=39590
2023-08-13 23:48:50 | INFO | train_inner | epoch 033:   1052 / 1474 loss=1.883, trans_loss=4.729, nll_loss=1.918, w2v_ctc_loss=0.592, task_loss=1.405, contrastive_loss=0.178, total=4140.1, n_correct=2892.4, ppl=3.78, accuracy=69.863, wps=11873.9, ups=1.43, wpb=8280.2, bsz=307.6, num_updates=48200, lr=6.44157e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=69, gb_free=11.2, wall=39659
2023-08-13 23:49:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-13 23:50:00 | INFO | train_inner | epoch 033:   1153 / 1474 loss=1.875, trans_loss=4.74, nll_loss=1.932, w2v_ctc_loss=0.59, task_loss=1.434, contrastive_loss=0.077, total=4171.38, n_correct=2909.24, ppl=3.82, accuracy=69.743, wps=11802, ups=1.41, wpb=8342.8, bsz=304.1, num_updates=48300, lr=6.43489e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=70, gb_free=14.8, wall=39730
2023-08-13 23:51:10 | INFO | train_inner | epoch 033:   1253 / 1474 loss=1.873, trans_loss=4.73, nll_loss=1.919, w2v_ctc_loss=0.597, task_loss=1.474, contrastive_loss=0.069, total=4115.76, n_correct=2877.98, ppl=3.78, accuracy=69.926, wps=11795.8, ups=1.43, wpb=8231.5, bsz=294.7, num_updates=48400, lr=6.42824e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=39800
2023-08-13 23:52:20 | INFO | train_inner | epoch 033:   1353 / 1474 loss=1.873, trans_loss=4.734, nll_loss=1.926, w2v_ctc_loss=0.592, task_loss=1.381, contrastive_loss=0.089, total=4120.69, n_correct=2880.25, ppl=3.8, accuracy=69.897, wps=11726.8, ups=1.42, wpb=8241.4, bsz=311.9, num_updates=48500, lr=6.42161e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=70, gb_free=16.5, wall=39870
2023-08-13 23:53:30 | INFO | train_inner | epoch 033:   1453 / 1474 loss=1.886, trans_loss=4.734, nll_loss=1.926, w2v_ctc_loss=0.59, task_loss=1.398, contrastive_loss=0.233, total=4125.28, n_correct=2877.24, ppl=3.8, accuracy=69.747, wps=11928.6, ups=1.45, wpb=8250.6, bsz=308.7, num_updates=48600, lr=6.415e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=39939
2023-08-13 23:53:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 23:54:07 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.949 | trans_loss 5.152 | nll_loss 2.403 | w2v_ctc_loss 1.336 | task_loss 4.657 | contrastive_loss 0.285 | total 4003.4 | n_correct 2686.8 | ppl 5.29 | accuracy 67.113 | uer 16.975 | wer 18.814 | raw_wer 18.814 | bleu 22.89 | wps 2199.4 | wpb 4003.4 | bsz 141.8 | num_updates 48621 | best_bleu 22.89
2023-08-13 23:54:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48621 updates
2023-08-13 23:54:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 23:54:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 23:54:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 33 @ 48621 updates, score 22.89) (writing took 28.606252390891314 seconds)
2023-08-13 23:54:36 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-13 23:54:36 | INFO | train | epoch 033 | loss 1.875 | trans_loss 4.731 | nll_loss 1.92 | w2v_ctc_loss 0.591 | task_loss 1.406 | contrastive_loss 0.111 | total 4137.9 | n_correct 2892.45 | ppl 3.79 | accuracy 69.901 | wps 10770.8 | ups 1.3 | wpb 8275.8 | bsz 305.3 | num_updates 48621 | lr 6.41362e-05 | gnorm 0.53 | clip 0 | loss_scale 32 | train_wall 1017 | gb_free 17.5 | wall 40006
2023-08-13 23:54:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 23:54:36 | INFO | fairseq.trainer | begin training epoch 34
2023-08-13 23:54:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 23:55:39 | INFO | train_inner | epoch 034:     79 / 1474 loss=1.866, trans_loss=4.721, nll_loss=1.907, w2v_ctc_loss=0.588, task_loss=1.388, contrastive_loss=0.071, total=4131.47, n_correct=2894.6, ppl=3.75, accuracy=70.062, wps=6374.5, ups=0.77, wpb=8262.9, bsz=301.7, num_updates=48700, lr=6.40841e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=40069
2023-08-13 23:56:48 | INFO | train_inner | epoch 034:    179 / 1474 loss=1.861, trans_loss=4.71, nll_loss=1.893, w2v_ctc_loss=0.585, task_loss=1.466, contrastive_loss=0.072, total=4065.88, n_correct=2860.73, ppl=3.71, accuracy=70.359, wps=11750.1, ups=1.44, wpb=8131.8, bsz=295.1, num_updates=48800, lr=6.40184e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=40138
2023-08-13 23:57:59 | INFO | train_inner | epoch 034:    279 / 1474 loss=1.89, trans_loss=4.732, nll_loss=1.923, w2v_ctc_loss=0.582, task_loss=1.312, contrastive_loss=0.281, total=4246.3, n_correct=2965.03, ppl=3.79, accuracy=69.826, wps=12030.9, ups=1.42, wpb=8492.6, bsz=328.7, num_updates=48900, lr=6.39529e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=70, gb_free=17.5, wall=40209
2023-08-13 23:59:08 | INFO | train_inner | epoch 034:    379 / 1474 loss=1.868, trans_loss=4.713, nll_loss=1.897, w2v_ctc_loss=0.578, task_loss=1.335, contrastive_loss=0.169, total=4156.17, n_correct=2918.65, ppl=3.72, accuracy=70.225, wps=11986.6, ups=1.44, wpb=8312.3, bsz=316.7, num_updates=49000, lr=6.38877e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=17.5, wall=40278
2023-08-14 00:00:18 | INFO | train_inner | epoch 034:    479 / 1474 loss=1.873, trans_loss=4.725, nll_loss=1.912, w2v_ctc_loss=0.597, task_loss=1.541, contrastive_loss=0.066, total=4070.55, n_correct=2848.19, ppl=3.76, accuracy=69.971, wps=11742.6, ups=1.44, wpb=8141.1, bsz=284.6, num_updates=49100, lr=6.38226e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=40347
2023-08-14 00:01:27 | INFO | train_inner | epoch 034:    579 / 1474 loss=1.862, trans_loss=4.714, nll_loss=1.899, w2v_ctc_loss=0.582, task_loss=1.426, contrastive_loss=0.069, total=4119.38, n_correct=2893.68, ppl=3.73, accuracy=70.246, wps=11925.3, ups=1.45, wpb=8238.8, bsz=300.3, num_updates=49200, lr=6.37577e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=12.7, wall=40417
2023-08-14 00:02:36 | INFO | train_inner | epoch 034:    679 / 1474 loss=1.863, trans_loss=4.722, nll_loss=1.909, w2v_ctc_loss=0.584, task_loss=1.424, contrastive_loss=0.062, total=4124.83, n_correct=2893.45, ppl=3.75, accuracy=70.147, wps=11830.6, ups=1.43, wpb=8249.7, bsz=300.2, num_updates=49300, lr=6.3693e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=13.9, wall=40486
2023-08-14 00:03:46 | INFO | train_inner | epoch 034:    779 / 1474 loss=1.879, trans_loss=4.741, nll_loss=1.934, w2v_ctc_loss=0.584, task_loss=1.476, contrastive_loss=0.132, total=4082.07, n_correct=2847.11, ppl=3.82, accuracy=69.747, wps=11726.3, ups=1.44, wpb=8164.1, bsz=295, num_updates=49400, lr=6.36285e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=15.3, wall=40556
2023-08-14 00:04:56 | INFO | train_inner | epoch 034:    879 / 1474 loss=1.875, trans_loss=4.729, nll_loss=1.918, w2v_ctc_loss=0.593, task_loss=1.484, contrastive_loss=0.091, total=4100.9, n_correct=2869.03, ppl=3.78, accuracy=69.961, wps=11706.4, ups=1.43, wpb=8201.8, bsz=296.6, num_updates=49500, lr=6.35642e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=70, gb_free=11.8, wall=40626
2023-08-14 00:06:05 | INFO | train_inner | epoch 034:    979 / 1474 loss=1.873, trans_loss=4.728, nll_loss=1.916, w2v_ctc_loss=0.596, task_loss=1.379, contrastive_loss=0.086, total=4168.39, n_correct=2914.25, ppl=3.77, accuracy=69.913, wps=12044.4, ups=1.44, wpb=8336.8, bsz=311.9, num_updates=49600, lr=6.35001e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=40695
2023-08-14 00:07:15 | INFO | train_inner | epoch 034:   1079 / 1474 loss=1.869, trans_loss=4.727, nll_loss=1.914, w2v_ctc_loss=0.594, task_loss=1.36, contrastive_loss=0.068, total=4150.57, n_correct=2904.2, ppl=3.77, accuracy=69.971, wps=11995.6, ups=1.45, wpb=8301.1, bsz=308.5, num_updates=49700, lr=6.34361e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=40764
2023-08-14 00:08:24 | INFO | train_inner | epoch 034:   1179 / 1474 loss=1.869, trans_loss=4.727, nll_loss=1.915, w2v_ctc_loss=0.587, task_loss=1.451, contrastive_loss=0.08, total=4098.77, n_correct=2868.56, ppl=3.77, accuracy=69.986, wps=11838, ups=1.44, wpb=8197.5, bsz=297.1, num_updates=49800, lr=6.33724e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=40834
2023-08-14 00:09:33 | INFO | train_inner | epoch 034:   1279 / 1474 loss=1.868, trans_loss=4.723, nll_loss=1.91, w2v_ctc_loss=0.59, task_loss=1.413, contrastive_loss=0.065, total=4150.54, n_correct=2906.79, ppl=3.76, accuracy=70.034, wps=11992.2, ups=1.44, wpb=8301.1, bsz=301, num_updates=49900, lr=6.33089e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=40903
2023-08-14 00:10:43 | INFO | train_inner | epoch 034:   1379 / 1474 loss=1.88, trans_loss=4.733, nll_loss=1.923, w2v_ctc_loss=0.597, task_loss=1.342, contrastive_loss=0.13, total=4196.91, n_correct=2928.65, ppl=3.79, accuracy=69.781, wps=12019, ups=1.43, wpb=8393.8, bsz=321.4, num_updates=50000, lr=6.32456e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=15.8, wall=40973
2023-08-14 00:10:43 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-14 00:10:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 00:11:07 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.95 | trans_loss 5.154 | nll_loss 2.404 | w2v_ctc_loss 1.33 | task_loss 4.674 | contrastive_loss 0.29 | total 4003.4 | n_correct 2682.4 | ppl 5.29 | accuracy 67.003 | uer 16.882 | wer 18.702 | raw_wer 18.702 | bleu 22.36 | wps 2155.8 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 22.89
2023-08-14 00:11:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-08-14 00:11:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_34_50000.pt
2023-08-14 00:11:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_34_50000.pt
2023-08-14 00:11:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0813_AT_sentence_mixup0.5_alpha1.5_mt0.5/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 22.36) (writing took 25.92139834165573 seconds)
2023-08-14 00:11:33 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-14 00:11:33 | INFO | train | epoch 034 | loss 1.871 | trans_loss 4.725 | nll_loss 1.912 | w2v_ctc_loss 0.588 | task_loss 1.414 | contrastive_loss 0.105 | total 4133.04 | n_correct 2893.85 | ppl 3.76 | accuracy 70.018 | wps 11203.6 | ups 1.36 | wpb 8266.1 | bsz 304.2 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.532 | clip 0 | loss_scale 32 | train_wall 953 | gb_free 15.8 | wall 41023
2023-08-14 00:11:33 | INFO | fairseq_cli.train | done training in 40972.0 seconds
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    raise EOFError
EOFError
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
