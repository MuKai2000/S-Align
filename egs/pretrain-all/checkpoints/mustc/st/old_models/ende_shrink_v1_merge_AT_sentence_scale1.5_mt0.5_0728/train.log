2023-07-28 01:54:33 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:14751
2023-07-28 01:54:33 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:14751
2023-07-28 01:54:33 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:14751
2023-07-28 01:54:33 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:14751
2023-07-28 01:54:33 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-28 01:54:33 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:14751
2023-07-28 01:54:33 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-28 01:54:33 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:14751
2023-07-28 01:54:33 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-28 01:54:33 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:14751
2023-07-28 01:54:33 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-28 01:54:33 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:14751
2023-07-28 01:54:33 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-28 01:54:34 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-28 01:54:34 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-28 01:54:34 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-28 01:54:34 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-28 01:54:34 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-07-28 01:54:34 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-28 01:54:34 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-07-28 01:54:34 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-28 01:54:34 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-07-28 01:54:34 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-28 01:54:34 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-28 01:54:34 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-07-28 01:54:34 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-07-28 01:54:34 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-28 01:54:34 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-28 01:54:34 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-28 01:54:34 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-07-28 01:54:34 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-07-28 01:54:34 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-07-28 01:54:38 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:14751', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-07-28 01:54:38 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-07-28 01:54:38 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-07-28 01:54:38 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-28 01:54:38 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-07-28 01:54:38 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-28 01:54:43 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-07-28 01:54:43 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-28 01:54:43 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-28 01:54:45 | INFO | root | load pretrained hubert
2023-07-28 01:54:45 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-28 01:54:47 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-28 01:54:48 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-28 01:54:48 | INFO | root | share the sematic adapter and textual encoder
2023-07-28 01:54:48 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-28 01:54:48 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-07-28 01:54:48 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-28 01:54:48 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-07-28 01:54:48 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-28 01:54:48 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-28 01:54:48 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-28 01:54:48 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-28 01:54:48 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-28 01:54:48 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-28 01:54:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-28 01:54:52 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-28 01:54:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-28 01:54:53 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-28 01:54:53 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-28 01:54:53 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-28 01:54:53 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-28 01:54:53 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-28 01:54:53 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-28 01:54:53 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-28 01:54:53 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-28 01:54:53 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-28 01:54:53 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-28 01:54:53 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-28 01:54:53 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-28 01:54:53 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_last.pt
2023-07-28 01:54:53 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_last.pt
2023-07-28 01:54:53 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-28 01:54:53 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-28 01:54:53 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-28 01:54:53 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-28 01:54:54 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-28 01:54:56 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-28 01:54:58 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-28 01:56:09 | INFO | fairseq.optim.adam | using FusedAdam
2023-07-28 01:56:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 01:56:09 | INFO | fairseq.trainer | begin training epoch 1
2023-07-28 01:56:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 01:57:31 | INFO | train_inner | epoch 001:    100 / 1474 loss=19.137, trans_loss=5.598, nll_loss=4.163, w2v_ctc_loss=22.485, task_loss=2.623, contrastive_loss=3.325, total=4207.04, n_correct=209.37, ppl=17.91, accuracy=4.977, wps=18940.4, ups=1.51, wpb=12551.1, bsz=471.4, num_updates=100, lr=4.098e-06, gnorm=0.891, clip=0, loss_scale=128, train_wall=72, gb_free=19.5, wall=158
2023-07-28 01:58:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-28 01:58:37 | INFO | train_inner | epoch 001:    201 / 1474 loss=16.991, trans_loss=5.477, nll_loss=4.065, w2v_ctc_loss=19.358, task_loss=2.558, contrastive_loss=3.278, total=4124.14, n_correct=223.4, ppl=16.74, accuracy=5.417, wps=18629.7, ups=1.51, wpb=12313.4, bsz=461, num_updates=200, lr=8.096e-06, gnorm=3.625, clip=0, loss_scale=64, train_wall=66, gb_free=19.2, wall=224
2023-07-28 01:59:41 | INFO | train_inner | epoch 001:    301 / 1474 loss=10.084, trans_loss=5.476, nll_loss=4.118, w2v_ctc_loss=8.784, task_loss=2.555, contrastive_loss=3.203, total=4079.62, n_correct=208.65, ppl=17.37, accuracy=5.114, wps=18959.2, ups=1.56, wpb=12186.7, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=4.607, clip=0, loss_scale=64, train_wall=64, gb_free=19.9, wall=288
2023-07-28 02:00:46 | INFO | train_inner | epoch 001:    401 / 1474 loss=8.848, trans_loss=5.516, nll_loss=4.19, w2v_ctc_loss=6.815, task_loss=2.242, contrastive_loss=3.237, total=4174.14, n_correct=193.71, ppl=18.25, accuracy=4.641, wps=19231.1, ups=1.54, wpb=12463.5, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=2.947, clip=0, loss_scale=64, train_wall=64, gb_free=18.9, wall=353
2023-07-28 02:01:52 | INFO | train_inner | epoch 001:    501 / 1474 loss=8.415, trans_loss=5.495, nll_loss=4.179, w2v_ctc_loss=6.176, task_loss=2.048, contrastive_loss=3.233, total=4176.18, n_correct=188.59, ppl=18.11, accuracy=4.516, wps=19105, ups=1.53, wpb=12479.7, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=1.416, clip=0, loss_scale=64, train_wall=65, gb_free=19.2, wall=419
2023-07-28 02:02:56 | INFO | train_inner | epoch 001:    601 / 1474 loss=8.165, trans_loss=5.524, nll_loss=4.215, w2v_ctc_loss=5.809, task_loss=1.906, contrastive_loss=3.288, total=4147.79, n_correct=184, ppl=18.57, accuracy=4.436, wps=19093, ups=1.54, wpb=12371.6, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.727, clip=0, loss_scale=64, train_wall=64, gb_free=18.9, wall=483
2023-07-28 02:04:00 | INFO | train_inner | epoch 001:    701 / 1474 loss=8.009, trans_loss=5.525, nll_loss=4.221, w2v_ctc_loss=5.69, task_loss=1.984, contrastive_loss=3.039, total=4152.1, n_correct=192.93, ppl=18.65, accuracy=4.647, wps=19365.2, ups=1.56, wpb=12395.5, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=0.548, clip=0, loss_scale=64, train_wall=63, gb_free=19.5, wall=547
2023-07-28 02:05:05 | INFO | train_inner | epoch 001:    801 / 1474 loss=7.732, trans_loss=5.461, nll_loss=4.153, w2v_ctc_loss=5.464, task_loss=1.92, contrastive_loss=2.947, total=4123.83, n_correct=237.85, ppl=17.78, accuracy=5.768, wps=19178, ups=1.56, wpb=12306.1, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=0.822, clip=0, loss_scale=64, train_wall=64, gb_free=19.2, wall=612
2023-07-28 02:06:09 | INFO | train_inner | epoch 001:    901 / 1474 loss=7.472, trans_loss=5.427, nll_loss=4.122, w2v_ctc_loss=5.281, task_loss=1.952, contrastive_loss=2.707, total=4163.61, n_correct=263.51, ppl=17.41, accuracy=6.329, wps=19180.6, ups=1.54, wpb=12433.9, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=1.331, clip=0, loss_scale=64, train_wall=64, gb_free=18.9, wall=676
2023-07-28 02:07:14 | INFO | train_inner | epoch 001:   1001 / 1474 loss=7.212, trans_loss=5.403, nll_loss=4.101, w2v_ctc_loss=5.07, task_loss=1.965, contrastive_loss=2.557, total=4135.34, n_correct=286.14, ppl=17.16, accuracy=6.919, wps=19249.6, ups=1.56, wpb=12353.2, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=1.418, clip=0, loss_scale=64, train_wall=64, gb_free=19, wall=741
2023-07-28 02:08:17 | INFO | train_inner | epoch 001:   1101 / 1474 loss=6.943, trans_loss=5.39, nll_loss=4.088, w2v_ctc_loss=4.871, task_loss=1.981, contrastive_loss=2.335, total=4147.38, n_correct=308.58, ppl=17.01, accuracy=7.44, wps=19338.9, ups=1.56, wpb=12367, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=1.652, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=805
2023-07-28 02:09:21 | INFO | train_inner | epoch 001:   1201 / 1474 loss=6.723, trans_loss=5.37, nll_loss=4.071, w2v_ctc_loss=4.705, task_loss=2.065, contrastive_loss=2.131, total=4139.9, n_correct=316, ppl=16.81, accuracy=7.633, wps=19363.4, ups=1.57, wpb=12366.5, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=1.76, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=868
2023-07-28 02:10:27 | INFO | train_inner | epoch 001:   1301 / 1474 loss=6.502, trans_loss=5.368, nll_loss=4.071, w2v_ctc_loss=4.51, task_loss=1.986, contrastive_loss=1.941, total=4046.58, n_correct=318.49, ppl=16.8, accuracy=7.871, wps=18471.1, ups=1.53, wpb=12081.6, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=1.737, clip=0, loss_scale=64, train_wall=65, gb_free=19.7, wall=934
2023-07-28 02:11:31 | INFO | train_inner | epoch 001:   1401 / 1474 loss=6.296, trans_loss=5.357, nll_loss=4.061, w2v_ctc_loss=4.31, task_loss=1.962, contrastive_loss=2.009, total=4133.18, n_correct=332.2, ppl=16.69, accuracy=8.037, wps=19267, ups=1.56, wpb=12350, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=1.624, clip=0, loss_scale=64, train_wall=64, gb_free=19.9, wall=998
2023-07-28 02:12:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 02:12:56 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.569 | trans_loss 10.92 | nll_loss 9.903 | w2v_ctc_loss 5.606 | task_loss 11.319 | contrastive_loss 2.368 | total 4003.4 | n_correct 383.7 | ppl 957.68 | accuracy 9.584 | uer 71.937 | wer 69.882 | raw_wer 69.882 | bleu 0.03 | wps 1191.4 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-07-28 02:12:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-07-28 02:12:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 02:13:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 02:13:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.03) (writing took 5.470607960596681 seconds)
2023-07-28 02:13:02 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-07-28 02:13:02 | INFO | train | epoch 001 | loss 9.041 | trans_loss 5.452 | nll_loss 4.126 | w2v_ctc_loss 7.644 | task_loss 2.113 | contrastive_loss 2.762 | total 4138.55 | n_correct 251.767 | ppl 17.46 | accuracy 6.083 | wps 18252.3 | ups 1.48 | wpb 12355.5 | bsz 458.4 | num_updates 1473 | lr 5.89905e-05 | gnorm 1.788 | clip 0 | loss_scale 64 | train_wall 951 | gb_free 19.2 | wall 1089
2023-07-28 02:13:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 02:13:02 | INFO | fairseq.trainer | begin training epoch 2
2023-07-28 02:13:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 02:13:29 | INFO | train_inner | epoch 002:     27 / 1474 loss=6.107, trans_loss=5.35, nll_loss=4.048, w2v_ctc_loss=4.117, task_loss=1.869, contrastive_loss=1.855, total=4162.95, n_correct=337.83, ppl=16.54, accuracy=8.115, wps=10547.5, ups=0.85, wpb=12416.8, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=1.655, clip=0, loss_scale=64, train_wall=64, gb_free=19.6, wall=1116
2023-07-28 02:14:32 | INFO | train_inner | epoch 002:    127 / 1474 loss=5.947, trans_loss=5.347, nll_loss=4.043, w2v_ctc_loss=4.001, task_loss=1.994, contrastive_loss=1.653, total=4155.98, n_correct=339.91, ppl=16.48, accuracy=8.179, wps=19419, ups=1.57, wpb=12394.8, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=1.726, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=1180
2023-07-28 02:15:37 | INFO | train_inner | epoch 002:    227 / 1474 loss=5.783, trans_loss=5.326, nll_loss=4.022, w2v_ctc_loss=3.805, task_loss=1.73, contrastive_loss=1.683, total=4179.21, n_correct=348.48, ppl=16.25, accuracy=8.338, wps=19192.8, ups=1.54, wpb=12484.6, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=1.51, clip=0, loss_scale=64, train_wall=65, gb_free=19, wall=1245
2023-07-28 02:16:42 | INFO | train_inner | epoch 002:    327 / 1474 loss=5.623, trans_loss=5.325, nll_loss=4.017, w2v_ctc_loss=3.715, task_loss=1.987, contrastive_loss=1.392, total=4146.1, n_correct=352.61, ppl=16.19, accuracy=8.505, wps=19234.2, ups=1.55, wpb=12374.1, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=1.396, clip=0, loss_scale=64, train_wall=64, gb_free=18.8, wall=1309
2023-07-28 02:17:45 | INFO | train_inner | epoch 002:    427 / 1474 loss=5.483, trans_loss=5.316, nll_loss=4.01, w2v_ctc_loss=3.618, task_loss=2.184, contrastive_loss=1.215, total=4037.99, n_correct=343.58, ppl=16.12, accuracy=8.509, wps=19016.6, ups=1.58, wpb=12069.2, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=1.438, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=1372
2023-07-28 02:18:49 | INFO | train_inner | epoch 002:    527 / 1474 loss=5.372, trans_loss=5.304, nll_loss=3.992, w2v_ctc_loss=3.457, task_loss=1.899, contrastive_loss=1.31, total=4176.97, n_correct=360.78, ppl=15.91, accuracy=8.637, wps=19611.9, ups=1.57, wpb=12463.5, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=1.28, clip=0, loss_scale=64, train_wall=63, gb_free=19.6, wall=1436
2023-07-28 02:18:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 02:19:28 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.957 | trans_loss 10.761 | nll_loss 9.688 | w2v_ctc_loss 4.515 | task_loss 11.318 | contrastive_loss 1.646 | total 4003.4 | n_correct 409.8 | ppl 824.76 | accuracy 10.236 | uer 61.471 | wer 59.293 | raw_wer 59.293 | bleu 0.06 | wps 1166.7 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.06
2023-07-28 02:19:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-07-28 02:19:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_2_2000.pt
2023-07-28 02:19:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_2_2000.pt
2023-07-28 02:19:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.06) (writing took 19.9893118776381 seconds)
2023-07-28 02:20:53 | INFO | train_inner | epoch 002:    627 / 1474 loss=5.24, trans_loss=5.297, nll_loss=3.983, w2v_ctc_loss=3.352, task_loss=1.963, contrastive_loss=1.111, total=4126.49, n_correct=367.49, ppl=15.81, accuracy=8.906, wps=9887.8, ups=0.8, wpb=12314.9, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=1.172, clip=0, loss_scale=64, train_wall=64, gb_free=19.2, wall=1560
2023-07-28 02:21:57 | INFO | train_inner | epoch 002:    727 / 1474 loss=5.167, trans_loss=5.282, nll_loss=3.967, w2v_ctc_loss=3.267, task_loss=1.924, contrastive_loss=1.212, total=4149.06, n_correct=374.53, ppl=15.64, accuracy=9.027, wps=19521.3, ups=1.58, wpb=12386.4, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=1.14, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=1624
2023-07-28 02:23:00 | INFO | train_inner | epoch 002:    827 / 1474 loss=5.078, trans_loss=5.267, nll_loss=3.95, w2v_ctc_loss=3.197, task_loss=1.976, contrastive_loss=1.161, total=4175.4, n_correct=384.11, ppl=15.45, accuracy=9.199, wps=19608, ups=1.57, wpb=12471.9, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=1.031, clip=0, loss_scale=128, train_wall=63, gb_free=19.8, wall=1688
2023-07-28 02:24:04 | INFO | train_inner | epoch 002:    927 / 1474 loss=4.987, trans_loss=5.254, nll_loss=3.933, w2v_ctc_loss=3.104, task_loss=2.016, contrastive_loss=1.143, total=4104.2, n_correct=380.43, ppl=15.27, accuracy=9.269, wps=19289.6, ups=1.57, wpb=12253.1, bsz=445.9, num_updates=2400, lr=9.6052e-05, gnorm=1.025, clip=0, loss_scale=128, train_wall=63, gb_free=19, wall=1751
2023-07-28 02:25:09 | INFO | train_inner | epoch 002:   1027 / 1474 loss=4.902, trans_loss=5.248, nll_loss=3.928, w2v_ctc_loss=3.034, task_loss=1.957, contrastive_loss=0.996, total=4102.5, n_correct=385.95, ppl=15.22, accuracy=9.408, wps=18827, ups=1.54, wpb=12251.2, bsz=456.3, num_updates=2500, lr=0.00010005, gnorm=0.898, clip=0, loss_scale=128, train_wall=65, gb_free=19.2, wall=1816
2023-07-28 02:26:13 | INFO | train_inner | epoch 002:   1127 / 1474 loss=4.858, trans_loss=5.242, nll_loss=3.918, w2v_ctc_loss=2.943, task_loss=1.781, contrastive_loss=1.207, total=4187.61, n_correct=400.54, ppl=15.12, accuracy=9.565, wps=19494.7, ups=1.56, wpb=12495.7, bsz=487.1, num_updates=2600, lr=0.000104048, gnorm=0.904, clip=0, loss_scale=128, train_wall=64, gb_free=19.5, wall=1880
2023-07-28 02:27:18 | INFO | train_inner | epoch 002:   1227 / 1474 loss=4.801, trans_loss=5.229, nll_loss=3.903, w2v_ctc_loss=2.899, task_loss=1.792, contrastive_loss=1.13, total=4221.06, n_correct=416.97, ppl=14.96, accuracy=9.878, wps=19576.6, ups=1.55, wpb=12596.1, bsz=492.8, num_updates=2700, lr=0.000108046, gnorm=0.816, clip=0, loss_scale=128, train_wall=64, gb_free=19.5, wall=1945
2023-07-28 02:28:21 | INFO | train_inner | epoch 002:   1327 / 1474 loss=4.708, trans_loss=5.221, nll_loss=3.898, w2v_ctc_loss=2.864, task_loss=1.888, contrastive_loss=0.838, total=4157.86, n_correct=415.45, ppl=14.91, accuracy=9.992, wps=19596.1, ups=1.58, wpb=12425.5, bsz=460.7, num_updates=2800, lr=0.000112044, gnorm=0.778, clip=0, loss_scale=128, train_wall=63, gb_free=19.5, wall=2008
2023-07-28 02:29:26 | INFO | train_inner | epoch 002:   1427 / 1474 loss=4.671, trans_loss=5.227, nll_loss=3.905, w2v_ctc_loss=2.823, task_loss=2.12, contrastive_loss=0.927, total=4054.34, n_correct=399.79, ppl=14.98, accuracy=9.861, wps=18579, ups=1.53, wpb=12107, bsz=438.8, num_updates=2900, lr=0.000116042, gnorm=0.73, clip=0, loss_scale=128, train_wall=65, gb_free=19.4, wall=2073
2023-07-28 02:29:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 02:30:36 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.193 | trans_loss 10.254 | nll_loss 9.072 | w2v_ctc_loss 3.615 | task_loss 11.319 | contrastive_loss 0.99 | total 4003.4 | n_correct 500 | ppl 538.13 | accuracy 12.489 | uer 51.934 | wer 50.721 | raw_wer 50.721 | bleu 0.12 | wps 1145.4 | wpb 4003.4 | bsz 141.8 | num_updates 2947 | best_bleu 0.12
2023-07-28 02:30:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2947 updates
2023-07-28 02:30:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 02:30:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 02:30:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt (epoch 2 @ 2947 updates, score 0.12) (writing took 19.671913331374526 seconds)
2023-07-28 02:30:55 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-07-28 02:30:55 | INFO | train | epoch 002 | loss 5.186 | trans_loss 5.277 | nll_loss 3.961 | w2v_ctc_loss 3.29 | task_loss 1.938 | contrastive_loss 1.215 | total 4138.65 | n_correct 376.775 | ppl 15.58 | accuracy 9.104 | wps 16965.4 | ups 1.37 | wpb 12355.8 | bsz 458.5 | num_updates 2947 | lr 0.000117921 | gnorm 1.126 | clip 0 | loss_scale 128 | train_wall 937 | gb_free 19.3 | wall 2162
2023-07-28 02:30:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 02:30:56 | INFO | fairseq.trainer | begin training epoch 3
2023-07-28 02:30:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 02:31:39 | INFO | train_inner | epoch 003:     53 / 1474 loss=4.597, trans_loss=5.2, nll_loss=3.871, w2v_ctc_loss=2.762, task_loss=1.987, contrastive_loss=0.827, total=4071.2, n_correct=416.48, ppl=14.63, accuracy=10.23, wps=9144.4, ups=0.75, wpb=12154.1, bsz=442.6, num_updates=3000, lr=0.00012004, gnorm=0.721, clip=0, loss_scale=128, train_wall=63, gb_free=19.1, wall=2206
2023-07-28 02:31:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-28 02:31:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-28 02:31:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-28 02:31:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-28 02:31:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-07-28 02:33:15 | INFO | train_inner | epoch 003:    158 / 1474 loss=3.809, trans_loss=4.369, nll_loss=2.783, w2v_ctc_loss=2.443, task_loss=1.354, contrastive_loss=0.777, total=4144.18, n_correct=1152.59, ppl=6.88, accuracy=27.812, wps=12931.1, ups=1.04, wpb=12374.6, bsz=458.6, num_updates=3100, lr=0.000124038, gnorm=2.118, clip=1, loss_scale=4, train_wall=95, gb_free=16.6, wall=2302
2023-07-28 02:34:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-07-28 02:34:50 | INFO | train_inner | epoch 003:    259 / 1474 loss=3.426, trans_loss=4.141, nll_loss=2.487, w2v_ctc_loss=2.229, task_loss=1.362, contrastive_loss=0.651, total=4163.45, n_correct=1423.44, ppl=5.61, accuracy=34.189, wps=13027.8, ups=1.05, wpb=12439.6, bsz=469.2, num_updates=3200, lr=0.000128036, gnorm=1.754, clip=0, loss_scale=2, train_wall=95, gb_free=17.7, wall=2397
2023-07-28 02:36:23 | INFO | train_inner | epoch 003:    359 / 1474 loss=3.302, trans_loss=4.09, nll_loss=2.416, w2v_ctc_loss=2.124, task_loss=1.369, contrastive_loss=0.679, total=4154.07, n_correct=1501.24, ppl=5.34, accuracy=36.139, wps=13389.9, ups=1.08, wpb=12396.6, bsz=464.9, num_updates=3300, lr=0.000132034, gnorm=1.512, clip=0, loss_scale=2, train_wall=92, gb_free=15.7, wall=2490
2023-07-28 02:37:56 | INFO | train_inner | epoch 003:    459 / 1474 loss=3.207, trans_loss=4.051, nll_loss=2.365, w2v_ctc_loss=2.065, task_loss=1.344, contrastive_loss=0.537, total=4212.17, n_correct=1586.04, ppl=5.15, accuracy=37.654, wps=13463.1, ups=1.07, wpb=12572.6, bsz=473.8, num_updates=3400, lr=0.000136032, gnorm=1.593, clip=0, loss_scale=2, train_wall=93, gb_free=15.7, wall=2583
2023-07-28 02:39:30 | INFO | train_inner | epoch 003:    559 / 1474 loss=3.097, trans_loss=4.019, nll_loss=2.325, w2v_ctc_loss=1.977, task_loss=1.47, contrastive_loss=0.503, total=4081.04, n_correct=1583.18, ppl=5.01, accuracy=38.794, wps=13029.1, ups=1.07, wpb=12190.8, bsz=440.1, num_updates=3500, lr=0.00014003, gnorm=1.287, clip=0, loss_scale=2, train_wall=93, gb_free=16.4, wall=2677
2023-07-28 02:41:05 | INFO | train_inner | epoch 003:    659 / 1474 loss=3.028, trans_loss=3.983, nll_loss=2.273, w2v_ctc_loss=1.892, task_loss=1.308, contrastive_loss=0.603, total=4231.09, n_correct=1707.18, ppl=4.83, accuracy=40.348, wps=13302.8, ups=1.05, wpb=12615.6, bsz=484.4, num_updates=3600, lr=0.000144028, gnorm=1.104, clip=0, loss_scale=2, train_wall=94, gb_free=15.9, wall=2772
2023-07-28 02:42:37 | INFO | train_inner | epoch 003:    759 / 1474 loss=2.951, trans_loss=3.953, nll_loss=2.239, w2v_ctc_loss=1.861, task_loss=1.325, contrastive_loss=0.365, total=4160.74, n_correct=1718.95, ppl=4.72, accuracy=41.314, wps=13457.9, ups=1.08, wpb=12428.5, bsz=469.2, num_updates=3700, lr=0.000148026, gnorm=1.156, clip=0, loss_scale=2, train_wall=92, gb_free=16.8, wall=2864
2023-07-28 02:44:10 | INFO | train_inner | epoch 003:    859 / 1474 loss=2.895, trans_loss=3.939, nll_loss=2.217, w2v_ctc_loss=1.815, task_loss=1.4, contrastive_loss=0.334, total=4160.47, n_correct=1748.43, ppl=4.65, accuracy=42.025, wps=13375.1, ups=1.08, wpb=12423.6, bsz=455.4, num_updates=3800, lr=0.000152024, gnorm=1.106, clip=0, loss_scale=2, train_wall=92, gb_free=16.3, wall=2957
2023-07-28 02:45:44 | INFO | train_inner | epoch 003:    959 / 1474 loss=2.851, trans_loss=3.915, nll_loss=2.185, w2v_ctc_loss=1.775, task_loss=1.344, contrastive_loss=0.361, total=4162.26, n_correct=1800.29, ppl=4.55, accuracy=43.253, wps=13243.6, ups=1.07, wpb=12416.1, bsz=467.9, num_updates=3900, lr=0.000156022, gnorm=1.022, clip=0, loss_scale=2, train_wall=93, gb_free=17.8, wall=3051
2023-07-28 02:47:16 | INFO | train_inner | epoch 003:   1059 / 1474 loss=2.82, trans_loss=3.894, nll_loss=2.16, w2v_ctc_loss=1.763, task_loss=1.464, contrastive_loss=0.317, total=4062.67, n_correct=1777.2, ppl=4.47, accuracy=43.745, wps=13148.2, ups=1.08, wpb=12131.7, bsz=443.2, num_updates=4000, lr=0.00016002, gnorm=1.051, clip=0, loss_scale=2, train_wall=92, gb_free=15.6, wall=3143
2023-07-28 02:47:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 02:47:39 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.061 | trans_loss 6.442 | nll_loss 3.992 | w2v_ctc_loss 2.134 | task_loss 6.418 | contrastive_loss 0.428 | total 4003.4 | n_correct 1961.8 | ppl 15.92 | accuracy 49.003 | uer 30.672 | wer 31.095 | raw_wer 31.095 | bleu 11 | wps 2222.9 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 11
2023-07-28 02:47:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-07-28 02:47:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_3_4000.pt
2023-07-28 02:47:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_3_4000.pt
2023-07-28 02:48:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 11.0) (writing took 38.843254413455725 seconds)
2023-07-28 02:49:49 | INFO | train_inner | epoch 003:   1159 / 1474 loss=2.769, trans_loss=3.886, nll_loss=2.147, w2v_ctc_loss=1.713, task_loss=1.489, contrastive_loss=0.292, total=4046.76, n_correct=1788.21, ppl=4.43, accuracy=44.189, wps=7878.8, ups=0.65, wpb=12078.6, bsz=433.9, num_updates=4100, lr=0.000164018, gnorm=0.962, clip=0, loss_scale=2, train_wall=91, gb_free=16.2, wall=3296
2023-07-28 02:51:23 | INFO | train_inner | epoch 003:   1259 / 1474 loss=2.725, trans_loss=3.863, nll_loss=2.119, w2v_ctc_loss=1.68, task_loss=1.466, contrastive_loss=0.274, total=4064.26, n_correct=1833.35, ppl=4.34, accuracy=45.109, wps=13003.6, ups=1.07, wpb=12137.6, bsz=434, num_updates=4200, lr=0.000168016, gnorm=0.997, clip=0, loss_scale=2, train_wall=93, gb_free=16.6, wall=3390
2023-07-28 02:52:56 | INFO | train_inner | epoch 003:   1359 / 1474 loss=2.708, trans_loss=3.847, nll_loss=2.098, w2v_ctc_loss=1.641, task_loss=1.39, contrastive_loss=0.384, total=4137.36, n_correct=1894.43, ppl=4.28, accuracy=45.788, wps=13214.6, ups=1.07, wpb=12352.2, bsz=461.5, num_updates=4300, lr=0.000172014, gnorm=0.938, clip=0, loss_scale=2, train_wall=93, gb_free=16.2, wall=3483
2023-07-28 02:54:29 | INFO | train_inner | epoch 003:   1459 / 1474 loss=2.682, trans_loss=3.836, nll_loss=2.085, w2v_ctc_loss=1.623, task_loss=1.323, contrastive_loss=0.367, total=4207.75, n_correct=1947.77, ppl=4.24, accuracy=46.29, wps=13528.7, ups=1.08, wpb=12567.9, bsz=476.7, num_updates=4400, lr=0.000176012, gnorm=0.958, clip=0, loss_scale=2, train_wall=92, gb_free=17.4, wall=3576
2023-07-28 02:54:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 02:55:05 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 4.889 | trans_loss 6.299 | nll_loss 3.811 | w2v_ctc_loss 1.892 | task_loss 6.298 | contrastive_loss 0.416 | total 4003.4 | n_correct 2045 | ppl 14.03 | accuracy 51.082 | uer 29.597 | wer 29.872 | raw_wer 29.872 | bleu 12.51 | wps 2292.8 | wpb 4003.4 | bsz 141.8 | num_updates 4415 | best_bleu 12.51
2023-07-28 02:55:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4415 updates
2023-07-28 02:55:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 02:55:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 02:55:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt (epoch 3 @ 4415 updates, score 12.51) (writing took 19.676054133102298 seconds)
2023-07-28 02:55:25 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-07-28 02:55:25 | INFO | train | epoch 003 | loss 3.073 | trans_loss 4.027 | nll_loss 2.334 | w2v_ctc_loss 1.928 | task_loss 1.406 | contrastive_loss 0.477 | total 4140.09 | n_correct 1632.4 | ppl 5.04 | accuracy 39.429 | wps 12345.9 | ups 1 | wpb 12360.2 | bsz 459.1 | num_updates 4415 | lr 0.000176612 | gnorm 1.231 | clip 0.1 | loss_scale 2 | train_wall 1347 | gb_free 16.4 | wall 3632
2023-07-28 02:55:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 02:55:25 | INFO | fairseq.trainer | begin training epoch 4
2023-07-28 02:55:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 02:56:53 | INFO | train_inner | epoch 004:     85 / 1474 loss=2.604, trans_loss=3.802, nll_loss=2.037, w2v_ctc_loss=1.577, task_loss=1.444, contrastive_loss=0.22, total=4095.18, n_correct=1932.48, ppl=4.1, accuracy=47.189, wps=8510.8, ups=0.7, wpb=12222.9, bsz=437.8, num_updates=4500, lr=0.00018001, gnorm=0.906, clip=0, loss_scale=2, train_wall=92, gb_free=12.5, wall=3720
2023-07-28 02:58:25 | INFO | train_inner | epoch 004:    185 / 1474 loss=2.586, trans_loss=3.783, nll_loss=2.014, w2v_ctc_loss=1.557, task_loss=1.318, contrastive_loss=0.247, total=4178.83, n_correct=2004.29, ppl=4.04, accuracy=47.963, wps=13560.3, ups=1.09, wpb=12476.1, bsz=469.5, num_updates=4600, lr=0.000184008, gnorm=0.92, clip=0, loss_scale=2, train_wall=91, gb_free=14.7, wall=3812
2023-07-28 02:59:58 | INFO | train_inner | epoch 004:    285 / 1474 loss=2.601, trans_loss=3.788, nll_loss=2.022, w2v_ctc_loss=1.556, task_loss=1.401, contrastive_loss=0.373, total=4142.3, n_correct=1979.15, ppl=4.06, accuracy=47.779, wps=13271.5, ups=1.07, wpb=12373.8, bsz=460.7, num_updates=4700, lr=0.000188006, gnorm=0.947, clip=0, loss_scale=2, train_wall=93, gb_free=13.2, wall=3905
2023-07-28 03:01:31 | INFO | train_inner | epoch 004:    385 / 1474 loss=2.565, trans_loss=3.788, nll_loss=2.019, w2v_ctc_loss=1.539, task_loss=1.44, contrastive_loss=0.216, total=4124.92, n_correct=1982.18, ppl=4.05, accuracy=48.054, wps=13215.8, ups=1.07, wpb=12307.7, bsz=444.2, num_updates=4800, lr=0.000192004, gnorm=0.952, clip=0, loss_scale=2, train_wall=93, gb_free=12.3, wall=3998
2023-07-28 03:03:05 | INFO | train_inner | epoch 004:    485 / 1474 loss=2.592, trans_loss=3.766, nll_loss=1.994, w2v_ctc_loss=1.508, task_loss=1.263, contrastive_loss=0.616, total=4216.09, n_correct=2059.61, ppl=3.98, accuracy=48.851, wps=13430.1, ups=1.07, wpb=12585.8, bsz=497.6, num_updates=4900, lr=0.000196002, gnorm=0.924, clip=0, loss_scale=2, train_wall=93, gb_free=16.8, wall=4092
2023-07-28 03:04:38 | INFO | train_inner | epoch 004:    585 / 1474 loss=2.544, trans_loss=3.758, nll_loss=1.984, w2v_ctc_loss=1.517, task_loss=1.294, contrastive_loss=0.289, total=4231.12, n_correct=2086.72, ppl=3.95, accuracy=49.318, wps=13577.5, ups=1.08, wpb=12629.4, bsz=490.1, num_updates=5000, lr=0.0002, gnorm=0.873, clip=0, loss_scale=2, train_wall=92, gb_free=16, wall=4185
mt_weight tensor(0.5000)
asr_weight tensor(0.5119, device='cuda:0')
2023-07-28 03:06:13 | INFO | train_inner | epoch 004:    685 / 1474 loss=2.517, trans_loss=3.763, nll_loss=1.984, w2v_ctc_loss=1.483, task_loss=1.437, contrastive_loss=0.33, total=4176.95, n_correct=2066.46, ppl=3.96, accuracy=49.473, wps=13122, ups=1.05, wpb=12451, bsz=455.2, num_updates=5100, lr=0.00019803, gnorm=0.608, clip=0, loss_scale=2, train_wall=94, gb_free=15, wall=4280
2023-07-28 03:07:46 | INFO | train_inner | epoch 004:    785 / 1474 loss=2.514, trans_loss=3.758, nll_loss=1.983, w2v_ctc_loss=1.509, task_loss=1.538, contrastive_loss=0.205, total=4016.91, n_correct=1990.08, ppl=3.95, accuracy=49.543, wps=12856, ups=1.07, wpb=11995.1, bsz=418.7, num_updates=5200, lr=0.000196116, gnorm=0.668, clip=0, loss_scale=4, train_wall=93, gb_free=16.1, wall=4373
2023-07-28 03:09:19 | INFO | train_inner | epoch 004:    885 / 1474 loss=2.522, trans_loss=3.742, nll_loss=1.964, w2v_ctc_loss=1.49, task_loss=1.395, contrastive_loss=0.383, total=4183.4, n_correct=2087.62, ppl=3.9, accuracy=49.902, wps=13464.9, ups=1.08, wpb=12493.2, bsz=465.4, num_updates=5300, lr=0.000194257, gnorm=0.62, clip=0, loss_scale=4, train_wall=92, gb_free=15.4, wall=4466
2023-07-28 03:10:52 | INFO | train_inner | epoch 004:    985 / 1474 loss=2.493, trans_loss=3.736, nll_loss=1.956, w2v_ctc_loss=1.483, task_loss=1.414, contrastive_loss=0.255, total=4128.78, n_correct=2075.42, ppl=3.88, accuracy=50.267, wps=13203.4, ups=1.07, wpb=12332, bsz=456.8, num_updates=5400, lr=0.00019245, gnorm=0.675, clip=0, loss_scale=4, train_wall=93, gb_free=15.9, wall=4559
2023-07-28 03:12:25 | INFO | train_inner | epoch 004:   1085 / 1474 loss=2.488, trans_loss=3.742, nll_loss=1.963, w2v_ctc_loss=1.482, task_loss=1.489, contrastive_loss=0.23, total=4080.2, n_correct=2051.12, ppl=3.9, accuracy=50.27, wps=13038.8, ups=1.07, wpb=12179.1, bsz=437.7, num_updates=5500, lr=0.000190693, gnorm=0.604, clip=0, loss_scale=4, train_wall=93, gb_free=16.2, wall=4653
2023-07-28 03:13:59 | INFO | train_inner | epoch 004:   1185 / 1474 loss=2.492, trans_loss=3.73, nll_loss=1.951, w2v_ctc_loss=1.47, task_loss=1.302, contrastive_loss=0.343, total=4163.45, n_correct=2107.42, ppl=3.87, accuracy=50.617, wps=13299.6, ups=1.07, wpb=12436, bsz=485.6, num_updates=5600, lr=0.000188982, gnorm=0.648, clip=0, loss_scale=4, train_wall=93, gb_free=15.2, wall=4746
2023-07-28 03:15:31 | INFO | train_inner | epoch 004:   1285 / 1474 loss=2.475, trans_loss=3.723, nll_loss=1.941, w2v_ctc_loss=1.466, task_loss=1.332, contrastive_loss=0.302, total=4152.41, n_correct=2114.24, ppl=3.84, accuracy=50.916, wps=13459.8, ups=1.09, wpb=12401.3, bsz=471.4, num_updates=5700, lr=0.000187317, gnorm=0.678, clip=0, loss_scale=4, train_wall=92, gb_free=12.7, wall=4838
2023-07-28 03:17:03 | INFO | train_inner | epoch 004:   1385 / 1474 loss=2.439, trans_loss=3.72, nll_loss=1.936, w2v_ctc_loss=1.451, task_loss=1.427, contrastive_loss=0.18, total=4103.57, n_correct=2096.82, ppl=3.83, accuracy=51.097, wps=13285.8, ups=1.08, wpb=12255.2, bsz=437.9, num_updates=5800, lr=0.000185695, gnorm=0.579, clip=0, loss_scale=4, train_wall=92, gb_free=16.7, wall=4930
2023-07-28 03:18:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.5119, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.5119, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.5119, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.5119, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.5119, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.5119, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.5119, device='cuda:5')
2023-07-28 03:18:50 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.574 | trans_loss 5.971 | nll_loss 3.366 | w2v_ctc_loss 1.632 | task_loss 6.638 | contrastive_loss 0.33 | total 4003.4 | n_correct 2228.8 | ppl 10.31 | accuracy 55.673 | uer 24.776 | wer 26.192 | raw_wer 26.192 | bleu 16.01 | wps 2062.3 | wpb 4003.4 | bsz 141.8 | num_updates 5889 | best_bleu 16.01
2023-07-28 03:18:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5889 updates
2023-07-28 03:18:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 03:19:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 03:19:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt (epoch 4 @ 5889 updates, score 16.01) (writing took 19.90185033902526 seconds)
2023-07-28 03:19:10 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-07-28 03:19:10 | INFO | train | epoch 004 | loss 2.523 | trans_loss 3.754 | nll_loss 1.978 | w2v_ctc_loss 1.5 | task_loss 1.392 | contrastive_loss 0.298 | total 4138.65 | n_correct 2049.48 | ppl 3.94 | accuracy 49.52 | wps 12785.9 | ups 1.03 | wpb 12355.8 | bsz 458.5 | num_updates 5889 | lr 0.000184287 | gnorm 0.745 | clip 0 | loss_scale 4 | train_wall 1363 | gb_free 14.8 | wall 5057
2023-07-28 03:19:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 03:19:10 | INFO | fairseq.trainer | begin training epoch 5
2023-07-28 03:19:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 03:19:28 | INFO | train_inner | epoch 005:     11 / 1474 loss=2.411, trans_loss=3.706, nll_loss=1.918, w2v_ctc_loss=1.415, task_loss=1.457, contrastive_loss=0.197, total=4031.51, n_correct=2079.46, ppl=3.78, accuracy=51.58, wps=8311.5, ups=0.69, wpb=12037.5, bsz=436.7, num_updates=5900, lr=0.000184115, gnorm=0.578, clip=0, loss_scale=4, train_wall=91, gb_free=14.2, wall=5075
2023-07-28 03:21:01 | INFO | train_inner | epoch 005:    111 / 1474 loss=2.345, trans_loss=3.65, nll_loss=1.845, w2v_ctc_loss=1.342, task_loss=1.244, contrastive_loss=0.223, total=4256.63, n_correct=2268.17, ppl=3.59, accuracy=53.286, wps=13662.9, ups=1.07, wpb=12710, bsz=500.1, num_updates=6000, lr=0.000182574, gnorm=0.537, clip=0, loss_scale=4, train_wall=93, gb_free=16.1, wall=5168
2023-07-28 03:21:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 03:21:25 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.554 | trans_loss 5.955 | nll_loss 3.34 | w2v_ctc_loss 1.605 | task_loss 6.64 | contrastive_loss 0.328 | total 4003.4 | n_correct 2241 | ppl 10.13 | accuracy 55.977 | uer 24.121 | wer 25.659 | raw_wer 25.659 | bleu 16.04 | wps 2123.9 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 16.04
2023-07-28 03:21:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-07-28 03:21:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_5_6000.pt
2023-07-28 03:21:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_5_6000.pt
2023-07-28 03:21:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 16.04) (writing took 20.953360754996538 seconds)
2023-07-28 03:23:19 | INFO | train_inner | epoch 005:    211 / 1474 loss=2.375, trans_loss=3.66, nll_loss=1.857, w2v_ctc_loss=1.355, task_loss=1.298, contrastive_loss=0.414, total=4186.83, n_correct=2225.31, ppl=3.62, accuracy=53.15, wps=9071.2, ups=0.73, wpb=12492.2, bsz=485.3, num_updates=6100, lr=0.000181071, gnorm=0.532, clip=0, loss_scale=4, train_wall=93, gb_free=16.1, wall=5306
2023-07-28 03:24:51 | INFO | train_inner | epoch 005:    311 / 1474 loss=2.369, trans_loss=3.656, nll_loss=1.856, w2v_ctc_loss=1.376, task_loss=1.423, contrastive_loss=0.274, total=4094.07, n_correct=2165.82, ppl=3.62, accuracy=52.901, wps=13255.2, ups=1.08, wpb=12241.2, bsz=446, num_updates=6200, lr=0.000179605, gnorm=0.56, clip=0, loss_scale=4, train_wall=92, gb_free=16.1, wall=5398
2023-07-28 03:26:25 | INFO | train_inner | epoch 005:    411 / 1474 loss=2.36, trans_loss=3.65, nll_loss=1.848, w2v_ctc_loss=1.341, task_loss=1.366, contrastive_loss=0.365, total=4140.39, n_correct=2207.51, ppl=3.6, accuracy=53.316, wps=13237.4, ups=1.07, wpb=12372.8, bsz=467.9, num_updates=6300, lr=0.000178174, gnorm=0.558, clip=0, loss_scale=4, train_wall=93, gb_free=16, wall=5492
2023-07-28 03:27:58 | INFO | train_inner | epoch 005:    511 / 1474 loss=2.328, trans_loss=3.657, nll_loss=1.855, w2v_ctc_loss=1.347, task_loss=1.555, contrastive_loss=0.15, total=4026.21, n_correct=2139.74, ppl=3.62, accuracy=53.145, wps=12944.8, ups=1.08, wpb=12028.8, bsz=418.1, num_updates=6400, lr=0.000176777, gnorm=0.544, clip=0, loss_scale=4, train_wall=92, gb_free=17, wall=5585
2023-07-28 03:29:32 | INFO | train_inner | epoch 005:    611 / 1474 loss=2.344, trans_loss=3.663, nll_loss=1.86, w2v_ctc_loss=1.333, task_loss=1.441, contrastive_loss=0.322, total=4109.94, n_correct=2187.65, ppl=3.63, accuracy=53.228, wps=13064.7, ups=1.07, wpb=12260.2, bsz=449.8, num_updates=6500, lr=0.000175412, gnorm=0.547, clip=0, loss_scale=4, train_wall=93, gb_free=15.3, wall=5679
2023-07-28 03:31:04 | INFO | train_inner | epoch 005:    711 / 1474 loss=2.348, trans_loss=3.658, nll_loss=1.856, w2v_ctc_loss=1.339, task_loss=1.31, contrastive_loss=0.303, total=4176.83, n_correct=2233.32, ppl=3.62, accuracy=53.469, wps=13421.8, ups=1.08, wpb=12467.5, bsz=483.6, num_updates=6600, lr=0.000174078, gnorm=0.578, clip=0, loss_scale=4, train_wall=92, gb_free=17, wall=5772
2023-07-28 03:32:39 | INFO | train_inner | epoch 005:    811 / 1474 loss=2.328, trans_loss=3.657, nll_loss=1.854, w2v_ctc_loss=1.332, task_loss=1.441, contrastive_loss=0.227, total=4127.9, n_correct=2209.26, ppl=3.62, accuracy=53.52, wps=13066.1, ups=1.06, wpb=12321.2, bsz=447.5, num_updates=6700, lr=0.000172774, gnorm=0.569, clip=0, loss_scale=4, train_wall=94, gb_free=15.7, wall=5866
2023-07-28 03:34:12 | INFO | train_inner | epoch 005:    911 / 1474 loss=2.305, trans_loss=3.647, nll_loss=1.843, w2v_ctc_loss=1.319, task_loss=1.434, contrastive_loss=0.188, total=4101.19, n_correct=2209.1, ppl=3.59, accuracy=53.865, wps=13160.5, ups=1.07, wpb=12245.9, bsz=447.9, num_updates=6800, lr=0.000171499, gnorm=0.543, clip=0, loss_scale=4, train_wall=92, gb_free=17.2, wall=5959
2023-07-28 03:35:44 | INFO | train_inner | epoch 005:   1011 / 1474 loss=2.313, trans_loss=3.647, nll_loss=1.842, w2v_ctc_loss=1.317, task_loss=1.383, contrastive_loss=0.269, total=4164.27, n_correct=2245.45, ppl=3.59, accuracy=53.922, wps=13426, ups=1.08, wpb=12430.2, bsz=462, num_updates=6900, lr=0.000170251, gnorm=0.533, clip=0, loss_scale=4, train_wall=92, gb_free=14.9, wall=6051
2023-07-28 03:37:19 | INFO | train_inner | epoch 005:   1111 / 1474 loss=2.327, trans_loss=3.65, nll_loss=1.846, w2v_ctc_loss=1.326, task_loss=1.388, contrastive_loss=0.274, total=4168.94, n_correct=2248.1, ppl=3.59, accuracy=53.925, wps=13194.8, ups=1.06, wpb=12436.1, bsz=464.1, num_updates=7000, lr=0.000169031, gnorm=0.543, clip=0, loss_scale=4, train_wall=94, gb_free=16.6, wall=6146
2023-07-28 03:38:52 | INFO | train_inner | epoch 005:   1211 / 1474 loss=2.287, trans_loss=3.645, nll_loss=1.839, w2v_ctc_loss=1.299, task_loss=1.415, contrastive_loss=0.176, total=4171.16, n_correct=2259.27, ppl=3.58, accuracy=54.164, wps=13365.5, ups=1.07, wpb=12443.2, bsz=456.3, num_updates=7100, lr=0.000167836, gnorm=0.535, clip=0, loss_scale=4, train_wall=93, gb_free=15.8, wall=6239
2023-07-28 03:40:25 | INFO | train_inner | epoch 005:   1311 / 1474 loss=2.273, trans_loss=3.642, nll_loss=1.837, w2v_ctc_loss=1.29, task_loss=1.421, contrastive_loss=0.139, total=4126.97, n_correct=2240.18, ppl=3.57, accuracy=54.281, wps=13186.6, ups=1.07, wpb=12317.9, bsz=443.4, num_updates=7200, lr=0.000166667, gnorm=0.532, clip=0, loss_scale=4, train_wall=93, gb_free=15.4, wall=6332
2023-07-28 03:41:58 | INFO | train_inner | epoch 005:   1411 / 1474 loss=2.281, trans_loss=3.642, nll_loss=1.839, w2v_ctc_loss=1.285, task_loss=1.401, contrastive_loss=0.207, total=4138.54, n_correct=2247.54, ppl=3.58, accuracy=54.308, wps=13328.4, ups=1.08, wpb=12359.3, bsz=459, num_updates=7300, lr=0.000165521, gnorm=0.528, clip=0, loss_scale=8, train_wall=92, gb_free=16.7, wall=6425
2023-07-28 03:42:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 03:43:19 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.44 | trans_loss 5.862 | nll_loss 3.23 | w2v_ctc_loss 1.428 | task_loss 6.695 | contrastive_loss 0.338 | total 4003.4 | n_correct 2291.8 | ppl 9.38 | accuracy 57.246 | uer 22.196 | wer 23.84 | raw_wer 23.84 | bleu 17.09 | wps 2014.6 | wpb 4003.4 | bsz 141.8 | num_updates 7363 | best_bleu 17.09
2023-07-28 03:43:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7363 updates
2023-07-28 03:43:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 03:43:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 03:43:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt (epoch 5 @ 7363 updates, score 17.09) (writing took 21.416288720443845 seconds)
2023-07-28 03:43:41 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-07-28 03:43:41 | INFO | train | epoch 005 | loss 2.326 | trans_loss 3.651 | nll_loss 1.848 | w2v_ctc_loss 1.328 | task_loss 1.393 | contrastive_loss 0.252 | total 4138.65 | n_correct 2219.6 | ppl 3.6 | accuracy 53.631 | wps 12378.3 | ups 1 | wpb 12355.8 | bsz 458.5 | num_updates 7363 | lr 0.000164812 | gnorm 0.546 | clip 0 | loss_scale 8 | train_wall 1365 | gb_free 16.2 | wall 6528
2023-07-28 03:43:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 03:43:41 | INFO | fairseq.trainer | begin training epoch 6
2023-07-28 03:43:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 03:44:25 | INFO | train_inner | epoch 006:     37 / 1474 loss=2.265, trans_loss=3.618, nll_loss=1.806, w2v_ctc_loss=1.28, task_loss=1.435, contrastive_loss=0.203, total=4113.87, n_correct=2256.03, ppl=3.5, accuracy=54.84, wps=8358.4, ups=0.68, wpb=12276.7, bsz=447.4, num_updates=7400, lr=0.000164399, gnorm=0.534, clip=0, loss_scale=8, train_wall=93, gb_free=17.8, wall=6572
2023-07-28 03:45:58 | INFO | train_inner | epoch 006:    137 / 1474 loss=2.218, trans_loss=3.584, nll_loss=1.762, w2v_ctc_loss=1.225, task_loss=1.38, contrastive_loss=0.246, total=4161.2, n_correct=2315.88, ppl=3.39, accuracy=55.654, wps=13341.2, ups=1.07, wpb=12428.5, bsz=458.1, num_updates=7500, lr=0.000163299, gnorm=0.516, clip=0, loss_scale=8, train_wall=93, gb_free=16.8, wall=6665
2023-07-28 03:47:31 | INFO | train_inner | epoch 006:    237 / 1474 loss=2.233, trans_loss=3.596, nll_loss=1.778, w2v_ctc_loss=1.261, task_loss=1.498, contrastive_loss=0.155, total=4110.12, n_correct=2271.92, ppl=3.43, accuracy=55.276, wps=13192.6, ups=1.07, wpb=12279.2, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.52, clip=0, loss_scale=8, train_wall=92, gb_free=17.1, wall=6758
2023-07-28 03:49:05 | INFO | train_inner | epoch 006:    337 / 1474 loss=2.239, trans_loss=3.584, nll_loss=1.763, w2v_ctc_loss=1.207, task_loss=1.309, contrastive_loss=0.46, total=4170.52, n_correct=2329.76, ppl=3.39, accuracy=55.863, wps=13200.4, ups=1.06, wpb=12453.1, bsz=488.4, num_updates=7700, lr=0.000161165, gnorm=0.525, clip=0, loss_scale=8, train_wall=94, gb_free=15.6, wall=6852
2023-07-28 03:50:38 | INFO | train_inner | epoch 006:    437 / 1474 loss=2.202, trans_loss=3.587, nll_loss=1.767, w2v_ctc_loss=1.219, task_loss=1.339, contrastive_loss=0.171, total=4154.89, n_correct=2323.14, ppl=3.4, accuracy=55.913, wps=13342.3, ups=1.08, wpb=12405.6, bsz=470.4, num_updates=7800, lr=0.000160128, gnorm=0.527, clip=0, loss_scale=8, train_wall=92, gb_free=16.4, wall=6945
2023-07-28 03:52:11 | INFO | train_inner | epoch 006:    537 / 1474 loss=2.207, trans_loss=3.594, nll_loss=1.774, w2v_ctc_loss=1.23, task_loss=1.386, contrastive_loss=0.155, total=4174.46, n_correct=2331.3, ppl=3.42, accuracy=55.847, wps=13385.4, ups=1.07, wpb=12460.1, bsz=458.3, num_updates=7900, lr=0.000159111, gnorm=0.52, clip=0, loss_scale=8, train_wall=92, gb_free=17.2, wall=7039
2023-07-28 03:53:44 | INFO | train_inner | epoch 006:    637 / 1474 loss=2.206, trans_loss=3.595, nll_loss=1.777, w2v_ctc_loss=1.214, task_loss=1.327, contrastive_loss=0.213, total=4145.19, n_correct=2315.25, ppl=3.43, accuracy=55.854, wps=13328.7, ups=1.08, wpb=12372.7, bsz=470.9, num_updates=8000, lr=0.000158114, gnorm=0.527, clip=0, loss_scale=8, train_wall=92, gb_free=15.8, wall=7131
2023-07-28 03:53:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 03:54:07 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.404 | trans_loss 5.804 | nll_loss 3.148 | w2v_ctc_loss 1.455 | task_loss 6.758 | contrastive_loss 0.311 | total 4003.4 | n_correct 2325.4 | ppl 8.87 | accuracy 58.086 | uer 21.434 | wer 23.288 | raw_wer 23.288 | bleu 17.72 | wps 2220.9 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 17.72
2023-07-28 03:54:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-07-28 03:54:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_6_8000.pt
2023-07-28 03:54:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_6_8000.pt
2023-07-28 03:54:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 17.72) (writing took 20.19343522004783 seconds)
2023-07-28 03:56:02 | INFO | train_inner | epoch 006:    737 / 1474 loss=2.213, trans_loss=3.599, nll_loss=1.782, w2v_ctc_loss=1.233, task_loss=1.422, contrastive_loss=0.168, total=4151.01, n_correct=2315.32, ppl=3.44, accuracy=55.777, wps=9027.5, ups=0.73, wpb=12393.7, bsz=454.2, num_updates=8100, lr=0.000157135, gnorm=0.525, clip=0, loss_scale=8, train_wall=94, gb_free=12.9, wall=7269
2023-07-28 03:57:35 | INFO | train_inner | epoch 006:    837 / 1474 loss=2.205, trans_loss=3.605, nll_loss=1.79, w2v_ctc_loss=1.224, task_loss=1.472, contrastive_loss=0.146, total=4108.83, n_correct=2282.52, ppl=3.46, accuracy=55.552, wps=13148.7, ups=1.07, wpb=12267.1, bsz=439.4, num_updates=8200, lr=0.000156174, gnorm=0.523, clip=0, loss_scale=8, train_wall=93, gb_free=17.1, wall=7362
2023-07-28 03:59:08 | INFO | train_inner | epoch 006:    937 / 1474 loss=2.223, trans_loss=3.605, nll_loss=1.79, w2v_ctc_loss=1.228, task_loss=1.466, contrastive_loss=0.245, total=4076.46, n_correct=2268.26, ppl=3.46, accuracy=55.643, wps=13020.8, ups=1.07, wpb=12166, bsz=443, num_updates=8300, lr=0.00015523, gnorm=0.531, clip=0, loss_scale=8, train_wall=93, gb_free=12.5, wall=7455
2023-07-28 04:00:41 | INFO | train_inner | epoch 006:   1037 / 1474 loss=2.209, trans_loss=3.59, nll_loss=1.772, w2v_ctc_loss=1.203, task_loss=1.309, contrastive_loss=0.319, total=4175.9, n_correct=2340.22, ppl=3.42, accuracy=56.041, wps=13431.9, ups=1.08, wpb=12465, bsz=480.4, num_updates=8400, lr=0.000154303, gnorm=0.532, clip=0, loss_scale=8, train_wall=92, gb_free=14.1, wall=7548
2023-07-28 04:02:14 | INFO | train_inner | epoch 006:   1137 / 1474 loss=2.201, trans_loss=3.596, nll_loss=1.778, w2v_ctc_loss=1.221, task_loss=1.534, contrastive_loss=0.153, total=4077.2, n_correct=2277.74, ppl=3.43, accuracy=55.865, wps=13139.9, ups=1.08, wpb=12172.7, bsz=430.6, num_updates=8500, lr=0.000153393, gnorm=0.537, clip=0, loss_scale=8, train_wall=92, gb_free=16.2, wall=7641
2023-07-28 04:03:48 | INFO | train_inner | epoch 006:   1237 / 1474 loss=2.228, trans_loss=3.588, nll_loss=1.772, w2v_ctc_loss=1.203, task_loss=1.369, contrastive_loss=0.466, total=4133.46, n_correct=2315.07, ppl=3.41, accuracy=56.008, wps=13123.6, ups=1.06, wpb=12346.4, bsz=470.3, num_updates=8600, lr=0.000152499, gnorm=0.526, clip=0, loss_scale=8, train_wall=93, gb_free=12.2, wall=7735
2023-07-28 04:05:20 | INFO | train_inner | epoch 006:   1337 / 1474 loss=2.178, trans_loss=3.594, nll_loss=1.775, w2v_ctc_loss=1.199, task_loss=1.385, contrastive_loss=0.136, total=4127.77, n_correct=2320.26, ppl=3.42, accuracy=56.211, wps=13358.3, ups=1.08, wpb=12312.7, bsz=454.1, num_updates=8700, lr=0.00015162, gnorm=0.513, clip=0, loss_scale=8, train_wall=92, gb_free=17, wall=7827
2023-07-28 04:06:54 | INFO | train_inner | epoch 006:   1437 / 1474 loss=2.177, trans_loss=3.586, nll_loss=1.767, w2v_ctc_loss=1.2, task_loss=1.399, contrastive_loss=0.142, total=4190.32, n_correct=2364.7, ppl=3.4, accuracy=56.432, wps=13325.2, ups=1.07, wpb=12507.6, bsz=460.5, num_updates=8800, lr=0.000150756, gnorm=0.511, clip=0, loss_scale=8, train_wall=93, gb_free=16.8, wall=7921
2023-07-28 04:07:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 04:07:52 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.355 | trans_loss 5.764 | nll_loss 3.1 | w2v_ctc_loss 1.392 | task_loss 6.767 | contrastive_loss 0.294 | total 4003.4 | n_correct 2346.8 | ppl 8.58 | accuracy 58.62 | uer 20.221 | wer 21.975 | raw_wer 21.975 | bleu 17.83 | wps 2149.4 | wpb 4003.4 | bsz 141.8 | num_updates 8837 | best_bleu 17.83
2023-07-28 04:07:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8837 updates
2023-07-28 04:07:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 04:08:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 04:08:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt (epoch 6 @ 8837 updates, score 17.83) (writing took 19.56287182867527 seconds)
2023-07-28 04:08:11 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-07-28 04:08:11 | INFO | train | epoch 006 | loss 2.209 | trans_loss 3.593 | nll_loss 1.774 | w2v_ctc_loss 1.219 | task_loss 1.395 | contrastive_loss 0.226 | total 4138.65 | n_correct 2312.23 | ppl 3.42 | accuracy 55.869 | wps 12385.1 | ups 1 | wpb 12355.8 | bsz 458.5 | num_updates 8837 | lr 0.00015044 | gnorm 0.524 | clip 0 | loss_scale 8 | train_wall 1366 | gb_free 15.1 | wall 7999
2023-07-28 04:08:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 04:08:12 | INFO | fairseq.trainer | begin training epoch 7
2023-07-28 04:08:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 04:09:20 | INFO | train_inner | epoch 007:     63 / 1474 loss=2.145, trans_loss=3.563, nll_loss=1.737, w2v_ctc_loss=1.167, task_loss=1.36, contrastive_loss=0.16, total=4110.43, n_correct=2340.28, ppl=3.33, accuracy=56.935, wps=8421.1, ups=0.69, wpb=12272.9, bsz=462.8, num_updates=8900, lr=0.000149906, gnorm=0.517, clip=0, loss_scale=8, train_wall=93, gb_free=17.3, wall=8067
2023-07-28 04:10:53 | INFO | train_inner | epoch 007:    163 / 1474 loss=2.144, trans_loss=3.552, nll_loss=1.721, w2v_ctc_loss=1.155, task_loss=1.418, contrastive_loss=0.231, total=4109.53, n_correct=2348.04, ppl=3.3, accuracy=57.136, wps=13209.5, ups=1.08, wpb=12269.6, bsz=454.1, num_updates=9000, lr=0.000149071, gnorm=0.53, clip=0, loss_scale=8, train_wall=92, gb_free=13.5, wall=8160
2023-07-28 04:12:26 | INFO | train_inner | epoch 007:    263 / 1474 loss=2.129, trans_loss=3.547, nll_loss=1.714, w2v_ctc_loss=1.159, task_loss=1.397, contrastive_loss=0.138, total=4133.29, n_correct=2374.3, ppl=3.28, accuracy=57.443, wps=13247.2, ups=1.07, wpb=12335.8, bsz=455.5, num_updates=9100, lr=0.00014825, gnorm=0.52, clip=0, loss_scale=8, train_wall=93, gb_free=15.2, wall=8253
2023-07-28 04:14:00 | INFO | train_inner | epoch 007:    363 / 1474 loss=2.162, trans_loss=3.556, nll_loss=1.726, w2v_ctc_loss=1.149, task_loss=1.358, contrastive_loss=0.399, total=4194.76, n_correct=2396.08, ppl=3.31, accuracy=57.121, wps=13315.4, ups=1.06, wpb=12518.2, bsz=477.6, num_updates=9200, lr=0.000147442, gnorm=0.517, clip=0, loss_scale=8, train_wall=93, gb_free=12.9, wall=8347
2023-07-28 04:15:32 | INFO | train_inner | epoch 007:    463 / 1474 loss=2.151, trans_loss=3.555, nll_loss=1.728, w2v_ctc_loss=1.147, task_loss=1.382, contrastive_loss=0.319, total=4153.22, n_correct=2372.4, ppl=3.31, accuracy=57.122, wps=13433.1, ups=1.08, wpb=12403.3, bsz=463, num_updates=9300, lr=0.000146647, gnorm=0.522, clip=0, loss_scale=16, train_wall=92, gb_free=16.8, wall=8439
2023-07-28 04:17:05 | INFO | train_inner | epoch 007:    563 / 1474 loss=2.124, trans_loss=3.555, nll_loss=1.724, w2v_ctc_loss=1.148, task_loss=1.366, contrastive_loss=0.146, total=4168.14, n_correct=2395.38, ppl=3.3, accuracy=57.469, wps=13405.9, ups=1.08, wpb=12434.7, bsz=459.8, num_updates=9400, lr=0.000145865, gnorm=0.51, clip=0, loss_scale=16, train_wall=92, gb_free=16.8, wall=8532
2023-07-28 04:18:38 | INFO | train_inner | epoch 007:    663 / 1474 loss=2.117, trans_loss=3.553, nll_loss=1.723, w2v_ctc_loss=1.142, task_loss=1.385, contrastive_loss=0.134, total=4157.82, n_correct=2390.14, ppl=3.3, accuracy=57.485, wps=13262.5, ups=1.07, wpb=12406.4, bsz=455.4, num_updates=9500, lr=0.000145095, gnorm=0.512, clip=0, loss_scale=16, train_wall=93, gb_free=15.5, wall=8625
2023-07-28 04:20:12 | INFO | train_inner | epoch 007:    763 / 1474 loss=2.118, trans_loss=3.55, nll_loss=1.72, w2v_ctc_loss=1.143, task_loss=1.459, contrastive_loss=0.129, total=4122.1, n_correct=2363.57, ppl=3.3, accuracy=57.339, wps=13101.5, ups=1.06, wpb=12308.4, bsz=446.2, num_updates=9600, lr=0.000144338, gnorm=0.512, clip=0, loss_scale=16, train_wall=93, gb_free=15.6, wall=8719
2023-07-28 04:21:46 | INFO | train_inner | epoch 007:    863 / 1474 loss=2.121, trans_loss=3.558, nll_loss=1.731, w2v_ctc_loss=1.143, task_loss=1.406, contrastive_loss=0.152, total=4147.23, n_correct=2375.7, ppl=3.32, accuracy=57.284, wps=13269.1, ups=1.07, wpb=12377.6, bsz=460.9, num_updates=9700, lr=0.000143592, gnorm=0.515, clip=0, loss_scale=16, train_wall=93, gb_free=17.5, wall=8813
2023-07-28 04:23:19 | INFO | train_inner | epoch 007:    963 / 1474 loss=2.127, trans_loss=3.552, nll_loss=1.725, w2v_ctc_loss=1.131, task_loss=1.329, contrastive_loss=0.248, total=4140.14, n_correct=2380.3, ppl=3.3, accuracy=57.493, wps=13242.4, ups=1.07, wpb=12359.1, bsz=474.6, num_updates=9800, lr=0.000142857, gnorm=0.514, clip=0, loss_scale=16, train_wall=93, gb_free=15.9, wall=8906
2023-07-28 04:24:52 | INFO | train_inner | epoch 007:   1063 / 1474 loss=2.119, trans_loss=3.564, nll_loss=1.739, w2v_ctc_loss=1.147, task_loss=1.464, contrastive_loss=0.114, total=4103.51, n_correct=2347.41, ppl=3.34, accuracy=57.205, wps=13134.1, ups=1.07, wpb=12251.1, bsz=437.5, num_updates=9900, lr=0.000142134, gnorm=0.51, clip=0, loss_scale=16, train_wall=93, gb_free=16.8, wall=8999
2023-07-28 04:26:25 | INFO | train_inner | epoch 007:   1163 / 1474 loss=2.151, trans_loss=3.55, nll_loss=1.724, w2v_ctc_loss=1.135, task_loss=1.359, contrastive_loss=0.381, total=4137.04, n_correct=2376.63, ppl=3.3, accuracy=57.448, wps=13295.9, ups=1.08, wpb=12361.6, bsz=470.9, num_updates=10000, lr=0.000141421, gnorm=0.528, clip=0, loss_scale=16, train_wall=92, gb_free=15.9, wall=9092
2023-07-28 04:26:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 04:26:48 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.304 | trans_loss 5.715 | nll_loss 3.041 | w2v_ctc_loss 1.338 | task_loss 6.838 | contrastive_loss 0.285 | total 4003.4 | n_correct 2379.2 | ppl 8.23 | accuracy 59.429 | uer 19.154 | wer 21.103 | raw_wer 21.103 | bleu 18.52 | wps 2240.5 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 18.52
2023-07-28 04:26:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-07-28 04:26:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_7_10000.pt
2023-07-28 04:26:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_7_10000.pt
2023-07-28 04:27:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 18.52) (writing took 19.952542113140225 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:0')
2023-07-28 04:28:41 | INFO | train_inner | epoch 007:   1263 / 1474 loss=2.111, trans_loss=3.557, nll_loss=1.731, w2v_ctc_loss=1.132, task_loss=1.411, contrastive_loss=0.144, total=4129.52, n_correct=2369.38, ppl=3.32, accuracy=57.377, wps=9081.4, ups=0.74, wpb=12331.4, bsz=450.2, num_updates=10100, lr=0.00014072, gnorm=0.417, clip=0, loss_scale=16, train_wall=92, gb_free=16.7, wall=9228
2023-07-28 04:30:14 | INFO | train_inner | epoch 007:   1363 / 1474 loss=2.122, trans_loss=3.549, nll_loss=1.721, w2v_ctc_loss=1.14, task_loss=1.312, contrastive_loss=0.181, total=4172.87, n_correct=2410.4, ppl=3.3, accuracy=57.764, wps=13367.3, ups=1.07, wpb=12458.1, bsz=476.2, num_updates=10200, lr=0.000140028, gnorm=0.416, clip=0, loss_scale=16, train_wall=93, gb_free=17.2, wall=9321
2023-07-28 04:31:48 | INFO | train_inner | epoch 007:   1463 / 1474 loss=2.131, trans_loss=3.555, nll_loss=1.731, w2v_ctc_loss=1.139, task_loss=1.504, contrastive_loss=0.243, total=4109.42, n_correct=2358.82, ppl=3.32, accuracy=57.4, wps=13029.3, ups=1.06, wpb=12278.1, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.422, clip=0, loss_scale=16, train_wall=94, gb_free=16.4, wall=9415
2023-07-28 04:31:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:3')
2023-07-28 04:32:22 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.309 | trans_loss 5.709 | nll_loss 3.031 | w2v_ctc_loss 1.368 | task_loss 6.857 | contrastive_loss 0.285 | total 4003.4 | n_correct 2379.3 | ppl 8.17 | accuracy 59.432 | uer 19.672 | wer 21.535 | raw_wer 21.535 | bleu 18.41 | wps 2178.5 | wpb 4003.4 | bsz 141.8 | num_updates 10311 | best_bleu 18.52
2023-07-28 04:32:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10311 updates
2023-07-28 04:32:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_18.4104.pt
2023-07-28 04:32:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_18.4104.pt
2023-07-28 04:32:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_18.4104.pt (epoch 7 @ 10311 updates, score 18.41) (writing took 15.336042284965515 seconds)
2023-07-28 04:32:37 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-07-28 04:32:37 | INFO | train | epoch 007 | loss 2.13 | trans_loss 3.553 | nll_loss 1.725 | w2v_ctc_loss 1.144 | task_loss 1.396 | contrastive_loss 0.21 | total 4138.65 | n_correct 2373.93 | ppl 3.31 | accuracy 57.36 | wps 12422.8 | ups 1.01 | wpb 12355.8 | bsz 458.5 | num_updates 10311 | lr 0.000139272 | gnorm 0.497 | clip 0 | loss_scale 16 | train_wall 1366 | gb_free 13.1 | wall 9465
2023-07-28 04:32:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 04:32:38 | INFO | fairseq.trainer | begin training epoch 8
2023-07-28 04:32:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 04:34:09 | INFO | train_inner | epoch 008:     89 / 1474 loss=2.078, trans_loss=3.53, nll_loss=1.691, w2v_ctc_loss=1.102, task_loss=1.475, contrastive_loss=0.139, total=4116.25, n_correct=2399.5, ppl=3.23, accuracy=58.293, wps=8715.3, ups=0.71, wpb=12273, bsz=443.3, num_updates=10400, lr=0.000138675, gnorm=0.413, clip=0, loss_scale=16, train_wall=93, gb_free=16.9, wall=9556
2023-07-28 04:35:42 | INFO | train_inner | epoch 008:    189 / 1474 loss=2.076, trans_loss=3.522, nll_loss=1.68, w2v_ctc_loss=1.098, task_loss=1.517, contrastive_loss=0.158, total=4037.23, n_correct=2359.15, ppl=3.2, accuracy=58.435, wps=13020.6, ups=1.08, wpb=12041.5, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.424, clip=0, loss_scale=16, train_wall=92, gb_free=12.6, wall=9649
2023-07-28 04:37:15 | INFO | train_inner | epoch 008:    289 / 1474 loss=2.073, trans_loss=3.518, nll_loss=1.679, w2v_ctc_loss=1.095, task_loss=1.312, contrastive_loss=0.16, total=4207.78, n_correct=2463.57, ppl=3.2, accuracy=58.548, wps=13521, ups=1.08, wpb=12556.5, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.413, clip=0, loss_scale=16, train_wall=92, gb_free=12.8, wall=9742
2023-07-28 04:38:49 | INFO | train_inner | epoch 008:    389 / 1474 loss=2.092, trans_loss=3.528, nll_loss=1.69, w2v_ctc_loss=1.116, task_loss=1.488, contrastive_loss=0.18, total=4127.24, n_correct=2403.94, ppl=3.23, accuracy=58.246, wps=13072.8, ups=1.06, wpb=12316.2, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=0.437, clip=0, loss_scale=16, train_wall=94, gb_free=11.6, wall=9836
2023-07-28 04:40:23 | INFO | train_inner | epoch 008:    489 / 1474 loss=2.121, trans_loss=3.521, nll_loss=1.685, w2v_ctc_loss=1.094, task_loss=1.247, contrastive_loss=0.443, total=4203.76, n_correct=2459.8, ppl=3.21, accuracy=58.514, wps=13301.8, ups=1.06, wpb=12548.2, bsz=504.5, num_updates=10800, lr=0.000136083, gnorm=0.418, clip=0, loss_scale=16, train_wall=94, gb_free=14.4, wall=9930
2023-07-28 04:41:56 | INFO | train_inner | epoch 008:    589 / 1474 loss=2.081, trans_loss=3.525, nll_loss=1.692, w2v_ctc_loss=1.116, task_loss=1.526, contrastive_loss=0.113, total=4062.5, n_correct=2362.41, ppl=3.23, accuracy=58.152, wps=13068.7, ups=1.08, wpb=12145.4, bsz=427.9, num_updates=10900, lr=0.000135457, gnorm=0.429, clip=0, loss_scale=16, train_wall=92, gb_free=11.1, wall=10023
2023-07-28 04:43:29 | INFO | train_inner | epoch 008:    689 / 1474 loss=2.074, trans_loss=3.52, nll_loss=1.682, w2v_ctc_loss=1.109, task_loss=1.44, contrastive_loss=0.126, total=4142.78, n_correct=2425.23, ppl=3.21, accuracy=58.541, wps=13303.5, ups=1.08, wpb=12364.4, bsz=448.6, num_updates=11000, lr=0.00013484, gnorm=0.417, clip=0, loss_scale=16, train_wall=92, gb_free=15.8, wall=10116
2023-07-28 04:45:02 | INFO | train_inner | epoch 008:    789 / 1474 loss=2.082, trans_loss=3.519, nll_loss=1.686, w2v_ctc_loss=1.102, task_loss=1.432, contrastive_loss=0.209, total=4118.9, n_correct=2404.92, ppl=3.22, accuracy=58.387, wps=13267.6, ups=1.08, wpb=12310.9, bsz=447.8, num_updates=11100, lr=0.000134231, gnorm=0.416, clip=0, loss_scale=16, train_wall=92, gb_free=15.1, wall=10209
2023-07-28 04:46:36 | INFO | train_inner | epoch 008:    889 / 1474 loss=2.076, trans_loss=3.521, nll_loss=1.687, w2v_ctc_loss=1.088, task_loss=1.342, contrastive_loss=0.221, total=4169.01, n_correct=2447.21, ppl=3.22, accuracy=58.7, wps=13250.9, ups=1.06, wpb=12452.5, bsz=473.7, num_updates=11200, lr=0.000133631, gnorm=0.416, clip=0, loss_scale=16, train_wall=93, gb_free=16, wall=10303
2023-07-28 04:48:08 | INFO | train_inner | epoch 008:    989 / 1474 loss=2.059, trans_loss=3.523, nll_loss=1.687, w2v_ctc_loss=1.089, task_loss=1.338, contrastive_loss=0.122, total=4154.69, n_correct=2438.96, ppl=3.22, accuracy=58.704, wps=13422.6, ups=1.08, wpb=12403.4, bsz=464.9, num_updates=11300, lr=0.000133038, gnorm=0.422, clip=0, loss_scale=16, train_wall=92, gb_free=17.7, wall=10395
2023-07-28 04:49:42 | INFO | train_inner | epoch 008:   1089 / 1474 loss=2.093, trans_loss=3.53, nll_loss=1.697, w2v_ctc_loss=1.09, task_loss=1.389, contrastive_loss=0.349, total=4199.1, n_correct=2445.45, ppl=3.24, accuracy=58.237, wps=13324.8, ups=1.06, wpb=12534.3, bsz=465.3, num_updates=11400, lr=0.000132453, gnorm=0.418, clip=0, loss_scale=32, train_wall=94, gb_free=12.5, wall=10489
2023-07-28 04:51:15 | INFO | train_inner | epoch 008:   1189 / 1474 loss=2.064, trans_loss=3.522, nll_loss=1.688, w2v_ctc_loss=1.091, task_loss=1.321, contrastive_loss=0.131, total=4177.31, n_correct=2444.85, ppl=3.22, accuracy=58.527, wps=13427.8, ups=1.08, wpb=12476.3, bsz=472.6, num_updates=11500, lr=0.000131876, gnorm=0.413, clip=0, loss_scale=32, train_wall=92, gb_free=14.8, wall=10582
2023-07-28 04:52:48 | INFO | train_inner | epoch 008:   1289 / 1474 loss=2.077, trans_loss=3.527, nll_loss=1.695, w2v_ctc_loss=1.105, task_loss=1.457, contrastive_loss=0.155, total=4063.85, n_correct=2367.83, ppl=3.24, accuracy=58.266, wps=13152.1, ups=1.08, wpb=12140.6, bsz=438.4, num_updates=11600, lr=0.000131306, gnorm=0.423, clip=0, loss_scale=32, train_wall=92, gb_free=16.7, wall=10675
2023-07-28 04:54:21 | INFO | train_inner | epoch 008:   1389 / 1474 loss=2.082, trans_loss=3.529, nll_loss=1.697, w2v_ctc_loss=1.096, task_loss=1.384, contrastive_loss=0.208, total=4141.5, n_correct=2420.91, ppl=3.24, accuracy=58.455, wps=13284.7, ups=1.07, wpb=12367.2, bsz=461.5, num_updates=11700, lr=0.000130744, gnorm=0.427, clip=0, loss_scale=32, train_wall=92, gb_free=16.3, wall=10768
2023-07-28 04:55:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 04:56:04 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.287 | trans_loss 5.684 | nll_loss 2.994 | w2v_ctc_loss 1.357 | task_loss 6.871 | contrastive_loss 0.273 | total 4003.4 | n_correct 2398.7 | ppl 7.97 | accuracy 59.917 | uer 18.947 | wer 20.622 | raw_wer 20.622 | bleu 18.87 | wps 2192.7 | wpb 4003.4 | bsz 141.8 | num_updates 11785 | best_bleu 18.87
2023-07-28 04:56:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11785 updates
2023-07-28 04:56:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 04:56:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 04:56:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt (epoch 8 @ 11785 updates, score 18.87) (writing took 19.209754038602114 seconds)
2023-07-28 04:56:24 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-07-28 04:56:24 | INFO | train | epoch 008 | loss 2.08 | trans_loss 3.524 | nll_loss 1.688 | w2v_ctc_loss 1.098 | task_loss 1.398 | contrastive_loss 0.201 | total 4138.65 | n_correct 2418.71 | ppl 3.22 | accuracy 58.442 | wps 12769.5 | ups 1.03 | wpb 12355.8 | bsz 458.5 | num_updates 11785 | lr 0.000130272 | gnorm 0.42 | clip 0 | loss_scale 32 | train_wall 1365 | gb_free 16.8 | wall 10891
2023-07-28 04:56:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 04:56:24 | INFO | fairseq.trainer | begin training epoch 9
2023-07-28 04:56:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 04:56:47 | INFO | train_inner | epoch 009:     15 / 1474 loss=2.079, trans_loss=3.521, nll_loss=1.685, w2v_ctc_loss=1.078, task_loss=1.35, contrastive_loss=0.333, total=4139.35, n_correct=2430.25, ppl=3.21, accuracy=58.711, wps=8420.7, ups=0.68, wpb=12350.9, bsz=472.9, num_updates=11800, lr=0.000130189, gnorm=0.423, clip=0, loss_scale=32, train_wall=93, gb_free=15.4, wall=10914
2023-07-28 04:58:20 | INFO | train_inner | epoch 009:    115 / 1474 loss=2.025, trans_loss=3.485, nll_loss=1.639, w2v_ctc_loss=1.052, task_loss=1.33, contrastive_loss=0.152, total=4181.9, n_correct=2494.02, ppl=3.11, accuracy=59.638, wps=13476.6, ups=1.08, wpb=12488.1, bsz=475.9, num_updates=11900, lr=0.000129641, gnorm=0.41, clip=0, loss_scale=32, train_wall=92, gb_free=16.2, wall=11007
2023-07-28 04:59:53 | INFO | train_inner | epoch 009:    215 / 1474 loss=2.023, trans_loss=3.492, nll_loss=1.646, w2v_ctc_loss=1.056, task_loss=1.511, contrastive_loss=0.109, total=4062.07, n_correct=2414.16, ppl=3.13, accuracy=59.432, wps=12966.6, ups=1.07, wpb=12129.1, bsz=431.6, num_updates=12000, lr=0.000129099, gnorm=0.42, clip=0, loss_scale=32, train_wall=93, gb_free=15.5, wall=11101
2023-07-28 04:59:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 05:00:17 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.279 | trans_loss 5.693 | nll_loss 3.005 | w2v_ctc_loss 1.309 | task_loss 6.816 | contrastive_loss 0.277 | total 4003.4 | n_correct 2393.2 | ppl 8.03 | accuracy 59.779 | uer 18.809 | wer 20.637 | raw_wer 20.637 | bleu 18.47 | wps 2228.7 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 18.87
2023-07-28 05:00:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-07-28 05:00:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_9_12000.pt
2023-07-28 05:00:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_9_12000.pt
2023-07-28 05:00:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.47) (writing took 17.24750317633152 seconds)
2023-07-28 05:02:08 | INFO | train_inner | epoch 009:    315 / 1474 loss=2.017, trans_loss=3.48, nll_loss=1.634, w2v_ctc_loss=1.042, task_loss=1.307, contrastive_loss=0.16, total=4152.1, n_correct=2482.89, ppl=3.1, accuracy=59.798, wps=9216, ups=0.74, wpb=12407.3, bsz=476.6, num_updates=12100, lr=0.000128565, gnorm=0.412, clip=0, loss_scale=32, train_wall=93, gb_free=16.2, wall=11235
2023-07-28 05:03:42 | INFO | train_inner | epoch 009:    415 / 1474 loss=2.023, trans_loss=3.496, nll_loss=1.653, w2v_ctc_loss=1.052, task_loss=1.366, contrastive_loss=0.127, total=4203.78, n_correct=2496.63, ppl=3.15, accuracy=59.39, wps=13398.3, ups=1.07, wpb=12551.8, bsz=469.8, num_updates=12200, lr=0.000128037, gnorm=0.411, clip=0, loss_scale=32, train_wall=93, gb_free=17.1, wall=11329
2023-07-28 05:05:15 | INFO | train_inner | epoch 009:    515 / 1474 loss=2.05, trans_loss=3.501, nll_loss=1.659, w2v_ctc_loss=1.076, task_loss=1.471, contrastive_loss=0.176, total=4112.78, n_correct=2435.1, ppl=3.16, accuracy=59.208, wps=13228.1, ups=1.08, wpb=12275.6, bsz=437.7, num_updates=12300, lr=0.000127515, gnorm=0.422, clip=0, loss_scale=32, train_wall=92, gb_free=16.1, wall=11422
2023-07-28 05:06:48 | INFO | train_inner | epoch 009:    615 / 1474 loss=2.02, trans_loss=3.493, nll_loss=1.653, w2v_ctc_loss=1.047, task_loss=1.421, contrastive_loss=0.138, total=4131.32, n_correct=2453.98, ppl=3.14, accuracy=59.399, wps=13203.1, ups=1.07, wpb=12347.4, bsz=455, num_updates=12400, lr=0.000127, gnorm=0.418, clip=0, loss_scale=32, train_wall=93, gb_free=17.8, wall=11515
2023-07-28 05:08:21 | INFO | train_inner | epoch 009:    715 / 1474 loss=2.053, trans_loss=3.504, nll_loss=1.665, w2v_ctc_loss=1.073, task_loss=1.431, contrastive_loss=0.22, total=4082.11, n_correct=2411.88, ppl=3.17, accuracy=59.084, wps=13164, ups=1.08, wpb=12194.8, bsz=449.7, num_updates=12500, lr=0.000126491, gnorm=0.429, clip=0, loss_scale=32, train_wall=92, gb_free=16.9, wall=11608
2023-07-28 05:09:54 | INFO | train_inner | epoch 009:    815 / 1474 loss=2.071, trans_loss=3.496, nll_loss=1.658, w2v_ctc_loss=1.062, task_loss=1.261, contrastive_loss=0.365, total=4221.08, n_correct=2503, ppl=3.16, accuracy=59.298, wps=13535.7, ups=1.07, wpb=12613.9, bsz=501.6, num_updates=12600, lr=0.000125988, gnorm=0.419, clip=0, loss_scale=32, train_wall=93, gb_free=17.6, wall=11701
2023-07-28 05:11:28 | INFO | train_inner | epoch 009:    915 / 1474 loss=2.054, trans_loss=3.503, nll_loss=1.66, w2v_ctc_loss=1.058, task_loss=1.445, contrastive_loss=0.342, total=4142.34, n_correct=2454.51, ppl=3.16, accuracy=59.254, wps=13138.2, ups=1.06, wpb=12359.9, bsz=448.9, num_updates=12700, lr=0.000125491, gnorm=0.415, clip=0, loss_scale=32, train_wall=94, gb_free=17.2, wall=11795
2023-07-28 05:13:01 | INFO | train_inner | epoch 009:   1015 / 1474 loss=2.039, trans_loss=3.51, nll_loss=1.67, w2v_ctc_loss=1.068, task_loss=1.569, contrastive_loss=0.123, total=4097.15, n_correct=2416.71, ppl=3.18, accuracy=58.985, wps=13170.3, ups=1.08, wpb=12228.7, bsz=422.6, num_updates=12800, lr=0.000125, gnorm=0.422, clip=0, loss_scale=32, train_wall=92, gb_free=16.8, wall=11888
2023-07-28 05:14:33 | INFO | train_inner | epoch 009:   1115 / 1474 loss=2.031, trans_loss=3.504, nll_loss=1.661, w2v_ctc_loss=1.056, task_loss=1.305, contrastive_loss=0.149, total=4182.29, n_correct=2487.58, ppl=3.16, accuracy=59.479, wps=13518.5, ups=1.08, wpb=12467.1, bsz=477.6, num_updates=12900, lr=0.000124515, gnorm=0.424, clip=0, loss_scale=32, train_wall=92, gb_free=17.2, wall=11980
2023-07-28 05:16:06 | INFO | train_inner | epoch 009:   1215 / 1474 loss=2.04, trans_loss=3.507, nll_loss=1.668, w2v_ctc_loss=1.072, task_loss=1.482, contrastive_loss=0.129, total=4141.43, n_correct=2450.61, ppl=3.18, accuracy=59.173, wps=13301.9, ups=1.08, wpb=12364.7, bsz=446.6, num_updates=13000, lr=0.000124035, gnorm=0.415, clip=0, loss_scale=32, train_wall=92, gb_free=17.5, wall=12073
2023-07-28 05:17:39 | INFO | train_inner | epoch 009:   1315 / 1474 loss=2.053, trans_loss=3.501, nll_loss=1.661, w2v_ctc_loss=1.052, task_loss=1.268, contrastive_loss=0.322, total=4203.91, n_correct=2502, ppl=3.16, accuracy=59.516, wps=13444.3, ups=1.07, wpb=12545.2, bsz=492.3, num_updates=13100, lr=0.00012356, gnorm=0.411, clip=0, loss_scale=32, train_wall=93, gb_free=17.2, wall=12167
2023-07-28 05:19:12 | INFO | train_inner | epoch 009:   1415 / 1474 loss=2.033, trans_loss=3.513, nll_loss=1.675, w2v_ctc_loss=1.065, task_loss=1.511, contrastive_loss=0.105, total=4077.08, n_correct=2408.94, ppl=3.19, accuracy=59.085, wps=13088.2, ups=1.08, wpb=12165, bsz=429.1, num_updates=13200, lr=0.000123091, gnorm=0.416, clip=0, loss_scale=32, train_wall=92, gb_free=17.3, wall=12260
2023-07-28 05:20:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 05:20:29 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.259 | trans_loss 5.66 | nll_loss 2.966 | w2v_ctc_loss 1.32 | task_loss 6.884 | contrastive_loss 0.269 | total 4003.4 | n_correct 2408.5 | ppl 7.82 | accuracy 60.161 | uer 18.331 | wer 20.167 | raw_wer 20.167 | bleu 18.93 | wps 2204.2 | wpb 4003.4 | bsz 141.8 | num_updates 13259 | best_bleu 18.93
2023-07-28 05:20:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13259 updates
2023-07-28 05:20:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 05:20:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 05:20:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt (epoch 9 @ 13259 updates, score 18.93) (writing took 19.68467180430889 seconds)
2023-07-28 05:20:50 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-07-28 05:20:50 | INFO | train | epoch 009 | loss 2.038 | trans_loss 3.499 | nll_loss 1.657 | w2v_ctc_loss 1.059 | task_loss 1.398 | contrastive_loss 0.193 | total 4138.65 | n_correct 2456.02 | ppl 3.15 | accuracy 59.344 | wps 12424.4 | ups 1.01 | wpb 12355.8 | bsz 458.5 | num_updates 13259 | lr 0.000122817 | gnorm 0.418 | clip 0 | loss_scale 32 | train_wall 1363 | gb_free 11.4 | wall 12357
2023-07-28 05:20:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 05:20:50 | INFO | fairseq.trainer | begin training epoch 10
2023-07-28 05:20:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 05:21:37 | INFO | train_inner | epoch 010:     41 / 1474 loss=2.024, trans_loss=3.491, nll_loss=1.648, w2v_ctc_loss=1.041, task_loss=1.331, contrastive_loss=0.207, total=4100.86, n_correct=2449.62, ppl=3.13, accuracy=59.734, wps=8490.8, ups=0.69, wpb=12239.9, bsz=470.2, num_updates=13300, lr=0.000122628, gnorm=0.418, clip=0, loss_scale=32, train_wall=91, gb_free=16.4, wall=12404
2023-07-28 05:23:11 | INFO | train_inner | epoch 010:    141 / 1474 loss=1.983, trans_loss=3.465, nll_loss=1.614, w2v_ctc_loss=1.014, task_loss=1.322, contrastive_loss=0.13, total=4240.18, n_correct=2560.96, ppl=3.06, accuracy=60.397, wps=13436.3, ups=1.06, wpb=12664, bsz=479.1, num_updates=13400, lr=0.000122169, gnorm=0.41, clip=0, loss_scale=64, train_wall=94, gb_free=14.8, wall=12498
2023-07-28 05:24:44 | INFO | train_inner | epoch 010:    241 / 1474 loss=2.007, trans_loss=3.467, nll_loss=1.615, w2v_ctc_loss=1.024, task_loss=1.385, contrastive_loss=0.253, total=4126.3, n_correct=2492.67, ppl=3.06, accuracy=60.409, wps=13262.4, ups=1.08, wpb=12312.3, bsz=460.9, num_updates=13500, lr=0.000121716, gnorm=0.414, clip=0, loss_scale=64, train_wall=92, gb_free=15.4, wall=12591
2023-07-28 05:26:17 | INFO | train_inner | epoch 010:    341 / 1474 loss=1.988, trans_loss=3.464, nll_loss=1.616, w2v_ctc_loss=1.017, task_loss=1.421, contrastive_loss=0.162, total=4132.25, n_correct=2492.84, ppl=3.07, accuracy=60.326, wps=13211.7, ups=1.07, wpb=12352, bsz=452.8, num_updates=13600, lr=0.000121268, gnorm=0.41, clip=0, loss_scale=64, train_wall=93, gb_free=14.6, wall=12684
2023-07-28 05:27:52 | INFO | train_inner | epoch 010:    441 / 1474 loss=2.006, trans_loss=3.471, nll_loss=1.622, w2v_ctc_loss=1.007, task_loss=1.341, contrastive_loss=0.338, total=4203.14, n_correct=2531.51, ppl=3.08, accuracy=60.229, wps=13235.9, ups=1.05, wpb=12548.6, bsz=481.7, num_updates=13700, lr=0.000120824, gnorm=0.414, clip=0, loss_scale=64, train_wall=94, gb_free=16.3, wall=12779
2023-07-28 05:29:25 | INFO | train_inner | epoch 010:    541 / 1474 loss=2.006, trans_loss=3.487, nll_loss=1.638, w2v_ctc_loss=1.041, task_loss=1.488, contrastive_loss=0.117, total=4106.5, n_correct=2459.71, ppl=3.11, accuracy=59.898, wps=13129.7, ups=1.07, wpb=12244.6, bsz=440, num_updates=13800, lr=0.000120386, gnorm=0.417, clip=0, loss_scale=64, train_wall=93, gb_free=16.3, wall=12872
2023-07-28 05:30:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-28 05:30:59 | INFO | train_inner | epoch 010:    642 / 1474 loss=2.005, trans_loss=3.48, nll_loss=1.633, w2v_ctc_loss=1.034, task_loss=1.363, contrastive_loss=0.146, total=4153.88, n_correct=2495.39, ppl=3.1, accuracy=60.074, wps=13244.9, ups=1.07, wpb=12398.2, bsz=466.4, num_updates=13900, lr=0.000119952, gnorm=0.425, clip=0, loss_scale=32, train_wall=93, gb_free=16.1, wall=12966
2023-07-28 05:32:31 | INFO | train_inner | epoch 010:    742 / 1474 loss=2.009, trans_loss=3.483, nll_loss=1.637, w2v_ctc_loss=1.046, task_loss=1.399, contrastive_loss=0.115, total=4125.87, n_correct=2474.09, ppl=3.11, accuracy=59.965, wps=13369.1, ups=1.09, wpb=12315.3, bsz=454.4, num_updates=14000, lr=0.000119523, gnorm=0.422, clip=0, loss_scale=32, train_wall=91, gb_free=14.4, wall=13058
2023-07-28 05:32:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 05:32:54 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.257 | trans_loss 5.661 | nll_loss 2.963 | w2v_ctc_loss 1.31 | task_loss 6.874 | contrastive_loss 0.275 | total 4003.4 | n_correct 2409.4 | ppl 7.8 | accuracy 60.184 | uer 18.761 | wer 20.484 | raw_wer 20.484 | bleu 18.96 | wps 2211.6 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 18.96
2023-07-28 05:32:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-07-28 05:32:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_10_14000.pt
2023-07-28 05:32:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_10_14000.pt
2023-07-28 05:33:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 18.96) (writing took 20.274089137092233 seconds)
2023-07-28 05:34:48 | INFO | train_inner | epoch 010:    842 / 1474 loss=1.988, trans_loss=3.477, nll_loss=1.631, w2v_ctc_loss=1.021, task_loss=1.383, contrastive_loss=0.118, total=4128.44, n_correct=2483.84, ppl=3.1, accuracy=60.164, wps=8974.9, ups=0.73, wpb=12327.8, bsz=456.3, num_updates=14100, lr=0.000119098, gnorm=0.414, clip=0, loss_scale=32, train_wall=92, gb_free=14.6, wall=13195
2023-07-28 05:36:20 | INFO | train_inner | epoch 010:    942 / 1474 loss=2.003, trans_loss=3.48, nll_loss=1.632, w2v_ctc_loss=1.029, task_loss=1.345, contrastive_loss=0.158, total=4160.94, n_correct=2504.25, ppl=3.1, accuracy=60.185, wps=13516, ups=1.09, wpb=12411.1, bsz=468.1, num_updates=14200, lr=0.000118678, gnorm=0.422, clip=0, loss_scale=32, train_wall=91, gb_free=15.3, wall=13287
2023-07-28 05:37:53 | INFO | train_inner | epoch 010:   1042 / 1474 loss=2, trans_loss=3.483, nll_loss=1.637, w2v_ctc_loss=1.032, task_loss=1.513, contrastive_loss=0.13, total=4067.53, n_correct=2434.9, ppl=3.11, accuracy=59.862, wps=13103, ups=1.08, wpb=12145, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.421, clip=0, loss_scale=32, train_wall=92, gb_free=16.9, wall=13380
2023-07-28 05:39:26 | INFO | train_inner | epoch 010:   1142 / 1474 loss=2.01, trans_loss=3.492, nll_loss=1.648, w2v_ctc_loss=1.046, task_loss=1.561, contrastive_loss=0.112, total=4044.03, n_correct=2411.19, ppl=3.13, accuracy=59.623, wps=12943.8, ups=1.07, wpb=12074.4, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.426, clip=0, loss_scale=32, train_wall=93, gb_free=17.3, wall=13473
2023-07-28 05:40:59 | INFO | train_inner | epoch 010:   1242 / 1474 loss=1.999, trans_loss=3.479, nll_loss=1.637, w2v_ctc_loss=1.038, task_loss=1.435, contrastive_loss=0.106, total=4110.41, n_correct=2467.18, ppl=3.11, accuracy=60.023, wps=13305.1, ups=1.08, wpb=12291.6, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.418, clip=0, loss_scale=32, train_wall=92, gb_free=16.4, wall=13566
2023-07-28 05:42:31 | INFO | train_inner | epoch 010:   1342 / 1474 loss=1.999, trans_loss=3.487, nll_loss=1.645, w2v_ctc_loss=1.033, task_loss=1.43, contrastive_loss=0.12, total=4121.38, n_correct=2472.19, ppl=3.13, accuracy=59.985, wps=13318.2, ups=1.08, wpb=12308.4, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.42, clip=0, loss_scale=32, train_wall=92, gb_free=13.9, wall=13658
2023-07-28 05:44:06 | INFO | train_inner | epoch 010:   1442 / 1474 loss=2.036, trans_loss=3.49, nll_loss=1.647, w2v_ctc_loss=1.019, task_loss=1.318, contrastive_loss=0.375, total=4192.39, n_correct=2511.2, ppl=3.13, accuracy=59.899, wps=13176.2, ups=1.05, wpb=12506.1, bsz=482, num_updates=14700, lr=0.000116642, gnorm=0.425, clip=0, loss_scale=32, train_wall=94, gb_free=17, wall=13753
2023-07-28 05:44:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 05:44:58 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.259 | trans_loss 5.643 | nll_loss 2.94 | w2v_ctc_loss 1.36 | task_loss 6.877 | contrastive_loss 0.267 | total 4003.4 | n_correct 2423.4 | ppl 7.67 | accuracy 60.534 | uer 18.095 | wer 19.779 | raw_wer 19.779 | bleu 19.25 | wps 2254.5 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 19.25
2023-07-28 05:44:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-07-28 05:44:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 05:45:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 05:45:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt (epoch 10 @ 14732 updates, score 19.25) (writing took 20.42710829898715 seconds)
2023-07-28 05:45:19 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-07-28 05:45:19 | INFO | train | epoch 010 | loss 2.003 | trans_loss 3.479 | nll_loss 1.632 | w2v_ctc_loss 1.027 | task_loss 1.401 | contrastive_loss 0.181 | total 4137.5 | n_correct 2485.99 | ppl 3.1 | accuracy 60.084 | wps 12380.9 | ups 1 | wpb 12352.5 | bsz 457.9 | num_updates 14732 | lr 0.000116516 | gnorm 0.418 | clip 0 | loss_scale 32 | train_wall 1363 | gb_free 17.2 | wall 13826
2023-07-28 05:45:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 05:45:20 | INFO | fairseq.trainer | begin training epoch 11
2023-07-28 05:45:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 05:46:30 | INFO | train_inner | epoch 011:     68 / 1474 loss=1.974, trans_loss=3.453, nll_loss=1.599, w2v_ctc_loss=1.001, task_loss=1.297, contrastive_loss=0.196, total=4175.24, n_correct=2540.56, ppl=3.03, accuracy=60.848, wps=8638.1, ups=0.69, wpb=12463.5, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.415, clip=0, loss_scale=32, train_wall=91, gb_free=16.7, wall=13897
2023-07-28 05:48:03 | INFO | train_inner | epoch 011:    168 / 1474 loss=1.968, trans_loss=3.455, nll_loss=1.604, w2v_ctc_loss=1.006, task_loss=1.441, contrastive_loss=0.114, total=4087.78, n_correct=2482.06, ppl=3.04, accuracy=60.719, wps=13188.8, ups=1.08, wpb=12214.2, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.434, clip=0, loss_scale=32, train_wall=92, gb_free=16.4, wall=13990
2023-07-28 05:49:36 | INFO | train_inner | epoch 011:    268 / 1474 loss=1.958, trans_loss=3.455, nll_loss=1.601, w2v_ctc_loss=0.995, task_loss=1.441, contrastive_loss=0.11, total=4118.77, n_correct=2503.5, ppl=3.03, accuracy=60.783, wps=13158.8, ups=1.07, wpb=12299.1, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.425, clip=0, loss_scale=32, train_wall=93, gb_free=12.2, wall=14083
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:0')
2023-07-28 05:50:46 | INFO | train_inner | epoch 011:    368 / 1474 loss=2.112, trans_loss=5.134, nll_loss=2.383, w2v_ctc_loss=0.747, task_loss=2.138, contrastive_loss=0.088, total=4097.83, n_correct=2490.19, ppl=5.22, accuracy=60.769, wps=11801.2, ups=1.43, wpb=8240.8, bsz=298, num_updates=15100, lr=0.000115087, gnorm=0.563, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=14153
2023-07-28 05:51:56 | INFO | train_inner | epoch 011:    468 / 1474 loss=2.127, trans_loss=5.172, nll_loss=2.409, w2v_ctc_loss=0.742, task_loss=2.196, contrastive_loss=0.206, total=4110.64, n_correct=2488.29, ppl=5.31, accuracy=60.533, wps=11766.7, ups=1.43, wpb=8221.3, bsz=300.4, num_updates=15200, lr=0.000114708, gnorm=0.556, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=14223
2023-07-28 05:53:06 | INFO | train_inner | epoch 011:    568 / 1474 loss=2.13, trans_loss=5.171, nll_loss=2.408, w2v_ctc_loss=0.754, task_loss=2.25, contrastive_loss=0.204, total=4071.69, n_correct=2459.47, ppl=5.31, accuracy=60.404, wps=11558.9, ups=1.42, wpb=8143.4, bsz=293.7, num_updates=15300, lr=0.000114332, gnorm=0.563, clip=0, loss_scale=32, train_wall=70, gb_free=16, wall=14294
2023-07-28 05:54:16 | INFO | train_inner | epoch 011:    668 / 1474 loss=2.134, trans_loss=5.174, nll_loss=2.412, w2v_ctc_loss=0.749, task_loss=2.059, contrastive_loss=0.261, total=4157.2, n_correct=2508.99, ppl=5.32, accuracy=60.353, wps=11878, ups=1.43, wpb=8314.4, bsz=309.6, num_updates=15400, lr=0.000113961, gnorm=0.556, clip=0, loss_scale=32, train_wall=70, gb_free=16.7, wall=14364
2023-07-28 05:55:26 | INFO | train_inner | epoch 011:    768 / 1474 loss=2.128, trans_loss=5.183, nll_loss=2.424, w2v_ctc_loss=0.761, task_loss=2.108, contrastive_loss=0.087, total=4174.91, n_correct=2525.77, ppl=5.37, accuracy=60.499, wps=12061.5, ups=1.44, wpb=8349.8, bsz=306.9, num_updates=15500, lr=0.000113592, gnorm=0.554, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=14433
2023-07-28 05:56:35 | INFO | train_inner | epoch 011:    868 / 1474 loss=2.127, trans_loss=5.183, nll_loss=2.425, w2v_ctc_loss=0.756, task_loss=2.192, contrastive_loss=0.075, total=4118.44, n_correct=2485.47, ppl=5.37, accuracy=60.35, wps=11877.4, ups=1.44, wpb=8236.9, bsz=293.7, num_updates=15600, lr=0.000113228, gnorm=0.553, clip=0, loss_scale=32, train_wall=69, gb_free=10.6, wall=14502
2023-07-28 05:57:45 | INFO | train_inner | epoch 011:    968 / 1474 loss=2.125, trans_loss=5.18, nll_loss=2.421, w2v_ctc_loss=0.759, task_loss=2.145, contrastive_loss=0.088, total=4140.92, n_correct=2502.24, ppl=5.36, accuracy=60.427, wps=11832.4, ups=1.43, wpb=8281.8, bsz=301.9, num_updates=15700, lr=0.000112867, gnorm=0.555, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=14572
2023-07-28 05:58:54 | INFO | train_inner | epoch 011:   1068 / 1474 loss=2.123, trans_loss=5.176, nll_loss=2.417, w2v_ctc_loss=0.758, task_loss=2.061, contrastive_loss=0.108, total=4136.99, n_correct=2506.6, ppl=5.34, accuracy=60.59, wps=11919, ups=1.44, wpb=8274, bsz=308.8, num_updates=15800, lr=0.000112509, gnorm=0.554, clip=0, loss_scale=32, train_wall=69, gb_free=17.6, wall=14642
2023-07-28 06:00:04 | INFO | train_inner | epoch 011:   1168 / 1474 loss=2.125, trans_loss=5.184, nll_loss=2.427, w2v_ctc_loss=0.758, task_loss=2.09, contrastive_loss=0.093, total=4185.65, n_correct=2524.79, ppl=5.38, accuracy=60.32, wps=11995, ups=1.43, wpb=8371.3, bsz=309.8, num_updates=15900, lr=0.000112154, gnorm=0.55, clip=0, loss_scale=32, train_wall=69, gb_free=13.9, wall=14711
2023-07-28 06:01:15 | INFO | train_inner | epoch 011:   1268 / 1474 loss=2.128, trans_loss=5.177, nll_loss=2.419, w2v_ctc_loss=0.756, task_loss=2.017, contrastive_loss=0.162, total=4171.89, n_correct=2523.69, ppl=5.35, accuracy=60.493, wps=11856.6, ups=1.42, wpb=8343.8, bsz=314.1, num_updates=16000, lr=0.000111803, gnorm=0.554, clip=0, loss_scale=64, train_wall=70, gb_free=15.8, wall=14782
2023-07-28 06:01:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:3')
2023-07-28 06:01:38 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.256 | trans_loss 5.641 | nll_loss 2.94 | w2v_ctc_loss 1.356 | task_loss 6.933 | contrastive_loss 0.265 | total 4003.4 | n_correct 2430.1 | ppl 7.68 | accuracy 60.701 | uer 18.085 | wer 20.029 | raw_wer 20.029 | bleu 18.95 | wps 2163.2 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.25
2023-07-28 06:01:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-07-28 06:01:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_11_16000.pt
2023-07-28 06:01:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_11_16000.pt
2023-07-28 06:02:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 18.95) (writing took 29.714963886886835 seconds)
2023-07-28 06:03:19 | INFO | train_inner | epoch 011:   1368 / 1474 loss=2.133, trans_loss=5.179, nll_loss=2.422, w2v_ctc_loss=0.745, task_loss=1.936, contrastive_loss=0.325, total=4190.34, n_correct=2532.94, ppl=5.36, accuracy=60.447, wps=6744.9, ups=0.8, wpb=8380.7, bsz=327.9, num_updates=16100, lr=0.000111456, gnorm=0.548, clip=0, loss_scale=64, train_wall=70, gb_free=17, wall=14906
2023-07-28 06:04:28 | INFO | train_inner | epoch 011:   1468 / 1474 loss=2.122, trans_loss=5.183, nll_loss=2.427, w2v_ctc_loss=0.752, task_loss=2.026, contrastive_loss=0.098, total=4158.39, n_correct=2512.54, ppl=5.38, accuracy=60.421, wps=12001.7, ups=1.44, wpb=8316.8, bsz=312, num_updates=16200, lr=0.000111111, gnorm=0.552, clip=0, loss_scale=64, train_wall=69, gb_free=16.9, wall=14975
2023-07-28 06:04:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 06:04:55 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.221 | trans_loss 5.625 | nll_loss 2.924 | w2v_ctc_loss 1.274 | task_loss 6.868 | contrastive_loss 0.263 | total 4003.4 | n_correct 2435.4 | ppl 7.59 | accuracy 60.833 | uer 17.87 | wer 19.764 | raw_wer 19.764 | bleu 19.27 | wps 2326.2 | wpb 4003.4 | bsz 141.8 | num_updates 16206 | best_bleu 19.27
2023-07-28 06:04:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16206 updates
2023-07-28 06:04:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 06:05:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 06:05:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt (epoch 11 @ 16206 updates, score 19.27) (writing took 19.711075639352202 seconds)
2023-07-28 06:05:15 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-07-28 06:05:15 | INFO | train | epoch 011 | loss 2.086 | trans_loss 4.746 | nll_loss 2.213 | w2v_ctc_loss 0.814 | task_loss 1.924 | contrastive_loss 0.141 | total 4138.65 | n_correct 2505.21 | ppl 4.64 | accuracy 60.532 | wps 11121.7 | ups 1.23 | wpb 9021 | bsz 333.4 | num_updates 16206 | lr 0.000111091 | gnorm 0.531 | clip 0 | loss_scale 64 | train_wall 1082 | gb_free 17.2 | wall 15022
2023-07-28 06:05:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 06:05:15 | INFO | fairseq.trainer | begin training epoch 12
2023-07-28 06:05:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 06:05:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-28 06:06:31 | INFO | train_inner | epoch 012:     95 / 1474 loss=2.096, trans_loss=5.122, nll_loss=2.346, w2v_ctc_loss=0.736, task_loss=2.022, contrastive_loss=0.129, total=4140.56, n_correct=2545.2, ppl=5.08, accuracy=61.47, wps=6757.3, ups=0.82, wpb=8281.1, bsz=313.2, num_updates=16300, lr=0.00011077, gnorm=0.55, clip=0, loss_scale=32, train_wall=70, gb_free=15.9, wall=15098
2023-07-28 06:07:40 | INFO | train_inner | epoch 012:    195 / 1474 loss=2.103, trans_loss=5.134, nll_loss=2.36, w2v_ctc_loss=0.745, task_loss=2.157, contrastive_loss=0.08, total=4126.87, n_correct=2525.45, ppl=5.14, accuracy=61.195, wps=11892, ups=1.44, wpb=8253.7, bsz=295.9, num_updates=16400, lr=0.000110432, gnorm=0.556, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=15167
2023-07-28 06:08:49 | INFO | train_inner | epoch 012:    295 / 1474 loss=2.096, trans_loss=5.132, nll_loss=2.359, w2v_ctc_loss=0.729, task_loss=1.965, contrastive_loss=0.113, total=4203.54, n_correct=2577.55, ppl=5.13, accuracy=61.319, wps=12118.9, ups=1.44, wpb=8407.1, bsz=321.1, num_updates=16500, lr=0.000110096, gnorm=0.552, clip=0, loss_scale=32, train_wall=69, gb_free=14.5, wall=15237
2023-07-28 06:10:00 | INFO | train_inner | epoch 012:    395 / 1474 loss=2.106, trans_loss=5.143, nll_loss=2.373, w2v_ctc_loss=0.744, task_loss=2.056, contrastive_loss=0.097, total=4149.28, n_correct=2538.38, ppl=5.18, accuracy=61.176, wps=11852.5, ups=1.43, wpb=8298.6, bsz=307.1, num_updates=16600, lr=0.000109764, gnorm=0.561, clip=0, loss_scale=32, train_wall=69, gb_free=15.1, wall=15307
2023-07-28 06:11:09 | INFO | train_inner | epoch 012:    495 / 1474 loss=2.112, trans_loss=5.154, nll_loss=2.389, w2v_ctc_loss=0.749, task_loss=2.118, contrastive_loss=0.102, total=4106.46, n_correct=2505.54, ppl=5.24, accuracy=61.015, wps=11757, ups=1.43, wpb=8212.9, bsz=301.2, num_updates=16700, lr=0.000109435, gnorm=0.556, clip=0, loss_scale=32, train_wall=69, gb_free=17.8, wall=15376
2023-07-28 06:12:20 | INFO | train_inner | epoch 012:    595 / 1474 loss=2.108, trans_loss=5.145, nll_loss=2.377, w2v_ctc_loss=0.742, task_loss=2.005, contrastive_loss=0.168, total=4190.91, n_correct=2567.09, ppl=5.19, accuracy=61.254, wps=11930.6, ups=1.42, wpb=8381.8, bsz=316.5, num_updates=16800, lr=0.000109109, gnorm=0.575, clip=0, loss_scale=32, train_wall=70, gb_free=15.8, wall=15447
2023-07-28 06:13:29 | INFO | train_inner | epoch 012:    695 / 1474 loss=2.105, trans_loss=5.143, nll_loss=2.375, w2v_ctc_loss=0.727, task_loss=1.93, contrastive_loss=0.256, total=4203.66, n_correct=2577.12, ppl=5.19, accuracy=61.307, wps=12078.6, ups=1.44, wpb=8407.3, bsz=324.4, num_updates=16900, lr=0.000108786, gnorm=0.559, clip=0, loss_scale=32, train_wall=69, gb_free=17.4, wall=15516
2023-07-28 06:14:39 | INFO | train_inner | epoch 012:    795 / 1474 loss=2.106, trans_loss=5.146, nll_loss=2.378, w2v_ctc_loss=0.746, task_loss=2.124, contrastive_loss=0.091, total=4095.72, n_correct=2504.94, ppl=5.2, accuracy=61.16, wps=11731.4, ups=1.43, wpb=8191.4, bsz=298.9, num_updates=17000, lr=0.000108465, gnorm=0.576, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=15586
2023-07-28 06:15:49 | INFO | train_inner | epoch 012:    895 / 1474 loss=2.113, trans_loss=5.154, nll_loss=2.388, w2v_ctc_loss=0.744, task_loss=2.154, contrastive_loss=0.145, total=4162.82, n_correct=2540.37, ppl=5.23, accuracy=61.025, wps=11915.8, ups=1.43, wpb=8325.6, bsz=305.4, num_updates=17100, lr=0.000108148, gnorm=0.562, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=15656
2023-07-28 06:16:58 | INFO | train_inner | epoch 012:    995 / 1474 loss=2.115, trans_loss=5.161, nll_loss=2.397, w2v_ctc_loss=0.747, task_loss=2.142, contrastive_loss=0.15, total=4117.63, n_correct=2507.56, ppl=5.27, accuracy=60.898, wps=11895, ups=1.44, wpb=8235.3, bsz=301.6, num_updates=17200, lr=0.000107833, gnorm=0.559, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=15725
2023-07-28 06:18:07 | INFO | train_inner | epoch 012:   1095 / 1474 loss=2.125, trans_loss=5.167, nll_loss=2.405, w2v_ctc_loss=0.754, task_loss=2.217, contrastive_loss=0.194, total=4046.48, n_correct=2458.62, ppl=5.3, accuracy=60.759, wps=11685.6, ups=1.44, wpb=8093, bsz=289.6, num_updates=17300, lr=0.000107521, gnorm=0.577, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=15795
2023-07-28 06:19:17 | INFO | train_inner | epoch 012:   1195 / 1474 loss=2.127, trans_loss=5.175, nll_loss=2.418, w2v_ctc_loss=0.759, task_loss=2.045, contrastive_loss=0.168, total=4201.13, n_correct=2543.32, ppl=5.34, accuracy=60.539, wps=12009.9, ups=1.43, wpb=8402.3, bsz=319.2, num_updates=17400, lr=0.000107211, gnorm=0.556, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=15865
2023-07-28 06:20:27 | INFO | train_inner | epoch 012:   1295 / 1474 loss=2.122, trans_loss=5.167, nll_loss=2.406, w2v_ctc_loss=0.764, task_loss=2.338, contrastive_loss=0.077, total=4070.27, n_correct=2471.68, ppl=5.3, accuracy=60.725, wps=11647.5, ups=1.43, wpb=8140.5, bsz=286.1, num_updates=17500, lr=0.000106904, gnorm=0.562, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=15934
2023-07-28 06:21:37 | INFO | train_inner | epoch 012:   1395 / 1474 loss=2.114, trans_loss=5.166, nll_loss=2.406, w2v_ctc_loss=0.737, task_loss=2.115, contrastive_loss=0.181, total=4139.63, n_correct=2519.22, ppl=5.3, accuracy=60.856, wps=11889.9, ups=1.44, wpb=8279.3, bsz=305.8, num_updates=17600, lr=0.0001066, gnorm=0.562, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=16004
2023-07-28 06:22:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 06:22:58 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.232 | trans_loss 5.616 | nll_loss 2.908 | w2v_ctc_loss 1.331 | task_loss 6.891 | contrastive_loss 0.268 | total 4003.4 | n_correct 2445.8 | ppl 7.5 | accuracy 61.093 | uer 17.816 | wer 19.619 | raw_wer 19.619 | bleu 20.09 | wps 1874.5 | wpb 4003.4 | bsz 141.8 | num_updates 17679 | best_bleu 20.09
2023-07-28 06:22:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17679 updates
2023-07-28 06:22:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 06:23:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 06:23:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt (epoch 12 @ 17679 updates, score 20.09) (writing took 20.009356431663036 seconds)
2023-07-28 06:23:18 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-07-28 06:23:18 | INFO | train | epoch 012 | loss 2.111 | trans_loss 5.152 | nll_loss 2.385 | w2v_ctc_loss 0.745 | task_loss 2.1 | contrastive_loss 0.137 | total 4138.61 | n_correct 2526.37 | ppl 5.22 | accuracy 61.044 | wps 11254.6 | ups 1.36 | wpb 8277.2 | bsz 305.7 | num_updates 17679 | lr 0.000106362 | gnorm 0.562 | clip 0 | loss_scale 32 | train_wall 1019 | gb_free 12.7 | wall 16105
2023-07-28 06:23:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 06:23:19 | INFO | fairseq.trainer | begin training epoch 13
2023-07-28 06:23:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 06:23:42 | INFO | train_inner | epoch 013:     21 / 1474 loss=2.115, trans_loss=5.165, nll_loss=2.403, w2v_ctc_loss=0.755, task_loss=2.186, contrastive_loss=0.087, total=4096.49, n_correct=2495.22, ppl=5.29, accuracy=60.911, wps=6562.2, ups=0.8, wpb=8193, bsz=295.4, num_updates=17700, lr=0.000106299, gnorm=0.562, clip=0, loss_scale=32, train_wall=69, gb_free=14.5, wall=16129
2023-07-28 06:24:52 | INFO | train_inner | epoch 013:    121 / 1474 loss=2.088, trans_loss=5.114, nll_loss=2.335, w2v_ctc_loss=0.731, task_loss=2.106, contrastive_loss=0.099, total=4160.97, n_correct=2568.47, ppl=5.04, accuracy=61.728, wps=11865.8, ups=1.43, wpb=8321.9, bsz=302.9, num_updates=17800, lr=0.000106, gnorm=0.561, clip=0, loss_scale=32, train_wall=70, gb_free=16.2, wall=16199
2023-07-28 06:26:02 | INFO | train_inner | epoch 013:    221 / 1474 loss=2.103, trans_loss=5.125, nll_loss=2.351, w2v_ctc_loss=0.726, task_loss=1.939, contrastive_loss=0.321, total=4212.08, n_correct=2589.36, ppl=5.1, accuracy=61.475, wps=11993.7, ups=1.42, wpb=8424.2, bsz=329.7, num_updates=17900, lr=0.000105703, gnorm=0.561, clip=0, loss_scale=32, train_wall=70, gb_free=14.6, wall=16269
2023-07-28 06:27:12 | INFO | train_inner | epoch 013:    321 / 1474 loss=2.086, trans_loss=5.115, nll_loss=2.336, w2v_ctc_loss=0.727, task_loss=2.183, contrastive_loss=0.082, total=4102.3, n_correct=2534.79, ppl=5.05, accuracy=61.789, wps=11824.3, ups=1.44, wpb=8204.6, bsz=294.1, num_updates=18000, lr=0.000105409, gnorm=0.574, clip=0, loss_scale=32, train_wall=69, gb_free=17.3, wall=16339
2023-07-28 06:27:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 06:27:34 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.239 | trans_loss 5.631 | nll_loss 2.923 | w2v_ctc_loss 1.319 | task_loss 6.9 | contrastive_loss 0.266 | total 4003.4 | n_correct 2438.3 | ppl 7.58 | accuracy 60.906 | uer 17.832 | wer 19.809 | raw_wer 19.809 | bleu 19.5 | wps 2290.1 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 20.09
2023-07-28 06:27:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-07-28 06:27:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_13_18000.pt
2023-07-28 06:27:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_13_18000.pt
2023-07-28 06:27:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.5) (writing took 16.956545321270823 seconds)
2023-07-28 06:29:02 | INFO | train_inner | epoch 013:    421 / 1474 loss=2.092, trans_loss=5.123, nll_loss=2.349, w2v_ctc_loss=0.733, task_loss=1.962, contrastive_loss=0.133, total=4177.29, n_correct=2577.11, ppl=5.09, accuracy=61.693, wps=7577.4, ups=0.91, wpb=8354.6, bsz=318.4, num_updates=18100, lr=0.000105118, gnorm=0.553, clip=0, loss_scale=32, train_wall=69, gb_free=17.5, wall=16449
2023-07-28 06:30:12 | INFO | train_inner | epoch 013:    521 / 1474 loss=2.098, trans_loss=5.131, nll_loss=2.358, w2v_ctc_loss=0.734, task_loss=2.037, contrastive_loss=0.172, total=4201.22, n_correct=2581.02, ppl=5.13, accuracy=61.435, wps=11964.3, ups=1.42, wpb=8402.4, bsz=319, num_updates=18200, lr=0.000104828, gnorm=0.56, clip=0, loss_scale=32, train_wall=70, gb_free=12.8, wall=16519
2023-07-28 06:31:21 | INFO | train_inner | epoch 013:    621 / 1474 loss=2.086, trans_loss=5.125, nll_loss=2.351, w2v_ctc_loss=0.728, task_loss=2.034, contrastive_loss=0.08, total=4161.98, n_correct=2564.44, ppl=5.1, accuracy=61.616, wps=12054.6, ups=1.45, wpb=8324, bsz=308.3, num_updates=18300, lr=0.000104542, gnorm=0.559, clip=0, loss_scale=64, train_wall=68, gb_free=15.8, wall=16588
2023-07-28 06:32:30 | INFO | train_inner | epoch 013:    721 / 1474 loss=2.107, trans_loss=5.14, nll_loss=2.369, w2v_ctc_loss=0.755, task_loss=2.334, contrastive_loss=0.077, total=4096.76, n_correct=2506.31, ppl=5.17, accuracy=61.178, wps=11863.4, ups=1.45, wpb=8193.5, bsz=284.6, num_updates=18400, lr=0.000104257, gnorm=0.562, clip=0, loss_scale=64, train_wall=68, gb_free=16.6, wall=16657
2023-07-28 06:33:40 | INFO | train_inner | epoch 013:    821 / 1474 loss=2.101, trans_loss=5.137, nll_loss=2.367, w2v_ctc_loss=0.736, task_loss=2.12, contrastive_loss=0.131, total=4121.73, n_correct=2527.96, ppl=5.16, accuracy=61.332, wps=11825.1, ups=1.43, wpb=8243.5, bsz=306.7, num_updates=18500, lr=0.000103975, gnorm=0.573, clip=0, loss_scale=64, train_wall=69, gb_free=14.8, wall=16727
2023-07-28 06:34:49 | INFO | train_inner | epoch 013:    921 / 1474 loss=2.1, trans_loss=5.14, nll_loss=2.371, w2v_ctc_loss=0.74, task_loss=2.146, contrastive_loss=0.089, total=4107.01, n_correct=2519.32, ppl=5.17, accuracy=61.342, wps=11908, ups=1.45, wpb=8214, bsz=296.5, num_updates=18600, lr=0.000103695, gnorm=0.576, clip=0, loss_scale=64, train_wall=68, gb_free=15.9, wall=16796
2023-07-28 06:35:58 | INFO | train_inner | epoch 013:   1021 / 1474 loss=2.108, trans_loss=5.145, nll_loss=2.377, w2v_ctc_loss=0.745, task_loss=2.213, contrastive_loss=0.139, total=4081.02, n_correct=2494.36, ppl=5.19, accuracy=61.121, wps=11740.3, ups=1.44, wpb=8162, bsz=293.4, num_updates=18700, lr=0.000103418, gnorm=0.578, clip=0, loss_scale=64, train_wall=69, gb_free=16.2, wall=16866
2023-07-28 06:37:08 | INFO | train_inner | epoch 013:   1121 / 1474 loss=2.093, trans_loss=5.131, nll_loss=2.36, w2v_ctc_loss=0.732, task_loss=2.07, contrastive_loss=0.121, total=4105.62, n_correct=2528.81, ppl=5.13, accuracy=61.594, wps=11837.8, ups=1.44, wpb=8211.2, bsz=305.9, num_updates=18800, lr=0.000103142, gnorm=0.559, clip=0, loss_scale=64, train_wall=69, gb_free=16.7, wall=16935
2023-07-28 06:38:17 | INFO | train_inner | epoch 013:   1221 / 1474 loss=2.103, trans_loss=5.147, nll_loss=2.381, w2v_ctc_loss=0.745, task_loss=2.232, contrastive_loss=0.08, total=4110.35, n_correct=2518.14, ppl=5.21, accuracy=61.263, wps=11827.7, ups=1.44, wpb=8220.7, bsz=295.1, num_updates=18900, lr=0.000102869, gnorm=0.568, clip=0, loss_scale=64, train_wall=69, gb_free=14.8, wall=17004
2023-07-28 06:39:27 | INFO | train_inner | epoch 013:   1321 / 1474 loss=2.098, trans_loss=5.132, nll_loss=2.363, w2v_ctc_loss=0.734, task_loss=2.068, contrastive_loss=0.178, total=4112.2, n_correct=2535.77, ppl=5.14, accuracy=61.665, wps=11854.8, ups=1.44, wpb=8224.4, bsz=308.2, num_updates=19000, lr=0.000102598, gnorm=0.565, clip=0, loss_scale=64, train_wall=69, gb_free=17.6, wall=17074
2023-07-28 06:40:36 | INFO | train_inner | epoch 013:   1421 / 1474 loss=2.104, trans_loss=5.146, nll_loss=2.38, w2v_ctc_loss=0.731, task_loss=2.053, contrastive_loss=0.192, total=4180.88, n_correct=2563.93, ppl=5.2, accuracy=61.325, wps=12007.5, ups=1.44, wpb=8361.8, bsz=312.2, num_updates=19100, lr=0.000102329, gnorm=0.558, clip=0, loss_scale=64, train_wall=69, gb_free=15.2, wall=17143
2023-07-28 06:41:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 06:41:36 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.23 | trans_loss 5.615 | nll_loss 2.904 | w2v_ctc_loss 1.326 | task_loss 6.872 | contrastive_loss 0.276 | total 4003.4 | n_correct 2440.3 | ppl 7.49 | accuracy 60.956 | uer 17.846 | wer 19.611 | raw_wer 19.611 | bleu 19.27 | wps 2221.6 | wpb 4003.4 | bsz 141.8 | num_updates 19153 | best_bleu 20.09
2023-07-28 06:41:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19153 updates
2023-07-28 06:41:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.2704.pt
2023-07-28 06:41:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.2704.pt
2023-07-28 06:41:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.2704.pt (epoch 13 @ 19153 updates, score 19.27) (writing took 11.745775073766708 seconds)
2023-07-28 06:41:48 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-07-28 06:41:48 | INFO | train | epoch 013 | loss 2.097 | trans_loss 5.132 | nll_loss 2.36 | w2v_ctc_loss 0.736 | task_loss 2.098 | contrastive_loss 0.136 | total 4138.65 | n_correct 2544.57 | ppl 5.13 | accuracy 61.483 | wps 10991.1 | ups 1.33 | wpb 8277.3 | bsz 305.7 | num_updates 19153 | lr 0.000102187 | gnorm 0.564 | clip 0 | loss_scale 64 | train_wall 1017 | gb_free 17.6 | wall 17215
2023-07-28 06:41:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 06:41:49 | INFO | fairseq.trainer | begin training epoch 14
2023-07-28 06:41:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 06:42:29 | INFO | train_inner | epoch 014:     47 / 1474 loss=2.073, trans_loss=5.1, nll_loss=2.321, w2v_ctc_loss=0.721, task_loss=1.921, contrastive_loss=0.096, total=4176.2, n_correct=2601.3, ppl=5, accuracy=62.289, wps=7389.2, ups=0.88, wpb=8352.4, bsz=322.3, num_updates=19200, lr=0.000102062, gnorm=0.552, clip=0, loss_scale=64, train_wall=69, gb_free=10.5, wall=17256
2023-07-28 06:43:38 | INFO | train_inner | epoch 014:    147 / 1474 loss=2.072, trans_loss=5.089, nll_loss=2.305, w2v_ctc_loss=0.724, task_loss=2.119, contrastive_loss=0.078, total=4080.86, n_correct=2547.93, ppl=4.94, accuracy=62.436, wps=11829.9, ups=1.45, wpb=8161.7, bsz=299.6, num_updates=19300, lr=0.000101797, gnorm=0.55, clip=0, loss_scale=64, train_wall=68, gb_free=16.9, wall=17325
2023-07-28 06:44:49 | INFO | train_inner | epoch 014:    247 / 1474 loss=2.088, trans_loss=5.107, nll_loss=2.328, w2v_ctc_loss=0.725, task_loss=2.207, contrastive_loss=0.178, total=4106.97, n_correct=2546.5, ppl=5.02, accuracy=62.004, wps=11697.7, ups=1.42, wpb=8213.9, bsz=293.3, num_updates=19400, lr=0.000101535, gnorm=0.558, clip=0, loss_scale=64, train_wall=70, gb_free=12.2, wall=17396
2023-07-28 06:45:58 | INFO | train_inner | epoch 014:    347 / 1474 loss=2.073, trans_loss=5.097, nll_loss=2.316, w2v_ctc_loss=0.72, task_loss=1.928, contrastive_loss=0.116, total=4179.8, n_correct=2604.19, ppl=4.98, accuracy=62.304, wps=12128.5, ups=1.45, wpb=8359.6, bsz=322.5, num_updates=19500, lr=0.000101274, gnorm=0.564, clip=0, loss_scale=64, train_wall=68, gb_free=17.3, wall=17465
2023-07-28 06:47:07 | INFO | train_inner | epoch 014:    447 / 1474 loss=2.08, trans_loss=5.113, nll_loss=2.336, w2v_ctc_loss=0.721, task_loss=2.168, contrastive_loss=0.072, total=4120.38, n_correct=2549.55, ppl=5.05, accuracy=61.877, wps=11901.4, ups=1.44, wpb=8240.8, bsz=296.3, num_updates=19600, lr=0.000101015, gnorm=0.559, clip=0, loss_scale=64, train_wall=69, gb_free=17.1, wall=17534
2023-07-28 06:48:17 | INFO | train_inner | epoch 014:    547 / 1474 loss=2.094, trans_loss=5.117, nll_loss=2.34, w2v_ctc_loss=0.744, task_loss=2.224, contrastive_loss=0.111, total=4089.86, n_correct=2524.17, ppl=5.06, accuracy=61.718, wps=11676.7, ups=1.43, wpb=8179.7, bsz=295.5, num_updates=19700, lr=0.000100759, gnorm=0.566, clip=0, loss_scale=64, train_wall=70, gb_free=11.9, wall=17604
2023-07-28 06:49:27 | INFO | train_inner | epoch 014:    647 / 1474 loss=2.087, trans_loss=5.114, nll_loss=2.337, w2v_ctc_loss=0.726, task_loss=2.099, contrastive_loss=0.153, total=4158.94, n_correct=2572.07, ppl=5.05, accuracy=61.844, wps=11866.7, ups=1.43, wpb=8317.9, bsz=306.7, num_updates=19800, lr=0.000100504, gnorm=0.562, clip=0, loss_scale=64, train_wall=70, gb_free=16.1, wall=17674
2023-07-28 06:50:36 | INFO | train_inner | epoch 014:    747 / 1474 loss=2.074, trans_loss=5.104, nll_loss=2.325, w2v_ctc_loss=0.72, task_loss=2.034, contrastive_loss=0.084, total=4150.03, n_correct=2580.75, ppl=5.01, accuracy=62.186, wps=11937.2, ups=1.44, wpb=8300.1, bsz=310.4, num_updates=19900, lr=0.000100251, gnorm=0.556, clip=0, loss_scale=64, train_wall=69, gb_free=15.5, wall=17744
2023-07-28 06:51:46 | INFO | train_inner | epoch 014:    847 / 1474 loss=2.086, trans_loss=5.108, nll_loss=2.332, w2v_ctc_loss=0.723, task_loss=2.005, contrastive_loss=0.195, total=4162.8, n_correct=2581.49, ppl=5.04, accuracy=62.013, wps=11930.9, ups=1.43, wpb=8325.6, bsz=317.2, num_updates=20000, lr=0.0001, gnorm=0.554, clip=0, loss_scale=64, train_wall=69, gb_free=17.1, wall=17813
2023-07-28 06:51:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 06:52:10 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.225 | trans_loss 5.611 | nll_loss 2.9 | w2v_ctc_loss 1.322 | task_loss 6.879 | contrastive_loss 0.264 | total 4003.4 | n_correct 2447.6 | ppl 7.46 | accuracy 61.138 | uer 17.862 | wer 19.708 | raw_wer 19.708 | bleu 19.24 | wps 2100 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 20.09
2023-07-28 06:52:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-07-28 06:52:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_14_20000.pt
2023-07-28 06:52:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_14_20000.pt
2023-07-28 06:52:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.24) (writing took 16.812785979360342 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:0')
2023-07-28 06:53:38 | INFO | train_inner | epoch 014:    947 / 1474 loss=2.083, trans_loss=5.116, nll_loss=2.341, w2v_ctc_loss=0.728, task_loss=2.128, contrastive_loss=0.086, total=4159.46, n_correct=2572.06, ppl=5.07, accuracy=61.836, wps=7474.3, ups=0.9, wpb=8318.9, bsz=306.7, num_updates=20100, lr=9.97509e-05, gnorm=0.567, clip=0, loss_scale=64, train_wall=70, gb_free=15.3, wall=17925
2023-07-28 06:54:48 | INFO | train_inner | epoch 014:   1047 / 1474 loss=2.087, trans_loss=5.121, nll_loss=2.348, w2v_ctc_loss=0.719, task_loss=2.088, contrastive_loss=0.151, total=4155.93, n_correct=2567.22, ppl=5.09, accuracy=61.772, wps=11877.2, ups=1.43, wpb=8311.9, bsz=305.9, num_updates=20200, lr=9.95037e-05, gnorm=0.559, clip=0, loss_scale=64, train_wall=69, gb_free=16.3, wall=17995
2023-07-28 06:55:57 | INFO | train_inner | epoch 014:   1147 / 1474 loss=2.104, trans_loss=5.119, nll_loss=2.346, w2v_ctc_loss=0.731, task_loss=1.97, contrastive_loss=0.379, total=4228.09, n_correct=2606.08, ppl=5.08, accuracy=61.637, wps=12134.2, ups=1.43, wpb=8456.2, bsz=326.3, num_updates=20300, lr=9.92583e-05, gnorm=0.561, clip=0, loss_scale=64, train_wall=69, gb_free=17.6, wall=18064
2023-07-28 06:57:07 | INFO | train_inner | epoch 014:   1247 / 1474 loss=2.102, trans_loss=5.14, nll_loss=2.371, w2v_ctc_loss=0.747, task_loss=2.445, contrastive_loss=0.067, total=4027.71, n_correct=2473, ppl=5.17, accuracy=61.4, wps=11492.1, ups=1.43, wpb=8055.4, bsz=273.6, num_updates=20400, lr=9.90148e-05, gnorm=0.574, clip=0, loss_scale=128, train_wall=70, gb_free=16.5, wall=18134
2023-07-28 06:57:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-28 06:58:17 | INFO | train_inner | epoch 014:   1348 / 1474 loss=2.082, trans_loss=5.125, nll_loss=2.354, w2v_ctc_loss=0.722, task_loss=1.98, contrastive_loss=0.085, total=4212.38, n_correct=2601.34, ppl=5.11, accuracy=61.755, wps=12039.8, ups=1.43, wpb=8424.8, bsz=318.9, num_updates=20500, lr=9.8773e-05, gnorm=0.57, clip=0, loss_scale=64, train_wall=69, gb_free=16.1, wall=18204
2023-07-28 06:58:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-28 06:59:27 | INFO | train_inner | epoch 014:   1449 / 1474 loss=2.09, trans_loss=5.131, nll_loss=2.361, w2v_ctc_loss=0.727, task_loss=2.111, contrastive_loss=0.123, total=4117.41, n_correct=2542.28, ppl=5.14, accuracy=61.745, wps=11810.8, ups=1.43, wpb=8234.8, bsz=301.9, num_updates=20600, lr=9.85329e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=18274
2023-07-28 06:59:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:2')
2023-07-28 07:00:07 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.229 | trans_loss 5.606 | nll_loss 2.901 | w2v_ctc_loss 1.346 | task_loss 6.922 | contrastive_loss 0.264 | total 4003.4 | n_correct 2453.7 | ppl 7.47 | accuracy 61.29 | uer 17.803 | wer 19.645 | raw_wer 19.645 | bleu 19.32 | wps 1982.8 | wpb 4003.4 | bsz 141.8 | num_updates 20625 | best_bleu 20.09
2023-07-28 07:00:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20625 updates
2023-07-28 07:00:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.3209.pt
2023-07-28 07:00:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.3209.pt
2023-07-28 07:00:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.3209.pt (epoch 14 @ 20625 updates, score 19.32) (writing took 15.80472794175148 seconds)
2023-07-28 07:00:23 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-07-28 07:00:23 | INFO | train | epoch 014 | loss 2.085 | trans_loss 5.114 | nll_loss 2.338 | w2v_ctc_loss 0.727 | task_loss 2.099 | contrastive_loss 0.133 | total 4138.35 | n_correct 2561.91 | ppl 5.06 | accuracy 61.906 | wps 10926.7 | ups 1.32 | wpb 8276.7 | bsz 305.6 | num_updates 20625 | lr 9.84732e-05 | gnorm 0.562 | clip 0 | loss_scale 32 | train_wall 1018 | gb_free 16.4 | wall 18330
2023-07-28 07:00:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 07:00:24 | INFO | fairseq.trainer | begin training epoch 15
2023-07-28 07:00:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 07:01:25 | INFO | train_inner | epoch 015:     75 / 1474 loss=2.08, trans_loss=5.101, nll_loss=2.322, w2v_ctc_loss=0.72, task_loss=2.106, contrastive_loss=0.171, total=4090.99, n_correct=2541.66, ppl=5, accuracy=62.128, wps=6948.7, ups=0.85, wpb=8182, bsz=300.8, num_updates=20700, lr=9.82946e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=18392
2023-07-28 07:02:35 | INFO | train_inner | epoch 015:    175 / 1474 loss=2.073, trans_loss=5.09, nll_loss=2.305, w2v_ctc_loss=0.725, task_loss=2.177, contrastive_loss=0.083, total=4115.56, n_correct=2565.5, ppl=4.94, accuracy=62.337, wps=11770.1, ups=1.43, wpb=8231.1, bsz=298.5, num_updates=20800, lr=9.80581e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=18462
2023-07-28 07:03:44 | INFO | train_inner | epoch 015:    275 / 1474 loss=2.062, trans_loss=5.089, nll_loss=2.305, w2v_ctc_loss=0.708, task_loss=2.042, contrastive_loss=0.071, total=4182.19, n_correct=2616.7, ppl=4.94, accuracy=62.568, wps=12130.8, ups=1.45, wpb=8364.4, bsz=310.5, num_updates=20900, lr=9.78232e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=18531
2023-07-28 07:04:53 | INFO | train_inner | epoch 015:    375 / 1474 loss=2.067, trans_loss=5.084, nll_loss=2.299, w2v_ctc_loss=0.714, task_loss=2.095, contrastive_loss=0.101, total=4172.52, n_correct=2601.95, ppl=4.92, accuracy=62.359, wps=12024.8, ups=1.44, wpb=8345, bsz=307.7, num_updates=21000, lr=9.759e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=18600
2023-07-28 07:06:03 | INFO | train_inner | epoch 015:    475 / 1474 loss=2.076, trans_loss=5.094, nll_loss=2.312, w2v_ctc_loss=0.707, task_loss=2.195, contrastive_loss=0.186, total=4076.84, n_correct=2538.32, ppl=4.97, accuracy=62.262, wps=11697.3, ups=1.43, wpb=8153.7, bsz=293.4, num_updates=21100, lr=9.73585e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=18670
2023-07-28 07:07:12 | INFO | train_inner | epoch 015:    575 / 1474 loss=2.071, trans_loss=5.093, nll_loss=2.31, w2v_ctc_loss=0.719, task_loss=2.141, contrastive_loss=0.101, total=4156.05, n_correct=2593.79, ppl=4.96, accuracy=62.41, wps=12080.4, ups=1.45, wpb=8312.1, bsz=302.8, num_updates=21200, lr=9.71286e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=68, gb_free=11.6, wall=18739
2023-07-28 07:08:22 | INFO | train_inner | epoch 015:    675 / 1474 loss=2.08, trans_loss=5.096, nll_loss=2.315, w2v_ctc_loss=0.724, task_loss=2.153, contrastive_loss=0.148, total=4118.87, n_correct=2565.08, ppl=4.98, accuracy=62.276, wps=11721.1, ups=1.42, wpb=8237.7, bsz=303, num_updates=21300, lr=9.69003e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=70, gb_free=16.9, wall=18809
2023-07-28 07:09:32 | INFO | train_inner | epoch 015:    775 / 1474 loss=2.073, trans_loss=5.102, nll_loss=2.322, w2v_ctc_loss=0.72, task_loss=2.118, contrastive_loss=0.084, total=4176.64, n_correct=2599.55, ppl=5, accuracy=62.24, wps=11975.8, ups=1.43, wpb=8353.3, bsz=305.3, num_updates=21400, lr=9.66736e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=69, gb_free=13.9, wall=18879
2023-07-28 07:10:41 | INFO | train_inner | epoch 015:    875 / 1474 loss=2.082, trans_loss=5.109, nll_loss=2.333, w2v_ctc_loss=0.73, task_loss=2.266, contrastive_loss=0.078, total=4056.99, n_correct=2516.78, ppl=5.04, accuracy=62.036, wps=11779.6, ups=1.45, wpb=8114, bsz=288, num_updates=21500, lr=9.64486e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=18948
2023-07-28 07:11:49 | INFO | train_inner | epoch 015:    975 / 1474 loss=2.075, trans_loss=5.101, nll_loss=2.322, w2v_ctc_loss=0.713, task_loss=2.088, contrastive_loss=0.162, total=4134.44, n_correct=2574.97, ppl=5, accuracy=62.281, wps=12013.5, ups=1.45, wpb=8268.9, bsz=304.8, num_updates=21600, lr=9.6225e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=19016
2023-07-28 07:13:00 | INFO | train_inner | epoch 015:   1075 / 1474 loss=2.09, trans_loss=5.109, nll_loss=2.334, w2v_ctc_loss=0.719, task_loss=1.974, contrastive_loss=0.323, total=4185.02, n_correct=2594.07, ppl=5.04, accuracy=61.985, wps=11854.2, ups=1.42, wpb=8370, bsz=324.2, num_updates=21700, lr=9.60031e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=70, gb_free=16.6, wall=19087
2023-07-28 07:14:10 | INFO | train_inner | epoch 015:   1175 / 1474 loss=2.06, trans_loss=5.096, nll_loss=2.318, w2v_ctc_loss=0.697, task_loss=1.872, contrastive_loss=0.127, total=4187.68, n_correct=2622.28, ppl=4.99, accuracy=62.619, wps=12041.5, ups=1.44, wpb=8375.4, bsz=329.7, num_updates=21800, lr=9.57826e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=19157
2023-07-28 07:15:19 | INFO | train_inner | epoch 015:   1275 / 1474 loss=2.079, trans_loss=5.107, nll_loss=2.33, w2v_ctc_loss=0.73, task_loss=2.166, contrastive_loss=0.082, total=4141.6, n_correct=2569.98, ppl=5.03, accuracy=62.053, wps=11934.1, ups=1.44, wpb=8283.2, bsz=301.1, num_updates=21900, lr=9.55637e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=69, gb_free=13.4, wall=19226
2023-07-28 07:16:29 | INFO | train_inner | epoch 015:   1375 / 1474 loss=2.071, trans_loss=5.106, nll_loss=2.328, w2v_ctc_loss=0.714, task_loss=2.176, contrastive_loss=0.066, total=4099.6, n_correct=2551.44, ppl=5.02, accuracy=62.236, wps=11755.4, ups=1.43, wpb=8199.2, bsz=293.2, num_updates=22000, lr=9.53463e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=69, gb_free=14.3, wall=19296
2023-07-28 07:16:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 07:16:52 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.207 | trans_loss 5.607 | nll_loss 2.892 | w2v_ctc_loss 1.272 | task_loss 6.874 | contrastive_loss 0.266 | total 4003.4 | n_correct 2453.6 | ppl 7.42 | accuracy 61.288 | uer 17.689 | wer 19.503 | raw_wer 19.503 | bleu 19.56 | wps 2104.8 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 20.09
2023-07-28 07:16:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-07-28 07:16:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_15_22000.pt
2023-07-28 07:16:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_15_22000.pt
2023-07-28 07:17:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.56) (writing took 15.904368311166763 seconds)
2023-07-28 07:18:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 07:18:43 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.214 | trans_loss 5.598 | nll_loss 2.884 | w2v_ctc_loss 1.315 | task_loss 6.925 | contrastive_loss 0.262 | total 4003.4 | n_correct 2460.6 | ppl 7.38 | accuracy 61.463 | uer 17.604 | wer 19.451 | raw_wer 19.451 | bleu 19.81 | wps 2105.8 | wpb 4003.4 | bsz 141.8 | num_updates 22099 | best_bleu 20.09
2023-07-28 07:18:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22099 updates
2023-07-28 07:18:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.8106.pt
2023-07-28 07:18:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.8106.pt
2023-07-28 07:18:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.8106.pt (epoch 15 @ 22099 updates, score 19.81) (writing took 11.781613258644938 seconds)
2023-07-28 07:18:56 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-07-28 07:18:56 | INFO | train | epoch 015 | loss 2.074 | trans_loss 5.098 | nll_loss 2.318 | w2v_ctc_loss 0.717 | task_loss 2.099 | contrastive_loss 0.131 | total 4138.65 | n_correct 2577.3 | ppl 4.99 | accuracy 62.274 | wps 10970.3 | ups 1.33 | wpb 8277.3 | bsz 305.7 | num_updates 22099 | lr 9.51325e-05 | gnorm 0.56 | clip 0 | loss_scale 32 | train_wall 1018 | gb_free 16.9 | wall 19443
2023-07-28 07:18:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 07:18:56 | INFO | fairseq.trainer | begin training epoch 16
2023-07-28 07:18:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 07:19:05 | INFO | train_inner | epoch 016:      1 / 1474 loss=2.081, trans_loss=5.112, nll_loss=2.339, w2v_ctc_loss=0.72, task_loss=2.011, contrastive_loss=0.16, total=4149.9, n_correct=2573.54, ppl=5.06, accuracy=62.015, wps=5300.4, ups=0.64, wpb=8299.8, bsz=316.3, num_updates=22100, lr=9.51303e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=71, gb_free=17.4, wall=19452
2023-07-28 07:20:15 | INFO | train_inner | epoch 016:    101 / 1474 loss=2.053, trans_loss=5.066, nll_loss=2.277, w2v_ctc_loss=0.706, task_loss=2.022, contrastive_loss=0.102, total=4118.73, n_correct=2595.89, ppl=4.85, accuracy=63.026, wps=11883.6, ups=1.44, wpb=8237.5, bsz=314, num_updates=22200, lr=9.49158e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=19522
2023-07-28 07:21:25 | INFO | train_inner | epoch 016:    201 / 1474 loss=2.051, trans_loss=5.066, nll_loss=2.275, w2v_ctc_loss=0.699, task_loss=2.156, contrastive_loss=0.074, total=4106.45, n_correct=2586.99, ppl=4.84, accuracy=62.998, wps=11684.1, ups=1.42, wpb=8212.9, bsz=297.4, num_updates=22300, lr=9.47027e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=70, gb_free=16.4, wall=19592
2023-07-28 07:22:35 | INFO | train_inner | epoch 016:    301 / 1474 loss=2.064, trans_loss=5.074, nll_loss=2.287, w2v_ctc_loss=0.71, task_loss=2.071, contrastive_loss=0.15, total=4169.65, n_correct=2615.2, ppl=4.88, accuracy=62.72, wps=11904.3, ups=1.43, wpb=8339.3, bsz=309.9, num_updates=22400, lr=9.44911e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=69, gb_free=10.6, wall=19662
2023-07-28 07:23:44 | INFO | train_inner | epoch 016:    401 / 1474 loss=2.071, trans_loss=5.079, nll_loss=2.291, w2v_ctc_loss=0.717, task_loss=2.252, contrastive_loss=0.161, total=4063.79, n_correct=2540.88, ppl=4.9, accuracy=62.525, wps=11732.4, ups=1.44, wpb=8127.6, bsz=286.5, num_updates=22500, lr=9.42809e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=69, gb_free=12.6, wall=19731
2023-07-28 07:24:54 | INFO | train_inner | epoch 016:    501 / 1474 loss=2.056, trans_loss=5.073, nll_loss=2.287, w2v_ctc_loss=0.705, task_loss=2.019, contrastive_loss=0.108, total=4179.53, n_correct=2630.88, ppl=4.88, accuracy=62.947, wps=11903.3, ups=1.42, wpb=8359.1, bsz=319.5, num_updates=22600, lr=9.40721e-05, gnorm=0.567, clip=0, loss_scale=64, train_wall=70, gb_free=17.7, wall=19802
2023-07-28 07:26:04 | INFO | train_inner | epoch 016:    601 / 1474 loss=2.059, trans_loss=5.08, nll_loss=2.295, w2v_ctc_loss=0.706, task_loss=2.114, contrastive_loss=0.068, total=4121.37, n_correct=2583.04, ppl=4.91, accuracy=62.674, wps=11875.7, ups=1.44, wpb=8242.7, bsz=297.5, num_updates=22700, lr=9.38647e-05, gnorm=0.561, clip=0, loss_scale=64, train_wall=69, gb_free=17.8, wall=19871
2023-07-28 07:27:13 | INFO | train_inner | epoch 016:    701 / 1474 loss=2.061, trans_loss=5.084, nll_loss=2.3, w2v_ctc_loss=0.711, task_loss=2.146, contrastive_loss=0.07, total=4099.17, n_correct=2569.33, ppl=4.92, accuracy=62.679, wps=11849.2, ups=1.45, wpb=8198.3, bsz=297.5, num_updates=22800, lr=9.36586e-05, gnorm=0.571, clip=0, loss_scale=64, train_wall=69, gb_free=16.7, wall=19940
2023-07-28 07:28:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-28 07:28:23 | INFO | train_inner | epoch 016:    802 / 1474 loss=2.06, trans_loss=5.084, nll_loss=2.3, w2v_ctc_loss=0.698, task_loss=2.004, contrastive_loss=0.133, total=4180.48, n_correct=2620.13, ppl=4.92, accuracy=62.675, wps=11908, ups=1.42, wpb=8361, bsz=312.7, num_updates=22900, lr=9.34539e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=70, gb_free=17.8, wall=20010
2023-07-28 07:29:33 | INFO | train_inner | epoch 016:    902 / 1474 loss=2.062, trans_loss=5.082, nll_loss=2.299, w2v_ctc_loss=0.706, task_loss=2.067, contrastive_loss=0.126, total=4150.23, n_correct=2603.99, ppl=4.92, accuracy=62.743, wps=11872.2, ups=1.43, wpb=8300.5, bsz=306.5, num_updates=23000, lr=9.32505e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=69, gb_free=12, wall=20080
2023-07-28 07:30:43 | INFO | train_inner | epoch 016:   1002 / 1474 loss=2.075, trans_loss=5.098, nll_loss=2.318, w2v_ctc_loss=0.721, task_loss=2.162, contrastive_loss=0.125, total=4116.59, n_correct=2564.57, ppl=4.99, accuracy=62.298, wps=11752.8, ups=1.43, wpb=8233.2, bsz=300.6, num_updates=23100, lr=9.30484e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=70, gb_free=16.8, wall=20150
2023-07-28 07:31:53 | INFO | train_inner | epoch 016:   1102 / 1474 loss=2.077, trans_loss=5.102, nll_loss=2.324, w2v_ctc_loss=0.725, task_loss=2.225, contrastive_loss=0.101, total=4112.71, n_correct=2559.48, ppl=5.01, accuracy=62.233, wps=11728.3, ups=1.43, wpb=8225.4, bsz=295.7, num_updates=23200, lr=9.28477e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=70, gb_free=12.1, wall=20221
2023-07-28 07:33:04 | INFO | train_inner | epoch 016:   1202 / 1474 loss=2.067, trans_loss=5.091, nll_loss=2.31, w2v_ctc_loss=0.698, task_loss=2.128, contrastive_loss=0.194, total=4161.11, n_correct=2599.78, ppl=4.96, accuracy=62.478, wps=11746.6, ups=1.41, wpb=8322.2, bsz=308.2, num_updates=23300, lr=9.26482e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=70, gb_free=15.7, wall=20291
2023-07-28 07:34:14 | INFO | train_inner | epoch 016:   1302 / 1474 loss=2.073, trans_loss=5.094, nll_loss=2.314, w2v_ctc_loss=0.718, task_loss=2.066, contrastive_loss=0.175, total=4149.14, n_correct=2594.29, ppl=4.97, accuracy=62.526, wps=11895.6, ups=1.43, wpb=8298.3, bsz=311.9, num_updates=23400, lr=9.245e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=69, gb_free=11.2, wall=20361
2023-07-28 07:35:24 | INFO | train_inner | epoch 016:   1402 / 1474 loss=2.066, trans_loss=5.096, nll_loss=2.318, w2v_ctc_loss=0.713, task_loss=1.991, contrastive_loss=0.105, total=4200.01, n_correct=2623.43, ppl=4.99, accuracy=62.462, wps=12004.6, ups=1.43, wpb=8400, bsz=322.2, num_updates=23500, lr=9.22531e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=69, gb_free=16.9, wall=20431
2023-07-28 07:36:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 07:36:38 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.206 | trans_loss 5.593 | nll_loss 2.879 | w2v_ctc_loss 1.303 | task_loss 6.909 | contrastive_loss 0.252 | total 4003.4 | n_correct 2468.3 | ppl 7.36 | accuracy 61.655 | uer 17.373 | wer 19.071 | raw_wer 19.071 | bleu 19.97 | wps 2138.8 | wpb 4003.4 | bsz 141.8 | num_updates 23572 | best_bleu 20.09
2023-07-28 07:36:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23572 updates
2023-07-28 07:36:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.9702.pt
2023-07-28 07:36:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.9702.pt
2023-07-28 07:36:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.9702.pt (epoch 16 @ 23572 updates, score 19.97) (writing took 11.20714477263391 seconds)
2023-07-28 07:36:50 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-07-28 07:36:50 | INFO | train | epoch 016 | loss 2.064 | trans_loss 5.084 | nll_loss 2.3 | w2v_ctc_loss 0.709 | task_loss 2.099 | contrastive_loss 0.13 | total 4138.57 | n_correct 2592.14 | ppl 4.93 | accuracy 62.634 | wps 11346.9 | ups 1.37 | wpb 8277.1 | bsz 305.7 | num_updates 23572 | lr 9.21121e-05 | gnorm 0.566 | clip 0 | loss_scale 32 | train_wall 1021 | gb_free 15.4 | wall 20517
2023-07-28 07:36:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 07:36:50 | INFO | fairseq.trainer | begin training epoch 17
2023-07-28 07:36:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 07:37:18 | INFO | train_inner | epoch 017:     28 / 1474 loss=2.067, trans_loss=5.078, nll_loss=2.292, w2v_ctc_loss=0.703, task_loss=2.149, contrastive_loss=0.237, total=4141.79, n_correct=2596.88, ppl=4.9, accuracy=62.699, wps=7252.4, ups=0.88, wpb=8283.6, bsz=301.5, num_updates=23600, lr=9.20575e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=20545
2023-07-28 07:38:28 | INFO | train_inner | epoch 017:    128 / 1474 loss=2.051, trans_loss=5.055, nll_loss=2.261, w2v_ctc_loss=0.708, task_loss=2.167, contrastive_loss=0.074, total=4110.88, n_correct=2594.51, ppl=4.79, accuracy=63.113, wps=11793.6, ups=1.43, wpb=8221.8, bsz=295.4, num_updates=23700, lr=9.1863e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=20615
2023-07-28 07:39:38 | INFO | train_inner | epoch 017:    228 / 1474 loss=2.054, trans_loss=5.055, nll_loss=2.263, w2v_ctc_loss=0.69, task_loss=1.969, contrastive_loss=0.238, total=4171.95, n_correct=2634.57, ppl=4.8, accuracy=63.15, wps=11920.6, ups=1.43, wpb=8343.9, bsz=320.4, num_updates=23800, lr=9.16698e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=20685
2023-07-28 07:40:47 | INFO | train_inner | epoch 017:    328 / 1474 loss=2.058, trans_loss=5.062, nll_loss=2.272, w2v_ctc_loss=0.696, task_loss=2.096, contrastive_loss=0.242, total=4157.94, n_correct=2619.83, ppl=4.83, accuracy=63.008, wps=11992.7, ups=1.44, wpb=8315.9, bsz=305, num_updates=23900, lr=9.14779e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=69, gb_free=14.4, wall=20754
2023-07-28 07:41:57 | INFO | train_inner | epoch 017:    428 / 1474 loss=2.046, trans_loss=5.062, nll_loss=2.271, w2v_ctc_loss=0.696, task_loss=2.087, contrastive_loss=0.073, total=4141.8, n_correct=2614.5, ppl=4.83, accuracy=63.125, wps=11817.5, ups=1.43, wpb=8283.6, bsz=306.7, num_updates=24000, lr=9.12871e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=70, gb_free=17.3, wall=20824
2023-07-28 07:41:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 07:42:21 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.215 | trans_loss 5.592 | nll_loss 2.875 | w2v_ctc_loss 1.335 | task_loss 6.902 | contrastive_loss 0.254 | total 4003.4 | n_correct 2460 | ppl 7.34 | accuracy 61.448 | uer 17.517 | wer 19.272 | raw_wer 19.272 | bleu 19.42 | wps 2103.2 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 20.09
2023-07-28 07:42:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-07-28 07:42:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_17_24000.pt
2023-07-28 07:42:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_17_24000.pt
2023-07-28 07:42:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.42) (writing took 18.521880703046918 seconds)
2023-07-28 07:43:51 | INFO | train_inner | epoch 017:    528 / 1474 loss=2.056, trans_loss=5.068, nll_loss=2.279, w2v_ctc_loss=0.705, task_loss=2.185, contrastive_loss=0.121, total=4180.09, n_correct=2628.63, ppl=4.85, accuracy=62.885, wps=7354.5, ups=0.88, wpb=8360.2, bsz=307.5, num_updates=24100, lr=9.10975e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=70, gb_free=17.1, wall=20938
2023-07-28 07:45:01 | INFO | train_inner | epoch 017:    628 / 1474 loss=2.05, trans_loss=5.071, nll_loss=2.284, w2v_ctc_loss=0.698, task_loss=2.113, contrastive_loss=0.068, total=4166.6, n_correct=2625.75, ppl=4.87, accuracy=63.019, wps=11969.9, ups=1.44, wpb=8333.2, bsz=302.3, num_updates=24200, lr=9.09091e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=21008
2023-07-28 07:46:10 | INFO | train_inner | epoch 017:    728 / 1474 loss=2.061, trans_loss=5.074, nll_loss=2.288, w2v_ctc_loss=0.711, task_loss=2.072, contrastive_loss=0.122, total=4168.97, n_correct=2619.36, ppl=4.88, accuracy=62.83, wps=12012.4, ups=1.44, wpb=8337.9, bsz=308.4, num_updates=24300, lr=9.07218e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=69, gb_free=16.9, wall=21077
2023-07-28 07:47:20 | INFO | train_inner | epoch 017:    828 / 1474 loss=2.055, trans_loss=5.076, nll_loss=2.29, w2v_ctc_loss=0.704, task_loss=2.111, contrastive_loss=0.081, total=4097.38, n_correct=2574.26, ppl=4.89, accuracy=62.827, wps=11763.8, ups=1.44, wpb=8194.8, bsz=297.3, num_updates=24400, lr=9.05357e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=69, gb_free=10.3, wall=21147
2023-07-28 07:48:29 | INFO | train_inner | epoch 017:    928 / 1474 loss=2.051, trans_loss=5.074, nll_loss=2.289, w2v_ctc_loss=0.699, task_loss=2.076, contrastive_loss=0.079, total=4105.01, n_correct=2580.64, ppl=4.89, accuracy=62.866, wps=11874.4, ups=1.45, wpb=8210, bsz=304.1, num_updates=24500, lr=9.03508e-05, gnorm=0.586, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=21216
2023-07-28 07:49:38 | INFO | train_inner | epoch 017:   1028 / 1474 loss=2.054, trans_loss=5.076, nll_loss=2.29, w2v_ctc_loss=0.703, task_loss=2.097, contrastive_loss=0.084, total=4105.88, n_correct=2580.6, ppl=4.89, accuracy=62.851, wps=11854.8, ups=1.44, wpb=8211.8, bsz=303.4, num_updates=24600, lr=9.0167e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=21285
2023-07-28 07:50:47 | INFO | train_inner | epoch 017:   1128 / 1474 loss=2.051, trans_loss=5.075, nll_loss=2.289, w2v_ctc_loss=0.697, task_loss=2.147, contrastive_loss=0.074, total=4095.58, n_correct=2575.99, ppl=4.89, accuracy=62.897, wps=11879.6, ups=1.45, wpb=8191.2, bsz=298.5, num_updates=24700, lr=8.99843e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=68, gb_free=15.5, wall=21354
2023-07-28 07:51:59 | INFO | train_inner | epoch 017:   1228 / 1474 loss=2.072, trans_loss=5.086, nll_loss=2.305, w2v_ctc_loss=0.697, task_loss=2.056, contrastive_loss=0.318, total=4162.14, n_correct=2599.54, ppl=4.94, accuracy=62.457, wps=11627.4, ups=1.4, wpb=8324.3, bsz=320.2, num_updates=24800, lr=8.98027e-05, gnorm=0.586, clip=0, loss_scale=32, train_wall=71, gb_free=16.1, wall=21426
2023-07-28 07:53:09 | INFO | train_inner | epoch 017:   1328 / 1474 loss=2.057, trans_loss=5.082, nll_loss=2.3, w2v_ctc_loss=0.691, task_loss=2.089, contrastive_loss=0.154, total=4149.03, n_correct=2601.67, ppl=4.93, accuracy=62.705, wps=11866.7, ups=1.43, wpb=8298.1, bsz=306.7, num_updates=24900, lr=8.96221e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=21496
2023-07-28 07:54:18 | INFO | train_inner | epoch 017:   1428 / 1474 loss=2.052, trans_loss=5.081, nll_loss=2.298, w2v_ctc_loss=0.697, task_loss=2.107, contrastive_loss=0.073, total=4117.13, n_correct=2585.16, ppl=4.92, accuracy=62.79, wps=11794, ups=1.43, wpb=8234.3, bsz=303.7, num_updates=25000, lr=8.94427e-05, gnorm=0.572, clip=0, loss_scale=64, train_wall=69, gb_free=17.5, wall=21566
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:0')
2023-07-28 07:54:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:4')
2023-07-28 07:55:17 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.227 | trans_loss 5.591 | nll_loss 2.879 | w2v_ctc_loss 1.373 | task_loss 6.939 | contrastive_loss 0.265 | total 4003.4 | n_correct 2462.2 | ppl 7.36 | accuracy 61.503 | uer 17.822 | wer 19.645 | raw_wer 19.645 | bleu 19.72 | wps 1875.7 | wpb 4003.4 | bsz 141.8 | num_updates 25046 | best_bleu 20.09
2023-07-28 07:55:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25046 updates
2023-07-28 07:55:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.7206.pt
2023-07-28 07:55:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.7206.pt
2023-07-28 07:55:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.7206.pt (epoch 17 @ 25046 updates, score 19.72) (writing took 12.277998497709632 seconds)
2023-07-28 07:55:30 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-07-28 07:55:30 | INFO | train | epoch 017 | loss 2.055 | trans_loss 5.071 | nll_loss 2.284 | w2v_ctc_loss 0.7 | task_loss 2.099 | contrastive_loss 0.127 | total 4138.65 | n_correct 2603.03 | ppl 4.87 | accuracy 62.896 | wps 10894.5 | ups 1.32 | wpb 8277.3 | bsz 305.7 | num_updates 25046 | lr 8.93605e-05 | gnorm 0.568 | clip 0 | loss_scale 64 | train_wall 1021 | gb_free 16.3 | wall 21637
2023-07-28 07:55:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 07:55:30 | INFO | fairseq.trainer | begin training epoch 18
2023-07-28 07:55:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 07:56:18 | INFO | train_inner | epoch 018:     54 / 1474 loss=2.051, trans_loss=5.066, nll_loss=2.277, w2v_ctc_loss=0.703, task_loss=2.143, contrastive_loss=0.084, total=4138.21, n_correct=2606.61, ppl=4.85, accuracy=62.989, wps=6946.3, ups=0.84, wpb=8276.4, bsz=303.2, num_updates=25100, lr=8.92644e-05, gnorm=0.583, clip=0, loss_scale=64, train_wall=70, gb_free=17.7, wall=21685
2023-07-28 07:57:27 | INFO | train_inner | epoch 018:    154 / 1474 loss=2.039, trans_loss=5.039, nll_loss=2.242, w2v_ctc_loss=0.675, task_loss=1.997, contrastive_loss=0.206, total=4158.88, n_correct=2642.51, ppl=4.73, accuracy=63.539, wps=12017.2, ups=1.44, wpb=8317.8, bsz=314, num_updates=25200, lr=8.90871e-05, gnorm=0.553, clip=0, loss_scale=64, train_wall=69, gb_free=16.7, wall=21754
2023-07-28 07:58:36 | INFO | train_inner | epoch 018:    254 / 1474 loss=2.032, trans_loss=5.041, nll_loss=2.244, w2v_ctc_loss=0.685, task_loss=2.04, contrastive_loss=0.074, total=4164.11, n_correct=2649.6, ppl=4.74, accuracy=63.629, wps=11986.5, ups=1.44, wpb=8328.2, bsz=312.5, num_updates=25300, lr=8.89108e-05, gnorm=0.565, clip=0, loss_scale=64, train_wall=69, gb_free=14.9, wall=21823
2023-07-28 07:59:46 | INFO | train_inner | epoch 018:    354 / 1474 loss=2.04, trans_loss=5.047, nll_loss=2.252, w2v_ctc_loss=0.691, task_loss=2.131, contrastive_loss=0.09, total=4163.13, n_correct=2638.89, ppl=4.76, accuracy=63.387, wps=11925.3, ups=1.43, wpb=8326.3, bsz=301.5, num_updates=25400, lr=8.87357e-05, gnorm=0.571, clip=0, loss_scale=64, train_wall=69, gb_free=17.6, wall=21893
2023-07-28 08:00:56 | INFO | train_inner | epoch 018:    454 / 1474 loss=2.053, trans_loss=5.058, nll_loss=2.266, w2v_ctc_loss=0.693, task_loss=2.244, contrastive_loss=0.179, total=4087.83, n_correct=2579.55, ppl=4.81, accuracy=63.103, wps=11684.5, ups=1.43, wpb=8175.7, bsz=295.3, num_updates=25500, lr=8.85615e-05, gnorm=0.572, clip=0, loss_scale=64, train_wall=69, gb_free=16.2, wall=21963
2023-07-28 08:02:05 | INFO | train_inner | epoch 018:    554 / 1474 loss=2.03, trans_loss=5.042, nll_loss=2.248, w2v_ctc_loss=0.684, task_loss=1.889, contrastive_loss=0.091, total=4204.41, n_correct=2673.07, ppl=4.75, accuracy=63.578, wps=12232.1, ups=1.45, wpb=8408.8, bsz=328, num_updates=25600, lr=8.83883e-05, gnorm=0.553, clip=0, loss_scale=64, train_wall=68, gb_free=17.4, wall=22032
2023-07-28 08:03:13 | INFO | train_inner | epoch 018:    654 / 1474 loss=2.053, trans_loss=5.066, nll_loss=2.277, w2v_ctc_loss=0.696, task_loss=2.172, contrastive_loss=0.158, total=4096.81, n_correct=2583.96, ppl=4.85, accuracy=63.072, wps=11955.5, ups=1.46, wpb=8193.6, bsz=298.9, num_updates=25700, lr=8.82162e-05, gnorm=0.573, clip=0, loss_scale=64, train_wall=68, gb_free=16.6, wall=22101
2023-07-28 08:04:24 | INFO | train_inner | epoch 018:    754 / 1474 loss=2.057, trans_loss=5.063, nll_loss=2.275, w2v_ctc_loss=0.701, task_loss=2.003, contrastive_loss=0.25, total=4208.29, n_correct=2651.31, ppl=4.84, accuracy=63.002, wps=12012, ups=1.43, wpb=8416.6, bsz=322.8, num_updates=25800, lr=8.80451e-05, gnorm=0.571, clip=0, loss_scale=64, train_wall=70, gb_free=17.8, wall=22171
2023-07-28 08:05:33 | INFO | train_inner | epoch 018:    854 / 1474 loss=2.044, trans_loss=5.062, nll_loss=2.273, w2v_ctc_loss=0.693, task_loss=2.133, contrastive_loss=0.064, total=4166.81, n_correct=2631.9, ppl=4.83, accuracy=63.163, wps=12048.5, ups=1.45, wpb=8333.6, bsz=301.9, num_updates=25900, lr=8.7875e-05, gnorm=0.572, clip=0, loss_scale=64, train_wall=69, gb_free=12.5, wall=22240
2023-07-28 08:06:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-28 08:06:42 | INFO | train_inner | epoch 018:    955 / 1474 loss=2.034, trans_loss=5.054, nll_loss=2.263, w2v_ctc_loss=0.68, task_loss=1.931, contrastive_loss=0.089, total=4148.92, n_correct=2633.21, ppl=4.8, accuracy=63.467, wps=11929, ups=1.44, wpb=8297.8, bsz=318, num_updates=26000, lr=8.77058e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=22309
2023-07-28 08:06:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 08:07:09 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.208 | trans_loss 5.59 | nll_loss 2.872 | w2v_ctc_loss 1.313 | task_loss 6.925 | contrastive_loss 0.261 | total 4003.4 | n_correct 2465.2 | ppl 7.32 | accuracy 61.578 | uer 17.328 | wer 19.186 | raw_wer 19.186 | bleu 19.9 | wps 1797.5 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 20.09
2023-07-28 08:07:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-07-28 08:07:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_18_26000.pt
2023-07-28 08:07:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_18_26000.pt
2023-07-28 08:07:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 19.9) (writing took 16.830674473196268 seconds)
2023-07-28 08:08:36 | INFO | train_inner | epoch 018:   1055 / 1474 loss=2.044, trans_loss=5.065, nll_loss=2.277, w2v_ctc_loss=0.686, task_loss=2.211, contrastive_loss=0.076, total=4133.59, n_correct=2607.07, ppl=4.85, accuracy=63.07, wps=7283, ups=0.88, wpb=8267.2, bsz=298.7, num_updates=26100, lr=8.75376e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=69, gb_free=15.8, wall=22423
2023-07-28 08:09:45 | INFO | train_inner | epoch 018:   1155 / 1474 loss=2.045, trans_loss=5.053, nll_loss=2.262, w2v_ctc_loss=0.686, task_loss=1.981, contrastive_loss=0.181, total=4154.22, n_correct=2631.4, ppl=4.8, accuracy=63.343, wps=12079.6, ups=1.45, wpb=8308.4, bsz=315.1, num_updates=26200, lr=8.73704e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=68, gb_free=14.9, wall=22492
2023-07-28 08:10:53 | INFO | train_inner | epoch 018:   1255 / 1474 loss=2.046, trans_loss=5.071, nll_loss=2.284, w2v_ctc_loss=0.691, task_loss=2.249, contrastive_loss=0.069, total=4089.17, n_correct=2576.31, ppl=4.87, accuracy=63.003, wps=11877.2, ups=1.45, wpb=8178.3, bsz=287.6, num_updates=26300, lr=8.72041e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=22561
2023-07-28 08:12:03 | INFO | train_inner | epoch 018:   1355 / 1474 loss=2.062, trans_loss=5.082, nll_loss=2.3, w2v_ctc_loss=0.711, task_loss=2.247, contrastive_loss=0.098, total=4068.84, n_correct=2551.16, ppl=4.92, accuracy=62.7, wps=11749.6, ups=1.44, wpb=8137.7, bsz=291.4, num_updates=26400, lr=8.70388e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=69, gb_free=15.3, wall=22630
2023-07-28 08:13:12 | INFO | train_inner | epoch 018:   1455 / 1474 loss=2.053, trans_loss=5.074, nll_loss=2.29, w2v_ctc_loss=0.7, task_loss=2.229, contrastive_loss=0.082, total=4113.23, n_correct=2587.25, ppl=4.89, accuracy=62.901, wps=11846.9, ups=1.44, wpb=8226.5, bsz=297.2, num_updates=26500, lr=8.68744e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=22699
2023-07-28 08:13:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 08:13:49 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.224 | trans_loss 5.587 | nll_loss 2.87 | w2v_ctc_loss 1.375 | task_loss 6.931 | contrastive_loss 0.261 | total 4003.4 | n_correct 2462.8 | ppl 7.31 | accuracy 61.518 | uer 17.187 | wer 19.022 | raw_wer 19.022 | bleu 19.77 | wps 2210.8 | wpb 4003.4 | bsz 141.8 | num_updates 26519 | best_bleu 20.09
2023-07-28 08:13:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26519 updates
2023-07-28 08:13:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.7707.pt
2023-07-28 08:13:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.7707.pt
2023-07-28 08:14:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.7707.pt (epoch 18 @ 26519 updates, score 19.77) (writing took 14.317829443141818 seconds)
2023-07-28 08:14:03 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-07-28 08:14:03 | INFO | train | epoch 018 | loss 2.045 | trans_loss 5.058 | nll_loss 2.268 | w2v_ctc_loss 0.691 | task_loss 2.1 | contrastive_loss 0.125 | total 4138.94 | n_correct 2616.2 | ppl 4.82 | accuracy 63.209 | wps 10951.3 | ups 1.32 | wpb 8277.9 | bsz 305.7 | num_updates 26519 | lr 8.68433e-05 | gnorm 0.569 | clip 0 | loss_scale 32 | train_wall 1013 | gb_free 15.9 | wall 22750
2023-07-28 08:14:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 08:14:04 | INFO | fairseq.trainer | begin training epoch 19
2023-07-28 08:14:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 08:15:08 | INFO | train_inner | epoch 019:     81 / 1474 loss=2.035, trans_loss=5.033, nll_loss=2.234, w2v_ctc_loss=0.685, task_loss=2.09, contrastive_loss=0.129, total=4107.26, n_correct=2610.07, ppl=4.71, accuracy=63.548, wps=7096.7, ups=0.86, wpb=8214.5, bsz=297.5, num_updates=26600, lr=8.6711e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=68, gb_free=12.6, wall=22815
2023-07-28 08:16:18 | INFO | train_inner | epoch 019:    181 / 1474 loss=2.032, trans_loss=5.026, nll_loss=2.226, w2v_ctc_loss=0.69, task_loss=1.958, contrastive_loss=0.128, total=4222.18, n_correct=2693.92, ppl=4.68, accuracy=63.804, wps=12056.7, ups=1.43, wpb=8444.4, bsz=324.4, num_updates=26700, lr=8.65485e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=69, gb_free=11.5, wall=22885
2023-07-28 08:17:27 | INFO | train_inner | epoch 019:    281 / 1474 loss=2.027, trans_loss=5.029, nll_loss=2.229, w2v_ctc_loss=0.684, task_loss=2.056, contrastive_loss=0.065, total=4187.37, n_correct=2674.58, ppl=4.69, accuracy=63.873, wps=12081.1, ups=1.44, wpb=8374.7, bsz=307, num_updates=26800, lr=8.63868e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=69, gb_free=17.5, wall=22954
2023-07-28 08:18:37 | INFO | train_inner | epoch 019:    381 / 1474 loss=2.033, trans_loss=5.032, nll_loss=2.234, w2v_ctc_loss=0.675, task_loss=2.073, contrastive_loss=0.174, total=4170.67, n_correct=2659.23, ppl=4.7, accuracy=63.76, wps=11985.5, ups=1.44, wpb=8341.3, bsz=310.5, num_updates=26900, lr=8.62261e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=23024
2023-07-28 08:19:46 | INFO | train_inner | epoch 019:    481 / 1474 loss=2.035, trans_loss=5.042, nll_loss=2.247, w2v_ctc_loss=0.69, task_loss=2.153, contrastive_loss=0.082, total=4115.22, n_correct=2615.77, ppl=4.75, accuracy=63.563, wps=11853.6, ups=1.44, wpb=8230.4, bsz=301.9, num_updates=27000, lr=8.60663e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=69, gb_free=15.1, wall=23093
2023-07-28 08:20:55 | INFO | train_inner | epoch 019:    581 / 1474 loss=2.032, trans_loss=5.038, nll_loss=2.242, w2v_ctc_loss=0.679, task_loss=2.057, contrastive_loss=0.146, total=4129.22, n_correct=2631.81, ppl=4.73, accuracy=63.736, wps=11967, ups=1.45, wpb=8258.4, bsz=306, num_updates=27100, lr=8.59074e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=23162
2023-07-28 08:22:04 | INFO | train_inner | epoch 019:    681 / 1474 loss=2.022, trans_loss=5.041, nll_loss=2.246, w2v_ctc_loss=0.668, task_loss=1.91, contrastive_loss=0.073, total=4197.2, n_correct=2673.36, ppl=4.74, accuracy=63.694, wps=12219.5, ups=1.46, wpb=8394.4, bsz=320.8, num_updates=27200, lr=8.57493e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=68, gb_free=14.6, wall=23231
2023-07-28 08:23:14 | INFO | train_inner | epoch 019:    781 / 1474 loss=2.036, trans_loss=5.043, nll_loss=2.247, w2v_ctc_loss=0.691, task_loss=2.105, contrastive_loss=0.087, total=4142.6, n_correct=2634.42, ppl=4.75, accuracy=63.593, wps=11904, ups=1.44, wpb=8285.2, bsz=305.1, num_updates=27300, lr=8.55921e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=23301
2023-07-28 08:24:23 | INFO | train_inner | epoch 019:    881 / 1474 loss=2.039, trans_loss=5.053, nll_loss=2.26, w2v_ctc_loss=0.691, task_loss=2.14, contrastive_loss=0.068, total=4153.47, n_correct=2629.25, ppl=4.79, accuracy=63.302, wps=11898.8, ups=1.43, wpb=8306.9, bsz=303.1, num_updates=27400, lr=8.54358e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=23371
2023-07-28 08:25:34 | INFO | train_inner | epoch 019:    981 / 1474 loss=2.054, trans_loss=5.063, nll_loss=2.275, w2v_ctc_loss=0.684, task_loss=2.097, contrastive_loss=0.305, total=4101.29, n_correct=2590.41, ppl=4.84, accuracy=63.161, wps=11678.8, ups=1.42, wpb=8202.6, bsz=309.9, num_updates=27500, lr=8.52803e-05, gnorm=0.591, clip=0, loss_scale=32, train_wall=70, gb_free=16.6, wall=23441
2023-07-28 08:26:43 | INFO | train_inner | epoch 019:   1081 / 1474 loss=2.044, trans_loss=5.063, nll_loss=2.275, w2v_ctc_loss=0.686, task_loss=2.244, contrastive_loss=0.113, total=4036.97, n_correct=2552.92, ppl=4.84, accuracy=63.239, wps=11685.2, ups=1.45, wpb=8073.9, bsz=291, num_updates=27600, lr=8.51257e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=68, gb_free=14.6, wall=23510
2023-07-28 08:27:53 | INFO | train_inner | epoch 019:   1181 / 1474 loss=2.053, trans_loss=5.062, nll_loss=2.273, w2v_ctc_loss=0.692, task_loss=2.132, contrastive_loss=0.196, total=4137.49, n_correct=2608.06, ppl=4.83, accuracy=63.035, wps=11779.4, ups=1.42, wpb=8275, bsz=307.7, num_updates=27700, lr=8.49719e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=70, gb_free=14.8, wall=23580
2023-07-28 08:29:02 | INFO | train_inner | epoch 019:   1281 / 1474 loss=2.039, trans_loss=5.062, nll_loss=2.274, w2v_ctc_loss=0.679, task_loss=2.121, contrastive_loss=0.093, total=4141.89, n_correct=2620.66, ppl=4.84, accuracy=63.272, wps=11992.7, ups=1.45, wpb=8283.8, bsz=300.1, num_updates=27800, lr=8.48189e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=68, gb_free=15.5, wall=23649
2023-07-28 08:30:11 | INFO | train_inner | epoch 019:   1381 / 1474 loss=2.04, trans_loss=5.057, nll_loss=2.267, w2v_ctc_loss=0.689, task_loss=2.146, contrastive_loss=0.081, total=4133.26, n_correct=2619.49, ppl=4.81, accuracy=63.376, wps=11962.8, ups=1.45, wpb=8266.5, bsz=301, num_updates=27900, lr=8.46668e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=23718
2023-07-28 08:31:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 08:31:40 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.212 | trans_loss 5.582 | nll_loss 2.864 | w2v_ctc_loss 1.346 | task_loss 6.961 | contrastive_loss 0.263 | total 4003.4 | n_correct 2466.1 | ppl 7.28 | accuracy 61.6 | uer 17.304 | wer 19.213 | raw_wer 19.213 | bleu 19.91 | wps 2175.5 | wpb 4003.4 | bsz 141.8 | num_updates 27993 | best_bleu 20.09
2023-07-28 08:31:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27993 updates
2023-07-28 08:31:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.9101.pt
2023-07-28 08:31:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.9101.pt
2023-07-28 08:32:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.9101.pt (epoch 19 @ 27993 updates, score 19.91) (writing took 26.643801283091307 seconds)
2023-07-28 08:32:07 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-07-28 08:32:07 | INFO | train | epoch 019 | loss 2.037 | trans_loss 5.046 | nll_loss 2.252 | w2v_ctc_loss 0.684 | task_loss 2.096 | contrastive_loss 0.124 | total 4138.65 | n_correct 2628.18 | ppl 4.76 | accuracy 63.503 | wps 11259.7 | ups 1.36 | wpb 8277.3 | bsz 305.7 | num_updates 27993 | lr 8.4526e-05 | gnorm 0.569 | clip 0 | loss_scale 32 | train_wall 1013 | gb_free 17.3 | wall 23834
2023-07-28 08:32:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 08:32:07 | INFO | fairseq.trainer | begin training epoch 20
2023-07-28 08:32:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 08:32:22 | INFO | train_inner | epoch 020:      7 / 1474 loss=2.037, trans_loss=5.05, nll_loss=2.258, w2v_ctc_loss=0.676, task_loss=2.114, contrastive_loss=0.162, total=4119.08, n_correct=2615.88, ppl=4.78, accuracy=63.506, wps=6312.2, ups=0.77, wpb=8238.2, bsz=304.1, num_updates=28000, lr=8.45154e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=70, gb_free=16.1, wall=23849
2023-07-28 08:32:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 08:32:46 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.213 | trans_loss 5.581 | nll_loss 2.859 | w2v_ctc_loss 1.351 | task_loss 6.967 | contrastive_loss 0.256 | total 4003.4 | n_correct 2473.1 | ppl 7.26 | accuracy 61.775 | uer 17.371 | wer 19.347 | raw_wer 19.347 | bleu 19.98 | wps 2051.6 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.09
2023-07-28 08:32:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-07-28 08:32:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_20_28000.pt
2023-07-28 08:32:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_20_28000.pt
2023-07-28 08:32:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 19.98) (writing took 13.553339527919888 seconds)
2023-07-28 08:34:12 | INFO | train_inner | epoch 020:    107 / 1474 loss=2.016, trans_loss=5.014, nll_loss=2.21, w2v_ctc_loss=0.669, task_loss=2.027, contrastive_loss=0.088, total=4195.03, n_correct=2690.54, ppl=4.63, accuracy=64.136, wps=7611.9, ups=0.91, wpb=8390.1, bsz=313.7, num_updates=28100, lr=8.43649e-05, gnorm=0.571, clip=0, loss_scale=64, train_wall=69, gb_free=14.9, wall=23959
2023-07-28 08:35:22 | INFO | train_inner | epoch 020:    207 / 1474 loss=2.027, trans_loss=5.024, nll_loss=2.223, w2v_ctc_loss=0.675, task_loss=2.174, contrastive_loss=0.138, total=4154.14, n_correct=2652.62, ppl=4.67, accuracy=63.855, wps=11901.6, ups=1.43, wpb=8308.3, bsz=301, num_updates=28200, lr=8.42152e-05, gnorm=0.568, clip=0, loss_scale=64, train_wall=69, gb_free=17.2, wall=24029
2023-07-28 08:36:31 | INFO | train_inner | epoch 020:    307 / 1474 loss=2.016, trans_loss=5.016, nll_loss=2.214, w2v_ctc_loss=0.676, task_loss=1.892, contrastive_loss=0.078, total=4188.05, n_correct=2687.17, ppl=4.64, accuracy=64.163, wps=12067.9, ups=1.44, wpb=8376.1, bsz=326.2, num_updates=28300, lr=8.40663e-05, gnorm=0.558, clip=0, loss_scale=64, train_wall=69, gb_free=15.5, wall=24098
2023-07-28 08:37:40 | INFO | train_inner | epoch 020:    407 / 1474 loss=2.02, trans_loss=5.023, nll_loss=2.222, w2v_ctc_loss=0.67, task_loss=2.127, contrastive_loss=0.074, total=4115.16, n_correct=2633.55, ppl=4.66, accuracy=63.996, wps=11936.2, ups=1.45, wpb=8230.3, bsz=297, num_updates=28400, lr=8.39181e-05, gnorm=0.568, clip=0, loss_scale=64, train_wall=68, gb_free=15.4, wall=24167
2023-07-28 08:38:50 | INFO | train_inner | epoch 020:    507 / 1474 loss=2.032, trans_loss=5.037, nll_loss=2.24, w2v_ctc_loss=0.673, task_loss=2.146, contrastive_loss=0.16, total=4108.46, n_correct=2617.65, ppl=4.72, accuracy=63.714, wps=11829.3, ups=1.44, wpb=8216.9, bsz=300.4, num_updates=28500, lr=8.37708e-05, gnorm=0.569, clip=0, loss_scale=64, train_wall=69, gb_free=16.4, wall=24237
2023-07-28 08:39:59 | INFO | train_inner | epoch 020:    607 / 1474 loss=2.037, trans_loss=5.038, nll_loss=2.241, w2v_ctc_loss=0.677, task_loss=2.212, contrastive_loss=0.166, total=4094.9, n_correct=2605.37, ppl=4.73, accuracy=63.625, wps=11887.4, ups=1.45, wpb=8189.8, bsz=296.1, num_updates=28600, lr=8.36242e-05, gnorm=0.57, clip=0, loss_scale=64, train_wall=68, gb_free=11.8, wall=24306
2023-07-28 08:41:08 | INFO | train_inner | epoch 020:    707 / 1474 loss=2.029, trans_loss=5.039, nll_loss=2.242, w2v_ctc_loss=0.682, task_loss=2.104, contrastive_loss=0.066, total=4140.23, n_correct=2634.13, ppl=4.73, accuracy=63.623, wps=11986.6, ups=1.45, wpb=8280.5, bsz=300.6, num_updates=28700, lr=8.34784e-05, gnorm=0.565, clip=0, loss_scale=64, train_wall=68, gb_free=16.1, wall=24375
2023-07-28 08:42:17 | INFO | train_inner | epoch 020:    807 / 1474 loss=2.028, trans_loss=5.036, nll_loss=2.24, w2v_ctc_loss=0.683, task_loss=2.088, contrastive_loss=0.072, total=4140.66, n_correct=2639.94, ppl=4.73, accuracy=63.757, wps=12006, ups=1.45, wpb=8281.3, bsz=305.6, num_updates=28800, lr=8.33333e-05, gnorm=0.582, clip=0, loss_scale=64, train_wall=68, gb_free=17.5, wall=24444
2023-07-28 08:42:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-28 08:43:27 | INFO | train_inner | epoch 020:    908 / 1474 loss=2.044, trans_loss=5.045, nll_loss=2.252, w2v_ctc_loss=0.681, task_loss=2.053, contrastive_loss=0.263, total=4136.06, n_correct=2627.47, ppl=4.76, accuracy=63.526, wps=11703.8, ups=1.41, wpb=8272.1, bsz=315.6, num_updates=28900, lr=8.3189e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=70, gb_free=17.4, wall=24514
2023-07-28 08:44:37 | INFO | train_inner | epoch 020:   1008 / 1474 loss=2.026, trans_loss=5.04, nll_loss=2.244, w2v_ctc_loss=0.672, task_loss=2.091, contrastive_loss=0.077, total=4168.14, n_correct=2653.7, ppl=4.74, accuracy=63.666, wps=11982.9, ups=1.44, wpb=8336.3, bsz=307.3, num_updates=29000, lr=8.30455e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=24584
2023-07-28 08:45:46 | INFO | train_inner | epoch 020:   1108 / 1474 loss=2.037, trans_loss=5.045, nll_loss=2.252, w2v_ctc_loss=0.674, task_loss=2.029, contrastive_loss=0.216, total=4166.49, n_correct=2649.76, ppl=4.76, accuracy=63.597, wps=12008.7, ups=1.44, wpb=8333, bsz=315.4, num_updates=29100, lr=8.29027e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=69, gb_free=14.7, wall=24653
2023-07-28 08:46:55 | INFO | train_inner | epoch 020:   1208 / 1474 loss=2.036, trans_loss=5.043, nll_loss=2.248, w2v_ctc_loss=0.692, task_loss=2.32, contrastive_loss=0.065, total=4029.18, n_correct=2560.72, ppl=4.75, accuracy=63.554, wps=11661.3, ups=1.45, wpb=8058.4, bsz=284, num_updates=29200, lr=8.27606e-05, gnorm=0.591, clip=0, loss_scale=32, train_wall=68, gb_free=11.6, wall=24722
2023-07-28 08:48:05 | INFO | train_inner | epoch 020:   1308 / 1474 loss=2.031, trans_loss=5.048, nll_loss=2.256, w2v_ctc_loss=0.677, task_loss=2.216, contrastive_loss=0.069, total=4123.21, n_correct=2622.08, ppl=4.78, accuracy=63.593, wps=11869.6, ups=1.44, wpb=8246.4, bsz=297.1, num_updates=29300, lr=8.26192e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=69, gb_free=17.4, wall=24792
2023-07-28 08:49:15 | INFO | train_inner | epoch 020:   1408 / 1474 loss=2.03, trans_loss=5.045, nll_loss=2.251, w2v_ctc_loss=0.678, task_loss=2.217, contrastive_loss=0.069, total=4116.28, n_correct=2616.65, ppl=4.76, accuracy=63.568, wps=11776.9, ups=1.43, wpb=8232.6, bsz=295, num_updates=29400, lr=8.24786e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=69, gb_free=17.5, wall=24862
2023-07-28 08:50:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 08:50:25 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.21 | trans_loss 5.584 | nll_loss 2.862 | w2v_ctc_loss 1.338 | task_loss 6.932 | contrastive_loss 0.256 | total 4003.4 | n_correct 2471.8 | ppl 7.27 | accuracy 61.743 | uer 17.243 | wer 18.963 | raw_wer 18.963 | bleu 19.69 | wps 2070.2 | wpb 4003.4 | bsz 141.8 | num_updates 29466 | best_bleu 20.09
2023-07-28 08:50:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29466 updates
2023-07-28 08:50:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.6902.pt
2023-07-28 08:50:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.6902.pt
2023-07-28 08:50:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.6902.pt (epoch 20 @ 29466 updates, score 19.69) (writing took 12.706428052857518 seconds)
2023-07-28 08:50:38 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-07-28 08:50:38 | INFO | train | epoch 020 | loss 2.029 | trans_loss 5.036 | nll_loss 2.239 | w2v_ctc_loss 0.677 | task_loss 2.105 | contrastive_loss 0.115 | total 4136.98 | n_correct 2637.03 | ppl 4.72 | accuracy 63.743 | wps 10972.8 | ups 1.33 | wpb 8274 | bsz 305.1 | num_updates 29466 | lr 8.23862e-05 | gnorm 0.571 | clip 0 | loss_scale 32 | train_wall 1014 | gb_free 16.1 | wall 24945
2023-07-28 08:50:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 08:50:38 | INFO | fairseq.trainer | begin training epoch 21
2023-07-28 08:50:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 08:51:11 | INFO | train_inner | epoch 021:     34 / 1474 loss=2.032, trans_loss=5.039, nll_loss=2.244, w2v_ctc_loss=0.673, task_loss=2.001, contrastive_loss=0.191, total=4152.26, n_correct=2647.42, ppl=4.74, accuracy=63.759, wps=7156, ups=0.86, wpb=8304.5, bsz=316.3, num_updates=29500, lr=8.23387e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=24978
2023-07-28 08:52:20 | INFO | train_inner | epoch 021:    134 / 1474 loss=2.017, trans_loss=5.005, nll_loss=2.199, w2v_ctc_loss=0.665, task_loss=1.963, contrastive_loss=0.182, total=4195.08, n_correct=2696.44, ppl=4.59, accuracy=64.276, wps=12087.8, ups=1.44, wpb=8390.2, bsz=319.6, num_updates=29600, lr=8.21995e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=25047
2023-07-28 08:53:29 | INFO | train_inner | epoch 021:    234 / 1474 loss=2.009, trans_loss=5.009, nll_loss=2.204, w2v_ctc_loss=0.655, task_loss=2.003, contrastive_loss=0.135, total=4155.31, n_correct=2673.63, ppl=4.61, accuracy=64.342, wps=12000.3, ups=1.44, wpb=8310.6, bsz=312.6, num_updates=29700, lr=8.2061e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=25117
2023-07-28 08:54:39 | INFO | train_inner | epoch 021:    334 / 1474 loss=2.018, trans_loss=5.013, nll_loss=2.209, w2v_ctc_loss=0.67, task_loss=2.083, contrastive_loss=0.14, total=4151.51, n_correct=2665.11, ppl=4.62, accuracy=64.196, wps=11870.9, ups=1.43, wpb=8303, bsz=310.8, num_updates=29800, lr=8.19232e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=69, gb_free=15.5, wall=25187
2023-07-28 08:55:49 | INFO | train_inner | epoch 021:    434 / 1474 loss=2.011, trans_loss=5.015, nll_loss=2.212, w2v_ctc_loss=0.661, task_loss=2.042, contrastive_loss=0.061, total=4180.85, n_correct=2686.18, ppl=4.63, accuracy=64.25, wps=12104.1, ups=1.45, wpb=8361.7, bsz=306.8, num_updates=29900, lr=8.17861e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=25256
2023-07-28 08:56:58 | INFO | train_inner | epoch 021:    534 / 1474 loss=2.015, trans_loss=5.014, nll_loss=2.211, w2v_ctc_loss=0.673, task_loss=2.188, contrastive_loss=0.061, total=4083.98, n_correct=2624.21, ppl=4.63, accuracy=64.256, wps=11770, ups=1.44, wpb=8168, bsz=295.1, num_updates=30000, lr=8.16497e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=69, gb_free=12.9, wall=25325
2023-07-28 08:56:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 08:57:22 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.203 | trans_loss 5.597 | nll_loss 2.879 | w2v_ctc_loss 1.282 | task_loss 6.913 | contrastive_loss 0.256 | total 4003.4 | n_correct 2463.7 | ppl 7.36 | accuracy 61.54 | uer 17.233 | wer 18.955 | raw_wer 18.955 | bleu 19.72 | wps 2046.4 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.09
2023-07-28 08:57:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-07-28 08:57:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_21_30000.pt
2023-07-28 08:57:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_21_30000.pt
2023-07-28 08:57:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 19.72) (writing took 13.489231681451201 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:0')
2023-07-28 08:58:49 | INFO | train_inner | epoch 021:    634 / 1474 loss=2.024, trans_loss=5.019, nll_loss=2.218, w2v_ctc_loss=0.661, task_loss=2.076, contrastive_loss=0.235, total=4215.41, n_correct=2700.26, ppl=4.65, accuracy=64.057, wps=7598.9, ups=0.9, wpb=8430.8, bsz=315.4, num_updates=30100, lr=8.15139e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=69, gb_free=11.2, wall=25436
2023-07-28 08:59:58 | INFO | train_inner | epoch 021:    734 / 1474 loss=2.023, trans_loss=5.03, nll_loss=2.232, w2v_ctc_loss=0.671, task_loss=2.085, contrastive_loss=0.098, total=4152.97, n_correct=2654.97, ppl=4.7, accuracy=63.929, wps=12031.5, ups=1.45, wpb=8305.9, bsz=309.3, num_updates=30200, lr=8.13788e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=25505
2023-07-28 09:01:07 | INFO | train_inner | epoch 021:    834 / 1474 loss=2.027, trans_loss=5.034, nll_loss=2.237, w2v_ctc_loss=0.672, task_loss=2.218, contrastive_loss=0.108, total=4066.93, n_correct=2596.01, ppl=4.71, accuracy=63.832, wps=11720, ups=1.44, wpb=8133.9, bsz=294.4, num_updates=30300, lr=8.12444e-05, gnorm=0.606, clip=0, loss_scale=32, train_wall=69, gb_free=16.9, wall=25574
2023-07-28 09:02:16 | INFO | train_inner | epoch 021:    934 / 1474 loss=2.019, trans_loss=5.025, nll_loss=2.225, w2v_ctc_loss=0.67, task_loss=2.1, contrastive_loss=0.081, total=4103.34, n_correct=2623.75, ppl=4.68, accuracy=63.942, wps=11904.7, ups=1.45, wpb=8206.7, bsz=301, num_updates=30400, lr=8.11107e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=68, gb_free=13.9, wall=25643
2023-07-28 09:03:25 | INFO | train_inner | epoch 021:   1034 / 1474 loss=2.025, trans_loss=5.04, nll_loss=2.246, w2v_ctc_loss=0.67, task_loss=2.135, contrastive_loss=0.079, total=4099.86, n_correct=2615.07, ppl=4.74, accuracy=63.784, wps=11877.1, ups=1.45, wpb=8199.7, bsz=298.8, num_updates=30500, lr=8.09776e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=69, gb_free=11.2, wall=25712
2023-07-28 09:04:34 | INFO | train_inner | epoch 021:   1134 / 1474 loss=2.025, trans_loss=5.032, nll_loss=2.234, w2v_ctc_loss=0.673, task_loss=2.259, contrastive_loss=0.081, total=4120.75, n_correct=2630.95, ppl=4.7, accuracy=63.846, wps=12057.4, ups=1.46, wpb=8241.5, bsz=293.5, num_updates=30600, lr=8.08452e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=25781
2023-07-28 09:05:43 | INFO | train_inner | epoch 021:   1234 / 1474 loss=2.022, trans_loss=5.03, nll_loss=2.233, w2v_ctc_loss=0.667, task_loss=1.992, contrastive_loss=0.135, total=4154.73, n_correct=2653.06, ppl=4.7, accuracy=63.856, wps=12003.6, ups=1.44, wpb=8309.5, bsz=311.6, num_updates=30700, lr=8.07134e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=69, gb_free=12.5, wall=25850
2023-07-28 09:06:52 | INFO | train_inner | epoch 021:   1334 / 1474 loss=2.023, trans_loss=5.033, nll_loss=2.237, w2v_ctc_loss=0.672, task_loss=2.025, contrastive_loss=0.096, total=4147.17, n_correct=2651.39, ppl=4.72, accuracy=63.933, wps=12074, ups=1.46, wpb=8294.3, bsz=311.9, num_updates=30800, lr=8.05823e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=25919
2023-07-28 09:08:01 | INFO | train_inner | epoch 021:   1434 / 1474 loss=2.041, trans_loss=5.045, nll_loss=2.253, w2v_ctc_loss=0.69, task_loss=2.192, contrastive_loss=0.147, total=4133.93, n_correct=2623.83, ppl=4.77, accuracy=63.471, wps=11891.1, ups=1.44, wpb=8267.9, bsz=304.5, num_updates=30900, lr=8.04518e-05, gnorm=0.592, clip=0, loss_scale=64, train_wall=69, gb_free=15.5, wall=25988
2023-07-28 09:08:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:5')
2023-07-28 09:08:53 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.218 | trans_loss 5.592 | nll_loss 2.874 | w2v_ctc_loss 1.345 | task_loss 6.909 | contrastive_loss 0.26 | total 4003.4 | n_correct 2468.1 | ppl 7.33 | accuracy 61.65 | uer 17.373 | wer 19.131 | raw_wer 19.131 | bleu 19.65 | wps 2085.8 | wpb 4003.4 | bsz 141.8 | num_updates 30940 | best_bleu 20.09
2023-07-28 09:08:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30940 updates
2023-07-28 09:08:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_last.pt
2023-07-28 09:09:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_last.pt
2023-07-28 09:09:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_last.pt (epoch 21 @ 30940 updates, score 19.65) (writing took 10.66404763609171 seconds)
2023-07-28 09:09:04 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-07-28 09:09:04 | INFO | train | epoch 021 | loss 2.022 | trans_loss 5.025 | nll_loss 2.225 | w2v_ctc_loss 0.669 | task_loss 2.099 | contrastive_loss 0.121 | total 4138.65 | n_correct 2648.44 | ppl 4.68 | accuracy 63.993 | wps 11032.1 | ups 1.33 | wpb 8277.3 | bsz 305.7 | num_updates 30940 | lr 8.03998e-05 | gnorm 0.581 | clip 0 | loss_scale 64 | train_wall 1012 | gb_free 15.4 | wall 26051
2023-07-28 09:09:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 09:09:04 | INFO | fairseq.trainer | begin training epoch 22
2023-07-28 09:09:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 09:09:55 | INFO | train_inner | epoch 022:     60 / 1474 loss=2.013, trans_loss=5.01, nll_loss=2.206, w2v_ctc_loss=0.67, task_loss=2.134, contrastive_loss=0.06, total=4128.84, n_correct=2654.97, ppl=4.62, accuracy=64.303, wps=7250.9, ups=0.88, wpb=8257.7, bsz=297.7, num_updates=31000, lr=8.03219e-05, gnorm=0.586, clip=0, loss_scale=64, train_wall=69, gb_free=14.1, wall=26102
2023-07-28 09:11:04 | INFO | train_inner | epoch 022:    160 / 1474 loss=2.012, trans_loss=5, nll_loss=2.192, w2v_ctc_loss=0.664, task_loss=2.112, contrastive_loss=0.148, total=4123.35, n_correct=2655.94, ppl=4.57, accuracy=64.412, wps=11978.2, ups=1.45, wpb=8246.7, bsz=310.3, num_updates=31100, lr=8.01927e-05, gnorm=0.584, clip=0, loss_scale=64, train_wall=68, gb_free=14.6, wall=26171
2023-07-28 09:12:13 | INFO | train_inner | epoch 022:    260 / 1474 loss=1.997, trans_loss=4.997, nll_loss=2.19, w2v_ctc_loss=0.648, task_loss=1.848, contrastive_loss=0.087, total=4267.16, n_correct=2758.87, ppl=4.56, accuracy=64.654, wps=12377.1, ups=1.45, wpb=8534.3, bsz=329.9, num_updates=31200, lr=8.00641e-05, gnorm=0.559, clip=0, loss_scale=64, train_wall=68, gb_free=16.6, wall=26240
2023-07-28 09:12:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-28 09:12:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-28 09:13:25 | INFO | train_inner | epoch 022:    362 / 1474 loss=2.021, trans_loss=5.009, nll_loss=2.204, w2v_ctc_loss=0.667, task_loss=2.22, contrastive_loss=0.186, total=4146.75, n_correct=2665.84, ppl=4.61, accuracy=64.287, wps=11569.7, ups=1.4, wpb=8293.5, bsz=298.8, num_updates=31300, lr=7.99361e-05, gnorm=0.588, clip=0, loss_scale=16, train_wall=71, gb_free=17.7, wall=26312
2023-07-28 09:14:34 | INFO | train_inner | epoch 022:    462 / 1474 loss=2.019, trans_loss=5.016, nll_loss=2.212, w2v_ctc_loss=0.664, task_loss=2.171, contrastive_loss=0.131, total=4143.46, n_correct=2658.26, ppl=4.63, accuracy=64.156, wps=11972.5, ups=1.44, wpb=8286.9, bsz=300.6, num_updates=31400, lr=7.98087e-05, gnorm=0.578, clip=0, loss_scale=16, train_wall=69, gb_free=15.8, wall=26381
2023-07-28 09:15:43 | INFO | train_inner | epoch 022:    562 / 1474 loss=2.011, trans_loss=5.01, nll_loss=2.206, w2v_ctc_loss=0.665, task_loss=2.127, contrastive_loss=0.072, total=4143.14, n_correct=2663.56, ppl=4.62, accuracy=64.288, wps=11905.6, ups=1.44, wpb=8286.3, bsz=304.4, num_updates=31500, lr=7.96819e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=26450
2023-07-28 09:16:52 | INFO | train_inner | epoch 022:    662 / 1474 loss=2.005, trans_loss=5.002, nll_loss=2.197, w2v_ctc_loss=0.648, task_loss=1.996, contrastive_loss=0.156, total=4146.54, n_correct=2673.25, ppl=4.58, accuracy=64.469, wps=12142.7, ups=1.46, wpb=8293.1, bsz=311.9, num_updates=31600, lr=7.95557e-05, gnorm=0.583, clip=0, loss_scale=16, train_wall=68, gb_free=13.2, wall=26519
2023-07-28 09:18:01 | INFO | train_inner | epoch 022:    762 / 1474 loss=2.013, trans_loss=5.012, nll_loss=2.208, w2v_ctc_loss=0.668, task_loss=2.154, contrastive_loss=0.076, total=4170.82, n_correct=2680.48, ppl=4.62, accuracy=64.267, wps=12024.9, ups=1.44, wpb=8341.6, bsz=303.9, num_updates=31700, lr=7.94301e-05, gnorm=0.575, clip=0, loss_scale=16, train_wall=69, gb_free=11.7, wall=26588
2023-07-28 09:19:10 | INFO | train_inner | epoch 022:    862 / 1474 loss=2.015, trans_loss=5.02, nll_loss=2.219, w2v_ctc_loss=0.665, task_loss=2.255, contrastive_loss=0.062, total=4077.65, n_correct=2613.39, ppl=4.66, accuracy=64.091, wps=11879.7, ups=1.46, wpb=8155.3, bsz=290.5, num_updates=31800, lr=7.93052e-05, gnorm=0.575, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=26657
2023-07-28 09:20:19 | INFO | train_inner | epoch 022:    962 / 1474 loss=2.01, trans_loss=5.015, nll_loss=2.214, w2v_ctc_loss=0.659, task_loss=2.108, contrastive_loss=0.072, total=4136.66, n_correct=2659.55, ppl=4.64, accuracy=64.292, wps=12019.5, ups=1.45, wpb=8273.3, bsz=304.7, num_updates=31900, lr=7.91808e-05, gnorm=0.572, clip=0, loss_scale=16, train_wall=68, gb_free=14.7, wall=26726
2023-07-28 09:21:27 | INFO | train_inner | epoch 022:   1062 / 1474 loss=2.014, trans_loss=5.013, nll_loss=2.211, w2v_ctc_loss=0.653, task_loss=2.01, contrastive_loss=0.226, total=4152.13, n_correct=2670.74, ppl=4.63, accuracy=64.322, wps=12045.7, ups=1.45, wpb=8304.3, bsz=313.8, num_updates=32000, lr=7.90569e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=68, gb_free=16, wall=26795
2023-07-28 09:21:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 09:21:53 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.213 | trans_loss 5.585 | nll_loss 2.865 | w2v_ctc_loss 1.345 | task_loss 6.937 | contrastive_loss 0.256 | total 4003.4 | n_correct 2469.9 | ppl 7.29 | accuracy 61.695 | uer 17.275 | wer 19.153 | raw_wer 19.153 | bleu 19.97 | wps 1916.1 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.09
2023-07-28 09:21:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-07-28 09:21:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_22_32000.pt
2023-07-28 09:21:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_22_32000.pt
2023-07-28 09:22:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 19.97) (writing took 16.722222309559584 seconds)
2023-07-28 09:23:18 | INFO | train_inner | epoch 022:   1162 / 1474 loss=2.031, trans_loss=5.039, nll_loss=2.244, w2v_ctc_loss=0.678, task_loss=2.173, contrastive_loss=0.114, total=4102.27, n_correct=2614.16, ppl=4.74, accuracy=63.725, wps=7400.5, ups=0.9, wpb=8204.5, bsz=296.1, num_updates=32100, lr=7.89337e-05, gnorm=0.577, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=26905
2023-07-28 09:24:27 | INFO | train_inner | epoch 022:   1262 / 1474 loss=2.016, trans_loss=5.027, nll_loss=2.23, w2v_ctc_loss=0.662, task_loss=1.949, contrastive_loss=0.111, total=4179.1, n_correct=2673.43, ppl=4.69, accuracy=63.971, wps=12122.9, ups=1.45, wpb=8358.2, bsz=321.7, num_updates=32200, lr=7.8811e-05, gnorm=0.574, clip=0, loss_scale=16, train_wall=68, gb_free=17.1, wall=26974
2023-07-28 09:25:36 | INFO | train_inner | epoch 022:   1362 / 1474 loss=2.014, trans_loss=5.019, nll_loss=2.219, w2v_ctc_loss=0.657, task_loss=2.102, contrastive_loss=0.131, total=4061.14, n_correct=2605.83, ppl=4.66, accuracy=64.165, wps=11887, ups=1.46, wpb=8122.3, bsz=299.1, num_updates=32300, lr=7.86889e-05, gnorm=0.574, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=27043
2023-07-28 09:26:45 | INFO | train_inner | epoch 022:   1462 / 1474 loss=2.026, trans_loss=5.038, nll_loss=2.243, w2v_ctc_loss=0.676, task_loss=2.247, contrastive_loss=0.078, total=4083.08, n_correct=2606.68, ppl=4.73, accuracy=63.841, wps=11766, ups=1.44, wpb=8166.2, bsz=289.3, num_updates=32400, lr=7.85674e-05, gnorm=0.575, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=27112
2023-07-28 09:26:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 09:27:17 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.203 | trans_loss 5.583 | nll_loss 2.859 | w2v_ctc_loss 1.313 | task_loss 6.89 | contrastive_loss 0.259 | total 4003.4 | n_correct 2480.1 | ppl 7.26 | accuracy 61.95 | uer 17.267 | wer 19.041 | raw_wer 19.041 | bleu 19.96 | wps 2110.2 | wpb 4003.4 | bsz 141.8 | num_updates 32412 | best_bleu 20.09
2023-07-28 09:27:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32412 updates
2023-07-28 09:27:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.9600.pt
2023-07-28 09:27:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.9600.pt
2023-07-28 09:27:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_19.9600.pt (epoch 22 @ 32412 updates, score 19.96) (writing took 11.896494204178452 seconds)
2023-07-28 09:27:29 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-07-28 09:27:29 | INFO | train | epoch 022 | loss 2.014 | trans_loss 5.015 | nll_loss 2.212 | w2v_ctc_loss 0.663 | task_loss 2.104 | contrastive_loss 0.116 | total 4136.5 | n_correct 2656.68 | ppl 4.63 | accuracy 64.225 | wps 11016.9 | ups 1.33 | wpb 8273 | bsz 304.9 | num_updates 32412 | lr 7.85529e-05 | gnorm 0.575 | clip 0 | loss_scale 16 | train_wall 1010 | gb_free 11.6 | wall 27156
2023-07-28 09:27:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 09:27:29 | INFO | fairseq.trainer | begin training epoch 23
2023-07-28 09:27:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 09:28:39 | INFO | train_inner | epoch 023:     88 / 1474 loss=2.002, trans_loss=4.991, nll_loss=2.182, w2v_ctc_loss=0.663, task_loss=2.136, contrastive_loss=0.07, total=4093.3, n_correct=2646.6, ppl=4.54, accuracy=64.657, wps=7204.7, ups=0.88, wpb=8186.6, bsz=301.3, num_updates=32500, lr=7.84465e-05, gnorm=0.592, clip=0, loss_scale=16, train_wall=68, gb_free=16.1, wall=27226
2023-07-28 09:29:48 | INFO | train_inner | epoch 023:    188 / 1474 loss=1.999, trans_loss=4.987, nll_loss=2.175, w2v_ctc_loss=0.654, task_loss=2.235, contrastive_loss=0.066, total=4116.26, n_correct=2666.25, ppl=4.51, accuracy=64.774, wps=11893.8, ups=1.44, wpb=8232.5, bsz=294.4, num_updates=32600, lr=7.8326e-05, gnorm=0.584, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=27295
2023-07-28 09:30:57 | INFO | train_inner | epoch 023:    288 / 1474 loss=2.002, trans_loss=4.996, nll_loss=2.187, w2v_ctc_loss=0.643, task_loss=2.108, contrastive_loss=0.146, total=4148.03, n_correct=2678.72, ppl=4.55, accuracy=64.578, wps=11922.5, ups=1.44, wpb=8296.1, bsz=305.7, num_updates=32700, lr=7.82062e-05, gnorm=0.569, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=27365
2023-07-28 09:32:06 | INFO | train_inner | epoch 023:    388 / 1474 loss=2.001, trans_loss=4.997, nll_loss=2.188, w2v_ctc_loss=0.653, task_loss=2.173, contrastive_loss=0.056, total=4115.99, n_correct=2657.99, ppl=4.56, accuracy=64.577, wps=11985.7, ups=1.46, wpb=8232, bsz=294.1, num_updates=32800, lr=7.80869e-05, gnorm=0.588, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=27433
2023-07-28 09:33:15 | INFO | train_inner | epoch 023:    488 / 1474 loss=2.009, trans_loss=5.003, nll_loss=2.196, w2v_ctc_loss=0.658, task_loss=2.055, contrastive_loss=0.12, total=4156.5, n_correct=2677.4, ppl=4.58, accuracy=64.415, wps=12132.3, ups=1.46, wpb=8313, bsz=312.2, num_updates=32900, lr=7.79681e-05, gnorm=0.58, clip=0, loss_scale=16, train_wall=68, gb_free=17.3, wall=27502
2023-07-28 09:34:24 | INFO | train_inner | epoch 023:    588 / 1474 loss=1.993, trans_loss=4.991, nll_loss=2.182, w2v_ctc_loss=0.647, task_loss=1.981, contrastive_loss=0.063, total=4174.84, n_correct=2708.74, ppl=4.54, accuracy=64.882, wps=12066.1, ups=1.45, wpb=8349.7, bsz=316.3, num_updates=33000, lr=7.78499e-05, gnorm=0.567, clip=0, loss_scale=16, train_wall=69, gb_free=17.2, wall=27571
2023-07-28 09:35:33 | INFO | train_inner | epoch 023:    688 / 1474 loss=2.001, trans_loss=4.998, nll_loss=2.19, w2v_ctc_loss=0.648, task_loss=2.107, contrastive_loss=0.105, total=4139.68, n_correct=2675.92, ppl=4.56, accuracy=64.641, wps=12029.7, ups=1.45, wpb=8279.4, bsz=302.2, num_updates=33100, lr=7.77322e-05, gnorm=0.572, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=27640
2023-07-28 09:36:41 | INFO | train_inner | epoch 023:    788 / 1474 loss=2.008, trans_loss=5.007, nll_loss=2.202, w2v_ctc_loss=0.661, task_loss=2.117, contrastive_loss=0.086, total=4147.97, n_correct=2670.54, ppl=4.6, accuracy=64.382, wps=12117.5, ups=1.46, wpb=8295.9, bsz=305.8, num_updates=33200, lr=7.76151e-05, gnorm=0.58, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=27708
2023-07-28 09:37:50 | INFO | train_inner | epoch 023:    888 / 1474 loss=2.007, trans_loss=5.003, nll_loss=2.198, w2v_ctc_loss=0.655, task_loss=1.914, contrastive_loss=0.167, total=4182.69, n_correct=2700.77, ppl=4.59, accuracy=64.57, wps=12194.1, ups=1.46, wpb=8365.4, bsz=325, num_updates=33300, lr=7.74984e-05, gnorm=0.579, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=27777
2023-07-28 09:38:59 | INFO | train_inner | epoch 023:    988 / 1474 loss=2.017, trans_loss=5.007, nll_loss=2.203, w2v_ctc_loss=0.646, task_loss=2.106, contrastive_loss=0.319, total=4165.01, n_correct=2682.82, ppl=4.6, accuracy=64.413, wps=12038.6, ups=1.45, wpb=8330, bsz=309.6, num_updates=33400, lr=7.73823e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=69, gb_free=17.7, wall=27846
2023-07-28 09:40:08 | INFO | train_inner | epoch 023:   1088 / 1474 loss=2.014, trans_loss=5.015, nll_loss=2.213, w2v_ctc_loss=0.668, task_loss=2.23, contrastive_loss=0.07, total=4092.37, n_correct=2629.53, ppl=4.64, accuracy=64.254, wps=11892.1, ups=1.45, wpb=8184.7, bsz=290.8, num_updates=33500, lr=7.72667e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=27915
2023-07-28 09:41:17 | INFO | train_inner | epoch 023:   1188 / 1474 loss=2.006, trans_loss=5.014, nll_loss=2.213, w2v_ctc_loss=0.658, task_loss=2.088, contrastive_loss=0.063, total=4164.9, n_correct=2676.26, ppl=4.64, accuracy=64.257, wps=11970, ups=1.44, wpb=8329.8, bsz=309.2, num_updates=33600, lr=7.71517e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=69, gb_free=13.6, wall=27985
2023-07-28 09:42:26 | INFO | train_inner | epoch 023:   1288 / 1474 loss=2.001, trans_loss=5.01, nll_loss=2.208, w2v_ctc_loss=0.649, task_loss=2.041, contrastive_loss=0.077, total=4136.96, n_correct=2665.26, ppl=4.62, accuracy=64.426, wps=12126.4, ups=1.47, wpb=8273.9, bsz=309.8, num_updates=33700, lr=7.70371e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=28053
2023-07-28 09:43:35 | INFO | train_inner | epoch 023:   1388 / 1474 loss=2.019, trans_loss=5.03, nll_loss=2.233, w2v_ctc_loss=0.66, task_loss=2.12, contrastive_loss=0.134, total=4142.84, n_correct=2654.18, ppl=4.7, accuracy=64.067, wps=11989.7, ups=1.45, wpb=8285.7, bsz=304.8, num_updates=33800, lr=7.69231e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=28122
2023-07-28 09:44:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 09:44:58 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.208 | trans_loss 5.58 | nll_loss 2.858 | w2v_ctc_loss 1.34 | task_loss 6.927 | contrastive_loss 0.259 | total 4003.4 | n_correct 2476.2 | ppl 7.25 | accuracy 61.852 | uer 16.97 | wer 18.59 | raw_wer 18.59 | bleu 20.46 | wps 2134.8 | wpb 4003.4 | bsz 141.8 | num_updates 33886 | best_bleu 20.46
2023-07-28 09:44:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33886 updates
2023-07-28 09:44:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 09:45:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt
2023-07-28 09:45:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_best.pt (epoch 23 @ 33886 updates, score 20.46) (writing took 19.606936624273658 seconds)
2023-07-28 09:45:18 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-07-28 09:45:18 | INFO | train | epoch 023 | loss 2.007 | trans_loss 5.005 | nll_loss 2.2 | w2v_ctc_loss 0.654 | task_loss 2.1 | contrastive_loss 0.118 | total 4138.65 | n_correct 2667.95 | ppl 4.59 | accuracy 64.464 | wps 11410.6 | ups 1.38 | wpb 8277.3 | bsz 305.7 | num_updates 33886 | lr 7.68254e-05 | gnorm 0.578 | clip 0 | loss_scale 32 | train_wall 1008 | gb_free 13.6 | wall 28225
2023-07-28 09:45:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 09:45:19 | INFO | fairseq.trainer | begin training epoch 24
2023-07-28 09:45:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 09:45:37 | INFO | train_inner | epoch 024:     14 / 1474 loss=2.022, trans_loss=5.023, nll_loss=2.224, w2v_ctc_loss=0.656, task_loss=2.122, contrastive_loss=0.213, total=4084.21, n_correct=2617.5, ppl=4.67, accuracy=64.088, wps=6672, ups=0.82, wpb=8168.4, bsz=303.7, num_updates=33900, lr=7.68095e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=69, gb_free=15.3, wall=28244
2023-07-28 09:46:47 | INFO | train_inner | epoch 024:    114 / 1474 loss=1.998, trans_loss=4.978, nll_loss=2.164, w2v_ctc_loss=0.642, task_loss=1.94, contrastive_loss=0.227, total=4168.61, n_correct=2708.54, ppl=4.48, accuracy=64.975, wps=12017, ups=1.44, wpb=8337.2, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=69, gb_free=11.3, wall=28314
2023-07-28 09:46:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 09:47:10 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.21 | trans_loss 5.586 | nll_loss 2.863 | w2v_ctc_loss 1.331 | task_loss 6.922 | contrastive_loss 0.261 | total 4003.4 | n_correct 2469.6 | ppl 7.28 | accuracy 61.688 | uer 17.057 | wer 18.773 | raw_wer 18.773 | bleu 19.84 | wps 2199.4 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.46
2023-07-28 09:47:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-07-28 09:47:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_24_34000.pt
2023-07-28 09:47:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_24_34000.pt
2023-07-28 09:47:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 19.84) (writing took 15.930686006322503 seconds)
2023-07-28 09:48:36 | INFO | train_inner | epoch 024:    214 / 1474 loss=1.997, trans_loss=4.979, nll_loss=2.167, w2v_ctc_loss=0.634, task_loss=1.831, contrastive_loss=0.287, total=4252.53, n_correct=2760.86, ppl=4.49, accuracy=64.923, wps=7790.8, ups=0.92, wpb=8505.1, bsz=341.3, num_updates=34100, lr=7.6584e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=28423
2023-07-28 09:49:44 | INFO | train_inner | epoch 024:    314 / 1474 loss=1.991, trans_loss=4.985, nll_loss=2.173, w2v_ctc_loss=0.647, task_loss=2.046, contrastive_loss=0.059, total=4138.44, n_correct=2685.86, ppl=4.51, accuracy=64.9, wps=12043.3, ups=1.46, wpb=8276.9, bsz=307.1, num_updates=34200, lr=7.64719e-05, gnorm=0.593, clip=0, loss_scale=32, train_wall=68, gb_free=15.5, wall=28492
2023-07-28 09:50:54 | INFO | train_inner | epoch 024:    414 / 1474 loss=2.014, trans_loss=4.991, nll_loss=2.181, w2v_ctc_loss=0.659, task_loss=2.22, contrastive_loss=0.207, total=4153.83, n_correct=2684.45, ppl=4.53, accuracy=64.626, wps=11886.4, ups=1.43, wpb=8307.7, bsz=298.4, num_updates=34300, lr=7.63604e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=28561
2023-07-28 09:52:03 | INFO | train_inner | epoch 024:    514 / 1474 loss=2, trans_loss=4.991, nll_loss=2.18, w2v_ctc_loss=0.65, task_loss=2.143, contrastive_loss=0.13, total=4141.88, n_correct=2683.43, ppl=4.53, accuracy=64.788, wps=12007.3, ups=1.45, wpb=8283.8, bsz=302.6, num_updates=34400, lr=7.62493e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=68, gb_free=15.1, wall=28630
2023-07-28 09:53:12 | INFO | train_inner | epoch 024:    614 / 1474 loss=1.994, trans_loss=4.989, nll_loss=2.179, w2v_ctc_loss=0.64, task_loss=2.111, contrastive_loss=0.096, total=4162.06, n_correct=2698.76, ppl=4.53, accuracy=64.842, wps=12131.5, ups=1.46, wpb=8324.1, bsz=308.1, num_updates=34500, lr=7.61387e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=28699
2023-07-28 09:54:21 | INFO | train_inner | epoch 024:    714 / 1474 loss=2.004, trans_loss=5.003, nll_loss=2.197, w2v_ctc_loss=0.651, task_loss=2.177, contrastive_loss=0.103, total=4097.35, n_correct=2646.66, ppl=4.58, accuracy=64.594, wps=11806, ups=1.44, wpb=8194.7, bsz=293.8, num_updates=34600, lr=7.60286e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=28769
2023-07-28 09:55:31 | INFO | train_inner | epoch 024:    814 / 1474 loss=2.001, trans_loss=5.005, nll_loss=2.2, w2v_ctc_loss=0.649, task_loss=2.091, contrastive_loss=0.085, total=4124.25, n_correct=2661.59, ppl=4.6, accuracy=64.535, wps=11933, ups=1.45, wpb=8248.5, bsz=308.2, num_updates=34700, lr=7.5919e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=28838
2023-07-28 09:56:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-28 09:56:39 | INFO | train_inner | epoch 024:    915 / 1474 loss=2.01, trans_loss=5.011, nll_loss=2.206, w2v_ctc_loss=0.66, task_loss=2.353, contrastive_loss=0.054, total=4045.34, n_correct=2599.25, ppl=4.61, accuracy=64.253, wps=11754.1, ups=1.45, wpb=8090.7, bsz=279.9, num_updates=34800, lr=7.58098e-05, gnorm=0.599, clip=0, loss_scale=16, train_wall=68, gb_free=12.2, wall=28906
2023-07-28 09:57:49 | INFO | train_inner | epoch 024:   1015 / 1474 loss=2, trans_loss=5.004, nll_loss=2.199, w2v_ctc_loss=0.648, task_loss=2.201, contrastive_loss=0.06, total=4124.2, n_correct=2664.35, ppl=4.59, accuracy=64.603, wps=11859.6, ups=1.44, wpb=8248.4, bsz=295.7, num_updates=34900, lr=7.57011e-05, gnorm=0.581, clip=0, loss_scale=16, train_wall=69, gb_free=13.2, wall=28976
2023-07-28 09:58:57 | INFO | train_inner | epoch 024:   1115 / 1474 loss=2.001, trans_loss=4.995, nll_loss=2.188, w2v_ctc_loss=0.655, task_loss=2.004, contrastive_loss=0.105, total=4133.96, n_correct=2675.96, ppl=4.56, accuracy=64.731, wps=12064.5, ups=1.46, wpb=8267.9, bsz=310.6, num_updates=35000, lr=7.55929e-05, gnorm=0.584, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=29045
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:0')
2023-07-28 10:00:07 | INFO | train_inner | epoch 024:   1215 / 1474 loss=1.999, trans_loss=5.002, nll_loss=2.198, w2v_ctc_loss=0.646, task_loss=2.087, contrastive_loss=0.096, total=4152.6, n_correct=2683.58, ppl=4.59, accuracy=64.624, wps=12007, ups=1.45, wpb=8305.2, bsz=310.7, num_updates=35100, lr=7.54851e-05, gnorm=0.578, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=29114
2023-07-28 10:01:16 | INFO | train_inner | epoch 024:   1315 / 1474 loss=2.011, trans_loss=5.013, nll_loss=2.21, w2v_ctc_loss=0.666, task_loss=2.253, contrastive_loss=0.066, total=4108.12, n_correct=2643.91, ppl=4.63, accuracy=64.358, wps=11828.8, ups=1.44, wpb=8216.2, bsz=293.3, num_updates=35200, lr=7.53778e-05, gnorm=0.578, clip=0, loss_scale=16, train_wall=69, gb_free=12.9, wall=29183
2023-07-28 10:02:25 | INFO | train_inner | epoch 024:   1415 / 1474 loss=2.01, trans_loss=5.015, nll_loss=2.213, w2v_ctc_loss=0.663, task_loss=2.175, contrastive_loss=0.065, total=4099.36, n_correct=2636.6, ppl=4.64, accuracy=64.317, wps=11963.2, ups=1.46, wpb=8198.7, bsz=294.7, num_updates=35300, lr=7.5271e-05, gnorm=0.589, clip=0, loss_scale=16, train_wall=68, gb_free=15.2, wall=29252
2023-07-28 10:03:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:3')
2023-07-28 10:03:29 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.188 | trans_loss 5.572 | nll_loss 2.845 | w2v_ctc_loss 1.294 | task_loss 6.992 | contrastive_loss 0.253 | total 4003.4 | n_correct 2481.5 | ppl 7.19 | accuracy 61.985 | uer 16.869 | wer 18.664 | raw_wer 18.664 | bleu 20.09 | wps 2112.7 | wpb 4003.4 | bsz 141.8 | num_updates 35359 | best_bleu 20.46
2023-07-28 10:03:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35359 updates
2023-07-28 10:03:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.0901.pt
2023-07-28 10:03:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.0901.pt
2023-07-28 10:03:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.0901.pt (epoch 24 @ 35359 updates, score 20.09) (writing took 11.29755668155849 seconds)
2023-07-28 10:03:41 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-07-28 10:03:41 | INFO | train | epoch 024 | loss 2.001 | trans_loss 4.997 | nll_loss 2.19 | w2v_ctc_loss 0.65 | task_loss 2.103 | contrastive_loss 0.117 | total 4138.86 | n_correct 2676.16 | ppl 4.56 | accuracy 64.659 | wps 11056.2 | ups 1.34 | wpb 8277.7 | bsz 305.7 | num_updates 35359 | lr 7.52082e-05 | gnorm 0.579 | clip 0 | loss_scale 16 | train_wall 1010 | gb_free 16.1 | wall 29328
2023-07-28 10:03:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 10:03:41 | INFO | fairseq.trainer | begin training epoch 25
2023-07-28 10:03:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 10:04:18 | INFO | train_inner | epoch 025:     41 / 1474 loss=1.992, trans_loss=4.988, nll_loss=2.178, w2v_ctc_loss=0.647, task_loss=2.043, contrastive_loss=0.071, total=4161.08, n_correct=2702.78, ppl=4.53, accuracy=64.954, wps=7359.9, ups=0.88, wpb=8322.2, bsz=309.6, num_updates=35400, lr=7.51646e-05, gnorm=0.594, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=29365
2023-07-28 10:05:27 | INFO | train_inner | epoch 025:    141 / 1474 loss=1.979, trans_loss=4.966, nll_loss=2.15, w2v_ctc_loss=0.634, task_loss=2.038, contrastive_loss=0.071, total=4139.23, n_correct=2702.35, ppl=4.44, accuracy=65.286, wps=11983.8, ups=1.45, wpb=8278.5, bsz=309.8, num_updates=35500, lr=7.50587e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=29434
2023-07-28 10:06:36 | INFO | train_inner | epoch 025:    241 / 1474 loss=1.984, trans_loss=4.971, nll_loss=2.156, w2v_ctc_loss=0.638, task_loss=2.159, contrastive_loss=0.075, total=4117.76, n_correct=2683.3, ppl=4.46, accuracy=65.164, wps=11845.3, ups=1.44, wpb=8235.5, bsz=302.9, num_updates=35600, lr=7.49532e-05, gnorm=0.579, clip=0, loss_scale=16, train_wall=69, gb_free=16.9, wall=29503
2023-07-28 10:07:45 | INFO | train_inner | epoch 025:    341 / 1474 loss=1.994, trans_loss=4.98, nll_loss=2.166, w2v_ctc_loss=0.643, task_loss=2.23, contrastive_loss=0.101, total=4142.17, n_correct=2687.01, ppl=4.49, accuracy=64.87, wps=12015.2, ups=1.45, wpb=8284.3, bsz=295.5, num_updates=35700, lr=7.48481e-05, gnorm=0.588, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=29572
2023-07-28 10:08:55 | INFO | train_inner | epoch 025:    441 / 1474 loss=2.011, trans_loss=4.987, nll_loss=2.175, w2v_ctc_loss=0.661, task_loss=2.205, contrastive_loss=0.18, total=4167.72, n_correct=2698.45, ppl=4.52, accuracy=64.746, wps=12028.9, ups=1.44, wpb=8335.4, bsz=296.8, num_updates=35800, lr=7.47435e-05, gnorm=0.589, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=29642
2023-07-28 10:10:04 | INFO | train_inner | epoch 025:    541 / 1474 loss=1.993, trans_loss=4.99, nll_loss=2.181, w2v_ctc_loss=0.648, task_loss=2.049, contrastive_loss=0.075, total=4154.79, n_correct=2698.27, ppl=4.53, accuracy=64.944, wps=11913.4, ups=1.43, wpb=8309.6, bsz=313.5, num_updates=35900, lr=7.46393e-05, gnorm=0.578, clip=0, loss_scale=16, train_wall=69, gb_free=17.6, wall=29711
2023-07-28 10:11:14 | INFO | train_inner | epoch 025:    641 / 1474 loss=1.998, trans_loss=4.984, nll_loss=2.173, w2v_ctc_loss=0.65, task_loss=2.083, contrastive_loss=0.141, total=4156.33, n_correct=2692.92, ppl=4.51, accuracy=64.791, wps=11957.7, ups=1.44, wpb=8312.7, bsz=309.3, num_updates=36000, lr=7.45356e-05, gnorm=0.584, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=29781
2023-07-28 10:11:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 10:11:37 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.2 | trans_loss 5.579 | nll_loss 2.857 | w2v_ctc_loss 1.317 | task_loss 6.918 | contrastive_loss 0.252 | total 4003.4 | n_correct 2474.5 | ppl 7.25 | accuracy 61.81 | uer 16.824 | wer 18.769 | raw_wer 18.769 | bleu 19.91 | wps 2125.5 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.46
2023-07-28 10:11:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-07-28 10:11:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_25_36000.pt
2023-07-28 10:11:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_25_36000.pt
2023-07-28 10:11:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 19.91) (writing took 15.534402692690492 seconds)
2023-07-28 10:13:03 | INFO | train_inner | epoch 025:    741 / 1474 loss=1.998, trans_loss=4.987, nll_loss=2.178, w2v_ctc_loss=0.646, task_loss=2.114, contrastive_loss=0.137, total=4133.94, n_correct=2682.65, ppl=4.52, accuracy=64.893, wps=7608.1, ups=0.92, wpb=8267.9, bsz=303.3, num_updates=36100, lr=7.44323e-05, gnorm=0.58, clip=0, loss_scale=16, train_wall=68, gb_free=15, wall=29890
2023-07-28 10:14:12 | INFO | train_inner | epoch 025:    841 / 1474 loss=1.988, trans_loss=4.987, nll_loss=2.178, w2v_ctc_loss=0.641, task_loss=1.944, contrastive_loss=0.084, total=4174.24, n_correct=2712.01, ppl=4.53, accuracy=64.97, wps=12089.6, ups=1.45, wpb=8348.5, bsz=324, num_updates=36200, lr=7.43294e-05, gnorm=0.583, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=29959
2023-07-28 10:15:21 | INFO | train_inner | epoch 025:    941 / 1474 loss=1.998, trans_loss=4.994, nll_loss=2.188, w2v_ctc_loss=0.647, task_loss=1.995, contrastive_loss=0.14, total=4154.13, n_correct=2689.94, ppl=4.56, accuracy=64.753, wps=11901.3, ups=1.43, wpb=8308.3, bsz=316.7, num_updates=36300, lr=7.4227e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=69, gb_free=10.8, wall=30029
2023-07-28 10:16:30 | INFO | train_inner | epoch 025:   1041 / 1474 loss=2.006, trans_loss=5.001, nll_loss=2.196, w2v_ctc_loss=0.638, task_loss=2.086, contrastive_loss=0.25, total=4178.3, n_correct=2700.24, ppl=4.58, accuracy=64.625, wps=12117.4, ups=1.45, wpb=8356.6, bsz=309.7, num_updates=36400, lr=7.41249e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=30097
2023-07-28 10:17:39 | INFO | train_inner | epoch 025:   1141 / 1474 loss=1.991, trans_loss=4.994, nll_loss=2.186, w2v_ctc_loss=0.637, task_loss=2.249, contrastive_loss=0.053, total=4042.33, n_correct=2619.29, ppl=4.55, accuracy=64.797, wps=11744.4, ups=1.45, wpb=8084.7, bsz=286.5, num_updates=36500, lr=7.40233e-05, gnorm=0.579, clip=0, loss_scale=16, train_wall=68, gb_free=17.8, wall=30166
2023-07-28 10:18:48 | INFO | train_inner | epoch 025:   1241 / 1474 loss=1.994, trans_loss=4.998, nll_loss=2.192, w2v_ctc_loss=0.641, task_loss=2.134, contrastive_loss=0.064, total=4087.78, n_correct=2644.56, ppl=4.57, accuracy=64.694, wps=11910.3, ups=1.46, wpb=8175.6, bsz=295.1, num_updates=36600, lr=7.39221e-05, gnorm=0.579, clip=0, loss_scale=16, train_wall=68, gb_free=17.7, wall=30235
2023-07-28 10:19:57 | INFO | train_inner | epoch 025:   1341 / 1474 loss=2.002, trans_loss=4.997, nll_loss=2.191, w2v_ctc_loss=0.647, task_loss=2.052, contrastive_loss=0.158, total=4166.64, n_correct=2694.29, ppl=4.57, accuracy=64.663, wps=11996.4, ups=1.44, wpb=8333.3, bsz=309.3, num_updates=36700, lr=7.38213e-05, gnorm=0.575, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=30304
2023-07-28 10:21:07 | INFO | train_inner | epoch 025:   1441 / 1474 loss=2.009, trans_loss=5.013, nll_loss=2.211, w2v_ctc_loss=0.653, task_loss=2.139, contrastive_loss=0.13, total=4114.64, n_correct=2646.24, ppl=4.63, accuracy=64.313, wps=11779.3, ups=1.43, wpb=8229.3, bsz=304.3, num_updates=36800, lr=7.3721e-05, gnorm=0.584, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=30374
2023-07-28 10:21:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 10:21:53 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.194 | trans_loss 5.571 | nll_loss 2.847 | w2v_ctc_loss 1.311 | task_loss 6.915 | contrastive_loss 0.258 | total 4003.4 | n_correct 2478.4 | ppl 7.2 | accuracy 61.907 | uer 17.017 | wer 18.981 | raw_wer 18.981 | bleu 20.11 | wps 2219.8 | wpb 4003.4 | bsz 141.8 | num_updates 36833 | best_bleu 20.46
2023-07-28 10:21:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36833 updates
2023-07-28 10:21:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.1101.pt
2023-07-28 10:21:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.1101.pt
2023-07-28 10:22:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.1101.pt (epoch 25 @ 36833 updates, score 20.11) (writing took 11.306071504950523 seconds)
2023-07-28 10:22:05 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-07-28 10:22:05 | INFO | train | epoch 025 | loss 1.996 | trans_loss 4.989 | nll_loss 2.18 | w2v_ctc_loss 0.645 | task_loss 2.099 | contrastive_loss 0.116 | total 4138.65 | n_correct 2682.86 | ppl 4.53 | accuracy 64.825 | wps 11056.5 | ups 1.34 | wpb 8277.3 | bsz 305.7 | num_updates 36833 | lr 7.36879e-05 | gnorm 0.58 | clip 0 | loss_scale 16 | train_wall 1013 | gb_free 14.2 | wall 30432
2023-07-28 10:22:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 10:22:05 | INFO | fairseq.trainer | begin training epoch 26
2023-07-28 10:22:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 10:23:00 | INFO | train_inner | epoch 026:     67 / 1474 loss=1.98, trans_loss=4.966, nll_loss=2.15, w2v_ctc_loss=0.634, task_loss=1.987, contrastive_loss=0.093, total=4172.16, n_correct=2722.06, ppl=4.44, accuracy=65.243, wps=7415, ups=0.89, wpb=8344.3, bsz=316.9, num_updates=36900, lr=7.3621e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=30487
2023-07-28 10:24:09 | INFO | train_inner | epoch 026:    167 / 1474 loss=1.984, trans_loss=4.962, nll_loss=2.145, w2v_ctc_loss=0.623, task_loss=1.85, contrastive_loss=0.267, total=4265.22, n_correct=2789.22, ppl=4.42, accuracy=65.395, wps=12262.5, ups=1.44, wpb=8530.4, bsz=338.7, num_updates=37000, lr=7.35215e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=69, gb_free=15.4, wall=30556
2023-07-28 10:25:18 | INFO | train_inner | epoch 026:    267 / 1474 loss=1.991, trans_loss=4.969, nll_loss=2.153, w2v_ctc_loss=0.642, task_loss=2.08, contrastive_loss=0.155, total=4123.94, n_correct=2689.34, ppl=4.45, accuracy=65.213, wps=11954.4, ups=1.45, wpb=8247.9, bsz=306.6, num_updates=37100, lr=7.34223e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=30625
2023-07-28 10:25:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-28 10:26:28 | INFO | train_inner | epoch 026:    368 / 1474 loss=1.986, trans_loss=4.972, nll_loss=2.158, w2v_ctc_loss=0.639, task_loss=1.995, contrastive_loss=0.115, total=4167.04, n_correct=2716.4, ppl=4.46, accuracy=65.188, wps=11976.3, ups=1.44, wpb=8334.1, bsz=315.5, num_updates=37200, lr=7.33236e-05, gnorm=0.583, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=30695
2023-07-28 10:27:37 | INFO | train_inner | epoch 026:    468 / 1474 loss=1.984, trans_loss=4.964, nll_loss=2.148, w2v_ctc_loss=0.635, task_loss=2.017, contrastive_loss=0.156, total=4167.54, n_correct=2725.92, ppl=4.43, accuracy=65.408, wps=12077.7, ups=1.45, wpb=8335.1, bsz=314.7, num_updates=37300, lr=7.32252e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=68, gb_free=17.6, wall=30764
2023-07-28 10:28:46 | INFO | train_inner | epoch 026:    568 / 1474 loss=1.99, trans_loss=4.977, nll_loss=2.164, w2v_ctc_loss=0.65, task_loss=2.105, contrastive_loss=0.077, total=4158.38, n_correct=2706.51, ppl=4.48, accuracy=65.086, wps=12072.5, ups=1.45, wpb=8316.8, bsz=303.9, num_updates=37400, lr=7.31272e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=30833
2023-07-28 10:29:55 | INFO | train_inner | epoch 026:    668 / 1474 loss=1.985, trans_loss=4.979, nll_loss=2.166, w2v_ctc_loss=0.634, task_loss=2.153, contrastive_loss=0.062, total=4132.34, n_correct=2689.21, ppl=4.49, accuracy=65.077, wps=11986, ups=1.45, wpb=8264.7, bsz=297.7, num_updates=37500, lr=7.30297e-05, gnorm=0.576, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=30902
2023-07-28 10:31:04 | INFO | train_inner | epoch 026:    768 / 1474 loss=1.997, trans_loss=4.984, nll_loss=2.174, w2v_ctc_loss=0.64, task_loss=2.123, contrastive_loss=0.175, total=4092.35, n_correct=2654.91, ppl=4.51, accuracy=64.875, wps=11887.2, ups=1.45, wpb=8184.7, bsz=300.1, num_updates=37600, lr=7.29325e-05, gnorm=0.59, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=30971
2023-07-28 10:32:13 | INFO | train_inner | epoch 026:    868 / 1474 loss=1.992, trans_loss=4.982, nll_loss=2.17, w2v_ctc_loss=0.647, task_loss=2.111, contrastive_loss=0.077, total=4176.13, n_correct=2708.94, ppl=4.5, accuracy=64.867, wps=12022.2, ups=1.44, wpb=8352.3, bsz=305.9, num_updates=37700, lr=7.28357e-05, gnorm=0.58, clip=0, loss_scale=16, train_wall=69, gb_free=16.7, wall=31040
2023-07-28 10:33:23 | INFO | train_inner | epoch 026:    968 / 1474 loss=1.993, trans_loss=4.99, nll_loss=2.181, w2v_ctc_loss=0.633, task_loss=2.167, contrastive_loss=0.13, total=4142.72, n_correct=2684.67, ppl=4.54, accuracy=64.805, wps=11937.4, ups=1.44, wpb=8285.4, bsz=300, num_updates=37800, lr=7.27393e-05, gnorm=0.572, clip=0, loss_scale=16, train_wall=69, gb_free=17.6, wall=31110
2023-07-28 10:34:31 | INFO | train_inner | epoch 026:   1068 / 1474 loss=1.988, trans_loss=4.986, nll_loss=2.176, w2v_ctc_loss=0.638, task_loss=2.206, contrastive_loss=0.06, total=4116.69, n_correct=2677.32, ppl=4.52, accuracy=65.036, wps=11939.2, ups=1.45, wpb=8233.4, bsz=294.1, num_updates=37900, lr=7.26433e-05, gnorm=0.576, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=31179
2023-07-28 10:35:41 | INFO | train_inner | epoch 026:   1168 / 1474 loss=1.995, trans_loss=4.993, nll_loss=2.184, w2v_ctc_loss=0.642, task_loss=2.193, contrastive_loss=0.099, total=4112.79, n_correct=2664.51, ppl=4.55, accuracy=64.786, wps=11857.8, ups=1.44, wpb=8225.6, bsz=299, num_updates=38000, lr=7.25476e-05, gnorm=0.572, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=31248
2023-07-28 10:35:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 10:36:04 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.211 | trans_loss 5.579 | nll_loss 2.858 | w2v_ctc_loss 1.351 | task_loss 6.958 | contrastive_loss 0.255 | total 4003.4 | n_correct 2475.6 | ppl 7.25 | accuracy 61.837 | uer 17.049 | wer 18.911 | raw_wer 18.911 | bleu 19.96 | wps 2163.4 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.46
2023-07-28 10:36:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-07-28 10:36:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_26_38000.pt
2023-07-28 10:36:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_26_38000.pt
2023-07-28 10:36:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 19.96) (writing took 31.767166428267956 seconds)
2023-07-28 10:37:49 | INFO | train_inner | epoch 026:   1268 / 1474 loss=2.005, trans_loss=5.007, nll_loss=2.202, w2v_ctc_loss=0.657, task_loss=2.331, contrastive_loss=0.064, total=4005.82, n_correct=2581.27, ppl=4.6, accuracy=64.438, wps=6270.3, ups=0.78, wpb=8011.6, bsz=280.5, num_updates=38100, lr=7.24524e-05, gnorm=0.597, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=31376
2023-07-28 10:38:59 | INFO | train_inner | epoch 026:   1368 / 1474 loss=1.99, trans_loss=4.995, nll_loss=2.188, w2v_ctc_loss=0.634, task_loss=2.096, contrastive_loss=0.08, total=4158.84, n_correct=2697.4, ppl=4.56, accuracy=64.859, wps=11755.5, ups=1.41, wpb=8317.7, bsz=311.2, num_updates=38200, lr=7.23575e-05, gnorm=0.576, clip=0, loss_scale=16, train_wall=70, gb_free=13.6, wall=31446
2023-07-28 10:40:08 | INFO | train_inner | epoch 026:   1468 / 1474 loss=1.982, trans_loss=4.987, nll_loss=2.179, w2v_ctc_loss=0.63, task_loss=2.006, contrastive_loss=0.072, total=4151.66, n_correct=2702.95, ppl=4.53, accuracy=65.105, wps=12112.6, ups=1.46, wpb=8303.3, bsz=315.5, num_updates=38300, lr=7.22629e-05, gnorm=0.572, clip=0, loss_scale=16, train_wall=68, gb_free=17.5, wall=31515
2023-07-28 10:40:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 10:40:35 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.193 | trans_loss 5.578 | nll_loss 2.854 | w2v_ctc_loss 1.3 | task_loss 6.902 | contrastive_loss 0.247 | total 4003.4 | n_correct 2484 | ppl 7.23 | accuracy 62.047 | uer 17.017 | wer 18.829 | raw_wer 18.829 | bleu 20.33 | wps 2221.2 | wpb 4003.4 | bsz 141.8 | num_updates 38306 | best_bleu 20.46
2023-07-28 10:40:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38306 updates
2023-07-28 10:40:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.3302.pt
2023-07-28 10:40:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.3302.pt
2023-07-28 10:40:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.3302.pt (epoch 26 @ 38306 updates, score 20.33) (writing took 11.763185128569603 seconds)
2023-07-28 10:40:47 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-07-28 10:40:47 | INFO | train | epoch 026 | loss 1.989 | trans_loss 4.98 | nll_loss 2.168 | w2v_ctc_loss 0.638 | task_loss 2.099 | contrastive_loss 0.114 | total 4138.74 | n_correct 2691.71 | ppl 4.5 | accuracy 65.037 | wps 10859.4 | ups 1.31 | wpb 8277.5 | bsz 305.7 | num_updates 38306 | lr 7.22573e-05 | gnorm 0.577 | clip 0 | loss_scale 16 | train_wall 1012 | gb_free 15.9 | wall 31554
2023-07-28 10:40:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 10:40:48 | INFO | fairseq.trainer | begin training epoch 27
2023-07-28 10:40:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 10:41:59 | INFO | train_inner | epoch 027:     94 / 1474 loss=1.97, trans_loss=4.946, nll_loss=2.122, w2v_ctc_loss=0.623, task_loss=2.243, contrastive_loss=0.049, total=4072.63, n_correct=2671.47, ppl=4.35, accuracy=65.596, wps=7327.2, ups=0.9, wpb=8145.3, bsz=284.2, num_updates=38400, lr=7.21688e-05, gnorm=0.596, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=31626
2023-07-28 10:43:09 | INFO | train_inner | epoch 027:    194 / 1474 loss=1.973, trans_loss=4.954, nll_loss=2.134, w2v_ctc_loss=0.633, task_loss=2.011, contrastive_loss=0.083, total=4179.66, n_correct=2740.64, ppl=4.39, accuracy=65.571, wps=11954.5, ups=1.43, wpb=8359.3, bsz=321.7, num_updates=38500, lr=7.2075e-05, gnorm=0.587, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=31696
2023-07-28 10:44:19 | INFO | train_inner | epoch 027:    294 / 1474 loss=1.975, trans_loss=4.961, nll_loss=2.142, w2v_ctc_loss=0.631, task_loss=2.088, contrastive_loss=0.063, total=4173.27, n_correct=2735.86, ppl=4.41, accuracy=65.557, wps=11864.9, ups=1.42, wpb=8346.5, bsz=307, num_updates=38600, lr=7.19816e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=70, gb_free=16.9, wall=31766
2023-07-28 10:45:36 | INFO | train_inner | epoch 027:    394 / 1474 loss=1.992, trans_loss=4.968, nll_loss=2.152, w2v_ctc_loss=0.629, task_loss=2.19, contrastive_loss=0.247, total=4078.73, n_correct=2663.29, ppl=4.44, accuracy=65.297, wps=10717, ups=1.31, wpb=8157.5, bsz=297.5, num_updates=38700, lr=7.18885e-05, gnorm=0.585, clip=0, loss_scale=16, train_wall=76, gb_free=16.4, wall=31843
2023-07-28 10:46:50 | INFO | train_inner | epoch 027:    494 / 1474 loss=1.986, trans_loss=4.973, nll_loss=2.161, w2v_ctc_loss=0.63, task_loss=1.92, contrastive_loss=0.187, total=4245.37, n_correct=2766.75, ppl=4.47, accuracy=65.171, wps=11423.6, ups=1.35, wpb=8490.7, bsz=331.5, num_updates=38800, lr=7.17958e-05, gnorm=0.582, clip=0, loss_scale=16, train_wall=74, gb_free=16.8, wall=31917
2023-07-28 10:48:01 | INFO | train_inner | epoch 027:    594 / 1474 loss=1.988, trans_loss=4.972, nll_loss=2.158, w2v_ctc_loss=0.641, task_loss=2.056, contrastive_loss=0.124, total=4134.93, n_correct=2696.37, ppl=4.46, accuracy=65.21, wps=11679.8, ups=1.41, wpb=8269.9, bsz=312, num_updates=38900, lr=7.17035e-05, gnorm=0.581, clip=0, loss_scale=16, train_wall=70, gb_free=17.6, wall=31988
2023-07-28 10:49:10 | INFO | train_inner | epoch 027:    694 / 1474 loss=1.987, trans_loss=4.975, nll_loss=2.161, w2v_ctc_loss=0.639, task_loss=2.094, contrastive_loss=0.102, total=4162.17, n_correct=2712.81, ppl=4.47, accuracy=65.178, wps=12036.4, ups=1.45, wpb=8324.3, bsz=305.1, num_updates=39000, lr=7.16115e-05, gnorm=0.587, clip=0, loss_scale=16, train_wall=69, gb_free=15.4, wall=32057
2023-07-28 10:50:18 | INFO | train_inner | epoch 027:    794 / 1474 loss=1.985, trans_loss=4.976, nll_loss=2.162, w2v_ctc_loss=0.638, task_loss=2.199, contrastive_loss=0.064, total=4107.17, n_correct=2673.18, ppl=4.48, accuracy=65.086, wps=11994.4, ups=1.46, wpb=8214.3, bsz=294.3, num_updates=39100, lr=7.15199e-05, gnorm=0.582, clip=0, loss_scale=16, train_wall=68, gb_free=11.4, wall=32125
2023-07-28 10:51:27 | INFO | train_inner | epoch 027:    894 / 1474 loss=1.98, trans_loss=4.98, nll_loss=2.167, w2v_ctc_loss=0.625, task_loss=2.175, contrastive_loss=0.053, total=4101.4, n_correct=2673.35, ppl=4.49, accuracy=65.181, wps=11943.5, ups=1.46, wpb=8202.8, bsz=292.8, num_updates=39200, lr=7.14286e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=32194
2023-07-28 10:52:37 | INFO | train_inner | epoch 027:    994 / 1474 loss=1.99, trans_loss=4.975, nll_loss=2.162, w2v_ctc_loss=0.629, task_loss=2.031, contrastive_loss=0.244, total=4195.5, n_correct=2733.12, ppl=4.48, accuracy=65.144, wps=11981.1, ups=1.43, wpb=8391, bsz=315.9, num_updates=39300, lr=7.13376e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=70, gb_free=16.8, wall=32264
2023-07-28 10:53:48 | INFO | train_inner | epoch 027:   1094 / 1474 loss=1.978, trans_loss=4.974, nll_loss=2.16, w2v_ctc_loss=0.628, task_loss=2.115, contrastive_loss=0.076, total=4147.99, n_correct=2704.81, ppl=4.47, accuracy=65.208, wps=11622.5, ups=1.4, wpb=8296, bsz=304.7, num_updates=39400, lr=7.1247e-05, gnorm=0.586, clip=0, loss_scale=32, train_wall=71, gb_free=16.1, wall=32336
2023-07-28 10:54:58 | INFO | train_inner | epoch 027:   1194 / 1474 loss=1.991, trans_loss=4.984, nll_loss=2.174, w2v_ctc_loss=0.644, task_loss=2.199, contrastive_loss=0.08, total=4104.84, n_correct=2667.61, ppl=4.51, accuracy=64.987, wps=11716.1, ups=1.43, wpb=8209.7, bsz=297.2, num_updates=39500, lr=7.11568e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=70, gb_free=12.1, wall=32406
2023-07-28 10:56:07 | INFO | train_inner | epoch 027:   1294 / 1474 loss=1.997, trans_loss=4.99, nll_loss=2.182, w2v_ctc_loss=0.639, task_loss=2.228, contrastive_loss=0.128, total=4062.86, n_correct=2633.28, ppl=4.54, accuracy=64.813, wps=11796.8, ups=1.45, wpb=8125.7, bsz=293.6, num_updates=39600, lr=7.10669e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=32474
2023-07-28 10:57:15 | INFO | train_inner | epoch 027:   1394 / 1474 loss=1.983, trans_loss=4.981, nll_loss=2.171, w2v_ctc_loss=0.628, task_loss=1.979, contrastive_loss=0.116, total=4157.6, n_correct=2710.08, ppl=4.5, accuracy=65.184, wps=12276.7, ups=1.48, wpb=8315.2, bsz=314, num_updates=39700, lr=7.09773e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=67, gb_free=17.6, wall=32542
2023-07-28 10:58:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 10:58:35 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.204 | trans_loss 5.572 | nll_loss 2.846 | w2v_ctc_loss 1.348 | task_loss 6.945 | contrastive_loss 0.251 | total 4003.4 | n_correct 2481.9 | ppl 7.19 | accuracy 61.995 | uer 16.911 | wer 18.743 | raw_wer 18.743 | bleu 20.42 | wps 2068.6 | wpb 4003.4 | bsz 141.8 | num_updates 39780 | best_bleu 20.46
2023-07-28 10:58:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39780 updates
2023-07-28 10:58:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.4202.pt
2023-07-28 10:58:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.4202.pt
2023-07-28 10:58:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.4202.pt (epoch 27 @ 39780 updates, score 20.42) (writing took 16.904755795374513 seconds)
2023-07-28 10:58:52 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-07-28 10:58:52 | INFO | train | epoch 027 | loss 1.983 | trans_loss 4.972 | nll_loss 2.158 | w2v_ctc_loss 0.632 | task_loss 2.098 | contrastive_loss 0.114 | total 4138.65 | n_correct 2699.75 | ppl 4.46 | accuracy 65.233 | wps 11244.6 | ups 1.36 | wpb 8277.3 | bsz 305.7 | num_updates 39780 | lr 7.09059e-05 | gnorm 0.581 | clip 0 | loss_scale 32 | train_wall 1028 | gb_free 17.8 | wall 32640
2023-07-28 10:58:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 10:58:53 | INFO | fairseq.trainer | begin training epoch 28
2023-07-28 10:58:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 10:59:15 | INFO | train_inner | epoch 028:     20 / 1474 loss=1.974, trans_loss=4.972, nll_loss=2.158, w2v_ctc_loss=0.623, task_loss=2.042, contrastive_loss=0.062, total=4107.3, n_correct=2684.69, ppl=4.46, accuracy=65.364, wps=6842.4, ups=0.83, wpb=8214.6, bsz=304.5, num_updates=39800, lr=7.08881e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=69, gb_free=17.3, wall=32662
2023-07-28 11:00:24 | INFO | train_inner | epoch 028:    120 / 1474 loss=1.967, trans_loss=4.942, nll_loss=2.118, w2v_ctc_loss=0.625, task_loss=2.199, contrastive_loss=0.057, total=4112.44, n_correct=2709.51, ppl=4.34, accuracy=65.886, wps=11877.1, ups=1.44, wpb=8224.9, bsz=292.7, num_updates=39900, lr=7.07992e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=69, gb_free=13.7, wall=32732
2023-07-28 11:01:38 | INFO | train_inner | epoch 028:    220 / 1474 loss=1.965, trans_loss=4.952, nll_loss=2.131, w2v_ctc_loss=0.618, task_loss=1.986, contrastive_loss=0.07, total=4193.3, n_correct=2756.24, ppl=4.38, accuracy=65.73, wps=11402, ups=1.36, wpb=8386.6, bsz=316.4, num_updates=40000, lr=7.07107e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=73, gb_free=16.9, wall=32805
2023-07-28 11:01:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 11:02:06 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.208 | trans_loss 5.579 | nll_loss 2.855 | w2v_ctc_loss 1.343 | task_loss 6.947 | contrastive_loss 0.252 | total 4003.4 | n_correct 2480.4 | ppl 7.24 | accuracy 61.957 | uer 16.871 | wer 18.758 | raw_wer 18.758 | bleu 20.18 | wps 1796.6 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.46
2023-07-28 11:02:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-07-28 11:02:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_28_40000.pt
2023-07-28 11:02:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_28_40000.pt
2023-07-28 11:02:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 20.18) (writing took 32.67027541436255 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:0')
2023-07-28 11:03:49 | INFO | train_inner | epoch 028:    320 / 1474 loss=1.995, trans_loss=4.96, nll_loss=2.143, w2v_ctc_loss=0.621, task_loss=2.103, contrastive_loss=0.399, total=4138.69, n_correct=2701.74, ppl=4.42, accuracy=65.28, wps=6307, ups=0.76, wpb=8277.4, bsz=314.4, num_updates=40100, lr=7.06225e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=70, gb_free=13.2, wall=32936
2023-07-28 11:04:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-28 11:04:59 | INFO | train_inner | epoch 028:    421 / 1474 loss=1.976, trans_loss=4.959, nll_loss=2.14, w2v_ctc_loss=0.632, task_loss=2.205, contrastive_loss=0.052, total=4077.02, n_correct=2672.66, ppl=4.41, accuracy=65.554, wps=11652.5, ups=1.43, wpb=8154, bsz=292.1, num_updates=40200, lr=7.05346e-05, gnorm=0.586, clip=0, loss_scale=16, train_wall=69, gb_free=17.6, wall=33006
2023-07-28 11:06:08 | INFO | train_inner | epoch 028:    521 / 1474 loss=1.974, trans_loss=4.96, nll_loss=2.142, w2v_ctc_loss=0.625, task_loss=2.162, contrastive_loss=0.074, total=4109.15, n_correct=2690.31, ppl=4.41, accuracy=65.471, wps=12013.4, ups=1.46, wpb=8218.3, bsz=298.6, num_updates=40300, lr=7.0447e-05, gnorm=0.59, clip=0, loss_scale=16, train_wall=68, gb_free=14.9, wall=33075
2023-07-28 11:07:17 | INFO | train_inner | epoch 028:    621 / 1474 loss=1.978, trans_loss=4.97, nll_loss=2.155, w2v_ctc_loss=0.632, task_loss=2.125, contrastive_loss=0.061, total=4178.56, n_correct=2731.13, ppl=4.45, accuracy=65.361, wps=12037.5, ups=1.44, wpb=8357.1, bsz=304.4, num_updates=40400, lr=7.03598e-05, gnorm=0.59, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=33144
2023-07-28 11:08:27 | INFO | train_inner | epoch 028:    721 / 1474 loss=1.979, trans_loss=4.967, nll_loss=2.152, w2v_ctc_loss=0.623, task_loss=1.914, contrastive_loss=0.181, total=4184.74, n_correct=2737.19, ppl=4.45, accuracy=65.409, wps=11968.7, ups=1.43, wpb=8369.5, bsz=327.2, num_updates=40500, lr=7.02728e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=33214
2023-07-28 11:09:36 | INFO | train_inner | epoch 028:    821 / 1474 loss=1.972, trans_loss=4.965, nll_loss=2.15, w2v_ctc_loss=0.625, task_loss=2.07, contrastive_loss=0.057, total=4087.21, n_correct=2677.24, ppl=4.44, accuracy=65.503, wps=11907.5, ups=1.46, wpb=8174.4, bsz=304.8, num_updates=40600, lr=7.01862e-05, gnorm=0.604, clip=0, loss_scale=16, train_wall=68, gb_free=17.1, wall=33283
2023-07-28 11:10:45 | INFO | train_inner | epoch 028:    921 / 1474 loss=1.988, trans_loss=4.976, nll_loss=2.164, w2v_ctc_loss=0.634, task_loss=2.174, contrastive_loss=0.123, total=4119.18, n_correct=2682.28, ppl=4.48, accuracy=65.117, wps=11840.7, ups=1.44, wpb=8238.4, bsz=299.7, num_updates=40700, lr=7.01e-05, gnorm=0.599, clip=0, loss_scale=16, train_wall=69, gb_free=16.9, wall=33352
2023-07-28 11:11:56 | INFO | train_inner | epoch 028:   1021 / 1474 loss=1.991, trans_loss=4.976, nll_loss=2.163, w2v_ctc_loss=0.636, task_loss=2.052, contrastive_loss=0.176, total=4174.98, n_correct=2718.99, ppl=4.48, accuracy=65.126, wps=11839.2, ups=1.42, wpb=8350, bsz=310.9, num_updates=40800, lr=7.0014e-05, gnorm=0.586, clip=0, loss_scale=16, train_wall=70, gb_free=17, wall=33423
2023-07-28 11:13:05 | INFO | train_inner | epoch 028:   1121 / 1474 loss=1.972, trans_loss=4.962, nll_loss=2.147, w2v_ctc_loss=0.624, task_loss=2.015, contrastive_loss=0.082, total=4222.19, n_correct=2765.86, ppl=4.43, accuracy=65.508, wps=12267.7, ups=1.45, wpb=8444.4, bsz=321.5, num_updates=40900, lr=6.99284e-05, gnorm=0.597, clip=0, loss_scale=16, train_wall=68, gb_free=17.8, wall=33492
2023-07-28 11:14:13 | INFO | train_inner | epoch 028:   1221 / 1474 loss=1.975, trans_loss=4.972, nll_loss=2.158, w2v_ctc_loss=0.623, task_loss=2.072, contrastive_loss=0.067, total=4104.72, n_correct=2682.06, ppl=4.46, accuracy=65.341, wps=11921.2, ups=1.45, wpb=8209.4, bsz=305.5, num_updates=41000, lr=6.9843e-05, gnorm=0.601, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=33561
2023-07-28 11:15:24 | INFO | train_inner | epoch 028:   1321 / 1474 loss=1.995, trans_loss=4.985, nll_loss=2.175, w2v_ctc_loss=0.647, task_loss=2.328, contrastive_loss=0.081, total=4074.43, n_correct=2644.37, ppl=4.51, accuracy=64.902, wps=11619, ups=1.43, wpb=8148.9, bsz=282.9, num_updates=41100, lr=6.9758e-05, gnorm=0.607, clip=0, loss_scale=16, train_wall=69, gb_free=17.8, wall=33631
2023-07-28 11:16:34 | INFO | train_inner | epoch 028:   1421 / 1474 loss=1.981, trans_loss=4.974, nll_loss=2.16, w2v_ctc_loss=0.628, task_loss=2.171, contrastive_loss=0.102, total=4156.52, n_correct=2714.01, ppl=4.47, accuracy=65.295, wps=11887.9, ups=1.43, wpb=8313, bsz=300.8, num_updates=41200, lr=6.96733e-05, gnorm=0.572, clip=0, loss_scale=16, train_wall=69, gb_free=17.7, wall=33701
2023-07-28 11:17:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:5')
2023-07-28 11:17:34 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.213 | trans_loss 5.577 | nll_loss 2.851 | w2v_ctc_loss 1.365 | task_loss 6.946 | contrastive_loss 0.251 | total 4003.4 | n_correct 2488.3 | ppl 7.22 | accuracy 62.155 | uer 17.108 | wer 18.929 | raw_wer 18.929 | bleu 20.36 | wps 2107.2 | wpb 4003.4 | bsz 141.8 | num_updates 41253 | best_bleu 20.46
2023-07-28 11:17:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41253 updates
2023-07-28 11:17:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.3601.pt
2023-07-28 11:17:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.3601.pt
2023-07-28 11:17:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.3601.pt (epoch 28 @ 41253 updates, score 20.36) (writing took 14.830885918810964 seconds)
2023-07-28 11:17:49 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-07-28 11:17:49 | INFO | train | epoch 028 | loss 1.979 | trans_loss 4.966 | nll_loss 2.15 | w2v_ctc_loss 0.628 | task_loss 2.104 | contrastive_loss 0.112 | total 4137.89 | n_correct 2706.19 | ppl 4.44 | accuracy 65.4 | wps 10726 | ups 1.3 | wpb 8275.8 | bsz 305.5 | num_updates 41253 | lr 6.96285e-05 | gnorm 0.589 | clip 0 | loss_scale 16 | train_wall 1018 | gb_free 16.4 | wall 33776
2023-07-28 11:17:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 11:17:49 | INFO | fairseq.trainer | begin training epoch 29
2023-07-28 11:17:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 11:18:31 | INFO | train_inner | epoch 029:     47 / 1474 loss=1.971, trans_loss=4.951, nll_loss=2.132, w2v_ctc_loss=0.629, task_loss=2.027, contrastive_loss=0.08, total=4169.02, n_correct=2741.99, ppl=4.38, accuracy=65.771, wps=7087, ups=0.85, wpb=8338, bsz=315.1, num_updates=41300, lr=6.95889e-05, gnorm=0.578, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=33818
2023-07-28 11:19:41 | INFO | train_inner | epoch 029:    147 / 1474 loss=1.971, trans_loss=4.948, nll_loss=2.125, w2v_ctc_loss=0.626, task_loss=2.092, contrastive_loss=0.099, total=4110.03, n_correct=2700.72, ppl=4.36, accuracy=65.71, wps=11761.1, ups=1.43, wpb=8220.1, bsz=305.5, num_updates=41400, lr=6.95048e-05, gnorm=0.597, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=33888
2023-07-28 11:20:51 | INFO | train_inner | epoch 029:    247 / 1474 loss=1.964, trans_loss=4.94, nll_loss=2.117, w2v_ctc_loss=0.608, task_loss=1.911, contrastive_loss=0.182, total=4197.89, n_correct=2767.01, ppl=4.34, accuracy=65.914, wps=12084.6, ups=1.44, wpb=8395.8, bsz=329.5, num_updates=41500, lr=6.9421e-05, gnorm=0.58, clip=0, loss_scale=16, train_wall=69, gb_free=17.5, wall=33958
2023-07-28 11:22:00 | INFO | train_inner | epoch 029:    347 / 1474 loss=1.979, trans_loss=4.963, nll_loss=2.145, w2v_ctc_loss=0.636, task_loss=2.25, contrastive_loss=0.063, total=4094.4, n_correct=2679.98, ppl=4.42, accuracy=65.455, wps=11855.9, ups=1.45, wpb=8188.8, bsz=291.2, num_updates=41600, lr=6.93375e-05, gnorm=0.6, clip=0, loss_scale=16, train_wall=68, gb_free=16.5, wall=34027
2023-07-28 11:23:09 | INFO | train_inner | epoch 029:    447 / 1474 loss=1.958, trans_loss=4.937, nll_loss=2.112, w2v_ctc_loss=0.616, task_loss=2.012, contrastive_loss=0.054, total=4157.41, n_correct=2743.47, ppl=4.32, accuracy=65.99, wps=12019.4, ups=1.45, wpb=8314.8, bsz=308.5, num_updates=41700, lr=6.92543e-05, gnorm=0.602, clip=0, loss_scale=16, train_wall=69, gb_free=14.6, wall=34096
2023-07-28 11:24:19 | INFO | train_inner | epoch 029:    547 / 1474 loss=1.985, trans_loss=4.964, nll_loss=2.147, w2v_ctc_loss=0.627, task_loss=2.255, contrastive_loss=0.154, total=4149.27, n_correct=2710.42, ppl=4.43, accuracy=65.323, wps=11840, ups=1.43, wpb=8298.5, bsz=293.3, num_updates=41800, lr=6.91714e-05, gnorm=0.607, clip=0, loss_scale=16, train_wall=69, gb_free=15.3, wall=34166
2023-07-28 11:25:28 | INFO | train_inner | epoch 029:    647 / 1474 loss=1.972, trans_loss=4.949, nll_loss=2.129, w2v_ctc_loss=0.615, task_loss=1.976, contrastive_loss=0.222, total=4145.39, n_correct=2722.8, ppl=4.37, accuracy=65.683, wps=12005.1, ups=1.45, wpb=8290.8, bsz=319.3, num_updates=41900, lr=6.90889e-05, gnorm=0.59, clip=0, loss_scale=16, train_wall=68, gb_free=17.4, wall=34235
2023-07-28 11:26:38 | INFO | train_inner | epoch 029:    747 / 1474 loss=1.968, trans_loss=4.951, nll_loss=2.132, w2v_ctc_loss=0.615, task_loss=1.936, contrastive_loss=0.142, total=4242.46, n_correct=2788.42, ppl=4.38, accuracy=65.726, wps=12174.3, ups=1.43, wpb=8484.9, bsz=329.9, num_updates=42000, lr=6.90066e-05, gnorm=0.577, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=34305
2023-07-28 11:26:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 11:27:02 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.214 | trans_loss 5.577 | nll_loss 2.855 | w2v_ctc_loss 1.366 | task_loss 6.935 | contrastive_loss 0.258 | total 4003.4 | n_correct 2483.3 | ppl 7.24 | accuracy 62.03 | uer 17.02 | wer 18.776 | raw_wer 18.776 | bleu 19.86 | wps 2110.2 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.46
2023-07-28 11:27:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-07-28 11:27:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_29_42000.pt
2023-07-28 11:27:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_29_42000.pt
2023-07-28 11:27:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 19.86) (writing took 11.696362080052495 seconds)
2023-07-28 11:28:23 | INFO | train_inner | epoch 029:    847 / 1474 loss=1.981, trans_loss=4.974, nll_loss=2.159, w2v_ctc_loss=0.629, task_loss=2.333, contrastive_loss=0.054, total=4027.03, n_correct=2624.04, ppl=4.47, accuracy=65.161, wps=7637.2, ups=0.95, wpb=8054.1, bsz=280.3, num_updates=42100, lr=6.89246e-05, gnorm=0.603, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=34410
2023-07-28 11:29:32 | INFO | train_inner | epoch 029:    947 / 1474 loss=1.978, trans_loss=4.971, nll_loss=2.157, w2v_ctc_loss=0.629, task_loss=2.147, contrastive_loss=0.067, total=4086.72, n_correct=2670.38, ppl=4.46, accuracy=65.343, wps=11902, ups=1.46, wpb=8173.4, bsz=296.3, num_updates=42200, lr=6.88428e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=68, gb_free=15.3, wall=34479
2023-07-28 11:30:41 | INFO | train_inner | epoch 029:   1047 / 1474 loss=1.973, trans_loss=4.96, nll_loss=2.143, w2v_ctc_loss=0.619, task_loss=2.1, contrastive_loss=0.143, total=4139.4, n_correct=2714.81, ppl=4.42, accuracy=65.585, wps=11994.2, ups=1.45, wpb=8278.8, bsz=307.4, num_updates=42300, lr=6.87614e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=68, gb_free=15.5, wall=34548
2023-07-28 11:31:51 | INFO | train_inner | epoch 029:   1147 / 1474 loss=1.98, trans_loss=4.975, nll_loss=2.162, w2v_ctc_loss=0.631, task_loss=2.294, contrastive_loss=0.049, total=4072.33, n_correct=2659.81, ppl=4.48, accuracy=65.314, wps=11605.7, ups=1.42, wpb=8144.7, bsz=284.1, num_updates=42400, lr=6.86803e-05, gnorm=0.601, clip=0, loss_scale=32, train_wall=69, gb_free=16.9, wall=34618
2023-07-28 11:33:00 | INFO | train_inner | epoch 029:   1247 / 1474 loss=1.977, trans_loss=4.972, nll_loss=2.159, w2v_ctc_loss=0.63, task_loss=2.129, contrastive_loss=0.06, total=4160.52, n_correct=2720.24, ppl=4.47, accuracy=65.382, wps=12080.2, ups=1.45, wpb=8321, bsz=301.5, num_updates=42500, lr=6.85994e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=68, gb_free=15.5, wall=34687
2023-07-28 11:34:09 | INFO | train_inner | epoch 029:   1347 / 1474 loss=1.976, trans_loss=4.965, nll_loss=2.15, w2v_ctc_loss=0.621, task_loss=2.073, contrastive_loss=0.126, total=4168.02, n_correct=2729.94, ppl=4.44, accuracy=65.497, wps=12075.2, ups=1.45, wpb=8336, bsz=310.2, num_updates=42600, lr=6.85189e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=34756
2023-07-28 11:35:18 | INFO | train_inner | epoch 029:   1447 / 1474 loss=1.978, trans_loss=4.964, nll_loss=2.149, w2v_ctc_loss=0.627, task_loss=2.05, contrastive_loss=0.154, total=4166.06, n_correct=2723.63, ppl=4.44, accuracy=65.377, wps=12000.1, ups=1.44, wpb=8332.1, bsz=313.1, num_updates=42700, lr=6.84386e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=34826
2023-07-28 11:35:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 11:36:01 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.207 | trans_loss 5.57 | nll_loss 2.845 | w2v_ctc_loss 1.36 | task_loss 6.945 | contrastive_loss 0.254 | total 4003.4 | n_correct 2489.1 | ppl 7.18 | accuracy 62.175 | uer 16.805 | wer 18.646 | raw_wer 18.646 | bleu 20.28 | wps 2191.5 | wpb 4003.4 | bsz 141.8 | num_updates 42727 | best_bleu 20.46
2023-07-28 11:36:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42727 updates
2023-07-28 11:36:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.2804.pt
2023-07-28 11:36:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.2804.pt
2023-07-28 11:36:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.2804.pt (epoch 29 @ 42727 updates, score 20.28) (writing took 15.67785974778235 seconds)
2023-07-28 11:36:17 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-07-28 11:36:17 | INFO | train | epoch 029 | loss 1.974 | trans_loss 4.959 | nll_loss 2.141 | w2v_ctc_loss 0.623 | task_loss 2.1 | contrastive_loss 0.112 | total 4138.65 | n_correct 2712.98 | ppl 4.41 | accuracy 65.552 | wps 11013.3 | ups 1.33 | wpb 8277.3 | bsz 305.7 | num_updates 42727 | lr 6.8417e-05 | gnorm 0.59 | clip 0 | loss_scale 32 | train_wall 1012 | gb_free 16 | wall 34884
2023-07-28 11:36:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 11:36:17 | INFO | fairseq.trainer | begin training epoch 30
2023-07-28 11:36:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 11:37:17 | INFO | train_inner | epoch 030:     73 / 1474 loss=1.965, trans_loss=4.942, nll_loss=2.119, w2v_ctc_loss=0.609, task_loss=2.003, contrastive_loss=0.17, total=4175.11, n_correct=2747.85, ppl=4.34, accuracy=65.815, wps=7028.6, ups=0.84, wpb=8350.2, bsz=318.6, num_updates=42800, lr=6.83586e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=69, gb_free=17.1, wall=34944
2023-07-28 11:38:26 | INFO | train_inner | epoch 030:    173 / 1474 loss=1.958, trans_loss=4.926, nll_loss=2.099, w2v_ctc_loss=0.617, task_loss=1.969, contrastive_loss=0.104, total=4202.64, n_correct=2781.97, ppl=4.28, accuracy=66.196, wps=12136.6, ups=1.44, wpb=8405.3, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.592, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=35014
2023-07-28 11:39:36 | INFO | train_inner | epoch 030:    273 / 1474 loss=1.965, trans_loss=4.942, nll_loss=2.118, w2v_ctc_loss=0.626, task_loss=2.172, contrastive_loss=0.052, total=4120.21, n_correct=2716.9, ppl=4.34, accuracy=65.941, wps=11856.5, ups=1.44, wpb=8240.4, bsz=294.9, num_updates=43000, lr=6.81994e-05, gnorm=0.586, clip=0, loss_scale=32, train_wall=69, gb_free=15.2, wall=35083
2023-07-28 11:40:46 | INFO | train_inner | epoch 030:    373 / 1474 loss=1.957, trans_loss=4.935, nll_loss=2.109, w2v_ctc_loss=0.614, task_loss=2.095, contrastive_loss=0.059, total=4178.23, n_correct=2760.68, ppl=4.31, accuracy=66.073, wps=11894.9, ups=1.42, wpb=8356.5, bsz=307.5, num_updates=43100, lr=6.81203e-05, gnorm=0.591, clip=0, loss_scale=32, train_wall=70, gb_free=9.9, wall=35153
2023-07-28 11:41:55 | INFO | train_inner | epoch 030:    473 / 1474 loss=1.962, trans_loss=4.941, nll_loss=2.117, w2v_ctc_loss=0.611, task_loss=2.017, contrastive_loss=0.125, total=4124.47, n_correct=2719.91, ppl=4.34, accuracy=65.946, wps=12027.6, ups=1.46, wpb=8248.9, bsz=312.6, num_updates=43200, lr=6.80414e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=68, gb_free=17.5, wall=35222
2023-07-28 11:43:04 | INFO | train_inner | epoch 030:    573 / 1474 loss=1.965, trans_loss=4.951, nll_loss=2.13, w2v_ctc_loss=0.615, task_loss=2.039, contrastive_loss=0.085, total=4168.41, n_correct=2741.97, ppl=4.38, accuracy=65.78, wps=12032.5, ups=1.44, wpb=8336.8, bsz=312.4, num_updates=43300, lr=6.79628e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=35291
2023-07-28 11:44:14 | INFO | train_inner | epoch 030:    673 / 1474 loss=1.971, trans_loss=4.949, nll_loss=2.129, w2v_ctc_loss=0.627, task_loss=2.074, contrastive_loss=0.103, total=4187.95, n_correct=2750.53, ppl=4.37, accuracy=65.677, wps=12005, ups=1.43, wpb=8375.9, bsz=315, num_updates=43400, lr=6.78844e-05, gnorm=0.593, clip=0, loss_scale=32, train_wall=69, gb_free=15.8, wall=35361
2023-07-28 11:45:23 | INFO | train_inner | epoch 030:    773 / 1474 loss=1.984, trans_loss=4.962, nll_loss=2.145, w2v_ctc_loss=0.632, task_loss=2.148, contrastive_loss=0.177, total=4105.32, n_correct=2682.68, ppl=4.42, accuracy=65.346, wps=11963.1, ups=1.46, wpb=8210.6, bsz=302.6, num_updates=43500, lr=6.78064e-05, gnorm=0.595, clip=0, loss_scale=32, train_wall=68, gb_free=12.9, wall=35430
2023-07-28 11:46:32 | INFO | train_inner | epoch 030:    873 / 1474 loss=1.968, trans_loss=4.957, nll_loss=2.138, w2v_ctc_loss=0.617, task_loss=2.166, contrastive_loss=0.068, total=4102.11, n_correct=2694.43, ppl=4.4, accuracy=65.684, wps=11816.6, ups=1.44, wpb=8204.2, bsz=295.6, num_updates=43600, lr=6.77285e-05, gnorm=0.598, clip=0, loss_scale=32, train_wall=69, gb_free=17.4, wall=35499
2023-07-28 11:47:42 | INFO | train_inner | epoch 030:    973 / 1474 loss=1.974, trans_loss=4.962, nll_loss=2.146, w2v_ctc_loss=0.625, task_loss=2.151, contrastive_loss=0.071, total=4129.98, n_correct=2706.91, ppl=4.42, accuracy=65.543, wps=11773.6, ups=1.43, wpb=8260, bsz=300.4, num_updates=43700, lr=6.7651e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=70, gb_free=16.3, wall=35569
2023-07-28 11:48:51 | INFO | train_inner | epoch 030:   1073 / 1474 loss=1.985, trans_loss=4.969, nll_loss=2.154, w2v_ctc_loss=0.628, task_loss=2.353, contrastive_loss=0.144, total=4101.17, n_correct=2676.5, ppl=4.45, accuracy=65.262, wps=11876.7, ups=1.45, wpb=8202.3, bsz=282.3, num_updates=43800, lr=6.75737e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=35638
2023-07-28 11:50:00 | INFO | train_inner | epoch 030:   1173 / 1474 loss=1.966, trans_loss=4.955, nll_loss=2.138, w2v_ctc_loss=0.607, task_loss=2.021, contrastive_loss=0.129, total=4168.36, n_correct=2737.2, ppl=4.4, accuracy=65.666, wps=12109.4, ups=1.45, wpb=8336.7, bsz=314, num_updates=43900, lr=6.74967e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=35707
2023-07-28 11:51:09 | INFO | train_inner | epoch 030:   1273 / 1474 loss=1.977, trans_loss=4.966, nll_loss=2.15, w2v_ctc_loss=0.629, task_loss=2.318, contrastive_loss=0.063, total=4036.17, n_correct=2639.63, ppl=4.44, accuracy=65.399, wps=11671.1, ups=1.45, wpb=8072.3, bsz=284.3, num_updates=44000, lr=6.742e-05, gnorm=0.592, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=35776
2023-07-28 11:51:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 11:51:33 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.193 | trans_loss 5.569 | nll_loss 2.844 | w2v_ctc_loss 1.317 | task_loss 6.863 | contrastive_loss 0.254 | total 4003.4 | n_correct 2486.5 | ppl 7.18 | accuracy 62.11 | uer 16.699 | wer 18.456 | raw_wer 18.456 | bleu 20.43 | wps 2185.9 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.46
2023-07-28 11:51:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-07-28 11:51:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_30_44000.pt
2023-07-28 11:51:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_30_44000.pt
2023-07-28 11:51:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 20.43) (writing took 25.4544883556664 seconds)
2023-07-28 11:53:08 | INFO | train_inner | epoch 030:   1373 / 1474 loss=1.964, trans_loss=4.957, nll_loss=2.141, w2v_ctc_loss=0.617, task_loss=1.982, contrastive_loss=0.076, total=4165.07, n_correct=2734.84, ppl=4.41, accuracy=65.661, wps=7019, ups=0.84, wpb=8330.1, bsz=321.6, num_updates=44100, lr=6.73435e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=35895
2023-07-28 11:54:16 | INFO | train_inner | epoch 030:   1473 / 1474 loss=1.972, trans_loss=4.96, nll_loss=2.145, w2v_ctc_loss=0.607, task_loss=1.974, contrastive_loss=0.218, total=4141.76, n_correct=2718.65, ppl=4.42, accuracy=65.64, wps=12147.5, ups=1.47, wpb=8283.5, bsz=314.3, num_updates=44200, lr=6.72673e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=35963
2023-07-28 11:54:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 11:54:42 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.208 | trans_loss 5.573 | nll_loss 2.848 | w2v_ctc_loss 1.359 | task_loss 6.939 | contrastive_loss 0.25 | total 4003.4 | n_correct 2482.5 | ppl 7.2 | accuracy 62.01 | uer 16.994 | wer 18.866 | raw_wer 18.866 | bleu 19.8 | wps 1821.8 | wpb 4003.4 | bsz 141.8 | num_updates 44201 | best_bleu 20.46
2023-07-28 11:54:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44201 updates
2023-07-28 11:54:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_last.pt
2023-07-28 11:54:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_last.pt
2023-07-28 11:54:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_last.pt (epoch 30 @ 44201 updates, score 19.8) (writing took 10.78277001529932 seconds)
2023-07-28 11:54:53 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-07-28 11:54:53 | INFO | train | epoch 030 | loss 1.969 | trans_loss 4.951 | nll_loss 2.131 | w2v_ctc_loss 0.619 | task_loss 2.1 | contrastive_loss 0.111 | total 4138.65 | n_correct 2719.69 | ppl 4.38 | accuracy 65.714 | wps 10934.2 | ups 1.32 | wpb 8277.3 | bsz 305.7 | num_updates 44201 | lr 6.72665e-05 | gnorm 0.587 | clip 0 | loss_scale 32 | train_wall 1011 | gb_free 17.1 | wall 36000
2023-07-28 11:54:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 11:54:53 | INFO | fairseq.trainer | begin training epoch 31
2023-07-28 11:54:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 11:56:12 | INFO | train_inner | epoch 031:     99 / 1474 loss=1.96, trans_loss=4.932, nll_loss=2.104, w2v_ctc_loss=0.621, task_loss=2.245, contrastive_loss=0.056, total=4054.44, n_correct=2680.14, ppl=4.3, accuracy=66.104, wps=7023.6, ups=0.87, wpb=8108.9, bsz=288.2, num_updates=44300, lr=6.71913e-05, gnorm=0.589, clip=0, loss_scale=64, train_wall=69, gb_free=16.4, wall=36079
2023-07-28 11:57:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-28 11:57:22 | INFO | train_inner | epoch 031:    200 / 1474 loss=1.962, trans_loss=4.934, nll_loss=2.108, w2v_ctc_loss=0.619, task_loss=2.14, contrastive_loss=0.088, total=4150.52, n_correct=2743.4, ppl=4.31, accuracy=66.098, wps=11787.1, ups=1.42, wpb=8301, bsz=303.4, num_updates=44400, lr=6.71156e-05, gnorm=0.587, clip=0, loss_scale=32, train_wall=70, gb_free=11.8, wall=36149
2023-07-28 11:58:32 | INFO | train_inner | epoch 031:    300 / 1474 loss=1.961, trans_loss=4.933, nll_loss=2.107, w2v_ctc_loss=0.612, task_loss=2.145, contrastive_loss=0.123, total=4148.01, n_correct=2743.37, ppl=4.31, accuracy=66.137, wps=11885.1, ups=1.43, wpb=8296, bsz=301.1, num_updates=44500, lr=6.70402e-05, gnorm=0.592, clip=0, loss_scale=32, train_wall=69, gb_free=13.2, wall=36219
2023-07-28 11:59:41 | INFO | train_inner | epoch 031:    400 / 1474 loss=1.965, trans_loss=4.947, nll_loss=2.124, w2v_ctc_loss=0.616, task_loss=2.287, contrastive_loss=0.06, total=4095.42, n_correct=2696.93, ppl=4.36, accuracy=65.852, wps=11764.8, ups=1.44, wpb=8190.8, bsz=286.3, num_updates=44600, lr=6.6965e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=69, gb_free=13.3, wall=36289
2023-07-28 12:00:51 | INFO | train_inner | epoch 031:    500 / 1474 loss=1.966, trans_loss=4.941, nll_loss=2.117, w2v_ctc_loss=0.627, task_loss=2.187, contrastive_loss=0.07, total=4115.61, n_correct=2711.17, ppl=4.34, accuracy=65.875, wps=11790.4, ups=1.43, wpb=8231.2, bsz=300.6, num_updates=44700, lr=6.689e-05, gnorm=0.589, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=36358
2023-07-28 12:02:00 | INFO | train_inner | epoch 031:    600 / 1474 loss=1.959, trans_loss=4.94, nll_loss=2.116, w2v_ctc_loss=0.61, task_loss=2.205, contrastive_loss=0.059, total=4075.9, n_correct=2688.75, ppl=4.33, accuracy=65.967, wps=11794.5, ups=1.45, wpb=8151.8, bsz=293.3, num_updates=44800, lr=6.68153e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=68, gb_free=11.7, wall=36427
2023-07-28 12:03:09 | INFO | train_inner | epoch 031:    700 / 1474 loss=1.953, trans_loss=4.937, nll_loss=2.113, w2v_ctc_loss=0.606, task_loss=2.006, contrastive_loss=0.06, total=4208.99, n_correct=2781.67, ppl=4.33, accuracy=66.089, wps=12245.3, ups=1.45, wpb=8418, bsz=315.1, num_updates=44900, lr=6.67409e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=68, gb_free=17.8, wall=36496
2023-07-28 12:04:19 | INFO | train_inner | epoch 031:    800 / 1474 loss=1.971, trans_loss=4.952, nll_loss=2.133, w2v_ctc_loss=0.616, task_loss=2.183, contrastive_loss=0.132, total=4104.19, n_correct=2697.04, ppl=4.38, accuracy=65.714, wps=11702.1, ups=1.43, wpb=8208.4, bsz=297.4, num_updates=45000, lr=6.66667e-05, gnorm=0.597, clip=0, loss_scale=32, train_wall=69, gb_free=15.3, wall=36566
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:0')
2023-07-28 12:05:28 | INFO | train_inner | epoch 031:    900 / 1474 loss=1.966, trans_loss=4.945, nll_loss=2.123, w2v_ctc_loss=0.619, task_loss=2.216, contrastive_loss=0.075, total=4099.13, n_correct=2695.34, ppl=4.36, accuracy=65.754, wps=11942.4, ups=1.46, wpb=8198.3, bsz=294.3, num_updates=45100, lr=6.65927e-05, gnorm=0.605, clip=0, loss_scale=32, train_wall=68, gb_free=15.1, wall=36635
2023-07-28 12:06:37 | INFO | train_inner | epoch 031:   1000 / 1474 loss=1.967, trans_loss=4.954, nll_loss=2.136, w2v_ctc_loss=0.611, task_loss=1.96, contrastive_loss=0.159, total=4186.81, n_correct=2756.89, ppl=4.4, accuracy=65.847, wps=12111.9, ups=1.45, wpb=8373.6, bsz=320.9, num_updates=45200, lr=6.6519e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=68, gb_free=13.3, wall=36704
2023-07-28 12:07:46 | INFO | train_inner | epoch 031:   1100 / 1474 loss=1.963, trans_loss=4.947, nll_loss=2.128, w2v_ctc_loss=0.611, task_loss=2.055, contrastive_loss=0.11, total=4149.25, n_correct=2729.11, ppl=4.37, accuracy=65.774, wps=11985.1, ups=1.44, wpb=8298.5, bsz=315.2, num_updates=45300, lr=6.64455e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=36773
2023-07-28 12:08:55 | INFO | train_inner | epoch 031:   1200 / 1474 loss=1.971, trans_loss=4.953, nll_loss=2.135, w2v_ctc_loss=0.61, task_loss=1.98, contrastive_loss=0.222, total=4187.45, n_correct=2753.64, ppl=4.39, accuracy=65.759, wps=12138.9, ups=1.45, wpb=8374.9, bsz=320.3, num_updates=45400, lr=6.63723e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=36842
2023-07-28 12:10:04 | INFO | train_inner | epoch 031:   1300 / 1474 loss=1.96, trans_loss=4.953, nll_loss=2.135, w2v_ctc_loss=0.612, task_loss=1.882, contrastive_loss=0.067, total=4227.39, n_correct=2786.33, ppl=4.39, accuracy=65.911, wps=12306.7, ups=1.46, wpb=8454.8, bsz=326.7, num_updates=45500, lr=6.62994e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=36911
2023-07-28 12:11:14 | INFO | train_inner | epoch 031:   1400 / 1474 loss=1.98, trans_loss=4.956, nll_loss=2.14, w2v_ctc_loss=0.615, task_loss=1.919, contrastive_loss=0.275, total=4191.1, n_correct=2746.5, ppl=4.41, accuracy=65.532, wps=12020.3, ups=1.43, wpb=8382.2, bsz=327, num_updates=45600, lr=6.62266e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=36981
2023-07-28 12:11:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-28 12:12:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2481, device='cuda:2')
2023-07-28 12:12:28 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.197 | trans_loss 5.571 | nll_loss 2.845 | w2v_ctc_loss 1.329 | task_loss 6.927 | contrastive_loss 0.247 | total 4003.4 | n_correct 2487.1 | ppl 7.18 | accuracy 62.125 | uer 16.611 | wer 18.351 | raw_wer 18.351 | bleu 20.28 | wps 2289.5 | wpb 4003.4 | bsz 141.8 | num_updates 45673 | best_bleu 20.46
2023-07-28 12:12:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45673 updates
2023-07-28 12:12:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.2804.pt
2023-07-28 12:12:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.2804.pt
2023-07-28 12:12:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.2804.pt (epoch 31 @ 45673 updates, score 20.28) (writing took 19.203144416213036 seconds)
2023-07-28 12:12:47 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-07-28 12:12:47 | INFO | train | epoch 031 | loss 1.965 | trans_loss 4.945 | nll_loss 2.124 | w2v_ctc_loss 0.615 | task_loss 2.102 | contrastive_loss 0.11 | total 4138.01 | n_correct 2725.86 | ppl 4.36 | accuracy 65.874 | wps 11335.6 | ups 1.37 | wpb 8276 | bsz 305.5 | num_updates 45673 | lr 6.61737e-05 | gnorm 0.587 | clip 0 | loss_scale 16 | train_wall 1012 | gb_free 12 | wall 37074
2023-07-28 12:12:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 12:12:48 | INFO | fairseq.trainer | begin training epoch 32
2023-07-28 12:12:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 12:13:15 | INFO | train_inner | epoch 032:     27 / 1474 loss=1.963, trans_loss=4.947, nll_loss=2.126, w2v_ctc_loss=0.616, task_loss=2.222, contrastive_loss=0.055, total=4041.12, n_correct=2660.4, ppl=4.36, accuracy=65.833, wps=6673.6, ups=0.83, wpb=8082.2, bsz=288.6, num_updates=45700, lr=6.61541e-05, gnorm=0.603, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=37102
2023-07-28 12:14:24 | INFO | train_inner | epoch 032:    127 / 1474 loss=1.939, trans_loss=4.91, nll_loss=2.077, w2v_ctc_loss=0.594, task_loss=1.969, contrastive_loss=0.066, total=4208.32, n_correct=2802.27, ppl=4.22, accuracy=66.589, wps=12142.6, ups=1.44, wpb=8416.6, bsz=319.1, num_updates=45800, lr=6.60819e-05, gnorm=0.576, clip=0, loss_scale=16, train_wall=69, gb_free=11.5, wall=37171
2023-07-28 12:15:34 | INFO | train_inner | epoch 032:    227 / 1474 loss=1.95, trans_loss=4.928, nll_loss=2.102, w2v_ctc_loss=0.606, task_loss=2.001, contrastive_loss=0.078, total=4157.86, n_correct=2752.51, ppl=4.29, accuracy=66.2, wps=11914.7, ups=1.43, wpb=8315.7, bsz=320.3, num_updates=45900, lr=6.60098e-05, gnorm=0.589, clip=0, loss_scale=16, train_wall=69, gb_free=14.3, wall=37241
2023-07-28 12:16:43 | INFO | train_inner | epoch 032:    327 / 1474 loss=1.944, trans_loss=4.917, nll_loss=2.087, w2v_ctc_loss=0.597, task_loss=1.992, contrastive_loss=0.07, total=4179.17, n_correct=2776.39, ppl=4.25, accuracy=66.434, wps=12071.4, ups=1.44, wpb=8358.3, bsz=313.4, num_updates=46000, lr=6.5938e-05, gnorm=0.58, clip=0, loss_scale=16, train_wall=69, gb_free=17.1, wall=37310
2023-07-28 12:16:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 12:17:07 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.213 | trans_loss 5.581 | nll_loss 2.858 | w2v_ctc_loss 1.355 | task_loss 6.918 | contrastive_loss 0.256 | total 4003.4 | n_correct 2487.1 | ppl 7.25 | accuracy 62.125 | uer 16.824 | wer 18.534 | raw_wer 18.534 | bleu 20.11 | wps 2123 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.46
2023-07-28 12:17:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-07-28 12:17:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_32_46000.pt
2023-07-28 12:17:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_32_46000.pt
2023-07-28 12:17:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 20.11) (writing took 16.38778635300696 seconds)
2023-07-28 12:18:33 | INFO | train_inner | epoch 032:    427 / 1474 loss=1.949, trans_loss=4.923, nll_loss=2.095, w2v_ctc_loss=0.605, task_loss=2.026, contrastive_loss=0.067, total=4179.5, n_correct=2772.16, ppl=4.27, accuracy=66.328, wps=7592.6, ups=0.91, wpb=8359, bsz=312.2, num_updates=46100, lr=6.58665e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=68, gb_free=17.8, wall=37420
2023-07-28 12:19:43 | INFO | train_inner | epoch 032:    527 / 1474 loss=1.964, trans_loss=4.937, nll_loss=2.113, w2v_ctc_loss=0.614, task_loss=2.064, contrastive_loss=0.152, total=4188.83, n_correct=2766.82, ppl=4.33, accuracy=66.052, wps=12042.7, ups=1.44, wpb=8377.7, bsz=313.9, num_updates=46200, lr=6.57952e-05, gnorm=0.589, clip=0, loss_scale=16, train_wall=69, gb_free=12.7, wall=37490
2023-07-28 12:20:53 | INFO | train_inner | epoch 032:    627 / 1474 loss=1.961, trans_loss=4.942, nll_loss=2.118, w2v_ctc_loss=0.614, task_loss=2.204, contrastive_loss=0.075, total=4133.19, n_correct=2724.94, ppl=4.34, accuracy=65.928, wps=11752.5, ups=1.42, wpb=8266.4, bsz=298.7, num_updates=46300, lr=6.57241e-05, gnorm=0.599, clip=0, loss_scale=16, train_wall=70, gb_free=17.2, wall=37560
2023-07-28 12:22:02 | INFO | train_inner | epoch 032:    727 / 1474 loss=1.961, trans_loss=4.942, nll_loss=2.119, w2v_ctc_loss=0.619, task_loss=2.117, contrastive_loss=0.057, total=4162.1, n_correct=2748.45, ppl=4.34, accuracy=66.035, wps=12052.6, ups=1.45, wpb=8324.2, bsz=304.3, num_updates=46400, lr=6.56532e-05, gnorm=0.581, clip=0, loss_scale=16, train_wall=69, gb_free=15.8, wall=37629
2023-07-28 12:23:11 | INFO | train_inner | epoch 032:    827 / 1474 loss=1.954, trans_loss=4.937, nll_loss=2.111, w2v_ctc_loss=0.605, task_loss=2.187, contrastive_loss=0.054, total=4107.86, n_correct=2716.52, ppl=4.32, accuracy=66.13, wps=11921.7, ups=1.45, wpb=8215.7, bsz=292.6, num_updates=46500, lr=6.55826e-05, gnorm=0.577, clip=0, loss_scale=16, train_wall=68, gb_free=15.7, wall=37698
2023-07-28 12:24:21 | INFO | train_inner | epoch 032:    927 / 1474 loss=1.955, trans_loss=4.94, nll_loss=2.117, w2v_ctc_loss=0.604, task_loss=2.148, contrastive_loss=0.052, total=4146.9, n_correct=2739.16, ppl=4.34, accuracy=66.053, wps=11865.6, ups=1.43, wpb=8293.8, bsz=300.4, num_updates=46600, lr=6.55122e-05, gnorm=0.584, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=37768
2023-07-28 12:25:30 | INFO | train_inner | epoch 032:   1027 / 1474 loss=1.968, trans_loss=4.951, nll_loss=2.13, w2v_ctc_loss=0.615, task_loss=2.078, contrastive_loss=0.148, total=4112.45, n_correct=2703.17, ppl=4.38, accuracy=65.731, wps=11972.6, ups=1.46, wpb=8224.9, bsz=304.3, num_updates=46700, lr=6.5442e-05, gnorm=0.612, clip=0, loss_scale=16, train_wall=68, gb_free=17.1, wall=37837
2023-07-28 12:26:40 | INFO | train_inner | epoch 032:   1127 / 1474 loss=1.972, trans_loss=4.954, nll_loss=2.133, w2v_ctc_loss=0.618, task_loss=2.495, contrastive_loss=0.09, total=4015.2, n_correct=2637.44, ppl=4.39, accuracy=65.686, wps=11532.6, ups=1.44, wpb=8030.4, bsz=269.7, num_updates=46800, lr=6.5372e-05, gnorm=0.605, clip=0, loss_scale=16, train_wall=69, gb_free=14.3, wall=37907
2023-07-28 12:27:49 | INFO | train_inner | epoch 032:   1227 / 1474 loss=1.975, trans_loss=4.957, nll_loss=2.14, w2v_ctc_loss=0.613, task_loss=2.057, contrastive_loss=0.199, total=4158.99, n_correct=2728.92, ppl=4.41, accuracy=65.615, wps=12007, ups=1.44, wpb=8318, bsz=312.1, num_updates=46900, lr=6.53023e-05, gnorm=0.597, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=37976
2023-07-28 12:28:58 | INFO | train_inner | epoch 032:   1327 / 1474 loss=1.962, trans_loss=4.948, nll_loss=2.127, w2v_ctc_loss=0.615, task_loss=2.141, contrastive_loss=0.053, total=4079.56, n_correct=2681.54, ppl=4.37, accuracy=65.731, wps=11817.8, ups=1.45, wpb=8159.1, bsz=297.9, num_updates=47000, lr=6.52328e-05, gnorm=0.592, clip=0, loss_scale=16, train_wall=68, gb_free=17.1, wall=38045
2023-07-28 12:30:07 | INFO | train_inner | epoch 032:   1427 / 1474 loss=1.981, trans_loss=4.956, nll_loss=2.138, w2v_ctc_loss=0.621, task_loss=2.126, contrastive_loss=0.287, total=4107.37, n_correct=2695.34, ppl=4.4, accuracy=65.622, wps=11950.1, ups=1.45, wpb=8214.7, bsz=304.2, num_updates=47100, lr=6.51635e-05, gnorm=0.581, clip=0, loss_scale=16, train_wall=68, gb_free=17.3, wall=38114
2023-07-28 12:30:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 12:31:02 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.212 | trans_loss 5.572 | nll_loss 2.847 | w2v_ctc_loss 1.375 | task_loss 6.919 | contrastive_loss 0.253 | total 4003.4 | n_correct 2483.9 | ppl 7.19 | accuracy 62.045 | uer 16.712 | wer 18.638 | raw_wer 18.638 | bleu 20.08 | wps 2163.8 | wpb 4003.4 | bsz 141.8 | num_updates 47147 | best_bleu 20.46
2023-07-28 12:31:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47147 updates
2023-07-28 12:31:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_last.pt
2023-07-28 12:31:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_last.pt
2023-07-28 12:31:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_last.pt (epoch 32 @ 47147 updates, score 20.08) (writing took 10.738703580573201 seconds)
2023-07-28 12:31:13 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-07-28 12:31:13 | INFO | train | epoch 032 | loss 1.96 | trans_loss 4.938 | nll_loss 2.114 | w2v_ctc_loss 0.609 | task_loss 2.099 | contrastive_loss 0.108 | total 4138.65 | n_correct 2732.2 | ppl 4.33 | accuracy 66.017 | wps 11034.6 | ups 1.33 | wpb 8277.3 | bsz 305.7 | num_updates 47147 | lr 6.5131e-05 | gnorm 0.589 | clip 0 | loss_scale 16 | train_wall 1013 | gb_free 16.5 | wall 38180
2023-07-28 12:31:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 12:31:13 | INFO | fairseq.trainer | begin training epoch 33
2023-07-28 12:31:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 12:32:00 | INFO | train_inner | epoch 033:     53 / 1474 loss=1.958, trans_loss=4.933, nll_loss=2.109, w2v_ctc_loss=0.602, task_loss=1.991, contrastive_loss=0.159, total=4146.91, n_correct=2742.01, ppl=4.31, accuracy=66.122, wps=7303.8, ups=0.88, wpb=8293.8, bsz=319.7, num_updates=47200, lr=6.50945e-05, gnorm=0.587, clip=0, loss_scale=16, train_wall=70, gb_free=16, wall=38227
2023-07-28 12:33:10 | INFO | train_inner | epoch 033:    153 / 1474 loss=1.945, trans_loss=4.917, nll_loss=2.085, w2v_ctc_loss=0.594, task_loss=2.251, contrastive_loss=0.043, total=4073.36, n_correct=2708.05, ppl=4.24, accuracy=66.482, wps=11729.6, ups=1.44, wpb=8146.7, bsz=285.1, num_updates=47300, lr=6.50256e-05, gnorm=0.577, clip=0, loss_scale=16, train_wall=69, gb_free=16.7, wall=38297
2023-07-28 12:34:19 | INFO | train_inner | epoch 033:    253 / 1474 loss=1.954, trans_loss=4.917, nll_loss=2.089, w2v_ctc_loss=0.598, task_loss=1.784, contrastive_loss=0.229, total=4283.64, n_correct=2845.19, ppl=4.25, accuracy=66.42, wps=12309.6, ups=1.44, wpb=8567.3, bsz=347.6, num_updates=47400, lr=6.4957e-05, gnorm=0.582, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=38366
2023-07-28 12:35:29 | INFO | train_inner | epoch 033:    353 / 1474 loss=1.953, trans_loss=4.928, nll_loss=2.101, w2v_ctc_loss=0.605, task_loss=2.137, contrastive_loss=0.077, total=4131.27, n_correct=2735.62, ppl=4.29, accuracy=66.217, wps=11874.9, ups=1.44, wpb=8262.5, bsz=302.3, num_updates=47500, lr=6.48886e-05, gnorm=0.588, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=38436
2023-07-28 12:36:38 | INFO | train_inner | epoch 033:    453 / 1474 loss=1.94, trans_loss=4.914, nll_loss=2.082, w2v_ctc_loss=0.597, task_loss=1.993, contrastive_loss=0.052, total=4135.1, n_correct=2750.9, ppl=4.24, accuracy=66.526, wps=12006.1, ups=1.45, wpb=8270.2, bsz=309.7, num_updates=47600, lr=6.48204e-05, gnorm=0.576, clip=0, loss_scale=16, train_wall=68, gb_free=15.5, wall=38505
2023-07-28 12:37:46 | INFO | train_inner | epoch 033:    553 / 1474 loss=1.958, trans_loss=4.934, nll_loss=2.107, w2v_ctc_loss=0.61, task_loss=2.182, contrastive_loss=0.076, total=4132.78, n_correct=2731.05, ppl=4.31, accuracy=66.083, wps=12042.1, ups=1.46, wpb=8265.6, bsz=294.2, num_updates=47700, lr=6.47524e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=68, gb_free=17.8, wall=38573
2023-07-28 12:38:56 | INFO | train_inner | epoch 033:    653 / 1474 loss=1.962, trans_loss=4.945, nll_loss=2.122, w2v_ctc_loss=0.608, task_loss=2.154, contrastive_loss=0.107, total=4156.26, n_correct=2740.85, ppl=4.35, accuracy=65.945, wps=11874.1, ups=1.43, wpb=8312.5, bsz=300.7, num_updates=47800, lr=6.46846e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=38643
2023-07-28 12:40:06 | INFO | train_inner | epoch 033:    753 / 1474 loss=1.963, trans_loss=4.941, nll_loss=2.117, w2v_ctc_loss=0.62, task_loss=2.269, contrastive_loss=0.053, total=4074.99, n_correct=2688.1, ppl=4.34, accuracy=65.966, wps=11757.5, ups=1.44, wpb=8150, bsz=288.2, num_updates=47900, lr=6.46171e-05, gnorm=0.602, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=38713
2023-07-28 12:41:15 | INFO | train_inner | epoch 033:    853 / 1474 loss=1.944, trans_loss=4.926, nll_loss=2.1, w2v_ctc_loss=0.59, task_loss=2.006, contrastive_loss=0.125, total=4127.6, n_correct=2742.6, ppl=4.29, accuracy=66.445, wps=11960.9, ups=1.45, wpb=8255.2, bsz=315.3, num_updates=48000, lr=6.45497e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=38782
2023-07-28 12:41:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 12:41:39 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.206 | trans_loss 5.572 | nll_loss 2.845 | w2v_ctc_loss 1.356 | task_loss 6.965 | contrastive_loss 0.247 | total 4003.4 | n_correct 2491.5 | ppl 7.18 | accuracy 62.235 | uer 16.901 | wer 18.657 | raw_wer 18.657 | bleu 20.12 | wps 2156.4 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.46
2023-07-28 12:41:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-07-28 12:41:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_33_48000.pt
2023-07-28 12:41:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_33_48000.pt
2023-07-28 12:41:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 20.12) (writing took 15.94929570518434 seconds)
2023-07-28 12:43:04 | INFO | train_inner | epoch 033:    953 / 1474 loss=1.957, trans_loss=4.934, nll_loss=2.11, w2v_ctc_loss=0.615, task_loss=2.082, contrastive_loss=0.067, total=4157.37, n_correct=2749.31, ppl=4.32, accuracy=66.131, wps=7578.6, ups=0.91, wpb=8314.7, bsz=310.1, num_updates=48100, lr=6.44826e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=68, gb_free=17.4, wall=38891
2023-07-28 12:44:15 | INFO | train_inner | epoch 033:   1053 / 1474 loss=1.963, trans_loss=4.937, nll_loss=2.114, w2v_ctc_loss=0.606, task_loss=2.127, contrastive_loss=0.173, total=4134.8, n_correct=2728.01, ppl=4.33, accuracy=65.977, wps=11790.8, ups=1.43, wpb=8269.6, bsz=306, num_updates=48200, lr=6.44157e-05, gnorm=0.591, clip=0, loss_scale=32, train_wall=70, gb_free=15.7, wall=38962
2023-07-28 12:45:24 | INFO | train_inner | epoch 033:   1153 / 1474 loss=1.961, trans_loss=4.942, nll_loss=2.119, w2v_ctc_loss=0.601, task_loss=2.098, contrastive_loss=0.159, total=4181.58, n_correct=2760.91, ppl=4.34, accuracy=66.026, wps=12127.5, ups=1.45, wpb=8363.2, bsz=310, num_updates=48300, lr=6.43489e-05, gnorm=0.586, clip=0, loss_scale=32, train_wall=68, gb_free=15, wall=39031
2023-07-28 12:46:32 | INFO | train_inner | epoch 033:   1253 / 1474 loss=1.959, trans_loss=4.94, nll_loss=2.117, w2v_ctc_loss=0.614, task_loss=2.203, contrastive_loss=0.059, total=4115.76, n_correct=2718.54, ppl=4.34, accuracy=66.052, wps=11962.8, ups=1.45, wpb=8231.5, bsz=294.7, num_updates=48400, lr=6.42824e-05, gnorm=0.602, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=39099
2023-07-28 12:47:42 | INFO | train_inner | epoch 033:   1353 / 1474 loss=1.954, trans_loss=4.939, nll_loss=2.117, w2v_ctc_loss=0.607, task_loss=2.062, contrastive_loss=0.08, total=4120.69, n_correct=2725.5, ppl=4.34, accuracy=66.142, wps=11855.2, ups=1.44, wpb=8241.4, bsz=311.9, num_updates=48500, lr=6.42161e-05, gnorm=0.589, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=39169
2023-07-28 12:48:51 | INFO | train_inner | epoch 033:   1453 / 1474 loss=1.964, trans_loss=4.941, nll_loss=2.119, w2v_ctc_loss=0.605, task_loss=2.093, contrastive_loss=0.224, total=4125.28, n_correct=2725.47, ppl=4.35, accuracy=66.068, wps=11864.3, ups=1.44, wpb=8250.6, bsz=308.7, num_updates=48600, lr=6.415e-05, gnorm=0.592, clip=0, loss_scale=32, train_wall=69, gb_free=16.9, wall=39239
2023-07-28 12:49:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 12:49:29 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.209 | trans_loss 5.572 | nll_loss 2.844 | w2v_ctc_loss 1.364 | task_loss 6.895 | contrastive_loss 0.251 | total 4003.4 | n_correct 2489.1 | ppl 7.18 | accuracy 62.175 | uer 16.858 | wer 18.635 | raw_wer 18.635 | bleu 20.24 | wps 2159.6 | wpb 4003.4 | bsz 141.8 | num_updates 48621 | best_bleu 20.46
2023-07-28 12:49:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48621 updates
2023-07-28 12:49:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.2404.pt
2023-07-28 12:49:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.2404.pt
2023-07-28 12:49:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint.best_bleu_20.2404.pt (epoch 33 @ 48621 updates, score 20.24) (writing took 11.588900061324239 seconds)
2023-07-28 12:49:41 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-07-28 12:49:41 | INFO | train | epoch 033 | loss 1.955 | trans_loss 4.932 | nll_loss 2.107 | w2v_ctc_loss 0.605 | task_loss 2.099 | contrastive_loss 0.108 | total 4138.65 | n_correct 2739.01 | ppl 4.31 | accuracy 66.181 | wps 11014 | ups 1.33 | wpb 8277.3 | bsz 305.7 | num_updates 48621 | lr 6.41362e-05 | gnorm 0.588 | clip 0 | loss_scale 32 | train_wall 1014 | gb_free 17.8 | wall 39288
2023-07-28 12:49:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-28 12:49:41 | INFO | fairseq.trainer | begin training epoch 34
2023-07-28 12:49:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-28 12:50:45 | INFO | train_inner | epoch 034:     79 / 1474 loss=1.945, trans_loss=4.913, nll_loss=2.082, w2v_ctc_loss=0.604, task_loss=2.074, contrastive_loss=0.061, total=4131.47, n_correct=2750.38, ppl=4.23, accuracy=66.571, wps=7297.8, ups=0.88, wpb=8262.9, bsz=301.7, num_updates=48700, lr=6.40841e-05, gnorm=0.586, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=39352
2023-07-28 12:51:55 | INFO | train_inner | epoch 034:    179 / 1474 loss=1.941, trans_loss=4.908, nll_loss=2.074, w2v_ctc_loss=0.598, task_loss=2.19, contrastive_loss=0.062, total=4065.88, n_correct=2710.06, ppl=4.21, accuracy=66.654, wps=11614.4, ups=1.43, wpb=8131.8, bsz=295.1, num_updates=48800, lr=6.40184e-05, gnorm=0.607, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=39422
2023-07-28 12:53:05 | INFO | train_inner | epoch 034:    279 / 1474 loss=1.962, trans_loss=4.927, nll_loss=2.1, w2v_ctc_loss=0.597, task_loss=1.959, contrastive_loss=0.272, total=4246.3, n_correct=2811.44, ppl=4.29, accuracy=66.209, wps=12150.6, ups=1.43, wpb=8492.6, bsz=328.7, num_updates=48900, lr=6.39529e-05, gnorm=0.589, clip=0, loss_scale=32, train_wall=69, gb_free=17.8, wall=39492
2023-07-28 12:54:13 | INFO | train_inner | epoch 034:    379 / 1474 loss=1.944, trans_loss=4.91, nll_loss=2.078, w2v_ctc_loss=0.593, task_loss=1.996, contrastive_loss=0.161, total=4156.17, n_correct=2768.86, ppl=4.22, accuracy=66.62, wps=12107, ups=1.46, wpb=8312.3, bsz=316.7, num_updates=49000, lr=6.38877e-05, gnorm=0.605, clip=0, loss_scale=32, train_wall=68, gb_free=17.7, wall=39560
2023-07-28 12:55:23 | INFO | train_inner | epoch 034:    479 / 1474 loss=1.954, trans_loss=4.928, nll_loss=2.098, w2v_ctc_loss=0.611, task_loss=2.298, contrastive_loss=0.054, total=4070.55, n_correct=2695.86, ppl=4.28, accuracy=66.228, wps=11731.5, ups=1.44, wpb=8141.1, bsz=284.6, num_updates=49100, lr=6.38226e-05, gnorm=0.594, clip=0, loss_scale=32, train_wall=69, gb_free=17.4, wall=39630
2023-07-28 12:56:32 | INFO | train_inner | epoch 034:    579 / 1474 loss=1.944, trans_loss=4.915, nll_loss=2.084, w2v_ctc_loss=0.6, task_loss=2.126, contrastive_loss=0.057, total=4119.38, n_correct=2741.47, ppl=4.24, accuracy=66.551, wps=11854.3, ups=1.44, wpb=8238.8, bsz=300.3, num_updates=49200, lr=6.37577e-05, gnorm=0.597, clip=0, loss_scale=32, train_wall=69, gb_free=13, wall=39699
2023-07-28 12:57:40 | INFO | train_inner | epoch 034:    679 / 1474 loss=1.943, trans_loss=4.92, nll_loss=2.092, w2v_ctc_loss=0.597, task_loss=2.127, contrastive_loss=0.051, total=4124.83, n_correct=2740.96, ppl=4.26, accuracy=66.45, wps=12088.9, ups=1.47, wpb=8249.7, bsz=300.2, num_updates=49300, lr=6.3693e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=68, gb_free=14.2, wall=39767
2023-07-28 12:58:50 | INFO | train_inner | epoch 034:    779 / 1474 loss=1.956, trans_loss=4.94, nll_loss=2.117, w2v_ctc_loss=0.593, task_loss=2.206, contrastive_loss=0.121, total=4082.07, n_correct=2698.34, ppl=4.34, accuracy=66.102, wps=11767.6, ups=1.44, wpb=8164.1, bsz=295, num_updates=49400, lr=6.36285e-05, gnorm=0.608, clip=0, loss_scale=32, train_wall=69, gb_free=15.5, wall=39837
2023-07-28 13:00:00 | INFO | train_inner | epoch 034:    879 / 1474 loss=1.955, trans_loss=4.933, nll_loss=2.108, w2v_ctc_loss=0.606, task_loss=2.214, contrastive_loss=0.083, total=4100.9, n_correct=2714.99, ppl=4.31, accuracy=66.205, wps=11757.9, ups=1.43, wpb=8201.8, bsz=296.6, num_updates=49500, lr=6.35642e-05, gnorm=0.592, clip=0, loss_scale=32, train_wall=69, gb_free=12.1, wall=39907
2023-07-28 13:01:08 | INFO | train_inner | epoch 034:    979 / 1474 loss=1.953, trans_loss=4.931, nll_loss=2.105, w2v_ctc_loss=0.61, task_loss=2.062, contrastive_loss=0.077, total=4168.39, n_correct=2759.65, ppl=4.3, accuracy=66.204, wps=12119.2, ups=1.45, wpb=8336.8, bsz=311.9, num_updates=49600, lr=6.35001e-05, gnorm=0.592, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=39975
2023-07-28 13:02:17 | INFO | train_inner | epoch 034:   1079 / 1474 loss=1.952, trans_loss=4.935, nll_loss=2.111, w2v_ctc_loss=0.609, task_loss=2.035, contrastive_loss=0.058, total=4150.57, n_correct=2746.56, ppl=4.32, accuracy=66.173, wps=12098.1, ups=1.46, wpb=8301.1, bsz=308.5, num_updates=49700, lr=6.34361e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=40044
2023-07-28 13:03:27 | INFO | train_inner | epoch 034:   1179 / 1474 loss=1.952, trans_loss=4.934, nll_loss=2.109, w2v_ctc_loss=0.602, task_loss=2.169, contrastive_loss=0.07, total=4098.77, n_correct=2711.42, ppl=4.31, accuracy=66.152, wps=11706.2, ups=1.43, wpb=8197.5, bsz=297.1, num_updates=49800, lr=6.33724e-05, gnorm=0.585, clip=0, loss_scale=64, train_wall=70, gb_free=16.9, wall=40114
2023-07-28 13:04:36 | INFO | train_inner | epoch 034:   1279 / 1474 loss=1.949, trans_loss=4.93, nll_loss=2.104, w2v_ctc_loss=0.6, task_loss=2.116, contrastive_loss=0.054, total=4150.54, n_correct=2747, ppl=4.3, accuracy=66.184, wps=12007.6, ups=1.45, wpb=8301.1, bsz=301, num_updates=49900, lr=6.33089e-05, gnorm=0.573, clip=0, loss_scale=64, train_wall=69, gb_free=17.1, wall=40183
2023-07-28 13:05:46 | INFO | train_inner | epoch 034:   1379 / 1474 loss=1.96, trans_loss=4.938, nll_loss=2.115, w2v_ctc_loss=0.613, task_loss=2.009, contrastive_loss=0.122, total=4196.91, n_correct=2770.45, ppl=4.33, accuracy=66.012, wps=11981, ups=1.43, wpb=8393.8, bsz=321.4, num_updates=50000, lr=6.32456e-05, gnorm=0.586, clip=0, loss_scale=64, train_wall=70, gb_free=16, wall=40253
2023-07-28 13:05:46 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-07-28 13:05:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-28 13:06:10 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.19 | trans_loss 5.573 | nll_loss 2.848 | w2v_ctc_loss 1.3 | task_loss 6.956 | contrastive_loss 0.25 | total 4003.4 | n_correct 2487.9 | ppl 7.2 | accuracy 62.145 | uer 16.553 | wer 18.415 | raw_wer 18.415 | bleu 20.05 | wps 2142.9 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.46
2023-07-28 13:06:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-07-28 13:06:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_34_50000.pt
2023-07-28 13:06:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_34_50000.pt
2023-07-28 13:06:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1.5_mt0.5_0728/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 20.05) (writing took 10.846413400024176 seconds)
2023-07-28 13:06:21 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-07-28 13:06:21 | INFO | train | epoch 034 | loss 1.951 | trans_loss 4.926 | nll_loss 2.098 | w2v_ctc_loss 0.602 | task_loss 2.112 | contrastive_loss 0.095 | total 4133.04 | n_correct 2740.62 | ppl 4.28 | accuracy 66.31 | wps 11392.3 | ups 1.38 | wpb 8266.1 | bsz 304.2 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.591 | clip 0 | loss_scale 64 | train_wall 949 | gb_free 16 | wall 40288
2023-07-28 13:06:21 | INFO | fairseq_cli.train | done training in 40212.6 seconds
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    raise EOFError
EOFError
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    raise EOFError
EOFError
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
