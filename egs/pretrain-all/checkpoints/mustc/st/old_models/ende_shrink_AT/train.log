2023-07-01 11:14:27 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:19837
2023-07-01 11:14:27 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:19837
2023-07-01 11:14:27 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:19837
2023-07-01 11:14:27 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:19837
2023-07-01 11:14:27 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:19837
2023-07-01 11:14:27 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-01 11:14:27 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:19837
2023-07-01 11:14:27 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:19837
2023-07-01 11:14:27 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:19837
2023-07-01 11:14:27 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-01 11:14:27 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-01 11:14:27 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-01 11:14:27 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-01 11:14:27 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-01 11:14:27 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-01 11:14:27 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-01 11:14:27 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-01 11:14:27 | INFO | fairseq.distributed.utils | initialized host capios as rank 2
2023-07-01 11:14:27 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-01 11:14:27 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-01 11:14:27 | INFO | fairseq.distributed.utils | initialized host capios as rank 7
2023-07-01 11:14:27 | INFO | fairseq.distributed.utils | initialized host capios as rank 0
2023-07-01 11:14:27 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-01 11:14:27 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-01 11:14:27 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-01 11:14:27 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-01 11:14:27 | INFO | fairseq.distributed.utils | initialized host capios as rank 1
2023-07-01 11:14:27 | INFO | fairseq.distributed.utils | initialized host capios as rank 3
2023-07-01 11:14:27 | INFO | fairseq.distributed.utils | initialized host capios as rank 5
2023-07-01 11:14:27 | INFO | fairseq.distributed.utils | initialized host capios as rank 6
2023-07-01 11:14:27 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-01 11:14:27 | INFO | fairseq.distributed.utils | initialized host capios as rank 4
2023-07-01 11:14:29 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19837', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 40000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=40000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=40000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=40000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-01 11:14:29 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-01 11:14:29 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-01 11:14:29 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-01 11:14:29 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-01 11:14:29 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-01 11:14:34 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-01 11:14:34 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-01 11:14:34 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-01 11:14:36 | INFO | root | load pretrained hubert
2023-07-01 11:14:40 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-01 11:14:42 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-01 11:14:47 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-01 11:14:47 | INFO | root | share the sematic adapter and textual encoder
2023-07-01 11:14:47 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-01 11:14:47 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-01 11:14:47 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-01 11:14:47 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-01 11:14:47 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-01 11:14:47 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-01 11:14:47 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-01 11:14:47 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-01 11:14:47 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-01 11:14:47 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-01 11:14:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-01 11:14:52 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-01 11:14:52 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-01 11:14:52 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-01 11:14:52 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-01 11:14:52 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-01 11:14:52 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-01 11:14:52 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-01 11:14:52 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-01 11:14:52 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-01 11:14:52 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-01 11:14:52 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-01 11:14:52 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-01 11:14:52 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-01 11:14:52 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-01 11:14:52 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_last.pt
2023-07-01 11:14:52 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_last.pt
2023-07-01 11:14:52 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-01 11:14:52 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-01 11:14:52 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-01 11:14:52 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-0.12.3/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-01 11:14:54 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-01 11:14:56 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-01 11:14:58 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-01 11:16:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 11:16:02 | INFO | fairseq.trainer | begin training epoch 1
2023-07-01 11:16:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 11:16:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-01 11:17:27 | INFO | train_inner | epoch 001:    101 / 1474 loss=20.77, trans_loss=5.641, nll_loss=4.216, w2v_ctc_loss=22.495, task_loss=0.685, contrastive_loss=3.311, total=4200.41, n_correct=212.2, ppl=18.59, accuracy=5.052, wps=16782.9, ups=1.34, wpb=12542.9, bsz=467.5, num_updates=100, lr=4.098e-06, gnorm=0.933, clip=0, loss_scale=64, train_wall=76, gb_free=19, wall=154
2023-07-01 11:18:41 | INFO | train_inner | epoch 001:    201 / 1474 loss=18.558, trans_loss=5.461, nll_loss=4.051, w2v_ctc_loss=19.352, task_loss=0.674, contrastive_loss=3.286, total=4127.38, n_correct=244.92, ppl=16.57, accuracy=5.934, wps=16612.3, ups=1.35, wpb=12327, bsz=463.1, num_updates=200, lr=8.096e-06, gnorm=3.622, clip=0, loss_scale=64, train_wall=74, gb_free=19.2, wall=229
2023-07-01 11:19:54 | INFO | train_inner | epoch 001:    301 / 1474 loss=11.637, trans_loss=5.435, nll_loss=4.076, w2v_ctc_loss=8.802, task_loss=0.65, contrastive_loss=3.201, total=4079.62, n_correct=238.81, ppl=16.86, accuracy=5.854, wps=16622.7, ups=1.36, wpb=12195.4, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=4.659, clip=0, loss_scale=64, train_wall=73, gb_free=19.9, wall=302
2023-07-01 11:21:08 | INFO | train_inner | epoch 001:    401 / 1474 loss=10.392, trans_loss=5.469, nll_loss=4.138, w2v_ctc_loss=6.828, task_loss=0.608, contrastive_loss=3.234, total=4174.14, n_correct=226.79, ppl=17.61, accuracy=5.433, wps=16994.1, ups=1.36, wpb=12461.1, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=3.012, clip=0, loss_scale=64, train_wall=73, gb_free=18.9, wall=375
2023-07-01 11:22:21 | INFO | train_inner | epoch 001:    501 / 1474 loss=9.94, trans_loss=5.457, nll_loss=4.132, w2v_ctc_loss=6.165, task_loss=0.549, contrastive_loss=3.228, total=4176.18, n_correct=216.33, ppl=17.53, accuracy=5.18, wps=17052.2, ups=1.36, wpb=12513, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=1.439, clip=0, loss_scale=64, train_wall=73, gb_free=19.2, wall=449
2023-07-01 11:23:34 | INFO | train_inner | epoch 001:    601 / 1474 loss=9.694, trans_loss=5.479, nll_loss=4.167, w2v_ctc_loss=5.811, task_loss=0.511, contrastive_loss=3.28, total=4147.79, n_correct=215.83, ppl=17.96, accuracy=5.203, wps=16863.2, ups=1.36, wpb=12368.1, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.738, clip=0, loss_scale=64, train_wall=73, gb_free=18.9, wall=522
2023-07-01 11:24:47 | INFO | train_inner | epoch 001:    701 / 1474 loss=9.539, trans_loss=5.473, nll_loss=4.166, w2v_ctc_loss=5.702, task_loss=0.495, contrastive_loss=3.029, total=4152.1, n_correct=229.25, ppl=17.95, accuracy=5.521, wps=17063.4, ups=1.38, wpb=12373.8, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=0.603, clip=0, loss_scale=64, train_wall=72, gb_free=19.5, wall=594
2023-07-01 11:26:00 | INFO | train_inner | epoch 001:    801 / 1474 loss=9.264, trans_loss=5.431, nll_loss=4.117, w2v_ctc_loss=5.469, task_loss=0.491, contrastive_loss=2.927, total=4123.83, n_correct=251.22, ppl=17.35, accuracy=6.092, wps=16944.5, ups=1.38, wpb=12311.9, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=0.838, clip=0, loss_scale=64, train_wall=72, gb_free=19.1, wall=667
2023-07-01 11:27:12 | INFO | train_inner | epoch 001:    901 / 1474 loss=9.012, trans_loss=5.409, nll_loss=4.106, w2v_ctc_loss=5.3, task_loss=0.489, contrastive_loss=2.673, total=4163.61, n_correct=278.02, ppl=17.22, accuracy=6.677, wps=17102.4, ups=1.38, wpb=12409.7, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=1.219, clip=0, loss_scale=64, train_wall=72, gb_free=18.8, wall=740
2023-07-01 11:28:25 | INFO | train_inner | epoch 001:   1001 / 1474 loss=8.752, trans_loss=5.39, nll_loss=4.086, w2v_ctc_loss=5.071, task_loss=0.488, contrastive_loss=2.534, total=4135.34, n_correct=297.32, ppl=16.98, accuracy=7.19, wps=16878.4, ups=1.37, wpb=12363.9, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=1.494, clip=0, loss_scale=64, train_wall=73, gb_free=19, wall=813
2023-07-01 11:29:38 | INFO | train_inner | epoch 001:   1101 / 1474 loss=8.497, trans_loss=5.382, nll_loss=4.079, w2v_ctc_loss=4.881, task_loss=0.486, contrastive_loss=2.315, total=4147.38, n_correct=314.49, ppl=16.9, accuracy=7.583, wps=17031.2, ups=1.38, wpb=12356.9, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=1.716, clip=0, loss_scale=64, train_wall=72, gb_free=18.8, wall=886
2023-07-01 11:30:51 | INFO | train_inner | epoch 001:   1201 / 1474 loss=8.259, trans_loss=5.36, nll_loss=4.057, w2v_ctc_loss=4.698, task_loss=0.485, contrastive_loss=2.101, total=4139.9, n_correct=326.64, ppl=16.64, accuracy=7.89, wps=16969, ups=1.37, wpb=12386.7, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=1.673, clip=0, loss_scale=64, train_wall=73, gb_free=18.9, wall=959
2023-07-01 11:32:03 | INFO | train_inner | epoch 001:   1301 / 1474 loss=8.046, trans_loss=5.36, nll_loss=4.059, w2v_ctc_loss=4.508, task_loss=0.484, contrastive_loss=1.923, total=4046.58, n_correct=322.36, ppl=16.67, accuracy=7.966, wps=16779.4, ups=1.39, wpb=12092.5, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=1.745, clip=0, loss_scale=64, train_wall=72, gb_free=19.7, wall=1031
2023-07-01 11:33:15 | INFO | train_inner | epoch 001:   1401 / 1474 loss=7.873, trans_loss=5.357, nll_loss=4.068, w2v_ctc_loss=4.332, task_loss=0.484, contrastive_loss=2.009, total=4133.18, n_correct=330.89, ppl=16.77, accuracy=8.006, wps=16972.8, ups=1.38, wpb=12300.7, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=1.894, clip=0, loss_scale=64, train_wall=72, gb_free=19.9, wall=1103
2023-07-01 11:34:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-07-01 11:34:42 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.922 | trans_loss 10.957 | nll_loss 9.944 | w2v_ctc_loss 5.799 | task_loss 0 | contrastive_loss 2.333 | total 4003.4 | n_correct 374.5 | ppl 985.2 | accuracy 9.355 | uer 71.42 | wer 69.457 | raw_wer 69.457 | bleu 0.03 | wps 1466.6 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-07-01 11:34:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-07-01 11:34:42 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt
2023-07-01 11:34:44 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt
2023-07-01 11:34:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.03) (writing took 4.400790151208639 seconds)
2023-07-01 11:34:47 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-07-01 11:34:47 | INFO | train | epoch 001 | loss 10.593 | trans_loss 5.432 | nll_loss 4.106 | w2v_ctc_loss 7.65 | task_loss 0.539 | contrastive_loss 2.748 | total 4138.32 | n_correct 268.358 | ppl 17.22 | accuracy 6.485 | wps 16327.7 | ups 1.32 | wpb 12354.6 | bsz 458.3 | num_updates 1473 | lr 5.89905e-05 | gnorm 1.814 | clip 0 | loss_scale 64 | train_wall 1072 | gb_free 19.2 | wall 1194
2023-07-01 11:34:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 11:34:47 | INFO | fairseq.trainer | begin training epoch 2
2023-07-01 11:34:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 11:35:16 | INFO | train_inner | epoch 002:     27 / 1474 loss=7.668, trans_loss=5.351, nll_loss=4.05, w2v_ctc_loss=4.125, task_loss=0.484, contrastive_loss=1.842, total=4162.95, n_correct=340.02, ppl=16.57, accuracy=8.168, wps=10341.1, ups=0.83, wpb=12414, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=1.608, clip=0, loss_scale=64, train_wall=74, gb_free=19.6, wall=1223
2023-07-01 11:36:28 | INFO | train_inner | epoch 002:    127 / 1474 loss=7.512, trans_loss=5.352, nll_loss=4.052, w2v_ctc_loss=4.007, task_loss=0.484, contrastive_loss=1.641, total=4155.98, n_correct=338.91, ppl=16.58, accuracy=8.155, wps=17135.6, ups=1.38, wpb=12390, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=1.619, clip=0, loss_scale=64, train_wall=72, gb_free=18.9, wall=1295
2023-07-01 11:37:40 | INFO | train_inner | epoch 002:    227 / 1474 loss=7.335, trans_loss=5.324, nll_loss=4.02, w2v_ctc_loss=3.806, task_loss=0.484, contrastive_loss=1.672, total=4179.21, n_correct=350.42, ppl=16.22, accuracy=8.385, wps=17398.6, ups=1.39, wpb=12488.1, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=1.511, clip=0, loss_scale=64, train_wall=71, gb_free=19, wall=1367
2023-07-01 11:38:52 | INFO | train_inner | epoch 002:    327 / 1474 loss=7.18, trans_loss=5.326, nll_loss=4.019, w2v_ctc_loss=3.711, task_loss=0.484, contrastive_loss=1.383, total=4146.1, n_correct=349.51, ppl=16.21, accuracy=8.43, wps=17096.6, ups=1.38, wpb=12381, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=1.421, clip=0, loss_scale=64, train_wall=72, gb_free=18.8, wall=1440
2023-07-01 11:40:04 | INFO | train_inner | epoch 002:    427 / 1474 loss=7.044, trans_loss=5.314, nll_loss=4.009, w2v_ctc_loss=3.616, task_loss=0.484, contrastive_loss=1.205, total=4037.99, n_correct=344.55, ppl=16.1, accuracy=8.533, wps=16769.5, ups=1.39, wpb=12079.4, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=1.431, clip=0, loss_scale=64, train_wall=72, gb_free=18.9, wall=1512
2023-07-01 11:41:16 | INFO | train_inner | epoch 002:    527 / 1474 loss=6.946, trans_loss=5.313, nll_loss=4.001, w2v_ctc_loss=3.457, task_loss=0.484, contrastive_loss=1.31, total=4176.97, n_correct=363.03, ppl=16.01, accuracy=8.691, wps=17318.8, ups=1.39, wpb=12475.1, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=1.384, clip=0, loss_scale=64, train_wall=72, gb_free=19.6, wall=1584
2023-07-01 11:41:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 11:41:50 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 9.321 | trans_loss 10.82 | nll_loss 9.767 | w2v_ctc_loss 4.684 | task_loss 0 | contrastive_loss 1.656 | total 4003.4 | n_correct 398.5 | ppl 871.39 | accuracy 9.954 | uer 61.795 | wer 59.416 | raw_wer 59.416 | bleu 0.03 | wps 1472.7 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.03
2023-07-01 11:41:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-07-01 11:41:50 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_2_2000.pt
2023-07-01 11:41:52 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_2_2000.pt
2023-07-01 11:41:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.03) (writing took 8.942376120947301 seconds)
2023-07-01 11:43:11 | INFO | train_inner | epoch 002:    627 / 1474 loss=6.813, trans_loss=5.306, nll_loss=3.998, w2v_ctc_loss=3.357, task_loss=0.484, contrastive_loss=1.096, total=4126.49, n_correct=361.27, ppl=15.98, accuracy=8.755, wps=10675.2, ups=0.87, wpb=12299.1, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=1.151, clip=0, loss_scale=128, train_wall=72, gb_free=19.2, wall=1699
2023-07-01 11:44:23 | INFO | train_inner | epoch 002:    727 / 1474 loss=6.736, trans_loss=5.288, nll_loss=3.979, w2v_ctc_loss=3.267, task_loss=0.484, contrastive_loss=1.203, total=4149.06, n_correct=369.91, ppl=15.77, accuracy=8.916, wps=17165.2, ups=1.39, wpb=12372.9, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=1.175, clip=0, loss_scale=128, train_wall=72, gb_free=19.2, wall=1771
2023-07-01 11:45:36 | INFO | train_inner | epoch 002:    827 / 1474 loss=6.649, trans_loss=5.271, nll_loss=3.955, w2v_ctc_loss=3.197, task_loss=0.484, contrastive_loss=1.149, total=4175.4, n_correct=380.73, ppl=15.51, accuracy=9.118, wps=17256.4, ups=1.38, wpb=12477.6, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=1.013, clip=0, loss_scale=128, train_wall=72, gb_free=19.8, wall=1843
2023-07-01 11:46:48 | INFO | train_inner | epoch 002:    927 / 1474 loss=6.551, trans_loss=5.258, nll_loss=3.941, w2v_ctc_loss=3.1, task_loss=0.484, contrastive_loss=1.131, total=4104.2, n_correct=377.74, ppl=15.35, accuracy=9.204, wps=16871.5, ups=1.38, wpb=12243.8, bsz=445.9, num_updates=2400, lr=9.6052e-05, gnorm=1.01, clip=0, loss_scale=128, train_wall=72, gb_free=19, wall=1916
2023-07-01 11:48:00 | INFO | train_inner | epoch 002:   1027 / 1474 loss=6.47, trans_loss=5.255, nll_loss=3.935, w2v_ctc_loss=3.023, task_loss=0.484, contrastive_loss=0.987, total=4102.5, n_correct=378.91, ppl=15.3, accuracy=9.236, wps=17091.7, ups=1.39, wpb=12270.3, bsz=456.3, num_updates=2500, lr=0.00010005, gnorm=0.92, clip=0, loss_scale=128, train_wall=71, gb_free=19.2, wall=1988
2023-07-01 11:49:13 | INFO | train_inner | epoch 002:   1127 / 1474 loss=6.428, trans_loss=5.245, nll_loss=3.925, w2v_ctc_loss=2.943, task_loss=0.484, contrastive_loss=1.199, total=4187.61, n_correct=395.34, ppl=15.19, accuracy=9.441, wps=17208, ups=1.38, wpb=12484.3, bsz=487.1, num_updates=2600, lr=0.000104048, gnorm=0.84, clip=0, loss_scale=128, train_wall=72, gb_free=19.5, wall=2060
2023-07-01 11:50:25 | INFO | train_inner | epoch 002:   1227 / 1474 loss=6.375, trans_loss=5.239, nll_loss=3.917, w2v_ctc_loss=2.898, task_loss=0.484, contrastive_loss=1.12, total=4221.06, n_correct=407.44, ppl=15.1, accuracy=9.653, wps=17308.5, ups=1.37, wpb=12590.1, bsz=492.8, num_updates=2700, lr=0.000108046, gnorm=0.826, clip=0, loss_scale=128, train_wall=72, gb_free=19.4, wall=2133
2023-07-01 11:51:37 | INFO | train_inner | epoch 002:   1327 / 1474 loss=6.278, trans_loss=5.224, nll_loss=3.902, w2v_ctc_loss=2.859, task_loss=0.484, contrastive_loss=0.835, total=4157.86, n_correct=407.07, ppl=14.95, accuracy=9.79, wps=17317.7, ups=1.39, wpb=12422.5, bsz=460.7, num_updates=2800, lr=0.000112044, gnorm=0.79, clip=0, loss_scale=128, train_wall=71, gb_free=19.5, wall=2205
2023-07-01 11:52:50 | INFO | train_inner | epoch 002:   1427 / 1474 loss=6.242, trans_loss=5.222, nll_loss=3.895, w2v_ctc_loss=2.813, task_loss=0.484, contrastive_loss=0.921, total=4054.34, n_correct=397.18, ppl=14.88, accuracy=9.796, wps=16703.9, ups=1.38, wpb=12128.6, bsz=438.8, num_updates=2900, lr=0.000116042, gnorm=0.747, clip=0, loss_scale=128, train_wall=72, gb_free=19.4, wall=2277
2023-07-01 11:53:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 11:53:58 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.492 | trans_loss 10.279 | nll_loss 9.088 | w2v_ctc_loss 3.72 | task_loss 0 | contrastive_loss 0.986 | total 4003.4 | n_correct 499.9 | ppl 544.18 | accuracy 12.487 | uer 51.374 | wer 50.442 | raw_wer 50.442 | bleu 0.13 | wps 1451.2 | wpb 4003.4 | bsz 141.8 | num_updates 2947 | best_bleu 0.13
2023-07-01 11:53:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2947 updates
2023-07-01 11:53:58 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt
2023-07-01 11:54:02 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt
2023-07-01 11:54:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt (epoch 2 @ 2947 updates, score 0.13) (writing took 8.129890316165984 seconds)
2023-07-01 11:54:06 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-07-01 11:54:06 | INFO | train | epoch 002 | loss 6.753 | trans_loss 5.28 | nll_loss 3.967 | w2v_ctc_loss 3.289 | task_loss 0.484 | contrastive_loss 1.206 | total 4138.65 | n_correct 373.183 | ppl 15.64 | accuracy 9.017 | wps 15703.1 | ups 1.27 | wpb 12355.8 | bsz 458.5 | num_updates 2947 | lr 0.000117921 | gnorm 1.129 | clip 0 | loss_scale 128 | train_wall 1061 | gb_free 19.3 | wall 2354
2023-07-01 11:54:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 11:54:07 | INFO | fairseq.trainer | begin training epoch 3
2023-07-01 11:54:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 11:54:54 | INFO | train_inner | epoch 003:     53 / 1474 loss=6.166, trans_loss=5.203, nll_loss=3.873, w2v_ctc_loss=2.761, task_loss=0.484, contrastive_loss=0.819, total=4071.2, n_correct=410.89, ppl=14.65, accuracy=10.093, wps=9747, ups=0.8, wpb=12148.3, bsz=442.6, num_updates=3000, lr=0.00012004, gnorm=0.716, clip=0, loss_scale=128, train_wall=73, gb_free=19.1, wall=2402
2023-07-01 11:54:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-01 11:54:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-01 11:54:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-01 11:54:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-01 11:55:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-07-01 11:56:39 | INFO | train_inner | epoch 003:    158 / 1474 loss=5.385, trans_loss=4.47, nll_loss=2.915, w2v_ctc_loss=2.406, task_loss=0.484, contrastive_loss=0.684, total=4144.18, n_correct=1070.21, ppl=7.54, accuracy=25.824, wps=11877.3, ups=0.96, wpb=12381.7, bsz=458.6, num_updates=3100, lr=0.000124038, gnorm=1.689, clip=1, loss_scale=4, train_wall=104, gb_free=16.7, wall=2506
2023-07-01 11:58:20 | INFO | train_inner | epoch 003:    258 / 1474 loss=4.955, trans_loss=4.188, nll_loss=2.545, w2v_ctc_loss=2.136, task_loss=0.484, contrastive_loss=0.601, total=4161.13, n_correct=1383.66, ppl=5.84, accuracy=33.252, wps=12340.7, ups=0.99, wpb=12444.3, bsz=467, num_updates=3200, lr=0.000128036, gnorm=1.131, clip=0, loss_scale=4, train_wall=100, gb_free=17.3, wall=2607
2023-07-01 11:59:59 | INFO | train_inner | epoch 003:    358 / 1474 loss=4.818, trans_loss=4.098, nll_loss=2.425, w2v_ctc_loss=2.039, task_loss=0.484, contrastive_loss=0.636, total=4150.02, n_correct=1505.68, ppl=5.37, accuracy=36.281, wps=12448.7, ups=1.01, wpb=12369, bsz=461.6, num_updates=3300, lr=0.000132034, gnorm=1.148, clip=0, loss_scale=4, train_wall=99, gb_free=17.3, wall=2706
2023-07-01 12:01:39 | INFO | train_inner | epoch 003:    458 / 1474 loss=4.673, trans_loss=4.02, nll_loss=2.326, w2v_ctc_loss=1.95, task_loss=0.484, contrastive_loss=0.492, total=4209.57, n_correct=1637.6, ppl=5.01, accuracy=38.902, wps=12500.7, ups=1, wpb=12537.6, bsz=476.8, num_updates=3400, lr=0.000136032, gnorm=1.043, clip=0, loss_scale=4, train_wall=100, gb_free=16.2, wall=2807
2023-07-01 12:03:19 | INFO | train_inner | epoch 003:    558 / 1474 loss=4.567, trans_loss=3.979, nll_loss=2.266, w2v_ctc_loss=1.858, task_loss=0.484, contrastive_loss=0.46, total=4088.48, n_correct=1654.94, ppl=4.81, accuracy=40.478, wps=12321.8, ups=1.01, wpb=12237.1, bsz=439.7, num_updates=3500, lr=0.00014003, gnorm=0.999, clip=0, loss_scale=4, train_wall=99, gb_free=17.8, wall=2906
2023-07-01 12:05:00 | INFO | train_inner | epoch 003:    658 / 1474 loss=4.504, trans_loss=3.934, nll_loss=2.209, w2v_ctc_loss=1.799, task_loss=0.484, contrastive_loss=0.57, total=4221.58, n_correct=1787.91, ppl=4.62, accuracy=42.352, wps=12402.7, ups=0.99, wpb=12558.6, bsz=481.9, num_updates=3600, lr=0.000144028, gnorm=0.953, clip=0, loss_scale=4, train_wall=101, gb_free=16.5, wall=3007
2023-07-01 12:06:39 | INFO | train_inner | epoch 003:    758 / 1474 loss=4.422, trans_loss=3.901, nll_loss=2.166, w2v_ctc_loss=1.759, task_loss=0.484, contrastive_loss=0.335, total=4167.41, n_correct=1810.68, ppl=4.49, accuracy=43.449, wps=12505, ups=1, wpb=12462.8, bsz=472.6, num_updates=3700, lr=0.000148026, gnorm=0.944, clip=0, loss_scale=4, train_wall=99, gb_free=16.5, wall=3107
2023-07-01 12:08:20 | INFO | train_inner | epoch 003:    858 / 1474 loss=4.371, trans_loss=3.882, nll_loss=2.14, w2v_ctc_loss=1.717, task_loss=0.484, contrastive_loss=0.299, total=4165.53, n_correct=1845.1, ppl=4.41, accuracy=44.294, wps=12377.9, ups=0.99, wpb=12445.3, bsz=456.1, num_updates=3800, lr=0.000152024, gnorm=0.92, clip=0, loss_scale=4, train_wall=100, gb_free=17.2, wall=3208
2023-07-01 12:10:00 | INFO | train_inner | epoch 003:    958 / 1474 loss=4.34, trans_loss=3.855, nll_loss=2.105, w2v_ctc_loss=1.697, task_loss=0.484, contrastive_loss=0.333, total=4162.3, n_correct=1891.91, ppl=4.3, accuracy=45.453, wps=12384.9, ups=1, wpb=12408.5, bsz=469.2, num_updates=3900, lr=0.000156022, gnorm=0.922, clip=0, loss_scale=4, train_wall=100, gb_free=16.9, wall=3308
2023-07-01 12:11:40 | INFO | train_inner | epoch 003:   1058 / 1474 loss=4.314, trans_loss=3.844, nll_loss=2.091, w2v_ctc_loss=1.682, task_loss=0.484, contrastive_loss=0.288, total=4069.95, n_correct=1866.52, ppl=4.26, accuracy=45.861, wps=12241, ups=1.01, wpb=12168.2, bsz=443.6, num_updates=4000, lr=0.00016002, gnorm=0.923, clip=0, loss_scale=4, train_wall=99, gb_free=16.5, wall=3407
2023-07-01 12:11:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 12:12:12 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.186 | trans_loss 6.436 | nll_loss 3.988 | w2v_ctc_loss 2.062 | task_loss 0 | contrastive_loss 0.404 | total 4003.4 | n_correct 1943.3 | ppl 15.87 | accuracy 48.541 | uer 29.334 | wer 30.211 | raw_wer 30.211 | bleu 6.89 | wps 1573 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 6.89
2023-07-01 12:12:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-07-01 12:12:12 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_3_4000.pt
2023-07-01 12:12:14 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_3_4000.pt
2023-07-01 12:12:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 6.89) (writing took 8.50317951431498 seconds)
2023-07-01 12:13:59 | INFO | train_inner | epoch 003:   1158 / 1474 loss=4.278, trans_loss=3.836, nll_loss=2.079, w2v_ctc_loss=1.644, task_loss=0.484, contrastive_loss=0.269, total=4038.49, n_correct=1867.87, ppl=4.23, accuracy=46.252, wps=8631.9, ups=0.72, wpb=12064, bsz=432.5, num_updates=4100, lr=0.000164018, gnorm=0.893, clip=0, loss_scale=4, train_wall=99, gb_free=16.6, wall=3547
2023-07-01 12:15:38 | INFO | train_inner | epoch 003:   1258 / 1474 loss=4.239, trans_loss=3.818, nll_loss=2.057, w2v_ctc_loss=1.608, task_loss=0.484, contrastive_loss=0.252, total=4064.31, n_correct=1916.43, ppl=4.16, accuracy=47.153, wps=12257.6, ups=1.01, wpb=12147.9, bsz=433.9, num_updates=4200, lr=0.000168016, gnorm=0.879, clip=0, loss_scale=4, train_wall=99, gb_free=17.5, wall=3646
2023-07-01 12:17:19 | INFO | train_inner | epoch 003:   1358 / 1474 loss=4.227, trans_loss=3.797, nll_loss=2.033, w2v_ctc_loss=1.591, task_loss=0.484, contrastive_loss=0.366, total=4134.58, n_correct=1968.74, ppl=4.09, accuracy=47.616, wps=12298.4, ups=1, wpb=12326.9, bsz=460.7, num_updates=4300, lr=0.000172014, gnorm=0.895, clip=0, loss_scale=4, train_wall=100, gb_free=17.9, wall=3746
2023-07-01 12:19:00 | INFO | train_inner | epoch 003:   1458 / 1474 loss=4.192, trans_loss=3.782, nll_loss=2.014, w2v_ctc_loss=1.559, task_loss=0.484, contrastive_loss=0.345, total=4209.94, n_correct=2033.97, ppl=4.04, accuracy=48.314, wps=12449.1, ups=0.99, wpb=12573.7, bsz=477.4, num_updates=4400, lr=0.000176012, gnorm=0.864, clip=0, loss_scale=4, train_wall=101, gb_free=17.2, wall=3847
2023-07-01 12:19:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 12:19:48 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.043 | trans_loss 6.322 | nll_loss 3.833 | w2v_ctc_loss 1.866 | task_loss 0 | contrastive_loss 0.372 | total 4003.4 | n_correct 2025.5 | ppl 14.25 | accuracy 50.594 | uer 28.039 | wer 28.634 | raw_wer 28.634 | bleu 7.96 | wps 1586.6 | wpb 4003.4 | bsz 141.8 | num_updates 4416 | best_bleu 7.96
2023-07-01 12:19:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4416 updates
2023-07-01 12:19:48 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt
2023-07-01 12:19:52 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt
2023-07-01 12:19:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt (epoch 3 @ 4416 updates, score 7.96) (writing took 7.892402144148946 seconds)
2023-07-01 12:19:56 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-07-01 12:19:56 | INFO | train | epoch 003 | loss 4.576 | trans_loss 4.001 | nll_loss 2.297 | w2v_ctc_loss 1.849 | task_loss 0.484 | contrastive_loss 0.441 | total 4140.05 | n_correct 1686.23 | ppl 4.92 | accuracy 40.73 | wps 11718.4 | ups 0.95 | wpb 12360.2 | bsz 459 | num_updates 4416 | lr 0.000176652 | gnorm 1.002 | clip 0.1 | loss_scale 4 | train_wall 1453 | gb_free 16.8 | wall 3903
2023-07-01 12:19:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 12:19:56 | INFO | fairseq.trainer | begin training epoch 4
2023-07-01 12:19:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 12:21:27 | INFO | train_inner | epoch 004:     84 / 1474 loss=4.113, trans_loss=3.754, nll_loss=1.976, w2v_ctc_loss=1.516, task_loss=0.484, contrastive_loss=0.201, total=4099.41, n_correct=2011.39, ppl=3.93, accuracy=49.065, wps=8287.7, ups=0.68, wpb=12215.8, bsz=439.5, num_updates=4500, lr=0.00018001, gnorm=0.846, clip=0, loss_scale=4, train_wall=98, gb_free=16.6, wall=3995
2023-07-01 12:23:06 | INFO | train_inner | epoch 004:    184 / 1474 loss=4.095, trans_loss=3.739, nll_loss=1.955, w2v_ctc_loss=1.498, task_loss=0.484, contrastive_loss=0.225, total=4175.15, n_correct=2078.07, ppl=3.88, accuracy=49.772, wps=12579.6, ups=1.01, wpb=12466.1, bsz=468.3, num_updates=4600, lr=0.000184008, gnorm=0.86, clip=0, loss_scale=4, train_wall=99, gb_free=16.8, wall=4094
2023-07-01 12:24:46 | INFO | train_inner | epoch 004:    284 / 1474 loss=4.112, trans_loss=3.74, nll_loss=1.958, w2v_ctc_loss=1.493, task_loss=0.484, contrastive_loss=0.354, total=4145.23, n_correct=2061.27, ppl=3.89, accuracy=49.726, wps=12378.3, ups=1, wpb=12387.3, bsz=463, num_updates=4700, lr=0.000188006, gnorm=0.85, clip=0, loss_scale=4, train_wall=100, gb_free=16.1, wall=4194
2023-07-01 12:26:26 | INFO | train_inner | epoch 004:    384 / 1474 loss=4.079, trans_loss=3.739, nll_loss=1.954, w2v_ctc_loss=1.48, task_loss=0.484, contrastive_loss=0.197, total=4127.66, n_correct=2062.06, ppl=3.88, accuracy=49.957, wps=12385.4, ups=1.01, wpb=12298.8, bsz=443.5, num_updates=4800, lr=0.000192004, gnorm=0.837, clip=0, loss_scale=4, train_wall=99, gb_free=17.6, wall=4293
2023-07-01 12:28:06 | INFO | train_inner | epoch 004:    484 / 1474 loss=4.094, trans_loss=3.718, nll_loss=1.932, w2v_ctc_loss=1.439, task_loss=0.484, contrastive_loss=0.592, total=4218.78, n_correct=2136.59, ppl=3.81, accuracy=50.645, wps=12503.5, ups=0.99, wpb=12578.2, bsz=497.8, num_updates=4900, lr=0.000196002, gnorm=0.827, clip=0, loss_scale=4, train_wall=100, gb_free=16.7, wall=4394
2023-07-01 12:29:46 | INFO | train_inner | epoch 004:    584 / 1474 loss=4.067, trans_loss=3.717, nll_loss=1.93, w2v_ctc_loss=1.47, task_loss=0.484, contrastive_loss=0.27, total=4217.52, n_correct=2141, ppl=3.81, accuracy=50.764, wps=12567.9, ups=1, wpb=12583.6, bsz=485.9, num_updates=5000, lr=0.0002, gnorm=0.837, clip=0, loss_scale=4, train_wall=100, gb_free=16.3, wall=4494
tensor(0.8528, device='cuda:0')
tensor(0.8147, device='cuda:0')
2023-07-01 12:31:28 | INFO | train_inner | epoch 004:    684 / 1474 loss=4.049, trans_loss=3.72, nll_loss=1.929, w2v_ctc_loss=1.435, task_loss=0.484, contrastive_loss=0.318, total=4176.39, n_correct=2132.47, ppl=3.81, accuracy=51.06, wps=12213.7, ups=0.98, wpb=12440.1, bsz=455.8, num_updates=5100, lr=0.00019803, gnorm=0.704, clip=0, loss_scale=8, train_wall=101, gb_free=17.2, wall=4596
2023-07-01 12:33:09 | INFO | train_inner | epoch 004:    784 / 1474 loss=4.039, trans_loss=3.716, nll_loss=1.924, w2v_ctc_loss=1.447, task_loss=0.484, contrastive_loss=0.19, total=4026.63, n_correct=2056.25, ppl=3.79, accuracy=51.066, wps=11998.1, ups=1, wpb=12049.9, bsz=420.6, num_updates=5200, lr=0.000196116, gnorm=0.723, clip=0, loss_scale=8, train_wall=100, gb_free=13.5, wall=4696
2023-07-01 12:34:49 | INFO | train_inner | epoch 004:    884 / 1474 loss=4.043, trans_loss=3.701, nll_loss=1.91, w2v_ctc_loss=1.434, task_loss=0.484, contrastive_loss=0.364, total=4186.04, n_correct=2155.51, ppl=3.76, accuracy=51.493, wps=12490.5, ups=1, wpb=12493.4, bsz=466.3, num_updates=5300, lr=0.000194257, gnorm=0.706, clip=0, loss_scale=8, train_wall=100, gb_free=17.8, wall=4796
2023-07-01 12:36:29 | INFO | train_inner | epoch 004:    984 / 1474 loss=3.994, trans_loss=3.692, nll_loss=1.897, w2v_ctc_loss=1.406, task_loss=0.484, contrastive_loss=0.228, total=4125.02, n_correct=2143.4, ppl=3.73, accuracy=51.961, wps=12263.2, ups=1, wpb=12319.9, bsz=457.1, num_updates=5400, lr=0.00019245, gnorm=0.7, clip=0, loss_scale=8, train_wall=100, gb_free=13.1, wall=4897
2023-07-01 12:38:09 | INFO | train_inner | epoch 004:   1084 / 1474 loss=4.006, trans_loss=3.698, nll_loss=1.903, w2v_ctc_loss=1.414, task_loss=0.484, contrastive_loss=0.207, total=4075.6, n_correct=2112.21, ppl=3.74, accuracy=51.826, wps=12167.4, ups=1, wpb=12166.1, bsz=435.7, num_updates=5500, lr=0.000190693, gnorm=0.706, clip=0, loss_scale=8, train_wall=100, gb_free=16.2, wall=4997
2023-07-01 12:39:49 | INFO | train_inner | epoch 004:   1184 / 1474 loss=4.003, trans_loss=3.689, nll_loss=1.893, w2v_ctc_loss=1.396, task_loss=0.484, contrastive_loss=0.315, total=4161.18, n_correct=2180.18, ppl=3.71, accuracy=52.393, wps=12503, ups=1, wpb=12451.8, bsz=483.4, num_updates=5600, lr=0.000188982, gnorm=0.695, clip=0, loss_scale=8, train_wall=99, gb_free=16.9, wall=5096
2023-07-01 12:41:28 | INFO | train_inner | epoch 004:   1284 / 1474 loss=3.988, trans_loss=3.683, nll_loss=1.885, w2v_ctc_loss=1.384, task_loss=0.484, contrastive_loss=0.28, total=4156.53, n_correct=2188.7, ppl=3.69, accuracy=52.657, wps=12467.3, ups=1, wpb=12424.6, bsz=472.7, num_updates=5700, lr=0.000187317, gnorm=0.698, clip=0, loss_scale=8, train_wall=99, gb_free=16.2, wall=5196
2023-07-01 12:43:07 | INFO | train_inner | epoch 004:   1384 / 1474 loss=3.965, trans_loss=3.678, nll_loss=1.88, w2v_ctc_loss=1.387, task_loss=0.484, contrastive_loss=0.16, total=4101.23, n_correct=2163.71, ppl=3.68, accuracy=52.758, wps=12408.8, ups=1.01, wpb=12255, bsz=437.6, num_updates=5800, lr=0.000185695, gnorm=0.675, clip=0, loss_scale=8, train_wall=98, gb_free=15.8, wall=5295
2023-07-01 12:44:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.8528, device='cuda:7')
tensor(0.8147, device='cuda:7')
tensor(0.8528, device='cuda:1')
tensor(0.8147, device='cuda:1')
tensor(0.8528, device='cuda:5')
tensor(0.8147, device='cuda:5')
tensor(0.8528, device='cuda:2')
tensor(0.8147, device='cuda:2')
tensor(0.8528, device='cuda:3')
tensor(0.8147, device='cuda:3')
tensor(0.8528, device='cuda:6')
tensor(0.8147, device='cuda:6')
tensor(0.8528, device='cuda:4')
tensor(0.8147, device='cuda:4')
2023-07-01 12:45:05 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.675 | trans_loss 5.943 | nll_loss 3.33 | w2v_ctc_loss 1.569 | task_loss 0 | contrastive_loss 0.304 | total 4003.4 | n_correct 2252.3 | ppl 10.06 | accuracy 56.26 | uer 22.775 | wer 24.376 | raw_wer 24.376 | bleu 14.31 | wps 1881.2 | wpb 4003.4 | bsz 141.8 | num_updates 5890 | best_bleu 14.31
2023-07-01 12:45:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5890 updates
2023-07-01 12:45:05 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt
2023-07-01 12:45:10 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt
2023-07-01 12:45:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt (epoch 4 @ 5890 updates, score 14.31) (writing took 8.534132005181164 seconds)
2023-07-01 12:45:14 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-07-01 12:45:14 | INFO | train | epoch 004 | loss 4.039 | trans_loss 3.71 | nll_loss 1.92 | w2v_ctc_loss 1.437 | task_loss 0.484 | contrastive_loss 0.277 | total 4138.65 | n_correct 2119.78 | ppl 3.78 | accuracy 51.219 | wps 11997.6 | ups 0.97 | wpb 12355.8 | bsz 458.5 | num_updates 5890 | lr 0.000184271 | gnorm 0.756 | clip 0 | loss_scale 8 | train_wall 1467 | gb_free 15 | wall 5421
2023-07-01 12:45:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 12:45:14 | INFO | fairseq.trainer | begin training epoch 5
2023-07-01 12:45:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 12:45:32 | INFO | train_inner | epoch 005:     10 / 1474 loss=3.943, trans_loss=3.673, nll_loss=1.873, w2v_ctc_loss=1.36, task_loss=0.484, contrastive_loss=0.176, total=4037.7, n_correct=2139.02, ppl=3.66, accuracy=52.976, wps=8313.3, ups=0.69, wpb=12062.8, bsz=439.3, num_updates=5900, lr=0.000184115, gnorm=0.682, clip=0, loss_scale=8, train_wall=99, gb_free=17, wall=5440
2023-07-01 12:47:12 | INFO | train_inner | epoch 005:    110 / 1474 loss=3.846, trans_loss=3.62, nll_loss=1.804, w2v_ctc_loss=1.277, task_loss=0.484, contrastive_loss=0.185, total=4247.37, n_correct=2315.75, ppl=3.49, accuracy=54.522, wps=12677.8, ups=1, wpb=12683.8, bsz=495.1, num_updates=6000, lr=0.000182574, gnorm=0.65, clip=0, loss_scale=8, train_wall=100, gb_free=16.9, wall=5540
2023-07-01 12:47:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 12:47:42 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.644 | trans_loss 5.91 | nll_loss 3.282 | w2v_ctc_loss 1.545 | task_loss 0 | contrastive_loss 0.3 | total 4003.4 | n_correct 2266.8 | ppl 9.73 | accuracy 56.622 | uer 21.769 | wer 23.426 | raw_wer 23.426 | bleu 14.99 | wps 1813.2 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 14.99
2023-07-01 12:47:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-07-01 12:47:42 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_5_6000.pt
2023-07-01 12:47:44 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_5_6000.pt
2023-07-01 12:47:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 14.99) (writing took 9.36500159977004 seconds)
2023-07-01 12:49:30 | INFO | train_inner | epoch 005:    210 / 1474 loss=3.894, trans_loss=3.631, nll_loss=1.817, w2v_ctc_loss=1.296, task_loss=0.484, contrastive_loss=0.406, total=4189.85, n_correct=2272.06, ppl=3.52, accuracy=54.228, wps=9092.7, ups=0.73, wpb=12492.8, bsz=488.2, num_updates=6100, lr=0.000181071, gnorm=0.661, clip=0, loss_scale=8, train_wall=98, gb_free=17.9, wall=5677
2023-07-01 12:51:08 | INFO | train_inner | epoch 005:    310 / 1474 loss=3.888, trans_loss=3.63, nll_loss=1.818, w2v_ctc_loss=1.315, task_loss=0.484, contrastive_loss=0.257, total=4090.1, n_correct=2211.52, ppl=3.53, accuracy=54.07, wps=12391.4, ups=1.01, wpb=12240, bsz=443.9, num_updates=6200, lr=0.000179605, gnorm=0.669, clip=0, loss_scale=8, train_wall=98, gb_free=16.4, wall=5776
2023-07-01 12:52:48 | INFO | train_inner | epoch 005:    410 / 1474 loss=3.869, trans_loss=3.622, nll_loss=1.812, w2v_ctc_loss=1.276, task_loss=0.484, contrastive_loss=0.339, total=4147.17, n_correct=2260.27, ppl=3.51, accuracy=54.502, wps=12408.6, ups=1, wpb=12381.8, bsz=472.5, num_updates=6300, lr=0.000178174, gnorm=0.672, clip=0, loss_scale=8, train_wall=99, gb_free=15.1, wall=5876
2023-07-01 12:54:28 | INFO | train_inner | epoch 005:    510 / 1474 loss=3.862, trans_loss=3.635, nll_loss=1.822, w2v_ctc_loss=1.291, task_loss=0.484, contrastive_loss=0.132, total=4026.81, n_correct=2184.79, ppl=3.54, accuracy=54.256, wps=12067.4, ups=1, wpb=12047.2, bsz=416.6, num_updates=6400, lr=0.000176777, gnorm=0.666, clip=0, loss_scale=8, train_wall=99, gb_free=17.5, wall=5976
2023-07-01 12:56:08 | INFO | train_inner | epoch 005:    610 / 1474 loss=3.866, trans_loss=3.629, nll_loss=1.815, w2v_ctc_loss=1.277, task_loss=0.484, contrastive_loss=0.307, total=4107.75, n_correct=2232.89, ppl=3.52, accuracy=54.358, wps=12312.1, ups=1.01, wpb=12245.3, bsz=451.2, num_updates=6500, lr=0.000175412, gnorm=0.671, clip=0, loss_scale=8, train_wall=99, gb_free=16.3, wall=6075
2023-07-01 12:57:48 | INFO | train_inner | epoch 005:    710 / 1474 loss=3.866, trans_loss=3.622, nll_loss=1.809, w2v_ctc_loss=1.283, task_loss=0.484, contrastive_loss=0.283, total=4178.85, n_correct=2280.32, ppl=3.5, accuracy=54.568, wps=12401, ups=1, wpb=12462.3, bsz=480.9, num_updates=6600, lr=0.000174078, gnorm=0.662, clip=0, loss_scale=8, train_wall=100, gb_free=17.8, wall=6176
2023-07-01 12:59:29 | INFO | train_inner | epoch 005:    810 / 1474 loss=3.854, trans_loss=3.625, nll_loss=1.81, w2v_ctc_loss=1.274, task_loss=0.484, contrastive_loss=0.207, total=4127.73, n_correct=2260.02, ppl=3.51, accuracy=54.752, wps=12248.7, ups=0.99, wpb=12320.4, bsz=449.2, num_updates=6700, lr=0.000172774, gnorm=0.655, clip=0, loss_scale=8, train_wall=100, gb_free=15.4, wall=6276
2023-07-01 13:01:08 | INFO | train_inner | epoch 005:    910 / 1474 loss=3.835, trans_loss=3.621, nll_loss=1.807, w2v_ctc_loss=1.263, task_loss=0.484, contrastive_loss=0.169, total=4095.48, n_correct=2246.79, ppl=3.5, accuracy=54.86, wps=12300.7, ups=1.01, wpb=12237.9, bsz=445.3, num_updates=6800, lr=0.000171499, gnorm=0.656, clip=0, loss_scale=8, train_wall=99, gb_free=15.8, wall=6376
2023-07-01 13:02:47 | INFO | train_inner | epoch 005:   1010 / 1474 loss=3.852, trans_loss=3.623, nll_loss=1.81, w2v_ctc_loss=1.271, task_loss=0.484, contrastive_loss=0.253, total=4165.12, n_correct=2288.55, ppl=3.51, accuracy=54.946, wps=12528, ups=1.01, wpb=12426.3, bsz=463.5, num_updates=6900, lr=0.000170251, gnorm=0.648, clip=0, loss_scale=8, train_wall=99, gb_free=15.9, wall=6475
2023-07-01 13:04:28 | INFO | train_inner | epoch 005:   1110 / 1474 loss=3.859, trans_loss=3.623, nll_loss=1.806, w2v_ctc_loss=1.27, task_loss=0.484, contrastive_loss=0.253, total=4176.72, n_correct=2299.58, ppl=3.5, accuracy=55.057, wps=12381.3, ups=0.99, wpb=12467.3, bsz=466.1, num_updates=7000, lr=0.000169031, gnorm=0.65, clip=0, loss_scale=8, train_wall=100, gb_free=16.9, wall=6576
2023-07-01 13:06:08 | INFO | train_inner | epoch 005:   1210 / 1474 loss=3.828, trans_loss=3.621, nll_loss=1.806, w2v_ctc_loss=1.254, task_loss=0.484, contrastive_loss=0.154, total=4164.13, n_correct=2300.86, ppl=3.5, accuracy=55.254, wps=12381, ups=1, wpb=12416.1, bsz=453.8, num_updates=7100, lr=0.000167836, gnorm=0.654, clip=0, loss_scale=16, train_wall=100, gb_free=17.1, wall=6676
2023-07-01 13:07:48 | INFO | train_inner | epoch 005:   1310 / 1474 loss=3.814, trans_loss=3.616, nll_loss=1.798, w2v_ctc_loss=1.24, task_loss=0.484, contrastive_loss=0.125, total=4134.91, n_correct=2288.01, ppl=3.48, accuracy=55.334, wps=12422.9, ups=1.01, wpb=12356.4, bsz=445.6, num_updates=7200, lr=0.000166667, gnorm=0.644, clip=0, loss_scale=16, train_wall=99, gb_free=16.6, wall=6775
2023-07-01 13:09:27 | INFO | train_inner | epoch 005:   1410 / 1474 loss=3.814, trans_loss=3.609, nll_loss=1.795, w2v_ctc_loss=1.243, task_loss=0.484, contrastive_loss=0.187, total=4134.37, n_correct=2283.02, ppl=3.47, accuracy=55.221, wps=12382.3, ups=1, wpb=12339.9, bsz=458.5, num_updates=7300, lr=0.000165521, gnorm=0.643, clip=0, loss_scale=16, train_wall=99, gb_free=17.9, wall=6875
2023-07-01 13:10:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 13:11:01 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.606 | trans_loss 5.885 | nll_loss 3.256 | w2v_ctc_loss 1.477 | task_loss 0 | contrastive_loss 0.303 | total 4003.4 | n_correct 2279 | ppl 9.55 | accuracy 56.927 | uer 21.918 | wer 23.653 | raw_wer 23.653 | bleu 14.77 | wps 1756.9 | wpb 4003.4 | bsz 141.8 | num_updates 7364 | best_bleu 14.99
2023-07-01 13:11:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7364 updates
2023-07-01 13:11:01 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_14.7706.pt
2023-07-01 13:11:03 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_14.7706.pt
2023-07-01 13:11:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_14.7706.pt (epoch 5 @ 7364 updates, score 14.77) (writing took 5.14682697923854 seconds)
2023-07-01 13:11:06 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-07-01 13:11:06 | INFO | train | epoch 005 | loss 3.852 | trans_loss 3.623 | nll_loss 1.809 | w2v_ctc_loss 1.273 | task_loss 0.484 | contrastive_loss 0.233 | total 4138.65 | n_correct 2265.6 | ppl 3.5 | accuracy 54.742 | wps 11732.7 | ups 0.95 | wpb 12355.8 | bsz 458.5 | num_updates 7364 | lr 0.0001648 | gnorm 0.658 | clip 0 | loss_scale 16 | train_wall 1464 | gb_free 16.4 | wall 6974
2023-07-01 13:11:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 13:11:06 | INFO | fairseq.trainer | begin training epoch 6
2023-07-01 13:11:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 13:11:50 | INFO | train_inner | epoch 006:     36 / 1474 loss=3.794, trans_loss=3.594, nll_loss=1.771, w2v_ctc_loss=1.225, task_loss=0.484, contrastive_loss=0.183, total=4115.45, n_correct=2305.34, ppl=3.41, accuracy=56.017, wps=8591.2, ups=0.7, wpb=12279.2, bsz=447.9, num_updates=7400, lr=0.000164399, gnorm=0.662, clip=0, loss_scale=16, train_wall=100, gb_free=16.6, wall=7018
2023-07-01 13:13:30 | INFO | train_inner | epoch 006:    136 / 1474 loss=3.742, trans_loss=3.568, nll_loss=1.739, w2v_ctc_loss=1.173, task_loss=0.484, contrastive_loss=0.229, total=4154.25, n_correct=2347.68, ppl=3.34, accuracy=56.513, wps=12437.6, ups=1, wpb=12409.6, bsz=456.1, num_updates=7500, lr=0.000163299, gnorm=0.643, clip=0, loss_scale=16, train_wall=99, gb_free=15.7, wall=7118
2023-07-01 13:15:10 | INFO | train_inner | epoch 006:    236 / 1474 loss=3.759, trans_loss=3.578, nll_loss=1.753, w2v_ctc_loss=1.211, task_loss=0.484, contrastive_loss=0.137, total=4112.66, n_correct=2306.13, ppl=3.37, accuracy=56.074, wps=12345.6, ups=1.01, wpb=12281.7, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.642, clip=0, loss_scale=16, train_wall=99, gb_free=16.3, wall=7217
2023-07-01 13:16:51 | INFO | train_inner | epoch 006:    336 / 1474 loss=3.763, trans_loss=3.566, nll_loss=1.739, w2v_ctc_loss=1.164, task_loss=0.484, contrastive_loss=0.438, total=4177.51, n_correct=2368.38, ppl=3.34, accuracy=56.694, wps=12316.9, ups=0.99, wpb=12463.7, bsz=491.3, num_updates=7700, lr=0.000161165, gnorm=0.636, clip=0, loss_scale=16, train_wall=101, gb_free=16.3, wall=7318
2023-07-01 13:18:30 | INFO | train_inner | epoch 006:    436 / 1474 loss=3.729, trans_loss=3.569, nll_loss=1.741, w2v_ctc_loss=1.171, task_loss=0.484, contrastive_loss=0.152, total=4154.57, n_correct=2356.24, ppl=3.34, accuracy=56.714, wps=12499.6, ups=1.01, wpb=12407.2, bsz=470.2, num_updates=7800, lr=0.000160128, gnorm=0.634, clip=0, loss_scale=16, train_wall=99, gb_free=16.3, wall=7418
2023-07-01 13:20:10 | INFO | train_inner | epoch 006:    536 / 1474 loss=3.738, trans_loss=3.572, nll_loss=1.745, w2v_ctc_loss=1.184, task_loss=0.484, contrastive_loss=0.138, total=4167.79, n_correct=2365.69, ppl=3.35, accuracy=56.761, wps=12411.9, ups=1, wpb=12419.2, bsz=455.2, num_updates=7900, lr=0.000159111, gnorm=0.639, clip=0, loss_scale=16, train_wall=100, gb_free=15.9, wall=7518
2023-07-01 13:21:50 | INFO | train_inner | epoch 006:    636 / 1474 loss=3.734, trans_loss=3.573, nll_loss=1.744, w2v_ctc_loss=1.164, task_loss=0.484, contrastive_loss=0.195, total=4146.17, n_correct=2349.38, ppl=3.35, accuracy=56.664, wps=12442, ups=1, wpb=12395.5, bsz=471.6, num_updates=8000, lr=0.000158114, gnorm=0.632, clip=0, loss_scale=16, train_wall=99, gb_free=16.7, wall=7617
2023-07-01 13:21:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 13:22:18 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.533 | trans_loss 5.803 | nll_loss 3.145 | w2v_ctc_loss 1.437 | task_loss 0 | contrastive_loss 0.286 | total 4003.4 | n_correct 2323.7 | ppl 8.85 | accuracy 58.043 | uer 20.24 | wer 21.919 | raw_wer 21.919 | bleu 16.6 | wps 1932 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 16.6
2023-07-01 13:22:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-07-01 13:22:18 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_6_8000.pt
2023-07-01 13:22:20 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_6_8000.pt
2023-07-01 13:22:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 16.6) (writing took 8.88231378281489 seconds)
2023-07-01 13:24:07 | INFO | train_inner | epoch 006:    736 / 1474 loss=3.747, trans_loss=3.576, nll_loss=1.751, w2v_ctc_loss=1.19, task_loss=0.484, contrastive_loss=0.149, total=4148.65, n_correct=2348.16, ppl=3.37, accuracy=56.601, wps=9019.3, ups=0.73, wpb=12378.4, bsz=453.7, num_updates=8100, lr=0.000157135, gnorm=0.64, clip=0, loss_scale=16, train_wall=100, gb_free=15.8, wall=7755
2023-07-01 13:25:47 | INFO | train_inner | epoch 006:    836 / 1474 loss=3.739, trans_loss=3.581, nll_loss=1.755, w2v_ctc_loss=1.174, task_loss=0.484, contrastive_loss=0.131, total=4114.34, n_correct=2318.75, ppl=3.37, accuracy=56.358, wps=12315.6, ups=1, wpb=12292.5, bsz=441.6, num_updates=8200, lr=0.000156174, gnorm=0.639, clip=0, loss_scale=16, train_wall=99, gb_free=15.3, wall=7854
2023-07-01 13:27:26 | INFO | train_inner | epoch 006:    936 / 1474 loss=3.757, trans_loss=3.578, nll_loss=1.753, w2v_ctc_loss=1.186, task_loss=0.484, contrastive_loss=0.228, total=4081.53, n_correct=2305.56, ppl=3.37, accuracy=56.488, wps=12231.4, ups=1.01, wpb=12166.1, bsz=444.5, num_updates=8300, lr=0.00015523, gnorm=0.648, clip=0, loss_scale=16, train_wall=99, gb_free=17.9, wall=7954
2023-07-01 13:29:06 | INFO | train_inner | epoch 006:   1036 / 1474 loss=3.751, trans_loss=3.572, nll_loss=1.746, w2v_ctc_loss=1.166, task_loss=0.484, contrastive_loss=0.303, total=4165.84, n_correct=2369.03, ppl=3.35, accuracy=56.868, wps=12513.8, ups=1.01, wpb=12437.3, bsz=477.2, num_updates=8400, lr=0.000154303, gnorm=0.645, clip=0, loss_scale=16, train_wall=99, gb_free=17, wall=8053
2023-07-01 13:30:45 | INFO | train_inner | epoch 006:   1136 / 1474 loss=3.738, trans_loss=3.578, nll_loss=1.752, w2v_ctc_loss=1.173, task_loss=0.484, contrastive_loss=0.133, total=4072.29, n_correct=2309.32, ppl=3.37, accuracy=56.708, wps=12246.4, ups=1.01, wpb=12165.1, bsz=428, num_updates=8500, lr=0.000153393, gnorm=0.638, clip=0, loss_scale=16, train_wall=99, gb_free=17.1, wall=8153
2023-07-01 13:32:25 | INFO | train_inner | epoch 006:   1236 / 1474 loss=3.761, trans_loss=3.57, nll_loss=1.744, w2v_ctc_loss=1.153, task_loss=0.484, contrastive_loss=0.451, total=4141.55, n_correct=2356.27, ppl=3.35, accuracy=56.893, wps=12362.4, ups=1, wpb=12385.8, bsz=474.8, num_updates=8600, lr=0.000152499, gnorm=0.637, clip=0, loss_scale=16, train_wall=100, gb_free=13.5, wall=8253
2023-07-01 13:34:05 | INFO | train_inner | epoch 006:   1336 / 1474 loss=3.722, trans_loss=3.577, nll_loss=1.748, w2v_ctc_loss=1.156, task_loss=0.484, contrastive_loss=0.119, total=4125.31, n_correct=2353.79, ppl=3.36, accuracy=57.057, wps=12399.6, ups=1.01, wpb=12316, bsz=452.6, num_updates=8700, lr=0.00015162, gnorm=0.633, clip=0, loss_scale=16, train_wall=99, gb_free=17.8, wall=8352
2023-07-01 13:35:45 | INFO | train_inner | epoch 006:   1436 / 1474 loss=3.719, trans_loss=3.566, nll_loss=1.739, w2v_ctc_loss=1.164, task_loss=0.484, contrastive_loss=0.126, total=4196.2, n_correct=2399.42, ppl=3.34, accuracy=57.181, wps=12529, ups=1, wpb=12515.5, bsz=461.5, num_updates=8800, lr=0.000150756, gnorm=0.628, clip=0, loss_scale=16, train_wall=99, gb_free=11.8, wall=8452
2023-07-01 13:36:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 13:36:48 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.494 | trans_loss 5.766 | nll_loss 3.091 | w2v_ctc_loss 1.398 | task_loss 0 | contrastive_loss 0.277 | total 4003.4 | n_correct 2348 | ppl 8.52 | accuracy 58.65 | uer 19.42 | wer 21.185 | raw_wer 21.185 | bleu 17.45 | wps 2184.9 | wpb 4003.4 | bsz 141.8 | num_updates 8838 | best_bleu 17.45
2023-07-01 13:36:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8838 updates
2023-07-01 13:36:48 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt
2023-07-01 13:36:52 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt
2023-07-01 13:36:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt (epoch 6 @ 8838 updates, score 17.45) (writing took 8.016092638950795 seconds)
2023-07-01 13:36:56 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-07-01 13:36:56 | INFO | train | epoch 006 | loss 3.741 | trans_loss 3.572 | nll_loss 1.746 | w2v_ctc_loss 1.173 | task_loss 0.484 | contrastive_loss 0.209 | total 4138.65 | n_correct 2346.84 | ppl 3.35 | accuracy 56.705 | wps 11751.3 | ups 0.95 | wpb 12355.8 | bsz 458.5 | num_updates 8838 | lr 0.000150431 | gnorm 0.638 | clip 0 | loss_scale 16 | train_wall 1465 | gb_free 15.3 | wall 8524
2023-07-01 13:36:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 13:36:56 | INFO | fairseq.trainer | begin training epoch 7
2023-07-01 13:36:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 13:38:07 | INFO | train_inner | epoch 007:     62 / 1474 loss=3.673, trans_loss=3.542, nll_loss=1.707, w2v_ctc_loss=1.121, task_loss=0.484, contrastive_loss=0.139, total=4108.19, n_correct=2370.23, ppl=3.27, accuracy=57.695, wps=8593.9, ups=0.7, wpb=12269.7, bsz=461.9, num_updates=8900, lr=0.000149906, gnorm=0.623, clip=0, loss_scale=16, train_wall=99, gb_free=17.2, wall=8595
2023-07-01 13:39:46 | INFO | train_inner | epoch 007:    162 / 1474 loss=3.661, trans_loss=3.534, nll_loss=1.696, w2v_ctc_loss=1.103, task_loss=0.484, contrastive_loss=0.214, total=4106.05, n_correct=2380.37, ppl=3.24, accuracy=57.972, wps=12388.6, ups=1.01, wpb=12254.3, bsz=455.4, num_updates=9000, lr=0.000149071, gnorm=0.624, clip=0, loss_scale=16, train_wall=99, gb_free=16.9, wall=8694
2023-07-01 13:41:26 | INFO | train_inner | epoch 007:    262 / 1474 loss=3.655, trans_loss=3.532, nll_loss=1.693, w2v_ctc_loss=1.11, task_loss=0.484, contrastive_loss=0.122, total=4129.3, n_correct=2397.35, ppl=3.23, accuracy=58.057, wps=12368.3, ups=1, wpb=12322.9, bsz=451.8, num_updates=9100, lr=0.00014825, gnorm=0.627, clip=0, loss_scale=16, train_wall=99, gb_free=17.4, wall=8793
2023-07-01 13:43:06 | INFO | train_inner | epoch 007:    362 / 1474 loss=3.683, trans_loss=3.538, nll_loss=1.702, w2v_ctc_loss=1.099, task_loss=0.484, contrastive_loss=0.385, total=4201.67, n_correct=2428.62, ppl=3.25, accuracy=57.801, wps=12485.4, ups=1, wpb=12533.1, bsz=479.7, num_updates=9200, lr=0.000147442, gnorm=0.63, clip=0, loss_scale=32, train_wall=100, gb_free=15.6, wall=8894
2023-07-01 13:44:46 | INFO | train_inner | epoch 007:    462 / 1474 loss=3.68, trans_loss=3.537, nll_loss=1.705, w2v_ctc_loss=1.107, task_loss=0.484, contrastive_loss=0.31, total=4155.31, n_correct=2398.19, ppl=3.26, accuracy=57.714, wps=12445.5, ups=1, wpb=12394.6, bsz=465.5, num_updates=9300, lr=0.000146647, gnorm=0.634, clip=0, loss_scale=32, train_wall=99, gb_free=16.9, wall=8993
2023-07-01 13:46:26 | INFO | train_inner | epoch 007:    562 / 1474 loss=3.657, trans_loss=3.537, nll_loss=1.701, w2v_ctc_loss=1.109, task_loss=0.484, contrastive_loss=0.13, total=4165.88, n_correct=2420.42, ppl=3.25, accuracy=58.101, wps=12327.9, ups=0.99, wpb=12401.8, bsz=459, num_updates=9400, lr=0.000145865, gnorm=0.627, clip=0, loss_scale=32, train_wall=100, gb_free=17.3, wall=9094
2023-07-01 13:48:06 | INFO | train_inner | epoch 007:    662 / 1474 loss=3.651, trans_loss=3.541, nll_loss=1.703, w2v_ctc_loss=1.094, task_loss=0.484, contrastive_loss=0.115, total=4149.29, n_correct=2412.31, ppl=3.26, accuracy=58.138, wps=12395.6, ups=1, wpb=12393.1, bsz=451.6, num_updates=9500, lr=0.000145095, gnorm=0.622, clip=0, loss_scale=32, train_wall=100, gb_free=17.2, wall=9194
2023-07-01 13:49:46 | INFO | train_inner | epoch 007:    762 / 1474 loss=3.661, trans_loss=3.538, nll_loss=1.701, w2v_ctc_loss=1.108, task_loss=0.484, contrastive_loss=0.117, total=4134.54, n_correct=2399.2, ppl=3.25, accuracy=58.028, wps=12359.2, ups=1, wpb=12358.8, bsz=449.8, num_updates=9600, lr=0.000144338, gnorm=0.628, clip=0, loss_scale=32, train_wall=100, gb_free=14.1, wall=9294
2023-07-01 13:51:26 | INFO | train_inner | epoch 007:    862 / 1474 loss=3.657, trans_loss=3.539, nll_loss=1.701, w2v_ctc_loss=1.1, task_loss=0.484, contrastive_loss=0.136, total=4151.77, n_correct=2413.07, ppl=3.25, accuracy=58.121, wps=12401.8, ups=1, wpb=12405.1, bsz=461.9, num_updates=9700, lr=0.000143592, gnorm=0.629, clip=0, loss_scale=32, train_wall=100, gb_free=15.1, wall=9394
2023-07-01 13:53:06 | INFO | train_inner | epoch 007:    962 / 1474 loss=3.665, trans_loss=3.537, nll_loss=1.702, w2v_ctc_loss=1.094, task_loss=0.484, contrastive_loss=0.23, total=4124.8, n_correct=2398.96, ppl=3.25, accuracy=58.159, wps=12365.4, ups=1, wpb=12316.5, bsz=471.2, num_updates=9800, lr=0.000142857, gnorm=0.636, clip=0, loss_scale=32, train_wall=99, gb_free=16.8, wall=9494
2023-07-01 13:54:46 | INFO | train_inner | epoch 007:   1062 / 1474 loss=3.661, trans_loss=3.546, nll_loss=1.712, w2v_ctc_loss=1.105, task_loss=0.484, contrastive_loss=0.099, total=4113.08, n_correct=2386.42, ppl=3.28, accuracy=58.02, wps=12330.5, ups=1, wpb=12291.6, bsz=439.4, num_updates=9900, lr=0.000142134, gnorm=0.623, clip=0, loss_scale=32, train_wall=99, gb_free=15, wall=9593
2023-07-01 13:56:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-01 13:56:27 | INFO | train_inner | epoch 007:   1163 / 1474 loss=3.674, trans_loss=3.534, nll_loss=1.703, w2v_ctc_loss=1.097, task_loss=0.484, contrastive_loss=0.306, total=4112.66, n_correct=2386.25, ppl=3.26, accuracy=58.022, wps=12179.4, ups=0.99, wpb=12274, bsz=460.2, num_updates=10000, lr=0.000141421, gnorm=0.634, clip=0, loss_scale=16, train_wall=100, gb_free=16.2, wall=9694
2023-07-01 13:56:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 13:56:54 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.46 | trans_loss 5.725 | nll_loss 3.045 | w2v_ctc_loss 1.386 | task_loss 0 | contrastive_loss 0.271 | total 4003.4 | n_correct 2374.9 | ppl 8.25 | accuracy 59.322 | uer 18.692 | wer 20.603 | raw_wer 20.603 | bleu 17.81 | wps 1934.6 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 17.81
2023-07-01 13:56:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-07-01 13:56:54 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_7_10000.pt
2023-07-01 13:56:56 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_7_10000.pt
2023-07-01 13:57:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 17.81) (writing took 8.794030766934156 seconds)
tensor(0.6153, device='cuda:0')
tensor(0.5168, device='cuda:0')
2023-07-01 13:58:43 | INFO | train_inner | epoch 007:   1263 / 1474 loss=3.642, trans_loss=3.532, nll_loss=1.696, w2v_ctc_loss=1.088, task_loss=0.484, contrastive_loss=0.126, total=4129.52, n_correct=2404.34, ppl=3.24, accuracy=58.223, wps=9042.6, ups=0.73, wpb=12329.2, bsz=450.2, num_updates=10100, lr=0.00014072, gnorm=0.482, clip=0, loss_scale=16, train_wall=100, gb_free=17, wall=9830
2023-07-01 14:00:22 | INFO | train_inner | epoch 007:   1363 / 1474 loss=3.651, trans_loss=3.529, nll_loss=1.693, w2v_ctc_loss=1.097, task_loss=0.484, contrastive_loss=0.163, total=4172.87, n_correct=2442.04, ppl=3.23, accuracy=58.522, wps=12541.3, ups=1.01, wpb=12453.5, bsz=476.2, num_updates=10200, lr=0.000140028, gnorm=0.483, clip=0, loss_scale=16, train_wall=99, gb_free=17.3, wall=9930
2023-07-01 14:02:03 | INFO | train_inner | epoch 007:   1463 / 1474 loss=3.671, trans_loss=3.541, nll_loss=1.709, w2v_ctc_loss=1.1, task_loss=0.484, contrastive_loss=0.226, total=4109.42, n_correct=2389.35, ppl=3.27, accuracy=58.143, wps=12146.6, ups=0.99, wpb=12285.7, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.494, clip=0, loss_scale=16, train_wall=101, gb_free=16.6, wall=10031
2023-07-01 14:02:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.6153, device='cuda:1')
tensor(0.5168, device='cuda:1')
tensor(0.6153, device='cuda:6')
tensor(0.5168, device='cuda:6')
tensor(0.6153, device='cuda:5')
tensor(0.5168, device='cuda:5')
tensor(0.6153, device='cuda:7')
tensor(0.5168, device='cuda:7')
tensor(0.6153, device='cuda:2')
tensor(0.5168, device='cuda:2')
tensor(0.6153, device='cuda:4')
tensor(0.5168, device='cuda:4')
tensor(0.6153, device='cuda:3')
tensor(0.5168, device='cuda:3')
2023-07-01 14:02:42 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.449 | trans_loss 5.714 | nll_loss 3.03 | w2v_ctc_loss 1.376 | task_loss 0 | contrastive_loss 0.265 | total 4003.4 | n_correct 2377.3 | ppl 8.17 | accuracy 59.382 | uer 18.679 | wer 20.544 | raw_wer 20.544 | bleu 18.03 | wps 1979.3 | wpb 4003.4 | bsz 141.8 | num_updates 10311 | best_bleu 18.03
2023-07-01 14:02:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10311 updates
2023-07-01 14:02:42 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt
2023-07-01 14:02:46 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt
2023-07-01 14:02:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt (epoch 7 @ 10311 updates, score 18.03) (writing took 8.16659509530291 seconds)
2023-07-01 14:02:50 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-07-01 14:02:50 | INFO | train | epoch 007 | loss 3.662 | trans_loss 3.537 | nll_loss 1.701 | w2v_ctc_loss 1.101 | task_loss 0.484 | contrastive_loss 0.189 | total 4137.22 | n_correct 2402.36 | ppl 3.25 | accuracy 58.067 | wps 11706.8 | ups 0.95 | wpb 12351.6 | bsz 457.8 | num_updates 10311 | lr 0.000139272 | gnorm 0.598 | clip 0 | loss_scale 16 | train_wall 1466 | gb_free 13.5 | wall 10078
2023-07-01 14:02:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 14:02:50 | INFO | fairseq.trainer | begin training epoch 8
2023-07-01 14:02:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 14:04:27 | INFO | train_inner | epoch 008:     89 / 1474 loss=3.6, trans_loss=3.511, nll_loss=1.664, w2v_ctc_loss=1.054, task_loss=0.484, contrastive_loss=0.121, total=4116.25, n_correct=2428.25, ppl=3.17, accuracy=58.992, wps=8520.4, ups=0.69, wpb=12265.9, bsz=443.3, num_updates=10400, lr=0.000138675, gnorm=0.485, clip=0, loss_scale=16, train_wall=99, gb_free=17.1, wall=10175
2023-07-01 14:06:07 | INFO | train_inner | epoch 008:    189 / 1474 loss=3.61, trans_loss=3.514, nll_loss=1.669, w2v_ctc_loss=1.057, task_loss=0.484, contrastive_loss=0.144, total=4037.23, n_correct=2384.1, ppl=3.18, accuracy=59.053, wps=12093.9, ups=1.01, wpb=12033.3, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.489, clip=0, loss_scale=16, train_wall=99, gb_free=13.1, wall=10274
2023-07-01 14:07:46 | INFO | train_inner | epoch 008:    289 / 1474 loss=3.586, trans_loss=3.502, nll_loss=1.654, w2v_ctc_loss=1.038, task_loss=0.484, contrastive_loss=0.139, total=4207.78, n_correct=2497.82, ppl=3.15, accuracy=59.362, wps=12655.8, ups=1.01, wpb=12570.1, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.476, clip=0, loss_scale=16, train_wall=99, gb_free=13.3, wall=10374
2023-07-01 14:09:27 | INFO | train_inner | epoch 008:    389 / 1474 loss=3.618, trans_loss=3.511, nll_loss=1.666, w2v_ctc_loss=1.067, task_loss=0.484, contrastive_loss=0.163, total=4127.24, n_correct=2431.65, ppl=3.17, accuracy=58.917, wps=12168.7, ups=0.99, wpb=12318.5, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=0.485, clip=0, loss_scale=16, train_wall=101, gb_free=12.1, wall=10475
2023-07-01 14:11:08 | INFO | train_inner | epoch 008:    489 / 1474 loss=3.64, trans_loss=3.51, nll_loss=1.666, w2v_ctc_loss=1.044, task_loss=0.484, contrastive_loss=0.42, total=4203.76, n_correct=2480.08, ppl=3.17, accuracy=58.997, wps=12513.5, ups=1, wpb=12567.7, bsz=504.5, num_updates=10800, lr=0.000136083, gnorm=0.484, clip=0, loss_scale=16, train_wall=100, gb_free=14.7, wall=10575
2023-07-01 14:12:48 | INFO | train_inner | epoch 008:    589 / 1474 loss=3.603, trans_loss=3.51, nll_loss=1.667, w2v_ctc_loss=1.058, task_loss=0.484, contrastive_loss=0.096, total=4062.5, n_correct=2392.93, ppl=3.18, accuracy=58.903, wps=12122.2, ups=1, wpb=12171.9, bsz=427.9, num_updates=10900, lr=0.000135457, gnorm=0.482, clip=0, loss_scale=16, train_wall=100, gb_free=11.7, wall=10676
2023-07-01 14:14:28 | INFO | train_inner | epoch 008:    689 / 1474 loss=3.602, trans_loss=3.507, nll_loss=1.664, w2v_ctc_loss=1.065, task_loss=0.484, contrastive_loss=0.108, total=4142.78, n_correct=2456.8, ppl=3.17, accuracy=59.303, wps=12389.6, ups=1, wpb=12347.9, bsz=448.6, num_updates=11000, lr=0.00013484, gnorm=0.485, clip=0, loss_scale=16, train_wall=99, gb_free=16, wall=10775
2023-07-01 14:16:07 | INFO | train_inner | epoch 008:    789 / 1474 loss=3.605, trans_loss=3.504, nll_loss=1.662, w2v_ctc_loss=1.05, task_loss=0.484, contrastive_loss=0.196, total=4118.9, n_correct=2438.61, ppl=3.16, accuracy=59.205, wps=12431, ups=1.01, wpb=12327.8, bsz=447.8, num_updates=11100, lr=0.000134231, gnorm=0.487, clip=0, loss_scale=16, train_wall=99, gb_free=15.3, wall=10875
2023-07-01 14:17:47 | INFO | train_inner | epoch 008:    889 / 1474 loss=3.603, trans_loss=3.507, nll_loss=1.666, w2v_ctc_loss=1.041, task_loss=0.484, contrastive_loss=0.205, total=4169.01, n_correct=2472.59, ppl=3.17, accuracy=59.309, wps=12505.9, ups=1, wpb=12455.3, bsz=473.7, num_updates=11200, lr=0.000133631, gnorm=0.486, clip=0, loss_scale=16, train_wall=99, gb_free=16.3, wall=10974
2023-07-01 14:19:26 | INFO | train_inner | epoch 008:    989 / 1474 loss=3.577, trans_loss=3.502, nll_loss=1.658, w2v_ctc_loss=1.034, task_loss=0.484, contrastive_loss=0.103, total=4154.69, n_correct=2470.89, ppl=3.16, accuracy=59.472, wps=12529.9, ups=1.01, wpb=12398.4, bsz=464.9, num_updates=11300, lr=0.000133038, gnorm=0.483, clip=0, loss_scale=16, train_wall=99, gb_free=17.8, wall=11073
2023-07-01 14:21:07 | INFO | train_inner | epoch 008:   1089 / 1474 loss=3.616, trans_loss=3.508, nll_loss=1.667, w2v_ctc_loss=1.045, task_loss=0.484, contrastive_loss=0.329, total=4199.1, n_correct=2479.78, ppl=3.17, accuracy=59.055, wps=12405.4, ups=0.99, wpb=12520.7, bsz=465.3, num_updates=11400, lr=0.000132453, gnorm=0.48, clip=0, loss_scale=16, train_wall=101, gb_free=13, wall=11174
2023-07-01 14:22:46 | INFO | train_inner | epoch 008:   1189 / 1474 loss=3.592, trans_loss=3.507, nll_loss=1.665, w2v_ctc_loss=1.045, task_loss=0.484, contrastive_loss=0.115, total=4177.31, n_correct=2481.22, ppl=3.17, accuracy=59.398, wps=12529.7, ups=1, wpb=12476.4, bsz=472.6, num_updates=11500, lr=0.000131876, gnorm=0.478, clip=0, loss_scale=16, train_wall=99, gb_free=15.1, wall=11274
2023-07-01 14:24:25 | INFO | train_inner | epoch 008:   1289 / 1474 loss=3.603, trans_loss=3.509, nll_loss=1.668, w2v_ctc_loss=1.055, task_loss=0.484, contrastive_loss=0.135, total=4063.85, n_correct=2401.47, ppl=3.18, accuracy=59.093, wps=12243.3, ups=1.01, wpb=12141.2, bsz=438.4, num_updates=11600, lr=0.000131306, gnorm=0.484, clip=0, loss_scale=16, train_wall=99, gb_free=16.9, wall=11373
2023-07-01 14:26:04 | INFO | train_inner | epoch 008:   1389 / 1474 loss=3.607, trans_loss=3.51, nll_loss=1.671, w2v_ctc_loss=1.049, task_loss=0.484, contrastive_loss=0.189, total=4141.5, n_correct=2452.33, ppl=3.19, accuracy=59.214, wps=12494, ups=1.01, wpb=12351.9, bsz=461.5, num_updates=11700, lr=0.000130744, gnorm=0.479, clip=0, loss_scale=16, train_wall=98, gb_free=16.7, wall=11472
2023-07-01 14:27:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 14:27:56 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.431 | trans_loss 5.683 | nll_loss 2.988 | w2v_ctc_loss 1.387 | task_loss 0 | contrastive_loss 0.267 | total 4003.4 | n_correct 2406.7 | ppl 7.93 | accuracy 60.116 | uer 18.207 | wer 19.992 | raw_wer 19.992 | bleu 18.26 | wps 2059.3 | wpb 4003.4 | bsz 141.8 | num_updates 11785 | best_bleu 18.26
2023-07-01 14:27:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11785 updates
2023-07-01 14:27:56 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt
2023-07-01 14:28:00 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt
2023-07-01 14:28:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt (epoch 8 @ 11785 updates, score 18.26) (writing took 8.12695885822177 seconds)
2023-07-01 14:28:04 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-07-01 14:28:04 | INFO | train | epoch 008 | loss 3.604 | trans_loss 3.508 | nll_loss 1.665 | w2v_ctc_loss 1.049 | task_loss 0.484 | contrastive_loss 0.183 | total 4138.65 | n_correct 2449.2 | ppl 3.17 | accuracy 59.179 | wps 12029.4 | ups 0.97 | wpb 12355.8 | bsz 458.5 | num_updates 11785 | lr 0.000130272 | gnorm 0.483 | clip 0 | loss_scale 16 | train_wall 1464 | gb_free 17.1 | wall 11592
2023-07-01 14:28:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 14:28:04 | INFO | fairseq.trainer | begin training epoch 9
2023-07-01 14:28:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 14:28:27 | INFO | train_inner | epoch 009:     15 / 1474 loss=3.601, trans_loss=3.504, nll_loss=1.662, w2v_ctc_loss=1.028, task_loss=0.484, contrastive_loss=0.315, total=4139.35, n_correct=2463.63, ppl=3.16, accuracy=59.517, wps=8620.7, ups=0.7, wpb=12332.8, bsz=472.9, num_updates=11800, lr=0.000130189, gnorm=0.484, clip=0, loss_scale=16, train_wall=100, gb_free=16.4, wall=11615
2023-07-01 14:30:07 | INFO | train_inner | epoch 009:    115 / 1474 loss=3.535, trans_loss=3.475, nll_loss=1.622, w2v_ctc_loss=0.994, task_loss=0.484, contrastive_loss=0.132, total=4181.9, n_correct=2527.11, ppl=3.08, accuracy=60.43, wps=12571.3, ups=1.01, wpb=12493.2, bsz=475.9, num_updates=11900, lr=0.000129641, gnorm=0.477, clip=0, loss_scale=16, train_wall=99, gb_free=16.4, wall=11714
2023-07-01 14:31:46 | INFO | train_inner | epoch 009:    215 / 1474 loss=3.544, trans_loss=3.486, nll_loss=1.635, w2v_ctc_loss=1.004, task_loss=0.484, contrastive_loss=0.092, total=4062.07, n_correct=2439.02, ppl=3.11, accuracy=60.044, wps=12154.2, ups=1, wpb=12136.5, bsz=431.6, num_updates=12000, lr=0.000129099, gnorm=0.482, clip=0, loss_scale=16, train_wall=99, gb_free=15.8, wall=11814
2023-07-01 14:31:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 14:32:12 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.418 | trans_loss 5.687 | nll_loss 2.991 | w2v_ctc_loss 1.332 | task_loss 0 | contrastive_loss 0.273 | total 4003.4 | n_correct 2402.9 | ppl 7.95 | accuracy 60.021 | uer 18.249 | wer 20.23 | raw_wer 20.23 | bleu 18.62 | wps 2087.3 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 18.62
2023-07-01 14:32:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-07-01 14:32:12 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_9_12000.pt
2023-07-01 14:32:14 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_9_12000.pt
2023-07-01 14:32:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.62) (writing took 9.119342911057174 seconds)
2023-07-01 14:34:01 | INFO | train_inner | epoch 009:    315 / 1474 loss=3.531, trans_loss=3.473, nll_loss=1.621, w2v_ctc_loss=0.988, task_loss=0.484, contrastive_loss=0.14, total=4152.1, n_correct=2511.11, ppl=3.08, accuracy=60.478, wps=9241.5, ups=0.74, wpb=12422.8, bsz=476.6, num_updates=12100, lr=0.000128565, gnorm=0.481, clip=0, loss_scale=32, train_wall=99, gb_free=16.5, wall=11948
2023-07-01 14:35:42 | INFO | train_inner | epoch 009:    415 / 1474 loss=3.541, trans_loss=3.48, nll_loss=1.631, w2v_ctc_loss=1.001, task_loss=0.484, contrastive_loss=0.109, total=4203.78, n_correct=2526.26, ppl=3.1, accuracy=60.095, wps=12451.9, ups=0.99, wpb=12545.5, bsz=469.8, num_updates=12200, lr=0.000128037, gnorm=0.474, clip=0, loss_scale=32, train_wall=100, gb_free=17.2, wall=12049
2023-07-01 14:37:21 | INFO | train_inner | epoch 009:    515 / 1474 loss=3.573, trans_loss=3.491, nll_loss=1.644, w2v_ctc_loss=1.026, task_loss=0.484, contrastive_loss=0.159, total=4112.78, n_correct=2459.16, ppl=3.13, accuracy=59.793, wps=12345.2, ups=1.01, wpb=12260.1, bsz=437.7, num_updates=12300, lr=0.000127515, gnorm=0.487, clip=0, loss_scale=32, train_wall=99, gb_free=16.3, wall=12149
2023-07-01 14:39:00 | INFO | train_inner | epoch 009:    615 / 1474 loss=3.543, trans_loss=3.481, nll_loss=1.633, w2v_ctc_loss=1, task_loss=0.484, contrastive_loss=0.12, total=4131.32, n_correct=2482.84, ppl=3.1, accuracy=60.098, wps=12421, ups=1.01, wpb=12355.3, bsz=455, num_updates=12400, lr=0.000127, gnorm=0.486, clip=0, loss_scale=32, train_wall=99, gb_free=17.9, wall=12248
2023-07-01 14:40:39 | INFO | train_inner | epoch 009:    715 / 1474 loss=3.573, trans_loss=3.489, nll_loss=1.641, w2v_ctc_loss=1.018, task_loss=0.484, contrastive_loss=0.201, total=4082.11, n_correct=2445.47, ppl=3.12, accuracy=59.907, wps=12345.1, ups=1.01, wpb=12206.9, bsz=449.7, num_updates=12500, lr=0.000126491, gnorm=0.49, clip=0, loss_scale=32, train_wall=98, gb_free=17.1, wall=12347
2023-07-01 14:41:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-01 14:42:21 | INFO | train_inner | epoch 009:    816 / 1474 loss=3.561, trans_loss=3.477, nll_loss=1.63, w2v_ctc_loss=1.016, task_loss=0.484, contrastive_loss=0.2, total=4197.6, n_correct=2520.66, ppl=3.1, accuracy=60.05, wps=12345.5, ups=0.98, wpb=12537.8, bsz=489.3, num_updates=12600, lr=0.000125988, gnorm=0.483, clip=0, loss_scale=16, train_wall=101, gb_free=14.6, wall=12448
2023-07-01 14:44:02 | INFO | train_inner | epoch 009:    916 / 1474 loss=3.573, trans_loss=3.487, nll_loss=1.639, w2v_ctc_loss=1.006, task_loss=0.484, contrastive_loss=0.326, total=4146.05, n_correct=2486.01, ppl=3.12, accuracy=59.961, wps=12220.1, ups=0.99, wpb=12355.9, bsz=450.3, num_updates=12700, lr=0.000125491, gnorm=0.476, clip=0, loss_scale=16, train_wall=101, gb_free=17.9, wall=12550
2023-07-01 14:45:42 | INFO | train_inner | epoch 009:   1016 / 1474 loss=3.564, trans_loss=3.498, nll_loss=1.651, w2v_ctc_loss=1.015, task_loss=0.484, contrastive_loss=0.106, total=4101.48, n_correct=2445.81, ppl=3.14, accuracy=59.632, wps=12254.9, ups=1, wpb=12243.2, bsz=424.4, num_updates=12800, lr=0.000125, gnorm=0.483, clip=0, loss_scale=16, train_wall=99, gb_free=16.1, wall=12650
2023-07-01 14:47:22 | INFO | train_inner | epoch 009:   1116 / 1474 loss=3.556, trans_loss=3.487, nll_loss=1.637, w2v_ctc_loss=1.012, task_loss=0.484, contrastive_loss=0.131, total=4179.09, n_correct=2513.24, ppl=3.11, accuracy=60.138, wps=12459.8, ups=1, wpb=12439.9, bsz=474.7, num_updates=12900, lr=0.000124515, gnorm=0.48, clip=0, loss_scale=16, train_wall=99, gb_free=15.5, wall=12749
2023-07-01 14:49:03 | INFO | train_inner | epoch 009:   1216 / 1474 loss=3.565, trans_loss=3.494, nll_loss=1.644, w2v_ctc_loss=1.015, task_loss=0.484, contrastive_loss=0.113, total=4140.66, n_correct=2484.66, ppl=3.13, accuracy=60.006, wps=12278.9, ups=0.99, wpb=12405, bsz=448.1, num_updates=13000, lr=0.000124035, gnorm=0.481, clip=0, loss_scale=16, train_wall=101, gb_free=17.2, wall=12850
2023-07-01 14:50:42 | INFO | train_inner | epoch 009:   1316 / 1474 loss=3.557, trans_loss=3.48, nll_loss=1.631, w2v_ctc_loss=0.988, task_loss=0.484, contrastive_loss=0.303, total=4204.43, n_correct=2539.12, ppl=3.1, accuracy=60.392, wps=12641.2, ups=1.01, wpb=12539.3, bsz=492.5, num_updates=13100, lr=0.00012356, gnorm=0.48, clip=0, loss_scale=16, train_wall=99, gb_free=17.8, wall=12950
2023-07-01 14:52:21 | INFO | train_inner | epoch 009:   1416 / 1474 loss=3.564, trans_loss=3.498, nll_loss=1.651, w2v_ctc_loss=1.02, task_loss=0.484, contrastive_loss=0.09, total=4069.19, n_correct=2436.2, ppl=3.14, accuracy=59.869, wps=12260.5, ups=1.01, wpb=12152.5, bsz=427.7, num_updates=13200, lr=0.000123091, gnorm=0.485, clip=0, loss_scale=16, train_wall=99, gb_free=16.8, wall=13049
2023-07-01 14:53:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 14:53:46 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.409 | trans_loss 5.669 | nll_loss 2.973 | w2v_ctc_loss 1.35 | task_loss 0 | contrastive_loss 0.257 | total 4003.4 | n_correct 2412.1 | ppl 7.85 | accuracy 60.251 | uer 17.854 | wer 19.824 | raw_wer 19.824 | bleu 18.39 | wps 1866.2 | wpb 4003.4 | bsz 141.8 | num_updates 13258 | best_bleu 18.62
2023-07-01 14:53:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13258 updates
2023-07-01 14:53:46 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_18.3907.pt
2023-07-01 14:53:49 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_18.3907.pt
2023-07-01 14:53:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_18.3907.pt (epoch 9 @ 13258 updates, score 18.39) (writing took 5.299956234637648 seconds)
2023-07-01 14:53:52 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-07-01 14:53:52 | INFO | train | epoch 009 | loss 3.556 | trans_loss 3.485 | nll_loss 1.636 | w2v_ctc_loss 1.008 | task_loss 0.484 | contrastive_loss 0.164 | total 4137.17 | n_correct 2485.55 | ppl 3.11 | accuracy 60.079 | wps 11755.6 | ups 0.95 | wpb 12352.1 | bsz 457.7 | num_updates 13258 | lr 0.000122822 | gnorm 0.483 | clip 0 | loss_scale 16 | train_wall 1465 | gb_free 12 | wall 13139
2023-07-01 14:53:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 14:53:52 | INFO | fairseq.trainer | begin training epoch 10
2023-07-01 14:53:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 14:54:42 | INFO | train_inner | epoch 010:     42 / 1474 loss=3.542, trans_loss=3.478, nll_loss=1.627, w2v_ctc_loss=0.99, task_loss=0.484, contrastive_loss=0.187, total=4100.8, n_correct=2482.2, ppl=3.09, accuracy=60.53, wps=8698.4, ups=0.71, wpb=12243.3, bsz=469.4, num_updates=13300, lr=0.000122628, gnorm=0.489, clip=0, loss_scale=16, train_wall=98, gb_free=16.4, wall=13189
2023-07-01 14:56:22 | INFO | train_inner | epoch 010:    142 / 1474 loss=3.496, trans_loss=3.459, nll_loss=1.6, w2v_ctc_loss=0.958, task_loss=0.484, contrastive_loss=0.109, total=4247.35, n_correct=2594.78, ppl=3.03, accuracy=61.092, wps=12679.7, ups=1, wpb=12717.5, bsz=479.6, num_updates=13400, lr=0.000122169, gnorm=0.466, clip=0, loss_scale=16, train_wall=100, gb_free=12.1, wall=13290
2023-07-01 14:58:02 | INFO | train_inner | epoch 010:    242 / 1474 loss=3.51, trans_loss=3.454, nll_loss=1.598, w2v_ctc_loss=0.967, task_loss=0.484, contrastive_loss=0.231, total=4122.82, n_correct=2516.82, ppl=3.03, accuracy=61.046, wps=12294.7, ups=1, wpb=12279.5, bsz=461.4, num_updates=13500, lr=0.000121716, gnorm=0.48, clip=0, loss_scale=16, train_wall=99, gb_free=16.4, wall=13390
2023-07-01 14:59:43 | INFO | train_inner | epoch 010:    342 / 1474 loss=3.505, trans_loss=3.456, nll_loss=1.602, w2v_ctc_loss=0.966, task_loss=0.484, contrastive_loss=0.145, total=4138.27, n_correct=2525.76, ppl=3.04, accuracy=61.034, wps=12285.2, ups=0.99, wpb=12378.7, bsz=453.8, num_updates=13600, lr=0.000121268, gnorm=0.475, clip=0, loss_scale=16, train_wall=100, gb_free=16.6, wall=13490
2023-07-01 15:01:24 | INFO | train_inner | epoch 010:    442 / 1474 loss=3.515, trans_loss=3.46, nll_loss=1.605, w2v_ctc_loss=0.95, task_loss=0.484, contrastive_loss=0.321, total=4196.37, n_correct=2556.37, ppl=3.04, accuracy=60.919, wps=12340.5, ups=0.99, wpb=12523.5, bsz=481.1, num_updates=13700, lr=0.000120824, gnorm=0.477, clip=0, loss_scale=16, train_wall=101, gb_free=16.6, wall=13592
2023-07-01 15:03:04 | INFO | train_inner | epoch 010:    542 / 1474 loss=3.523, trans_loss=3.472, nll_loss=1.616, w2v_ctc_loss=0.986, task_loss=0.484, contrastive_loss=0.1, total=4102.8, n_correct=2491.35, ppl=3.07, accuracy=60.723, wps=12241.3, ups=1, wpb=12224.8, bsz=437.8, num_updates=13800, lr=0.000120386, gnorm=0.484, clip=0, loss_scale=16, train_wall=99, gb_free=17.1, wall=13692
2023-07-01 15:04:44 | INFO | train_inner | epoch 010:    642 / 1474 loss=3.531, trans_loss=3.47, nll_loss=1.616, w2v_ctc_loss=0.977, task_loss=0.484, contrastive_loss=0.214, total=4176.56, n_correct=2536.08, ppl=3.07, accuracy=60.722, wps=12498.1, ups=1, wpb=12467.5, bsz=477.2, num_updates=13900, lr=0.000119952, gnorm=0.48, clip=0, loss_scale=16, train_wall=99, gb_free=16.4, wall=13792
2023-07-01 15:06:23 | INFO | train_inner | epoch 010:    742 / 1474 loss=3.524, trans_loss=3.469, nll_loss=1.616, w2v_ctc_loss=0.994, task_loss=0.484, contrastive_loss=0.097, total=4125.87, n_correct=2502.5, ppl=3.06, accuracy=60.654, wps=12430.8, ups=1.01, wpb=12315.5, bsz=454.4, num_updates=14000, lr=0.000119523, gnorm=0.489, clip=0, loss_scale=16, train_wall=99, gb_free=14.7, wall=13891
2023-07-01 15:06:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 15:06:51 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.406 | trans_loss 5.662 | nll_loss 2.963 | w2v_ctc_loss 1.358 | task_loss 0 | contrastive_loss 0.26 | total 4003.4 | n_correct 2421.7 | ppl 7.8 | accuracy 60.491 | uer 17.75 | wer 19.567 | raw_wer 19.567 | bleu 18.49 | wps 1998.9 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 18.62
2023-07-01 15:06:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-07-01 15:06:51 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_10_14000.pt
2023-07-01 15:06:53 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_10_14000.pt
2023-07-01 15:06:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 18.49) (writing took 5.935321338940412 seconds)
2023-07-01 15:08:37 | INFO | train_inner | epoch 010:    842 / 1474 loss=3.509, trans_loss=3.468, nll_loss=1.614, w2v_ctc_loss=0.968, task_loss=0.484, contrastive_loss=0.099, total=4128.44, n_correct=2512.58, ppl=3.06, accuracy=60.86, wps=9203, ups=0.75, wpb=12345, bsz=456.3, num_updates=14100, lr=0.000119098, gnorm=0.477, clip=0, loss_scale=16, train_wall=100, gb_free=14.9, wall=14025
2023-07-01 15:10:16 | INFO | train_inner | epoch 010:    942 / 1474 loss=3.519, trans_loss=3.465, nll_loss=1.613, w2v_ctc_loss=0.982, task_loss=0.484, contrastive_loss=0.138, total=4160.94, n_correct=2530.14, ppl=3.06, accuracy=60.807, wps=12484.4, ups=1.01, wpb=12380.2, bsz=468.1, num_updates=14200, lr=0.000118678, gnorm=0.485, clip=0, loss_scale=16, train_wall=99, gb_free=15.6, wall=14124
2023-07-01 15:11:57 | INFO | train_inner | epoch 010:   1042 / 1474 loss=3.522, trans_loss=3.471, nll_loss=1.62, w2v_ctc_loss=0.983, task_loss=0.484, contrastive_loss=0.112, total=4067.53, n_correct=2463.01, ppl=3.07, accuracy=60.553, wps=12048.8, ups=0.99, wpb=12142, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.49, clip=0, loss_scale=16, train_wall=100, gb_free=17, wall=14225
2023-07-01 15:13:37 | INFO | train_inner | epoch 010:   1142 / 1474 loss=3.524, trans_loss=3.474, nll_loss=1.623, w2v_ctc_loss=0.988, task_loss=0.484, contrastive_loss=0.093, total=4044.03, n_correct=2446.24, ppl=3.08, accuracy=60.49, wps=12083.2, ups=1, wpb=12072.9, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.485, clip=0, loss_scale=16, train_wall=99, gb_free=17.4, wall=14325
2023-07-01 15:15:17 | INFO | train_inner | epoch 010:   1242 / 1474 loss=3.514, trans_loss=3.467, nll_loss=1.617, w2v_ctc_loss=0.982, task_loss=0.484, contrastive_loss=0.088, total=4110.41, n_correct=2497.65, ppl=3.07, accuracy=60.764, wps=12283.5, ups=1, wpb=12302.3, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.483, clip=0, loss_scale=16, train_wall=100, gb_free=16.6, wall=14425
2023-07-01 15:16:57 | INFO | train_inner | epoch 010:   1342 / 1474 loss=3.513, trans_loss=3.467, nll_loss=1.614, w2v_ctc_loss=0.977, task_loss=0.484, contrastive_loss=0.101, total=4121.38, n_correct=2507.57, ppl=3.06, accuracy=60.843, wps=12315.4, ups=1, wpb=12315.5, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.484, clip=0, loss_scale=32, train_wall=100, gb_free=14.3, wall=14525
2023-07-01 15:17:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-01 15:18:39 | INFO | train_inner | epoch 010:   1443 / 1474 loss=3.535, trans_loss=3.471, nll_loss=1.622, w2v_ctc_loss=0.961, task_loss=0.484, contrastive_loss=0.301, total=4186.84, n_correct=2542.74, ppl=3.08, accuracy=60.732, wps=12292, ups=0.99, wpb=12460.4, bsz=477.7, num_updates=14700, lr=0.000116642, gnorm=0.487, clip=0, loss_scale=16, train_wall=101, gb_free=16.7, wall=14626
2023-07-01 15:19:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 15:19:36 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.382 | trans_loss 5.644 | nll_loss 2.935 | w2v_ctc_loss 1.322 | task_loss 0 | contrastive_loss 0.255 | total 4003.4 | n_correct 2425.1 | ppl 7.64 | accuracy 60.576 | uer 17.323 | wer 19.242 | raw_wer 19.242 | bleu 19.03 | wps 1878.4 | wpb 4003.4 | bsz 141.8 | num_updates 14731 | best_bleu 19.03
2023-07-01 15:19:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14731 updates
2023-07-01 15:19:36 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt
2023-07-01 15:19:41 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt
2023-07-01 15:19:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt (epoch 10 @ 14731 updates, score 19.03) (writing took 8.415147845633328 seconds)
2023-07-01 15:19:45 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-07-01 15:19:45 | INFO | train | epoch 010 | loss 3.518 | trans_loss 3.466 | nll_loss 1.613 | w2v_ctc_loss 0.973 | task_loss 0.484 | contrastive_loss 0.164 | total 4137.97 | n_correct 2516.05 | ppl 3.06 | accuracy 60.804 | wps 11715.8 | ups 0.95 | wpb 12353.7 | bsz 458.1 | num_updates 14731 | lr 0.00011652 | gnorm 0.481 | clip 0 | loss_scale 16 | train_wall 1469 | gb_free 17.4 | wall 14693
2023-07-01 15:19:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 15:19:45 | INFO | fairseq.trainer | begin training epoch 11
2023-07-01 15:19:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 15:21:01 | INFO | train_inner | epoch 011:     69 / 1474 loss=3.483, trans_loss=3.447, nll_loss=1.588, w2v_ctc_loss=0.944, task_loss=0.484, contrastive_loss=0.175, total=4166, n_correct=2565.8, ppl=3.01, accuracy=61.589, wps=8702.8, ups=0.7, wpb=12433.1, bsz=475.7, num_updates=14800, lr=0.000116248, gnorm=0.47, clip=0, loss_scale=16, train_wall=99, gb_free=17.9, wall=14769
2023-07-01 15:22:42 | INFO | train_inner | epoch 011:    169 / 1474 loss=3.472, trans_loss=3.447, nll_loss=1.588, w2v_ctc_loss=0.942, task_loss=0.484, contrastive_loss=0.102, total=4100.74, n_correct=2522.56, ppl=3.01, accuracy=61.515, wps=12245.2, ups=1, wpb=12262.6, bsz=450.6, num_updates=14900, lr=0.000115857, gnorm=0.48, clip=0, loss_scale=16, train_wall=100, gb_free=14.6, wall=14869
2023-07-01 15:24:21 | INFO | train_inner | epoch 011:    269 / 1474 loss=3.463, trans_loss=3.444, nll_loss=1.586, w2v_ctc_loss=0.938, task_loss=0.484, contrastive_loss=0.085, total=4115.58, n_correct=2534.05, ppl=3, accuracy=61.572, wps=12311.2, ups=1, wpb=12275.7, bsz=444.2, num_updates=15000, lr=0.00011547, gnorm=0.479, clip=0, loss_scale=16, train_wall=99, gb_free=16.2, wall=14969
tensor(0.2554, device='cuda:0')
tensor(0.1117, device='cuda:0')
2023-07-01 15:26:01 | INFO | train_inner | epoch 011:    369 / 1474 loss=3.463, trans_loss=3.443, nll_loss=1.583, w2v_ctc_loss=0.932, task_loss=0.484, contrastive_loss=0.094, total=4094.16, n_correct=2523.63, ppl=3, accuracy=61.64, wps=12242.4, ups=1, wpb=12192.1, bsz=443.4, num_updates=15100, lr=0.000115087, gnorm=0.351, clip=0, loss_scale=16, train_wall=99, gb_free=13.1, wall=15069
2023-07-01 15:27:42 | INFO | train_inner | epoch 011:    469 / 1474 loss=3.502, trans_loss=3.456, nll_loss=1.596, w2v_ctc_loss=0.94, task_loss=0.484, contrastive_loss=0.257, total=4112.8, n_correct=2518.93, ppl=3.02, accuracy=61.246, wps=12200.2, ups=0.99, wpb=12272.4, bsz=453.2, num_updates=15200, lr=0.000114708, gnorm=0.352, clip=0, loss_scale=16, train_wall=100, gb_free=17.3, wall=15169
2023-07-01 15:29:22 | INFO | train_inner | epoch 011:    569 / 1474 loss=3.514, trans_loss=3.456, nll_loss=1.602, w2v_ctc_loss=0.961, task_loss=0.484, contrastive_loss=0.249, total=4071.06, n_correct=2491.88, ppl=3.04, accuracy=61.21, wps=12143.8, ups=1, wpb=12174, bsz=438.9, num_updates=15300, lr=0.000114332, gnorm=0.356, clip=0, loss_scale=16, train_wall=100, gb_free=16.7, wall=15269
2023-07-01 15:31:02 | INFO | train_inner | epoch 011:    669 / 1474 loss=3.512, trans_loss=3.452, nll_loss=1.593, w2v_ctc_loss=0.947, task_loss=0.484, contrastive_loss=0.329, total=4156.4, n_correct=2549.69, ppl=3.02, accuracy=61.344, wps=12348.6, ups=1, wpb=12399.3, bsz=465.3, num_updates=15400, lr=0.000113961, gnorm=0.356, clip=0, loss_scale=16, train_wall=100, gb_free=16.7, wall=15370
2023-07-01 15:32:42 | INFO | train_inner | epoch 011:    769 / 1474 loss=3.493, trans_loss=3.456, nll_loss=1.598, w2v_ctc_loss=0.96, task_loss=0.484, contrastive_loss=0.096, total=4169.17, n_correct=2557.7, ppl=3.03, accuracy=61.348, wps=12434.1, ups=1, wpb=12460.4, bsz=457.2, num_updates=15500, lr=0.000113592, gnorm=0.351, clip=0, loss_scale=16, train_wall=100, gb_free=12.5, wall=15470
2023-07-01 15:34:22 | INFO | train_inner | epoch 011:    869 / 1474 loss=3.488, trans_loss=3.454, nll_loss=1.6, w2v_ctc_loss=0.959, task_loss=0.484, contrastive_loss=0.082, total=4120.01, n_correct=2521.12, ppl=3.03, accuracy=61.192, wps=12293.9, ups=1, wpb=12288.7, bsz=440.2, num_updates=15600, lr=0.000113228, gnorm=0.352, clip=0, loss_scale=16, train_wall=100, gb_free=13.7, wall=15570
2023-07-01 15:36:03 | INFO | train_inner | epoch 011:    969 / 1474 loss=3.487, trans_loss=3.451, nll_loss=1.594, w2v_ctc_loss=0.956, task_loss=0.484, contrastive_loss=0.099, total=4145.45, n_correct=2544.21, ppl=3.02, accuracy=61.374, wps=12305.9, ups=0.99, wpb=12369.7, bsz=455.5, num_updates=15700, lr=0.000112867, gnorm=0.353, clip=0, loss_scale=16, train_wall=100, gb_free=17.2, wall=15670
2023-07-01 15:37:43 | INFO | train_inner | epoch 011:   1069 / 1474 loss=3.495, trans_loss=3.453, nll_loss=1.597, w2v_ctc_loss=0.96, task_loss=0.484, contrastive_loss=0.122, total=4141.18, n_correct=2538.52, ppl=3.03, accuracy=61.299, wps=12352.4, ups=1, wpb=12378.8, bsz=464.1, num_updates=15800, lr=0.000112509, gnorm=0.35, clip=0, loss_scale=16, train_wall=100, gb_free=16.7, wall=15771
2023-07-01 15:39:23 | INFO | train_inner | epoch 011:   1169 / 1474 loss=3.492, trans_loss=3.454, nll_loss=1.603, w2v_ctc_loss=0.963, task_loss=0.484, contrastive_loss=0.104, total=4173.93, n_correct=2550.4, ppl=3.04, accuracy=61.103, wps=12450.4, ups=1, wpb=12444.5, bsz=460.9, num_updates=15900, lr=0.000112154, gnorm=0.351, clip=0, loss_scale=16, train_wall=100, gb_free=17, wall=15871
2023-07-01 15:41:03 | INFO | train_inner | epoch 011:   1269 / 1474 loss=3.518, trans_loss=3.455, nll_loss=1.6, w2v_ctc_loss=0.972, task_loss=0.484, contrastive_loss=0.197, total=4174.26, n_correct=2555.28, ppl=3.03, accuracy=61.215, wps=12466, ups=1, wpb=12472, bsz=471.6, num_updates=16000, lr=0.000111803, gnorm=0.35, clip=0, loss_scale=16, train_wall=100, gb_free=17.5, wall=15971
2023-07-01 15:41:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.2554, device='cuda:1')
tensor(0.1117, device='cuda:1')
tensor(0.2554, device='cuda:2')
tensor(0.1117, device='cuda:2')
tensor(0.2554, device='cuda:5')
tensor(0.1117, device='cuda:5')
tensor(0.2554, device='cuda:4')
tensor(0.1117, device='cuda:4')
tensor(0.2554, device='cuda:7')
tensor(0.1117, device='cuda:7')
tensor(0.2554, device='cuda:3')
tensor(0.1117, device='cuda:3')
tensor(0.2554, device='cuda:6')
tensor(0.1117, device='cuda:6')
2023-07-01 15:41:30 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.396 | trans_loss 5.632 | nll_loss 2.919 | w2v_ctc_loss 1.393 | task_loss 0 | contrastive_loss 0.262 | total 4003.4 | n_correct 2442.3 | ppl 7.56 | accuracy 61.006 | uer 17.509 | wer 19.209 | raw_wer 19.209 | bleu 19.34 | wps 2040.9 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.34
2023-07-01 15:41:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-07-01 15:41:30 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_11_16000.pt
2023-07-01 15:41:33 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_11_16000.pt
2023-07-01 15:41:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 19.34) (writing took 8.901297327131033 seconds)
2023-07-01 15:43:21 | INFO | train_inner | epoch 011:   1369 / 1474 loss=3.522, trans_loss=3.453, nll_loss=1.597, w2v_ctc_loss=0.944, task_loss=0.484, contrastive_loss=0.415, total=4191.56, n_correct=2572.25, ppl=3.03, accuracy=61.367, wps=9071.5, ups=0.72, wpb=12516.8, bsz=491.5, num_updates=16100, lr=0.000111456, gnorm=0.349, clip=0, loss_scale=16, train_wall=101, gb_free=17.6, wall=16109
2023-07-01 15:45:01 | INFO | train_inner | epoch 011:   1469 / 1474 loss=3.487, trans_loss=3.454, nll_loss=1.599, w2v_ctc_loss=0.952, task_loss=0.484, contrastive_loss=0.109, total=4161.81, n_correct=2550.55, ppl=3.03, accuracy=61.285, wps=12459.4, ups=1, wpb=12429.3, bsz=469.8, num_updates=16200, lr=0.000111111, gnorm=0.35, clip=0, loss_scale=16, train_wall=99, gb_free=17, wall=16208
2023-07-01 15:45:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 15:45:33 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.376 | trans_loss 5.629 | nll_loss 2.915 | w2v_ctc_loss 1.341 | task_loss 0 | contrastive_loss 0.25 | total 4003.4 | n_correct 2436.7 | ppl 7.54 | accuracy 60.866 | uer 17.402 | wer 19.108 | raw_wer 19.108 | bleu 19.17 | wps 2034.2 | wpb 4003.4 | bsz 141.8 | num_updates 16205 | best_bleu 19.34
2023-07-01 15:45:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16205 updates
2023-07-01 15:45:33 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.1709.pt
2023-07-01 15:45:35 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.1709.pt
2023-07-01 15:45:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.1709.pt (epoch 11 @ 16205 updates, score 19.17) (writing took 5.049977126996964 seconds)
2023-07-01 15:45:38 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-07-01 15:45:38 | INFO | train | epoch 011 | loss 3.492 | trans_loss 3.451 | nll_loss 1.595 | w2v_ctc_loss 0.951 | task_loss 0.484 | contrastive_loss 0.165 | total 4138.65 | n_correct 2539.63 | ppl 3.02 | accuracy 61.364 | wps 11729 | ups 0.95 | wpb 12355.8 | bsz 458.5 | num_updates 16205 | lr 0.000111094 | gnorm 0.375 | clip 0 | loss_scale 16 | train_wall 1470 | gb_free 17.3 | wall 16245
2023-07-01 15:45:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 15:45:38 | INFO | fairseq.trainer | begin training epoch 12
2023-07-01 15:45:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 15:47:20 | INFO | train_inner | epoch 012:     95 / 1474 loss=3.457, trans_loss=3.428, nll_loss=1.563, w2v_ctc_loss=0.928, task_loss=0.484, contrastive_loss=0.15, total=4139.2, n_correct=2577.67, ppl=2.96, accuracy=62.275, wps=8884.7, ups=0.72, wpb=12361.4, bsz=468.8, num_updates=16300, lr=0.00011077, gnorm=0.348, clip=0, loss_scale=16, train_wall=98, gb_free=16.1, wall=16348
2023-07-01 15:49:00 | INFO | train_inner | epoch 012:    195 / 1474 loss=3.458, trans_loss=3.431, nll_loss=1.569, w2v_ctc_loss=0.935, task_loss=0.484, contrastive_loss=0.086, total=4126.87, n_correct=2565, ppl=2.97, accuracy=62.154, wps=12345.6, ups=1, wpb=12361.2, bsz=443.9, num_updates=16400, lr=0.000110432, gnorm=0.348, clip=0, loss_scale=16, train_wall=100, gb_free=16.6, wall=16448
2023-07-01 15:50:40 | INFO | train_inner | epoch 012:    295 / 1474 loss=3.448, trans_loss=3.429, nll_loss=1.567, w2v_ctc_loss=0.916, task_loss=0.484, contrastive_loss=0.127, total=4203.54, n_correct=2617.31, ppl=2.96, accuracy=62.264, wps=12545.6, ups=1, wpb=12550.7, bsz=481.6, num_updates=16500, lr=0.000110096, gnorm=0.343, clip=0, loss_scale=16, train_wall=100, gb_free=14.8, wall=16548
2023-07-01 15:52:21 | INFO | train_inner | epoch 012:    395 / 1474 loss=3.454, trans_loss=3.433, nll_loss=1.572, w2v_ctc_loss=0.928, task_loss=0.484, contrastive_loss=0.104, total=4149.28, n_correct=2580.91, ppl=2.97, accuracy=62.201, wps=12364.6, ups=1, wpb=12403.5, bsz=460.7, num_updates=16600, lr=0.000109764, gnorm=0.35, clip=0, loss_scale=16, train_wall=100, gb_free=15.4, wall=16648
2023-07-01 15:54:00 | INFO | train_inner | epoch 012:    495 / 1474 loss=3.481, trans_loss=3.447, nll_loss=1.586, w2v_ctc_loss=0.949, task_loss=0.484, contrastive_loss=0.115, total=4106.46, n_correct=2540.84, ppl=3, accuracy=61.874, wps=12268.3, ups=1, wpb=12220.6, bsz=451.8, num_updates=16700, lr=0.000109435, gnorm=0.354, clip=0, loss_scale=32, train_wall=99, gb_free=17.9, wall=16748
2023-07-01 15:55:41 | INFO | train_inner | epoch 012:    595 / 1474 loss=3.476, trans_loss=3.434, nll_loss=1.576, w2v_ctc_loss=0.937, task_loss=0.484, contrastive_loss=0.201, total=4190.91, n_correct=2599.21, ppl=2.98, accuracy=62.02, wps=12461.4, ups=0.99, wpb=12532.1, bsz=474.7, num_updates=16800, lr=0.000109109, gnorm=0.348, clip=0, loss_scale=32, train_wall=100, gb_free=16, wall=16848
2023-07-01 15:57:20 | INFO | train_inner | epoch 012:    695 / 1474 loss=3.472, trans_loss=3.432, nll_loss=1.572, w2v_ctc_loss=0.922, task_loss=0.484, contrastive_loss=0.318, total=4203.66, n_correct=2611.42, ppl=2.97, accuracy=62.123, wps=12574.4, ups=1.01, wpb=12493.6, bsz=486.5, num_updates=16900, lr=0.000108786, gnorm=0.346, clip=0, loss_scale=32, train_wall=99, gb_free=17.5, wall=16948
2023-07-01 15:59:00 | INFO | train_inner | epoch 012:    795 / 1474 loss=3.471, trans_loss=3.438, nll_loss=1.576, w2v_ctc_loss=0.943, task_loss=0.484, contrastive_loss=0.101, total=4095.72, n_correct=2543.45, ppl=2.98, accuracy=62.1, wps=12298.8, ups=1, wpb=12238.8, bsz=448.3, num_updates=17000, lr=0.000108465, gnorm=0.355, clip=0, loss_scale=32, train_wall=99, gb_free=17.3, wall=17047
2023-07-01 16:00:40 | INFO | train_inner | epoch 012:    895 / 1474 loss=3.471, trans_loss=3.436, nll_loss=1.577, w2v_ctc_loss=0.932, task_loss=0.484, contrastive_loss=0.168, total=4162.82, n_correct=2582.93, ppl=2.98, accuracy=62.048, wps=12411.1, ups=1, wpb=12435.1, bsz=458.1, num_updates=17100, lr=0.000108148, gnorm=0.347, clip=0, loss_scale=32, train_wall=100, gb_free=16.3, wall=17147
2023-07-01 16:02:19 | INFO | train_inner | epoch 012:    995 / 1474 loss=3.482, trans_loss=3.443, nll_loss=1.585, w2v_ctc_loss=0.943, task_loss=0.484, contrastive_loss=0.183, total=4117.63, n_correct=2543.89, ppl=3, accuracy=61.78, wps=12358.1, ups=1.01, wpb=12286.8, bsz=452.4, num_updates=17200, lr=0.000107833, gnorm=0.349, clip=0, loss_scale=32, train_wall=99, gb_free=17.1, wall=17247
2023-07-01 16:03:59 | INFO | train_inner | epoch 012:   1095 / 1474 loss=3.502, trans_loss=3.446, nll_loss=1.587, w2v_ctc_loss=0.953, task_loss=0.484, contrastive_loss=0.241, total=4046.48, n_correct=2502.83, ppl=3, accuracy=61.852, wps=12087.7, ups=1, wpb=12084, bsz=434.4, num_updates=17300, lr=0.000107521, gnorm=0.355, clip=0, loss_scale=32, train_wall=100, gb_free=16.1, wall=17347
2023-07-01 16:05:39 | INFO | train_inner | epoch 012:   1195 / 1474 loss=3.504, trans_loss=3.446, nll_loss=1.591, w2v_ctc_loss=0.965, task_loss=0.484, contrastive_loss=0.199, total=4201.13, n_correct=2583.91, ppl=3.01, accuracy=61.505, wps=12511.4, ups=1, wpb=12545, bsz=478.7, num_updates=17400, lr=0.000107211, gnorm=0.351, clip=0, loss_scale=32, train_wall=100, gb_free=17.4, wall=17447
2023-07-01 16:07:20 | INFO | train_inner | epoch 012:   1295 / 1474 loss=3.481, trans_loss=3.446, nll_loss=1.591, w2v_ctc_loss=0.954, task_loss=0.484, contrastive_loss=0.083, total=4070.27, n_correct=2516.35, ppl=3.01, accuracy=61.823, wps=12152.9, ups=1, wpb=12168, bsz=429.2, num_updates=17500, lr=0.000106904, gnorm=0.355, clip=0, loss_scale=32, train_wall=100, gb_free=16.1, wall=17547
2023-07-01 16:08:59 | INFO | train_inner | epoch 012:   1395 / 1474 loss=3.478, trans_loss=3.441, nll_loss=1.584, w2v_ctc_loss=0.931, task_loss=0.484, contrastive_loss=0.22, total=4139.63, n_correct=2563.09, ppl=3, accuracy=61.916, wps=12346.2, ups=1, wpb=12331.2, bsz=458.7, num_updates=17600, lr=0.0001066, gnorm=0.35, clip=0, loss_scale=32, train_wall=99, gb_free=17.2, wall=17647
2023-07-01 16:10:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 16:10:44 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.377 | trans_loss 5.621 | nll_loss 2.905 | w2v_ctc_loss 1.359 | task_loss 0 | contrastive_loss 0.254 | total 4003.4 | n_correct 2444.2 | ppl 7.49 | accuracy 61.053 | uer 17.421 | wer 19.201 | raw_wer 19.201 | bleu 19.05 | wps 2097.5 | wpb 4003.4 | bsz 141.8 | num_updates 17679 | best_bleu 19.34
2023-07-01 16:10:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17679 updates
2023-07-01 16:10:44 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.0508.pt
2023-07-01 16:10:47 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.0508.pt
2023-07-01 16:10:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.0508.pt (epoch 12 @ 17679 updates, score 19.05) (writing took 5.144704520236701 seconds)
2023-07-01 16:10:50 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-07-01 16:10:50 | INFO | train | epoch 012 | loss 3.474 | trans_loss 3.438 | nll_loss 1.579 | w2v_ctc_loss 0.939 | task_loss 0.484 | contrastive_loss 0.161 | total 4138.65 | n_correct 2565.34 | ppl 2.99 | accuracy 61.985 | wps 12047.9 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 17679 | lr 0.000106362 | gnorm 0.35 | clip 0 | loss_scale 32 | train_wall 1466 | gb_free 13.2 | wall 17757
2023-07-01 16:10:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 16:10:50 | INFO | fairseq.trainer | begin training epoch 13
2023-07-01 16:10:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 16:11:18 | INFO | train_inner | epoch 013:     21 / 1474 loss=3.479, trans_loss=3.441, nll_loss=1.583, w2v_ctc_loss=0.954, task_loss=0.484, contrastive_loss=0.094, total=4096.49, n_correct=2530.76, ppl=3, accuracy=61.779, wps=8810.2, ups=0.72, wpb=12243.5, bsz=443.1, num_updates=17700, lr=0.000106299, gnorm=0.354, clip=0, loss_scale=32, train_wall=99, gb_free=14.8, wall=17786
2023-07-01 16:12:59 | INFO | train_inner | epoch 013:    121 / 1474 loss=3.431, trans_loss=3.416, nll_loss=1.55, w2v_ctc_loss=0.911, task_loss=0.484, contrastive_loss=0.109, total=4160.97, n_correct=2612.18, ppl=2.93, accuracy=62.778, wps=12377.5, ups=1, wpb=12418.2, bsz=454.3, num_updates=17800, lr=0.000106, gnorm=0.346, clip=0, loss_scale=32, train_wall=100, gb_free=16.5, wall=17886
2023-07-01 16:14:40 | INFO | train_inner | epoch 013:    221 / 1474 loss=3.475, trans_loss=3.419, nll_loss=1.558, w2v_ctc_loss=0.916, task_loss=0.484, contrastive_loss=0.396, total=4212.08, n_correct=2638.02, ppl=2.94, accuracy=62.63, wps=12432.7, ups=0.99, wpb=12529.8, bsz=494.6, num_updates=17900, lr=0.000105703, gnorm=0.347, clip=0, loss_scale=32, train_wall=100, gb_free=14.9, wall=17987
2023-07-01 16:16:19 | INFO | train_inner | epoch 013:    321 / 1474 loss=3.436, trans_loss=3.422, nll_loss=1.555, w2v_ctc_loss=0.912, task_loss=0.484, contrastive_loss=0.091, total=4102.3, n_correct=2578.81, ppl=2.94, accuracy=62.863, wps=12266.3, ups=1, wpb=12230, bsz=441.1, num_updates=18000, lr=0.000105409, gnorm=0.351, clip=0, loss_scale=32, train_wall=99, gb_free=17.4, wall=18087
2023-07-01 16:16:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 16:16:47 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.366 | trans_loss 5.618 | nll_loss 2.9 | w2v_ctc_loss 1.329 | task_loss 0 | contrastive_loss 0.255 | total 4003.4 | n_correct 2444.1 | ppl 7.46 | accuracy 61.051 | uer 17.278 | wer 19.239 | raw_wer 19.239 | bleu 19.61 | wps 2194.1 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.61
2023-07-01 16:16:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-07-01 16:16:47 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_13_18000.pt
2023-07-01 16:16:49 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_13_18000.pt
2023-07-01 16:16:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.61) (writing took 8.960701911710203 seconds)
2023-07-01 16:18:36 | INFO | train_inner | epoch 013:    421 / 1474 loss=3.455, trans_loss=3.426, nll_loss=1.563, w2v_ctc_loss=0.921, task_loss=0.484, contrastive_loss=0.154, total=4177.29, n_correct=2621.03, ppl=2.95, accuracy=62.745, wps=9140.4, ups=0.73, wpb=12461.8, bsz=477.6, num_updates=18100, lr=0.000105118, gnorm=0.345, clip=0, loss_scale=32, train_wall=99, gb_free=17.6, wall=18223
2023-07-01 16:20:17 | INFO | train_inner | epoch 013:    521 / 1474 loss=3.46, trans_loss=3.428, nll_loss=1.565, w2v_ctc_loss=0.925, task_loss=0.484, contrastive_loss=0.202, total=4201.22, n_correct=2621.68, ppl=2.96, accuracy=62.403, wps=12416.8, ups=0.99, wpb=12536.9, bsz=478.4, num_updates=18200, lr=0.000104828, gnorm=0.349, clip=0, loss_scale=32, train_wall=101, gb_free=13.2, wall=18324
2023-07-01 16:21:56 | INFO | train_inner | epoch 013:    621 / 1474 loss=3.434, trans_loss=3.421, nll_loss=1.557, w2v_ctc_loss=0.913, task_loss=0.484, contrastive_loss=0.085, total=4161.98, n_correct=2611.17, ppl=2.94, accuracy=62.739, wps=12456, ups=1, wpb=12435.5, bsz=462.4, num_updates=18300, lr=0.000104542, gnorm=0.347, clip=0, loss_scale=32, train_wall=99, gb_free=16, wall=18424
2023-07-01 16:23:36 | INFO | train_inner | epoch 013:    721 / 1474 loss=3.46, trans_loss=3.428, nll_loss=1.565, w2v_ctc_loss=0.945, task_loss=0.484, contrastive_loss=0.084, total=4096.76, n_correct=2555.96, ppl=2.96, accuracy=62.39, wps=12229.3, ups=1, wpb=12226.1, bsz=426.8, num_updates=18400, lr=0.000104257, gnorm=0.353, clip=0, loss_scale=32, train_wall=100, gb_free=16.8, wall=18524
2023-07-01 16:25:17 | INFO | train_inner | epoch 013:    821 / 1474 loss=3.452, trans_loss=3.427, nll_loss=1.565, w2v_ctc_loss=0.922, task_loss=0.484, contrastive_loss=0.145, total=4121.73, n_correct=2568.55, ppl=2.96, accuracy=62.317, wps=12211.1, ups=0.99, wpb=12319.8, bsz=460, num_updates=18500, lr=0.000103975, gnorm=0.356, clip=0, loss_scale=32, train_wall=100, gb_free=15, wall=18625
2023-07-01 16:26:57 | INFO | train_inner | epoch 013:    921 / 1474 loss=3.446, trans_loss=3.428, nll_loss=1.567, w2v_ctc_loss=0.921, task_loss=0.484, contrastive_loss=0.096, total=4107.01, n_correct=2568.25, ppl=2.96, accuracy=62.533, wps=12331.4, ups=1.01, wpb=12264.1, bsz=444.7, num_updates=18600, lr=0.000103695, gnorm=0.352, clip=0, loss_scale=32, train_wall=99, gb_free=16.1, wall=18724
2023-07-01 16:28:36 | INFO | train_inner | epoch 013:   1021 / 1474 loss=3.463, trans_loss=3.425, nll_loss=1.567, w2v_ctc_loss=0.934, task_loss=0.484, contrastive_loss=0.164, total=4081.02, n_correct=2539.83, ppl=2.96, accuracy=62.235, wps=12259.3, ups=1, wpb=12208.8, bsz=440.1, num_updates=18700, lr=0.000103418, gnorm=0.352, clip=0, loss_scale=32, train_wall=99, gb_free=16.4, wall=18824
2023-07-01 16:30:15 | INFO | train_inner | epoch 013:   1121 / 1474 loss=3.448, trans_loss=3.425, nll_loss=1.561, w2v_ctc_loss=0.917, task_loss=0.484, contrastive_loss=0.14, total=4105.62, n_correct=2573.59, ppl=2.95, accuracy=62.685, wps=12382.6, ups=1.01, wpb=12265.4, bsz=458.9, num_updates=18800, lr=0.000103142, gnorm=0.349, clip=0, loss_scale=64, train_wall=99, gb_free=16.9, wall=18923
2023-07-01 16:31:55 | INFO | train_inner | epoch 013:   1221 / 1474 loss=3.465, trans_loss=3.435, nll_loss=1.574, w2v_ctc_loss=0.938, task_loss=0.484, contrastive_loss=0.087, total=4110.35, n_correct=2561.21, ppl=2.98, accuracy=62.311, wps=12299.8, ups=1, wpb=12287.7, bsz=442.6, num_updates=18900, lr=0.000102869, gnorm=0.357, clip=0, loss_scale=64, train_wall=99, gb_free=15.1, wall=19023
2023-07-01 16:33:35 | INFO | train_inner | epoch 013:   1321 / 1474 loss=3.457, trans_loss=3.424, nll_loss=1.565, w2v_ctc_loss=0.921, task_loss=0.484, contrastive_loss=0.217, total=4112.2, n_correct=2573.76, ppl=2.96, accuracy=62.588, wps=12343, ups=1.01, wpb=12280.4, bsz=462.3, num_updates=19000, lr=0.000102598, gnorm=0.351, clip=0, loss_scale=64, train_wall=99, gb_free=17.7, wall=19122
2023-07-01 16:35:15 | INFO | train_inner | epoch 013:   1421 / 1474 loss=3.471, trans_loss=3.434, nll_loss=1.573, w2v_ctc_loss=0.921, task_loss=0.484, contrastive_loss=0.23, total=4180.88, n_correct=2604.63, ppl=2.97, accuracy=62.299, wps=12449.2, ups=1, wpb=12470.5, bsz=468.3, num_updates=19100, lr=0.000102329, gnorm=0.347, clip=0, loss_scale=64, train_wall=100, gb_free=15.5, wall=19223
2023-07-01 16:36:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 16:36:36 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.361 | trans_loss 5.605 | nll_loss 2.891 | w2v_ctc_loss 1.347 | task_loss 0 | contrastive_loss 0.251 | total 4003.4 | n_correct 2446.6 | ppl 7.42 | accuracy 61.113 | uer 17.238 | wer 19.224 | raw_wer 19.224 | bleu 19.36 | wps 1942.5 | wpb 4003.4 | bsz 141.8 | num_updates 19153 | best_bleu 19.61
2023-07-01 16:36:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19153 updates
2023-07-01 16:36:36 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.3600.pt
2023-07-01 16:36:38 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.3600.pt
2023-07-01 16:36:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.3600.pt (epoch 13 @ 19153 updates, score 19.36) (writing took 5.35783164203167 seconds)
2023-07-01 16:36:41 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-07-01 16:36:41 | INFO | train | epoch 013 | loss 3.454 | trans_loss 3.425 | nll_loss 1.563 | w2v_ctc_loss 0.923 | task_loss 0.484 | contrastive_loss 0.157 | total 4138.65 | n_correct 2588.26 | ppl 2.95 | accuracy 62.539 | wps 11735.6 | ups 0.95 | wpb 12355.8 | bsz 458.5 | num_updates 19153 | lr 0.000102187 | gnorm 0.35 | clip 0 | loss_scale 64 | train_wall 1467 | gb_free 17.7 | wall 19309
2023-07-01 16:36:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 16:36:42 | INFO | fairseq.trainer | begin training epoch 14
2023-07-01 16:36:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 16:37:36 | INFO | train_inner | epoch 014:     47 / 1474 loss=3.418, trans_loss=3.406, nll_loss=1.54, w2v_ctc_loss=0.904, task_loss=0.484, contrastive_loss=0.104, total=4176.2, n_correct=2637.98, ppl=2.91, accuracy=63.167, wps=8835, ups=0.71, wpb=12486.4, bsz=483.4, num_updates=19200, lr=0.000102062, gnorm=0.341, clip=0, loss_scale=64, train_wall=99, gb_free=11.2, wall=19364
2023-07-01 16:39:16 | INFO | train_inner | epoch 014:    147 / 1474 loss=3.415, trans_loss=3.405, nll_loss=1.534, w2v_ctc_loss=0.901, task_loss=0.484, contrastive_loss=0.08, total=4080.86, n_correct=2589.81, ppl=2.9, accuracy=63.462, wps=12254.4, ups=1, wpb=12203.2, bsz=449.3, num_updates=19300, lr=0.000101797, gnorm=0.345, clip=0, loss_scale=64, train_wall=99, gb_free=17, wall=19463
2023-07-01 16:40:55 | INFO | train_inner | epoch 014:    247 / 1474 loss=3.437, trans_loss=3.417, nll_loss=1.55, w2v_ctc_loss=0.899, task_loss=0.484, contrastive_loss=0.214, total=4106.97, n_correct=2593.11, ppl=2.93, accuracy=63.139, wps=12294.8, ups=1.01, wpb=12224.4, bsz=440, num_updates=19400, lr=0.000101535, gnorm=0.35, clip=0, loss_scale=64, train_wall=99, gb_free=12.7, wall=19563
2023-07-01 16:42:35 | INFO | train_inner | epoch 014:    347 / 1474 loss=3.406, trans_loss=3.399, nll_loss=1.537, w2v_ctc_loss=0.897, task_loss=0.484, contrastive_loss=0.127, total=4179.8, n_correct=2640.43, ppl=2.9, accuracy=63.171, wps=12515.5, ups=1, wpb=12454.9, bsz=483.8, num_updates=19500, lr=0.000101274, gnorm=0.349, clip=0, loss_scale=64, train_wall=99, gb_free=17.4, wall=19662
2023-07-01 16:44:14 | INFO | train_inner | epoch 014:    447 / 1474 loss=3.42, trans_loss=3.414, nll_loss=1.549, w2v_ctc_loss=0.902, task_loss=0.484, contrastive_loss=0.076, total=4120.38, n_correct=2595.91, ppl=2.93, accuracy=63.002, wps=12329.7, ups=1, wpb=12283.1, bsz=444.5, num_updates=19600, lr=0.000101015, gnorm=0.348, clip=0, loss_scale=64, train_wall=99, gb_free=17.3, wall=19762
2023-07-01 16:45:55 | INFO | train_inner | epoch 014:    547 / 1474 loss=3.448, trans_loss=3.421, nll_loss=1.556, w2v_ctc_loss=0.921, task_loss=0.484, contrastive_loss=0.119, total=4089.86, n_correct=2567.81, ppl=2.94, accuracy=62.785, wps=12183, ups=0.99, wpb=12262.9, bsz=443.3, num_updates=19700, lr=0.000100759, gnorm=0.353, clip=0, loss_scale=64, train_wall=100, gb_free=12.4, wall=19863
2023-07-01 16:47:35 | INFO | train_inner | epoch 014:    647 / 1474 loss=3.437, trans_loss=3.416, nll_loss=1.552, w2v_ctc_loss=0.904, task_loss=0.484, contrastive_loss=0.181, total=4158.94, n_correct=2617.79, ppl=2.93, accuracy=62.944, wps=12419.1, ups=1, wpb=12415.4, bsz=460, num_updates=19800, lr=0.000100504, gnorm=0.351, clip=0, loss_scale=64, train_wall=99, gb_free=16.4, wall=19963
2023-07-01 16:49:14 | INFO | train_inner | epoch 014:    747 / 1474 loss=3.421, trans_loss=3.41, nll_loss=1.544, w2v_ctc_loss=0.904, task_loss=0.484, contrastive_loss=0.091, total=4150.03, n_correct=2623.89, ppl=2.92, accuracy=63.226, wps=12536.1, ups=1.01, wpb=12407.3, bsz=465.5, num_updates=19900, lr=0.000100251, gnorm=0.346, clip=0, loss_scale=64, train_wall=99, gb_free=15.7, wall=20062
2023-07-01 16:50:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-01 16:50:55 | INFO | train_inner | epoch 014:    848 / 1474 loss=3.411, trans_loss=3.405, nll_loss=1.54, w2v_ctc_loss=0.898, task_loss=0.484, contrastive_loss=0.089, total=4145.38, n_correct=2619.49, ppl=2.91, accuracy=63.191, wps=12268.3, ups=0.99, wpb=12379.8, bsz=467.1, num_updates=20000, lr=0.0001, gnorm=0.344, clip=0, loss_scale=32, train_wall=100, gb_free=16.9, wall=20163
2023-07-01 16:50:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 16:51:22 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.367 | trans_loss 5.593 | nll_loss 2.871 | w2v_ctc_loss 1.394 | task_loss 0 | contrastive_loss 0.25 | total 4003.4 | n_correct 2451.8 | ppl 7.32 | accuracy 61.243 | uer 17.209 | wer 19.179 | raw_wer 19.179 | bleu 19.93 | wps 2073.5 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.93
2023-07-01 16:51:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-07-01 16:51:22 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_14_20000.pt
2023-07-01 16:51:24 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_14_20000.pt
2023-07-01 16:51:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.93) (writing took 8.882212485186756 seconds)
tensor(0.0258, device='cuda:0')
tensor(0.0002, device='cuda:0')
2023-07-01 16:52:46 | INFO | train_inner | epoch 014:    948 / 1474 loss=3.95, trans_loss=5.371, nll_loss=2.718, w2v_ctc_loss=1.301, task_loss=1.426, contrastive_loss=0.222, total=4167.75, n_correct=2605.14, ppl=6.58, accuracy=62.507, wps=3842.2, ups=0.9, wpb=4260.9, bsz=157.9, num_updates=20100, lr=9.97509e-05, gnorm=0.973, clip=0, loss_scale=32, train_wall=74, gb_free=16.8, wall=20274
2023-07-01 16:54:01 | INFO | train_inner | epoch 014:   1048 / 1474 loss=3.969, trans_loss=5.435, nll_loss=2.758, w2v_ctc_loss=1.319, task_loss=1.452, contrastive_loss=0.181, total=4143.92, n_correct=2592.74, ppl=6.76, accuracy=62.567, wps=5533.7, ups=1.34, wpb=4143.9, bsz=150.4, num_updates=20200, lr=9.95037e-05, gnorm=0.976, clip=0, loss_scale=32, train_wall=74, gb_free=16.2, wall=20348
2023-07-01 16:55:14 | INFO | train_inner | epoch 014:   1148 / 1474 loss=3.989, trans_loss=5.438, nll_loss=2.761, w2v_ctc_loss=1.322, task_loss=1.452, contrastive_loss=0.723, total=4228.69, n_correct=2645.25, ppl=6.78, accuracy=62.555, wps=5739.9, ups=1.36, wpb=4228.7, bsz=163.6, num_updates=20300, lr=9.92583e-05, gnorm=0.965, clip=0, loss_scale=32, train_wall=73, gb_free=16, wall=20422
2023-07-01 16:56:27 | INFO | train_inner | epoch 014:   1248 / 1474 loss=3.995, trans_loss=5.446, nll_loss=2.768, w2v_ctc_loss=1.353, task_loss=1.452, contrastive_loss=0.105, total=4021.19, n_correct=2513.28, ppl=6.81, accuracy=62.501, wps=5519.5, ups=1.37, wpb=4021.2, bsz=135.8, num_updates=20400, lr=9.90148e-05, gnorm=0.986, clip=0, loss_scale=32, train_wall=72, gb_free=16.5, wall=20495
2023-07-01 16:57:40 | INFO | train_inner | epoch 014:   1348 / 1474 loss=3.938, trans_loss=5.422, nll_loss=2.741, w2v_ctc_loss=1.29, task_loss=1.452, contrastive_loss=0.139, total=4213.9, n_correct=2645.05, ppl=6.68, accuracy=62.77, wps=5764.5, ups=1.37, wpb=4213.9, bsz=159.7, num_updates=20500, lr=9.8773e-05, gnorm=0.948, clip=0, loss_scale=32, train_wall=73, gb_free=16.3, wall=20568
2023-07-01 16:58:53 | INFO | train_inner | epoch 014:   1448 / 1474 loss=3.975, trans_loss=5.445, nll_loss=2.771, w2v_ctc_loss=1.32, task_loss=1.452, contrastive_loss=0.215, total=4130.28, n_correct=2580.48, ppl=6.83, accuracy=62.477, wps=5690.8, ups=1.38, wpb=4130.3, bsz=152, num_updates=20600, lr=9.85329e-05, gnorm=0.978, clip=0, loss_scale=32, train_wall=72, gb_free=15.6, wall=20641
2023-07-01 16:59:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0258, device='cuda:7')
tensor(0.0002, device='cuda:7')
tensor(0.0258, device='cuda:5')
tensor(0.0002, device='cuda:5')
tensor(0.0258, device='cuda:1')
tensor(0.0002, device='cuda:1')
tensor(0.0258, device='cuda:6')
tensor(0.0002, device='cuda:6')
tensor(0.0258, device='cuda:2')
tensor(0.0002, device='cuda:2')
tensor(0.0258, device='cuda:4')
tensor(0.0002, device='cuda:4')
tensor(0.0258, device='cuda:3')
tensor(0.0002, device='cuda:3')
2023-07-01 16:59:40 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.374 | trans_loss 5.597 | nll_loss 2.88 | w2v_ctc_loss 1.401 | task_loss 0 | contrastive_loss 0.263 | total 4003.4 | n_correct 2457.3 | ppl 7.36 | accuracy 61.38 | uer 17.652 | wer 19.593 | raw_wer 19.593 | bleu 19.51 | wps 1969.9 | wpb 4003.4 | bsz 141.8 | num_updates 20626 | best_bleu 19.93
2023-07-01 16:59:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20626 updates
2023-07-01 16:59:40 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.5100.pt
2023-07-01 16:59:43 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.5100.pt
2023-07-01 16:59:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.5100.pt (epoch 14 @ 20626 updates, score 19.51) (writing took 5.144766059238464 seconds)
2023-07-01 16:59:46 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-07-01 16:59:46 | INFO | train | epoch 014 | loss 3.536 | trans_loss 3.812 | nll_loss 1.785 | w2v_ctc_loss 0.988 | task_loss 0.674 | contrastive_loss 0.149 | total 4137.12 | n_correct 2601.82 | ppl 3.45 | accuracy 62.89 | wps 9431.6 | ups 1.06 | wpb 8862.4 | bsz 328.6 | num_updates 20626 | lr 9.84708e-05 | gnorm 0.613 | clip 0 | loss_scale 32 | train_wall 1299 | gb_free 16.6 | wall 20693
2023-07-01 16:59:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 16:59:46 | INFO | fairseq.trainer | begin training epoch 15
2023-07-01 16:59:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 17:00:47 | INFO | train_inner | epoch 015:     74 / 1474 loss=3.94, trans_loss=5.4, nll_loss=2.711, w2v_ctc_loss=1.287, task_loss=1.452, contrastive_loss=0.315, total=4083.88, n_correct=2580.64, ppl=6.55, accuracy=63.191, wps=3581.5, ups=0.88, wpb=4083.9, bsz=150.1, num_updates=20700, lr=9.82946e-05, gnorm=0.97, clip=0, loss_scale=32, train_wall=72, gb_free=16.4, wall=20755
2023-07-01 17:02:01 | INFO | train_inner | epoch 015:    174 / 1474 loss=3.928, trans_loss=5.386, nll_loss=2.692, w2v_ctc_loss=1.301, task_loss=1.452, contrastive_loss=0.132, total=4115.73, n_correct=2608.52, ppl=6.46, accuracy=63.379, wps=5595.3, ups=1.36, wpb=4115.7, bsz=148.9, num_updates=20800, lr=9.80581e-05, gnorm=0.958, clip=0, loss_scale=32, train_wall=73, gb_free=17, wall=20828
2023-07-01 17:03:14 | INFO | train_inner | epoch 015:    274 / 1474 loss=3.909, trans_loss=5.38, nll_loss=2.685, w2v_ctc_loss=1.279, task_loss=1.452, contrastive_loss=0.114, total=4193.15, n_correct=2662.56, ppl=6.43, accuracy=63.498, wps=5700, ups=1.36, wpb=4193.1, bsz=156.3, num_updates=20900, lr=9.78232e-05, gnorm=0.936, clip=0, loss_scale=32, train_wall=73, gb_free=13.1, wall=20902
2023-07-01 17:04:27 | INFO | train_inner | epoch 015:    374 / 1474 loss=3.921, trans_loss=5.383, nll_loss=2.688, w2v_ctc_loss=1.287, task_loss=1.452, contrastive_loss=0.163, total=4167.66, n_correct=2642.31, ppl=6.45, accuracy=63.4, wps=5700.2, ups=1.37, wpb=4167.7, bsz=153, num_updates=21000, lr=9.759e-05, gnorm=0.961, clip=0, loss_scale=32, train_wall=73, gb_free=16.3, wall=20975
2023-07-01 17:05:40 | INFO | train_inner | epoch 015:    474 / 1474 loss=3.945, trans_loss=5.394, nll_loss=2.702, w2v_ctc_loss=1.293, task_loss=1.452, contrastive_loss=0.347, total=4074.53, n_correct=2578.15, ppl=6.51, accuracy=63.275, wps=5573.3, ups=1.37, wpb=4074.5, bsz=147.1, num_updates=21100, lr=9.73585e-05, gnorm=0.97, clip=0, loss_scale=32, train_wall=73, gb_free=16, wall=21048
2023-07-01 17:06:53 | INFO | train_inner | epoch 015:    574 / 1474 loss=3.938, trans_loss=5.396, nll_loss=2.707, w2v_ctc_loss=1.311, task_loss=1.452, contrastive_loss=0.129, total=4140.59, n_correct=2613.76, ppl=6.53, accuracy=63.125, wps=5685.1, ups=1.37, wpb=4140.6, bsz=149.4, num_updates=21200, lr=9.71286e-05, gnorm=0.965, clip=0, loss_scale=32, train_wall=72, gb_free=12.6, wall=21121
2023-07-01 17:08:06 | INFO | train_inner | epoch 015:    674 / 1474 loss=3.937, trans_loss=5.39, nll_loss=2.699, w2v_ctc_loss=1.3, task_loss=1.452, contrastive_loss=0.294, total=4134.99, n_correct=2620.2, ppl=6.49, accuracy=63.367, wps=5661.3, ups=1.37, wpb=4135, bsz=153.5, num_updates=21300, lr=9.69003e-05, gnorm=0.977, clip=0, loss_scale=32, train_wall=73, gb_free=11.1, wall=21194
2023-07-01 17:09:20 | INFO | train_inner | epoch 015:    774 / 1474 loss=3.939, trans_loss=5.403, nll_loss=2.715, w2v_ctc_loss=1.311, task_loss=1.452, contrastive_loss=0.134, total=4173.66, n_correct=2631.03, ppl=6.57, accuracy=63.039, wps=5667.2, ups=1.36, wpb=4173.7, bsz=152.5, num_updates=21400, lr=9.66736e-05, gnorm=0.962, clip=0, loss_scale=32, train_wall=73, gb_free=16.9, wall=21268
2023-07-01 17:10:33 | INFO | train_inner | epoch 015:    874 / 1474 loss=3.952, trans_loss=5.412, nll_loss=2.728, w2v_ctc_loss=1.316, task_loss=1.452, contrastive_loss=0.127, total=4059.35, n_correct=2555.08, ppl=6.62, accuracy=62.943, wps=5576.9, ups=1.37, wpb=4059.3, bsz=144.1, num_updates=21500, lr=9.64486e-05, gnorm=0.975, clip=0, loss_scale=32, train_wall=72, gb_free=15.8, wall=21340
2023-07-01 17:11:46 | INFO | train_inner | epoch 015:    974 / 1474 loss=3.934, trans_loss=5.394, nll_loss=2.704, w2v_ctc_loss=1.283, task_loss=1.452, contrastive_loss=0.295, total=4122.87, n_correct=2608.55, ppl=6.51, accuracy=63.27, wps=5593.9, ups=1.36, wpb=4122.9, bsz=150.8, num_updates=21600, lr=9.6225e-05, gnorm=0.959, clip=0, loss_scale=32, train_wall=73, gb_free=17.7, wall=21414
2023-07-01 17:13:00 | INFO | train_inner | epoch 015:   1074 / 1474 loss=3.952, trans_loss=5.408, nll_loss=2.725, w2v_ctc_loss=1.29, task_loss=1.452, contrastive_loss=0.605, total=4192.24, n_correct=2639.61, ppl=6.61, accuracy=62.964, wps=5673.5, ups=1.35, wpb=4192.2, bsz=162.6, num_updates=21700, lr=9.60031e-05, gnorm=0.959, clip=0, loss_scale=32, train_wall=73, gb_free=17.3, wall=21488
2023-07-01 17:14:13 | INFO | train_inner | epoch 015:   1174 / 1474 loss=3.899, trans_loss=5.381, nll_loss=2.691, w2v_ctc_loss=1.261, task_loss=1.452, contrastive_loss=0.22, total=4185, n_correct=2659.77, ppl=6.46, accuracy=63.555, wps=5771.8, ups=1.38, wpb=4185, bsz=164.6, num_updates=21800, lr=9.57826e-05, gnorm=0.947, clip=0, loss_scale=32, train_wall=72, gb_free=16.4, wall=21560
2023-07-01 17:15:26 | INFO | train_inner | epoch 015:   1274 / 1474 loss=3.934, trans_loss=5.396, nll_loss=2.707, w2v_ctc_loss=1.311, task_loss=1.452, contrastive_loss=0.13, total=4152.04, n_correct=2625.22, ppl=6.53, accuracy=63.227, wps=5678.9, ups=1.37, wpb=4152, bsz=151.8, num_updates=21900, lr=9.55637e-05, gnorm=0.953, clip=0, loss_scale=32, train_wall=73, gb_free=16.8, wall=21634
2023-07-01 17:16:39 | INFO | train_inner | epoch 015:   1374 / 1474 loss=3.936, trans_loss=5.399, nll_loss=2.711, w2v_ctc_loss=1.302, task_loss=1.452, contrastive_loss=0.102, total=4100.21, n_correct=2592.06, ppl=6.55, accuracy=63.218, wps=5620.1, ups=1.37, wpb=4100.2, bsz=146.8, num_updates=22000, lr=9.53463e-05, gnorm=0.956, clip=0, loss_scale=64, train_wall=72, gb_free=17.6, wall=21707
2023-07-01 17:16:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 17:17:06 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.348 | trans_loss 5.6 | nll_loss 2.878 | w2v_ctc_loss 1.315 | task_loss 0 | contrastive_loss 0.247 | total 4003.4 | n_correct 2457.2 | ppl 7.35 | accuracy 61.378 | uer 17.378 | wer 19.377 | raw_wer 19.377 | bleu 19.56 | wps 1948.9 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 19.93
2023-07-01 17:17:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-07-01 17:17:06 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_15_22000.pt
2023-07-01 17:17:08 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_15_22000.pt
2023-07-01 17:17:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.56) (writing took 6.004145955201238 seconds)
2023-07-01 17:18:26 | INFO | train_inner | epoch 015:   1474 / 1474 loss=3.944, trans_loss=5.409, nll_loss=2.726, w2v_ctc_loss=1.31, task_loss=1.452, contrastive_loss=0.279, total=4141.17, n_correct=2610.46, ppl=6.62, accuracy=63.037, wps=3861.2, ups=0.93, wpb=4141.2, bsz=157.2, num_updates=22100, lr=9.51303e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=74, gb_free=17.2, wall=21814
2023-07-01 17:18:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 17:18:53 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.364 | trans_loss 5.593 | nll_loss 2.874 | w2v_ctc_loss 1.386 | task_loss 0 | contrastive_loss 0.25 | total 4003.4 | n_correct 2454.7 | ppl 7.33 | accuracy 61.315 | uer 17.344 | wer 19.149 | raw_wer 19.149 | bleu 19.61 | wps 2049.8 | wpb 4003.4 | bsz 141.8 | num_updates 22100 | best_bleu 19.93
2023-07-01 17:18:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22100 updates
2023-07-01 17:18:53 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.6101.pt
2023-07-01 17:18:57 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.6101.pt
2023-07-01 17:19:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.6101.pt (epoch 15 @ 22100 updates, score 19.61) (writing took 6.989851190708578 seconds)
2023-07-01 17:19:00 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-07-01 17:19:00 | INFO | train | epoch 015 | loss 3.933 | trans_loss 5.394 | nll_loss 2.705 | w2v_ctc_loss 1.295 | task_loss 1.452 | contrastive_loss 0.229 | total 4138.65 | n_correct 2617.74 | ppl 6.52 | accuracy 63.251 | wps 5283.1 | ups 1.28 | wpb 4138.6 | bsz 152.8 | num_updates 22100 | lr 9.51303e-05 | gnorm 0.96 | clip 0 | loss_scale 64 | train_wall 1072 | gb_free 17.2 | wall 21848
2023-07-01 17:19:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 17:19:00 | INFO | fairseq.trainer | begin training epoch 16
2023-07-01 17:19:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 17:20:21 | INFO | train_inner | epoch 016:    100 / 1474 loss=3.873, trans_loss=5.344, nll_loss=2.639, w2v_ctc_loss=1.251, task_loss=1.452, contrastive_loss=0.16, total=4126.22, n_correct=2643.95, ppl=6.23, accuracy=64.077, wps=3584.5, ups=0.87, wpb=4126.2, bsz=157.8, num_updates=22200, lr=9.49158e-05, gnorm=0.962, clip=0, loss_scale=64, train_wall=73, gb_free=16.3, wall=21929
2023-07-01 17:21:36 | INFO | train_inner | epoch 016:    200 / 1474 loss=3.883, trans_loss=5.344, nll_loss=2.639, w2v_ctc_loss=1.253, task_loss=1.452, contrastive_loss=0.114, total=4100.6, n_correct=2628.02, ppl=6.23, accuracy=64.089, wps=5528.4, ups=1.35, wpb=4100.6, bsz=148.4, num_updates=22300, lr=9.47027e-05, gnorm=0.96, clip=0, loss_scale=64, train_wall=74, gb_free=13, wall=22003
2023-07-01 17:22:49 | INFO | train_inner | epoch 016:    300 / 1474 loss=3.91, trans_loss=5.365, nll_loss=2.668, w2v_ctc_loss=1.281, task_loss=1.452, contrastive_loss=0.26, total=4166.94, n_correct=2657.13, ppl=6.35, accuracy=63.767, wps=5690.9, ups=1.37, wpb=4166.9, bsz=154.5, num_updates=22400, lr=9.44911e-05, gnorm=0.956, clip=0, loss_scale=64, train_wall=73, gb_free=17.3, wall=22076
2023-07-01 17:24:02 | INFO | train_inner | epoch 016:    400 / 1474 loss=3.925, trans_loss=5.371, nll_loss=2.673, w2v_ctc_loss=1.288, task_loss=1.452, contrastive_loss=0.283, total=4073.3, n_correct=2591.66, ppl=6.38, accuracy=63.626, wps=5595.8, ups=1.37, wpb=4073.3, bsz=144, num_updates=22500, lr=9.42809e-05, gnorm=0.975, clip=0, loss_scale=64, train_wall=72, gb_free=17.2, wall=22149
2023-07-01 17:25:15 | INFO | train_inner | epoch 016:    500 / 1474 loss=3.889, trans_loss=5.357, nll_loss=2.658, w2v_ctc_loss=1.267, task_loss=1.452, contrastive_loss=0.176, total=4174.67, n_correct=2669.3, ppl=6.31, accuracy=63.94, wps=5658.5, ups=1.36, wpb=4174.7, bsz=159.5, num_updates=22600, lr=9.40721e-05, gnorm=0.942, clip=0, loss_scale=64, train_wall=73, gb_free=16.2, wall=22223
2023-07-01 17:26:28 | INFO | train_inner | epoch 016:    600 / 1474 loss=3.907, trans_loss=5.368, nll_loss=2.672, w2v_ctc_loss=1.279, task_loss=1.453, contrastive_loss=0.102, total=4124.65, n_correct=2627.88, ppl=6.37, accuracy=63.712, wps=5678.2, ups=1.38, wpb=4124.6, bsz=148.8, num_updates=22700, lr=9.38647e-05, gnorm=0.961, clip=0, loss_scale=64, train_wall=72, gb_free=16.4, wall=22296
2023-07-01 17:27:41 | INFO | train_inner | epoch 016:    700 / 1474 loss=3.911, trans_loss=5.372, nll_loss=2.675, w2v_ctc_loss=1.288, task_loss=1.459, contrastive_loss=0.107, total=4095.49, n_correct=2604.01, ppl=6.39, accuracy=63.582, wps=5643.5, ups=1.38, wpb=4095.5, bsz=148.2, num_updates=22800, lr=9.36586e-05, gnorm=0.957, clip=0, loss_scale=64, train_wall=72, gb_free=16.4, wall=22368
2023-07-01 17:28:54 | INFO | train_inner | epoch 016:    800 / 1474 loss=3.906, trans_loss=5.368, nll_loss=2.673, w2v_ctc_loss=1.256, task_loss=2.117, contrastive_loss=0.25, total=4174.94, n_correct=2656.77, ppl=6.38, accuracy=63.636, wps=5660.8, ups=1.36, wpb=4174.9, bsz=155.4, num_updates=22900, lr=9.34539e-05, gnorm=0.957, clip=0, loss_scale=64, train_wall=73, gb_free=16.6, wall=22442
2023-07-01 17:30:08 | INFO | train_inner | epoch 016:    900 / 1474 loss=3.906, trans_loss=5.367, nll_loss=2.671, w2v_ctc_loss=1.269, task_loss=2, contrastive_loss=0.228, total=4163.19, n_correct=2652.51, ppl=6.37, accuracy=63.713, wps=5623.2, ups=1.35, wpb=4163.2, bsz=155.3, num_updates=23000, lr=9.32505e-05, gnorm=0.962, clip=0, loss_scale=64, train_wall=74, gb_free=17.1, wall=22516
2023-07-01 17:31:22 | INFO | train_inner | epoch 016:   1000 / 1474 loss=3.93, trans_loss=5.383, nll_loss=2.691, w2v_ctc_loss=1.299, task_loss=2, contrastive_loss=0.217, total=4103.45, n_correct=2601.29, ppl=6.46, accuracy=63.393, wps=5570, ups=1.36, wpb=4103.4, bsz=149, num_updates=23100, lr=9.30484e-05, gnorm=0.959, clip=0, loss_scale=64, train_wall=73, gb_free=15.1, wall=22590
2023-07-01 17:32:36 | INFO | train_inner | epoch 016:   1100 / 1474 loss=3.938, trans_loss=5.39, nll_loss=2.701, w2v_ctc_loss=1.312, task_loss=2, contrastive_loss=0.168, total=4119.27, n_correct=2607.01, ppl=6.5, accuracy=63.288, wps=5602.7, ups=1.36, wpb=4119.3, bsz=147.7, num_updates=23200, lr=9.28477e-05, gnorm=0.967, clip=0, loss_scale=64, train_wall=73, gb_free=17.9, wall=22663
2023-07-01 17:33:49 | INFO | train_inner | epoch 016:   1200 / 1474 loss=3.928, trans_loss=5.385, nll_loss=2.695, w2v_ctc_loss=1.274, task_loss=2, contrastive_loss=0.361, total=4165.11, n_correct=2639.38, ppl=6.48, accuracy=63.369, wps=5633.8, ups=1.35, wpb=4165.1, bsz=154.3, num_updates=23300, lr=9.26482e-05, gnorm=0.962, clip=0, loss_scale=64, train_wall=74, gb_free=17, wall=22737
2023-07-01 17:35:03 | INFO | train_inner | epoch 016:   1300 / 1474 loss=3.925, trans_loss=5.382, nll_loss=2.691, w2v_ctc_loss=1.295, task_loss=2, contrastive_loss=0.313, total=4134.61, n_correct=2623.8, ppl=6.46, accuracy=63.459, wps=5657.7, ups=1.37, wpb=4134.6, bsz=155.4, num_updates=23400, lr=9.245e-05, gnorm=0.961, clip=0, loss_scale=64, train_wall=73, gb_free=16.9, wall=22810
2023-07-01 17:36:16 | INFO | train_inner | epoch 016:   1400 / 1474 loss=3.908, trans_loss=5.377, nll_loss=2.685, w2v_ctc_loss=1.289, task_loss=2, contrastive_loss=0.177, total=4206.33, n_correct=2669.36, ppl=6.43, accuracy=63.461, wps=5702.6, ups=1.36, wpb=4206.3, bsz=161.1, num_updates=23500, lr=9.22531e-05, gnorm=0.952, clip=0, loss_scale=64, train_wall=73, gb_free=15.7, wall=22884
2023-07-01 17:37:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 17:37:37 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.356 | trans_loss 5.589 | nll_loss 2.866 | w2v_ctc_loss 1.368 | task_loss 0 | contrastive_loss 0.253 | total 4003.4 | n_correct 2466.3 | ppl 7.29 | accuracy 61.605 | uer 17.357 | wer 19.093 | raw_wer 19.093 | bleu 20.04 | wps 2013.8 | wpb 4003.4 | bsz 141.8 | num_updates 23574 | best_bleu 20.04
2023-07-01 17:37:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23574 updates
2023-07-01 17:37:37 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt
2023-07-01 17:37:41 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt
2023-07-01 17:37:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt (epoch 16 @ 23574 updates, score 20.04) (writing took 8.022676180116832 seconds)
2023-07-01 17:37:45 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-07-01 17:37:45 | INFO | train | epoch 016 | loss 3.911 | trans_loss 5.37 | nll_loss 2.674 | w2v_ctc_loss 1.278 | task_loss 1.751 | contrastive_loss 0.226 | total 4138.65 | n_correct 2634.04 | ppl 6.38 | accuracy 63.645 | wps 5421.6 | ups 1.31 | wpb 4138.6 | bsz 152.8 | num_updates 23574 | lr 9.21082e-05 | gnorm 0.96 | clip 0 | loss_scale 64 | train_wall 1076 | gb_free 15.6 | wall 22973
2023-07-01 17:37:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 17:37:46 | INFO | fairseq.trainer | begin training epoch 17
2023-07-01 17:37:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 17:38:13 | INFO | train_inner | epoch 017:     26 / 1474 loss=3.907, trans_loss=5.355, nll_loss=2.656, w2v_ctc_loss=1.26, task_loss=2, contrastive_loss=0.446, total=4152.31, n_correct=2654.61, ppl=6.3, accuracy=63.931, wps=3563.2, ups=0.86, wpb=4152.3, bsz=152.3, num_updates=23600, lr=9.20575e-05, gnorm=0.95, clip=0, loss_scale=64, train_wall=73, gb_free=14.2, wall=23000
2023-07-01 17:39:27 | INFO | train_inner | epoch 017:    126 / 1474 loss=3.885, trans_loss=5.332, nll_loss=2.624, w2v_ctc_loss=1.278, task_loss=2, contrastive_loss=0.117, total=4118.91, n_correct=2642.64, ppl=6.16, accuracy=64.159, wps=5558.2, ups=1.35, wpb=4118.9, bsz=147.9, num_updates=23700, lr=9.1863e-05, gnorm=0.966, clip=0, loss_scale=64, train_wall=74, gb_free=16.6, wall=23075
2023-07-01 17:40:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-01 17:40:41 | INFO | train_inner | epoch 017:    227 / 1474 loss=3.885, trans_loss=5.335, nll_loss=2.631, w2v_ctc_loss=1.251, task_loss=2, contrastive_loss=0.365, total=4141.88, n_correct=2660.31, ppl=6.19, accuracy=64.23, wps=5627.1, ups=1.36, wpb=4141.9, bsz=156.1, num_updates=23800, lr=9.16698e-05, gnorm=0.956, clip=0, loss_scale=32, train_wall=73, gb_free=17.1, wall=23148
2023-07-01 17:41:53 | INFO | train_inner | epoch 017:    327 / 1474 loss=3.897, trans_loss=5.341, nll_loss=2.637, w2v_ctc_loss=1.256, task_loss=2, contrastive_loss=0.455, total=4156.91, n_correct=2660.72, ppl=6.22, accuracy=64.007, wps=5714.6, ups=1.37, wpb=4156.9, bsz=152.9, num_updates=23900, lr=9.14779e-05, gnorm=0.959, clip=0, loss_scale=32, train_wall=72, gb_free=17.6, wall=23221
2023-07-01 17:43:07 | INFO | train_inner | epoch 017:    427 / 1474 loss=3.877, trans_loss=5.337, nll_loss=2.631, w2v_ctc_loss=1.267, task_loss=2, contrastive_loss=0.118, total=4146.43, n_correct=2665.53, ppl=6.2, accuracy=64.285, wps=5654, ups=1.36, wpb=4146.4, bsz=154, num_updates=24000, lr=9.12871e-05, gnorm=0.954, clip=0, loss_scale=32, train_wall=73, gb_free=16.7, wall=23294
2023-07-01 17:43:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 17:43:34 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.374 | trans_loss 5.599 | nll_loss 2.878 | w2v_ctc_loss 1.403 | task_loss 0 | contrastive_loss 0.259 | total 4003.4 | n_correct 2456.6 | ppl 7.35 | accuracy 61.363 | uer 17.214 | wer 19.075 | raw_wer 19.075 | bleu 19.86 | wps 2101.8 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 20.04
2023-07-01 17:43:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-07-01 17:43:34 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_17_24000.pt
2023-07-01 17:43:36 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_17_24000.pt
2023-07-01 17:43:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.86) (writing took 5.817175182048231 seconds)
2023-07-01 17:44:54 | INFO | train_inner | epoch 017:    527 / 1474 loss=3.901, trans_loss=5.351, nll_loss=2.651, w2v_ctc_loss=1.284, task_loss=2, contrastive_loss=0.211, total=4182.1, n_correct=2672.17, ppl=6.28, accuracy=63.895, wps=3885, ups=0.93, wpb=4182.1, bsz=153.9, num_updates=24100, lr=9.10975e-05, gnorm=0.959, clip=0, loss_scale=32, train_wall=74, gb_free=17, wall=23402
2023-07-01 17:46:08 | INFO | train_inner | epoch 017:    627 / 1474 loss=3.886, trans_loss=5.345, nll_loss=2.643, w2v_ctc_loss=1.26, task_loss=2, contrastive_loss=0.109, total=4167.27, n_correct=2668.93, ppl=6.24, accuracy=64.045, wps=5684.1, ups=1.36, wpb=4167.3, bsz=151.1, num_updates=24200, lr=9.09091e-05, gnorm=0.938, clip=0, loss_scale=32, train_wall=73, gb_free=11.3, wall=23475
2023-07-01 17:47:22 | INFO | train_inner | epoch 017:    727 / 1474 loss=3.903, trans_loss=5.356, nll_loss=2.657, w2v_ctc_loss=1.286, task_loss=2, contrastive_loss=0.203, total=4166.12, n_correct=2662.3, ppl=6.31, accuracy=63.904, wps=5634.9, ups=1.35, wpb=4166.1, bsz=154.1, num_updates=24300, lr=9.07218e-05, gnorm=0.971, clip=0, loss_scale=32, train_wall=73, gb_free=16.5, wall=23549
2023-07-01 17:48:35 | INFO | train_inner | epoch 017:    827 / 1474 loss=3.9, trans_loss=5.354, nll_loss=2.655, w2v_ctc_loss=1.281, task_loss=2, contrastive_loss=0.131, total=4091.64, n_correct=2617.17, ppl=6.3, accuracy=63.964, wps=5562.9, ups=1.36, wpb=4091.6, bsz=147.7, num_updates=24400, lr=9.05357e-05, gnorm=0.965, clip=0, loss_scale=32, train_wall=73, gb_free=17.4, wall=23623
2023-07-01 17:49:48 | INFO | train_inner | epoch 017:    927 / 1474 loss=3.881, trans_loss=5.346, nll_loss=2.644, w2v_ctc_loss=1.256, task_loss=2, contrastive_loss=0.127, total=4106.83, n_correct=2631.72, ppl=6.25, accuracy=64.082, wps=5661.7, ups=1.38, wpb=4106.8, bsz=152.3, num_updates=24500, lr=9.03508e-05, gnorm=0.958, clip=0, loss_scale=32, train_wall=72, gb_free=16, wall=23695
2023-07-01 17:51:00 | INFO | train_inner | epoch 017:   1027 / 1474 loss=3.882, trans_loss=5.345, nll_loss=2.644, w2v_ctc_loss=1.262, task_loss=2, contrastive_loss=0.133, total=4115.49, n_correct=2637.34, ppl=6.25, accuracy=64.083, wps=5657.2, ups=1.37, wpb=4115.5, bsz=152.9, num_updates=24600, lr=9.0167e-05, gnorm=0.959, clip=0, loss_scale=32, train_wall=72, gb_free=16.8, wall=23768
2023-07-01 17:52:13 | INFO | train_inner | epoch 017:   1127 / 1474 loss=3.884, trans_loss=5.345, nll_loss=2.644, w2v_ctc_loss=1.252, task_loss=2, contrastive_loss=0.108, total=4078.39, n_correct=2610.07, ppl=6.25, accuracy=63.998, wps=5640.6, ups=1.38, wpb=4078.4, bsz=146.9, num_updates=24700, lr=8.99843e-05, gnorm=0.961, clip=0, loss_scale=32, train_wall=72, gb_free=15.8, wall=23840
2023-07-01 17:53:27 | INFO | train_inner | epoch 017:   1227 / 1474 loss=3.91, trans_loss=5.361, nll_loss=2.666, w2v_ctc_loss=1.255, task_loss=2, contrastive_loss=0.595, total=4173.49, n_correct=2660.36, ppl=6.35, accuracy=63.744, wps=5656.5, ups=1.36, wpb=4173.5, bsz=161.9, num_updates=24800, lr=8.98027e-05, gnorm=0.954, clip=0, loss_scale=32, train_wall=73, gb_free=16.3, wall=23914
2023-07-01 17:54:40 | INFO | train_inner | epoch 017:   1327 / 1474 loss=3.894, trans_loss=5.355, nll_loss=2.657, w2v_ctc_loss=1.248, task_loss=2, contrastive_loss=0.277, total=4156.28, n_correct=2652.38, ppl=6.31, accuracy=63.816, wps=5673.7, ups=1.37, wpb=4156.3, bsz=154, num_updates=24900, lr=8.96221e-05, gnorm=0.957, clip=0, loss_scale=32, train_wall=73, gb_free=17.9, wall=23987
2023-07-01 17:55:53 | INFO | train_inner | epoch 017:   1427 / 1474 loss=3.885, trans_loss=5.348, nll_loss=2.648, w2v_ctc_loss=1.262, task_loss=2, contrastive_loss=0.116, total=4112.95, n_correct=2630.17, ppl=6.27, accuracy=63.949, wps=5584.7, ups=1.36, wpb=4112.9, bsz=151.6, num_updates=25000, lr=8.94427e-05, gnorm=0.956, clip=0, loss_scale=32, train_wall=73, gb_free=17, wall=24061
tensor(0.0258, device='cuda:0')
tensor(0.0002, device='cuda:0')
2023-07-01 17:56:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0258, device='cuda:5')
tensor(0.0002, device='cuda:5')
tensor(0.0258, device='cuda:4')
tensor(0.0002, device='cuda:4')
tensor(0.0258, device='cuda:7')
tensor(0.0002, device='cuda:7')
tensor(0.0258, device='cuda:6')
tensor(0.0002, device='cuda:6')
tensor(0.0258, device='cuda:2')
tensor(0.0002, device='cuda:2')
tensor(0.0258, device='cuda:1')
tensor(0.0002, device='cuda:1')
tensor(0.0258, device='cuda:3')
tensor(0.0002, device='cuda:3')
2023-07-01 17:56:55 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.371 | trans_loss 5.576 | nll_loss 2.856 | w2v_ctc_loss 1.447 | task_loss 0 | contrastive_loss 0.257 | total 4003.4 | n_correct 2469.5 | ppl 7.24 | accuracy 61.685 | uer 17.567 | wer 19.373 | raw_wer 19.373 | bleu 20.05 | wps 2178.2 | wpb 4003.4 | bsz 141.8 | num_updates 25047 | best_bleu 20.05
2023-07-01 17:56:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25047 updates
2023-07-01 17:56:55 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt
2023-07-01 17:56:59 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt
2023-07-01 17:57:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_best.pt (epoch 17 @ 25047 updates, score 20.05) (writing took 8.513192267157137 seconds)
2023-07-01 17:57:04 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-07-01 17:57:04 | INFO | train | epoch 017 | loss 3.89 | trans_loss 5.346 | nll_loss 2.644 | w2v_ctc_loss 1.264 | task_loss 2 | contrastive_loss 0.217 | total 4137.84 | n_correct 2649.2 | ppl 6.25 | accuracy 64.024 | wps 5262.6 | ups 1.27 | wpb 4137.8 | bsz 152.7 | num_updates 25047 | lr 8.93588e-05 | gnorm 0.958 | clip 0 | loss_scale 32 | train_wall 1075 | gb_free 16.6 | wall 24131
2023-07-01 17:57:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 17:57:04 | INFO | fairseq.trainer | begin training epoch 18
2023-07-01 17:57:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 17:57:51 | INFO | train_inner | epoch 018:     53 / 1474 loss=3.888, trans_loss=5.341, nll_loss=2.639, w2v_ctc_loss=1.278, task_loss=2, contrastive_loss=0.138, total=4139.04, n_correct=2653.01, ppl=6.23, accuracy=64.097, wps=3514.1, ups=0.85, wpb=4139, bsz=151.7, num_updates=25100, lr=8.92644e-05, gnorm=0.952, clip=0, loss_scale=32, train_wall=74, gb_free=17.2, wall=24179
2023-07-01 17:59:05 | INFO | train_inner | epoch 018:    153 / 1474 loss=3.857, trans_loss=5.307, nll_loss=2.593, w2v_ctc_loss=1.213, task_loss=2, contrastive_loss=0.383, total=4154.85, n_correct=2684.72, ppl=6.03, accuracy=64.617, wps=5663.1, ups=1.36, wpb=4154.9, bsz=156.4, num_updates=25200, lr=8.90871e-05, gnorm=0.945, clip=0, loss_scale=32, train_wall=73, gb_free=16.9, wall=24252
2023-07-01 18:00:18 | INFO | train_inner | epoch 018:    253 / 1474 loss=3.846, trans_loss=5.306, nll_loss=2.592, w2v_ctc_loss=1.24, task_loss=2, contrastive_loss=0.119, total=4162.72, n_correct=2694.28, ppl=6.03, accuracy=64.724, wps=5658.1, ups=1.36, wpb=4162.7, bsz=156.5, num_updates=25300, lr=8.89108e-05, gnorm=0.945, clip=0, loss_scale=32, train_wall=73, gb_free=16.4, wall=24326
2023-07-01 18:01:31 | INFO | train_inner | epoch 018:    353 / 1474 loss=3.871, trans_loss=5.322, nll_loss=2.614, w2v_ctc_loss=1.252, task_loss=2, contrastive_loss=0.15, total=4161.22, n_correct=2679.4, ppl=6.12, accuracy=64.39, wps=5680.4, ups=1.37, wpb=4161.2, bsz=150.7, num_updates=25400, lr=8.87357e-05, gnorm=0.959, clip=0, loss_scale=32, train_wall=73, gb_free=14.7, wall=24399
2023-07-01 18:02:45 | INFO | train_inner | epoch 018:    453 / 1474 loss=3.888, trans_loss=5.333, nll_loss=2.628, w2v_ctc_loss=1.252, task_loss=2, contrastive_loss=0.33, total=4092.36, n_correct=2629.04, ppl=6.18, accuracy=64.243, wps=5564.2, ups=1.36, wpb=4092.4, bsz=147.7, num_updates=25500, lr=8.85615e-05, gnorm=0.973, clip=0, loss_scale=32, train_wall=73, gb_free=16.9, wall=24473
2023-07-01 18:03:58 | INFO | train_inner | epoch 018:    553 / 1474 loss=3.836, trans_loss=5.306, nll_loss=2.595, w2v_ctc_loss=1.228, task_loss=2, contrastive_loss=0.145, total=4206.45, n_correct=2722.31, ppl=6.04, accuracy=64.718, wps=5772.8, ups=1.37, wpb=4206.4, bsz=164.5, num_updates=25600, lr=8.83883e-05, gnorm=0.936, clip=0, loss_scale=32, train_wall=72, gb_free=17.9, wall=24545
2023-07-01 18:05:11 | INFO | train_inner | epoch 018:    653 / 1474 loss=3.892, trans_loss=5.342, nll_loss=2.639, w2v_ctc_loss=1.261, task_loss=2, contrastive_loss=0.282, total=4097.96, n_correct=2629.3, ppl=6.23, accuracy=64.161, wps=5622.3, ups=1.37, wpb=4098, bsz=149.3, num_updates=25700, lr=8.82162e-05, gnorm=0.976, clip=0, loss_scale=32, train_wall=72, gb_free=12.7, wall=24618
2023-07-01 18:06:25 | INFO | train_inner | epoch 018:    753 / 1474 loss=3.889, trans_loss=5.336, nll_loss=2.633, w2v_ctc_loss=1.265, task_loss=2, contrastive_loss=0.461, total=4208.5, n_correct=2705.02, ppl=6.2, accuracy=64.275, wps=5684.7, ups=1.35, wpb=4208.5, bsz=161.3, num_updates=25800, lr=8.80451e-05, gnorm=0.948, clip=0, loss_scale=64, train_wall=74, gb_free=16.4, wall=24692
2023-07-01 18:07:38 | INFO | train_inner | epoch 018:    853 / 1474 loss=3.868, trans_loss=5.325, nll_loss=2.618, w2v_ctc_loss=1.249, task_loss=2, contrastive_loss=0.102, total=4166.07, n_correct=2681.71, ppl=6.14, accuracy=64.37, wps=5689.7, ups=1.37, wpb=4166.1, bsz=151.2, num_updates=25900, lr=8.7875e-05, gnorm=0.953, clip=0, loss_scale=64, train_wall=73, gb_free=16.5, wall=24766
2023-07-01 18:08:50 | INFO | train_inner | epoch 018:    953 / 1474 loss=3.849, trans_loss=5.317, nll_loss=2.609, w2v_ctc_loss=1.228, task_loss=2, contrastive_loss=0.145, total=4141.27, n_correct=2671.33, ppl=6.1, accuracy=64.505, wps=5716.6, ups=1.38, wpb=4141.3, bsz=158, num_updates=26000, lr=8.77058e-05, gnorm=0.952, clip=0, loss_scale=64, train_wall=72, gb_free=16.2, wall=24838
2023-07-01 18:08:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 18:09:15 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.35 | trans_loss 5.572 | nll_loss 2.844 | w2v_ctc_loss 1.392 | task_loss 0 | contrastive_loss 0.248 | total 4003.4 | n_correct 2477.9 | ppl 7.18 | accuracy 61.895 | uer 17.302 | wer 19.142 | raw_wer 19.142 | bleu 20.14 | wps 2233.8 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 20.14
2023-07-01 18:09:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-07-01 18:09:15 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_18_26000.pt
2023-07-01 18:09:17 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_18_26000.pt
2023-07-01 18:09:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 20.14) (writing took 8.93634078791365 seconds)
2023-07-01 18:10:39 | INFO | train_inner | epoch 018:   1053 / 1474 loss=3.866, trans_loss=5.327, nll_loss=2.621, w2v_ctc_loss=1.234, task_loss=2, contrastive_loss=0.123, total=4134.55, n_correct=2658.75, ppl=6.15, accuracy=64.306, wps=3823.7, ups=0.92, wpb=4134.6, bsz=150.4, num_updates=26100, lr=8.75376e-05, gnorm=0.954, clip=0, loss_scale=64, train_wall=74, gb_free=16.6, wall=24946
2023-07-01 18:11:52 | INFO | train_inner | epoch 018:   1153 / 1474 loss=3.87, trans_loss=5.319, nll_loss=2.611, w2v_ctc_loss=1.244, task_loss=2, contrastive_loss=0.338, total=4157.63, n_correct=2679.77, ppl=6.11, accuracy=64.454, wps=5676.5, ups=1.37, wpb=4157.6, bsz=157, num_updates=26200, lr=8.73704e-05, gnorm=0.954, clip=0, loss_scale=64, train_wall=73, gb_free=17.2, wall=25019
2023-07-01 18:13:05 | INFO | train_inner | epoch 018:   1253 / 1474 loss=3.886, trans_loss=5.339, nll_loss=2.636, w2v_ctc_loss=1.253, task_loss=2, contrastive_loss=0.112, total=4085.66, n_correct=2617.4, ppl=6.21, accuracy=64.063, wps=5602, ups=1.37, wpb=4085.7, bsz=143.3, num_updates=26300, lr=8.72041e-05, gnorm=0.951, clip=0, loss_scale=64, train_wall=72, gb_free=17.6, wall=25092
2023-07-01 18:14:18 | INFO | train_inner | epoch 018:   1353 / 1474 loss=3.901, trans_loss=5.348, nll_loss=2.649, w2v_ctc_loss=1.283, task_loss=2, contrastive_loss=0.162, total=4065.6, n_correct=2602.38, ppl=6.27, accuracy=64.01, wps=5591.2, ups=1.38, wpb=4065.6, bsz=145.6, num_updates=26400, lr=8.70388e-05, gnorm=0.968, clip=0, loss_scale=64, train_wall=72, gb_free=13.5, wall=25165
2023-07-01 18:15:32 | INFO | train_inner | epoch 018:   1453 / 1474 loss=3.887, trans_loss=5.342, nll_loss=2.641, w2v_ctc_loss=1.269, task_loss=2, contrastive_loss=0.132, total=4122.48, n_correct=2639.96, ppl=6.24, accuracy=64.038, wps=5526.3, ups=1.34, wpb=4122.5, bsz=149.7, num_updates=26500, lr=8.68744e-05, gnorm=0.961, clip=0, loss_scale=64, train_wall=74, gb_free=17.2, wall=25240
2023-07-01 18:15:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 18:16:18 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.355 | trans_loss 5.57 | nll_loss 2.846 | w2v_ctc_loss 1.411 | task_loss 0 | contrastive_loss 0.252 | total 4003.4 | n_correct 2475.7 | ppl 7.19 | accuracy 61.84 | uer 17.068 | wer 18.929 | raw_wer 18.929 | bleu 19.8 | wps 1753.9 | wpb 4003.4 | bsz 141.8 | num_updates 26521 | best_bleu 20.14
2023-07-01 18:16:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26521 updates
2023-07-01 18:16:18 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.8001.pt
2023-07-01 18:16:21 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.8001.pt
2023-07-01 18:16:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.8001.pt (epoch 18 @ 26521 updates, score 19.8) (writing took 5.263385056052357 seconds)
2023-07-01 18:16:23 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-07-01 18:16:23 | INFO | train | epoch 018 | loss 3.873 | trans_loss 5.327 | nll_loss 2.62 | w2v_ctc_loss 1.249 | task_loss 2 | contrastive_loss 0.22 | total 4138.65 | n_correct 2662.88 | ppl 6.15 | accuracy 64.342 | wps 5259.5 | ups 1.27 | wpb 4138.6 | bsz 152.8 | num_updates 26521 | lr 8.684e-05 | gnorm 0.955 | clip 0 | loss_scale 64 | train_wall 1075 | gb_free 16.1 | wall 25291
2023-07-01 18:16:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 18:16:24 | INFO | fairseq.trainer | begin training epoch 19
2023-07-01 18:16:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 18:17:29 | INFO | train_inner | epoch 019:     79 / 1474 loss=3.855, trans_loss=5.3, nll_loss=2.585, w2v_ctc_loss=1.229, task_loss=2, contrastive_loss=0.236, total=4101.48, n_correct=2652.47, ppl=6, accuracy=64.671, wps=3503, ups=0.85, wpb=4101.5, bsz=148.5, num_updates=26600, lr=8.6711e-05, gnorm=0.961, clip=0, loss_scale=64, train_wall=72, gb_free=17.3, wall=25357
2023-07-01 18:18:43 | INFO | train_inner | epoch 019:    179 / 1474 loss=3.84, trans_loss=5.29, nll_loss=2.573, w2v_ctc_loss=1.243, task_loss=2, contrastive_loss=0.213, total=4227.39, n_correct=2743.75, ppl=5.95, accuracy=64.904, wps=5730, ups=1.36, wpb=4227.4, bsz=162.4, num_updates=26700, lr=8.65485e-05, gnorm=0.941, clip=0, loss_scale=64, train_wall=73, gb_free=15.8, wall=25431
2023-07-01 18:19:56 | INFO | train_inner | epoch 019:    279 / 1474 loss=3.837, trans_loss=5.288, nll_loss=2.568, w2v_ctc_loss=1.235, task_loss=2, contrastive_loss=0.103, total=4186.65, n_correct=2720.17, ppl=5.93, accuracy=64.972, wps=5710.3, ups=1.36, wpb=4186.6, bsz=153.2, num_updates=26800, lr=8.63868e-05, gnorm=0.941, clip=0, loss_scale=64, train_wall=73, gb_free=14.1, wall=25504
2023-07-01 18:21:10 | INFO | train_inner | epoch 019:    379 / 1474 loss=3.852, trans_loss=5.298, nll_loss=2.583, w2v_ctc_loss=1.222, task_loss=2, contrastive_loss=0.323, total=4165.84, n_correct=2696.7, ppl=5.99, accuracy=64.734, wps=5688.4, ups=1.37, wpb=4165.8, bsz=155, num_updates=26900, lr=8.62261e-05, gnorm=0.942, clip=0, loss_scale=64, train_wall=73, gb_free=16.2, wall=25577
2023-07-01 18:22:23 | INFO | train_inner | epoch 019:    479 / 1474 loss=3.851, trans_loss=5.305, nll_loss=2.592, w2v_ctc_loss=1.24, task_loss=2, contrastive_loss=0.132, total=4122.98, n_correct=2666.83, ppl=6.03, accuracy=64.682, wps=5620.4, ups=1.36, wpb=4123, bsz=151.3, num_updates=27000, lr=8.60663e-05, gnorm=0.956, clip=0, loss_scale=64, train_wall=73, gb_free=17.3, wall=25651
2023-07-01 18:23:36 | INFO | train_inner | epoch 019:    579 / 1474 loss=3.847, trans_loss=5.297, nll_loss=2.583, w2v_ctc_loss=1.224, task_loss=2, contrastive_loss=0.262, total=4121.66, n_correct=2670.63, ppl=5.99, accuracy=64.795, wps=5666.6, ups=1.37, wpb=4121.7, bsz=152.2, num_updates=27100, lr=8.59074e-05, gnorm=0.948, clip=0, loss_scale=64, train_wall=72, gb_free=17, wall=25723
2023-07-01 18:24:49 | INFO | train_inner | epoch 019:    679 / 1474 loss=3.831, trans_loss=5.303, nll_loss=2.591, w2v_ctc_loss=1.211, task_loss=2, contrastive_loss=0.12, total=4205.65, n_correct=2723.82, ppl=6.02, accuracy=64.766, wps=5706.8, ups=1.36, wpb=4205.6, bsz=161.5, num_updates=27200, lr=8.57493e-05, gnorm=0.944, clip=0, loss_scale=64, train_wall=73, gb_free=16.3, wall=25797
2023-07-01 18:26:03 | INFO | train_inner | epoch 019:    779 / 1474 loss=3.857, trans_loss=5.305, nll_loss=2.592, w2v_ctc_loss=1.25, task_loss=2, contrastive_loss=0.125, total=4120.36, n_correct=2664.28, ppl=6.03, accuracy=64.661, wps=5568.5, ups=1.35, wpb=4120.4, bsz=149.3, num_updates=27300, lr=8.55921e-05, gnorm=0.951, clip=0, loss_scale=64, train_wall=74, gb_free=14.1, wall=25871
2023-07-01 18:27:17 | INFO | train_inner | epoch 019:    879 / 1474 loss=3.858, trans_loss=5.316, nll_loss=2.607, w2v_ctc_loss=1.246, task_loss=2, contrastive_loss=0.126, total=4176.52, n_correct=2693.55, ppl=6.09, accuracy=64.493, wps=5705.1, ups=1.37, wpb=4176.5, bsz=154.9, num_updates=27400, lr=8.54358e-05, gnorm=0.951, clip=0, loss_scale=64, train_wall=73, gb_free=17.1, wall=25944
2023-07-01 18:28:31 | INFO | train_inner | epoch 019:    979 / 1474 loss=3.888, trans_loss=5.327, nll_loss=2.622, w2v_ctc_loss=1.24, task_loss=2, contrastive_loss=0.584, total=4079.93, n_correct=2624.74, ppl=6.16, accuracy=64.333, wps=5492.1, ups=1.35, wpb=4079.9, bsz=152.5, num_updates=27500, lr=8.52803e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=74, gb_free=16.7, wall=26018
2023-07-01 18:29:44 | INFO | train_inner | epoch 019:   1079 / 1474 loss=3.875, trans_loss=5.328, nll_loss=2.624, w2v_ctc_loss=1.239, task_loss=2, contrastive_loss=0.198, total=4041.08, n_correct=2595.68, ppl=6.16, accuracy=64.232, wps=5523.8, ups=1.37, wpb=4041.1, bsz=146.2, num_updates=27600, lr=8.51257e-05, gnorm=0.961, clip=0, loss_scale=64, train_wall=73, gb_free=16.4, wall=26092
2023-07-01 18:30:58 | INFO | train_inner | epoch 019:   1179 / 1474 loss=3.879, trans_loss=5.326, nll_loss=2.62, w2v_ctc_loss=1.245, task_loss=2, contrastive_loss=0.364, total=4146.59, n_correct=2666.78, ppl=6.15, accuracy=64.313, wps=5598.1, ups=1.35, wpb=4146.6, bsz=155, num_updates=27700, lr=8.49719e-05, gnorm=0.971, clip=0, loss_scale=64, train_wall=74, gb_free=12.7, wall=26166
2023-07-01 18:32:11 | INFO | train_inner | epoch 019:   1279 / 1474 loss=3.873, trans_loss=5.33, nll_loss=2.626, w2v_ctc_loss=1.239, task_loss=2, contrastive_loss=0.158, total=4142.96, n_correct=2660.45, ppl=6.17, accuracy=64.216, wps=5691.4, ups=1.37, wpb=4143, bsz=150.1, num_updates=27800, lr=8.48189e-05, gnorm=0.967, clip=0, loss_scale=64, train_wall=72, gb_free=16.3, wall=26238
2023-07-01 18:33:25 | INFO | train_inner | epoch 019:   1379 / 1474 loss=3.867, trans_loss=5.318, nll_loss=2.611, w2v_ctc_loss=1.255, task_loss=2, contrastive_loss=0.13, total=4129.64, n_correct=2660.64, ppl=6.11, accuracy=64.428, wps=5557.5, ups=1.35, wpb=4129.6, bsz=150.2, num_updates=27900, lr=8.46668e-05, gnorm=0.955, clip=0, loss_scale=128, train_wall=74, gb_free=16.9, wall=26313
2023-07-01 18:33:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-01 18:34:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 18:35:01 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.358 | trans_loss 5.568 | nll_loss 2.847 | w2v_ctc_loss 1.427 | task_loss 0 | contrastive_loss 0.244 | total 4003.4 | n_correct 2469.4 | ppl 7.19 | accuracy 61.683 | uer 17.198 | wer 18.922 | raw_wer 18.922 | bleu 19.99 | wps 1928.2 | wpb 4003.4 | bsz 141.8 | num_updates 27994 | best_bleu 20.14
2023-07-01 18:35:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27994 updates
2023-07-01 18:35:01 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.9909.pt
2023-07-01 18:35:04 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.9909.pt
2023-07-01 18:35:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.9909.pt (epoch 19 @ 27994 updates, score 19.99) (writing took 5.277062694076449 seconds)
2023-07-01 18:35:07 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-07-01 18:35:07 | INFO | train | epoch 019 | loss 3.857 | trans_loss 5.309 | nll_loss 2.598 | w2v_ctc_loss 1.238 | task_loss 2 | contrastive_loss 0.205 | total 4137.63 | n_correct 2672.49 | ppl 6.05 | accuracy 64.59 | wps 5426 | ups 1.31 | wpb 4137.6 | bsz 152.6 | num_updates 27994 | lr 8.45245e-05 | gnorm 0.955 | clip 0 | loss_scale 64 | train_wall 1077 | gb_free 17.5 | wall 26414
2023-07-01 18:35:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 18:35:07 | INFO | fairseq.trainer | begin training epoch 20
2023-07-01 18:35:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 18:35:20 | INFO | train_inner | epoch 020:      6 / 1474 loss=3.864, trans_loss=5.314, nll_loss=2.606, w2v_ctc_loss=1.255, task_loss=2, contrastive_loss=0.109, total=4104.55, n_correct=2646.56, ppl=6.09, accuracy=64.479, wps=3589.1, ups=0.87, wpb=4104.6, bsz=148.1, num_updates=28000, lr=8.45154e-05, gnorm=0.971, clip=0, loss_scale=64, train_wall=74, gb_free=16.6, wall=26427
2023-07-01 18:35:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 18:35:46 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.349 | trans_loss 5.57 | nll_loss 2.845 | w2v_ctc_loss 1.397 | task_loss 0 | contrastive_loss 0.239 | total 4003.4 | n_correct 2471.2 | ppl 7.19 | accuracy 61.728 | uer 17.097 | wer 18.858 | raw_wer 18.858 | bleu 20.33 | wps 1957.3 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.33
2023-07-01 18:35:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-07-01 18:35:46 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_20_28000.pt
2023-07-01 18:35:48 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_20_28000.pt
2023-07-01 18:35:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 20.33) (writing took 8.998945374041796 seconds)
2023-07-01 18:37:09 | INFO | train_inner | epoch 020:    106 / 1474 loss=3.815, trans_loss=5.268, nll_loss=2.544, w2v_ctc_loss=1.206, task_loss=2, contrastive_loss=0.141, total=4192.82, n_correct=2741.68, ppl=5.83, accuracy=65.39, wps=3819.9, ups=0.91, wpb=4192.8, bsz=156.4, num_updates=28100, lr=8.43649e-05, gnorm=0.948, clip=0, loss_scale=64, train_wall=73, gb_free=16.5, wall=26537
2023-07-01 18:38:23 | INFO | train_inner | epoch 020:    206 / 1474 loss=3.835, trans_loss=5.279, nll_loss=2.559, w2v_ctc_loss=1.213, task_loss=2, contrastive_loss=0.248, total=4155.9, n_correct=2703.31, ppl=5.89, accuracy=65.048, wps=5619.9, ups=1.35, wpb=4155.9, bsz=151.1, num_updates=28200, lr=8.42152e-05, gnorm=0.953, clip=0, loss_scale=64, train_wall=73, gb_free=12.2, wall=26611
2023-07-01 18:39:37 | INFO | train_inner | epoch 020:    306 / 1474 loss=3.8, trans_loss=5.266, nll_loss=2.543, w2v_ctc_loss=1.201, task_loss=2, contrastive_loss=0.124, total=4192.69, n_correct=2736.58, ppl=5.83, accuracy=65.27, wps=5726.8, ups=1.37, wpb=4192.7, bsz=163.8, num_updates=28300, lr=8.40663e-05, gnorm=0.946, clip=0, loss_scale=64, train_wall=73, gb_free=17.1, wall=26684
2023-07-01 18:40:50 | INFO | train_inner | epoch 020:    406 / 1474 loss=3.826, trans_loss=5.276, nll_loss=2.555, w2v_ctc_loss=1.208, task_loss=2, contrastive_loss=0.12, total=4116.96, n_correct=2683.35, ppl=5.88, accuracy=65.178, wps=5622.1, ups=1.37, wpb=4117, bsz=148.4, num_updates=28400, lr=8.39181e-05, gnorm=0.952, clip=0, loss_scale=64, train_wall=73, gb_free=13, wall=26757
2023-07-01 18:42:03 | INFO | train_inner | epoch 020:    506 / 1474 loss=3.852, trans_loss=5.298, nll_loss=2.584, w2v_ctc_loss=1.22, task_loss=2, contrastive_loss=0.298, total=4100.73, n_correct=2654.56, ppl=5.99, accuracy=64.734, wps=5575.6, ups=1.36, wpb=4100.7, bsz=149.2, num_updates=28500, lr=8.37708e-05, gnorm=0.978, clip=0, loss_scale=64, train_wall=73, gb_free=16.5, wall=26831
2023-07-01 18:42:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-01 18:43:18 | INFO | train_inner | epoch 020:    607 / 1474 loss=3.855, trans_loss=5.297, nll_loss=2.582, w2v_ctc_loss=1.234, task_loss=2, contrastive_loss=0.213, total=4090.01, n_correct=2648.53, ppl=5.99, accuracy=64.756, wps=5504.9, ups=1.35, wpb=4090, bsz=146.8, num_updates=28600, lr=8.36242e-05, gnorm=0.956, clip=0, loss_scale=32, train_wall=74, gb_free=12.4, wall=26905
2023-07-01 18:44:31 | INFO | train_inner | epoch 020:    707 / 1474 loss=3.847, trans_loss=5.297, nll_loss=2.583, w2v_ctc_loss=1.238, task_loss=2, contrastive_loss=0.109, total=4140.23, n_correct=2683.34, ppl=5.99, accuracy=64.811, wps=5657.9, ups=1.37, wpb=4140.2, bsz=150.3, num_updates=28700, lr=8.34784e-05, gnorm=0.955, clip=0, loss_scale=32, train_wall=73, gb_free=16.5, wall=26978
2023-07-01 18:45:44 | INFO | train_inner | epoch 020:    807 / 1474 loss=3.834, trans_loss=5.287, nll_loss=2.571, w2v_ctc_loss=1.226, task_loss=2, contrastive_loss=0.115, total=4140.66, n_correct=2691.09, ppl=5.94, accuracy=64.992, wps=5649.2, ups=1.36, wpb=4140.7, bsz=152.8, num_updates=28800, lr=8.33333e-05, gnorm=0.96, clip=0, loss_scale=32, train_wall=73, gb_free=17.6, wall=27052
2023-07-01 18:46:59 | INFO | train_inner | epoch 020:    907 / 1474 loss=3.874, trans_loss=5.311, nll_loss=2.603, w2v_ctc_loss=1.221, task_loss=2, contrastive_loss=0.701, total=4157.15, n_correct=2683.9, ppl=6.08, accuracy=64.561, wps=5561.4, ups=1.34, wpb=4157.1, bsz=161.3, num_updates=28900, lr=8.3189e-05, gnorm=0.966, clip=0, loss_scale=32, train_wall=74, gb_free=17.8, wall=27126
2023-07-01 18:48:13 | INFO | train_inner | epoch 020:   1007 / 1474 loss=3.833, trans_loss=5.293, nll_loss=2.578, w2v_ctc_loss=1.212, task_loss=2, contrastive_loss=0.125, total=4171.86, n_correct=2708.63, ppl=5.97, accuracy=64.926, wps=5629.4, ups=1.35, wpb=4171.9, bsz=154.3, num_updates=29000, lr=8.30455e-05, gnorm=0.954, clip=0, loss_scale=32, train_wall=74, gb_free=16.2, wall=27201
2023-07-01 18:49:26 | INFO | train_inner | epoch 020:   1107 / 1474 loss=3.857, trans_loss=5.304, nll_loss=2.594, w2v_ctc_loss=1.22, task_loss=2, contrastive_loss=0.401, total=4162.96, n_correct=2694.44, ppl=6.04, accuracy=64.724, wps=5688.7, ups=1.37, wpb=4163, bsz=157.5, num_updates=29100, lr=8.29027e-05, gnorm=0.963, clip=0, loss_scale=32, train_wall=73, gb_free=17.2, wall=27274
2023-07-01 18:50:39 | INFO | train_inner | epoch 020:   1207 / 1474 loss=3.855, trans_loss=5.296, nll_loss=2.582, w2v_ctc_loss=1.248, task_loss=2, contrastive_loss=0.106, total=4033.74, n_correct=2614.3, ppl=5.99, accuracy=64.811, wps=5500.6, ups=1.36, wpb=4033.7, bsz=142.6, num_updates=29200, lr=8.27606e-05, gnorm=0.974, clip=0, loss_scale=32, train_wall=73, gb_free=17.4, wall=27347
2023-07-01 18:51:54 | INFO | train_inner | epoch 020:   1307 / 1474 loss=3.854, trans_loss=5.305, nll_loss=2.595, w2v_ctc_loss=1.237, task_loss=2, contrastive_loss=0.111, total=4124.42, n_correct=2666.74, ppl=6.04, accuracy=64.657, wps=5526.9, ups=1.34, wpb=4124.4, bsz=148.5, num_updates=29300, lr=8.26192e-05, gnorm=0.959, clip=0, loss_scale=32, train_wall=74, gb_free=16.2, wall=27422
2023-07-01 18:53:08 | INFO | train_inner | epoch 020:   1407 / 1474 loss=3.855, trans_loss=5.305, nll_loss=2.594, w2v_ctc_loss=1.236, task_loss=2, contrastive_loss=0.109, total=4114.1, n_correct=2658.41, ppl=6.04, accuracy=64.617, wps=5595.7, ups=1.36, wpb=4114.1, bsz=146.8, num_updates=29400, lr=8.24786e-05, gnorm=0.967, clip=0, loss_scale=32, train_wall=73, gb_free=14.7, wall=27495
2023-07-01 18:53:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 18:54:23 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.337 | trans_loss 5.565 | nll_loss 2.843 | w2v_ctc_loss 1.364 | task_loss 0 | contrastive_loss 0.244 | total 4003.4 | n_correct 2479.5 | ppl 7.17 | accuracy 61.935 | uer 16.938 | wer 18.802 | raw_wer 18.802 | bleu 19.94 | wps 2013.2 | wpb 4003.4 | bsz 141.8 | num_updates 29467 | best_bleu 20.33
2023-07-01 18:54:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29467 updates
2023-07-01 18:54:23 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.9402.pt
2023-07-01 18:54:25 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.9402.pt
2023-07-01 18:54:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_19.9402.pt (epoch 20 @ 29467 updates, score 19.94) (writing took 5.409198945853859 seconds)
2023-07-01 18:54:28 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-07-01 18:54:28 | INFO | train | epoch 020 | loss 3.842 | trans_loss 5.292 | nll_loss 2.577 | w2v_ctc_loss 1.223 | task_loss 2 | contrastive_loss 0.21 | total 4138.21 | n_correct 2685.06 | ppl 5.97 | accuracy 64.885 | wps 5248.4 | ups 1.27 | wpb 4138.2 | bsz 152.7 | num_updates 29467 | lr 8.23848e-05 | gnorm 0.959 | clip 0 | loss_scale 32 | train_wall 1079 | gb_free 16.8 | wall 27576
2023-07-01 18:54:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 18:54:28 | INFO | fairseq.trainer | begin training epoch 21
2023-07-01 18:54:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 18:55:01 | INFO | train_inner | epoch 021:     33 / 1474 loss=3.847, trans_loss=5.299, nll_loss=2.587, w2v_ctc_loss=1.221, task_loss=2, contrastive_loss=0.349, total=4155.01, n_correct=2694.55, ppl=6.01, accuracy=64.851, wps=3676.2, ups=0.88, wpb=4155, bsz=158.8, num_updates=29500, lr=8.23387e-05, gnorm=0.963, clip=0, loss_scale=32, train_wall=73, gb_free=16.5, wall=27608
2023-07-01 18:56:14 | INFO | train_inner | epoch 021:    133 / 1474 loss=3.818, trans_loss=5.26, nll_loss=2.535, w2v_ctc_loss=1.202, task_loss=2, contrastive_loss=0.339, total=4186.67, n_correct=2739.02, ppl=5.8, accuracy=65.422, wps=5721.9, ups=1.37, wpb=4186.7, bsz=158.7, num_updates=29600, lr=8.21995e-05, gnorm=0.955, clip=0, loss_scale=32, train_wall=73, gb_free=13.4, wall=27681
2023-07-01 18:57:27 | INFO | train_inner | epoch 021:    233 / 1474 loss=3.804, trans_loss=5.259, nll_loss=2.534, w2v_ctc_loss=1.184, task_loss=2, contrastive_loss=0.242, total=4166.37, n_correct=2726.76, ppl=5.79, accuracy=65.447, wps=5710.3, ups=1.37, wpb=4166.4, bsz=157.6, num_updates=29700, lr=8.2061e-05, gnorm=0.953, clip=0, loss_scale=32, train_wall=73, gb_free=14.3, wall=27754
2023-07-01 18:58:41 | INFO | train_inner | epoch 021:    333 / 1474 loss=3.832, trans_loss=5.273, nll_loss=2.551, w2v_ctc_loss=1.225, task_loss=2, contrastive_loss=0.246, total=4132.25, n_correct=2691.68, ppl=5.86, accuracy=65.138, wps=5603.2, ups=1.36, wpb=4132.2, bsz=152.5, num_updates=29800, lr=8.19232e-05, gnorm=0.962, clip=0, loss_scale=32, train_wall=73, gb_free=16.8, wall=27828
2023-07-01 18:59:53 | INFO | train_inner | epoch 021:    433 / 1474 loss=3.81, trans_loss=5.265, nll_loss=2.542, w2v_ctc_loss=1.203, task_loss=2, contrastive_loss=0.11, total=4195.53, n_correct=2741.3, ppl=5.82, accuracy=65.339, wps=5791.7, ups=1.38, wpb=4195.5, bsz=155.8, num_updates=29900, lr=8.17861e-05, gnorm=0.954, clip=0, loss_scale=32, train_wall=72, gb_free=16.7, wall=27901
2023-07-01 19:01:07 | INFO | train_inner | epoch 021:    533 / 1474 loss=3.817, trans_loss=5.263, nll_loss=2.539, w2v_ctc_loss=1.213, task_loss=2, contrastive_loss=0.099, total=4085.05, n_correct=2670.07, ppl=5.81, accuracy=65.362, wps=5554.9, ups=1.36, wpb=4085.1, bsz=148, num_updates=30000, lr=8.16497e-05, gnorm=0.958, clip=0, loss_scale=32, train_wall=73, gb_free=16.4, wall=27974
2023-07-01 19:01:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 19:01:33 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.349 | trans_loss 5.572 | nll_loss 2.85 | w2v_ctc_loss 1.386 | task_loss 0 | contrastive_loss 0.247 | total 4003.4 | n_correct 2480 | ppl 7.21 | accuracy 61.947 | uer 17.015 | wer 18.877 | raw_wer 18.877 | bleu 19.66 | wps 2099.3 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.33
2023-07-01 19:01:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-07-01 19:01:33 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_21_30000.pt
2023-07-01 19:01:35 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_21_30000.pt
2023-07-01 19:01:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 19.66) (writing took 5.896861511282623 seconds)
tensor(0.0258, device='cuda:0')
tensor(0.0002, device='cuda:0')
2023-07-01 19:02:53 | INFO | train_inner | epoch 021:    633 / 1474 loss=3.832, trans_loss=5.274, nll_loss=2.554, w2v_ctc_loss=1.197, task_loss=2, contrastive_loss=0.442, total=4220.3, n_correct=2753.77, ppl=5.87, accuracy=65.251, wps=3967.6, ups=0.94, wpb=4220.3, bsz=157.9, num_updates=30100, lr=8.15139e-05, gnorm=0.949, clip=0, loss_scale=32, train_wall=73, gb_free=15.9, wall=28081
2023-07-01 19:04:06 | INFO | train_inner | epoch 021:    733 / 1474 loss=3.818, trans_loss=5.274, nll_loss=2.554, w2v_ctc_loss=1.197, task_loss=2, contrastive_loss=0.163, total=4148.18, n_correct=2706.26, ppl=5.87, accuracy=65.24, wps=5643.1, ups=1.36, wpb=4148.2, bsz=154.2, num_updates=30200, lr=8.13788e-05, gnorm=0.946, clip=0, loss_scale=32, train_wall=73, gb_free=12.3, wall=28154
2023-07-01 19:05:21 | INFO | train_inner | epoch 021:    833 / 1474 loss=3.848, trans_loss=5.294, nll_loss=2.579, w2v_ctc_loss=1.225, task_loss=2, contrastive_loss=0.191, total=4062.56, n_correct=2632.55, ppl=5.98, accuracy=64.8, wps=5483.9, ups=1.35, wpb=4062.6, bsz=146.5, num_updates=30300, lr=8.12444e-05, gnorm=0.984, clip=0, loss_scale=32, train_wall=74, gb_free=16.5, wall=28228
2023-07-01 19:06:33 | INFO | train_inner | epoch 021:    933 / 1474 loss=3.828, trans_loss=5.278, nll_loss=2.559, w2v_ctc_loss=1.22, task_loss=2, contrastive_loss=0.134, total=4103.66, n_correct=2668.1, ppl=5.89, accuracy=65.018, wps=5671.1, ups=1.38, wpb=4103.7, bsz=150.7, num_updates=30400, lr=8.11107e-05, gnorm=0.966, clip=0, loss_scale=32, train_wall=72, gb_free=17.3, wall=28300
2023-07-01 19:07:45 | INFO | train_inner | epoch 021:   1033 / 1474 loss=3.842, trans_loss=5.294, nll_loss=2.58, w2v_ctc_loss=1.226, task_loss=2, contrastive_loss=0.129, total=4100.54, n_correct=2660.68, ppl=5.98, accuracy=64.886, wps=5661.4, ups=1.38, wpb=4100.5, bsz=149.1, num_updates=30500, lr=8.09776e-05, gnorm=0.972, clip=0, loss_scale=32, train_wall=72, gb_free=18, wall=28373
2023-07-01 19:08:58 | INFO | train_inner | epoch 021:   1133 / 1474 loss=3.838, trans_loss=5.284, nll_loss=2.566, w2v_ctc_loss=1.219, task_loss=2, contrastive_loss=0.136, total=4119.98, n_correct=2675.51, ppl=5.92, accuracy=64.94, wps=5663.4, ups=1.37, wpb=4120, bsz=147, num_updates=30600, lr=8.08452e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=72, gb_free=18, wall=28446
2023-07-01 19:10:11 | INFO | train_inner | epoch 021:   1233 / 1474 loss=3.833, trans_loss=5.282, nll_loss=2.566, w2v_ctc_loss=1.216, task_loss=2, contrastive_loss=0.24, total=4161.49, n_correct=2706.15, ppl=5.92, accuracy=65.028, wps=5671.2, ups=1.36, wpb=4161.5, bsz=156.5, num_updates=30700, lr=8.07134e-05, gnorm=0.943, clip=0, loss_scale=64, train_wall=73, gb_free=17, wall=28519
2023-07-01 19:11:25 | INFO | train_inner | epoch 021:   1333 / 1474 loss=3.82, trans_loss=5.278, nll_loss=2.561, w2v_ctc_loss=1.204, task_loss=2, contrastive_loss=0.161, total=4141.76, n_correct=2695.93, ppl=5.9, accuracy=65.091, wps=5667.3, ups=1.37, wpb=4141.8, bsz=155.8, num_updates=30800, lr=8.05823e-05, gnorm=0.953, clip=0, loss_scale=64, train_wall=73, gb_free=17.5, wall=28592
2023-07-01 19:12:38 | INFO | train_inner | epoch 021:   1433 / 1474 loss=3.868, trans_loss=5.307, nll_loss=2.597, w2v_ctc_loss=1.258, task_loss=2, contrastive_loss=0.258, total=4127.02, n_correct=2669.86, ppl=6.05, accuracy=64.692, wps=5591.7, ups=1.35, wpb=4127, bsz=151.1, num_updates=30900, lr=8.04518e-05, gnorm=0.971, clip=0, loss_scale=64, train_wall=73, gb_free=16.7, wall=28666
2023-07-01 19:13:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0258, device='cuda:2')
tensor(0.0002, device='cuda:2')
tensor(0.0258, device='cuda:1')
tensor(0.0002, device='cuda:1')
tensor(0.0258, device='cuda:4')
tensor(0.0002, device='cuda:4')
tensor(0.0258, device='cuda:5')
tensor(0.0002, device='cuda:5')
tensor(0.0258, device='cuda:6')
tensor(0.0002, device='cuda:6')
tensor(0.0258, device='cuda:7')
tensor(0.0002, device='cuda:7')
tensor(0.0258, device='cuda:3')
tensor(0.0002, device='cuda:3')
2023-07-01 19:13:35 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.337 | trans_loss 5.567 | nll_loss 2.845 | w2v_ctc_loss 1.359 | task_loss 0 | contrastive_loss 0.243 | total 4003.4 | n_correct 2480.6 | ppl 7.18 | accuracy 61.962 | uer 17.102 | wer 19.007 | raw_wer 19.007 | bleu 19.62 | wps 2031.3 | wpb 4003.4 | bsz 141.8 | num_updates 30941 | best_bleu 20.33
2023-07-01 19:13:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30941 updates
2023-07-01 19:13:35 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_last.pt
2023-07-01 19:13:39 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_last.pt
2023-07-01 19:13:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_last.pt (epoch 21 @ 30941 updates, score 19.62) (writing took 4.104691947810352 seconds)
2023-07-01 19:13:39 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-07-01 19:13:39 | INFO | train | epoch 021 | loss 3.83 | trans_loss 5.278 | nll_loss 2.559 | w2v_ctc_loss 1.213 | task_loss 2 | contrastive_loss 0.215 | total 4138.65 | n_correct 2694.97 | ppl 5.89 | accuracy 65.117 | wps 5302.5 | ups 1.28 | wpb 4138.6 | bsz 152.8 | num_updates 30941 | lr 8.03985e-05 | gnorm 0.96 | clip 0 | loss_scale 64 | train_wall 1073 | gb_free 15.6 | wall 28726
2023-07-01 19:13:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 19:13:39 | INFO | fairseq.trainer | begin training epoch 22
2023-07-01 19:13:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 19:14:30 | INFO | train_inner | epoch 022:     59 / 1474 loss=3.81, trans_loss=5.258, nll_loss=2.533, w2v_ctc_loss=1.202, task_loss=2, contrastive_loss=0.1, total=4140.16, n_correct=2708.83, ppl=5.79, accuracy=65.428, wps=3714.6, ups=0.9, wpb=4140.2, bsz=150.1, num_updates=31000, lr=8.03219e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=73, gb_free=17.8, wall=28777
2023-07-01 19:15:43 | INFO | train_inner | epoch 022:    159 / 1474 loss=3.808, trans_loss=5.249, nll_loss=2.522, w2v_ctc_loss=1.204, task_loss=2, contrastive_loss=0.264, total=4115.86, n_correct=2698.4, ppl=5.74, accuracy=65.561, wps=5594.7, ups=1.36, wpb=4115.9, bsz=154.7, num_updates=31100, lr=8.01927e-05, gnorm=0.965, clip=0, loss_scale=64, train_wall=73, gb_free=17.5, wall=28851
2023-07-01 19:16:56 | INFO | train_inner | epoch 022:    259 / 1474 loss=3.781, trans_loss=5.24, nll_loss=2.51, w2v_ctc_loss=1.173, task_loss=2, contrastive_loss=0.126, total=4247.73, n_correct=2790.75, ppl=5.7, accuracy=65.7, wps=5814.2, ups=1.37, wpb=4247.7, bsz=161.6, num_updates=31200, lr=8.00641e-05, gnorm=0.935, clip=0, loss_scale=64, train_wall=73, gb_free=14.2, wall=28924
2023-07-01 19:18:11 | INFO | train_inner | epoch 022:    359 / 1474 loss=3.83, trans_loss=5.264, nll_loss=2.542, w2v_ctc_loss=1.198, task_loss=2, contrastive_loss=0.47, total=4212.22, n_correct=2753.87, ppl=5.82, accuracy=65.378, wps=5666.7, ups=1.35, wpb=4212.2, bsz=159, num_updates=31300, lr=7.99361e-05, gnorm=0.959, clip=0, loss_scale=64, train_wall=74, gb_free=15.8, wall=28998
2023-07-01 19:19:25 | INFO | train_inner | epoch 022:    459 / 1474 loss=3.831, trans_loss=5.271, nll_loss=2.548, w2v_ctc_loss=1.206, task_loss=2, contrastive_loss=0.223, total=4131.12, n_correct=2695.21, ppl=5.85, accuracy=65.242, wps=5560.7, ups=1.35, wpb=4131.1, bsz=148.6, num_updates=31400, lr=7.98087e-05, gnorm=0.97, clip=0, loss_scale=64, train_wall=74, gb_free=16.6, wall=29073
2023-07-01 19:20:39 | INFO | train_inner | epoch 022:    559 / 1474 loss=3.812, trans_loss=5.259, nll_loss=2.534, w2v_ctc_loss=1.214, task_loss=2, contrastive_loss=0.125, total=4153.54, n_correct=2717.55, ppl=5.79, accuracy=65.427, wps=5643.1, ups=1.36, wpb=4153.5, bsz=153.6, num_updates=31500, lr=7.96819e-05, gnorm=0.972, clip=0, loss_scale=64, train_wall=73, gb_free=15.2, wall=29146
2023-07-01 19:21:51 | INFO | train_inner | epoch 022:    659 / 1474 loss=3.796, trans_loss=5.248, nll_loss=2.521, w2v_ctc_loss=1.169, task_loss=2, contrastive_loss=0.29, total=4143.91, n_correct=2717.27, ppl=5.74, accuracy=65.573, wps=5728.8, ups=1.38, wpb=4143.9, bsz=156.6, num_updates=31600, lr=7.95557e-05, gnorm=0.953, clip=0, loss_scale=64, train_wall=72, gb_free=16, wall=29219
2023-07-01 19:23:05 | INFO | train_inner | epoch 022:    759 / 1474 loss=3.811, trans_loss=5.256, nll_loss=2.53, w2v_ctc_loss=1.207, task_loss=2, contrastive_loss=0.127, total=4168.91, n_correct=2727.53, ppl=5.77, accuracy=65.425, wps=5668.8, ups=1.36, wpb=4168.9, bsz=151.8, num_updates=31700, lr=7.94301e-05, gnorm=0.96, clip=0, loss_scale=64, train_wall=73, gb_free=17.7, wall=29292
2023-07-01 19:24:18 | INFO | train_inner | epoch 022:    859 / 1474 loss=3.822, trans_loss=5.267, nll_loss=2.545, w2v_ctc_loss=1.205, task_loss=2, contrastive_loss=0.101, total=4079.59, n_correct=2662.24, ppl=5.83, accuracy=65.258, wps=5520.5, ups=1.35, wpb=4079.6, bsz=144.3, num_updates=31800, lr=7.93052e-05, gnorm=0.979, clip=0, loss_scale=64, train_wall=73, gb_free=17.4, wall=29366
2023-07-01 19:25:32 | INFO | train_inner | epoch 022:    959 / 1474 loss=3.804, trans_loss=5.261, nll_loss=2.537, w2v_ctc_loss=1.186, task_loss=2, contrastive_loss=0.104, total=4129.75, n_correct=2701.25, ppl=5.81, accuracy=65.41, wps=5654, ups=1.37, wpb=4129.8, bsz=151.9, num_updates=31900, lr=7.91808e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=73, gb_free=17.9, wall=29439
2023-07-01 19:26:44 | INFO | train_inner | epoch 022:   1059 / 1474 loss=3.813, trans_loss=5.26, nll_loss=2.537, w2v_ctc_loss=1.178, task_loss=2, contrastive_loss=0.443, total=4155.56, n_correct=2721.08, ppl=5.8, accuracy=65.48, wps=5710.6, ups=1.37, wpb=4155.6, bsz=157.7, num_updates=32000, lr=7.90569e-05, gnorm=0.952, clip=0, loss_scale=64, train_wall=72, gb_free=17.2, wall=29512
2023-07-01 19:26:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 19:27:11 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.346 | trans_loss 5.568 | nll_loss 2.848 | w2v_ctc_loss 1.384 | task_loss 0 | contrastive_loss 0.248 | total 4003.4 | n_correct 2475.1 | ppl 7.2 | accuracy 61.825 | uer 17.055 | wer 18.713 | raw_wer 18.713 | bleu 19.7 | wps 1995.4 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.33
2023-07-01 19:27:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-07-01 19:27:11 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_22_32000.pt
2023-07-01 19:27:13 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_22_32000.pt
2023-07-01 19:27:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 19.7) (writing took 6.168914586305618 seconds)
2023-07-01 19:28:30 | INFO | train_inner | epoch 022:   1159 / 1474 loss=3.844, trans_loss=5.287, nll_loss=2.572, w2v_ctc_loss=1.216, task_loss=2, contrastive_loss=0.204, total=4089.92, n_correct=2656.6, ppl=5.95, accuracy=64.955, wps=3853.7, ups=0.94, wpb=4089.9, bsz=146.1, num_updates=32100, lr=7.89337e-05, gnorm=0.969, clip=0, loss_scale=64, train_wall=73, gb_free=16.4, wall=29618
2023-07-01 19:29:44 | INFO | train_inner | epoch 022:   1259 / 1474 loss=3.819, trans_loss=5.279, nll_loss=2.562, w2v_ctc_loss=1.208, task_loss=2, contrastive_loss=0.196, total=4179.82, n_correct=2719.84, ppl=5.9, accuracy=65.071, wps=5718.1, ups=1.37, wpb=4179.8, bsz=161.2, num_updates=32200, lr=7.8811e-05, gnorm=0.948, clip=0, loss_scale=64, train_wall=73, gb_free=16.6, wall=29691
2023-07-01 19:30:56 | INFO | train_inner | epoch 022:   1359 / 1474 loss=3.812, trans_loss=5.264, nll_loss=2.543, w2v_ctc_loss=1.188, task_loss=2, contrastive_loss=0.24, total=4076.98, n_correct=2666.15, ppl=5.83, accuracy=65.395, wps=5638.4, ups=1.38, wpb=4077, bsz=151.5, num_updates=32300, lr=7.86889e-05, gnorm=0.965, clip=0, loss_scale=64, train_wall=72, gb_free=11.2, wall=29763
2023-07-01 19:32:09 | INFO | train_inner | epoch 022:   1459 / 1474 loss=3.84, trans_loss=5.281, nll_loss=2.563, w2v_ctc_loss=1.222, task_loss=2, contrastive_loss=0.131, total=4070.93, n_correct=2647.79, ppl=5.91, accuracy=65.041, wps=5552.2, ups=1.36, wpb=4070.9, bsz=143.2, num_updates=32400, lr=7.85674e-05, gnorm=0.977, clip=0, loss_scale=64, train_wall=73, gb_free=16.9, wall=29837
2023-07-01 19:32:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 19:32:50 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.345 | trans_loss 5.571 | nll_loss 2.843 | w2v_ctc_loss 1.376 | task_loss 0 | contrastive_loss 0.249 | total 4003.4 | n_correct 2482 | ppl 7.17 | accuracy 61.997 | uer 17.004 | wer 18.747 | raw_wer 18.747 | bleu 20 | wps 1803 | wpb 4003.4 | bsz 141.8 | num_updates 32415 | best_bleu 20.33
2023-07-01 19:32:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32415 updates
2023-07-01 19:32:50 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_20.0005.pt
2023-07-01 19:32:53 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_20.0005.pt
2023-07-01 19:32:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_20.0005.pt (epoch 22 @ 32415 updates, score 20.0) (writing took 5.143702716100961 seconds)
2023-07-01 19:32:56 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-07-01 19:32:56 | INFO | train | epoch 022 | loss 3.815 | trans_loss 5.262 | nll_loss 2.539 | w2v_ctc_loss 1.198 | task_loss 2 | contrastive_loss 0.214 | total 4138.65 | n_correct 2705.23 | ppl 5.81 | accuracy 65.365 | wps 5272.6 | ups 1.27 | wpb 4138.6 | bsz 152.8 | num_updates 32415 | lr 7.85492e-05 | gnorm 0.962 | clip 0 | loss_scale 64 | train_wall 1074 | gb_free 12.2 | wall 29883
2023-07-01 19:32:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 19:32:56 | INFO | fairseq.trainer | begin training epoch 23
2023-07-01 19:32:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 19:34:06 | INFO | train_inner | epoch 023:     85 / 1474 loss=3.794, trans_loss=5.238, nll_loss=2.508, w2v_ctc_loss=1.199, task_loss=2, contrastive_loss=0.116, total=4094.01, n_correct=2693.16, ppl=5.69, accuracy=65.783, wps=3503.7, ups=0.86, wpb=4094, bsz=150.5, num_updates=32500, lr=7.84465e-05, gnorm=0.964, clip=0, loss_scale=64, train_wall=73, gb_free=16.6, wall=29954
2023-07-01 19:35:19 | INFO | train_inner | epoch 023:    185 / 1474 loss=3.79, trans_loss=5.232, nll_loss=2.498, w2v_ctc_loss=1.184, task_loss=2, contrastive_loss=0.113, total=4118.15, n_correct=2713.77, ppl=5.65, accuracy=65.898, wps=5643.9, ups=1.37, wpb=4118.1, bsz=148.1, num_updates=32600, lr=7.8326e-05, gnorm=0.966, clip=0, loss_scale=64, train_wall=73, gb_free=15.6, wall=30027
2023-07-01 19:36:33 | INFO | train_inner | epoch 023:    285 / 1474 loss=3.802, trans_loss=5.243, nll_loss=2.514, w2v_ctc_loss=1.179, task_loss=2, contrastive_loss=0.267, total=4156.76, n_correct=2729.15, ppl=5.71, accuracy=65.656, wps=5633.5, ups=1.36, wpb=4156.8, bsz=152.8, num_updates=32700, lr=7.82062e-05, gnorm=0.954, clip=0, loss_scale=128, train_wall=73, gb_free=16.2, wall=30100
2023-07-01 19:37:46 | INFO | train_inner | epoch 023:    385 / 1474 loss=3.792, trans_loss=5.238, nll_loss=2.507, w2v_ctc_loss=1.177, task_loss=2, contrastive_loss=0.099, total=4114.42, n_correct=2706, ppl=5.69, accuracy=65.769, wps=5591.7, ups=1.36, wpb=4114.4, bsz=147.5, num_updates=32800, lr=7.80869e-05, gnorm=0.961, clip=0, loss_scale=128, train_wall=73, gb_free=13.4, wall=30174
2023-07-01 19:38:59 | INFO | train_inner | epoch 023:    485 / 1474 loss=3.791, trans_loss=5.241, nll_loss=2.511, w2v_ctc_loss=1.176, task_loss=2, contrastive_loss=0.209, total=4156.07, n_correct=2731.13, ppl=5.7, accuracy=65.714, wps=5719.7, ups=1.38, wpb=4156.1, bsz=156.3, num_updates=32900, lr=7.79681e-05, gnorm=0.962, clip=0, loss_scale=128, train_wall=72, gb_free=15.8, wall=30247
2023-07-01 19:40:12 | INFO | train_inner | epoch 023:    585 / 1474 loss=3.776, trans_loss=5.231, nll_loss=2.498, w2v_ctc_loss=1.176, task_loss=2, contrastive_loss=0.106, total=4169.74, n_correct=2746.38, ppl=5.65, accuracy=65.865, wps=5721.6, ups=1.37, wpb=4169.7, bsz=157.4, num_updates=33000, lr=7.78499e-05, gnorm=0.967, clip=0, loss_scale=128, train_wall=72, gb_free=16.7, wall=30320
2023-07-01 19:40:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-01 19:41:26 | INFO | train_inner | epoch 023:    686 / 1474 loss=3.793, trans_loss=5.237, nll_loss=2.506, w2v_ctc_loss=1.186, task_loss=2, contrastive_loss=0.104, total=4123.62, n_correct=2710.21, ppl=5.68, accuracy=65.724, wps=5576.5, ups=1.35, wpb=4123.6, bsz=148.6, num_updates=33100, lr=7.77322e-05, gnorm=0.954, clip=0, loss_scale=64, train_wall=74, gb_free=17.8, wall=30393
2023-07-01 19:42:39 | INFO | train_inner | epoch 023:    786 / 1474 loss=3.806, trans_loss=5.253, nll_loss=2.527, w2v_ctc_loss=1.197, task_loss=2, contrastive_loss=0.144, total=4147.22, n_correct=2718.98, ppl=5.76, accuracy=65.562, wps=5691.9, ups=1.37, wpb=4147.2, bsz=152.6, num_updates=33200, lr=7.76151e-05, gnorm=0.968, clip=0, loss_scale=64, train_wall=72, gb_free=17.4, wall=30466
2023-07-01 19:43:51 | INFO | train_inner | epoch 023:    886 / 1474 loss=3.79, trans_loss=5.24, nll_loss=2.513, w2v_ctc_loss=1.181, task_loss=2, contrastive_loss=0.304, total=4193.16, n_correct=2758.35, ppl=5.71, accuracy=65.782, wps=5768, ups=1.38, wpb=4193.2, bsz=163.6, num_updates=33300, lr=7.74984e-05, gnorm=0.964, clip=0, loss_scale=64, train_wall=72, gb_free=16.2, wall=30539
2023-07-01 19:45:05 | INFO | train_inner | epoch 023:    986 / 1474 loss=3.822, trans_loss=5.253, nll_loss=2.528, w2v_ctc_loss=1.174, task_loss=2, contrastive_loss=0.622, total=4164.33, n_correct=2727.03, ppl=5.77, accuracy=65.485, wps=5690.1, ups=1.37, wpb=4164.3, bsz=155.1, num_updates=33400, lr=7.73823e-05, gnorm=0.966, clip=0, loss_scale=64, train_wall=73, gb_free=17.8, wall=30612
2023-07-01 19:46:19 | INFO | train_inner | epoch 023:   1086 / 1474 loss=3.821, trans_loss=5.257, nll_loss=2.533, w2v_ctc_loss=1.217, task_loss=2, contrastive_loss=0.121, total=4088.37, n_correct=2674.93, ppl=5.79, accuracy=65.428, wps=5483.8, ups=1.34, wpb=4088.4, bsz=144.8, num_updates=33500, lr=7.72667e-05, gnorm=0.972, clip=0, loss_scale=64, train_wall=74, gb_free=15.8, wall=30687
2023-07-01 19:47:33 | INFO | train_inner | epoch 023:   1186 / 1474 loss=3.804, trans_loss=5.254, nll_loss=2.53, w2v_ctc_loss=1.204, task_loss=2, contrastive_loss=0.108, total=4162.3, n_correct=2723.02, ppl=5.77, accuracy=65.421, wps=5654.4, ups=1.36, wpb=4162.3, bsz=154.5, num_updates=33600, lr=7.71517e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=73, gb_free=15.8, wall=30760
2023-07-01 19:48:46 | INFO | train_inner | epoch 023:   1286 / 1474 loss=3.791, trans_loss=5.247, nll_loss=2.52, w2v_ctc_loss=1.176, task_loss=2, contrastive_loss=0.129, total=4131.74, n_correct=2713.48, ppl=5.74, accuracy=65.674, wps=5677.5, ups=1.37, wpb=4131.7, bsz=154.4, num_updates=33700, lr=7.70371e-05, gnorm=0.947, clip=0, loss_scale=64, train_wall=72, gb_free=17.2, wall=30833
2023-07-01 19:50:00 | INFO | train_inner | epoch 023:   1386 / 1474 loss=3.826, trans_loss=5.274, nll_loss=2.555, w2v_ctc_loss=1.196, task_loss=2, contrastive_loss=0.244, total=4141.25, n_correct=2702.39, ppl=5.88, accuracy=65.255, wps=5603.3, ups=1.35, wpb=4141.2, bsz=152.4, num_updates=33800, lr=7.69231e-05, gnorm=0.97, clip=0, loss_scale=64, train_wall=73, gb_free=17, wall=30907
2023-07-01 19:50:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-01 19:51:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 19:51:28 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.359 | trans_loss 5.557 | nll_loss 2.834 | w2v_ctc_loss 1.451 | task_loss 0 | contrastive_loss 0.252 | total 4003.4 | n_correct 2484.4 | ppl 7.13 | accuracy 62.057 | uer 17.036 | wer 18.993 | raw_wer 18.993 | bleu 19.68 | wps 2301.2 | wpb 4003.4 | bsz 141.8 | num_updates 33887 | best_bleu 20.33
2023-07-01 19:51:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33887 updates
2023-07-01 19:51:28 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_last.pt
2023-07-01 19:51:32 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_last.pt
2023-07-01 19:51:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_last.pt (epoch 23 @ 33887 updates, score 19.68) (writing took 4.450646601151675 seconds)
2023-07-01 19:51:33 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-07-01 19:51:33 | INFO | train | epoch 023 | loss 3.801 | trans_loss 5.247 | nll_loss 2.519 | w2v_ctc_loss 1.188 | task_loss 2 | contrastive_loss 0.193 | total 4135.72 | n_correct 2714.1 | ppl 5.73 | accuracy 65.626 | wps 5450.7 | ups 1.32 | wpb 4135.7 | bsz 152.3 | num_updates 33887 | lr 7.68243e-05 | gnorm 0.963 | clip 0 | loss_scale 32 | train_wall 1073 | gb_free 14.1 | wall 31000
2023-07-01 19:51:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 19:51:33 | INFO | fairseq.trainer | begin training epoch 24
2023-07-01 19:51:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 19:51:51 | INFO | train_inner | epoch 024:     13 / 1474 loss=3.815, trans_loss=5.263, nll_loss=2.542, w2v_ctc_loss=1.193, task_loss=2, contrastive_loss=0.169, total=4062.78, n_correct=2654.98, ppl=5.82, accuracy=65.349, wps=3660.4, ups=0.9, wpb=4062.8, bsz=147.6, num_updates=33900, lr=7.68095e-05, gnorm=0.978, clip=0, loss_scale=32, train_wall=73, gb_free=13, wall=31018
2023-07-01 19:53:04 | INFO | train_inner | epoch 024:    113 / 1474 loss=3.776, trans_loss=5.217, nll_loss=2.482, w2v_ctc_loss=1.157, task_loss=2, contrastive_loss=0.43, total=4171.44, n_correct=2758.62, ppl=5.58, accuracy=66.131, wps=5699, ups=1.37, wpb=4171.4, bsz=162.3, num_updates=34000, lr=7.66965e-05, gnorm=0.95, clip=0, loss_scale=32, train_wall=73, gb_free=16.6, wall=31091
2023-07-01 19:53:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 19:53:28 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.342 | trans_loss 5.56 | nll_loss 2.831 | w2v_ctc_loss 1.392 | task_loss 0 | contrastive_loss 0.247 | total 4003.4 | n_correct 2481.4 | ppl 7.12 | accuracy 61.982 | uer 16.97 | wer 18.791 | raw_wer 18.791 | bleu 19.87 | wps 2226.8 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.33
2023-07-01 19:53:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-07-01 19:53:28 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_24_34000.pt
2023-07-01 19:53:30 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_24_34000.pt
2023-07-01 19:53:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 19.87) (writing took 5.888953333720565 seconds)
2023-07-01 19:54:48 | INFO | train_inner | epoch 024:    213 / 1474 loss=3.772, trans_loss=5.22, nll_loss=2.486, w2v_ctc_loss=1.139, task_loss=2, contrastive_loss=0.537, total=4251.29, n_correct=2808.42, ppl=5.6, accuracy=66.06, wps=4066.5, ups=0.96, wpb=4251.3, bsz=170.4, num_updates=34100, lr=7.6584e-05, gnorm=0.945, clip=0, loss_scale=32, train_wall=73, gb_free=16.9, wall=31196
2023-07-01 19:56:02 | INFO | train_inner | epoch 024:    313 / 1474 loss=3.768, trans_loss=5.217, nll_loss=2.48, w2v_ctc_loss=1.166, task_loss=2, contrastive_loss=0.101, total=4128.18, n_correct=2731.99, ppl=5.58, accuracy=66.179, wps=5593.6, ups=1.35, wpb=4128.2, bsz=152.8, num_updates=34200, lr=7.64719e-05, gnorm=0.939, clip=0, loss_scale=32, train_wall=73, gb_free=16.3, wall=31270
2023-07-01 19:57:16 | INFO | train_inner | epoch 024:    413 / 1474 loss=3.82, trans_loss=5.243, nll_loss=2.514, w2v_ctc_loss=1.197, task_loss=2, contrastive_loss=0.386, total=4158.92, n_correct=2730.35, ppl=5.71, accuracy=65.65, wps=5660.8, ups=1.36, wpb=4158.9, bsz=149.9, num_updates=34300, lr=7.63604e-05, gnorm=0.974, clip=0, loss_scale=32, train_wall=73, gb_free=16.8, wall=31343
2023-07-01 19:58:29 | INFO | train_inner | epoch 024:    513 / 1474 loss=3.797, trans_loss=5.235, nll_loss=2.503, w2v_ctc_loss=1.188, task_loss=2, contrastive_loss=0.239, total=4144.91, n_correct=2731.85, ppl=5.67, accuracy=65.909, wps=5676, ups=1.37, wpb=4144.9, bsz=151.6, num_updates=34400, lr=7.62493e-05, gnorm=0.957, clip=0, loss_scale=32, train_wall=73, gb_free=17.1, wall=31416
2023-07-01 19:59:43 | INFO | train_inner | epoch 024:    613 / 1474 loss=3.78, trans_loss=5.226, nll_loss=2.494, w2v_ctc_loss=1.165, task_loss=2, contrastive_loss=0.165, total=4165.3, n_correct=2745.3, ppl=5.63, accuracy=65.909, wps=5629.8, ups=1.35, wpb=4165.3, bsz=153.8, num_updates=34500, lr=7.61387e-05, gnorm=0.957, clip=0, loss_scale=32, train_wall=74, gb_free=16, wall=31490
2023-07-01 20:00:56 | INFO | train_inner | epoch 024:    713 / 1474 loss=3.801, trans_loss=5.239, nll_loss=2.509, w2v_ctc_loss=1.186, task_loss=2, contrastive_loss=0.189, total=4102.21, n_correct=2695.67, ppl=5.69, accuracy=65.713, wps=5620.7, ups=1.37, wpb=4102.2, bsz=147.5, num_updates=34600, lr=7.60286e-05, gnorm=0.979, clip=0, loss_scale=32, train_wall=73, gb_free=17.2, wall=31563
2023-07-01 20:02:09 | INFO | train_inner | epoch 024:    813 / 1474 loss=3.782, trans_loss=5.233, nll_loss=2.503, w2v_ctc_loss=1.17, task_loss=2, contrastive_loss=0.14, total=4110.6, n_correct=2707.54, ppl=5.67, accuracy=65.867, wps=5613.7, ups=1.37, wpb=4110.6, bsz=152.7, num_updates=34700, lr=7.5919e-05, gnorm=0.958, clip=0, loss_scale=32, train_wall=73, gb_free=16.8, wall=31636
2023-07-01 20:03:22 | INFO | train_inner | epoch 024:    913 / 1474 loss=3.808, trans_loss=5.245, nll_loss=2.516, w2v_ctc_loss=1.195, task_loss=2, contrastive_loss=0.093, total=4043.03, n_correct=2649.42, ppl=5.72, accuracy=65.531, wps=5559, ups=1.37, wpb=4043, bsz=140.5, num_updates=34800, lr=7.58098e-05, gnorm=0.969, clip=0, loss_scale=32, train_wall=72, gb_free=11.7, wall=31709
2023-07-01 20:04:35 | INFO | train_inner | epoch 024:   1013 / 1474 loss=3.786, trans_loss=5.237, nll_loss=2.507, w2v_ctc_loss=1.162, task_loss=2, contrastive_loss=0.102, total=4136.81, n_correct=2721.83, ppl=5.69, accuracy=65.795, wps=5606.1, ups=1.36, wpb=4136.8, bsz=149.2, num_updates=34900, lr=7.57011e-05, gnorm=0.962, clip=0, loss_scale=32, train_wall=73, gb_free=17.1, wall=31783
2023-07-01 20:05:49 | INFO | train_inner | epoch 024:   1113 / 1474 loss=3.786, trans_loss=5.228, nll_loss=2.496, w2v_ctc_loss=1.186, task_loss=2, contrastive_loss=0.189, total=4135.73, n_correct=2724.11, ppl=5.64, accuracy=65.868, wps=5627.9, ups=1.36, wpb=4135.7, bsz=154.4, num_updates=35000, lr=7.55929e-05, gnorm=0.957, clip=0, loss_scale=32, train_wall=73, gb_free=17.2, wall=31856
tensor(0.0258, device='cuda:0')
tensor(0.0002, device='cuda:0')
2023-07-01 20:07:02 | INFO | train_inner | epoch 024:   1213 / 1474 loss=3.786, trans_loss=5.241, nll_loss=2.513, w2v_ctc_loss=1.165, task_loss=2, contrastive_loss=0.163, total=4148.3, n_correct=2725.15, ppl=5.71, accuracy=65.693, wps=5649.2, ups=1.36, wpb=4148.3, bsz=155.4, num_updates=35100, lr=7.54851e-05, gnorm=0.975, clip=0, loss_scale=32, train_wall=73, gb_free=16.8, wall=31930
2023-07-01 20:08:17 | INFO | train_inner | epoch 024:   1313 / 1474 loss=3.805, trans_loss=5.248, nll_loss=2.522, w2v_ctc_loss=1.192, task_loss=2, contrastive_loss=0.111, total=4110.05, n_correct=2693.48, ppl=5.74, accuracy=65.534, wps=5524.1, ups=1.34, wpb=4110.1, bsz=147.1, num_updates=35200, lr=7.53778e-05, gnorm=0.974, clip=0, loss_scale=32, train_wall=74, gb_free=17.4, wall=32004
2023-07-01 20:09:30 | INFO | train_inner | epoch 024:   1413 / 1474 loss=3.804, trans_loss=5.246, nll_loss=2.52, w2v_ctc_loss=1.195, task_loss=2, contrastive_loss=0.107, total=4090.91, n_correct=2687.05, ppl=5.74, accuracy=65.683, wps=5604.4, ups=1.37, wpb=4090.9, bsz=146.4, num_updates=35300, lr=7.5271e-05, gnorm=0.964, clip=0, loss_scale=32, train_wall=73, gb_free=16.6, wall=32077
2023-07-01 20:10:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0258, device='cuda:7')
tensor(0.0002, device='cuda:7')
tensor(0.0258, device='cuda:5')
tensor(0.0002, device='cuda:5')
tensor(0.0258, device='cuda:4')
tensor(0.0002, device='cuda:4')
tensor(0.0258, device='cuda:6')
tensor(0.0002, device='cuda:6')
tensor(0.0258, device='cuda:1')
tensor(0.0002, device='cuda:1')
tensor(0.0258, device='cuda:2')
tensor(0.0002, device='cuda:2')
tensor(0.0258, device='cuda:3')
tensor(0.0002, device='cuda:3')
2023-07-01 20:10:40 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.349 | trans_loss 5.561 | nll_loss 2.831 | w2v_ctc_loss 1.41 | task_loss 0 | contrastive_loss 0.251 | total 4003.4 | n_correct 2487.4 | ppl 7.12 | accuracy 62.132 | uer 16.967 | wer 18.881 | raw_wer 18.881 | bleu 20.16 | wps 2215.9 | wpb 4003.4 | bsz 141.8 | num_updates 35361 | best_bleu 20.33
2023-07-01 20:10:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35361 updates
2023-07-01 20:10:40 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_20.1600.pt
2023-07-01 20:10:42 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_20.1600.pt
2023-07-01 20:10:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_20.1600.pt (epoch 24 @ 35361 updates, score 20.16) (writing took 5.164534580893815 seconds)
2023-07-01 20:10:45 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-07-01 20:10:45 | INFO | train | epoch 024 | loss 3.79 | trans_loss 5.234 | nll_loss 2.503 | w2v_ctc_loss 1.175 | task_loss 2 | contrastive_loss 0.211 | total 4138.65 | n_correct 2724.46 | ppl 5.67 | accuracy 65.83 | wps 5291.2 | ups 1.28 | wpb 4138.6 | bsz 152.8 | num_updates 35361 | lr 7.5206e-05 | gnorm 0.961 | clip 0 | loss_scale 32 | train_wall 1076 | gb_free 16.3 | wall 32153
2023-07-01 20:10:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 20:10:46 | INFO | fairseq.trainer | begin training epoch 25
2023-07-01 20:10:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 20:11:22 | INFO | train_inner | epoch 025:     39 / 1474 loss=3.767, trans_loss=5.218, nll_loss=2.483, w2v_ctc_loss=1.162, task_loss=2, contrastive_loss=0.124, total=4166.95, n_correct=2754.51, ppl=5.59, accuracy=66.104, wps=3717.4, ups=0.89, wpb=4166.9, bsz=156, num_updates=35400, lr=7.51646e-05, gnorm=0.954, clip=0, loss_scale=32, train_wall=72, gb_free=16.6, wall=32189
2023-07-01 20:12:35 | INFO | train_inner | epoch 025:    139 / 1474 loss=3.751, trans_loss=5.201, nll_loss=2.46, w2v_ctc_loss=1.146, task_loss=2, contrastive_loss=0.118, total=4133.64, n_correct=2742.68, ppl=5.5, accuracy=66.35, wps=5641.7, ups=1.36, wpb=4133.6, bsz=153.9, num_updates=35500, lr=7.50587e-05, gnorm=0.96, clip=0, loss_scale=32, train_wall=73, gb_free=16, wall=32263
2023-07-01 20:13:50 | INFO | train_inner | epoch 025:    239 / 1474 loss=3.766, trans_loss=5.209, nll_loss=2.47, w2v_ctc_loss=1.164, task_loss=2, contrastive_loss=0.126, total=4114.53, n_correct=2722.32, ppl=5.54, accuracy=66.164, wps=5510.6, ups=1.34, wpb=4114.5, bsz=151.4, num_updates=35600, lr=7.49532e-05, gnorm=0.961, clip=0, loss_scale=32, train_wall=74, gb_free=17.2, wall=32337
2023-07-01 20:15:03 | INFO | train_inner | epoch 025:    339 / 1474 loss=3.78, trans_loss=5.216, nll_loss=2.478, w2v_ctc_loss=1.162, task_loss=2, contrastive_loss=0.186, total=4148.7, n_correct=2739.02, ppl=5.57, accuracy=66.021, wps=5627.6, ups=1.36, wpb=4148.7, bsz=147.6, num_updates=35700, lr=7.48481e-05, gnorm=0.951, clip=0, loss_scale=32, train_wall=73, gb_free=16.8, wall=32411
2023-07-01 20:16:17 | INFO | train_inner | epoch 025:    439 / 1474 loss=3.8, trans_loss=5.222, nll_loss=2.487, w2v_ctc_loss=1.184, task_loss=2, contrastive_loss=0.341, total=4167.03, n_correct=2751.55, ppl=5.61, accuracy=66.031, wps=5660.4, ups=1.36, wpb=4167, bsz=149.2, num_updates=35800, lr=7.47435e-05, gnorm=0.97, clip=0, loss_scale=32, train_wall=73, gb_free=12.7, wall=32485
2023-07-01 20:17:31 | INFO | train_inner | epoch 025:    539 / 1474 loss=3.772, trans_loss=5.223, nll_loss=2.49, w2v_ctc_loss=1.168, task_loss=2, contrastive_loss=0.126, total=4156.93, n_correct=2746.12, ppl=5.62, accuracy=66.061, wps=5646.2, ups=1.36, wpb=4156.9, bsz=156.4, num_updates=35900, lr=7.46393e-05, gnorm=0.953, clip=0, loss_scale=64, train_wall=73, gb_free=17.2, wall=32558
2023-07-01 20:18:44 | INFO | train_inner | epoch 025:    639 / 1474 loss=3.772, trans_loss=5.214, nll_loss=2.478, w2v_ctc_loss=1.16, task_loss=2, contrastive_loss=0.26, total=4153.23, n_correct=2750.52, ppl=5.57, accuracy=66.226, wps=5665.1, ups=1.36, wpb=4153.2, bsz=154.8, num_updates=36000, lr=7.45356e-05, gnorm=0.955, clip=0, loss_scale=64, train_wall=73, gb_free=15.1, wall=32632
2023-07-01 20:18:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 20:19:09 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.345 | trans_loss 5.561 | nll_loss 2.834 | w2v_ctc_loss 1.397 | task_loss 0 | contrastive_loss 0.25 | total 4003.4 | n_correct 2488.1 | ppl 7.13 | accuracy 62.15 | uer 16.81 | wer 18.773 | raw_wer 18.773 | bleu 19.85 | wps 2251.8 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.33
2023-07-01 20:19:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-07-01 20:19:09 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_25_36000.pt
2023-07-01 20:19:11 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_25_36000.pt
2023-07-01 20:19:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 19.85) (writing took 4.898516604211181 seconds)
2023-07-01 20:20:27 | INFO | train_inner | epoch 025:    739 / 1474 loss=3.782, trans_loss=5.219, nll_loss=2.483, w2v_ctc_loss=1.161, task_loss=2, contrastive_loss=0.25, total=4123.21, n_correct=2726.79, ppl=5.59, accuracy=66.133, wps=4012.3, ups=0.97, wpb=4123.2, bsz=150.4, num_updates=36100, lr=7.44323e-05, gnorm=0.962, clip=0, loss_scale=64, train_wall=73, gb_free=15, wall=32734
2023-07-01 20:21:40 | INFO | train_inner | epoch 025:    839 / 1474 loss=3.758, trans_loss=5.219, nll_loss=2.485, w2v_ctc_loss=1.157, task_loss=2, contrastive_loss=0.145, total=4197.27, n_correct=2774.3, ppl=5.6, accuracy=66.098, wps=5747, ups=1.37, wpb=4197.3, bsz=164.1, num_updates=36200, lr=7.43294e-05, gnorm=0.955, clip=0, loss_scale=64, train_wall=73, gb_free=16.3, wall=32807
2023-07-01 20:22:54 | INFO | train_inner | epoch 025:    939 / 1474 loss=3.778, trans_loss=5.222, nll_loss=2.489, w2v_ctc_loss=1.168, task_loss=2, contrastive_loss=0.259, total=4137.23, n_correct=2732.31, ppl=5.61, accuracy=66.042, wps=5586.8, ups=1.35, wpb=4137.2, bsz=156.7, num_updates=36300, lr=7.4227e-05, gnorm=0.958, clip=0, loss_scale=64, train_wall=74, gb_free=16.8, wall=32881
2023-07-01 20:24:07 | INFO | train_inner | epoch 025:   1039 / 1474 loss=3.799, trans_loss=5.237, nll_loss=2.508, w2v_ctc_loss=1.155, task_loss=2, contrastive_loss=0.477, total=4183.45, n_correct=2749.94, ppl=5.69, accuracy=65.734, wps=5686.9, ups=1.36, wpb=4183.4, bsz=155.5, num_updates=36400, lr=7.41249e-05, gnorm=0.952, clip=0, loss_scale=64, train_wall=73, gb_free=16.9, wall=32955
2023-07-01 20:25:20 | INFO | train_inner | epoch 025:   1139 / 1474 loss=3.785, trans_loss=5.228, nll_loss=2.496, w2v_ctc_loss=1.167, task_loss=2, contrastive_loss=0.096, total=4045.24, n_correct=2666.59, ppl=5.64, accuracy=65.919, wps=5542.4, ups=1.37, wpb=4045.2, bsz=143.5, num_updates=36500, lr=7.40233e-05, gnorm=0.977, clip=0, loss_scale=64, train_wall=73, gb_free=16.5, wall=33028
2023-07-01 20:26:34 | INFO | train_inner | epoch 025:   1239 / 1474 loss=3.788, trans_loss=5.234, nll_loss=2.504, w2v_ctc_loss=1.171, task_loss=2, contrastive_loss=0.102, total=4079.17, n_correct=2685.73, ppl=5.67, accuracy=65.84, wps=5577.1, ups=1.37, wpb=4079.2, bsz=146.2, num_updates=36600, lr=7.39221e-05, gnorm=0.972, clip=0, loss_scale=64, train_wall=73, gb_free=17.2, wall=33101
2023-07-01 20:27:47 | INFO | train_inner | epoch 025:   1339 / 1474 loss=3.78, trans_loss=5.225, nll_loss=2.493, w2v_ctc_loss=1.156, task_loss=2, contrastive_loss=0.306, total=4173.55, n_correct=2758.74, ppl=5.63, accuracy=66.101, wps=5688.9, ups=1.36, wpb=4173.6, bsz=156.3, num_updates=36700, lr=7.38213e-05, gnorm=0.954, clip=0, loss_scale=64, train_wall=73, gb_free=16.9, wall=33175
2023-07-01 20:29:01 | INFO | train_inner | epoch 025:   1439 / 1474 loss=3.807, trans_loss=5.252, nll_loss=2.528, w2v_ctc_loss=1.184, task_loss=2, contrastive_loss=0.203, total=4102.27, n_correct=2685.37, ppl=5.77, accuracy=65.461, wps=5548.9, ups=1.35, wpb=4102.3, bsz=149.9, num_updates=36800, lr=7.3721e-05, gnorm=0.974, clip=0, loss_scale=64, train_wall=73, gb_free=16.2, wall=33248
2023-07-01 20:29:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 20:29:53 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.344 | trans_loss 5.559 | nll_loss 2.832 | w2v_ctc_loss 1.395 | task_loss 0 | contrastive_loss 0.255 | total 4003.4 | n_correct 2486.1 | ppl 7.12 | accuracy 62.1 | uer 17.01 | wer 19.09 | raw_wer 19.09 | bleu 20.18 | wps 2046.1 | wpb 4003.4 | bsz 141.8 | num_updates 36835 | best_bleu 20.33
2023-07-01 20:29:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36835 updates
2023-07-01 20:29:53 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_20.1804.pt
2023-07-01 20:29:56 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_20.1804.pt
2023-07-01 20:29:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_20.1804.pt (epoch 25 @ 36835 updates, score 20.18) (writing took 5.299368964973837 seconds)
2023-07-01 20:29:59 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-07-01 20:29:59 | INFO | train | epoch 025 | loss 3.779 | trans_loss 5.222 | nll_loss 2.489 | w2v_ctc_loss 1.164 | task_loss 2 | contrastive_loss 0.212 | total 4138.65 | n_correct 2732.19 | ppl 5.61 | accuracy 66.017 | wps 5290.2 | ups 1.28 | wpb 4138.6 | bsz 152.8 | num_updates 36835 | lr 7.36859e-05 | gnorm 0.961 | clip 0 | loss_scale 64 | train_wall 1077 | gb_free 14.6 | wall 33306
2023-07-01 20:29:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 20:29:59 | INFO | fairseq.trainer | begin training epoch 26
2023-07-01 20:29:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 20:30:55 | INFO | train_inner | epoch 026:     65 / 1474 loss=3.746, trans_loss=5.194, nll_loss=2.452, w2v_ctc_loss=1.142, task_loss=2, contrastive_loss=0.17, total=4178.19, n_correct=2778.5, ppl=5.47, accuracy=66.5, wps=3667.9, ups=0.88, wpb=4178.2, bsz=158.7, num_updates=36900, lr=7.3621e-05, gnorm=0.955, clip=0, loss_scale=64, train_wall=73, gb_free=14.5, wall=33362
2023-07-01 20:32:09 | INFO | train_inner | epoch 026:    165 / 1474 loss=3.743, trans_loss=5.187, nll_loss=2.445, w2v_ctc_loss=1.11, task_loss=2, contrastive_loss=0.537, total=4269.55, n_correct=2844.9, ppl=5.44, accuracy=66.632, wps=5781.9, ups=1.35, wpb=4269.6, bsz=170.7, num_updates=37000, lr=7.35215e-05, gnorm=0.931, clip=0, loss_scale=64, train_wall=73, gb_free=15.6, wall=33436
2023-07-01 20:33:22 | INFO | train_inner | epoch 026:    265 / 1474 loss=3.767, trans_loss=5.201, nll_loss=2.461, w2v_ctc_loss=1.159, task_loss=2, contrastive_loss=0.289, total=4128.39, n_correct=2737.88, ppl=5.51, accuracy=66.318, wps=5634.4, ups=1.36, wpb=4128.4, bsz=153.4, num_updates=37100, lr=7.34223e-05, gnorm=0.96, clip=0, loss_scale=64, train_wall=73, gb_free=10.6, wall=33510
2023-07-01 20:34:35 | INFO | train_inner | epoch 026:    365 / 1474 loss=3.755, trans_loss=5.199, nll_loss=2.459, w2v_ctc_loss=1.149, task_loss=2, contrastive_loss=0.206, total=4166.22, n_correct=2763.91, ppl=5.5, accuracy=66.341, wps=5716.7, ups=1.37, wpb=4166.2, bsz=157.5, num_updates=37200, lr=7.33236e-05, gnorm=0.969, clip=0, loss_scale=64, train_wall=72, gb_free=17, wall=33582
2023-07-01 20:35:48 | INFO | train_inner | epoch 026:    465 / 1474 loss=3.756, trans_loss=5.195, nll_loss=2.453, w2v_ctc_loss=1.148, task_loss=2, contrastive_loss=0.294, total=4171.18, n_correct=2774.78, ppl=5.48, accuracy=66.523, wps=5717.4, ups=1.37, wpb=4171.2, bsz=157.7, num_updates=37300, lr=7.32252e-05, gnorm=0.945, clip=0, loss_scale=64, train_wall=72, gb_free=16.9, wall=33655
2023-07-01 20:37:01 | INFO | train_inner | epoch 026:    565 / 1474 loss=3.775, trans_loss=5.21, nll_loss=2.472, w2v_ctc_loss=1.178, task_loss=2, contrastive_loss=0.135, total=4139.82, n_correct=2739.35, ppl=5.55, accuracy=66.171, wps=5655, ups=1.37, wpb=4139.8, bsz=150, num_updates=37400, lr=7.31272e-05, gnorm=0.967, clip=0, loss_scale=64, train_wall=73, gb_free=15.3, wall=33729
2023-07-01 20:38:14 | INFO | train_inner | epoch 026:    665 / 1474 loss=3.757, trans_loss=5.203, nll_loss=2.464, w2v_ctc_loss=1.145, task_loss=2, contrastive_loss=0.111, total=4146.72, n_correct=2750.74, ppl=5.52, accuracy=66.335, wps=5671.3, ups=1.37, wpb=4146.7, bsz=151.4, num_updates=37500, lr=7.30297e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=73, gb_free=17.1, wall=33802
2023-07-01 20:39:27 | INFO | train_inner | epoch 026:    765 / 1474 loss=3.784, trans_loss=5.216, nll_loss=2.481, w2v_ctc_loss=1.155, task_loss=2, contrastive_loss=0.333, total=4084.89, n_correct=2698.35, ppl=5.58, accuracy=66.057, wps=5619.9, ups=1.38, wpb=4084.9, bsz=148.6, num_updates=37600, lr=7.29325e-05, gnorm=0.98, clip=0, loss_scale=64, train_wall=72, gb_free=17.4, wall=33874
2023-07-01 20:40:40 | INFO | train_inner | epoch 026:    865 / 1474 loss=3.765, trans_loss=5.211, nll_loss=2.473, w2v_ctc_loss=1.158, task_loss=2, contrastive_loss=0.139, total=4180.78, n_correct=2765.98, ppl=5.55, accuracy=66.159, wps=5731.7, ups=1.37, wpb=4180.8, bsz=154.8, num_updates=37700, lr=7.28357e-05, gnorm=0.965, clip=0, loss_scale=64, train_wall=73, gb_free=16.2, wall=33947
2023-07-01 20:41:53 | INFO | train_inner | epoch 026:    965 / 1474 loss=3.781, trans_loss=5.221, nll_loss=2.487, w2v_ctc_loss=1.148, task_loss=2, contrastive_loss=0.247, total=4147.79, n_correct=2737.52, ppl=5.6, accuracy=65.999, wps=5665.1, ups=1.37, wpb=4147.8, bsz=149.8, num_updates=37800, lr=7.27393e-05, gnorm=0.961, clip=0, loss_scale=64, train_wall=73, gb_free=12.9, wall=34021
2023-07-01 20:43:06 | INFO | train_inner | epoch 026:   1065 / 1474 loss=3.776, trans_loss=5.215, nll_loss=2.479, w2v_ctc_loss=1.166, task_loss=2, contrastive_loss=0.109, total=4118.07, n_correct=2721.35, ppl=5.58, accuracy=66.083, wps=5632.6, ups=1.37, wpb=4118.1, bsz=146.8, num_updates=37900, lr=7.26433e-05, gnorm=0.973, clip=0, loss_scale=64, train_wall=73, gb_free=16, wall=34094
2023-07-01 20:44:20 | INFO | train_inner | epoch 026:   1165 / 1474 loss=3.785, trans_loss=5.225, nll_loss=2.491, w2v_ctc_loss=1.168, task_loss=2, contrastive_loss=0.189, total=4108.48, n_correct=2707.81, ppl=5.62, accuracy=65.908, wps=5578.6, ups=1.36, wpb=4108.5, bsz=149, num_updates=38000, lr=7.25476e-05, gnorm=0.972, clip=0, loss_scale=128, train_wall=73, gb_free=16.8, wall=34167
2023-07-01 20:44:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 20:44:45 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.348 | trans_loss 5.562 | nll_loss 2.835 | w2v_ctc_loss 1.403 | task_loss 0 | contrastive_loss 0.252 | total 4003.4 | n_correct 2489.2 | ppl 7.14 | accuracy 62.177 | uer 16.866 | wer 18.788 | raw_wer 18.788 | bleu 20.1 | wps 2165.2 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.33
2023-07-01 20:44:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-07-01 20:44:45 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_26_38000.pt
2023-07-01 20:44:47 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_26_38000.pt
2023-07-01 20:44:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 20.1) (writing took 6.447995241265744 seconds)
2023-07-01 20:46:06 | INFO | train_inner | epoch 026:   1265 / 1474 loss=3.8, trans_loss=5.236, nll_loss=2.505, w2v_ctc_loss=1.189, task_loss=2, contrastive_loss=0.114, total=4005.94, n_correct=2636.12, ppl=5.68, accuracy=65.805, wps=3780.8, ups=0.94, wpb=4005.9, bsz=140.3, num_updates=38100, lr=7.24524e-05, gnorm=0.986, clip=0, loss_scale=128, train_wall=73, gb_free=16.6, wall=34273
2023-07-01 20:47:19 | INFO | train_inner | epoch 026:   1365 / 1474 loss=3.766, trans_loss=5.22, nll_loss=2.487, w2v_ctc_loss=1.143, task_loss=2, contrastive_loss=0.131, total=4146.34, n_correct=2740.72, ppl=5.6, accuracy=66.1, wps=5624.5, ups=1.36, wpb=4146.3, bsz=153.8, num_updates=38200, lr=7.23575e-05, gnorm=0.975, clip=0, loss_scale=128, train_wall=73, gb_free=15.8, wall=34347
2023-07-01 20:48:33 | INFO | train_inner | epoch 026:   1465 / 1474 loss=3.757, trans_loss=5.216, nll_loss=2.481, w2v_ctc_loss=1.146, task_loss=2, contrastive_loss=0.139, total=4172.4, n_correct=2762.25, ppl=5.58, accuracy=66.203, wps=5693, ups=1.36, wpb=4172.4, bsz=160, num_updates=38300, lr=7.22629e-05, gnorm=0.956, clip=0, loss_scale=128, train_wall=73, gb_free=16.4, wall=34420
2023-07-01 20:48:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 20:49:04 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.347 | trans_loss 5.558 | nll_loss 2.833 | w2v_ctc_loss 1.411 | task_loss 0 | contrastive_loss 0.255 | total 4003.4 | n_correct 2490.1 | ppl 7.12 | accuracy 62.2 | uer 16.951 | wer 18.784 | raw_wer 18.784 | bleu 20.01 | wps 2353.5 | wpb 4003.4 | bsz 141.8 | num_updates 38309 | best_bleu 20.33
2023-07-01 20:49:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38309 updates
2023-07-01 20:49:04 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_20.0103.pt
2023-07-01 20:49:06 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_20.0103.pt
2023-07-01 20:49:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_20.0103.pt (epoch 26 @ 38309 updates, score 20.01) (writing took 5.1406071381643414 seconds)
2023-07-01 20:49:09 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-07-01 20:49:09 | INFO | train | epoch 026 | loss 3.767 | trans_loss 5.209 | nll_loss 2.472 | w2v_ctc_loss 1.153 | task_loss 2 | contrastive_loss 0.212 | total 4138.65 | n_correct 2740.62 | ppl 5.55 | accuracy 66.22 | wps 5303.4 | ups 1.28 | wpb 4138.6 | bsz 152.8 | num_updates 38309 | lr 7.22544e-05 | gnorm 0.964 | clip 0 | loss_scale 128 | train_wall 1073 | gb_free 16.2 | wall 34457
2023-07-01 20:49:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 20:49:09 | INFO | fairseq.trainer | begin training epoch 27
2023-07-01 20:49:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 20:50:23 | INFO | train_inner | epoch 027:     91 / 1474 loss=3.738, trans_loss=5.168, nll_loss=2.416, w2v_ctc_loss=1.129, task_loss=2, contrastive_loss=0.088, total=4051.87, n_correct=2708.77, ppl=5.34, accuracy=66.852, wps=3665.4, ups=0.9, wpb=4051.9, bsz=140.6, num_updates=38400, lr=7.21688e-05, gnorm=0.979, clip=0, loss_scale=128, train_wall=72, gb_free=16.9, wall=34531
2023-07-01 20:51:37 | INFO | train_inner | epoch 027:    191 / 1474 loss=3.724, trans_loss=5.173, nll_loss=2.424, w2v_ctc_loss=1.132, task_loss=2, contrastive_loss=0.148, total=4197.99, n_correct=2804.43, ppl=5.37, accuracy=66.804, wps=5684.7, ups=1.35, wpb=4198, bsz=162.2, num_updates=38500, lr=7.2075e-05, gnorm=0.955, clip=0, loss_scale=128, train_wall=73, gb_free=16.9, wall=34605
2023-07-01 20:52:51 | INFO | train_inner | epoch 027:    291 / 1474 loss=3.743, trans_loss=5.187, nll_loss=2.441, w2v_ctc_loss=1.141, task_loss=2, contrastive_loss=0.11, total=4161.57, n_correct=2772.64, ppl=5.43, accuracy=66.625, wps=5660.2, ups=1.36, wpb=4161.6, bsz=152.7, num_updates=38600, lr=7.19816e-05, gnorm=0.962, clip=0, loss_scale=128, train_wall=73, gb_free=15.6, wall=34678
2023-07-01 20:54:05 | INFO | train_inner | epoch 027:    391 / 1474 loss=3.779, trans_loss=5.203, nll_loss=2.463, w2v_ctc_loss=1.146, task_loss=2, contrastive_loss=0.472, total=4085.81, n_correct=2711.31, ppl=5.51, accuracy=66.359, wps=5515.4, ups=1.35, wpb=4085.8, bsz=149.1, num_updates=38700, lr=7.18885e-05, gnorm=0.968, clip=0, loss_scale=128, train_wall=74, gb_free=15.7, wall=34752
2023-07-01 20:54:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-01 20:55:20 | INFO | train_inner | epoch 027:    492 / 1474 loss=3.752, trans_loss=5.199, nll_loss=2.459, w2v_ctc_loss=1.135, task_loss=2, contrastive_loss=0.315, total=4218.5, n_correct=2804.42, ppl=5.5, accuracy=66.479, wps=5635.8, ups=1.34, wpb=4218.5, bsz=162.6, num_updates=38800, lr=7.17958e-05, gnorm=0.944, clip=0, loss_scale=64, train_wall=74, gb_free=15.9, wall=34827
2023-07-01 20:56:33 | INFO | train_inner | epoch 027:    592 / 1474 loss=3.748, trans_loss=5.193, nll_loss=2.451, w2v_ctc_loss=1.138, task_loss=2, contrastive_loss=0.224, total=4137.92, n_correct=2752.56, ppl=5.47, accuracy=66.52, wps=5670.5, ups=1.37, wpb=4137.9, bsz=156.7, num_updates=38900, lr=7.17035e-05, gnorm=0.959, clip=0, loss_scale=64, train_wall=73, gb_free=16.1, wall=34900
2023-07-01 20:57:46 | INFO | train_inner | epoch 027:    692 / 1474 loss=3.768, trans_loss=5.206, nll_loss=2.467, w2v_ctc_loss=1.155, task_loss=2, contrastive_loss=0.188, total=4158.48, n_correct=2758.32, ppl=5.53, accuracy=66.33, wps=5658.5, ups=1.36, wpb=4158.5, bsz=152, num_updates=39000, lr=7.16115e-05, gnorm=0.962, clip=0, loss_scale=64, train_wall=73, gb_free=15.9, wall=34974
2023-07-01 20:58:59 | INFO | train_inner | epoch 027:    792 / 1474 loss=3.763, trans_loss=5.201, nll_loss=2.461, w2v_ctc_loss=1.154, task_loss=2, contrastive_loss=0.11, total=4100.88, n_correct=2720.68, ppl=5.5, accuracy=66.344, wps=5600.2, ups=1.37, wpb=4100.9, bsz=146.1, num_updates=39100, lr=7.15199e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=73, gb_free=15.9, wall=35047
2023-07-01 21:00:12 | INFO | train_inner | epoch 027:    892 / 1474 loss=3.756, trans_loss=5.203, nll_loss=2.463, w2v_ctc_loss=1.132, task_loss=2, contrastive_loss=0.101, total=4111.94, n_correct=2727.49, ppl=5.52, accuracy=66.331, wps=5648.3, ups=1.37, wpb=4111.9, bsz=147.4, num_updates=39200, lr=7.14286e-05, gnorm=0.964, clip=0, loss_scale=64, train_wall=72, gb_free=16.5, wall=35120
2023-07-01 21:01:26 | INFO | train_inner | epoch 027:    992 / 1474 loss=3.775, trans_loss=5.207, nll_loss=2.47, w2v_ctc_loss=1.145, task_loss=2, contrastive_loss=0.47, total=4189.27, n_correct=2777.62, ppl=5.54, accuracy=66.303, wps=5673.8, ups=1.35, wpb=4189.3, bsz=157.5, num_updates=39300, lr=7.13376e-05, gnorm=0.96, clip=0, loss_scale=64, train_wall=73, gb_free=14.6, wall=35194
2023-07-01 21:02:39 | INFO | train_inner | epoch 027:   1092 / 1474 loss=3.75, trans_loss=5.197, nll_loss=2.456, w2v_ctc_loss=1.14, task_loss=2, contrastive_loss=0.134, total=4160.42, n_correct=2764.14, ppl=5.49, accuracy=66.439, wps=5657.4, ups=1.36, wpb=4160.4, bsz=153.7, num_updates=39400, lr=7.1247e-05, gnorm=0.951, clip=0, loss_scale=64, train_wall=73, gb_free=17.2, wall=35267
2023-07-01 21:03:53 | INFO | train_inner | epoch 027:   1192 / 1474 loss=3.765, trans_loss=5.206, nll_loss=2.468, w2v_ctc_loss=1.152, task_loss=2, contrastive_loss=0.14, total=4103.72, n_correct=2718.9, ppl=5.53, accuracy=66.255, wps=5566.2, ups=1.36, wpb=4103.7, bsz=148.6, num_updates=39500, lr=7.11568e-05, gnorm=0.971, clip=0, loss_scale=64, train_wall=73, gb_free=17.8, wall=35341
2023-07-01 21:05:06 | INFO | train_inner | epoch 027:   1292 / 1474 loss=3.784, trans_loss=5.22, nll_loss=2.486, w2v_ctc_loss=1.155, task_loss=2, contrastive_loss=0.251, total=4065.94, n_correct=2681.6, ppl=5.6, accuracy=65.953, wps=5568, ups=1.37, wpb=4065.9, bsz=146.2, num_updates=39600, lr=7.10669e-05, gnorm=0.993, clip=0, loss_scale=64, train_wall=73, gb_free=16.3, wall=35414
2023-07-01 21:06:19 | INFO | train_inner | epoch 027:   1392 / 1474 loss=3.763, trans_loss=5.211, nll_loss=2.475, w2v_ctc_loss=1.147, task_loss=2, contrastive_loss=0.21, total=4149.21, n_correct=2745.04, ppl=5.56, accuracy=66.158, wps=5715, ups=1.38, wpb=4149.2, bsz=156.3, num_updates=39700, lr=7.09773e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=72, gb_free=17, wall=35486
2023-07-01 21:07:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 21:07:43 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.351 | trans_loss 5.563 | nll_loss 2.839 | w2v_ctc_loss 1.413 | task_loss 0 | contrastive_loss 0.245 | total 4003.4 | n_correct 2482.5 | ppl 7.16 | accuracy 62.01 | uer 16.975 | wer 18.81 | raw_wer 18.81 | bleu 20.09 | wps 2250.4 | wpb 4003.4 | bsz 141.8 | num_updates 39782 | best_bleu 20.33
2023-07-01 21:07:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39782 updates
2023-07-01 21:07:43 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_20.0903.pt
2023-07-01 21:07:46 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_20.0903.pt
2023-07-01 21:07:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint.best_bleu_20.0903.pt (epoch 27 @ 39782 updates, score 20.09) (writing took 5.495939599815756 seconds)
2023-07-01 21:07:49 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-07-01 21:07:49 | INFO | train | epoch 027 | loss 3.756 | trans_loss 5.198 | nll_loss 2.457 | w2v_ctc_loss 1.142 | task_loss 2 | contrastive_loss 0.209 | total 4137.5 | n_correct 2748.02 | ppl 5.49 | accuracy 66.417 | wps 5440.7 | ups 1.31 | wpb 4137.5 | bsz 152.7 | num_updates 39782 | lr 7.09042e-05 | gnorm 0.963 | clip 0 | loss_scale 64 | train_wall 1075 | gb_free 17.9 | wall 35577
2023-07-01 21:07:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-01 21:07:49 | INFO | fairseq.trainer | begin training epoch 28
2023-07-01 21:07:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-01 21:08:11 | INFO | train_inner | epoch 028:     18 / 1474 loss=3.739, trans_loss=5.19, nll_loss=2.448, w2v_ctc_loss=1.125, task_loss=2, contrastive_loss=0.113, total=4106.72, n_correct=2732.64, ppl=5.46, accuracy=66.541, wps=3674.1, ups=0.89, wpb=4106.7, bsz=152.5, num_updates=39800, lr=7.08881e-05, gnorm=0.966, clip=0, loss_scale=64, train_wall=73, gb_free=16.4, wall=35598
2023-07-01 21:09:23 | INFO | train_inner | epoch 028:    118 / 1474 loss=3.739, trans_loss=5.17, nll_loss=2.42, w2v_ctc_loss=1.142, task_loss=2, contrastive_loss=0.107, total=4103.42, n_correct=2746.62, ppl=5.35, accuracy=66.935, wps=5635, ups=1.37, wpb=4103.4, bsz=146, num_updates=39900, lr=7.07992e-05, gnorm=0.974, clip=0, loss_scale=64, train_wall=72, gb_free=16.3, wall=35671
2023-07-01 21:10:37 | INFO | train_inner | epoch 028:    218 / 1474 loss=3.715, trans_loss=5.163, nll_loss=2.411, w2v_ctc_loss=1.115, task_loss=2, contrastive_loss=0.121, total=4200.12, n_correct=2815.14, ppl=5.32, accuracy=67.025, wps=5736, ups=1.37, wpb=4200.1, bsz=158.9, num_updates=40000, lr=7.07107e-05, gnorm=0.953, clip=0, loss_scale=64, train_wall=73, gb_free=11.5, wall=35744
2023-07-01 21:10:37 | INFO | fairseq_cli.train | Stopping training due to num_updates: 40000 >= max_update: 40000
2023-07-01 21:10:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-01 21:11:03 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.339 | trans_loss 5.561 | nll_loss 2.835 | w2v_ctc_loss 1.378 | task_loss 0 | contrastive_loss 0.242 | total 4003.4 | n_correct 2492.8 | ppl 7.14 | accuracy 62.267 | uer 16.651 | wer 18.571 | raw_wer 18.571 | bleu 20.08 | wps 2195 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.33
2023-07-01 21:11:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-07-01 21:11:03 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_28_40000.pt
2023-07-01 21:11:05 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT/checkpoint_28_40000.pt
2023-07-01 21:11:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 20.08) (writing took 5.996508123818785 seconds)
2023-07-01 21:11:09 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-07-01 21:11:09 | INFO | train | epoch 028 | loss 3.727 | trans_loss 5.166 | nll_loss 2.416 | w2v_ctc_loss 1.127 | task_loss 2 | contrastive_loss 0.112 | total 4143.1 | n_correct 2774.95 | ppl 5.34 | accuracy 66.978 | wps 4511.8 | ups 1.09 | wpb 4143.1 | bsz 151.5 | num_updates 40000 | lr 7.07107e-05 | gnorm 0.966 | clip 0 | loss_scale 64 | train_wall 158 | gb_free 11.5 | wall 35777
2023-07-01 21:11:09 | INFO | fairseq_cli.train | done training in 35706.9 seconds
/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1200 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
